name: Run ArXiv Crawler Daily

# Schedule to run every day at midnight UTC
on:
  schedule:
    - cron: '0 5 * * *' # Run daily at midnight Eastern Time (5 a.m. UTC)

  # Allow manual triggering of the workflow
  workflow_dispatch:

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v3

    # Step 2: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9' # Use the version compatible with your script

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Step 4: Run the script
    - name: Run ArXiv Crawler
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        python crawl_arxiv_eees.py

    - name: Commit and Push Changes
      if: success()
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add .
        git commit -m "Update arxiv_eess HTML file [skip ci]"
        git push
