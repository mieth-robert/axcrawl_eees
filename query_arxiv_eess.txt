
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Dueling QR Codes: The Hyding of Dr. Jeckyl
Authors: David Noever, Forrest McKee
Abstract: The paper presents a novel technique for encoding dual messages within standard Quick Response (QR) codes through precise half-pixel module splitting. This work challenges fundamental assumptions about deterministic decoding in the ISO/IEC 18004:2015 standard while maintaining complete compatibility with existing QR infrastructure. The proposed two-dimensional barcode attack enables angle-dependent message selection while maintaining compatibility with unmodified QR readers and the 100 million US mobile users who use their phone's built-in scanners. Unlike previous approaches that rely on nested codes, watermarking, or error correction exploitation, our method achieves true one-to-many mapping by manipulating the physical sampling process built into the QR standard. By preserving critical function patterns while bifurcating data modules, we create automated codes that produce different but valid readings based on camera viewing angle. Experimental results demonstrate successful implementation across multiple use cases, including simple message text pairs, complex URLs (this http URL), and security test patterns for malware and spam detectors (EICAR/GTUBE). Our technique achieves reliable dual-message decoding using standard QR readers at module scales of 9-11 pixels, with successful angle-dependent reading demonstrated across vertical, horizontal, and diagonal orientations. The method's success suggests potential applications beyond QR code phishing ('quishing') including two-factor authentication, anti-counterfeiting, and information density optimization. The half-pixel technique may offer future avenues for similar implementations in other 2D barcode formats such as Data Matrix and Aztec Code.

Paper number 2:
Title: BodySense: An Expandable and Wearable-Sized Wireless Evaluation Platform for Human Body Communication
Authors: Lukas Schulthess, Philipp Mayer, Christian Vogt, Luca Benini, Michele Magno
Abstract: Wearable, wirelessly connected sensors have become a common part of daily life and have the potential to play a pivotal role in shaping the future of personalized healthcare. A key challenge in this evolution is designing long-lasting and unobtrusive devices. These design requirements inherently demand smaller batteries, inevitably increasing the need for energy-sensitive wireless communication interfaces. Capacitive Human Body Communication (HBC) is a promising, power-efficient alternative to traditional RF-based communication, enabling point-to-multipoint data and energy exchange. However, as this concept relies on capacitive coupling to the surrounding area, it is naturally influenced by uncontrollable environmental factors, making testing with classical setups particularly challenging. This work presents a customizable, wearable-sized, wireless evaluation platform for capacitive HBC, designed to enable realistic evaluation of wearable-to-wearable applications. Comparative measurements of channel gains were conducted using classical grid-connected and wireless Data Acquisition (DAQ) across various transmission distances within the frequency range of 4 MHz to 64 MHz and revealed an average overestimation of 18.15 dB over all investigated distances in the classical setup.

Paper number 3:
Title: A novel Fourier Adjacency Transformer for advanced EEG emotion recognition
Authors: Jinfeng Wang, Yanhao Huang, Sifan Song, Boqian Wang, Jionglong Su, Jiaman Ding
Abstract: EEG emotion recognition faces significant hurdles due to noise interference, signal nonstationarity, and the inherent complexity of brain activity which make accurately emotion classification. In this study, we present the Fourier Adjacency Transformer, a novel framework that seamlessly integrates Fourier-based periodic analysis with graph-driven structural modeling. Our method first leverages novel Fourier-inspired modules to extract periodic features from embedded EEG signals, effectively decoupling them from aperiodic components. Subsequently, we employ an adjacency attention scheme to reinforce universal inter-channel correlation patterns, coupling these patterns with their sample-based counterparts. Empirical evaluations on SEED and DEAP datasets demonstrate that our method surpasses existing state-of-the-art techniques, achieving an improvement of approximately 6.5% in recognition accuracy. By unifying periodicity and structural insights, this framework offers a promising direction for future research in EEG emotion analysis.

Paper number 4:
Title: A comprehensive review of sensor technologies, instrumentation, and signal processing solutions for low-power Internet of Things systems with mini-computing devices
Authors: Alexandros Gazis, Ioannis Papadongonas, Athanasios Andriopoulos, Constantinos Zioudas, Theodoros Vavouras
Abstract: This article provides a comprehensive overview of sensors commonly used in low-cost, low-power systems, focusing on key concepts such as Internet of Things (IoT), Big Data, and smart sensor technologies. It outlines the evolving roles of sensors, emphasizing their characteristics, technological advancements, and the transition toward "smart sensors" with integrated processing capabilities. The article also explores the growing importance of mini-computing devices in educational environments. These devices provide cost-effective and energy-efficient solutions for system monitoring, prototype validation, and real-world application development. By interfacing with wireless sensor networks and IoT systems, mini-computers enable students and researchers to design, test, and deploy sensor-based systems with minimal resource requirements. Furthermore, this article examines the most widely used sensors, detailing their properties and modes of operation to help readers understand how sensor systems function. The aim of this study is to provide an overview of the most suitable sensors for various applications by explaining their uses and operations in simple terms. This clarity will assist researchers in selecting the appropriate sensors for educational and research purposes or understanding why specific sensors were chosen, along with their capabilities and possible limitations. Ultimately, this research seeks to equip future engineers with the knowledge and tools needed to integrate cutting-edge sensor networks, IoT, and Big Data technologies into scalable, real-world solutions.

Paper number 5:
Title: A CGAN-LSTM-Based Framework for Time-Varying Non-Stationary Channel Modeling
Authors: Keying Guo, Ruisi He, Mi Yang, Yuxin Zhang, Bo Ai, Haoxiang Zhang, Jiahui Han, Ruifeng Chen
Abstract: Time-varying non-stationary channels, with complex dynamic variations and temporal evolution characteristics, have significant challenges in channel modeling and communication system performance evaluation. Most existing methods of time-varying channel modeling focus on predicting channel state at a given moment or simulating short-term channel fluctuations, which are unable to capture the long-term evolution of the channel. This paper emphasizes the generation of long-term dynamic channel to fully capture evolution of non-stationary channel properties. The generated channel not only reflects temporal dynamics but also ensures consistent stationarity. We propose a hybrid deep learning framework that combines conditional generative adversarial networks (CGAN) with long short-term memory (LSTM) networks. A stationarity-constrained approach is designed to ensure temporal correlation of the generated time-series channel. This method can generate channel with required temporal non-stationarity. The model is validated by comparing channel statistical features, and the results show that the generated channel is in good agreement with raw channel and provides good performance in terms of non-stationarity.

Paper number 6:
Title: Conditional Electrocardiogram Generation Using Hierarchical Variational Autoencoders
Authors: Ivan Sviridov, Konstantin Egorov
Abstract: Cardiovascular diseases (CVDs) are disorders impacting the heart and circulatory system. These disorders are the foremost and continuously escalating cause of mortality worldwide. One of the main tasks when working with CVDs is analyzing and identifying pathologies on a 12-lead electrocardiogram (ECG) with a standard 10-second duration. Using machine learning (ML) in automatic ECG analysis increases CVD diagnostics' availability, speed, and accuracy. However, the most significant difficulty in developing ML models is obtaining a sufficient training dataset. Due to the limitations of medical data usage, such as expensiveness, errors, the ambiguity of labels, imbalance of classes, and privacy issues, utilizing synthetic samples depending on specific pathologies bypasses these restrictions and improves algorithm quality. Existing solutions for the conditional generation of ECG signals are mainly built on Generative Adversarial Networks (GANs), and only a few papers consider the architectures based on Variational Autoencoders (VAEs), showing comparable results in recent works. This paper proposes the publicly available conditional Nouveau VAE model for ECG signal generation (cNVAE-ECG), which produces high-resolution ECGs with multiple pathologies. We provide an extensive comparison of the proposed model on various practical downstream tasks, including transfer learning scenarios showing an area under the receiver operating characteristic (AUROC) increase up to 2% surpassing GAN-like competitors.

Paper number 7:
Title: Multimodal Lead-Specific Modeling of ECG for Low-Cost Pulmonary Hypertension Assessment
Authors: Mohammod N. I. Suvon, Shuo Zhou, Prasun C. Tripathi, Wenrui Fan, Samer Alabed, Bishesh Khanal, Venet Osmani, Andrew J. Swift, Chen (Cherise)Chen, Haiping Lu
Abstract: Pulmonary hypertension (PH) is frequently underdiagnosed in low- and middle-income countries (LMICs) primarily due to the scarcity of advanced diagnostic tools. Several studies in PH have applied machine learning to low-cost diagnostic tools like 12-lead ECG (12L-ECG), but they mainly focus on areas with limited resources, overlooking areas with no diagnostic tools, such as rural primary healthcare in LMICs. Recent studies have shown the effectiveness of 6-lead ECG (6L-ECG), as a cheaper and portable alternative in detecting various cardiac conditions, but its clinical value for PH detection is not well proved. Furthermore, existing methods treat 12L-/6L-ECG as a single modality, capturing only shared features while overlooking lead-specific features essential for identifying complex cardiac hemodynamic changes. In this paper, we propose Lead-Specific Electrocardiogram Multimodal Variational Autoencoder (LS-EMVAE), a model pre-trained on large-population 12L-ECG data and fine-tuned on task-specific data (12L-ECG or 6L-ECG). LS-EMVAE models each 12L-ECG lead as a separate modality and introduces a hierarchical expert composition using Mixture and Product of Experts for adaptive latent feature fusion between lead-specific and shared features. Unlike existing approaches, LS-EMVAE makes better predictions on both 12L-ECG and 6L-ECG at inference, making it an equitable solution for areas with limited or no diagnostic tools. We pre-trained LS-EMVAE on 800,000 publicly available 12L-ECG samples and fine-tuned it for two tasks: 1) PH detection and 2) phenotyping pre-/post-capillary PH, on in-house datasets of 892 and 691 subjects across 12L-ECG and 6L-ECG settings. Extensive experiments show that LS-EMVAE outperforms existing baselines in both ECG settings, while 6L-ECG achieves performance comparable to 12L-ECG, unlocking its potential for global PH screening in areas without diagnostic tools.

Paper number 8:
Title: Medical Support System for Spontaneous Breathing Trial Prediction Using Nonuniform Discrete Fourier Transform
Authors: Hernando Gonzalez, Carlos Julio Arizmendi, Beatriz F. Giraldo
Abstract: Spontaneous breathing trials (SBTs) represent a pivotal phase in the weaning process of mechanically ventilated patients. The objective of these trials is to assess patients readiness to resume independent breathing, thereby facilitating timely weaning and reducing the duration of mechanical ventilation (MV). Nevertheless, accurately predicting the success or failure of SBT remains a significant challenge in clinical practice. This study proposes a healthcare system that employs machine learning techniques to predict the outcome of SBT. The model is trained on respiratory flow and electrocardiogram (ECG) signals, employing the non-uniform discrete Fourier transform (NUDFT) for frequency domain analysis. The SBT prediction model has the potential to significantly enhance clinical decision-making by enabling the early identification of patients at risk for SBT failure, achieving an accuracy of 84.4.

Paper number 9:
Title: Toward Scalable Access to Neurodevelopmental Screening: Insights, Implementation, and Challenges
Authors: Andreas Bauer, William Bosl, Oliver Aalami, Paul Schmiedmayer
Abstract: Children with neurodevelopmental disorders require timely intervention to improve long-term outcomes, yet early screening remains inaccessible in many regions. A scalable solution integrating standardized assessments with physiological data collection, such as electroencephalogram (EEG) recordings, could enable early detection in routine settings by non-specialists. To address this, we introduce NeuroNest, a mobile and cloud-based platform for large-scale EEG data collection, neurodevelopmental screening, and research. We provide a comprehensive review of existing behavioral and biomarker-based approaches, consumer-grade EEG devices, and emerging machine learning techniques. NeuroNest integrates low-cost EEG devices with digital screening tools, establishing a scalable, open-source infrastructure for non-invasive data collection, automated analysis, and interoperability across diverse hardware. Beyond the system architecture and reference implementation, we highlight key challenges in EEG data standardization, device interoperability, and bridging behavioral and physiological assessments. Our findings emphasize the need for future research on standardized data exchange, algorithm validation, and ecosystem development to expand screening accessibility. By providing an extensible, open-source system, NeuroNest advances machine learning-based early detection while fostering collaboration in screening technologies, clinical applications, and public health.

Paper number 10:
Title: Robust Detection of Extremely Thin Lines Using 0.2mm Piano Wire
Authors: Jisoo Hong, Youngjin Jung, Jihwan Bae, Seungho Song, Sung-Woo Kang
Abstract: This study developed an algorithm capable of detecting a reference line (a 0.2 mm thick piano wire) to accurately determine the position of an automated installation robot within an elevator shaft. A total of 3,245 images were collected from the experimental tower of H Company, the leading elevator manufacturer in South Korea, and the detection performance was evaluated using four experimental approaches (GCH, GSCH, GECH, FCH). During the initial image processing stage, Gaussian blurring, sharpening filter, embossing filter, and Fourier Transform were applied, followed by Canny Edge Detection and Hough Transform. Notably, the method was developed to accurately extract the reference line by averaging the x-coordinates of the lines detected through the Hough Transform. This approach enabled the detection of the 0.2 mm thick piano wire with high accuracy, even in the presence of noise and other interfering factors (e.g., concrete cracks inside the elevator shaft or safety bars for filming equipment). The experimental results showed that Experiment 4 (FCH), which utilized Fourier Transform in the preprocessing stage, achieved the highest detection rate for the LtoL, LtoR, and RtoL datasets. Experiment 2(GSCH), which applied Gaussian blurring and a sharpening filter, demonstrated superior detection performance on the RtoR dataset. This study proposes a reference line detection algorithm that enables precise position calculation and control of automated robots in elevator shaft installation. Moreover, the developed method shows potential for applicability even in confined working spaces. Future work aims to develop a line detection algorithm equipped with machine learning-based hyperparameter tuning capabilities.

Paper number 11:
Title: ISLS: An IoT-Based Smart Lighting System for Improving Energy Conservation in Office Buildings
Authors: Peace Obioma, Obinna Agbodike, Jenhui Chen, Lei Wang
Abstract: With the Internet of Things (IoT) fostering seamless device-to-human and device-to-device interactions, the domain of intelligent lighting systems have evolved beyond simple occupancy and daylight sensing towards autonomous monitoring and control of power consumption and illuminance levels. To this regard, this paper proposes a new do-it-yourself (DIY) IoT-based method of smart lighting system featuring an illuminance control algorithm. The design involves the integration of occupancy and presence sensors alongside a communication module, to enable real-time wireless interaction and remote monitoring of the system parameters from any location through an end-user application. A constrained optimization problem was formulated to determine the optimal dimming vector for achieving target illuminance at minimal power consumption. The simplex algorithm was used to solve this problem, and the system's performance was validated through both MATLAB simulations and real-world prototype testing in an indoor office environment. The obtained experimental results demonstrate substantial power savings across multiple user occupancy scenarios, achieving reductions of approx. 80%, 48%, and 26% for one, two, and four user settings, respectively, in comparison to traditional basic lighting installation systems.

Paper number 12:
Title: Cross-Subject Depression Level Classification Using EEG Signals with a Sample Confidence Method
Authors: ZhongYi Zhang, ChenYang Xu, LiXuan Zhao, HuiRang Hou, QingHao Meng
Abstract: Electroencephalogram (EEG) is a non-invasive tool for real-time neural monitoring,widely used in depression detection via deep learning. However, existing models primarily focus on binary classification (depression/normal), lacking granularity for severity assessment. To address this, we proposed the DepL-GCN, i.e., Depression Level classification based on GCN model. This model tackles two key challenges: (1) subjectivity in depres-sion-level labeling due to patient self-report biases, and (2) class imbalance across severity categories. Inspired by the model learning patterns, we introduced two novel modules: the sample confidence module and the minority sample penalty module. The former leverages the L2-norm of prediction errors to progressively filter EEG samples with weak label alignment during training, thereby reducing the impact of subjectivity; the latter automatically upweights misclassified minority-class samples to address imbalance issues. After testing on two public EEG datasets, DepL-GCN achieved accuracies of 81.13% and 81.36% for multi-class severity recognition, outperforming baseline this http URL studies confirmed both modules' contributions. We further discussed the strengths and limitations of regression-based models for depression-level recognition.

Paper number 13:
Title: Radar Pulse Deinterleaving with Transformer Based Deep Metric Learning
Authors: Edward Gunn, Adam Hosford, Daniel Mannion, Jarrod Williams, Varun Chhabra, Victoria Nockles
Abstract: When receiving radar pulses it is common for a recorded pulse train to contain pulses from many different emitters. The radar pulse deinterleaving problem is the task of separating out these pulses by the emitter from which they originated. Notably, the number of emitters in any particular recorded pulse train is considered unknown. In this paper, we define the problem and present metrics that can be used to measure model performance. We propose a metric learning approach to this problem using a transformer trained with the triplet loss on synthetic data. This model achieves strong results in comparison with other deep learning models with an adjusted mutual information score of 0.882.

Paper number 14:
Title: Advancing Highway Work Zone Safety: A Comprehensive Review of Sensor Technologies for Intrusion and Proximity Hazards
Authors: Ayenew Yihune Demeke, Moein Younesi Heravi, Israt Sharmin Dola, Youjin Jang, Chau Le, Inbae Jeong, Zhibin Lin, Danling Wang
Abstract: Highway work zones are critical areas where accidents frequently occur, often due to the proximity of workers to heavy machinery and ongoing traffic. With technological advancements in sensor technologies and the Internet of Things, promising solutions are emerging to address these safety concerns. This paper provides a systematic review of existing studies on the application of sensor technologies in enhancing highway work zone safety, particularly in preventing intrusion and proximity hazards. Following the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) protocol, the review examines a broad spectrum of publications on various sensor technologies, including GPS, radar, laser, infrared, RFID, Bluetooth, ultrasonic, and infrared sensors, detailing their application in reducing intrusion and proximity incidents. The review also assesses these technologies in terms of their accuracy, range, power consumption, cost, and user-friendliness, with a specific emphasis on their suitability for highway work zones. The findings highlight the potential of sensor technologies to significantly enhance work zone safety. As there are a wide range of sensor technologies to choose from, the review also revealed that selection of sensors for a particular application needs careful consideration of different factors. Finally, while sensor technologies offer promising solutions for enhancing highway work zone safety, their effective implementation requires comprehensive consideration of various factors beyond technological capabilities, including developing integrated, cost-effective, user-friendly, and secure systems, and creating regulatory frameworks to support the rapid development of these technologies.

Paper number 15:
Title: EAGLE: Contextual Point Cloud Generation via Adaptive Continuous Normalizing Flow with Self-Attention
Authors: Linhao Wang, Qichang Zhang, Yifan Yang, Hao Wang
Abstract: As 3D point clouds become the prevailing shape representation in computer vision, how to generate high-resolution point clouds has become a pressing issue. Flow-based generative models can effectively perform point cloud generation tasks. However, traditional CNN-based flow architectures rely only on local information to extract features, making it difficult to capture global contextual information. Inspired by the wide adoption of Transformers, we explored the complementary roles of self-attention mechanisms in Transformers, CNN, and continuous normalizing flows. To this end, we propose a probabilistic model via adaptive normalizing flows and self-attention. Our idea leverages self-attention mechanisms to capture global contextual information. We also propose adaptive continuous normalizing flows by introducing adaptive bias correction mechanism. Combined with normalization, the mechanism dynamically handles different input contexts and mitigates potential bias-shift issues from standard initialization. Experimental results demonstrate that EAGLE achieves competitive performance in point cloud generation.

Paper number 16:
Title: WVEmbs with its Masking: A Method For Radar Signal Sorting
Authors: Xianan Hu, Fu Li, Kairui Niu, Peihan Qi, Zhiyong Liang
Abstract: Our study proposes a novel embedding method, Wide-Value-Embeddings (WVEmbs), for processing Pulse Descriptor Words (PDWs) as normalized inputs to neural networks. This method adapts to the distribution of interleaved radar signals, ranking original signal features from trivial to useful and stabilizing the learning process. To address the imbalance in radar signal interleaving, we introduce a value dimension masking method on WVEmbs, which automatically and efficiently generates challenging samples, and constructs interleaving scenarios, thereby compelling the model to learn robust features. Experimental results demonstrate that our method is an efficient end-to-end approach, achieving high-granularity, sample-level pulse sorting for high-density interleaved radar pulse sequences in complex and non-ideal environments.

Paper number 17:
Title: An On-Chip Ultra-wideband Antenna with Area-Bandwidth Optimization for Sub-Terahertz Transceivers and Radars
Authors: Boxun Yan, Runzhou Chen, Mau-Chung Frank Chang
Abstract: In this paper, we present an on-chip antenna at 290 GHz that achieves a maximum efficiency of 42\% on a low-resistivity silicon substrate for sub-terahertz integrated transceivers. The proposed antenna is based on a dual-slot structure to accommodate a limited ground plane and maintain desired radiation and impedance characteristics across the target frequency range. The antenna impedance bandwidth reaches 39\% with compact physical dimensions of 0.24$\lambda_0\times$0.42$\lambda_0$. Simulation and measurement results confirm its promising antenna performance for potential transceiver and radar applications.

Paper number 18:
Title: PiEEG kit -- bioscience Lab in home for your Brain and Body
Authors: Ildar Rakhmatulin
Abstract: PiEEG kit is a multifunctional, compact, and mobile device that allows measure EEG, EMG, EOG, and EKG signals. The PiEEG Box incorporates the Raspberry Pi-based PiEEG shield, an EEG electrode cap, a display screen, additional sensors about body parameters and the environment, and other necessary peripherals, software, and an SDK course to learn signal processing into a single, portable unit. This integrated solution addresses the need for a compact, user-friendly, and accessible EEG measurement tool for researchers and hobbyists. The PiEEG Box builds upon the open-source foundation of the original PiEEG device, offering 8-channel EEG recording capabilities. By combining all required elements into one package, the PiEEG Box significantly reduces setup time and complexity, potentially broadening the application of EEG technology in various fields including neuroscience research, brain-computer interfaces, and educational settings.

Paper number 19:
Title: Using Test-Time Data Augmentation for Cross-Domain Atrial Fibrillation Detection from ECG Signals
Authors: Majid Soleimani, Maedeh H.Toosi, Siamak Mohammadi, Babak Hossein Khalaj
Abstract: Atrial fibrillation (AF) detection from electrocardiogram (ECG) signals is crucial for early diagnosis and management of cardiovascular diseases. However, deploying robust AF detection models across different datasets with significant domain variations remains a challenge. In this paper, we use test-time data augmentation (TTA) to address the cross-domain problem and enhance AF detection performance. We use a publicly available dataset for training - Physionet Computing in Cardiology Challenge 2017 -, while collecting a distinct test set, creating a cross-domain scenario. We employ a neural network architecture that integrates transformer-based encoding of ECG signals and convolutional layers for spectrogram feature extraction. The model combines the latent representations obtained from both encoders to classify the input signals. By incorporating TTA during inference, we enhance the model's performance, achieving an F1 score of 76.6\% on our test set. Furthermore, our experiments demonstrate that the model becomes more resilient to perturbations in the input signal, enhancing its robustness. We show that TTA can be effective in addressing the cross-domain problem, where training and test data originate from disparate sources. This work contributes to advancing the field of AF detection in real-world scenarios.

Paper number 20:
Title: Machine learning for triage of strokes with large vessel occlusion using photoplethysmography biomarkers
Authors: Márton Á. Goda, Helen Badge, Jasmeen Khan, Yosef Solewicz, Moran Davoodi, Rumbidzai Teramayi, Dennis Cordato, Longting Lin, Lauren Christie, Christopher Blair, Gagan Sharma, Mark Parsons, Joachim A. Behar
Abstract: Objective. Large vessel occlusion (LVO) stroke presents a major challenge in clinical practice due to the potential for poor outcomes with delayed treatment. Treatment for LVO involves highly specialized care, in particular endovascular thrombectomy, and is available only at certain hospitals. Therefore, prehospital identification of LVO by emergency ambulance services, can be critical for triaging LVO stroke patients directly to a hospital with access to endovascular therapy. Clinical scores exist to help distinguish LVO from less severe strokes, but they are based on a series of examinations that can take minutes and may be impractical for patients with dementia or those who cannot follow commands due to their stroke. There is a need for a fast and reliable method to aid in the early identification of LVO. In this study, our objective was to assess the feasibility of using 30-second photoplethysmography (PPG) recording to assist in recognizing LVO stroke. Method. A total of 88 patients, including 25 with LVO, 27 with stroke mimic (SM), and 36 non-LVO stroke patients (NL), were recorded at the Liverpool Hospital emergency department in Sydney, Australia. Demographics (age, sex), as well as morphological features and beating rate variability measures, were extracted from the PPG. A binary classification approach was employed to differentiate between LVO stroke and NL+SM (this http URL). A 2:1 train-test split was stratified and repeated randomly across 100 iterations. Results. The best model achieved a median test set area under the receiver operating characteristic curve (AUROC) of 0.77 (0.71--0.82). \textit{Conclusion.} Our study demonstrates the potential of utilizing a 30-second PPG recording for identifying LVO stroke.

Paper number 21:
Title: Statistical Study of Sensor Data and Investigation of ML-based Calibration Algorithms for Inexpensive Sensor Modules: Experiments from Cape Point
Authors: Travis Barrett, Amit Kumar Mishra
Abstract: In this paper we present the statistical analysis of data from inexpensive sensors. We also present the performance of machine learning algorithms when used for automatic calibration such sensors. In this we have used low-cost Non-Dispersive Infrared CO$_2$ sensor placed at a co-located site at Cape Point, South Africa (maintained by Weather South Africa). The collected low-cost sensor data and site truth data are investigated and compared. We compare and investigate the performance of Random Forest Regression, Support Vector Regression, 1D Convolutional Neural Network and 1D-CNN Long Short-Term Memory Network models as a method for automatic calibration and the statistical properties of these model predictions. In addition, we also investigate the drift in performance of these algorithms with time.

Paper number 22:
Title: Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data
Authors: Mengbing Liu, Xin Li, Jiancheng An, Chau Yuen
Abstract: This paper introduces a novel approach for real-time onboard terrain classification from Sentinel-1 (S1) level-0 raw In-phase/Quadrature (IQ) data, leveraging a Stacked Intelligent Metasurface (SIM) to perform inference directly in the analog wave domain. Unlike conventional digital deep neural networks, the proposed multi-layer Diffractive Deep Neural Network (D$^2$NN) setup implements automatic feature extraction as electromagnetic waves propagate through stacked metasurface layers. This design not only reduces reliance on expensive downlink bandwidth and high-power computing at terrestrial stations but also achieves performance levels around 90\% directly from the real raw IQ data, in terms of accuracy, precision, recall, and F1 Score. Our method therefore helps bridge the gap between next-generation remote sensing tasks and in-orbit processing needs, paving the way for computationally efficient remote sensing applications.

Paper number 23:
Title: Cascade of one-class classifier ensemble and dynamic naive Bayes classifier applied to the myoelectric-based upper limb prosthesis control with contaminated channels detection
Authors: Pawel Trajdos, Marek Kurzynski
Abstract: Modern upper limb bioprostheses are typically controlled by sEMG signals using a pattern recognition scheme in the control process. Unfortunately, the sEMG signal is very susceptible to contamination that deteriorates the quality of the control system and reduces the usefulness of the prosthesis in the patient's everyday life. In the paper, the authors propose a new recognition system intended for sEMG-based control of the hand prosthesis with detection of contaminated sEMG signals. The originality of the proposed solution lies in the co-operation of two recognition systems working in a cascade structure: (1) an ensemble of one-class classifiers used to recognise contaminated signals and (2) a naive Bayes classifier (NBC) which recognises the patient's intentions using the information about contaminations produced by the ensemble. Although in the proposed approach, the NBC model is changed dynamically, due to the multiplicative form of the classification functions, training can be performed in a one-shot procedure. Experimental studies were conducted using real sEMG signals. The results obtained confirm the hypothesis that the use of the one-class classifier ensemble and the dynamic NBC model leads to improved classification quality.

Paper number 24:
Title: FLP-XR: Future Location Prediction on Extreme Scale Maritime Data in Real-time
Authors: George S. Theodoropoulos, Andreas Patakis, Andreas Tritsarolis, Yannis Theodoridis
Abstract: Movements of maritime vessels are inherently complex and challenging to model due to the dynamic and often unpredictable nature of maritime operations. Even within structured maritime environments, such as shipping lanes and port approaches, where vessels adhere to navigational rules and predefined sea routes, uncovering underlying patterns is far from trivial. The necessity for accurate modeling of the mobility of maritime vessels arises from the numerous applications it serves, including risk assessment for collision avoidance, optimization of shipping routes, and efficient port management. This paper introduces FLP-XR, a model that leverages maritime mobility data to construct a robust framework that offers precise predictions while ensuring extremely fast training and inference capabilities. We demonstrate the efficiency of our approach through an extensive experimental study using three real-world AIS datasets. According to the experimental results, FLP-XR outperforms the current state-of-the-art in many cases, whereas it performs 2-3 orders of magnitude faster in terms of training and inference.

Paper number 25:
Title: Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition
Authors: Yuqi Ding, Elisa Donati, Haobo Li, Hadi Heidari
Abstract: Wearable health devices have a strong demand in real-time biomedical signal processing. However traditional methods often require data transmission to centralized processing unit with substantial computational resources after collecting it from edge devices. Neuromorphic computing is an emerging field that seeks to design specialized hardware for computing systems inspired by the structure, function, and dynamics of the human brain, offering significant advantages in latency and power consumption. This paper explores a novel neuromorphic implementation approach for gesture recognition by extracting spatiotemporal spiking information from surface electromyography (sEMG) data in an event-driven manner. At the same time, the network was designed by implementing a simple-structured and hardware-friendly Physical Reservoir Computing (PRC) framework called Rotating Neuron Reservoir (RNR) within the domain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to pipeline an innovative solution to compact embedded wearable systems, enabling low-latency, real-time processing directly at the sensor level. The proposed system was validated by an open-access large-scale sEMG database and achieved an average classification accuracy of 74.6\% and 80.3\% using a classical machine learning classifier and a delta learning rule algorithm respectively. While the delta learning rule could be fully spiking and implementable on neuromorphic chips, the proposed gesture recognition system demonstrates the potential for near-sensor low-latency processing.

Paper number 26:
Title: Analysis of Learning-based Offshore Wind Power Prediction Models with Various Feature Combinations
Authors: Linhan Fang, Fan Jiang, Ann Mary Toms, Xingpeng Li
Abstract: Accurate wind speed prediction is crucial for designing and selecting sites for offshore wind farms. This paper investigates the effectiveness of various machine learning models in predicting offshore wind power for a site near the Gulf of Mexico by analyzing meteorological data. After collecting and preprocessing meteorological data, nine different input feature combinations were designed to assess their impact on wind power predictions at multiple heights. The results show that using wind speed as the output feature improves prediction accuracy by approximately 10% compared to using wind power as the output. In addition, the improvement of multi-feature input compared with single-feature input is not obvious mainly due to the poor correlation among key features and limited generalization ability of models. These findings underscore the importance of selecting appropriate output features and highlight considerations for using machine learning in wind power forecasting, offering insights that could guide future wind power prediction models and conversion techniques.

Paper number 27:
Title: TransECG: Leveraging Transformers for Explainable ECG Re-identification Risk Analysis
Authors: Ziyu Wang, Elahe Khatibi, Kianoosh Kazemi, Iman Azimi, Sanaz Mousavi, Shaista Malik, Amir M. Rahmani
Abstract: Electrocardiogram (ECG) signals are widely shared across multiple clinical applications for diagnosis, health monitoring, and biometric authentication. While valuable for healthcare, they also carry unique biometric identifiers that pose privacy risks, especially when ECG data shared across multiple entities. These risks are amplified in shared environments, where re-identification threats can compromise patient privacy. Existing deep learning re-identification models prioritize accuracy but lack explainability, making it challenging to understand how the unique biometric characteristics encoded within ECG signals are recognized and utilized for identification. Without these insights, despite high accuracy, developing secure and trustable ECG data-sharing frameworks remains difficult, especially in diverse, multi-source environments. In this work, we introduce TransECG, a Vision Transformer (ViT)-based method that uses attention mechanisms to pinpoint critical ECG segments associated with re-identification tasks like gender, age, and participant ID. Our approach demonstrates high accuracy (89.9% for gender, 89.9% for age, and 88.6% for ID re-identification) across four real-world datasets with 87 participants. Importantly, we provide key insights into ECG components such as the R-wave, QRS complex, and P-Q interval in re-identification. For example, in the gender classification, the R wave contributed 58.29% to the model's attention, while in the age classification, the P-R interval contributed 46.29%. By combining high predictive performance with enhanced explainability, TransECG provides a robust solution for privacy-conscious ECG data sharing, supporting the development of secure and trusted healthcare data environment.

Paper number 28:
Title: Finger-to-Chest Style Transfer-assisted Deep Learning Method For Photoplethysmogram Waveform Restoration with Timing Preservation
Authors: Sara Maria Pagotto, Federico Tognoni, Matteo Rossi, Dario Bovio, Caterina Salito, Luca Mainardi, Pietro Cerveri
Abstract: Wearable measurements, such as those obtained by photoplethysmogram (PPG) sensors are highly susceptible to motion artifacts and noise, affecting cardiovascular measures. Chest-acquired PPG signals are especially vulnerable, with signal degradation primarily resulting from lower perfusion, breathing-induced motion, and mechanical interference from chest movements. Traditional restoration methods often degrade the signal, and supervised deep learning (DL) struggles with random and systematic distortions, requiring very large datasets for successful training. To efficiently restore chest PPG waveform, we propose a style transfer-assisted cycle-consistent generative adversarial network, called starGAN, whose performance is evaluated on a three-channel PPG signal (red, green,and infrared) acquired by a chest-worn multi-modal sensor, called Soundi. Two identical devices are adopted, one sensor to collect the PPG signal on the chest, considered to feature low quality and undergoing restoration, and another sensor to obtain a high-quality PPG signal measured on the finger, considered the reference signal. Extensive validation over some 8,000 5-second chunks collected from 40 subjects showed about 90% correlation of the restored chest PPG with the reference finger PPG, with a 30% improvement over raw chest PPG. Likewise, the signal-to-noise ratio improved on average of about 125%, over the three channels. The agreement with heart-rate computed from concurrent ECG was extremely high, overcoming 84% on average. These results demonstrate effective signal restoration, comparable with findings in recent literature papers. Significance: PPG signals collected from wearable devices are highly susceptible to artifacts, making innovative AI-based techniques fundamental towards holistic health assessments in a single device.

Paper number 29:
Title: Is Limited Participant Diversity Impeding EEG-based Machine Learning?
Authors: Philipp Bomatter, Henry Gouk
Abstract: The application of machine learning (ML) to electroencephalography (EEG) has great potential to advance both neuroscientific research and clinical applications. However, the generalisability and robustness of EEG-based ML models often hinge on the amount and diversity of training data. It is common practice to split EEG recordings into small segments, thereby increasing the number of samples substantially compared to the number of individual recordings or participants. We conceptualise this as a multi-level data generation process and investigate the scaling behaviour of model performance with respect to the overall sample size and the participant diversity through large-scale empirical studies. We then use the same framework to investigate the effectiveness of different ML strategies designed to address limited data problems: data augmentations and self-supervised learning. Our findings show that model performance scaling can be severely constrained by participant distribution shifts and provide actionable guidance for data collection and ML research.

Paper number 30:
Title: Analysis and Knowledge Discovery from Sensors Data to Improve Energy Efficiency
Authors: Xavier Vasques, Thibaut Possompes, Herve Rey, Marine Le Touze, Nicolas Auboin, Emmanuelle Passot, Benoit Lange
Abstract: Increases in energy prices and the global goal of mitigating CO2 emissions necessitate the development of intelligent Building Management Systems (BMS) that operate on an energy-efficient basis. Data Centers, buildings and/or group of buildings are often responsible for huge energy consumption. One way to monitor and optimize energy consumption is to instrument buildings using sensors (temperature, pressure, humidity ...) in order to track and solve wrong usage of energy management systems. The majority of the BMS are processing the data dynamically without taking into account the data history due to their constraint problems (time, bandwidth and calculation capability) and data resources. The RIDER project brings together a consortium of research laboratories and enterprises including IBM, to share their expertise in research and development of smart Information Technology (IT) energy platforms. In this context, we aim to improve energy efficiency of buildings or group of building (including data centers) using IT. One of the objectives is to identify valid, potentially useful, and ultimately understandable patterns in data for improving energy efficiency. We propose in this paper an approach of using an integrated platform able to interconnect instrumented buildings and sites, and to provide a high-level point of view for increasing our knowledge from sensors. The expected results are to estimate physical parameters that influence energy consumption based on data set history. Different correlation could be found between different variables, for example, indoor air quality and energy consumption. These results could be applied at a location where no sensor is placed and predict energy consumption from different variables.

Paper number 31:
Title: Federated Learning for Secure and Efficient Device Activity Detection in mMTC Networks
Authors: Ali Elkeshawy, Ibrahim Al Ghosh, Haifa Fares, Amor Nafkha
Abstract: Grant-free random access in massive machine-type communications enables low-latency connectivity with minimal signaling. However, sporadic device activation requires efficient device activity detection. We propose a federated learning-based device activity detection approach, leveraging distributed training to enhance security and privacy while maintaining low computational complexity. Compared to existing methods, our solution achieves competitive detection performance, addressing scalability and security challenges in mMTC networks.

Paper number 32:
Title: Internet of Things-Based Smart Precision Farming in Soilless Agriculture: Opportunities and Challenges for Global Food Security
Authors: Monica Dutta, Deepali Gupta, Sumegh Tharewal, Deepam Goyal, Jasminder Kaur Sandhu, Manjit Kaur, Ahmad Ali Alzubi, Jazem Mutared Alanazi
Abstract: The rapid growth of the global population and the continuous decline in cultivable land pose significant threats to food security. This challenge worsens as climate change further reduces the availability of farmland. Soilless agriculture, such as hydroponics, aeroponics, and aquaponics, offers a sustainable solution by enabling efficient crop cultivation in controlled environments. The integration of the Internet of Things (IoT) with smart precision farming improves resource efficiency, automates environmental control, and ensures stable and high-yield crop production. IoT-enabled smart farming systems utilize real-time monitoring, data-driven decision-making, and automation to optimize water and nutrient usage while minimizing human intervention. This paper explores the opportunities and challenges of IoT-based soilless farming, highlighting its role in sustainable agriculture, urban farming, and global food security. These advanced farming methods ensure greater productivity, resource conservation, and year-round cultivation. However, they also face challenges such as high initial investment, technological dependency, and energy consumption. Through a comprehensive study, bibliometric analysis, and comparative analysis, this research highlights current trends and research gaps. It also outlines future directions for researchers, policymakers, and industry stakeholders to drive innovation and scalability in IoT-driven soilless agriculture. By emphasizing the benefits of vertical farming and Controlled Environment Agriculture (CEA)-enabled soilless techniques, this paper supports informed decision-making to address food security challenges and promote sustainable agricultural innovations.

Paper number 33:
Title: Fast data augmentation for battery degradation prediction
Authors: Weihan Li, Harshvardhan Samsukha, Bruis van Vlijmen, Lisen Yan, Samuel Greenbank, Simona Onori, Venkat Viswanathan
Abstract: Degradation prediction for lithium-ion batteries using data-driven methods requires high-quality aging data. However, generating such data, whether in the laboratory or the field, is time- and resource-intensive. Here, we propose a method for the synthetic generation of capacity fade curves based on limited battery tests or operation data without the need for invasive battery characterization, aiming to augment the datasets used by data-driven models for degradation prediction. We validate our method by evaluating the performance of both shallow and deep learning models using diverse datasets from laboratory and field applications. These datasets encompass various chemistries and realistic conditions, including cell-to-cell variations, measurement noise, varying charge-discharge conditions, and capacity recovery. Our results show that it is possible to reduce cell-testing efforts by at least 50% by substituting synthetic data into an existing dataset. This paper highlights the effectiveness of our synthetic data augmentation method in supplementing existing methodologies in battery health prognostics while dramatically reducing the expenditure of time and resources on battery aging experiments.

Paper number 34:
Title: Feasibility study for reconstruction of knee MRI from one corresponding X-ray via CNN
Authors: Zhe Wang, Aladine Chetouani, Rachid Jennane
Abstract: Generally, X-ray, as an inexpensive and popular medical imaging technique, is widely chosen by medical practitioners. With the development of medical technology, Magnetic Resonance Imaging (MRI), an advanced medical imaging technique, has already become a supplementary diagnostic option for the diagnosis of KOA. We propose in this paper a deep-learning-based approach for generating MRI from one corresponding X-ray. Our method uses the hidden variables of a Convolutional Auto-Encoder (CAE) model, trained for reconstructing X-ray image, as inputs of a generator model to provide 3D MRI.

Paper number 35:
Title: Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life
Authors: Jingyuan Xue, Longfei Wei, Fang Sheng, Yuxin Gao, Jianfei Zhang
Abstract: The accurate prediction of RUL for lithium-ion batteries is crucial for enhancing the reliability and longevity of energy storage systems. Traditional methods for RUL prediction often struggle with issues such as data sparsity, varying battery chemistries, and the inability to capture complex degradation patterns over time. In this study, we propose a survival analysis-based framework combined with deep learning models to predict the RUL of lithium-ion batteries. Specifically, we utilize five advanced models: the Cox-type models (Cox, CoxPH, and CoxTime) and two machine-learning-based models (DeepHit and MTLR). These models address the challenges of accurate RUL estimation by transforming raw time-series battery data into survival data, including key degradation indicators such as voltage, current, and internal resistance. Advanced feature extraction techniques enhance the model's robustness in diverse real-world scenarios, including varying charging conditions and battery chemistries. Our models are tested using 10-fold cross-validation, ensuring generalizability and minimizing overfitting. Experimental results show that our survival-based framework significantly improves RUL prediction accuracy compared to traditional methods, providing a reliable tool for battery management and maintenance optimization. This study contributes to the advancement of predictive maintenance in battery technology, offering valuable insights for both researchers and industry practitioners aiming to enhance the operational lifespan of lithium-ion batteries.

Paper number 36:
Title: MSWAL: 3D Multi-class Segmentation of Whole Abdominal Lesions Dataset
Authors: Zhaodong Wu, Qiaochu Zhao, Ming Hu, Yulong Li, Haochen Xue, Kang Dang, Zhengyong Jiang, Angelos Stefanidis, Qiufeng Wang, Imran Razzak, Zongyuan Ge, Junjun He, Yu Qiao, Zhong Zheng, Feilong Tang, Jionglong Su
Abstract: With the significantly increasing incidence and prevalence of abdominal diseases, there is a need to embrace greater use of new innovations and technology for the diagnosis and treatment of patients. Although deep-learning methods have notably been developed to assist radiologists in diagnosing abdominal diseases, existing models have the restricted ability to segment common lesions in the abdomen due to missing annotations for typical abdominal pathologies in their training datasets. To address the limitation, we introduce MSWAL, the first 3D Multi-class Segmentation of the Whole Abdominal Lesions dataset, which broadens the coverage of various common lesion types, such as gallstones, kidney stones, liver tumors, kidney tumors, pancreatic cancer, liver cysts, and kidney cysts. With CT scans collected from 694 patients (191,417 slices) of different genders across various scanning phases, MSWAL demonstrates strong robustness and generalizability. The transfer learning experiment from MSWAL to two public datasets, LiTS and KiTS, effectively demonstrates consistent improvements, with Dice Similarity Coefficient (DSC) increase of 3.00% for liver tumors and 0.89% for kidney tumors, demonstrating that the comprehensive annotations and diverse lesion types in MSWAL facilitate effective learning across different domains and data distributions. Furthermore, we propose Inception nnU-Net, a novel segmentation framework that effectively integrates an Inception module with the nnU-Net architecture to extract information from different receptive fields, achieving significant enhancement in both voxel-level DSC and region-level F1 compared to the cutting-edge public algorithms on MSWAL. Our dataset will be released after being accepted, and the code is publicly released at this https URL.

Paper number 37:
Title: Classification of power quality events in the transmission grid: comparative evaluation of different machine learning models
Authors: Umut Güvengir, Dilek Küçük, Serkan Buhan, Cuma Ali Mantaş, Murathan Yeniceli
Abstract: Automatic classification of electric power quality events with respect to their root causes is critical for electrical grid management. In this paper, we present comparative evaluation results of an extensive set of machine learning models for the classification of power quality events, based on their root causes. After extensive experiments using different machine learning libraries, it is observed that the best performing learning models turn out to be Cubic SVM and XGBoost. During error analysis, it is observed that the main source of performance degradation for both models is the classification of ABC faults as ABCG faults, or vice versa. Ultimately, the models achieving the best results will be integrated into the event classification module of a large-scale power quality and grid monitoring system for the Turkish electricity transmission system.

Paper number 38:
Title: Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor
Authors: Benoît Savoini, Jonathan Bertolaccini, Stéphane Montavon, Michel Deriaz
Abstract: Lameness and gait irregularities are significant concerns in equine health management, affecting performance, welfare, and economic value. Traditional observational methods rely on subjective expert assessments, which can lead to inconsistencies in detecting subtle or early-stage lameness. While AI-based approaches have emerged, many require multiple sensors, force plates, or video systems, making them costly and impractical for field deployment. In this applied research study, we present a stride-level classification system that utilizes a single inertial measurement unit (IMU) and a one-dimensional convolutional neural network (1D CNN) to objectively differentiate between sound and lame horses, with a primary focus on the trot gait. The proposed system was tested under real-world conditions, achieving a 90% session-level accuracy with no false positives, demonstrating its robustness for practical applications. By employing a single, non-intrusive, and readily available sensor, our approach significantly reduces the complexity and cost of hardware requirements while maintaining high classification performance. These results highlight the potential of our CNN-based method as a field-tested, scalable solution for automated lameness detection. By enabling early diagnosis, this system offers a valuable tool for preventing minor gait irregularities from developing into severe conditions, ultimately contributing to improved equine welfare and performance in veterinary and equestrian practice.

Paper number 39:
Title: Subgroup Performance of a Commercial Digital Breast Tomosynthesis Model for Breast Cancer Detection
Authors: Beatrice Brown-Mulry, Rohan Satya Isaac, Sang Hyup Lee, Ambika Seth, KyungJee Min, Theo Dapamede, Frank Li, Aawez Mansuri, MinJae Woo, Christian Allison Fauria-Robinson, Bhavna Paryani, Judy Wawira Gichoya, Hari Trivedi
Abstract: While research has established the potential of AI models for mammography to improve breast cancer screening outcomes, there have not been any detailed subgroup evaluations performed to assess the strengths and weaknesses of commercial models for digital breast tomosynthesis (DBT) imaging. This study presents a granular evaluation of the Lunit INSIGHT DBT model on a large retrospective cohort of 163,449 screening mammography exams from the Emory Breast Imaging Dataset (EMBED). Model performance was evaluated in a binary context with various negative exam types (162,081 exams) compared against screen detected cancers (1,368 exams) as the positive class. The analysis was stratified across demographic, imaging, and pathologic subgroups to identify potential disparities. The model achieved an overall AUC of 0.91 (95% CI: 0.90-0.92) with a precision of 0.08 (95% CI: 0.08-0.08), and a recall of 0.73 (95% CI: 0.71-0.76). Performance was found to be robust across demographics, but cases with non-invasive cancers (AUC: 0.85, 95% CI: 0.83-0.87), calcifications (AUC: 0.80, 95% CI: 0.78-0.82), and dense breast tissue (AUC: 0.90, 95% CI: 0.88-0.91) were associated with significantly lower performance compared to other groups. These results highlight the need for detailed evaluation of model characteristics and vigilance in considering adoption of new tools for clinical deployment.

Paper number 40:
Title: Stability results for MIMO LTI systems via Scaled Relative Graphs
Authors: Eder Baron-Prada, Adolfo Anta, Alberto Padoan, Florian Dörfler
Abstract: This paper proposes a new approach for stability analysis of multi-input, multi-output (MIMO) feedback systems through Scaled Relative Graphs (SRGs). Unlike traditional methods, such as the Generalized Nyquist Criterion (GNC), which relies on a coupled analysis that requires the multiplication of models, our approach enables the evaluation of system stability in a decoupled fashion and provides an intuitive, visual representation of system behavior. Our results provide conditions for certifying the stability of feedback MIMO Linear Time-Invariant (LTI) systems.

Paper number 41:
Title: Single Sparse Graph Enhanced Expectation Propagation Algorithm Design for Uplink MIMO-SCMA
Authors: Qu Luo, Jing Zhu, Gaojie Chen, Pei Xiao, Rahim Tafazolli
Abstract: Sparse code multiple access (SCMA) and multiple input multiple output (MIMO) are considered as two efficient techniques to provide both massive connectivity and high spectrum efficiency for future machine-type wireless networks. This paper proposes a single sparse graph (SSG) enhanced expectation propagation algorithm (EPA) receiver, referred to as SSG-EPA, for uplink MIMO-SCMA systems. Firstly, we reformulate the sparse codebook mapping process using a linear encoding model, which transforms the variable nodes (VNs) of SCMA from symbol-level to bit-level VNs. Such transformation facilitates the integration of the VNs of SCMA and low-density parity-check (LDPC), thereby emerging the SCMA and LDPC graphs into a SSG. Subsequently, to further reduce the detection complexity, the message propagation between SCMA VNs and function nodes (FNs) are designed based on EPA principles. Different from the existing iterative detection and decoding (IDD) structure, the proposed EPA-SSG allows a simultaneously detection and decoding at each iteration, and eliminates the use of interleavers, de-interleavers, symbol-to-bit, and bit-to-symbol LLR transformations. Simulation results show that the proposed SSG-EPA achieves better error rate performance compared to the state-of-the-art schemes.

Paper number 42:
Title: Cooperative Deterministic Learning-Based Formation Control for a Group of Nonlinear Mechanical Systems Under Complete Uncertainty
Authors: Maryam Norouzi, Mingxi Zhou, Chengzhi Yuan
Abstract: In this work we address the formation control problem for a group of nonlinear mechanical systems with complete uncertain dynamics under a virtual leader-following framework. We propose a novel cooperative deterministic learning-based adaptive formation control algorithm. This algorithm is designed by utilizing artificial neural networks to simultaneously achieve formation tracking control and locally-accurate identification/learning of the nonlinear uncertain dynamics of the considered group of mechanical systems. To demonstrate the practicality and verify the effectiveness of the proposed results, numerical simulations have been conducted.

Paper number 43:
Title: From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence
Authors: Krti Tallam
Abstract: The rapid evolution of artificial intelligence (AI) has ushered in a new era of integrated systems that merge computational prowess with human decision-making. In this paper, we introduce the concept of \textbf{Orchestrated Distributed Intelligence (ODI)}, a novel paradigm that reconceptualizes AI not as isolated autonomous agents, but as cohesive, orchestrated networks that work in tandem with human expertise. ODI leverages advanced orchestration layers, multi-loop feedback mechanisms, and a high cognitive density framework to transform static, record-keeping systems into dynamic, action-oriented environments. Through a comprehensive review of multi-agent system literature, recent technological advances, and practical insights from industry forums, we argue that the future of AI lies in integrating distributed intelligence within human-centric workflows. This approach not only enhances operational efficiency and strategic agility but also addresses challenges related to scalability, transparency, and ethical decision-making. Our work outlines key theoretical implications and presents a practical roadmap for future research and enterprise innovation, aiming to pave the way for responsible and adaptive AI systems that drive sustainable innovation in human organizations.

Paper number 44:
Title: Zero-Shot Denoising for Fluorescence Lifetime Imaging Microscopy with Intensity-Guided Learning
Authors: Hao Chen, Julian Najera, Dagmawit Geresu, Meenal Datta, Cody Smith, Scott Howard
Abstract: Multimodal and multi-information microscopy techniques such as Fluorescence Lifetime Imaging Microscopy (FLIM) extend the informational channels beyond intensity-based fluorescence microscopy but suffer from reduced image quality due to complex noise patterns. For FLIM, the intrinsic relationship between intensity and lifetime information means noise in each channel is a multivariate function across channels without necessarily sharing structural features. Based on this, we present a novel Zero-Shot Denoising Framework with an Intensity-Guided Learning approach. Our correlation-preserving strategy maintains important biological information that might be lost when channels are processed independently. Our framework implements separate processing paths for each channel and utilizes a pre-trained intensity denoising prior to guide the refinement of lifetime components across multiple channels. Through experiments on real-world FLIM-acquired biological samples, we show that our approach outperforms existing methods in both noise reduction and lifetime preservation, thereby enabling more reliable extraction of physiological and molecular information.

Paper number 45:
Title: Geometry of the Feasible Output Regions of Grid-Interfacing Inverters with Current Limits
Authors: Lauren Streitmatter, Trager Joswig-Jones, Baosen Zhang
Abstract: Many resources in the grid connect to power grids via programmable grid-interfacing inverters that can provide grid services and offer greater control flexibility and faster response times compared to synchronous generators. However, the current through the inverter needs to be limited to protect the semiconductor components. Existing controllers are designed using somewhat ad hoc methods, for example, by adding current limiters to preexisting control loops, which can lead to stability issues or overly conservative operations. In this paper, we study the geometry of the feasible output region of a current-limited inverter. We show that under a commonly used model, the feasible region is convex. We provide an explicit characterization of this region, which allows us to efficiently find the optimal operating points of the inverter. We demonstrate how knowing the feasible set and its convexity allows us to design safe controllers such that the transient trajectories always remain within the current magnitude limit, whereas standard droop controllers can lead to violations.

Paper number 46:
Title: Send Pilot or Data? Leveraging Age of Channel State Information for Throughput Maximization
Authors: Sirin Chakraborty, Yin Sun
Abstract: In this paper, we study the optimal timing for pilot and data transmissions to maximize effective throughput, also known as goodput, over a wireless fading channel. The receiver utilizes the received pilot signal and its Age of Information (AoI), termed the Age of Channel State Information (AoCSI), to estimate the channel state. Based on this estimation, the transmitter selects an appropriate modulation and coding scheme (MCS) to maximize goodput while ensuring compliance with a predefined block error probability constraint. Furthermore, we design an optimal pilot scheduling policy that determines whether to transmit a pilot or data at each time step, with the objective of maximizing the long-term average goodput. This problem involves a non-monotonic AoI metric optimization challenge, as the goodput function is non-monotonic with respect to AoCSI. The numerical results illustrate the performance gains achieved by the proposed policy under various SNR levels and mobility speeds.

Paper number 47:
Title: Joint Array Partitioning and Beamforming Designs in ISAC Systems: A Bayesian CRB Perspective
Authors: Rang Liu, Ming Li, A. Lee Swindlehurst
Abstract: Integrated sensing and communication (ISAC) has emerged as a promising paradigm for next-generation (6G) wireless networks, unifying radar sensing and communication on a shared hardware platform. This paper proposes a dynamic array partitioning framework for monostatic ISAC systems to fully exploit available spatial degrees of freedom (DoFs) and reconfigurable antenna topologies, enhancing sensing performance in complex scenarios. We first establish a theoretical foundation for our work by deriving Bayesian Cramér-Rao bounds (BCRBs) under prior distribution constraints for heterogeneous target models, encompassing both point-like and extended targets. Building on this, we formulate a joint optimization framework for transmit beamforming and dynamic array partitioning to minimize the derived BCRBs for direction-of-arrival (DOA) estimation. The optimization problem incorporates practical constraints, including multi-user communication signal-to-interference-plus-noise ratio (SINR) requirements, transmit power budgets, and array partitioning feasibility conditions. To address the non-convexity of the problem, we develop an efficient alternating optimization algorithm combining the alternating direction method of multipliers (ADMM) with semi-definite relaxation (SDR). We also design novel maximum a posteriori (MAP) DOA estimation algorithms specifically adapted to the statistical characteristics of each target model. Extensive simulations illustrate the superiority of the proposed dynamic partitioning strategy over conventional fixed-array architectures across diverse system configurations.

Paper number 48:
Title: Optimization and Characterization of Near-Field Beams with Uniform Linear Arrays
Authors: Sota Uchimura, Josep Miquel Jornet, Koji Ishibashi
Abstract: In this paper, we consider near-field beams that can mitigate signal attenuation and blockage effects using a uniform linear array (ULA). In particular, closed-form expressions for phase distributions in a ULA are derived to generate Bessel beams and curving beams based on the desired propagation directions and trajectories. Based on the phase distributions, the maximum steering angle and propagation distance of Bessel beams with a ULA are revealed. In addition, from the sampling theorem in the spatial domain, the requirements for ULAs to properly generate Bessel beams are clarified. For curving beams, trajectories to reach a user while avoiding one obstacle are designed via the Lagrangian method. Numerical results obtained by electromagnetic wave simulations confirm the effectiveness of the analyses for Bessel beams and the curving beam designs. Furthermore, the characteristics of Gaussian beams, beamfocusing, Bessel beams, and curving beams are summarized in terms of the statistical behavior of their intensity and signal processing.

Paper number 49:
Title: Joint ADS-B in B5G for Hierarchical UAV Networks: Performance Analysis and MEC Based Optimization
Authors: Chao Dong, Yiyang Liao, Ziye Jia, Qihui Wu, Lei Zhang
Abstract: Unmanned aerial vehicles (UAVs) play significant roles in multiple fields, which brings great challenges for the airspace safety. In order to achieve efficient surveillance and break the limitation of application scenarios caused by single communication, we propose the collaborative surveillance model for hierarchical UAVs based on the cooperation of automatic dependent surveillance-broadcast (ADS-B) and 5G. Specifically, UAVs are hierarchical deployed, with the low-altitude central UAV equipped with the 5G module, and the high-altitude central UAV with ADS-B, which helps automatically broadcast the flight information to surrounding aircraft and ground stations. Firstly, we build the framework, derive the analytic expression, and analyze the channel performance of both air-to-ground (A2G) and air-to-air (A2A). Then, since the redundancy or information loss during transmission aggravates the monitoring performance, the mobile edge computing (MEC) based on-board processing algorithm is proposed. Finally, the performances of the proposed model and algorithm are verified through both simulations and experiments. In detail, the redundant data filtered out by the proposed algorithm accounts for 53.48%, and the supplementary data accounts for 16.42% of the optimized data. This work designs a UAV monitoring framework and proposes an algorithm to enhance the observability of trajectory surveillance, which helps improve the airspace safety and enhance the air traffic flow management.

Paper number 50:
Title: Fibonacci-Net: A Lightweight CNN model for Automatic Brain Tumor Classification
Authors: Santanu Roy, Ashvath Suresh, Archit Gupta, Shubhi Tiwari, Palak Sahu, Prashant Adhikari, Yuvraj S. Shekhawat
Abstract: This research proposes a very lightweight model "Fibonacci-Net" along with a novel pooling technique, for automatic brain tumor classification from imbalanced Magnetic Resonance Imaging (MRI) datasets. Automatic brain tumor detection from MRI dataset has garnered significant attention in the research community, since the inception of Convolutional Neural Network (CNN) models. However, the performance of conventional CNN models is hindered due to class imbalance problems. The novelties of this work are as follows: (I) A lightweight CNN model is proposed in which the number of filters in different convolutional layers is chosen according to the numbers of Fibonacci series. (II) In the last two blocks of the proposed model, depth-wise separable convolution (DWSC) layers are employed to considerably reduce the computational complexity of the model. (III) Two parallel concatenations (or, skip connections) are deployed from 2nd to 4th, and 3rd to 5th convolutional block in the proposed Fibonacci-Net. This skip connection encompasses a novel Average-2Max pooling layer that produces two stacks of convoluted output, having a bit different statistics. Therefore, this parallel concatenation block works as an efficient feature augmenter inside the model, thus, automatically alleviating the class imbalance problem to a certain extent. For validity purpose, we have implemented the proposed framework on three MRI datasets which are highly class-imbalanced. (a) The first dataset has four classes, i.e., glioma tumor, meningioma tumor, pituitary tumor, and no-tumor. (b) Second and third MRI datasets have 15 and 44 classes respectively. Experimental results reveal that, after employing the proposed Fibonacci-Net we have achieved 96.2% accuracy, 97.17% precision, 95.9% recall, 96.5% F1 score, and 99.9% specificity on the most challenging ``44-classes MRI dataset''.

Paper number 51:
Title: What was Said, What was not Said
Authors: Hamid Jahanian
Abstract: In the process industry, the configuration of Safety Instrumented Systems (SIS) must comply with a defined set of safety requirements, typically documented in the Safety Requirements Specification (SRS). The functional safety standard IEC 61511 outlines the necessary content and quality criteria for the SRS. However, developing an effective SRS can be challenging. This article examines some of these challenges and proposes good practices to address them. It discusses SRS ownership, "staged" development of SRS, and the classification and traceability of requirements. Additionally, it explores the issue of untold "negative" requirements and suggests exploratory "inspection" of SIS Application Programs (APs) as a potential remedy.

Paper number 52:
Title: Identification of non-causal systems with random switching modes (Extended Version)
Authors: Yanxin Zhang, Chengpu Yu, Filippo Fabiani
Abstract: We consider the identification of non-causal systems with random switching modes (NCSRSM), a class of models essential for describing typical power load management and department store inventory dynamics. The simultaneous identification of causal-andanticausal subsystems, along with the presence of random switching sequences, however, make the overall identification problem particularly challenging. To this end, we develop an expectation-maximization (EM) based system identification technique, where the E-step proposes a modified Kalman filter (KF) to estimate the states and switching sequences of causal-and-anticausal subsystems, while the M-step consists in a switching least-squares algorithm to estimate the parameters of individual subsystems. We establish the main convergence features of the proposed identification procedure, also providing bounds on the parameter estimation errors under mild conditions. Finally, the effectiveness of our identification method is validated through two numerical simulations.

Paper number 53:
Title: Striving for Simplicity: Simple Yet Effective Prior-Aware Pseudo-Labeling for Semi-Supervised Ultrasound Image Segmentation
Authors: Yaxiong Chen, Yujie Wang, Zixuan Zheng, Jingliang Hu, Yilei Shi, Shengwu Xiong, Xiao Xiang Zhu, Lichao Mou
Abstract: Medical ultrasound imaging is ubiquitous, but manual analysis struggles to keep pace. Automated segmentation can help but requires large labeled datasets, which are scarce. Semi-supervised learning leveraging both unlabeled and limited labeled data is a promising approach. State-of-the-art methods use consistency regularization or pseudo-labeling but grow increasingly complex. Without sufficient labels, these models often latch onto artifacts or allow anatomically implausible segmentations. In this paper, we present a simple yet effective pseudo-labeling method with an adversarially learned shape prior to regularize segmentations. Specifically, we devise an encoder-twin-decoder network where the shape prior acts as an implicit shape model, penalizing anatomically implausible but not ground-truth-deviating predictions. Without bells and whistles, our simple approach achieves state-of-the-art performance on two benchmarks under different partition protocols. We provide a strong baseline for future semi-supervised medical image segmentation. Code is available at this https URL.

Paper number 54:
Title: Robust Safety Critical Control Under Multiple State and Input Constraints: Volume Control Barrier Function Method
Authors: Jinyang Dong, Shizhen Wu, Rui Liu, Xiao Liang, Biao Lu, Yongchun Fang
Abstract: In this paper, the safety-critical control problem for uncertain systems under multiple control barrier function (CBF) constraints and input constraints is investigated. A novel framework is proposed to generate a safety filter that minimizes changes to reference inputs when safety risks arise, ensuring a balance between safety and performance. A nonlinear disturbance observer (DOB) based on the robust integral of the sign of the error (RISE) is used to estimate system uncertainties, ensuring that the estimation error converges to zero exponentially. This error bound is integrated into the safety-critical controller to reduce conservativeness while ensuring safety. To further address the challenges arising from multiple CBF and input constraints, a novel Volume CBF (VCBF) is proposed by analyzing the feasible space of the quadratic programming (QP) problem. % ensuring solution feasibility by keeping the volume as a positive value. To ensure that the feasible space does not vanish under disturbances, a DOB-VCBF-based method is introduced, ensuring system safety while maintaining the feasibility of the resulting QP. Subsequently, several groups of simulation and experimental results are provided to validate the effectiveness of the proposed controller.

Paper number 55:
Title: Multitaper-Based Post-Processing of Compact Antenna Responses Obtained in Non-Anechoic Conditions
Authors: Mariusz Dzwonkowski, Adrian Bekasiewicz, Slawomir Koziel
Abstract: The process of developing antenna structures typically involves prototype measurements. While accurate validation of far-field performance can be performed in dedicated facilities like anechoic chambers, high cost of construction and maintenance might not justify their use for teaching, or low-budget research scenarios. Non-anechoic experiments provide a cost-effective alternative, however the performance metrics obtained in such conditions require appropriate correction. In this paper, we consider a multitaper approach for post-processing antenna far-field characteristics measured in challenging, non-anechoic environments. The discussed algorithm enhances one-shot measurements to enable extraction of line-of-sight responses while attenuating interferences from multi-path propagation and the noise from external sources of electromagnetic radiation. The performance of the considered method has been demonstrated in uncontrolled conditions using a compact spline-based monopole. Furthermore, the approach has been favorably validated against the state-of-the-art techniques from the literature.

Paper number 56:
Title: Balanced Opto-electronic Joint Transform Correlator for Enhanced Real-Time Pattern Recognition
Authors: Julian Gamboa, Xi Shen, Tabassom Hamidfar, Shamima Mitu, Selim M. Shahriar
Abstract: Opto-electronic joint transform correlators (JTCs) use a focal plane array (FPA) to detect the joint power spectrum (JPS) of two input images, projecting it onto a spatial light modulator (SLM) to be optically Fourier transformed. The JPS is composed of two self-intensities and two conjugate-products, where only the latter produce the cross-correlation. However, the self-intensity terms are typically much stronger than the conjugate-products, consuming most of the available bit-depth on the FPA and SLM. Here we propose and demonstrate, through simulation and experiment, a balanced opto-electronic JTC that electronically processes the JPS to remove the self-intensity terms, thereby enhancing the quality of the cross-correlation result.

Paper number 57:
Title: SWIPT in Cell-Free Massive MIMO Using Stacked Intelligent Metasurfaces
Authors: Thien Duc Hua, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou
Abstract: We investigate the integration of stacked intelligent metasurfaces (SIMs) into cell-free massive multiple input multiple output (CF-mMIMO) system to enhance the simultaneous wireless information and power transfer (SWIPT) performance. Closed-form expressions for the spectral efficiency (SE) of the information-decoding receivers (IRs) and the average sum of harvested energy (sum-HE) at the energy-harvesting receivers (ERs) in the novel system model are derived to subsequently formulate a maximum total average sum-HE problem under a minimum SE threshold per each IR. This problem jointly optimizes the SIM phase-shift (PS) configuration and access points' (APs) power allocation, relying on long-term statistical channel state information (CSI). This non-convex problem is then transformed into more tractable forms. Then, efficient algorithms are proposed, including a layer-by-layer heuristic method for SIMs PS configuration that prioritizes sum-HE for the ERs and a successive convex approximation (SCA)-based power allocation scheme to improve the achievable SE for the IRs. Numerical results show that our proposed algorithms achieve an almost 7-fold sum-HE gain as we increase the number of SIM layers, while the proposed power allocation (PPA) scheme often gains up to 40% in terms of the achievable minimum SE, compared to the equal power allocation.

Paper number 58:
Title: Shift, Scale and Rotation Invariant Multiple Object Detection using Balanced Joint Transform Correlator
Authors: Xi Shen, Julian Gamboa, Tabassom Hamidfar, Shamima Mitu, Selim M. Shahriar
Abstract: The Polar Mellin Transform (PMT) is a well-known technique that converts images into shift, scale and rotation invariant signatures for object detection using opto-electronic correlators. However, this technique cannot be properly applied when there are multiple targets in a single input. Here, we propose a Segmented PMT (SPMT) that extends this methodology for cases where multiple objects are present within the same frame. Simulations show that this SPMT can be integrated into an opto-electronic joint transform correlator to create a correlation system capable of detecting multiple objects simultaneously, presenting robust detection capabilities across various transformation conditions, with remarkable discrimination between matching and non-matching targets.

Paper number 59:
Title: Variational Autoencoder for Personalized Pathological Speech Enhancement
Authors: Mingchi Hou, Ina Kodrasi
Abstract: The generalizability of speech enhancement (SE) models across speaker conditions remains largely unexplored, despite its critical importance for broader applicability. This paper investigates the performance of the hybrid variational autoencoder (VAE)-non-negative matrix factorization (NMF) model for SE, focusing primarily on its generalizability to pathological speakers with Parkinson's disease. We show that VAE models trained on large neurotypical datasets perform poorly on pathological speech. While fine-tuning these pre-trained models with pathological speech improves performance, a performance gap remains between neurotypical and pathological speakers. To address this gap, we propose using personalized SE models derived from fine-tuning pre-trained models with only a few seconds of clean data from each speaker. Our results demonstrate that personalized models considerably enhance performance for all speakers, achieving comparable results for both neurotypical and pathological speakers.

Paper number 60:
Title: A Modular Edge Device Network for Surgery Digitalization
Authors: Vincent Schorp, Frédéric Giraud, Gianluca Pargätzi, Michael Wäspe, Lorenzo von Ritter-Zahony, Marcel Wegmann, John Garcia Henao, Dominique Cachin, Sebastiano Caprara, Philipp Fürnstahl, Fabio Carrillo
Abstract: Future surgical care demands real-time, integrated data to drive informed decision-making and improve patient outcomes. The pressing need for seamless and efficient data capture in the OR motivates our development of a modular solution that bridges the gap between emerging machine learning techniques and interventional medicine. We introduce a network of edge devices, called Data Hubs (DHs), that interconnect diverse medical sensors, imaging systems, and robotic tools via optical fiber and a centralized network switch. Built on the NVIDIA Jetson Orin NX, each DH supports multiple interfaces (HDMI, USB-C, Ethernet) and encapsulates device-specific drivers within Docker containers using the Isaac ROS framework and ROS2. A centralized user interface enables straightforward configuration and real-time monitoring, while an Nvidia DGX computer provides state-of-the-art data processing and storage. We validate our approach through an ultrasound-based 3D anatomical reconstruction experiment that combines medical imaging, pose tracking, and RGB-D data acquisition.

Paper number 61:
Title: Dynamic Joint Communications and Sensing Precoding Design: A Lyapunov Approach
Authors: Abolfazl Zakeri, Nhan Thanh Nguyen, Ahmed Alkhateeb, Markku Juntti
Abstract: This letter proposes a dynamic joint communications and sensing (JCAS) framework to adaptively design dedicated sensing and communications precoders. We first formulate a stochastic control problem to maximize the long-term average signal-to-noise ratio for sensing, subject to a minimum average communications signal-to-interference-plus-noise ratio requirement and a power budget. Using Lyapunov optimization, specifically the drift-plus-penalty method, we cast the problem into a sequence of per-slot non-convex problems. To solve these problems, we develop a successive convex approximation method. Additionally, we derive a closed-form solution to the per-slot problems based on the notion of zero-forcing. Numerical evaluations demonstrate the efficacy of the proposed methods and highlight their superiority compared to a baseline method based on conventional design.

Paper number 62:
Title: Deep Reinforcement Learning-based Video-Haptic Radio Resource Slicing in Tactile Internet
Authors: Georgios Kokkinis, Alexandros Iosifidis, Qi Zhang
Abstract: Enabling video-haptic radio resource slicing in the Tactile Internet requires a sophisticated strategy to meet the distinct requirements of video and haptic data, ensure their synchronized transmission, and address the stringent latency demands of haptic feedback. This paper introduces a Deep Reinforcement Learning-based radio resource slicing framework that addresses video-haptic teleoperation challenges by dynamically balancing radio resources between the video and haptic modalities. The proposed framework employs a refined reward function that considers latency, packet loss, data rate, and the synchronization requirements of both modalities to optimize resource allocation. By catering to the specific service requirements of video-haptic teleoperation, the proposed framework achieves up to a 25% increase in user satisfaction over existing methods, while maintaining effective resource slicing with execution intervals up to 50 ms.

Paper number 63:
Title: Modeling, Analysis, and Optimization of Cascaded Power Amplifiers
Authors: Oksana Moryakova, Thomas Eriksson, Håkan Johansson
Abstract: This paper deals with modeling, analysis, and optimization of power amplifiers (PAs) placed in a cascaded structure, particularly the effect of cascaded nonlinearities is studied by showing potential ways to minimize the total nonlinearities. The nonlinear least-squares algorithm is proposed to optimize the PA parameters along with the input power level, and thereby minimize the total nonlinearities in the cascaded structure. The simulation results demonstrate that the performance of the optimized configurations for up to five PAs using the proposed framework can improve the linearity properties of the overall cascade.

Paper number 64:
Title: Semantic Communication in Dynamic Channel Scenarios: Collaborative Optimization of Dual-Pipeline Joint Source-Channel Coding and Personalized Federated Learning
Authors: Xingrun Yan, Shiyuan Zuo, Yifeng Lyu, Rongfei Fan, Han Hu
Abstract: Semantic communication is designed to tackle issues like bandwidth constraints and high latency in communication systems. However, in complex network topologies with multiple users, the enormous combinations of client data and channel state information (CSI) pose significant challenges for existing semantic communication architectures. To improve the generalization ability of semantic communication models in complex scenarios while meeting the personalized needs of each user in their local environments, we propose a novel personalized federated learning framework with dual-pipeline joint source-channel coding based on channel awareness model (PFL-DPJSCCA). Within this framework, we present a method that achieves zero optimization gap for non-convex loss functions. Experiments conducted under varying SNR distributions validate the outstanding performance of our framework across diverse datasets.

Paper number 65:
Title: Image-Based Metrics in Ultrasound for Estimation of Global Speed-of-Sound
Authors: Roman Denkin, Orcun Goksel
Abstract: Accurate speed-of-sound (SoS) estimation is crucial for ultrasound image formation, yet conventional systems often rely on an assumed value for imaging. While several methods exist for SoS estimation, they typically depend on complex physical models of acoustic propagation. We propose to leverage conventional image analysis techniques and metrics, as a novel and simple approach to estimate tissue SoS. We study eleven metrics in three categories for assessing image quality, image similarity and multi-frame variation, by testing them in numerical simulations and phantom experiments. Among single-frame image quality metrics, conventional Focus and our proposed Smoothed Threshold Tenengrad metrics achieved satisfactory accuracy, however only when applied to compounded images. Image quality metrics were largely surpassed by various image comparison metrics, which exhibited errors consistently under 8 m/s even applied to a single pair of images. Particularly, Mean Square Error is a computationally efficient alternative for global estimation. Mutual Information and Correlation are found to be robust to processing small image segments, making them suitable, e.g., for multi-layer SoS estimation. The above metrics do not require access to raw channel data as they can operate on post-beamformed data, and in the case of image quality metrics they can operate on B-mode images, given that the beamforming SoS can be controlled for beamforming using a multitude of values. These image analysis based SoS estimation methods offer a computationally efficient and data-accessible alternative to conventional physics-based methods, with potential extensions to layered or local SoS imaging.

Paper number 66:
Title: Sheaf-Theoretic Causal Emergence for Resilience Analysis in Distributed Systems
Authors: Anatoly A. Krasnovsky
Abstract: Distributed systems often exhibit emergent behaviors that impact their resilience (Franz-Kaiser et al., 2020; Adilson E. Motter, 2002; Jianxi Gao, 2016). This paper presents a theoretical framework combining attributed graph models, flow-on-graph simulation, and sheaf-theoretic causal emergence analysis to evaluate system resilience. We model a distributed system as a graph with attributes (capturing component state and connections) and use sheaf theory to formalize how local interactions compose into global states. A flow simulation on this graph propagates functional loads and failures. To assess resilience, we apply the concept of causal emergence, quantifying whether macro-level dynamics (coarse-grained groupings) exhibit stronger causal efficacy (via effective information) than micro-level dynamics. The novelty lies in uniting sheaf-based formalization with causal metrics to identify emergent resilient structures. We discuss limitless potential applications (illustrated by microservices, neural networks, and power grids) and outline future steps toward implementing this framework (Lake et al., 2015).

Paper number 67:
Title: Decentralized Continuification Control of Multi-Agent Systems via Distributed Density Estimation
Authors: Beniamino Di Lorenzo, Gian Carlo Maffettone, Mario di Bernardo
Abstract: This paper introduces a novel decentralized implementation of a continuification-based strategy to control the density of large-scale multi-agent systems on the unit circle. While continuification methods effectively address micro-to-macro control problems by reformulating ordinary/stochastic differential equations (ODEs/SDEs) agent-based models into more tractable partial differential equations (PDEs), they traditionally require centralized knowledge of macroscopic state observables. We overcome this limitation by developing a distributed density estimation framework that combines kernel density estimation with PI consensus dynamics. Our approach enables agents to compute local density estimates and derive local control actions using only information from neighboring agents in a communication network. Numerical validations across multiple scenarios - including regulation, tracking, and time-varying communication topologies - confirm the effectiveness of the proposed approach. They also convincingly demonstrate that our decentralized implementation achieves performance comparable to centralized approaches while enhancing reliability and practical applicability.

Paper number 68:
Title: Room Impulse Response Estimation through Optimal Mass Transport Barycenters
Authors: Rumeshika Pallewela, Yuyang Liu, Filip Elvander
Abstract: In this work, we consider the problem of jointly estimating a set of room impulse responses (RIRs) corresponding to closely spaced microphones. The accurate estimation of RIRs is crucial in acoustic applications such as speech enhancement, noise cancellation, and auralization. However, real-world constraints such as short excitation signals, low signal-to-noise ratios, and poor spectral excitation, often render the estimation problem ill-posed. In this paper, we address these challenges by means of optimal mass transport (OMT) regularization. In particular, we propose to use an OMT barycenter, or generalized mean, as a mechanism for information sharing between the microphones. This allows us to quantify and exploit similarities in the delay-structures between the different microphones without having to impose rigid assumptions on the room acoustics. The resulting estimator is formulated in terms of the solution to a convex optimization problem which can be implemented using standard solvers. In numerical examples, we demonstrate the potential of the proposed method in addressing otherwise ill-conditioned estimation scenarios.

Paper number 69:
Title: Stacked-Residual PINN for State Reconstruction of Hyperbolic Systems
Authors: Katayoun Eshkofti, Matthieu Barreau
Abstract: In a more connected world, modeling multi-agent systems with hyperbolic partial differential equations (PDEs) offers a potential solution to the curse of dimensionality. However, classical control tools need adaptation for these complex systems. Physics-informed neural networks (PINNs) provide a powerful framework to fix this issue by inferring solutions to PDEs by embedding governing equations into the neural network. A major limitation of original PINNs is their inability to capture steep gradients and discontinuities in hyperbolic PDEs. This paper proposes a stacked residual PINN method enhanced with a vanishing viscosity mechanism. Initially, a basic PINN with a small viscosity coefficient provides a stable, low-fidelity solution. Residual correction blocks with learnable scaling parameters then iteratively refine this solution, progressively decreasing the viscosity coefficient to transition from parabolic to hyperbolic PDEs. Applying this method to traffic state reconstruction improved results by an order of magnitude in relative $\mathcal{L}^2$ error, demonstrating its potential to accurately estimate solutions where original PINNs struggle with instability and low fidelity.

Paper number 70:
Title: Cross-Environment Transfer Learning for Location-Aided Beam Prediction in 5G and Beyond Millimeter-Wave Networks
Authors: Enrico Tosi, Panwei Hu, Aleksandar Ichkov, Marina Petrova, Ljiljana Simić
Abstract: Millimeter-wave (mm-wave) communications requirebeamforming and consequent precise beam alignmentbetween the gNodeB (gNB) and the user equipment (UE) toovercome high propagation losses. This beam alignment needs tobe constantly updated for different UE locations based on beamsweepingradio frequency measurements, leading to significantbeam management overhead. One potential solution involvesusing machine learning (ML) beam prediction algorithms thatleverage UE position information to select the serving beamwithout the overhead of beam sweeping. However, the highlysite-specific nature of mm-wave propagation means that MLmodels require training from scratch for each scenario, whichis inefficient in practice. In this paper, we propose a robustcross-environment transfer learning solution for location-aidedbeam prediction, whereby the ML model trained on a referencegNB is transferred to a target gNB by fine-tuning with a limiteddataset. Extensive simulation results based on ray-tracing in twourban environments show the effectiveness of our solution forboth inter- and intra-city model transfer. Our results show thatby training the model on a reference gNB and transferring themodel by fine-tuning with only 5% of the target gNB dataset,we can achieve 80% accuracy in predicting the best beamfor the target gNB. Importantly, our approach improves thepoor generalization accuracy of transferring the model to newenvironments without fine-tuning by around 75 percentage this http URL demonstrates that transfer learning enables high predictionaccuracy while reducing the computational and training datasetcollection burden of ML-based beam prediction, making itpractical for 5G-and-beyond deployments.

Paper number 71:
Title: Principal Component Maximization: A Novel Method for SAR Image Formation from Raw Data without System Parameters
Authors: Huizhang Yang, Zhong Liu, Jian Yang
Abstract: Synthetic aperture radar (SAR) imaging traditionally requires precise knowledge of system parameters to implement focusing algorithms that transform raw data into high-resolution images. These algorithms require knowledge of SAR system parameters, such as wavelength, center slant range, fast time sampling rate, pulse repetition interval (PRI), waveform parameters (e.g., frequency modulation rate), and platform speed. This paper presents a novel framework for recovering SAR images from raw data without the requirement of any SAR system parameters. Firstly, we introduce an approximate matched filtering model that leverages the inherent shift-invariance properties of SAR echoes, enabling image formation through an adaptive reference echo estimation. To estimate this unknown reference echo, we develop a principal component maximization (PCM) technique that exploits the low-dimensional structure of the SAR signal. The PCM method employs a three-stage procedure: 1) data block segmentation, 2) energy normalization, and 3) principal component energy maximization across blocks, effectively handling non-stationary clutter environments. Secondly, we present a range-varying azimuth reference signal estimation method that compensates for the quadratic phase errors. For cases where PRI is unknown, we propose a two-step PRI estimation scheme that enables robust reconstruction of 2-D images from 1-D data streams. Experimental results on various SAR datasets demonstrate that our method can effectively recover SAR images from raw data without any prior system parameters.

Paper number 72:
Title: RoMedFormer: A Rotary-Embedding Transformer Foundation Model for 3D Genito-Pelvic Structure Segmentation in MRI and CT
Authors: Yuheng Li, Mingzhe Hu, Richard L.J. Qiu, Maria Thor, Andre Williams, Deborah Marshall, Xiaofeng Yang
Abstract: Deep learning-based segmentation of genito-pelvic structures in MRI and CT is crucial for applications such as radiation therapy, surgical planning, and disease diagnosis. However, existing segmentation models often struggle with generalizability across imaging modalities, and anatomical variations. In this work, we propose RoMedFormer, a rotary-embedding transformer-based foundation model designed for 3D female genito-pelvic structure segmentation in both MRI and CT. RoMedFormer leverages self-supervised learning and rotary positional embeddings to enhance spatial feature representation and capture long-range dependencies in 3D medical data. We pre-train our model using a diverse dataset of 3D MRI and CT scans and fine-tune it for downstream segmentation tasks. Experimental results demonstrate that RoMedFormer achieves superior performance segmenting genito-pelvic organs. Our findings highlight the potential of transformer-based architectures in medical image segmentation and pave the way for more transferable segmentation frameworks.

Paper number 73:
Title: An Assessment of the UK Government Clean Energy Strategy for the Year 2030
Authors: Anthony D. Stephens, David R. Walwyn
Abstract: In 2024, the UK Government made two striking announcements on its plans to decarbonise the energy system; it pledged GBP22 billion to establish carbon capture and storage hubs on Teesside and Merseyside and released the Clean Power 2030 Action Plan. This paper questions the validity of both plans, arguing that they do not take adequate account of the consequences of the highly variable nature of wind and solar generations. Using dynamic models of future UK electricity systems which are designed to take account of these variabilities, it is shown that the Clean Power 2030 Action Plan overestimates the ability of wind and solar generations to decarbonise the electricity system as they increase in size relative to the demand of the electricity system. More importantly, the dynamic models show that most of the achievable decarbonization is the result of increasing wind generation from the current level of around 10 GW to around 20 GW. Increasing wind generation to only 20 GW, rather than to 30 GW as proposed in the Action Plan, should halve the proposed cost, a saving of perhaps GBP 120 billion, with little disbenefit in terms of reduced decarbonization. Furthermore, the dynamic modelling shows that UK gas storage capacity of 7.5 winter days looks hopeless inadequate in comparison with the storage capacities deemed necessary by its continental neighbors. Concern is expressed that a consequence of the Climate Change Act of 2008 requiring the UK to meet arbitrary decarbonization targets is leading government advisors to propose several unproven and therefore highly risky technological solutions.

Paper number 74:
Title: Equiripple MIMO Beampattern Synthesis using Chebyshev Approximation
Authors: David A. Hague, David G. Felton
Abstract: This letter presents a method for synthesizing equiripple MIMO transmit beampatterns using Chebyshev approximation. The MIMO beampattern is represented as a non-negative real-valued trigonometric polynomial where the $\ell^{\text{th}}$ order polynomial coefficient is the sum of the $\ell^{\text{th}}$ order diagonal of the waveform correlation matrix. The optimal coefficients for a given equiripple beampattern design is then posed as a Chebyshev approximation problem which is efficiently solved using the Parks-McClellan algorithm from optimal Finite Impulse Response (FIR) filter design theory. The unique advantage of this synthesis method is that it provides a closed form method to generating MIMO correlation matrices that realize the desired equiripple beampattern. This correspondingly facilitates the design of waveform sets that closely approximate those correlation matrices. This method is demonstrated via two illustrative design examples; the first using traditional partial signal correlation methods and the second using transmit beamspace processing. Both examples realize equiripple beampatterns using constant envelope and spectrally compact waveform sets.

Paper number 75:
Title: Near-Field Beam Prediction Using Far-Field Codebooks in Ultra-Massive MIMO Systems
Authors: Ahmed Hussain, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil
Abstract: Ultra-massive multiple-input multiple-output (UM-MIMO) technology is a key enabler for 6G networks, offering exceptional high data rates in millimeter-wave (mmWave) and Terahertz (THz) frequency bands. The deployment of large antenna arrays at high frequencies transitions wireless communication into the radiative near-field, where precise beam alignment becomes essential for accurate channel estimation. Unlike far-field systems, which rely on angular domain only, near-field necessitates beam search across both angle and distance dimensions, leading to substantially higher training overhead. To address this challenge, we propose a discrete Fourier transform (DFT) based beam alignment to mitigate the training overhead. We highlight that the reduced path loss at shorter distances can compensate for the beamforming losses typically associated with using far-field codebooks in near-field scenarios. Additionally, far-field beamforming in the near-field exhibits angular spread, with its width determined by the user's range and angle. Leveraging this relationship, we develop a correlation interferometry (CI) algorithm, termed CI-DFT, to efficiently estimate user angle and range parameters. Simulation results demonstrate that the proposed scheme achieves performance close to exhaustive search in terms of achievable rate while significantly reducing the training overhead by 87.5%.

Paper number 76:
Title: Multi-Prototype Embedding Refinement for Semi-Supervised Medical Image Segmentation
Authors: Yali Bi, Enyu Che, Yinan Chen, Yuanpeng He, Jingwei Qu
Abstract: Medical image segmentation aims to identify anatomical structures at the voxel-level. Segmentation accuracy relies on distinguishing voxel differences. Compared to advancements achieved in studies of the inter-class variance, the intra-class variance receives less attention. Moreover, traditional linear classifiers, limited by a single learnable weight per class, struggle to capture this finer distinction. To address the above challenges, we propose a Multi-Prototype-based Embedding Refinement method for semi-supervised medical image segmentation. Specifically, we design a multi-prototype-based classification strategy, rethinking the segmentation from the perspective of structural relationships between voxel embeddings. The intra-class variations are explored by clustering voxels along the distribution of multiple prototypes in each class. Next, we introduce a consistency constraint to alleviate the limitation of linear classifiers. This constraint integrates different classification granularities from a linear classifier and the proposed prototype-based classifier. In the thorough evaluation on two popular benchmarks, our method achieves superior performance compared with state-of-the-art methods. Code is available at this https URL.

Paper number 77:
Title: MoonCast: High-Quality Zero-Shot Podcast Generation
Authors: Zeqian Ju, Dongchao Yang, Jianwei Yu, Kai Shen, Yichong Leng, Zhengtao Wang, Xu Tan, Xinyu Zhou, Tao Qin, Xiangyang Li
Abstract: Recent advances in text-to-speech synthesis have achieved notable success in generating high-quality short utterances for individual speakers. However, these systems still face challenges when extending their capabilities to long, multi-speaker, and spontaneous dialogues, typical of real-world scenarios such as podcasts. These limitations arise from two primary challenges: 1) long speech: podcasts typically span several minutes, exceeding the upper limit of most existing work; 2) spontaneity: podcasts are marked by their spontaneous, oral nature, which sharply contrasts with formal, written contexts; existing works often fall short in capturing this spontaneity. In this paper, we propose MoonCast, a solution for high-quality zero-shot podcast generation, aiming to synthesize natural podcast-style speech from text-only sources (e.g., stories, technical reports, news in TXT, PDF, or Web URL formats) using the voices of unseen speakers. To generate long audio, we adopt a long-context language model-based audio modeling approach utilizing large-scale long-context speech data. To enhance spontaneity, we utilize a podcast generation module to generate scripts with spontaneous details, which have been empirically shown to be as crucial as the text-to-speech modeling itself. Experiments demonstrate that MoonCast outperforms baselines, with particularly notable improvements in spontaneity and coherence.

Paper number 78:
Title: Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework
Authors: Erik G. Larsson, Nicolo Michelusi
Abstract: The decentralized gradient descent (DGD) algorithm, and its sibling, diffusion, are workhorses in decentralized machine learning, distributed inference and estimation, and multi-agent coordination. We propose a novel, principled framework for the analysis of DGD and diffusion for strongly convex, smooth objectives, and arbitrary undirected topologies, using contraction mappings coupled with a result called the mean Hessian theorem (MHT). The use of these tools yields tight convergence bounds, both in the noise-free and noisy regimes. While these bounds are qualitatively similar to results found in the literature, our approach using contractions together with the MHT decouples the algorithm dynamics (how quickly the algorithm converges to its fixed point) from its asymptotic convergence properties (how far the fixed point is from the global optimum). This yields a simple, intuitive analysis that is accessible to a broader audience. Extensions are provided to multiple local gradient updates, time-varying step sizes, noisy gradients (stochastic DGD and diffusion), communication noise, and random topologies.

Paper number 79:
Title: Online ResNet-Based Adaptive Control for Nonlinear Target Tracking
Authors: Cristian F. Nino, Omkar Sudhir Patil, Marla R. Eisman, Warren E. Dixon
Abstract: This work introduces a generalized ResNet architecture for adaptive control of nonlinear systems with black box uncertainties. The approach overcomes limitations in existing methods by incorporating pre-activation shortcut connections and a zeroth layer block that accommodates different input-output dimensions. The developed Lyapunov-based adaptation law establishes semi-global exponential convergence to a neighborhood of the target state despite unknown dynamics and disturbances. Furthermore, the theoretical results are validated through a comparative simulation.

Paper number 80:
Title: On the Standard Performance Criteria for Applied Control Design: PID, MPC or Machine Learning Controller?
Authors: Pouria Sarhadi
Abstract: The traditional control theory and its application to basic and complex systems have reached an advanced level of maturity. This includes aerial, marine, and ground vehicles, as well as robotics, chemical, transportation, and electrical systems widely used in our daily lives. The emerging era of data-driven methods, Large Language Models (LLMs), and AI-based controllers does not indicate a weakness in well-established control theory. Instead, it aims to reduce dependence on models and uncertainties, address increasingly complex systems, and potentially achieve decision-making capabilities comparable to human-level performance. This revolution integrates knowledge from computer science, machine learning, biology, and classical control, producing promising algorithms that are yet to demonstrate widespread real-world applicability. Despite the maturity of control theory and the presence of various performance criteria, there is still a lack of standardised metrics for testing, evaluation, Verification and Validation ($V\&V$) of algorithms. This gap can lead to algorithms that, while optimal in certain aspects, may fall short of practical implementation, sparking debates within the literature. For a controller to succeed in real-world applications, it must satisfy three key categories of performance metrics: tracking quality, control effort (energy consumption), and robustness. This paper rather takes an applied perspective, proposing and consolidating standard performance criteria for testing and analysing control systems, intended for researchers and students. The proposed framework ensures the post-design applicability of a black-box algorithm, aligning with modern data analysis and $V\&V$ perspectives to prevent resource allocation to systems with limited impact or imprecise claims.

Paper number 81:
Title: Inference and Learning of Nonlinear LFR State-space Models
Authors: Merijn Floren, Jean-Philippe Noël, Jan Swevers
Abstract: Estimating the parameters of nonlinear block-oriented state-space models from input-output data typically involves solving a highly non-convex optimization problem, making it susceptible to poor local minima and slow convergence. This paper presents a computationally efficient initialization method for fully parametrizing nonlinear linear fractional representation (NL-LFR) models using periodic data. The approach first infers the latent variables and then estimates the model parameters, yielding initial estimates that serve as a starting point for further nonlinear optimization. The proposed method shows robustness against poor local minima, and achieves a twofold error reduction compared to the state-of-the-art on a challenging benchmark dataset.

Paper number 82:
Title: Decentralized RISE-based Control for Exponential Heterogeneous Multi-Agent Target Tracking of Second-Order Nonlinear Systems
Authors: Cristian F. Nino, Omkar Sudhir Patil, Sage C. Edwards, Warren E. Dixon
Abstract: This work presents a decentralized implementation of a Robust Integral of the Sign of the Error (RISE) controller for multi-agent target tracking problems with exponential convergence guarantees. Previous RISE-based approaches for multi-agent systems required 2-hop communication, limiting practical applicability. New insights from a Lyapunov-based design-analysis approach are used to eliminate the need for multi-hop communication required in previous literature, while yielding exponential target tracking. The new insights include the development of a new P-function which is developed which works in tandem with the inclusion of the interaction matrix in the Lyapunov function. Nonsmooth Lyapunov-based stability analysis methods are used to yield semi-global exponential convergence to the target agent state despite the presence of bounded disturbances with bounded derivatives. The resulting outcome is a controller that achieves exponential target tracking with only local information exchange between neighboring agents.

Paper number 83:
Title: A Comprehensive Study of IPTV: Challenges, Opportunities, and Future Trends
Authors: Georgios Giannakopoulos, Khushbu Mehboob Shaikh, Maria Antonnette Perez
Abstract: IPTV (Internet Protocol Television) is a transformative approach to delivering audio and video services through high-speed Internet networks, enabling direct access to television content via home computers or set-top boxes. Despite its promising advantages, including flexibility, interactivity, and bundled services such as triple play (voice, Internet, and TV) and quadruple play (adding mobile services), IPTV is still in its development phase. Key challenges include achieving a Quality of Service (QoS) comparable to traditional broadcasters, addressing limited bandwidth, and overcoming a lack of standardization among service providers. This paper explores the technical, operational, and consumer-oriented aspects of IPTV. It discusses data compression techniques, protocols like IGMP and RTSP, and the role of advanced codecs like H.264 in ensuring efficient data transmission. The study also examines the distinctions between IPTV and open-network Internet TV, the importance of security and privacy, and the emergence of new business opportunities through targeted advertising and interactive services. Although IPTV is unlikely to completely replace traditional broadcasting, it is poised to play an important role in shaping the future of television by offering personalized, secure, and scalable viewing experiences.

Paper number 84:
Title: AI-driven control of bioelectric signalling for real-time topological reorganization of cells
Authors: Gonçalo Hora de Carvalho
Abstract: Understanding and manipulating bioelectric signaling could present a new wave of progress in developmental biology, regenerative medicine, and synthetic biology. Bioelectric signals, defined as voltage gradients across cell membranes caused by ionic movements, play a role in regulating crucial processes including cellular differentiation, proliferation, apoptosis, and tissue morphogenesis. Recent studies demonstrate the ability to modulate these signals to achieve controlled tissue regeneration and morphological outcomes in organisms such as planaria and frogs. However, significant knowledge gaps remain, particularly in predicting and controlling the spatial and temporal dynamics of membrane potentials (V_mem), understanding their regulatory roles in tissue and organ development, and exploring their therapeutic potential in diseases. In this work we propose an experiment using Deep Reinforcement Learning (DRL) framework together with lab automation techniques for real-time manipulation of bioelectric signals to guide tissue regeneration and morphogenesis. The proposed framework should interact continuously with biological systems, adapting strategies based on direct biological feedback. Combining DRL with real-time measurement techniques -- such as optogenetics, voltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could provide a comprehensive platform for precise bioelectric control, leading to improved understanding of bioelectric mechanisms in morphogenesis, quantitative bioelectric models, identification of minimal experimental setups, and advancements in bioelectric modulation techniques relevant to regenerative medicine and cancer therapy. Ultimately, this research aims to utilize bioelectric signaling to develop new biomedical and bioengineering applications.

Paper number 85:
Title: Transformable Modular Robots: A CPG-Based Approach to Independent and Collective Locomotion
Authors: Jiayu Ding, Rohit Jakkula, Tom Xiao, Zhenyu Gan
Abstract: Modular robotics enables the development of versatile and adaptive robotic systems with autonomous reconfiguration. This paper presents a modular robotic system in which each module has independent actuation, battery power, and control, allowing both individual mobility and coordinated locomotion. A hierarchical Central Pattern Generator (CPG) framework governs motion, with a low-level CPG controlling individual modules and a high-level CPG synchronizing inter-module coordination, enabling smooth transitions between independent and collective behaviors. To validate the system, we conduct simulations in MuJoCo and hardware experiments, evaluating locomotion across different configurations. We first analyze single-module motion, followed by two-module cooperative locomotion. Results demonstrate the effectiveness of the CPG-based control framework in achieving robust, flexible, and scalable locomotion. The proposed modular architecture has potential applications in search and rescue, environmental monitoring, and autonomous exploration, where adaptability and reconfigurability are essential.

Paper number 86:
Title: A finite-sample bound for identifying partially observed linear switched systems from a single trajectory
Authors: Daniel Racz, Mihaly Petreczky, Balint Daroczy
Abstract: We derive a finite-sample probabilistic bound on the parameter estimation error of a system identification algorithm for Linear Switched Systems. The algorithm estimates Markov parameters from a single trajectory and applies a variant of the Ho-Kalman algorithm to recover the system matrices. Our bound guarantees statistical consistency under the assumption that the true system exhibits quadratic stability. The proof leverages the theory of weakly dependent processes. To the best of our knowledge, this is the first finite-sample bound for this algorithm in the single-trajectory setting.

Paper number 87:
Title: SCAN-BEST: Efficient Sub-6GHz-Aided Near-field Beam Selection with Formal Reliability Guarantee
Authors: Weicao Deng, Binpu Shi, Min Li, Osvaldo Simeone
Abstract: As millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems continue to incorporate larger antenna arrays, the range of near-field propagation expands, making it more likely for users close to the transmitter to fall within the near-field regime. Traditional far-field beam training methods are no longer effective in this context. Additionally, near-field beam training presents challenges, since the training codebook must account for both angular and distance dimensions, leading to large codebook sizes. To reduce the in-band training overhead, we propose the Sub-6G Channel-Aided Near-field BEam SelecTion (SCAN-BEST) framework, which is motivated by the spatial-temporal congruence between sub-6 GHz (sub-6G) and mmWave channels. SCAN-BEST utilizes preprocessed sub-6G channel estimates as input, and employs a convolutional neural network (CNN) to predict the probability of each beam being optimal within the near-field beam training codebook. Given the prediction uncertainty arising from the variance between sub-6G and mmWave channels, we introduce a conformal risk control (CRC)-based module that generates a set of beam candidates for further limited in-band training, enabling the final beam selection to formally meet user-defined target coverage rate. Numerical results confirm the thereoretical properties of SCAN-BEST in terms of the achieved coverage rate of the beam candidates and various metrics. Moreover, SCAN-BEST enjoys good scalability and robustness to various sub-6G system configurations, including to the sizes of calibration datasets.

Paper number 88:
Title: Multi-Modal Self-Supervised Semantic Communication
Authors: Hang Zhao, Hongru Li, Dongfang Xu, Shenghui Song, Khaled B. Letaief
Abstract: Semantic communication is emerging as a promising paradigm that focuses on the extraction and transmission of semantic meanings using deep learning techniques. While current research primarily addresses the reduction of semantic communication overhead, it often overlooks the training phase, which can incur significant communication costs in dynamic wireless environments. To address this challenge, we propose a multi-modal semantic communication system that leverages multi-modal self-supervised learning to enhance task-agnostic feature extraction. The proposed approach employs self-supervised learning during the pre-training phase to extract task-agnostic semantic features, followed by supervised fine-tuning for downstream tasks. This dual-phase strategy effectively captures both modality-invariant and modality-specific features while minimizing training-related communication overhead. Experimental results on the NYU Depth V2 dataset demonstrate that the proposed method significantly reduces training-related communication overhead while maintaining or exceeding the performance of existing supervised learning approaches. The findings underscore the advantages of multi-modal self-supervised learning in semantic communication, paving the way for more efficient and scalable edge inference systems.

Paper number 89:
Title: ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors
Authors: Jake Rap, Amritam Das
Abstract: Accurate traffic flow estimation and prediction are critical for the efficient management of transportation systems, particularly under increasing urbanization. Traditional methods relying on static sensors often suffer from limited spatial coverage, while probe vehicles provide richer, albeit sparse and irregular data. This work introduces ON-Traffic, a novel deep operator Network and a receding horizon learning-based framework tailored for online estimation of spatio-temporal traffic state along with quantified uncertainty by using measurements from moving probe vehicles and downstream boundary inputs. Our framework is evaluated in both numerical and simulation datasets, showcasing its ability to handle irregular, sparse input data, adapt to time-shifted scenarios, and provide well-calibrated uncertainty estimates. The results demonstrate that the model captures complex traffic phenomena, including shockwaves and congestion propagation, while maintaining robustness to noise and sensor dropout. These advancements present a significant step toward online, adaptive traffic management systems.

Paper number 90:
Title: Modular Distributed Nonconvex Learning with Error Feedback
Authors: Guido Carnevale, Nicola Bastianello
Abstract: In this paper, we design a novel distributed learning algorithm using stochastic compressed communications. In detail, we pursue a modular approach, merging ADMM and a gradient-based approach, benefiting from the robustness of the former and the computational efficiency of the latter. Additionally, we integrate a stochastic integral action (error feedback) enabling almost sure rejection of the compression error. We analyze the resulting method in nonconvex scenarios and guarantee almost sure asymptotic convergence to the set of stationary points of the problem. This result is obtained using system-theoretic tools based on stochastic timescale separation. We corroborate our findings with numerical simulations in nonconvex classification.

Paper number 91:
Title: Comparative and Interpretative Analysis of CNN and Transformer Models in Predicting Wildfire Spread Using Remote Sensing Data
Authors: Yihang Zhou, Ruige Kong, Zhengsen Xu, Linlin Xu, Sibo Cheng
Abstract: Facing the escalating threat of global wildfires, numerous computer vision techniques using remote sensing data have been applied in this area. However, the selection of deep learning methods for wildfire prediction remains uncertain due to the lack of comparative analysis in a quantitative and explainable manner, crucial for improving prevention measures and refining models. This study aims to thoroughly compare the performance, efficiency, and explainability of four prevalent deep learning architectures: Autoencoder, ResNet, UNet, and Transformer-based Swin-UNet. Employing a real-world dataset that includes nearly a decade of remote sensing data from California, U.S., these models predict the spread of wildfires for the following day. Through detailed quantitative comparison analysis, we discovered that Transformer-based Swin-UNet and UNet generally outperform Autoencoder and ResNet, particularly due to the advanced attention mechanisms in Transformer-based Swin-UNet and the efficient use of skip connections in both UNet and Transformer-based Swin-UNet, which contribute to superior predictive accuracy and model interpretability. Then we applied XAI techniques on all four models, this not only enhances the clarity and trustworthiness of models but also promotes focused improvements in wildfire prediction capabilities. The XAI analysis reveals that UNet and Transformer-based Swin-UNet are able to focus on critical features such as 'Previous Fire Mask', 'Drought', and 'Vegetation' more effectively than the other two models, while also maintaining balanced attention to the remaining features, leading to their superior performance. The insights from our thorough comparative analysis offer substantial implications for future model design and also provide guidance for model selection in different scenarios.

Paper number 92:
Title: RBFIM: Perceptual Quality Assessment for Compressed Point Clouds Using Radial Basis Function Interpolation
Authors: Zhang Chen, Shuai Wan, Siyu Ren, Fuzheng Yang, Mengting Yu, Junhui Hou
Abstract: One of the main challenges in point cloud compression (PCC) is how to evaluate the perceived distortion so that the codec can be optimized for perceptual quality. Current standard practices in PCC highlight a primary issue: while single-feature metrics are widely used to assess compression distortion, the classic method of searching point-to-point nearest neighbors frequently fails to adequately build precise correspondences between point clouds, resulting in an ineffective capture of human perceptual features. To overcome the related limitations, we propose a novel assessment method called RBFIM, utilizing radial basis function (RBF) interpolation to convert discrete point features into a continuous feature function for the distorted point cloud. By substituting the geometry coordinates of the original point cloud into the feature function, we obtain the bijective sets of point features. This enables an establishment of precise corresponding features between distorted and original point clouds and significantly improves the accuracy of quality assessments. Moreover, this method avoids the complexity caused by bidirectional searches. Extensive experiments on multiple subjective quality datasets of compressed point clouds demonstrate that our RBFIM excels in addressing human perception tasks, thereby providing robust support for PCC optimization efforts.

Paper number 93:
Title: Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images
Authors: Simon Niedermayr, Christoph Neuhauser Rüdiger Westermann
Abstract: We introduce an image upscaling technique tailored for 3D Gaussian Splatting (3DGS) on lightweight GPUs. Compared to 3DGS, it achieves significantly higher rendering speeds and reduces artifacts commonly observed in 3DGS reconstructions. Our technique upscales low-resolution 3DGS renderings with a marginal increase in cost by directly leveraging the analytical image gradients of Gaussians for gradient-based bicubic spline interpolation. The technique is agnostic to the specific 3DGS implementation, achieving novel view synthesis at rates 3x-4x higher than the baseline implementation. Through extensive experiments on multiple datasets, we showcase the performance improvements and high reconstruction fidelity attainable with gradient-aware upscaling of 3DGS images. We further demonstrate the integration of gradient-aware upscaling into the gradient-based optimization of a 3DGS model and analyze its effects on reconstruction quality and performance.

Paper number 94:
Title: Distributions and Direct Parametrization for Stable Stochastic State-Space Models
Authors: Mohamad Al Ahdab, Zheng-Hua Tan, John Leth
Abstract: We present a direct parametrization for continuous-time stochastic state-space models that ensures external stability via the stochastic bounded-real lemma. Our formulation facilitates the construction of probabilistic priors that enforce almost-sure stability which are suitable for sampling-based Bayesian inference methods. We validate our work with a simulation example and demonstrate its ability to yield stable predictions with uncertainty quantification.

Paper number 95:
Title: Variable Time-Step MPC for Agile Multi-Rotor UAV Interception of Dynamic Targets
Authors: Atharva Ghotavadekar, František Nekovář, Martin Saska, Jan Faigl
Abstract: Agile trajectory planning can improve the efficiency of multi-rotor Uncrewed Aerial Vehicles (UAVs) in scenarios with combined task-oriented and kinematic trajectory planning, such as monitoring spatio-temporal phenomena or intercepting dynamic targets. Agile planning using existing non-linear model predictive control methods is limited by the number of planning steps as it becomes increasingly computationally demanding. That reduces the prediction horizon length, leading to a decrease in solution quality. Besides, the fixed time-step length limits the utilization of the available UAV dynamics in the target neighborhood. In this paper, we propose to address these limitations by introducing variable time steps and coupling them with the prediction horizon length. A simplified point-mass motion primitive is used to leverage the differential flatness of quadrotor dynamics and the generation of feasible trajectories in the flat output space. Based on the presented evaluation results and experimentally validated deployment, the proposed method increases the solution quality by enabling planning for long flight segments but allowing tightly sampled maneuvering.

Paper number 96:
Title: AdaST: Dynamically Adapting Encoder States in the Decoder for End-to-End Speech-to-Text Translation
Authors: Wuwei Huang, Dexin Wang, Deyi Xiong
Abstract: In end-to-end speech translation, acoustic representations learned by the encoder are usually fixed and static, from the perspective of the decoder, which is not desirable for dealing with the cross-modal and cross-lingual challenge in speech translation. In this paper, we show the benefits of varying acoustic states according to decoder hidden states and propose an adaptive speech-to-text translation model that is able to dynamically adapt acoustic states in the decoder. We concatenate the acoustic state and target word embedding sequence and feed the concatenated sequence into subsequent blocks in the decoder. In order to model the deep interaction between acoustic states and target hidden states, a speech-text mixed attention sublayer is introduced to replace the conventional cross-attention network. Experiment results on two widely-used datasets show that the proposed method significantly outperforms state-of-the-art neural speech translation models.

Paper number 97:
Title: Segmentation-Guided Neural Radiance Fields for Novel Street View Synthesis
Authors: Yizhou Li, Yusuke Monno, Masatoshi Okutomi, Yuuichi Tanaka, Seiichi Kataoka, Teruaki Kosiba
Abstract: Recent advances in Neural Radiance Fields (NeRF) have shown great potential in 3D reconstruction and novel view synthesis, particularly for indoor and small-scale scenes. However, extending NeRF to large-scale outdoor environments presents challenges such as transient objects, sparse cameras and textures, and varying lighting conditions. In this paper, we propose a segmentation-guided enhancement to NeRF for outdoor street scenes, focusing on complex urban environments. Our approach extends ZipNeRF and utilizes Grounded SAM for segmentation mask generation, enabling effective handling of transient objects, modeling of the sky, and regularization of the ground. We also introduce appearance embeddings to adapt to inconsistent lighting across view sequences. Experimental results demonstrate that our method outperforms the baseline ZipNeRF, improving novel view synthesis quality with fewer artifacts and sharper details.

Paper number 98:
Title: CTSR: Controllable Fidelity-Realness Trade-off Distillation for Real-World Image Super Resolution
Authors: Runyi Li, Bin Chen, Jian Zhang, Radu Timofte
Abstract: Real-world image super-resolution is a critical image processing task, where two key evaluation criteria are the fidelity to the original image and the visual realness of the generated results. Although existing methods based on diffusion models excel in visual realness by leveraging strong priors, they often struggle to achieve an effective balance between fidelity and realness. In our preliminary experiments, we observe that a linear combination of multiple models outperforms individual models, motivating us to harness the strengths of different models for a more effective trade-off. Based on this insight, we propose a distillation-based approach that leverages the geometric decomposition of both fidelity and realness, alongside the performance advantages of multiple teacher models, to strike a more balanced trade-off. Furthermore, we explore the controllability of this trade-off, enabling a flexible and adjustable super-resolution process, which we call CTSR (Controllable Trade-off Super-Resolution). Experiments conducted on several real-world image super-resolution benchmarks demonstrate that our method surpasses existing state-of-the-art approaches, achieving superior performance across both fidelity and realness metrics.

Paper number 99:
Title: Improved Scalable Lipschitz Bounds for Deep Neural Networks
Authors: Usman Syed, Bin Hu
Abstract: Computing tight Lipschitz bounds for deep neural networks is crucial for analyzing their robustness and stability, but existing approaches either produce relatively conservative estimates or rely on semidefinite programming (SDP) formulations (namely the LipSDP condition) that face scalability issues. Building upon ECLipsE-Fast, the state-of-the-art Lipschitz bound method that avoids SDP formulations, we derive a new family of improved scalable Lipschitz bounds that can be combined to outperform ECLipsE-Fast. Specifically, we leverage more general parameterizations of feasible points of LipSDP to derive various closed-form Lipschitz bounds, avoiding the use of SDP solvers. In addition, we show that our technique encompasses ECLipsE-Fast as a special case and leads to a much larger class of scalable Lipschitz bounds for deep neural networks. Our empirical study shows that our bounds improve ECLipsE-Fast, further advancing the scalability and precision of Lipschitz estimation for large neural networks.

Paper number 100:
Title: LeanVAE: An Ultra-Efficient Reconstruction VAE for Video Diffusion Models
Authors: Yu Cheng, Fajie Yuan
Abstract: Recent advances in Latent Video Diffusion Models (LVDMs) have revolutionized video generation by leveraging Video Variational Autoencoders (Video VAEs) to compress intricate video data into a compact latent this http URL, as LVDM training scales, the computational overhead of Video VAEs becomes a critical bottleneck, particularly for encoding high-resolution videos. To address this, we propose LeanVAE, a novel and ultra-efficient Video VAE framework that introduces two key innovations: (1) a lightweight architecture based on a Neighborhood-Aware Feedforward (NAF) module and non-overlapping patch operations, drastically reducing computational cost, and (2) the integration of wavelet transforms and compressed sensing techniques to enhance reconstruction quality. Extensive experiments validate LeanVAE's superiority in video reconstruction and generation, particularly in enhancing efficiency over existing Video this http URL model offers up to 50x fewer FLOPs and 44x faster inference speed while maintaining competitive reconstruction quality, providing insights for scalable, efficient video this http URL models and code are available at this https URL.

Paper number 101:
Title: Risk-Sensitive Model Predictive Control for Interaction-Aware Planning -- A Sequential Convexification Algorithm
Authors: Renzi Wang, Mathijs Schuurmans, Panagiotis Patrinos
Abstract: This paper considers risk-sensitive model predictive control for stochastic systems with a decision-dependent distribution. This class of systems is commonly found in human-robot interaction scenarios. We derive computationally tractable convex upper bounds to both the objective function, and to frequently used penalty terms for collision avoidance, allowing us to efficiently solve the generally nonconvex optimal control problem as a sequence of convex problems. Simulations of a robot navigating a corridor demonstrate the effectiveness and the computational advantage of the proposed approach.

Paper number 102:
Title: ADAPT: An Autonomous Forklift for Construction Site Operation
Authors: Johannes Huemer, Markus Murschitz, Matthias Schörghuber, Lukas Reisinger, Thomas Kadiofsky, Christoph Weidinger, Mario Niedermeyer, Benedikt Widy, Marcel Zeilinger, Csaba Beleznai, Tobias Glück, Andreas Kugi, Patrik Zips
Abstract: Efficient material logistics play a critical role in controlling costs and schedules in the construction industry. However, manual material handling remains prone to inefficiencies, delays, and safety risks. Autonomous forklifts offer a promising solution to streamline on-site logistics, reducing reliance on human operators and mitigating labor shortages. This paper presents the development and evaluation of the Autonomous Dynamic All-terrain Pallet Transporter (ADAPT), a fully autonomous off-road forklift designed for construction environments. Unlike structured warehouse settings, construction sites pose significant challenges, including dynamic obstacles, unstructured terrain, and varying weather conditions. To address these challenges, our system integrates AI-driven perception techniques with traditional approaches for decision making, planning, and control, enabling reliable operation in complex environments. We validate the system through extensive real-world testing, comparing its long-term performance against an experienced human operator across various weather conditions. We also provide a comprehensive analysis of challenges and key lessons learned, contributing to the advancement of autonomous heavy machinery. Our findings demonstrate that autonomous outdoor forklifts can operate near human-level performance, offering a viable path toward safer and more efficient construction logistics.

Paper number 103:
Title: Flying in Highly Dynamic Environments with End-to-end Learning Approach
Authors: Xiyu Fan, Minghao Lu, Bowen Xu, Peng Lu
Abstract: Obstacle avoidance for unmanned aerial vehicles like quadrotors is a popular research topic. Most existing research focuses only on static environments, and obstacle avoidance in environments with multiple dynamic obstacles remains challenging. This paper proposes a novel deep-reinforcement learning-based approach for the quadrotors to navigate through highly dynamic environments. We propose a lidar data encoder to extract obstacle information from the massive point cloud data from the lidar. Multi frames of historical scans will be compressed into a 2-dimension obstacle map while maintaining the obstacle features required. An end-to-end deep neural network is trained to extract the kinematics of dynamic and static obstacles from the obstacle map, and it will generate acceleration commands to the quadrotor to control it to avoid these obstacles. Our approach contains perception and navigating functions in a single neural network, which can change from a navigating state into a hovering state without mode switching. We also present simulations and real-world experiments to show the effectiveness of our approach while navigating in highly dynamic cluttered environments.

Paper number 104:
Title: Retrospective: A CORDIC Based Configurable Activation Function for NN Applications
Authors: Omkar Kokane, Gopal Raut, Salim Ullah, Mukul Lokhande, Adam Teman, Akash Kumar, Santosh Kumar Vishvakarma
Abstract: A CORDIC-based configuration for the design of Activation Functions (AF) was previously suggested to accelerate ASIC hardware design for resource-constrained systems by providing functional reconfigurability. Since its introduction, this new approach for neural network acceleration has gained widespread popularity, influencing numerous designs for activation functions in both academic and commercial AI processors. In this retrospective analysis, we explore the foundational aspects of this initiative, summarize key developments over recent years, and introduce the DA-VINCI AF tailored for the evolving needs of AI applications. This new generation of dynamically configurable and precision-adjustable activation function cores promise greater adaptability for a range of activation functions in AI workloads, including Swish, SoftMax, SeLU, and GeLU, utilizing the Shift-and-Add CORDIC technique. The previously presented design has been optimized for MAC, Sigmoid, and Tanh functionalities and incorporated into ReLU AFs, culminating in an accumulative NEURIC compute unit. These enhancements position NEURIC as a fundamental component in the resource-efficient vector engine for the realization of AI accelerators that focus on DNNs, RNNs/LSTMs, and Transformers, achieving a quality of results (QoR) of 98.5%.

Paper number 105:
Title: A Comprehensive Scatter Correction Model for Micro-Focus Dual-Source Imaging Systems: Combining Ambient, Cross, and Forward Scatter
Authors: Jianing Sun, Jigang Duan, Guangyin Li, Xu Jiang, Xing Zhao
Abstract: Compared to single-source imaging systems, dual-source imaging systems equipped with two cross-distributed scanning beams significantly enhance temporal resolution and capture more comprehensive object scanning information. Nevertheless, the interaction between the two scanning beams introduces more complex scatter signals into the acquired projection data. Existing methods typically model these scatter signals as the sum of cross-scatter and forward scatter, with cross-scatter estimation limited to single-scatter along primary paths. Through experimental measurements on our selfdeveloped micro-focus dual-source imaging system, we observed that the peak ratio of hardware-induced ambient scatter to single-source projection intensity can even exceed 60%, a factor often overlooked in conventional models. To address this limitation, we propose a more comprehensive model that decomposes the total scatter signals into three distinct components: ambient scatter, cross-scatter, and forward scatter. Furthermore, we introduce a cross-scatter kernel superposition (xSKS) module to enhance the accuracy of cross-scatter estimation by modeling both single and multiple crossscatter events along non-primary paths. Additionally, we employ a fast object-adaptive scatter kernel superposition (FOSKS) module for efficient forward scatter estimation. In Monte Carlo (MC) simulation experiments performed on a custom-designed waterbone phantom, our model demonstrated remarkable superiority, achieving a scatter-toprimary-weighted mean absolute percentage error (SPMAPE) of 1.32%, significantly lower than the 12.99% attained by the state-of-the-art method. Physical experiments further validate the superior performance of our model in correcting scatter artifacts.

Paper number 106:
Title: Graph-CNNs for RF Imaging: Learning the Electric Field Integral Equations
Authors: Kyriakos Stylianopoulos, Panagiotis Gavriilidis, Gabriele Gradoni, George C. Alexandropoulos
Abstract: Radio-Frequency (RF) imaging concerns the digital recreation of the surfaces of scene objects based on the scattered field at distributed receivers. To solve this difficult inverse scattering problems, data-driven methods are often employed that extract patterns from similar training examples, while offering minimal latency. In this paper, we first provide an approximate yet fast electromagnetic model, which is based on the electric field integral equations, for data generation, and subsequently propose a Deep Neural Network (DNN) architecture to learn the corresponding inverse model. A graph-attention backbone allows for the system geometry to be passed to the DNN, where residual convolutional layers extract features about the objects, while a UNet head performs the final image reconstruction. Our quantitative and qualitative evaluations on two synthetic data sets of different characteristics showcase the performance gains of thee proposed advanced architecture and its relative resilience to signal noise levels and various reception configurations.

Paper number 107:
Title: Evaluation of a beam switching smart antenna array for use in traffic telematics V2X applications
Authors: Hagen Ußler, Oliver Michler
Abstract: With the digitalization of transportation new use cases for digital information services are emerging. For example, prioritization of road users at traffic signals, especially emergency vehicles, is a desired goal. Requirements for the necessary communication link between road user and C-ITS station are often inadequately met. In particular, increasing communication distances while minimizing latencies are key requirements for timely influencing the control of traffic light signal programs. This paper presents the automotive application of a fast-switchable antenna array with targeted transmission direction selection and high antenna gain. In addition to antenna design requirements, theoretical analyses to increase transmission distance are performed using radio propagation simulation. Furthermore, practical evaluation is performed both in laboratory and test field environment using continuous wave and C-ITS service measurements. An automatic switching of antenna sectors based on geolocation is implemented and discussed from a scientific point of view. As a result, using an adaptive antenna array in traffic telematics environments is proposed to provide more robust communication links and increase the radio transmission distance.

Paper number 108:
Title: On Embedding B-Splines in Recursive State Estimation
Authors: Kailai Li
Abstract: We present a principled study on establishing a probabilistic framework for continuous-time state estimation. B-splines are embedded into state-space modeling as a continuous-time intermediate, linking the state of recurrent control points with asynchronous sensor measurements. Based thereon, the spline-embedded recursive estimation scheme is established w.r.t. common sensor fusion tasks, and corresponding technique for modeling uncertain motion estimates is introduced. We evaluate the proposed estimation scheme using real-world-based synthesized data in a range-inertial setting. Numerical results demonstrate several advantages of spline embedding in recursive state estimation compared to classical discrete-time filtering approaches.

Paper number 109:
Title: Co-Learning Semantic-aware Unsupervised Segmentation for Pathological Image Registration
Authors: Yang Liu, Shi Gu
Abstract: The registration of pathological images plays an important role in medical applications. Despite its significance, most researchers in this field primarily focus on the registration of normal tissue into normal tissue. The negative impact of focal tissue, such as the loss of spatial correspondence information and the abnormal distortion of tissue, are rarely considered. In this paper, we propose GIRNet, a novel unsupervised approach for pathological image registration by incorporating segmentation and inpainting through the principles of Generation, Inpainting, and Registration (GIR). The registration, segmentation, and inpainting modules are trained simultaneously in a co-learning manner so that the segmentation of the focal area and the registration of inpainted pairs can improve collaboratively. Overall, the registration of pathological images is achieved in a completely unsupervised learning framework. Experimental results on multiple datasets, including Magnetic Resonance Imaging (MRI) of T1 sequences, demonstrate the efficacy of our proposed method. Our results show that our method can accurately achieve the registration of pathological images and identify lesions even in challenging imaging modalities. Our unsupervised approach offers a promising solution for the efficient and cost-effective registration of pathological images. Our code is available at this https URL.

Paper number 110:
Title: Spectral-wise Implicit Neural Representation for Hyperspectral Image Reconstruction
Authors: Huan Chen, Wangcai Zhao, Tingfa Xu, Shiyun Zhou, Peifu Liu, Jianan Li
Abstract: Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to recover the 3D spatial-spectral signal from 2D measurement. Existing methods for reconstructing Hyperspectral Image (HSI) typically involve learning mappings from a 2D compressed image to a predetermined set of discrete spectral bands. However, this approach overlooks the inherent continuity of the spectral information. In this study, we propose an innovative method called Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward addressing this limitation. SINR introduces a continuous spectral amplification process for HSI reconstruction, enabling spectral super-resolution with customizable magnification factors. To achieve this, we leverage the concept of implicit neural representation. Specifically, our approach introduces a spectral-wise attention mechanism that treats individual channels as distinct tokens, thereby capturing global spectral dependencies. Additionally, our approach incorporates two components, namely a Fourier coordinate encoder and a spectral scale factor module. The Fourier coordinate encoder enhances the SINR's ability to emphasize high-frequency components, while the spectral scale factor module guides the SINR to adapt to the variable number of spectral channels. Notably, the SINR framework enhances the flexibility of CASSI reconstruction by accommodating an unlimited number of spectral bands in the desired output. Extensive experiments demonstrate that our SINR outperforms baseline methods. By enabling continuous reconstruction within the CASSI framework, we take the initial stride toward integrating implicit neural representation into the field.

Paper number 111:
Title: Composite learning backstepping control with guaranteed exponential stability and robustness
Authors: Tian Shi, Changyun Wen, Yongping Pan
Abstract: Adaptive backstepping control provides a feasible solution to achieve asymptotic tracking for mismatched uncertain nonlinear systems. However, input-to-state stability depends on high-gain feedback generated by nonlinear damping terms, and closed-loop exponential stability with parameter convergence involves a stringent condition named persistent excitation (PE). This paper proposes a composite learning backstepping control (CLBC) strategy based on modular backstepping and high-order tuners to compensate for the transient process of parameter estimation and achieve closed-loop exponential stability without the nonlinear damping terms and the PE condition. A novel composite learning mechanism that maximizes the staged exciting strength is designed for parameter estimation, such that parameter convergence can be achieved under a condition of interval excitation (IE) or even partial IE that is strictly weaker than PE. An extra prediction error is employed in the adaptive law to ensure the transient performance without nonlinear damping terms. The exponential stability of the closed-loop system is proved rigorously under the partial IE or IE condition. Simulations have demonstrated the effectiveness and superiority of the proposed method in both parameter estimation and control compared to state-of-the-art methods.

Paper number 112:
Title: On future power system digital twins: A vision towards a standard architecture
Authors: Wouter Zomerdijk, Peter Palensky, Tarek AlSkaif, Pedro P. Vergara
Abstract: The energy sector's digital transformation brings mutually dependent communication and energy infrastructure, tightening the relationship between the physical and the digital world. Digital twins (DT) are the key concept for this. This paper initially discusses the evolution of the DT concept across various engineering applications before narrowing its focus to the power systems domain. By reviewing different definitions and applications, the authors present a new definition of DTs specifically tailored to power systems. Based on the proposed definition and extensive deliberations and consultations with distribution system operators, energy traders, and municipalities, the authors introduce a vision of a standard DT ecosystem architecture that offers services beyond real-time updates and can seamlessly integrate with existing transmission and distribution system operators' processes while reconciling with concepts such as microgrids and local energy communities based on a system-of-systems view. The authors also discuss their vision related to the integration of power system DTs into various phases of the system's life cycle, such as long-term planning, emphasising challenges that remain to be addressed, such as managing measurement and model errors, and uncertainty propagation. Finally, the authors present their vision of how artificial intelligence and machine learning can enhance several power systems DT modules established in the proposed architecture.

Paper number 113:
Title: Exploiting Spatial and Temporal Correlations in Massive MIMO Systems Over Non-Stationary Aging Channels
Authors: Sajad Daei, Gabor Fodor, Mikael Skoglund
Abstract: This work investigates a multi-user, multi-antenna uplink wireless system, where multiple users transmit signals to a base station. Previous research has explored the potential for linear growth in spectral efficiency by employing multiple transmit and receive antennas. This gain depends on the quality of channel state information and uncorrelated antennas. However, spatial correlations, arising from closely-spaced antennas, and channel aging effects, stemming from the difference between the channel at pilot and data time instances, can substantially counteract these benefits and degrade the transmission rate, especially in non-stationary environments. To address these challenges, this work introduces a real-time beamforming framework to compensate for the spatial correlation effect. A channel estimation scheme is then developed, leveraging temporal channel correlations and considering mobile device velocity and antenna spacing. Subsequently, an expression approximating the average spectral efficiency is obtained, dependent on pilot spacing, pilot and data powers, and beamforming vectors. By maximizing this expression, optimal parameters are identified. Numerical results reveal the effectiveness of the proposed approach compared to prior works. Moreover, optimal pilot spacing remains unaffected by interference components such as path loss and the velocity of interference users. The impact of interference components also diminishes with an increasing number of transmit antennas.

Paper number 114:
Title: Synesthesia of Machines (SoM)-Enhanced Wideband Multi-User CSI Learning With LiDAR Sensing
Authors: Haotian Zhang, Shijian Gao, Xiang Cheng, Liuqing Yang
Abstract: Light detection and ranging (LiDAR) has been utilized for optimizing wireless communications due to its ability to detect the environment. This paper explores the use of LiDAR in channel estimation for wideband multi-user multiple-input-multiple-output orthogonal frequency division multiplexing systems and introduces a LiDAR-enhanced Channel State Information (CSI) learning network (LE-CLN). By utilizing user positioning information, LE-CLN first calculates user-localized over-complete angular measurements. It then investigates the correlation between LiDAR and CSI, transforming raw LiDAR data into a low-complexity format embedded with signal propagation characteristics. LE-CLN also adapts the use of LiDAR based on channel conditions through attention mechanisms. Thanks to the unique wireless features offered by LiDAR, LE-CLN achieves higher estimation accuracy and spectrum efficiency compared to benchmarks, particularly in latency-sensitive applications where pilot transmissions are expected to be reduced.

Paper number 115:
Title: TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control
Authors: Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao
Abstract: Zero-shot singing voice synthesis (SVS) with style transfer and style control aims to generate high-quality singing voices with unseen timbres and styles (including singing method, emotion, rhythm, technique, and pronunciation) from audio and text prompts. However, the multifaceted nature of singing styles poses a significant challenge for effective modeling, transfer, and control. Furthermore, current SVS models often fail to generate singing voices rich in stylistic nuances for unseen singers. To address these challenges, we introduce TCSinger, the first zero-shot SVS model for style transfer across cross-lingual speech and singing styles, along with multi-level style control. Specifically, TCSinger proposes three primary modules: 1) the clustering style encoder employs a clustering vector quantization model to stably condense style information into a compact latent space; 2) the Style and Duration Language Model (S\&D-LM) concurrently predicts style information and phoneme duration, which benefits both; 3) the style adaptive decoder uses a novel mel-style adaptive normalization method to generate singing voices with enhanced details. Experimental results show that TCSinger outperforms all baseline models in synthesis quality, singer similarity, and style controllability across various tasks, including zero-shot style transfer, multi-level style control, cross-lingual style transfer, and speech-to-singing style transfer. Singing voice samples can be accessed at this https URL.

Paper number 116:
Title: Targeted Neural Architectures in Multi-Objective Frameworks for Complete Glioma Characterization from Multimodal MRI
Authors: Shravan Venkatraman, Pandiyaraju V, Abeshek A, Aravintakshan S A, Pavan Kumar S, Kannan A, Madhan S
Abstract: Brain tumors result from abnormal cell growth in brain tissue. If undiagnosed, they cause neurological deficits, including cognitive impairment, motor dysfunction, and sensory loss. As tumors grow, intracranial pressure increases, potentially leading to fatal complications such as brain herniation. Early diagnosis and treatment are crucial to controlling these effects and slowing tumor progression. Deep learning (DL) and artificial intelligence (AI) are increasingly used to assist doctors in early diagnosis through magnetic resonance imaging (MRI) scans. Our research proposes targeted neural architectures within multi-objective frameworks that can localize, segment, and classify the grade of these gliomas from multimodal MRI images to solve this critical issue. Our localization framework utilizes a targeted architecture that enhances the LinkNet framework with an encoder inspired by VGG19 for better multimodal feature extraction from the tumor along with spatial and graph attention mechanisms that sharpen feature focus and inter-feature relationships. For the segmentation objective, we deployed a specialized framework using the SeResNet101 CNN model as the encoder backbone integrated into the LinkNet architecture, achieving an IoU Score of 96%. The classification objective is addressed through a distinct framework implemented by combining the SeResNet152 feature extractor with Adaptive Boosting classifier, reaching an accuracy of 98.53%. Our multi-objective approach with targeted neural architectures demonstrated promising results for complete glioma characterization, with the potential to advance medical AI by enabling early diagnosis and providing more accurate treatment options for patients.

Paper number 117:
Title: Exploring the Impact of HAPS-RIS on UAV-Based Networks: a Novel Network Architecture
Authors: Arman Azizi, Mustafa A. Kishk, Arman Farhang
Abstract: In this paper, we propose a network architecture where two types of aerial infrastructures together with a ground station provide connectivity to a remote area. A high altitude platform station (HAPS) is equipped with reconfigurable intelligent surface (RIS), so-called HAPS-RIS, to be exploited to assist the unmanned aerial vehicle (UAV)-based wireless networks. A key challenge in such networks is the restricted number of UAVs, which limits full coverage and leaves some users unsupported. To tackle this issue, we propose a hierarchical bilevel optimization framework including a leader and a follower problem. The users served by HAPS-RIS are in a zone called HAPS-RIS zone and the users served by the UAVs are in another zone called UAV zone. In the leader problem, the goal is to establish the zone boundary and practical RIS phase shift design that maximizes the number of users covered by HAPS-RIS while ensuring that users in this zone meet their rate requirements. This is achieved through our proposed relaxation method and algorithm based on the RIS clustering concept. The follower problem focuses on minimizing the number of UAVs required, ensuring that the rate requirements of the users in the UAV zone are met. This is addressed through our proposed dynamic method adopting k-means clustering technique with adaptive UAV selection. Our study reveals that increasing the number of RIS elements significantly decreases the number of required UAVs.

Paper number 118:
Title: Deep Adversarial Learning with Activity-Based User Discrimination Task for Human Activity Recognition
Authors: Francisco M. Calatrava-Nicolás, Shoko Miyauchi, Oscar Martinez Mozos
Abstract: We present a new adversarial deep learning framework for the problem of human activity recognition (HAR) using inertial sensors worn by people. Our framework incorporates a novel adversarial activity-based discrimination task that addresses inter-person variability-i.e., the fact that different people perform the same activity in different ways. Overall, our proposed framework outperforms previous approaches on three HAR datasets using a leave-one-(person)-out cross-validation (LOOCV) benchmark. Additional results demonstrate that our discrimination task yields better classification results compared to previous tasks within the same adversarial framework.

Paper number 119:
Title: Evaluating the Posterior Sampling Ability of Plug&Play Diffusion Methods in Sparse-View CT
Authors: Liam Moroy, Guillaume Bourmaud, Frédéric Champagnat, Jean-François Giovannelli
Abstract: Plug&Play (PnP) diffusion models are state-of-the-art methods in computed tomography (CT) reconstruction. Such methods usually consider applications where the sinogram contains a sufficient amount of information for the posterior distribution to be concentrated around a single mode, and consequently are evaluated using image-to-image metrics such as PSNR/SSIM. Instead, we are interested in reconstructing compressible flow images from sinograms having a small number of projections, which results in a posterior distribution no longer concentrated or even multimodal. Thus, in this paper, we aim at evaluating the approximate posterior of PnP diffusion models and introduce two posterior evaluation properties. We quantitatively evaluate three PnP diffusion methods on three different datasets for several numbers of projections. We surprisingly find that, for each method, the approximate posterior deviates from the true posterior when the number of projections decreases.

Paper number 120:
Title: Average Predictor-Feedback Control Design for Switched Linear Systems
Authors: Andreas Katsanikakis, Nikolaos Bekiaris-Liberis, Delphine Bresch-Pietri
Abstract: We develop an input delay-compensating feedback law for linear switched systems with time-dependent switching. Because the future values of the switching signal, which are needed for constructing an exact predictor-feedback law, may be unavailable at current time, the key design challenge is how to construct a proper predictor state. We resolve this challenge constructing an average predictor-based feedback law, which may be viewed as an exact predictor-feedback law for a particular average system without switching. We establish that, under the predictor-based control law introduced, the closed-loop system is exponentially stable, provided that the plant's parameters are sufficiently close to the corresponding parameters of the average system. In particular, the allowable difference is inversely proportional to the size of delay and proportional to the dwell time of the switching signal. Since no restriction is imposed on the size of delay or dwell time themselves, such a limitation on the parameters of each mode is inherent to the problem considered (in which no a priori information on the switching signal is available), and thus, it cannot be removed. The stability proof relies on two main ingredients-a Lyapunov functional constructed via backstepping and derivation of solutions' estimates for the difference between the average and the exact predictor states. We present consistent, numerical simulation results, which illustrate the necessity of employing the average predictor-based law for achieving stabilization and desired performance of the closed-loop system.

Paper number 121:
Title: Koopman-based control of nonlinear systems with closed-loop guarantees
Authors: Robin Strässer, Julian Berberich, Manuel Schaller, Karl Worthmann, Frank Allgöwer
Abstract: In this paper, we provide a tutorial overview and an extension of a recently developed framework for data-driven control of unknown nonlinear systems with rigorous closed-loop guarantees. The proposed approach relies on the Koopman operator representation of the nonlinear system, for which a bilinear surrogate model is estimated based on data. In contrast to existing Koopman-based estimation procedures, we state guaranteed bounds on the approximation error using the stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) framework. The resulting surrogate model and the uncertainty bounds allow us to design controllers via robust control theory and sum-of-squares optimization, guaranteeing desirable properties for the closed-loop system. We present results on stabilization both in discrete and continuous time, and we derive a method for controller design with performance objectives. The benefits of the presented framework over established approaches are demonstrated with a numerical example.

Paper number 122:
Title: Performance Analysis and Power Allocation for Massive MIMO ISAC Systems
Authors: Nhan Thanh Nguyen, Van-Dinh Nguyen, Hieu V. Nguyen, Hien Quoc Ngo, A. Lee Swindlehurst, Markku Juntti
Abstract: Integrated sensing and communications (ISAC) is envisioned as a key feature in future wireless communications networks. Its integration with massive multiple-input-multiple-output (MIMO) techniques promises to leverage substantial spatial beamforming gains for both functionalities. In this work, we consider a massive MIMO-ISAC system employing a uniform planar array with zero-forcing and maximum-ratio downlink transmission schemes combined with monostatic radar-type sensing. Our focus lies on deriving closed-form expressions for the achievable communications rate and the Cramér--Rao lower bound (CRLB), which serve as performance metrics for communications and sensing operations, respectively. The expressions enable us to investigate important operational characteristics of massive MIMO-ISAC, including the mutual effects of communications and sensing as well as the advantages stemming from using a very large antenna array for each functionality. Furthermore, we devise a power allocation strategy based on successive convex approximation to maximize the communications rate while guaranteeing the CRLB constraints and transmit power budget. Extensive numerical results are presented to validate our theoretical analyses and demonstrate the efficiency of the proposed power allocation approach.

Paper number 123:
Title: Is JPEG AI going to change image forensics?
Authors: Edoardo Daniele Cannas, Sara Mandelli, Nataša Popović, Ayman Alkhateeb, Alessandro Gnutti, Paolo Bestagini, Stefano Tubaro
Abstract: In this paper, we investigate the counter-forensic effects of the new JPEG AI standard based on neural image compression, focusing on two critical areas: deepfake image detection and image splicing localization. Neural image compression leverages advanced neural network algorithms to achieve higher compression rates while maintaining image quality. However, it introduces artifacts that closely resemble those generated by image synthesis techniques and image splicing pipelines, complicating the work of researchers when discriminating pristine from manipulated content. We comprehensively analyze JPEG AI's counter-forensic effects through extensive experiments on several state-of-the-art detectors and datasets. Our results demonstrate a reduction in the performance of leading forensic detectors when analyzing content processed through JPEG AI. By exposing the vulnerabilities of the available forensic tools, we aim to raise the urgent need for multimedia forensics researchers to include JPEG AI images in their experimental setups and develop robust forensic techniques to distinguish between neural compression artifacts and actual manipulations.

Paper number 124:
Title: Synthetic Discrete Inertia
Authors: A. Vaca, F. Milano
Abstract: This letter demonstrates how synthetic inertia can be obtained with the control of flexible discrete devices to keep the power balance of power systems, even if the system does not include any synchronous generator or conventional grid-forming converter. The letter also discusses solutions to cycling issues, which can arise due to the interaction of uncoordinated discrete inertia controllers. The effectiveness, dynamic performance, and challenges of the proposed approach are validated through simulations using modified versions of the WSCC 9-bus test system and of the all-island Irish transmission system.

Paper number 125:
Title: A Two-step Linear Mixing Model for Unmixing under Hyperspectral Variability
Authors: Xander Haijen, Bikram Koirala, Xuanwen Tao, Paul Scheunders
Abstract: Spectral unmixing is an important task in the research field of hyperspectral image processing. It can be thought of as a regression problem, where the observed variable (i.e., an image pixel) is to be found as a function of the response variables (i.e., the pure materials in a scene, called endmembers). The Linear Mixing Model (LMM) has received a great deal of attention, due to its simplicity and ease of use in, e.g., optimization problems. Its biggest flaw is that it assumes that any pure material can be characterized by one unique spectrum throughout the entire scene. In many cases this is incorrect: the endmembers face a significant amount of spectral variability caused by, e.g., illumination conditions, atmospheric effects, or intrinsic variability. Researchers have suggested several generalizations of the LMM to mitigate this effect. However, most models lead to ill-posed and highly non-convex optimization problems, which are hard to solve and have hyperparameters that are difficult to tune. In this paper, we propose a two-step LMM that bridges the gap between model complexity and computational tractability. We show that this model leads to only a mildly non-convex optimization problem, which we solve with an interior-point solver. This method requires virtually no hyperparameter tuning, and can therefore be used easily and quickly in a wide range of unmixing tasks. We show that the model is competitive and in some cases superior to existing and well-established unmixing methods and algorithms. We do this through several experiments on synthetic data, real-life satellite data, and hybrid synthetic-real data.

Paper number 126:
Title: Balanced Rate-Distortion Optimization in Learned Image Compression
Authors: Yichi Zhang, Zhihao Duan, Yuning Huang, Fengqing Zhu
Abstract: Learned image compression (LIC) using deep learning architectures has seen significant advancements, yet standard rate-distortion (R-D) optimization often encounters imbalanced updates due to diverse gradients of the rate and distortion objectives. This imbalance can lead to suboptimal optimization, where one objective dominates, thereby reducing overall compression efficiency. To address this challenge, we reformulate R-D optimization as a multi-objective optimization (MOO) problem and introduce two balanced R-D optimization strategies that adaptively adjust gradient updates to achieve more equitable improvements in both rate and distortion. The first proposed strategy utilizes a coarse-to-fine gradient descent approach along standard R-D optimization trajectories, making it particularly suitable for training LIC models from scratch. The second proposed strategy analytically addresses the reformulated optimization as a quadratic programming problem with an equality constraint, which is ideal for fine-tuning existing models. Experimental results demonstrate that both proposed methods enhance the R-D performance of LIC models, achieving around a 2\% BD-Rate reduction with acceptable additional training cost, leading to a more balanced and efficient optimization process. Code will be available at this https URL.

Paper number 127:
Title: Towards Practical Real-Time Neural Video Compression
Authors: Zhaoyang Jia, Bin Li, Jiahao Li, Wenxuan Xie, Linfeng Qi, Houqiang Li, Yan Lu
Abstract: We introduce a practical real-time neural video codec (NVC) designed to deliver high compression ratio, low latency and broad versatility. In practice, the coding speed of NVCs depends on 1) computational costs, and 2) non-computational operational costs, such as memory I/O and the number of function calls. While most efficient NVCs prioritize reducing computational cost, we identify operational cost as the primary bottleneck to achieving higher coding speed. Leveraging this insight, we introduce a set of efficiency-driven design improvements focused on minimizing operational costs. Specifically, we employ implicit temporal modeling to eliminate complex explicit motion modules, and use single low-resolution latent representations rather than progressive downsampling. These innovations significantly accelerate NVC without sacrificing compression quality. Additionally, we implement model integerization for consistent cross-device coding and a module-bank-based rate control scheme to improve practical adaptability. Experiments show our proposed DCVC-RT achieves an impressive average encoding/decoding speed at 125.2/112.8 fps (frames per second) for 1080p video, while saving an average of 21% in bitrate compared to H.266/VTM. The code is available at this https URL.

Paper number 128:
Title: Conformal Lyapunov Optimization: Optimal Resource Allocation under Deterministic Reliability Constraints
Authors: Francesco Binucci, Osvaldo Simeone, Paolo Banelli
Abstract: This paper introduces conformal Lyapunov optimization (CLO), a novel resource allocation framework for networked systems that optimizes average long-term objectives, while satisfying deterministic long-term reliability constraints. Unlike traditional Lyapunov optimization (LO), which addresses resource allocation tasks under average long-term constraints, CLO provides formal worst-case deterministic reliability guarantees. This is achieved by integrating the standard LO optimization framework with online conformal risk control (O-CRC), an adaptive update mechanism controlling long-term risks. The effectiveness of CLO is verified via experiments for hierarchal edge inference targeting image segmentation tasks in a networked computing architecture. Specifically, simulation results confirm that CLO can control reliability constraints, measured via the false negative rate of all the segmentation decisions made in the network, while at the same time minimizing the weighted sum of energy consumption and imprecision, with the latter accounting for the rate of false positives.

Paper number 129:
Title: LesionDiffusion: Towards Text-controlled General Lesion Synthesis
Authors: Henrui Tian, Wenhui Lei, Linrui Dai, Hanyu Chen, Xiaofan Zhang
Abstract: Fully-supervised lesion recognition methods in medical imaging face challenges due to the reliance on large annotated datasets, which are expensive and difficult to collect. To address this, synthetic lesion generation has become a promising approach. However, existing models struggle with scalability, fine-grained control over lesion attributes, and the generation of complex structures. We propose LesionDiffusion, a text-controllable lesion synthesis framework for 3D CT imaging that generates both lesions and corresponding masks. By utilizing a structured lesion report template, our model provides greater control over lesion attributes and supports a wider variety of lesion types. We introduce a dataset of 1,505 annotated CT scans with paired lesion masks and structured reports, covering 14 lesion types across 8 organs. LesionDiffusion consists of two components: a lesion mask synthesis network (LMNet) and a lesion inpainting network (LINet), both guided by lesion attributes and image features. Extensive experiments demonstrate that LesionDiffusion significantly improves segmentation performance, with strong generalization to unseen lesion types and organs, outperforming current state-of-the-art models. Code will be available at this https URL.

Paper number 130:
Title: Semantic Prior Distillation with Vision Foundation Model for Enhanced Rapid Bone Scintigraphy Image Restoration
Authors: Pengchen Liang, Leijun Shi, Huiping Yao, Bin Pu, Jianguo Chen, Lei Zhao, Haishan Huang, Zhuangzhuang Chen, Zhaozhao Xu, Lite Xu, Qing Chang, Yiwei Li
Abstract: Rapid bone scintigraphy is an essential tool for diagnosing skeletal diseases and tumor metastasis in pediatric patients, as it reduces scan time and minimizes patient discomfort. However, rapid scans often result in poor image quality, potentially affecting diagnosis due to reduced resolution and detail, which make it challenging to identify and evaluate finer anatomical structures. To address this issue, we propose the first application of SAM-based semantic priors for medical image restoration, leveraging the Segment Anything Model (SAM) to enhance rapid bone scintigraphy images in pediatric populations. Our method comprises two cascaded networks, $f^{IR1}$ and $f^{IR2}$, augmented by three key modules: a Semantic Prior Integration (SPI) module, a Semantic Knowledge Distillation (SKD) module, and a Semantic Consistency Module (SCM). The SPI and SKD modules incorporate domain-specific semantic information from a fine-tuned SAM, while the SCM maintains consistent semantic feature representation throughout the cascaded networks. In addition, we will release a novel Rapid Bone Scintigraphy dataset called RBS, the first dataset dedicated to rapid bone scintigraphy image restoration in pediatric patients. RBS consists of 137 pediatric patients aged between 0.5 and 16 years who underwent both standard and rapid bone scans. The dataset includes scans performed at 20 cm/min (standard) and 40 cm/min (rapid), representing a $2\times$ acceleration. We conducted extensive experiments on both the publicly available endoscopic dataset and RBS. The results demonstrate that our method outperforms all existing methods across various metrics, including PSNR, SSIM, FID, and LPIPS.

Paper number 131:
Title: Identification and Classification of Human Performance related Challenges during Remote Driving
Authors: Ole Hans, Jürgen Adamy
Abstract: Remote driving of vehicles is gaining in importance in the transportation sector, especially when Automated Driving Systems (ADSs) reach the limits of their system boundaries. This study investigates the challenges faced by human Remote Drivers (RDs) during remote driving, particularly focusing on the identification and classification of human performance-related challenges through a comprehensive analysis of real-world remote driving data Las Vegas. For this purpose, a total of 183 RD performance-related Safety Driver (SD) interventions were analyzed and classified using an introduced severity classification. As it is essential to prevent the need for SD interventions, this study identified and analyzed harsh driving events to detect an increased likelihood of interventions by the SD. In addition, the results of the subjective RD questionnaire are used to evaluate whether the objective metrics from SD interventions and harsh driving events can also be confirmed by the RDs and whether additional challenges can be uncovered. The analysis reveals learning curves, showing a significant decrease in SD interventions as RD experience increases. Early phases of remote driving experience, especially below 200 km of experience, showed the highest frequency of safety-related events, including braking late for traffic signs and responding impatiently to other traffic participants. Over time, RDs follow defined rules for improving their control, with experience leading to less harsh braking, acceleration, and steering maneuvers. The study contributes to understanding the requirements of RDS, emphasizing the importance of targeted training to address human performance limitations. It further highlights the need for system improvements to address challenges like latency and the limited haptic feedback replaced by visual feedback, which affect the RDs' perception and vehicle control.

Paper number 132:
Title: Approximate Hamilton-Jacobi Reachability Analysis for a Class of Two-Timescale Systems, with Application to Biological Models
Authors: Dylan Hirsch, Sylvia Herbert
Abstract: Hamilton-Jacobi reachability (HJR) is an exciting framework used for control of safety-critical systems with nonlinear and possibly uncertain dynamics. However, HJR suffers from the curse of dimensionality, with computation times growing exponentially in the dimension of the system state. Many autonomous and controlled systems involve dynamics that evolve on multiple timescales, and for these systems, singular perturbation methods can be used for model reduction. However, such methods are more challenging to apply in HJR due to the presence of an underlying differential game. In this work, we leverage prior work on singularly perturbed differential games to identify a class of systems which can be readily reduced, and we relate these results to the quantities of interest in HJR. We demonstrate the utility of our results on two examples involving biological systems, where dynamics fitting the identified class are frequently encountered.

Paper number 133:
Title: AI and Deep Learning for Automated Segmentation and Quantitative Measurement of Spinal Structures in MRI
Authors: Praveen Shastry, Bhawana Sonawane, Kavya Mohan, Naveen Kumarasami, Ragothm Sripadraj, Anandakumar D, Keerthana R, Mounigasri M, Kaviya SP, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: Accurate spinal structure measurement is crucial for assessing spine health and diagnosing conditions like spondylosis, disc herniation, and stenosis. Manual methods for measuring intervertebral disc height and spinal canal diameter are subjective and time-consuming. Automated solutions are needed to improve accuracy, efficiency, and reproducibility in clinical practice. Purpose: This study develops an autonomous AI system for segmenting and measuring key spinal structures in MRI scans, focusing on intervertebral disc height and spinal canal anteroposterior (AP) diameter in the cervical, lumbar, and thoracic regions. The goal is to reduce clinician workload, enhance diagnostic consistency, and improve assessments. Methods: The AI model leverages deep learning architectures, including UNet, nnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated against expert annotations. Performance was evaluated using Dice coefficients and segmentation accuracy. Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for cervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely measured spinal parameters like disc height and canal diameter, demonstrating robustness and clinical applicability. Conclusion: The AI system effectively automates MRI-based spinal measurements, improving accuracy and reducing clinician workload. Its consistent performance across spinal regions supports clinical decision-making, particularly in high-demand settings, enhancing spinal assessments and patient outcomes.

Paper number 134:
Title: Automotive Battery Pack Standards and Design Characteristics: A Review
Authors: Saeid Haghbin, Morteza Rezaei Larijani, MohammadReza Zolghadri, Shahin Hedayati Kia
Abstract: This paper outlines the existing situation and future trends related to automobile battery packs, specifically from the automobile manufacturer's point of view. It formulates the specifications required for such packs to adhere to prevailing regulatory schemes and examines top-level solutions to target a uniform architecture for passenger cars. Key elements such as electrical performance, safety, mechanical integrity, reliability, environmental issues, diagnostics, and real-world implications have been extensively examined. This paper draws attention to the industry trend of shifting to high-voltage battery architectures to enable ultra-fast charging above 350 kW, reducing the charging time to less than 20 minutes. Technological advancements in energy density and battery pack capacities are poised to take electric vehicle ranges over 1000 km from a single charge. This study also examines developments in artificial intelligence-improved battery management systems, enhanced safety, mechanical integrity, reliability, diagnostics, and practical considerations. Furthermore, future developments, such as the incorporation of batteries in aviation and other new uses, are investigated to provide insight into the future generation of economically viable, secure, and high-performance battery systems.

Paper number 135:
Title: Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN-LSTM With WOA-GWO Parameter Optimization: Global COVID-19 Case Study
Authors: Mousa Alizadeh, Mohammad Hossein Samaei, Azam Seilsepour, Mohammad TH Beheshti
Abstract: Effective epidemic modeling is essential for managing public health crises, requiring robust methods to predict disease spread and optimize resource allocation. This study introduces a novel deep learning framework that advances time series forecasting for infectious diseases, with its application to COVID 19 data as a critical case study. Our hybrid approach integrates Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTM) models to capture spatial and temporal dynamics of disease transmission across diverse regions. The CNN extracts spatial features from raw epidemiological data, while the LSTM models temporal patterns, yielding precise and adaptable predictions. To maximize performance, we employ a hybrid optimization strategy combining the Whale Optimization Algorithm (WOA) and Gray Wolf Optimization (GWO) to fine tune hyperparameters, such as learning rates, batch sizes, and training epochs enhancing model efficiency and accuracy. Applied to COVID 19 case data from 24 countries across six continents, our method outperforms established benchmarks, including ARIMA and standalone LSTM models, with statistically significant gains in predictive accuracy (e.g., reduced RMSE). This framework demonstrates its potential as a versatile method for forecasting epidemic trends, offering insights for resource planning and decision making in both historical contexts, like the COVID 19 pandemic, and future outbreaks.

Paper number 136:
Title: On The Convergence of Euler Discretization of Finite-Time Convergent Gradient Flows
Authors: Siqi Zhang, Mouhacine Benosman, Orlando Romero
Abstract: In this study, we investigate the performance of two novel first-order optimization algorithms, namely the rescaled-gradient flow (RGF) and the signed-gradient flow (SGF). These algorithms are derived from the forward Euler discretization of finite-time convergent flows, comprised of non-Lipschitz dynamical systems, which locally converge to the minima of gradient-dominated functions. We first characterize the closeness between the continuous flows and the discretizations, then we proceed to present (linear) convergence guarantees of the discrete algorithms (in the general and the stochastic case). Furthermore, in cases where problem parameters remain unknown or exhibit non-uniformity, we further integrate the line-search strategy with RGF/SGF and provide convergence analysis in this setting. We then apply the proposed algorithms to academic examples and deep neural network training, our results show that our schemes demonstrate faster convergences against standard optimization alternatives.

Paper number 137:
Title: Automated Layout and Control Co-Design of Robust Multi-UAV Transportation Systems
Authors: Carlo Bosio, Mark W. Mueller
Abstract: The joint optimization of physical parameters and controllers in robotic systems is challenging. This is due to the difficulties of predicting the effect that changes in physical parameters have on final performances. At the same time, physical and morphological modifications can improve robot capabilities, perhaps completely unlocking new skills and tasks. We present a novel approach to co-optimize the physical layout and the control of a cooperative aerial transportation system. The goal is to achieve the most precise and robust flight when carrying a payload. We assume the agents are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with ``thrust modules" at the attachment locations of the quadcopters. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system achieves the best disturbance rejection capabilities. We propose a novel metric of robustness inspired by H2 control, and propose an algorithm to optimize the layout of the vehicles around the object and their controller altogether. We experimentally validate the effectiveness of our approach using fleets of three and four quadcopters and payloads of diverse shapes.

Paper number 138:
Title: Sensory Glove-Based Surgical Robot User Interface
Authors: Leonardo Borgioli, Ki-Hwan Oh, Valentina Valle, Alvaro Ducas, Mohammad Halloum, Diego Federico Mendoza Medina, Arman Sharifi, Paula A L'opez, Jessica Cassiani, Milos Zefran, Liaohai Chen, Pier Cristoforo Giulianotti
Abstract: Robotic surgery has reached a high level of maturity and has become an integral part of standard surgical care. However, existing surgeon consoles are bulky, take up valuable space in the operating room, make surgical team coordination challenging, and their proprietary nature makes it difficult to take advantage of recent technological advances, especially in virtual and augmented reality. One potential area for further improvement is the integration of modern sensory gloves into robotic platforms, allowing surgeons to control robotic arms intuitively with their hand movements. We propose one such system that combines an HTC Vive tracker, a Manus Meta Prime 3 XR sensory glove, and SCOPEYE wireless smart glasses. The system controls one arm of a da Vinci surgical robot. In addition to moving the arm, the surgeon can use fingers to control the end-effector of the surgical instrument. Hand gestures are used to implement clutching and similar functions. In particular, we introduce clutching of the instrument orientation, a functionality unavailable in the da Vinci system. The vibrotactile elements of the glove are used to provide feedback to the user when gesture commands are invoked. A qualitative and quantitative evaluation has been conducted that compares the current device with the dVRK console. The system is shown to have excellent tracking accuracy, and the new interface allows surgeons to perform common surgical training tasks with minimal practice efficiently.

Paper number 139:
Title: Bracket Diffusion: HDR Image Generation by Consistent LDR Denoising
Authors: Mojtaba Bemana, Thomas Leimkühler, Karol Myszkowski, Hans-Peter Seidel, Tobias Ritschel
Abstract: We demonstrate generating HDR images using the concerted action of multiple black-box, pre-trained LDR image diffusion models. Relying on a pre-trained LDR generative diffusion models is vital as, first, there is no sufficiently large HDR image dataset available to re-train them, and, second, even if it was, re-training such models is impossible for most compute budgets. Instead, we seek inspiration from the HDR image capture literature that traditionally fuses sets of LDR images, called "exposure brackets'', to produce a single HDR image. We operate multiple denoising processes to generate multiple LDR brackets that together form a valid HDR result. The key to making this work is to introduce a consistency term into the diffusion process to couple the brackets such that they agree across the exposure range they share while accounting for possible differences due to the quantization error. We demonstrate state-of-the-art unconditional and conditional or restoration-type (LDR2HDR) generative modeling results, yet in HDR.

Paper number 140:
Title: Visibility-Aware RRT* for Safety-Critical Navigation of Perception-Limited Robots in Unknown Environments
Authors: Taekyung Kim, Dimitra Panagou
Abstract: Safe autonomous navigation in unknown environments remains a critical challenge for robots with limited sensing capabilities. While safety-critical control techniques, such as Control Barrier Functions (CBFs), have been proposed to ensure safety, their effectiveness relies on the assumption that the robot has complete knowledge of its surroundings. In reality, robots often operate with restricted field-of-view and finite sensing range, which can lead to collisions with unknown obstacles if the planner is agnostic to these limitations. To address this issue, we introduce the Visibility-Aware RRT* algorithm that combines sampling-based planning with CBFs to generate safe and efficient global reference paths in partially unknown environments. The algorithm incorporates a collision avoidance CBF and a novel visibility CBF, which guarantees that the robot remains within locally collision-free regions, enabling timely detection and avoidance of unknown obstacles. We conduct extensive experiments interfacing the path planners with two different safety-critical controllers, wherein our method outperforms all other compared baselines across both safety and efficiency aspects.

Paper number 141:
Title: Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems
Authors: Yilie Huang, Yanwei Jia, Xun Yu Zhou
Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.

Paper number 142:
Title: CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation
Authors: Weiheng Yao, Zhihan Lyu, Mufti Mahmud, Ning Zhong, Baiying Lei, Shuqiang Wang
Abstract: Multi-modal neuroimaging analysis is crucial for a comprehensive understanding of brain function and pathology, as it allows for the integration of different imaging techniques, thus overcoming the limitations of individual modalities. However, the high costs and limited availability of certain modalities pose significant challenges. To address these issues, this paper proposed the Condition-Aligned Temporal Diffusion (CATD) framework for end-to-end cross-modal synthesis of neuroimaging, enabling the generation of functional magnetic resonance imaging (fMRI)-detected Blood Oxygen Level Dependent (BOLD) signals from more accessible Electroencephalography (EEG) signals. By constructing Conditionally Aligned Block (CAB), heterogeneous neuroimages are aligned into a potential space, achieving a unified representation that provides the foundation for cross-modal transformation in neuroimaging. The combination with the constructed Dynamic Time-Frequency Segmentation (DTFS) module also enables the use of EEG signals to improve the temporal resolution of BOLD signals, thus augmenting the capture of the dynamic details of the brain. Experimental validation demonstrated the effectiveness of the framework in improving the accuracy of neural activity prediction, identifying abnormal brain regions, and enhancing the temporal resolution of BOLD signals. The proposed framework establishes a new paradigm for cross-modal synthesis of neuroimaging by unifying heterogeneous neuroimaging data into a potential representation space, showing promise in medical applications such as improving Parkinson's disease prediction and identifying abnormal brain regions.

Paper number 143:
Title: Information and motor constraints shape melodic diversity across cultures
Authors: John M McBride, Nahie Kim, Yuri Nishikawa, Mekhmed Saadakeev, Marcus T Pearce, Tsvi Tlusty
Abstract: The number of possible melodies is unfathomably large, yet despite this virtually unlimited potential for melodic variation, melodies from different societies can be surprisingly similar. The motor constraint hypothesis accounts for certain similarities, such as scalar motion and contour shape, but not for other major common features, such as repetition, song length, and scale size. Here we investigate the role of information constraints arising from limitations on human memory in shaping these hallmarks of melodies. We measure determinants of information rate in 62 corpora of Folk melodies spanning several continents, finding multiple trade-offs that all act to constrain the information rate across societies. By contrast, 39 corpora of Art music from Europe (including Turkey) show longer, more complex melodies, and increased complexity over time, suggesting different cultural-evolutionary selection pressures in Art and Folk music, possibly due to the use of written versus oral transmission. Our parameter-free model predicts the empirical scale degree distribution using information constraints on scalar motion, melody length, and, most importantly, information rate. This provides strong evidence that information constraints during cultural transmission of music limit the number of notes in a scale, and proposes that preference for intermediate melodic complexity is a fundamental constraint on the cultural evolution of melody.

Paper number 144:
Title: MusicLIME: Explainable Multimodal Music Understanding
Authors: Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou
Abstract: Multimodal models are critical for music understanding tasks, as they capture the complex interplay between audio and lyrics. However, as these models become more prevalent, the need for explainability grows-understanding how these systems make decisions is vital for ensuring fairness, reducing bias, and fostering trust. In this paper, we introduce MusicLIME, a model-agnostic feature importance explanation method designed for multimodal music models. Unlike traditional unimodal methods, which analyze each modality separately without considering the interaction between them, often leading to incomplete or misleading explanations, MusicLIME reveals how audio and lyrical features interact and contribute to predictions, providing a holistic view of the model's decision-making. Additionally, we enhance local explanations by aggregating them into global explanations, giving users a broader perspective of model behavior. Through this work, we contribute to improving the interpretability of multimodal music models, empowering users to make informed choices, and fostering more equitable, fair, and transparent music understanding systems.

Paper number 145:
Title: Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations
Authors: Gösta Stomberg, Roland Schwan, Andrea Grillo, Colin N. Jones, Timm Faulwasser
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.

Paper number 146:
Title: Cross-Domain Knowledge Transfer for Underwater Acoustic Classification Using Pre-trained Models
Authors: Amirmohammad Mohammadi, Tejashri Kelhe, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples
Abstract: Transfer learning is commonly employed to leverage large, pre-trained models and perform fine-tuning for downstream tasks. The most prevalent pre-trained models are initially trained using ImageNet. However, their ability to generalize can vary across different data modalities. This study compares pre-trained Audio Neural Networks (PANNs) and ImageNet pre-trained models within the context of underwater acoustic target recognition (UATR). It was observed that the ImageNet pre-trained models slightly out-perform pre-trained audio models in passive sonar classification. We also analyzed the impact of audio sampling rates for model pre-training and fine-tuning. This study contributes to transfer learning applications of UATR, illustrating the potential of pre-trained models to address limitations caused by scarce, labeled data in the UATR domain.

Paper number 147:
Title: Investigation of Time-Frequency Feature Combinations with Histogram Layer Time Delay Neural Networks
Authors: Amirmohammad Mohammadi, Iren'e Masabarakiza, Ethan Barnes, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples
Abstract: While deep learning has reduced the prevalence of manual feature extraction, transformation of data via feature engineering remains essential for improving model performance, particularly for underwater acoustic signals. The methods by which audio signals are converted into time-frequency representations and the subsequent handling of these spectrograms can significantly impact performance. This work demonstrates the performance impact of using different combinations of time-frequency features in a histogram layer time delay neural network. An optimal set of features is identified with results indicating that specific feature combinations outperform single data features.

Paper number 148:
Title: Synthesizing Interpretable Control Policies through Large Language Model Guided Search
Authors: Carlo Bosio, Mark W. Mueller
Abstract: The combination of Large Language Models (LLMs), systematic evaluation, and evolutionary algorithms has enabled breakthroughs in combinatorial optimization and scientific discovery. We propose to extend this powerful combination to the control of dynamical systems, generating interpretable control policies capable of complex behaviors. With our novel method, we represent control policies as programs in standard languages like Python. We evaluate candidate controllers in simulation and evolve them using a pre-trained LLM. Unlike conventional learning-based control techniques, which rely on black-box neural networks to encode control policies, our approach enhances transparency and interpretability. We still take advantage of the power of large AI models, but only at the policy design phase, ensuring that all system components remain interpretable and easily verifiable at runtime. Additionally, the use of standard programming languages makes it straightforward for humans to finetune or adapt the controllers based on their expertise and intuition. We illustrate our method through its application to the synthesis of an interpretable control policy for the pendulum swing-up and the ball in cup tasks. We make the code available at this https URL.

Paper number 149:
Title: Offline Hierarchical Reinforcement Learning via Inverse Optimization
Authors: Carolin Schmidt, Daniele Gammelli, James Harrison, Marco Pavone, Filipe Rodrigues
Abstract: Hierarchical policies enable strong performance in many sequential decision-making problems, such as those with high-dimensional action spaces, those requiring long-horizon planning, and settings with sparse rewards. However, learning hierarchical policies from static offline datasets presents a significant challenge. Crucially, actions taken by higher-level policies may not be directly observable within hierarchical controllers, and the offline dataset might have been generated using a different policy structure, hindering the use of standard offline learning algorithms. In this work, we propose OHIO: a framework for offline reinforcement learning (RL) of hierarchical policies. Our framework leverages knowledge of the policy structure to solve the \textit{inverse problem}, recovering the unobservable high-level actions that likely generated the observed data under our hierarchical policy. This approach constructs a dataset suitable for off-the-shelf offline training. We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness. We investigate a variety of instantiations of our framework, both in direct deployment of policies trained offline and when online fine-tuning is performed. Code and data are available at this https URL

Paper number 150:
Title: Is Linear Feedback on Smoothed Dynamics Sufficient for Stabilizing Contact-Rich Plans?
Authors: Yuki Shirai, Tong Zhao, H.J. Terry Suh, Huaijiang Zhu, Xinpei Ni, Jiuguang Wang, Max Simchowitz, Tao Pang
Abstract: Designing planners and controllers for contact-rich manipulation is extremely challenging as contact violates the smoothness conditions that many gradient-based controller synthesis tools assume. Contact smoothing approximates a non-smooth system with a smooth one, allowing one to use these synthesis tools more effectively. However, applying classical control synthesis methods to smoothed contact dynamics remains relatively under-explored. This paper analyzes the efficacy of linear controller synthesis using differential simulators based on contact smoothing. We introduce natural baselines for leveraging contact smoothing to compute (a) open-loop plans robust to uncertain conditions and/or dynamics, and (b) feedback gains to stabilize around open-loop plans. Using robotic bimanual whole-body manipulation as a testbed, we perform extensive empirical experiments on over 300 trajectories and analyze why LQR seems insufficient for stabilizing contact-rich plans. The video summarizing this paper and hardware experiments is found here: this https URL.

Paper number 151:
Title: Uncertainty-Aware Hybrid Inference with On-Device Small and Remote Large Language Models
Authors: Seungeun Oh, Jinhyuk Kim, Jihong Park, Seung-Woo Ko, Tony Q. S. Quek, Seong-Lyun Kim
Abstract: This paper studies a hybrid language model (HLM) architecture that integrates a small language model (SLM) operating on a mobile device with a large language model (LLM) hosted at the base station (BS) of a wireless network. The HLM token generation process follows the speculative inference principle: the SLM's vocabulary distribution is uploaded to the LLM, which either accepts or rejects it, with rejected tokens being resampled by the LLM. While this approach ensures alignment between the vocabulary distributions of the SLM and LLM, it suffers from low token throughput due to uplink transmission and the computation costs of running both language models. To address this, we propose a novel HLM structure coined Uncertainty-aware opportunistic HLM (U-HLM), wherein the SLM locally measures its output uncertainty and skips both uplink transmissions and LLM operations for tokens that are likely to be accepted. This opportunistic skipping is enabled by our empirical finding of a linear correlation between the SLM's uncertainty and the LLM's rejection probability. We analytically derive the uncertainty threshold and evaluate its expected risk of rejection. Simulations show that U-HLM reduces uplink transmissions and LLM computations by 45.93%, while achieving up to 97.54% of the LLM's inference accuracy and 2.54$\times$ faster token throughput than HLM without skipping.

Paper number 152:
Title: CodecFake+: A Large-Scale Neural Audio Codec-Based Deepfake Speech Dataset
Authors: Xuanjun Chen, Jiawei Du, Haibin Wu, Lin Zhang, I-Ming Lin, I-Hsiang Chiu, Wenze Ren, Yuan Tseng, Yu Tsao, Jyh-Shing Roger Jang, Hung-yi Lee
Abstract: With the rapid advancement of neural audio codecs, codec-based speech generation (CoSG) systems have become highly powerful. Unfortunately, CoSG also enables the creation of highly realistic deepfake speech, making it easier to mimic an individual's voice and spread misinformation. We refer to this emerging deepfake speech generated by CoSG systems as CodecFake. Detecting such CodecFake is an urgent challenge, yet most existing systems primarily focus on detecting fake speech generated by traditional speech synthesis models. In this paper, we introduce CodecFake+, a large-scale dataset designed to advance CodecFake detection. To our knowledge, CodecFake+ is the largest dataset encompassing the most diverse range of codec architectures. The training set is generated through re-synthesis using 31 publicly available open-source codec models, while the evaluation set includes web-sourced data from 17 advanced CoSG models. We also propose a comprehensive taxonomy that categorizes codecs by their root components: vector quantizer, auxiliary objectives, and decoder types. Our proposed dataset and taxonomy enable detailed analysis at multiple levels to discern the key factors for successful CodecFake detection. At the individual codec level, we validate the effectiveness of using codec re-synthesized speech (CoRS) as training data for large-scale CodecFake detection. At the taxonomy level, we show that detection performance is strongest when the re-synthesis model incorporates disentanglement auxiliary objectives or a frequency-domain decoder. Furthermore, from the perspective of using all the CoRS training data, we show that our proposed taxonomy can be used to select better training data for improving detection performance. Overall, we envision that CodecFake+ will be a valuable resource for both general and fine-grained exploration to develop better anti-spoofing models against CodecFake.

Paper number 153:
Title: Deep Self-Supervised Disturbance Mapping with the OPERA Sentinel-1 Radiometric Terrain Corrected SAR Backscatter Product
Authors: Harris Hardiman-Mostow, Charles Marshak, Alexander L. Handwerger
Abstract: Mapping land surface disturbances supports disaster response, resource and ecosystem management, and climate adaptation efforts. Synthetic aperture radar (SAR) is an invaluable tool for disturbance mapping, providing consistent time-series images of the ground regardless of weather or illumination conditions. Despite SAR's potential for disturbance mapping, processing SAR data to an analysis-ready format requires expertise and significant compute resources, particularly for large-scale global analysis. In October 2023, NASA's Observational Products for End-Users from Remote Sensing Analysis (OPERA) project released the near-global Radiometric Terrain Corrected SAR backscatter from Sentinel-1 (RTC-S1) dataset, providing publicly available, analysis-ready SAR imagery. In this work, we utilize this new dataset to systematically analyze land surface disturbances. As labeling SAR data is often prohibitively time-consuming, we train a self-supervised vision transformer - which requires no labels to train - on OPERA RTC-S1 data to estimate a per-pixel distribution from the set of baseline imagery and assess disturbances when there is significant deviation from the modeled distribution. To test our model's capability and generality, we evaluate three different natural disasters - which represent high-intensity, abrupt disturbances - from three different regions of the world. Across events, our approach yields high quality delineations: F1 scores exceeding 0.6 and Areas Under the Precision-Recall Curve exceeding 0.65, consistently outperforming existing SAR disturbance methods. Our findings suggest that a self-supervised vision transformer is well-suited for global disturbance mapping and can be a valuable tool for operational, near-global disturbance monitoring, particularly when labeled data does not exist.

Paper number 154:
Title: Scalable and Interpretable Verification of Image-based Neural Network Controllers for Autonomous Vehicles
Authors: Aditya Parameshwaran, Yue Wang
Abstract: Existing formal verification methods for image-based neural network controllers in autonomous vehicles often struggle with high-dimensional inputs, computational inefficiency, and a lack of explainability. These challenges make it difficult to ensure safety and reliability, as processing high-dimensional image data is computationally intensive and neural networks are typically treated as black boxes. To address these issues, we propose SEVIN (Scalable and Explainable Verification of Image-Based Neural Network Controllers), a framework that leverages a Variational Autoencoders (VAE) to encode high-dimensional images into a lower-dimensional, explainable latent space. By annotating latent variables with corresponding control actions, we generate convex polytopes that serve as structured input spaces for verification, significantly reducing computational complexity and enhancing scalability. Integrating the VAE's decoder with the neural network controller allows for formal and robustness verification using these explainable polytopes. Our approach also incorporates robustness verification under real-world perturbations by augmenting the dataset and retraining the VAE to capture environmental variations. Experimental results demonstrate that SEVIN achieves efficient and scalable verification while providing explainable insights into controller behavior, bridging the gap between formal verification techniques and practical applications in safety-critical systems.

Paper number 155:
Title: An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue
Authors: Koji Inoue, Divesh Lala, Mikey Elmers, Keiko Ochi, Tatsuya Kawahara
Abstract: Handling multi-party dialogues represents a significant step for advancing spoken dialogue systems, necessitating the development of tasks specific to multi-party interactions. To address this challenge, we are constructing a multi-modal multi-party dialogue corpus of triadic (three-participant) discussions. This paper focuses on the task of addressee recognition, identifying who is being addressed to take the next turn, a critical component unique to multi-party dialogue systems. A subset of the corpus was annotated with addressee information, revealing that explicit addressees are indicated in approximately 20% of conversational turns. To evaluate the task's complexity, we benchmarked the performance of a large language model (GPT-4o) on addressee recognition. The results showed that GPT-4o achieved an accuracy only marginally above chance, underscoring the challenges of addressee recognition in multi-party dialogue. These findings highlight the need for further research to enhance the capabilities of large language models in understanding and navigating the intricacies of multi-party conversational dynamics.

Paper number 156:
Title: Latent Swap Joint Diffusion for 2D Long-Form Latent Generation
Authors: Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao
Abstract: This paper introduces Swap Forward (SaFa), a modality-agnostic and efficient method to generate seamless and coherence long spectrum and panorama through latent swap joint diffusion across multi-views. We first investigate the spectrum aliasing problem in spectrum-based audio generation caused by existing joint diffusion methods. Through a comparative analysis of the VAE latent representation of Mel-spectra and RGB images, we identify that the failure arises from excessive suppression of high-frequency components during the spectrum denoising process due to the averaging operator. To address this issue, we propose Self-Loop Latent Swap, a frame-level bidirectional swap applied to the overlapping region of adjacent views. Leveraging stepwise differentiated trajectories of adjacent subviews, this swap operator adaptively enhances high-frequency components and avoid spectrum distortion. Furthermore, to improve global cross-view consistency in non-overlapping regions, we introduce Reference-Guided Latent Swap, a unidirectional latent swap operator that provides a centralized reference trajectory to synchronize subview diffusions. By refining swap timing and intervals, we can achieve a cross-view similarity-diversity balance in a forward-only manner. Quantitative and qualitative experiments demonstrate that SaFa significantly outperforms existing joint diffusion methods and even training-based methods in audio generation using both U-Net and DiT models, along with effective longer length adaptation. It also adapts well to panorama generation, achieving comparable performance with 2 $\sim$ 20 $\times$ faster speed and greater model generalizability. More generation demos are available at this https URL

Paper number 157:
Title: A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem
Authors: Vatsal Maru
Abstract: The Aircraft Landing Problem (ALP) is one of the challenging problems in aircraft transportation and management. The challenge is to schedule the arriving aircraft in a sequence so that the cost and delays are optimized. There are various solution approaches to solving this problem, most of which are based on operations research algorithms and meta-heuristics. Although traditional methods perform better on one or the other factors, there remains a problem of solving real-time rescheduling and computational scalability altogether. This paper presents a novel deep reinforcement learning (DRL) framework that combines graph neural networks with actor-critic architectures to address the ALP. This paper introduces three key contributions: A graph-based state representation that efficiently captures temporal and spatial relationships between aircraft, a specialized actor-critic architecture designed to handle multiple competing objectives in landing scheduling, and a runway balance strategy that ensures efficient resource utilization while maintaining safety constraints. The results show that the trained algorithm can be tested on different problem sets and the results are competitive to operation research algorithms. The experimental results on standard benchmark data sets demonstrate a 99.95% reduction in computational time compared to Mixed Integer Programming (MIP) and 38% higher runway throughput over First Come First Serve (FCFS) approaches. Therefore, the proposed solution is competitive to traditional approaches and achieves substantial advancements. Notably, it does not require retraining, making it particularly suitable for industrial deployment. The frameworks capability to generate solutions within 1 second enables real-time rescheduling, addressing critical requirements of air traffic management.

Paper number 158:
Title: Self-Supervised Z-Slice Augmentation for 3D Bio-Imaging via Knowledge Distillation
Authors: Alessandro Pasqui, Sajjad Mahdavi, Benoit Vianay, Alexandra Colin, Alex McDougall, Rémi Dumollard, Yekaterina A. Miroshnikova, Elsa Labrune, Hervé Turlier
Abstract: Three-dimensional biological microscopy has significantly advanced our understanding of complex biological structures. However, limitations due to microscopy techniques, sample properties or phototoxicity often result in poor z-resolution, hindering accurate cellular measurements. Here, we introduce ZAugNet, a fast, accurate, and self-supervised deep learning method for enhancing z-resolution in biological images. By performing nonlinear interpolation between consecutive slices, ZAugNet effectively doubles resolution with each iteration. Compared on several microscopy modalities and biological objects, it outperforms competing methods on most metrics. Our method leverages a generative adversarial network (GAN) architecture combined with knowledge distillation to maximize prediction speed without compromising accuracy. We also developed ZAugNet+, an extended version enabling continuous interpolation at arbitrary distances, making it particularly useful for datasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide high-performance, scalable z-slice augmentation solutions for large-scale 3D imaging. They are available as open-source frameworks in PyTorch, with an intuitive Colab notebook interface for easy access by the scientific community.

Paper number 159:
Title: Enhancing AUTOSAR-Based Firmware Over-the-Air Updates in the Automotive Industry with a Practical Implementation on a Steering System
Authors: Mostafa A. Mostafa, Mohamed K. Mohamed, Radwa W. Ezzat
Abstract: The automotive industry is increasingly reliant on software to manage complex vehicle functionalities, making efficient and secure firmware updates essential. Traditional firmware update methods, requiring physical connections through On-Board Diagnostics (OBD) ports, are inconvenient, costly, and time-consuming. Firmware Over-the-Air (FOTA) technology offers a revolutionary solution by enabling wireless updates, reducing operational costs, and enhancing the user experience. This project aims to design and implement an advanced FOTA system tailored for modern vehicles, incorporating the AUTOSAR architecture for scalability and standardization, and utilizing delta updating to minimize firmware update sizes, thereby improving bandwidth efficiency and reducing flashing times. To ensure security, the system integrates the UDS 0x27 protocol for authentication and data integrity during the update process. Communication between Electronic Control Units (ECUs) is achieved using the CAN protocol, while the ESP8266 module and the master ECU communicate via SPI for data transfer. The system's architecture includes key components such as a bootloader, boot manager, and bootloader updater to facilitate seamless firmware updates. The functionality of the system is demonstrated through two applications: a blinking LED and a Lane Keeping Assist (LKA) system, showcasing its versatility in handling critical automotive features. This project represents a significant step forward in automotive technology, offering a user-centric, efficient, and secure solution for automotive firmware management.

Paper number 160:
Title: SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey
Authors: Joohwan Seo, Soochul Yoo, Junwoo Chang, Hyunseok An, Hyunwoo Ryu, Soomi Lee, Arvind Kruthiventy, Jongeun Choi, Roberto Horowitz
Abstract: Recent advances in deep learning and Transformers have driven major breakthroughs in robotics by employing techniques such as imitation learning, reinforcement learning, and LLM-based multimodal perception and decision-making. However, conventional deep learning and Transformer models often struggle to process data with inherent symmetries and invariances, typically relying on large datasets or extensive data augmentation. Equivariant neural networks overcome these limitations by explicitly integrating symmetry and invariance into their architectures, leading to improved efficiency and generalization. This tutorial survey reviews a wide range of equivariant deep learning and control methods for robotics, from classic to state-of-the-art, with a focus on SE(3)-equivariant models that leverage the natural 3D rotational and translational symmetries in visual robotic manipulation and control design. Using unified mathematical notation, we begin by reviewing key concepts from group theory, along with matrix Lie groups and Lie algebras. We then introduce foundational group-equivariant neural network design and show how the group-equivariance can be obtained through their structure. Next, we discuss the applications of SE(3)-equivariant neural networks in robotics in terms of imitation learning and reinforcement learning. The SE(3)-equivariant control design is also reviewed from the perspective of geometric control. Finally, we highlight the challenges and future directions of equivariant methods in developing more robust, sample-efficient, and multi-modal real-world robotic systems.

Paper number 161:
Title: Prosody-Enhanced Acoustic Pre-training and Acoustic-Disentangled Prosody Adapting for Movie Dubbing
Authors: Zhedong Zhang, Liang Li, Chenggang Yan, Chunshan Liu, Anton van den Hengel, Yuankai Qi
Abstract: Movie dubbing describes the process of transforming a script into speech that aligns temporally and emotionally with a given movie clip while exemplifying the speaker's voice demonstrated in a short reference audio clip. This task demands the model bridge character performances and complicated prosody structures to build a high-quality video-synchronized dubbing track. The limited scale of movie dubbing datasets, along with the background noise inherent in audio data, hinder the acoustic modeling performance of trained models. To address these issues, we propose an acoustic-prosody disentangled two-stage method to achieve high-quality dubbing generation with precise prosody alignment. First, we propose a prosody-enhanced acoustic pre-training to develop robust acoustic modeling capabilities. Then, we freeze the pre-trained acoustic system and design a disentangled framework to model prosodic text features and dubbing style while maintaining acoustic quality. Additionally, we incorporate an in-domain emotion analysis module to reduce the impact of visual domain shifts across different movies, thereby enhancing emotion-prosody alignment. Extensive experiments show that our method performs favorably against the state-of-the-art models on two primary benchmarks. The demos are available at this https URL.

Paper number 162:
Title: Low-PAPR OFDM-ISAC Waveform Design Based on Frequency-Domain Phase Differences
Authors: Kaimin Li, Jiahuan Wang, Haixia Cui, Bingpeng Zhou, Pingzhi Fan
Abstract: Low peak-to-average power ratio (PAPR) orthogonal frequency division multiplexing (OFDM) waveform design is a crucial issue in integrated sensing and communications (ISAC). This paper introduces an OFDM-ISAC waveform design that utilizes the entire spectrum simultaneously for both communication and sensing by leveraging a novel degree of freedom (DoF): the frequency-domain phase difference (PD). Based on this concept, we develop a novel PD-based OFDM-ISAC waveform structure and utilize it to design a PD-based Low-PAPR OFDM-ISAC (PLPOI) waveform. The design is formulated as an optimization problem incorporating four key constraints: the time-frequency relationship equation, frequency-domain unimodular constraints, PD constraints, and time-domain low PAPR requirements. To solve this challenging non-convex problem, we develop an efficient algorithm, ADMM-PLPOI, based on the alternating direction method of multipliers (ADMM) framework. Extensive simulation results demonstrate that the proposed PLPOI waveform achieves significant improvements in both PAPR and bit error rate (BER) performance compared to conventional OFDM-ISAC waveforms.
    