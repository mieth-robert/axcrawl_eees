
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization
Authors: Yang Zhao, Yue Xiu, Chengxiao Dai, Ning Wei, Dusit Niyato
Abstract: Large language model (LLM) training in 6G networks faces stringent latency and energy constraints while operating over bandwidth-limited wireless links. A commonly adopted workflow separates training into a centralized pre-training phase and a federated fine-tuning phase on domain-specific data; however, over-the-air (OTA) gradient aggregation during fine-tuning remains vulnerable to fading and interference. This study explores the integration of movable antennas (MAs), whose element positions can be reconfigured in real time, to mitigate such channel impairments. An auxiliary channel representation embeds transmit power terms in the effective gain, thereby removing explicit power-control variables. We derive the convergence bound that determines the relationship between the final fine-tuning loss to OTA noise and the distribution shift between the two data stages, measured via the Wasserstein distance. These findings lead to a mixed integer, nonconvex resource allocation problem that jointly determines the numbers of global rounds, CPU frequencies, mini-batch sizes, positions of MAs, and beamformers under latency-energy constraints. We propose a hybrid successive convex approximation (SCA) and penalty dual decomposition (PDD) algorithm to solve the problem. Experiments with the OpenLLaMA v2 model with 3 billion parameters demonstrate up to $95\%$ faster convergence and over $90\%$ lower total energy consumption relative to the leading wireless federated learning baselines, underscoring the promise of MAs-assisted federated LLM fine-tuning for 6G edge intelligence.

Paper number 2:
Title: MRDust: Wireless Implant Data Uplink & Localization via Magnetic Resonance Image Modulation
Authors: Biqi Rebekah Zhao, Alexander Chou, Robert Peltekov, Elad Alon, Chunlei Liu, Rikky Muller, Michael Lustig
Abstract: Magnetic resonance imaging (MRI) exhibits rich and clinically useful endogenous contrast mechanisms, which can differentiate soft tissues and are sensitive to flow, diffusion, magnetic susceptibility, blood oxygenation level, and more. However, MRI sensitivity is ultimately constrained by Nuclear Magnetic Resonance (NMR) physics, and its spatiotemporal resolution is limited by SNR and spatial encoding. On the other hand, miniaturized implantable sensors offer highly localized physiological information, yet communication and localization can be challenging when multiple implants are present. This paper introduces the MRDust, an active ``contrast agent" that integrates active sensor implants with MRI, enabling the direct encoding of highly localized physiological data into MR images to augment the anatomical images. MRDust employs a micrometer-scale on-chip coil to actively modulate the local magnetic field, enabling MR signal amplitude and phase modulation for digital data transmission. Since MRI inherently captures the anatomical tissue structure, this method has the potential to enable simultaneous data communication, localization, and image registration with multiple implants. This paper presents the underlying physical principles, design tradeoffs, and design methodology for this approach. To validate the concept, a 900 $\times$ 990 $\mu$m$^2$ chip was designed using TSMC 28 nm technology, with an on-chip coil measuring 630 $\mu$m in diameter. The chip was tested with custom hardware in an MR750W GE3T MRI scanner. Successful voxel amplitude modulation is demonstrated with Spin-Echo Echo-Planar-Imaging (SE-EPI) sequence, achieving a contrast-to-noise ratio (CNR) of 25.58 with a power consumption of 130 $\mu$W.

Paper number 3:
Title: Pushing the Limits of Beam Search Decoding for Transducer-based ASR models
Authors: Lilit Grigoryan, Vladimir Bataev, Andrei Andrusenko, Hainan Xu, Vitaly Lavrukhin, Boris Ginsburg
Abstract: Transducer models have emerged as a promising choice for end-to-end ASR systems, offering a balanced trade-off between recognition accuracy, streaming capabilities, and inference speed in greedy decoding. However, beam search significantly slows down Transducers due to repeated evaluations of key network components, limiting practical applications. This paper introduces a universal method to accelerate beam search for Transducers, enabling the implementation of two optimized algorithms: ALSD++ and AES++. The proposed method utilizes batch operations, a tree-based hypothesis structure, novel blank scoring for enhanced shallow fusion, and CUDA graph execution for efficient GPU inference. This narrows the speed gap between beam and greedy modes to only 10-20% for the whole system, achieves 14-30% relative improvement in WER compared to greedy decoding, and improves shallow fusion for low-resource up to 11% compared to existing implementations. All the algorithms are open sourced.

Paper number 4:
Title: STARS-assisted Near-field ISAC: Sensor Deployment and Beamforming Design
Authors: Na Xue, Xidong Mu, Yue Chen, Yuanwei Liu
Abstract: A simultaneously transmitting and reflecting surface (STARS) assisted near-field (NF) integrated sensing and communication (ISAC) framework is proposed, where the radio sensors are installed on the STARS to directly conduct the distance-domain sensing by exploiting the characteristic spherical wavefront. A new squared position error bound (SPEB) expression is derived to reveal the dependence on beamforming (BF) design and sensor deployment. To balance the trade-off between the SPEB and the sensor deployment cost, a cost function minimization problem, a cost function minimization problem is formulated to jointly optimize the sensor deployment, the active and passive BF, subject to communication and power consumption constraints. For the sensor deployment optimization, a joint sensor deployment algorithm is proposed by invoking the successive convex approximation. Under a specific relationship between the sensor numbers and BF design, we derive the optimal sensor interval in a closed-form expression. For the joint BF optimization, a penalty-based method is invoked. Simulation results validated that the derived SPEB expression is close to the exact SPEB, which reveals the Fisher information Matrix of position estimation in NF can be approximated as a diagonal matrix. Furthermore, the proposed algorithms achieve the best SPEB performance than the benchmark schemes accompanying the lowest deployment cost.

Paper number 5:
Title: The Impact of Uniform Circular Array on Near-field ISAC
Authors: Na Xue, Xidong Mu, Yue Chen, Yuanwei Liu
Abstract: A novel uniform circular array (UCA) based near-field (NF) integrated sensing and communication (ISAC) framework is proposed, where the Cylindrical coordinate is invoked to evaluate the joint positioning performance. The joint squared position error bound (SPEB) of the sensing target (ST) is derived for the coplanar and non-coplanar cases. For the coplanar case, where the ST is located in the coplanar region of the UCA, the approximate Cram{Ã©}r-Rao bound (CRB) expressions for the separate angle and distance estimation are given by exploiting the uniform spherical wavefront model. A SPEB minimization problem is formulated with the constraints of communication requirement and power budget, where the closed-form solution to minimize the CRB of the angle is derived. Inspired by the close-form expression, a low complexity vector-based quadratic transformation (VQF) algorithm is proposed by invoking the Rayleigh quotient. For the non-coplanar case, where the ST is located beyond the coplanar region of the UCA, the separate CRBs over three-dimensional coordinates and the joint SPEB approximations are derived. To minimize the SPEB performance, the semi-definite relaxation (SDR) method and extended low-complexity VQF algorithm are proposed. Numerical results validated that i) the Fisher Information Matrix about angle and distance in NF propagation can be approximated as a diagonal matrix with the trinity loss; ii) Compared with the uniform planar array, the UCA achieve better positioning performance when ST located in the coplanar of the antenna array; and iii) the proposed VQF algorithms reach higher solution precision than conventional SDR algorithm with much less computation complexity.

Paper number 6:
Title: Enhancing Spatio-Temporal Resolution of Process-Based Life Cycle Analysis with Model-Based Systems Engineering \& Hetero-functional Graph Theory
Authors: Niraj Gohil, Nawshad Haque, Amgad Elgowainy, Amro M. Farid
Abstract: Life cycle analysis (LCA) has emerged as a vital tool for assessing the environmental impacts of products, processes, and systems throughout their entire lifecycle. It provides a systematic approach to quantifying resource consumption, emissions, and waste, enabling industries, researchers, and policymakers to identify hotspots for sustainability improvements. By providing a comprehensive assessment of systems, from raw material extraction to end-of-life disposal, LCA facilitates the development of environmentally sound strategies, thereby contributing significantly to sustainable engineering and informed decision-making. Despite its strengths and ubiquitous use, life cycle analysis has not been reconciled with the broader literature in model-based systems engineering and analysis, thus hindering its integration into the design of complex systems more generally. This lack of reconciliation poses a significant problem, as it hinders the seamless integration of environmental sustainability into the design and optimization of complex systems. Without alignment between life cycle analysis (LCA) and model-based systems engineering (MBSE), sustainability remains an isolated consideration rather than an inherent part of the system's architecture and design. The original contribution of this paper is twofold. First, the paper reconciles process-based life cycle analysis with the broader literature and vocabulary of model-based systems engineering and hetero-functional graph theory. It ultimately proves that model-based systems engineering and hetero-functional graph theory are a formal generalization of process-based life cycle analysis. Secondly, the paper demonstrates how model-based systems engineering and hetero-functional graph theory may be used to enhance the spatio-temporal resolution of process-based life cycle analysis in a manner that aligns with system design objectives.

Paper number 7:
Title: Adaptive Voxelization for Transform coding of 3D Gaussian splatting data
Authors: Chenjunjie Wang, Shashank N. Sridhara, Eduardo Pavez, Antonio Ortega, Cheng Chang
Abstract: We present a novel compression framework for 3D Gaussian splatting (3DGS) data that leverages transform coding tools originally developed for point clouds. Contrary to existing 3DGS compression methods, our approach can produce compressed 3DGS models at multiple bitrates in a computationally efficient way. Point cloud voxelization is a discretization technique that point cloud codecs use to improve coding efficiency while enabling the use of fast transform coding algorithms. We propose an adaptive voxelization algorithm tailored to 3DGS data, to avoid the inefficiencies introduced by uniform voxelization used in point cloud codecs. We ensure the positions of larger volume Gaussians are represented at high resolution, as these significantly impact rendering quality. Meanwhile, a low-resolution representation is used for dense regions with smaller Gaussians, which have a relatively lower impact on rendering quality. This adaptive voxelization approach significantly reduces the number of Gaussians and the bitrate required to encode the 3DGS data. After voxelization, many Gaussians are moved or eliminated. Thus, we propose to fine-tune/recolor the remaining 3DGS attributes with an initialization that can reduce the amount of retraining required. Experimental results on pre-trained datasets show that our proposed compression framework outperforms existing methods.

Paper number 8:
Title: SoundSculpt: Direction and Semantics Driven Ambisonic Target Sound Extraction
Authors: Tuochao Chen, D Shin, Hakan Erdogan, Sinan Hersek
Abstract: This paper introduces SoundSculpt, a neural network designed to extract target sound fields from ambisonic recordings. SoundSculpt employs an ambisonic-in-ambisonic-out architecture and is conditioned on both spatial information (e.g., target direction obtained by pointing at an immersive video) and semantic embeddings (e.g., derived from image segmentation and captioning). Trained and evaluated on synthetic and real ambisonic mixtures, SoundSculpt demonstrates superior performance compared to various signal processing baselines. Our results further reveal that while spatial conditioning alone can be effective, the combination of spatial and semantic information is beneficial in scenarios where there are secondary sound sources spatially close to the target. Additionally, we compare two different semantic embeddings derived from a text description of the target sound using text encoders.

Paper number 9:
Title: Power-of-Two (PoT) Weights in Large Language Models (LLMs)
Authors: Mahmoud Elgenedy
Abstract: Complexity of Neural Networks is increasing rapidly due to the massive increase in model parameters. Specifically, in Large Language Models (LLMs), the number of model parameters has grown exponentially in the past few years, for example, from 1.5 billion parameters in GPT2 to 175 billion in GPT3. This raises a significant challenge for implementation, especially for Edge devices where memory and processing power are very limited. In this work, we investigate reducing LLM complexity with special type of quantization, power of two (PoT), for linear layers weights and transformer tables. PoT not only provides memory reduction but more importantly provides significant computational reduction through converting multiplication to bit shifting. We obtained preliminary results of PoT quantization on Nano-GPT implementation using Shakespeare dataset. We then extended results to 124-M GPT-2 model. The PoT quantization results are shown to be very promising with cross entropy loss degradation $\approx$[1.3-0.88] with number of bits range [4-6] to represent power levels.

Paper number 10:
Title: Single-layer Circular SIW Filtenna With Beam Scanning Capability for 5G Millimeter Wave Communication Applications
Authors: Jiawang Li
Abstract: In this communication, two novel low-cost single-layer filtering antennas (filtennas) are proposed for millimeter wave (mmWave) applications. The proposed filtennas consists of a compact circular substrate integrated waveguide (SIW) cavity, a metal post close to the center of the cavity for power feeding, a metal post in the center for modes controlling, and a slot for radiating power. In the passband, the fundamental TM010 mode and the TM110 mode in the circular SIW cavity are excited by the feeding post. In addition, thanks to the high-pass characteristics of the cavity, it exhibits more than 20 dB suppression in the lower frequency band. There are three radiation nulls in Filtenna 1 and one radiation null in Filtenna 2 in the upper band which increase the suppression level as high as 18 dB. As a proof of concept, the proposed filtennas are fabricated and measured. It is shown that the Filtenna 1 can achieve simulated and measured -10 dB impedance fractional bandwidth (FBW) of 7.1% (27.14 - 29.13 GHz) and 8.6% (27.62 - 30.11 GHz), respectively. While filtenna 2 can achieve simulated and measured -10 dB FBW of 7.4% (27.86 - 29.99 GHz) and 10.1% (28.11 - 31.09 GHz), respectively. The filtennas features stable radiation patterns with an average gain of 5.0 dBi. The lower and upper sideband suppression levels for both filtennas exceed 18 dB. These filtennas are good candidates for 5G mmWave applications, as they simultaneously provide beam scanning and filtering capability with a low cost, and single layer structure.

Paper number 11:
Title: Neural Network-based Information-Theoretic Transceivers for High-Order Modulation Schemes
Authors: Ngoc Long Pham, Tri Nhu Do
Abstract: Neural network (NN)-based end-to-end (E2E) communication systems, in which each system component may consist of a portion of a neural network, have been investigated as potential tools for developing artificial intelligence (Al)-native E2E systems. In this paper, we propose an NN-based bitwise receiver that improves computational efficiency while maintaining performance comparable to baseline demappers. Building on this foundation, we introduce a novel symbol-wise autoencoder (AE)-based E2E system that jointly optimizes the transmitter and receiver at the physical layer. We evaluate the proposed NN-based receiver using bit-error rate (BER) analysis to confirm that the numerical BER achieved by NN-based receivers or transceivers is accurate. Results demonstrate that the AE-based system outperforms baseline architectures, particularly for higher-order modulation schemes. We further show that the training signal-to-noise ratio (SNR) significantly affects the performance of the systems when inference is conducted at different SNR levels.

Paper number 12:
Title: Physics-based Generative Models for Geometrically Consistent and Interpretable Wireless Channel Synthesis
Authors: Satyavrat Wagle, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, David J.Love, Christopher G. Brinton
Abstract: In recent years, machine learning (ML) methods have become increasingly popular in wireless communication systems for several applications. A critical bottleneck for designing ML systems for wireless communications is the availability of realistic wireless channel datasets, which are extremely resource-intensive to produce. To this end, the generation of realistic wireless channels plays a key role in the subsequent design of effective ML algorithms for wireless communication systems. Generative models have been proposed to synthesize channel matrices, but outputs produced by such methods may not correspond to geometrically viable channels and do not provide any insight into the scenario being generated. In this work, we aim to address both these issues by integrating established parametric, physics-based geometric channel (PPGC) modeling frameworks with generative methods to produce realistic channel matrices with interpretable representations in the parameter domain. We show that generative models converge to prohibitively suboptimal stationary points when learning the underlying prior directly over the parameters due to the non-convex PPGC model. To address this limitation, we propose a linearized reformulation of the problem to ensure smooth gradient flow during generative model training, while also providing insights into the underlying physical environment. We evaluate our model against prior baselines by comparing the generated, scenario-specific samples in terms of the 2-Wasserstein distance and through its utility when used for downstream compression tasks.

Paper number 13:
Title: Sensor Fusion Methods for Gaussian Mixture Models
Authors: Ishan Paranjape, Islam Hussein, Jeremy Murray-Krezan, Sean Phillips, Suman Chakravorty
Abstract: Consensus is a popular technique for distributed state estimation. This formulation allows networks of connected agents or sensors to exchange information about the distribution of a set of targets with their immediate neighbors without the need of a centralized node or layer. We present decentralized consensus-based fusion techniques for a system whose target prior estimates are a weighted mixture of Gaussian probability density functions (PDFs) for the following cases: 1) in which all agents have the same a priori Gaussian mixture estimate of the target, and 2) in which agents have different a priori Gaussian mixture estimates of the target. For the second case, we present a formulation that fuses each agent's a priori estimate without using local observations such that each agent's posterior estimate is the same across the network.

Paper number 14:
Title: A Family of Robust Generalized Adaptive Filters and Application for Time-series Prediction
Authors: Yi Peng, Haiquan Zhao, Jinhui Hu
Abstract: The continuous development of new adaptive filters (AFs) based on novel cost functions (CFs) is driven by the demands of various application scenarios and noise environments. However, these algorithms typically demonstrate optimal performance only in specific conditions. In the event of the noise change, the performance of these AFs often declines, rendering simple parameter adjustments ineffective. Instead, a modification of the CF is necessary. To address this issue, the robust generalized adaptive AF (RGA-AF) with strong adaptability and flexibility is proposed in this paper. The flexibility of the RGA-AF's CF allows for smooth adaptation to varying noise environments through parameter adjustments, ensuring optimal filtering performance in diverse scenarios. Moreover, we introduce several fundamental properties of negative RGA (NRGA) entropy and present the negative asymmetric RGA-AF (NAR-GA-AF) and kernel recursive NRGA-AF (KRNRGA-AF). These AFs address asymmetric noise distribution and nonlinear filtering issues, respectively. Simulations of linear system identification and time-series prediction for Chua's circuit under different noise environments demonstrate the superiority of the proposed algorithms in comparison to existing techniques.

Paper number 15:
Title: Transient Error Analysis of the LMS and RLS Algorithm for Graph Signal Estimation
Authors: Haiquan Zhao, Chengjin Li
Abstract: Recently, the proposal of the least mean square (LMS) and recursive least squares (RLS) algorithm for graph signal processing (GSP) provides excellent solutions for processing signals defined on irregular structures such as sensor networks. The existing work has completed the steady state error analysis of the GSP LMS algorithm and GSP RLS algorithm in Gaussian noise scenarios, and a range of values for the step size of the GSP LMS algorithm has also been given. Meanwhile, the transient error analysis of the GSP LMS algorithm and GSP RLS algorithm is also important and challenging. Completing the above work will help to quantitatively analyze the performance of the graph signal adaptive estimation algorithm at transient moments, which is what this paper is working on. By using formula derivation and mathematical induction, the transient errors expressions of the GSP LMS and GSP RLS algorithm are given in this paper. Based on the Brazilian temperature datasets, the related simulation experiments are executed, which strongly demonstrate the correctness of our proposed theoretical analysis

Paper number 16:
Title: Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention
Authors: TaeJun Ha, Chaehyun Jung, Hyeonuk Kim, Jeongwoo Park, Jeonghun Park
Abstract: In orthogonal frequency division multiplexing (OFDM), accurate channel estimation is crucial. Classical signal processing based approaches, such as minimum mean-squared error (MMSE) estimation, often require second-order statistics that are difficult to obtain in practice. Recent deep neural networks based methods have been introduced to address this; yet they often suffer from high complexity. This paper proposes an Attention-aided MMSE (A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter via the Attention Transformer. Once trained, the A-MMSE estimates the channel through a single linear operation for channel estimation, eliminating nonlinear activations during inference and thus reducing computational complexity. To enhance the learning efficiency of the A-MMSE, we develop a two-stage Attention encoder, designed to effectively capture the channel correlation structure. Additionally, a rank-adaptive extension of the proposed A-MMSE allows flexible trade-offs between complexity and channel estimation accuracy. Extensive simulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE consistently outperforms other baseline methods in terms of normalized MSE across a wide range of SNR conditions. In particular, the A-MMSE and its rank-adaptive extension establish a new frontier in the performance complexity trade-off, redefining the standard for practical channel estimation methods.

Paper number 17:
Title: Towards Temporally Explainable Dysarthric Speech Clarity Assessment
Authors: Seohyun Park, Chitralekha Gupta, Michelle Kah Yian Kwan, Xinhui Fung, Alexander Wenjun Yip, Suranga Nanayakkara
Abstract: Dysarthria, a motor speech disorder, affects intelligibility and requires targeted interventions for effective communication. In this work, we investigate automated mispronunciation feedback by collecting a dysarthric speech dataset from six speakers reading two passages, annotated by a speech therapist with temporal markers and mispronunciation descriptions. We design a three-stage framework for explainable mispronunciation evaluation: (1) overall clarity scoring, (2) mispronunciation localization, and (3) mispronunciation type classification. We systematically analyze pretrained Automatic Speech Recognition (ASR) models in each stage, assessing their effectiveness in dysarthric speech evaluation (Code available at: this https URL, Supplementary webpage: this https URL). Our findings offer clinically relevant insights for automating actionable feedback for pronunciation assessment, which could enable independent practice for patients and help therapists deliver more effective interventions.

Paper number 18:
Title: M3ANet: Multi-scale and Multi-Modal Alignment Network for Brain-Assisted Target Speaker Extraction
Authors: Cunhang Fan, Ying Chen, Jian Zhou, Zexu Pan, Jingjing Zhang, Youdian Gao, Xiaoke Yang, Zhengqi Wen, Zhao Lv
Abstract: The brain-assisted target speaker extraction (TSE) aims to extract the attended speech from mixed speech by utilizing the brain neural activities, for example Electroencephalography (EEG). However, existing models overlook the issue of temporal misalignment between speech and EEG modalities, which hampers TSE performance. In addition, the speech encoder in current models typically uses basic temporal operations (e.g., one-dimensional convolution), which are unable to effectively extract target speaker information. To address these issues, this paper proposes a multi-scale and multi-modal alignment network (M3ANet) for brain-assisted TSE. Specifically, to eliminate the temporal inconsistency between EEG and speech modalities, the modal alignment module that uses a contrastive learning strategy is applied to align the temporal features of both modalities. Additionally, to fully extract speech information, multi-scale convolutions with GroupMamba modules are used as the speech encoder, which scans speech features at each scale from different directions, enabling the model to capture deep sequence information. Experimental results on three publicly available datasets show that the proposed model outperforms current state-of-the-art methods across various evaluation metrics, highlighting the effectiveness of our proposed method. The source code is available at: this https URL.

Paper number 19:
Title: A European Multi-Center Breast Cancer MRI Dataset
Authors: Gustav MÃ¼ller-Franzes, Lorena Escudero SÃ¡nchez, Nicholas Payne, Alexandra Athanasiou, Michael Kalogeropoulos, Aitor Lopez, Alfredo Miguel Soro Busto, Julia Camps Herrero, Nika Rasoolzadeh, Tianyu Zhang, Ritse Mann, Debora Jutz, Maike Bode, Christiane Kuhl, Wouter Veldhuis, Oliver Lester Saldanha, JieFu Zhu, Jakob Nikolas Kather, Daniel Truhn, Fiona J. Gilbert
Abstract: Detecting breast cancer early is of the utmost importance to effectively treat the millions of women afflicted by breast cancer worldwide every year. Although mammography is the primary imaging modality for screening breast cancer, there is an increasing interest in adding magnetic resonance imaging (MRI) to screening programmes, particularly for women at high risk. Recent guidelines by the European Society of Breast Imaging (EUSOBI) recommended breast MRI as a supplemental screening tool for women with dense breast tissue. However, acquiring and reading MRI scans requires significantly more time from expert radiologists. This highlights the need to develop new automated methods to detect cancer accurately using MRI and Artificial Intelligence (AI), which have the potential to support radiologists in breast MRI interpretation and classification and help detect cancer earlier. For this reason, the ODELIA consortium has made this multi-centre dataset publicly available to assist in developing AI tools for the detection of breast cancer on MRI.

Paper number 20:
Title: The Coupling Effect of Sensing Targets on the Environment for 3GPP ISAC Channels: Observation, Modeling, and Validation
Authors: Yameng Liu, Jianhua Zhang, Yuxiang Zhang, Hongbo Xing, Yifeng Xiong, Zhiqiang Yuan, Guangyi Liu
Abstract: Integrated Sensing And Communication (ISAC) has been identified as a key 6G application by ITU and 3GPP, with standardization efforts already underway. Sensing tasks, such as target localization, demand more precise characterization of the sensing target (ST) in ISAC channel modeling. The ST couples complexly with environmental scatterers, potentially blocking some multipaths and generating new ones, resulting in power variations compared to the original channel. To accurately model this effect, this paper proposes a coupled ISAC channel model based on measurements and validates it through similarity analysis between simulated and measured channels. In this work, we first conduct ISAC channel measurements in an indoor factory scenario at 105 GHz, where the multipath power variations caused by the ST's interaction with the environment are clearly observed. Then, we propose an ISAC channel modeling framework that incorporates two novel parameters: the Blockage-Region Coupling Factor (BR-CF) and the Forward-Scattering (FS)-CF, which characterize the spatial region and intensity of the coupling effect, respectively. Finally, the proposed model is validated through similarity comparison with measured data, demonstrating higher accuracy for both LoS and NLoS scenarios compared to the non-coupled model. This realistic ISAC channel model provides an effective framework for capturing the ST-environment coupling effect, supporting the design and evaluation of ISAC technologies.

Paper number 21:
Title: Second-Order Characterization of Micro Doppler Radar Signatures of Drone Swarms
Authors: Anders Malthe Westerkam, Alba Spliid DamkjÃ¦r, Rasmus Erik Villadsen, Magnus Ãrum Bastrup Poulsen, Troels Pedersen
Abstract: We investigate the second-order characteristics of the radar return signal from a swarm of rotor drones. We consider the case of a swarm of identical drones, with each a number of rotors comprised of a number of rotor blades. By considering the orientation and speed of each rotor as stochastic variables, we derive expressions for the autocorrelation function (ACF) and power spectral density (PSD). The ACF and PSD are in the form of an infinite series with coefficients that drop to zero at a predictable limit. Thus in practical applications, the series may be truncated. As a special case, we show that for deterministic rotor speed, the ACF can be expressed in closed form. We further investigate how system parameters (Blade length, Rotor speed, number of blades, and number of drones) influence the derived expressions for the ACF and PSD.

Paper number 22:
Title: Quality Assessment of Noisy and Enhanced Speech with Limited Data: UWB-NTIS System for VoiceMOS 2024 and Beyond
Authors: Marie KuneÅ¡ovÃ¡
Abstract: In this preprint, we present the UWB-NTIS-TTS team's submission to Track 3 of the VoiceMOS 2024 Challenge, the goal of which was to automatically assess the speech quality of noisy and de-noised speech in terms of the ITU-T P.835 metrics of "SIG", "BAK", and "OVRL". Our proposed system, based on wav2vec 2.0, placed among the top systems in the challenge, achieving the best prediction of the BAK scores (background noise intrusiveness), the second-best prediction of the OVRL score (overall audio quality), and the third-best prediction of SIG (speech signal quality) out of the five participating systems. We describe our approach, such as the two-stage fine-tuning process we used to contend with the challenge's very limiting restrictions on allowable training data, and present the results achieved both on the VoiceMOS 2024 Challenge data and on the recently released CHiME 7 - UDASE dataset.

Paper number 23:
Title: Integrated Sensing, Computing and Semantic Communication for Vehicular Networks
Authors: Yinchao Yang, Zhaohui Yang, Chongwen Huang, Wei Xu, Zhaoyang Zhang, Dusit Niyato, Mohammad Shikh-Bahaei
Abstract: This paper introduces a novel framework for integrated sensing, computing, and semantic communication (ISCSC) within vehicular networks comprising a roadside unit (RSU) and multiple autonomous vehicles. Both the RSU and the vehicles are equipped with local knowledge bases to facilitate semantic communication. The framework incorporates a secure communication design to ensure that messages intended for specific vehicles are protected against interception. In this model, an extended Kalman filter (EKF) is employed by the RSU to accurately track all vehicles. We formulate a joint optimization problem that balances maximizing the probabilistically constrained semantic secrecy rate for each vehicle while minimizing the sum of the posterior CramÃ©r-Rao bound (PCRB), subject to the RSU's computing capabilities. This non-convex optimization problem is addressed using Bernstein-type inequality (BTI) and alternating optimization (AO) techniques. Simulation results validate the effectiveness of the proposed framework, demonstrating its advantages in reliable sensing, high data throughput, and secure communication.

Paper number 24:
Title: Your Demands Deserve More Bits: Referring Semantic Image Compression at Ultra-low Bitrate
Authors: Chenhao Wu, Qingbo Wu, Haoran Wei, Shuai Chen, Mingzhou He, King Ngi Ngan, Fanman Meng, Hongliang Li
Abstract: With the help of powerful generative models, Semantic Image Compression (SIC) has achieved impressive performance at ultra-low bitrate. However, due to coarse-grained visual-semantic alignment and inherent randomness, the reliability of SIC is seriously concerned for reconstructing completely different object instances, even they are semantically consistent with original images. To tackle this issue, we propose a novel Referring Semantic Image Compression (RSIC) framework to improve the fidelity of user-specified content while retaining extreme compression ratios. Specifically, RSIC consists of three modules: Global Description Encoding (GDE), Referring Guidance Encoding (RGE), and Guided Generative Decoding (GGD). GDE and RGE encode global semantic information and local features, respectively, while GGD handles the non-uniformly guided generative process based on the encoded information. In this way, our RSIC achieves flexible customized compression according to user demands, which better balance the local fidelity, global realism, semantic alignment, and bit overhead. Extensive experiments on three datasets verify the compression efficiency and flexibility of the proposed method.

Paper number 25:
Title: Image Restoration Learning via Noisy Supervision in the Fourier Domain
Authors: Haosen Liu, Jiahao Liu, Shan Tan, Edmund Y. Lam
Abstract: Noisy supervision refers to supervising image restoration learning with noisy targets. It can alleviate the data collection burden and enhance the practical applicability of deep learning techniques. However, existing methods suffer from two key drawbacks. Firstly, they are ineffective in handling spatially correlated noise commonly observed in practical applications such as low-light imaging and remote sensing. Secondly, they rely on pixel-wise loss functions that only provide limited supervision information. This work addresses these challenges by leveraging the Fourier domain. We highlight that the Fourier coefficients of spatially correlated noise exhibit sparsity and independence, making them easier to handle. Additionally, Fourier coefficients contain global information, enabling more significant supervision. Motivated by these insights, we propose to establish noisy supervision in the Fourier domain. We first prove that Fourier coefficients of a wide range of noise converge in distribution to the Gaussian distribution. Exploiting this statistical property, we establish the equivalence between using noisy targets and clean targets in the Fourier domain. This leads to a unified learning framework applicable to various image restoration tasks, diverse network architectures, and different noise models. Extensive experiments validate the outstanding performance of this framework in terms of both quantitative indices and perceptual quality.

Paper number 26:
Title: Joint Activity Detection and Channel Estimation for Massive Connectivity: Where Message Passing Meets Score-Based Generative Priors
Authors: Chang Cai, Wenjun Jiang, Xiaojun Yuan, Ying-Jun Angela Zhang
Abstract: Massive connectivity supports the sporadic access of a vast number of devices without requiring prior permission from the base station (BS). In such scenarios, the BS must perform joint activity detection and channel estimation (JADCE) prior to data reception. Message passing algorithms have emerged as a prominent solution for JADCE under a Bayesian inference framework. The existing message passing algorithms, however, typically rely on some hand-crafted and overly simplistic priors of the wireless channel, leading to significant channel estimation errors and reduced activity detection accuracy. In this paper, we focus on the problem of JADCE in a multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) grant-free random access network. We propose to incorporate a more accurate channel prior learned by score-based generative models into message passing, so as to push towards the performance limit of JADCE. Specifically, we develop a novel turbo message passing (TMP) framework that models the entire channel matrix as a super node, rather than factorizing it element-wise. This design enables the seamless integration of score-based generative models as a minimum mean-squared error (MMSE) denoiser. The variance of the denoiser, which is essential in message passing, can also be learned through score-based generative models. Our approach, termed score-based TMP for JADCE (STMP-JADCE), takes full advantages of the powerful generative prior and, meanwhile, benefits from the fast convergence speed of message passing. Numerical simulations show that STMP-JADCE drastically enhances the activity detection and channel estimation performance compared to the state-of-the-art baseline algorithms.

Paper number 27:
Title: Exploiting Pinching-Antenna Systems in Multicast Communications
Authors: Shan Shan, Chongjun Ouyang, Yong Li, Yuanwei Liu
Abstract: The pinching-antenna system (PASS) reconfigures wireless links through pinching beamforming, in which the activated locations of pinching antennas (PAs) along dielectric waveguides are optimized. This article investigates the application of PASS in multicast communication systems, where pinching beamforming is designed to maximize the multicast rate. i) In the single-waveguide scenario, a closed-form solution for the optimal activated location is derived under the assumption of a single PA and linearly distributed users. Based on this, a closed-form expression for the achievable multicast rate is obtained and proven to be larger than that of conventional fixed-location antenna systems. For the general multiple-PA case with arbitrary user distributions, an element-wise alternating optimization (AO) algorithm is proposed to design the pinching beamformer. ii) In the multiple-waveguide scenario, an AO-based method is developed to jointly optimize the transmit and pinching beamformers. Specifically, the transmit beamformer is updated using a majorization-minimization (MM) framework together with second-order cone programming (SOCP), while the pinching beamformer is optimized via element-wise sequential refinement. Numerical results are provided to demonstrate that: i) PASS achieves significantly higher multicast rates than conventional fixed-location antenna systems, particularly when the number of users and spatial coverage increase; ii) increasing the number of PAs further improves the multicast performance of PASS.

Paper number 28:
Title: Over-the-air Multifunctional Wideband Electromagnetic Signal Processing using Dynamic Scattering Arrays
Authors: Davide Dardari
Abstract: To meet the stringent requirements of next-generation wireless networks, multiple-input multiple-output (MIMO) technology is expected to become massive and pervasive. Unfortunately, this could pose scalability issues in terms of complexity, power consumption, cost, and processing latency. Therefore, novel technologies and design approaches, such as the recently introduced holographic MIMO paradigm, must be investigated to make future networks sustainable. In this context, we investigate the concept of a dynamic scattering array (DSA) as a versatile electromagnetic (EM) structure capable of performing joint wave-based computing and radiation by moving the processing from the digital domain to the EM domain. We provide a general, wideband analytical framework for modeling the DSA, which includes a power matching network and realistic reconfigurable loads. Then we introduce specific design algorithms, and apply them to various use cases. We demonstrate that some recent EM processing structures can be seen as particular cases of our general framework. The examples presented in the numerical results corroborate the potential of DSAs to reduce complexity and the number of radiofrequency (RF) chains in holographic MIMO systems while achieving enhanced EM wave processing and radiation flexibility for tasks such as beamforming and single- and multi-user MIMO, also exhibiting superdirectivity capabilities.

Paper number 29:
Title: Real-Time Sounding in ISAC networks: Design and Implementation of a Multi-Node Testbed with Synchronized Airborne and Ground-Based Sensors
Authors: Julia Beuster, Carsten Andrich, Sebastian Giehl, Marc Miranda, Lorenz Mohr, Dieter Novotny, Tom Kaufmann, Christian Schneider, Reiner S. ThomÃ¤
Abstract: As integrated sensing and communication (ISAC) capabilities become more prevalent in the mobile 6G radio landscape, there is a substantial opportunity to enhance situational awareness across diverse applications through multi-static radar sensing within meshed ISAC networks. To facilitate the development and testing of detection and localization algorithms across diverse scenarios, this paper introduces a synchronized distributed channel sounding testbed with airborne and ground-based multi-channel transceiver nodes with centimeter-level positioning accuracy enabled by real-time kinematic (RTK) and inertial navigation system (INS) data. Our modular experimental measurement system is designed to include stationary sensor nodes and light-weight to medium-weight mobile nodes deployable on unmanned aerial vehicles (UAVs), cars, pedestrians, and cyclists. Utilizing commercial off-the-shelf (COTS) hardware, specifically software defined radios (SDRs), the testbed encourages reproducibility in academic research laboratories. We detail the individual modules and integration steps required to achieve the specified performance. The testbed's capabilities are validated through a real-world measurement campaign, including stationary and flying sensor nodes, aimed at detecting radar targets such as vertical take-off and landing (VTOL) aircrafts, small hexacopters, cars and vulnerable road users (VRUs) in air-to-air (A2A) and air-to-ground (A2G) scenarios.

Paper number 30:
Title: Electromagnetically Reconfigurable Antennas for 6G: Enabling Technologies, Prototype Studies, and Research Outlook
Authors: Pinjun Zheng, Ruiqi Wang, Yuchen Zhang, Md. Jahangir Hossain, Anas Chaaban, Atif Shamim, Tareq Y. Al-Naffouri
Abstract: The transition to the sixth-generation (6G) network is anticipated to redefine wireless transceiver architectures, demanding higher adaptability and efficiency at the antenna layer. Electromagnetically reconfigurable antennas (ERAs) have emerged as a promising solution capable of dynamically reconfiguring wireless channels to meet these requirements. This article presents an overview of recent advancements in ERA technology, underscoring its transformative potential for 6G applications. Drawing from several initial studies, we demonstrate that ERAs can significantly enhance communication rates and hardware efficiency. Nevertheless, critical challenges remain in hardware design and signal processing methodologies, necessitating concerted efforts from both the antenna and communication communities. We identify these gaps and outline key research directions to fully unlock the capabilities of ERAs in next-generation wireless networks.

Paper number 31:
Title: Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT
Authors: Megan Harris, Ehsanoddin Ghorbanichemazkati, Mohammad Mahdi Naderi, John C. Little, Amro M. Farid
Abstract: Worsening global challenges in the Anthropocene demand complex, adaptive solutions grounded in a systems-level understanding of coupled social and environmental dynamics. However, existing modeling approaches often fall short due to disciplinary silos, limited scalability, and the absence of shared ontological frameworks. Model-Based Systems Engineering (MBSE), when integrated with Hetero-functional Graph Theory (HFGT), offers a powerful methodology for modeling systems of systems while preserving subsystem heterogeneity and enabling cross-disciplinary integration. This paper presents the first application of the MBSE-HFGT methodology to environmental systems, using a series of worked examples involving flow through lake and land segments. These examples demonstrate how the approach enables consistent, scalable, and integrative modeling of complex environmental processes.

Paper number 32:
Title: On the Use of BjÃ¶rck Sequences in LEO-based PNT Systems
Authors: Harish K. Dureppagari, Chiranjib Saha, R. Michael Buehrer, Harpreet S. Dhillon
Abstract: In this paper, we investigate the use of BjÃ¶rck sequences, a class of constant amplitude zero autocorrelation (CAZAC) sequences, as a potential candidate for the design of positioning reference signals (PRS) in Low Earth Orbit (LEO)-based positioning, navigation, and timing (PNT) systems. Unlike legacy systems such as Global Navigation Satellite Systems (GNSS) or terrestrial networks (TNs), LEO-based systems experience large Doppler shifts and delay spreads, where traditional orthogonalization methods become ineffective. Compared to commonly used sequences such as Gold and Zadoff-Chu (ZC), BjÃ¶rck sequences offer improved ambiguity function behavior, nearly ideal autocorrelation, greater resilience to interference, and accurate delay estimation in high Doppler environments. We further propose a novel sequence construction method to extend BjÃ¶rck sequences to non-prime lengths while minimizing cyclic autocorrelation. Focusing on LEO-based non-terrestrial network (NTN) localization, we evaluate positioning accuracy under various interference conditions, comparing the performance of BjÃ¶rck sequences against Gold sequences, which are traditionally used for PRS generation. While BjÃ¶rck sequences demonstrate strong performance in Doppler-rich environments, we identify an inherent Doppler-dependent behavior that may lead to sequence misidentification. To mitigate this, we propose two strategies: 1) leveraging the availability of a coarse Doppler estimate and 2) employing sequence subset selection to ensure sufficient separation between sequences to account for maximum Doppler uncertainty. Finally, we present scalable sequence reuse strategies for large LEO constellations.

Paper number 33:
Title: Bi-Level optimization for parameter estimation of differential equations using interpolation
Authors: Siddharth Prabhu, Srinivas Rangarajan, Mayuresh Kothare
Abstract: Inverse problem or parameter estimation of ordinary differential equations is a process of obtaining the best parameters using experimental measurements of the states. Single (Multiple)-shooting is a type of sequential optimization method that minimizes the error in the measured and numerically integrated states. However, this requires computing sensitivities i.e. the derivatives of states with respect to the parameters over the numerical integrator, which can get computationally expensive. To address this challenge, many interpolation-based approaches have been proposed to either reduce the computational cost of sensitivity calculations or eliminate their need. In this paper, we use a bi-level optimization framework that leverages interpolation and exploits the structure of the differential equation to solve an inner convex optimization problem. We apply this method to two different problem formulations. First, parameter estimation for differential equations, and delayed differential equations, where the model structure is known but the parameters are unknown. Second, model discovery problems, where both the model structure and parameters are unknown.

Paper number 34:
Title: Quantifying and Reducing Speaker Heterogeneity within the Common Voice Corpus for Phonetic Analysis
Authors: Miao Zhang, Aref Farhadipour, Annie Baker, Jiachen Ma, Bogdan Pricop, Eleanor Chodroff
Abstract: With its crosslinguistic and cross-speaker diversity, the Mozilla Common Voice Corpus (CV) has been a valuable resource for multilingual speech technology and holds tremendous potential for research in crosslinguistic phonetics and speech sciences. Properly accounting for speaker variation is, however, key to the theoretical and statistical bases of speech research. While CV provides a client ID as an approximation to a speaker ID, multiple speakers can contribute under the same ID. This study aims to quantify and reduce heterogeneity in the client ID for a better approximation of a true, though still anonymous speaker ID. Using ResNet-based voice embeddings, we obtained a similarity score among recordings with the same client ID, then implemented a speaker discrimination task to identify an optimal threshold for reducing perceived speaker heterogeneity. These results have major downstream applications for phonetic analysis and the development of speaker-based speech technology.

Paper number 35:
Title: IMPACT: Iterative Mask-based Parallel Decoding for Text-to-Audio Generation with Diffusion Modeling
Authors: Kuan-Po Huang, Shu-wen Yang, Huy Phan, Bo-Ru Lu, Byeonggeun Kim, Sashank Macha, Qingming Tang, Shalini Ghosh, Hung-yi Lee, Chieh-Chi Kao, Chao Wang
Abstract: Text-to-audio generation synthesizes realistic sounds or music given a natural language prompt. Diffusion-based frameworks, including the Tango and the AudioLDM series, represent the state-of-the-art in text-to-audio generation. Despite achieving high audio fidelity, they incur significant inference latency due to the slow diffusion sampling process. MAGNET, a mask-based model operating on discrete tokens, addresses slow inference through iterative mask-based parallel decoding. However, its audio quality still lags behind that of diffusion-based models. In this work, we introduce IMPACT, a text-to-audio generation framework that achieves high performance in audio quality and fidelity while ensuring fast inference. IMPACT utilizes iterative mask-based parallel decoding in a continuous latent space powered by diffusion modeling. This approach eliminates the fidelity constraints of discrete tokens while maintaining competitive inference speed. Results on AudioCaps demonstrate that IMPACT achieves state-of-the-art performance on key metrics including FrÃ©chet Distance (FD) and FrÃ©chet Audio Distance (FAD) while significantly reducing latency compared to prior models. The project website is available at this https URL.

Paper number 36:
Title: CLAP-ART: Automated Audio Captioning with Semantic-rich Audio Representation Tokenizer
Authors: Daiki Takeuchi, Binh Thien Nguyen, Masahiro Yasuda, Yasunori Ohishi, Daisuke Niizumi, Noboru Harada
Abstract: Automated Audio Captioning (AAC) aims to describe the semantic contexts of general sounds, including acoustic events and scenes, by leveraging effective acoustic features. To enhance performance, an AAC method, EnCLAP, employed discrete tokens from EnCodec as an effective input for fine-tuning a language model BART. However, EnCodec is designed to reconstruct waveforms rather than capture the semantic contexts of general sounds, which AAC should describe. To address this issue, we propose CLAP-ART, an AAC method that utilizes ``semantic-rich and discrete'' tokens as input. CLAP-ART computes semantic-rich discrete tokens from pre-trained audio representations through vector quantization. We experimentally confirmed that CLAP-ART outperforms baseline EnCLAP on two AAC benchmarks, indicating that semantic-rich discrete tokens derived from semantically rich AR are beneficial for AAC.

Paper number 37:
Title: Conceal Truth while Show Fake: T/F Frequency Multiplexing based Anti-Intercepting Transmission
Authors: Zhisheng Yin, Nan Cheng, Tom H. Luan, Mingjie Wang, Dongbo Li, Yiliang Liu, Changle Li
Abstract: In wireless communication adversarial scenarios, signals are easily intercepted by non-cooperative parties, exposing the transmission of confidential information. This paper proposes a true-and-false (T/F) frequency multiplexing based anti-intercepting transmission scheme capable of concealing truth while showing fake (CTSF), integrating both offensive and defensive strategies. Specifically, through multi-source cooperation, true and false signals are transmitted over multiple frequency bands using non-orthogonal frequency division multiplexing. The decoy signals are used to deceive non-cooperative eavesdropper, while the true signals are hidden to counter interception threats. Definitions for the interception and deception probabilities are provided, and the mechanism of CTSF is discussed. To improve the secrecy performance of true signals while ensuring decoy signals achieve their deceptive purpose, we model the problem as maximizing the sum secrecy rate of true signals, with constraint on the decoy effect. Furthermore, we propose a bi-stage alternating dual-domain optimization approach for joint optimization of both power allocation and correlation coefficients among multiple sources, and a Newton's method is proposed for fitting the T/F frequency multiplexing factor. In addition, simulation results verify the efficiency of anti-intercepting performance of our proposed CTSF scheme.

Paper number 38:
Title: HASRD: Hierarchical Acoustic and Semantic Representation Disentanglement
Authors: Amir Hussein, Sameer Khurana, Gordon Wichern, Francois G. Germain, Jonathan Le Roux
Abstract: Effective speech representations for spoken language models must balance semantic relevance with acoustic fidelity for high-quality reconstruction. However, existing approaches struggle to achieve both simultaneously. To address this, we introduce Hierarchical Acoustic and Semantic Representation Disentanglement (HASRD, pronounced `hazard'), a framework that factorizes self-supervised learning representations into discrete semantic and acoustic tokens. HASRD assigns the semantic representation to the first codebook, while encoding acoustic residuals in subsequent codebooks. This preserves ASR performance while achieving high-quality reconstruction. Additionally, we enhance HASRD's encoder efficiency, improving ASR performance without compromising reconstruction quality. Compared to SpeechTokenizer, HASRD achieves a 44% relative WER improvement, superior reconstruction quality, and 2x lower bitrate, demonstrating its effectiveness in disentangling acoustic and semantic information.

Paper number 39:
Title: Interpretable Spatio-Temporal Features Extraction based Industrial Process Modeling and Monitoring by Soft Sensor
Authors: Qianchao Wang, Peng Sha, Leena Heistrene, Yuxuan Ding, Yaping Du
Abstract: Data-driven soft sensors have been widely applied in complex industrial processes. However, the interpretable spatio-temporal features extraction by soft sensors remains a challenge. In this light, this work introduces a novel method termed spatio-temporal consistent and interpretable model (STCIM). First, temporal and spatial features are captured and aligned by a far topological spatio-temporal consistency extraction block. Then, the features are mapped into an interpretable latent space for further prediction by explicitly giving physical meanings to latent variables. The efficacy of the proposed STCIM is demonstrated through the modeling of two generated datasets and a real-life dataset of coal-fired power plants. The corresponding experiments show: 1) The generalization of STCIM outperforms other methods, especially in different operation situations. 2) The far topological spatio-temporal consistency is vital for feature alignment. 3) The hyper-parameters of physics-informed interpretable latent space loss decide the performance of STCIM.

Paper number 40:
Title: Leveraging AM and FM Rhythm Spectrograms for Dementia Classification and Assessment
Authors: Parismita Gogoi, Vishwanath Pratap Singh, Seema Khadirnaikar, Soma Siddhartha, Sishir Kalita, Jagabandhu Mishra, Md Sahidullah, Priyankoo Sarmah, S. R. M. Prasanna
Abstract: This study explores the potential of Rhythm Formant Analysis (RFA) to capture long-term temporal modulations in dementia speech. Specifically, we introduce RFA-derived rhythm spectrograms as novel features for dementia classification and regression tasks. We propose two methodologies: (1) handcrafted features derived from rhythm spectrograms, and (2) a data-driven fusion approach, integrating proposed RFA-derived rhythm spectrograms with vision transformer (ViT) for acoustic representations along with BERT-based linguistic embeddings. We compare these with existing features. Notably, our handcrafted features outperform eGeMAPs with a relative improvement of $14.2\%$ in classification accuracy and comparable performance in the regression task. The fusion approach also shows improvement, with RFA spectrograms surpassing Mel spectrograms in classification by around a relative improvement of $13.1\%$ and a comparable regression score with the baselines.

Paper number 41:
Title: Near-Field Multiuser Localization Based on Extremely Large Antenna Array with Limited RF Chains
Authors: Boyu Teng, Xiaojun Yuan, Rui Wang, Ying-Chang Liang
Abstract: Extremely large antenna array (ELAA) not only effectively enhances system communication performance but also improves the sensing capabilities of communication systems, making it one of the key enabling technologies in 6G wireless networks. This paper investigates the multiuser localization problem in an uplink Multiple Input Multiple Output (MIMO) system, where the base station (BS) is equipped with an ELAA to receive signals from multiple single-antenna users. We exploit analog beamforming to reduce the number of radio frequency (RF) chains. We first develop a comprehensive near-field ELAA channel model that accounts for the antenna radiation pattern and free space path loss. Due to the large aperture of the ELAA, the angular resolution of the array is high, which improves user localization accuracy. However, it also makes the user localization problem highly non-convex, posing significant challenges when the number of RF chains is limited. To address this issue, we use an array partitioning strategy to divide the ELAA channel into multiple subarray channels and utilize the geometric constraints between user locations and subarrays for probabilistic modeling. To fully exploit these geometric constraints, we propose the array partitioning-based location estimation with limited measurements (APLE-LM) algorithm based on the message passing principle to achieve multiuser localization. We derive the Bayesian Cramer-Rao Bound (BCRB) as the theoretical performance lower bound for our formulated near-field multiuser localization problem. Extensive simulations under various parameter configurations validate the proposed APLE-LM algorithm. The results demonstrate that APLE-LM achieves superior localization accuracy compared to baseline algorithms and approaches the BCRB at high signal-to-noise ratio (SNR).

Paper number 42:
Title: HMPC-assisted Adversarial Inverse Reinforcement Learning for Smart Home Energy Management
Authors: Jiadong He, Liang Yu, Zhiqiang Chen, Dawei Qiu, Dong Yue, Goran Strbac, Meng Zhang, Yujian Ye, Yi Wang
Abstract: This letter proposes an Adversarial Inverse Reinforcement Learning (AIRL)-based energy management method for a smart home, which incorporates an implicit thermal dynamics model. In the proposed method, historical optimal decisions are first generated using a neural network-assisted Hierarchical Model Predictive Control (HMPC) framework. These decisions are then used as expert demonstrations in the AIRL module, which aims to train a discriminator to distinguish expert demonstrations from transitions generated by a reinforcement learning agent policy, while simultaneously updating the agent policy that can produce transitions to confuse the discriminator. The proposed HMPC-AIRL method eliminates the need for explicit thermal dynamics models, prior or predictive knowledge of uncertain parameters, or manually designed reward functions. Simulation results based on real-world traces demonstrate the effectiveness and data efficiency of the proposed method.

Paper number 43:
Title: Training Beam Design for Channel Estimation in Hybrid mmWave MIMO Systems
Authors: Xiaochun Ge, Wenqian Shen, Chengwen Xing, Lian Zhao, Jianping An
Abstract: Training beam design for channel estimation with infinite-resolution and low-resolution phase shifters (PSs) in hybrid analog-digital milimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems is considered in this paper. By exploiting the sparsity of mmWave channels, the optimization of the sensing matrices (corresponding to training beams) is formulated according to the compressive sensing (CS) theory. Under the condition of infinite-resolution PSs, we propose relevant algorithms to construct the sensing matrix, where the theory of convex optimization and the gradient descent in Riemannian manifold is used to design the digital and analog part, respectively. Furthermore, a block-wise alternating hybrid analog-digital algorithm is proposed to tackle the design of training beams with low-resolution PSs, where the performance degeneration caused by non-convex constant modulus and discrete phase constraints is effectively compensated to some extent thanks to the iterations among blocks. Finally, the orthogonal matching pursuit (OMP) based estimator is adopted for achieving an effective recovery of the sparse mmWave channel. Simulation results demonstrate the performance advantages of proposed algorithms compared with some existing schemes.

Paper number 44:
Title: IAE Optimized PID Tuning with Phase Margin and Crossover Frequency Constraints
Authors: Senol Gulgonul
Abstract: This paper presents PMwc-Tune, a novel PID tuning method that uniquely combines frequency-domain robustness constraints with time-domain performance optimization through constrained nonlinear programming. The key contribution is a unified formulation that simultaneously enforces phase margin and crossover frequency requirements (via nonlinear equality constraints) while minimizing the Integral Absolute Error (IAE) of the closed-loop response. The algorithm employs Sequential Quadratic Programming (SQP) to solve this constrained optimization problem, guaranteeing specification attainment within numerical tolerances while optimizing transient performance. Numerical validation on benchmark systems demonstrates precise convergence to design targets (phase margin and crossover frequency errors <1%) with a 4.6% IAE reduction compared to MATLAB's pidtune. The open-source implementation provides both methodological transparency and practical design flexibility, enabling PID controllers that rigorously balance frequency-domain robustness and time-domain performance.

Paper number 45:
Title: Crowdsourcing MUSHRA Tests in the Age of Generative Speech Technologies: A Comparative Analysis of Subjective and Objective Testing Methods
Authors: Laura Lechler, Chamran Moradi, Ivana Balic
Abstract: The MUSHRA framework is widely used for detecting subtle audio quality differences but traditionally relies on expert listeners in controlled environments, making it costly and impractical for model development. As a result, objective metrics are often used during development, with expert evaluations conducted later. While effective for traditional DSP codecs, these metrics often fail to reliably evaluate generative models. This paper proposes adaptations for conducting MUSHRA tests with non-expert, crowdsourced listeners, focusing on generative speech codecs. We validate our approach by comparing results from MTurk and Prolific crowdsourcing platforms with expert listener data, assessing test-retest reliability and alignment. Additionally, we evaluate six objective metrics, showing that traditional metrics undervalue generative models. Our findings reveal platform-specific biases and emphasize codec-aware metrics, offering guidance for scalable perceptual testing of speech codecs.

Paper number 46:
Title: Near-Field Directional Modulation for RIS-Aided Movable Antenna MIMO Systems with Hardware Impairments
Authors: Maolin Li, Feng Shu, Riqing Chen, Cunhua Pan, Yongpeng Wu
Abstract: Movable antennas (MAs) are a promising technology to achieve a significant enhancement in rate for future wireless networks. The pioneering investigation on near-field directional modulation design for a reconfigurable intelligent surface (RIS)-assisted MA system is presented, with the base station equipped with a MA array. To maximize the secrecy sum rate (Max-SSR) with hardware impairments (HWIs) and imperfect channel state information (CSI), which involves a joint optimization of beamforming vectors for confidential messages and artificial noise (AN), power allocation factors, phase shift matrices, MA positions, and receive beamforming vectors. Firstly, the transmit beamforming vectors and phase shift matrices are iteratively optimized, leveraging leakage theory and phase alignment techniques. Then, two novel algorithms for discrete MA positioning are proposed, respectively, employing uniform and compressed sensing (CS)-based non-uniform grouping strategies. Subsequently, the AN is considered and designed as the additional energy required for zero-space projection, and the receive beamforming vector is derived using the minimum mean square error (MMSE) method. The proposed algorithms have low computational complexity. Simulation results demonstrate the effectiveness of the proposed algorithms. Under HWIs and imperfect CSI, the proposed algorithm can achieve a 28\% enhancement in SSR performance while reducing the number of antennas by 37.5\% compared to traditional fixed-position antenna (FPA) systems.

Paper number 47:
Title: Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching
Authors: Jialong Zuo, Shengpeng Ji, Minghui Fang, Mingze Li, Ziyue Jiang, Xize Cheng, Xiaoda Yang, Chen Feiyang, Xinyu Duan, Zhou Zhao
Abstract: Zero-Shot Voice Conversion (VC) aims to transform the source speaker's timbre into an arbitrary unseen one while retaining speech content. Most prior work focuses on preserving the source's prosody, while fine-grained timbre information may leak through prosody, and transferring target prosody to synthesized speech is rarely studied. In light of this, we propose R-VC, a rhythm-controllable and efficient zero-shot voice conversion model. R-VC employs data perturbation techniques and discretize source speech into Hubert content tokens, eliminating much content-irrelevant information. By leveraging a Mask Generative Transformer for in-context duration modeling, our model adapts the linguistic content duration to the desired target speaking style, facilitating the transfer of the target speaker's rhythm. Furthermore, R-VC introduces a powerful Diffusion Transformer (DiT) with shortcut flow matching during training, conditioning the network not only on the current noise level but also on the desired step size, enabling high timbre similarity and quality speech generation in fewer sampling steps, even in just two, thus minimizing latency. Experimental results show that R-VC achieves comparable speaker similarity to state-of-the-art VC methods with a smaller dataset, and surpasses them in terms of speech naturalness, intelligibility and style transfer performance.

Paper number 48:
Title: Self-Supervised-ISAR-Net Enables Fast Sparse ISAR Imaging
Authors: Ziwen Wang, Jianping wang, Pucheng Li, Yifan Wu, Zegang Ding
Abstract: Numerous sparse inverse synthetic aperture radar (ISAR) imaging methods based on unfolded neural networks have been developed for high-quality image reconstruction with sparse measurements. However, their training typically requires paired ISAR images and echoes, which are often difficult to obtain. Meanwhile, one property can be observed that for a certain sparse measurement configuration of ISAR, when a target is rotated around its center of mass, only the image of the target undergoes the corresponding rotation after ISAR imaging, while the grating lobes do not follow this rotation and are solely determined by the sparse-sampling pattern. This property is mathematically termed as the equivariant property. Taking advantage of this property, an unfolded neural network for sparse ISAR imaging with self-supervised learning, named SS-ISAR-Net is proposed. It effectively mitigates grating lobes caused by sparse radar echo, allowing high-quality training to be achieved using only sparse radar echo data. The superiority of the proposed SS-ISAR-Net, compared to existing methods, is verified through experiments with both synthetic and real-world measurement data.

Paper number 49:
Title: PseudoVC: Improving One-shot Voice Conversion with Pseudo Paired Data
Authors: Songjun Cao, Qinghua Wu, Jie Chen, Jin Li, Long Ma
Abstract: As parallel training data is scarce for one-shot voice conversion (VC) tasks, waveform reconstruction is typically performed by various VC systems. A typical one-shot VC system comprises a content encoder and a speaker encoder. However, two types of mismatches arise: one for the inputs to the content encoder during training and inference, and another for the inputs to the speaker encoder. To address these mismatches, we propose a novel VC training method called \textit{PseudoVC} in this paper. First, we introduce an innovative information perturbation approach named \textit{Pseudo Conversion} to tackle the first mismatch problem. This approach leverages pretrained VC models to convert the source utterance into a perturbed utterance, which is fed into the content encoder during training. Second, we propose an approach termed \textit{Speaker Sampling} to resolve the second mismatch problem, which will substitute the input to the speaker encoder by another utterance from the same speaker during training. Experimental results demonstrate that our proposed \textit{Pseudo Conversion} outperforms previous information perturbation methods, and the overall \textit{PseudoVC} method surpasses publicly available VC models. Audio examples are available.

Paper number 50:
Title: A Group-Wise Narrow Beam Design for Uplink Channel Estimation in Hybrid Beamforming Systems
Authors: Yufan Zhou, Yongbo Xiao, An Liu
Abstract: In this paper, we consider uplink channel estimation for massive multi-input multi-output (MIMO) systems with partially connected hybrid beamforming (PC-HBF) structures. Existing beam design and channel estimation schemes are usually based on ideal assumptions and require transmitting pilots across multiple timeslots, making them unsuitable for practical PC-HBF systems. To overcome these drawbacks, we propose a novel beam design and a corresponding channel estimation algorithm to achieve accurate and real-time uplink channel estimation. Firstly, we introduce a group-wise narrow beam design in the vertical dimension to suppress interference from undesired angular components and improve vertical angle estimation accuracy,which divides the columns of the uniform planar array (UPA)into groups and the vertical angle interval into this http URL this way, each group is assigned with a narrow beam to cover one vertical angle sub-interval, and the set of narrow beams is designed based on the filter design theory. Secondly, we optimize the antenna grouping pattern using the Estimation of Distribution Algorithm (EDA), balancing interference suppression and resolution capability in the horizontal dimension, leading to a better horizontal angle estimation performance. Finally, we design a low-complexity group-wise subspace constrained variational Bayesian inference (GW-SC-VBI) algorithm to fully take advantage of the proposed beam design to achieve both low-complexity and high-accurate channel estimation. Simulation results demonstrate that the proposed scheme achieves notable performance gains over baseline methods.

Paper number 51:
Title: Chaotic Noncoherent SWIPT in Multi-Functional RIS-Aided Systems
Authors: Priyadarshi Mukherjee, Constantinos Psomas, Himal A. Suraweera, Ioannis Krikidis
Abstract: In this letter, we investigate the design of chaotic signal-based transmit waveforms in a multi-functional reconfigurable intelligent surface (MF-RIS)-aided set-up for simultaneous wireless information and power transfer. We propose a differential chaos shift keying-based MF-RIS-aided set-up, where the MF-RIS is partitioned into three non-overlapping surfaces. The elements of the first sub-surface perform energy harvesting (EH), which in turn, provide the required power to the other two sub-surfaces responsible for transmission and reflection of the incident signal. By considering a frequency selective scenario and a realistic EH model, we characterize the chaotic MF-RIS-aided system in terms of its EH performance and the associated bit error rate. Thereafter, we characterize the harvested energy-bit error rate trade-off and derive a lower bound on the number of elements required to operate in the EH mode. Accordingly, we propose novel transmit waveform designs to demonstrate the importance of the choice of appropriate system parameters in the context of achieving self-sustainability.

Paper number 52:
Title: Scalable Association of Users in CF-mMIMO: A Synergy of Communication, Sensing, and JCAS
Authors: Ahmed Naeem, Anastassia Gharib, El Mehdi Amhoud, HÃ¼seyin Arslan
Abstract: Cell-free massive multiple-input multiple-output (CF-mMIMO) is a key enabler for the sixth generation (6G) networks, offering unprecedented spectral efficiency and ubiquitous coverage. In CF-mMIMO systems, the association of user equipments (UEs) to access points (APs) is a critical challenge, as it directly impacts network scalability, interference management, and overall system performance. Conventional association methods primarily focus on optimizing communication performance. However, with the emergence of sensing and joint communication and sensing (JCAS) requirements, conventional approaches become insufficient. To address this challenge, we propose a scalable user association (SUA) scheme for CF-mMIMO networks, considering heterogeneous UE requirements. Designed to enhance the performance of both sensing and communication, the proposed SUA scheme aims to ensure network scalability. This is achieved by dynamically assigning APs to UEs based on their specific service requirements (communication, sensing, or JCAS), while considering link quality, interference mitigation, and network-related constraints. Specifically, the proposed SUA scheme employs AP masking, link prioritization, and an optimization-based association mechanism to select the most suitable APs for each UE. Simulations show that, compared to conventional CF-mMIMO methods, the proposed SUA scheme significantly reduces interference and computational runtime, while improving the symbol error rate for communication and the probability of detection for sensing.

Paper number 53:
Title: TRUST - Transformer-Driven U-Net for Sparse Target Recovery
Authors: Di An, Dylan Poppert, Jiayue Li, Mark Foster, Trac D. Tran
Abstract: In the context of inverse problems $\bf y = Ax$, sparse recovery offers a powerful paradigm shift by enabling the stable solution of ill-posed or underdetermined systems through the exploitation of structure, particularly sparsity. Sparse regularization techniques via $\ell_0$- or $\ell_1$-norm minimization encourage solutions $\bf x$ that are both consistent with observations $\bf y$ and parsimonious in representation, often yielding physically meaningful interpretations. In this work, we address the classical inverse problem under the challenging condition where the sensing operator $\bf A$ is unknown and only a limited set of observation-target pairs $\{ \bf x,\bf y \}$ is available. We propose a novel neural architecture, TRUST, that integrates the attention mechanism of Transformers with the decoder pathway of a UNet to simultaneously learn the sensing operator and reconstruct the sparse signal. The TRUST model incorporates a Transformer-based encoding branch to capture long-range dependencies and estimate sparse support, which then guides a U-Net-style decoder to refine reconstruction through multiscale feature integration. The skip connections between the transformer stages and the decoder not only enhance image quality but also enable the decoder to access image features at different levels of abstraction. This hybrid architecture enables more accurate and robust recovery by combining global context with local details. Experimental results demonstrate that TRUST significantly outperforms traditional sparse recovery methods and standalone U-Net models, achieving superior performance in SSIM and PSNR metrics while effectively suppressing hallucination artifacts that commonly plague deep learning-based inverse solvers.

Paper number 54:
Title: Analysis of Local Methane Emissions Using Near-Simultaneous Multi-Satellite Observations: Insights from Landfills and Oil-Gas Facilities
Authors: Alvise Ferrari, Giovanni Laneve, Raul Alejandro Carvajal Tellez, Valerio Pampanoni, Simone Saquella, Rocchina Guarini
Abstract: Methane (CH4) is a potent greenhouse gas, and its detection and quantification are crucial for mitigating the greenhouse effect. This study presents a comparative analysis of methane emissions observed using near-simultaneous observations from hyperspectral imaging spectrometers hosted aboard different satellite platforms (PRISMA, EnMAP, EMIT and GHGSat). Methane emissions from oil and gas facilities and landfills are analyzed to evaluate the consistency and precision of the sensors and temporal variability of the source. Landfills, characterized by diffuse and stable emissions, and dynamic oil and gas facilities, subject to operational variability, provide contrasting use cases for emission monitoring. Emission rates are quantified using the Integrated Mass Enhancement (IME) model and validated across satellites with overlapping acquisitions. This study highlights the advantages and limitations of each satellite system, emphasizing the critical role of multi-sensor integration in bridging temporal and spatial observation gaps. Insights derived here aim to enhance global methane monitoring frameworks and guide future satellite design for improved emission quantification.

Paper number 55:
Title: PARROT: Synergizing Mamba and Attention-based SSL Pre-Trained Models via Parallel Branch Hadamard Optimal Transport for Speech Emotion Recognition
Authors: Orchid Chetia Phukan, Mohd Mujtaba Akhtar, Girish, Swarup Ranjan Behera, Jaya Sai Kiran Patibandla, Arun Balaji Buduru, Rajesh Sharma
Abstract: The emergence of Mamba as an alternative to attention-based architectures has led to the development of Mamba-based self-supervised learning (SSL) pre-trained models (PTMs) for speech and audio processing. Recent studies suggest that these models achieve comparable or superior performance to state-of-the-art (SOTA) attention-based PTMs for speech emotion recognition (SER). Motivated by prior work demonstrating the benefits of PTM fusion across different speech processing tasks, we hypothesize that leveraging the complementary strengths of Mamba-based and attention-based PTMs will enhance SER performance beyond the fusion of homogenous attention-based PTMs. To this end, we introduce a novel framework, PARROT that integrates parallel branch fusion with Optimal Transport and Hadamard Product. Our approach achieves SOTA results against individual PTMs, homogeneous PTMs fusion, and baseline fusion techniques, thus, highlighting the potential of heterogeneous PTM fusion for SER.

Paper number 56:
Title: Towards Fusion of Neural Audio Codec-based Representations with Spectral for Heart Murmur Classification via Bandit-based Cross-Attention Mechanism
Authors: Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Priyabrata Mallick, Santanu Roy, Arun Balaji Buduru, Rajesh Sharma
Abstract: In this study, we focus on heart murmur classification (HMC) and hypothesize that combining neural audio codec representations (NACRs) such as EnCodec with spectral features (SFs), such as MFCC, will yield superior performance. We believe such fusion will trigger their complementary behavior as NACRs excel at capturing fine-grained acoustic patterns such as rhythm changes, spectral features focus on frequency-domain properties such as harmonic structure, spectral energy distribution crucial for analyzing the complex of heart sounds. To this end, we propose, BAOMI, a novel framework banking on novel bandit-based cross-attention mechanism for effective fusion. Here, a agent provides more weightage to most important heads in multi-head cross-attention mechanism and helps in mitigating the noise. With BAOMI, we report the topmost performance in comparison to individual NACRs, SFs, and baseline fusion techniques and setting new state-of-the-art.

Paper number 57:
Title: Wasserstein Distributionally Robust Adaptive Beamforming
Authors: Kiarash Hassas Irani, Sergiy A. Vorobyov, Yongwei Huang
Abstract: Distributionally robust optimization (DRO)-based robust adaptive beamforming (RAB) enables enhanced robustness against model uncertainties, such as steering vector mismatches and interference-plus-noise covariance matrix estimation errors. Existing DRO-based RAB methods primarily rely on uncertainty sets characterized by the first- and second-order moments. In this work, we propose a novel Wasserstein DRO-based beamformer, using the worst-case signal-to-interference-plus-noise ratio maximization formulation. The proposed method leverages the Wasserstein metric to define uncertainty sets, offering a data-driven characterization of uncertainty. We show that the choice of the Wasserstein cost function plays a crucial role in shaping the resulting formulation, with norm-based and Mahalanobis-like quadratic costs recovering classical norm-constrained and ellipsoidal robust beamforming models, respectively. This insight highlights the Wasserstein DRO framework as a unifying approach, bridging deterministic and distributionally robust beamforming methodologies.

Paper number 58:
Title: Source Tracing of Synthetic Speech Systems Through Paralinguistic Pre-Trained Representations
Authors: Girish, Mohd Mujtaba Akhtar, Orchid Chetia Phukan, Drishti Singh, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma
Abstract: In this work, we focus on source tracing of synthetic speech generation systems (STSGS). Each source embeds distinctive paralinguistic features--such as pitch, tone, rhythm, and intonation--into their synthesized speech, reflecting the underlying design of the generation model. While previous research has explored representations from speech pre-trained models (SPTMs), the use of representations from SPTM pre-trained for paralinguistic speech processing, which excel in paralinguistic tasks like synthetic speech detection, speech emotion recognition has not been investigated for STSGS. We hypothesize that representations from paralinguistic SPTM will be more effective due to its ability to capture source-specific paralinguistic cues attributing to its paralinguistic pre-training. Our comparative study of representations from various SOTA SPTMs, including paralinguistic, monolingual, multilingual, and speaker recognition, validates this hypothesis. Furthermore, we explore fusion of representations and propose TRIO, a novel framework that fuses SPTMs using a gated mechanism for adaptive weighting, followed by canonical correlation loss for inter-representation alignment and self-attention for feature refinement. By fusing TRILLsson (Paralinguistic SPTM) and x-vector (Speaker recognition SPTM), TRIO outperforms individual SPTMs, baseline fusion methods, and sets new SOTA for STSGS in comparison to previous works.

Paper number 59:
Title: Distributed perception of social power in influence networks with stubborn individuals
Authors: Ye Tian, Yu Kawano, Wei Zhang, Kenji Kashima
Abstract: Social power quantifies the ability of individuals to influence others and plays a central role in social influence networks. Yet computing social power typically requires global knowledge and significant computational or storage capability, especially in large-scale networks with stubborn individuals. This paper develops distributed algorithms for social power perception in groups with stubborn individuals. We propose two dynamical models for distributed perception of social power based on the Friedkin-Johnsen (FJ) opinion dynamics: one without and one with reflected appraisals. In both scenarios, our perception mechanism begins with independent initial perceptions and relies primarily on local information: each individual only needs to know its neighbors' stubbornness or self-appraisals, the influence weights they accord and the group size. We provide rigorous dynamical system analysis to characterize the properties of equilibria, invariant sets and convergence. Conditions under which individuals' perceived social power converges to the actual social power are established. The proposed perception mechanism demonstrates strong robustness to reflected appraisals, irrational perceptions, and timescale variations. Numerical examples are provided to illustrate our results.

Paper number 60:
Title: GigaAM: Efficient Self-Supervised Learner for Speech Recognition
Authors: Aleksandr Kutsakov, Alexandr Maximenko, Georgii Gospodinov, Pavel Bogomolov, Fyodor Minkin
Abstract: Self-Supervised Learning (SSL) has demonstrated strong performance in speech processing, particularly in automatic speech recognition. In this paper, we explore an SSL pretraining framework that leverages masked language modeling with targets derived from a speech recognition model. We also present chunkwise attention with dynamic chunk size sampling during pretraining to enable both full-context and streaming fine-tuning. Our experiments examine scaling with respect to model size and the amount of data. Using our method, we train the GigaAM family of models, including a state-of-the-art model for Russian speech recognition that outperforms Whisper-large-v3 by 50%. We have released our foundation and ASR models, along with the inference code, under the MIT license as open-source resources to the research community. Available at this https URL.

Paper number 61:
Title: Development of Hardware-in-Loop Framework for Satellite Communication Self-Healing Networks
Authors: Sambrama, Venkata Srirama Rohit Kantheti, Liang C Chu, Erik Blasch, Shih-Chun Lin
Abstract: The use of Low Earth Orbit (LEO) satellites in the next generation (Next-G) communication systems has been gaining traction over the last few years due to their potential for providing global connectivity with low latency. Since they are the closest to the earth they come with their own set of disadvantages including high vulnerability to jamming and interference. To address these issues, this paper introduces a resilient, self-healing network designed to optimize signal quality under dynamic interference and adversarial conditions. The network leverages inter-satellite communication and an intelligent algorithm selection process, incorporating combining techniques like distributed-Maximal Ratio Combining (d-MRC), distributed-Linear Minimum Mean Squared Error Estimation (d-LMMSE), and Selection Combining (SC). These algorithms are selected to improve performance by adapting to changing network conditions. To evaluate the effectiveness of the proposed solution, we develop a software-defined radio (SDR)-based hardware testbed and perform detailed performance evaluations. Additionally, we present results from field tests conducted on the AERPAW testbed, which validate the proposed combining solutions in real-world scenarios. The results show that our approach makes LEO satellite networks more reliable and better able to handle interference, making them suitable for critical communications.

Paper number 62:
Title: Flexible Mixed Precision Quantization for Learned Image Compression
Authors: Md Adnan Faisal Hossain, Zhihao Duan, Fengqing Zhu
Abstract: Despite its improvements in coding performance compared to traditional codecs, Learned Image Compression (LIC) suffers from large computational costs for storage and deployment. Model quantization offers an effective solution to reduce the computational complexity of LIC models. However, most existing works perform fixed-precision quantization which suffers from sub-optimal utilization of resources due to the varying sensitivity to quantization of different layers of a neural network. In this paper, we propose a Flexible Mixed Precision Quantization (FMPQ) method that assigns different bit-widths to different layers of the quantized network using the fractional change in rate-distortion loss as the bit-assignment criterion. We also introduce an adaptive search algorithm which reduces the time-complexity of searching for the desired distribution of quantization bit-widths given a fixed model size. Evaluation of our method shows improved BD-Rate performance under similar model size constraints compared to other works on quantization of LIC models. We have made the source code available at this http URL.

Paper number 63:
Title: React to Surprises: Stable-by-Design Neural Feedback Control and the Youla-REN
Authors: Nicholas H. Barbara, Ruigang Wang, Alexandre Megretski, Ian R. Manchester
Abstract: We study parameterizations of stabilizing nonlinear policies for learning-based control. We propose a structure based on a nonlinear version of the Youla-KuÄera parameterization combined with robust neural networks such as the recurrent equilibrium network (REN). The resulting parameterizations are unconstrained, and hence can be searched over with first-order optimization methods, while always ensuring closed-loop stability by construction. We study the combination of (a) nonlinear dynamics, (b) partial observation, and (c) incremental closed-loop stability requirements (contraction and Lipschitzness). We find that with any two of these three difficulties, a contracting and Lipschitz Youla parameter always leads to contracting and Lipschitz closed loops. However, if all three hold, then incremental stability can be lost with exogenous disturbances. Instead, a weaker condition is maintained, which we call d-tube contraction and Lipschitzness. We further obtain converse results showing that the proposed parameterization covers all contracting and Lipschitz closed loops for certain classes of nonlinear systems. Numerical experiments illustrate the utility of our parameterization when learning controllers with built-in stability certificates for: i) ``economic'' rewards without stabilizing effects; ii) short training horizons; and iii) uncertain systems.

Paper number 64:
Title: Structured Pruning and Quantization for Learned Image Compression
Authors: Md Adnan Faisal Hossain, Fengqing Zhu
Abstract: The high computational costs associated with large deep learning models significantly hinder their practical deployment. Model pruning has been widely explored in deep learning literature to reduce their computational burden, but its application has been largely limited to computer vision tasks such as image classification and object detection. In this work, we propose a structured pruning method targeted for Learned Image Compression (LIC) models that aims to reduce the computational costs associated with image compression while maintaining the rate-distortion performance. We employ a Neural Architecture Search (NAS) method based on the rate-distortion loss for computing the pruning ratio for each layer of the network. We compare our pruned model with the uncompressed LIC Model with same network architecture and show that it can achieve model size reduction without any BD-Rate performance drop. We further show that our pruning method can be integrated with model quantization to achieve further model compression while maintaining similar BD-Rate performance. We have made the source code available at this http URL.

Paper number 65:
Title: Energy-Efficient Integrated Communication and Computation via Non-Terrestrial Networks with Uncertainty Awareness
Authors: Xiao Tang, Yudan Jiang, Ruonan Zhang, Qinghe Du, Jinxin Liu, Naijin Liu
Abstract: Non-terrestrial network (NTN)-based integrated communication and computation empowers various emerging applications with global coverage. Yet this vision is severely challenged by the energy issue given the limited energy supply of NTN nodes and the energy-consuming nature of communication and computation. In this paper, we investigate the energy-efficient integrated communication and computation for the ground node data through a NTN, incorporating an unmanned aerial vehicle (UAV) and a satellite. We jointly consider ground data offloading to the UAV, edge processing on the UAV, and the forwarding of results from UAV to satellite, where we particularly address the uncertainties of the UAV-satellite links due to the large distance and high dynamics therein. Accordingly, we propose to minimize the weighted energy consumption due to data offloading, UAV computation, UAV transmission, and UAV propulsion, in the presence of angular uncertainties under Gaussian distribution within the UAV-satellite channels. The formulated problem with probabilistic constraints due to uncertainties is converted into a deterministic form by exploiting the Bernstein-type inequality, which is then solved using a block coordinate descent framework with algorithm design. Simulation results are provided to demonstrate the performance superiority of our proposal in terms of energy sustainability, along with the robustness against uncertain non-terrestrial environments.

Paper number 66:
Title: Confidence intervals for forced alignment boundaries using model ensembles
Authors: Matthew C. Kelley
Abstract: Forced alignment is a common tool to align audio with orthographic and phonetic transcriptions. Most forced alignment tools provide only a single estimate of a boundary. The present project introduces a method of deriving confidence intervals for these boundaries using a neural network ensemble technique. Ten different segment classifier neural networks were previously trained, and the alignment process is repeated with each model. The alignment ensemble is then used to place the boundary at the median of the boundaries in the ensemble, and 97.85% confidence intervals are constructed using order statistics. On the Buckeye and TIMIT corpora, the ensemble boundaries show a slight improvement over using just a single model. The confidence intervals are incorporated into Praat TextGrids using a point tier, and they are also output as a table for researchers to analyze separately as diagnostics or to incorporate uncertainty into their analyses.

Paper number 67:
Title: Online Audio-Visual Autoregressive Speaker Extraction
Authors: Zexu Pan, Wupeng Wang, Shengkui Zhao, Chong Zhang, Kun Zhou, Yukun Ma, Bin Ma
Abstract: This paper proposes a novel online audio-visual speaker extraction model. In the streaming regime, most studies optimize the audio network only, leaving the visual frontend less explored. We first propose a lightweight visual frontend based on depth-wise separable convolution. Then, we propose a lightweight autoregressive acoustic encoder to serve as the second cue, to actively explore the information in the separated speech signal from past steps. Scenario-wise, for the first time, we study how the algorithm performs when there is a change in focus of attention, i.e., the target speaker. Experimental results on LRS3 datasets show that our visual frontend performs comparably to the previous state-of-the-art on both SkiM and ConvTasNet audio backbones with only 0.1 million network parameters and 2.1 MACs per second of processing. The autoregressive acoustic encoder provides an additional 0.9 dB gain in terms of SI-SNRi, and its momentum is robust against the change in attention.

Paper number 68:
Title: Rydberg Atomic Quantum MIMO Receivers for The Multi-User Uplink
Authors: Tierui Gong, Chau Yuen, Chong Meng Samson See, MÃ©rouane Debbah, Lajos Hanzo
Abstract: Rydberg atomic quantum receivers (RAQRs) have emerged as a promising solution for evolving wireless receivers from the classical to the quantum domain. To further unleash their great potential in wireless communications, we propose a flexible architecture for Rydberg atomic quantum multiple-input multiple-output (RAQ-MIMO) receivers in the multi-user uplink. Then the corresponding signal model of the RAQ-MIMO system is constructed by paving the way from quantum physics to classical wireless communications. Explicitly, we outline the associated operating principles and transmission flow. We also validate the linearity of our model and its feasible region. Based on our model, we derive closed-form asymptotic formulas for the ergodic achievable rate (EAR) of both the maximum-ratio combining (MRC) and zero-forcing (ZF) receivers operating in uncorrelated fading channels (UFC) and the correlated fading channels (CFC), respectively. Furthermore, we theoretically characterize the EAR difference both between the UFC and CFC scenarios, as well as MRC and ZF schemes. More particularly, we quantify the superiority of RAQ-MIMO receivers over the classical massive MIMO (M-MIMO) receivers, specifying an increase of $\log_{2} \Pi$ of the EAR per user, $\Pi$-fold reduction of the users' transmit power, and $\sqrt[\nu]{\Pi}$-fold increase of the transmission distance, respectively, where $\Pi = \text{ReceiverGainRatio} / \text{ReceiverNoisePowerRatio}$ of the single-sensor receivers and $\nu$ is the path-loss exponent. Our simulation results reveal that, compared to classical M-MIMO receivers, our RAQ-MIMO scheme can either realize $\sim 12$ bits/s/Hz/user ($\sim 8$ bits/s/Hz/user) higher EAR, or $\sim 10000$-fold ($\sim 500$-fold) lower transmit power, or alternatively, $\sim 100$-fold ($\sim 21$-fold) longer distance in free-space transmissions, in the standard quantum limit (photon shot limit).

Paper number 69:
Title: Prediction of the Conditional Probability Densities of Time Interval Extrema for Risk-Sensitive Scheduling
Authors: Buyi Yu, Wenyuan Tang
Abstract: Planning and scheduling activities in the electrical power system, such as the commitment of reserve generation, often involve statistical characterization of peak demand. Extreme Value Analysis (EVA)-based probabilistic assessments of annual peaks are widely adopted by energy regulatory and oversight agencies to determine the likelihood and severity of potential energy shortfalls. Due to the inability of classical EVA to account for peak distributions that change with annual extreme temperatures, popular existing approaches apply EVA on simulated annual peaks created by weather-dependent surrogate models using MontÃ©-Carlo simulations on a per-scenario basis. In higher time resolutions such as day-ahead scheduling, the daily peak demand changes upon various factors besides temperature, MontÃ©-Carlo experiments become intractable, and EVA-based modeling manifests as a methodological vacuum. This article explores uncharted territories and pioneers an unparalleled nonstationary EVA estimator that predicts the probable peaks of high-resolution time intervals and their corresponding conditional probability densities based on calendar information and weather conditions where historical peaks are observed. We present a case study on the determination of day-ahead scheduling capacity and demonstrate that compared to the industry approach, our approach results in a $38\%$ reduction in the yearly total committed capacity while maintaining the given risk requirement.

Paper number 70:
Title: From Turbulence to Tranquility: AI-Driven Low-Altitude Network
Authors: KÃ¼rÅat TekbÄ±yÄ±k, Amir Hossein Fahim Raouf, Ä°smail GÃ¼venÃ§, Mingzhe Chen, GÃ¼neÅ Karabulut Kurt, Antoine Lesage-Landry
Abstract: Low Altitude Economy (LAE) networks own transformative potential in urban mobility, emergency response, and aerial logistics. However, these networks face significant challenges in spectrum management, interference mitigation, and real-time coordination across dynamic and resource-constrained environments. After addressing these challenges, this study explores three core elements for enabling intelligent LAE networks as follows machine learning-based spectrum sensing and coexistence, artificial intelligence (AI)-optimized resource allocation and trajectory planning, and testbed-driven validation and standardization. We highlight how federated and reinforcement learning techniques support decentralized, adaptive decision-making under mobility and energy constraints. In addition, we discuss the role of real-world platforms such as AERPAW in bridging the gap between simulation and deployment and enabling iterative system refinement under realistic conditions. This study aims to provide a forward-looking roadmap toward developing efficient and interoperable AI-driven LAE ecosystems.

Paper number 71:
Title: Enabling Scalable Distributed Beamforming via Networked LEO Satellites Towards 6G
Authors: Yuchen Zhang Seungnyun Kim, Tareq Y. Al-Naffouri
Abstract: In this paper, we propose scalable distributed beamforming schemes over low Earth orbit (LEO) satellite networks that rely solely on statistical channel state information for downlink orthogonal frequency division multiplexing systems. We begin by introducing the system model and presenting a pragmatic yet effective analog beamformer and user-scheduling design. We then derive a closed-form lower bound on the ergodic sum rate, based on the hardening bound, for the digital beamformer design. Next, we formulate a per-satellite power-constrained sum-rate maximization problem, whose centralized solution, obtained via the weighted minimum mean squared error (WMMSE) framework, establishes performance limits and motivates decentralized strategies. We subsequently introduce two decentralized optimization schemes, based on approximating the hardening bound and decentralizing the WMMSE framework, for representative inter-satellite link topologies. In the Ring scheme, satellites update beamformers locally and exchange intermediate parameters sequentially. In the Star scheme, edge satellites update beamformers locally and in parallel, achieving consensus on intermediate parameters at a central satellite using a penalty-dual decomposition framework. Extensive simulations demonstrate that our distributed designs achieve near-centralized performance with superior scalability, substantially outperforming simple closed-form beamformers and single-satellite baselines in sum rate. Additionally, the delay-overhead trade-off between the two topologies is revealed.

Paper number 72:
Title: Captivity-Escape Games as a Means for Safety in Online Motion Generation
Authors: Christopher Bohn, Manuel Hess, SÃ¶ren Hohmann
Abstract: This paper presents a method that addresses the conservatism, computational effort, and limited numerical accuracy of existing frameworks and methods that ensure safety in online model-based motion generation, commonly referred to as fast and safe tracking. Computational limitations restrict online motion planning to low-fidelity models. However, planning with low-fidelity models compromises safety, as the dynamic feasibility of resulting reference trajectories is not ensured. This potentially leads to unavoidable tracking errors that may cause safety-critical constraint violations. Existing frameworks mitigate this safety risk by augmenting safety-critical constraints in motion planning by a safety margin that prevents constraint violations under worst-case tracking errors. However, the methods employed in these frameworks determine the safety margin based on a heuristically selected performance of the planning model, which likely results in overly conservative reference trajectories. Furthermore, these methods are computationally intensive, and the state-of-the-art method is limited in numerical accuracy. We adopt a different perspective and address these limitations with a method that mitigates conservatism in existing frameworks by adapting the planning model performance to a given safety margin. Our method achieves numerical accuracy and requires significantly less computation time than existing methods by leveraging a captivity-escape game, which is a specific zero-sum differential game formulated in this paper. We demonstrate our method using a numerical example and compare it to the state of the art.

Paper number 73:
Title: Unified Interference-Aware Water-Filling for QoS-Constrained Communication, Sensing, and JRC
Authors: Ahmed Naeem, Anastassia Gharib, HÃ¼seyin Arslan
Abstract: Water-filling (WF) algorithms are pivotal in maximizing capacity and spectral efficiency in multiple-input and multiple-output (MIMO) systems. However, traditional WF approaches cater solely to communication requirements, neglecting the emerging heterogeneity of 6G, including sensing and joint radar-communication (JRC). As these diverse demands grow in importance and have different Quality of Service (QoS) constraints, traditional WF becomes inadequate. Therefore, in this paper, we propose a unified interference-aware and QoS-constrained WF algorithm for systems with communication, sensing, and JRC. The proposed algorithm enables power allocation for multi-user MIMO systems, effectively addressing interference and balancing the support for heterogeneous user requirements.

Paper number 74:
Title: Optimal Co-Design of a Hybrid Energy Storage System for Truck Charging
Authors: Juan Pablo Bertucci, Sudarshan Raghuraman, Mauro Salazar, Theo Hofman
Abstract: The major challenges to battery electric truck adoption are their high cost and grid this http URL this context, stationary energy storage systems can help mitigate both issues. Since their design and operation are strongly coupled, to make the best out of them, they should be jointly optimized. This paper presents a co-design framework for hybrid energy storage systems where their technology and sizing are optimized jointly with their operational strategies. Specifically, we consider a microgrid supporting truck chargers that consists of utility grid, solar panels, and energy storage systems including batteries, supercapacitors and flywheels. We frame the co-design problem as a mixed-integer linear program that can be solved with global optimality guarantees. We showcase our framework in a case-study of a distribution center in the Netherlands. Our results show that although the battery-only configuration is already competitive, adding supercapacitors or flywheel storage decrease total cost and increase energy sold back to the grid. Overall, the fully hybrid solution (Battery+Supercapacitors+Flywheel) offers the best outcomes, achieving the lowest overall cost (1.96\% lower compared to battery-only) and reduced grid dependency, but at a higher (2.6\%) initial investment.

Paper number 75:
Title: Inter-Speaker Relative Cues for Text-Guided Target Speech Extraction
Authors: Wang Dai, Archontis Politis, Tuomas Virtanen
Abstract: We propose a novel approach that utilize inter-speaker relative cues for distinguishing target speakers and extracting their voices from mixtures. Continuous cues (e.g., temporal order, age, pitch level) are grouped by relative differences, while discrete cues (e.g., language, gender, emotion) retain their categories. Relative cues offers greater flexibility than fixed speech attribute classification, facilitating much easier expansion of text-guided target speech extraction datasets. Our experiments show that combining all relative cues yields better performance than random subsets, with gender and temporal order being the most robust across languages and reverberant conditions. Additional cues like pitch level, loudness, distance, speaking duration, language, and pitch range also demonstrate notable benefit in complex scenarios. Fine-tuning pre-trained WavLM Base+ CNN encoders improves overall performance over the baseline of using only a Conv1d encoder.

Paper number 76:
Title: LinearVC: Linear transformations of self-supervised features through the lens of voice conversion
Authors: Herman Kamper, Benjamin van Niekerk, Julian ZaÃ¯di, Marc-AndrÃ© Carbonneau
Abstract: We introduce LinearVC, a simple voice conversion method that sheds light on the structure of self-supervised representations. First, we show that simple linear transformations of self-supervised features effectively convert voices. Next, we probe the geometry of the feature space by constraining the set of allowed transformations. We find that just rotating the features is sufficient for high-quality voice conversion. This suggests that content information is embedded in a low-dimensional subspace which can be linearly transformed to produce a target voice. To validate this hypothesis, we finally propose a method that explicitly factorizes content and speaker information using singular value decomposition; the resulting linear projection with a rank of just 100 gives competitive conversion results. Our work has implications for both practical voice conversion and a broader understanding of self-supervised speech representations. Samples and code: this https URL.

Paper number 77:
Title: Equivalence of Left- and Right-Invariant Extended Kalman Filters on Matrix Lie Groups
Authors: Finn G. Maurer, Erlend A. Basso, Henrik M. Schmidt-Didlaukies, Torleiv H. Bryne
Abstract: This paper derives the extended Kalman filter (EKF) for continuous-time systems on matrix Lie groups observed through discrete-time measurements. By modeling the system noise on the Lie algebra and adopting a Stratonovich interpretation for the stochastic differential equation (SDE), we ensure that solutions remain on the manifold. The derivation of the filter follows classical EKF principles, naturally integrating a necessary full-order covariance reset post-measurement update. A key contribution is proving that this full-order covariance reset guarantees that the Lie-group-valued state estimate is invariant to whether a left- or right-invariant error definition is used in the EKF. Monte Carlo simulations of the aided inertial navigation problem validate the invariance property and confirm its absence when employing reduced-order covariance resets.

Paper number 78:
Title: Lessons Learned from the URGENT 2024 Speech Enhancement Challenge
Authors: Wangyou Zhang, Kohei Saijo, Samuele Cornell, Robin Scheibler, Chenda Li, Zhaoheng Ni, Anurag Kumar, Marvin Sach, Wei Wang, Yihui Fu, Shinji Watanabe, Tim Fingscheidt, Yanmin Qian
Abstract: The URGENT 2024 Challenge aims to foster speech enhancement (SE) techniques with great universality, robustness, and generalizability, featuring a broader task definition, large-scale multi-domain data, and comprehensive evaluation metrics. Nourished by the challenge outcomes, this paper presents an in-depth analysis of two key, yet understudied, issues in SE system development: data cleaning and evaluation metrics. We highlight several overlooked problems in traditional SE pipelines: (1) mismatches between declared and effective audio bandwidths, along with label noise even in various "high-quality" speech corpora; (2) lack of both effective SE systems to conquer the hardest conditions (e.g., speech overlap, strong noise / reverberation) and reliable measure of speech sample difficulty; (3) importance of combining multifaceted metrics for a comprehensive evaluation correlating well with human judgment. We hope that this endeavor can inspire improved SE pipeline designs in the future.

Paper number 79:
Title: Unsupervised Rhythm and Voice Conversion to Improve ASR on Dysarthric Speech
Authors: Karl El Hajal, Enno Hermann, Sevada Hovsepyan, Mathew Magimai.-Doss
Abstract: Automatic speech recognition (ASR) systems struggle with dysarthric speech due to high inter-speaker variability and slow speaking rates. To address this, we explore dysarthric-to-healthy speech conversion for improved ASR performance. Our approach extends the Rhythm and Voice (RnV) conversion framework by introducing a syllable-based rhythm modeling method suited for dysarthric speech. We assess its impact on ASR by training LF-MMI models and fine-tuning Whisper on converted speech. Experiments on the Torgo corpus reveal that LF-MMI achieves significant word error rate reductions, especially for more severe cases of dysarthria, while fine-tuning Whisper on converted data has minimal effect on its performance. These results highlight the potential of unsupervised rhythm and voice conversion for dysarthric ASR. Code available at: this https URL

Paper number 80:
Title: Local Ambiguity Shaping for Doppler-Resilient Sequences Under Spectral and PAPR Constraints
Authors: Shi He, Lingsheng Meng, Yao Ge, Yong Liang Guan, David GonzÃ¡lez G., Zilong Liu
Abstract: This paper focuses on designing Doppler-resilient sequences with low local Ambiguity Function (AF) sidelobes, subject to certain spectral and Peak-to-Average Power Ratio (PAPR) constraints. To achieve this, we propose two distinctoptimization algorithms: (i) an Alternating Minimization (AM) algorithm for superior Weighted Peak Sidelobe Level (WPSL) minimization, and (ii) a low-complexity Augmented Lagrangian-assisted Majorization Minimization (ALaMM) algorithm with effective WPSL suppression. The proposed schemes hold great potential for sequence design in future 6G and integrated sensing and communication applications, supporting robust sensing under spectral coexistence constraints in high-mobility scenarios.

Paper number 81:
Title: Interpretable reinforcement learning for heat pump control through asymmetric differentiable decision trees
Authors: Toon Van Puyvelde, Mehran Zareh, Chris Develder
Abstract: In recent years, deep reinforcement learning (DRL) algorithms have gained traction in home energy management systems. However, their adoption by energy management companies remains limited due to the black-box nature of DRL, which fails to provide transparent decision-making feedback. To address this, explainable reinforcement learning (XRL) techniques have emerged, aiming to make DRL decisions more transparent. Among these, soft differential decision tree (DDT) distillation provides a promising approach due to the clear decision rules they are based on, which can be efficiently computed. However, achieving high performance often requires deep, and completely full, trees, which reduces interpretability. To overcome this, we propose a novel asymmetric soft DDT construction method. Unlike traditional soft DDTs, our approach adaptively constructs trees by expanding nodes only when necessary. This improves the efficient use of decision nodes, which require a predetermined depth to construct full symmetric trees, enhancing both interpretability and performance. We demonstrate the potential of asymmetric DDTs to provide transparent, efficient, and high-performing decision-making in home energy management systems.

Paper number 82:
Title: Self-Supervised Speech Quality Assessment (S3QA): Leveraging Speech Foundation Models for a Scalable Speech Quality Metric
Authors: Mattson Ogg, Caitlyn Bishop, Han Yi, Sarah Robinson
Abstract: Methods for automatically assessing speech quality are critical for many human language technologies. Behavioral ratings provided by human raters (e.g., mean opinion scores; MOS) are considered the gold standard, but they are susceptible to variability between individual raters, cannot easily be generalized across corpora, and are labor-intensive to collect, thus limiting the acoustic challenges they can quantify. Here, we present a new, scalable method for automatically assessing speech quality: the self-supervised speech quality assessment (S3QA) model. First, we processed high quality utterances from multiple speech corpora, using a wide range of acoustic manipulations intended to emulate common sources of quality degradation in the real-world: frequency filtering, reverberation, background noise, and digital compression. Second, we leveraged an existing, pre-trained speech foundation model, WavLM, to computationally derive a self-supervised training target for the level of signal degradation by calculating the cosine distances between the clean and degraded versions of each utterance in the embedding space. Next, we trained a transformer-based model to predict the cosine distance, or degradation index, given only the degraded versions of these utterances. Finally, the trained model was evaluated on unseen test corpora of synthetic mixtures, NISQA, and VOiCES. We show that the S3QA model trained on this task performs well and is aligned with both behavioral ratings (MOS), speech technology performance (automatic speech recognition) and other important features of the held-out data (e.g., microphone distances). This approach provides an automated, scalable method for assessing speech quality across a wide range of acoustic challenges, and could easily be adapted to other use cases where acoustic simulations are available.

Paper number 83:
Title: Missing Data in Signal Processing and Machine Learning: Models, Methods and Modern Approaches
Authors: A. Hippert-Ferrer, A. Sportisse, A. Javaheri, M. N. El Korso, D. P. Palomar
Abstract: The goal of this tutorial is to provide an overview of recent methods for handling missing data in signal processing methods, from their origins to the challenges ahead. Missing data approaches are grouped by three main categories: i) missing-data imputation, ii) estimation with missing values and iii) prediction with missing values. We focus on methodological and experimental results through specific case studies on real-world applications. Promising and future research directions, including a better integration of informative missingness, are also discussed. We believe that the proposed conceptual framework and the presentation of the main problems related to missing data will encourage researchers of the signal processing community to develop original methods for handling missing values and to efficiently deal with new applications involving missing data.

Paper number 84:
Title: A Vertical Approach to Designing and Managing Sustainable Heterogeneous Edge Data Centers
Authors: Aikaterini Maria Panteleaki, Varatheepan Paramanayakam, Vasileios Pentsos, Andreas Karatzas, Spyros Tragoudas, Iraklis Anagnostopoulos
Abstract: The increasing demand for Artificial Intelligence (AI) computing poses significant environmental challenges, with both operational and embodied carbon emissions becoming major contributors. This paper presents a carbon-aware holistic methodology for designing and managing sustainable Edge Data Centers (EDCs), based on three design principles that challenge the state-of-the-art optimization paradigms. Our approach employs vertical integration across the architecture, system, and runtime layers, balances operational and embodied carbon emissions while considering EDC performance as a co-optimization objective, rather than a constraint. At the architecture level, we propose carbon-aware and approximate accelerator designs to reduce embodied carbon. At the system level, we enhance resource utilization and adapt to real-time carbon intensity variations to minimize operational emissions. Finally, at the runtime level, we develop dynamic scheduling frameworks that adjust execution, based on energy constraints and carbon intensity.

Paper number 85:
Title: Update-Aware Robust Optimal Model Predictive Control for Nonlinear Systems
Authors: J. Wehbeh, E. C. Kerrigan
Abstract: Robust optimal or min-max model predictive control (MPC) approaches aim to guarantee constraint satisfaction over a known, bounded uncertainty set while minimizing a worst-case performance bound. Traditionally, these methods compute a trajectory that meets the desired properties over a fixed prediction horizon, apply a portion of the resulting input, and then re-solve the MPC problem using newly obtained measurements at the next time step. However, this approach fails to account for the fact that the control trajectory will be updated in the future, potentially leading to conservative designs. In this paper, we present a novel update-aware robust optimal MPC algorithm for decreasing horizon problems on nonlinear systems that explicitly accounts for future control trajectory updates. This additional insight allows our method to provably expand the feasible solution set and guarantee improved worst-case performance bounds compared to existing techniques. Our approach formulates the trajectory generation problem as a sequence of nested existence-constrained semi-infinite programs (SIPs), which can be efficiently solved using local reduction techniques. To demonstrate its effectiveness, we evaluate our approach on a planar quadrotor problem, where it clearly outperforms an equivalent method that does not account for future updates at the cost of increased computation time.

Paper number 86:
Title: Benchmarking Neural Speech Codec Intelligibility with SITool
Authors: Anna Leschanowsky, Kishor Kayyar Lakshminarayana, Anjana Rajasekhar, Lyonel Behringer, Ibrahim Kilinc, Guillaume Fuchs, EmanuÃ«l A. P. Habets
Abstract: Speech intelligibility assessment is essential for evaluating neural speech codecs, yet most evaluation efforts focus on overall quality rather than intelligibility. Only a few publicly available tools exist for conducting standardized intelligibility tests, like the Diagnostic Rhyme Test (DRT) and Modified Rhyme Test (MRT). We introduce the Speech Intelligibility Toolkit for Subjective Evaluation (SITool), a Flask-based web application for conducting DRT and MRT in laboratory and crowdsourcing settings. We use SITool to benchmark 13 neural and traditional speech codecs, analyzing phoneme-level degradations and comparing subjective DRT results with objective intelligibility metrics. Our findings show that, while neural speech codecs can outperform traditional ones in subjective intelligibility, only STOI and ESTOI - not WER - significantly correlate with subjective results, although they struggle to capture gender and wordlist-specific variations observed in subjective evaluations.

Paper number 87:
Title: Smooth Logic Constraints in Nonlinear Optimization and Optimal Control Problems
Authors: J. Wehbeh, E. C. Kerrigan
Abstract: In some optimal control problems, complex relationships between states and inputs cannot be easily represented using continuous constraints, necessitating the use of discrete logic instead. This paper presents a method for incorporating such logic constraints directly within continuous optimization frameworks, eliminating the need for binary variables or specialized solvers. Our approach reformulates arbitrary logic constraints under minimal assumptions as max-min constraints, which are then smoothed by introducing auxiliary variables into the optimization problem. When these reformulated constraints are satisfied, they guarantee that the original logical conditions hold, ensuring correctness in the optimization process. We demonstrate the effectiveness of this method on two planar quadrotor control tasks with complex logic constraints. Compared to existing techniques for encoding logic in continuous optimization, our approach achieves faster computational performance and improved convergence to feasible solutions.

Paper number 88:
Title: Generalized Super-Twisting Observer for a class of interconnected nonlinear systems with uncertainties
Authors: Rania Tafat, Jaime A. Moreno, Stefan Streif
Abstract: The Generalized Super-Twisting Observer (GSTO) is extended for a strongly observable class of nonlinearly interconnected systems with bounded uncertainties/perturbations. A nonsmooth strong Lyapunov function is used to prove the finite-time convergence of the proposed observer to the true system's trajectories, in the presence of the uncertainties. A case study on the interaction between two food production systems is presented, comparing the proposed observer with the High Gain observer. The results emphasize the critical role of the GSTO's discontinuous term in achieving exact estimation.

Paper number 89:
Title: Data-assimilated model-informed reinforcement learning
Authors: Defne E. Ozan, Andrea NÃ³voa, Georgios Rigas, Luca Magri
Abstract: The control of spatio-temporally chaos is challenging because of high dimensionality and unpredictability. Model-free reinforcement learning (RL) discovers optimal control policies by interacting with the system, typically requiring observations of the full physical this http URL practice, sensors often provide only partial and noisy measurements (observations) of the system. The objective of this paper is to develop a framework that enables the control of chaotic systems with partial and noisy observability. The proposed method, data-assimilated model-informed reinforcement learning (DA-MIRL), integrates (i) low-order models to approximate high-dimensional dynamics; (ii) sequential data assimilation to correct the model prediction when observations become available; and (iii) an off-policy actor-critic RL algorithm to adaptively learn an optimal control strategy based on the corrected state estimates. We test DA-MIRL on the spatiotemporally chaotic solutions of the Kuramoto-Sivashinsky equation. We estimate the full state of the environment with (i) a physics-based model, here, a coarse-grained model; and (ii) a data-driven model, here, the control-aware echo state network, which is proposed in this paper. We show that DA-MIRL successfully estimates and suppresses the chaotic dynamics of the environment in real time from partial observations and approximate models. This work opens opportunities for the control of partially observable chaotic systems.

Paper number 90:
Title: A New 5 bit/2D-symbol Modulation Format for Relative Intensity Noise-dominated IM-DD Systems
Authors: Felipe Villenas, Kaiquan Wu, Yunus Can GÃ¼ltekin, Jamal Riani, Alex Alvarado
Abstract: We propose a novel 5-bit/2D-symbol modulation format based on PAM-6 optimized for IM-DD systems dominated by relative intensity noise. The proposed modulation scheme improves SNR by 0.94 dB compared to conventional PAM-6 and achieves near-optimal BER performance.

Paper number 91:
Title: Beyond Pixel Agreement: Large Language Models as Clinical Guardrails for Reliable Medical Image Segmentation
Authors: Jiaxi Sheng, Leyi Yu, Haoyue Li, Yifan Gao, Xin Gao
Abstract: Evaluating AI-generated medical image segmentations for clinical acceptability poses a significant challenge, as traditional pixelagreement metrics often fail to capture true diagnostic utility. This paper introduces Hierarchical Clinical Reasoner (HCR), a novel framework that leverages Large Language Models (LLMs) as clinical guardrails for reliable, zero-shot quality assessment. HCR employs a structured, multistage prompting strategy that guides LLMs through a detailed reasoning process, encompassing knowledge recall, visual feature analysis, anatomical inference, and clinical synthesis, to evaluate segmentations. We evaluated HCR on a diverse dataset across six medical imaging tasks. Our results show that HCR, utilizing models like Gemini 2.5 Flash, achieved a classification accuracy of 78.12%, performing comparably to, and in instances exceeding, dedicated vision models such as ResNet50 (72.92% accuracy) that were specifically trained for this task. The HCR framework not only provides accurate quality classifications but also generates interpretable, step-by-step reasoning for its assessments. This work demonstrates the potential of LLMs, when appropriately guided, to serve as sophisticated evaluators, offering a pathway towards more trustworthy and clinically-aligned quality control for AI in medical imaging.

Paper number 92:
Title: On-device Streaming Discrete Speech Units
Authors: Kwanghee Choi, Masao Someki, Emma Strubell, Shinji Watanabe
Abstract: Discrete speech units (DSUs) are derived from clustering the features of self-supervised speech models (S3Ms). DSUs offer significant advantages for on-device streaming speech applications due to their rich phonetic information, high transmission efficiency, and seamless integration with large language models. However, conventional DSU-based approaches are impractical as they require full-length speech input and computationally expensive S3Ms. In this work, we reduce both the attention window and the model size while preserving the effectiveness of DSUs. Our results demonstrate that we can reduce floating-point operations (FLOPs) by 50% with only a relative increase of 6.5% in character error rate (CER) on the ML-SUPERB 1h dataset. These findings highlight the potential of DSUs for real-time speech processing in resource-constrained environments.

Paper number 93:
Title: Hybrid SIS Dynamics for Demand Modeling of Frequently Updated Products
Authors: Ian Walter, Jitesh H. Panchal, Philip E. ParÃ©
Abstract: We propose a hybrid spreading process model to capture the dynamics of demand for software-based products. We introduce discontinuous jumps in the state to model sudden surges in demand that can be seen immediately after a product update is released. After each update, the modeled demand evolves according to a continuous-time susceptible-infected-susceptible (SIS) epidemic model. We identify the necessary and sufficient conditions for estimating the hybrid model's parameters for an arbitrary finite number of sequential updates. We verify the parameter estimation conditions in simulation, and evaluate how the estimation of these parameters is impacted by the presence of observation and process noise. We then validate our model by applying our estimation method to daily user engagement data for a regularly updating software product, the live-service video game `Apex Legends.'

Paper number 94:
Title: DNCASR: End-to-End Training for Speaker-Attributed ASR
Authors: Xianrui Zheng, Chao Zhang, Philip C. Woodland
Abstract: This paper introduces DNCASR, a novel end-to-end trainable system designed for joint neural speaker clustering and automatic speech recognition (ASR), enabling speaker-attributed transcription of long multi-party meetings. DNCASR uses two separate encoders to independently encode global speaker characteristics and local waveform information, along with two linked decoders to generate speaker-attributed transcriptions. The use of linked decoders allows the entire system to be jointly trained under a unified loss function. By employing a serialised training approach, DNCASR effectively addresses overlapping speech in real-world meetings, where the link improves the prediction of speaker indices in overlapping segments. Experiments on the AMI-MDM meeting corpus demonstrate that the jointly trained DNCASR outperforms a parallel system that does not have links between the speaker and ASR decoders. Using cpWER to measure the speaker-attributed word error rate, DNCASR achieves a 9.0% relative reduction on the AMI-MDM Eval set.

Paper number 95:
Title: Characterization of the Combined Effective Radiation Pattern of UAV-Mounted Antennas and Ground Station
Authors: Mushfiqur Rahman, Ismail Guvenc, Jason A. Abrahamson, Amitabh Mishra, Arupjyoti Bhuyan
Abstract: An Unmanned Aerial Vehicle (UAV)-based communication typically involves a link between a UAV-mounted antenna and a ground station. The radiation pattern of both antennas is influenced by nearby reflecting surfaces and scatterers, such as the UAV body and the ground. Experimentally characterizing the effective radiation patterns of both antennas is challenging, as the received power depends on their interaction. In this study, we learn a combined radiation pattern from experimental UAV flight data, assuming the UAV travels with a fixed orientation (constant yaw angle and zero pitch/roll). We validate the characterized radiation pattern by cross-referencing it with experiments involving different UAV trajectories, all conducted under identical ground station and UAV orientation conditions. Experimental results show that the learned combined radiation pattern reduces received power estimation error by up to 10 dB, compared to traditional anechoic chamber radiation patterns that neglect the effects of the UAV body and surrounding objects.

Paper number 96:
Title: Probing Audio-Generation Capabilities of Text-Based Language Models
Authors: Arjun Prasaath Anbazhagan, Parteek Kumar, Ujjwal Kaur, Aslihan Akalin, Kevin Zhu, Sean O'Brien
Abstract: How does textual representation of audio relate to the Large Language Model's (LLMs) learning about the audio world? This research investigates the extent to which LLMs can be prompted to generate audio, despite their primary training in textual data. We employ a three-tier approach, progressively increasing the complexity of audio generation: 1) Musical Notes, 2) Environmental Sounds, and 3) Human Speech. To bridge the gap between text and audio, we leverage code as an intermediary, prompting LLMs to generate code that, when executed, produces the desired audio output. To evaluate the quality and accuracy of the generated audio, we employ FAD and CLAP scores. Our findings reveal that while LLMs can generate basic audio features, their performance deteriorates as the complexity of the audio increases. This suggests that while LLMs possess a latent understanding of the auditory world, their ability to translate this understanding into tangible audio output remains rudimentary. Further research into techniques that can enhance the quality and diversity of LLM-generated audio can lead to an improvement in the performance of text-based LLMs in generating audio.

Paper number 97:
Title: AbsoluteNet: A Deep Learning Neural Network to Classify Cerebral Hemodynamic Responses of Auditory Processing
Authors: Behtom Adeli, John Mclinden, Pankaj Pandey, Ming Shao, Yalda Shahriari
Abstract: In recent years, deep learning (DL) approaches have demonstrated promising results in decoding hemodynamic responses captured by functional near-infrared spectroscopy (fNIRS), particularly in the context of brain-computer interface (BCI) applications. This work introduces AbsoluteNet, a novel deep learning architecture designed to classify auditory event-related responses recorded using fNIRS. The proposed network is built upon principles of spatio-temporal convolution and customized activation functions. Our model was compared against several models, namely fNIRSNET, MDNN, DeepConvNet, and ShallowConvNet. The results showed that AbsoluteNet outperforms existing models, reaching 87.0% accuracy, 84.8% sensitivity, and 89.2% specificity in binary classification, surpassing fNIRSNET, the second-best model, by 3.8% in accuracy. These findings underscore the effectiveness of our proposed deep learning model in decoding hemodynamic responses related to auditory processing and highlight the importance of spatio-temporal feature aggregation and customized activation functions to better fit fNIRS dynamics.

Paper number 98:
Title: ACE-Step: A Step Towards Music Generation Foundation Model
Authors: Junmin Gong, Sean Zhao, Sen Wang, Shengyuan Xu, Joe Guo
Abstract: We introduce ACE-Step, a novel open-source foundation model for music generation that overcomes key limitations of existing approaches and achieves state-of-the-art performance through a holistic architectural design. Current methods face inherent trade-offs between generation speed, musical coherence, and controllability. For example, LLM-based models (e.g. Yue, SongGen) excel at lyric alignment but suffer from slow inference and structural artifacts. Diffusion models (e.g. DiffRhythm), on the other hand, enable faster synthesis but often lack long-range structural coherence. ACE-Step bridges this gap by integrating diffusion-based generation with Sana's Deep Compression AutoEncoder (DCAE) and a lightweight linear transformer. It also leverages MERT and m-hubert to align semantic representations (REPA) during training, allowing rapid convergence. As a result, our model synthesizes up to 4 minutes of music in just 20 seconds on an A100 GPU-15x faster than LLM-based baselines-while achieving superior musical coherence and lyric alignment across melody, harmony, and rhythm metrics. Moreover, ACE-Step preserves fine-grained acoustic details, enabling advanced control mechanisms such as voice cloning, lyric editing, remixing, and track generation (e.g. lyric2vocal, singing2accompaniment). Rather than building yet another end-to-end text-to-music pipeline, our vision is to establish a foundation model for music AI: a fast, general-purpose, efficient yet flexible architecture that makes it easy to train subtasks on top of it. This paves the way for the development of powerful tools that seamlessly integrate into the creative workflows of music artists, producers, and content creators. In short, our goal is to build a stable diffusion moment for music. The code, the model weights and the demo are available at: this https URL.

Paper number 99:
Title: Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry
Authors: Sujeet Kumar, Pretam Ray, Abhinay Beerukuri, Shrey Kamoji, Manoj Balaji Jagadeeshan, Pawan Goyal
Abstract: Sanskrit, an ancient language with a rich linguistic heritage, presents unique challenges for automatic speech recognition (ASR) due to its phonemic complexity and the phonetic transformations that occur at word junctures, similar to the connected speech found in natural conversations. Due to these complexities, there has been limited exploration of ASR in Sanskrit, particularly in the context of its poetic verses, which are characterized by intricate prosodic and rhythmic patterns. This gap in research raises the question: How can we develop an effective ASR system for Sanskrit, particularly one that captures the nuanced features of its poetic form? In this study, we introduce Vedavani, the first comprehensive ASR study focused on Sanskrit Vedic poetry. We present a 54-hour Sanskrit ASR dataset, consisting of 30,779 labelled audio samples from the Rig Veda and Atharva Veda. This dataset captures the precise prosodic and rhythmic features that define the language. We also benchmark the dataset on various state-of-the-art multilingual speech models.$^{1}$ Experimentation revealed that IndicWhisper performed the best among the SOTA models.

Paper number 100:
Title: Improving Code Switching with Supervised Fine Tuning and GELU Adapters
Authors: Linh Pham
Abstract: There are few code switching datasets, labeled or unlabled, that exist today. As a result, ASR requires new methods to utilize the vast monolingual data and models that exist. This paper uses OpenAI's open source ASR model, Whisper, which has been pre-trained on 680K hours of audio to perform monolingual ASR tasks. In Part 1, this paper examines how exploiting Whisper's monolingual ability to individually tokenize training text, called "Switching Tokenizers Method", improves transcription accuracy. In Part 2, we combine the Switching Tokenizers Method from part 1 and train a GELU based adapter on the encoder. These two methods reduced Total Mixed Error Rate (MER) to 9.4% for the ASCEND dataset, 6% for SEAME devman and 9.7% for SEAME devsge, outperforming current SoTA methods.

Paper number 101:
Title: OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning
Authors: Yifan Peng, Shakeel Muhammad, Yui Sudo, William Chen, Jinchuan Tian, Chyi-Jiunn Lin, Shinji Watanabe
Abstract: The Open Whisper-style Speech Models (OWSM) project has developed a series of fully open speech foundation models using academic-scale resources, but their training data remains insufficient. This work enhances OWSM by integrating YODAS, a large-scale web-crawled dataset with a Creative Commons license. However, incorporating YODAS is nontrivial due to its wild nature, which introduces challenges such as incorrect language labels and audio-text misalignments. To address this, we develop a scalable data-cleaning pipeline using public toolkits, yielding a dataset with 166,000 hours of speech across 75 languages. Our new series of OWSM v4 models, trained on this curated dataset alongside existing OWSM data, significantly outperform previous versions on multilingual benchmarks. Our models even match or surpass frontier industrial models like Whisper and MMS in multiple scenarios. We will publicly release the cleaned YODAS data, pre-trained models, and all associated scripts via the ESPnet toolkit.

Paper number 102:
Title: The iNaturalist Sounds Dataset
Authors: Mustafa Chasmai, Alexander Shepard, Subhransu Maji, Grant Van Horn
Abstract: We present the iNaturalist Sounds Dataset (iNatSounds), a collection of 230,000 audio files capturing sounds from over 5,500 species, contributed by more than 27,000 recordists worldwide. The dataset encompasses sounds from birds, mammals, insects, reptiles, and amphibians, with audio and species labels derived from observations submitted to iNaturalist, a global citizen science platform. Each recording in the dataset varies in length and includes a single species annotation. We benchmark multiple backbone architectures, comparing multiclass classification objectives with multilabel objectives. Despite weak labeling, we demonstrate that iNatSounds serves as a useful pretraining resource by benchmarking it on strongly labeled downstream evaluation datasets. The dataset is available as a single, freely accessible archive, promoting accessibility and research in this important domain. We envision models trained on this data powering next-generation public engagement applications, and assisting biologists, ecologists, and land use managers in processing large audio collections, thereby contributing to the understanding of species compositions in diverse soundscapes.

Paper number 103:
Title: DiffDSR: Dysarthric Speech Reconstruction Using Latent Diffusion Model
Authors: Xueyuan Chen, Dongchao Yang, Wenxuan Wu, Minglin Wu, Jing Xu, Xixin Wu, Zhiyong Wu, Helen Meng
Abstract: Dysarthric speech reconstruction (DSR) aims to convert dysarthric speech into comprehensible speech while maintaining the speaker's identity. Despite significant advancements, existing methods often struggle with low speech intelligibility and poor speaker similarity. In this study, we introduce a novel diffusion-based DSR system that leverages a latent diffusion model to enhance the quality of speech reconstruction. Our model comprises: (i) a speech content encoder for phoneme embedding restoration via pre-trained self-supervised learning (SSL) speech foundation models; (ii) a speaker identity encoder for speaker-aware identity preservation by in-context learning mechanism; (iii) a diffusion-based speech generator to reconstruct the speech based on the restored phoneme embedding and preserved speaker identity. Through evaluations on the widely-used UASpeech corpus, our proposed model shows notable enhancements in speech intelligibility and speaker similarity.

Paper number 104:
Title: $\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time
Authors: Sarthak Kumar Maharana, Saksham Singh Kushwaha, Baoming Zhang, Adrian Rodriguez, Songtao Wei, Yapeng Tian, Yunhui Guo
Abstract: While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur $\textit{simultaneously}$ in both audio and visual modalities, we introduce $\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the test-time robustness of audio-visual recognition models. $\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets, $\texttt{AUDIOSET-2C}$, $\texttt{VGGSOUND-2C}$, $\texttt{KINETICS-2C}$, and $\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual corruptions that are $\textit{co-occurring}$ and $\textit{correlated}$. Through extensive evaluations, we observe that state-of-the-art supervised and self-supervised audio-visual models exhibit declining robustness as corruption severity increases. Furthermore, online test-time adaptation (TTA) methods, on $\texttt{VGGSOUND-2C}$ and $\texttt{KINETICS-2C}$, offer minimal improvements in performance under bimodal corruptions. We further propose $\texttt{AV2C}$, a simple TTA approach enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which achieves improvements on $\texttt{VGGSOUND-2C}$. We hope that $\texttt{AVROBUSTBENCH}$ will steer the development of more effective and robust audio-visual TTA approaches. Our code is available $\href{this https URL}{here}$.

Paper number 105:
Title: Feature Fusion and Knowledge-Distilled Multi-Modal Multi-Target Detection
Authors: Ngoc Tuyen Do, Tri Nhu Do
Abstract: In the surveillance and defense domain, multi-target detection and classification (MTD) is considered essential yet challenging due to heterogeneous inputs from diverse data sources and the computational complexity of algorithms designed for resource-constrained embedded devices, particularly for Al-based solutions. To address these challenges, we propose a feature fusion and knowledge-distilled framework for multi-modal MTD that leverages data fusion to enhance accuracy and employs knowledge distillation for improved domain adaptation. Specifically, our approach utilizes both RGB and thermal image inputs within a novel fusion-based multi-modal model, coupled with a distillation training pipeline. We formulate the problem as a posterior probability optimization task, which is solved through a multi-stage training pipeline supported by a composite loss function. This loss function effectively transfers knowledge from a teacher model to a student model. Experimental results demonstrate that our student model achieves approximately 95% of the teacher model's mean Average Precision while reducing inference time by approximately 50%, underscoring its suitability for practical MTD deployment scenarios.

Paper number 106:
Title: RPRA-ADD: Forgery Trace Enhancement-Driven Audio Deepfake Detection
Authors: Ruibo Fu, Xiaopeng Wang, Zhengqi Wen, Jianhua Tao, Yuankun Xie, Zhiyong Wang, Chunyu Qiang, Xuefei Liu, Cunhang Fan, Chenxing Li, Guanjun Li
Abstract: Existing methods for deepfake audio detection have demonstrated some effectiveness. However, they still face challenges in generalizing to new forgery techniques and evolving attack patterns. This limitation mainly arises because the models rely heavily on the distribution of the training data and fail to learn a decision boundary that captures the essential characteristics of forgeries. Additionally, relying solely on a classification loss makes it difficult to capture the intrinsic differences between real and fake audio. In this paper, we propose the RPRA-ADD, an integrated Reconstruction-Perception-Reinforcement-Attention networks based forgery trace enhancement-driven robust audio deepfake detection framework. First, we propose a Global-Local Forgery Perception (GLFP) module for enhancing the acoustic perception capacity of forgery traces. To significantly reinforce the feature space distribution differences between real and fake audio, the Multi-stage Dispersed Enhancement Loss (MDEL) is designed, which implements a dispersal strategy in multi-stage feature spaces. Furthermore, in order to enhance feature awareness towards forgery traces, the Fake Trace Focused Attention (FTFA) mechanism is introduced to adjust attention weights dynamically according to the reconstruction discrepancy matrix. Visualization experiments not only demonstrate that FTFA improves attention to voice segments, but also enhance the generalization capability. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on 4 benchmark datasets, including ASVspoof2019, ASVspoof2021, CodecFake, and FakeSound, achieving over 20% performance improvement. In addition, it outperforms existing methods in rigorous 3*3 cross-domain evaluations across Speech, Sound, and Singing, demonstrating strong generalization capability across diverse audio domains.

Paper number 107:
Title: Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG
Authors: Siavash Shams, Richard Antonello, Gavin Mischler, Stephan Bickel, Ashesh Mehta, Nima Mesgarani
Abstract: Decoding continuous language from neural signals remains a significant challenge in the intersection of neuroscience and artificial intelligence. We introduce Neuro2Semantic, a novel framework that reconstructs the semantic content of perceived speech from intracranial EEG (iEEG) recordings. Our approach consists of two phases: first, an LSTM-based adapter aligns neural signals with pre-trained text embeddings; second, a corrector module generates continuous, natural text directly from these aligned embeddings. This flexible method overcomes the limitations of previous decoding approaches and enables unconstrained text generation. Neuro2Semantic achieves strong performance with as little as 30 minutes of neural data, outperforming a recent state-of-the-art method in low-data settings. These results highlight the potential for practical applications in brain-computer interfaces and neural decoding technologies.

Paper number 108:
Title: MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity Reconstruction and Generation
Authors: Yakun Song, Jiawei Chen, Xiaobin Zhuang, Chenpeng Du, Ziyang Ma, Jian Wu, Jian Cong, Dongya Jia, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen
Abstract: Neural audio codecs have made significant strides in efficiently mapping raw audio waveforms into discrete token representations, which are foundational for contemporary audio generative models. However, most existing codecs are optimized primarily for reconstruction quality, often at the expense of the downstream modelability of the encoded tokens. Motivated by the need to overcome this bottleneck, we introduce $\textbf{MagiCodec}$, a novel single-layer, streaming Transformer-based audio codec. MagiCodec is designed with a multistage training pipeline that incorporates Gaussian noise injection and latent regularization, explicitly targeting the enhancement of semantic expressiveness in the generated codes while preserving high reconstruction fidelity. We analytically derive the effect of noise injection in the frequency domain, demonstrating its efficacy in attenuating high-frequency components and fostering robust tokenization. Extensive experimental evaluations show that MagiCodec surpasses state-of-the-art codecs in both reconstruction quality and downstream tasks. Notably, the tokens produced by MagiCodec exhibit Zipf-like distributions, as observed in natural languages, thereby improving compatibility with language-model-based generative architectures. The code and pre-trained models are available at this https URL.

Paper number 109:
Title: Causal Structure Discovery for Error Diagnostics of Children's ASR
Authors: Vishwanath Pratap Singh, Md. Sahidullah, Tomi Kinnunen
Abstract: Children's automatic speech recognition (ASR) often underperforms compared to that of adults due to a confluence of interdependent factors: physiological (e.g., smaller vocal tracts), cognitive (e.g., underdeveloped pronunciation), and extrinsic (e.g., vocabulary limitations, background noise). Existing analysis methods examine the impact of these factors in isolation, neglecting interdependencies-such as age affecting ASR accuracy both directly and indirectly via pronunciation skills. In this paper, we introduce a causal structure discovery to unravel these interdependent relationships among physiology, cognition, extrinsic factors, and ASR errors. Then, we employ causal quantification to measure each factor's impact on children's ASR. We extend the analysis to fine-tuned models to identify which factors are mitigated by fine-tuning and which remain largely unaffected. Experiments on Whisper and Wav2Vec2.0 demonstrate the generalizability of our findings across different ASR systems.

Paper number 110:
Title: Latent Wavelet Diffusion: Enabling 4K Image Synthesis for Free
Authors: Luigi Sigillo, Shengfeng He, Danilo Comminiello
Abstract: High-resolution image synthesis remains a core challenge in generative modeling, particularly in balancing computational efficiency with the preservation of fine-grained visual detail. We present Latent Wavelet Diffusion (LWD), a lightweight framework that enables any latent diffusion model to scale to ultra-high-resolution image generation (2K to 4K) for free. LWD introduces three key components: (1) a scale-consistent variational autoencoder objective that enhances the spectral fidelity of latent representations; (2) wavelet energy maps that identify and localize detail-rich spatial regions within the latent space; and (3) a time-dependent masking strategy that focuses denoising supervision on high-frequency components during training. LWD requires no architectural modifications and incurs no additional computational overhead. Despite its simplicity, it consistently improves perceptual quality and reduces FID in ultra-high-resolution image synthesis, outperforming strong baseline models. These results highlight the effectiveness of frequency-aware, signal-driven supervision as a principled and efficient approach for high-resolution generative modeling.

Paper number 111:
Title: XMAD-Bench: Cross-Domain Multilingual Audio Deepfake Benchmark
Authors: Ioan-Paul Ciobanu, Andrei-Iulian Hiji, Nicolae-Catalin Ristea, Paul Irofti, Cristian Rusu, Radu Tudor Ionescu
Abstract: Recent advances in audio generation led to an increasing number of deepfakes, making the general public more vulnerable to financial scams, identity theft, and misinformation. Audio deepfake detectors promise to alleviate this issue, with many recent studies reporting accuracy rates close to 99%. However, these methods are typically tested in an in-domain setup, where the deepfake samples from the training and test sets are produced by the same generative models. To this end, we introduce XMAD-Bench, a large-scale cross-domain multilingual audio deepfake benchmark comprising 668.8 hours of real and deepfake speech. In our novel dataset, the speakers, the generative methods, and the real audio sources are distinct across training and test splits. This leads to a challenging cross-domain evaluation setup, where audio deepfake detectors can be tested ``in the wild''. Our in-domain and cross-domain experiments indicate a clear disparity between the in-domain performance of deepfake detectors, which is usually as high as 100%, and the cross-domain performance of the same models, which is sometimes similar to random chance. Our benchmark highlights the need for the development of robust audio deepfake detectors, which maintain their generalization capacity across different languages, speakers, generative methods, and data sources. Our benchmark is publicly released at this https URL.

Paper number 112:
Title: Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study
Authors: Diogo Landau, Ingeborg de Pater, Mihaela Mitici, Nishant Saurabh
Abstract: Complex systems such as aircraft engines are continuously monitored by sensors. In predictive aircraft maintenance, the collected sensor measurements are used to estimate the health condition and the Remaining Useful Life (RUL) of such systems. However, a major challenge when developing prognostics is the limited number of run-to-failure data samples. This challenge could be overcome if multiple airlines would share their run-to-failure data samples such that sufficient learning can be achieved. Due to privacy concerns, however, airlines are reluctant to share their data in a centralized setting. In this paper, a collaborative federated learning framework is therefore developed instead. Here, several airlines cooperate to train a collective RUL prognostic machine learning model, without the need to centrally share their data. For this, a decentralized validation procedure is proposed to validate the prognostics model without sharing any data. Moreover, sensor data is often noisy and of low quality. This paper therefore proposes four novel methods to aggregate the parameters of the global prognostic model. These methods enhance the robustness of the FL framework against noisy data. The proposed framework is illustrated for training a collaborative RUL prognostic model for aircraft engines, using the N-CMAPSS dataset. Here, six airlines are considered, that collaborate in the FL framework to train a collective RUL prognostic model for their aircraft's engines. When comparing the proposed FL framework with the case where each airline independently develops their own prognostic model, the results show that FL leads to more accurate RUL prognostics for five out of the six airlines. Moreover, the novel robust aggregation methods render the FL framework robust to noisy data samples.

Paper number 113:
Title: Helmet ultrasound for brain imaging in post-hemicraniectomy patients
Authors: Yang Zhang, Karteekeya Sastry, Iyla Rossi, Joshua Olick-Gibson, Jonathan J. Russin, Charles Y. Liu, Lihong V. Wang
Abstract: Noninvasive imaging deep into the adult brain at submillimeter and millisecond scales remains a challenge in medical imaging. Here, we report a helmet based ultrasound brain imager built from a customized helmet, a scanned ultrasound array, and three dimensional printing for real time imaging of human brain anatomical and functional information. Through its application to post hemicraniectomy patients in a sitting position, we achieved volumetric brain tissue structural, vascular, and blood flow images at centimeter scale depths with submillimeter and millisecond spatiotemporal resolutions. We also demonstrated the system capability to track cerebral blood flow over repeated imaging sessions, including during motion prone conditions. Our brain imager circumvents the skull and bridges the gap between high resolution human brain imaging and wearable convenience. This imager may serve as a platform for further investigations into human brain dynamics in post hemicraniectomy patients and offer insights into the brain that could surpass those obtained from non human primate studies.

Paper number 114:
Title: Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems
Authors: Zakir Hussain Shaik, Sai Subramanyam Thoota, Emil BjÃ¶rnson, Erik G. Larsson
Abstract: We propose a novel resource-efficient over-the-air(OTA) computation framework to address the huge fronthaul computational and control overhead requirements in cell-free massive multiple-input multiple-output (MIMO) networks. We show that the global sufficient statistics to decode the data symbols can be computed OTA using the locally available information at the access points (APs). We provide the essential signal processing aspects at the APs and the central processing unit (CPU) to facilitate the OTA computation of sufficient statistics. The proposed framework scales effectively with an increase in the number of APs. We also make a comprehensive study of the benefits of an OTA framework compared to a conventional digital fronthaul in terms of the overhead associated in transferring the sufficient statistics from the APs to the CPU. To evaluate the performance of the OTA framework, we give closed-form expressions for the mean-square error (MSE)of the estimators of sufficient statistics and the overall data estimator. Furthermore, we assess the symbol error rate (SER)and bit error rate (BER) of the user equipment (UEs) data to demonstrate the efficacy of our method, and benchmark them against the state-of-the-art wired fronthaul networks.

Paper number 115:
Title: Learning to Upsample and Upmix Audio in the Latent Domain
Authors: Dimitrios Bralios, Paris Smaragdis, Jonah Casebeer
Abstract: Neural audio autoencoders create compact latent representations that preserve perceptually important information, serving as the foundation for both modern audio compression systems and generation approaches like next-token prediction and latent diffusion. Despite their prevalence, most audio processing operations, such as spatial and spectral up-sampling, still inefficiently operate on raw waveforms or spectral representations rather than directly on these compressed representations. We propose a framework that performs audio processing operations entirely within an autoencoder's latent space, eliminating the need to decode to raw audio formats. Our approach dramatically simplifies training by operating solely in the latent domain, with a latent L1 reconstruction term, augmented by a single latent adversarial discriminator. This contrasts sharply with raw-audio methods that typically require complex combinations of multi-scale losses and discriminators. Through experiments in bandwidth extension and mono-to-stereo up-mixing, we demonstrate computational efficiency gains of up to 100x while maintaining quality comparable to post-processing on raw audio. This work establishes a more efficient paradigm for audio processing pipelines that already incorporate autoencoders, enabling significantly faster and more resource-efficient workflows across various audio tasks.

Paper number 116:
Title: Adaptive Traffic-Following Scheme for Orderly Distributed Control of Multi-Vehicle Systems
Authors: Anahita Jain, Husni Idris, John-Paul Clarke, Daniel Delahaye
Abstract: We present an adaptive control scheme to enable the emergence of order within distributed, autonomous multi-agent systems. Past studies showed that under high-density conditions, order generated from traffic-following behavior reduces travel times, while under low densities, choosing direct paths is more beneficial. In this paper, we leveraged those findings to allow aircraft to independently and dynamically adjust their degree of traffic-following behavior based on the current state of the airspace. This enables aircraft to follow other traffic only when beneficial. Quantitative analyses revealed that dynamic traffic-following behavior results in lower aircraft travel times at the cost of minimal levels of additional disorder to the airspace. The sensitivity of these benefits to temporal and spatial horizons was also investigated. Overall, this work highlights the benefits, and potential necessity, of incorporating self-organizing behavior in making distributed, autonomous multi-agent systems scalable.

Paper number 117:
Title: Chain-of-Thought Training for Open E2E Spoken Dialogue Systems
Authors: Siddhant Arora, Jinchuan Tian, Hayato Futami, Jee-weon Jung, Jiatong Shi, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe
Abstract: Unlike traditional cascaded pipelines, end-to-end (E2E) spoken dialogue systems preserve full differentiability and capture non-phonemic information, making them well-suited for modeling spoken interactions. However, existing E2E approaches often require large-scale training data and generates responses lacking semantic coherence. We propose a simple yet effective strategy leveraging a chain-of-thought (CoT) formulation, ensuring that training on conversational data remains closely aligned with the multimodal language model (LM)'s pre-training on speech recognition~(ASR), text-to-speech synthesis (TTS), and text LM tasks. Our method achieves over 1.5 ROUGE-1 improvement over the baseline, successfully training spoken dialogue systems on publicly available human-human conversation datasets, while being compute-efficient enough to train on just 300 hours of public human-human conversation data, such as the Switchboard. We will publicly release our models and training code.

Paper number 118:
Title: Length Aware Speech Translation for Video Dubbing
Authors: Harveen Singh Chadha, Aswin Shanmugam Subramanian, Vikas Joshi, Shubham Bansal, Jian Xue, Rupeshkumar Mehta, Jinyu Li
Abstract: In video dubbing, aligning translated audio with the source audio is a significant challenge. Our focus is on achieving this efficiently, tailored for real-time, on-device video dubbing scenarios. We developed a phoneme-based end-to-end length-sensitive speech translation (LSST) model, which generates translations of varying lengths short, normal, and long using predefined tags. Additionally, we introduced length-aware beam search (LABS), an efficient approach to generate translations of different lengths in a single decoding pass. This approach maintained comparable BLEU scores compared to a baseline without length awareness while significantly enhancing synchronization quality between source and target audio, achieving a mean opinion score (MOS) gain of 0.34 for Spanish and 0.65 for Korean, respectively.

Paper number 119:
Title: Action Dependency Graphs for Globally Optimal Coordinated Reinforcement Learning
Authors: Jianglin Ding, Jingcheng Tang, Gangshan Jing
Abstract: Action-dependent individual policies, which incorporate both environmental states and the actions of other agents in decision-making, have emerged as a promising paradigm for achieving global optimality in multi-agent reinforcement learning (MARL). However, the existing literature often adopts auto-regressive action-dependent policies, where each agent's policy depends on the actions of all preceding agents. This formulation incurs substantial computational complexity as the number of agents increases, thereby limiting scalability. In this work, we consider a more generalized class of action-dependent policies, which do not necessarily follow the auto-regressive form. We propose to use the `action dependency graph (ADG)' to model the inter-agent action dependencies. Within the context of MARL problems structured by coordination graphs, we prove that an action-dependent policy with a sparse ADG can achieve global optimality, provided the ADG satisfies specific conditions specified by the coordination graph. Building on this theoretical foundation, we develop a tabular policy iteration algorithm with guaranteed global optimality. Furthermore, we integrate our framework into several SOTA algorithms and conduct experiments in complex environments. The empirical results affirm the robustness and applicability of our approach in more general scenarios, underscoring its potential for broader MARL challenges.

Paper number 120:
Title: Three-Dimensional Channel Modeling for Molecular Communications in Tubular Environments with Heterogeneous Boundary Conditions
Authors: Yun-Feng Lo, Changmin Lee, Chan-Byoung Chae
Abstract: Molecular communication (MC), one of the emerging techniques in the field of communication, is entering a new phase following several decades of foundational research. Recently, attention has shifted toward MC in liquid media, particularly within tubular environments, due to novel application scenarios. The spatial constraints of such environments make accurate modeling of molecular movement in tubes more challenging than in traditional free-space channels. In this paper, we propose a three-dimensional channel model for molecular communications with an absorbing ring-shaped receiver in a tubular environment. To the best of our knowledge, this is the first theoretical study to model the impact of an absorbing ring-shaped receiver on the channel response in tube-based MC systems. The problem is formulated as a partial differential equation with heterogeneous boundary conditions, and an approximate solution is derived under flow-dominated conditions. The accuracy of the proposed model is validated through particle-based simulations. We anticipate that the results of this study will contribute to the design of practical MC systems in real-world tubular environments.

Paper number 121:
Title: FUSE: Universal Speech Enhancement using Multi-Stage Fusion of Sparse Compression and Token Generation Models for the URGENT 2025 Challenge
Authors: Nabarun Goswami, Tatsuya Harada
Abstract: We propose a multi-stage framework for universal speech enhancement, designed for the Interspeech 2025 URGENT Challenge. Our system first employs a Sparse Compression Network to robustly separate sources and extract an initial clean speech estimate from noisy inputs. This is followed by an efficient generative model that refines speech quality by leveraging self-supervised features and optimizing a masked language modeling objective on acoustic tokens derived from a neural audio codec. In the final stage, a fusion network integrates the outputs of the first two stages with the original noisy signal, achieving a balanced improvement in both signal fidelity and perceptual quality. Additionally, a shift trick that aggregates multiple time-shifted predictions, along with output blending, further boosts performance. Experimental results on challenging multilingual datasets with variable sampling rates and diverse distortion types validate the effectiveness of our approach.

Paper number 122:
Title: Counterfactual Activation Editing for Post-hoc Prosody and Mispronunciation Correction in TTS Models
Authors: Kyowoon Lee, Artyom Stitsyuk, Gunu Jho, Inchul Hwang, Jaesik Choi
Abstract: Recent advances in Text-to-Speech (TTS) have significantly improved speech naturalness, increasing the demand for precise prosody control and mispronunciation correction. Existing approaches for prosody manipulation often depend on specialized modules or additional training, limiting their capacity for post-hoc adjustments. Similarly, traditional mispronunciation correction relies on grapheme-to-phoneme dictionaries, making it less practical in low-resource settings. We introduce Counterfactual Activation Editing, a model-agnostic method that manipulates internal representations in a pre-trained TTS model to achieve post-hoc control of prosody and pronunciation. Experimental results show that our method effectively adjusts prosodic features and corrects mispronunciations while preserving synthesis quality. This opens the door to inference-time refinement of TTS outputs without retraining, bridging the gap between pre-trained TTS models and editable speech synthesis.

Paper number 123:
Title: Speech Unlearning
Authors: Jiali Cheng, Hadi Amiri
Abstract: We introduce machine unlearning for speech tasks, a novel and underexplored research problem that aims to efficiently and effectively remove the influence of specific data from trained speech models without full retraining. This has important applications in privacy preservation, removal of outdated or noisy data, and bias mitigation. While machine unlearning has been studied in computer vision and natural language processing, its application to speech is largely unexplored due to the high-dimensional, sequential, and speaker-dependent nature of speech data. We define two fundamental speech unlearning tasks: sample unlearning, which removes individual data points (e.g., a voice recording), and class unlearning, which removes an entire category (e.g., all data from a speaker), while preserving performance on the remaining data. Experiments on keyword spotting and speaker identification demonstrate that unlearning speech data is significantly more challenging than unlearning image or text data. We conclude with key future directions in this area, including structured training, robust evaluation, feature-level unlearning, broader applications, scalable methods, and adversarial robustness.

Paper number 124:
Title: Fine-Tuning ASR for Stuttered Speech: Personalized vs. Generalized Approaches
Authors: Dena Mujtaba, Nihar Mahapatra
Abstract: Stuttering -- characterized by involuntary disfluencies such as blocks, prolongations, and repetitions -- is often misinterpreted by automatic speech recognition (ASR) systems, resulting in elevated word error rates and making voice-driven technologies inaccessible to people who stutter. The variability of disfluencies across speakers and contexts further complicates ASR training, compounded by limited annotated stuttered speech data. In this paper, we investigate fine-tuning ASRs for stuttered speech, comparing generalized models (trained across multiple speakers) to personalized models tailored to individual speech characteristics. Using a diverse range of voice-AI scenarios, including virtual assistants and video interviews, we evaluate how personalization affects transcription accuracy. Our findings show that personalized ASRs significantly reduce word error rates, especially in spontaneous speech, highlighting the potential of tailored models for more inclusive voice technologies.

Paper number 125:
Title: CoVoMix2: Advancing Zero-Shot Dialogue Generation with Fully Non-Autoregressive Flow Matching
Authors: Leying Zhang, Yao Qian, Xiaofei Wang, Manthan Thakker, Dongmei Wang, Jianwei Yu, Haibin Wu, Yuxuan Hu, Jinyu Li, Yanmin Qian, Sheng Zhao
Abstract: Generating natural-sounding, multi-speaker dialogue is crucial for applications such as podcast creation, virtual agents, and multimedia content generation. However, existing systems struggle to maintain speaker consistency, model overlapping speech, and synthesize coherent conversations efficiently. In this paper, we introduce CoVoMix2, a fully non-autoregressive framework for zero-shot multi-talker dialogue generation. CoVoMix2 directly predicts mel-spectrograms from multi-stream transcriptions using a flow-matching-based generative model, eliminating the reliance on intermediate token representations. To better capture realistic conversational dynamics, we propose transcription-level speaker disentanglement, sentence-level alignment, and prompt-level random masking strategies. Our approach achieves state-of-the-art performance, outperforming strong baselines like MoonCast and Sesame in speech quality, speaker consistency, and inference speed. Notably, CoVoMix2 operates without requiring transcriptions for the prompt and supports controllable dialogue generation, including overlapping speech and precise timing control, demonstrating strong generalizability to real-world speech generation scenarios.

Paper number 126:
Title: In-the-wild Audio Spatialization with Flexible Text-guided Localization
Authors: Tianrui Pan, Jie Liu, Zewen Huang, Jie Tang, Gangshan Wu
Abstract: To enhance immersive experiences, binaural audio offers spatial awareness of sounding objects in AR, VR, and embodied AI applications. While existing audio spatialization methods can generally map any available monaural audio to binaural audio signals, they often lack the flexible and interactive control needed in complex multi-object user-interactive environments. To address this, we propose a Text-guided Audio Spatialization (TAS) framework that utilizes flexible text prompts and evaluates our model from unified generation and comprehension perspectives. Due to the limited availability of premium and large-scale stereo data, we construct the SpatialTAS dataset, which encompasses 376,000 simulated binaural audio samples to facilitate the training of our model. Our model learns binaural differences guided by 3D spatial location and relative position prompts, augmented by flipped-channel audio. It outperforms existing methods on both simulated and real-recorded datasets, demonstrating superior generalization and accuracy. Besides, we develop an assessment model based on Llama-3.1-8B, which evaluates the spatial semantic coherence between our generated binaural audio and text prompts through a spatial reasoning task. Results demonstrate that text prompts provide flexible and interactive control to generate binaural audio with excellent quality and semantic consistency in spatial locations. Dataset is available at \href{this https URL}

Paper number 127:
Title: General-purpose audio representation learning for real-world sound scenes
Authors: Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden
Abstract: While audio foundation models perform well on myriad of tasks from sound classification to speech analysis, these models are trained and tested on dry, non-spatial, single-source audio clips. This limits their success in real-world situations and results in spatially unaware audio embeddings. To address these limitations, we propose a novel self-supervised training approach for General-Purpose, Real-world Audio Models (GRAMs). The GRAM training approach enables robust spatial audio representation learning for naturalistic, noisy sound scenes and can be applied to any masking-based deep learning model. We demonstrate the success of our approach by training two state-of-the-art models, one with a transformer and one with a mamba backbone. We assess the quality of the extracted audio representations from GRAMs using the original version of the HEAR benchmark, a newly synthesized, naturalistic version of the HEAR benchmark, and novel sound localization tasks based on HEAR benchmark datasets. The results show that our approach minimizes the performance gap between dry, non-spatial, single-source sound scenes and naturalistic sound scenes for crucial tasks such as auditory scene analysis, outperforming existing state-of-the-art audio foundation models at a fraction of the training steps. Moreover, GRAMs show state-of-the-art performance on sound localization tasks, exceeding even supervised sound localization models. In sum, the proposed approach represents a significant advancement towards robust audio foundation models for real-world applications with state-of-the-art performance on naturalistic sound scenes as well as spatial audio representation learning.

Paper number 128:
Title: anyECG-chat: A Generalist ECG-MLLM for Flexible ECG Input and Multi-Task Understanding
Authors: Haitao Li, Ziyu Li, Yiheng Mao, Ziyi Liu, Zhoujian Sun, Zhengxing Huang
Abstract: The advent of multimodal large language models (MLLMs) has sparked interest in their application to electrocardiogram (ECG) analysis. However, existing ECG-focused MLLMs primarily focus on report generation tasks, often limited to single 12-lead, short-duration (10s) ECG inputs, thereby underutilizing the potential of MLLMs. To this end, we aim to develop a MLLM for ECG analysis that supports a broader range of tasks and more flexible ECG inputs. However, existing ECG-QA datasets are often monotonous. To address this gap, we first constructed the anyECG dataset, which encompasses a wide variety of tasks, including report generation, abnormal waveform localization, and open-ended question answering. In addition to standard hospital ECGs, we introduced long-duration reduced-lead ECGs for home environments and multiple ECG comparison scenarios commonly encountered in clinical practice. Furthermore, we propose the anyECG-chat model, which supports dynamic-length ECG inputs and multiple ECG inputs. We trained the model using a three-stage curriculum training recipe with the anyECG dataset. A comprehensive evaluation was conducted, demonstrating that anyECG-chat is capable of supporting various practical application scenarios, including not only common report generation tasks but also abnormal waveform localization for long-duration reduced-lead ECGs in home environments and comprehensive comparative analysis of multiple ECGs.

Paper number 129:
Title: NTPP: Generative Speech Language Modeling for Dual-Channel Spoken Dialogue via Next-Token-Pair Prediction
Authors: Qichao Wang, Ziqiao Meng, Wenqian Cui, Yifei Zhang, Pengcheng Wu, Bingzhe Wu, Irwin King, Liang Chen, Peilin Zhao
Abstract: Inspired by the impressive capabilities of GPT-4o, there is growing interest in enabling speech language models (SLMs) to engage in natural, fluid spoken interactions with humans. Recent advancements have led to the development of several SLMs that demonstrate promising results in this area. However, current approaches have yet to fully exploit dual-channel speech data, which inherently captures the structure and dynamics of human conversation. In this work, we systematically explore the use of dual-channel speech data in the context of modern large language models, and introduce a novel generative modeling paradigm, Next-Token-Pair Prediction (NTPP), to enable speaker-independent dual-channel spoken dialogue learning using decoder-only architectures for the first time. We evaluate our approach on standard benchmarks, and empirical results show that our proposed method, NTPP, significantly improves the conversational abilities of SLMs in terms of turn-taking prediction, response coherence, and naturalness. Moreover, compared to existing methods, NTPP achieves substantially lower inference latency, highlighting its practical efficiency for real-time applications.

Paper number 130:
Title: What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training
Authors: Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum
Abstract: How language-specific are speech representations learned by self-supervised models? Existing work has shown that a range of linguistic features can be successfully decoded from end-to-end models trained only on speech recordings. However, it's less clear to what extent pre-training on specific languages improves language-specific linguistic information. Here we test the encoding of Dutch phonetic and lexical information in internal representations of self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the representation of Dutch linguistic features as compared to pre-training on similar amounts of English or larger amounts of multilingual data. This language-specific advantage is well-detected by trained clustering or classification probes, and partially observable using zero-shot metrics. Furthermore, the language-specific benefit on linguistic feature encoding aligns with downstream performance on Automatic Speech Recognition.

Paper number 131:
Title: DS-TTS: Zero-Shot Speaker Style Adaptation from Voice Clips via Dynamic Dual-Style Feature Modulation
Authors: Ming Meng, Ziyi Yang, Jian Yang, Zhenjie Su, Yonggui Zhu, Zhaoxin Fan
Abstract: Recent advancements in text-to-speech (TTS) technology have increased demand for personalized audio synthesis. Zero-shot voice cloning, a specialized TTS task, aims to synthesize a target speaker's voice using only a single audio sample and arbitrary text, without prior exposure to the speaker during training. This process employs pattern recognition techniques to analyze and replicate the speaker's unique vocal features. Despite progress, challenges remain in adapting to the vocal style of unseen speakers, highlighting difficulties in generalizing TTS systems to handle diverse voices while maintaining naturalness, expressiveness, and speaker fidelity. To address the challenges of unseen speaker style adaptation, we propose DS-TTS, a novel approach aimed at enhancing the synthesis of diverse, previously unheard voices. Central to our method is a Dual-Style Encoding Network (DuSEN), where two distinct style encoders capture complementary aspects of a speaker's vocal identity. These speaker-specific style vectors are seamlessly integrated into the Dynamic Generator Network (DyGN) via a Style Gating-Film (SGF) mechanism, enabling more accurate and expressive reproduction of unseen speakers' unique vocal characteristics. In addition, we introduce a Dynamic Generator Network to tackle synthesis issues that arise with varying sentence lengths. By dynamically adapting to the length of the input, this component ensures robust performance across diverse text inputs and speaker styles, significantly improving the model's ability to generalize to unseen speakers in a more natural and expressive manner. Experimental evaluations on the VCTK dataset suggest that DS-TTS demonstrates superior overall performance in voice cloning tasks compared to existing state-of-the-art models, showing notable improvements in both word error rate and speaker similarity.

Paper number 132:
Title: A Two-Stage Hierarchical Deep Filtering Framework for Real-Time Speech Enhancement
Authors: Shenghui Lu, Hukai Huang, Jinanglong Yao, Kaidi Wang, Qingyang Hong, Lin Li
Abstract: This paper proposes a model that integrates sub-band processing and deep filtering to fully exploit information from the target time-frequency (TF) bin and its surrounding TF bins for single-channel speech enhancement. The sub-band module captures surrounding frequency bin information at the input, while the deep filtering module applies filtering at the output to both the target TF bin and its surrounding TF bins. To further improve the model performance, we decouple deep filtering into temporal and frequency components and introduce a two-stage framework, reducing the complexity of filter coefficient prediction at each stage. Additionally, we propose the TAConv module to strengthen convolutional feature extraction. Experimental results demonstrate that the proposed hierarchical deep filtering network (HDF-Net) effectively utilizes surrounding TF bin information and outperforms other advanced systems while using fewer resources.

Paper number 133:
Title: RoboTwin: A Robotic Teleoperation Framework Using Digital Twins
Authors: Harsha Yelchuri, Diwakar Kumar Singh, Nithish Krishnabharathi Gnani, T V Prabhakar, Chandramani Singh
Abstract: Robotic surgery imposes a significant cognitive burden on the surgeon. This cognitive burden increases in the case of remote robotic surgeries due to latency between entities and thus might affect the quality of surgery. Here, the patient side and the surgeon side are geographically separated by hundreds to thousands of kilometres. Real-time teleoperation of robots requires strict latency bounds for control and feedback. We propose a dual digital twin (DT) framework and explain the simulation environment and teleoperation framework. Here, the doctor visually controls the locally available DT of the patient side and thus experiences minimum latency. The second digital twin serves two purposes. Firstly, it provides a layer of safety for operator-related mishaps, and secondly, it conveys the coordinates of known and unknown objects back to the operator's side digital twin. We show that teleoperation accuracy and user experience are enhanced with our approach. Experimental results using the NASA-TLX metric show that the quality of surgery is vastly improved with DT, perhaps due to reduced cognitive burden. The network data rate for identifying objects at the operator side is 25x lower than normal.

Paper number 134:
Title: AEQUAM: Accelerating Quantum Algorithm Validation through FPGA-Based Emulation
Authors: Lorenzo Lagostina, Deborah Volpe, Maurizio Zamboni, Giovanna Turvani
Abstract: This work presents AEQUAM (Area Efficient QUAntum eMulation), a toolchain that enables faster and more accessible quantum circuit verification. It consists of a compiler that translates OpenQASM 2.0 into RISC-like instructions, Cython software models for selecting number representations and simulating circuits, and a VHDL generator that produces RTL descriptions for FPGA-based hardware emulators. The architecture leverages a SIMD approach to parallelize computation and reduces complexity by exploiting the sparsity of quantum gate matrices. The VHDL generator allows customization of the number of emulated qubits and parallelization levels to meet user requirements. Synthesized on an Altera Cyclone 10LP FPGA with a 20-bit fixed-point representation and nearest-type approximation, the architecture demonstrates better scalability than other state-of-the-art emulators. Specifically, the emulator has been validated by exploiting the well consolidated benchmark of mqt bench framework.

Paper number 135:
Title: ReFlow-VC: Zero-shot Voice Conversion Based on Rectified Flow and Speaker Feature Optimization
Authors: Pengyu Ren, Wenhao Guan, Kaidi Wang, Peijie Chen, Qingyang Hong, Lin Li
Abstract: In recent years, diffusion-based generative models have demonstrated remarkable performance in speech conversion, including Denoising Diffusion Probabilistic Models (DDPM) and others. However, the advantages of these models come at the cost of requiring a large number of sampling steps. This limitation hinders their practical application in real-world scenarios. In this paper, we introduce ReFlow-VC, a novel high-fidelity speech conversion method based on rectified flow. Specifically, ReFlow-VC is an Ordinary Differential Equation (ODE) model that transforms a Gaussian distribution to the true Mel-spectrogram distribution along the most direct path. Furthermore, we propose a modeling approach that optimizes speaker features by utilizing both content and pitch information, allowing speaker features to reflect the properties of the current speech more accurately. Experimental results show that ReFlow-VC performs exceptionally well in small datasets and zero-shot scenarios.

Paper number 136:
Title: Generative diffusion posterior sampling for informative likelihoods
Authors: Zheng Zhao
Abstract: Sequential Monte Carlo (SMC) methods have recently shown successful results for conditional sampling of generative diffusion models. In this paper we propose a new diffusion posterior SMC sampler achieving improved statistical efficiencies, particularly under outlier conditions or highly informative likelihoods. The key idea is to construct an observation path that correlates with the diffusion model and to design the sampler to leverage this correlation for more efficient sampling. Empirical results conclude the efficiency.

Paper number 137:
Title: FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion
Authors: Shunian Chen, Xinyuan Xie, Zheshu Chen, Liyan Zhao, Owen Lee, Zhan Su, Qilin Sun, Benyou Wang
Abstract: High-quality, large-scale audio captioning is crucial for advancing audio understanding, yet current automated methods often generate captions that lack fine-grained detail and contextual accuracy, primarily due to their reliance on limited unimodal or superficial multimodal information. Drawing inspiration from human auditory perception, which adeptly integrates cross-modal cues and performs sophisticated auditory scene analysis, we introduce a novel two-stage automated pipeline. This pipeline first employs specialized pretrained models to extract diverse contextual cues (e.g., speech, music, general sounds, and visual information from associated video). A large language model (LLM) then synthesizes these rich, multimodal inputs to generate detailed and context-aware audio captions. Key contributions of this work include: (1) the proposed scalable method for fine-grained audio caption generation; (2) FusionAudio, a new large-scale dataset comprising 1.2 million such detailed captions, combined with 6 million QA pairs; and (3) enhanced audio models developed using FusionAudio, specifically a CLAP-based audio encoder with superior audio-text alignment and instruction following. This paper paves the way for more nuanced and accurate automated understanding of complex audio environments. Code and data can be found in this https URL.

Paper number 138:
Title: Comparative Evaluation of Acoustic Feature Extraction Tools for Clinical Speech Analysis
Authors: Anna Seo Gyeong Choi, Alexander Richardson, Ryan Partlan, Sunny Tang, Sunghye Cho
Abstract: This study compares three acoustic feature extraction toolkits (OpenSMILE, Praat, and Librosa) applied to clinical speech data from individuals with schizophrenia spectrum disorders (SSD) and healthy controls (HC). By standardizing extraction parameters across the toolkits, we analyzed speech samples from 77 SSD and 87 HC participants and found significant toolkit-dependent variations. While F0 percentiles showed high cross-toolkit correlation (r=0.962 to 0.999), measures like F0 standard deviation and formant values often had poor, even negative, agreement. Additionally, correlation patterns differed between SSD and HC groups. Classification analysis identified F0 mean, HNR, and MFCC1 (AUC greater than 0.70) as promising discriminators. These findings underscore reproducibility concerns and advocate for standardized protocols, multi-toolkit cross-validation, and transparent reporting.

Paper number 139:
Title: From Words to Waves: Analyzing Concept Formation in Speech and Text-Based Foundation Models
Authors: AsÄ±m Ersoy, Basel Mousi, Shammur Chowdhury, Firoj Alam, Fahim Dalvi, Nadir Durrani
Abstract: The emergence of large language models (LLMs) has demonstrated that systems trained solely on text can acquire extensive world knowledge, develop reasoning capabilities, and internalize abstract semantic concepts--showcasing properties that can be associated with general intelligence. This raises an intriguing question: Do such concepts emerge in models trained on other modalities, such as speech? Furthermore, when models are trained jointly on multiple modalities: Do they develop a richer, more structured semantic understanding? To explore this, we analyze the conceptual structures learned by speech and textual models both individually and jointly. We employ Latent Concept Analysis, an unsupervised method for uncovering and interpreting latent representations in neural networks, to examine how semantic abstractions form across modalities. For reproducibility we made scripts and other resources available to the community.

Paper number 140:
Title: Mispronunciation Detection Without L2 Pronunciation Dataset in Low-Resource Setting: A Case Study in Finland Swedish
Authors: Nhan Phan, Mikko Kuronen, Maria Kautonen, Riikka Ullakonoja, Anna von Zansen, Yaroslav Getman, Ekaterina Voskoboinik, TamÃ¡s GrÃ³sz, Mikko Kurimo
Abstract: Mispronunciation detection (MD) models are the cornerstones of many language learning applications. Unfortunately, most systems are built for English and other major languages, while low-resourced language varieties, such as Finland Swedish (FS), lack such tools. In this paper, we introduce our MD model for FS, trained on 89 hours of first language (L1) speakers' spontaneous speech and tested on 33 minutes of L2 transcribed read-aloud speech. We trained a multilingual wav2vec 2.0 model with entropy regularization, followed by temperature scaling and top-k normalization after the inference to better adapt it for MD. The main novelty of our method lies in its simplicity, requiring minimal L2 data. The process is also language-independent, making it suitable for other low-resource languages. Our proposed algorithm allows us to balance Recall (43.2%) and Precision (29.8%), compared with the baseline model's Recall (77.5%) and Precision (17.6%).

Paper number 141:
Title: The Fastest Known First-Order Method for Minimizing Twice Continuously Differentiable Smooth Strongly Convex Functions
Authors: Bryan Van Scoy, Laurent Lessard
Abstract: We consider iterative gradient-based optimization algorithms applied to functions that are smooth and strongly convex. The fastest globally convergent algorithm for this class of functions is the Triple Momentum (TM) method. We show that if the objective function is also twice continuously differentiable, a new, faster algorithm emerges, which we call $C^2$-Momentum (C2M). We prove that C2M is globally convergent and that its worst-case convergence rate is strictly faster than that of TM, with no additional computational cost. We validate our theoretical findings with numerical examples, demonstrating that C2M outperforms TM when the objective function is twice continuously differentiable.

Paper number 142:
Title: Iola Walker: A Mobile Footfall Detection System for Music Composition
Authors: Will James
Abstract: This project is the first of several experiments composing music that changes in response to biosignals. The system is dubbed "iola walker" in reference to a common polyrhythm, the hemiola. A listener goes for a walk, and the Iola Walker app detects their walking pace. Iola Walker picks up footfalls using a foot-mounted accelerometer, processing the signals in real time using a recurrent neural network in an Android app. The Android app outputs a MIDI event for each footfall. The iola walker player, which might be a VST running in a DAW, plays the version of the next music passage with underlying polyrhythms closest to the listener's walking pace. This paper documents the process of training the model to detect the footfalls in real time. The model is trained on accelerometer data from an Mbient Labs foot-mounted IMU at 200~Hz, with the ground truth for footfalls annotated by pressing the volume-up button on the Android device when the foot hits the ground. To collect training data, I walked around my neighborhood clicking the volume-up button each time my foot hit the ground. Several methods were tried for detecting footfalls in real time from sensor data, including ones based on digital signal processing techniques and traditional machine learning techniques.

Paper number 143:
Title: On the Stability of Graph Convolutional Neural Networks: A Probabilistic Perspective
Authors: Ning Zhang, Henry Kenlay, Li Zhang, Mihai Cucuringu, Xiaowen Dong
Abstract: Graph convolutional neural networks (GCNNs) have emerged as powerful tools for analyzing graph-structured data, achieving remarkable success across diverse applications. However, the theoretical understanding of the stability of these models, i.e., their sensitivity to small changes in the graph structure, remains in rather limited settings, hampering the development and deployment of robust and trustworthy models in practice. To fill this gap, we study how perturbations in the graph topology affect GCNN outputs and propose a novel formulation for analyzing model stability. Unlike prior studies that focus only on worst-case perturbations, our distribution-aware formulation characterizes output perturbations across a broad range of input data. This way, our framework enables, for the first time, a probabilistic perspective on the interplay between the statistical properties of the node data and perturbations in the graph topology. We conduct extensive experiments to validate our theoretical findings and demonstrate their benefits over existing baselines, in terms of both representation stability and adversarial attacks on downstream tasks. Our results demonstrate the practical significance of the proposed formulation and highlight the importance of incorporating data distribution into stability analysis.

Paper number 144:
Title: WCTC-Biasing: Retraining-free Contextual Biasing ASR with Wildcard CTC-based Keyword Spotting and Inter-layer Biasing
Authors: Yu Nakagome, Michael Hentschel
Abstract: Despite recent advances in end-to-end speech recognition methods, the output tends to be biased to the training data's vocabulary, resulting in inaccurate recognition of proper nouns and other unknown terms. To address this issue, we propose a method to improve recognition accuracy of such rare words in CTC-based models without additional training or text-to-speech systems. Specifically, keyword spotting is performed using acoustic features of intermediate layers during inference, and a bias is applied to the subsequent layers of the acoustic model for detected keywords. For keyword detection, we adopt a wildcard CTC that is both fast and tolerant of ambiguous matches, allowing flexible handling of words that are difficult to match strictly. Since this method does not require retraining of existing models, it can be easily applied to even large-scale models. In experiments on Japanese speech recognition, the proposed method achieved a 29% improvement in the F1 score for unknown words.

Paper number 145:
Title: Learning Sparsity for Effective and Efficient Music Performance Question Answering
Authors: Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui
Abstract: Music performances, characterized by dense and continuous audio as well as seamless audio-visual integration, present unique challenges for multimodal scene understanding and reasoning. Recent Music Performance Audio-Visual Question Answering (Music AVQA) datasets have been proposed to reflect these challenges, highlighting the continued need for more effective integration of audio-visual representations in complex question answering. However, existing Music AVQA methods often rely on dense and unoptimized representations, leading to inefficiencies in the isolation of key information, the reduction of redundancy, and the prioritization of critical samples. To address these challenges, we introduce Sparsify, a sparse learning framework specifically designed for Music AVQA. It integrates three sparsification strategies into an end-to-end pipeline and achieves state-of-the-art performance on the Music AVQA datasets. In addition, it reduces training time by 28.32% compared to its fully trained dense counterpart while maintaining accuracy, demonstrating clear efficiency gains. To further improve data efficiency, we propose a key-subset selection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0 training data and retains 70-80% of full-data performance across models.

Paper number 146:
Title: Zero-Shot Text-to-Speech for Vietnamese
Authors: Thi Vu, Linh The Nguyen, Dat Quoc Nguyen
Abstract: This paper introduces PhoAudiobook, a newly curated dataset comprising 941 hours of high-quality audio for Vietnamese text-to-speech. Using PhoAudiobook, we conduct experiments on three leading zero-shot TTS models: VALL-E, VoiceCraft, and XTTS-V2. Our findings demonstrate that PhoAudiobook consistently enhances model performance across various metrics. Moreover, VALL-E and VoiceCraft exhibit superior performance in synthesizing short sentences, highlighting their robustness in handling diverse linguistic contexts. We publicly release PhoAudiobook to facilitate further research and development in Vietnamese text-to-speech.

Paper number 147:
Title: Two-Stage Learning of Stabilizing Neural Controllers via Zubov Sampling and Iterative Domain Expansion
Authors: Haoyu Li, Xiangru Zhong, Bin Hu, Huan Zhang
Abstract: Learning-based neural network (NN) control policies have shown impressive empirical performance. However, obtaining stability guarantees and estimations of the region of attraction of these learned neural controllers is challenging due to the lack of stable and scalable training and verification algorithms. Although previous works in this area have achieved great success, much conservatism remains in their framework. In this work, we propose a novel two-stage training framework to jointly synthesize the controller and Lyapunov function for continuous-time systems. By leveraging a Zubov-inspired region of attraction characterization to directly estimate stability boundaries, we propose a novel training data sampling strategy and a domain updating mechanism that significantly reduces the conservatism in training. Moreover, unlike existing works on continuous-time systems that rely on an SMT solver to formally verify the Lyapunov condition, we extend state-of-the-art neural network verifier $\alpha,\!\beta$-CROWN with the capability of performing automatic bound propagation through the Jacobian of dynamical systems and a novel verification scheme that avoids expensive bisection. To demonstrate the effectiveness of our approach, we conduct numerical experiments by synthesizing and verifying controllers on several challenging nonlinear systems across multiple dimensions. We show that our training can yield region of attractions with volume $5 - 1.5\cdot 10^{5}$ times larger compared to the baselines, and our verification on continuous systems can be up to $40-10000$ times faster compared to the traditional SMT solver dReal. Our code is available at this https URL.

Paper number 148:
Title: Quantitative Error Feedback for Quantization Noise Reduction of Filtering over Graphs
Authors: Xue Xian Zheng, Weihang Liu, Xin Lou, Stefan Vlaski, Tareq Al-Naffouri
Abstract: This paper introduces an innovative error feedback framework designed to mitigate quantization noise in distributed graph filtering, where communications are constrained to quantized messages. It comes from error spectrum shaping techniques from state-space digital filters, and therefore establishes connections between quantized filtering processes over different domains. In contrast to existing error compensation methods, our framework quantitatively feeds back the quantization noise for exact compensation. We examine the framework under three key scenarios: (i) deterministic graph filtering, (ii) graph filtering over random graphs, and (iii) graph filtering with random node-asynchronous updates. Rigorous theoretical analysis demonstrates that the proposed framework significantly reduces the effect of quantization noise, and we provide closed-form solutions for the optimal error feedback coefficients. Moreover, this quantitative error feedback mechanism can be seamlessly integrated into communication-efficient decentralized optimization frameworks, enabling lower error floors. Numerical experiments validate the theoretical results, consistently showing that our method outperforms conventional quantization strategies in terms of both accuracy and robustness.

Paper number 149:
Title: Whale: Large-Scale multilingual ASR model with w2v-BERT and E-Branchformer with large speech data
Authors: Yosuke Kashiwagi, Hayato Futami, Emiru Tsunoo, Satoshi Asakawa
Abstract: This paper reports on the development of a large-scale speech recognition model, Whale. Similar to models such as Whisper and OWSM, Whale leverages both a large model size and a diverse, extensive dataset. Whale's architecture integrates w2v-BERT self-supervised model, an encoder-decoder backbone built on E-Branchformer, and a joint CTC-attention decoding strategy. The training corpus comprises varied speech data, of not only public corpora but also in-house data, thereby enhancing the model's robustness to different speaking styles and acoustic conditions. Through evaluations on multiple benchmarks, Whale achieved comparable performance to existing models. In particular, it achieves a word error rate of 2.4% on the Librispeech test-clean set and a character error rate of 3.4% on the CSJ eval3 set, outperforming Whisper large-v3 and OWSM v3.1.

Paper number 150:
Title: Universal Preference-Score-based Pairwise Speech Quality Assessment
Authors: Yu-Fei Shi, Yang Ai, Zhen-Hua Ling
Abstract: To compare the performance of two speech generation sys- tems, one of the most effective approaches is estimating the preference score between their generated speech. This pa- per proposes a novel universal preference-score-based pairwise speech quality assessment (UPPSQA) model, aimed at predict- ing the preference score between paired speech samples to de- termine which one has better quality. The model first predicts the absolute mean opinion score (MOS) for the two speech sam- ples separately, and then aggregates them into a relative prefer- ence score using a preference function. To address the scarcity of preference data, we also construct a new pairwise speech dataset based on a MOS dataset for experiments. Experimental results confirm that, whether in training scenarios with differ- ent data types and label conditions, or in both in-domain and out-of-domain test scenarios, the prediction accuracy of UPP- SQA outperforms that of the baseline models, demonstrating its universality.

Paper number 151:
Title: TalTech Systems for the Interspeech 2025 ML-SUPERB 2.0 Challenge
Authors: Tanel AlumÃ¤e, Artem Fedorchenko
Abstract: This paper describes the language identification and multilingual speech recognition system developed at Tallinn University of Technology for the Interspeech 2025 ML-SUPERB 2.0 Challenge. A hybrid language identification system is used, consisting of a pretrained language embedding model and a light-weight speech recognition model with a shared encoder across languages and language-specific bigram language models. For speech recognition, three models are used, where only a single model is applied for each language, depending on the training data availability and performance on held-out data. The model set consists of a finetuned version of SeamlessM4T, MMS-1B-all with custom language adapters and MMS-zeroshot. The system obtained the top overall score in the challenge.

Paper number 152:
Title: Few-step Adversarial SchrÃ¶dinger Bridge for Generative Speech Enhancement
Authors: Seungu Han, Sungho Lee, Juheon Lee, Kyogu Lee
Abstract: Deep generative models have recently been employed for speech enhancement to generate perceptually valid clean speech on large-scale datasets. Several diffusion models have been proposed, and more recently, a tractable SchrÃ¶dinger Bridge has been introduced to transport between the clean and noisy speech distributions. However, these models often suffer from an iterative reverse process and require a large number of sampling steps -- more than 50. Our investigation reveals that the performance of baseline models significantly degrades when the number of sampling steps is reduced, particularly under low-SNR conditions. We propose integrating SchrÃ¶dinger Bridge with GANs to effectively mitigate this issue, achieving high-quality outputs on full-band datasets while substantially reducing the required sampling steps. Experimental results demonstrate that our proposed model outperforms existing baselines, even with a single inference step, in both denoising and dereverberation tasks.

Paper number 153:
Title: A State of the Art on Recent Progress and Emerging Challenges on Energy Transfer Between Vibrating Modes Under an External Mechanical Force With Time-Varying Frequency From 2020 to 2025
Authors: Jose Manoel Balthazar, Jorge Luis Palacios Felix, Mauricio A. Ribeiro, Angelo Marcelo Tusset, Jeferson Jose de Lima, Vinicius Piccirillo, Julijana Simonovic, Nikola D. Nevsic, Marcos Varanis, Clivaldo de Oliveira, Raphaela C. Machado, Gabriella O M Oliveira
Abstract: In this paper, we discuss an example of current importance with a future perspective in engineering, in which excitation sources always have limited power, limited inertia, and their frequencies vary according to the instantaneous state of the vibrating system. Practical examples of non-ideal systems are considered. The most common phenomenon for this kind of system is discussed. The period considered is from 2020 to 2025. The specific properties of various models are also discussed. Directions for future investigations are provided. In this paper, the authors revisited some publications based on the assumption that the external excitations are produced by non-ideal sources (RNIS), that is, with limited power supply. Among these applications, nonlinear phenomena such as the Sommerfeld effect and saturation phenomenon were observed, considering fractional damping. Energy harvesters and the Jacobi-Anger expansion were used in the governing equations of motion. We also used the Jacobi-Anger expansion in the case of energy transfer between vibrating modes under an external force with time-varying frequency, which represents one of the future directions of research on non-ideal vibrating systems (RNIS).

Paper number 154:
Title: Automatic Stage Lighting Control: Is it a Rule-Driven Process or Generative Task?
Authors: Zijian Zhao, Dian Jin, Zijing Zhou, Xiaoyu Zhang
Abstract: Stage lighting plays an essential role in live music performances, influencing the engaging experience of both musicians and audiences. Given the high costs associated with hiring or training professional lighting engineers, Automatic Stage Lighting Control (ASLC) has gained increasing attention. However, most existing approaches only classify music into limited categories and map them to predefined light patterns, resulting in formulaic and monotonous outcomes that lack rationality. To address this issue, this paper presents an end-to-end solution that directly learns from experienced lighting engineers -- Skip-BART. To the best of our knowledge, this is the first work to conceptualize ASLC as a generative task rather than merely a classification problem. Our method modifies the BART model to take audio music as input and produce light hue and value (intensity) as output, incorporating a novel skip connection mechanism to enhance the relationship between music and light within the frame this http URL validate our method through both quantitative analysis and an human evaluation, demonstrating that Skip-BART outperforms conventional rule-based methods across all evaluation metrics and shows only a limited gap compared to real lighting this http URL, our method yields a p-value of 0.72 in a statistical comparison based on human evaluations with human lighting engineers, suggesting that the proposed approach closely matches human lighting engineering performance. To support further research, we have made our self-collected dataset, code, and trained model parameters available at this https URL .

Paper number 155:
Title: Continual Speech Learning with Fused Speech Features
Authors: Guitao Wang, Jinming Zhao, Hao Yang, Guilin Qi, Tongtong Wu, Gholamreza Haffari
Abstract: Rapid growth in speech data demands adaptive models, as traditional static methods fail to keep pace with dynamic and diverse speech information. We introduce continuous speech learning, a new set-up targeting at bridging the adaptation gap in current speech models. We use the encoder-decoder Whisper model to standardize speech tasks into a generative format. We integrate a learnable gated-fusion layer on the top of the encoder to dynamically select task-specific features for downstream tasks. Our approach improves accuracy significantly over traditional methods in six speech processing tasks, demonstrating gains in adapting to new speech tasks without full retraining.

Paper number 156:
Title: Learning Perceptually Relevant Temporal Envelope Morphing
Authors: Satvik Dixit, Sungjoon Park, Chris Donahue, Laurie M. Heller
Abstract: Temporal envelope morphing, the process of interpolating between the amplitude dynamics of two audio signals, is an emerging problem in generative audio systems that lacks sufficient perceptual grounding. Morphing of temporal envelopes in a perceptually intuitive manner should enable new methods for sound blending in creative media and for probing perceptual organization in psychoacoustics. However, existing audio morphing techniques often fail to produce intermediate temporal envelopes when input sounds have distinct temporal structures; many morphers effectively overlay both temporal structures, leading to perceptually unnatural results. In this paper, we introduce a novel workflow for learning envelope morphing with perceptual guidance: we first derive perceptually grounded morphing principles through human listening studies, then synthesize large-scale datasets encoding these principles, and finally train machine learning models to create perceptually intermediate morphs. Specifically, we present: (1) perceptual principles that guide envelope morphing, derived from our listening studies, (2) a supervised framework to learn these principles, (3) an autoencoder that learns to compress temporal envelope structures into latent representations, and (4) benchmarks for evaluating audio envelope morphs, using both synthetic and naturalistic data, and show that our approach outperforms existing methods in producing temporally intermediate morphs. All code, models, and datasets will be made publicly available upon publication.

Paper number 157:
Title: The Promise of Spiking Neural Networks for Ubiquitous Computing: A Survey and New Perspectives
Authors: Hemanth Sabbella, Archit Mukherjee, Thivya Kandappu, Sounak Dey, Arpan Pal, Archan Misra, Dong Ma
Abstract: Spiking neural networks (SNNs) have emerged as a class of bio -inspired networks that leverage sparse, event- driven signaling to achieve low-power computation while inherently modeling temporal dynamics. Such characteristics align closely with the demands of ubiquitous computing systems, which often operate on resource- constrained devices while continuously monitoring and processing time - series sensor data. Despite their unique and promising features, SNNs have received limited attention and remain underexplored (or at least, under-adopted) within the ubiquitous computing community. To address this gap, this paper first introduces the core components of SNNs, both in terms of models and training mechanisms. It then presents a systematic survey of 76 SNN-based studies focused on time-series data analysis, categorizing them into six key application domains. For each domain, we summarize relevant works and subsequent advancements, distill core insights, and highlight key takeaways for researchers and practitioners. To facilitate hands-on experimentation, we also provide a comprehensive review of current software frameworks and neuromorphic hardware platforms, detailing their capabilities and specifications, and then offering tailored recommendations for selecting development tools based on specific application needs. Finally, we identify prevailing challenges within each application domain and propose future research directions that need be explored in ubiquitous community. Our survey highlights the transformative potential of SNNs in enabling energy-efficient ubiquitous sensing across diverse application domains, while also serving as an essential introduction for researchers looking to enter this emerging field.

Paper number 158:
Title: Practical Short-Length Coding Schemes for Binary Distributed Hypothesis Testing
Authors: Ismaila Salihou Adamou, Elsa Dupraz, Reza Asvadi, Tad Matsumoto
Abstract: This paper addresses the design of practical shortlength coding schemes for Distributed Hypothesis Testing (DHT). While most prior work on DHT has focused on informationtheoretic analyses, deriving bounds on Type-II error exponents via achievability schemes based on quantization and quantizebinning, the practical implementation of DHT coding schemes has remained largely unexplored. Moreover, existing practical coding solutions for quantization and quantize-binning approaches were developed for source reconstruction tasks considering very long code length, and they are not directly applicable to DHT. In this context, this paper introduces efficient shortlength implementations of quantization and quantize-binning schemes for DHT, constructed from short binary linear block codes. Numerical results show the efficiency of the proposed coding schemes compared to uncoded cases and to existing schemes initially developed for data reconstruction. In addition to practical code design, the paper derives exact analytical expressions for the Type-I and Type-II error probabilities associated with each proposed scheme. The provided analytical expressions are shown to predict accurately the practical performance measured from Monte-Carlo simulations of the proposed schemes. These theoretical results are novel and offer a useful framework for optimizing and comparing practical DHT schemes across a wide range of source and code parameters.

Paper number 159:
Title: ADEPT: Adaptive Diffusion Environment for Policy Transfer Sim-to-Real
Authors: Youwei Yu, Junhong Xu, Lantao Liu
Abstract: Model-free reinforcement learning has emerged as a powerful method for developing robust robot control policies capable of navigating through complex and unstructured environments. The effectiveness of these methods hinges on two essential elements: (1) the use of massively parallel physics simulations to expedite policy training, and (2) an environment generator tasked with crafting sufficiently challenging yet attainable environments to facilitate continuous policy improvement. Existing methods of outdoor environment generation often rely on heuristics constrained by a set of parameters, limiting the diversity and realism. In this work, we introduce ADEPT, a novel \textbf{A}daptive \textbf{D}iffusion \textbf{E}nvironment for \textbf{P}olicy \textbf{T}ransfer in the zero-shot sim-to-real fashion that leverages Denoising Diffusion Probabilistic Models to dynamically expand existing training environments by adding more diverse and complex environments adaptive to the current policy. ADEPT guides the diffusion model's generation process through initial noise optimization, blending noise-corrupted environments from existing training environments weighted by the policy's performance in each corresponding environment. By manipulating the noise corruption level, ADEPT seamlessly transitions between generating similar environments for policy fine-tuning and novel ones to expand training diversity. To benchmark ADEPT in off-road navigation, we propose a fast and effective multi-layer map representation for wild environment generation. Our experiments show that the policy trained by ADEPT outperforms both procedural generated and natural environments, along with popular navigation methods.

Paper number 160:
Title: Systematic Hazard Analysis for Frontier AI using STPA
Authors: Simon Mylius
Abstract: All of the frontier AI companies have published safety frameworks where they define capability thresholds and risk mitigations that determine how they will safely develop and deploy their models. Adoption of systematic approaches to risk modelling, based on established practices used in safety-critical industries, has been recommended, however frontier AI companies currently do not describe in detail any structured approach to identifying and analysing hazards. STPA (Systems-Theoretic Process Analysis) is a systematic methodology for identifying how complex systems can become unsafe, leading to hazards. It achieves this by mapping out controllers and controlled processes then analysing their interactions and feedback loops to understand how harmful outcomes could occur (Leveson & Thomas, 2018). We evaluate STPA's ability to broaden the scope, improve traceability and strengthen the robustness of safety assurance for frontier AI systems. Applying STPA to the threat model and scenario described in 'A Sketch of an AI Control Safety Case' (Korbak et al., 2025), we derive a list of Unsafe Control Actions. From these we select a subset and explore the Loss Scenarios that lead to them if left unmitigated. We find that STPA is able to identify causal factors that may be missed by unstructured hazard analysis methodologies thereby improving robustness. We suggest STPA could increase the safety assurance of frontier AI when used to complement or check coverage of existing AI governance techniques including capability thresholds, model evaluations and emergency procedures. The application of a systematic methodology supports scalability by increasing the proportion of the analysis that could be conducted by LLMs, reducing the burden on human domain experts.

Paper number 161:
Title: Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability
Authors: Genta Indra Winata, David Anugraha, Emmy Liu, Alham Fikri Aji, Shou-Yi Hung, Aditya Parashar, Patrick Amadeus Irawan, Ruochen Zhang, Zheng-Xin Yong, Jan Christian Blaise Cruz, Niklas Muennighoff, Seungone Kim, Hanyang Zhao, Sudipta Kar, Kezia Erina Suryoraharjo, M. Farid Adilazuarda, En-Shiun Annie Lee, Ayu Purwarianti, Derry Tanti Wijaya, Monojit Choudhury
Abstract: High-quality datasets are fundamental to training and evaluating machine learning models, yet their creation-especially with accurate human annotations-remains a significant challenge. Many dataset paper submissions lack originality, diversity, or rigorous quality control, and these shortcomings are often overlooked during peer review. Submissions also frequently omit essential details about dataset construction and properties. While existing tools such as datasheets aim to promote transparency, they are largely descriptive and do not provide standardized, measurable methods for evaluating data quality. Similarly, metadata requirements at conferences promote accountability but are inconsistently enforced. To address these limitations, this position paper advocates for the integration of systematic, rubric-based evaluation metrics into the dataset review process-particularly as submission volumes continue to grow. We also explore scalable, cost-effective methods for synthetic data generation, including dedicated tools and LLM-as-a-judge approaches, to support more efficient evaluation. As a call to action, we introduce DataRubrics, a structured framework for assessing the quality of both human- and model-generated datasets. Leveraging recent advances in LLM-based evaluation, DataRubrics offers a reproducible, scalable, and actionable solution for dataset quality assessment, enabling both authors and reviewers to uphold higher standards in data-centric research. We also release code to support reproducibility of LLM-based evaluations at this https URL.

Paper number 162:
Title: Efficient Learning of Balanced Signed Graphs via Sparse Linear Programming
Authors: Haruki Yokota, Hiroshi Higashi, Yuichi Tanaka, Gene Cheung
Abstract: Signed graphs are equipped with both positive and negative edge weights, encoding pairwise correlations as well as anti-correlations in data. A balanced signed graph is a signed graph with no cycles containing an odd number of negative edges. Laplacian of a balanced signed graph has eigenvectors that map via a simple linear transform to ones in a corresponding positive graph Laplacian, thus enabling reuse of spectral filtering tools designed for positive graphs. We propose an efficient method to learn a balanced signed graph Laplacian directly from data. Specifically, extending a previous linear programming (LP) based sparse inverse covariance estimation method called CLIME, we formulate a new LP problem for each Laplacian column $i$, where the linear constraints restrict weight signs of edges stemming from node $i$, so that nodes of same / different polarities are connected by positive / negative edges. Towards optimal model selection, we derive a suitable CLIME parameter $\rho$ based on a combination of the Hannan-Quinn information criterion and a minimum feasibility criterion. We solve the LP problem efficiently by tailoring a sparse LP method based on ADMM. We theoretically prove local solution convergence of our proposed iterative algorithm. Extensive experimental results on synthetic and real-world datasets show that our balanced graph learning method outperforms competing methods and enables reuse of spectral filters, wavelets, and graph convolutional nets (GCN) constructed for positive graphs.

Paper number 163:
Title: EEG Foundation Models for BCI Learn Diverse Features of Electrophysiology
Authors: Mattson Ogg, Rahul Hingorani, Diego Luna, Griffin W. Milsap, William G. Coon, Clara A. Scholl
Abstract: Brain computer interface (BCI) research, as well as increasing portions of the field of neuroscience, have found success deploying large-scale artificial intelligence (AI) pre-training methods in conjunction with vast public repositories of data. This approach of pre-training foundation models using label-free, self-supervised objectives offers the potential to learn robust representations of neurophysiology, potentially addressing longstanding challenges in neural decoding. However, to date, much of this work has focused explicitly on standard BCI benchmarks and tasks, which likely overlooks the multitude of features these powerful methods might learn about brain function as well as other electrophysiological information. We introduce a new method for self-supervised BCI foundation model pre-training for EEG inspired by a transformer-based approach adapted from the HuBERT framework originally developed for speech processing. Our pipeline is specifically focused on low-profile, real-time usage, involving minimally pre-processed data and just eight EEG channels on the scalp. We show that our foundation model learned a representation of EEG that supports standard BCI tasks (P300, motor imagery), but also that this model learns features of neural data related to individual variability, and other salient electrophysiological components (e.g., alpha rhythms). In addition to describing and evaluating a novel approach to pre-training BCI models and neural decoding, this work opens the aperture for what kind of tasks and use-cases might exist for neural data in concert with powerful AI methods.

Paper number 164:
Title: Generalized hybrid momentum maps and reduction by symmetries of forced mechanical systems with inelastic collisions
Authors: Leonardo J. Colombo, Manuel de LeÃ³n, MarÃ­a Emma Eyrea IrazÃº, Asier LÃ³pez-GordÃ³n
Abstract: This paper discusses reduction by symmetries for autonomous and non-autonomous forced mechanical systems with inelastic collisions. In particular, we introduce the notion of generalized hybrid momentum map and hybrid constants of the motion to give general conditions on whether it is possible to perform symmetry reduction for Hamiltonian and Lagrangian systems subject to non-conservative external forces and non-elastic impacts, as well as its extension to time-dependent mechanical systems subject to time-dependent external forces and time-dependent inelastic collisions. We illustrate the applicability of the method with examples and numerical simulations.

Paper number 165:
Title: Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution
Authors: Julien Cornebise, Ivan OrÅ¡oliÄ, Freddie Kalaitzis
Abstract: Analyzing the planet at scale with satellite imagery and machine learning is a dream that has been constantly hindered by the cost of difficult-to-access highly-representative high-resolution imagery. To remediate this, we introduce here the WorldStrat dataset. The largest and most varied such publicly available dataset, at Airbus SPOT 6/7 satellites' high resolution of up to 1.5 m/pixel, empowered by European Space Agency's Phi-Lab as part of the ESA-funded QueryPlanet project, we curate nearly 10,000 sqkm of unique locations to ensure stratified representation of all types of land-use across the world: from agriculture to ice caps, from forests to multiple urbanization densities. We also enrich those with locations typically under-represented in ML datasets: sites of humanitarian interest, illegal mining sites, and settlements of persons at risk. We temporally-match each high-resolution image with multiple low-resolution images from the freely accessible lower-resolution Sentinel-2 satellites at 10 m/pixel. We accompany this dataset with an open-source Python package to: rebuild or extend the WorldStrat dataset, train and infer baseline algorithms, and learn with abundant tutorials, all compatible with the popular EO-learn toolbox. We hereby hope to foster broad-spectrum applications of ML to satellite imagery, and possibly develop from free public low-resolution Sentinel2 imagery the same power of analysis allowed by costly private high-resolution imagery. We illustrate this specific point by training and releasing several highly compute-efficient baselines on the task of Multi-Frame Super-Resolution. High-resolution Airbus imagery is CC BY-NC, while the labels and Sentinel2 imagery are CC BY, and the source code and pre-trained models under BSD. The dataset is available at this https URL and the software package at this https URL .

Paper number 166:
Title: Beamforming Design with Partial Channel Estimation and Feedback for FDD RIS-Assisted Systems
Authors: Xiaochun Ge, Shanping Yu, Wenqian Shen, Chengwen Xing, Byonghyo Shim
Abstract: Beamforming design with partial channel estimation and feedback for frequency-division duplexing (FDD) reconfigurable intelligent surface (RIS) assisted systems is considered in this paper. We leverage the observation that path angle information (PAI) varies more slowly than path gain information (PGI). Then, several dominant paths are selected among all the cascaded paths according to the known PAI for maximizing the spectral efficiency of downlink data transmission. To acquire the dominating path gain information (DPGI, also regarded as the path gains of selected dominant paths) at the base station (BS), we propose a DPGI estimation and feedback scheme by jointly beamforming design at BS and RIS. Both the required number of downlink pilot signals and the length of uplink feedback vector are reduced to the number of dominant paths, and thus we achieve a great reduction of the pilot overhead and feedback overhead. Furthermore, we optimize the active BS beamformer and passive RIS beamformer by exploiting the feedback DPGI to further improve the spectral efficiency. From numerical results, we demonstrate the superiority of our proposed algorithms over the conventional schemes.

Paper number 167:
Title: Leveraging Complementary Attention maps in vision transformers for OCT image analysis
Authors: Haz Sameen Shahgir, Tanjeem Azwad Zaman, Khondker Salman Sayeed, Md. Asif Haider, Sheikh Saifur Rahman Jony, M. Sohel Rahman
Abstract: Optical Coherence Tomography (OCT) scan yields all possible cross-section images of a retina for detecting biomarkers linked to optical defects. Due to the high volume of data generated, an automated and reliable biomarker detection pipeline is necessary as a primary screening stage. We outline our new state-of-the-art pipeline for identifying biomarkers from OCT scans. In collaboration with trained ophthalmologists, we identify local and global structures in biomarkers. Through a comprehensive and systematic review of existing vision architectures, we evaluate different convolution and attention mechanisms for biomarker detection. We find that MaxViT, a hybrid vision transformer combining convolution layers with strided attention, is better suited for local feature detection, while EVA-02, a standard vision transformer leveraging pure attention and large-scale knowledge distillation, excels at capturing global features. We ensemble the predictions of both models to achieve first place in the IEEE Video and Image Processing Cup 2023 competition on OCT biomarker detection, achieving a patient-wise F1 score of 0.8527 in the final phase of the competition, scoring 3.8\% higher than the next best solution. Finally, we used knowledge distillation to train a single MaxViT to outperform our ensemble at a fraction of the computation cost.

Paper number 168:
Title: Extended Set-based Tasks for Multi-task Execution and Prioritization
Authors: Gennaro Notomista, Mario Selvaggio, Francesca Pagano, MarÃ­a Santos, Siddharth Mayya, Vincenzo Lippiello, Cristian Secchi
Abstract: The ability of executing multiple tasks simultaneously is an important feature of redundant robotic systems. As a matter of fact, complex behaviors can often be obtained as a result of the execution of several tasks. Moreover, in safety-critical applications, tasks designed to ensure the safety of the robot and its surroundings have to be executed along with other nominal tasks. In such cases, it is also important to prioritize the former over the latter. In this paper, we formalize the definition of extended set-based tasks, i.e., tasks which can be executed by rendering subsets of the task space asymptotically stable or forward invariant using control barrier functions. We propose a formal mathematical representation of such tasks that allows for the execution of more complex and time-varying prioritized stacks of tasks using kinematic and dynamic robot models alike. We present an optimization-based framework which is computationally efficient, accounts for input bounds, and allows for the stable execution of time-varying prioritized stacks of extended set-based tasks. The proposed framework is validated using extensive simulations, quantitative comparisons to the state-of-the-art hierarchical quadratic programming, and experiments with robotic manipulators.

Paper number 169:
Title: Self-supervised Reflective Learning through Self-distillation and Online Clustering for Speaker Representation Learning
Authors: Danwei Cai, Zexin Cai, Ze Li, Ming Li
Abstract: Speaker representation learning is crucial for voice recognition systems, with recent advances in self-supervised approaches reducing dependency on labeled data. Current two-stage iterative frameworks, while effective, suffer from significant computational overhead due to repeated rounds of clustering and training. They also struggle with noisy pseudo labels that can impair model learning. This paper introduces self-supervised reflective learning (SSRL), an improved framework that addresses these limitations by enabling continuous refinement of pseudo labels during training. Through a teacher-student architecture and online clustering mechanism, SSRL eliminates the need for iterative training rounds. To handle label noise, we incorporate noisy label modeling and pseudo label queues that maintain temporal consistency. Experiments on VoxCeleb show SSRL's superiority over current two-stage iterative approaches, surpassing the performance of a 5-round method in just a single training round. Ablation studies validate the contributions of key components like noisy label modeling and pseudo label queues. Moreover, consistent improvements in pseudo labeling and the convergence of cluster counts demonstrate SSRL's effectiveness in deciphering unlabeled data. This work marks an important advancement in efficient and accurate self-supervised speaker representation learning through the novel reflective learning paradigm.

Paper number 170:
Title: Online Control of Linear Systems under Unbounded Noise
Authors: Kaito Ito, Taira Tsuchiya
Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded stochastic noise with unknown convex cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we show that an $ \tilde{O}(\sqrt{T}) $ high-probability regret can be achieved under unbounded noise, where $ T $ denotes the time horizon. Notably, the noise is only required to have a finite fourth moment. Moreover, when the costs are strongly convex and the noise is sub-Gaussian, we establish an $ O({\rm poly} (\log T)) $ regret bound.

Paper number 171:
Title: A Tunable Universal Formula for Safety-Critical Control
Authors: Ming Li, Zhiyong Sun, Patrick J. W. Koelewijn, Siep Weiland
Abstract: Sontag's universal formula is a widely used technique for stabilizing control through control Lyapunov functions. Recently, it has been extended to address safety-critical control by incorporating control barrier functions (CBFs). However, deriving a universal formula that satisfies requirements on essential properties, including safety, smoothness, and robustness against input disturbances, is still an open problem. To address this challenge, this paper introduces a novel solution - a tunable universal formula - by incorporating a (state-dependent) tunable term into Sontag's formula. This tunable term enables the regulation of safety-critical control performances, allowing the attainment of desired properties through a proper selection of tunable terms. Generally, the tunable universal formula can be seen as a controller that improves the quadratic program (QP)-synthesized controllers in terms of robustness and smoothness, while also reducing the conservatism (corresponding to robustness) in Sontag's formula. Furthermore, we extend the tunable universal formula to address safety-critical control problems with norm-bounded input constraints, showcasing its applicability across diverse control scenarios. Finally, we demonstrate the efficacy of our method through a two-link manipulator safe tracking example, investigating the essential properties including safety, smoothness, and robustness against input disturbances under various tunable terms.

Paper number 172:
Title: Application based Evaluation of an Efficient Spike-Encoder, "Spiketrum"
Authors: MHD Anas Alsakkal, Runze Wang, Jayawan Wijekoon, Huajin Tang
Abstract: Spike-based encoders represent information as sequences of spikes or pulses, which are transmitted between neurons. A prevailing consensus suggests that spike-based approaches demonstrate exceptional capabilities in capturing the temporal dynamics of neural activity and have the potential to provide energy-efficient solutions for low-power applications. The Spiketrum encoder efficiently compresses input data using spike trains or code sets (for non-spiking applications) and is adaptable to both hardware and software implementations, with lossless signal reconstruction capability. The paper proposes and assesses Spiketrum's hardware, evaluating its output under varying spike rates and its classification performance with popular spiking and non-spiking classifiers, and also assessing the quality of information compression and hardware resource utilization. The paper extensively benchmarks both Spiketrum hardware and its software counterpart against state-of-the-art, biologically-plausible encoders. The evaluations encompass benchmarking criteria, including classification accuracy, training speed, and sparsity when using encoder outputs in pattern recognition and classification with both spiking and non-spiking classifiers. Additionally, they consider encoded output entropy and hardware resource utilization and power consumption of the hardware version of the encoders. Results demonstrate Spiketrum's superiority in most benchmarking criteria, making it a promising choice for various applications. It efficiently utilizes hardware resources with low power consumption, achieving high classification accuracy. This work also emphasizes the potential of encoders in spike-based processing to improve the efficiency and performance of neural computing systems.

Paper number 173:
Title: Context-Enhanced CSI Tracking Using Koopman-Inspired Dual Autoencoders in Dynamic Wireless Environments
Authors: Anis Hamadouche, Mathini Sellathurai
Abstract: This paper introduces a novel framework for tracking and predicting Channel State Information (CSI) by leveraging Physics-Informed Autoencoders (PIAE) integrated with a learned Koopman operator. The proposed approach models CSI as a nonlinear dynamical system governed by both intrinsic channel behavior and exogenous contextual factors such as position, temperature, and atmospheric conditions. The architecture comprises dual autoencoders-one dedicated to CSI and another to contextual inputs-linked via a shared latent state space, within which the Koopman operator captures the linear temporal evolution of CSI dynamics. This coupling enables accurate, data-driven forecasting of CSI trajectories while maintaining interpretability through a structured, physics-consistent representation. The framework supports real-time updates to the Channel Knowledge Map (CKM), enhancing the adaptability and reliability of communication systems in complex and time-varying environments. By unifying Koopman theory with learned latent representations, the proposed method provides a scalable and privacy-preserving solution for next-generation wireless networks. Empirical results demonstrate its effectiveness in delivering high-fidelity CSI predictions under diverse channel conditions.

Paper number 174:
Title: Meta-Learning for Adaptive Control with Automated Mirror Descent
Authors: Sunbochen Tang, Haoyuan Sun, Navid Azizan
Abstract: Adaptive control achieves concurrent parameter learning and stable control under uncertainties that are linearly parameterized with known nonlinear features. Nonetheless, it is often difficult to obtain such nonlinear features. To address this difficulty, recent progress has been made in integrating meta-learning with adaptive control to learn such nonlinear features from data. However, these meta-learning-based control methods rely on classical adaptation laws using gradient descent, which is confined to the Euclidean geometry. In this paper, we propose a novel method that combines meta-learning and adaptation laws based on mirror descent, a popular generalization of gradient descent, which takes advantage of the potentially non-Euclidean geometry of the parameter space. In our approach, meta-learning not only learns the nonlinear features but also searches for a suitable mirror-descent potential function that optimizes control performance. Through numerical simulations, we demonstrate the effectiveness of the proposed method in learning efficient representations and real-time tracking control performance under uncertain dynamics.

Paper number 175:
Title: ZSDEVC: Zero-Shot Diffusion-based Emotional Voice Conversion with Disentangled Mechanism
Authors: Hsing-Hang Chou, Yun-Shao Lin, Ching-Chin Sung, Yu Tsao, Chi-Chun Lee
Abstract: The human voice conveys not just words but also emotional states and individuality. Emotional voice conversion (EVC) modifies emotional expressions while preserving linguistic content and speaker identity, improving applications like human-machine interaction. While deep learning has advanced EVC models for specific target speakers on well-crafted emotional datasets, existing methods often face issues with emotion accuracy and speech distortion. In addition, the zero-shot scenario, in which emotion conversion is applied to unseen speakers, remains underexplored. This work introduces a novel diffusion framework with disentangled mechanisms and expressive guidance, trained on a large emotional speech dataset and evaluated on unseen speakers across in-domain and out-of-domain datasets. Experimental results show that our method produces expressive speech with high emotional accuracy, naturalness, and quality, showcasing its potential for broader EVC applications.

Paper number 176:
Title: Text-To-Speech Synthesis In The Wild
Authors: Jee-weon Jung, Wangyou Zhang, Soumi Maiti, Yihan Wu, Xin Wang, Ji-Hoon Kim, Yuta Matsunaga, Seyun Um, Jinchuan Tian, Hye-jin Shim, Nicholas Evans, Joon Son Chung, Shinnosuke Takamichi, Shinji Watanabe
Abstract: Traditional Text-to-Speech (TTS) systems rely on studio-quality speech recorded in controlled settings.a Recently, an effort known as noisy-TTS training has emerged, aiming to utilize in-the-wild data. However, the lack of dedicated datasets has been a significant limitation. We introduce the TTS In the Wild (TITW) dataset, which is publicly available, created through a fully automated pipeline applied to the VoxCeleb1 dataset. It comprises two training sets: TITW-Hard, derived from the transcription, segmentation, and selection of raw VoxCeleb1 data, and TITW-Easy, which incorporates additional enhancement and data selection based on DNSMOS. State-of-the-art TTS models achieve over 3.0 UTMOS score with TITW-Easy, while TITW-Hard remains difficult showing UTMOS below 2.8.

Paper number 177:
Title: Privacy-Preserving Framework for Cell-Free MIMO ISAC Systems
Authors: Henrik Ãkesson, Diana Pamela Moya Osorio
Abstract: Integrated Sensing and Communication (ISAC) systems are prone to privacy violations, once they aim at handling sensitive identifiable information in several applications. This paper raises the necessity of implementing privacy-preservation measures on the design of cell-free massive multiple-input multiple-output ISAC systems. To that purpose, given an adversary model, we propose an iterative framework of two blocks, precoder design and access point selection. The precoder design aims at maximizing the signal-to-interference-plus-noise ratio at the sensing receivers given communication constraints. The access point selection aims at minimizing the mutual information between the received signal at users and the sensing signal, by rearranging the access points that transmit ISAC-signals and the sensing receivers. Results show that a reduction in the probability of detection by the adversary is obtained with this method.

Paper number 178:
Title: End-to-end guarantees for indirect data-driven control of bilinear systems with finite stochastic data
Authors: Nicolas Chatzikiriakos, Robin StrÃ¤sser, Frank AllgÃ¶wer, Andrea Iannelli
Abstract: In this paper we propose an end-to-end algorithm for indirect data-driven control for bilinear systems with stability guarantees. We consider the case where the collected i.i.d. data is affected by probabilistic noise with possibly unbounded support and leverage tools from statistical learning theory to derive finite sample identification error bounds. To this end, we solve the bilinear identification problem by solving a set of linear and affine identification problems, by a particular choice of a control input during the data collection phase. We provide a priori as well as data-dependent finite sample identification error bounds on the individual matrices as well as ellipsoidal bounds, both of which are structurally suitable for control. Further, we integrate the structure of the derived identification error bounds in a robust controller design to obtain an exponentially stable closed-loop. By means of an extensive numerical study we showcase the interplay between the controller design and the derived identification error bounds. Moreover, we note appealing connections of our results to indirect data-driven control of general nonlinear systems through Koopman operator theory and discuss how our results may be applied in this setup.

Paper number 179:
Title: Simulation Results of Center-Manifold-Based Identification of Polynomial Nonlinear Systems with Uncontrollable Linearization
Authors: Chao Huang, Hao Zhang, Zhuping Wang
Abstract: Recently, a system identification method based on center manifold is proposed to identify polynomial nonlinear systems with uncontrollable linearization. This note presents a numerical example to show the effectiveness of this method.

Paper number 180:
Title: Structure and Control of Biology-inspired Networks
Authors: Zexin Sun, John Baillieul
Abstract: There is increasing interest in developing the theoretical foundations of networked control systems that illuminate how brain networks function so as to enable sensory perception, control of movement, memory and all the operations that are needed for animals to survive. The present paper proposes a biologically inspired network model featuring dynamic connections regulated by Hebbian learning. Drawing on the machinery of graph theory and classical control we show that our novel nonlinear model exhibits such biologically plausible features as bounded evolution, stability, resilience, and a kind of structural stability -- meaning that perturbations of the model parameters leave the essential properties of the model in tact. The proposed network model involves generalized cactus graphs with multiple control input nodes, and it is shown that the properties of the network are resilient to various changes in network topology provided these changes preserve the generalized cactus structure. A particular example described in what follows is an idealized network model of the visual system of a macaque monkey. The model displays resilience to network disruptions such as might occur in a living organism due to disease or injury. A different model of the same type provides an example of a system that can perform data classification.

Paper number 181:
Title: Minimum Radiative Heat and Propellant Aerocapture Guidance with Attitude Kinematics Constraints
Authors: Enrico Marco Zucchelli, Erwin Mooij
Abstract: Aerocapture leverages atmospheric drag to convert a spacecraft's hyperbolic trajectory into a bound orbit. For some aerocapture missions, heating due to the radiation of high temperature gases in the shock-layer can be much larger than the heat due to convection. This paper provides analytical proof and numerical validation that radiative heat load is minimized by the same trajectory that minimizes the final {\Delta} V: a single switch bang-bang trajectory, starting with lift up. The proof is very general and is valid for several formulations of radiative heat flux; further, the same proof can be used to conclude that convective heat load, computed according to many of the available formulations, is instead maximized by that trajectory. Further, a novel guidance that plans a bang-bang trajectory with constraints in the attitude kinematics is introduced. While achieving performance similar to that of the current state-of-the-art, the inclusion of constraints in attitude kinematics allows for much less tuning. Finally, a lateral guidance that makes use of information on the final inclination of the predicted trajectory is introduced. Such guidance allows for very high accuracy in the inclination requirements with only two reversals, by requiring a single parameter to be tuned.

Paper number 182:
Title: Neural Operators for Predictor Feedback Control of Nonlinear Delay Systems
Authors: Luke Bhan, Peijia Qin, Miroslav Krstic, Yuanyuan Shi
Abstract: Predictor feedback designs are critical for delay-compensating controllers in nonlinear systems. However, these designs are limited in practical applications as predictors cannot be directly implemented, but require numerical approximation schemes, which become computationally prohibitive when system dynamics are expensive to compute. To address this challenge, we recast the predictor design as an operator learning problem, and learn the predictor mapping via a neural operator. We prove the existence of an arbitrarily accurate neural operator approximation of the predictor operator. Under the approximated predictor, we achieve semiglobal practical stability of the closed-loop nonlinear delay system. The estimate is semiglobal in a unique sense - one can enlarge the set of initial states as desired, though this increases the difficulty of training a neural operator, which appears practically in the stability estimate. Furthermore, our analysis holds for any black-box predictor satisfying the universal approximation error bound. We demonstrate the approach by controlling a 5-link robotic manipulator with different neural operator models, achieving significant speedups compared to classic predictor feedback schemes while maintaining closed-loop stability.

Paper number 183:
Title: Domain-Agnostic Stroke Lesion Segmentation Using Physics-Constrained Synthetic Data
Authors: Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner
Abstract: Segmenting stroke lesions in MRI is challenging due to diverse acquisition protocols that limit model generalisability. In this work, we introduce two physics-constrained approaches to generate synthetic quantitative MRI (qMRI) images that improve segmentation robustness across heterogeneous domains. Our first method, $\texttt{qATLAS}$, trains a neural network to estimate qMRI maps from standard MPRAGE images, enabling the simulation of varied MRI sequences with realistic tissue contrasts. The second method, $\texttt{qSynth}$, synthesises qMRI maps directly from tissue labels using label-conditioned Gaussian mixture models, ensuring physical plausibility. Extensive experiments on multiple out-of-domain datasets show that both methods outperform a baseline UNet, with $\texttt{qSynth}$ notably surpassing previous synthetic data approaches. These results highlight the promise of integrating MRI physics into synthetic data generation for robust, generalisable stroke lesion segmentation. Code is available at this https URL

Paper number 184:
Title: Real-time Chest X-Ray Distributed Decision Support for Resource-constrained Clinics
Authors: Omar H. Khater, Basem Almadani, Farouq Aliyu
Abstract: Internet of Things (IoT) based healthcare systems offer significant potential for improving the delivery of healthcare services in humanitarian engineering, providing essential healthcare services to millions of underserved people in remote areas worldwide. However, these areas have poor network infrastructure, making communications difficult for traditional IoT. This paper presents a real-time chest X-ray classification system for hospitals in remote areas using FastDDS real-time middleware, offering reliable real-time communication. We fine-tuned a ResNet50 neural network to an accuracy of 88.61%, a precision of 88.76%, and a recall of 88.49\%. Our system results mark an average throughput of 3.2 KB/s and an average latency of 65 ms. The proposed system demonstrates how middleware-based systems can assist doctors in remote locations.

Paper number 185:
Title: Finite Sample Analysis of Tensor Decomposition for Learning Mixtures of Linear Systems
Authors: Maryann Rui, Munther Dahleh
Abstract: We study the problem of learning mixtures of linear dynamical systems (MLDS) from input-output data. The mixture setting allows us to leverage observations from related dynamical systems to improve the estimation of individual models. Building on spectral methods for mixtures of linear regressions, we propose a moment-based estimator that uses tensor decomposition to estimate the impulse response parameters of the mixture models. The estimator improves upon existing tensor decomposition approaches for MLDS by utilizing the entire length of the observed trajectories. We provide sample complexity bounds for estimating MLDS in the presence of noise, in terms of both the number of trajectories $N$ and the trajectory length $T$, and demonstrate the performance of the estimator through simulations.

Paper number 186:
Title: SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis
Authors: Runci Bai, Guibao Xu, Yanze Shi
Abstract: Brain tumors can lead to neurological dysfunction, cognitive and psychological changes, increased intracranial pressure, and seizures, posing significant risks to health. The You Only Look Once (YOLO) series has shown superior accuracy in medical imaging object detection. This paper presents a novel SCC-YOLO architecture that integrates the SCConv module into YOLOv9. The SCConv module optimizes convolutional efficiency by reducing spatial and channel redundancy, enhancing image feature learning. We examine the effects of different attention mechanisms with YOLOv9 for brain tumor detection using the Br35H dataset and our custom dataset (Brain_Tumor_Dataset). Results indicate that SCC-YOLO improved mAP50 by 0.3% on the Br35H dataset and by 0.5% on our custom dataset compared to YOLOv9. SCC-YOLO achieves state-of-the-art performance in brain tumor detection.

Paper number 187:
Title: UniRestore: Unified Perceptual and Task-Oriented Image Restoration Model Using Diffusion Prior
Authors: I-Hsiang Chen, Wei-Ting Chen, Yu-Wei Liu, Yuan-Chun Chiang, Sy-Yen Kuo, Ming-Hsuan Yang
Abstract: Image restoration aims to recover content from inputs degraded by various factors, such as adverse weather, blur, and noise. Perceptual Image Restoration (PIR) methods improve visual quality but often do not support downstream tasks effectively. On the other hand, Task-oriented Image Restoration (TIR) methods focus on enhancing image utility for high-level vision tasks, sometimes compromising visual quality. This paper introduces UniRestore, a unified image restoration model that bridges the gap between PIR and TIR by using a diffusion prior. The diffusion prior is designed to generate images that align with human visual quality preferences, but these images are often unsuitable for TIR scenarios. To solve this limitation, UniRestore utilizes encoder features from an autoencoder to adapt the diffusion prior to specific tasks. We propose a Complementary Feature Restoration Module (CFRM) to reconstruct degraded encoder features and a Task Feature Adapter (TFA) module to facilitate adaptive feature fusion in the decoder. This design allows UniRestore to optimize images for both human perception and downstream task requirements, addressing discrepancies between visual quality and functional needs. Integrating these modules also enhances UniRestore's adapability and efficiency across diverse tasks. Extensive expertments demonstrate the superior performance of UniRestore in both PIR and TIR scenarios.

Paper number 188:
Title: WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning
Authors: Rajath Rao, Adithya Ganesan, Oscar Kjell, Jonah Luby, Akshay Raghavan, Scott Feltman, Whitney Ringwald, Ryan L. Boyd, Benjamin Luft, Camilo Ruggero, Neville Ryant, Roman Kotov, H. Andrew Schwartz
Abstract: Current speech encoding pipelines often rely on an additional text-based LM to get robust representations of human communication, even though SotA speech-to-text models often have a LM within. This work proposes an approach to improve the LM within an audio model such that the subsequent text-LM is unnecessary. We introduce WhiSPA (Whisper with Semantic and Psychological Alignment), which leverages a novel audio training objective: contrastive loss with a language model embedding as a teacher. Using over 500k speech segments from mental health audio interviews, we evaluate the utility of aligning Whisper's latent space with semantic representations from a text autoencoder (SBERT) and lexically derived embeddings of basic psychological dimensions: emotion and personality. Over self-supervised affective tasks and downstream psychological tasks, WhiSPA surpasses current speech encoders, achieving an average error reduction of 73.4% and 83.8%, respectively. WhiSPA demonstrates that it is not always necessary to run a subsequent text LM on speech-to-text output in order to get a rich psychological representation of human communication.

Paper number 189:
Title: A General-Purpose Neuromorphic Sensor based on Spiketrum Algorithm: Hardware Details and Real-life Applications
Authors: MHD Anas Alsakkal, Runze Wang, Piotr Dudek, Jayawan Wijekoon
Abstract: Spiking Neural Networks (SNNs) offer a biologically inspired computational paradigm, enabling energy-efficient data processing through spike-based information transmission. Despite notable advancements in hardware for SNNs, spike encoding has largely remained software-dependent, limiting efficiency. This paper addresses the need for adaptable and resource-efficient spike encoding hardware by presenting an area-optimized hardware implementation of the Spiketrum algorithm, which encodes time-varying analogue signals into spatiotemporal spike patterns. Unlike earlier performance-optimized designs, which prioritize speed, our approach focuses on reducing hardware footprint, achieving a 52% reduction in Block RAMs (BRAMs), 31% fewer Digital Signal Processing (DSP) slices, and a 6% decrease in Look-Up Tables (LUTs). The proposed implementation has been verified on an FPGA and successfully integrated into an IC using TSMC180 technology. Experimental results demonstrate the system's effectiveness in real-world applications, including sound and ECG classification. This work highlights the trade-offs between performance and resource efficiency, offering a flexible, scalable solution for neuromorphic systems in power-sensitive applications like cochlear implants and neural devices.

Paper number 190:
Title: Segment Anything for Histopathology
Authors: Titus Griebel, Anwai Archit, Constantin Pape
Abstract: Nucleus segmentation is an important analysis task in digital pathology. However, methods for automatic segmentation often struggle with new data from a different distribution, requiring users to manually annotate nuclei and retrain data-specific models. Vision foundation models (VFMs), such as the Segment Anything Model (SAM), offer a more robust alternative for automatic and interactive segmentation. Despite their success in natural images, a foundation model for nucleus segmentation in histopathology is still missing. Initial efforts to adapt SAM have shown some success, but did not yet introduce a comprehensive model for diverse segmentation tasks. To close this gap, we introduce PathoSAM, a VFM for nucleus segmentation, based on training SAM on a diverse dataset. Our extensive experiments show that it is the new state-of-the-art model for automatic and interactive nucleus instance segmentation in histopathology. We also demonstrate how it can be adapted for other segmentation tasks, including semantic nucleus segmentation. For this task, we show that it yields results better than popular methods, while not yet beating the state-of-the-art, CellViT. Our models are open-source and compatible with popular tools for data annotation. We also provide scripts for whole-slide image segmentation. Our code and models are publicly available at this https URL.

Paper number 191:
Title: Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control
Authors: Xianghui Ze, Zhenbo Song, Qiwei Wang, Jianfeng Lu, Yujiao Shi
Abstract: Generating street-view images from satellite imagery is a challenging task, particularly in maintaining accurate pose alignment and incorporating diverse environmental conditions. While diffusion models have shown promise in generative tasks, their ability to maintain strict pose alignment throughout the diffusion process is limited. In this paper, we propose a novel Iterative Homography Adjustment (IHA) scheme applied during the denoising process, which effectively addresses pose misalignment and ensures spatial consistency in the generated street-view images. Additionally, currently, available datasets for satellite-to-street-view generation are limited in their diversity of illumination and weather conditions, thereby restricting the generalizability of the generated outputs. To mitigate this, we introduce a text-guided illumination and weather-controlled sampling strategy that enables fine-grained control over the environmental factors. Extensive quantitative and qualitative evaluations demonstrate that our approach significantly improves pose accuracy and enhances the diversity and realism of generated street-view images, setting a new benchmark for satellite-to-street-view generation tasks.

Paper number 192:
Title: Towards Explainable Spoofed Speech Attribution and Detection:a Probabilistic Approach for Characterizing Speech Synthesizer Components
Authors: Jagabandhu Mishra, Manasi Chhibber, Hye-jin Shim, Tomi H. Kinnunen
Abstract: We propose an explainable probabilistic framework for characterizing spoofed speech by decomposing it into probabilistic attribute embeddings. Unlike raw high-dimensional countermeasure embeddings, which lack interpretability, the proposed probabilistic attribute embeddings aim to detect specific speech synthesizer components, represented through high-level attributes and their corresponding values. We use these probabilistic embeddings with four classifier back-ends to address two downstream tasks: spoofing detection and spoofing attack attribution. The former is the well-known bonafide-spoof detection task, whereas the latter seeks to identify the source method (generator) of a spoofed utterance. We additionally use Shapley values, a widely used technique in machine learning, to quantify the relative contribution of each attribute value to the decision-making process in each task. Results on the ASVspoof2019 dataset demonstrate the substantial role of duration and conversion modeling in spoofing detection; and waveform generation and speaker modeling in spoofing attack attribution. In the detection task, the probabilistic attribute embeddings achieve $99.7\%$ balanced accuracy and $0.22\%$ equal error rate (EER), closely matching the performance of raw embeddings ($99.9\%$ balanced accuracy and $0.22\%$ EER). Similarly, in the attribution task, our embeddings achieve $90.23\%$ balanced accuracy and $2.07\%$ EER, compared to $90.16\%$ and $2.11\%$ with raw embeddings. These results demonstrate that the proposed framework is both inherently explainable by design and capable of achieving performance comparable to raw CM embeddings.

Paper number 193:
Title: Positioning-Aided Channel Estimation for Multi-LEO Satellite Cooperative Communications
Authors: Yuchen Zhang, Pinjun Zheng, Jie Ma, Henk Wymeersch, Tareq Y. Al-Naffouri
Abstract: We investigate a multi-low Earth orbit (LEO) satellite system that simultaneously provides positioning and communication services to terrestrial user terminals. To address the challenges of channel estimation in LEO satellite systems, we propose a novel two-timescale positioning-aided channel estimation framework, exploiting the distinct variation rates of position-related parameters and channel gains inherent in LEO satellite channels. Using the misspecified CramÃ©r-Rao bound (MCRB) theory, we systematically analyze positioning performance under practical imperfections, such as inter-satellite clock bias and carrier frequency offset. Furthermore, we theoretically demonstrate how position information derived from downlink positioning can enhance uplink channel estimation accuracy, even in the presence of positioning errors, through an MCRB-based analysis. To overcome the constraints of limited link budgets and communication rates associated with single-satellite-based communication, we develop a multi-LEO satellite cooperative beamforming strategy for downlink communication, capitalizing on the benefit of cluster-wise satellites cooperation. Theoretical analyses and numerical results confirm the effectiveness of the proposed framework in achieving high-precision downlink positioning under practical imperfections, facilitating uplink channel estimation, and enabling efficient downlink communication.

Paper number 194:
Title: Comparative Performance Analysis of Numerical Discretization Methods for Electrochemical Models of Lithium-ion Batteries
Authors: Feng Guo, Luis D. Couto
Abstract: This study evaluates numerical discretization methods for the Single Particle Model (SPM) used in electrochemical modeling. The methods include the Finite Difference Method (FDM), spectral methods, PadÃ© approximation, and parabolic approximation. Evaluation criteria are accuracy, execution time, and memory usage, aiming to guide method selection for electrochemical models. Under constant current conditions, the FDM explicit Euler and Runge-Kutta methods show significant errors, while the FDM implicit Euler method improves accuracy with more nodes. The spectral method achieves the best accuracy and convergence with as few as five nodes. The PadÃ© approximation exhibits increasing errors with higher current, and the parabolic approximation shows higher errors than the converged spectral and FDM implicit Euler methods. Under dynamic conditions, frequency domain analysis indicates that the FDM, spectral, and PadÃ© approximation methods improve high-frequency response by increasing node count or method order. In terms of execution time, the parabolic method is fastest, followed by the PadÃ© approximation. The spectral method is faster than FDM, while the FDM implicit Euler method is the slowest. Memory usage is lowest for the parabolic and PadÃ© methods, moderate for FDM, and highest for the spectral method. These findings provide practical guidance for selecting discretization methods under different operating scenarios.

Paper number 195:
Title: Performance Analysis of Multirate Systems: A Direct Frequency-Domain Identification Approach
Authors: Max van Haren, Lennart Blanken, Tom Oomen
Abstract: Frequency-domain performance analysis of intersample behavior in sampled-data and multirate systems is challenging due to the lack of a frequency-separation principle, and systematic identification techniques are lacking. The aim of this \manuscript is to develop an efficient technique for identifying the full intersample performance in the frequency-domain for closed-loop multirate systems, in particular the Performance Frequency Gain (PFG). Through local modeling techniques, aliased frequency components are effectively disentangled when identifying the PFG, which is directly facilitated by frequency-lifting the multirate system to a multivariable time-invariant representation. The developed method accurately and directly identifies the PFG in a single identification experiment. Finally, the developed method is experimentally validated on a prototype motion system, showing accurate identification of frequency-domain representations for the multirate system, including the PFG.

Paper number 196:
Title: Prioritized Planning for Continuous-time Lifelong Multi-agent Pathfinding
Authors: Alvin Combrink, Sabino Francesco Roselli, Martin Fabian
Abstract: Multi-agent Path Finding (MAPF) is the problem of planning collision-free movements of agents so that they get from where they are to where they need to be. Commonly, agents are located on a graph and can traverse edges. This problem has many variations and has been studied for decades. Two such variations are the continuous-time and the lifelong MAPF problems. In the former, edges have non-unit lengths and volumetric agents can traverse them at any real-valued time. In the latter, agents must attend to a continuous stream of incoming tasks. Much work has been devoted to designing solution methods within these two areas. To our knowledge, however, the combined problem of continuous-time lifelong MAPF has yet to be addressed. This work addresses continuous-time lifelong MAPF with volumetric agents by presenting the fast and sub-optimal Continuous-time Prioritized Lifelong Planner (CPLP). CPLP continuously assigns agents to tasks and computes plans using a combination of two path planners; one based on CCBS and the other based on SIPP. Experimental results with up to 800 agents on graphs with up to 12 000 vertices demonstrate practical performance, where maximum planning times fall within the available time budget. Additionally, CPLP ensures collision-free movement even when failing to meet this budget. Therefore, the robustness of CPLP highlights its potential for real-world applications.

Paper number 197:
Title: The value of hedging against energy storage uncertainties when designing energy parks
Authors: Max Langtry, Ruchi Choudhary
Abstract: Energy storage is needed to match renewable generation to industrial loads in energy parks. However, the future performance of bulk storage technologies is currently highly uncertain. Due to the urgency of decarbonization targets, energy park projects must be designed and begun now. But, as uncertainty in storage performance reduces, a different technology than identified during initial design may turn out cheaper. Enabling flexibility so that design adaptations can be made as better information becomes available would lower the cost of decarbonizing industry. But having this flexibility is itself costly. This raises the question, "Is it worth it?" This study quantifies the benefit of retaining flexibility to adapt energy park designs and optionality over storage technology choice as uncertainty reduces, to determine whether it is economically worthwhile. It applies the Value of Information analysis framework to the sizing of wind, solar, and storage in an illustrative energy park model based on a real-world proposal near Rotterdam, considering uncertainty in storage efficiency, lifetime, and capital cost. Updating asset sizings after storage uncertainty reduced is found to reduce total costs by 18% on average. Having the option to switch storage technology choice as well reduces costs by a further 13%, which is substantially greater than the cost of providing storage optionality. Using two storage technologies in the energy park reduces costs by 14%, and in this case storage optionality is not worthwhile. These results are robust to the level of uncertainty reduction in storage performance, and the risk aversion of the system designer.

Paper number 198:
Title: Verifiable Mission Planning For Space Operations
Authors: Quentin Rommel, Michael Hibbard, Pavan Shukla, Himanshu Save, Srinivas Bettadpur, Ufuk Topcu
Abstract: As space missions become more complex, planning methods must maximize mission performance while rigorously enforcing safety. We develop a probabilistic approach based on a finite-horizon Markov decision process to optimize spacecraft operations planning with safety guarantees. In the model, states capture essential mission parameters, and actions represent the operational adjustments needed to meet mission objectives. By directly incorporating uncertainties from environmental conditions and spacecraft dynamics, an optimal sequence of actions is computed that maximizes expected rewards and strictly enforces safety constraints. Numerical experiments on the GRACE-FO mission demonstrate robust performance under uncertainties while providing probabilistic safety guarantees, offering a reliable solution for autonomous spacecraft operations.

Paper number 199:
Title: A Comparative Study on Positional Encoding for Time-frequency Domain Dual-path Transformer-based Source Separation Models
Authors: Kohei Saijo, Tetsuji Ogawa
Abstract: In this study, we investigate the impact of positional encoding (PE) on source separation performance and the generalization ability to long sequences (length extrapolation) in Transformer-based time-frequency (TF) domain dual-path models. The length extrapolation capability in TF-domain dual-path models is a crucial factor, as it affects not only their performance on long-duration inputs but also their generalizability to signals with unseen sampling rates. While PE is known to significantly impact length extrapolation, there has been limited research that explores the choice of PEs for TF-domain dual-path models from this perspective. To address this gap, we compare various PE methods using a recent state-of-the-art model, TF-Locoformer, as the base architecture. Our analysis yields the following key findings: (i) When handling sequences that are the same length as or shorter than those seen during training, models with PEs achieve better performance. (ii) However, models without PE exhibit superior length extrapolation. This trend is particularly pronounced when the model contains convolutional layers.

Paper number 200:
Title: Omni-R1: Do You Really Need Audio to Fine-Tune Your Audio LLM?
Authors: Andrew Rouditchenko, Saurabhchand Bhati, Edson Araujo, Samuel Thomas, Hilde Kuehne, Rogerio Feris, James Glass
Abstract: We propose Omni-R1 which fine-tunes a recent multi-modal LLM, Qwen2.5-Omni, on an audio question answering dataset with the reinforcement learning method GRPO. This leads to new State-of-the-Art performance on the recent MMAU and MMAR benchmarks. Omni-R1 achieves the highest accuracies on the sounds, music, speech, and overall average categories, both on the Test-mini and Test-full splits. To understand the performance improvement, we tested models both with and without audio and found that much of the performance improvement from GRPO could be attributed to better text-based reasoning. We also made a surprising discovery that fine-tuning without audio on a text-only dataset was effective at improving the audio-based performance.

Paper number 201:
Title: LLM4SG: Large Language Models for Scatterer Generation via Synesthesia of Machines
Authors: Zengrui Han, Lu Bai, Ziwei Huang, Xiang Cheng
Abstract: Guided by Synesthesia of Machines (SoM), the nonlinear mapping relationship between sensory and communication information serves as a powerful tool to enhance both the accuracy and generalization of vehicle-to-vehicle (V2V) multi-modal intelligent channel modeling (MMICM) in intelligent transportation systems (ITSs). To explore the general mapping relationship between physical environment and electromagnetic space, a new intelligent sensing-communication integration dataset, named V2V-M3, is constructed for multiple scenarios in V2V communications with multiple frequency bands and multiple vehicular traffic densities (VTDs). Leveraging the strong representation and cross-modal inference capabilities of large language models (LLMs), a novel LLM-based method for Scatterer Generation (LLM4SG) from light detection and ranging (LiDAR) point clouds is developed. To address the inherent and significant differences across multi-modal data, synergistically optimized four-module architecture, i.e., preprocessor, embedding, backbone, and output modules, are designed by considering the sensing/channel characteristics and electromagnetic propagation mechanism. On the basis of cross-modal representation alignment and positional encoding, the network of LLM4SG is fine-tuned to capture the general mapping relationship between LiDAR point clouds and scatterers. Simulation results demonstrate that the proposed LLM4SG achieves superior performance in full-sample and generalization testing, significantly outperforming small models across different frequency bands, scenarios, and VTDs.

Paper number 202:
Title: NMCSE: Noise-Robust Multi-Modal Coupling Signal Estimation Method via Optimal Transport for Cardiovascular Disease Detection
Authors: Peihong Zhang, Zhixin Li, Rui Sang, Yuxuan Liu, Yiqiang Cai, Yizhou Tan, Shengchen Li
Abstract: Electrocardiogram (ECG) and Phonocardiogram (PCG) signals are linked by a latent coupling signal representing the electrical-to-mechanical cardiac transformation. While valuable for cardiovascular disease (CVD) detection, this coupling signal is traditionally estimated using deconvolution methods that amplify noise, limiting clinical utility. In this paper, we propose Noise-Robust Multi-Modal Coupling Signal Estimation (NMCSE), which reformulates the problem as distribution matching via optimal transport theory. By jointly optimizing amplitude and temporal alignment, NMCSE mitigates noise amplification without additional preprocessing. Integrated with our Temporal-Spatial Feature Extraction network, NMCSE enables robust multi-modal CVD detection. Experiments on the PhysioNet 2016 dataset with realistic hospital noise demonstrate that NMCSE reduces estimation errors by approximately 30% in Mean Squared Error while maintaining higher Pearson Correlation Coefficients across all tested signal-to-noise ratios. Our approach achieves 97.38% accuracy and 0.98 AUC in CVD detection, outperforming state-of-the-art methods and demonstrating robust performance for real-world clinical applications.

Paper number 203:
Title: SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline
Authors: Helin Wang, Jiarui Hai, Dongchao Yang, Chen Chen, Kai Li, Junyi Peng, Thomas Thebaud, Laureano Moro Velazquez, Jesus Villalba, Najim Dehak
Abstract: Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high perceptual quality, these models often introduce unwanted artifacts, reduce naturalness, and are sensitive to discrepancies between training and testing environments. On the other hand, generative models for TSE lag in perceptual quality and intelligibility. To address these challenges, we present SoloSpeech, a novel cascaded generative pipeline that integrates compression, extraction, reconstruction, and correction processes. SoloSpeech features a speaker-embedding-free target extractor that utilizes conditional information from the cue audio's latent space, aligning it with the mixture audio's latent space to prevent mismatches. Evaluated on the widely-used Libri2Mix dataset, SoloSpeech achieves the new state-of-the-art intelligibility and quality in target speech extraction and speech separation tasks while demonstrating exceptional generalization on out-of-domain data and real-world scenarios.

Paper number 204:
Title: VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and Extrapolation
Authors: Puyuan Peng, Shang-Wen Li, Abdelrahman Mohamed, David Harwath
Abstract: We present VoiceStar, the first zero-shot TTS model that achieves both output duration control and extrapolation. VoiceStar is an autoregressive encoder-decoder neural codec language model, that leverages a novel Progress-Monitoring Rotary Position Embedding (PM-RoPE) and is trained with Continuation-Prompt Mixed (CPM) training. PM-RoPE enables the model to better align text and speech tokens, indicates the target duration for the generated speech, and also allows the model to generate speech waveforms much longer in duration than those seen during. CPM training also helps to mitigate the training/inference mismatch, and significantly improves the quality of the generated speech in terms of speaker similarity and intelligibility. VoiceStar outperforms or is on par with current state-of-the-art models on short-form benchmarks such as Librispeech and Seed-TTS, and significantly outperforms these models on long-form/extrapolation benchmarks (20-50s) in terms of intelligibility and naturalness. Code and models: this https URL. Audio samples: this https URL

Paper number 205:
Title: Improving Speech Emotion Recognition Through Cross Modal Attention Alignment and Balanced Stacking Model
Authors: Lucas Ueda, JoÃ£o Lima, Leonardo Marques, Paula Costa
Abstract: Emotion plays a fundamental role in human interaction, and therefore systems capable of identifying emotions in speech are crucial in the context of human-computer interaction. Speech emotion recognition (SER) is a challenging problem, particularly in natural speech and when the available data is imbalanced across emotions. This paper presents our proposed system in the context of the 2025 Speech Emotion Recognition in Naturalistic Conditions Challenge. Our proposed architecture leverages cross-modality, utilizing cross-modal attention to fuse representations from different modalities. To address class imbalance, we employed two training designs: (i) weighted crossentropy loss (WCE); and (ii) WCE with an additional neutralexpressive soft margin loss and balancing. We trained a total of 12 multimodal models, which were ensembled using a balanced stacking model. Our proposed system achieves a MacroF1 score of 0.4094 and an accuracy of 0.4128 on 8-class speech emotion recognition.

Paper number 206:
Title: Interspeech 2025 URGENT Speech Enhancement Challenge
Authors: Kohei Saijo, Wangyou Zhang, Samuele Cornell, Robin Scheibler, Chenda Li, Zhaoheng Ni, Anurag Kumar, Marvin Sach, Yihui Fu, Wei Wang, Tim Fingscheidt, Shinji Watanabe
Abstract: There has been a growing effort to develop universal speech enhancement (SE) to handle inputs with various speech distortions and recording conditions. The URGENT Challenge series aims to foster such universal SE by embracing a broad range of distortion types, increasing data diversity, and incorporating extensive evaluation metrics. This work introduces the Interspeech 2025 URGENT Challenge, the second edition of the series, to explore several aspects that have received limited attention so far: language dependency, universality for more distortion types, data scalability, and the effectiveness of using noisy training data. We received 32 submissions, where the best system uses a discriminative model, while most other competitive ones are hybrid methods. Analysis reveals some key findings: (i) some generative or hybrid approaches are preferred in subjective evaluations over the top discriminative model, and (ii) purely generative SE models can exhibit language dependency.

Paper number 207:
Title: Advancing Image Super-resolution Techniques in Remote Sensing: A Comprehensive Survey
Authors: Yunliang Qi, Meng Lou, Yimin Liu, Lu Li, Zhen Yang, Wen Nie
Abstract: Remote sensing image super-resolution (RSISR) is a crucial task in remote sensing image processing, aiming to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Despite the growing number of RSISR methods proposed in recent years, a systematic and comprehensive review of these methods is still lacking. This paper presents a thorough review of RSISR algorithms, covering methodologies, datasets, and evaluation metrics. We provide an in-depth analysis of RSISR methods, categorizing them into supervised, unsupervised, and quality evaluation approaches, to help researchers understand current trends and challenges. Our review also discusses the strengths, limitations, and inherent challenges of these techniques. Notably, our analysis reveals significant limitations in existing methods, particularly in preserving fine-grained textures and geometric structures under large-scale degradation. Based on these findings, we outline future research directions, highlighting the need for domain-specific architectures and robust evaluation protocols to bridge the gap between synthetic and real-world RSISR scenarios.

Paper number 208:
Title: Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images
Authors: Aditya Retnanto (1), Son Le (1), Sebastian Mueller (1), Armin Leitner (2), Michael Riffler (2), Konrad Schindler (3), Yohan Iddawela (1) ((1) Asian Development Bank, Philippines, (2) GeoVille Information Systems and Data Processing GmbH, Austria, (3) ETH ZÃ¼rich, Switzerland)
Abstract: Super-resolution aims to increase the resolution of satellite images by reconstructing high-frequency details, which go beyond naÃ¯ve upsampling. This has particular relevance for Earth observation missions like Sentinel-2, which offer frequent, regular coverage at no cost; but at coarse resolution. Its pixel footprint is too large to capture small features like houses, streets, or hedge rows. To address this, we present SEN4X, a hybrid super-resolution architecture that combines the advantages of single-image and multi-image techniques. It combines temporal oversampling from repeated Sentinel-2 acquisitions with a learned prior from high-resolution PlÃ©iades Neo data. In doing so, SEN4X upgrades Sentinel-2 imagery to 2.5 m ground sampling distance. We test the super-resolved images on urban land-cover classification in Hanoi, Vietnam. We find that they lead to a significant performance improvement over state-of-the-art super-resolution baselines.

Paper number 209:
Title: Fact-Checking of AI-Generated Reports
Authors: Razi Mahmood, Diego Machado Reyes, Ge Wang, Mannudeep Kalra, Pingkun Yan
Abstract: With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility of such an examiner is demonstrated for verifying automatically generated reports by detecting and removing fake sentences. Future generative AI approaches can use the resulting tool to validate their reports leading to a more responsible use of AI in expediting clinical workflows.

Paper number 210:
Title: Sampling and Uniqueness Sets in Graphon Signal Processing
Authors: Alejandro Parada-Mayorga, Alejandro Ribeiro
Abstract: In this work, we study the properties of sampling sets on families of large graphs by leveraging the theory of graphons and graph limits. To this end, we extend to graphon signals the notion of removable and uniqueness sets, which was developed originally for the analysis of signals on graphs. We state the formal definition of a $\Lambda-$removable set and conditions under which a bandlimited graphon signal can be represented in a unique way when its samples are obtained from the complement of a given $\Lambda-$removable set in the graphon. By leveraging such results we show that graphon representations of graphs and graph signals can be used as a common framework to compare sampling sets between graphs with different numbers of nodes and edges, and different node labelings. Additionally, given a sequence of graphs that converges to a graphon, we show that the sequences of sampling sets whose graphon representation is identical in $[0,1]$ are convergent as well. We exploit the convergence results to provide an algorithm that obtains approximately close to optimal sampling sets. Performing a set of numerical experiments, we evaluate the quality of these sampling sets. Our results open the door for the efficient computation of optimal sampling sets in graphs of large size.

Paper number 211:
Title: SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition
Authors: Shuangrui Ding, Zihan Liu, Xiaoyi Dong, Pan Zhang, Rui Qian, Junhao Huang, Conghui He, Dahua Lin, Jiaqi Wang
Abstract: Creating lyrics and melodies for the vocal track in a symbolic format, known as song composition, demands expert musical knowledge of melody, an advanced understanding of lyrics, and precise alignment between them. Despite achievements in sub-tasks such as lyric generation, lyric-to-melody, and melody-to-lyric, etc, a unified model for song composition has not yet been achieved. In this paper, we introduce SongComposer, a pioneering step towards a unified song composition model that can readily create symbolic lyrics and melodies following instructions. SongComposer is a music-specialized large language model (LLM) that, for the first time, integrates the capability of simultaneously composing lyrics and melodies into LLMs by leveraging three key innovations: 1) a flexible tuple format for word-level alignment of lyrics and melodies, 2) an extended tokenizer vocabulary for song notes, with scalar initialization based on musical knowledge to capture rhythm, and 3) a multi-stage pipeline that captures musical structure, starting with motif-level melody patterns and progressing to phrase-level structure for improved coherence. Extensive experiments demonstrate that SongComposer outperforms advanced LLMs, including GPT-4, in tasks such as lyric-to-melody generation, melody-to-lyric generation, song continuation, and text-to-song creation. Moreover, we will release SongCompose, a large-scale dataset for training, containing paired lyrics and melodies in Chinese and English.

Paper number 212:
Title: Aerial Relay to Achieve Covertness and Security
Authors: Jiacheng Jiang, Hongjiang Lei, Ki-Hong Park, Gaofeng Pan, Mohamed-Slim Alouini
Abstract: In this work, a delay-tolerant unmanned aerial vehicle (UAV) relayed covert and secure communication framework is investigated. In this framework, a legitimate UAV serves as an aerial relay to realize communication when the direct link between the terrestrial transmitter and receiver is blocked and also acts as a friendly jammer to suppress the malicious nodes presented on the ground. Subsequently, considering the uncertainty of malicious nodes' positions, a robust fractional programming optimization problem is built to maximize energy efficiency by jointly optimizing the trajectory of the UAV, the transmit power of the transmitter, and the time-switching factor. For the extremely complicated covert constraint, Pinsker's inequality, Jensen's inequality, and the bisection search method are employed to construct a tractable shrunken one. After this, an alternate optimization-based algorithm is proposed to solve the fractional programming optimization problem. To achieve low complexity, we design the primal-dual search-based algorithm and the successive convex approximation-based algorithm, respectively, for each sub-problem. Numerical results show the effectiveness of our proposed algorithm.

Paper number 213:
Title: Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs
Authors: Haifeng Wen, Hong Xing, Osvaldo Simeone
Abstract: For modern artificial intelligence (AI) applications such as large language models (LLMs), the training paradigm has recently shifted to pre-training followed by fine-tuning. Furthermore, owing to dwindling open repositories of data and thanks to efforts to democratize access to AI models, pre-training is expected to increasingly migrate from the current centralized deployments to federated learning (FL) implementations. Meta-learning provides a general framework in which pre-training and fine-tuning can be formalized. Meta-learning-based personalized FL (meta-pFL) moves beyond basic personalization by targeting generalization to new agents and tasks. This paper studies the generalization performance of meta-pFL for a wireless setting in which the agents participating in the pre-training phase, i.e., meta-learning, are connected via a shared wireless channel to the server. Adopting over-the-air computing, we study the trade-off between generalization to new agents and tasks, on the one hand, and convergence, on the other hand. The trade-off arises from the fact that channel impairments may enhance generalization, while degrading convergence. Extensive numerical results validate the theory.

Paper number 214:
Title: On zero-shot learning in neural state estimation of power distribution systems
Authors: Aleksandr Berezin, Stephan Balduin, Thomas OberlieÃen, Sebastian Peter, Eric MSP Veith
Abstract: This paper addresses the challenge of neural state estimation in power distribution systems. We identified a research gap in the current state of the art, which lies in the inability of models to adapt to changes in the power grid, such as loss of sensors and branch switching, in a zero-shot fashion. Based on the literature, we identified graph neural networks as the most promising class of models for this use case. Our experiments confirm their robustness to some grid changes and also show that a deeper network does not always perform better. We propose data augmentations to improve performance and conduct a comprehensive grid search of different model configurations for common zero-shot learning scenarios.

Paper number 215:
Title: Agile Decision-Making and Safety-Critical Motion Planning for Emergency Autonomous Vehicles
Authors: Yiming Shu, Jingyuan Zhou, Fu Zhang
Abstract: Efficiency is critical for autonomous vehicles (AVs), especially for emergency AVs. However, most existing methods focus on regular vehicles, overlooking the distinct strategies required by emergency vehicles to address the challenge of maximizing efficiency while ensuring safety. In this paper, we propose an Integrated Agile Decision-Making with Active and Safety-Critical Motion Planning System (IDEAM). IDEAM focuses on enabling emergency AVs, such as ambulances, to actively attain efficiency in dense traffic scenarios with safety in mind. Firstly, the speed-centric decision-making algorithm named the long short-term spatio-temporal graph-centric decision-making (LSGM) is given. LSGM comprises conditional depth-first search (C-DFS) for multiple paths generation as well as methods for speed gains and risk evaluation for path selection, which presents a robust algorithm for high efficiency and safety consideration. Secondly, with an output path from LSGM, the motion planner reconsiders environmental conditions to decide constraints states for the final planning stage, among which the lane-probing state is designed for actively attaining spatial and speed advantage. Thirdly, under the Frenet-based model predictive control (MPC) framework with final constraints state and selected path, the safety-critical motion planner employs decoupled discrete control barrier functions (DCBFs) and linearized discrete-time high-order control barrier functions (DHOCBFs) to model the constraints associated with different driving behaviors, making the optimal optimization problem convex. Finally, we extensively validate our system using scenarios from a randomly synthetic dataset, demonstrating its capability to achieve speed benefits and assure safety simultaneously.

Paper number 216:
Title: Egocentric Speaker Classification in Child-Adult Dyadic Interactions: From Sensing to Computational Modeling
Authors: Tiantian Feng, Anfeng Xu, Xuan Shi, Somer Bishop, Shrikanth Narayanan
Abstract: Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by challenges in social communication, repetitive behavior, and sensory processing. One important research area in ASD is evaluating children's behavioral changes over time during treatment. The standard protocol with this objective is BOSCC, which involves dyadic interactions between a child and clinicians performing a pre-defined set of activities. A fundamental aspect of understanding children's behavior in these interactions is automatic speech understanding, particularly identifying who speaks and when. Conventional approaches in this area heavily rely on speech samples recorded from a spectator perspective, and there is limited research on egocentric speech modeling. In this study, we design an experiment to perform speech sampling in BOSCC interviews from an egocentric perspective using wearable sensors and explore pre-training Ego4D speech samples to enhance child-adult speaker classification in dyadic interactions. Our findings highlight the potential of egocentric speech collection and pre-training to improve speaker classification accuracy.

Paper number 217:
Title: Differential privacy enables fair and accurate AI-based analysis of speech disorders while protecting patient data
Authors: Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Mahtab Ranji, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang
Abstract: Speech pathology has impacts on communication abilities and quality of life. While deep learning-based models have shown potential in diagnosing these disorders, the use of sensitive data raises critical privacy concerns. Although differential privacy (DP) has been explored in the medical imaging domain, its application in pathological speech analysis remains largely unexplored despite the equally critical privacy concerns. To the best of our knowledge, this study is the first to investigate DP's impact on pathological speech data, focusing on the trade-offs between privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset of 200 hours of recordings from 2,839 German-speaking participants, we observed a maximum accuracy reduction of 3.85% when training with DP with high privacy levels. To highlight real-world privacy risks, we demonstrated the vulnerability of non-private models to gradient inversion attacks, reconstructing identifiable speech samples and showcasing DP's effectiveness in mitigating these risks. To explore the potential generalizability across languages and disorders, we validated our approach on a dataset of Spanish-speaking Parkinson's disease patients, leveraging pretrained models from healthy English-speaking datasets, and demonstrated that careful pretraining on large-scale task-specific datasets can maintain favorable accuracy under DP constraints. A comprehensive fairness analysis revealed minimal gender bias at reasonable privacy levels but underscored the need for addressing age-related disparities. Our results establish that DP can balance privacy and utility in speech disorder detection, while highlighting unique challenges in privacy-fairness trade-offs for speech data. This provides a foundation for refining DP methodologies and improving fairness across diverse patient groups in real-world deployments.

Paper number 218:
Title: AfriHuBERT: A self-supervised speech representation model for African languages
Authors: Jesujoba O. Alabi, Xuechen Liu, Dietrich Klakow, Junichi Yamagishi
Abstract: In this work, we present AfriHuBERT, an extension of mHuBERT-147, a compact self-supervised learning (SSL) model pretrained on 147 languages. While mHuBERT-147 covered 16 African languages, we expand this to 1,226 through continued pretraining on 10K+ hours of speech data from diverse sources, benefiting an African population of over 600M. We evaluate AfriHuBERT on two key speech tasks, Spoken Language Identification (SLID) and Automatic Speech Recognition (ASR), using the FLEURS benchmark. Our results show a +3.6% F1 score improvement for SLID and a -2.1% average Word Error Rate (WER) reduction for ASR over mHuBERT-147, and demonstrates competitiveness with larger SSL models such as MMS and XEUS. Further analysis shows that ASR models trained on AfriHuBERT exhibit improved cross-corpus generalization and are competitive in extremely low-resource ASR scenarios.

Paper number 219:
Title: Flex3D: Feed-Forward 3D Generation with Flexible Reconstruction Model and Input View Curation
Authors: Junlin Han, Jianyuan Wang, Andrea Vedaldi, Philip Torr, Filippos Kokkinos
Abstract: Generating high-quality 3D content from text, single images, or sparse view images remains a challenging task with broad applications. Existing methods typically employ multi-view diffusion models to synthesize multi-view images, followed by a feed-forward process for 3D reconstruction. However, these approaches are often constrained by a small and fixed number of input views, limiting their ability to capture diverse viewpoints and, even worse, leading to suboptimal generation results if the synthesized views are of poor quality. To address these limitations, we propose Flex3D, a novel two-stage framework capable of leveraging an arbitrary number of high-quality input views. The first stage consists of a candidate view generation and curation pipeline. We employ a fine-tuned multi-view image diffusion model and a video diffusion model to generate a pool of candidate views, enabling a rich representation of the target 3D object. Subsequently, a view selection pipeline filters these views based on quality and consistency, ensuring that only the high-quality and reliable views are used for reconstruction. In the second stage, the curated views are fed into a Flexible Reconstruction Model (FlexRM), built upon a transformer architecture that can effectively process an arbitrary number of inputs. FlemRM directly outputs 3D Gaussian points leveraging a tri-plane representation, enabling efficient and detailed 3D generation. Through extensive exploration of design and training strategies, we optimize FlexRM to achieve superior performance in both reconstruction and generation tasks. Our results demonstrate that Flex3D achieves state-of-the-art performance, with a user study winning rate of over 92% in 3D generation tasks when compared to several of the latest feed-forward 3D generative models.

Paper number 220:
Title: Learning to Drift in Extreme Turning with Active Exploration and Gaussian Process Based MPC
Authors: Guoqiang Wu, Cheng Hu, Wangjia Weng, Zhouheng Li, Yonghao Fu, Lei Xie, Hongye Su
Abstract: Extreme cornering in racing often leads to large sideslip angles, presenting a significant challenge for vehicle control. Conventional vehicle controllers struggle to manage this scenario, necessitating the use of a drifting controller. However, the large sideslip angle in drift conditions introduces model mismatch, which in turn affects control precision. To address this issue, we propose a model correction drift controller that integrates Model Predictive Control (MPC) with Gaussian Process Regression (GPR). GPR is employed to correct vehicle model mismatches during both drift equilibrium solving and the MPC optimization process. Additionally, the variance from GPR is utilized to actively explore different cornering drifting velocities, aiming to minimize trajectory tracking errors. The proposed algorithm is validated through simulations on the Simulink-Carsim platform and experiments with a 1:10 scale RC vehicle. In the simulation, the average lateral error with GPR is reduced by 52.8% compared to the non-GPR case. Incorporating exploration further decreases this error by 27.1%. The velocity tracking Root Mean Square Error (RMSE) also decreases by 10.6% with exploration. In the RC car experiment, the average lateral error with GPR is 36.7% lower, and exploration further leads to a 29.0% reduction. Moreover, the velocity tracking RMSE decreases by 7.2% with the inclusion of exploration.

Paper number 221:
Title: Convolutional Filtering with RKHS Algebras
Authors: Alejandro Parada-Mayorga, Leopoldo Agorio, Alejandro Ribeiro, Juan Bazerque
Abstract: In this paper, we develop a generalized theory of convolutional signal processing and neural networks for Reproducing Kernel Hilbert Spaces (RKHS). Leveraging the theory of algebraic signal processing (ASP), we show that any RKHS allows the formal definition of multiple algebraic convolutional models. We show that any RKHS induces algebras whose elements determine convolutional operators acting on RKHS elements. This approach allows us to achieve scalable filtering and learning as a byproduct of the convolutional model, and simultaneously take advantage of the well-known benefits of processing information in an RKHS. To emphasize the generality and usefulness of our approach, we show how algebraic RKHS can be used to define convolutional signal models on groups, graphons, and traditional Euclidean signal spaces. Furthermore, using algebraic RKHS models, we build convolutional networks, formally defining the notion of pointwise nonlinearities and deriving explicit expressions for the training. Such derivations are obtained in terms of the algebraic representation of the RKHS. We present a set of numerical experiments on real data in which wireless coverage is predicted from measurements captured by unmaned aerial vehicles. This particular real-life scenario emphasizes the benefits of the convolutional RKHS models in neural networks compared to fully connected and standard convolutional operators.

Paper number 222:
Title: Enhancing Sample Generation of Diffusion Models using Noise Level Correction
Authors: Abulikemu Abuduweili, Chenyang Yuan, Changliu Liu, Frank Permenter
Abstract: The denoising process of diffusion models can be interpreted as an approximate projection of noisy samples onto the data manifold. Moreover, the noise level in these samples approximates their distance to the underlying manifold. Building on this insight, we propose a novel method to enhance sample generation by aligning the estimated noise level with the true distance of noisy samples to the manifold. Specifically, we introduce a noise level correction network, leveraging a pre-trained denoising network, to refine noise level estimates during the denoising process. Additionally, we extend this approach to various image restoration tasks by integrating task-specific constraints, including inpainting, deblurring, super-resolution, colorization, and compressed sensing. Experimental results demonstrate that our method significantly improves sample quality in both unconstrained and constrained generation scenarios. Notably, the proposed noise level correction framework is compatible with existing denoising schedulers (e.g., DDIM), offering additional performance improvements.

Paper number 223:
Title: MADUV: The 1st INTERSPEECH Mice Autism Detection via Ultrasound Vocalization Challenge
Authors: Zijiang Yang, Meishu Song, Xin Jing, Haojie Zhang, Kun Qian, Bin Hu, Kota Tamada, Toru Takumi, BjÃ¶rn W. Schuller, Yoshiharu Yamamoto
Abstract: The Mice Autism Detection via Ultrasound Vocalization (MADUV) Challenge introduces the first INTERSPEECH challenge focused on detecting autism spectrum disorder (ASD) in mice through their vocalizations. Participants are tasked with developing models to automatically classify mice as either wild-type or ASD models based on recordings with a high sampling rate. Our baseline system employs a simple CNN-based classification using three different spectrogram features. Results demonstrate the feasibility of automated ASD detection, with the considered audible-range features achieving the best performance (UAR of 0.600 for segment-level and 0.625 for subject-level classification). This challenge bridges speech technology and biomedical research, offering opportunities to advance our understanding of ASD models through machine learning approaches. The findings suggest promising directions for vocalization analysis and highlight the potential value of audible and ultrasound vocalizations in ASD detection.

Paper number 224:
Title: Towards Early Prediction of Self-Supervised Speech Model Performance
Authors: Ryan Whetten, Lucas Maison, Titouan Parcollet, Marco Dinarelli, Yannick EstÃ¨ve
Abstract: In Self-Supervised Learning (SSL), pre-training and evaluation are resource intensive. In the speech domain, current indicators of the quality of SSL models during pre-training, such as the loss, do not correlate well with downstream performance. Consequently, it is often difficult to gauge the final downstream performance in a cost efficient manner during pre-training. In this work, we propose unsupervised efficient methods that give insights into the quality of the pre-training of SSL speech models, namely, measuring the cluster quality and rank of the embeddings of the SSL model. Results show that measures of cluster quality and rank correlate better with downstream performance than the pre-training loss with only one hour of unlabeled audio, reducing the need for GPU hours and labeled data in SSL model evaluation.

Paper number 225:
Title: In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review
Authors: Amelia JimÃ©nez-SÃ¡nchez, Natalia-Rozalia Avlona, Sarah de Boer, VÃ­ctor M. Campello, Aasa Feragen, Enzo Ferrante, Melanie Ganz, Judy Wawira Gichoya, Camila GonzÃ¡lez, Steff Groefsema, Alessa Hering, Adam Hulman, Leo Joskowicz, Dovile Juodelyte, Melih Kandemir, Thijs Kooi, Jorge del Pozo LÃ©rida, Livie Yumeng Li, Andre Pacheco, Tim RÃ¤dsch, Mauricio Reyes, ThÃ©o Sourget, Bram van Ginneken, David Wen, Nina Weng, Jack Junchi Xu, Hubert Dariusz ZajÄc, Maria A. Zuluaga, Veronika Cheplygina
Abstract: Datasets play a critical role in medical imaging research, yet issues such as label quality, shortcuts, and metadata are often overlooked. This lack of attention may harm the generalizability of algorithms and, consequently, negatively impact patient outcomes. While existing medical imaging literature reviews mostly focus on machine learning (ML) methods, with only a few focusing on datasets for specific applications, these reviews remain static -- they are published once and not updated thereafter. This fails to account for emerging evidence, such as biases, shortcuts, and additional annotations that other researchers may contribute after the dataset is published. We refer to these newly discovered findings of datasets as research artifacts. To address this gap, we propose a living review that continuously tracks public datasets and their associated research artifacts across multiple medical imaging applications. Our approach includes a framework for the living review to monitor data documentation artifacts, and an SQL database to visualize the citation relationships between research artifact and dataset. Lastly, we discuss key considerations for creating medical imaging datasets, review best practices for data annotation, discuss the significance of shortcuts and demographic diversity, and emphasize the importance of managing datasets throughout their entire lifecycle. Our demo is publicly available at this http URL.

Paper number 226:
Title: Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models
Authors: Hao Cheng, Erjia Xiao, Jing Shao, Yichi Wang, Le Yang, Chao Shen, Philip Torr, Jindong Gu, Renjing Xu
Abstract: Large Language Models (LLMs) demonstrate impressive zero-shot performance across a wide range of natural language processing tasks. Integrating various modality encoders further expands their capabilities, giving rise to Multimodal Large Language Models (MLLMs) that process not only text but also visual and auditory modality inputs. However, these advanced capabilities may also pose significant security risks, as models can be exploited to generate harmful or inappropriate content through jailbreak attack. While prior work has extensively explored how manipulating textual or visual modality inputs can circumvent safeguards in LLMs and MLLMs, the vulnerability of audio-specific Jailbreak on Large Audio-Language Models (LALMs) remains largely underexplored. To address this gap, we introduce \textbf{Jailbreak-AudioBench}, which consists of the Toolbox, curated Dataset, and comprehensive Benchmark. The Toolbox supports not only text-to-audio conversion but also various editing techniques for injecting audio hidden semantics. The curated Dataset provides diverse explicit and implicit jailbreak audio examples in both original and edited forms. Utilizing this dataset, we evaluate multiple state-of-the-art LALMs and establish the most comprehensive Jailbreak benchmark to date for audio modality. Finally, Jailbreak-AudioBench establishes a foundation for advancing future research on LALMs safety alignment by enabling the in-depth exposure of more powerful jailbreak threats, such as query-based audio editing, and by facilitating the development of effective defense mechanisms.

Paper number 227:
Title: Autonomous Robotic Radio Source Localization via a Novel Gaussian Mixture Filtering Approach
Authors: Sukkeun Kim, Sangwoo Moon, Ivan Petrunin, Hyo-Sang Shin, Shehryar Khattak
Abstract: This study proposes a new Gaussian Mixture Filter (GMF) to improve the estimation performance for the autonomous robotic radio signal source search and localization problem in unknown environments. The proposed filter is first tested with a benchmark numerical problem to validate the performance with other state-of-the-practice approaches such as Particle Filter (PF) and Particle Gaussian Mixture (PGM) filters. Then the proposed approach is tested and compared against PF and PGM filters in real-world robotic field experiments to validate its impact for real-world applications. The considered real-world scenarios have partial observability with the range-only measurement and uncertainty with the measurement model. The results show that the proposed filter can handle this partial observability effectively whilst showing improved performance compared to PF, reducing the computation requirements while demonstrating improved robustness over compared techniques.

Paper number 228:
Title: Distances between finite-horizon linear behaviors
Authors: Alberto Padoan, Jeremy Coulson
Abstract: The paper introduces a class of distances for linear behaviors over finite time horizons. These distances allow for comparisons between finite-horizon linear behaviors represented by matrices of possibly different dimensions. They remain invariant under coordinate changes, rotations, and permutations, ensuring independence from input-output partitions. Moreover, they naturally encode complexity-misfit trade-offs for Linear Time-Invariant (LTI) behaviors, providing a principled solution to a longstanding puzzle in behavioral systems theory. The resulting framework characterizes modeling as a minimum distance problem, identifying the Most Powerful Unfalsified Model (MPUM) as optimal among all systems unfalsified by a given dataset. Finally, we illustrate the value of these metrics in a time series anomaly detection task, where their finer resolution yields superior performance over existing distances.

Paper number 229:
Title: TeleMoM: Consensus-Driven Telecom Intelligence via Mixture of Models
Authors: Xinquan Wang, Fenghao Zhu, Chongwen Huang, Zhaohui Yang, Zhaoyang Zhang, Sami Muhaidat, Chau Yuen, MÃ©rouane Debbah
Abstract: Large language models (LLMs) face significant challenges in specialized domains like telecommunication (Telecom) due to technical complexity, specialized terminology, and rapidly evolving knowledge. Traditional methods, such as scaling model parameters or retraining on domain-specific corpora, are computationally expensive and yield diminishing returns, while existing approaches like retrieval-augmented generation, mixture of experts, and fine-tuning struggle with accuracy, efficiency, and coordination. To address this issue, we propose Telecom mixture of models (TeleMoM), a consensus-driven ensemble framework that integrates multiple LLMs for enhanced decision-making in Telecom. TeleMoM employs a two-stage process: proponent models generate justified responses, and an adjudicator finalizes decisions, supported by a quality-checking mechanism. This approach leverages strengths of diverse models to improve accuracy, reduce biases, and handle domain-specific complexities effectively. Evaluation results demonstrate that TeleMoM achieves a 9.7\% increase in answer accuracy, highlighting its effectiveness in Telecom applications.

Paper number 230:
Title: Optimizing Movable Antennas in Wideband Multi-User MIMO With Hardware Impairments
Authors: Amna Irshad, Emil BjÃ¶rnson, Alva Kosasih, Vitaly Petrov
Abstract: Movable antennas represent an emerging field in telecommunication research and a potential approach to achieving higher data rates in multiple-input multiple-output (MIMO) communications when the total number of antennas is limited. Most solutions and analyses to date have been limited to \emph{narrowband} setups. This work complements the prior studies by quantifying the benefit of using movable antennas in \emph{wideband} MIMO communication systems. First, we derive a novel uplink wideband system model that also accounts for distortion from transceiver hardware impairments. We then formulate and solve an optimization task to maximize the average sum rate by adjusting the antenna positions using particle swarm optimization. Finally, the performance with movable antennas is compared with fixed uniform arrays and the derived theoretical upper bound. The numerical study concludes that the data rate improvement from movable antennas over other arrays heavily depends on the level of hardware impairments, the richness of the multi-path environments, and the number of subcarriers. The present study provides vital insights into the most suitable use cases for movable antennas in future wideband systems.

Paper number 231:
Title: OODTE: A Differential Testing Engine for the ONNX Optimizer
Authors: Nikolaos Louloudakis, Ajitha Rajan
Abstract: With over 700 stars on GitHub and being part of the official ONNX repository, the ONNX Optimizer is the default tool for applying graph-based optimizations to ONNX models. Despite its widespread use, its ability to maintain model accuracy during optimization has not been thoroughly investigated. In this work, we present OODTE, a utility designed to automatically and comprehensively evaluate the correctness of the ONNX Optimizer. OODTE adopts a straightforward yet powerful differential testing and evaluation methodology, which can be readily adapted for use with other compiler optimizers. Specifically, OODTE takes a collection of ONNX models, applies optimizations, and executes both the original and optimized versions across a user-defined input set, automatically capturing any issues encountered during optimization. When discrepancies in accuracy arise, OODTE iteratively isolates the responsible optimization pass by repeating the process at a finer granularity. We applied OODTE to 130 well-known models from the official ONNX Model Hub, spanning diverse tasks including classification, object detection, semantic segmentation, text summarization, question answering, and sentiment analysis. Our evaluation revealed that 9.2% of the model instances either caused the optimizer to crash or led to the generation of invalid models using default optimization strategies. Additionally, 30% of classification models and 16.6% of object detection and segmentation models exhibited differing outputs across original and optimized versions, whereas models focused on text-related tasks were generally robust to optimization. OODTE uncovered 15 issues-14 previously unknown-affecting 9 of 47 optimization passes and the optimizer overall. All issues were reported to the ONNX Optimizer team. OODTE offers a simple but effective framework for validating AI model optimizers, applicable beyond the ONNX ecosystem.

Paper number 232:
Title: Bemba Speech Translation: Exploring a Low-Resource African Language
Authors: Muhammad Hazim Al Farouq, Aman Kassahun Wassie, Yasmin Moslem
Abstract: This paper describes our system submission to the International Conference on Spoken Language Translation (IWSLT 2025), low-resource languages track, namely for Bemba-to-English speech translation. We built cascaded speech translation systems based on Whisper and NLLB-200, and employed data augmentation techniques, such as back-translation. We investigate the effect of using synthetic data and discuss our experimental setup.

Paper number 233:
Title: Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces
Authors: Nikhil M. Pawar, Jorge A. Prozzi, Feng Hong, Surya Sarat Chandra Congress
Abstract: Recently, there has been an impetus for the application of cutting-edge data collection platforms such as drones mounted with camera sensors for infrastructure asset management. However, the sensor characteristics, proximity to the structure, hard-to-reach access, and environmental conditions often limit the resolution of the datasets. A few studies used super-resolution techniques to address the problem of low-resolution images. Nevertheless, these techniques were observed to increase computational cost and false alarms of distress detection due to the consideration of all the infrastructure images i.e., positive and negative distress classes. In order to address the pre-processing of false alarm and achieve efficient super-resolution, this study developed a framework consisting of convolutional neural network (CNN) and efficient sub-pixel convolutional neural network (ESPCNN). CNN accurately classified both the classes. ESPCNN, which is the lightweight super-resolution technique, generated high-resolution infrastructure image of positive distress obtained from CNN. The ESPCNN outperformed bicubic interpolation in all the evaluation metrics for super-resolution. Based on the performance metrics, the combination of CNN and ESPCNN was observed to be effective in preprocessing the infrastructure images with negative distress, reducing the computational cost and false alarms in the next step of super-resolution. The visual inspection showed that EPSCNN is able to capture crack propagation, complex geometry of even minor cracks. The proposed framework is expected to help the highway agencies in accurately performing distress detection and assist in efficient asset management practices.

Paper number 234:
Title: Particle Gibbs without the Gibbs bit
Authors: Adrien Corenflos
Abstract: Exact parameter and trajectory inference in state-space models is typically achieved by one of two methods: particle marginal Metropolis-Hastings (PMMH) or particle Gibbs (PGibbs). PMMH is a pseudo-marginal algorithm which jointly proposes a new trajectory and parameter, and accepts or rejects both at once. PGibbs instead alternates between sampling from the trajectory, using an algorithm known as conditional sequential Monte Carlo (CSMC) and the parameter in a Hastings-within-Gibbs fashion. While particle independent Metropolis Hastings (PIMH), the parameter-free version of PMMH, is known to be statistically worse than CSMC, PGibbs can induce a slow mixing if the parameter and the state trajectory are very correlated. This has made PMMH the method of choice for many practitioners, despite theory and experiments favouring CSMC over PIMH for the parameter-free problem. In this article, we describe a formulation of PGibbs which bypasses the Gibbs step, essentially marginalizing over the trajectory distribution in a fashion similar to PMMH. This is achieved by considering the implementation of a CSMC algortihm for the state-space model integrated over the joint distribution of the current parameter and the parameter proposal. We illustrate the benefits of method on a simple example known to be challenging for PMMH.

Paper number 235:
Title: Polarforming Antenna Enhanced Sensing and Communication: Modeling and Optimization
Authors: Xiaodan Shao, Rui Zhang, Haibo Zhou, Qijun Jiang, Conghao Zhou, Weihua Zhuang, Xuemin Shen
Abstract: In this paper, we propose a novel polarforming antenna (PA) to achieve cost-effective wireless sensing and communication. Specifically, the PA can enable polarforming to adaptively control the antenna's polarization electrically as well as tune its position/rotation mechanically, so as to effectively exploit polarization and spatial diversity to reconfigure wireless channels for improving sensing and communication performance. We study an PA-enhanced integrated sensing and communication (ISAC) system that utilizes user location sensing to facilitate communication between an PA-equipped base station (BS) and PA-equipped users. First, we model the PA channel in terms of transceiver antenna polarforming vectors and antenna positions/rotations. We then propose a two-timescale ISAC protocol, where in the slow timescale, user localization is first performed, followed by the optimization of the BS antennas' positions and rotations based on the sensed user locations; subsequently, in the fast timescale, transceiver polarforming is adapted to cater to the instantaneous channel state information (CSI), with the optimized BS antennas' positions and rotations. We propose a new polarforming-based user localization method that uses a structured time-domain pattern of pilot-polarforming vectors to extract the common stable components in the PA channel across different polarizations based on the parallel factor (PARAFAC) tensor model. Moreover, we maximize the achievable average sum-rate of users by jointly optimizing the fast-timescale transceiver polarforming, including phase shifts and amplitude variations, along with the slow-timescale antenna rotations and positions at the BS. Simulation results validate the effectiveness of polarforming-based localization algorithm and demonstrate the performance advantages of polarforming, antenna placement, and their joint design.

Paper number 236:
Title: A Comparative Study of SMT and MILP for the Nurse Rostering Problem
Authors: Alvin Combrink, Stephie Do, Kristofer Bengtsson, Sabino Francesco Roselli, Martin Fabian
Abstract: The effects of personnel scheduling on the quality of care and working conditions for healthcare personnel have been thoroughly documented. However, the ever-present demand and large variation of constraints make healthcare scheduling particularly challenging. This problem has been studied for decades, with limited research aimed at applying Satisfiability Modulo Theories (SMT). SMT has gained momentum within the formal verification community in the last decades, leading to the advancement of SMT solvers that have been shown to outperform standard mathematical programming techniques. In this work, we propose generic constraint formulations that can model a wide range of real-world scheduling constraints. Then, the generic constraints are formulated as SMT and MILP problems and used to compare the respective state-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired rostering problems. Experimental results show how each solver excels for certain types of problems; the MILP solver generally performs better when the problem is highly constrained or infeasible, while the SMT solver performs better otherwise. On real-world inspired problems containing a more varied set of shifts and personnel, the SMT solver excels. Additionally, it was noted during experimentation that the SMT solver was more sensitive to the way the generic constraints were formulated, requiring careful consideration and experimentation to achieve better performance. We conclude that SMT-based methods present a promising avenue for future research within the domain of personnel scheduling.

Paper number 237:
Title: Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy
Authors: Xuanjun Chen, I-Ming Lin, Lin Zhang, Jiawei Du, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang
Abstract: Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.

Paper number 238:
Title: From Structural Design to Dynamics Modeling: Control-Oriented Development of a 3-RRR Parallel Ankle Rehabilitation Robot
Authors: Siyuan Zhang, Yufei Zhang, Junlin Lyu, Sunil K. Agrawal
Abstract: This paper presents the development of a wearable ankle rehabilitation robot based on a 3-RRR spherical parallel mechanism (SPM) to support multi-DOF recovery through pitch, roll, and yaw motions. The system features a compact, ergonomic structure designed for comfort, safety, and compatibility with ankle biomechanics. A complete design-to-dynamics pipeline has been implemented, including structural design, kinematic modeling for motion planning, and Lagrangian-based dynamic modeling for torque estimation and simulation analysis. Preliminary simulations verify stable joint coordination and smooth motion tracking under representative rehabilitation trajectories. The control framework is currently being developed to enhance responsiveness across the workspace. Future work will focus on integrating personalized modeling and adaptive strategies to address kinematic singularities through model based control. This work establishes a foundational platform for intelligent, personalized ankle rehabilitation, enabling both static training and potential extension to gait-phase-timed assistance.

Paper number 239:
Title: Forensic deepfake audio detection using segmental speech features
Authors: Tianle Yang, Chengzhe Sun, Siwei Lyu, Phil Rose
Abstract: This study explores the potential of using acoustic features of segmental speech sounds to detect deepfake audio. These features are highly interpretable because of their close relationship with human articulatory processes and are expected to be more difficult for deepfake models to replicate. The results demonstrate that certain segmental features commonly used in forensic voice comparison (FVC) are effective in identifying deep-fakes, whereas some global features provide little value. These findings underscore the need to approach audio deepfake detection using methods that are distinct from those employed in traditional FVC, and offer a new perspective on leveraging segmental features for this purpose.

Paper number 240:
Title: Replay Attacks Against Audio Deepfake Detection
Authors: Nicolas MÃ¼ller, Piotr Kawa, Wei-Herng Choong, Adriana Stan, Aditya Tirumala Bukkapatnam, Karla Pizzi, Alexander Wagner, Philip Sperl
Abstract: We show how replay attacks undermine audio deepfake detection: By playing and re-recording deepfake audio through various speakers and microphones, we make spoofed samples appear authentic to the detection model. To study this phenomenon in more detail, we introduce ReplayDF, a dataset of recordings derived from M-AILABS and MLAAD, featuring 109 speaker-microphone combinations across six languages and four TTS models. It includes diverse acoustic conditions, some highly challenging for detection. Our analysis of six open-source detection models across five datasets reveals significant vulnerability, with the top-performing W2V2-AASIST model's Equal Error Rate (EER) surging from 4.7% to 18.2%. Even with adaptive Room Impulse Response (RIR) retraining, performance remains compromised with an 11.0% EER. We release ReplayDF for non-commercial research use.

Paper number 241:
Title: Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models
Authors: Shunsuke Kando, Yusuke Miyao, Shinnosuke Takamichi
Abstract: The purpose of speech tokenization is to transform a speech signal into a sequence of discrete representations, serving as the foundation for speech language models (SLMs). While speech tokenization has many options, their effect on the performance of SLMs remains unclear. This paper investigates two key aspects of speech tokenization: the segmentation width and the cluster size of discrete units. First, we segment speech signals into fixed/variable widths and pooled representations. We then train K-means models in multiple cluster sizes. Through the evaluation on zero-shot spoken language understanding benchmarks, we find the positive effect of moderately coarse segmentation and bigger cluster size. Notably, among the best-performing models, the most efficient one achieves a 50% reduction in training data and a 70% decrease in training runtime. Our analysis highlights the importance of combining multiple tokens to enhance fine-grained spoken language understanding.

Paper number 242:
Title: MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation
Authors: Kaixing Yang, Xulong Tang, Ziqiao Peng, Yuxuan Hu, Jun He, Hongyan Liu
Abstract: Music-driven 3D dance generation has attracted increasing attention in recent years, with promising applications in choreography, virtual reality, and creative content creation. Previous research has generated promising realistic dance movement from audio signals. However, traditional methods underutilize genre conditioning, often treating it as auxiliary modifiers rather than core semantic drivers. This oversight compromises music-motion synchronization and disrupts dance genre continuity, particularly during complex rhythmic transitions, thereby leading to visually unsatisfactory effects. To address the challenge, we propose MEGADance, a novel architecture for music-driven 3D dance generation. By decoupling choreographic consistency into dance generality and genre specificity, MEGADance demonstrates significant dance quality and strong genre controllability. It consists of two stages: (1) High-Fidelity Dance Quantization Stage (HFDQ), which encodes dance motions into a latent representation by Finite Scalar Quantization (FSQ) and reconstructs them with kinematic-dynamic constraints, and (2) Genre-Aware Dance Generation Stage (GADG), which maps music into the latent representation by synergistic utilization of Mixture-of-Experts (MoE) mechanism with Mamba-Transformer hybrid backbone. Extensive experiments on the FineDance and AIST++ dataset demonstrate the state-of-the-art performance of MEGADance both qualitatively and quantitatively. Code will be released upon acceptance.

Paper number 243:
Title: ALPCAHUS: Subspace Clustering for Heteroscedastic Data
Authors: Javier Salazar Cavazos, Jeffrey A Fessler, Laura Balzano
Abstract: Principal component analysis (PCA) is a key tool in the field of data dimensionality reduction. Various methods have been proposed to extend PCA to the union of subspace (UoS) setting for clustering data that come from multiple subspaces like K-Subspaces (KSS). However, some applications involve heterogeneous data that vary in quality due to noise characteristics associated with each data sample. Heteroscedastic methods aim to deal with such mixed data quality. This paper develops a heteroscedastic-focused subspace clustering method, named ALPCAHUS, that can estimate the sample-wise noise variances and use this information to improve the estimate of the subspace bases associated with the low-rank structure of the data. This clustering algorithm builds on K-Subspaces (KSS) principles by extending the recently proposed heteroscedastic PCA method, named LR-ALPCAH, for clusters with heteroscedastic noise in the UoS setting. Simulations and real-data experiments show the effectiveness of accounting for data heteroscedasticity compared to existing clustering algorithms. Code available at this https URL.

Paper number 244:
Title: Efficient Speech Translation through Model Compression and Knowledge Distillation
Authors: Yasmin Moslem
Abstract: Efficient deployment of large audio-language models for speech translation remains challenging due to their significant computational requirements. In this paper, we address this challenge through our system submissions to the "Model Compression" track at the International Conference on Spoken Language Translation (IWSLT 2025). We experiment with a combination of approaches including iterative layer pruning based on layer importance evaluation, low-rank adaptation with 4-bit quantization (QLoRA), and knowledge distillation. In our experiments, we use Qwen2-Audio-7B-Instruct for speech translation into German and Chinese. Our pruned (student) models achieve up to a 50% reduction in both model parameters and storage footprint, while retaining 97-100% of the translation quality of the in-domain (teacher) models.

Paper number 245:
Title: Training Articulatory Inversion Models for Inter-Speaker Consistency
Authors: Charles McGhee, Mark J.F. Gales, Kate M. Knill
Abstract: Acoustic-to-Articulatory Inversion (AAI) attempts to model the inverse mapping from speech to articulation. Exact articulatory prediction from speech alone may be impossible, as speakers can choose different forms of articulation seemingly without reference to their vocal tract structure. However, once a speaker has selected an articulatory form, their productions vary minimally. Recent works in AAI have proposed adapting Self-Supervised Learning (SSL) models to single-speaker datasets, claiming that these single-speaker models provide a universal articulatory template. In this paper, we investigate whether SSL-adapted models trained on single and multi-speaker data produce articulatory targets which are consistent across speaker identities for English and Russian. We do this through the use of a novel evaluation method which extracts articulatory targets using minimal pair sets. We also present a training method which can improve interspeaker consistency using only speech data.

Paper number 246:
Title: Polarforming for Wireless Networks: Opportunities and Challenges
Authors: Jingze Ding, Zijian Zhou, Xiaodan Shao, Bingli Jiao, Rui Zhang
Abstract: Polarforming emerges as a promising technique for manipulating the polarization of electromagnetic (EM) waves by shaping the polarization of an antenna into a desired state. By dynamically adjusting antenna polarization, polarforming enables real-time polarization matching or mismatching with received EM waves, thereby leveraging polarization degrees of freedom (DoFs) to enhance wireless communication performance. In this article, we first present an overview of the fundamental principles and design approaches underlying the polarforming technique. We then analyze the key advantages of polarforming, including hardware cost reduction, depolarization mitigation, channel adaptation, signal power enhancement, and interference suppression. Furthermore, we explore promising applications of polarforming for next-generation wireless networks. Numerical case studies demonstrate the substantial performance gains of polarforming over conventional fixed-polarization antenna (FPA) systems, along with a discussion of implementation challenges to motivate future research.

Paper number 247:
Title: A generalized global Hartman-Grobman theorem for asymptotically stable semiflows
Authors: Wouter Jongeneel
Abstract: Recently, Kvalheim and Sontag provided a generalized global Hartman-Grobman theorem for equilibria under asymptotically stable continuous vector fields. By leveraging topological properties of Lyapunov functions, their theorem works without assuming hyperbolicity. We extend their theorem to a class of possibly discontinuous vector fields, in particular, to vector fields generating asymptotically stable semiflows.

Paper number 248:
Title: Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices
Authors: Tiantian Feng, Thanathai Lertpetchpun, Dani Byrd, Shrikanth Narayanan
Abstract: Speech emotion recognition (SER), particularly for naturally expressed emotions, remains a challenging computational task. Key challenges include the inherent subjectivity in emotion annotation and the imbalanced distribution of emotion labels in datasets. This paper introduces the \texttt{SAILER} system developed for participation in the INTERSPEECH 2025 Emotion Recognition Challenge (Task 1). The challenge dataset, which contains natural emotional speech from podcasts, serves as a valuable resource for studying imbalanced and subjective emotion annotations. Our system is designed to be simple, reproducible, and effective, highlighting critical choices in modeling, learning objectives, data augmentation, and engineering choices. Results show that even a single system (without ensembling) can outperform more than 95\% of the submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of three systems further improves performance, achieving a competitively ranked score (top-3 performing team). Our model is at: this https URL.

Paper number 249:
Title: Split the Yield, Share the Risk: Pricing, Hedging and Fixed rates in DeFi
Authors: Viraj Nadkarni, Pramod Viswanath
Abstract: We present the first formal treatment of \emph{yield tokenization}, a mechanism that decomposes yield-bearing assets into principal and yield components to facilitate risk transfer and price discovery in decentralized finance (DeFi). We propose a model that characterizes yield token dynamics using stochastic differential equations. We derive a no-arbitrage pricing framework for yield tokens, enabling their use in hedging future yield volatility and managing interest rate risk in decentralized lending pools. Taking DeFi lending as our focus, we show how both borrowers and lenders can use yield tokens to achieve optimal hedging outcomes and mitigate exposure to adversarial interest rate manipulation. Furthermore, we design automated market makers (AMMs) that incorporate a menu of bonding curves to aggregate liquidity from participants with heterogeneous risk preferences. This leads to an efficient and incentive-compatible mechanism for trading yield tokens and yield futures. Building on these foundations, we propose a modular \textit{fixed-rate} lending protocol that synthesizes on-chain yield token markets and lending pools, enabling robust interest rate discovery and enhancing capital efficiency. Our work provides the theoretical underpinnings for risk management and fixed-income infrastructure in DeFi, offering practical mechanisms for stable and sustainable yield markets.

Paper number 250:
Title: Fast Compressed-Domain N-Point Discrete Fourier Transform: The "Twiddless" FFT Algorithm
Authors: Saulo Queiroz
Abstract: In this work, we present the \emph{twiddless fast Fourier transform (TFFT)}, a novel algorithm for computing the $N$-point discrete Fourier transform (DFT). The TFFT's divide strategy builds on recent results that decimate an $N$-point signal (by a factor of $p$) into an $N/p$-point compressed signal whose DFT readily yields $N/p$ coefficients of the original signal. However, existing compression-domain DFT analyses have been limited to computing only the even-indexed DFT coefficients. With TFFT, we overcome this limitation by efficiently computing both \emph{even- and odd-indexed} DFT coefficients in the compressed domain with $O(N \log N)$ complexity. TFFT introduces a new recursive decomposition of the DFT problem, wherein $N/2^i$ coefficients of the original input are computed at recursion level $i$, with no need for twiddle factor multiplications or butterfly structures. Additionally, TFFT generalizes the input length to $N = c \cdot 2^k$ (for $k \geq 0$ and non-power-of-two $c > 0$), reducing the need for zero-padding and potentially improving efficiency and stability over classical FFTs. We believe TFFT represents a \emph{novel paradigm} for DFT computation, opening new directions for research in optimized implementations, hardware design, parallel computation, and sparse transforms.

Paper number 251:
Title: SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking
Authors: Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Xun Chen, Miao Pan
Abstract: With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.

Paper number 252:
Title: MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR
Authors: Dimitrios Damianos, Georgios Paraskevopoulos, Alexandros Potamianos
Abstract: In this work, we investigate the Meta PL unsupervised domain adaptation framework for Automatic Speech Recognition (ASR). We introduce a Multi-Stage Domain Adaptation pipeline (MSDA), a sample-efficient, two-stage adaptation approach that integrates self-supervised learning with semi-supervised techniques. MSDA is designed to enhance the robustness and generalization of ASR models, making them more adaptable to diverse conditions. It is particularly effective for low-resource languages like Greek and in weakly supervised scenarios where labeled data is scarce or noisy. Through extensive experiments, we demonstrate that Meta PL can be applied effectively to ASR tasks, achieving state-of-the-art results, significantly outperforming state-of-the-art methods, and providing more robust solutions for unsupervised domain adaptation in ASR. Our ablations highlight the necessity of utilizing a cascading approach when combining self-supervision with self-training.
    