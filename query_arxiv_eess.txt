
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: A Lightweight Cubature Kalman Filter for Attitude and Heading Reference Systems Using Simplified Prediction Equations
Authors: Shunsei Yamagishi, Lei Jing
Abstract: Attitude and Heading Reference Systems (AHRSs) are broadly applied wherever reliable orientation and motion sensing is required. In this paper, we present an improved Cubature Kalman Filter (CKF) with lower computational cost while maintaining estimation accuracy, which is named "Kaisoku Cubature Kalman Filter (KCKF)". The computationally efficient equations of the KCKF are derived by simplifying those of the CKF, while preserving equivalent mathematical relations. The lightweight prediction equations in the KCKF are derived by expanding the summation terms in the CKF and simplifying the result. This paper shows that the KCKF requires fewer floating-point operations (FLOPs) than the CKF. The controlled experimental results show that the KCKF reduces the computation time by approximately 19% compared to the CKF on a high-performance computer, whereas the KCKF reduces the computation time by approximately 15% compared to the CKF on a low-cost single-board computer. In addition, the KCKF maintains the attitude estimation accuracy of the CKF.

Paper number 2:
Title: Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance
Authors: Xiaowen Tao, Yinuo Wang, Haitao Ding, Yuanyang Qi, Ziyu Song
Abstract: With the growth of intelligent civil infrastructure and smart cities, operation and maintenance (O&M) increasingly requires safe, efficient, and energy-conscious robotic manipulation of articulated components, including access doors, service drawers, and pipeline valves. However, existing robotic approaches either focus primarily on grasping or target object-specific articulated manipulation, and they rarely incorporate explicit actuation energy into multi-objective optimisation, which limits their scalability and suitability for long-term deployment in real O&M settings. Therefore, this paper proposes an articulation-agnostic and energy-aware reinforcement learning framework for robotic manipulation in intelligent infrastructure O&M. The method combines part-guided 3D perception, weighted point sampling, and PointNet-based encoding to obtain a compact geometric representation that generalises across heterogeneous articulated objects. Manipulation is formulated as a Constrained Markov Decision Process (CMDP), in which actuation energy is explicitly modelled and regulated via a Lagrangian-based constrained Soft Actor-Critic scheme. The policy is trained end-to-end under this CMDP formulation, enabling effective articulated-object operation while satisfying a long-horizon energy budget. Experiments on representative O&M tasks demonstrate 16%-30% reductions in energy consumption, 16%-32% fewer steps to success, and consistently high success rates, indicating a scalable and sustainable solution for infrastructure O&M manipulation.

Paper number 3:
Title: String-Level Ground Fault Localization for TN-Earthed Three-Phase Photovoltaic Systems
Authors: Yuanliang Li, Xun Gong, Reza Iravani, Bo Cao, Heng Liu, Ziming Chen
Abstract: The DC-side ground fault (GF) poses significant risks to three-phase TN-earthed photovoltaic (PV) systems, as the resulting high fault current can directly damage both PV inverters and PV modules. Once a fault occurs, locating the faulty string through manual string-by-string inspection is highly time-consuming and inefficient. This work presents a comprehensive analysis of GF characteristics through fault-current analysis and a simulation-based case study covering multiple fault locations. Building on these insights, we propose an edge-AI-based GF localization approach tailored for three-phase TN-earthed PV systems. A PLECS-based simulation model that incorporates PV hysteresis effects is developed to generate diverse GF scenarios, from which correlation-based features are extracted throughout the inverter's four-stage shutdown sequence. Using the simulated dataset, a lightweight Variational Information Bottleneck (VIB)-based localization model is designed and trained, achieving over 93% localization accuracy at typical sampling rates with low computational cost, demonstrating strong potential for deployment on resource-constrained PV inverters.

Paper number 4:
Title: A Gradient Boosted Mixed-Model Machine Learning Framework for Vessel Speed in the U.S. Arctic
Authors: Mauli Pant, Linda Fernandez, Indranil Sahoo
Abstract: Understanding how environmental and operational conditions influence vessel speed is crucial for characterizing navigational conditions in the Arctic. We analyzed Automatic Identification System (AIS) data from 2010-2019 to examine vessel speed over ground (SOG). Over half of the AIS records showed zero SOG, and treating zero and positive SOG as a single continuous process can obscure important patterns. We therefore applied a two-stage machine learning framework, first modeling the probability of SOG greater than zero and then modeling SOG conditional on being positive. AIS observations were integrated with sea ice concentration, course over ground, wind, bathymetric depth, distance to coast, vessel group, and navigational status. Gradient boosted decision trees with random effects captured nonlinear environmental responses while accounting for repeated observations. The positive SOG classifier achieved strong discrimination (AUC = 0.85), while the conditional speed model explained approximately 77 percent of out-of-fold variance. SHAP values quantified covariate effects by decomposing model predictions into additive contributions from individual variables. Distance to coast and bathymetric depth were dominant determinants of both the likelihood and magnitude of vessel speed, while changes in course, vessel group, and navigational status introduced secondary variation. Wind and sea ice effects were modest. Together, these results empirically characterize Arctic vessel operating regimes relevant to speed management and corridor-level assessment.

Paper number 5:
Title: Adaptive traffic signal control optimization using a novel road partition and multi-channel state representation method
Authors: Maojiang Deng, Shoufeng Lu, Jiazhao Shi, Wen Zhang
Abstract: This study proposes a novel adaptive traffic signal control method leveraging a Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) to optimize signal timing by integrating variable cell length and multi-channel state representation. A road partition formula consisting of the sum of logarithmic and linear functions was proposed. The state variables are a vector composed of three channels: the number of vehicles, the average speed, and space occupancy. The set of available signal phases constitutes the action space, the selected phase is executed with a fixed green time. The reward function is formulated using the absolute values of key traffic state metrics - waiting time, speed, and fuel consumption. Each metric is normalized by a typical maximum value and assigned a weight that reflects its priority and optimization direction. The simulation results, using Sumo-TensorFlow-Python, demonstrate a cross-range transferability evaluation and show that the proposed variable cell length and multi-channel state representation method excels compared to fixed cell length in optimization performance.

Paper number 6:
Title: Acoustivision Pro: An Open-Source Interactive Platform for Room Impulse Response Analysis and Acoustic Characterization
Authors: Mandip Goswami
Abstract: Room acoustics analysis plays a central role in architectural design, audio engineering, speech intelligibility assessment, and hearing research. Despite the availability of standardized metrics such as reverberation time, clarity, and speech transmission index, accessible tools that combine rigorous signal processing with intuitive visualization remain scarce. This paper presents AcoustiVision Pro, an open-source web-based platform for comprehensive room impulse response (RIR) analysis. The system computes twelve distinct acoustic parameters from uploaded or dataset-sourced RIRs, provides interactive 3D visualizations of early reflections, generates frequency-dependent decay characteristics through waterfall plots, and checks compliance against international standards including ANSI S12.60 and ISO 3382. We introduce the accompanying RIRMega and RIRMega Speech datasets hosted on Hugging Face, containing thousands of simulated room impulse responses with full metadata. The platform supports real-time auralization through FFT-based convolution, exports detailed PDF reports suitable for engineering documentation, and provides CSV data export for further analysis. We describe the mathematical foundations underlying each acoustic metric, detail the system architecture, and present preliminary case studies demonstrating the platform's utility across diverse application domains including classroom acoustics, healthcare facility design, and recording studio evaluation.

Paper number 7:
Title: Quantum walk inspired JPEG compression of images
Authors: Abhishek Verma, Sahil Tomar, Sandeep Kumar
Abstract: This work proposes a quantum inspired adaptive quantization framework that enhances the classical JPEG compression by introducing a learned, optimized Qtable derived using a Quantum Walk Inspired Optimization (QWIO) search strategy. The optimizer searches a continuous parameter space of frequency band scaling factors under a unified rate distortion objective that jointly considers reconstruction fidelity and compression efficiency. The proposed framework is evaluated on MNIST, CIFAR10, and ImageNet subsets, using Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM), Bits Per Pixel (BPP), and error heatmap visual analysis as evaluation metrics. Experimental results show average gains ranging from 3 to 6 dB PSNR, along with better structural preservation of edges, contours, and luminance transitions, without modifying decoder compatibility. The structure remains JPEG compliant and can be implemented using accessible scientific packages making it ideal for deployment and practical research use.

Paper number 8:
Title: Visible and Hyperspectral Imaging for Quality Assessment of Milk: Property Characterisation and Identification
Authors: Massimo Martinelli, Elena Tomassi, Nafiou Arouna, Morena Gabriele, Laryssa Perez Fabbri, Luisa Pozzo, Giuseppe Conte, Davide Moroni, Laura Pucci
Abstract: Rapid and non-destructive assessment of milk quality is crucial to ensuring both nutritional value and food safety. In this study, we investigated the potential of visible and hyperspectral imaging as cost-effective and quick-response alternatives to conventional chemical analyses for characterizing key properties of cowś milk. A total of 52 milk samples were analysed to determine their biochemical composition (polyphenols, antioxidant capacity, and fatty acids) using spectrophotometer methods and standard gas-liquid and high-performance liquid chromatography (GLC/HPLC). Concurrently, visible (RGB) images were captured using a standard smartphone, and hyperspectral data were acquired in the near-infrared range. A comprehensive analytical framework, including eleven different machine learning algorithms, was employed to correlate imaging features with biochemical measurements. Analysis of visible images accurately distinguished between fresh samples and those stored for 12 days (100 percent accuracy) and achieved perfect discrimination between antibiotic-treated and untreated groups (100 percent accuracy). Moreover, image-derived features enabled perfect prediction of the polyphenols content and the antioxidant capacity using an XGBoost model. Hyperspectral imaging further achieved classification accuracies exceeding 95 percent for several individual fatty acids and 94.8 percent for treatment groups using a Random Forest model. These findings demonstrate that both visible and hyperspectral imaging, when coupled with machine learning, are powerful, non-invasive tools for the rapid assessment of milkś chemical and nutritional profiles, highlighting the strong potential of imaging-based approaches for milk quality assessment.

Paper number 9:
Title: Conference Proceedings of the Inaugural Conference of the International Society for Tractography (IST 2025 Bordeaux)
Authors: Flavio Dell Acqua, Maxime Descoteaux, Graham Little, Laurent Petit, Dogu Baran Aydogan, Stephanie Forkel, Alexander Leemans, Simona Schiavi, Michel Thiebaut de Schotten
Abstract: This collection comprises the abstracts presented during poster, power pitch and oral sessions at the Inaugural Conference of the International Society for Tractography (IST Conference 2025), held in Bordeaux, France, from October 13-16, 2025. The conference was designed to foster meaningful exchange and collaboration between disparate fields. The overall focus was on advancing research, innovation, and community in the common fields of interest: neuroanatomy, tractography methods and scientific/clinical applications of tractography. The included abstracts cover the latest advancements in tractography, Diffusion MRI, and related fields including new work on; neurological and psychiatric disorders, deep brain stimulation targeting, and brain development. This landmark event brought together world-leading experts to discuss critical challenges and chart the future direction of the field.

Paper number 10:
Title: Interference-Robust Non-Coherent Over-the-Air Computation for Decentralized Optimization
Authors: Nicolò Michelusi
Abstract: Non-coherent over-the-air (NCOTA) computation enables low-latency and bandwidth-efficient decentralized optimization by exploiting the average energy superposition property of wireless channels. It has recently been proposed as a powerful tool for executing consensus-based optimization algorithms in fully decentralized systems. A key advantage of NCOTA is that it enables unbiased consensus estimation without channel state information at either transmitters or receivers, requires no transmission scheduling, and scales efficiently to dense network deployments. However, NCOTA is inherently susceptible to external interference, which can bias the consensus estimate and deteriorate the convergence of the underlying decentralized optimization algorithm. In this paper, we propose a novel interference-robust (IR-)NCOTA scheme. The core idea is to apply a coordinated random rotation of the frame of reference across all nodes, and transmit a pseudo-random pilot signal, allowing to transform external interference into a circularly symmetric distribution with zero mean relative to the rotated frame. This ensures that the consensus estimates remain unbiased, preserving the convergence guarantees of the underlying optimization algorithm. Through numerical results on a classification task, it is demonstrated that IR-NCOTA exhibits superior performance over the baseline NCOTA algorithm in the presence of external interference.

Paper number 11:
Title: Interpolation-Inspired Closure Certificates
Authors: Mohammed Adib Oumer, Vishnu Murali, Majid Zamani
Abstract: Barrier certificates, a form of state invariants, provide an automated approach to the verification of the safety of dynamical systems. Similarly to barrier certificates, recent works explore the notion of closure certificates, a form of transition invariants, to verify dynamical systems against $\omega$-regular properties including safety. A closure certificate, defined over state pairs of a dynamical system, is a real-valued function whose zero superlevel set characterizes an inductive transition invariant of the system. The search for such a certificate can be effectively automated by assuming it to be within a specific template class, e.g. a polynomial of a fixed degree, and then using optimization techniques such as sum-of-squares (SOS) programming to find it. Unfortunately, one may not be able to find such a certificate for a fixed template. In such a case, one must change the template, e.g. increase the degree of the polynomial. In this paper, we consider a notion of multiple closure certificates dubbed interpolation-inspired closure certificates. An interpolation-inspired closure certificate consists of a set of functions which jointly over-approximate a transition invariant by first considering one-step transitions, then two, and so on until a transition invariant is obtained. The advantage of interpolation-inspired closure certificates is that they allow us to prove properties even when a single function for a fixed template cannot be found using standard approaches. We present SOS programming and a scenario program to find these sets of functions and demonstrate the effectiveness of our proposed method to verify persistence and general $\omega$-regular specifications in some case studies.

Paper number 12:
Title: Practical RIS Gain without the Pain: Randomization and Opportunistic Scheduling in 5G NR
Authors: L. Yashvanth, Raju Malleboina, Venkatareddy Akumalla, Nekkanti Guna Sai Kiran, Debdeep Sarkar, Chandra R. Murthy
Abstract: We experimentally demonstrate the performance gains achieved by an in-house built reconfigurable intelligent surface (RIS) integrated with a real-time 5G new radio (NR) system implemented using the OpenAirInterface (OAI) framework. We first quantify the gain in throughput achievable by integrating an RIS with a 5G system. Next, we show that randomly setting the RIS phase configuration and leveraging the inherent proportional fair (PF) scheduling mechanism of 5G NR can yield near-optimal throughput, provided the throughput averaging window of the PF scheduler is chosen judiciously. This occurs because, in each time slot, the PF scheduler naturally prioritizes data transmission to the user equipment (UE) that experiences the best channel conditions, namely, the UE to which the randomly configured RIS is aligned. Subsequently, we experimentally evaluate key performance metrics, including the reference signal received power (RSRP), block error rate (BLER), modulation and coding scheme (MCS) index, and throughput, under random RIS configurations. These results confirm that even a randomly configured RIS with negligible overhead can deliver performance comparable to optimized RIS designs, in real-world 5G NR wireless communication systems.

Paper number 13:
Title: Implementation of a Directional Modulation Testbed for Reconfigurable Transmitters for Spatially Agile MIMO Systems
Authors: Jonathan E. Swindell, David W. Cox, Rebekah Edwards, Emma Lever, Adam C. Goad, Austin Egbert, Charles Baylis, Robert J. Marks II
Abstract: This paper demonstrates the implementation and validation of a microwave testbed for directionally modulated transmission. Directional modulation enables multiple communication and/or radar signals to be transmitted in multiple directions simultaneously using a single phased array aperture, helping to relieve spectral congestion. A two-element transmitter array is driven by a Xilinx ZCU208 Radio Frequency System on a Chip (RFSoC). Our testbed provides a foundation for developing a fully reconfigurable array transmitter for multi-user multiple-input multiple-output (MU-MIMO) radar and communications, which will incorporate in-situ measurement, reconfigurable matching circuitry, and fast tuning algorithms for frequency and directional selectivity. This testbed enables development and validation of reconfigurable techniques for adaptive spectral and spatial coexistence.

Paper number 14:
Title: Grid-ECO: Grid Aware Electric Vehicle Charging Stations Placement Optimizer
Authors: Bikram Panthee, Haoming Yang, Corey D. Harper, Amritanshu Pandey
Abstract: The paper develops a methodology, Grid-ECO, to optimally allocate electric vehicle charging stations (EVCS) within a distribution feeder, while considering EV charging demand at census-level granularity. The underlying problem is NP-hard and requires satisfying nonlinear, nonconvex, three-phase unbalanced AC network constraints while including integer decision variables. Existing works cannot guarantee AC feasibility nor optimality of this problem without either i) relaxing the integer decision variable space or ii) convexifying AC constraints. Proposed Grid-ECO exactly solves the underlying mixed-integer nonlinear program (MINLP) to near-zero optimality gap while prioritizing candidate locations based on grid voltage and current sensitivities. To solve the MINLP exactly, Grid-ECO exactly reformulates it into mixed-integer bilinear program (MIBLP), enabling global optimization using the spatial branch-and-bound algorithm (sBnB). To ensure computational tractability for large-scale feeders, we develop and include a novel presolving strategy based on Sequential Bound Tightening (SBT) with variable filtering and decomposition. Case studies demonstrate that Grid-ECO outperforms the off-the-shelf Gurobi sBnB solver by solving cases where no feasible solution is found within 167 hours. When feasible solution is found by off-the-shelf solver, Grid-ECO reduces solution time by up to 73\% and sBnB node exploration by up to 97\%, while achieving a 0\% optimality gap and guaranteed AC feasibility.

Paper number 15:
Title: Task- and Metric-Specific Signal Quality Indices for Medical Time Series
Authors: Jad Haidamous, Christoph Hoog Antink
Abstract: Medical time series such as electrocardiograms (ECGs) and photoplethysmograms (PPGs) are frequently affected by measurement artifacts due to challenging acquisition environments, such as in ambulances and during routine daily activities. Since automated algorithms for analyzing such signals increasingly inform clinically relevant decisions, identifying signal segments on which these algorithms may produce unreliable outputs is of critical importance. Signal quality indices (SQIs) are commonly used for this purpose. However, most existing SQIs are task agnostic and do not account for the specific algorithm and performance metric used downstream. In this work, we formalize signal quality as a task- and metric-dependent concept and propose a perturbation-based SQI (pSQI) that aims to detect an algorithm's performance degradation on an input signal with respect to a metric. The pSQI is defined as the worst-case value of the performance metric under an additive, colored Gaussian noise perturbation with a lower-bounded signal-to-noise ratio. We introduce formal requirements for task- and metric-specific SQIs, including monotonicity of the metric in expectation and maximal separation under thresholding. Experiments on R-peak detection and atrial fibrillation classification benchmarks demonstrate that the proposed pSQI consistently outperforms existing feature- and deep learning-based SQIs in identifying unreliable inputs without requiring training.

Paper number 16:
Title: Decoder-only Conformer with Modality-aware Sparse Mixtures of Experts for ASR
Authors: Jaeyoung Lee, Masato Mimura
Abstract: We present a decoder-only Conformer for automatic speech recognition (ASR) that processes speech and text in a single stack without external speech encoders or pretrained large language models (LLM). The model uses a modality-aware sparse mixture of experts (MoE): disjoint expert pools for speech and text with hard routing and top-1 selection, embedded in hybrid-causality Conformer blocks (bidirectional for speech, causal for text). Training combines CTC on speech positions with label-smoothed cross-entropy for text generation. Our 113M-parameter model consistently improves WER over a 139M AED baseline on Librispeech (2.8% vs. 3.2% test-clean; 5.6% vs. 6.0% test-other). On Common Voice 16.1 with a single multilingual model across five languages, our approach reduces average WER from 12.2% to 10.6%. To our knowledge, this is the first randomly initialized decoder-only ASR that surpasses strong AED baselines via modality-aware routing and sparse MoE, achieving better accuracy with fewer active parameters and without alignment/adaptation modules.

Paper number 17:
Title: Generative Site-Specific Beamforming via Information-Maximizing Codebook
Authors: Cheng-Jie Zhao, Zhaolin Wang, Yuanwei Liu
Abstract: A novel generative site-specific beamforming (GenSSBF) framework is proposed, which integrates a site-information-maximizing (SIM) codebook with a conditional flow matching (CFM)-based beam generator. By this framework, the site-specific radio propagation environment is learned at the base station (BS), enabling the generation of high fidelity communication beams from coarse reference-signal-received-power (RSRP) feedback provided by user equipments (UEs). In the proposed design, a low-dimensional SIM probing codebook is first constructed by maximizing the mutual information between the RSRP feedback and the site-specific channel. This design not only reduces the initial beam sweeping overhead, but also enhances the amount of channel state information conveyed through UE feedback. By treating the RSRP feedback as a conditional prior, a CFM-based generative model is further developed to explicitly capture the uncertainty in beam generation. Specifically, a small set of UE-specific candidate beams is generated by inferring the learned generative model and sampling from the corresponding posterior distribution, after which the final data transmission beam is selected by the UE. Extensive simulation results demonstrate the effectiveness of both the proposed SIM codebook and the CFM-based beam generator. The proposed GenSSBF framework achieves beamforming performance nearly identical to maximum ratio transmission while requiring only eight probing beams and eight candidate beams.

Paper number 18:
Title: Dynamic Network Prices for Prosumer-aware Hosting Capacity Management
Authors: Jiawei Zhang, Gregor Verbic, Frederik Geth, Mohsen Aldaadi, Rahmat Heidari, Julio Braslavsky
Abstract: The fast uptake of distributed energy resources (DERs) presents increasing challenges for managing hosting capacity in distribution networks. Existing solutions include direct load control, operating envelopes, and price-based control through dynamic energy prices. Despite their effectiveness, these methods often rely on assumed prosumer behavioural patterns and overlook prosumers' desire to retain control over their devices. Additionally, current fixed or Time-of-Use (ToU) prices are based on spatial and temporal averages, having limited impact on network conditions and DER operation. To address these limitations, this paper proposes a bilevel optimisation framework that explicitly models prosumer decision-making in the design of dynamic network prices. The upper level represents the distribution system operator (DSO), setting network prices under cost-recovery and network constraints, while the lower level models prosumers optimising DER operation in response. The proposed framework preserves customer prerogative, enhances DER flexibility, and offers actionable insights for network hosting capacity management and the evolution of network tariff structures under high DER penetration.

Paper number 19:
Title: Curvature-Guided Safety Filters: State-Dependent Hessian-Weighted Projection with Provable Performance Bounds
Authors: Ziyan Lin, Liang Xu
Abstract: Safety filters provide a lightweight mechanism for enforcing state and input safety in learning-enabled control. However, common Euclidean projections onto the safe set disregard long-term performance, while directly optimizing the action-value function within the safe set can be nonconvex and computationally prohibitive. This paper proposes a state-dependent, Hessian-guided projection for safety filtering that preserves convexity while improving performance. The key idea is to select a weighted projection matrix from the curvature of the action-value function, thereby biasing the correction toward action directions with higher value sensitivity. We establish (i) a uniform bound on the performance gap between the weighted projection and the safe value-optimal action, and (ii) a condition under which the weighted projection outperforms the Euclidean projection in long-term value. To support black-box controllers, we further present a data-driven construction of the weighted projection matrix via an iterative Q-function learning algorithm with quadratic feature blocks and regularization that enforces curvature dominance and bounded higher-order terms. Simulations on a quadrotor tracking-and-avoidance task indicate that the proposed filter maintains safety while reducing value degradation relative to Euclidean projection, with computational overhead compatible with real-time operation.

Paper number 20:
Title: When Environments Shift: Safe Planning with Generative Priors and Robust Conformal Prediction
Authors: Kaizer Rahaman, Jyotirmoy V. Deshmukh, Ashish R. Hota, Lars Lindemann
Abstract: Autonomous systems operate in environments that may change over time. An example is the control of a self-driving vehicle among pedestrians and human-controlled vehicles whose behavior may change based on factors such as traffic density, road visibility, and social norms. Therefore, the environment encountered during deployment rarely mirrors the environment and data encountered during training -- a phenomenon known as distribution shift -- which can undermine the safety of autonomous systems. Conformal prediction (CP) has recently been used along with data from the training environment to provide prediction regions that capture the behavior of the environment with a desired probability. When embedded within a model predictive controller (MPC), one can provide probabilistic safety guarantees, but only when the deployment and training environments coincide. Once a distribution shift occurs, these guarantees collapse. We propose a planning framework that is robust under distribution shifts by: (i) assuming that the underlying data distribution of the environment is parameterized by a nuisance parameter, i.e., an observable, interpretable quantity such as traffic density, (ii) training a conditional diffusion model that captures distribution shifts as a function of the nuisance parameter, (iii) observing the nuisance parameter online and generating cheap, synthetic data from the diffusion model for the observed nuisance parameter, and (iv) designing an MPC that embeds CP regions constructed from such synthetic data. Importantly, we account for discrepancies between the underlying data distribution and the diffusion model by using robust CP. Thus, the plans computed using robust CP enjoy probabilistic safety guarantees, in contrast with plans obtained from a single, static set of training data. We empirically demonstrate safety under diverse distribution shifts in the ORCA simulator.

Paper number 21:
Title: Safe Controller Synthesis Using Lyapunov-based Barriers for Linear Hybrid Systems with Simplex Architecture
Authors: Sunandan Adhikary, Soumyajit Dey
Abstract: Modern cyber-physical systems often have a two-layered design, where the primary controller is AI-enabled or an analytical controller optimising some specific cost function. If the resulting control action is perceived as unsafe, a secondary safety-focused backup controller is activated. The existing backup controller design schemes do not consider a real-time deadline for the course correction of a potentially unsafe system trajectory or constrain maximisation of the safe operating region as a synthesis criterion. This essentially implies an eventual safety guarantee over a small operating region. This paper proposes a novel design method for backup safe controllers (BSCs) that ensure invariance across the largest possible region in the safe state space, along with a guarantee for timely recovery when the system states deviate from their usual behaviour. This is the first work to synthesise safe controllers that ensure maximal safety and timely recovery while aiming at minimal resource usage by switching between BSCs with different execution rates. An online safe controller activation policy is also proposed to switch between BSCs (and the primary optimal controller) to optimise processing bandwidth for control computation. To establish the efficacy of the proposed method, we evaluate the safety and recovery time of the proposed safe controllers, as well as the activation policy, in closed loops with linear hybrid dynamical systems under budgeted bandwidth.

Paper number 22:
Title: Dual-Channel Feature Fusion for Joint Prediction in Dynamic Signed Weighted Networks
Authors: Gaoxin Zhang, Ruixing Ren, Junhui Zhao, Xiaoke Sun
Abstract: Link prediction is central to unraveling social network evolution and node relationships, as well as understanding the characteristic mechanisms of complex networks. Currently, research on link prediction for complex dynamic networks integrating temporal evolution, relational polarity and edge weight information remains significantly underexplored, failing to meet practical demands. For dynamic signed-weighted networks, this paper proposes a tripartite joint prediction framework for unified forecasting of links, signs and weights. First, the dynamic network is decomposed into temporal snapshots, and node semantic embeddings are generated via sign-aware weighted random walks. We then design multi-hop structural balance and temporal difference features to capture the structural characteristics and dynamic evolution laws of the network, respectively. The model adopts a dual-channel feature decoupling mechanism: node semantic embeddings are used for link existence prediction, while relational sign features are fed into a Transformer encoder to model temporal dependencies. Finally, prediction results are output synergistically through a multi-task unit. Simulation experiments demonstrate that, compared with baseline methods, the proposed framework achieves an average 2%-4% improvement in the performance of link existence and relational sign prediction, and a significant 40%-50% reduction in edge weight prediction error.

Paper number 23:
Title: GNSS Jamming Detection with Automatic Gain Control (AGC) and Carrier-to-Noise Ratio Density (CNO) Observables from a COTS receiver
Authors: Syed Ali Kazim (IRT Railenium), Anas Darwich (SNCF -- I\&amp;R), Juliette Marais (COSYS-LEOST)
Abstract: As rail transport moves toward higher degrees of automation under initiatives like the R2DATO project [1], accurate and reliable train localization has become essential. Global Satellite Navigation System (GNSS) is considered as a main technology in enabling operational advancements including Automatic Train Operation (ATO), moving block signaling, and virtual coupling, which are the core components of the Horizon Europe 2024 rail digitalization agenda. However, GNSS signal integrity is increasingly threatened by intentional and unintentional radio frequency interference (RFI). This include jamming and spoofing, which are particularly concerning as the broadcasted signal can deliberately disrupt or manipulate the GNSS signal. - Jamming refers to an intentional form of interference that induces disturbances in the GNSS band, causing performance degradation or can even entirely block the receiver from acquiring the satellite signals. - Spoofing involves broadcasting counterfeit satellite signals to deceive the GNSS receiver, leading to inaccurate estimation of position, navigation and timing information. This concern about interference is not unique to rail applications. The aeronautical sector has long recognized the risks posed by GNSS interference, with extensive documentation on its impact on navigation, landing procedures, and surveillance systems. In recent years, awareness of these risks has expanded to other transport sectors. Within the automotive industry, particularly in Intelligent Transport Systems (ITS), several studies [2][3][4] have addressed the vulnerability of GNSS against interference. Similar concerns are now emerging in the rail domain [5][6][7], especially as GNSS is increasingly adopted in safety-critical applications. In literature, several levels of actions have been explored, ranging from merely the detection of a malicious signal at the initial phase to the application of advanced signal processing methods aimed at suppressing the effects of interference [8]. In alignment with the goal of the R2DATO project, we evaluated the impact of various classes of interference signals such as amplitude modulation (AM), frequency modulation (FM), pulsed, frequency hopping and chirp signals on the GNSS observables including Automatic Gain Control (AGC) and Carrier to Noise Ratio (CNO) as measured by a Commercial Off-The-Shelf (COTS). However, in this work, the analysis is only limited to impact of chirp interference on GPS L1 receiver observables and detection performance.

Paper number 24:
Title: From Data $H(jω_i)$ to Balanced Truncation Family: A Projection-based Non-intrusive Approach
Authors: Umair Zulfiqar
Abstract: This paper presents data-driven implementations of balanced truncation and several of its generalizations that rely exclusively on transfer function samples on the imaginary axis. Rather than implicitly approximating the Gramians via numerical quadrature, the proposed approach approximates them implicitly through projection. This enables multiple members of the balanced truncation family to be implemented non-intrusively using practically measurable data, without requiring spectral factorizations. Using this projection-based framework, data-driven implementations are developed for standard balanced truncation, frequency-limited balanced truncation, time-limited balanced truncation, self-weighted balanced truncation, LQG balanced truncation, H-infinity balanced truncation, positive-real balanced truncation, bounded-real balanced truncation, and stochastic balanced truncation. Numerical results demonstrate that the proposed non-intrusive implementations achieve performance comparable to their intrusive counterparts and accurately capture the dominant Hankel singular values.

Paper number 25:
Title: Lung nodule classification on CT scan patches using 3D convolutional neural networks
Authors: Volodymyr Sydorskyi
Abstract: Lung cancer remains one of the most common and deadliest forms of cancer worldwide. The likelihood of successful treatment depends strongly on the stage at which the disease is diagnosed. Therefore, early detection of lung cancer represents a critical medical challenge. However, this task poses significant difficulties for thoracic radiologists due to the large number of studies to review, the presence of multiple nodules within the lungs, and the small size of many nodules, which complicates visual assessment. Consequently, the development of automated systems that incorporate highly accurate and computationally efficient lung nodule detection and classification modules is essential. This study introduces three methodological improvements for lung nodule classification: (1) an advanced CT scan cropping strategy that focuses the model on the target nodule while reducing computational cost; (2) target filtering techniques for removing noisy labels; (3) novel augmentation methods to improve model robustness. The integration of these techniques enables the development of a robust classification subsystem within a comprehensive Clinical Decision Support System for lung cancer detection, capable of operating across diverse acquisition protocols, scanner types, and upstream models (segmentation or detection). The multiclass model achieved a Macro ROC AUC of 0.9176 and a Macro F1-score of 0.7658, while the binary model reached a Binary ROC AUC of 0.9383 and a Binary F1-score of 0.8668 on the LIDC-IDRI dataset. These results outperform several previously reported approaches and demonstrate state-of-the-art performance for this task.

Paper number 26:
Title: Flexible RISs: Learning-based Array Manifold Estimation and Phase-shift Optimization
Authors: Mohamadreza Delbari, Ehsan Mohammadi, Mostafa Darabi, Arash Asadi, Alejandro Jiménez-Sáez, Vahid Jamali
Abstract: Reconfigurable intelligent surfaces (RISs) are envisioned as a key enabler for next-generation wireless networks, offering programmable control over propagation environments. While extensive research focuses on planar RIS architectures, practical deployments often involve non-planar surfaces, such as structural columns or curved facades, where standard planar beamforming models fail. Moreover, existing analytical solutions for curved RISs are often restricted to specific, pre-defined array manifold geometries. To address this limitation, this paper proposes a novel deep learning (DL) framework for optimizing the phase shifts of non-planar RISs. We first introduce a low-dimensional parametric model to capture arbitrary surface curvature effectively. Based on this, we design a neural network (NN) that utilizes a sparse set of received power measurements to estimate the surface geometry and derive the optimal phase configuration. Simulation results demonstrate that the proposed algorithm converges fast and significantly outperforms conventional planar beamforming designs, validating its robustness against arbitrary surface curvature. We also analyze the impact of the measurement location error on the algorithm's performance.

Paper number 27:
Title: VineetVC: Adaptive Video Conferencing Under Severe Bandwidth Constraints Using Audio-Driven Talking-Head Reconstruction
Authors: Vineet Kumar Rakesh, Soumya Mazumdar, Tapas Samanta, Hemendra Kumar Pandey, Amitabha Das, Sarbajit Pal
Abstract: Intense bandwidth depletion within consumer and constrained networks has the potential to undermine the stability of real-time video conferencing: encoder rate management becomes saturated, packet loss escalates, frame rates deteriorate, and end-to-end latency significantly increases. This work delineates an adaptive conferencing system that integrates WebRTC media delivery with a supplementary audio-driven talking-head reconstruction pathway and telemetry-driven mode regulation. The system consists of a WebSocket signaling service, an optional SFU for multi-party transmission, a browser client capable of real-time WebRTC statistics extraction and CSV telemetry export, and an AI REST service that processes a reference face image and recorded audio to produce a synthesized MP4; the browser can substitute its outbound camera track with the synthesized stream with a median bandwidth of 32.80 kbps. The solution incorporates a bandwidth-mode switching strategy and a client-side mode-state logger.

Paper number 28:
Title: Empirical Validation of a Dual-Defense Mechanism Reshaping Wholesale Electricity Price Dynamics in Singapore
Authors: Huang Zhenyu, Yuan Zhao
Abstract: While ex-ante screening and static price caps are global standards for mitigating price volatility, Singapore's electricity market employs a unique dual-defense mechanism integrating vesting contracts (VC) with a temporary price cap (TPC). Using high-frequency data from 2021 to 2024, this paper evaluates this mechanism and yields three primary findings. First, a structural trade-off exists within the VC framework: while VC quantity (VCQ) suppresses average prices, it paradoxically exacerbates instability via liquidity squeezes. Conversely, VC price (VCP) functions as a tail-risk anchor, dominating at extreme quantiles where VCQ efficacy wanes. Second, a structural break around the 2023 reform reveals a fundamental re-mapping of price dynamics; the previously positive pass-through from offer ratios to clearing prices was largely neutralized post-reform. Furthermore, diagnostics near the TPC threshold show no systematic evidence of strategic bid shading, confirming the TPC's operational integrity. Third, the dual-defense mechanism exhibits a critical synergy that resolves the volatility trade-off. The TPC reverses the volatility penalty of high VCQ, shifting the elasticity of conditional volatility from a destabilizing 0.636 to a stabilizing -0.213. This synergy enables the framework to enhance tail-risk control while eliminating liquidity-related stability costs. We conclude that this dual-defense mechanism successfully decouples price suppression from liquidity risks, thereby maximizing market stability.

Paper number 29:
Title: Comparison of OTFS and OFDM for RIS-aided Systems in the Presence of Phase Noise
Authors: Stephen McWade, Arman Farhang
Abstract: In this paper, we investigate the performance of RIS-aided orthogonal time frequency space (OTFS) and orthogonal frequency division multiplexing (OFDM) systems in the presence of oscillator phase noise. OFDM is known to be sensitive to phase noise, which could limit the potential gains promised by RIS systems. OTFS, on the other hand, is a compelling potential waveform for RIS-aided systems in the presence of phase noise due to it's resilience to time-varying channels. However, the effect of phase noise on OTFS has not been fully analyzed in the literature as of yet. Additionally, no existing works in the literature consider the effect of phase noise on an RIS-aided OTFS system. Hence, we propose a joint RIS channel and phase noise estimation technique using a Wiener filtering approach. Our proposed method exploits the statistical nature of both the phase noise and the Doppler spread channel in a setup with RIS. Our numerical analysis demonstrates the significant gain of RIS-aided OTFS offers compared to RIS-aided OFDM in the presence in the presence of phase noise. Additionally, our results demonstrate the superiority of our proposed estimation technique, with gains of up to 3~dB in terms of bit error rate (BER), over existing methods in the literature.

Paper number 30:
Title: 3DLAND: 3D Lesion Abdominal Anomaly Localization Dataset
Authors: Mehran Advand, Zahra Dehghanian, Navid Faraji, Reza Barati, Seyed Amir Ahmad Safavi-Naini, Hamid R. Rabiee
Abstract: Existing medical imaging datasets for abdominal CT often lack three-dimensional annotations, multi-organ coverage, or precise lesion-to-organ associations, hindering robust representation learning and clinical applications. To address this gap, we introduce 3DLAND, a large-scale benchmark dataset comprising over 6,000 contrast-enhanced CT volumes with over 20,000 high-fidelity 3D lesion annotations linked to seven abdominal organs: liver, kidneys, pancreas, spleen, stomach, and gallbladder. Our streamlined three-phase pipeline integrates automated spatial reasoning, prompt-optimized 2D segmentation, and memory-guided 3D propagation, validated by expert radiologists with surface dice scores exceeding 0.75. By providing diverse lesion types and patient demographics, 3DLAND enables scalable evaluation of anomaly detection, localization, and cross-organ transfer learning for medical AI. Our dataset establishes a new benchmark for evaluating organ-aware 3D segmentation models, paving the way for advancements in healthcare-oriented AI. To facilitate reproducibility and further research, the 3DLAND dataset and implementation code are publicly available at this https URL.

Paper number 31:
Title: Dual-Phase Cross-Modal Contrastive Learning for CMR-Guided ECG Representations for Cardiovascular Disease Assessment
Authors: Laura Alvarez-Florez, Angel Bujalance-Gomez, Femke Raijmakers, Samuel Ruiperez-Campillo, Maarten Z. H. Kolk, Jesse Wiers, Julia Vogt, Erik J. Bekkers, Ivana Išgum, Fleur V. Y. Tjong
Abstract: Cardiac magnetic resonance imaging (CMR) offers detailed evaluation of cardiac structure and function, but its limited accessibility restricts use to selected patient populations. In contrast, the electrocardiogram (ECG) is ubiquitous and inexpensive, and provides rich information on cardiac electrical activity and rhythm, yet offers limited insight into underlying cardiac structure and mechanical function. To address this, we introduce a contrastive learning framework that improves the extraction of clinically relevant cardiac phenotypes from ECG by learning from paired ECG-CMR data. Our approach aligns ECG representations with 3D CMR volumes at end-diastole (ED) and end-systole (ES), with a dual-phase contrastive loss to anchor each ECG jointly with both cardiac phases in a shared latent space. Unlike prior methods limited to 2D CMR representations with or without a temporal component, our framework models 3D anatomy at both ED and ES phases as distinct latent representations, enabling flexible disentanglement of structural and functional cardiac properties. Using over 34,000 ECG-CMR pairs from the UK Biobank, we demonstrate improved extraction of image-derived phenotypes from ECG, particularly for functional parameters ($\uparrow$ 9.2\%), while improvements in clinical outcome prediction remained modest ($\uparrow$ 0.7\%). This strategy could enable scalable and cost-effective extraction of image-derived traits from ECG. The code for this research is publicly available.

Paper number 32:
Title: HoRAMA: Holistic Reconstruction with Automated Material Assignment for Ray Tracing using NYURay
Authors: Mingjun Ying, Guanyue Qian, Xinquan Wang, Peijie Ma, Dipankar Shakya, Theodore S. Rappaport
Abstract: Next-generation wireless networks at upper mid-band and millimeter-wave frequencies require accurate site-specific deterministic channel propagation prediction. Wireless ray tracing (RT) provides site-specific predictions but demands high-fidelity three-dimensional (3D) environment models with material properties. Manual 3D model reconstruction achieves high accuracy but requires weeks of expert effort, creating scalability bottlenecks for large environment reconstruction. Traditional vision-based 3D reconstruction methods lack RT compatibility due to geometrically defective meshes and missing material properties. This paper presents Holistic Reconstruction with Automated Material Assignment (HoRAMA) for wireless propagation prediction using NYURay. HoRAMA generates RT-compatible 3D models from RGB video readily captured using a smartphone or low-cost portable camera, by integrating MASt3R-SLAM dense point cloud generation with vision language model-assisted material assignment. The HoRAMA 3D reconstruction method is verified by comparing NYURay RT predictions, using both manually created and HoRAMA-generated 3D models, against field measurements at 6.75 GHz and 16.95 GHz across 12 TX-RX locations in a 700 square meter factory. HoRAMA ray tracing predictions achieve a 2.28 dB RMSE for matched multipath component (MPC) power predictions, comparable to the manually created 3D model baseline (2.18 dB), while reducing 3D reconstruction time from two months to 16 hours. HoRAMA enables scalable wireless digital twin creation for RT network planning, infrastructure deployment, and beam management in 5G/6G systems, as well as eventual real-time implementation at the edge.

Paper number 33:
Title: Data Augmentation and Attention for massive MIMO-based Indoor Localization in Changing Environments
Authors: Luisa Schuhmacher, Hazem Sallouha, Ihsane Gryech, Sofie Pollin
Abstract: The demand for high-precision indoor localization has grown significantly with the rise of smart environments, industrial automation, and location-aware applications. While massive Multiple-Input and Multiple-Output (MIMO) systems enable millimeter-level accuracy by leveraging rich Channel State Information (CSI), most existing solutions are optimized for static environments, where users or devices remain fixed during data collection and inference. Real-world applications, however, often require real-time localization in changing environments, where rapid movement, unpredictable blockages, and dynamic channel conditions pose significant challenges. To address these challenges, we introduce two data augmentation techniques designed to resemble blocked antennas, enhancing the generalizability of localization models to dynamic scenarios. Additionally, we enhance an existing Deep Learning (DL) model by incorporating attention modules, improving its ability to focus on relevant channel features and antennas. We train our model on data from a static scenario, augmented with the proposed techniques, and evaluate it on a dataset collected in changing scenarios. We investigate the performance enhancements achieved by the data augmentation techniques and the Attention modules, and observe a localization accuracy improvement from a mean error of 286 mm, when trained without Attention and without data augmentations, to 66 mm, when trained with Attention and data augmentation. This shows that high localization accuracy can be maintained in changing environments, even without training data from those scenarios.

Paper number 34:
Title: RIS Nearfield Position and Velocity Estimation Using a Validated Propagation Model
Authors: Thomas Zemen, Musa Furkan Keskin, Moustafa Rahal, Thomas Wilding, Hamed Radpour, Markus Hofer, Benoit Denis, Henk Wymeersch
Abstract: We investigate reconfigurable intelligent surfaces (RISs) for the task of position and velocity estimation in non-LOS (NLOS) indoor scenarios, using a snapshot based multi-step estimation algorithm. We evaluate a compound RIS structure prototype composed of four RIS tiles with 1-bit phase control per RIS unit cell. Numerical simulation results taking the antenna patterns into account are presented for an 3 m x 3 m area of interest. We demonstrate that the initial grid search step using the far field assumption is not robust enough for small distances to the RIS center and propose a more robust algorithm. Furthermore, we show that the effect of the antenna pattern causes an increased position and velocity error. Our modified three-step algorithm achieves a position error of 7 mm and a velocity error of 0.12 m/s at a distance of 2 m to the RIS center under a realistic numerical propagation model.

Paper number 35:
Title: Represent Micro-Doppler Signature in Orders
Authors: Weicheng Gao
Abstract: Non-line-of-sight sensing of human activities in complex environments is enabled by multiple-input multiple-output through-the-wall radar (TWR). However, the distinctiveness of micro-Doppler signature between similar indoor human activities such as gun carrying and normal walking is minimal, while the large scale of input images required for effective identification utilizing time-frequency spectrograms creates challenges for model training and inference efficiency. To address this issue, the Chebyshev-time map is proposed in this paper, which is a method characterizing micro-Doppler signature using polynomial orders. The parametric kinematic models for human motion and the TWR echo model are first established. Then, a time-frequency feature representation method based on orthogonal Chebyshev polynomial decomposition is proposed. The kinematic envelopes of the torso and limbs are extracted, and the time-frequency spectrum slices are mapped into a robust Chebyshev-time coefficient space, preserving the multi-order morphological detail information of time-frequency spectrum. Numerical simulations and experiments are conducted to verify the effectiveness of the proposed method, which demonstrates the capability to characterize armed and unarmed indoor human activities while effectively compressing the scale of the time-frequency spectrum to achieve a balance between recognition accuracy and input data dimensions. The open-source code of this paper can be found in: this https URL.

Paper number 36:
Title: A two-step approach for speech enhancement in low-SNR scenarios using cyclostationary beamforming and DNNs
Authors: Giovanni Bologni, Nicolás Arrieta Larraza, Richard Heusdens, Richard C. Hendriks
Abstract: Deep Neural Networks (DNNs) often struggle to suppress noise at low signal-to-noise ratios (SNRs). This paper addresses speech enhancement in scenarios dominated by harmonic noise and proposes a framework that integrates cyclostationarity-aware preprocessing with lightweight DNN-based denoising. A cyclic minimum power distortionless response (cMPDR) spectral beamformer is used as a preprocessing block. It exploits the spectral correlations of cyclostationary noise to suppress harmonic components prior to learning-based enhancement and does not require modifications to the DNN architecture. The proposed pipeline is evaluated in a single-channel setting using two DNN architectures: a simple and lightweight convolutional recurrent neural network (CRNN), and a state-of-the-art model, namely ultra-low complexity network (ULCNet). Experiments on synthetic data and real-world recordings dominated by rotating machinery noise demonstrate consistent improvements over end-to-end DNN baselines, particularly at low SNRs. Remarkably, a parameter-efficient CRNN with cMPDR preprocessing surpasses the performance of the larger ULCNet operating on raw or Wiener-filtered inputs. These results indicate that explicitly incorporating cyclostationarity as a signal prior is more effective than increasing model capacity alone for suppressing harmonic interference.

Paper number 37:
Title: Bayesian Optimization Based Grid Point Allocation for LPV and Robust Control
Authors: E. Javier Olucha, Arash Sadeghzadeh, Amritam Das, Roland Tóth
Abstract: This paper investigates systematic selection of optimal grid points for grid-based Linear Parameter-Varying (LPV) and robust controller synthesis. In both settings, the objective is to identify a set of local models such that the controller synthesized for these local models will satisfy global stability and performance requirements for the entire system. Here, local models correspond to evaluations of the LPV or uncertain plant at fixed values of the scheduling signal or realizations of the uncertainty set, respectively. Then, Bayesian optimization is employed to discover the most informative points that govern the closed-loop performance of the designed LPV or robust controller for the complete system until no significant further performance increase or a user specified limit is reached. Furthermore, when local model evaluations are computationally demanding or difficult to obtain, the proposed method is capable to minimize the number of evaluations and adjust the overall computational cost to the available budget. Lastly, the capabilities of the proposed method in automatically obtaining a sufficiently informative grid set are demonstrated on three case-studies: a robust controller design for an unbalanced disk, a multi-objective robust attitude controller design for a satellite with uncertain parameters and two flexible rotating solar arrays, and an LPV controller design for a robotic arm.

Paper number 38:
Title: Near-Field Beampointing with Low Exposure Regions: a Dominant Subspace Projection Approach
Authors: Laurence Defraigne, Gilles Monnoyer, Jérôme Louveaux, Luc Vandendorpe
Abstract: The spherical nature of the wavefronts exhibited in the near-field of antenna arrays enables advanced beamforming capabilities, such as beampointing and beamnulling. In this paper, we exploit these properties to design a near-field beam pattern under a low exposure region constraint. We address the continuous region constraint through spatial discretization, which results in a large number of constraints that lead to prohibitive computational complexity. We propose a novel low-complexity algorithm that enables a computationally tractable beam pattern design. It uses a low-dimensional subspace representation of the low exposure region based on a singular value decomposition. Our approach achieves low complexity while providing a power received at a target user close to the optimal achievable power, yet with uniform power mitigation over the low exposure region.

Paper number 39:
Title: Efficient Plug-and-Play method for Dynamic Imaging Via Kalman Smoothing
Authors: Benjamin Hawkes, Mike Davies, Victor Elvira, Audrey Repetti
Abstract: State-space models (SSM) are common in signal processing, where Kalman smoothing (KS) methods are state-of-the-art. However, traditional KS techniques lack expressivity as they do not incorporate spatial prior information. Recently, [1] proposed an ADMM algorithm that handles the state-space fidelity term with KS while regularizing the object via a sparsity-based prior with proximity operators. Plug-and-Play (PnP) methods are a popular type of iterative algorithms that replace proximal operators encoding prior knowledge with powerful denoisers such as deep neural networks. These methods are widely used in image processing, achieving state-of-the-art results. In this work, we build on the KS-ADMM method, combining it with deep learning to achieve higher expressivity. We propose a PnP algorithm based on KS-ADMM iterations, efficiently handling the SSM through KS, while enabling the use of powerful denoising networks. Simulations on a 2D+t imaging problem show that the proposed PnP-KS-ADMM algorithm improves the computational efficiency over standard PnP-ADMM for large numbers of timesteps.

Paper number 40:
Title: Encoder initialisation methods in the model augmentation setting
Authors: J.H. Hoekstra, B. Györök, R. Töth, M. Schoukens
Abstract: Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.

Paper number 41:
Title: Properties of Near Field Focusing for Three-Dimensional Large Intelligent Surface
Authors: Jiawang Li, Mats Gustafsson, Alireza Saberkari, Buon Kiong Lau
Abstract: This work investigates near-field focusing using a three-dimensional (3D) large intelligent surface (LIS) across frequencies and polarizations. Specifically, the LIS elements are distributed in 3D space within a long corridor, rather than being confined to a single planar aperture, and the focal point is located at a prescribed position in the radiating near field. By formulating optimization problems under both local and global power constraints, we obtain the corresponding optima. For continuous apertures, the optimal current magnitude distribution matches time-reversal (TR) solution under the global constraint and conjugate-phase (CP) solution when the local constraint dominates. When both constraints are active, the solution assigns larger excitation magnitudes to elements closer to the illumination field. This behavior remains invariant with respect to frequency and polarization for a fixed-size LIS. These findings are consistent to the more practical case of using discretized apertures in the form of Hertzian dipole arrays, studied using both analytical results and full-wave simulation. In addition, with the CP method, specific polarizations lead to identical transverse and longitudinal resolution, in contrast, under the TR method, these quantities can differ across polarizations.

Paper number 42:
Title: 3-D Reconfigurable Intelligent Surface: From Reflection to Transmission and From Single Hemisphere to Full 3-D Coverage
Authors: Ruiqi Wang, Yiming Yang, Atif Shamim
Abstract: Reconfigurable intelligent surfaces (RIS) are conventionally implemented as two-dimensional (2D) electromagnetic (EM) structures to steer incident waves toward desired reflection angles. This approach limits the reflection to a single hemisphere, and the beam-scanning range is relatively small. In this work, a novel three-dimensional (3D) RIS concept is proposed, where beam-scanning can be realized not only through reflection from the illuminated surface but also through controlled transmission toward adjacent surfaces, enabling near blind-spot-free coverage in the full 3D spatial domain. A cube-based 3D-RIS design operating at millimeter-wave (mm-Wave) frequencies and consisting of six interconnected RIS surfaces is presented. Each surface integrates reconfigurable receiving and reflecting arrays with orthogonal polarizations to ensure intrinsic EM isolation, while a reconfigurable feeding network supports dynamic operation. A subarray-based synthesis approach with binary amplitude gating and predefined phase offsets is developed through a unified theoretical model. This model, validated through full-wave simulations, enables efficient beam switching through a shared aperture. Based on this framework, an 8 x 12 element surface comprising six 4 x 4 subarrays is designed, with each surface covering an angular range from -30 deg to +30 deg. The experimental prototype has been characterized in the 24 to 30 GHz band, and the results demonstrate a gain enhancement of 14.7 dB for reflection, while 14.1 dB is achieved for transmission to the neighboring surface. Finally, wireless communication trials using the Pluto software-defined radio platform combined with frequency up/down converters confirm improved constellation quality and a 6-7 dB improvement in error vector magnitude (EVM) for both reflection and neighboring surface transmission scenarios.

Paper number 43:
Title: Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction
Authors: Junjie An, Jingguang Tian, Tianyi Wang, Yu Gao, Xiaofeng Mou, Yi Xu
Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

Paper number 44:
Title: Real-Time Dynamic N-1 Screening: Identifying High-Risk Lines and Transformers After Common Faults
Authors: Ayrton Almada, Laurent Pagnier, Igal Goldshtein, Saif R. Kazi, Michael (Misha)Chertkov
Abstract: Power system operators routinely perform N-1 contingency analysis, yet conventional tools provide limited guidance on which lines or transformers deserve heightened attention during fast post-fault transients. In particular, static screening does not reveal whether (1) the same faulted line repeatedly triggers severe downstream overloads, or (2) a specific transformer emerges as vulnerable across many distinct fault scenarios. This paper introduces a real-time dynamic N-1 screening framework that addresses this gap by estimating, for each counterfactual single-phase transmission fault, the probability of transient overcurrent on critical grid elements. The output is an operator-facing dashboard that ranks (a) faulted lines whose outages most frequently lead to dangerous transformer overloads, and (b) transformers that consistently overload across top-risk scenarios, both of which are actionable indicators for real-time situational awareness. The approach models post-fault electromechanical dynamics using a linear stochastic formulation of the swing equations with short-lived, fault-localized uncertainty, and combines analytic transient evaluation with cross-entropy based importance sampling to efficiently estimate rare but high-impact events. All N-1 contingencies are evaluated in parallel with linear computational complexity. The framework is demonstrated on the IEEE 118-bus system, where it reveals latent high-risk lines and transformers that remain invisible under deterministic dynamic or static N-1 analysis. Results show orders-of-magnitude computational speedup relative to brute-force Monte Carlo, enabling practical deployment within real-time operational cycles.

Paper number 45:
Title: Beyond Musical Descriptors: Extracting Preference-Bearing Intent in Music Queries
Authors: Marion Baranes, Romain Hennequin, Elena V. Epure
Abstract: Although annotated music descriptor datasets for user queries are increasingly common, few consider the user's intent behind these descriptors, which is essential for effectively meeting their needs. We introduce MusicRecoIntent, a manually annotated corpus of 2,291 Reddit music requests, labeling musical descriptors across seven categories with positive, negative, or referential preference-bearing roles. We then investigate how reliably large language models (LLMs) can extract these music descriptors, finding that they do capture explicit descriptors but struggle with context-dependent ones. This work can further serve as a benchmark for fine-grained modeling of user intent and for gaining insights into improving LLM-based music understanding systems.

Paper number 46:
Title: OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video Generation Model
Authors: Maomao Li, Zhen Li, Kaipeng Zhang, Guosheng Yin, Zhifeng Li, Dong Xu
Abstract: Existing mainstream video customization methods focus on generating identity-consistent videos based on given reference images and textual prompts. Benefiting from the rapid advancement of joint audio-video generation, this paper proposes a more compelling new task: sync audio-video customization, which aims to synchronously customize both video identity and audio timbre. Specifically, given a reference image $I^{r}$ and a reference audio $A^{r}$, this novel task requires generating videos that maintain the identity of the reference image while imitating the timbre of the reference audio, with spoken content freely specifiable through user-provided textual prompts. To this end, we propose OmniCustom, a powerful DiT-based audio-video customization framework that can synthesize a video following reference image identity, audio timbre, and text prompts all at once in a zero-shot manner. Our framework is built on three key contributions. First, identity and audio timbre control are achieved through separate reference identity and audio LoRA modules that operate through self-attention layers within the base audio-video generation model. Second, we introduce a contrastive learning objective alongside the standard flow matching objective. It uses predicted flows conditioned on reference inputs as positive examples and those without reference conditions as negative examples, thereby enhancing the model ability to preserve identity and timbre. Third, we train OmniCustom on our constructed large-scale, high-quality audio-visual human dataset. Extensive experiments demonstrate that OmniCustom outperforms existing methods in generating audio-video content with consistent identity and timbre fidelity.

Paper number 47:
Title: Control Barrier Functions with Audio Risk Awareness for Robot Safe Navigation on Construction Sites
Authors: Johannes Mootz, Reza Akhavian
Abstract: Construction automation increasingly requires autonomous mobile robots, yet robust autonomy remains challenging on construction sites. These environments are dynamic and often visually occluded, which complicates perception and navigation. In this context, valuable information from audio sources remains underutilized in most autonomy stacks. This work presents a control barrier function (CBF)-based safety filter that provides safety guarantees for obstacle avoidance while adapting safety margins during navigation using an audio-derived risk cue. The proposed framework augments the CBF with a lightweight, real-time jackhammer detector based on signal envelope and periodicity. Its output serves as an exogenous risk that is directly enforced in the controller by modulating the barrier function. The approach is evaluated in simulation with two CBF formulations (circular and goal-aligned elliptical) with a unicycle robot navigating a cluttered construction environment. Results show that the CBF safety filter eliminates safety violations across all trials while reaching the target in 40.2% (circular) vs. 76.5% (elliptical), as the elliptical formulation better avoids deadlock. This integration of audio perception into a CBF-based controller demonstrates a pathway toward richer multimodal safety reasoning in autonomous robots for safety-critical and dynamic environments.

Paper number 48:
Title: MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs
Authors: Baorong Shi, Bo Cui, Boyuan Jiang, Deli Yu, Fang Qian, Haihua Yang, Huichao Wang, Jiale Chen, Jianfei Pan, Jieqiong Cao, Jinghao Lin, Kai Wu, Lin Yang, Shengsheng Yao, Tao Chen, Xiaojun Xiao, Xiaozhong Ji, Xu Wang, Yijun He, Zhixiong Yang
Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source multimodal systems on multiple capabilities. To achieve this, we propose an entity-aware continual pretraining framework that organizes heterogeneous medical corpora to broaden knowledge coverage and reduce long-tail gaps (e.g., rare diseases). For medical expert-level reasoning and interaction, MedXIAOHE incorporates diverse medical reasoning patterns via reinforcement learning and tool-augmented agentic training, enabling multi-step diagnostic reasoning with verifiable decision traces. To improve reliability in real-world use, MedXIAOHE integrates user-preference rubrics, evidence-grounded reasoning, and low-hallucination long-form report generation, with improved adherence to medical instructions. We release this report to document our practical design choices, scaling insights, and evaluation framework, hoping to inspire further research.

Paper number 49:
Title: Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting
Authors: Jing Xu, Minglin Wu, Xueyuan Chen, Xixin Wu, Helen Meng
Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.

Paper number 50:
Title: FPNet: Joint Wi-Fi Beamforming Matrix Feedback and Anomaly-Aware Indoor Positioning
Authors: Ran Tao, Jiajia Guo, Yiming Cui, Xiangyi Li, Chao-Kai Wen, Shi Jin
Abstract: Channel State Information (CSI) provides a detailed description of the wireless channel and has been widely adopted for Wi-Fi sensing, particularly for high-precision indoor positioning. However, complete CSI is rarely available in real-world deployments due to hardware constraints and the high communication overhead required for feedback. Moreover, existing positioning models lack mechanisms to detect when users move outside their trained regions, leading to unreliable estimates in dynamic environments. In this paper, we present FPNet, a unified deep learning framework that jointly addresses channel feedback compression, accurate indoor positioning, and robust anomaly detection (AD). FPNet leverages the beamforming feedback matrix (BFM), a compressed CSI representation natively supported by IEEE 802.11ac/ax/be protocols, to minimize feedback overhead while preserving critical positioning features. To enhance reliability, we integrate ADBlock, a lightweight AD module trained on normal BFM samples, which identifies out-of-distribution scenarios when users exit predefined spatial regions. Experimental results using standard 2.4 GHz Wi-Fi hardware show that FPNet achieves positioning accuracy above 97% with only 100 feedback bits, boosts net throughput by up to 22.92%, and attains AD accuracy over 99% with a false alarm rate below 1.5%. These results demonstrate FPNet's ability to deliver efficient, accurate, and reliable indoor positioning on commodity Wi-Fi devices.

Paper number 51:
Title: A Wavefield Correlation Approach to Improve Sound Speed Estimation in Ultrasound Autofocusing
Authors: Louise Zhuang, Samuel Beuret, Ben Frey, Saachi Munot, Jeremy J. Dahl
Abstract: Aberration often degrades ultrasound image quality when beamforming does not account for wavefront distortions. In the past decade, local sound speed estimators have been developed for distributed aberration correction throughout a medium. Recently, iterative sound speed optimization approaches have achieved more accurate estimates than earlier approaches, but these newer methods still struggle with decreased accuracy for media with reverberation clutter and large sound speed changes. To address these challenges, we propose using a wavefield correlation (WFC) beamforming approach when performing sound speed optimization. WFC correlates simulated forward-propagated transmit wavefields and backwards-propagated receive wavefields in order to form images. This process more accurately models wave propagation in heterogeneous media and can decrease diffuse clutter due to its spatiotemporal matched filtering effect. This beamformer is implemented using auto-differentiation software to then perform gradient descent optimization, using a total-variation regularized common midpoint phase focus metric loss, on the local sound speed map used during beamforming. This approach is compared to using delay and sum (DAS) with straight-ray time delay calculations in the same sound speed optimization approach on a variety of simulated, phantom, and in vivo data with large sound speed changes and clutter. Results show that using WFC decreases sound speed estimation error, and using the estimates for aberration correction improves image resolution and contrast. These promising results have potential to improve pulse-echo imaging for challenging clinical scenarios.

Paper number 52:
Title: SKYSURF: A Self-learning Framework for Persistent Surveillance using Cooperative Aerial Gliders
Authors: Houssem Eddine Mohamadi, Nadjia Kara
Abstract: The success of surveillance applications involving small unmanned aerial vehicles (UAVs) depends on how long the limited on-board power would persist. To cope with this challenge, alternative renewable sources of lift are sought. One promising solution is to extract energy from rising masses of buoyant air. This paper proposes a local-global behavioral management and decision-making approach for the autonomous deployment of soaring-capable UAVs. The cooperative UAVs are modeled as non-deterministic finite state-based rational agents. In addition to a mission planning module for assigning tasks and issuing dynamic navigation waypoints for a new path planning scheme, in which the concepts of visibility and prediction are applied to avoid the collisions. Moreover, a delayed learning and tuning strategy is employed optimize the gains of the path tracking controller. Rigorous comparative analyses carried out with three benchmarking baselines and 15 evolutionary algorithms highlight the adequacy of the proposed approach for maintaining the surveillance persistency (staying aloft for longer periods without landing) and maximizing the detection of targets (two times better than non-cooperative and semi-cooperative approaches) with less power consumption (almost 6% of battery consumed in six hours).

Paper number 53:
Title: EARL: Energy-Aware Adaptive Antenna Control with Reinforcement Learning in O-RAN Cell-Free Massive MIMO Networks
Authors: Zilin Ge, Ozan Alp Topal, Irshad Ahmad Meer, Pei Xiao, Cicek Cavdar
Abstract: Cell-free massive multi-input multi-output (MIMO) promises uniform high performance across the network, but also brings a high energy cost due to joint transmission from distributed radio units (RUs) and centralized processing in the cloud. Leveraging the resource-sharing capabilities of Open Radio Access Network (O-RAN), we propose EARL, an energy-aware adaptive antenna control framework based on reinforcement learning. EARL dynamically configures antenna elements in RUs to minimize radio, optical fronthaul, and cloud processing power consumption while meeting user spectral efficiency demands. Numerical results show power savings of up to 81% and 50% over full-on and heuristic baselines, respectively. The RL-based approach operates within 220 ms, satisfying O-RAN's near-real-time limit, and a greedy refinement further halves power consumption at a 2 s runtime.

Paper number 54:
Title: Model-Aware Rate-Distortion Limits for Task-Oriented Source Coding
Authors: Andriy Enttsel, Vincent Corlay
Abstract: Task-Oriented Source Coding (TOSC) has emerged as a paradigm for efficient visual data communication in machine-centric inference systems, where bitrate, latency, and task performance must be jointly optimized under resource constraints. While recent works have proposed rate-distortion bounds for coding for machines, these results often rely on strong assumptions on task identifiability and neglect the impact of deployed task models. In this work, we revisit the fundamental limits of single-TOSC through the lens of indirect rate-distortion theory. We highlight the conditions under which existing rate-distortion bounds are achievable and show their limitations in realistic settings. We then introduce task model-aware rate-distortion bounds that account for task model suboptimality and architectural constraints. Experiments on standard classification benchmarks confirm that current learned TOSC schemes operate far from these limits, highlighting transmitter-side complexity as a key bottleneck.

Paper number 55:
Title: Quantization-Aware Collaborative Inference for Large Embodied AI Models
Authors: Zhonghao Lyu, Ming Xiao, Mikael Skoglund, Merouane Debbah, H. Vincent Poor
Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

Paper number 56:
Title: A Data-Driven Algorithm for Model-Free Control Synthesis
Authors: Sean Bowerfind, Matthew R. Kirchner, Gary Hewer
Abstract: Presented is an algorithm to synthesize the optimal infinite-horizon LQR feedback controller for continuous-time systems. The algorithm does not require knowledge of the system dynamics but instead uses only a finite-length sampling of arbitrary input-output data. The algorithm is based on a constrained optimization problem that enforces a necessary condition on the dynamics of the optimal value function along any trajectory. In addition to calculating the standard LQR gain matrix, a feedforward gain can be found to implement a reference tracking controller. This paper presents a theoretical justification for the method and shows several examples, including a validation test on a real scale aircraft.

Paper number 57:
Title: Composite Learning Backstepping Control With Provable Exponential Stability and Robustness
Authors: Tian Shi, Shihua Li, Changyun Wen, Yongping Pan
Abstract: Adaptive backstepping control provides a feasible solution to achieve asymptotic tracking for mismatched uncertain nonlinear systems. However, the closed-loop stability depends on high-gain feedback generated by nonlinear damping terms, and closed-loop exponential stability with parameter convergence involves a stringent condition named persistent excitation (PE). This paper proposes a composite learning backstepping control (CLBC) strategy based on modular backstepping and high-order tuners to compensate for the transient process of parameter estimation and achieve closed-loop exponential stability without the nonlinear damping terms and the PE condition. A novel composite learning mechanism is designed to maximize the staged exciting strength for parameter estimation, such that parameter convergence can be achieved under a condition of interval excitation (IE) or even partial IE that is strictly weaker than PE. An extra prediction error is employed in the adaptive law to ensure the transient performance without nonlinear damping terms. The exponential stability of the closed-loop system is proved rigorously under the partial IE or IE condition. Simulations have demonstrated the effectiveness and superiority of the proposed method in both parameter estimation and control compared to state-of-the-art methods.

Paper number 58:
Title: A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling
Authors: Chinmay Rao, Matthias van Osch, Nicola Pezzotti, Jeroen de Bresser, Mark van Buchem, Laurens Beljaards, Jakob Meineke, Elwin de Weerdt, Huangling Lu, Mariya Doneva, Marius Staring
Abstract: Since multiple MRI contrasts of the same anatomy contain redundant information, one contrast can guide the reconstruction of an undersampled subsequent contrast. To this end, several end-to-end learning-based guided reconstruction methods have been proposed. However, a key challenge is the requirement of large paired training datasets comprising raw data and aligned reference images. We propose a modular two-stage approach that does not require any k-space training data, relying solely on image-domain datasets, a large part of which can be unpaired. Additionally, our approach provides an explanatory framework for the multi-contrast problem based on the shared and non-shared generative factors underlying two given contrasts. A content/style model of two-contrast image data is learned from a largely unpaired image-domain dataset and is subsequently applied as a plug-and-play operator in iterative reconstruction. The disentanglement of content and style allows explicit representation of contrast-independent and contrast-specific factors. Consequently, incorporating prior information into the reconstruction reduces to a simple replacement of the aliased content of the reconstruction iterate with high-quality content derived from the reference scan. Combining this component with a data consistency step and introducing a general corrective process for the content yields an iterative scheme. We name this novel approach PnP-CoSMo. Various aspects like interpretability and convergence are explored via simulations. Furthermore, its practicality is demonstrated on the public NYU fastMRI DICOM dataset, showing improved generalizability compared to end-to-end methods, and on two in-house multi-coil raw datasets, offering up to 32.6\% more acceleration over learning-based non-guided reconstruction for a given SSIM.

Paper number 59:
Title: A Synthetic Data-Driven Radiology Foundation Model for Pan-tumor Clinical Diagnosis
Authors: Wenhui Lei, Hanyu Chen, Zitian Zhang, Luyang Luo, Qiong Xiao, Yannian Gu, Peng Gao, Yankai Jiang, Ci Wang, Guangtao Wu, Tongjia Xu, Yingjie Zhang, Pranav Rajpurkar, Xiaofan Zhang, Shaoting Zhang, Zhenning Wang
Abstract: AI-assisted imaging made substantial advances in tumor diagnosis and management. However, a major barrier to developing robust oncology foundation models is the scarcity of large-scale, high-quality annotated datasets, which are limited by privacy restrictions and the high cost of manual labeling. To address this gap, we present PASTA, a pan-tumor radiology foundation model built on PASTA-Gen, a synthetic data framework that generated 30,000 3D CT scans with pixel-level lesion masks and structured reports of tumors across ten organ systems. Leveraging this resource, PASTA achieves state-of-the-art performance on 45 of 46 oncology tasks, including non-contrast CT tumor screening, lesion segmentation, structured reporting, tumor staging, survival prediction, and MRI-modality transfer. To assess clinical applicability, we developed PASTA-AID, a clinical decision support system, and ran a retrospective simulated clinical trial across two scenarios. For pan-tumor screening on plain CT with fixed reading time, PASTA-AID increased radiologists' throughput by 11.1-25.1% and improved sensitivity by 17.0-31.4% and precision by 10.5-24.9%; additionally, in a diagnosis-aid workflow, it reduced segmentation time by up to 78.2% and reporting time by up to 36.5%. Beyond gains in accuracy and efficiency, PASTA-AID narrowed the expertise gap, enabling less-experienced radiologists to approach expert-level performance. Together, this work establishes an end-to-end, synthetic data-driven pipeline spanning data generation, model development, and clinical validation, thereby demonstrating substantial potential for pan-tumor research and clinical translation.

Paper number 60:
Title: Network-Realised Model Predictive Control Part I: NRF-Enabled Closed-loop Decomposition
Authors: Andrei Sperilă, Alessio Iovine, Sorin Olaru, Patrick Panciatici
Abstract: A two-layer control architecture is proposed to enable scalable implementations for constraint-based decision strategies, such as model predictive controllers. The bottom layer is based upon a distributed feedback-feedforward scheme that directs the controlled network's information flow according to a pre-specified communication infrastructure. Explicit expressions for the resulting closed-loop maps are obtained, and an offline model-matching procedure is proposed for designing the first layer. The obtained control laws are deployed via distributed state-space-based implementations, and the resulting closed-loop models enable predictive control design for the constraint management procedure described in our companion paper.

Paper number 61:
Title: Network-Realised Model Predictive Control Part II: Distributed Constraint Management
Authors: Andrei Sperilă, Alessio Iovine, Sorin Olaru, Patrick Panciatici
Abstract: A two-layer control architecture is proposed, which promotes scalable implementations for model predictive controllers. The top layer acts as both a reference governor for the bottom layer and as a feedback controller for the regulated network. By employing set-based methods, global theoretical guarantees are obtained by enforcing local constraints upon the network's variables and upon those of the first layer's implementation. The proposed technique offers recursive feasibility guarantees as one of its central features, and the expressions of the resulting predictive strategies bear a striking resemblance to classical formulations from model predictive control literature, allowing for flexible and easily customisable implementations.

Paper number 62:
Title: LesionDiffusion: Towards Text-controlled General Lesion Synthesis
Authors: Wenhui Lei, Henrui Tian, Linrui Dai, Hanyu Chen, Xiaofan Zhang
Abstract: Fully-supervised lesion recognition methods in medical imaging face challenges due to the reliance on large annotated datasets, which are expensive and difficult to collect. To address this, synthetic lesion generation has become a promising approach. However, existing models struggle with scalability, fine-grained control over lesion attributes, and the generation of complex structures. We propose LesionDiffusion, a text-controllable lesion synthesis framework for 3D CT imaging that generates both lesions and corresponding masks. By utilizing a structured lesion report template, our model provides greater control over lesion attributes and supports a wider variety of lesion types. We introduce a dataset of 1,505 annotated CT scans with paired lesion masks and structured reports, covering 14 lesion types across 8 organs. LesionDiffusion consists of two components: a lesion mask synthesis network (LMNet) and a lesion inpainting network (LINet), both guided by lesion attributes and image features. Extensive experiments demonstrate that LesionDiffusion significantly improves segmentation performance, with strong generalization to unseen lesion types and organs, outperforming current state-of-the-art models. Code is available at this https URL.

Paper number 63:
Title: Precision yield estimation and mapping in manual strawberry harvesting with instrumented picking carts and a robust data processing pipeline
Authors: Uddhav Bhattarai, Rajkishan Arikapudi, Chen Peng, Steven A. Fennimore, Frank N Martin, Stavros G. Vougioukas
Abstract: High-resolution yield maps for manually harvested crops are impractical to generate on commercial scales because yield monitors are available only for mechanical harvesters. However, precision crop management relies on accurately determining spatial and temporal yield variability. This study presents the development of an integrated system for precision yield estimation and mapping for manually harvested strawberries. Conventional strawberry picking carts were instrumented with a Global Positioning System (GPS) receiver, an Inertial Measurement Unit (IMU), and load cells to record real-time geo-tagged harvest data and cart motion. Extensive data were collected in two strawberry fields in California, USA, during a harvest season. To address the inconsistencies and errors caused by the sensors and the manual harvesting process, a robust data processing pipeline was developed by integrating supervised deep learning models with unsupervised algorithms. The pipeline was used to estimate the yield distribution and generate yield maps for season-long harvests at the desired grid resolution. The estimated yield distributions were used to calculate two metrics: the total mass harvested over specific row segments and the total mass of trays harvested. The metrics were compared to ground truth and achieved accuracies of 90.48% and 94.05%, respectively. Additionally, the accuracy of the estimated yield based on the number of trays harvested per cart for season-long harvest was better than 94%. It showed a strong correlation (Pearson r = 0.99) with the actual number of counted trays in both fields. The proposed system provides a scalable and practical solution for specialty crops, assisting in efficient yield estimation and mapping, field management, and labor management for sustainable crop production.

Paper number 64:
Title: Multi-dimensional Parameter Estimation in RIS-aided MU-MIMO-OFDM Channels
Authors: Linlin Mo, Yi Song, Fabio Saggese, Xinhua Lu, Zhongyong Wang, Petar Popovski
Abstract: We address the channel estimation (CE) problem in reconfigurable intelligent surface (RIS) aided orthogonal frequency-division multiplexing (OFDM) systems by proposing a dual-structure and multi-dimensional transformations (DS-MDT) this http URL proposed approach leverages the dual-structure features of the channel parameters to assist users experiencing weaker channel conditions, thereby enhancing CE performance. Moreover, given that the channel parameters are distributed across multiple dimensions of the received tensor, the proposed algorithm employs multi-dimensional transformations to isolate and extract distinct parameters. The numerical results demonstrate the proposed algorithm reduces the normalized mean square error (NMSE) by up to 10 dB while maintaining lower complexity compared to state-of-the-art methods.

Paper number 65:
Title: Active Sampling for MRI-based Sequential Decision Making
Authors: Yuning Du, Jingshuai Liu, Rohan Dharmakumar, Sotirios A. Tsaftaris
Abstract: Despite the superior diagnostic capability of Magnetic Resonance Imaging (MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and complexity. To enable such a future by reducing the magnetic field strength, one key approach will be to improve sampling strategies. Previous work has shown that it is possible to make diagnostic decisions directly from k-space with fewer samples. Such work shows that single diagnostic decisions can be made, but if we aspire to see MRI as a true PoC, multiple and sequential decisions are necessary while minimizing the number of samples acquired. We present a novel multi-objective reinforcement learning framework enabling comprehensive, sequential, diagnostic evaluation from undersampled k-space data. Our approach during inference actively adapts to sequential decisions to optimally sample. To achieve this, we introduce a training methodology that identifies the samples that contribute the best to each diagnostic objective using a step-wise weighting reward function. We evaluate our approach in two sequential knee pathology assessment tasks: ACL sprain detection and cartilage thickness loss assessment. Our framework achieves diagnostic performance competitive with various policy-based benchmarks on disease detection, severity quantification, and overall sequential diagnosis, while substantially saving k-space samples. Our approach paves the way for the future of MRI as a comprehensive and affordable PoC device. Our code is publicly available at this https URL

Paper number 66:
Title: Data-based control of Logical Networks
Authors: Giorgia Disarò, Maria Elena Valcher
Abstract: In recent years, data-driven approaches have become increasingly pervasive across all areas of control engineering. However, the applications of data-based techniques to Boolean control networks (BCNs) are still very limited. In this paper we aim to fill this gap, by exploring the possibility of evaluating some basic features, i.e., reachability and equilibria, and of solving two fundamental control problems, i.e., safe control and output regulation, for a BCN, leveraging only a limited amount of data generated by the network, without knowing or identifying its model.

Paper number 67:
Title: CUHK-EE Systems for the vTAD Challenge at NCMMSC 2025
Authors: Aemon Yat Fei Chiu, Jingyu Li, Yusheng Tian, Guangyan Zhang, Tan Lee
Abstract: This paper presents the Voice Timbre Attribute Detection (vTAD) systems developed by the Digital Signal Processing & Speech Technology Laboratory (DSP&STL) of the Department of Electronic Engineering (EE) at The Chinese University of Hong Kong (CUHK) for the 20th National Conference on Human-Computer Speech Communication (NCMMSC 2025) vTAD Challenge. The proposed systems leverage WavLM-Large embeddings with attentive statistical pooling (ASTP) to extract robust speaker representations, followed by two variants of Diff-Net, i.e., Feed-Forward Neural Network (FFN) and Squeeze-and-Excitation-enhanced Residual FFN (SE-ResFFN), to compare timbre attribute intensities between utterance pairs. Experimental results demonstrate that the WavLM-Large+FFN system generalises better to unseen speakers, achieving 77.96% accuracy and 21.79% equal error rate (EER), while the WavLM-Large+SE-ResFFN model excels in the 'Seen' setting with 94.42% accuracy and 5.49% EER. These findings highlight a trade-off between model complexity and generalisation, and underscore the importance of architectural choices in fine-grained speaker modelling. Our analysis also reveals the impact of speaker identity, annotation subjectivity, and data imbalance on system performance, pointing to future directions for improving robustness and fairness in timbre attribute detection.

Paper number 68:
Title: EEG-FM-Bench: A Comprehensive Benchmark for the Systematic Evaluation of EEG Foundation Models
Authors: Wei Xiong, Jiangtong Li, Jie Li, Kun Zhu, Changjun Jiang
Abstract: Electroencephalography foundation models (EEG-FMs) have advanced brain signal analysis, but the lack of standardized evaluation benchmarks impedes model comparison and scientific progress. Current evaluations rely on inconsistent protocols that render cross-model comparisons unreliable, while a lack of diagnostic analyses obscures the internal mechanisms driving transfer efficiency and scaling behaviors. To address this, we introduce \textbf{EEG-FM-Bench}, a unified system for the standardized evaluation of EEG-FMs. The benchmark integrates 14 datasets across 10 paradigms and incorporates diverse experimental settings, including multiple fine-tuning strategies, task organizations, and classifier configurations, supported by tools for gradient and representation analysis. Our experiments and analysis reveal several critical insights: (1) multi-task learning acts as a critical regularizer to mitigate overfitting in data-scarce EEG contexts; (2) pre-training efficiency is currently limited by gradient conflicts between reconstruction objectives and downstream tasks; (3) model scaling deviates from typical laws, as compact architectures with domain-specific inductive biases consistently outperform significantly larger models. This benchmark enables fair comparison and reproducible analysis, shifting the field from fragmented results to interpretable advances. Code is available at this https URL.

Paper number 69:
Title: Solving Conic Programs over Sparse Graphs using a Variational Quantum Approach: The Case of the Optimal Power Flow
Authors: Thinh Viet Le, Mark M. Wilde, Vassilis Kekatos
Abstract: Conic programs arise broadly in physics, quantum information, machine learning, and engineering, many of which are defined over sparse graphs. Although such problems can be solved in polynomial time using classical interior-point solvers, the computational complexity scales unfavorably with graph size. In this context, this work proposes a variational quantum paradigm for solving conic programs, including quadratically constrained quadratic programs (QCQPs) and semidefinite programs (SDPs). We encode primal variables via the state of a parameterized quantum circuit (PQC), and dual variables via the probability mass function of a second PQC. The Lagrangian function can thus be expressed as scaled expectations of quantum observables. A primal-dual solution can be found by minimizing/maximizing the Lagrangian over the parameters of the first/second PQC. We pursue saddle points of the Lagrangian in a hybrid fashion. Gradients of the Lagrangian are estimated using the two PQCs, while PQC parameters are updated classically using a primal-dual method. We propose permuting the primal variables so that related observables are expressed in a banded form, enabling efficient measurement. The proposed framework is applied to the OPF problem, a large-scale optimization problem central to the operation of electric power systems. Numerical tests on the IEEE 57-node power system using Pennylane's simulator corroborate that the proposed doubly variational quantum framework can find high-quality OPF solutions. Although showcased for the OPF, this framework features a broader scope, including conic programs with numerous variables and constraints, problems defined over sparse graphs, and training quantum machine learning models to satisfy constraints.

Paper number 70:
Title: Optimal Control of an SIR Model with Noncompliance as a Social Contagion
Authors: Chloe Ngo, Christian Parkinson, Weinan Wang
Abstract: We propose and study a compartmental model for epidemiology with human behavioral effects. Specifically, our model incorporates governmental prevention measures aimed at lowering the disease infection rate, but we split the population into those who comply with the measures and those who do not comply and therefore do not receive the reduction in infectivity. We then allow the attitude of noncompliance to spread as a social contagion parallel to the disease. We derive the reproductive ratio for our model and provide stability analysis for the disease-free equilibria. We then propose an optimal control scenario wherein a policy-maker with access to control variables representing disease prevention mandates, treatment efforts, and educational campaigns aimed at encouraging compliance minimizes a cost functional incorporating several cost concerns. Via careful analysis of the control-to-state map, we are able to prove existence of optimal controls. Our proof applies to dynamics which can be nonlinear in the control variables and general cost functionals including the case of $L^1$ control costs. We numerically resolve optimal strategies using the sequential quadratic Hamiltonian method, a relatively new numerical method for optimal control which is easy to implement and has good convergence theory, as we demonstrate. We test our model in several parameter regimes with specific interest in observing how the policy-maker's optimal strategies depend on their particular preferences which are expressed via design of different cost functionals.

Paper number 71:
Title: Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization
Authors: SaiKrishna Saketh Yellapragada, Esa Ollila, Mario Costa
Abstract: As wireless communication systems advance toward Sixth Generation (6G) Radio Access Networks (RAN), Deep Learning (DL)-based neural receivers are emerging as transformative solutions for Physical Layer (PHY) processing, delivering superior Block Error Rate (BLER) performance compared to traditional model-based approaches. Practical deployment on resource-constrained hardware, however, requires efficient quantization to reduce latency, energy, and memory without sacrificing reliability. In this paper, we extend Post-Training Quantization (PTQ) by focusing on Quantization-Aware Training (QAT), which incorporates low-precision simulation during training for robustness at ultra-low bitwidths. In particular, we develop a QAT methodology for a neural receiver architecture and benchmark it against a PTQ approach across diverse 3GPP Clustered Delay Line (CDL) channel profiles under both Line-of-Sight (LoS) and Non-LoS (NLoS) conditions, with user velocities up to 40 m/s. Results show that 4-bit and 8-bit QAT models achieve BLERs comparable to FP32 models at a 10% target BLER. Moreover, QAT models succeed in NLoS scenarios where PTQ models fail to reach the 10% BLER target, while also yielding an 8x compression. These results with respect to full-precision demonstrate that QAT is a key enabler of low-complexity and latency-constrained inference at the PHY layer, facilitating real-time processing in 6G edge devices.

Paper number 72:
Title: Multi-Level Multi-Fidelity Methods for Path Integral and Safe Control
Authors: Zhuoyuan Wang, Takashi Tanaka, Yongxin Chen, Yorie Nakahira
Abstract: Sampling-based approaches are widely used in systems without analytic models to estimate risk or find optimal control. However, gathering sufficient data in such scenarios can be prohibitively costly. On the other hand, in many situations, low-fidelity models or simulators are available from which samples can be obtained at low cost. In this paper, we propose an efficient approach for risk quantification and path integral control that leverages such data from multiple models with heterogeneous sampling costs. A key technical novelty of our approach is the integration of Multi-level Monte Carlo (MLMC) and Multi-fidelity Monte Carlo (MFMC) that enable data from different time and state representations (system models) to be jointly used to reduce variance and improve sampling efficiency. We also provide theoretical analysis of the proposed method and show that our estimator is unbiased and consistent under mild conditions. Finally, we demonstrate via numerical simulation that the proposed method has improved computation (sampling costs) vs. accuracy trade-offs for risk quantification and path integral control.

Paper number 73:
Title: Direct Kernel Optimization: Efficient Design for Opto-Electronic Convolutional Neural Networks
Authors: Ali Almuallem, Harshana Weligampola, Abhiram Gnanasambandam, Wei Xu, Dilshan Godaliyadda, Hamid R. Sheikh, Stanley H. Chan, Qi Guo
Abstract: Hybrid opto-electronic neural networks combine optical front-ends with electronic back-ends to perform vision tasks, but joint end-to-end (E2E) optimization of optical and electronic components is computationally expensive due to large parameter spaces and repeated optical convolutions. We propose Direct Kernel Optimization (DKO), a two-stage training framework that first trains a conventional electronic CNN and then synthesizes optical kernels to replicate the first-layer convolutional filters, reducing optimization dimensionality and avoiding hefty simulated optical convolutions during optimization. We evaluate DKO in simulation on a monocular depth estimation model and show that it achieves twice the accuracy of E2E training under equal computational budgets while reducing training time. Given the substantial computational challenges of optimizing hybrid opto-electronic systems, our results position DKO as a scalable optimization approach to train and realize these systems.

Paper number 74:
Title: DRL-Based Beam Positioning for LEO Satellite Constellations with Weighted Least Squares
Authors: Po-Heng Chou, Chiapin Wang, Kuan-Hao Chen, Wei-Chen Hsiao
Abstract: In this paper, we propose a reinforcement learning based beam weighting framework that couples a policy network with an augmented weighted least squares (WLS) estimator for accurate and low-complexity positioning in multi-beam LEO constellations. Unlike conventional geometry or CSI-dependent approaches, the policy learns directly from uplink pilot responses and geometry features, enabling robust localization without explicit CSI estimation. An augmented WLS jointly estimates position and receiver clock bias, improving numerical stability under dynamic beam geometry. Across representative scenarios, the proposed method reduces the mean positioning error by 99.3% compared with the geometry-based baseline, achieving 0.395 m RMSE with near real-time inference.

Paper number 75:
Title: Risk-Based Capacity Accreditation of Resource-Colocated Large Loads in Capacity Markets
Authors: Siying Li, Lang Tong, Timothy D. Mount
Abstract: We study capacity accreditation of resource-colocated large loads, defined as large demands such as data center and manufacturing loads colocated with behind-the-meter generation and storage resources, synchronously connected to the bulk power system, and capable of participating in the wholesale electricity market as an integrated unit. Because the accredited capacity of a resource portfolio is not equal to the sum of its individual resources' capacity values, we adopt a risk-based capacity accreditation framework to evaluate the combined reliability contribution of colocated resources. Grounded in the effective load carrying capability (ELCC) metric, the proposed capacity accreditation employs a convex optimization engine that jointly dispatches colocated resources to minimize reliability risk. We apply the developed methodology to a hydrogen manufacturing facility with colocated renewable generation, storage, and fuel cell resources.

Paper number 76:
Title: Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction
Authors: Siying Xu, Kerstin Hammernik, Daniel Rueckert, Sergios Gatidis, Thomas Küstner
Abstract: The demand for high-resolution, non-invasive imaging continues to drive innovation in magnetic resonance imaging (MRI), yet prolonged acquisition times hinder accessibility and real-time applications. While deep learning-based reconstruction methods have accelerated MRI, their predominant supervised paradigm depends on fully-sampled reference data that are challenging to acquire. Recently, self-supervised learning (SSL) approaches have emerged as promising alternatives, but most are empirically designed and fragmented. Therefore, we introduce UNITS (Unified Theory for Self-supervision), a general framework for self-supervised MRI reconstruction. UNITS unifies prior SSL strategies within a common formalism, enabling consistent interpretation and systematic benchmarking. We prove that SSL can achieve the same expected performance as supervised learning. Under this theoretical guarantee, we introduce sampling stochasticity and flexible data utilization, which improve network generalization under out-of-domain distributions and stabilize training. Together, these contributions establish UNITS as a theoretical foundation and a practical paradigm for interpretable, generalizable, and clinically applicable self-supervised MRI reconstruction.

Paper number 77:
Title: Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables, and Uncertainty Quantification
Authors: George P. Kafentzis, Efstratios Selisios
Abstract: In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, reported gains are often not directly comparable, and it remains unclear whether improvements stem from modeling advances or from differences in data and evaluation. We address this gap by establishing a strong, well-documented baseline for TB prediction using cough recordings and accompanying clinical metadata from a recently compiled dataset from several countries. Our pipeline is reproducible end-to-end, covering feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and it reports a consistent suite of clinically relevant metrics to enable fair comparison. We further quantify performance for cough audio-only and fused (audio + clinical metadata) models, and release the full experimental protocol to facilitate benchmarking. This baseline is intended to serve as a common reference point and to reduce methodological variance that currently holds back progress in the field.

Paper number 78:
Title: Toward Agentic AI: Task-Oriented Communication for Hierarchical Planning of Long-Horizon Tasks
Authors: Sin-Yu Huang, Lele Wang, Vincent W.S. Wong
Abstract: Agentic artificial intelligence (AI) is an AI paradigm that can perceive the environment, reason over observations, and execute actions to achieve specific goals. Task-oriented communication supports agentic AI by transmitting only the task-related information instead of full raw data in order to reduce the bandwidth requirement. In real-world scenarios, AI agents often need to perform a sequence of actions to complete complex tasks. Completing these long-horizon tasks requires a hierarchical agentic AI architecture, where a high-level planner module decomposes a task into subtasks, and a low-level actor module executes each subtask sequentially. Since each subtask has a distinct goal, the existing task-oriented communication schemes are not designed to handle different goals for different subtasks. To address this challenge, in this paper, we develop a hierarchical task-oriented communication (HiTOC) framework. We consider a system with an edge server and a robot as an edge device. The high-level planner and low-level actor modules reside on the edge server. The robot transmits only the environmental observation that is relevant to the current subtask to the edge server. We propose a conditional variational information bottleneck (cVIB) approach to train the HiTOC framework to adaptively transmit minimal information required for each subtask. Simulations conducted on the AI2-THOR platform demonstrate that the proposed HiTOC framework outperforms three state-of-the-art schemes in terms of the success rate on MAP-THOR benchmark.

Paper number 79:
Title: Backstepping Control of PDEs on Domains with Graph-Monotone Boundaries
Authors: Mohamed Camil Belhadjoudja
Abstract: Despite the extensive body of work on backstepping for one-dimensional PDEs, results in higher dimensions remain comparatively limited. Most available methods either exploit particular symmetries of the PDE or address problems posed on parallelepiped domains. To the best of our knowledge, the only approach that enables the design of backstepping controllers on non-parallelepiped regions without symmetry assumptions is the domain extension technique. This method, however, presents several drawbacks. In particular, the control input at each time instant is obtained by simulating a PDE on an extended domain, from which the actual input on the original domain is approximated. By contrast, in the one-dimensional setting, once the time-independent backstepping gain kernel is known, the control input can be computed in closed form as a feedback depending solely on the state at that same instant. Moreover, problems such as output-feedback design or adaptive and robust control do not appear straightforward to address with the domain extension method, at least to the best of our knowledge. These considerations motivate the search, whenever possible, for alternatives that preserve the main advantages of one-dimensional backstepping. A motivating example for the domain extension method is the control of the heat equation on a piano-shaped domain, with actuation applied at the tail of the piano. In this extended abstract, we show through a simple calculation that the domain extension method is not required in this setting. Instead, a strategy akin to that used for parallelepiped domains can be adopted. This result constitutes a first instance of a broader framework for backstepping control of asymmetric PDEs posed on non-parallelepiped regions, which we refer to as domains with graph-monotone boundaries. The general framework is developed in a forthcoming paper.

Paper number 80:
Title: Is Downlink Training Necessary for User-Centric Cell-Free RSMA Systems With Mobile Users?
Authors: Ravi Kiran Palla, Dheeraj Naidu Amudala, Rohit Budhiraja
Abstract: We study the spectral efficiency (SE) of a ratesplitting multiple access (RSMA) enabled multi-clustered cell-free (CF) massive multiple-input multiple-output (mMIMO) system. The access points (APs) in each cluster serve mobile user equipments (UEs) by employing RSMA. The UEs employ successive interference cancellation to decode their data. This work emphasizes the role of downlink (DL) pilots in realizing RSMA benefits in practical CF systems with spatially-correlated Rician channels which observe random phase shifts, pilot contamination, and channel aging due to UE mobility. We numerically show that DL pilots are required for RSMA in user-centric CF mMIMO systems with channel aging to outperform spatial division multiple access. We show that the degraded channel quality due to higher UE velocity and longer resource block lengths significantly reduces the RSMA SE. Increasing the number of clusters can compensate for the SE loss.

Paper number 81:
Title: Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation
Authors: Can Yaras, Peng Wang, Laura Balzano, Qing Qu
Abstract: While overparameterization in machine learning models offers great benefits in terms of optimization and generalization, it also leads to increased computational requirements as model sizes grow. In this work, we show that by leveraging the inherent low-dimensional structures of data and compressible dynamics within the model parameters, we can reap the benefits of overparameterization without the computational burdens. In practice, we demonstrate the effectiveness of this approach for deep low-rank matrix completion as well as fine-tuning language models. Our approach is grounded in theoretical findings for deep overparameterized low-rank matrix recovery, where we show that the learning dynamics of each weight matrix are confined to an invariant low-dimensional subspace. Consequently, we can construct and train compact, highly compressed factorizations possessing the same benefits as their overparameterized counterparts. In the context of deep matrix completion, our technique substantially improves training efficiency while retaining the advantages of overparameterization. For language model fine-tuning, we propose a method called "Deep LoRA", which improves the existing low-rank adaptation (LoRA) technique, leading to reduced overfitting and a simplified hyperparameter setup, while maintaining comparable efficiency. We validate the effectiveness of Deep LoRA on natural language tasks, particularly when fine-tuning with limited data. Our code is available at this https URL.

Paper number 82:
Title: M6: Multi-generator, Multi-domain, Multi-lingual and cultural, Multi-genres, Multi-instrument Machine-Generated Music Detection Databases
Authors: Yupei Li, Hanqian Li, Lucia Specia, Björn W. Schuller
Abstract: Machine-generated music (MGM) has emerged as a powerful tool with applications in music therapy, personalised editing, and creative inspiration for the music community. However, its unregulated use threatens the entertainment, education, and arts sectors by diminishing the value of high-quality human compositions. Detecting machine-generated music (MGMD) is, therefore, critical to safeguarding these domains, yet the field lacks comprehensive datasets to support meaningful progress. To address this gap, we introduce \textbf{M6}, a large-scale benchmark dataset tailored for MGMD research. M6 is distinguished by its diversity, encompassing multiple generators, domains, languages, cultural contexts, genres, and instruments. We outline our methodology for data selection and collection, accompanied by detailed data analysis, providing all WAV form of music. Additionally, we provide baseline performance scores using foundational binary classification models, illustrating the complexity of MGMD and the significant room for improvement. By offering a robust and multifaceted resource, we aim to empower future research to develop more effective detection methods for MGM. We believe M6 will serve as a critical step toward addressing this societal challenge. The dataset and code will be freely available to support open collaboration and innovation in this field.

Paper number 83:
Title: A Tutorial on AI-Empowered Integrated Sensing and Communications
Authors: Mojtaba Vaezi, Gayan Aruma Baduge, Esa Ollila, Sergiy A. Vorobyov
Abstract: Integrating sensing and communication (ISAC) can help overcome the challenges of limited spectrum and expensive hardware, leading to improved energy and cost efficiency. While full cooperation between sensing and communication can result in significant performance gains, achieving optimal performance requires efficient designs of unified waveforms and beamformers for joint sensing and communication. Sophisticated statistical signal processing and multi-objective optimization techniques are necessary to balance the competing design requirements of joint sensing and communication tasks. As model-based approaches can be suboptimal or too complex, deep learning offers a powerful data-driven alternative, especially when optimal algorithms are unknown or impractical for real-time use. Unified waveform and beamformer design problems for ISAC fall into this category, where fundamental design trade-offs exist between sensing and communication performance metrics, and the underlying models may be inadequate or incomplete. This tutorial paper explores the application of artificial intelligence (AI) to enhance efficiency or reduce complexity in ISAC designs. We emphasize the integration benefits through AI-driven ISAC designs, prioritizing the development of unified waveforms, constellations, and beamforming strategies for both sensing and communication. To illustrate the practical potential of AI-driven ISAC, we present three case studies on waveform, beamforming, and constellation design, demonstrating how unsupervised learning and neural network-based optimization can effectively balance performance, complexity, and implementation constraints.

Paper number 84:
Title: Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting
Authors: Fei Teng, Kai Luo, Sheng Wu, Siyu Li, Pujun Guo, Jiale Wei, Jiaming Zhang, Kunyu Peng, Kailun Yang
Abstract: Panoramic perception holds significant potential for autonomous driving, enabling vehicles to acquire a comprehensive 360° surround view in a single shot. However, autonomous driving is a data-driven task. Complete panoramic data acquisition requires complex sampling systems and annotation pipelines, which are time-consuming and labor-intensive. Although existing street view generation models have demonstrated strong data regeneration capabilities, they can only learn from the fixed data distribution of existing datasets and cannot leverage stitched pinhole images as a supervisory signal. In this paper, we propose the first panoramic generation method Percep360 for autonomous driving. Percep360 enables coherent generation of panoramic data with control signals based on the stitched panoramic data. Percep360 focuses on two key aspects: coherence and controllability. Specifically, to overcome the inherent information loss caused by the pinhole sampling process, we propose the Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama generation as a spatially continuous diffusion process, bridging the gaps between different data distributions. Additionally, to achieve the controllable generation of panoramic images, we propose a Probabilistic Prompting Method (PPM). PPM dynamically selects the most relevant control cues, enabling controllable panoramic image generation. We evaluate the effectiveness of the generated images from three perspectives: image quality assessment (i.e., no-reference and with reference), controllability, and their utility in real-world Bird's Eye View (BEV) segmentation. Notably, the generated data consistently outperforms the original stitched images in no-reference quality metrics and enhances downstream perception models. The source code will be publicly available at this https URL.

Paper number 85:
Title: Algebraic Connectivity Reveals Modulated High-Order Functional Networks in Alzheimer's Disease
Authors: Giorgio Dolci, Silvia Saglia, Lorenza Brusini, Vince D. Calhoun, Ilaria Boscolo Galazzo, Gloria Menegaz
Abstract: Functional MRI is a neuroimaging technique that analyzes the functional activity of the brain by measuring blood-oxygen-level-dependent signals throughout the brain. The derived functional features can be used for investigating brain alterations in neurological and psychiatric disorders. In this work, we employed a hypergraph to model high-order functional relations across brain regions, introducing algebraic connectivity (a(G)) for estimating the hyperedge weights. The hypergraph structure was derived from healthy controls to build a common topology across individuals. The considered cohort for subsequent analyses included subjects covering the Alzheimer's disease (AD) continuum, encompassing both mild cognitive impairment and AD patients. Statistical analysis and three classification tasks: HC vs AD, MCI vs AD, and HC vs MCI, were performed to assess differences across the three groups and the potential of the hyperedge weights as functional features. Furthermore, a mediation analysis was performed to evaluate the reliability of the a(G) values, representing functional information as the mediator between tau-PET levels, a key biomarker of AD, and cognitive scores. The proposed approach identified a larger number of hyperedges statistically different across groups compared to state-of-the-art methods. The a(G) hyperedge weights also demonstrated a higher discriminative power in all three binary classifications. Finally, two hyperedges belonging to salience/ventral attention and somatomotor networks showed a partial mediation effect between the tau biomarker and cognitive decline. These results suggested that a(G) can be an effective approach for extracting the hyperedge weights, including important functional information that resides in the brain areas forming the hyperedges.

Paper number 86:
Title: Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer
Authors: Xuanhao Mu, Gökhan Demirel, Yuzhe Zhang, Jianlei Liu, Thorsten Schlachter, Veit Hagenmeyer
Abstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. The goal of time series generative models is to learn the distribution of the original data to generate high-resolution series with similar statistical characteristics. This is not entirely consistent with the definition of upsampling. Time series Super-Resolution models or imputation models can degrade the accuracy of upsampling because the input low-resolution time series are sparse and may have insufficient context. Moreover, such models usually rely on supervised learning paradigms. This presents a fundamental application paradox: their training requires the high-resolution time series that is intrinsically absent in upsampling application scenarios. To address the mentioned upsampling issue, this paper introduces a new method utilizing Generative Adversarial Transformers (GATs), which can be trained without access to any ground-truth high-resolution data. Compared with conventional interpolation methods, the introduced method can reduce the root mean square error (RMSE) of upsampling tasks by 10%, and the accuracy of a model predictive control (MPC) application scenario is improved by 13%.

Paper number 87:
Title: Diffusion-Based Scenario Tree Generation for Multivariate Time Series Prediction and Multistage Stochastic Optimization
Authors: Stelios Zarifis, Ioannis Kordonis, Petros Maragos
Abstract: Stochastic forecasting is critical for efficient decision-making in uncertain systems, such as energy markets and finance, where estimating the full distribution of future scenarios is essential. We propose Diffusion Scenario Tree (DST), a general framework for constructing scenario trees using diffusion-based probabilistic forecasting models to provide a structured model of system evolution for control tasks. DST recursively samples future trajectories and organizes them into a tree via clustering, ensuring non-anticipativity (decisions depending only on observed history) at each stage, offering a superior representation of uncertainty compared to using predictive models solely for forecasting system evolution. We integrate DST into Model Predictive Control (MPC) and evaluate it on energy arbitrage in New York State's day-ahead electricity market. Experimental results show that our approach significantly outperforms the same optimization algorithms that use scenario trees generated by more conventional models. Furthermore, using DST for stochastic optimization yields more efficient decision policies by better handling uncertainty than deterministic and stochastic MPC variants using the same diffusion-based forecaster, and simple Model-Free Reinforcement Learning (RL) baselines.

Paper number 88:
Title: Multi-Agent Stage-wise Conservative Linear Bandits
Authors: Amirhossein Afsharrad, Ahmadreza Moradipari, Sanjay Lall
Abstract: In many real-world applications such as recommendation systems, multiple learning agents must balance exploration and exploitation while maintaining safety guarantees to avoid catastrophic failures. We study the stochastic linear bandit problem in a multi-agent networked setting where agents must satisfy stage-wise conservative constraints. A network of $N$ agents collaboratively maximizes cumulative reward while ensuring that the expected reward at every round is no less than $(1-\alpha)$ times that of a baseline policy. Each agent observes local rewards with unknown parameters, but the network optimizes for the global parameter (average of local parameters). Agents communicate only with immediate neighbors, and each communication round incurs additional regret. We propose MA-SCLUCB (Multi-Agent Stage-wise Conservative Linear UCB), an episodic algorithm alternating between action selection and consensus-building phases. We prove that MA-SCLUCB achieves regret $\tilde{O}\left(\frac{d}{\sqrt{N}}\sqrt{T}\cdot\frac{\log(NT)}{\sqrt{\log(1/|\lambda_2|)}}\right)$ with high probability, where $d$ is the dimension, $T$ is the horizon, and $|\lambda_2|$ is the network's second largest eigenvalue magnitude. Our analysis shows: (i) collaboration yields $\frac{1}{\sqrt{N}}$ improvement despite local communication, (ii) communication overhead grows only logarithmically for well-connected networks, and (iii) stage-wise safety adds only lower-order regret. Thus, distributed learning with safety guarantees achieves near-optimal performance in reasonably connected networks.

Paper number 89:
Title: VDW-GNNs: Vector diffusion wavelets for geometric graph neural networks
Authors: David R. Johnson, Alexander Sietsema, Rishabh Anand, Deanna Needell, Smita Krishnaswamy, Michael Perlmutter
Abstract: We introduce vector diffusion wavelets (VDWs), a novel family of wavelets inspired by the vector diffusion maps algorithm that was introduced to analyze data lying in the tangent bundle of a Riemannian manifold. We show that these wavelets may be effectively incorporated into a family of geometric graph neural networks, which we refer to as VDW-GNNs. We demonstrate that such networks are effective on synthetic point cloud data, as well as on real-world data derived from wind-field measurements and neural activity data. Theoretically, we prove that these new wavelets have desirable frame theoretic properties, similar to traditional diffusion wavelets. Additionally, we prove that these wavelets have desirable symmetries with respect to rotations and translations.

Paper number 90:
Title: Multi-Window Temporal Analysis for Enhanced Arrhythmia Classification: Leveraging Long-Range Dependencies in Electrocardiogram Signals
Authors: Tiezhi Wang, Wilhelm Haverkamp, Nils Strodthoff
Abstract: Objective. Arrhythmia classification from electrocardiograms (ECGs) suffers from high false positive rates and limited cross-dataset generalization, particularly for atrial fibrillation (AF) detection where specificity ranges from 0.72 to 0.98 using conventional 30-s analysis windows. While most deep learning approaches analyze isolated 30-s ECG windows, many arrhythmias, including AF and atrial flutter, exhibit diagnostic features that emerge over extended time scales. Approach. We introduce S4ECG, a deep learning architecture based on structured state-space models (S4), designed to capture long-range temporal dependencies by jointly analyzing multiple consecutive ECG windows spanning up to 20 min. We evaluate S4ECG on four publicly available databases for multi-class arrhythmia classification and perform systematic cross-dataset evaluations to assess out-of-distribution robustness. Results. Multi-window analysis consistently outperforms single-window approaches across all datasets, improving macro-averaged AUROC by 1.0-11.6 percentage points. For AF, specificity increases from 0.718-0.979 to 0.967-0.998 at a fixed sensitivity threshold, yielding a 3-10-fold reduction in false positive rates. Significance. Compared with convolutional neural network baselines, the S4 architecture shows superior performance, and multi-window training substantially reduces cross-dataset degradation. Optimal diagnostic windows are 10-20 min, beyond which performance plateaus or degrades. These findings demonstrate that structured incorporation of extended temporal context enhances both arrhythmia classification accuracy and cross-dataset robustness. The identified optimal temporal windows provide practical guidance for ECG monitoring system design and may reflect underlying physiological timescales of arrhythmogenic dynamics.

Paper number 91:
Title: Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off
Authors: Muhammad Faraz Ul Abrar, Nicolò Michelusi
Abstract: Over-the-air (OTA) federated learning (FL) has been well recognized as a scalable paradigm that exploits the waveform superposition of the wireless multiple-access channel to aggregate model updates in a single use. Existing OTA-FL designs largely enforce zero-bias model updates by either assuming \emph{homogeneous} wireless conditions (equal path loss across devices) or forcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous} wireless scenarios, however, such designs are constrained by the weakest device and inflate the update variance. Moreover, prior analyses of biased OTA-FL largely address convex objectives, while most modern AI models are highly non-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient descent (SGD) for general smooth non-convex objectives under wireless heterogeneity. We develop novel OTA-FL SGD updates that allow a structured, time-invariant model bias while facilitating reduced variance updates. We derive a finite-time stationarity bound (expected time average squared gradient norm) that explicitly reveals a bias-variance trade-off. To optimize this trade-off, we pose a non-convex joint OTA power-control design and develop an efficient successive convex approximation (SCA) algorithm that requires only statistical CSI at the base station. Experiments on a non-convex image classification task validate the approach: the SCA-based design accelerates convergence via an optimized bias and improves generalization over prior OTA-FL baselines.

Paper number 92:
Title: Learning-based Radio Link Failure Prediction Based on Measurement Dataset in Railway Environments
Authors: Po-Heng Chou, Da-Chih Lin, Hung-Yu Wei, Walid Saad, Yu Tsao
Abstract: This paper presents a measurement-driven case study on early radio link failure (RLF) warning as device-side network sensing and analytics for proactive mobility management in 5G non-standalone (NSA) railway environments. Using 10~Hz metro-train measurement traces with serving- and neighbor-cell indicators, we benchmark six representative learning models, including CNN, LSTM, XGBoost, Anomaly Transformer, PatchTST, and TimesNet, under multiple observation windows and prediction horizons. Rather than proposing a new prediction architecture, this study focuses on quantifying the feasibility of early warning and the trade-offs among observation context, prediction horizon, and alarm reliability under real railway mobility. Experimental results show that learning models can anticipate RLF-related reliability degradation seconds in advance using lightweight features available on commercial devices. The presented benchmark provides practical insights for sensing-assisted communication control, such as proactive redundancy activation and adaptive handover strategies, aligning with the 6G vision of integrating sensing and analytics into mobility control.

Paper number 93:
Title: Robust and Real-Time Bangladeshi Currency Recognition: A Dual-Stream MobileNet and EfficientNet Approach
Authors: Subreena, Mohammad Amzad Hossain, Mirza Raquib, Saydul Akbar Murad, Farida Siddiqi Prity, Muhammad Hanif, Nick Rahimi
Abstract: Accurate currency recognition is essential for assistive technologies, particularly for visually impaired individuals who rely on others to identify banknotes. This dependency puts them at risk of fraud and exploitation. To address these challenges, we first build a new Bangladeshi banknote dataset that includes both controlled and real-world scenarios, ensuring a more comprehensive and diverse representation. Next, to enhance the dataset's robustness, we incorporate four additional datasets, including public benchmarks, to cover various complexities and improve the model's generalization. To overcome the limitations of current recognition models, we propose a novel hybrid CNN architecture that combines MobileNetV3-Large and EfficientNetB0 for efficient feature extraction. This is followed by an effective multilayer perceptron (MLP) classifier to improve performance while keeping computational costs low, making the system suitable for resource-constrained devices. The experimental results show that the proposed model achieves 97.95% accuracy on controlled datasets, 92.84% on complex backgrounds, and 94.98% accuracy when combining all datasets. The model's performance is thoroughly evaluated using five-fold cross-validation and seven metrics: accuracy, precision, recall, F1-score, Cohen's Kappa, MCC, and AUC. Additionally, explainable AI methods like LIME and SHAP are incorporated to enhance transparency and interpretability.
    