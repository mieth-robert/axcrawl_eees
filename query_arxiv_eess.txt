
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Autonomous Satellite Rendezvous via Hybrid Feedback Optimization
Authors: Oscar Jed R. Chuy, Matthew T. Hale, Vignesh Sivaramakrishnan, Sean Phillips, Ricardo G. Sanfelice
Abstract: As satellites have proliferated, interest has increased in autonomous rendezvous, proximity operations, and docking (ARPOD). A fundamental challenge in these tasks is the uncertainties when operating in space, e.g., in measurements of satellites' states, which can make future states difficult to predict. Another challenge is that satellites' onboard processors are typically much slower than their terrestrial counterparts. Therefore, to address these challenges we propose to solve an ARPOD problem with feedback optimization, which computes inputs to a system by measuring its outputs, feeding them into an optimization algorithm in the loop, and computing some number of iterations towards an optimal input. We focus on satellite rendezvous, and satellites' dynamics are modeled using the continuous-time Clohessy-Wiltshire equations, which are marginally stable. We develop an asymptotically stabilizing controller for them, and we use discrete-time gradient descent in the loop to compute inputs to them. Then, we analyze the hybrid feedback optimization system formed by the stabilized Clohessy-Wiltshire equations with gradient descent in the loop. We show that this model is well-posed and that maximal solutions are both complete and non-Zeno. Then, we show that solutions converge exponentially fast to a ball around a rendezvous point, and we bound the radius of that ball in terms of system parameters. Simulations show that this approach provides up to a 98.4\% reduction in the magnitude of disturbances across a range of simulations, which illustrates the viability of hybrid feedback optimization for autonomous satellite rendezvous.

Paper number 2:
Title: On Optimizing Image Codecs for VMAF NEG: Analysis, Issues, and a Robust Loss Proposal
Authors: Florian Fingscheidt, Alexander Karabutov, Panqi Jia, Elena Alshina, JÖrn Ostermann
Abstract: The VMAF (video multi-method assessment fusion) metric for image and video coding recently gained more and more popularity as it is supposed to have a high correlation with human perception. This makes training and particularly fine-tuning of machine-learned codecs on this metric interesting. However, VMAF is shown to be attackable in a way that, e.g., unsharpening an image can lead to a gain in VMAF quality while decreasing the quality in human perception. A particular version of VMAF called VMAF NEG has been designed to be more robust against such attacks and therefore it should be more useful for fine-tuning of codecs. In this paper, our contributions are threefold. First, we identify and analyze the still existing vulnerability of VMAF NEG towards attacks, particulary towards the attack that consists in employing VMAF NEG for image codec fine-tuning. Second, to benefit from VMAF NEG's high correlation with human perception, we propose a robust loss including VMAF NEG for fine-tuning either the encoder or the decoder. Third, we support our quantitative objective results by providing perceptive impressions of some image examples.

Paper number 3:
Title: RelA-Diffusion: Relativistic Adversarial Diffusion for Multi-Tracer PET Synthesis from Multi-Sequence MRI
Authors: Minhui Yu, Yongheng Sun, David S. Lalush, Jason P Mihalik, Pew-Thian Yap, Mingxia Liu
Abstract: Multi-tracer positron emission tomography (PET) provides critical insights into diverse neuropathological processes such as tau accumulation, neuroinflammation, and $\beta$-amyloid deposition in the brain, making it indispensable for comprehensive neurological assessment. However, routine acquisition of multi-tracer PET is limited by high costs, radiation exposure, and restricted tracer availability. Recent efforts have explored deep learning approaches for synthesizing PET images from structural MRI. While some methods rely solely on T1-weighted MRI, others incorporate additional sequences such as T2-FLAIR to improve pathological sensitivity. However, existing methods often struggle to capture fine-grained anatomical and pathological details, resulting in artifacts and unrealistic outputs. To this end, we propose RelA-Diffusion, a Relativistic Adversarial Diffusion framework for multi-tracer PET synthesis from multi-sequence MRI. By leveraging both T1-weighted and T2-FLAIR scans as complementary inputs, RelA-Diffusion captures richer structural information to guide image generation. To improve synthesis fidelity, we introduce a gradient-penalized relativistic adversarial loss to the intermediate clean predictions of the diffusion model. This loss compares real and generated images in a relative manner, encouraging the synthesis of more realistic local structures. Both the relativistic formulation and the gradient penalty contribute to stabilizing the training, while adversarial feedback at each diffusion timestep enables consistent refinement throughout the generation process. Extensive experiments on two datasets demonstrate that RelA-Diffusion outperforms existing methods in both visual fidelity and quantitative metrics, highlighting its potential for accurate synthesis of multi-tracer PET.

Paper number 4:
Title: Semi-Gridless Variational Bayes Channel Estimation in XL-MIMO: Near-Field Modeling and Inference
Authors: Van-Chung Luu, Toan-Van Nguyen, Nuria González-Prelcic, Duy H. N. Nguyen
Abstract: Extremely large antenna arrays and high-frequency operation are two key technologies that advance performance metrics such as higher data rates, lower latency, and wider coverage in sixth-generation communications. However, the adoption of these technologies fundamentally changes the characteristics of wavefronts, forcing communication systems to operate in the near-field region. The transition from planar far-field communications to spherical near-field propagation necessitates novel channel estimation algorithms to fully exploit the unique features of spherical wavefronts for advanced transceiver design. To this end, we propose a novel semi-gridless channel estimation approach based on a variational Bayesian (VB) inference framework. Specifically, we reformulate the near-field channel model for both uniform linear arrays and uniform planar arrays into separate direction-of-arrival (DoAs) and distance components. Building on these new representations, we employ a gridless approach for DoAs estimation using a von Mises distribution, and a coarse-to-fine grid search for distance estimation. We then develop a semi-gridless variational Bayesian (SG-VB) algorithm with efficient update rules that enables accurate channel reconstruction. Simulation results validate the effectiveness of the proposed SG-VB algorithm, demonstrating enhanced near-field channel reconstruction accuracy and superior estimation performance for both DoAs and distance components embedded in near-field channels.

Paper number 5:
Title: iMiGUE-Speech: A Spontaneous Speech Dataset for Affective Analysis
Authors: Sofoklis Kakouros, Fang Kang, Haoyu Chen
Abstract: This work presents iMiGUE-Speech, an extension of the iMiGUE dataset that provides a spontaneous affective corpus for studying emotional and affective states. The new release focuses on speech and enriches the original dataset with additional metadata, including speech transcripts, speaker-role separation between interviewer and interviewee, and word-level forced alignments. Unlike existing emotional speech datasets that rely on acted or laboratory-elicited emotions, iMiGUE-Speech captures spontaneous affect arising naturally from real match outcomes. To demonstrate the utility of the dataset and establish initial benchmarks, we introduce two evaluation tasks for comparative assessment: speech emotion recognition and transcript-based sentiment analysis. These tasks leverage state-of-the-art pre-trained representations to assess the dataset's ability to capture spontaneous affective states from both acoustic and linguistic modalities. iMiGUE-Speech can also be synchronously paired with micro-gesture annotations from the original iMiGUE dataset, forming a uniquely multimodal resource for studying speech-gesture affective dynamics. The extended dataset is available at this https URL.

Paper number 6:
Title: A Knowledge-Driven Approach to Music Segmentation, Music Source Separation and Cinematic Audio Source Separation
Authors: Chun-wei Ho, Sabato Marco Siniscalchi, Kai Li, Chin-Hui Lee
Abstract: We propose a knowledge-driven, model-based approach to segmenting audio into single-category and mixed-category chunks with applications to source separation. "Knowledge" here denotes information associated with the data, such as music scores. "Model" here refers to tool that can be used for audio segmentation and recognition, such as hidden Markov models. In contrast to conventional learning that often relies on annotated data with given segment categories and their corresponding boundaries to guide the learning process, the proposed framework does not depend on any pre-segmented training data and learns directly from the input audio and its related knowledge sources to build all necessary models autonomously. Evaluation on simulation data shows that score-guided learning achieves very good music segmentation and separation results. Tested on movie track data for cinematic audio source separation also shows that utilizing sound category knowledge achieves better separation results than those obtained with data-driven techniques without using such information.

Paper number 7:
Title: Perceptual Quality Optimization of Image Super-Resolution
Authors: Wei Zhou, Yixiao Li, Hadi Amirpour, Xiaoshuai Hao, Jiang Liu, Peng Wang, Hantao Liu
Abstract: Single-image super-resolution (SR) has achieved remarkable progress with deep learning, yet most approaches rely on distortion-oriented losses or heuristic perceptual priors, which often lead to a trade-off between fidelity and visual quality. To address this issue, we propose an \textit{Efficient Perceptual Bi-directional Attention Network (Efficient-PBAN)} that explicitly optimizes SR towards human-preferred quality. Unlike patch-based quality models, Efficient-PBAN avoids extensive patch sampling and enables efficient image-level perception. The proposed framework is trained on our self-constructed SR quality dataset that covers a wide range of state-of-the-art SR methods with corresponding human opinion scores. Using this dataset, Efficient-PBAN learns to predict perceptual quality in a way that correlates strongly with subjective judgments. The learned metric is further integrated into SR training as a differentiable perceptual loss, enabling closed-loop alignment between reconstruction and perceptual assessment. Extensive experiments demonstrate that our approach delivers superior perceptual quality. Code is publicly available at this https URL.

Paper number 8:
Title: Deep Unfolding Real-Time Super-Resolution Using Subpixel-Shift Twin Image and Convex Self-Similarity Prior
Authors: Chia-Hsiang Lin, Wei-Chih Liu, Yu-En Chiu, Jhao-Ting Lin
Abstract: Multi-image super-resolution (MISR) is a critical technique for satellite remote sensing. In the perspective of information, twin-image super-resolution (TISR) is regarded as the most challenging MISR scenario, having crucial applications like the SPOT-5 supermode imaging. In TISR, an image is super-resolved by its subpixel-shift counterpart (i.e., twin image), where the two images are typically offset by half a pixel both horizontally and vertically. We formulate the less investigated TISR using a convex criterion, which is implemented using a novel deep unfolding network. In the unfolding, an embedded simple shift operator trickily addresses the coupled TISR data-fitting terms, and a transformer trained with a convex self-similarity loss function elegantly implements the proximal mapping induced by the TISR regularizer. The proposed convex self-similarity unfolding supermode super-resolution (COSUP) algorithm is interpretable and achieves state-of-the-art performance with very fast millisecond-level computational time. COSUP is also tested on real-world data, for which the subpixel shifts would not be spatially uniform, with results showing great superiority over the official CNES supermode imaging product in terms of credible metrics (e.g., natural image quality evaluator, NIQE). Source codes: this https URL.

Paper number 9:
Title: Optimal Real-Time Fusion of Time-Series Data Under Rényi Differential Privacy
Authors: Chuanghong Weng, Ehsan Nekouei
Abstract: In this paper, we investigate the optimal real-time fusion of data collected by multiple sensors. In our set-up, the sensor measurements are considered to be private and are jointly correlated with an underlying process. A fusion center combines the private sensor measurements and releases its output to an honest-but-curious party, which is responsible for estimating the state of the underlying process based on the fusion center's output. The privacy leakage incurred by the fusion policy is quantified using Rényi differential privacy. We formulate the privacy-aware fusion design as a constrained finite-horizon optimization problem, in which the fusion policy and the state estimation are jointly optimized to minimize the state estimation error subject to a total privacy budget constraint. We derive the constrained optimality conditions for the proposed optimization problem and use them to characterize the structural properties of the optimal fusion policy. Unlike classical differential privacy mechanisms, the optimal fusion policy is shown to adaptively allocates the privacy budget and regulates the adversary's belief in a closed-loop manner. To reduce the computational burden of solving the resulting constrained optimality equations, we parameterize the fusion policy using a structured Gaussian distribution and show that the parameterized fusion policy satisfies the privacy constraint. We further develop a numerical algorithm to jointly optimize the fusion policy and state estimator. Finally, we demonstrate the effectiveness of the proposed fusion framework through a traffic density estimation case study.

Paper number 10:
Title: Diagnosis-Driven Co-planning of Network Reinforcement and BESS for Distribution Grid with High Penetration of Electric Vehicles
Authors: Linhan Fang, Elias Raffoul, Xingpeng Li
Abstract: While the rapid proliferation of electric vehicles (EVs) accelerates net-zero goals, uncoordinated charging activities impose severe operational challenges on distribution grids, including exacerbated peak loads, thermal overloading, and voltage violations. To overcome the computational intractability of jointly optimizing grid infrastructure reinforcements and battery energy storage system (BESS) installations, this paper proposes a novel three-stage diagnosis-driven co-planning (DDCP) framework. The methodology integrates a violation detection and quantification (VDQ) model to systematically identify system breaches, and a violation-mitigated BESS planning (VMBP) model for optimal BESS sitting and sizing. Specifically, Stage I of the DDCP framework diagnoses critical bottleneck lines that render standalone BESS solutions infeasible. Stage II targets cable upgrades exclusively at the Top-N prioritized bottleneck lines and Stage III then executes the optimal BESS deployment using a network-enhanced VMBP model. Furthermore, this study quantifies the EV hosting capacity thresholds before and after BESS integration across varying EV adoption rates and base voltages. Finally, a comprehensive comparative analysis evaluates four mitigation approaches: the VDQ-driven cable upgrade (VCU) model, the VMBP model, system-wide voltage uprating, and the proposed DDCP framework. The results demonstrate that the DDCP framework not only resolves the complex joint-optimization hurdle but also achieves the high techno-economic superiority in addressing high-EV-penetration challenges.

Paper number 11:
Title: Delay-Synchronous Wideband Channel Sounding Using Off-The-Shelf Multi-Antenna WiFi Devices
Authors: Koji Yamamoto, Katsuyuki Haneda
Abstract: It has been shown that WiFi devices enable sensing of environments and targets through their channel state information. However, the same devices have not been used for delay-synchronous channel sounding due to challenges related to the stability of synchronization and lack of reference power levels. Due to factors such as uncertainty in symbol reception timing, impulse responses are discontinuous across acquisitions. The present paper addresses the challenges to perform delay-synchronous channel sounding using off-the-shelf multiple-antenna IEEE 802.11ax WiFi devices, referred to as SoundiFi. Stable delay synchronization and power level reference are realized by remoting the antennas with coaxial cables and devoting one of the antennas as a reference channel, with which the gain and delay of other simultaneous channels are defined. Indoor experiments confirmed that the impulse response becomes continuous across successive acquisitions and provide the absolute delay. The impulse response has a noise level at -115 dB, indicating the maximum path gain value that can be measured with the devices. The impulse response also revealed the existence of long-delayed multipaths up to 132 m propagation distance in a reverberant 30-m-long corridor.

Paper number 12:
Title: Asymmetry Demystified: Strict CLFs and Feedbacks for Predator-Prey Interconnections
Authors: Miroslav Krstic
Abstract: The difficulty with control of population dynamics, besides the states being positive and the control having to also be positive, is the extreme difference in the dynamics near extinction and at overpopulated states. As hard as global stabilization is, even harder is finding CLFs that are strict, don't require LaSalle arguments, and permit quantification of convergence. Among the three canonical types of two-population dynamics (mutualism, which borders on trivial, predator-prey, and competition, which makes global stabilization with positive harvesting impossible), predator-prey is the ``sweet spot'' for the study of stabilization. Even when the predator-prey interaction is neutrally stable, global asymptotic stabilization with strict CLFs has proven very difficult, except by conservative, hard-to-gain-insight-from Matrosov-like techniques. In this little note we show directions for the design of clean, elegant, insight-bearing, majorization-free strict CLFs. They generalize the classical Volterra-style Lyapunov functions for population dynamics to non-separable Volterra-style constructions. As a bonus to strictification as an analysis activity, we provide examples of concurrent designs of feedback and CLFs, using customized versions of forwarding and backstepping (note that, in suitable coordinates, predator-prey is both strict-feedforward and strict-feedback), where the striking deviations from these methods' conventional forms is necessitated by the predator-prey's states and inputs needing to be kept positive.

Paper number 13:
Title: Geometry-Dependent Radiation of Pinching Antennas: Theory, Simulation, and Measurement
Authors: Haoyang Li, Weidong Liu, Zhensheng Chen, Chaoyun Song, Gaojie Chen
Abstract: Most existing studies achieve beamforming by adjusting the positions of pinching antennas (PAs) and typically model PAs as isotropic radiators. However, under the dielectric scatterer model, the PA radiation pattern depends on its geometry. This letter investigates the radiation patterns of PAs with different geometries through full-wave simulations and measurements, and demonstrates how geometry influences the radiation directivity. In addition, an arc-shaped PA is introduced to enable transmit-direction control in PA systems. A PA system prototype consisting of a dielectric waveguide, waveguide transitions, and a PA element is proposed. Prototype measurements are used to validate the simulations and to characterize the directivity of square and triangular PAs, and the measurement procedure can be applied to obtain radiation patterns for PAs with general geometries. The simulation and measurement results jointly demonstrate that PA geometry is critical in PA systems because it influences the radiation characteristics significantly.

Paper number 14:
Title: Pinching Antennas for Multiple Access in Multigroup Multicast Communications
Authors: Shan Shan, Chongjun Ouyang, Yong Li, Yuanwei Liu
Abstract: This paper aims to design multiple access (MA) schemes to improve the max-min fairness (MMF) for pinching antennas (PAs)-based multigroup multicast communications, where PA placement and resource allocation are jointly optimized. Specifically, three MA schemes are considered to facilitate the multicast transmission: i) treating interference as noise (TIN), ii) non-orthogonal multiple access (NOMA), and iii) time-division multiple access (TDMA) with two PA reconfiguration protocols, namely pinching switching (PS) and pinching multiplexing (PM). i) For TIN, a closed-form solution is derived for optimal power allocation, while a sequential element-wise optimization (SEO) is developed for the PA placement. ii) For NOMA, a recursive power allocation framework incorporating a bisection search is developed, and a hierarchical objective evaluation (HOE) mechanism is incorporated to simplify the SEO process for PA location update. iii) For TDMA, the PS protocol allows the PA locations to be optimized separately using the SEO method, after which the time-power allocation is solved as a convex problem with a global optimum. Under the PM protocol, the PA locations are jointly optimized with the time-power resources through a Karush-Kuhn-Tucker (KKT)-based analytical solution. Numerical results demonstrate that: i) the pinching-antenna system (PASS) architecture significantly outperforms traditional fixed-antenna systems. ii) TDMA-PS achieves superior performance by fully leveraging the flexible PA reconfiguration and benefiting from interference-free transmission, whereas TIN serves as a practical lower-bound solution due to its simplicity despite its limited performance. iii) NOMA consistently outperforms TDMA-PM and, in high transmit power regimes with heterogeneous multicast group distributions, can even surpass the performance achieved by TDMA-PS.

Paper number 15:
Title: Score-Based Conditional Flow Models for MIMO Receiver Design with Superimposed Pilots
Authors: Ruhao Zhang, Yupeng Li, Yitong Liu, Shijian Gao, Jing Jin, Hongwen Yang, Jiangzhou Wang
Abstract: Accurate channel state information (CSI) is vital for multiple-input multiple-output (MIMO) systems. However, superimposed pilots (SIP), which reduce overhead, introduce severe pilot contamination and data interference, complicating joint channel estimation and data detection. This paper proposes a conditional flow matching receiver (CFM-Rx), an unsupervised generative framework that learns directly from received signals, eliminating the need for labeled data and improving adaptability across diverse system settings. By leveraging flow-based generative modeling, CFM-Rx enables deterministic, low-latency inference and exploits model invertibility to capture the bidirectional nature of signal propagation. This framework unifies flow matching with score-based diffusion modeling via a moment-consistent ordinary differential equation (ODE), replacing stochastic differential equation (SDE) sampling with a deterministic and efficient process. Furthermore, it integrates receiver-side priors to ensure stable, data-consistent inference. Extensive simulation results across various MIMO configurations demonstrate that CFM-Rx consistently outperforms conventional estimators and state-of-the-art data-driven receivers, achieving notable gains in channel estimation accuracy and symbol detection robustness, particularly under severe pilot contamination.

Paper number 16:
Title: Deep Learning-based Low-Overhead Beam Alignment for mmWave Massive MIMO Systems
Authors: Weijie Jin, Jing Zhang, Hengtao He, Chao-Kai Wen, Xiao Li, Shi Jin
Abstract: Millimeter-wave massive multiple-input multiple-output systems employ highly directional beamforming to overcome severe path loss, and their performance critically depends on accurate beam alignment. Conventional codebook-based methods offer low training overhead but suffer from limited angular resolution and sensitivity to hardware impairments. To address these challenges, we propose a deep learning-enhanced super-resolution beam alignment framework with three key components. First, we design the Quaternary Search-based Super-Resolution (QSSR) algorithm, which leverages the monotonic power ratio property between two discrete Fourier transform (DFT) codebook beams to achieve super-resolution angle estimation without increasing measurement complexity relative to binary search. Second, we develop QSSR-Net, a gated recurrent unit-based neural network that exploits sequential multi-layer beam measurements to capture angular dependencies, thereby improving estimation accuracy, robustness to noise, and generalization across diverse propagation environments. Third, to mitigate the adverse effects of hardware impairments such as antenna position and phase errors, we propose a parametric self-calibration method that requires no additional hardware overhead and adapts compensation parameters in real time. Simulation results show that the proposed framework consistently outperforms binary search and even exhaustive search at high signal-to-noise ratios, achieving substantial performance gains while maintaining low overhead.

Paper number 17:
Title: Learning spatially adaptive sparsity level maps for arbitrary convolutional dictionaries
Authors: Joshua Schulz, David Schote, Christoph Kolbitsch, Kostas Papafitsoros, Andreas Kofler
Abstract: State-of-the-art learned reconstruction methods often rely on black-box modules that, despite their strong performance, raise questions about their interpretability and robustness. Here, we build on a recently proposed image reconstruction method, which is based on embedding data-driven information into a model-based convolutional dictionary regularization via neural network-inferred spatially adaptive sparsity level maps. By means of improved network design and dedicated training strategies, we extend the method to achieve filter-permutation invariance as well as the possibility to change the convolutional dictionary at inference time. We apply our method to low-field MRI and compare it to several other recent deep learning-based methods, also on in vivo data, in which the benefit for the use of a different dictionary is showcased. We further assess the method's robustness when tested on in- and out-of-distribution data. When tested on the latter, the proposed method suffers less from the data distribution shift compared to the other learned methods, which we attribute to its reduced reliance on training data due to its underlying model-based reconstruction component.

Paper number 18:
Title: Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach
Authors: Xu Yang, Chenhui Lin, Xiang Ma, Dong Liu, Ran Zheng, Haotian Liu, Wenchuan Wu
Abstract: The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method.

Paper number 19:
Title: Stability of Open Multi-agent Systems over Dynamic Signed Digraphs
Authors: Pelin Sekercioglu, Angela Fontan, Dimos V. Dimarogonas
Abstract: We address the synchronization problem in open multi-agent systems (OMAS) containing both cooperative and antagonistic interactions. In these systems, agents can join or leave the network over time, and the interaction structure may evolve accordingly. To capture these dynamical structural changes, we represent the network as a switched system interconnected over a dynamic and directed signed graph. Additionally, the network may contain one or multiple leader groups that influence the behavior of the remaining agents. In general, we show that the OMAS exhibit a more general form of synchronization, including trivial consensus, bipartite consensus and containment. Our approach uses the signed edge-based agreement protocol, and constructs strict Lyapunov functions for signed networks described by signed edge-Laplacian matrices containing multiple zero eigenvalues. Numerical simulations validate our theoretical results.

Paper number 20:
Title: Dual-Hop Joint Visible Light and Backscatter Communication Relaying under Finite Blocklength
Authors: Boxuan Xie, Lauri Mela, Alexis A. Dowhuszko, Jiacheng Wang, Kalle Ruttik, Riku Jäntti
Abstract: This paper investigates a dual-hop joint visible light communication (VLC) and backscatter communication (BC) relaying framework under the finite blocklength (FBL) constraint, aiming at energy-neutral Ambient Internet of Things (A-IoT) deployments. In the proposed system, indoor LED access points are used to simultaneously provide illumination and transmit information over light to a backscatter device (BD), which harvests optical energy and backscatters the received messages to user equipments (UEs) equipped with radio frequency (RF) front ends. This forwarding of the information from VLC to RF channels is implemented without the need for carrier synthesizers and power amplifiers at the IoT node. By modeling the end-to-end communication link with short-packet IoT traffic and realistic levels of interference between adjacent VLC coverage areas, we analyze the outage performance and achievable data rate of the proposed system. Simulation results demonstrate that key factors, such as placement and orientation of the BD, as well as the selected code rate of the system affect reliability and data rate that can be achieved for communication purposes. The insights gained from this study pave the way for ambient power-enabled IoT solutions and future hybrid VLC/RF network designs.

Paper number 21:
Title: Pilot-Free Optimal Control over Wireless Networks: A Control-Aided Channel Prediction Approach
Authors: Minjie Tang, Zunqi Li, Photios A. Stavrou, Marios Kountouris
Abstract: A recurring theme in optimal controller design for wireless networked control systems (WNCS) is the reliance on real-time channel state information (CSI). However, acquiring accurate CSI a priori is notoriously challenging due to the time-varying nature of wireless channels. In this work, we propose a pilot-free framework for optimal control over wireless channels in which control commands are generated from plant states together with control-aided channel prediction. For linear plants operating over an orthogonal frequency-division multiplexing (OFDM) architecture, channel prediction is performed via a Kalman filter (KF), and the optimal control policy is derived from the Bellman principle. To alleviate the curse of dimensionality in computing the optimal control policy, we approximate the solution using a coupled algebraic Riccati equation (CARE), which can be computed efficiently via a stochastic approximation (SA) algorithm. Rigorous performance guarantees are established by proving the stability of both the channel predictor and the closed-loop system under the resulting control policy, providing sufficient conditions for the existence and uniqueness of a stabilizing approximate CARE solution, and establishing convergence of the SA-based control algorithm. The framework is further extended to nonlinear plants under general wireless architectures by combining a KalmanNet-based predictor with a Markov-modulated deep deterministic policy gradient (MM-DDPG) controller. Numerical results show that the proposed pilot-free approach outperforms benchmark schemes in both control performance and channel prediction accuracy for linear and nonlinear scenarios.

Paper number 22:
Title: Learning-Based Geometric Leader-Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators
Authors: Omayra Yago Nieto, Leonardo Colombo
Abstract: This paper presents a learning-based tracking control framework for cooperative transport of a rigid payload by multiple aerial manipulators under rigid grasp constraints. A unified geometric model is developed, yielding a coupled agent--payload differential--algebraic system that explicitly captures contact wrenches, payload dynamics, and internal force redundancy. A leader--follower architecture is adopted in which a designated leader generates a desired payload wrench based on geometric tracking errors, while the remaining agents realize this wrench through constraint-consistent force allocation. Unknown disturbances and modeling uncertainties are compensated using Gaussian Process (GP) regression. High-probability bounds on the learning error are explicitly incorporated into the control design, combining GP feedforward compensation with geometric feedback. Lyapunov analysis establishes uniform ultimate boundedness of the payload tracking errors with high probability, with an ultimate bound that scales with the GP predictive uncertainty.

Paper number 23:
Title: Towards Object Segmentation Mask Selection Using Specular Reflections
Authors: Katja Kossira, Yunxuan Zhu, Jürgen Seiler, André Kaup
Abstract: Specular reflections pose a significant challenge for object segmentation, as their sharp intensity transitions often mislead both conventional algorithms and deep learning based methods. However, as the specular reflection must lie on the surface of the object, this fact can be exploited to improve the segmentation masks. By identifying the largest region containing the reflection as the object, we derive a more accurate object mask without requiring specialized training data or model adaption. We evaluate our method on both synthetic and real world images and compare it against established and state-of-the-art techniques including Otsu thresholding, YOLO, and SAM2. Compared to the best performing baseline SAM2, our approach achieves up to 26.7% improvement in IoU, 22.3% in DSC, and 9.7% in pixel accuracy. Qualitative evaluations on real world images further confirm the robustness and generalizability of the proposed approach.

Paper number 24:
Title: Availability of Aerial Heterogeneous Networks for Reliable Emergency Communications
Authors: Teng Wu, Jiandong Li, Junyu Liu, Min Sheng, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou
Abstract: We investigate network availability (NA) in aerial heterogeneous networks (AHetNets) for effective emergency rescue, where diverse delay-constrained communication services must be provided to user equipments (UEs) with varying mobility. The heterogeneity in delay constraints and UE mobility introduces resource allocation conflicts and imbalances, which undermine communication reliability and challenge NA. Although unified resource allocation (URA) can mitigate these issues, it remains unclear whether NA can be sustained under such diverse conditions. To address this, we derive expressions for the lower bound (LB) on NA in AHetNets under URA. Our analysis reveals that extended heterogeneity significantly degrades the LB due to resource limitations-even when the heterogeneity stems from additional services under less stringent delay constraints (LSDC) or from UEs with lower mobility. To overcome this degradation, we formulate and solve a joint optimization problem for the number of UEs sharing time-frequency resources ($K$) and pilot length ($\xi$), aiming to enhance the LB by improving spatial, frequency, and temporal resource efficiency. Simulation results validate our analysis and demonstrate that jointly optimizing $K$ and $\xi$ enables AHetNets to achieve the target NA under greater heterogeneity, outperforming existing resource allocation policies.

Paper number 25:
Title: Cross-Pilot Superposition for Fractional Parameter Estimation in DoA-Aided OTFS Receivers
Authors: Mauro Marchese, Pietro Savazzi
Abstract: In this letter, a novel superimposed pilot scheme is proposed for channel estimation in multi-antenna orthogonal time frequency space (OTFS) receivers. Under the assumption of a large uniform linear array (ULA) size at the receiver, the multipath components are separated directly in the angular domain. It is then shown that the proposed superimposed pilot scheme enables the computation of integrated delay and Doppler profiles by averaging the received delay-Doppler matrix across the Doppler and delay axes, respectively. This procedure helps reduce data-to-pilot interference through data averaging. Moreover, it is demonstrated that fractional delays and Dopplers of the multipath components can be estimated by correlating the integrated delay and Doppler profiles with the corresponding delay/Doppler terms. Simulation results show that the proposed approach outperforms existing OTFS superimposed pilot schemes, achieving a lower bit error rate (BER) while exhibiting a trade-off between peak-to-average power ratio (PAPR) and communication performance.

Paper number 26:
Title: LightSim: A Lightweight Cell Transmission Model Simulator for Traffic Signal Control Research
Authors: Haoran Su, Hanxiao Deng
Abstract: Reinforcement learning for traffic signal control is bottlenecked by simulators: training in SUMO takes hours, reproducing results often requires days of platform-specific setup, and the slow iteration cycle discourages the multi-seed experiments that rigorous evaluation demands. Much of this cost is unnecessary, since for signal timing optimization the relevant dynamics are queue formation and discharge, which the Cell Transmission Model (CTM) captures as a macroscopic flow model. We introduce LightSim, a pure Python, pip-installable traffic simulator with Gymnasium and PettingZoo interfaces that runs over 20000 steps per second on a single CPU. Across cross-simulator experiments spanning single intersections, grid networks, arterial corridors, and six real-world city networks, LightSim preserves controller rankings from SUMO for both classical and reinforcement learning strategies while training 3 to 7 times faster. LightSim is released as an open-source benchmark with nineteen built-in scenarios, seven controllers, and full reinforcement learning pipelines, lowering the barrier to signal control research from days to minutes.

Paper number 27:
Title: Leaky Coaxial Cable based Generalized Pinching-Antenna Systems with Dual-Port Feeding
Authors: Kaidi Wang, Zhiguo Ding, Daniel K. C. So
Abstract: By leveraging the distributed leakage radiation of leaky coaxial cables (LCXs), the concept of pinching antennas can be generalized from the conventional high-frequency waveguide based architectures to cable based structures in lower-frequency scenarios. This paper investigates an LCX based generalized pinching-antenna system with dual-port feeding. By enabling bidirectional excitation along each cable, the proposed design significantly enhances spatial degrees of freedom. A comprehensive channel model is developed to characterize intra-cable attenuation, bidirectional phase progression, slot based radiation, and wireless propagation. Based on this model, both analog and hybrid beamforming frameworks are studied with the objective of maximizing the minimum achievable data rate. For analog transmission, slot activation, port selection, and power allocation are jointly optimized using matching theory, coalitional games, and bisection based power control. For hybrid transmission, zero-forcing (ZF) digital precoding is incorporated to eliminate inter-user interference, thereby simplifying slot activation and enabling closed-form optimal power allocation. Simulation results demonstrate that dual-port feeding provides notable performance gains over single-port LCX systems and fixed-antenna benchmarks, validating the effectiveness of the proposed beamforming and resource allocation designs under various transmit power levels and cable parameters.

Paper number 28:
Title: On the airspace complexity metrics for predecessor-follower operations
Authors: Lucas Souza e Silva, Luis Rodrigues
Abstract: This technical note proposes a novel airspace complexity metric that quantifies the air traffic controller workload and coordination effort for pairwise predecessor-follower aircraft operations in cruise. The pairwise dynamic workload (PDW) is proposed as a continuous function that depends on the relevant parameters of these operations, such as the aircraft separation and separation rate. A comparison of this metric with the dynamic density (DD) shows that it is capable of continuously evaluating the variation of airspace complexity over time and monitoring the aircraft parameters that might lead to conflicts. This metric can be used to support the implementation of autonomous and supervised aircraft procedures, to achieve a more structured and coordinated airspace.

Paper number 29:
Title: Modeling of Human Body-coupled Electric Field Interference in Unshielded Ultra-Low Field MRI
Authors: Jiali He, Yamei Dai, Sheng Shen, Jiamin Wu, Zheng Xu
Abstract: Portable ultra-low field MRI (ULF-MRI) systems operated in unshielded environments are susceptible to electromagnetic interference (EMI). Subject presence in the imaging region will lead to substantial noise increases, yet the dominant coupling mechanism remains insufficiently characterized. We develop a lumped-parameter circuit model of the coupled environment-body-receiver system. The model indicates that ambient time-varying electric fields induce a body common-mode potential, which is converted into differential-mode noise through capacitive imbalance between the head and the receive-coil terminals, yielding strong dependence on subject position and geometry. Circuit analysis, simulations, and controlled experiments support the model, with predicted imbalance consistent with measured noise variations. Guided by this mechanism, we implement a capacitive low-impedance bypass to clamp the body potential, achieving an approximately 3.5-fold SNR improvement on a 50 mT prototype. The proposed model offers a compact circuit-based tool for analyzing and mitigating human body-coupled electric-field interference in portable ULF-MRI.

Paper number 30:
Title: Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs
Authors: Jie Han, Arash Khalatbarisoltani, Hai L. Vu, Xiaosong Hu, Jun Yang
Abstract: The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\% and 5.84\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information.

Paper number 31:
Title: A sliding-window approach for latent restoring force modeling
Authors: Merijn Floren, Jan Swevers
Abstract: Restoring force surface (RFS) methods offer an attractive nonparametric framework for identifying nonlinear restoring forces directly from data, but their reliance on complete kinematic measurements at each degree of freedom limits scalability to multidimensional systems. The aim of this paper is to overcome these measurement limitations by proposing an identification framework with relaxed sensing requirements that exploits periodic multisine excitation. Starting from an initial linear model, a sliding-window feedback approach reconstructs latent states and nonlinear restoring forces nonparametrically, enabling identification of the nonlinear component through linear-in-parameters regression instead of highly non-convex optimization. Validation on synthetic and experimental datasets demonstrates high simulation accuracy and reliable recovery of physical parameters under partial sensing and noisy conditions.

Paper number 32:
Title: Analyzing URA Geometry for Enhanced Near-Field Beamfocusing and Spatial Degrees of Freedom
Authors: Ahmed Hussain, Asmaa Abdallah, Abdulkadir Celik, Emil Björnson, Ahmed M. Eltawil
Abstract: With the deployment of large antenna arrays at high-frequency bands, future wireless communication systems are likely to operate in the radiative near-field. Unlike far-field beam steering, near-field beams can be focused on a spatial region with a finite depth, enabling spatial multiplexing in the range dimension. Moreover, in the line-of-sight MIMO near-field, multiple spatial degrees of freedom (DoF) are accessible, akin to a scattering- rich environment. In this paper, we derive the beamdepth for a generalized uniform rectangular array (URA) and investigate how the array geometry influences near-field beamdepth and its limits. We define the effective beamfocusing Rayleigh distance (EBRD), to present a near-field boundary with respect to beamfocusing and spatial multiplexing gains for the generalized URA. Our results demonstrate that under a fixed element count constraint, the array geometry has a strong impact on beamdepth, whereas this effect diminishes under a fixed aperture length constraint. Moreover, compared to uniform square arrays, elongated configurations such as uniform linear arrays (ULAs) yield narrower beamdepth and extend the effective near-field region defined by the EBRD. Building on these insights, we design a polar codebook for compressed-sensing-based channel estimation that leverages our findings. Simulation results show that the proposed polar codebook achieves a 2 dB NMSE improvement over state-of-the-art methods. Additionally, we present an analytical expression to quantify the effective spatial DoF in the near-field, revealing that they are also constrained by the EBRD. Notably, the maximum spatial DoF is achieved with a ULA configuration, outperforming a square URA in this regard.

Paper number 33:
Title: Aggressiveness-Aware Learning-based Control of Quadrotor UAVs with Safety Guarantees
Authors: Leonardo Colombo, Thomas Beckers, Juan Giribet
Abstract: This paper presents an aggressiveness-aware control framework for quadrotor UAVs that integrates learning-based oracles to mitigate the effects of unknown disturbances. Starting from a nominal tracking controller on $\mathrm{SE}(3)$, unmodeled generalized forces and moments are estimated using a learning-based oracle and compensated in the control inputs. An aggressiveness-aware gain scheduling mechanism adapts the feedback gains based on probabilistic model-error bounds, enabling reduced feedback-induced aggressiveness while guaranteeing a prescribed practical exponential tracking performance. The proposed approach makes explicit the trade-off between model accuracy, robustness, and control aggressiveness, and provides a principled way to exploit learning for safer and less aggressive quadrotor maneuvers.

Paper number 34:
Title: Spatial Degrees of Freedom in Near Field MIMO: Experimental Validation of Beamspace Perspective
Authors: Ahmed Hussain, Asmaa Abdallah, Ahmed Nasser, Abdulkadir Celik, Ahmed M. Eltawil
Abstract: Conventional far-field multiple-input multiple-output (MIMO) channels are limited to a single spatial degree of freedom (DoF) under a line-of-sight (LoS) condition. In contrast, the radiative near field (NF) supports multiple spatial DoF, enabled by spherical wavefronts and the reduced spatial footprint at short ranges. While recent research indicates that the effective DoF (EDoF) increases in NF, experimental validation and clear identification of the transition distances remain limited. In this letter, we develop an intuitive framework for characterizing the EDoF of a ULA-based MIMO system and derive two complementary analytical expressions: a closed-form formulation that relates the EDoF to the physical transmit beamwidth and receive aperture, and a discrete formulation based on the discrete Fourier transform (DFT) domain angular decomposition of the NF spherical wavefront, which is well suited for experimental evaluation. We further introduce the effective MIMO Rayleigh distance (EMRD) and the maximum spatial multiplexing distance (MSMD), which mark the distances where the EDoF reduces to one and attains its maximum, respectively. Experimental measurements using widely spaced phased arrays closely match the theoretical EDoF trends and validate the proposed distance metrics.

Paper number 35:
Title: Sparse Array Design for Near-Field MU-MIMO: Reconfigurable Array Thinning Approach
Authors: Ahmed Hussain, Asmaa Abdallah, Abdulkadir Celik, Emil Björnson, Ahmed M. Eltawil
Abstract: Future wireless networks, deploying thousands of antenna elements, may operate in the radiative near-field (NF), enabling spatial multiplexing across both angle and range domains. Sparse arrays have the potential to achieve comparable performance with fewer antenna elements. However, fixed sparse array designs are generally suboptimal under dynamic user distributions, while movable antenna architectures rely on mechanically reconfigurable elements, introducing latency and increased hardware complexity. To address these limitations, we propose a reconfigurable array thinning approach that selectively activates a subset of antennas to form a flexible sparse array design without physical repositioning. We first analyze grating lobes for uniform sparse arrays in the angle and range domains, showing their absence along the range dimension. Based on the analysis, we develop two particle swarm optimization-based strategies: a grating-lobe-based thinned array (GTA) for grating- lobe suppression and a sum-rate-based thinned array (STA) for multiuser sum-rate maximization. Simulation results demonstrate that GTA outperforms conventional uniform sparse arrays, while STA achieves performance comparable to movable antennas, thereby offering a practical and efficient array deployment strategy without the associated mechanical complexity.

Paper number 36:
Title: TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition
Authors: Cheng-Yeh Yang, Chien-Chun Wang, Li-Wei Chen, Hung-Shin Lee, Hsin-Min Wang, Berlin Chen
Abstract: Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recognition, a translation-guided ASR framework that utilizes multilingual translation embeddings to enhance recognition performance in low-resource environments. The framework is centered around the parallel gated cross-attention (PGCA) mechanism, which adaptively integrates embeddings from various auxiliary languages into the ASR decoder. This mechanism facilitates robust cross-linguistic semantic guidance while ensuring stable optimization and minimizing interference between languages. To support ongoing research initiatives, we present YT-THDC, a 30-hour corpus of Taiwanese Hokkien drama speech with aligned Mandarin subtitles and manually verified Taiwanese Hokkien transcriptions. Comprehensive experiments and analyses identify the auxiliary languages that most effectively enhance ASR performance, achieving a 14.77% relative reduction in character error rate and demonstrating the efficacy of translation-guided learning for underrepresented languages in practical applications.

Paper number 37:
Title: Transmission Delay Minimization for NOMA-Based F-RANs
Authors: Yuan Ai, Xidong Mu, Pengbo Si, Yuanwei Liu
Abstract: A novel non-orthogonal multiple access (NOMA) based low-delay service framework is proposed for fog radio access networks (F-RANs). Fog access points (FAPs) leverage NOMA for local delivery of cached content, while the cloud access point employs NOMA to simultaneously push content to FAPs and directly serve users. Based on this model, a delay minimization problem is formulated by jointly optimizing user association, cache placement, and power allocation. To address this non-convex mixed-integer nonlinear programming problem, an alternating optimization (AO) algorithm is developed, which decomposes the original problem into two subproblems, namely joint user association and cache placement, and power allocation. In particular, a low-complexity algorithm is designed to optimizing the user association and cache placement strategy using the McCormick envelope theory and Lagrangian partial relaxation. The power allocation is optimized by invoking the successive convex approximation. Simulation results reveal that: 1) the proposed AO-based algorithm effectively balances between the achieved performance and computational efficiency, and 2) the proposed NOMA-based F-RANs framework significantly outperforms orthogonal multiple access-based F-RANs systems in terms of average transmission delay in different scenarios.

Paper number 38:
Title: Tempered Christoffel-Weighted Polynomial Chaos Expansion for Resilience-Oriented Uncertainty Quantification
Authors: Mahsa Ebadat-Parast, Xiaozhe Wang
Abstract: Accurate and efficient uncertainty quantification is essential for resilience assessment of modern power systems under high impact and low probability disturbances. Data driven sparse polynomial chaos expansion (DDSPCE) provides a computationally efficient surrogate framework but may suffer from ill conditioned regression and loss of accuracy in the distribution tails that determine system risk. This paper studies the impact of regression weighting schemes on the stability and tail accuracy of DD-SPCE surrogates by introducing a tempered Christoffel weighted least squares (T-CWLS) formulation that balances numerical stability and tail fidelity. The tempering exponent is treated as a hyperparameter whose influence is examined with respect to distributional accuracy compared with Monte Carlo simulations. Case studies on distribution system load shedding show that the proposed method reduces 95th percentile deviation by 16%, 5th percentile deviation by 6%, and improves the regression stability index by over 130%. The results demonstrate that controlling the weighting intensity directly influences both stability index and the accuracy of tail prediction.

Paper number 39:
Title: Lumosaic: Hyperspectral Video via Active Illumination and Coded-Exposure Pixels
Authors: Dhruv Verma, Andrew Qiu, Roberto Rangel, Ayandev Barman, Hao Yang, Chenjia Hu, Fengqi Zhang, Roman Genov, David B. Lindell, Kiriakos N. Kutulakos, Alex Mariakakis
Abstract: We present Lumosaic, a compact active hyperspectral video system designed for real-time capture of dynamic scenes. Our approach combines a narrowband LED array with a coded-exposure-pixel (CEP) camera capable of high-speed, per-pixel exposure control, enabling joint encoding of scene information across space, time, and wavelength within each video frame. Unlike passive snapshot systems that divide light across multiple spectral channels simultaneously and assume no motion during a frame's exposure, Lumosaic actively synchronizes illumination and pixel-wise exposure, improving photon utilization and preserving spectral fidelity under motion. A learning-based reconstruction pipeline then recovers 31-channel hyperspectral (400-700 nm) video at 30 fps and VGA resolution, producing temporally coherent and spectrally accurate reconstructions. Experiments on synthetic and real data demonstrate that Lumosaic significantly improves reconstruction fidelity and temporal stability over existing snapshot hyperspectral imaging systems, enabling robust hyperspectral video across diverse materials and motion conditions.

Paper number 40:
Title: Heterogeneous Memory Design Exploration for AI Accelerators with a Gain Cell Memory Compiler
Authors: Xinxin Wang, Lixian Yan, Shuhan Liu, Luke Upton, Zhuoqi Cai, Yiming Tan, Shengman Li, Koustav Jana, Peijing Li, Jesse Cirimelli-Low, Thierry Tambe, Matthew Guthaus, H.-S. Philip Wong
Abstract: As memory increasingly dominates system cost and energy, heterogeneous on-chip memory systems that combine technologies with complementary characteristics are becoming essential. Gain Cell RAM (GCRAM) offers higher density, lower power, and tunable retention, expanding the design space beyond conventional SRAM. To this end, we create an OpenGCRAM compiler supporting both SRAM and GCRAM. It generates macro-level designs and layouts for commercial CMOS processes and characterizes area, delay, and power across user-defined configurations. The tool enables systematic identification of optimal heterogeneous memory configurations for AI tasks under specified performance metrics.

Paper number 41:
Title: Towards Controllable Video Synthesis of Routine and Rare OR Events
Authors: Dominik Schneider, Lalithkumar Seenivasan, Sampath Rapuri, Vishalroshan Anil, Aiza Maksutova, Yiqing Shen, Jan Emily Mangulabnan, Hao Ding, Jose L. Porras, Masaru Ishii, Mathias Unberath
Abstract: Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR. Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations. Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices. Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.

Paper number 42:
Title: An index of effective number of variables for uncertainty and reliability analysis in model selection problems
Authors: Luca Martino, Eduardo Morgado, Roberto San Millán-Castillo
Abstract: An index of an effective number of variables (ENV) is introduced for model selection in nested models. This is the case, for instance, when we have to decide the order of a polynomial function or the number of bases in a nonlinear regression, choose the number of clusters in a clustering problem, or the number of features in a variable selection application (to name few examples). It is inspired by the idea of the maximum area under the curve (AUC). The interpretation of the ENV index is identical to the effective sample size (ESS) indices concerning a set of samples. The ENV index improves {drawbacks of} the elbow detectors described in the literature and introduces different confidence measures of the proposed solution. These novel measures can be also employed jointly with the use of different information criteria, such as the well-known AIC and BIC, or any other model selection procedures. Comparisons with classical and recent schemes are provided in different experiments involving real datasets. Related Matlab code is given.

Paper number 43:
Title: Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting
Authors: Sunki Hong, Jisoo Lee, Yuanyuan Shi
Abstract: Selecting the right deep learning model for power grid forecasting is challenging, as performance heavily depends on the data available to the operator. This paper presents a comprehensive benchmark of five modern neural architectures: two state space models (PowerMamba, S-Mamba), two Transformers (iTransformer, PatchTST), and a traditional LSTM. We evaluate these models on hourly electricity demand across six diverse US power grids for forecast windows between 24 and 168 hours. To ensure a fair comparison, we adapt each model with specialized temporal processing and a modular layer that cleanly integrates weather covariates. Our results reveal that there is no single best model for all situations. When forecasting using only historical load, PatchTST and the state space models provide the highest accuracy. However, when explicit weather data is added to the inputs, the rankings reverse: iTransformer improves its accuracy three times more efficiently than PatchTST. By controlling for model size, we confirm that this advantage stems from the architecture's inherent ability to mix information across different variables. Extending our evaluation to solar generation, wind power, and wholesale prices further demonstrates that model rankings depend on the forecast task: PatchTST excels on highly rhythmic signals like solar, while state space models are better suited for the chaotic fluctuations of wind and price. Ultimately, this benchmark provides grid operators with actionable guidelines for selecting the optimal forecasting architecture based on their specific data environments.

Paper number 44:
Title: Provably Safe Generative Sampling with Constricting Barrier Functions
Authors: Darshan Gadginmath, Ahmed Allibhoy, Fabio Pasqualetti
Abstract: Flow-based generative models, such as diffusion models and flow matching models, have achieved remarkable success in learning complex data distributions. However, a critical gap remains for their deployment in safety-critical domains: the lack of formal guarantees that generated samples will satisfy hard constraints. We address this by proposing a safety filtering framework that acts as an online shield for any pre-trained generative model. Our key insight is to cooperate with the generative process rather than override it. We define a constricting safety tube that is relaxed at the initial noise distribution and progressively tightens to the target safe set at the final data distribution, mirroring the coarse-to-fine structure of the generative process itself. By characterizing this tube via Control Barrier Functions (CBFs), we synthesize a feedback control input through a convex Quadratic Program (QP) at each sampling step. As the tube is loosest when noise is high and intervention is cheapest in terms of control energy, most constraint enforcement occurs when it least disrupts the model's learned structure. We prove that this mechanism guarantees safe sampling while minimizing the distributional shift from the original model at each sampling step, as quantified by the KL divergence. Our framework applies to any pre-trained flow-based generative scheme requiring no retraining or architectural modifications. We validate the approach across constrained image generation, physically-consistent trajectory sampling, and safe robotic manipulation policies, achieving 100% constraint satisfaction while preserving semantic fidelity.

Paper number 45:
Title: Constructive Vector Fields for Path Following in Fully-Actuated Systems on Matrix Lie Groups
Authors: Felipe Bartelt, Vinicius M. Gonçalves, Luciano C. A. Pimenta
Abstract: This paper presents a novel vector field strategy for controlling fully-actuated systems on connected matrix Lie groups, ensuring convergence to and traversal along a curve defined on the group. Our approach generalizes our previous work (Rezende et al., 2022) and reduces to it when considering the Lie group of translations in Euclidean space. Since the proofs in Rezende et al. (2022) rely on key properties such as the orthogonality between the convergent and traversal components, we extend these results by leveraging Lie group properties. These properties also allow the control input to be non-redundant, meaning it matches the dimension of the Lie group, rather than the potentially larger dimension of the space in which the group is embedded. This can lead to more practical control inputs in certain scenarios. A particularly notable application of our strategy is in controlling systems on SE(3) -- in this case, the non-redundant input corresponds to the object's mechanical twist -- making it well-suited for controlling objects that can move and rotate freely, such as omnidirectional drones. In this case, we provide an efficient algorithm to compute the vector field. We experimentally validate the proposed method using a robotic manipulator to demonstrate its effectiveness.

Paper number 46:
Title: LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies
Authors: Yue Yang, Shuo Cheng, Yu Fang, Homanga Bharadhwaj, Mingyu Ding, Gedas Bertasius, Daniel Szafir
Abstract: General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: this https URL.

Paper number 47:
Title: From Specialist to Large Models: A Paradigm Evolution Towards Semantic-Aware MIMO
Authors: Keke Ying, Zhen Gao, Tingting Yang, Jianhua Zhang, Xiang Cheng, Tony Q.S. Quek, H. Vincent Poor
Abstract: The sixth generation (6G) network is expected to deploy larger multiple-input multiple-output (MIMO) arrays to support massive connectivity, which will increase overhead and latency at the physical layer. Meanwhile, emerging 6G demands such as immersive communications and environmental sensing pose challenges to traditional signal processing. To address these issues, we propose the ``semantic-aware MIMO'' paradigm, which leverages specialist models and large models to perceive, utilize, and fuse the inherent semantics of channels and sources for improved performance. Moreover, for representative MIMO physical-layer tasks, e.g., random access activity detection, channel feedback, and precoding, we design specialist models that exploit channel and source semantics for better performance. Additionally, in view of the more diversified functions of 6G MIMO, we further explore large models as a scalable solution for multi-task semantic-aware MIMO and review recent advances along with their advantages and limitations. Finally, we discuss the challenges, insights, and prospects of the evolution of specialist models and large models empowered semantic-aware MIMO paradigms.

Paper number 48:
Title: EmoOmni: Bridging Emotional Understanding and Expression in Omni-Modal LLMs
Authors: Wenjie Tian, Zhixian Zhao, Jingbin Hu, Huakang Chen, Haohe Liu, Binshen Mu, Lei Xie
Abstract: The evolution of Omni-Modal Large Language Models~(Omni-LLMs) has revolutionized human--computer interaction, enabling unified audio-visual perception and speech response. However, existing Omni-LLMs struggle with complex real-world scenarios, often leading to superficial understanding and contextually mismatched emotional responses. This issue is further intensified by Omni-LLM's Thinker-Talker architectures, which are implicitly connected through hidden states, leading to the loss of emotional details. In this work, we present EmoOmni, a unified framework for accurate understanding and expression in multimodal emotional dialogue. At its core, we introduce the emotional Chain-of-Thought~(E-CoT), which enforces a reasoning from fine-grained multimodal perception to textual response. Moreover, we explicitly treat E-CoT as high-level emotional instructions that guide the talker, enabling accurate emotional expression. Complementing the model, we construct EmoOmniPipe to obtain the real-world annotated dialogue data and establish a benchmark, EmoOmniEval, to facilitate systematic assessment of multimodal emotional dialogue task. Experiments show that EmoOmni-7B achieves comparable performance with Qwen3Omni-30B-A3B-Thinking under the same talker.

Paper number 49:
Title: MIDI-Informed Singing Accompaniment Generation in a Compositional Song Pipeline
Authors: Fang-Duo Tsai, Yi-An Lai, Fei-Yueh Chen, Hsueh-Wei Fu, Li Chai, Wei-Jaw Lee, Hao-Chung Cheng, Yi-Hsuan Yang
Abstract: Song generation aims to produce full songs with vocals and accompaniment from lyrics and text descriptions, yet end-to-end models remain data- and compute-intensive and provide limited editability. We advocate a compositional alternative that decomposes the task into melody composition, singing voice synthesis, and singing accompaniment generation. Central to our approach is MIDI-informed singing accompaniment generation (MIDI-SAG), which conditions accompaniment on the symbolic vocal-melody MIDI to improve rhythmic and harmonic alignment between singing and instrumentation. Moreover, beyond conventional SAG settings that assume continuously sung vocals, compositional song generation features intermittent vocals; we address this by combining explicit rhythmic/harmonic controls with audio continuation to keep the backing track consistent across vocal and non-vocal regions. With lightweight newly trained components requiring only 2.5k hours of audio on a single RTX 3090, our pipeline approaches the perceptual quality of recent open-source end-to-end baselines in several metrics. We provide audio demos and will open-source our model at this https URL.

Paper number 50:
Title: Secure Semantic Communications via AI Defenses: Fundamentals, Solutions, and Future Directions
Authors: Lan Zhang, Chengsi Liang, Zeming Zhuang, Yao Sun, Fang Fang, Xiaoyong Yuan, Dusit Niyato
Abstract: Semantic communication (SemCom) redefines wireless communication from reproducing symbols to transmitting task-relevant semantics. However, this AI-native architecture also introduces new vulnerabilities, as semantic failures may arise from adversarial perturbations to models, corrupted training data, desynchronized priors, or misaligned inference even when lower-layer transmission reliability and cryptographic protection remain intact. This survey provides a defense-centered and system-oriented synthesis of security in SemCom via AI defense. We analyze AI-centric threat models by consolidating existing studies and organizing attack surfaces across model-level, channel-realizable, knowledge-based, and networked inference vectors. Building on this foundation, we present a structured taxonomy of defense strategies organized by where semantic integrity can be compromised in SemCom systems despite correct symbol delivery, spanning semantic encoding, wireless transmission, knowledge integrity, and coordination among multiple agents. These categories correspond to distinct security failure modes, including representation fragility, channel-realizable manipulation, semantic prior poisoning or desynchronization, and adversarial propagation through distributed inference. We also examine security utility operating envelopes that capture tradeoffs among semantic fidelity, robustness, latency, and energy under realistic constraints, survey evaluation frameworks and representative applications, and identify open challenges in cross-layer composition and deployment-time certification. Overall, this survey offers a unified system-level perspective that enables readers to understand major threat and defense mechanisms in AI-native SemCom systems and to leverage emerging security techniques in the design and deployment of robust SemCom architectures for next-generation intelligent networks.

Paper number 51:
Title: MPC of Uncertain Nonlinear Systems with Meta-Learning for Fast Adaptation of Neural Predictive Models
Authors: Jiaqi Yan, Ankush Chakrabarty, Alisa Rupenyan, John Lygeros
Abstract: In this paper, we consider the problem of reference tracking in uncertain nonlinear systems. A neural State-Space Model (NSSM) is used to approximate the nonlinear system, where a deep encoder network learns the nonlinearity from data, and a state-space component captures the temporal relationship. This transforms the nonlinear system into a linear system in a latent space, enabling the application of model predictive control (MPC) to determine effective control actions. Our objective is to design the optimal controller using limited data from the \textit{target system} (the system of interest). To this end, we employ an implicit model-agnostic meta-learning (iMAML) framework that leverages information from \textit{source systems} (systems that share similarities with the target system) to expedite training in the target system and enhance its control performance. The framework consists of two phases: the (offine) meta-training phase learns a aggregated NSSM using data from source systems, and the (online) meta-inference phase quickly adapts this aggregated model to the target system using only a few data points and few online training iterations, based on local loss function gradients. The iMAML algorithm exploits the implicit function theorem to exactly compute the gradient during training, without relying on the entire optimization path. By focusing solely on the optimal solution, rather than the path, we can meta-train with less storage complexity and fewer approximations than other contemporary meta-learning algorithms. We demonstrate through numerical examples that our proposed method can yield accurate predictive models by adaptation, resulting in a downstream MPC that outperforms several baselines.

Paper number 52:
Title: A time-to-digital converter with steady calibration through single-photon detection
Authors: Matías Rubén Bolaños, Daniele Vogrig, Paolo Villoresi, Giuseppe Vallone, Andrea Stanco
Abstract: Time-to-Digital Converters (TDCs) are a crucial tool in a wide array of fields, in particular for quantum communication, where time taggers performance can severely affect the quality of the entire application. Nowadays, FPGA-based TDCs present a viable alternative to ASIC ones, once the non-linear behavior due to the intrinsic nature of the device is properly mitigated. To compensate for said nonlinearities, a calibration procedure is required, which should be maintained throughout its runtime. Here we present the design and the demonstration of a TDC that is FPGA-based showing a residual FWHM jitter of 27 ps, that is scalable for multichannel operation. The target application in Quantum Key Distribution (QKD) is discussed with a calibration method based on the exploitation of single-photon detection that does not require stopping the data acquisition or using any estimation methods, thus increasing accuracy and removing data loss. The calibration was tested in a relevant environment, investigating the behavior of the device between 5 °C and 80 °C. Moreover, our design is capable of continuously streaming up to 12 Mevents/s for up to ~1 week without the TDC overflowing making it ready for a real-life scenario deployment.

Paper number 53:
Title: On the Impact of Sample Size in Reconstructing Noisy Graph Signals: A Theoretical Characterisation
Authors: Baskaran Sripathmanathan, Xiaowen Dong, Michael Bronstein
Abstract: Reconstructing a signal on a graph from noisy observations of a subset of the vertices is a fundamental problem in the field of graph signal processing. This paper investigates how sample size affects reconstruction error in the presence of noise via an in-depth theoretical analysis of the two most common reconstruction methods in the literature, least-squares reconstruction (LS) and graph-Laplacian regularised reconstruction (GLR). Our theorems show that at sufficiently low signal-to-noise ratios (SNRs), under these reconstruction methods we may simultaneously decrease sample size and decrease average reconstruction error. We further show that at sufficiently low SNRs, for LS reconstruction we have a $\Lambda$-shaped error curve and for GLR reconstruction, a sample size of $ O(\sqrt{N})$, where $N$ is the total number of vertices, results in lower reconstruction error than near full observation. We present thresholds on the SNRs, $\tau$ and $\tau_{GLR}$, below which the error is non-monotonic, and illustrate these theoretical results with experiments across multiple random graph models, sampling schemes and SNRs. These results demonstrate that any decision in sample-size choice has to be made in light of the noise levels in the data.

Paper number 54:
Title: Adaptive RIS Control for Mobile mmWave NLoS Communication Using Single-Bit Feedback
Authors: Hamed Radpour, Markus Hofer, Thomas Zemen
Abstract: Reconfigurable intelligent surfaces (RISs) are emerging as key enablers of reliable industrial automation in the millimeter-wave (mmWave) band, particularly in environments with frequent line-of-sight (LoS) blockage. While prior works have largely focused on theoretical aspects, real-time validation under user mobility remains underexplored. In this work, we propose and experimentally evaluate an adaptive beamforming algorithm that enables RIS reconfiguration via a low-rate feedback link from the mobile user equipment (UE) to the RIS controller, operating without requiring UE position knowledge. The algorithm maintains the received signal power above a predefined threshold using only a single-bit comparison of received power levels. To analyze the algorithms performance, we establish a simulation-based Monte Carlo (MC) optimization benchmark that assumes full UE position knowledge, accounts for practical hardware constraints, and serves as an upper bound for performance evaluation. Using a hexagonal RIS with 127 elements and 1-bit phase quantization at 23.8 GHz, we validate the proposed approach in a semi-anechoic environment over a 60 cm by 92 cm area. The results demonstrate that the single-bit feedback-driven algorithm closes much of the performance gap to the MC upper bound while achieving up to 24 dB gain in received power compared to an inactive RIS baseline. These findings highlight the practical potential of feedback-based adaptive RIS control for robust mmWave non-line-of-sight (NLoS) communication with mobile users.

Paper number 55:
Title: MLICv2: Enhanced Multi-Reference Entropy Modeling for Learned Image Compression
Authors: Wei Jiang, Yongqi Zhai, Jiayu Yang, Feng Gao, Ronggang Wang
Abstract: Recent advances in learned image compression (LIC) have achieved remarkable performance improvements over traditional codecs. Notably, the MLIC series-LICs equipped with multi-reference entropy models-have substantially surpassed conventional image codecs such as Versatile Video Coding (VVC) Intra. However, existing MLIC variants suffer from several limitations: performance degradation at high bitrates due to insufficient transform capacity, suboptimal entropy modeling that fails to capture global correlations in initial slices, and lack of adaptive channel importance modeling. In this paper, we propose MLICv2 and MLICv2+, enhanced successors that systematically address these limitations through improved transform design, dvanced entropy modeling, and exploration of the potential of instance-specific optimization. For transform enhancement, we introduce a lightweight token mixing block inspired by the MetaFormer architecture, which effectively mitigates high-bitrate performance degradation while maintaining computational efficiency. For entropy modeling improvements, we propose hyperprior-guided global correlation prediction to extract global context even in the initial slice of latent representation, complemented by a channel reweighting module that dynamically emphasizes informative channels. We further explore enhanced positional embedding and guided selective compression strategies for superior context modeling. Additionally, we apply the Stochastic Gumbel Annealing (SGA) to demonstrate the potential for further performance improvements through input-specific optimization. Extensive experiments demonstrate that MLICv2 and MLICv2+ achieve state-of-the-art results, reducing Bjøntegaard-Delta Rate by 16.54%, 21.61%, 16.05% and 20.46%, 24.35%, 19.14% on Kodak, Tecnick, and CLIC Pro Val datasets, respectively, compared to VTM-17.0 Intra.

Paper number 56:
Title: Discrete Optimal Transport and Voice Conversion
Authors: Anton Selitskiy, Maitreya Kocharekar
Abstract: We propose kDOT, a discrete optimal transport (OT) framework for voice conversion (VC) operating in a pretrained speech embedding space. In contrast to the averaging strategies used in kNN-VC and SinkVC, and the independence assumption adopted in MKL, our method employs the barycentric projection of the discrete OT plan to construct a transport map between source and target speaker embedding distributions. We conduct a comprehensive ablation study over the number of transported embeddings and systematically analyze the impact of source and target utterance duration. Experiments on LibriSpeech demonstrate that OT with barycentric projection consistently improves distribution alignment and often outperforms averaging-based approaches in terms of WER, MOS, and FAD. Furthermore, we show that applying discrete OT as a post-processing step can transform spoofed speech into samples that are misclassified as bona fide by a state-of-the-art spoofing detector. This demonstrates the strong domain adaptation capability of OT in embedding space, while also revealing important security implications for spoof detection systems.

Paper number 57:
Title: Transformer-based cardiac substructure segmentation from contrast and non-contrast computed tomography for radiotherapy planning
Authors: Aneesh Rangnekar, Nikhil Mankuzhy, Jonas Willmann, Chloe Min Seo Choi, Abraham Wu, Maria Thor, Andreas Rimner, Harini Veeraraghavan
Abstract: Accurate segmentation of cardiac substructures on computed tomography (CT) scans is essential for radiotherapy planning but typically requires large annotated datasets and often generalizes poorly across imaging protocols and patient variations. This study evaluated whether pretrained transformers enable data-efficient training using a fixed architecture with balanced curriculum learning. A hybrid pretrained transformer-convolutional network (SMIT) was fine-tuned on lung cancer patients (Cohort I, N $=$ 180) imaged in the supine position and validated on 60 held-out Cohort I patients and 65 breast cancer patients (Cohort II) imaged in both supine and prone positions. Two configurations were evaluated: SMIT-Balanced (32 contrast-enhanced CTs and 32 non-contrast CTs) and SMIT-Oracle (180 CTs). Performance was compared with nnU-Net and TotalSegmentator. Segmentation accuracy was assessed primarily using the 95th percentile Hausdorff distance (HD95), with radiation dose and overlap-based metrics evaluated as secondary endpoints. SMIT-Balanced achieved accuracy comparable to SMIT-Oracle despite using 64$\%$ fewer training scans. On Cohort I, HD95 was 6.6 $\pm$ 4.3 mm versus 5.4 $\pm$ 2.6 mm, and on Cohort II, 10.0 $\pm$ 9.4 mm versus 9.4 $\pm$ 9.8 mm, respectively, demonstrating robustness to patient, imaging, and data variations. Radiation dose metrics derived from SMIT segmentations were equivalent to those from manual delineations. Although nnU-Net improved over the publicly trained TotalSegmentator, it showed reduced cross-domain robustness compared to SMIT. Balanced curriculum training reduced labeled data requirements without compromising accuracy relative to the oracle model and maintained robustness across patient and imaging variations. Pretraining reduced dependence on data domain and obviated the need for data-specific architectural reconfiguration required by nnU-Net.

Paper number 58:
Title: Development of a Scaled Setup for Experimental Study of the Effect of Lateral Dynamics on Energy Consumption in Electric Vehicles: An Extension
Authors: Simran Kumari, Anand Ronald K., Siddhartha Mukhopadhyay, Ashish R. Hota
Abstract: Most of the existing state-of-the-art approaches for energy consumption analysis do not account for the effect of lateral dynamics on energy consumption in electric vehicles (EVs) during vehicle maneuvers. This paper aims to validate this effect through an experimental study. We develop a scaled model using a radio-controlled (RC) car, modified to achieve dynamic similitude with on-road vehicles, to conduct scaled experiments. The experimental results confirm the impact of lateral dynamics on both energy demand and driving range in electric vehicles, aligning with our previous findings [1], and emphasize the need to incorporate these factors into energy consumption models. This is an extended version of a paper accepted at IEEE ITEC 2025. It includes additional results and analysis.

Paper number 59:
Title: Improving Convergence for Semi-Federated Learning: An Energy-Efficient Approach by Manipulating Over-the-Air Distortion
Authors: Jingheng Zheng, Hui Tian, Wanli Ni, Yang Tian, Ping Zhang
Abstract: In this paper, we propose a hybrid learning framework that combines federated and split learning, termed semi-federated learning (SemiFL), in which over-the-air computation is utilized for gradient aggregation. A key idea is to strategically adjust the learning rate by manipulating over-the-air distortion for improving SemiFL's convergence. Specifically, we intentionally amplify amplitude distortion to increase the learning rate in the non-stable region, thereby accelerating convergence and reducing communication energy consumption. In the stable region, we suppress noise perturbation to maintain a small learning rate for improving SemiFL's final convergence. Theoretical results demonstrate the antagonistic effects of over-the-air distortion in different regions, under both independent and identically distributed (IID) and non-IID data settings. Then, we formulate two energy consumption minimization problems, one for each region, which implements a two-region mean square error threshold configuration scheme. Accordingly, we propose two resource allocation algorithms with closed-form solutions. Simulation results show that under different network and data distribution conditions, strategically manipulating over-the-air distortion can efficiently adjust the learning rate to improve SemiFL's convergence. Moreover, energy consumption can be reduced by using the proposed algorithms.

Paper number 60:
Title: A Comprehensive Benchmark for Electrocardiogram Time-Series
Authors: Zhijiang Tang, Jiaxin Qi, Yuhua Zheng, Jianqiang Huang
Abstract: Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.

Paper number 61:
Title: Aligning Audio Captions with Human Preferences
Authors: Kartik Hegde, Rehana Mahfuz, Yinyi Guo, Erik Visser
Abstract: Current audio captioning relies on supervised learning with paired audio-caption data, which is costly to curate and may not reflect human preferences in real-world scenarios. To address this, we propose a preference-aligned audio captioning framework based on Reinforcement Learning from Human Feedback (RLHF). To capture nuanced preferences, we train a Contrastive Language-Audio Pretraining (CLAP) based reward model using human-labeled pairwise preference data. This reward model is integrated into an RL framework to fine-tune any baseline captioning system without ground-truth annotations. Extensive human evaluations across multiple datasets show that our method produces captions preferred over baseline models, particularly when baselines fail to provide correct and natural captions. Furthermore, our framework achieves performance comparable to supervised approaches with ground-truth data, demonstrating effective alignment with human preferences and scalability in real-world use.

Paper number 62:
Title: Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery
Authors: Antonio Martínez-Ibarra, Aurora González-Vidal, Adrián Cánovas-Rodríguez, Antonio F. Skarmeta
Abstract: The Mar Menor, Europe's largest hypersaline coastal lagoon, located in southeastern Spain, has undergone severe eutrophication crises, with devastating impacts on biodiversity and water quality. Monitoring chlorophyll-a, a proxy for phytoplankton biomass, is essential to anticipate harmful algal blooms and guide mitigation strategies. Traditional in situ measurements, while precise, are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable and long-term monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map chlorophyll-a concentrations across the water column of the Mar Menor. This work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Sentinel 2 images were atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth. Multiple ML algorithms, including CatBoost, XGBoost, SVMs, and MLPs, were trained and validated using a cross-validation scheme with multi-objective optimization functions. Band-combination experiments and spatial aggregation strategies were tested to optimize prediction. The results show depth-dependent performance. The Root Mean Squared Logarithmic Error (RMSLE) obtained ranges from 0.34 at the surface to 0.39 at 3-4 m, while the R2 value was 0.76 at the surface, 0.76 at 1-2 m, 0.70 at 2-3 m, and 0.60 at 3-4 m. Generated maps successfully reproduced known eutrophication events. The study delivers an end-to-end, validated methodology chlorophyll mapping. Its integration of multispectral band combinations, buoy calibration, and modeling offers a transferable framework for other turbid coastal systems.

Paper number 63:
Title: Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control
Authors: Ahmed Ali, Chiara Gabellieri, Antonio Franchi
Abstract: This paper presents a novel concept for achieving omnidirectionality in a multirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal forces at the equilibria. The concept integrates a single actively-tilting propeller along with 3 pendulum-like links, each carrying a propeller,connected by passive universal joints to the main body. We show that this design ensures omnidirectionality while minimizing the internal forces and without resorting to overactuation (i.e.,more than 6 inputs). A detailed dynamic model of the multi-link MAV is first developed. Afterwards, the analysis identifies the equilibrium configurations and illustrates that a forced equilibrium exists for every pose of the MAV's main platform. In order to render this equilibrium asymptotically stable for the closed-loop system, a coordinate-invariant nonlinear controller is constructed using dynamic feedback linearization and backstepping techniques with the main platform configuration error being the left-trivialized error on SE(3). The stability of the closed-loop system is then investigated by employing standard Lyapunov arguments on the zero dynamics. We conclude by providing numerical Gazebo simulations validating our approach. They demonstrate the MAV capability to perform decoupled attitude and translational motions under parametric uncertainty and actuators noise.

Paper number 64:
Title: Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty
Authors: Geon Roh, Jip Kim
Abstract: Dynamic line rating (DLR) enables greater utilization of existing transmission lines by leveraging real-time weather data. However, the elevated temperature operation (ETO) of conductors under DLR is often overlooked, despite its long-term impact on conductor health. This paper addresses this issue by 1) quantifying risk-based depreciation costs associated with ETO and 2) proposing a Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs in operational decisions. CHA-UC incorporates a robust linear approximation of conductor temperature and integration of expected depreciation costs due to hourly ETO into the objective function. Case studies on the Texas 123-bus backbone test system using NOAA weather data demonstrate that the proposed CHA-UC model reduces the total cost by 0.74\% and renewable curtailment by 85\% compared to static line rating (SLR) and outperforms quantile regression forest-based methods, while conventional DLR operation without risk consideration resulted in higher costs due to excessive ETO. Further analysis of the commitment decisions and the line temperature statistics confirms that the CHA-UC achieves safer line flows by shifting generator commitments. Finally, we examine the emergent correlation behaviors arising between wind generation and DLR forecast errors, and show that CHA-UC adaptively manages this effect by relaxing flows for risk-hedging conditions while tightening flows for risk-amplifying ones.

Paper number 65:
Title: Domain Adaptation for Camera-Specific Image Characteristics using Shallow Discriminators
Authors: Maximiliane Gruber, Jürgen Seiler, André Kaup
Abstract: Each image acquisition setup leads to its own camera-specific image characteristics degrading the image quality. In learning-based perception algorithms, characteristics occurring during the application phase, but absent in the training data, lead to a domain gap impeding the performance. Previously, pixel-level domain adaptation through unpaired learning of the pristine-to-distorted mapping function has been proposed. In this work, we propose shallow discriminator architectures to address limitations of these approaches. We show that a smaller receptive field size improves learning of unknown image distortions by more accurately reproducing local distortion characteristics at a low network complexity. In a domain adaptation setup for instance segmentation, we achieve mean average precision increases over previous methods of up to 0.15 for individual distortions and up to 0.16 for camera-specific image characteristics in a simplified camera model. In terms of number of parameters, our approach matches the complexity of one state of the art method while reducing complexity by a factor of 20 compared to another, demonstrating superior efficiency without compromising performance.

Paper number 66:
Title: Gauss-Newton accelerated MPPI Control
Authors: Hannes Homburger, Katrin Baumgärtner, Moritz Diehl, Johannes Reuter
Abstract: Model Predictive Path Integral (MPPI) control is a sampling-based optimization method that has recently attracted attention, particularly in the robotics and reinforcement learning communities. MPPI has been widely applied as a GPU-accelerated random search method to deterministic direct single-shooting optimal control problems arising in model predictive control (MPC) formulations. MPPI offers several key advantages, including flexibility, robustness, ease of implementation, and inherent parallelizability. However, its performance can deteriorate in high-dimensional settings since the optimal control problem is solved via Monte Carlo sampling. To address this limitation, this paper proposes an enhanced MPPI method that incorporates a Jacobian reconstruction technique and the second-order Generalized Gauss-Newton method. This novel approach is called \textit{Gauss-Newton accelerated MPPI}. The numerical results show that the Gauss-Newton accelerated MPPI approach substantially improves MPPI scalability and computational efficiency while preserving the key benefits of the classical MPPI framework, making it a promising approach even for high-dimensional problems.

Paper number 67:
Title: Toward a Decision Support System for Energy-Efficient Ferry Operation on Lake Constance based on Optimal Control
Authors: Hannes Homburger, Bastian Jäckl, Stefan Wirtensohn, Christian Stopp, Maximilian T. Fischer, Moritz Diehl, Daniel A. Keim, Johannes Reuter
Abstract: The maritime sector is undergoing a disruptive technological change driven by three main factors: autonomy, decarbonization, and digital transformation. Addressing these factors necessitates a reassessment of inland vessel operations. This paper presents the design and development of a decision support system for ferry operations based on a shrinking-horizon optimal control framework. The problem formulation incorporates a mathematical model of the ferry's dynamics and environmental disturbances, specifically water currents and wind, which can significantly influence the dynamics. Real-world data and illustrative scenarios demonstrate the potential of the proposed system to effectively support ferry crews by providing real-time guidance. This enables enhanced operational efficiency while maintaining predefined maneuver durations. The findings suggest that optimal control applications hold substantial promise for advancing future ferry operations on inland waters. A video of the real-world ferry MS Insel Mainau operating on Lake Constance is available at: this https URL

Paper number 68:
Title: Aligned Stable Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency
Authors: Yikai Wang, Junqiu Yu, Chenjie Cao, Xiangyang Xue, Yanwei Fu
Abstract: Generative image inpainting can produce realistic, high-fidelity results even with large, irregular masks. However, existing methods still face key issues that make inpainted images look unnatural. In this paper, we identify two main problems: (1) Unwanted object insertion: generative models may hallucinate arbitrary objects in the masked region that do not match the surrounding context. (2) Color inconsistency: inpainted regions often exhibit noticeable color shifts, leading to smeared textures and degraded image quality. We analyze the underlying causes of these issues and propose efficient post-hoc solutions for pre-trained inpainting models. Specifically, we introduce the principled framework of Aligned Stable inpainting with UnKnown Areas prior (ASUKA). To reduce unwanted object insertion, we use reconstruction-based priors to guide the generative model, suppressing hallucinated objects while preserving generative flexibility. To address color inconsistency, we design a specialized VAE decoder that formulates latent-to-image decoding as a local harmonization task. This design significantly reduces color shifts and produces more color-consistent results. We implement ASUKA on two representative inpainting architectures: a U-Net-based model and a DiT-based model. We analyze and propose lightweight injection strategies that minimize interference with the model's original generation capacity while ensuring the mitigation of the two issues. We evaluate ASUKA using the Places2 dataset and MISATO, our proposed diverse benchmark. Experiments show that ASUKA effectively suppresses object hallucination and improves color consistency, outperforming standard diffusion, rectified flow models, and other inpainting methods. Dataset, models and codes will be released in github.

Paper number 69:
Title: EExApp: GNN-Based Reinforcement Learning for Radio Unit Energy Optimization in 5G O-RAN
Authors: Jie Lu, Peihao Yan, Huacheng Zeng
Abstract: With over 3.5 million 5G base stations deployed globally, their collective energy consumption (projected to exceed 131 TWh annually) raises significant concerns over both operational costs and environmental impacts. In this paper, we present EExAPP, a deep reinforcement learning (DRL)-based xApp for 5G Open Radio Access Network (O-RAN) that jointly optimizes radio unit (RU) sleep scheduling and distributed unit (DU) resource slicing. EExAPP uses a dual-actor-dual-critic Proximal Policy Optimization (PPO) architecture, with dedicated actor-critic pairs targeting energy efficiency and quality-of-service (QoS) compliance. A transformer-based encoder enables scalable handling of variable user equipment (UE) populations by encoding all-UE observations into fixed-dimensional representations. To coordinate the two optimization objectives, a bipartite Graph Attention Network (GAT) is used to modulate actor updates based on both critic outputs, enabling adaptive trade-offs between power savings and QoS. We have implemented EExAPP and deployed it on a real-world 5G O-RAN testbed with live traffic, commercial RU and smartphones. Extensive over-the-air experiments and ablation studies confirm that EExAPP significantly outperforms existing methods in reducing the energy consumption of RU while maintaining QoS. The source code is available at this https URL.

Paper number 70:
Title: Beyond Calibration: Confounding Pathology Limits Foundation Model Specificity in Abdominal Trauma CT
Authors: Jineel H Raythatha, Shuchang Ye, Jeremy Hsu, Jinman Kim
Abstract: Purpose: Translating foundation models into clinical practice requires evaluating their performance under compound distribution shift, where severe class imbalance coexists with heterogeneous imaging appearances. This challenge is relevant for traumatic bowel injury, a rare but high-mortality diagnosis. We investigated whether specificity deficits in foundation models are associated with heterogeneity in the negative class. Methods: This retrospective study used the multi-institutional, RSNA Abdominal Traumatic Injury CT dataset (2019-2023), comprising scans from 23 centres. Two foundation models (MedCLIP, zero-shot; RadDINO, linear probe) were compared against three task-specific approaches (CNN, Transformer, Ensemble). Models were trained on 3,147 patients (2.3% bowel injury prevalence) and evaluated on an enriched 100-patient test set. To isolate negative-class effects, specificity was assessed in patients without bowel injury who had concurrent solid organ injury (n=58) versus no abdominal pathology (n=50). Results: Foundation models achieved equivalent discrimination to task-specific models (AUC, 0.64-0.68 versus 0.58-0.64) with higher sensitivity (79-91% vs 41-74%) but lower specificity (33-50% vs 50-88%). All models demonstrated high specificity in patients without abdominal pathology (84-100%). When solid organ injuries were present, specificity declined substantially for foundation models (50-51 percentage points) compared with smaller reductions of 12-41 percentage points for task-specific models. Conclusion: Foundation models matched task-specific discrimination without task-specific training, but their specificity deficits were driven primarily by confounding negative-class heterogeneity rather than prevalence alone. Susceptibility to negative-class heterogeneity decreased progressively with labelled training, suggesting adaptation is required before clinical implementation.

Paper number 71:
Title: MDM-ASR: Bridging Accuracy and Efficiency in ASR with Diffusion-Based Non-Autoregressive Decoding
Authors: Hao Yen, Pin-Jui Ku, Ante Jukić, Sabato Marco Siniscalchi
Abstract: In sequence-to-sequence Transformer ASR, autoregressive (AR) models achieve strong accuracy but suffer from slow decoding, while non-autoregressive (NAR) models enable parallel decoding at the cost of degraded performance. We propose a principled NAR ASR framework based on Masked Diffusion Models to reduce this gap. A pre-trained speech encoder is coupled with a Transformer diffusion decoder conditioned on acoustic features and partially masked transcripts for parallel token prediction. To mitigate the training-inference mismatch, we introduce Iterative Self-Correction Training that exposes the model to its own intermediate predictions. We also design a Position-Biased Entropy-Bounded Confidence-based sampler with positional bias to further boost results. Experiments across multiple benchmarks demonstrate consistent gains over prior NAR models and competitive performance with strong AR baselines, while retaining parallel decoding efficiency.

Paper number 72:
Title: High-Altitude Platforms in the Low-Altitude Economy: Bridging Communication, Computing, and Regulation
Authors: Bang Huang, Baha Eddine Youcef Belmekki, Mohamed-Slim Alouini
Abstract: The Low-Altitude Economy (LAE) is rapidly emerging as a new technological and industrial frontier, with unmanned aerial vehicles (UAVs), electric vertical takeoff and landing (eVTOL) aircraft, and aerial swarms increasingly deployed in logistics, infrastructure inspection, security, and emergency response. However, the large-scale development of the LAE demands a reliable aerial foundation that ensures not only real-time connectivity and computational support, but also navigation integrity and safe airspace management for safety-critical operations. High-Altitude Platforms (HAPs), positioned at around 20 km, provide a unique balance between wide-area coverage and low-latency responsiveness. Compared with low earth orbit (LEO) satellites, HAPs are closer to end users and thus capable of delivering millisecond-level connectivity, fine-grained regulatory oversight, and powerful onboard computing and caching resources. Beyond connectivity and computation, HAPs-assisted sensing and regulation further enable navigation integrity and airspace trust, which are essential for safety-critical UAV and eVTOL operations in the LAE. This article proposes a five-stage evolutionary roadmap for HAPs in the LAE: from serving as aerial infrastructure bases, to becoming super back-ends for UAV, to acting as frontline support for ground users, further enabling swarm-scale UAV coordination, and ultimately advancing toward edge-air-cloud closed-loop autonomy. In parallel, HAPs complement LEO satellites and cloud infrastructures to form a global-regional-local three-tier architecture. Looking forward, HAPs are expected to evolve from simple platforms into intelligent hubs, emerging as pivotal nodes for air traffic management, intelligent logistics, and emergency response. By doing so, they will accelerate the transition of the LAE toward large-scale deployment, autonomy, and sustainable growth.

Paper number 73:
Title: Comparing Implicit Neural Representations and B-Splines for Continuous Function Fitting from Sparse Samples
Authors: Hongze Yu, Yun Jiang, Jeffrey A. Fessler
Abstract: Continuous signal representations are naturally suited for inverse problems, such as magnetic resonance imaging (MRI) and computed tomography, because the measurements depend on an underlying physically continuous signal. While classical methods rely on predefined analytical bases like B-splines, implicit neural representations (INRs) have emerged as a powerful alternative that use coordinate-based networks to parameterize continuous functions with implicitly defined bases. Despite their empirical success, direct comparisons of their intrinsic representation capabilities with conventional models remain limited. This preliminary empirical study compares a positional-encoded INR with a cubic B-spline model for continuous function fitting from sparse random samples, isolating the representation capacity difference by only using coefficient-domain Tikhonov regularization. Results demonstrate that, under oracle hyperparameter selection, the INR achieves a lower normalized root-mean-squared error, yielding sharper edge transitions and fewer oscillatory artifacts than the oracle-tuned B-spline model. Additionally, we show that a practical bilevel optimization framework for INR hyperparameter selection based on measurement data split effectively approximates oracle performance. These findings empirically support the superior representation capacity of INRs for sparse data fitting.

Paper number 74:
Title: Synapse-Inspired Energy Networks: A Neuromorphic Approach to Microgrid Protection without Communication Links
Authors: Saurabh Prabhakar, Bijaya Ketan Panigrahi, Frede Blaabjerg, Subham Sahoo
Abstract: Traditional protection systems for microgrids, which rely on high fault currents and continuous communication, struggle to keep up with the changing dynamics and cybersecurity concerns of decentralized networks. In this study, we introduce a novel biologically inspired protection system based on neuromorphic principles, where each distributed energy resource (DER) functions as a simple neuron. These neurons process local changes in voltage, current signals, and converting them into spike patterns that represent the severity of disturbances. Just as neurons communicate via synapses in biological systems, we exploit transmission cables to coordinate between DERs, enabling them to share information and respond to faults collectively. Fault detection and circuit breaker activation are driven by a First-To-Spike (FTTS) mechanism, similar to the concept of traveling wave protection, but without needing GPS synchronization or communication links. A key innovation is the ability to use the timing of spikes to locally determine the nature of a fault, offering an intelligent, adaptive response to disturbances. Performance shows tripping latency of 10-58 ms, surpassing conventional relays and even traveling-wave methods (60 ms), while maintaining detection accuracy above 98% and spatial selectivity over 97%, enabling real-time, communication-free, scalable protection for plug-and-play microgrids.

Paper number 75:
Title: Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management
Authors: M. Saifullah, K.G. Papakonstantinou, A. Bhattacharya, S.M. Stoffels, C.P. Andriotis
Abstract: Life-cycle management of large-scale transportation systems requires determining a sequence of inspection and maintenance decisions to minimize long-term risks and costs while dealing with multiple uncertainties and constraints that lie in high-dimensional spaces. Traditional approaches have been widely applied but often suffer from limitations related to optimality, scalability, and the ability to properly handle uncertainty. Moreover, many existing methods rely on unconstrained formulations that overlook critical operational constraints. We address these issues in this work by casting the optimization problem within the framework of constrained Partially Observable Markov Decision Processes (POMDPs), which provide a robust mathematical foundation for stochastic sequential decision-making under observation uncertainties, in the presence of risk and resource limitations. To tackle the high dimensionality of state and action spaces, we propose DDMAC-CTDE, a Deep Decentralized Multi-Agent Actor-Critic (DDMAC) reinforcement learning architecture with Centralized Training and Decentralized Execution (CTDE). To demonstrate the utility of the proposed framework, we also develop a new comprehensive benchmark environment representing an existing transportation network in Virginia, U.S., with heterogeneous pavement and bridge assets undergoing nonstationary degradation. This environment incorporates multiple practical constraints related to budget limits, performance guidelines, traffic delays, and risk considerations. On this benchmark, DDMAC-CTDE consistently outperforms standard transportation management baselines, producing better policies. Together, the proposed framework and benchmark provide (i) a scalable, constraint-aware methodology, and (ii) a realistic, rigorous testbed for comprehensive evaluation of Deep Reinforcement Learning (DRL) for transportation infrastructure management.

Paper number 76:
Title: MSADM: Large Language Model (LLM) Assisted End-to-End Network Health Management Based on Multi-Scale Semanticization
Authors: Fengxiao Tang, Xiaonan Wang, Xun Yuan, Linfeng Luo, Ming Zhao, Tianchi Huang, Nei Kato
Abstract: Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the heterogeneous networks (HNs) environment. Moreover, current state-of-the-art distributed fault diagnosis methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for HNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a multi-scale data scaling method based on unsupervised learning to address the multi-scale data problem in HNs. Secondly, we combine the semantic rule tree with the attention mechanism to propose a Multi-Scale Semanticized Anomaly Detection Model (MSADM) that generates network semantic information while detecting anomalies. Finally, we embed a chain-of-thought-based large-scale language model downstream to adaptively analyze the fault diagnosis results and create an analysis report containing detailed fault information and optimization strategies. We compare our scheme with other fault diagnosis models and demonstrate that it performs well on several metrics of network fault diagnosis.

Paper number 77:
Title: MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization
Authors: Bogdan Vlahov, Jason Gibson, Manan Gandhi, Evangelos A. Theodorou
Abstract: This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: this https URL .

Paper number 78:
Title: Multi-Fidelity Bayesian Optimization for Nash Equilibria with Black-Box Utilities
Authors: Yunchuan Zhang, Osvaldo Simeone, H. Vincent Poor
Abstract: Modern open and softwarized systems -- such as O-RAN telecom networks and cloud computing platforms -- host independently developed applications with distinct, and potentially conflicting, objectives. Coordinating the behavior of such applications to ensure stable system operation poses significant challenges, especially when each application's utility is accessible only via costly, black-box evaluations. In this paper, we consider a centralized optimization framework in which a system controller suggests joint configurations to multiple strategic players, representing different applications, with the goal of aligning their incentives toward a stable outcome. This interaction is modeled as a learned optimization with an equilibrium constraint in which the central optimizer learns the utility functions through sequential, multi-fidelity evaluations with the goal of identifying a pure Nash equilibrium (PNE). To address this challenge, we propose MF-UCB-PNE, a novel multi-fidelity Bayesian optimization strategy that leverages a budget-constrained sampling process to approximate PNE solutions. MF-UCB-PNE systematically balances exploration across low-cost approximations with high-fidelity exploitation steps, enabling efficient convergence to incentive-compatible configurations. We provide theoretical and empirical insights into the trade-offs between query cost and equilibrium accuracy, demonstrating the effectiveness of MF-UCB-PNE in identifying effective equilibrium solutions under limited cost budgets.

Paper number 79:
Title: Learning to Pursue AC Optimal Power Flow Solutions with Feasibility Guarantees
Authors: Damola Ajeyemi, Yiting Chen, Antonin Colot, Jorge Cortes, Emiliano Dall'Anese
Abstract: This paper focuses on an AC optimal power flow (OPF) problem for distribution feeders equipped with controllable distributed energy resources (DERs). We consider a solution method that is based on a continuous approximation of the projected gradient flow - referred to as the safe gradient flow - that incorporates voltage and current information obtained either through real-time measurements or power flow computations. These two setups enable both online and offline implementations. The safe gradient flow involves the solution of convex quadratic programs (QPs). To enhance computational efficiency, we propose a novel framework that employs a neural network approximation of the optimal solution map of the QP. The resulting method has two key features: (a) it ensures that the DERs' setpoints are practically feasible, even for an online implementation or when an offline algorithm has an early termination; (b) it ensures convergence to a neighborhood of a strict local optimizer of the AC OPF. The proposed method is tested on a 93-node distribution system with realistic loads and renewable generation. The test shows that our method successfully regulates voltages within limits during periods with high renewable generation.

Paper number 80:
Title: Sonic4D: Spatial Audio Generation for Immersive 4D Scene Exploration
Authors: Siyi Xie, Hanxin Zhu, Tianyu He, Xin Li, Zhibo Chen
Abstract: Recent advancements in 4D generation have demonstrated its remarkable capability in synthesizing photorealistic renderings of dynamic 3D scenes. However, despite achieving impressive visual performance, almost all existing methods overlook the generation of spatial audio aligned with the corresponding 4D scenes, posing a significant limitation to truly immersive audiovisual experiences. To mitigate this issue, we propose Sonic4D, a novel framework that enables spatial audio generation for immersive exploration of 4D scenes. Specifically, our method is composed of three stages: 1) To capture both the dynamic visual content and raw auditory information from a monocular video, we first employ pre-trained expert models to generate the 4D scene and its corresponding monaural audio. 2) Subsequently, to transform the monaural audio into spatial audio, we localize and track the sound sources within the 4D scene, where their 3D spatial coordinates at different timestamps are estimated via a pixel-level visual grounding strategy. 3) Based on the estimated sound source locations, we further synthesize plausible spatial audio that varies across different viewpoints and timestamps using physics-based simulation. Extensive experiments have demonstrated that our proposed method generates realistic spatial audio consistent with the synthesized 4D scene in a training-free manner, significantly enhancing the immersive experience for users. Generated audio and video examples are available at this https URL.

Paper number 81:
Title: Capturing Stable HDR Videos Using a Dual-Camera System
Authors: Qianyu Zhang, Bolun Zheng, Lingyu Zhu, Hangjia Pan, Zunjie Zhu, Zongpeng Li, Shiqi Wang
Abstract: High Dynamic Range (HDR) video acquisition using the alternating exposure (AE) paradigm has garnered significant attention due to its cost-effectiveness with a single consumer camera. However, despite progress driven by deep neural networks, these methods remain prone to temporal flicker in real-world applications due to inter-frame exposure inconsistencies. To address this challenge while maintaining the cost-effectiveness of the AE paradigm, we propose a novel learning-based HDR video generation solution. Specifically, we propose a dual-stream HDR video generation paradigm that decouples temporal luminance anchoring from exposure-variant detail reconstruction, overcoming the inherent limitations of the AE paradigm. To support this, we design an asynchronous dual-camera system (DCS), which enables independent exposure control across two cameras, eliminating the need for synchronization typically required in traditional multi-camera setups. Furthermore, an exposure-adaptive fusion network (EAFNet) is formulated for the DCS system. EAFNet integrates a pre-alignment subnetwork that aligns features across varying exposures, ensuring robust feature extraction for subsequent fusion, an asymmetric cross-feature fusion subnetwork that emphasizes reference-based attention to effectively merge these features across exposures, and a reconstruction subnetwork to mitigate ghosting artifacts and preserve fine details. Extensive experimental evaluations demonstrate that the proposed method achieves state-of-the-art performance across various datasets, showing the remarkable potential of our solution in HDR video reconstruction. The codes and data captured by DCS will be available at this https URL.

Paper number 82:
Title: Training-free Mixed-Resolution Latent Upsampling for Spatially Accelerated Diffusion Transformers
Authors: Wongi Jeong, Kyungryeol Lee, Hoigi Seo, Se Young Chun
Abstract: Diffusion transformers (DiTs) offer excellent scalability for high-fidelity generation, but their computational overhead poses a great challenge for practical deployment. Existing acceleration methods primarily exploit the temporal dimension, whereas spatial acceleration remains underexplored. In this work, we investigate spatial acceleration for DiTs via latent upsampling. We found that naïve latent upsampling for spatial acceleration introduces artifacts, primarily due to aliasing in high-frequency edge regions and mismatching from noise-timestep discrepancies. Then, based on these findings and analyses, we propose a training-free spatial acceleration framework, dubbed Region-Adaptive Latent Upsampling (RALU), to mitigate those artifacts while achieving spatial acceleration of DiTs by our mixed-resolution latent upsampling. RALU achieves artifact-free, efficient acceleration with early upsampling only on artifact-prone edge regions and noise-timestep matching for different latent resolutions, leading to up to 7.0$\times$ speedup on this http URL and 3.0$\times$ on Stable Diffusion 3 with negligible quality degradation. Furthermore, our RALU is complementarily applicable to existing temporal acceleration methods and timestep-distilled models, leading to up to 15.9$\times$ speedup.

Paper number 83:
Title: Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic Paradigm for Defense and Dominance
Authors: Ya-Ting Yang, Quanyan Zhu
Abstract: Cyber warfare has become a central element of modern conflict, especially within multi-domain operations. As both a distinct and critical domain, cyber warfare requires integrating defensive and offensive technologies into coherent strategies. While prior research has emphasized isolated tactics or fragmented technologies, a holistic understanding is essential for effective resource deployment and risk mitigation. Game theory offers a unifying framework for this purpose. It not only models attacker-defender interactions but also provides quantitative tools for equilibrium analysis, risk assessment, and strategic reasoning. Integrated with modern AI techniques, game-theoretic models enable the design and optimization of strategies across multiple levels of cyber warfare, from policy and strategy to operations, tactics, and technical implementations. These models capture the paradoxical logic of conflict, where more resources do not always translate into greater advantage, and where nonlinear dynamics govern outcomes. To illustrate the approach, this chapter examines RedCyber, a synthetic cyber conflict, demonstrating how game-theoretic methods capture the interdependencies of cyber operations. The chapter concludes with directions for future research on resilience, cros-echelon planning, and the evolving role of AI in cyber warfare.

Paper number 84:
Title: Dual-Regularized Riccati Recursions for Interior-Point Optimal Control
Authors: João Sousa-Pinto, Dominique Orban
Abstract: We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each primal step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.

Paper number 85:
Title: Data-Augmented Deep Learning for Downhole Depth Sensing and Validation
Authors: Si-Yu Xiao, Xin-Di Zhao, Tian-Hao Mao, Yi-Wei Wang, Yu-Qiao Chen, Hong-Yun Zhang, Jian Wang, Jun-Jie Wang, Shuang Liu, Tu-Pei Chen, Yang Liu
Abstract: Accurate downhole depth measurement is essential for oil and gas well operations, directly influencing reservoir contact, production efficiency, and operational safety. Collar correlation using a casing collar locator (CCL) is fundamental for precise depth calibration. While neural network has achieved significant progress in collar recognition, preprocessing methods for such applications remain underdeveloped. Moreover, the limited availability of real well data poses substantial challenges for training neural network models that require extensive datasets. This paper presents a system integrated into a downhole toolstring for CCL log acquisition to facilitate dataset construction. Comprehensive preprocessing methods for data augmentation are proposed, and their effectiveness is evaluated using baseline neural network models. Through systematic experimentation across diverse configurations, the contribution of each augmentation method is analyzed. Results demonstrate that standardization, label distribution smoothing, and random cropping are fundamental prerequisites for model training, while label smoothing regularization, time scaling, and multiple sampling significantly enhance model generalization capabilities. Incorporating the proposed augmentation methods into the two baseline models results in maximum F1 score improvements of 0.027 and 0.024 for the TAN and MAN models, respectively. Furthermore, applying these techniques yields F1 score gains of up to 0.045 for the TAN model and 0.057 for the MAN model compared to prior studies. Performance evaluation on real CCL waveforms confirms the effectiveness and practical applicability of our approach. This work addresses the existing gaps in data augmentation methodologies for training casing collar recognition models under CCL data-limited conditions, and provides a technical foundation for the future automation of downhole operations.

Paper number 86:
Title: On Discrete Ambiguity Functions of Random Communication Waveforms
Authors: Ying Zhang, Fan Liu, Yifeng Xiong, Weijie Yuan, Shuangyang Li, Le Zheng, Tony Xiao Han, Christos Masouros, Shi Jin
Abstract: This paper provides a fundamental characterization of the discrete ambiguity functions (AFs) of random communication waveforms under arbitrary orthonormal modulation with random constellation symbols, which serve as a key metric for evaluating the delay-Doppler sensing performance in future ISAC applications. A unified analytical framework is developed for two types of AFs, namely the discrete periodic AF (DP-AF) and the fast-slow time AF (FST-AF), where the latter may be seen as a small-Doppler approximation of the DP-AF. By analyzing the expectation of squared AFs, we derive exact closed-form expressions for both the expected sidelobe level (ESL) and the expected integrated sidelobe level (EISL) under the DP-AF and FST-AF formulations. For the DP-AF, we prove that the normalized EISL is identical for all orthogonal waveforms. To gain structural insights, we introduce a matrix representation based on the finite Weyl-Heisenberg (WH) group, where each delay-Doppler shift corresponds to a WH operator acting on the ISAC signal. This WH-group viewpoint yields sharp geometric constraints on the lowest sidelobes: The minimum ESL can only occur along a one-dimensional cut or over a set of widely dispersed delay-Doppler bins. Consequently, no waveform can attain the minimum ESL over any compact two-dimensional region, leading to a no-optimality (no-go) result under the DP-AF framework. For the FST-AF, the closed-form ESL and EISL expressions reveal a constellation-dependent regime governed by its kurtosis: The OFDM modulation achieves the minimum ESL for sub-Gaussian constellations, whereas the OTFS waveform becomes optimal for super-Gaussian constellations. Finally, four representative waveforms, namely, SC, OFDM, OTFS, and AFDM, are examined under both frameworks, and all theoretical results are verified through numerical examples.

Paper number 87:
Title: Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study
Authors: Ata Akbari Asanjan, Milad Memarzadeh, Bryan Matthews, Nikunj Oza
Abstract: In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.

Paper number 88:
Title: DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations
Authors: Minghao Li, Ruihang Wang, Rui Tan, Yonggang Wen
Abstract: Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.

Paper number 89:
Title: OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video Generation Model
Authors: Maomao Li, Zhen Li, Kaipeng Zhang, Guosheng Yin, Zhifeng Li, Dong Xu
Abstract: Existing mainstream video customization methods focus on generating identity-consistent videos based on given reference images and textual prompts. Benefiting from the rapid advancement of joint audio-video generation, this paper proposes a more compelling new task: sync audio-video customization, which aims to synchronously customize both video identity and audio timbre. Specifically, given a reference image $I^{r}$ and a reference audio $A^{r}$, this novel task requires generating videos that maintain the identity of the reference image while imitating the timbre of the reference audio, with spoken content freely specifiable through user-provided textual prompts. To this end, we propose OmniCustom, a powerful DiT-based audio-video customization framework that can synthesize a video following reference image identity, audio timbre, and text prompts all at once in a zero-shot manner. Our framework is built on three key contributions. First, identity and audio timbre control are achieved through separate reference identity and audio LoRA modules that operate through self-attention layers within the base audio-video generation model. Second, we introduce a contrastive learning objective alongside the standard flow matching objective. It uses predicted flows conditioned on reference inputs as positive examples and those without reference conditions as negative examples, thereby enhancing the model ability to preserve identity and timbre. Third, we train OmniCustom on our constructed large-scale, high-quality audio-visual human dataset. Extensive experiments demonstrate that OmniCustom outperforms existing methods in generating audio-video content with consistent identity and timbre fidelity. Project page: this https URL.
    