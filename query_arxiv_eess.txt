
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: On the Bias, Fairness, and Bias Mitigation for a Wearable-based Freezing of Gait Detection in Parkinson's Disease
Authors: Timothy Odonga, Christine D. Esper, Stewart A. Factor, J. Lucas McKay, Hyeokhyen Kwon
Abstract: Freezing of gait (FOG) is a debilitating feature of Parkinson's disease (PD), which is a cause of injurious falls among PD patients. Recent advances in wearable-based human activity recognition (HAR) technology have enabled the detection of FOG subtypes across benchmark datasets. Since FOG manifestation is heterogeneous, developing models that quantify FOG consistently across patients with varying demographics, FOG types, and PD conditions is important. Bias and fairness in FOG models remain understudied in HAR, with research focused mainly on FOG detection using single benchmark datasets. We evaluated the bias and fairness of HAR models for wearable-based FOG detection across demographics and PD conditions using multiple datasets and the effectiveness of transfer learning as a potential bias mitigation approach. Our evaluation using demographic parity ratio (DPR) and equalized odds ratio (EOR) showed model bias (DPR & EOR < 0.8) for all stratified demographic variables, including age, sex, and disease duration. Our experiments demonstrated that transfer learning from multi-site datasets and generic human activity representations significantly improved fairness (average change in DPR +0.027, +0.039, respectively) and performance (average change in F1-score +0.026, +0.018, respectively) across attributes, supporting the hypothesis that generic human activity representations learn fairer representations applicable to health analytics.

Paper number 2:
Title: Volumetric Temporal Texture Synthesis for Smoke Stylization using Neural Cellular Automata
Authors: Dongqing Wang, Ehsan Pajouheshgar, Yitao Xu, Tong Zhang, Sabine Süsstrunk
Abstract: Artistic stylization of 3D volumetric smoke data is still a challenge in computer graphics due to the difficulty of ensuring spatiotemporal consistency given a reference style image, and that within reasonable time and computational resources. In this work, we introduce Volumetric Neural Cellular Automata (VNCA), a novel model for efficient volumetric style transfer that synthesizes, in real-time, multi-view consistent stylizing features on the target smoke with temporally coherent transitions between stylized simulation frames. VNCA synthesizes a 3D texture volume with color and density stylization and dynamically aligns this volume with the intricate motion patterns of the smoke simulation under the Eulerian framework. Our approach replaces the explicit fluid advection modeling and the inter-frame smoothing terms with the self-emerging motion of the underlying cellular automaton, thus reducing the training time by over an order of magnitude. Beyond smoke simulations, we demonstrate the versatility of our approach by showcasing its applicability to mesh stylization.

Paper number 3:
Title: SASVi - Segment Any Surgical Video
Authors: Ssharvien Kumar Sivakumar, Yannik Frisch, Amin Ranem, Anirban Mukhopadhyay
Abstract: Purpose: Foundation models, trained on multitudes of public datasets, often require additional fine-tuning or re-prompting mechanisms to be applied to visually distinct target domains such as surgical videos. Further, without domain knowledge, they cannot model the specific semantics of the target domain. Hence, when applied to surgical video segmentation, they fail to generalise to sections where previously tracked objects leave the scene or new objects enter. Methods: We propose SASVi, a novel re-prompting mechanism based on a frame-wise Mask R-CNN Overseer model, which is trained on a minimal amount of scarcely available annotations for the target domain. This model automatically re-prompts the foundation model SAM2 when the scene constellation changes, allowing for temporally smooth and complete segmentation of full surgical videos. Results: Re-prompting based on our Overseer model significantly improves the temporal consistency of surgical video segmentation compared to similar prompting techniques and especially frame-wise segmentation, which neglects temporal information, by at least 1.5%. Our proposed approach allows us to successfully deploy SAM2 to surgical videos, which we quantitatively and qualitatively demonstrate for three different cholecystectomy and cataract surgery datasets. Conclusion: SASVi can serve as a new baseline for smooth and temporally consistent segmentation of surgical videos with scarcely available annotation data. Our method allows us to leverage scarce annotations and obtain complete annotations for full videos of the large-scale counterpart datasets. We make those annotations publicly available, providing extensive annotation data for the future development of surgical data science models.

Paper number 4:
Title: Heterogeneous Mixture of Experts for Remote Sensing Image Super-Resolution
Authors: Bowen Chen, Keyan Chen, Mohan Yang, Zhengxia Zou, Zhenwei Shi
Abstract: Remote sensing image super-resolution (SR) aims to reconstruct high-resolution remote sensing images from low-resolution inputs, thereby addressing limitations imposed by sensors and imaging conditions. However, the inherent characteristics of remote sensing images, including diverse ground object types and complex details, pose significant challenges to achieving high-quality reconstruction. Existing methods typically employ a uniform structure to process various types of ground objects without distinction, making it difficult to adapt to the complex characteristics of remote sensing images. To address this issue, we introduce a Mixture of Experts (MoE) model and design a set of heterogeneous experts. These experts are organized into multiple expert groups, where experts within each group are homogeneous while being heterogeneous across groups. This design ensures that specialized activation parameters can be employed to handle the diverse and intricate details of ground objects effectively. To better accommodate the heterogeneous experts, we propose a multi-level feature aggregation strategy to guide the routing process. Additionally, we develop a dual-routing mechanism to adaptively select the optimal expert for each pixel. Experiments conducted on the UCMerced and AID datasets demonstrate that our proposed method achieves superior SR reconstruction accuracy compared to state-of-the-art methods. The code will be available at this https URL.

Paper number 5:
Title: Lifespan tree of brain anatomy: diagnostic values for motor and cognitive neurodegenerative diseases
Authors: Pierrick Coupé, Boris Mansencal, José V. Manjón, Patrice Péran, Wassilios G. Meissner, Thomas Tourdias, Vincent Planche
Abstract: The differential diagnosis of neurodegenerative diseases, characterized by overlapping symptoms, may be challenging. Brain imaging coupled with artificial intelligence has been previously proposed for diagnostic support, but most of these methods have been trained to discriminate only isolated diseases from controls. Here, we develop a novel machine learning framework, named lifespan tree of brain anatomy, dedicated to the differential diagnosis between multiple diseases simultaneously. It integrates the modeling of volume changes for 124 brain structures during the lifespan with non-linear dimensionality reduction and synthetic sampling techniques to create easily interpretable representations of brain anatomy over the course of disease progression. As clinically relevant proof- of-concept applications, we constructed a cognitive lifespan tree of brain anatomy for the differential diagnosis of six causes of neurodegenerative dementia and a motor lifespan tree of brain anatomy for the differential diagnosis of four causes of parkinsonism using 37594 MRI as a training dataset. This original approach enhanced significantly the efficiency of differential diagnosis in the external validation cohort of 1754 cases, outperforming existing state-of-the art machine learning techniques. Lifespan tree holds promise as a valuable tool for differential diagnostic in relevant clinical conditions, especially for diseases still lacking effective biological markers.

Paper number 6:
Title: Power System Electromagnetic Transient Stability: an Analysis Based on Convergent Hamiltonian
Authors: Xinyuan Jiang, Constantino M. Lagoa, Yan Li
Abstract: Transient stability is crucial to the reliable operation of power systems. Existing theories rely on the simplified electromechanical models, substituting the detailed electromagnetic dynamics of inductor and capacitor with their impedance representations. However, this simplification is inadequate for the growing penetration of fast-switching power electronic devices. Attempts to extend the existing theories to include electromagnetic dynamics lead to overly conservative stability conditions. To tackle this problem more directly, we study the condition under which the power source and dissipation in the electromagnetic dynamics tend to balance each other asymptotically. This is equivalent to the convergence of the Hamiltonian (total stored energy) and can be shown to imply transient stability. Using contraction analysis, we prove that this property holds for a large class of time-varying port-Hamiltonian systems with (i) constant damping matrix and (ii) strictly convex Hamiltonian. Then through port-Hamiltonian modeling of the electromagnetic dynamics, we obtain that the synchronized steady state of the power system is globally stable if it exists. This result provides new insights into the reliable operation of power systems. The proposed theory is illustrated in the simulation results of a two-machine system.

Paper number 7:
Title: Perch like a bird: bio-inspired optimal maneuvers and nonlinear control for Flapping-Wing Unmanned Aerial Vehicles
Authors: C. Ruiz, J. Á. Acosta
Abstract: This research endeavors to design the perching maneuver and control in ornithopter robots. By analyzing the dynamic interplay between the robot's flight dynamics, feedback loops, and the environmental constraints, we aim to advance our understanding of the perching maneuver, drawing parallels to biological systems. Inspired by the elegant control strategies observed in avian flight, we develop an optimal maneuver and a corresponding controller to achieve stable perching. The maneuver consists of a deceleration and a rapid pitch-up (vertical turn), which arises from analytically solving the optimization problem of minimal velocity at perch, subject to kinematic and dynamic constraints. The controller for the flapping frequency and tail symmetric deflection is nonlinear and adaptive, ensuring robustly stable perching. Indeed, such adaptive behavior in a sense incorporates homeostatic principles of cybernetics into the control system, enhancing the robot's ability to adapt to unexpected disturbances and maintain a stable posture during the perching maneuver. The resulting autonomous perching maneuvers -- closed-loop descent and turn -- , have been verified and validated, demonstrating excellent agreement with real bird perching trajectories reported in the literature. These findings lay the theoretical groundwork for the development of future prototypes that better imitate the skillful perching maneuvers of birds.

Paper number 8:
Title: Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis
Authors: Yaqian Chen, Hanxue Gu, Yuwen Chen, Jicheng Yang, Haoyu Dong, Joseph Y. Cao, Adrian Camarena, Christopher Mantyh, Roy Colglazier, Maciej A. Mazurowski
Abstract: Body composition assessment using CT images can potentially be used for a number of clinical applications, including the prognostication of cardiovascular outcomes, evaluation of metabolic health, monitoring of disease progression, assessment of nutritional status, prediction of treatment response in oncology, and risk stratification for surgical and critical care outcomes. While multiple groups have developed in-house segmentation tools for this analysis, there are very limited publicly available tools that could be consistently used across different applications. To mitigate this gap, we present a publicly accessible, end-to-end segmentation and feature calculation model specifically for CT body composition analysis. Our model performs segmentation of skeletal muscle, subcutaneous adipose tissue (SAT), and visceral adipose tissue (VAT) across the chest, abdomen, and pelvis area in axial CT images. It also provides various body composition metrics, including muscle density, visceral-to-subcutaneous fat (VAT/SAT) ratio, muscle area/volume, and skeletal muscle index (SMI), supporting both 2D and 3D assessments. The model is shared for public use. To evaluate the model, the segmentation was applied to both internal and external datasets, with body composition metrics analyzed across different age, sex, and race groups. The model achieved high dice coefficients on both internal and external datasets, exceeding 89% for skeletal muscle, SAT, and VAT segmentation. The model outperforms the benchmark by 2.40% on skeletal muscle and 10.26% on SAT compared to the manual annotations given by the publicly available dataset. Body composition metrics show mean relative absolute errors (MRAEs) under 10% for all measures. Furthermore, the model provided muscular fat segmentation with a Dice coefficient of 56.27%, which can be utilized for additional analyses as needed.

Paper number 9:
Title: Acute Lymphoblastic Leukemia Diagnosis Employing YOLOv11, YOLOv8, ResNet50, and Inception-ResNet-v2 Deep Learning Models
Authors: Alaa Awad, Salah A. Aly
Abstract: Thousands of individuals succumb annually to leukemia alone. As artificial intelligence-driven technologies continue to evolve and advance, the question of their applicability and reliability remains unresolved. This study aims to utilize image processing and deep learning methodologies to achieve state-of-the-art results for the detection of Acute Lymphoblastic Leukemia (ALL) using data that best represents real-world scenarios. ALL is one of several types of blood cancer, and it is an aggressive form of leukemia. In this investigation, we examine the most recent advancements in ALL detection, as well as the latest iteration of the YOLO series and its performance. We address the question of whether white blood cells are malignant or benign. Additionally, the proposed models can identify different ALL stages, including early stages. Furthermore, these models can detect hematogones despite their frequent misclassification as ALL. By utilizing advanced deep learning models, namely, YOLOv8, YOLOv11, ResNet50 and Inception-ResNet-v2, the study achieves accuracy rates as high as 99.7%, demonstrating the effectiveness of these algorithms across multiple datasets and various real-world situations.

Paper number 10:
Title: Towards Patient-Specific Surgical Planning for Bicuspid Aortic Valve Repair: Fully Automated Segmentation of the Aortic Valve in 4D CT
Authors: Zaiyang Guo, Ningjun J Dong, Harold Litt, Natalie Yushkevich, Melanie Freas, Jessica Nunez, Victor Ferrari, Jilei Hao, Shir Goldfinger, Matthew A. Jolley, Joseph Bavaria, Nimesh Desai, Alison M. Pouch
Abstract: The bicuspid aortic valve (BAV) is the most prevalent congenital heart defect and may require surgery for complications such as stenosis, regurgitation, and aortopathy. BAV repair surgery is effective but challenging due to the heterogeneity of BAV morphology. Multiple imaging modalities can be employed to assist the quantitative assessment of BAVs for surgical planning. Contrast-enhanced 4D computed tomography (CT) produces volumetric temporal sequences with excellent contrast and spatial resolution. Segmentation of the aortic cusps and root in these images is an essential step in creating patient specific models for visualization and quantification. While deep learning-based methods are capable of fully automated segmentation, no BAV-specific model exists. Among valve segmentation studies, there has been limited quantitative assessment of the clinical usability of the segmentation results. In this work, we developed a fully auto- mated multi-label BAV segmentation pipeline based on nnU-Net. The predicted segmentations were used to carry out surgically relevant morphological measurements including geometric cusp height, commissural angle and annulus diameter, and the results were compared against manual segmentation. Automated segmentation achieved average Dice scores of over 0.7 and symmetric mean distance below 0.7 mm for all three aortic cusps and the root wall. Clinically relevant benchmarks showed good consistency between manual and predicted segmentations. Overall, fully automated BAV segmentation of 3D frames in 4D CT can produce clinically usable measurements for surgical risk stratification, but the temporal consistency of segmentations needs to be improved.

Paper number 11:
Title: Safe Reinforcement Learning-based Control for Hydrogen Diesel Dual-Fuel Engines
Authors: Vasu Sharma, Alexander Winkler, Armin Norouzi, Jakob Andert, David Gordon, Hongsheng Guo
Abstract: The urgent energy transition requirements towards a sustainable future stretch across various industries and are a significant challenge facing humanity. Hydrogen promises a clean, carbon-free future, with the opportunity to integrate with existing solutions in the transportation sector. However, adding hydrogen to existing technologies such as diesel engines requires additional modeling effort. Reinforcement Learning (RL) enables interactive data-driven learning that eliminates the need for mathematical modeling. The algorithms, however, may not be real-time capable and need large amounts of data to work in practice. This paper presents a novel approach which uses offline model learning with RL to demonstrate safe control of a 4.5 L Hydrogen Diesel Dual-Fuel (H2DF) engine. The controllers are demonstrated to be constraint compliant and can leverage a novel state-augmentation approach for sample-efficient learning. The offline policy is subsequently experimentally validated on the real engine where the control algorithm is executed on a Raspberry Pi controller and requires 6 times less computation time compared to online Model Predictive Control (MPC) optimization.

Paper number 12:
Title: Joint Beamforming and Antenna Position Optimization for Multi-user Position-Reconfigurable Full-Duplex MIMO Systems
Authors: Chengjie Zhao, Tho Le-Ngoc
Abstract: Fluid antenna system (FAS) or movable antenna system (MAS) is an emerging antenna design technique that can fully exploit the wireless channel spatial variation and consequently improve the communication performance, both in terms of achievable rate and hardware cost, via relocating the positions of antennas in a confined region. Full-duplex (FD) communication enables simultaneous transmission and reception over the same time and frequency resource block, which theoretically double the spectral efficiency. The integration of FAS/MAS and FD communication is expected to greatly improve the system capacity and save the spectral and hardware resources.

Paper number 13:
Title: Compressive Sensing Empirical Wavelet Transform for Frequency-Banded Power Measurement Considering Interharmonics
Authors: Jian Liu, Wei Zhao, Shisong Li
Abstract: Power measurement algorithms based on Fourier transform are susceptible to errors caused by interharmonics, while wavelet transform algorithms are particularly sensitive to even harmonics due to band decomposition effects. The empirical wavelet transform (EWT) has been demonstrated to improve measurement accuracy by effectively partitioning transition bands. However, for detecting interharmonic components, the limitation of the observation time window restricts spectral resolution, thereby limiting measurement accuracy. To address this challenge, this paper proposes a Compressive Sensing Empirical Wavelet Transform (CSEWT). The approach aims to enhance frequency resolution by integrating compressive sensing with the EWT, allowing precise identification of components across different frequency bands. This enables accurate determination of the power associated with the fundamental frequency, harmonics, and interharmonics. Test results indicate that the proposed CSEWT method can significantly improve the precision of individual frequency component measurements, even under dynamic and noisy conditions.

Paper number 14:
Title: Port-LLM: A Port Prediction Method for Fluid Antenna based on Large Language Models
Authors: Yali Zhang, Haifan Yin, Weidong Li, Emil Bjornson, Merouane Debbah
Abstract: The objective of this study is to address the mobility challenges faced by User Equipment (UE) through the implementation of fluid antenna (FA) on the UE side. This approach aims to maintain the time-varying channel in a relatively stable state by strategically relocating the FA to an appropriate port. To the best of our knowledge, this paper introduces, for the first time, the application of large language models (LLMs) in the prediction of FA ports, presenting a novel model termed Port-LLM. The proposed method consists of two primary steps for predicting the moving port of the FA: the first involves utilizing the channel tables that encompass historical channel state information from all movable ports of the FA to forecast the channel tables for subsequent time periods; the second step entails selecting the port of the FA for the forthcoming time based on the predicted channel tables and the known reference channels that require alignment. To enhance the learning capabilities of the LLM model in the context of FA port prediction, we incorporate the Low-Rank Adaptation (LoRA) fine-tuning technology. Furthermore, during the model training phase, we implement the warm-up-aided cosine learning rate (LR) technique to augment the accuracy of the predictions. The simulation results show that our model exhibits strong generalization ability and robustness under different numbers of base station antennas and medium-to-high mobility speeds of UE. In comparison to existing FA port calculation methods, the performance of the port predicted by our model demonstrates superior efficacy. Additionally, our model exhibits lower prediction costs and faster prediction and reasoning speeds.

Paper number 15:
Title: Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT System for the DASR Task of the CHiME-8 Challenge
Authors: Naoyuki Kamo, Naohiro Tawara, Atsushi Ando, Takatomo Kano, Hiroshi Sato, Rintaro Ikeshita, Takafumi Moriya, Shota Horiguch, Kohei Matsuura, Atsunori Ogawa, Alexis Plaquet, Takanori Ashihara, Tsubasa Ochiai, Masato Mimura, Marc Delcroix, Tomohiro Nakatani, Taichi Asami, Shoko Araki
Abstract: In this paper, we introduce a multi-talker distant automatic speech recognition (DASR) system we designed for the DASR task 1 of the CHiME-8 challenge. Our system performs speaker counting, diarization, and ASR. It handles various recording conditions, from diner parties to professional meetings and from two to eight speakers. We perform diarization first, followed by speech enhancement, and then ASR as the challenge baseline. However, we introduced several key refinements. First, we derived a powerful speaker diarization relying on end-to-end speaker diarization with vector clustering (EEND-VC), multi-channel speaker counting using enhanced embeddings from EEND-VC, and target-speaker voice activity detection (TS-VAD). For speech enhancement, we introduced a novel microphone selection rule to better select the most relevant microphones among the distributed microphones and investigated improvements to beamforming. Finally, for ASR, we developed several models exploiting Whisper and WavLM speech foundation models. We present the results we submitted to the challenge and updated results we obtained afterward. Our strongest system achieves a 63% relative macro tcpWER improvement over the baseline and outperforms the challenge best results on the NOTSOFAR-1 meeting evaluation data among geometry-independent systems.

Paper number 16:
Title: Stretching Rubber, Not Budgets: Accurate Parking Utilization on a Shoestring
Authors: Christopher K. Allsup
Abstract: Effective parking management is essential for ensuring accessibility, safety, and convenience in master-planned communities, particularly in active adult neighborhoods experiencing rapid growth. Accurately assessing parking utilization is a crucial first step in planning for future demand, but data collection methods can be costly and labor-intensive. This paper presents a low-cost yet highly accurate methodology for measuring parking utilization using road tubes connected to portable traffic counters from JAMAR Technologies, Inc. By integrating results from JAMAR's analysis tool with custom Python scripting, the methodology enables precise parking lot counts through parameter optimization and automated error correction. The system's efficiency allows for scalable deployment without significant manual observation, reducing both costs and disruptions to daily operations. Using Tellico Village as a case study, this research demonstrates that community planners can obtain actionable parking insights on a limited budget, empowering them to make informed decisions about capacity expansion, traffic flow improvements, and facility scheduling. The findings underscore the feasibility of leveraging cost-effective technology to optimize infrastructure planning and ensure long-term resident satisfaction as communities grow.

Paper number 17:
Title: Low-Complexity On-Grid Channel Estimation for Partially-Connected Hybrid XL-MIMO
Authors: Sunho Kim, Wan Choi
Abstract: This paper addresses the challenge of channel estimation in extremely large-scale multiple-input multiple-output (XL-MIMO) systems, pivotal for the advancement of 6G communications. XL-MIMO systems, characterized by their vast antenna arrays, necessitate accurate channel state information (CSI) to leverage high spatial multiplexing and beamforming gains. However, conventional channel estimation methods for near-field XL-MIMO encounter significant computational complexity due to the exceedingly high parameter quantization levels needed for estimating the parametric near-field channel. To address this, we propose a low-complexity two-stage on-grid channel estimation algorithm designed for near-field XL-MIMO systems. The first stage focuses on estimating the LoS channel component while treating the NLoS paths as interference. This estimation is accomplished through an alternating subarray-wise array gain maximization (ASAGM) approach based on the piecewise outer product model (SOPM). In the second stage, we estimate the NLoS channel component by utilizing the sensing matrix refinement-based orthogonal matching pursuit (SMR-OMP) algorithm. This approach helps reduce the high computational complexity associated with large-dimensional joint sensing matrices. Simulation results demonstrate the effectiveness of our proposed low-complexity method, showcasing its significant superiority over existing near-field XL-MIMO channel estimation techniques, particularly in intermediate and high SNR regimes, and in practical scenarios involving arbitrary array placements.

Paper number 18:
Title: Recovering nonlinear dynamics from non-uniform observations: A physics-based identification approach with practical case studies
Authors: Cesare Donati, Martina Mammarella, Fabrizio Dabbene, Carlo Novara, Constantino Lagoa
Abstract: Uniform and smooth data collection is often infeasible in real-world scenarios. In this paper, we propose an identification framework to effectively handle the so-called non-uniform observations, i.e., data scenarios that include missing measurements, multiple runs, or aggregated observations. The goal is to provide a general approach for accurately recovering the overall dynamics of possibly nonlinear systems, allowing the capture of the system behavior over time from non-uniform observations. The proposed approach exploits prior knowledge by integrating domain-specific, interpretable, physical principles with black-box approximators, proving significant flexibility and adaptability in handling different types of non-uniform measurements, and addressing the limitations of traditional linear and black-box methods. The description of this novel framework is supported by a theoretical study on the effect of non-uniform observations on the accuracy of parameter estimation. Specifically, we demonstrate the existence of upper bounds on the parametric error resulting from missing measurements and aggregated observations. Then, the effectiveness of the approach is demonstrated through two case studies. These include a practical application with missing samples, i.e., the identification of a continuous stirred-tank reactor using real data, and a simulated Lotka-Volterra system under aggregated observations. The results highlight the ability of the framework to robustly estimate the system parameters and to accurately reconstruct the model dynamics despite the availability of non-uniform measurements.

Paper number 19:
Title: LifeSaver: Predictive Load Limit Estimation for Transport Vehicles in Hilly Areas
Authors: Chanakya Rao, Vaibhav Chopra, Moksh Soni, Prashant Mishra
Abstract: The transportation of essential goods in moun- tainous regions faces severe logistical challenges and frequent disruptions. To mitigate these difficulties, transport companies often overload trucks, which, though cost-saving, significantly heightens the risk of accidents and mechanical failures. This paper presents the development of a device that detects over- loaded and insecurely fastened loads on trucks and commercial vehicles. Using advanced load sensors, the device offers real- time monitoring of cargo weight distribution, alerting drivers and authorities to unsafe conditions. The initial prototype utilised two basic load cells and an Arduino microcontroller. The second version was enhanced with four load cells and extended sensors. This version was tested by placing an electric golf cart onto the prototype. Various loads were then added to the cart in different orientations to assess whether the system could accurately detect improper or excessive load conditions.

Paper number 20:
Title: Near-Field Localization with Physics-Compliant Electromagnetic Model: Algorithms and Model Mismatch Analysis
Authors: Alexandr M. Kuzminskiy, Ahmed Elzanaty, Gabriele Gradoni, Fan Wang, Rahim Tafazolli
Abstract: Accurate signal localization is critical for Internet of Things applications, but precise propagation models are often unavailable due to uncontrollable factors. Simplified models such as planar and spherical wavefront approximations are widely used but can cause model mismatches that reduce accuracy. To address this, we propose an expected likelihood ratio framework for model mismatch analysis and online model selection without requiring knowledge of the true propagation model. The framework leverages the scenario independent distribution of the likelihood ratio of the actual covariance matrix, enabling the detection of mismatches and outliers by comparing given models to a predefined distribution. When an accurate electromagnetic model is unavailable, the robustness of the framework is analyzed using data generated from a precise electromagnetic model and simplified models within positioning algorithms. Validation in direct localization and reconfigurable intelligent surface assisted scenarios demonstrates the ability to improve localization accuracy and reliably detect model mismatches in diverse Internet of Things environments.

Paper number 21:
Title: Physics-Informed Generative Modeling of Wireless Channels
Authors: Benedikt Böck, Andreas Oeldemann, Timo Mayer, Francesco Rossetto, Wolfgang Utschick
Abstract: Learning the distribution of the wireless channel within a specific environment of interest is essential to exploit the full potential of machine learning (ML) for wireless communications and radar applications. Generative modeling offers a promising framework to address this problem. However, existing approaches pose unresolved challenges, including the need for high-quality training data, limited generalizability, and a lack of physical interpretability. To address these issues, we propose a model that combines the physics-related compressibility of wireless channels with sparse Bayesian generative modeling (SBGM) to learn the distribution of the underlying physical channel parameters. By leveraging the sparsity-inducing characteristics of SBGM, our method can learn from compressed observations received by an access point (AP) during default online operation. Moreover, it is physically interpretable and generalizes to arbitrary system configurations without requiring retraining.

Paper number 22:
Title: Safe platooning control of connected and autonomous vehicles on curved multi-lane roads
Authors: Xiao Chen, Zhiqi Tang, Karl Henrik Johansson, Jonas Mårtensson
Abstract: This paper investigates the safe platoon formation tracking and merging control problem of connected and automated vehicles (CAVs) on curved multi-lane roads. The first novelty is the separation of the control designs into two distinct parts: a lateral control law that ensures a geometrical convergence towards the reference path regardless of the translational velocity, and a longitudinal control design for each vehicle to achieve the desired relative arc length and velocity with respect to its neighboring vehicle. The second novelty is exploiting the constructive barrier feedback as an additive term to the nominal tracking control, ensuring both lateral and longitudinal collision avoidance. This constructive barrier feedback acts as a dissipative term, slowing down the relative velocity toward obstacles without affecting the nominal controller's performance. Consequently, our proposed control method enables safe platoon formation of vehicles on curved multi-lane roads, with theoretical guarantees for safety invariance and stability analysis. Simulation and experimental results on connected vehicles are provided to further validate the effectiveness of the proposed method.

Paper number 23:
Title: Reinforcement Learning based Constrained Optimal Control: an Interpretable Reward Design
Authors: Jingjie Ni, Fangfei Li, Xin Jin, Xianlun Peng, Yang Tang
Abstract: This paper presents an interpretable reward design framework for reinforcement learning based constrained optimal control problems with state and terminal constraints. The problem is formalized within a standard partially observable Markov decision process framework. The reward function is constructed from four weighted components: a terminal constraint reward, a guidance reward, a penalty for state constraint violations, and a cost reduction incentive reward. A theoretically justified reward design is then presented, which establishes bounds on the weights of the components. This approach ensures that constraints are satisfied and objectives are optimized while mitigating numerical instability. Acknowledging the importance of prior knowledge in reward design, we sequentially solve two subproblems, using each solution to inform the reward design for the subsequent problem. Subsequently, we integrate reinforcement learning with curriculum learning, utilizing policies derived from simpler subproblems to assist in tackling more complex challenges, thereby facilitating convergence. The framework is evaluated against original and randomly weighted reward designs in a multi-agent particle environment. Experimental results demonstrate that the proposed approach significantly enhances satisfaction of terminal and state constraints and optimization of control cost.

Paper number 24:
Title: Optimal and Coordinated Voltage Control: Case Study on a 132 kV Norwegian Grid Subsystem
Authors: Hugo Rodrigues de Brito, Daniel Simon Baltensperger, Kjetil Obstfelder Uhlen
Abstract: This work presents a framework for dynamic performance assessment of the higher layers in the hierarchical voltage regulation scheme, with case studies applied to specific areas of the Norwegian grid. Unlike the primary (PVR) level, the secondary (SVR) and tertiary (TVR) levels are not tuned to a single device at a time, handling instead several reactive power resources available within a control zone including generator units, static VAr compensators and others. Proper SVR-TVR coordination for realistic transmission systems is a challenging topic at the core of many ongoing discussions in voltage control literature. Special focus is placed on practical considerations from the system operator perspective, since this research is also aimed at simplifying daily control centre routines. Dynamic simulation results concern a 21-bus equivalent of a 132 kV network model that accurately represents a Norwegian grid subsystem. Case studies address daily grid operation with real-life load demand and wind power generation profiles, showing that the proposed strategy is effective not only to minimize total active power losses as much as possible within system-wide limitations, but also to maintain adequate voltage profiles and reactive power flows. Findings pertaining to this work showcase the benefits of applying hierarchical voltage regulation layers as an asset to day-to-day control center management of a realistic transmission network.

Paper number 25:
Title: Safety Blind Spot in Remote Driving: Considerations for Risk Assessment of Connection Loss Fallback Strategies
Authors: Leon Johann Brettin, Niklas Braun, Robert Graubohm, Markus Maurer
Abstract: As part of the overall goal of driverless road vehicles, remote driving is a major emerging field of research of its own. Current remote driving concepts for public road traffic often establish a fallback strategy of immediate braking to a standstill in the event of a connection loss. This may seem like the most logical option when human control of the vehicle is lost. However, our simulation results from hundreds of scenarios based on naturalistic traffic scenes indicate high collision rates for any immediate substantial deceleration to a standstill in urban settings. We show that such a fallback strategy can result in a SOTIF relevant hazard, making it questionable whether such a design decision can be considered acceptable. Therefore, from a safety perspective, we would call this problem a safety blind spot, as safety analyses in this regard seem to be very rare. In this article, we first present a simulation on a naturalistic dataset that shows a high probability of collision in the described case. Second, we discuss the severity of the resulting potential rear-end collisions and provide an even more severe example by including a large commercial vehicle in the potential collision.

Paper number 26:
Title: Optimized Strategies for Peak Shaving and BESS Efficiency Enhancement through Cycle-Based Control and Cluster-Level Power Allocation
Authors: Guo Gan, Li Junhui, Mu Gang, Yan Gangui
Abstract: Battery Energy Storage Systems (BESS) are essential for peak shaving, balancing power supply and demand while enhancing grid efficiency. This study proposes a cycle-based control strategy for charging and discharging, which optimizes capture rate (CR), release rate (RR), and capacity utilization rate (CUR), improving BESS performance. Compared to traditional day-ahead methods, the cycle-based approach enhances operational accuracy and reduces capacity waste, achieving a CUR increase from 75.1% to 79.9%. An innovative cluster-level power allocation method, leveraging an improved Particle Swarm Optimization (PSO) algorithm, is introduced. This strategy reduces daily energy loss by 174.21 kWh (3.7%) and increases BESS efficiency by 0.4%. Transient and steady-state energy loss components are analyzed, revealing that transient loss proportion decreases significantly as power depth increases, from 27.2% at 1 MW to 1.3% at 10 MW. Simulations based on a detailed Simulink/Simscape model validate these methods, demonstrating enhanced peak shaving effectiveness and prolonged BESS lifespan by reducing equivalent cycles. The study provides a robust framework for optimizing BESS performance and efficiency in real-world applications.

Paper number 27:
Title: SegX: Improving Interpretability of Clinical Image Diagnosis with Segmentation-based Enhancement
Authors: Yuhao Zhang, Mingcheng Zhu, Zhiyao Luo
Abstract: Deep learning-based medical image analysis faces a significant barrier due to the lack of interpretability. Conventional explainable AI (XAI) techniques, such as Grad-CAM and SHAP, often highlight regions outside clinical interests. To address this issue, we propose Segmentation-based Explanation (SegX), a plug-and-play approach that enhances interpretability by aligning the model's explanation map with clinically relevant areas leveraging the power of segmentation models. Furthermore, we introduce Segmentation-based Uncertainty Assessment (SegU), a method to quantify the uncertainty of the prediction model by measuring the 'distance' between interpretation maps and clinically significant regions. Our experiments on dermoscopic and chest X-ray datasets show that SegX improves interpretability consistently across mortalities, and the certainty score provided by SegU reliably reflects the correctness of the model's predictions. Our approach offers a model-agnostic enhancement to medical image diagnosis towards reliable and interpretable AI in clinical decision-making.

Paper number 28:
Title: Analysis and Prediction of Coverage and Channel Rank for UAV Networks in Rural Scenarios with Foliage
Authors: Donggu Lee, Ozgur Ozdemir, Asokan Ram, Ismail Guvenc
Abstract: Unmanned aerial vehicles (UAVs) are expected to play a key role in 6G-enabled vehicular-to-everything (V2X) communications requiring high data rates, low latency, and reliable connectivity for mission-critical applications. Multi-input multi-output (MIMO) technology is essential for meeting these demands. However, UAV link performance is significantly affected by environmental factors such as signal attenuation, multipath propagation, and blockage from obstacles, particularly dense foliage in rural areas. In this paper, we investigate RF coverage and channel rank over UAV channels in foliage-dominated rural environments using ray tracing (RT) simulations. We conduct RT-based channel rank and RF coverage analysis over Lake Wheeler Field Labs at NC State University to examine the impact on UAV links. Custom-modeled trees are integrated into the RT simulations using NVIDIA Sionna, Blender, and Open Street Map (OSM) database to capture realistic blockage effects. Results indicate that tree-induced blockage impacts RF coverage and channel rank at lower UAV altitudes. We also propose a Kriging interpolation-based 3D channel rank interpolation scheme, leveraging the observed spatial correlation of channel rank in the given environments. The accuracy of the proposed scheme is evaluated using the mean absolute error (MAE) metric and compared against baseline interpolation methods. Finally, we compare the RT-based received signal strength (RSS) and channel rank results with real-world measurements from the NSF AERPAW testbed demonstrating reasonable consistency between simulation results and the measurements.

Paper number 29:
Title: Decentralized State Estimation and Opacity Verification Based on Partially Ordered Observation Sequences
Authors: Dajiang Sun, Christoforos N. Hadjicostis, Zhiwu Li
Abstract: In this paper, we investigate state estimation and opacity verification problems within a decentralized observation architecture. Specifically, we consider a discrete event system whose behavior is recorded by a set of observation sites. These sites transmit the partially ordered sequences of observations that they record to a coordinator whenever a \textit{synchronization} occurs. To properly analyze the system behavior from the coordinator's viewpoint, we first introduce the notion of an \textit{All Sequence Structure} (ASS), which concisely captures the state evolution of each system state upon different information provided by the observation sites. Based on the ASS, we then construct corresponding current-state and initial-state estimators for offline state estimation at the coordinator. When used to verify state-isolation properties under this decentralized architecture, the use of ASS demonstrates a significant reduction in complexity compared with existing approaches in the literature. In particular, we discuss how to verify initial-state opacity at the coordinator, as well as a novel opacity notion, namely current-state-at-synchronization opacity.

Paper number 30:
Title: CISSIR: Beam Codebooks with Self-Interference Reduction Guarantees for Integrated Sensing and Communication Beyond 5G
Authors: Rodrigo Hernangómez, Jochen Fink, Renato L. G. Cavalcante, Sławomir Stańczak
Abstract: We propose a beam codebook design to reduce self-interference (SI) in integrated sensing and communication (ISAC) systems. Our optimization methods, which can be applied to both tapered beamforming and phased arrays, adapt the codebooks to the SI channel such that a certain SI level is achieved. Furthermore, we derive an upper bound on the quantization noise in terms of the achieved SI level, which provides guidelines to pose the optimization problem in order to obtain performance guarantees for sensing. By selecting standard reference codebooks in our simulations, we show substantially improved sensing quality with little impact on 5G-NR communication. Our proposed method is not only less dependent on hyperparameters than other approaches in the literature, but it can also reduce SI further, and thus deliver better sensing and communication performance.

Paper number 31:
Title: Multi-Omics Fusion with Soft Labeling for Enhanced Prediction of Distant Metastasis in Nasopharyngeal Carcinoma Patients after Radiotherapy
Authors: Jiabao Sheng, SaiKit Lam, Jiang Zhang, Yuanpeng Zhang, Jing Cai
Abstract: Omics fusion has emerged as a crucial preprocessing approach in the field of medical image processing, providing significant assistance to several studies. One of the challenges encountered in the integration of omics data is the presence of unpredictability arising from disparities in data sources and medical imaging equipment. In order to overcome this challenge and facilitate the integration of their joint application to specific medical objectives, this study aims to develop a fusion methodology that mitigates the disparities inherent in omics data. The utilization of the multi-kernel late-fusion method has gained significant popularity as an effective strategy for addressing this particular challenge. An efficient representation of the data may be achieved by utilizing a suitable single-kernel function to map the inherent features and afterward merging them in a space with a high number of dimensions. This approach effectively addresses the differences noted before. The inflexibility of label fitting poses a constraint on the use of multi-kernel late-fusion methods in complex nasopharyngeal carcinoma (NPC) datasets, hence affecting the efficacy of general classifiers in dealing with high-dimensional characteristics. This innovative methodology aims to increase the disparity between the two cohorts, hence providing a more flexible structure for the allocation of labels. The examination of the NPC-ContraParotid dataset demonstrates the model's robustness and efficacy, indicating its potential as a valuable tool for predicting distant metastases in patients with nasopharyngeal carcinoma (NPC).

Paper number 32:
Title: Towards Fine-grained Interactive Segmentation in Images and Videos
Authors: Yuan Yao, Qiushi Yang, Miaomiao Cui, Liefeng Bo
Abstract: The recent Segment Anything Models (SAMs) have emerged as foundational visual models for general interactive segmentation. Despite demonstrating robust generalization abilities, they still suffer performance degradations in scenarios demanding accurate masks. Existing methods for high-precision interactive segmentation face a trade-off between the ability to perceive intricate local details and maintaining stable prompting capability, which hinders the applicability and effectiveness of foundational segmentation models. To this end, we present an SAM2Refiner framework built upon the SAM2 backbone. This architecture allows SAM2 to generate fine-grained segmentation masks for both images and videos while preserving its inherent strengths. Specifically, we design a localization augment module, which incorporates local contextual cues to enhance global features via a cross-attention mechanism, thereby exploiting potential detailed patterns and maintaining semantic information. Moreover, to strengthen the prompting ability toward the enhanced object embedding, we introduce a prompt retargeting module to renew the embedding with spatially aligned prompt features. In addition, to obtain accurate high resolution segmentation masks, a mask refinement module is devised by employing a multi-scale cascaded structure to fuse mask features with hierarchical representations from the encoder. Extensive experiments demonstrate the effectiveness of our approach, revealing that the proposed method can produce highly precise masks for both images and videos, surpassing state-of-the-art methods.

Paper number 33:
Title: SIToBI - A Speech Prosody Annotation Tool for Indian Languages
Authors: Preethi Thinakaran, Malarvizhi Muthuramalingam, Sooriya S, Anushiya Rachel Gladston, P. Vijayalakshmi, Hema A Murthy, T. Nagarajan
Abstract: The availability of prosodic information from speech signals is useful in a wide range of applications. However, deriving this information from speech signals can be a laborious task involving manual intervention. Therefore, the current work focuses on developing a tool that can provide prosodic annotations corresponding to a given speech signal, particularly for Indian languages. The proposed Segmentation with Intensity, Tones and Break Indices (SIToBI) tool provides time-aligned phoneme, syllable, and word transcriptions, syllable-level pitch contour annotations, break indices, and syllable-level relative intensity indices. The tool focuses more on syllable-level annotations since Indian languages are syllable-timed. Indians, regardless of the language they speak, may exhibit influences from other languages. As a result, other languages spoken in India may also exhibit syllable-timed characteristics. The accuracy of the annotations derived from the tool is analyzed by comparing them against manual annotations and the tool is observed to perform well. While the current work focuses on three languages, namely, Tamil, Hindi, and Indian English, the tool can easily be extended to other Indian languages and possibly other syllable-timed languages as well.

Paper number 34:
Title: Generalizable Cervical Cancer Screening via Large-scale Pretraining and Test-Time Adaptation
Authors: Hao Jiang, Cheng Jin, Huangjing Lin, Yanning Zhou, Xi Wang, Jiabo Ma, Li Ding, Jun Hou, Runsheng Liu, Zhizhong Chai, Luyang Luo, Huijuan Shi, Yinling Qian, Qiong Wang, Changzhong Li, Anjia Han, Ronald Cheong Kin Chan, Hao Chen
Abstract: Cervical cancer is a leading malignancy in female reproductive system. While AI-assisted cytology offers a cost-effective and non-invasive screening solution, current systems struggle with generalizability in complex clinical scenarios. To address this issue, we introduced Smart-CCS, a generalizable Cervical Cancer Screening paradigm based on pretraining and adaptation to create robust and generalizable screening systems. To develop and validate Smart-CCS, we first curated a large-scale, multi-center dataset named CCS-127K, which comprises a total of 127,471 cervical cytology whole-slide images collected from 48 medical centers. By leveraging large-scale self-supervised pretraining, our CCS models are equipped with strong generalization capability, potentially generalizing across diverse scenarios. Then, we incorporated test-time adaptation to specifically optimize the trained CCS model for complex clinical settings, which adapts and refines predictions, improving real-world applicability. We conducted large-scale system evaluation among various cohorts. In retrospective cohorts, Smart-CCS achieved an overall area under the curve (AUC) value of 0.965 and sensitivity of 0.913 for cancer screening on 11 internal test datasets. In external testing, system performance maintained high at 0.950 AUC across 6 independent test datasets. In prospective cohorts, our Smart-CCS achieved AUCs of 0.947, 0.924, and 0.986 in three prospective centers, respectively. Moreover, the system demonstrated superior sensitivity in diagnosing cervical cancer, confirming the accuracy of our cancer screening results by using histology findings for validation. Interpretability analysis with cell and slide predictions further indicated that the system's decision-making aligns with clinical practice. Smart-CCS represents a significant advancement in cancer screening across diverse clinical contexts.

Paper number 35:
Title: Carbon- and Precedence-Aware Scheduling for Data Processing Clusters
Authors: Adam Lechowicz, Rohan Shenoy, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Christina Delimitrou
Abstract: As large-scale data processing workloads continue to grow, their carbon footprint raises concerns. Prior research on carbon-aware schedulers has focused on shifting computation to align with availability of low-carbon energy, but these approaches assume that each task can be executed independently. In contrast, data processing jobs have precedence constraints (i.e., outputs of one task are inputs for another) that complicate decisions, since delaying an upstream ``bottleneck'' task to a low-carbon period will also block downstream tasks, impacting the entire job's completion time. In this paper, we show that carbon-aware scheduling for data processing benefits from knowledge of both time-varying carbon and precedence constraints. Our main contribution is $\texttt{PCAPS}$, a carbon-aware scheduler that interfaces with modern ML scheduling policies to explicitly consider the precedence-driven importance of each task in addition to carbon. To illustrate the gains due to fine-grained task information, we also study $\texttt{CAP}$, a wrapper for any carbon-agnostic scheduler that adapts the key provisioning ideas of $\texttt{PCAPS}$. Our schedulers enable a configurable priority between carbon reduction and job completion time, and we give analytical results characterizing the trade-off between the two. Furthermore, our Spark prototype on a 100-node Kubernetes cluster shows that a moderate configuration of $\texttt{PCAPS}$ reduces carbon footprint by up to 32.9% without significantly impacting the cluster's total efficiency.

Paper number 36:
Title: Contracting Strategies for Electrolyzers to Secure Grid Connection: The Dutch Case
Authors: Thomas Swarts, Jalal Kazempour, Wouter van den Akker, Johan Morren, Arjan van Voorden, Han Slootweg
Abstract: In response to increasing grid congestion in the Netherlands, non-firm connection and transport agreements (CTAs) and capacity restriction contracts (CRCs) have been introduced, allowing consumer curtailment in exchange for grid tariff discounts or per-MW compensations. This study examines the interaction between an electrolyzer project, facing sizing and contracting decisions, and a network operator, responsible for contract activations and determining grid connection capacity, under the new Dutch regulations. The interaction is modeled using two bilevel optimization problems with alternating leader-follower roles. Results highlight a trade-off between CRC income and non-firm CTA tariff discounts, showing that voluntary congestion management by the network operator increases electrolyzer profitability at CRC prices below 10 euro per MW but reduces it at higher prices. Furthermore, the network operator benefits more from reacting to the electrolyzer owner's CTA decisions than from leading the interaction at CRC prices above 10 euro per MW. Ignoring the other party's optimization problem overestimates profits for both the network operator and the electrolyzer owner, emphasizing the importance of coordinated decision-making.

Paper number 37:
Title: Fast Inexact Bilevel Optimization for Analytical Deep Image Priors
Authors: Mohammad Sadegh Salehi, Tatiana A. Bubba, Yury Korolev
Abstract: The analytical deep image prior (ADP) introduced by Dittmer et al. (2020) establishes a link between deep image priors and classical regularization theory via bilevel optimization. While this is an elegant construction, it involves expensive computations if the lower-level problem is to be solved accurately. To overcome this issue, we propose to use adaptive inexact bilevel optimization to solve ADP problems. We discuss an extension of a recent inexact bilevel method called the method of adaptive inexact descent of Salehi et al.(2024) to an infinite-dimensional setting required by the ADP framework. In our numerical experiments we demonstrate that the computational speed-up achieved by adaptive inexact bilevel optimization allows one to use ADP on larger-scale problems than in the previous literature, e.g. in deblurring of 2D color images.

Paper number 38:
Title: Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models
Authors: Jin Hyun Park, Seyyed Ali Ayati, Yichen Cai
Abstract: The increasing prevalence of microphones in everyday devices and the growing reliance on online services have amplified the risk of acoustic side-channel attacks (ASCAs) targeting keyboards. This study explores deep learning techniques, specifically vision transformers (VTs) and large language models (LLMs), to enhance the effectiveness and applicability of such attacks. We present substantial improvements over prior research, with the CoAtNet model achieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement for keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via Zoom compared to previous benchmarks. We also evaluate transformer architectures and language models, with the best VT model matching CoAtNet's performance. A key advancement is the introduction of a noise mitigation method for real-world scenarios. By using LLMs for contextual understanding, we detect and correct erroneous keystrokes in noisy environments, enhancing ASCA performance. Additionally, fine-tuned lightweight language models with Low-Rank Adaptation (LoRA) deliver comparable performance to heavyweight models with 67X more parameters. This integration of VTs and LLMs improves the practical applicability of ASCA mitigation, marking the first use of these technologies to address ASCAs and error correction in real-world scenarios.

Paper number 39:
Title: Suture Thread Modeling Using Control Barrier Functions for Autonomous Surgery
Authors: Kimia Forghani, Suraj Raval, Lamar Mair, Axel Krieger, Yancy Diaz-Mercado
Abstract: Automating surgical systems enhances precision and safety while reducing human involvement in high-risk environments. A major challenge in automating surgical procedures like suturing is accurately modeling the suture thread, a highly flexible and compliant component. Existing models either lack the accuracy needed for safety critical procedures or are too computationally intensive for real time execution. In this work, we introduce a novel approach for modeling suture thread dynamics using control barrier functions (CBFs), achieving both realism and computational efficiency. Thread like behavior, collision avoidance, stiffness, and damping are all modeled within a unified CBF and control Lyapunov function (CLF) framework. Our approach eliminates the need to calculate complex forces or solve differential equations, significantly reducing computational overhead while maintaining a realistic model suitable for both automation and virtual reality surgical training systems. The framework also allows visual cues to be provided based on the thread's interaction with the environment, enhancing user experience when performing suture or ligation tasks. The proposed model is tested on the MagnetoSuture system, a minimally invasive robotic surgical platform that uses magnetic fields to manipulate suture needles, offering a less invasive solution for surgical procedures.

Paper number 40:
Title: Dual Control for Interactive Autonomous Merging with Model Predictive Diffusion
Authors: Jacob Knaup, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Panagiotis Tsiotras
Abstract: Interactive decision-making is essential in applications such as autonomous driving, where the agent must infer the behavior of nearby human drivers while planning in real-time. Traditional predict-then-act frameworks are often insufficient or inefficient because accurate inference of human behavior requires a continuous interaction rather than isolated prediction. To address this, we propose an active learning framework in which we rigorously derive predicted belief distributions. Additionally, we introduce a novel model-based diffusion solver tailored for online receding horizon control problems, demonstrated through a complex, non-convex highway merging scenario. Our approach extends previous high-fidelity dual control simulations to hardware experiments, which may be viewed at this https URL, and verifies behavior inference in human-driven traffic scenarios, moving beyond idealized models. The results show improvements in adaptive planning under uncertainty, advancing the field of interactive decision-making for real-world applications.

Paper number 41:
Title: Machine Learning for Phase Estimation in Satellite-to-Earth Quantum Communication
Authors: Nathan K Long, Robert Malaney, Kenneth J Grant
Abstract: A global continuous-variable quantum key distribution (CV-QKD) network can be established using a series of satellite-to-Earth channels. Increased performance in such a network is provided by performing coherent measurement of the optical quantum signals using a real local oscillator, calibrated locally by encoding known information on transmitted reference pulses and using signal phase error estimation algorithms. The speed and accuracy of the signal phase error estimation algorithm are vital to practical CV-QKD implementation. Our work provides a framework to analyze long short-term memory neural network (NN) architecture parameterization, with respect to the quantum Cramér-Rao uncertainty bound of the signal phase error estimation, with a focus on reducing the model complexity. More specifically, we demonstrate that signal phase error estimation can be achieved using a low-complexity NN architecture, without significantly sacrificing accuracy. Our results significantly improve the real-time performance of practical CV-QKD systems deployed over satellite-to-Earth channels, thereby contributing to the ongoing development of the Quantum Internet.

Paper number 42:
Title: A Preliminary Exploration with GPT-4o Voice Mode
Authors: Yu-Xiang Lin, Chih-Kai Yang, Wei-Chih Chen, Chen-An Li, Chien-yu Huang, Xuanjun Chen, Hung-yi Lee
Abstract: With the rise of multimodal large language models, GPT-4o stands out as a pioneering model, driving us to evaluate its capabilities. This report assesses GPT-4o across various tasks to analyze its audio processing and reasoning abilities. We find that GPT-4o exhibits strong knowledge in audio, speech, and music understanding, performing well in tasks like intent classification, spoken command classification, semantic and grammatical reasoning., multilingual speech recognition, and singing analysis. It also shows greater robustness against hallucinations than other large audio-language models (LALMs). However, it struggles with tasks such as audio duration prediction and instrument classification. Additionally, GPT-4o's safety mechanisms cause it to decline tasks like speaker identification, age classification, MOS prediction, and audio deepfake detection. Notably, the model exhibits a significantly different refusal rate when responding to speaker verification tasks on different datasets. This is likely due to variations in the accompanying instructions or the quality of the input audio, suggesting the sensitivity of its built-in safeguards. Finally, we acknowledge that model performance varies with evaluation protocols. This report only serves as a preliminary exploration of the current state of LALMs.

Paper number 43:
Title: InterGridNet: An Electric Network Frequency Approach for Audio Source Location Classification Using Convolutional Neural Networks
Authors: Christos Korgialas, Ioannis Tsingalis, Georgios Tzolopoulos, Constantine Kotropoulos
Abstract: A novel framework, called InterGridNet, is introduced, leveraging a shallow RawNet model for geolocation classification of Electric Network Frequency (ENF) signatures in the SP Cup 2016 dataset. During data preparation, recordings are sorted into audio and power groups based on inherent characteristics, further divided into 50 Hz and 60 Hz groups via spectrogram analysis. Residual blocks within the classification model extract frame-level embeddings, aiding decision-making through softmax activation. The topology and the hyperparameters of the shallow RawNet are optimized using a Neural Architecture Search. The overall accuracy of InterGridNet in the test recordings is 92%, indicating its effectiveness against the state-of-the-art methods tested in the SP Cup 2016. These findings underscore InterGridNet's effectiveness in accurately classifying audio recordings from diverse power grids, advancing state-of-the-art geolocation estimation methods.

Paper number 44:
Title: MTLM: an Innovative Language Model Training Paradigm for ASR
Authors: Qingliang Meng, Pengju Ren, Tian Li, Changsong Dai
Abstract: Pre-training Transformer-based language models (LMs) on a large amount of text has proven crucial for improving automatic speech recognition (ASR) performance. Generally, traditional LMs are unidirectional and unable to access the context on the right. This paper proposes a method for training LMs that enable traditional unidirectional LMs to fully utilize left and right contexts. Compared with the unidirectional LMs, our LM facilitates ASR to transcribe hypotheses more consistently and in a more semantically unambiguous way, as it incorporates richer contextual representations. Finally, our experimental results on the LibriSpeech corpus demonstrate that our model outperforms traditional unidirectional LMs, whether n-best rescoring or shallow fusion is used as the decoding algorithm.

Paper number 45:
Title: Coordinated control of multiple autonomous surface vehicles: challenges and advances - a systematic review
Authors: Manuel Gantiva Osorioa, Carmelina Ierardia, Isabel Jurado Floresa, Mario Pereira Martína, Pablo Millán Gata
Abstract: The increasing use and implementation of Autonomous Surface Vessels (ASVs) for various activities in maritime environments is expected to drive a rise in developments and research on their control. Particularly, the coordination of multiple ASVs presents novel challenges and opportunities, requiring interdisciplinary research efforts at the intersection of robotics, control theory, communication systems, and marine sciences. The wide variety of missions or objectives for which these vessels can be collectively used allows for the application and combination of different control techniques. This includes the exploration of machine learning to consider aspects previously deemed infeasible. This review provides a comprehensive exploration of coordinated ASV control while addressing critical gaps left by previous reviews. Unlike previous works, we adopt a systematic approach to ensure integrity and minimize bias in article selection. We delve into the complex world of sub-actuated ASVs with a focus on customized control strategies and the integration of machine learning techniques for increased autonomy. By synthesizing recent advances and identifying emerging trends, we offer insights that drive this field forward, providing both a comprehensive overview of state-of-the-art techniques and guidance for future research efforts.

Paper number 46:
Title: ELAA-ISAC: Environmental Mapping Utilizing the LoS State of Communication Channel
Authors: Jiuyu Liu, Chunmei Xu, Yi Ma, Rahim Tafazolli, Ahmed Elzanaty
Abstract: In this paper, a novel environmental mapping method is proposed to outline the indoor layout utilizing the line-of-sight (LoS) state information of extremely large aperture array (ELAA) channels. It leverages the spatial resolution provided by ELAA and the mobile terminal (MT)'s mobility to infer the presence and location of obstacles in the environment. The LoS state estimation is formulated as a binary hypothesis testing problem, and the optimal decision rule is derived based on the likelihood ratio test. Subsequently, the theoretical error probability of LoS estimation is derived, showing close alignment with simulation results. Then, an environmental mapping method is proposed, which progressively outlines the layout by combining LoS state information from multiple MT locations. It is demonstrated that the proposed method can accurately outline the environment layout, with the mapping accuracy improving as the number of service-antennas and MT locations increases. This paper also investigates the impact of channel estimation error and non-LoS (NLoS) components on the quality of environmental mapping. The proposed method exhibits particularly promising performance in LoS dominated wireless environments characterized by high Rician K-factor. Specifically, it achieves an average intersection over union (IoU) exceeding 80% when utilizing 256 service antennas and 18 MT locations.

Paper number 47:
Title: Strain-Induced Optical and Molecular Transformations in PET Films for Organic Electronic Applications
Authors: Mahya Ghorab, Ayush K. Ranga, Patrice Donfack, Arnulf Materny, Veit Wagner, Mojtaba Joodaki
Abstract: Poly(ethylene terephthalate) (PET) films are widely used in flexible electronics and optoelectronics, where their mechanical durability and optical performance under strain are essential for device reliability. This study investigates the impact of applied mechanical strain on the optical and molecular properties of PET at room temperature,using UV-Vis absorption and Raman spectroscopy. The work explores how varying strain levels, from 0% (unstretched) to 30%, affect the transparency, vibrational modes, and molecular reorganization within PET films. UV-Vis absorbance measurements reveal that strain induces significant changes in the light transmission properties of PET, particularly in the visible range, and increases absorption in the UVA and visible region by up to 100%. Raman spectra indicate that strain levels higher than 5% lead to irreversible shifts of vibrational lines, accompanied by an increase of their full width at half maximum (FWHM), suggesting molecular reorientation and crystallinity changes. The phonon mode coupled with C-O stretching [O-CH2] shows the strongest response to applied mechanical stress. This study provides a comprehensive understanding of strain-induced optical and structural alterations in PET, with implications for improving the mechanical and optical performance of PET-based devices in strainsensitive applications, such as organic solar cells (OSCs), organic light-emitting diodes (OLEDs), and flexible sensors.

Paper number 48:
Title: Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries
Authors: Serkan Sulun, Paula Viana, Matthew E. P. Davies
Abstract: We introduce EMSYNC, a video-based symbolic music generation model that aligns music with a video's emotional content and temporal boundaries. It follows a two-stage framework, where a pretrained video emotion classifier extracts emotional features, and a conditional music generator produces MIDI sequences guided by both emotional and temporal cues. We introduce boundary offsets, a novel temporal conditioning mechanism that enables the model to anticipate and align musical chords with scene cuts. Unlike existing models, our approach retains event-based encoding, ensuring fine-grained timing control and expressive musical nuances. We also propose a mapping scheme to bridge the video emotion classifier, which produces discrete emotion categories, with the emotion-conditioned MIDI generator, which operates on continuous-valued valence-arousal inputs. In subjective listening tests, EMSYNC outperforms state-of-the-art models across all subjective metrics, for music theory-aware participants as well as the general listeners.

Paper number 49:
Title: Technical Risks of (Lethal) Autonomous Weapons Systems
Authors: Heramb Podar, Alycia Colijn
Abstract: The autonomy and adaptability of (Lethal) Autonomous Weapons Systems, (L)AWS in short, promise unprecedented operational capabilities, but they also introduce profound risks that challenge the principles of control, accountability, and stability in international security. This report outlines the key technological risks associated with (L)AWS deployment, emphasizing their unpredictability, lack of transparency, and operational unreliability, which can lead to severe unintended consequences. Key Takeaways: 1. Proposed advantages of (L)AWS can only be achieved through objectification and classification, but a range of systematic risks limit the reliability and predictability of classifying algorithms. 2. These systematic risks include the black-box nature of AI decision-making, susceptibility to reward hacking, goal misgeneralization and potential for emergent behaviors that escape human control. 3. (L)AWS could act in ways that are not just unexpected but also uncontrollable, undermining mission objectives and potentially escalating conflicts. 4. Even rigorously tested systems may behave unpredictably and harmfully in real-world conditions, jeopardizing both strategic stability and humanitarian principles.

Paper number 50:
Title: Anomaly Detection with LWE Encrypted Control
Authors: Rijad Alisic, Junsoo Kim, Henrik Sandberg
Abstract: Detecting attacks using encrypted signals is challenging since encryption hides its information content. We present a novel mechanism for anomaly detection over Learning with Errors (LWE) encrypted signals without using decryption, secure channels, nor complex communication schemes. Instead, the detector exploits the homomorphic property of LWE encryption to perform hypothesis tests on transformations of the encrypted samples. The specific transformations are determined by solutions to a hard lattice-based minimization problem. While the test's sensitivity deteriorates with suboptimal solutions, similar to the exponential deterioration of the (related) test that breaks the cryptosystem, we show that the deterioration is polynomial for our test. This rate gap can be exploited to pick parameters that lead to somewhat weaker encryption but large gains in detection capability. Finally, we conclude the paper by presenting a numerical example that simulates anomaly detection, demonstrating the effectiveness of our method in identifying attacks.

Paper number 51:
Title: VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect
Authors: Qingyuan Fei, Wenjie Hou, Xuan Hai, Xin Liu
Abstract: The rapid advancements in AI voice cloning, fueled by machine learning, have significantly impacted text-to-speech (TTS) and voice conversion (VC) fields. While these developments have led to notable progress, they have also raised concerns about the misuse of AI VC technology, causing economic losses and negative public perceptions. To address this challenge, this study focuses on creating active defense mechanisms against AI VC systems. We propose a novel active defense method, VocalCrypt, which embeds pseudo-timbre (jamming information) based on SFS into audio segments that are imperceptible to the human ear, thereby forming systematic fragments to prevent voice cloning. This approach protects the voice without compromising its quality. In comparison to existing methods, such as adversarial noise incorporation, VocalCrypt significantly enhances robustness and real-time performance, achieving a 500\% increase in generation speed while maintaining interference effectiveness. Unlike audio watermarking techniques, which focus on post-detection, our method offers preemptive defense, reducing implementation costs and enhancing feasibility. Extensive experiments using the Zhvoice and VCTK Corpus datasets show that our AI-cloned speech defense system performs excellently in automatic speaker verification (ASV) tests while preserving the integrity of the protected audio.

Paper number 52:
Title: CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages
Authors: Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun
Abstract: CLaMP 3 is a unified framework developed to address challenges of cross-modal and cross-lingual generalization in music information retrieval. Using contrastive learning, it aligns all major music modalities--including sheet music, performance signals, and audio recordings--with multilingual text in a shared representation space, enabling retrieval across unaligned modalities with text as a bridge. It features a multilingual text encoder adaptable to unseen languages, exhibiting strong cross-lingual generalization. Leveraging retrieval-augmented generation, we curated M4-RAG, a web-scale dataset consisting of 2.31 million music-text pairs. This dataset is enriched with detailed metadata that represents a wide array of global musical traditions. To advance future research, we release WikiMT-X, a benchmark comprising 1,000 triplets of sheet music, audio, and richly varied text descriptions. Experiments show that CLaMP 3 achieves state-of-the-art performance on multiple MIR tasks, significantly surpassing previous strong baselines and demonstrating excellent generalization in multimodal and multilingual music contexts.

Paper number 53:
Title: OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models
Authors: William Chen, Jinchuan Tian, Yifan Peng, Brian Yan, Chao-Han Huck Yang, Shinji Watanabe
Abstract: Neural scaling laws offer valuable insights for designing robust sequence processing architectures. While these laws have been extensively characterized in other modalities, their behavior in speech remains comparatively underexplored. In this work, we introduce OWLS, an open-access, reproducible suite of multilingual speech recognition and translation models spanning 0.25B to 18B parameters, with the 18B version being the largest speech model, to the best of our knowledge. OWLS leverages up to 360K hours of public speech data across 150 languages, enabling a systematic investigation into how data, model, and compute scaling each influence performance in multilingual speech tasks. We use OWLS to derive neural scaling laws, showing how final performance can be reliably predicted when scaling. One of our key findings is that scaling enhances performance on low-resource languages/dialects, helping to mitigate bias and improve the accessibility of speech technologies. Finally, we show how OWLS can be used to power new research directions by discovering emergent abilities in large-scale speech models. Model checkpoints will be released on this https URL for future studies.

Paper number 54:
Title: SNR/CRB-Constrained Joint Beamforming and Reflection Designs for RIS-ISAC Systems
Authors: Rang Liu, Ming Li, Qian Liu, A. Lee Swindlehurst
Abstract: In this paper, we investigate the integration of integrated sensing and communication (ISAC) and reconfigurable intelligent surfaces (RIS) for providing wide-coverage and ultra-reliable communication and high-accuracy sensing functions. In particular, we consider an RIS-assisted ISAC system in which a multi-antenna base station (BS) simultaneously performs multi-user multi-input single-output (MU-MISO) communications and radar sensing with the assistance of an RIS. We focus on both target detection and parameter estimation performance in terms of the signal-to-noise ratio (SNR) and Cramer-Rao bound (CRB), respectively. Two optimization problems are formulated for maximizing the achievable sum-rate of the multi-user communications under an SNR constraint for target detection or a CRB constraint for parameter estimation, the transmit power budget, and the unit-modulus constraint of the RIS reflection coefficients. Efficient algorithms are developed to solve these two complicated non-convex problems. Extensive simulation results demonstrate the advantages of the proposed joint beamforming and reflection designs compared with other schemes. In addition, it is shown that more RIS reflection elements bring larger performance gains for direct-of-arrival (DoA) estimation than for target detection.

Paper number 55:
Title: Experiencing Urban Air Mobility: How Passengers evaluate a simulated flight with an Air Taxi
Authors: Anne Papenfuss, Maria Stolz, Nele Riedesel, Franziska Dunkel, Johannes Maria Ernst, Tim Laudien, Helge Lenz, Aytek Korkmaz, Albert End, Bianca Isabella Schuchardt
Abstract: For the successful development and implementation of novel concepts and technology, the acceptance of potential users is crucial. Therefore, within the project HorizonUAM of the German Aerospace Center (DLR), we investigated passengers' acceptance of air taxis. One challenge is that not many people have real experiences with urban air mobility (UAM) at the moment and thus requirements formulated by potential users refer to rather abstract concepts. To allow participants to gain realistic impressions of UAM concepts, a Mixed Reality (MR) Air Taxi Simulator was set up. In a study, 30 participants experienced an inner-city business shuttle flight. We assessed the influence of another person on board on wellbeing and information needs in nominal (experiment 1) and non-nominal situations (experiment 2). For the latter, participants experienced a re-routing of the flight due to landing side unavailability. During and after the flights, participants answered questionnaires and extensive interviews were conducted. The study produced empirical data on relevant factors regarding interaction, information needs and comfort within an air taxi. The findings show that passengers want to be informed about intentions of the vehicle. The presence of a flight attendant on board is not necessary but can increase wellbeing especially during non-nominal situations.

Paper number 56:
Title: Joint semi-supervised and contrastive learning enables domain generalization and multi-domain segmentation
Authors: Alvaro Gomariz, Yusuke Kikuchi, Yun Yvonna Li, Thomas Albrecht, Andreas Maunz, Daniela Ferrara, Huanxiang Lu, Orcun Goksel
Abstract: Despite their effectiveness, current deep learning models face challenges with images coming from different domains with varying appearance and content. We introduce SegCLR, a versatile framework designed to segment images across different domains, employing supervised and contrastive learning simultaneously to effectively learn from both labeled and unlabeled data. We demonstrate the superior performance of SegCLR through a comprehensive evaluation involving three diverse clinical datasets of 3D retinal Optical Coherence Tomography (OCT) images, for the slice-wise segmentation of fluids with various network configurations and verification across 10 different network initializations. In an unsupervised domain adaptation context, SegCLR achieves results on par with a supervised upper-bound model trained on the intended target domain. Notably, we discover that the segmentation performance of SegCLR framework is marginally impacted by the abundance of unlabeled data from the target domain, thereby we also propose an effective domain generalization extension of SegCLR, known also as zero-shot domain adaptation, which eliminates the need for any target domain information. This shows that our proposed addition of contrastive loss in standard supervised training for segmentation leads to superior models, inherently more generalizable to both in- and out-of-domain test data. We additionally propose a pragmatic solution for SegCLR deployment in realistic scenarios with multiple domains containing labeled data. Accordingly, our framework pushes the boundaries of deep-learning based segmentation in multi-domain applications, regardless of data availability - labeled, unlabeled, or nonexistent.

Paper number 57:
Title: MEMS and ECM Sensor Technologies for Cardiorespiratory Sound Monitoring - A Comprehensive Review
Authors: Yasaman Torabi, Shahram Shirani, James P. Reilly, Gail M Gauvreau
Abstract: This paper presents a comprehensive review of cardiorespiratory auscultation sensing devices (i.e., stethoscopes), which is useful for understanding the theoretical aspects and practical design notes. In this paper, we first introduce the acoustic properties of the heart and lungs, as well as a brief history of stethoscope evolution. Then, we discuss the basic concept of electret condenser microphones (ECMs) and a stethoscope based on them. Then, we discuss the microelectromechanical systems (MEMSs) technology, particularly focusing on piezoelectric transducer sensors. This paper comprehensively reviews sensing technologies for cardiorespiratory auscultation, emphasizing MEMS-based wearable designs in the past decade. To our knowledge, this is the first paper to summarize ECM and MEMS applications for heart and lung sound analysis.

Paper number 58:
Title: LUT-Assisted Clock Data Recovery and Equalization for Burst-Mode 50-100 Gbit/s Bandwidth-Limited Flexible PON
Authors: Yanlu Huang, Liyan Wu, Shangya Han, Kai Jin, Kun Xu, Yanni Ou
Abstract: We demonstrated LUT-assisted CDR and equalization for burst-mode 50-100 Gbit/s bandwidth-limited PON, achieving signal recovery under large 100 ppm frequency offsets and 0.5 UI phase mismatch using reduced 50ns preambles, with 0.3dB sensitivity penalty only.

Paper number 59:
Title: Enhanced Support Vector Machine Based Signal Recovery in Bandwidth-Limited 50-100 Gbit/s Flexible DS-PON
Authors: Liyan Wu, Yanlu Huang, Kai Jin, Shangya Han, Kun Xu, Yanni Ou
Abstract: We proposed an adaptive signal recovery algorithm with reduced complexity based on the SVM principle for flexible downstream PON. Experimental results indicate a record-high link power budget of 24 dB for bandwidth-limited 100 Gbit/s direct-detection transmission@1E-3.

Paper number 60:
Title: Enhancing Expressway Ramp Merge Safety and Efficiency via Spatiotemporal Cooperative Control
Authors: Ting Peng, Xiaoxue Xu, Yuan Li, Jie WU, Tao Li, Xiang Dong, Yincai Cai, Peng Wu, Sana Ullah
Abstract: In the context of autonomous driving on expressways, the issue of ensuring safe and efficient ramp merging remains a significant challenge. Existing systems often struggle to accurately assess the status and intentions of other vehicles, leading to a persistent occurrence of accidents despite efforts to maintain safe distances. This study proposes a novel spatiotemporal cooperative control approach integrating vehicle-road coordination to address this critical issue. A comprehensive methodology is developed, beginning with the calculation of safe distances under varying spatiotemporal conditions. This involves considering multiple factors, including vehicle speed differentials, positioning errors, and clock synchronization errors. Subsequently, an advanced vehicle conflict risk evaluation model is constructed. By incorporating collision acceleration and emergency acceleration as key parameters, this model offers a more accurate and detailed evaluation of potential risks during the ramp merging process. Based on the calculated safe distances and conflict risk evaluations, a mainline priority coordinated control method is formulated. This method enables the pre-planning of vehicle trajectories, effectively reducing conflicts among vehicles. Through rigorous simulations using diverse traffic volume and speed scenarios, the efficacy of the proposed strategy is validated. The results demonstrate remarkable improvements, with the average delay time reduced by an impressive 97.96% and fuel consumption decreased by 6.01%. These outcomes indicate that the proposed approach not only enhances the speed of vehicle merging but also significantly reduces latency and fuel consumption, thereby enhancing the overall performance of ramp merging operations.

Paper number 61:
Title: Performance and Robustness of Signal-Dependent vs. Signal-Independent Binaural Signal Matching with Wearable Microphone Arrays
Authors: Ami Berger, Vladimir Tourbabin, Jacob Donley, Zamir Ben-Hur, Boaz Rafaely
Abstract: The increasing popularity of spatial audio in applications such as teleconferencing, entertainment, and virtual reality has led to the recent developments of binaural reproduction methods. However, only a few of these methods are well-suited for wearable and mobile arrays, which typically consist of a small number of microphones. One such method is binaural signal matching (BSM), which has been shown to produce high-quality binaural signals for wearable arrays. However, BSM may be suboptimal in cases of high direct-to-reverberant ratio (DRR) as it is based on the diffuse sound field assumption. To overcome this limitation, previous studies incorporated sound-field models other than diffuse. However, performance may be sensitive to signal estimation errors. This paper aims to provide a systematic and comprehensive analysis of signal-dependent vs. signal-independent BSM, so that the benefits and limitations of the methods become clearer. Two signal-dependent BSM-based methods designed for high DRR scenarios that incorporate a sound field model composed of direct and reverberant components are investigated mathematically, using simulations, and finally validated by a listening test, and compared to the signal-independent BSM. The results show that signal-dependent BSM can significantly improve performance, in particular in the direction of the source, while presenting only a negligible degradation in other directions. Furthermore, when source direction estimation is inaccurate, performance of of the signal-dependent BSM degrade to equal that of the signal-independent BSM, presenting a desired robustness quality.

Paper number 62:
Title: A scalable, gradient-stable approach to multi-step, nonlinear system identification using first-order methods
Authors: Cesare Donati, Martina Mammarella, Fabrizio Dabbene, Carlo Novara, Constantino Lagoa
Abstract: This paper presents three main contributions to the field of multi-step system identification. First, drawing inspiration from Neural Network (NN) training, it introduces a tool for solving identification problems by leveraging first-order optimization and Automatic Differentiation (AD). The proposed method exploits gradients with respect to the parameters to be identified and leverages Linear Parameter-Varying (LPV) sensitivity equations to model gradient evolution. Second, it demonstrates that the computational complexity of the proposed method is linear in both the multi-step horizon length and the parameter size, ensuring scalability for large identification problems. Third, it formally addresses the "exploding gradient" issue: via a stability analysis of the LPV equations, it derives conditions for a reliable and efficient optimization and identification process for dynamical systems. Simulation results indicate that the proposed method is both effective and efficient, making it a promising tool for future research and applications in nonlinear system identification and non-convex optimization.

Paper number 63:
Title: CR-CTC: Consistency regularization on CTC for improved speech recognition
Authors: Zengwei Yao, Wei Kang, Xiaoyu Yang, Fangjun Kuang, Liyong Guo, Han Zhu, Zengrui Jin, Zhaoqing Li, Long Lin, Daniel Povey
Abstract: Connectionist Temporal Classification (CTC) is a widely used method for automatic speech recognition (ASR), renowned for its simplicity and computational efficiency. However, it often falls short in recognition performance. In this work, we propose the Consistency-Regularized CTC (CR-CTC), which enforces consistency between two CTC distributions obtained from different augmented views of the input speech mel-spectrogram. We provide in-depth insights into its essential behaviors from three perspectives: 1) it conducts self-distillation between random pairs of sub-models that process different augmented views; 2) it learns contextual representation through masked prediction for positions within time-masked regions, especially when we increase the amount of time masking; 3) it suppresses the extremely peaky CTC distributions, thereby reducing overfitting and improving the generalization ability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech datasets demonstrate the effectiveness of our CR-CTC. It significantly improves the CTC performance, achieving state-of-the-art results comparable to those attained by transducer or systems combining CTC and attention-based encoder-decoder (CTC/AED). We release our code at this https URL.

Paper number 64:
Title: DOA Estimation-Oriented Joint Array Partitioning and Beamforming Designs for ISAC Systems
Authors: Rang Liu, Ming Li, Qian Liu, A. Lee Swindlehurst
Abstract: Integrated sensing and communication has been identified as an enabling technology for forthcoming wireless networks. In an effort to achieve an improved performance trade-off between multiuser communications and radar sensing, this paper considers a dynamically-partitioned antenna array architecture for monostatic ISAC systems, in which each element of the array at the base station can function as either a transmit or receive antenna. To fully exploit the available spatial degrees of freedom for both communication and sensing functions, we jointly design the partitioning of the array between transmit and receive antennas together with the transmit beamforming in order to minimize the direction-of-arrival (DOA) estimation error, while satisfying constraints on the communication signal-to-interference-plus-noise ratio and the transmit power budget. An alternating algorithm based on Dinkelbach's transform, the alternative direction method of multipliers, and majorization-minimization is developed to solve the resulting complicated optimization problem. To reduce the computational complexity, we also present a heuristic three-step strategy that optimizes the transmit beamforming after determining the antenna partitioning. Simulation results confirm the effectiveness of the proposed algorithms in significantly reducing the DOA estimation error.

Paper number 65:
Title: Joint Space-Time Adaptive Processing and Beamforming Design for Cell-Free ISAC Systems
Authors: Rang Liu, Ming Li, Qian Liu
Abstract: In this paper, we explore cooperative sensing and communication within cell-free integrated sensing and communication (ISAC) systems. Specifically, multiple transmit access points (APs) collaboratively serve multiple communication users while simultaneously illuminating a potential target, with a separate sensing AP dedicated to collecting echo signals for target detection. To improve the performance of identifying a moving target in the presence of strong interference originating from transmit APs, we employ the space-time adaptive processing (STAP) technique and jointly optimize the transmit/receive beamforming. Our goal is to maximize the radar output signal-to-interference-plus-noise ratio (SINR), subject to the communication SINR requirements and the power budget. An efficient alternating algorithm is developed to solve the resulting non-convex optimization problem. Simulations demonstrate significant performance improvements in target detection and validate the advantages of the proposed joint STAP and beamforming design for cell-free ISAC systems.

Paper number 66:
Title: Intensity-Spatial Dual Masked Autoencoder for Multi-Scale Feature Learning in Chest CT Segmentation
Authors: Yuexing Ding, Jun Wang, Hongbing Lyu
Abstract: In the field of medical image segmentation, challenges such as indistinct lesion features, ambiguous boundaries,and multi-scale characteristics have long revailed. This paper proposes an improved method named Intensity-Spatial Dual Masked AutoEncoder (ISD-MAE). Based on the tissue-contrast semi-masked autoencoder, a Masked AutoEncoder (MAE) branch is introduced to perform intensity masking and spatial masking operations on chest CT images for multi-scale feature learning and segmentation tasks. The model utilizes a dual-branch structure and contrastive learning to enhance the ability to learn tissue features and boundary details. Experiments are conducted on multiple 2D and 3D datasets. The results show that ISD-MAE significantly outperforms other methods in 2D pneumonia and mediastinal tumor segmentation tasks. For example, the Dice score reaches 90.10% on the COVID19 LESION dataset, and the performance is relatively stable. However, there is still room for improvement on 3D datasets. In response to this, improvement directions are proposed, including optimizing the loss function, using enhanced 3D convolution blocks, and processing datasets from multiple this http URL code is available at:this https URL.

Paper number 67:
Title: A Comprehensive Framework for Automated Segmentation of Perivascular Spaces in Brain MRI with the nnU-Net
Authors: William Pham, Alexander Jarema, Donggyu Rim, Zhibin Chen, Mohamed S. H. Khlif, Vaughan G. Macefield, Luke A. Henderson, Amy Brodtmann
Abstract: Background: Enlargement of perivascular spaces (PVS) is common in neurodegenerative disorders including cerebral small vessel disease, Alzheimer's disease, and Parkinson's disease. PVS enlargement may indicate impaired clearance pathways and there is a need for reliable PVS detection methods which are currently lacking. Aim: To optimise a widely used deep learning model, the no-new-UNet (nnU-Net), for PVS segmentation. Methods: In 30 healthy participants (mean$\pm$SD age: 50$\pm$18.9 years; 13 females), T1-weighted MRI images were acquired using three different protocols on three MRI scanners (3T Siemens Tim Trio, 3T Philips Achieva, and 7T Siemens Magnetom). PVS were manually segmented across ten axial slices in each participant. Segmentations were completed using a sparse annotation strategy. In total, 11 models were compared using various strategies for image handling, preprocessing and semi-supervised learning with pseudo-labels. Model performance was evaluated using 5-fold cross validation (5FCV). The main performance metric was the Dice Similarity Coefficient (DSC). Results: The voxel-spacing agnostic model (mean$\pm$SD DSC=64.3$\pm$3.3%) outperformed models which resampled images to a common resolution (DSC=40.5-55%). Model performance improved substantially following iterative label cleaning (DSC=85.7$\pm$1.2%). Semi-supervised learning with pseudo-labels (n=12,740) from 18 additional datasets improved the agreement between raw and predicted PVS cluster counts (Lin's concordance correlation coefficient=0.89, 95%CI=0.82-0.94). We extended the model to enable PVS segmentation in the midbrain (DSC=64.3$\pm$6.5%) and hippocampus (DSC=67.8$\pm$5%). Conclusions: Our deep learning models provide a robust and holistic framework for the automated quantification of PVS in brain MRI.

Paper number 68:
Title: Topological Signal Processing and Learning: Recent Advances and Future Challenges
Authors: Elvin Isufi, Geert Leus, Baltasar Beferull-Lozano, Sergio Barbarossa, Paolo Di Lorenzo
Abstract: Developing methods to process irregularly structured data is crucial in applications like gene-regulatory, brain, power, and socioeconomic networks. Graphs have been the go-to algebraic tool for modeling the structure via nodes and edges capturing their interactions, leading to the establishment of the fields of graph signal processing (GSP) and graph machine learning (GML). Key graph-aware methods include Fourier transform, filtering, sampling, as well as topology identification and spatiotemporal processing. Although versatile, graphs can model only pairwise dependencies in the data. To this end, topological structures such as simplicial and cell complexes have emerged as algebraic representations for more intricate structure modeling in data-driven systems, fueling the rapid development of novel topological-based processing and learning methods. This paper first presents the core principles of topological signal processing through the Hodge theory, a framework instrumental in propelling the field forward thanks to principled connections with GSP-GML. It then outlines advances in topological signal representation, filtering, and sampling, as well as inferring topological structures from data, processing spatiotemporal topological signals, and connections with topological machine learning. The impact of topological signal processing and learning is finally highlighted in applications dealing with flow data over networks, geometric processing, statistical ranking, biology, and semantic communication.

Paper number 69:
Title: Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control
Authors: Lo Pang-Yun Ting, Ali Şenol, Huan-Yang Wang, Hsu-Chao Lai, Kun-Ta Chuang, Huan Liu
Abstract: The advanced bidirectional EV charging and discharging technology, aimed at supporting grid stability and emergency operations, has driven a growing interest in workplace applications. It not only reduces electricity expenses but also enhances the resilience in handling practical matters, such as peak power limitation, fluctuating energy prices, and unpredictable EV departures. Considering these factors systematically can benefit energy efficiency in office buildings and for EV users simultaneously. To employ AI to address these issues, we propose HUCA, a novel real-time charging control for regulating energy demands for both the building and EVs. HUCA employs hierarchical actor-critic networks to dynamically reduce electricity costs in buildings, accounting for the needs of EV charging in the dynamic pricing scenario. To tackle the uncertain EV departures, we introduce a new critic augmentation to account for departure uncertainties in evaluating the charging decisions, while maintaining the robustness of the charging control. Experiments on real-world electricity datasets under both simulated certain and uncertain departure scenarios demonstrate that HUCA outperforms baselines in terms of total electricity costs while maintaining competitive performance in fulfilling EV charging requirements. A case study also manifests that HUCA effectively balances energy supply between the building and EVs based on real-time information, showcasing its potential as a key AI-driven solution for vehicle charging control.

Paper number 70:
Title: Artifact-free Sound Quality in DNN-based Closed-loop Systems for Audio Processing
Authors: Chuan Wen, Guy Torfs, Sarah Verhulst
Abstract: Recent advances in deep neural networks (DNNs) have significantly improved various audio processing applications, including speech enhancement, synthesis, and hearing aid algorithms. DNN-based closed-loop systems have gained popularity in these applications due to their robust performance and ability to adapt to diverse conditions. Despite their effectiveness, current DNN-based closed-loop systems often suffer from sound quality degradation caused by artifacts introduced by suboptimal sampling methods. To address this challenge, we introduce dCoNNear, a novel DNN architecture designed for seamless integration into closed-loop frameworks. This architecture specifically aims to prevent the generation of spurious artifacts. We demonstrate the effectiveness of dCoNNear through a proof-of-principle example within a closed-loop framework that employs biophysically realistic models of auditory processing for both normal and hearing-impaired profiles to design personalized hearing aid algorithms. Our results show that dCoNNear not only accurately simulates all processing stages of existing non-DNN biophysical models but also eliminates audible artifacts, thereby enhancing the sound quality of the resulting hearing aid algorithms. This study presents a novel, artifact-free closed-loop framework that improves the sound quality of audio processing systems, offering a promising solution for high-fidelity applications in audio and hearing technologies.

Paper number 71:
Title: A Note on the Conversion of Nonnegative Integers to the Canonical Signed-digit Representation
Authors: R. J. Cintra
Abstract: This note addresses the signed-digit representation of nonnegative binary integers. Popular literature methods for the conversion into the canonical signed-digit representation are reviewed and revisited. A method based on string substitution is discussed.

Paper number 72:
Title: Collaborative Channel Access and Transmission for NR Sidelink and Wi-Fi Coexistence over Unlicensed Spectrum
Authors: Zhuangzhuang Yan, Xinyu Gu, Zhenyu Liu, Liyang Lu
Abstract: With the rapid development of various internet of things (IoT) applications, including industrial IoT (IIoT) and visual IoT (VIoT), the demand for direct device-to-device communication to support high data rates continues to grow. To address this demand, 5G-Advanced has introduced sidelink communication over the unlicensed spectrum (SL-U) to increase data rates. However, the primary challenge of SL-U in the unlicensed spectrum is ensuring fair coexistence with other incumbent systems, such as Wi-Fi. In this paper, we address the challenge by designing channel access mechanisms and power control strategies to mitigate interference and ensure fair coexistence. First, we propose a novel collaborative channel access (CCHA) mechanism that integrates channel access with resource allocation through collaborative interactions between base stations (BS) and SL-U users. This mechanism ensures fair coexistence with incumbent systems while improving resource utilization. Second, to further enhance the performance of the coexistence system, we develop a cooperative subgoal-based hierarchical deep reinforcement learning (C-GHDRL) algorithm framework. The framework enables SL-U users to make globally optimal decisions by leveraging cooperative operations between the BS and SL-U users, effectively overcoming the limitations of traditional optimization methods in solving joint optimization problems with nonlinear constraints. Finally, we mathematically model the joint channel access and power control problem and balance the trade-off between fairness and transmission rate in the coexistence system by defining a suitable reward function in the C-GHDRL algorithm. Simulation results demonstrate that the proposed scheme significantly enhances the performance of the coexistence system while ensuring fair coexistence between SL-U and Wi-Fi users.

Paper number 73:
Title: Improving Quality Control Of MRI Images Using Synthetic Motion Data
Authors: Charles Bricout, Kang Ik K. Cho, Michael Harms, Ofer Pasternak, Carrie E. Bearden, Patrick D. McGorry, Rene S. Kahn, John Kane, Barnaby Nelson, Scott W. Woods, Martha E. Shenton, Sylvain Bouix, Samira Ebrahimi Kahou
Abstract: MRI quality control (QC) is challenging due to unbalanced and limited datasets, as well as subjective scoring, which hinder the development of reliable automated QC systems. To address these issues, we introduce an approach that pretrains a model on synthetically generated motion artifacts before applying transfer learning for QC classification. This method not only improves the accuracy in identifying poor-quality scans but also reduces training time and resource requirements compared to training from scratch. By leveraging synthetic data, we provide a more robust and resource-efficient solution for QC automation in MRI, paving the way for broader adoption in diverse research settings.

Paper number 74:
Title: DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation
Authors: Dongya Jia, Zhuo Chen, Jiawei Chen, Chenpeng Du, Jian Wu, Jian Cong, Xiaobin Zhuang, Chumin Li, Zhen Wei, Yuping Wang, Yuxuan Wang
Abstract: Several recent studies have attempted to autoregressively generate continuous speech representations without discrete speech tokens by combining diffusion and autoregressive models, yet they often face challenges with excessive computational loads or suboptimal outcomes. In this work, we propose Diffusion Transformer Autoregressive Modeling (DiTAR), a patch-based autoregressive framework combining a language model with a diffusion transformer. This approach significantly enhances the efficacy of autoregressive models for continuous tokens and reduces computational demands. DiTAR utilizes a divide-and-conquer strategy for patch generation, where the language model processes aggregated patch embeddings and the diffusion transformer subsequently generates the next patch based on the output of the language model. For inference, we propose defining temperature as the time point of introducing noise during the reverse diffusion ODE to balance diversity and determinism. We also show in the extensive scaling analysis that DiTAR has superb scalability. In zero-shot speech generation, DiTAR achieves state-of-the-art performance in robustness, speaker similarity, and naturalness.

Paper number 75:
Title: MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin
Authors: Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo
Abstract: Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is introduced as a multimodal framework inspired by real-world diagnostic processes. It uses pretrained models such as DINOv2, Vision Transformer, and ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into low-dimensional, semantically meaningful features. A learnable self-attention-based fusion network then integrates these imaging features with clinical data for classification. Using 416 FUO patient cases from Sichuan University West China Hospital from 2017 to 2023, the multimodal fusion classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to 0.9291 across seven tasks, outperforming conventional machine learning and single-modality deep learning methods. Ablation studies and five-fold cross-validation further validated its effectiveness. By combining the strengths of pretrained large models and deep learning, MedMimic offers a promising solution for disease classification.

Paper number 76:
Title: Less is More for Synthetic Speech Detection in the Wild
Authors: Ashi Garg, Zexin Cai, Henry Li Xinyuan, Leibny Paola García-Perera, Kevin Duh, Sanjeev Khudanpur, Matthew Wiesner, Nicholas Andrews
Abstract: Driven by advances in self-supervised learning for speech, state-of-the-art synthetic speech detectors have achieved low error rates on popular benchmarks such as ASVspoof. However, prior benchmarks do not address the wide range of real-world variability in speech. Are reported error rates realistic in real-world conditions? To assess detector failure modes and robustness under controlled distribution shifts, we introduce ShiftySpeech, a benchmark with more than 3000 hours of synthetic speech from 7 domains, 6 TTS systems, 12 vocoders, and 3 languages. We found that all distribution shifts degraded model performance, and contrary to prior findings, training on more vocoders, speakers, or with data augmentation did not guarantee better generalization. In fact, we found that training on less diverse data resulted in better generalization, and that a detector fit using samples from a single carefully selected vocoder and a small number of speakers, without data augmentations, achieved state-of-the-art results on the challenging In-the-Wild benchmark.

Paper number 77:
Title: Pre-Equalization Aided Grant-Free Massive Access in Massive MIMO System
Authors: Yueqing Wang, Yikun Mei, Zhen Gao, Ziwei Wan, Boyu Ning, De Mi, Sami Muhaidat
Abstract: The spatial diversity and multiplexing advantages of massive multi-input-multi-output (mMIMO) can significantly improve the capacity of massive non-orthogonal multiple access (NOMA) in machine type communications. However, state-of-the-art grant-free massive NOMA schemes for mMIMO systems require accurate estimation of random access channels to perform activity detection and the following coherent data demodulation, which suffers from excessive pilot overhead and access latency. To address this, we propose a pre-equalization aided grant-free massive access scheme for mMIMO systems, where an iterative detection scheme is conceived. Specifically, the base station (BS) firstly activates one of its antennas (i.e., beacon antenna) to broadcast a beacon signal, which facilitates the user equipment (UEs) to perform downlink channel estimation and pre-equalize the uplink random access signal with respect to the channels associated with the beacon antenna. During the uplink transmission stage, the BS detects UEs' activity and data by using the proposed iterative detection algorithm, which consists of three modules: coarse data detection (DD), data-aided channel estimation (CE), and fine DD. In the proposed algorithm, the joint activity and DD is firstly performed based on the signals received by the beacon antenna. Subsequently, the DD is further refined by iteratively performing data-aided CE module and fine DD module using signals received by all BS antennas. Our simulation results demonstrate that the proposed scheme outperforms state-of-the-art mMIMO-based grant-free massive NOMA schemes with the same access latency. Simulation codes are provided to reproduce the results in this article: this https URL.

Paper number 78:
Title: The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation
Authors: Raman Dutt
Abstract: Generative models, particularly text-to-image (T2I) diffusion models, play a crucial role in medical image analysis. However, these models are prone to training data memorization, posing significant risks to patient privacy. Synthetic chest X-ray generation is one of the most common applications in medical image analysis with the MIMIC-CXR dataset serving as the primary data repository for this task. This study presents the first systematic attempt to identify prompts and text tokens in MIMIC-CXR that contribute the most to training data memorization. Our analysis reveals two unexpected findings: (1) prompts containing traces of de-identification procedures (markers introduced to hide Protected Health Information) are the most memorized, and (2) among all tokens, de-identification markers contribute the most towards memorization. This highlights a broader issue with the standard anonymization practices and T2I synthesis with MIMIC-CXR. To exacerbate, existing inference-time memorization mitigation strategies are ineffective and fail to sufficiently reduce the model's reliance on memorized text tokens. On this front, we propose actionable strategies for different stakeholders to enhance privacy and improve the reliability of generative models in medical imaging. Finally, our results provide a foundation for future work on developing and benchmarking memorization mitigation techniques for synthetic chest X-ray generation using the MIMIC-CXR dataset. The anonymized code is available at this https URL

Paper number 79:
Title: EIQP: Execution-time-certified and Infeasibility-detecting QP Solver
Authors: Liang Wu, Wei Xiao, Richard D. Braatz
Abstract: Solving real-time quadratic programming (QP) is a ubiquitous task in control engineering, such as in model predictive control and control barrier function-based QP. In such real-time scenarios, certifying that the employed QP algorithm can either return a solution within a predefined level of optimality or detect QP infeasibility before the predefined sampling time is a pressing requirement. This article considers convex QP (including linear programming) and adopts its homogeneous formulation to achieve infeasibility detection. Exploiting this homogeneous formulation, this article proposes a novel infeasible interior-point method (IPM) algorithm with the best theoretical $O(\sqrt{n})$ iteration complexity that feasible IPM algorithms enjoy. The iteration complexity is proved to be \textit{exact} (rather than an upper bound), \textit{simple to calculate}, and \textit{data independent}, with the value $\left\lceil\frac{\log(\frac{n+1}{\epsilon})}{-\log(1-\frac{0.414213}{\sqrt{n+1}})}\right\rceil$ (where $n$ and $\epsilon$ denote the number of constraints and the predefined optimality level, respectively), making it appealing to certify the execution time of online time-varying convex QPs. The proposed algorithm is simple to implement without requiring a line search procedure (uses the full Newton step), and its C-code implementation (offering MATLAB, Julia, and Python interfaces) and numerical examples are publicly available at this https URL.

Paper number 80:
Title: ASVspoof 5: Design, Collection and Validation of Resources for Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech
Authors: Xin Wang, Héctor Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee, Junichi Yamagishi, Myeonghun Jeong, Ge Zhu, Yongyi Zang, You Zhang, Soumi Maiti, Florian Lux, Nicolas Müller, Wangyou Zhang, Chengzhe Sun, Shuwei Hou, Siwei Lyu, Sébastien Le Maguer, Cheng Gong, Hanjie Guo, Liping Chen, Vishwanath Singh
Abstract: ASVspoof 5 is the fifth edition in a series of challenges which promote the study of speech spoofing and deepfake attacks as well as the design of detection solutions. We introduce the ASVspoof 5 database which is generated in crowdsourced fashion from data collected in diverse acoustic conditions (cf. studio-quality data for earlier ASVspoof databases) and from ~2,000 speakers (cf. ~100 earlier). The database contains attacks generated with 32 different algorithms, also crowdsourced, and optimised to varying degrees using new surrogate detection models. Among them are attacks generated with a mix of legacy and contemporary text-to-speech synthesis and voice conversion models, in addition to adversarial attacks which are incorporated for the first time. ASVspoof 5 protocols comprise seven speaker-disjoint partitions. They include two distinct partitions for the training of different sets of attack models, two more for the development and evaluation of surrogate detection models, and then three additional partitions which comprise the ASVspoof 5 training, development and evaluation sets. An auxiliary set of data collected from an additional 30k speakers can also be used to train speaker encoders for the implementation of attack algorithms. Also described herein is an experimental validation of the new ASVspoof 5 database using a set of automatic speaker verification and spoof/deepfake baseline detectors. With the exception of protocols and tools for the generation of spoofed/deepfake speech, the resources described in this paper, already used by participants of the ASVspoof 5 challenge in 2024, are now all freely available to the community.

Paper number 81:
Title: Intermittently Observable Markov Decision Processes
Authors: Gongpu Chen, Soung-Chang Liew
Abstract: This paper investigates MDPs with intermittent state information. We consider a scenario where the controller perceives the state information of the process via an unreliable communication channel. The transmissions of state information over the whole time horizon are modeled as a Bernoulli lossy process. Hence, the problem is finding an optimal policy for selecting actions in the presence of state information losses. We first formulate the problem as a belief MDP to establish structural results. The effect of state information losses on the expected total discounted reward is studied systematically. Then, we reformulate the problem as a tree MDP whose state space is organized in a tree structure. Two finite-state approximations to the tree MDP are developed to find near-optimal policies efficiently. Finally, we put forth a nested value iteration algorithm for the finite-state approximations, which is proved to be faster than standard value iteration. Numerical results demonstrate the effectiveness of our methods.

Paper number 82:
Title: Virtual VNA: Minimal-Ambiguity Scattering Matrix Estimation with a Fixed Set of "Virtual" Load-Tunable Ports
Authors: Philipp del Hougne
Abstract: We estimate the scattering matrix of an arbitrarily complex linear, passive, time-invariant system with $N$ monomodal lumped ports by inputting and outputting waves only via a fixed set of $N_\mathrm{A}<N$ ports while terminating the remaining $N_\mathrm{S}=N-N_\mathrm{A}$ "not-directly-accessible" (NDA) ports with tunable individual loads. First, we present a closed-form approach requiring at least three arbitrary, distinct, and known loads at each NDA port; sign ambiguities on off-diagonal scattering coefficients associated with NDA ports are inevitable. Being matrix-valued, our approach is ideally suited to mitigate noise sensitivity using more accessible ports. It also yields $1+2N_\mathrm{S}+N_S(N_S-1)/2$ as upper bound on the number of required measurements $N_\mathrm{cal}$ for $N_\mathrm{A}>1$ in the low-noise regime. Second, we present a gradient-descent approach using random load configurations, enabling flexible adjustments of $N_\mathrm{cal}$ to further mitigate noise. Third, we present an intensity-only gradient-descent approach, dispensing with phase-sensitive detectors at the expense of an additional blockwise phase ambiguity. Then, we discuss in what applications the inevitable remaining ambiguities are problematic and how to lift them. Finally, we experimentally validate all three approaches with an eight-port reverberation chamber and $N_\mathrm{A}=N_\mathrm{S}=4$, systematically assessing the sensitivity to noise and $N_\mathrm{cal}$. We coin our technique "virtual vector network analyzer (VNA)" because it implies that suitably tunable and characterized individual loads can essentially be interpreted as additional "virtual" VNA ports. Our method can characterize static large antenna systems with many and/or embedded ports, but also reconfigurable wave systems; it may further enable wireless sensing in indoor surveillance, non-destructive testing, and bioelectronics.

Paper number 83:
Title: RASPNet: A Benchmark Dataset for Radar Adaptive Signal Processing Applications
Authors: Shyam Venkatasubramanian, Bosung Kang, Ali Pezeshki, Muralidhar Rangaswamy, Vahid Tarokh
Abstract: We present a large-scale dataset for radar adaptive signal processing (RASP) applications to support the development of data-driven models within the adaptive radar community. The dataset, RASPNet, exceeds 16 TB in size and comprises 100 realistic scenarios compiled over a variety of topographies and land types from across the contiguous United States. For each scenario, RASPNet consists of 10,000 clutter realizations from an airborne radar setting, which can be used to benchmark radar and complex-valued learning algorithms. RASPNet intends to fill a prominent gap in the availability of a large-scale, realistic dataset that standardizes the evaluation of adaptive radar processing techniques and complex-valued neural networks. We outline its construction, organization, and several applications, including a transfer learning example to demonstrate how RASPNet can be used for realistic adaptive radar processing scenarios.

Paper number 84:
Title: CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network
Authors: Zijian Zhao, Tingwei Chen, Zhijie Cai, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu
Abstract: In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. The code for our model is publicly available at this https URL.

Paper number 85:
Title: The shape of the brain's connections is predictive of cognitive performance: an explainable machine learning study
Authors: Yui Lo, Yuqian Chen, Dongnan Liu, Wan Liu, Leo Zekelman, Jarrett Rushmore, Fan Zhang, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell
Abstract: The shape of the brain's white matter connections is relatively unexplored in diffusion MRI tractography analysis. While it is known that tract shape varies in populations and across the human lifespan, it is unknown if the variability in dMRI tractography-derived shape may relate to the brain's functional variability across individuals. This work explores the potential of leveraging tractography fiber cluster shape measures to predict subject-specific cognitive performance. We implement machine learning models to predict individual cognitive performance scores. We study a large-scale database from the HCP-YA study. We apply an atlas-based fiber cluster parcellation to the dMRI tractography of each individual. We compute 15 shape, microstructure, and connectivity features for each fiber cluster. Using these features as input, we train a total of 210 models to predict 7 different NIH Toolbox cognitive performance assessments. We apply an explainable AI technique, SHAP, to assess the importance of each fiber cluster for prediction. Our results demonstrate that shape measures are predictive of individual cognitive performance. The studied shape measures, such as irregularity, diameter, total surface area, volume, and branch volume, are as effective for prediction as microstructure and connectivity measures. The overall best-performing feature is a shape feature, irregularity, which describes how different a cluster's shape is from an idealized cylinder. Further interpretation using SHAP values suggest that fiber clusters with features highly predictive of cognitive ability are widespread throughout the brain, including fiber clusters from the superficial association, deep association, cerebellar, striatal, and projection pathways. This study demonstrates the strong potential of shape descriptors to enhance the study of the brain's white matter and its relationship to cognitive function.

Paper number 86:
Title: UAV Communications: Impact of Obstacles on Channel Characteristics
Authors: Kamal Shayegan
Abstract: In recent years, Unmanned Aerial Vehicles (UAVs) have been utilized as effective platforms for carrying Wi-Fi Access Points (APs) and cellular Base Stations (BSs), enabling low-cost, agile, and flexible wireless networks with high Quality of Service (QoS). The next generation of wireless communications will rely on increasingly higher frequencies, which are easily obstructed by obstacles. One of the most critical concepts yet to be fully addressed is positioning the UAV at optimal coordinates while accounting for obstacles. To ensure a line of sight (LoS) between UAVs and user equipment (UE), improve QoS, and establish reliable wireless links with maximum coverage, obstacles must be integrated into the proposed placement algorithms. This paper introduces a simulation-based measurement approach for characterizing an air-to-ground (AG) channel in a simple scenario. By considering obstacles, we present a novel perspective on channel characterization. The results, in terms of throughput, packet delivery, packet loss, and delay, are compared using the proposed positioning approach.

Paper number 87:
Title: Data Center Cooling System Optimization Using Offline Reinforcement Learning
Authors: Xianyuan Zhan, Xiangyu Zhu, Peng Cheng, Xiao Hu, Ziteng He, Hanfei Geng, Jichao Leng, Huiwen Zheng, Chenhui Liu, Tianshun Hong, Yan Liang, Yunxin Liu, Feng Zhao
Abstract: The recent advances in information technology and artificial intelligence have fueled a rapid expansion of the data center (DC) industry worldwide, accompanied by an immense appetite for electricity to power the DCs. In a typical DC, around 30~40% of the energy is spent on the cooling system rather than on computer servers, posing a pressing need for developing new energy-saving optimization technologies for DC cooling systems. However, optimizing such real-world industrial systems faces numerous challenges, including but not limited to a lack of reliable simulation environments, limited historical data, and stringent safety and control robustness requirements. In this work, we present a novel physics-informed offline reinforcement learning (RL) framework for energy efficiency optimization of DC cooling systems. The proposed framework models the complex dynamical patterns and physical dependencies inside a server room using a purposely designed graph neural network architecture that is compliant with the fundamental time-reversal symmetry. Because of its well-behaved and generalizable state-action representations, the model enables sample-efficient and robust latent space offline policy learning using limited real-world operational data. Our framework has been successfully deployed and verified in a large-scale production DC for closed-loop control of its air-cooling units (ACUs). We conducted a total of 2000 hours of short and long-term experiments in the production DC environment. The results show that our method achieves 14~21% energy savings in the DC cooling system, without any violation of the safety or operational constraints. Our results have demonstrated the significant potential of offline RL in solving a broad range of data-limited, safety-critical real-world industrial control problems.

Paper number 88:
Title: S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation
Authors: Yunuo Chen, Qian Li, Bing He, Donghui Feng, Ronghua Wu, Qi Wang, Li Song, Guo Lu, Wenjun Zhang
Abstract: Transformers have achieved significant success in learned image compression (LIC), with Swin Transformers emerging as the mainstream choice for nonlinear transforms. A common belief is that their sophisticated spatial operations contribute most to their efficacy. However, the crucial role of the feed-forward network (FFN) based Channel Aggregation module within the transformer architecture has been largely overlooked, and the over-design of spatial operations leads to a suboptimal trade-off between decoding latency and R-D performance. In this paper, we reevaluate the key factors behind the competence of transformers in LIC. By replacing spatial operations with identity mapping, we are surprised to find that channel operations alone can approach the R-D performance of the leading methods. This solid lower bound of performance emphasizes that the presence of channel aggregation is more essential for the LIC model to achieve competitive performance, while the previously complex spatial interactions are partly redundant. Based on this insight, we initiate the "S2CFormer" paradigm, a general architecture that reorients the focus of LIC from Spatial Interaction to Channel Aggregation. We present two instantiations of the S2CFormer: S2C-Conv, and S2C-Attention. Each one incorporates a simple operator for spatial interaction and serves as nonlinear transform blocks for our LIC models. Both models demonstrate state-of-the-art (SOTA) R-D performance and significantly faster decoding speed. These results also motivate further exploration of advanced FFN structures to enhance the R-D performance while maintaining model efficiency. With these foundations, we introduce S2C-Hybrid, an enhanced LIC model that combines the strengths of different S2CFormer instantiations. This model outperforms all the existing methods on several datasets, setting a new benchmark for efficient and high-performance LIC.

Paper number 89:
Title: Learning to Predict Global Atrial Fibrillation Dynamics from Sparse Measurements
Authors: Alexander Jenkins, Andrea Cini, Joseph Barker, Alexander Sharp, Arunashis Sau, Varun Valentine, Srushti Valasang, Xinyang Li, Tom Wong, Timothy Betts, Danilo Mandic, Cesare Alippi, Fu Siong Ng
Abstract: Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all treatment with limited success in persistent AF. This may be due to our inability to map the dynamics of AF with the limited resolution and coverage provided by sequential contact mapping catheters, preventing effective patient phenotyping for personalised, targeted ablation. Here we introduce FibMap, a graph recurrent neural network model that reconstructs global AF dynamics from sparse measurements. Trained and validated on 51 non-contact whole atria recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage, achieving a 210% lower mean absolute error and an order of magnitude higher performance in tracking phase singularities compared to baseline methods. Clinical utility of FibMap is demonstrated on real-world contact mapping recordings, achieving reconstruction fidelity comparable to non-contact mapping. FibMap's state-spaces and patient-specific parameters offer insights for electrophenotyping AF. Integrating FibMap into clinical practice could enable personalised AF care and improve outcomes.
    