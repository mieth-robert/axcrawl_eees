
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Auctioning Future Services in Edge Networks with Moving Vehicles: N-Step Look-Ahead Contracts for Sustainable Resource Provision
Authors: Ziqi Ling, Minghui Liwang, Xianbin Wang, Seyyedali Hosseinalipour, Zhipeng Cheng, Sai Zou, Wei Ni, Xiaoyu Xia
Abstract: Timely resource allocation in edge-assisted vehicular networks is essential for compute-intensive services such as autonomous driving and navigation. However, vehicle mobility leads to spatio-temporal unpredictability of resource demands, while real-time double auctions incur significant latency. To address these challenges, we propose a look-ahead contract-based auction framework that shifts decision-making from runtime to planning time. Our approach establishes N-step service contracts between edge servers (ESs) using demand forecasts and modified double auctions. The system operates in two stages: first, an LSTM-based prediction module forecasts multi-slot resource needs and determines ES roles (buyer or seller), after which a pre-double auction generates contracts specifying resource quantities, prices, and penalties. Second, these contracts are enforced in real time without rerunning auctions. The framework incorporates energy costs, transmission overhead, and contract breach risks into utility models, ensuring truthful, rational, and energy-efficient trading. Experiments on real-world (UTD19) and synthetic traces demonstrate that our method improves time efficiency, energy use, and social welfare compared with existing baselines.

Paper number 2:
Title: Nonlinear System Identification for Model-Based Control of Waked Wind Turbines
Authors: Sebastiano Randino, Lorenzo Schena, Nicolas Coudou, Emanuele Garone, Miguel Alfonso Mendez
Abstract: This work presents a nonlinear system identification framework for modeling the power extraction dynamics of wind turbines, including both freestream and waked conditions. The approach models turbine dynamics using data-driven power coefficient maps expressed as combinations of compact radial basis functions and polynomial bases, parameterized in terms of tip-speed ratio and upstream conditions. These surrogate models are embedded in a first-order dynamic system suitable for model-based control. Experimental validation is carried out in two wind tunnel configurations: a low-turbulence tandem setup and a high-turbulence wind farm scenario. In the tandem case, the identified model is integrated into an adapted K\omega^2 controller, resulting in improved tip-speed ratio tracking and power stability compared to BEM-based and steady-state models. In the wind farm scenario, the model captures the statistical behavior of the turbines despite unresolved turbulence. The proposed method enables interpretable, adaptive control across a range of operating conditions without relying on black-box learning strategies.

Paper number 3:
Title: Techno-economic analysis of self-sustainable thermophotovoltaic systems for grid-scale energy generation
Authors: Jihun Lim, Sungwon Lee
Abstract: To facilitate the widespread adoption of renewable energy, dispatchable, zero-emission power sources are essential for grid stability. This work performs a comprehensive techno-economic analysis of a self-sustainable thermophotovoltaic (TPV) system, an architecture that integrates solar charging to function as a standalone power generation asset. Using theory-based models for air-bridge InGaAs and Si diode cells, our analysis reveals that while the system is not currently competitive from a pure levelized of storage cost (LCOS) perspective due to the high capital expenditure for thermal battery materials, its primary value lies in its competitive levelized cost of electricity (LCOE). The results demonstrate that the LCOE of this self-sustaining system can be competitive with conventional dispatchable generators, such as gas turbines. Furthermore, at scales exceeding the gigawatt-hour level, a Si-based system can also achieve an LCOE comparable to that of traditional gas-turbine power plants, despite having a lower conversion efficiency than its InGaAs counterpart. This highlights a practical engineering pathway for leveraging silicon's immense manufacturing scalability, offering a lower-risk route to deployment compared to III-V materials. Ultimately, this work establishes the self-sustainable TPV architecture as a compelling pathway toward providing grid-scale, on-demand, zero-emission power.

Paper number 4:
Title: Autoencoding Coordinate Sequences from Psychophysiologic Signals
Authors: Timothy L. Hutcheson, Anil K. Raj
Abstract: We present a method for converting 24 channels of psychophysiologic time series data collected from individual participants via electroencephalogram (EEG), electrocardiogram (ECG), electrodermal activity (EDA), respiration rate (RR) into trackable three dimensional (3D) coordinates sufficient to estimate participation in specific task and cognitive states.

Paper number 5:
Title: Flexible Intelligent Metasurface for Reconfiguring Radio Environments
Authors: Hanwen Hu, Jiancheng An, Lu Gan, Naofal Al-Dhahir
Abstract: Flexible intelligent metasurface (FIM) technology holds immense potential for increasing the spectral efficiency and energy efficiency of wireless networks. In contrast to traditional rigid reconfigurable intelligent surfaces (RIS), an FIM consists of an array of elements, each capable of independently tuning electromagnetic signals, while flexibly adjusting its position along the direction perpendicular to the surface. In contrast to traditional rigid metasurfaces, FIM is capable of morphing its surface shape to attain better channel conditions. In this paper, we investigate the single-input single-output (SISO) and multiple-input single-output (MISO) communication systems aided by a transmissive FIM. In the SISO scenario, we jointly optimize the FIM phase shift matrix and surface shape to maximize the end-to-end channel gain. First, we derive the optimal phase-shift matrix for each tentative FIM surface shape to decompose the high-dimensional non-convex optimization problem into multiple one-dimensional subproblems. Then, we utilize the particle swarm optimization (PSO) algorithm and the multi-interval gradient descent (MIGD) method for updating the FIM's surface shape to maximize the channel gain. In the MISO scenario, we jointly optimize the transmit beamforming, the FIM surface shape, and the phase shift matrix to maximize the channel gain. To tackle this complex problem with multiple highly coupled variables, an efficient alternating optimization algorithm is proposed. Simulation results demonstrate that FIM significantly improves channel gain compared to traditional RIS and exhibits good adaptability to multipath channels.

Paper number 6:
Title: Time-Frequency Filtering Meets Graph Clustering
Authors: Marcelo A. Colominas, Stefan Steinerberger, Hau-Tieng Wu
Abstract: We show that the problem of identifying different signal components from a time-frequency representation can be equivalently phrased as a graph clustering problem: given a graph $G=(V,E)$ one aims to identify `clusters', subgraphs that are strongly connected and have relatively few connections between them. The graph clustering problem is well studied, we show how these ideas can suggest (many) new ways to identify signal components. Numerical experiments illustrate the ideas.

Paper number 7:
Title: Adaptive Control Allocation for Underactuated Time-Scale Separated Non-Affine Systems
Authors: Daniel M. Cherenson, Dimitra Panagou
Abstract: Many robotic systems are underactuated, meaning not all degrees of freedom can be directly controlled due to lack of actuators, input constraints, or state-dependent actuation. This property, compounded by modeling uncertainties and disturbances, complicates the control design process for trajectory tracking. In this work, we propose an adaptive control architecture for uncertain, nonlinear, underactuated systems with input constraints. Leveraging time-scale separation, we construct a reduced-order model where fast dynamics provide virtual inputs to the slower subsystem and use dynamic control allocation to select the optimal control inputs given the non-affine dynamics. To handle uncertainty, we introduce a state predictor-based adaptive law, and through singular perturbation theory and Lyapunov analysis, we prove stability and bounded tracking of reference trajectories. The proposed method is validated on a VTOL quadplane with nonlinear, state-dependent actuation, demonstrating its utility as a unified controller across various flight regimes, including cruise, landing transition, and hover.

Paper number 8:
Title: SALAD-VAE: Semantic Audio Compression with Language-Audio Distillation
Authors: Sebastian Braun, Hannes Gamper, Dimitra Emmanouilidou
Abstract: Modern generative and multimodal models increasingly rely on compact latent representations that trade and balance semantic richness with high-fidelity reconstruction. We introduce SALAD-VAE, a continuous and highly compact semantic Audio Variational Autoencoder, which operates in the frequency domain and achieves state-of-the-art compression with very low latent frame rate (7.8 Hz) while surfacing semantic structure and producing high audio quality. We enhance the standard VAE semantic losses and augmentation, specifically contrastive learning and CLAP-based embedding distillation, enabling it to generalize across diverse audio domains. With a significantly less computational complex architecture than comparable state-of-the-art VAEs, SALAD-VAE matches their reconstruction quality while it consistently outperforms them on a wide range of classification benchmarks. Furthermore, the proposed additional loss function provides a trained CLAP projection layer, which can be used zero-shot audio captioning and classification matching pretrained CLAP audio-text embeddings.

Paper number 9:
Title: An Energy-Efficient Edge Coprocessor for Neural Rendering with Explicit Data Reuse Strategies
Authors: Binzhe Yuan, Xiangyu Zhang, Zeyu Zheng, Yuefeng Zhang, Haochuan Wan, Zhechen Yuan, Junsheng Chen, Yunxiang He, Junran Ding, Xiaoming Zhang, Chaolin Rao, Wenyan Su, Pingqiang Zhou, Jingyi Yu, Xin Lou
Abstract: Neural radiance fields (NeRF) have transformed 3D reconstruction and rendering, facilitating photorealistic image synthesis from sparse viewpoints. This work introduces an explicit data reuse neural rendering (EDR-NR) architecture, which reduces frequent external memory accesses (EMAs) and cache misses by exploiting the spatial locality from three phases, including rays, ray packets (RPs), and samples. The EDR-NR architecture features a four-stage scheduler that clusters rays on the basis of Z-order, prioritize lagging rays when ray divergence happens, reorders RPs based on spatial proximity, and issues samples out-of-orderly (OoO) according to the availability of on-chip feature data. In addition, a four-tier hierarchical RP marching (HRM) technique is integrated with an axis-aligned bounding box (AABB) to facilitate spatial skipping (SS), reducing redundant computations and improving throughput. Moreover, a balanced allocation strategy for feature storage is proposed to mitigate SRAM bank conflicts. Fabricated using a 40 nm process with a die area of 10.5 mmX, the EDR-NR chip demonstrates a 2.41X enhancement in normalized energy efficiency, a 1.21X improvement in normalized area efficiency, a 1.20X increase in normalized throughput, and a 53.42% reduction in on-chip SRAM consumption compared to state-of-the-art accelerators.

Paper number 10:
Title: Rate Maximization for UAV-assisted ISAC System with Fluid Antennas
Authors: Xingtao Yang, Zhenghe Guo, Siyun Liang, Zhaohui Yang, Chen Zhu, Zhaoyang Zhang
Abstract: This letter investigates the joint sensing problem between unmanned aerial vehicles (UAV) and base stations (BS) in integrated sensing and communication (ISAC) systems with fluid antennas (FA). In this system, the BS enhances its sensing performance through the UAV's perception system. We aim to maximize the communication rate between the BS and UAV while guaranteeing the joint system's sensing capability. By establishing a communication-sensing model with convex optimization properties, we decompose the problem and apply convex optimization to progressively solve key variables. An iterative algorithm employing an alternating optimization approach is subsequently developed to determine the optimal solution, significantly reducing the solution complexity. Simulation results validate the algorithm's effectiveness in balancing system performance.

Paper number 11:
Title: Some Reflections on Sliding Mode Designs in Control Systems: An Example of Adaptive Tracking Control for Simple Mechanical Systems With Friction Without Measurement of Velocity
Authors: Romeo Ortega, Leyan Fang, Jose Guadalupe Romero
Abstract: The objective of this note is to share some reflections of the authors regarding the use of sliding mode designs in control systems. We believe the abundant, and ever increasing, appearance of this kind of works on our scientific publications deserves some critical evaluation of their actual role, relevance and pertinence. First, we discuss the procedure followed by most of these designs -- illustrated with examples from the literature. Second, we bring to the readers attention several aspects of the control problem, central in classical designs, which are disregarded in the sliding mode literature. Finally, to illustrate with an specific example our previous considerations, we compare the performance of two adaptive tracking controllers for a simple one degree of freedom mechanical systems with unknown parameters and static and Coulomb friction -- that do not rely on the measurement of velocity.

Paper number 12:
Title: Curriculum Learning with Synthetic Data for Enhanced Pulmonary Nodule Detection in Chest Radiographs
Authors: Pranav Sambhu, Om Guin, Madhav Sambhu, Jinho Cha
Abstract: This study evaluates whether integrating curriculum learning with diffusion-based synthetic augmentation can enhance the detection of difficult pulmonary nodules in chest radiographs, particularly those with low size, brightness, and contrast, which often challenge conventional AI models due to data imbalance and limited annotation. A Faster R-CNN with a Feature Pyramid Network (FPN) backbone was trained on a hybrid dataset comprising expert-labeled NODE21 (1,213 patients; 52.4 percent male; mean age 63.2 +/- 11.5 years), VinDr-CXR, CheXpert, and 11,206 DDPM-generated synthetic images. Difficulty scores based on size, brightness, and contrast guided curriculum learning. Performance was compared to a non-curriculum baseline using mean average precision (mAP), Dice score, and area under the curve (AUC). Statistical tests included bootstrapped confidence intervals, DeLong tests, and paired t-tests. The curriculum model achieved a mean AUC of 0.95 versus 0.89 for the baseline (p < 0.001), with improvements in sensitivity (70 percent vs. 48 percent) and accuracy (82 percent vs. 70 percent). Stratified analysis demonstrated consistent gains across all difficulty bins (Easy to Very Hard). Grad-CAM visualizations confirmed more anatomically focused attention under curriculum learning. These results suggest that curriculum-guided synthetic augmentation enhances model robustness and generalization for pulmonary nodule detection.

Paper number 13:
Title: Space Logistics Analysis and Incentive Design for Commercialization of Orbital Debris Remediation
Authors: Asaad Abdul-Hamid, Brycen D. Pearl, Hang Woon Lee, Hao Chen
Abstract: As orbital debris continues to become a higher priority for the space industry, there is a need to explore how partnerships between the public and private space sector may aid in addressing this issue. This research develops a space logistics framework for planning orbital debris remediation missions, providing a quantitative basis for partnerships that are mutually beneficial between space operators and debris remediators. By integrating network-based space logistics and game theory, we illuminate the high-level costs of remediating orbital debris, and the surplus that stands to be shared as a result. These findings indicate significant progress toward the continued development of a safe, sustainable, and profitable space economy.

Paper number 14:
Title: Multi-Level Multi-Fidelity Methods for Path Integral and Safe Control
Authors: Zhuoyuan Wang, Takashi Tanaka, Yongxin Chen, Yorie Nakahira
Abstract: Sampling-based approaches are widely used in systems without analytic models to estimate risk or find optimal control. However, gathering sufficient data in such scenarios can be prohibitively costly. On the other hand, in many situations, low-fidelity models or simulators are available from which samples can be obtained at low cost. In this paper, we propose an efficient approach for risk quantification and path integral control that leverages such data from multiple models with heterogeneous sampling costs. A key technical novelty of our approach is the integration of Multi-level Monte Carlo (MLMC) and Multi-fidelity Monte Carlo (MFMC) that enable data from different time and state representations (system models) to be jointly used to reduce variance and improve sampling efficiency. We also provide theoretical analysis of the proposed method and show that our estimator is unbiased and consistent under mild conditions. Finally, we demonstrate via numerical simulation that the proposed method has improved computation (sampling costs) vs. accuracy trade-offs for risk quantification and path integral control.

Paper number 15:
Title: Utilizing Model-Free Reinforcement Learning for Optimizing Secure Multi-Party Computation Protocols
Authors: Javad Sayyadi, Mahdi Nangir, Mahmood Mohassel Feghhi, Hamid Sayyadi
Abstract: In this manuscript, we explore the application of model-free reinforcement learning in optimizing secure multiparty computation (SMPC) protocols. SMPC is a crucial tool for performing computations on private data without the need to disclose it, holding significant importance in various domains, including information security and privacy. However, the efficiency of current protocols is often suboptimal due to computational and communicational complexities. Our proposed approach leverages model-free reinforcement learning algorithms to enhance the performance of these protocols. We have designed a reinforcement learning model capable of dynamically learning and adapting optimal strategies for secure computations. Our experimental results demonstrate that employing this method leads to a substantial reduction in execution time and communication costs of the protocols. These achievements highlight the high potential of reinforcement learning in improving the efficiency of secure multiparty computation protocols, providing an effective solution to the existing challenges in this field.

Paper number 16:
Title: Wideband dynamic metasurface antenna performance with practical design characteristics
Authors: Joseph M. Carlson, Nitish V. Deshpande, Miguel Rodrigo Castellanos, Robert W. Heath Jr
Abstract: Dynamic metasurface antennas (DMA) provide low-power beamforming through reconfigurable radiative slots. Each slot has a tunable component that consumes low power compared to typical analog components like phase shifters. This makes DMAs a potential candidate to minimize the power consumption of multiple-input multiple-output (MIMO) antenna arrays. In this paper, we investigate the use of DMAs in a wideband communication setting with practical DMA design characteristics. We develop approximations for the DMA beamforming gain that account for the effects of waveguide attenuation, element frequency-selectivity, and limited reconfigurability of the tunable components as a function of the signal bandwidth. The approximations allow for key insights into the wideband performance of DMAs in terms of different design variables. We develop a simple successive beamforming algorithm to improve the wideband performance of DMAs by sequentially configuring each DMA element. Simulation results for a line-of-sight (LOS) wideband system show the accuracy of the approximations with the simulated DMA model in terms of spectral efficiency. We also find that the proposed successive beamforming algorithm increases the overall spectral efficiency of the DMA-based wideband system compared with a baseline DMA beamforming method.

Paper number 17:
Title: Full-Duplex-Bench-v2: A Multi-Turn Evaluation Framework for Duplex Dialogue Systems with an Automated Examiner
Authors: Guan-Ting Lin, Shih-Yun Shan Kuan, Jiatong Shi, Kai-Wei Chang, Siddhant Arora, Shinji Watanabe, Hung-yi Lee
Abstract: While full-duplex speech agents enable natural, low-latency interaction by speaking and listening simultaneously, their consistency and task performance in multi-turn settings remain underexplored. We introduce Full-Duplex-Bench-v2 (FDB-v2), a streaming framework that integrates with an automated examiner that enforces staged goals under two pacing setups (Fast vs. Slow). FDB-v2 covers four task families: daily, correction, entity tracking, and safety. We report turn-taking fluency, multi-turn instruction following, and task-specific competence. The framework is extensible, supporting both commercial APIs and open source models. When we test full-duplex systems with FDB-v2, they often get confused when people talk at the same time, struggle to handle corrections smoothly, and sometimes lose track of who or what is being talked about. Through an open-sourced, standardized streaming protocol and a task set, FDB-v2 makes it easy to extend to new task families, allowing the community to tailor and accelerate evaluation of multi-turn full-duplex systems.

Paper number 18:
Title: Accelerating vRAN and O-RAN with SIMD: Architectural Perspectives and Performance Evaluation
Authors: Jaebum Park, Chan-Byoung Chae, Robert W. Heath Jr
Abstract: The evolution of radio access networks (RANs) toward virtualization and openness creates new opportunities for flexible, cost-effective, and high-performance deployments. Achieving real-time and energy-efficient baseband processing on commercial off-the-shelf platforms, however, remains a critical challenge. This article explores how single instruction multiple data (SIMD) architectures can accelerate RAN workloads. We first outline why key physical-layer functions, such as channel estimation, multiple-input multiple-output (MIMO) detection, and forward error correction, are well aligned with SIMD's data-level parallelism. We then present practical design guidelines and prototype results, showing significant improvements in throughput and energy efficiency compared to conventional CPU-only processing, while retaining programmability and ease of integration. Finally, we discuss open challenges in workload balancing and hardware heterogeneity, and highlight the role of SIMD as an enabling technology for flexible, efficient, and sustainable 6G-ready RANs.

Paper number 19:
Title: Light Field Super-Resolution: A Critical Review on Challenges and Opportunities
Authors: Sumit Sharma
Abstract: Advances in portability and low cost of plenoptic cameras have revived interest in light field imaging. Light-field imaging has evolved into a technology that enables us to capture richer visual information. This high-dimensional representation of visual data provides a powerful way to understand the scene, with remarkable improvement in traditional computer vision problems such as depth sensing , post-capture refocusing , material classification, segmentation, and video stabilization. Capturing light fields with high spatial-angular resolution and capturing light field video at high frame rates remains a major challenge due to the limited resolution of the sensors, with limited processing speed. In this paper, we presented an extensive literature review of light field acquisition techniques, challenges associated with different capturing methodology and algorithms proposed for light-field super-resolution, in order to deal with spatial-angular resolution trade-off issue.

Paper number 20:
Title: Topology optimization of nonlinear forced response curves via reduction on spectral submanifolds
Authors: Hongming Liang, Matteo Pozzi, Jacopo Marconi, Shobhit Jain, Mingwu Li
Abstract: Forced response curves (FRCs) of nonlinear systems can exhibit complex behaviors, including hardening/softening behavior and bifurcations. Although topology optimization holds great potential for tuning these nonlinear dynamic responses, its use in high-dimensional systems is limited by the high cost of repeated response and sensitivity analyses. To address this challenge, we employ the spectral submanifolds (SSMs) reduction theory, which reformulates the periodic response as the equilibria of an associated reduced-order model (ROM). This enables efficient and analytic evaluation of both response amplitudes and their sensitivities. Based on the SSM-based ROM, we formulate optimization problems that optimize the peak amplitude, the hardening/softening behavior, and the distance between two saddle-node bifurcations for an FRC. The proposed method is applied to the design of nonlinear MEMS devices, achieving targeted performance optimization. This framework provides a practical and efficient strategy for incorporating nonlinear dynamic effects into the topology optimization of structures.

Paper number 21:
Title: Multi-level informed optimization via decomposed Kriging for large design problems under uncertainty
Authors: Enrico Ampellio, Blazhe Gjorgiev, Giovanni Sansavini
Abstract: Engineering design involves demanding models encompassing many decision variables and uncontrollable parameters. In addition, unavoidable aleatoric and epistemic uncertainties can be very impactful and add further complexity. The state-of-the-art adopts two steps, uncertainty quantification and design optimization, to optimize systems under uncertainty by means of robust or stochastic metrics. However, conventional scenario-based, surrogate-assisted, and mathematical programming methods are not sufficiently scalable to be affordable and precise in large and complex cases. Here, a multi-level approach is proposed to accurately optimize resource-intensive, high-dimensional, and complex engineering problems under uncertainty with minimal resources. A non-intrusive, fast-scaling, Kriging-based surrogate is developed to map the combined design/parameter domain efficiently. Multiple surrogates are adaptively updated by hierarchical and orthogonal decomposition to leverage the fewer and most uncertainty-informed data. The proposed method is statistically compared to the state-of-the-art via an analytical testbed and is shown to be concurrently faster and more accurate by orders of magnitude.

Paper number 22:
Title: SatFusion: A Unified Framework for Enhancing Satellite IoT Images via Multi-Temporal and Multi-Source Data Fusion
Authors: Yufei Tong, Guanjie Cheng, Peihan Wu, Yicheng Zhu, Kexu Lu, Feiyi Chen, Meng Xi, Junqin Huang, Shuiguang Deng
Abstract: With the rapid advancement of the digital society, the proliferation of satellites in the Satellite Internet of Things (Sat-IoT) has led to the continuous accumulation of large-scale multi-temporal and multi-source images across diverse application scenarios. However, existing methods fail to fully exploit the complementary information embedded in both temporal and source dimensions. For example, Multi-Image Super-Resolution (MISR) enhances reconstruction quality by leveraging temporal complementarity across multiple observations, yet the limited fine-grained texture details in input images constrain its performance. Conversely, pansharpening integrates multi-source images by injecting high-frequency spatial information from panchromatic data, but typically relies on pre-interpolated low-resolution inputs and assumes noise-free alignment, making it highly sensitive to noise and misregistration. To address these issues, we propose SatFusion: A Unified Framework for Enhancing Satellite IoT Images via Multi-Temporal and Multi-Source Data Fusion. Specifically, SatFusion first employs a Multi-Temporal Image Fusion (MTIF) module to achieve deep feature alignment with the panchromatic image. Then, a Multi-Source Image Fusion (MSIF) module injects fine-grained texture information from the panchromatic data. Finally, a Fusion Composition module adaptively integrates the complementary advantages of both modalities while dynamically refining spectral consistency, supervised by a weighted combination of multiple loss functions. Extensive experiments on the WorldStrat, WV3, QB, and GF2 datasets demonstrate that SatFusion significantly improves fusion quality, robustness under challenging conditions, and generalizability to real-world Sat-IoT scenarios. The code is available at: this https URL.

Paper number 23:
Title: Guitar Tone Morphing by Diffusion-based Model
Authors: Kuan-Yu Chen, Kuan-Lin Chen, Yu-Chieh Yu, Jian-Jiun Ding
Abstract: In Music Information Retrieval (MIR), modeling and transforming the tone of musical instruments, particularly electric guitars, has gained increasing attention due to the richness of the instrument tone and the flexibility of expression. Tone morphing enables smooth transitions between different guitar sounds, giving musicians greater freedom to explore new textures and personalize their performances. This study explores learning-based approaches for guitar tone morphing, beginning with LoRA fine-tuning to improve the model performance on limited data. Moreover, we introduce a simpler method, named spherical interpolation using Music2Latent. It yields significantly better results than the more complex fine-tuning approach. Experiments show that the proposed architecture generates smoother and more natural tone transitions, making it a practical and efficient tool for music production and real-time audio effects.

Paper number 24:
Title: Bloodroot: When Watermarking Turns Poisonous For Stealthy Backdoor
Authors: Kuan-Yu Chen, Yi-Cheng Lin, Jeng-Lin Li, Jian-Jiun Ding
Abstract: Backdoor data poisoning is a crucial technique for ownership protection and defending against malicious attacks. Embedding hidden triggers in training data can manipulate model outputs, enabling provenance verification, and deterring unauthorized use. However, current audio backdoor methods are suboptimal, as poisoned audio often exhibits degraded perceptual quality, which is noticeable to human listeners. This work explores the intrinsic stealthiness and effectiveness of audio watermarking in achieving successful poisoning. We propose a novel Watermark-as-Trigger concept, integrated into the Bloodroot backdoor framework via adversarial LoRA fine-tuning, which enhances perceptual quality while achieving a much higher trigger success rate and clean-sample accuracy. Experiments on speech recognition (SR) and speaker identification (SID) datasets show that watermark-based poisoning remains effective under acoustic filtering and model pruning. The proposed Bloodroot backdoor framework not only secures data-to-model ownership, but also well reveals the risk of adversarial misuse.

Paper number 25:
Title: Statistical Analysis of Target Parameter Estimation Using Passive Radar
Authors: Mats Viberg, Daniele Gerosa, Tomas McKelvey, Thomas Eriksson
Abstract: A passive radar system uses one or more so-called Illuminators of Opportunity (IO) to detect and localize targets. In such systems, a reference channel is often used at each receiving node to capture the transmitted IO signal, while targets are detected using the main surveillance channel. The purpose of the present contribution is to analyze a method for estimating the target parameters in such a system. Specifically, we quantify the additional error contribution due to not knowing the transmitted IO waveform perfectly. A sufficient condition for this error to be negligible as compared to errors due to clutter and noise in the surveillance channel is then given.

Paper number 26:
Title: A Stable, Accurate and Well-Conditioned Time-Domain PMCHWT Formulation
Authors: Van Chien Le, Cedric Munger, Francesco P. Andriulli, Kristof Cools
Abstract: This paper introduces a new boundary element formulation for transient electromagnetic scattering by homogeneous dielectric objects based on the time-domain PMCHWT equation. To address dense-mesh breakdown, a multiplicative Calderon preconditioner utilizing a modified static electric field integral operator is employed. Large-timestep breakdown and late-time instability are simultaneously resolved by rescaling the Helmholtz components leveraging the quasi-Helmholtz projectors and using temporal differentiation and integration as rescaling operators. This rescaling also balances the loop and star components at large timesteps, improving solution accuracy. The resulting discrete system is solved using a marching-on-in-time scheme and iterative solvers. Numerical experiments for simply- and multiply-connected dielectric scatterers, including highly non-smooth geometries, corroborate the accuracy, stability, and efficiency of the proposed approach.

Paper number 27:
Title: Over-The-Air Phase Calibration of Spaceborne Phased Array for LEO Satellite Communications
Authors: Wei Zhang, Ding Chen, Bin Zhou
Abstract: To avoid the unpredictable phase deviations of the spaceborne phased array (SPA), this paper considers the over-the-air (OTA) phase calibration of the SPA for the low earth orbit (LEO) satellite communications, where the phase deviations of the SPA and the unknown channel are jointly estimated with multiple transmissions of the pilots. Moreover, the Cramer Rao Bound (CRB) is derived, and the optimization of beam patterns is also presented to lower the root mean squared error (RMSE) of the OTA calibration. The simulation results verify the effectiveness of the proposed OTA phase calibration algorithm as the RMSEs of the phase estimates closely approach the corresponding CRB, and the beam pattern optimization scheme is also validated for more than 4dB gain of SNR over the randomly generated beam patterns.

Paper number 28:
Title: Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition
Authors: Yi-Cheng Lin, Yu-Hsuan Li Liang, Hsuan Su, Tzu-Quan Lin, Shang-Tse Chen, Yun-Nung Chen, Hung-yi Lee
Abstract: Robust ASR under domain shift is crucial because real-world systems encounter unseen accents and domains with limited labeled data. Although pseudo-labeling offers a practical workaround, it often introduces systematic, accent-specific errors that filtering fails to fix. We ask: How can we correct these recurring biases without target ground truth? We propose a simple parameter-space correction: in a source domain containing both real and pseudo-labeled data, two ASR models are fine-tuned from the same initialization, one on ground-truth labels and the other on pseudo-labels, and their weight difference forms a correction vector that captures pseudo-label biases. When applied to a pseudo-labeled target model, this vector enhances recognition, achieving up to a 35% relative Word Error Rate (WER) reduction on AfriSpeech-200 across ten African accents with the Whisper tiny model.

Paper number 29:
Title: General formulation of an analytic, Lipschitz continuous control allocation for thrust-vectored controlled rigid-bodies
Authors: Frank Mukwege, Tam Willy Nguyen, Emanuele Garone
Abstract: This study introduces a systematic and scalable method for arbitrary rigid-bodies equipped with vectorized thrusters. Two novel solutions are proposed: a closed-form, Lipschitz continuous mapping that ensures smooth actuator orientation references, and a convex optimization formulation capable of handling practical actuator constraints such as thrust saturation and angular rate limits. Both methods leverage the null-space structure of the allocation mapping to perform singularity avoidance while generating sub-optimal yet practical solutions. The effectiveness and generality of the proposed framework are demonstrated through numerical simulations on a 3DOF marine vessel and a 6DOF aerial quadcopter.

Paper number 30:
Title: Closed-loop control of sloshing fuel in a spinning spacecraft
Authors: Umberto Zucchelli, Miguel Alfonso Mendez, Annafederica Urbano, Sebastien Vincent-Bonnieu, Piotr Wenderski, Francesco Sanfedino
Abstract: New-generation space missions require satellites to carry substantial amounts of liquid propellant, making it essential to analyse the coupled control-structure-propellant dynamics in detail. While Computational Fluid Dynamics (CFD) offers high-fidelity predictions, its computational cost limits its use in iterative design. Equivalent Mechanical Models (EMMs) provide a faster alternative, though their predictive performance, especially in closed-loop scenarios, remains largely unexplored. This work presents a comparative analysis of a spacecraft under feedback control, using both CFD and a reduced-order sloshing model. Results show good agreement, validating the simplified model for the manoeuvrer considered. This validation enables efficient sensitivity and stability studies, offering a practical tool for early-stage spacecraft design.

Paper number 31:
Title: Towards Precise Channel Knowledge Map: Exploiting Environmental Information from 2D Visuals to 3D Point Clouds
Authors: Yancheng Wang, Chuan Huang, Songyang Zhang, Guanying Chen, Wei Guo, Shenglun Lan, Lexi Xu, Xinzhou Cheng, Xiongyan Tang, Shuguang Cui
Abstract: The substantial communication resources consumed by conventional pilot-based channel sounding impose an unsustainable overhead, presenting a critical scalability challenge for the future 6G networks characterized by massive channel dimensions, ultra-wide bandwidth, and dense user deployments. As a generalization of radio map, channel knowledge map (CKM) offers a paradigm shift, enabling access to location-tagged channel information without exhaustive measurements. To fully utilize the power of CKM, this work highlights the necessity of leveraging three-dimensional (3D) environmental information, beyond conventional two-dimensional (2D) visual representations, to construct high-precision CKMs. Specifically, we present a novel framework that integrates 3D point clouds into CKM construction through a hybrid model- and data-driven approach, with extensive case studies in real-world scenarios. The experimental results demonstrate the potential for constructing precise CKMs based on 3D environments enhanced with semantic understanding, together with their applications in the next-generation wireless communications. We also release a real-world dataset of measured channel paired with high-resolution 3D environmental data to support future research and validation.

Paper number 32:
Title: Channel Charting based Fast Beam Tracking Design and Implementation
Authors: Jiawei Zhang, Shihan Wang, Jienan Chen, Fan Wu, Jiyun Tao, Zheqi Gu
Abstract: In the beyond fifth-generation (B5G) and upcoming sixth-generation (6G) wireless communication systems, millimeter (mmWave) wave technology is a promising solution for offering additional bandwidth resources and mitigating spectrum congestion. Beam tracking is an essential procedure for providing reliable communication services in the mmWave communication system, with the challenge of providing consistent and accurate tracking performance. In this study, we introduce a low-overhead beam tracking algorithm based on channel charting, which significantly reduces beam scanning times during the tracking process. By projecting the beam information to the channel chart, the beam tracking problem is transformed into the acquisition of the beam cluster in the channel chart. Leveraging contrastive learning, the proposed channel chart projects high-dimensional channel state information into a low-dimensional feature space that preserves spatial proximities. Using a dynamic candidate beam acquisition strategy, the complexity of our beam tracking algorithm is significantly reduced. The proposed algorithm significantly reduces scanning complexity while maintaining high prediction accuracy, achieving an accuracy of 98.27\% in simulation environments. Compared to existing methods, the proposed method can reduce beam scanning times by up to 55.9\%. In addition, we also performed field tests, and the measured results demonstrated excellent communication quality during mobility.

Paper number 33:
Title: Attitude and Heading Estimation in Symmetrical Inertial Arrays
Authors: Yaakov Libero, Itzik Klein
Abstract: Attitude and heading reference systems (AHRS) play a central role in autonomous navigation systems on land, air and maritime platforms. AHRS utilize inertial sensor measurements to estimate platform orientation. In recent years, there has been increasing interest in multiple inertial measurement units (MIMU) arrays to improve navigation accuracy and robustness. A particularly challenging MIMU implementation is the gyro-free (GF) configuration, in which angular velocity is derived solely from accelerometer measurements. While the GF configurations have multiple benefits, including outlier detection and in angular acceleration measurements, their main drawbacks are inherent instability and an increased divergence rate. To address these shortcomings, we introduce a novel symmetrical MIMU formulation, in which the IMUs are arranged in symmetric diagonal pairs to decouple linear and rotational acceleration components. To this end, we derive the theoretical foundations for the symmetrical MIMU formulation of the GF equations, develop a nonlinear least squares estimation process, and integrate statistical hypothesis testing into an AHRS error-state extended Kalman filter. We validate our approach using real-world datasets containing 85 minutes of navigation data recorded on both airborne and land platforms. Our results demonstrated a 30\% average reduction in attitude estimation errors, rotation detection accuracy exceeding 95\% improvement, and significantly improved stability compared to a standard GF implementation. These results enable reliable GF navigation in applications where gyroscopes are unavailable, unreliable, or energy-constrained. Common examples include miniature platforms, computational-constraint platforms, and long-endurance marine platforms.

Paper number 34:
Title: SecuLEx: a Secure Limit Exchange Market for Dynamic Operating Envelopes
Authors: Maurizio Vassallo, Adrien Bolland, Alireza Bahmanyar, Louis Wehenkel, Laurine Duchesne, Dong Liu, Sania Khaskheli, Alexis Ha Thuc, Pedro P. Vergara, Amjad Anvari-Moghaddam, Simon Gerard, Damien Ernst
Abstract: Distributed energy resources (DERs) are transforming power networks, challenging traditional operational methods, and requiring new coordination mechanisms. To address this challenge, this paper introduces SecuLEx (Secure Limit Exchange), a new market-based paradigm to allocate power injection and withdrawal limits that guarantee network security during time periods, called dynamic operating envelopes (DOEs). Under this paradigm, distribution system operators (DSOs) assign initial DOEs to customers. These limits can be exchanged afterward through a market, allowing customers to reallocate them according to their needs while ensuring network operational constraints. We formalize SecuLEx and illustrate DOE allocation and market exchanges on a small-scale low-voltage (LV) network, demonstrating that both procedures are computationally tractable. In this example, SecuLEx reduces renewable curtailment and improves grid utilization and social welfare compared to traditional approaches.

Paper number 35:
Title: Satellite Navigation and Control using Physics-Informed Artificial Potential Field and Sliding Mode Controller
Authors: Rakesh Kumar Sahoo, Paridhi Choudhary, Manoranjan Sinha
Abstract: Increase in the number of space exploration missions has led to the accumulation of space debris, posing risk of collision with the operational satellites. Addressing this challenge is crucial for the sustainability of space operations. To plan a safe trajectory in the presence of moving space debris, an integrated approach of artificial potential field and sliding mode controller is proposed and implemented in this paper. The relative 6-DOF kinematics and dynamics of the spacecraft is modelled in the framework of geometric mechanics with the relative configuration expressed through exponential coordinates. Various collision avoidance guidance algorithms have been proposed in the literature but the Artificial Potential Field guidance algorithm is computationally efficient and enables real-time path adjustments to avoid collision with obstacles. However, it is prone to issues such as local minima. In literature, local minima issue is typically avoided by either redefining the potential function such as adding vorticity or by employing search techniques which are computationally expensive. To address these challenges, a physics-informed APF is proposed in this paper where Hamiltonian mechanics is used instead of the traditional Newtonian mechanics-based approach. In this approach, instead of relying on attractive and repulsive forces for path planning, the Hamiltonian approach uses the potential field to define a path of minimum potential. Additionally, to track the desired trajectory planned by the guidance algorithm within a fixed-time frame, a non-singular fixed-time sliding mode controller (FTSMC) is used. The proposed fixed-time sliding surface not only ensures fixed-time convergence of system states but also guarantees the global stability of the closed-loop system without singularity. The simulation results presented support the claims made.

Paper number 36:
Title: A Control Allocation Algorithm for Hypersonic Glide Vehicles with Input Limitations
Authors: Johannes Autenrieb, Patrick Gruhn
Abstract: Hypersonic glide vehicles (HGVs) operate in challenging flight regimes characterized by strong nonlinearities in actuation and stringent physical constraints. These include state-dependent actuator limitations, asymmetric control bounds, and thermal loads that vary with maneuvering conditions. This paper introduces an iterative control allocation method to address these challenges in real time. The proposed algorithm searches for control inputs that achieve the desired moment commands while respecting constraints on input magnitude and rate. For slender HGV configurations, thermal loads and drag generation are strongly correlated-lower drag typically results in reduced surface heating. By embedding drag-sensitive soft constraints, the method improves energy efficiency and implicitly reduces surface temperatures, lowering the vehicle's infrared signature. These features are particularly advantageous for long-range military operations that require low observability. The approach is demonstrated using the DLR's Generic Hypersonic Glide Vehicle 2 (GHGV-2) simulation model. The results confirm the method's effectiveness in maintaining control authority under realistic, constrained flight conditions.

Paper number 37:
Title: CPU- and GPU-Based Parallelization of the Robust Reference Governor
Authors: Hamid R. Ossareh, William Shayne, Samuel Chevalier
Abstract: Constraint management is a central challenge in modern control systems. A solution is the Reference Governor (RG), which is an add-on strategy to pre-stabilized feedback control systems to enforce state and input constraints by shaping the reference command. While robust formulations of RG exist for linear systems, their extension to nonlinear systems is often computationally intractable. This paper develops a scenario-based robust RG formulation for nonlinear systems and investigates its parallel implementation on multi-core CPUs and CUDA-enabled GPUs. We analyze the computational structure of the algorithm, identify parallelization opportunities, and implement the resulting schemes on modern parallel hardware. Benchmarking on a nonlinear hydrogen fuel cell model demonstrates order-of-magnitude speedups (by as much as three orders of magnitude) compared to sequential implementations.

Paper number 38:
Title: Underground Power Distribution System Restoration Using Inverter Based Resources
Authors: Wenlong Shi, Hongyi Li, Zhaoyu Wang
Abstract: Underground power distribution systems (PDSs) are increasingly deployed in urban areas. The integration of smart devices including smart switchgears, pad-mounted distribution transformers and inverter-based resources (IBRs) enhance system resilience, however simultaneously introducing unique challenges. The challenges include inrush currents caused by trapped charges in underground cables, ferroresonance in distribution transformers during energization, and three-phase load imbalance resulting from single-phase underground laterals. To address these issues, this paper proposes an underground PDS restoration framework using IBRs. Firstly, an underground cable energization model is developed to quantify inrush current by analyzing voltage differences across both switchgear terminals. Secondly, a distribution transformer energization model is proposed to evaluate ferroresonance using Q-factor constraints based on underground cable capacitance and damping resistance. Thirdly, a phase-swapping model is proposed to improve load balancing by dynamically reassigning lateral-phase connections through smart switchgears. The proposed models are further integrated into a mixed-integer nonlinear programming (MINLP) formulation to maximize the total weighted restored load while constraining inrush currents, ferroresonance, and phase imbalance. To address the nonlinearity induced by impedance matrix reordering during phase swapping, a permutation-based linearization technique is proposed. Finally, case studies on an underground PDS established based on IEEE 123-Node Test Feeder validate the effectiveness of the proposed strategy in improving uderground PDS restoration performance.

Paper number 39:
Title: Learning to Mitigate Post-Outage Load Surges: A Data-Driven Framework for Electrifying and Decarbonizing Grids
Authors: Wenlong Shi, Dingwei Wang, Liming Liu, Zhaoyu Wang
Abstract: Electrification and decarbonization are transforming power system demand and recovery dynamics, yet their implications for post-outage load surges remain poorly understood. Here we analyze a metropolitan-scale heterogeneous dataset for Indianapolis comprising 30,046 feeder-level outages between 2020 and 2024, linked to smart meters and submetering, to quantify the causal impact of electric vehicles (EVs), heat pumps (HPs) and distributed energy resources (DERs) on restoration surges. Statistical analysis and causal forest inference demonstrate that rising penetrations of all three assets significantly increase surge ratios, with effects strongly modulated by restoration timing, outage duration and weather conditions. We develop a component-aware multi-task Transformer estimator that disaggregates EV, HP and DER contributions, and apply it to project historical outages under counterfactual 2035 adoption pathways. In a policy-aligned pathway, evening restorations emerge as the binding reliability constraint, with exceedance probabilities of 0.057 when 30\% of system load is restored within the first 15 minutes. Mitigation measures, probabilistic EV restarts, short thermostat offsets and accelerated DER reconnection, reduce exceedance to 0.019 and eliminate it entirely when 20\% or less of system load is restored. These results demonstrate that transition-era surges are asset-driven and causally linked to electrification and decarbonization, but can be effectively managed through integrated operational strategies.

Paper number 40:
Title: DialoSpeech: Dual-Speaker Dialogue Generation with LLM and Flow Matching
Authors: Hanke Xie, Dake Guo, Chengyou Wang, Yue Li, Wenjie Tian, Xinfa Zhu, Xinsheng Wang, Xiulin Li, Guanqiong Miao, Bo Liu, Lei Xie
Abstract: Recent advances in text-to-speech (TTS) synthesis, particularly those leveraging large language models (LLMs), have significantly improved expressiveness and naturalness. However, generating human-like, interactive dialogue speech remains challenging. Current systems face limitations due to the scarcity of dual-track data and difficulties in achieving naturalness, contextual coherence, and interactional dynamics, such as turn-taking, overlapping speech, and speaker consistency, in multi-turn conversations. To address these challenges, we propose DialoSpeech, a dual-track architecture combining a large language model with Chunked Flow Matching for expressive, human-like dialogue speech synthesis. DialoSpeech generates natural multi-turn conversations with coherent speaker turns and natural overlaps, supporting both Chinese and English and cross-lingual speech synthesis. We introduce a data processing pipeline to construct dual-track dialogue datasets, facilitating scalable training and experimental validation. Experiments show that our model outperforms baselines, offering a solution for generating human-like spoken dialogues. Audio samples are available at this https URL

Paper number 41:
Title: MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean Flows
Authors: Guobin Ma, Jixun Yao, Ziqian Ning, Yuepeng Jiang, Lingxin Xiong, Lei Xie, Pengcheng Zhu
Abstract: Zero-shot voice conversion (VC) aims to transfer timbre from a source speaker to any unseen target speaker while preserving linguistic content. Growing application scenarios demand models with streaming inference capabilities. This has created a pressing need for models that are simultaneously fast, lightweight, and high-fidelity. However, existing streaming methods typically rely on either autoregressive (AR) or non-autoregressive (NAR) frameworks, which either require large parameter sizes to achieve strong performance or struggle to generalize to unseen speakers. In this study, we propose MeanVC, a lightweight and streaming zero-shot VC approach. MeanVC introduces a diffusion transformer with a chunk-wise autoregressive denoising strategy, combining the strengths of both AR and NAR paradigms for efficient streaming processing. By introducing mean flows, MeanVC regresses the average velocity field during training, enabling zero-shot VC with superior speech quality and speaker similarity in a single sampling step by directly mapping from the start to the endpoint of the flow trajectory. Additionally, we incorporate diffusion adversarial post-training to mitigate over-smoothing and further enhance speech quality. Experimental results demonstrate that MeanVC significantly outperforms existing zero-shot streaming VC systems, achieving superior conversion quality with higher efficiency and significantly fewer parameters. Audio demos and code are publicly available at this https URL.

Paper number 42:
Title: A Digital Pheromone-Based Approach for In/Out-of-Control Classification
Authors: Pedro Pestana, M. Ftima Brilhante
Abstract: In complex production lines, it is essential to have strict, fast-acting rules to determine whether the system is In Control (InC) or Out of Control (OutC). This study explores a bio-inspired method that digitally mimics ant colony behavior to classify InC/OutC states and forecast imminent transitions requiring maintenance. A case study on industrial potato chip frying provides the application context. During each two-minute frying cycle, sequences of eight temperature readings are collected. Each sequence is treated as a digital ant depositing virtual pheromones, generating a Base Score. New sequences, representing new ants, can either reinforce or weaken this score, leading to a Modified Base Score that reflects the system's evolving condition. Signals such as extreme temperatures, large variations within a sequence, or the detection of change-points contribute to a Threat Score, which is added to the Modified Base Score. Since pheromones naturally decay over time unless reinforced, an Environmental Score is incorporated to reflect recent system dynamics, imitating real ant behavior. This score is calculated from the Modified Base Scores collected over the past hour. The resulting Total Score - the sum of the Modified Base Score, Threat Score, and Environmental Score - is used as the main indicator for real-time system classification and forecasting of transitions from InC to OutC. This ant colony optimization-inspired approach provides an adaptive and interpretable framework for process monitoring and predictive maintenance in industrial environments.

Paper number 43:
Title: Beyond Grid-Locked Voxels: Neural Response Functions for Continuous Brain Encoding
Authors: Haomiao Chen, Keith W Jamison, Mert R. Sabuncu, Amy Kuceyeski
Abstract: Neural encoding models aim to predict fMRI-measured brain responses to natural images. fMRI data is acquired as a 3D volume of voxels, where each voxel has a defined spatial location in the brain. However, conventional encoding models often flatten this volume into a 1D vector and treat voxel responses as independent outputs. This removes spatial context, discards anatomical information, and ties each model to a subject-specific voxel grid. We introduce the Neural Response Function (NRF), a framework that models fMRI activity as a continuous function over anatomical space rather than a flat vector of voxels. NRF represents brain activity as a continuous implicit function: given an image and a spatial coordinate (x, y, z) in standardized MNI space, the model predicts the response at that location. This formulation decouples predictions from the training grid, supports querying at arbitrary spatial resolutions, and enables resolution-agnostic analyses. By grounding the model in anatomical space, NRF exploits two key properties of brain responses: (1) local smoothness -- neighboring voxels exhibit similar response patterns; modeling responses continuously captures these correlations and improves data efficiency, and (2) cross-subject alignment -- MNI coordinates unify data across individuals, allowing a model pretrained on one subject to be fine-tuned on new subjects. In experiments, NRF outperformed baseline models in both intrasubject encoding and cross-subject adaptation, achieving high performance while reducing the data size needed by orders of magnitude. To our knowledge, NRF is the first anatomically aware encoding model to move beyond flattened voxels, learning a continuous mapping from images to brain responses in 3D space.

Paper number 44:
Title: Local MAP Sampling for Diffusion Models
Authors: Shaorong Zhang, Rob Brekelmans, Greg Ver Steeg
Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the goal of inverse problem solving is not to cover the posterior but to recover the most accurate reconstruction, where optimization-based diffusion solvers often excel despite lacking a clear probabilistic foundation. We introduce Local MAP Sampling (LMAPS), a new inference framework that iteratively solving local MAP subproblems along the diffusion trajectory. This perspective clarifies their connection to global MAP estimation and DPS, offering a unified probabilistic interpretation for optimization-based methods. Building on this foundation, we develop practical algorithms with a probabilistically interpretable covariance approximation, a reformulated objective for stability and interpretability, and a gradient approximation for non-differentiable operators. Across a broad set of image restoration and scientific tasks, LMAPS achieves state-of-the-art performance, including $\geq 2$ dB gains on motion deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on inverse scattering benchmarks.

Paper number 45:
Title: Mitigating Surgical Data Imbalance with Dual-Prediction Video Diffusion Model
Authors: Danush Kumar Venkatesh, Adam Schmidt, Muhammad Abdullah Jamal, Omid Mohareri
Abstract: Surgical video datasets are essential for scene understanding, enabling procedural modeling and intra-operative support. However, these datasets are often heavily imbalanced, with rare actions and tools under-represented, which limits the robustness of downstream models. We address this challenge with $SurgiFlowVid$, a sparse and controllable video diffusion framework for generating surgical videos of under-represented classes. Our approach introduces a dual-prediction diffusion module that jointly denoises RGB frames and optical flow, providing temporal inductive biases to improve motion modeling from limited samples. In addition, a sparse visual encoder conditions the generation process on lightweight signals (e.g., sparse segmentation masks or RGB frames), enabling controllability without dense annotations. We validate our approach on three surgical datasets across tasks including action recognition, tool presence detection, and laparoscope motion prediction. Synthetic data generated by our method yields consistent gains of 10-20% over competitive baselines, establishing $SurgiFlowVid$ as a promising strategy to mitigate data imbalance and advance surgical video understanding methods.

Paper number 46:
Title: Learning from Limited Multi-Phase CT: Dual-Branch Prototype-Guided Framework for Early Recurrence Prediction in HCC
Authors: Hsin-Pei Yu, Si-Qin Lyu, Yi-Hsien Hsieh, Weichung Wang, Tung-Hung Su, Jia-Horng Kao, Che Lin
Abstract: Early recurrence (ER) prediction after curative-intent resection remains a critical challenge in the clinical management of hepatocellular carcinoma (HCC). Although contrast-enhanced computed tomography (CT) with full multi-phase acquisition is recommended in clinical guidelines and routinely performed in many tertiary centers, complete phase coverage is not consistently available across all institutions. In practice, single-phase portal venous (PV) scans are often used alone, particularly in settings with limited imaging resources, variations in acquisition protocols, or patient-related factors such as contrast intolerance or motion artifacts. This variability results in a mismatch between idealized model assumptions and the practical constraints of real-world deployment, underscoring the need for methods that can effectively leverage limited multi-phase data. To address this challenge, we propose a Dual-Branch Prototype-guided (DuoProto) framework that enhances ER prediction from single-phase CT by leveraging limited multi-phase data during training. DuoProto employs a dual-branch architecture: the main branch processes single-phase images, while the auxiliary branch utilizes available multi-phase scans to guide representation learning via cross-domain prototype alignment. Structured prototype representations serve as class anchors to improve feature discrimination, and a ranking-based supervision mechanism incorporates clinically relevant recurrence risk factors. Extensive experiments demonstrate that DuoProto outperforms existing methods, particularly under class imbalance and missing-phase conditions. Ablation studies further validate the effectiveness of the dual-branch, prototype-guided design. Our framework aligns with current clinical application needs and provides a general solution for recurrence risk prediction in HCC, supporting more informed decision-making.

Paper number 47:
Title: LASER: An LLM-based ASR Scoring and Evaluation Rubric
Authors: Amruta Parulekar, Preethi Jyothi
Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly penalize morphological and syntactic nuances that do not significantly alter sentence semantics. We introduce an LLM-based scoring rubric LASER that leverages state-of-the-art LLMs' in-context learning abilities to learn from prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro achieved a very high correlation score of 94% with human annotations. Hindi examples in the prompt were also effective in analyzing errors in other Indian languages such as Marathi, Kannada and Malayalam. We also demonstrate how a smaller LLM like Llama 3 can be finetuned on word-pair examples derived from reference and ASR predictions to predict what kind of penalty should be applied with close to 89% accuracy.

Paper number 48:
Title: Can Speech LLMs Think while Listening?
Authors: Yi-Jen Shih, Desh Raj, Chunyang Wu, Wei Zhou, SK Bong, Yashesh Gaur, Jay Mahadeokar, Ozlem Kalinli, Mike Seltzer
Abstract: Recent advances in speech large language models (speech LLMs) have enabled seamless spoken interactions, but these systems still struggle with complex reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning has been to shown to significantly improve the reasoning abilities of text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for multi-stream speech LLMs, demonstrating that reasoning in text space improves the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken reasoning tasks. Beyond accuracy, the latency of the spoken response is a crucial factor for interacting with voice-based agents. Inspired by the human behavior of "thinking while listening," we propose methods to reduce the additional latency from reasoning by allowing the model to start reasoning before the user query has ended. To achieve this, we introduce an entropy-based metric, "question completeness," which acts as an indicator to guide the model on the optimal time to start reasoning. This method provides greater control over the accuracy-latency trade-off compared with heuristic-based approaches and, under equivalent latency conditions, yields a 4% accuracy gain on ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference data created using rejection sampling to push the accuracy-latency pareto frontier further, resulting in a 70% reduction in latency without loss in accuracy.

Paper number 49:
Title: Estimating Fair Graphs from Graph-Stationary Data
Authors: Madeline Navarro, Andrei Buciulea, Samuel Rey, Antonio G. Marques, Santiago Segarra
Abstract: We estimate fair graphs from graph-stationary nodal observations such that connections are not biased with respect to sensitive attributes. Edges in real-world graphs often exhibit preferences for connecting certain pairs of groups. Biased connections can not only exacerbate but even induce unfair treatment for downstream graph-based tasks. We therefore consider group and individual fairness for graphs corresponding to group- and node-level definitions, respectively. To evaluate the fairness of a given graph, we provide multiple bias metrics, including novel measurements in the spectral domain. Furthermore, we propose Fair Spectral Templates (FairSpecTemp), an optimization-based method with two variants for estimating fair graphs from stationary graph signals, a general model for graph data subsuming many existing ones. One variant of FairSpecTemp exploits commutativity properties of graph stationarity while directly constraining bias, while the other implicitly encourages fair estimates by restricting bias in the graph spectrum and is thus more flexible. Our methods enjoy high probability performance bounds, yielding a conditional tradeoff between fairness and accuracy. In particular, our analysis reveals that accuracy need not be sacrificed to recover fair graphs. We evaluate FairSpecTemp on synthetic and real-world data sets to illustrate its effectiveness and highlight the advantages of both variants of FairSpecTemp.

Paper number 50:
Title: Accuracy, Memory Efficiency and Generalization: A Comparative Study on Liquid Neural Networks and Recurrent Neural Networks
Authors: Shilong Zong, Alex Bierly, Almuatazbellah Boker, Hoda Eldardiry
Abstract: This review aims to conduct a comparative analysis of liquid neural networks (LNNs) and traditional recurrent neural networks (RNNs) and their variants, such as long short-term memory networks (LSTMs) and gated recurrent units (GRUs). The core dimensions of the analysis include model accuracy, memory efficiency, and generalization ability. By systematically reviewing existing research, this paper explores the basic principles, mathematical models, key characteristics, and inherent challenges of these neural network architectures in processing sequential data. Research findings reveal that LNN, as an emerging, biologically inspired, continuous-time dynamic neural network, demonstrates significant potential in handling noisy, non-stationary data, and achieving out-of-distribution (OOD) generalization. Additionally, some LNN variants outperform traditional RNN in terms of parameter efficiency and computational speed. However, RNN remains a cornerstone in sequence modeling due to its mature ecosystem and successful applications across various tasks. This review identifies the commonalities and differences between LNNs and RNNs, summarizes their respective shortcomings and challenges, and points out valuable directions for future research, particularly emphasizing the importance of improving the scalability of LNNs to promote their application in broader and more complex scenarios.

Paper number 51:
Title: Transformer-Based Indirect Structural Health Monitoring of Rail Infrastructure with Attention-Driven Detection and Localization of Transient Defects
Authors: Sizhe Ma, Katherine A. Flanigan, Mario Bergs, James D. Brooks
Abstract: Indirect structural health monitoring (iSHM) for broken rail detection using onboard sensors presents a cost-effective paradigm for railway track assessment, yet reliably detecting small, transient anomalies (2-10 cm) remains a significant challenge due to complex vehicle dynamics, signal noise, and the scarcity of labeled data limiting supervised approaches. This study addresses these issues through unsupervised deep learning. We introduce an incremental synthetic data benchmark designed to systematically evaluate model robustness against progressively complex challenges like speed variations, multi-channel inputs, and realistic noise patterns encountered in iSHM. Using this benchmark, we evaluate several established unsupervised models alongside our proposed Attention-Focused Transformer. Our model employs a self-attention mechanism, trained via reconstruction but innovatively deriving anomaly scores primarily from deviations in learned attention weights, aiming for both effectiveness and computational efficiency. Benchmarking results reveal that while transformer-based models generally outperform others, all tested models exhibit significant vulnerability to high-frequency localized noise, identifying this as a critical bottleneck for practical deployment. Notably, our proposed model achieves accuracy comparable to the state-of-the-art solution while demonstrating better inference speed. This highlights the crucial need for enhanced noise robustness in future iSHM models and positions our more efficient attention-based approach as a promising foundation for developing practical onboard anomaly detection systems.

Paper number 52:
Title: GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control
Authors: Alexander Du, Emre Adabag, Gabriel Bravo, Brian Plancher
Abstract: While Model Predictive Control (MPC) delivers strong performance across robotics applications, solving the underlying (batches of) nonlinear trajectory optimization (TO) problems online remains computationally demanding. Existing GPU-accelerated approaches typically (i) parallelize a single solve to meet real-time deadlines, (ii) scale to very large batches at slower-than-real-time rates, or (iii) achieve speed by restricting model generality (e.g., point-mass dynamics or a single linearization). This leaves a large gap in solver performance for many state-of-the-art MPC applications that require real-time batches of tens to low-hundreds of solves. As such, we present GATO, an open source, GPU-accelerated, batched TO solver co-designed across algorithm, software, and computational hardware to deliver real-time throughput for these moderate batch size regimes. Our approach leverages a combination of block-, warp-, and thread-level parallelism within and across solves for ultra-high performance. We demonstrate the effectiveness of our approach through a combination of: simulated benchmarks showing speedups of 18-21x over CPU baselines and 1.4-16x over GPU baselines as batch size increases; case studies highlighting improved disturbance rejection and convergence behavior; and finally a validation on hardware using an industrial manipulator. We open source GATO to support reproducibility and adoption.

Paper number 53:
Title: EB-MBD: Emerging-Barrier Model-Based Diffusion for Safe Trajectory Optimization in Highly Constrained Environments
Authors: Raghav Mishra, Ian R. Manchester
Abstract: We propose enforcing constraints on Model-Based Diffusion by introducing emerging barrier functions inspired by interior point methods. We show that constraints on Model-Based Diffusion can lead to catastrophic performance degradation, even on simple 2D systems due to sample inefficiency in the Monte Carlo approximation of the score function. We introduce Emerging-Barrier Model-Based Diffusion (EB-MBD) which uses progressively introduced barrier constraints to avoid these problems, significantly improving solution quality, without the need for computationally expensive operations such as projections. We analyze the sampling liveliness of samples each iteration to inform barrier parameter scheduling choice. We demonstrate results for 2D collision avoidance and a 3D underwater manipulator system and show that our method achieves lower cost solutions than Model-Based Diffusion, and requires orders of magnitude less computation time than projection based methods.

Paper number 54:
Title: ACMID: Automatic Curation of Musical Instrument Dataset for 7-Stem Music Source Separation
Authors: Ji Yu, Yang shuo, Xu Yuetonghui, Liu Mengmei, Ji Qiang, Han Zerui
Abstract: Most current music source separation (MSS) methods rely on supervised learning, limited by training data quantity and quality. Though web-crawling can bring abundant data, platform-level track labeling often causes metadata mismatches, impeding accurate "audio-label" pair acquisition. To address this, we present ACMID: a dataset for MSS generated through web crawling of extensive raw data, followed by automatic cleaning via an instrument classifier built on a pre-trained audio encoder that filters and aggregates clean segments of target instruments from the crawled tracks, resulting in the refined ACMID-Cleaned dataset. Leveraging abundant data, we expand the conventional classification from 4-stem (Vocal/Bass/Drums/Others) to 7-stem (Piano/Drums/Bass/Acoustic Guitar/Electric Guitar/Strings/Wind-Brass), enabling high granularity MSS systems. Experiments on SOTA MSS model demonstrates two key results: (i) MSS model trained with ACMID-Cleaned achieved a 2.39dB improvement in SDR performance compared to that with ACMID-Uncleaned, demostrating the effectiveness of our data cleaning procedure; (ii) incorporating ACMID-Cleaned to training enhances MSS model's average performance by 1.16dB, confirming the value of our dataset. Our data crawling code, cleaning model code and weights are available at: this https URL.

Paper number 55:
Title: Personality-Enhanced Multimodal Depression Detection in the Elderly
Authors: Honghong Wang, Jing Deng, Rong Zheng
Abstract: This paper presents our solution to the Multimodal Personality-aware Depression Detection (MPDD) challenge at ACM MM 2025. We propose a multimodal depression detection model in the Elderly that incorporates personality characteristics. We introduce a multi-feature fusion approach based on a co-attention mechanism to effectively integrate LLDs, MFCCs, and Wav2Vec features in the audio modality. For the video modality, we combine representations extracted from OpenFace, ResNet, and DenseNet to construct a comprehensive visual feature set. Recognizing the critical role of personality in depression detection, we design an interaction module that captures the relationships between personality traits and multimodal features. Experimental results from the MPDD Elderly Depression Detection track demonstrate that our method significantly enhances performance, providing valuable insights for future research in multimodal depression detection among elderly populations.

Paper number 56:
Title: Optimizing BCI Rehabilitation Protocols for Stroke: Exploring Task Design and Training Duration
Authors: Aniana Cruz, Marko Kuzmanoski, Gabriel Pires
Abstract: Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions.

Paper number 57:
Title: Leveraging Whisper Embeddings for Audio-based Lyrics Matching
Authors: Eleonora Mancini, Joan Serr, Paolo Torroni, Yuki Mitsufuji
Abstract: Audio-based lyrics matching can be an appealing alternative to other content-based retrieval approaches, but existing methods often suffer from limited reproducibility and inconsistent baselines. In this work, we introduce WEALY, a fully reproducible pipeline that leverages Whisper decoder embeddings for lyrics matching tasks. WEALY establishes robust and transparent baselines, while also exploring multimodal extensions that integrate textual and acoustic features. Through extensive experiments on standard datasets, we demonstrate that WEALY achieves a performance comparable to state-of-the-art methods that lack reproducibility. In addition, we provide ablation studies and analyses on language robustness, loss functions, and embedding strategies. This work contributes a reliable benchmark for future research, and underscores the potential of speech technologies for music information retrieval tasks.

Paper number 58:
Title: Quantum memory optimisation using finite-horizon, decoherence time and discounted mean-square performance criteria
Authors: Igor G. Vladimirov, Ian R. Petersen, Guodong Shi
Abstract: This paper is concerned with open quantum memory systems for approximately retaining quantum information, such as initial dynamic variables or quantum states to be stored over a bounded time interval. In the Heisenberg picture of quantum dynamics, the deviation of the system variables from their initial values lends itself to closed-form computation in terms of tractable moment dynamics for open quantum harmonic oscillators and finite-level quantum systems governed by linear or quasi-linear Hudson-Parthasarathy quantum stochastic differential equations, respectively. This tractability is used in a recently proposed optimality criterion for varying the system parameters so as to maximise the memory decoherence time when the mean-square deviation achieves a given critical threshold. The memory decoherence time maximisation approach is extended beyond the previously considered low-threshold asymptotic approximation and to Schrdinger type mean-square deviation functionals for the reduced system state governed by the Lindblad master equation. We link this approach with the minimisation of the mean-square deviation functionals at a finite time horizon and with their discounted version which quantifies the averaged performance of the quantum system as a temporary memory under a Poisson flow of storage requests.

Paper number 59:
Title: Reliability of Single-Level Equality-Constrained Inverse Optimal Control
Authors: Filip Beanovi (1), Kosta Jovanovi (1), Vincent Bonnet (2) ((1) University of Belgrade - School of Electrical Engineering, (2) LAAS-CNRS)
Abstract: Inverse optimal control (IOC) allows the retrieval of optimal cost function weights, or behavioral parameters, from human motion. The literature on IOC uses methods that are either based on a slow bilevel process or a fast but noise-sensitive minimization of optimality condition violation. Assuming equality-constrained optimal control models of human motion, this article presents a faster but robust approach to solving IOC using a single-level reformulation of the bilevel method and yields equivalent results. Through numerical experiments in simulation, we analyze the robustness to noise of the proposed single-level reformulation to the bilevel IOC formulation with a human-like planar reaching task that is used across recent studies. The approach shows resilience to very large levels of noise and reduces the computation time of the IOC on this task by a factor of 15 when compared to a classical bilevel implementation.

Paper number 60:
Title: Conformal Robust Control of Linear Systems
Authors: Yash Patel, Sahana Rayan, Ambuj Tewari
Abstract: End-to-end engineering design pipelines, in which designs are evaluated using concurrently defined optimal controllers, are becoming increasingly common in practice. To discover designs that perform well even under the misspecification of system dynamics, such end-to-end pipelines have now begun evaluating designs with a robust control objective in place of the nominal optimal control setup. Current approaches of specifying such robust control subproblems, however, rely on hand specification of perturbations anticipated to be present upon deployment or margin methods that ignore problem structure, resulting in a lack of theoretical guarantees and overly conservative empirical performance. We, instead, propose a novel methodology for LQR systems that leverages conformal prediction to specify such uncertainty regions in a data-driven fashion. Such regions have distribution-free coverage guarantees on the true system dynamics, in turn allowing for a probabilistic characterization of the regret of the resulting robust controller. We then demonstrate that such a controller can be efficiently produced via a novel policy gradient method that has convergence guarantees. We finally demonstrate the superior empirical performance of our method over alternate robust control specifications, such as $H_{\infty}$ and LQR with multiplicative noise, across a collection of engineering control systems.

Paper number 61:
Title: From Simulation to Practice: Generalizable Deep Reinforcement Learning for Cellular Schedulers
Authors: Petteri Kela, Bryan Liu, Alvaro Valcarce
Abstract: Efficient radio packet scheduling remains one of the most challenging tasks in cellular networks, and while heuristic methods exist, practical deep learning-based schedulers that are 3GPP-compliant and capable of real-time operation in 5G and beyond are still missing. To address this, we first take a critical look at previous deep scheduler efforts. Secondly, we enhance State-of-the-Art (SoTA) deep Reinforcement Learning (RL) algorithms and adapt them to train our deep scheduler. In particular, we propose a novel combination of training techniques for Proximal Policy Optimization (PPO) and a new Distributional Soft Actor-Critic Discrete (DSACD) algorithm, which outperformed other variants tested. These improvements were achieved while maintaining minimal actor network complexity, making them suitable for real-time computing environments. Furthermore, entropy learning in SACD was fine-tuned to accommodate resource allocation action spaces of varying sizes. Our proposed deep schedulers exhibited strong generalization across different bandwidths, number of Multi-User MIMO (MU-MIMO) layers, and traffic models. Ultimately, we show that our pre-trained deep schedulers outperform their heuristic rivals in realistic and standard-compliant 5G system-level simulations.

Paper number 62:
Title: A Long-Duration Autonomy Approach to Connected and Automated Vehicles
Authors: Logan E. Beaver
Abstract: In this article, we present a long-duration autonomy approach for the control of connected and automated vehicles (CAVs) operating in a transportation network. In particular, we focus on the performance of CAVs at traffic bottlenecks, including roundabouts, merging roadways, and intersections. We take a principled approach based on optimal control, and derive a reactive controller with guarantees on safety, performance, and energy efficiency. We guarantee safety through high order control barrier functions (HOCBFs), which we ``lift'' to first order CBFs using time-optimal motion primitives. This yields a set of first-order CBFs that are compatible with the control bounds. We demonstrate the performance of our approach in simulation and compare it to an optimal control-based approach.

Paper number 63:
Title: WaveMax: Radar Waveform Design via Convex Maximization of FrFT Phase Retrieval
Authors: Samuel Pinilla, Kumar Vijay Mishra, Brian M. Sadler
Abstract: The ambiguity function (AF) is a critical tool in radar waveform design, representing the two-dimensional correlation between a transmitted signal and its time-delayed, frequency-shifted version. Obtaining a radar signal to match a specified AF magnitude is a bi-variate variant of the well-known phase retrieval problem. Prior approaches to this problem were either limited to a few classes of waveforms or lacked a computable procedure to estimate the signal. Our recent work provided a framework for solving this problem for both band- and time-limited signals using non-convex optimization. In this paper, we introduce a novel approach WaveMax that formulates waveform recovery as a convex optimization problem by relying on the fractional Fourier transform (FrFT)-based AF. We exploit the fact that AF of the FrFT of the original signal is equivalent to a rotation of the original AF. In particular, we reconstruct the radar signal by solving a low-rank minimization problem, which approximates the waveform using the leading eigenvector of a matrix derived from the AF. Our theoretical analysis shows that unique waveform reconstruction is achievable with a sample size no more than three times the signal frequencies or time samples. Numerical experiments validate the efficacy of WaveMax in recovering signals from noiseless and noisy AF, including scenarios with randomly and uniformly sampled sparse data.

Paper number 64:
Title: Efficient Multi Subject Visual Reconstruction from fMRI Using Aligned Representations
Authors: Christos Zangos, Danish Ebadulla, Thomas Christopher Sprague, Ambuj Singh
Abstract: This work introduces a novel approach to fMRI-based visual image reconstruction using a subject-agnostic common representation space. We show that the brain signals of the subjects can be aligned in this common space during training to form a semantically aligned common brain. This is leveraged to demonstrate that aligning subject-specific lightweight modules to a reference subject is significantly more efficient than traditional end-to-end training methods. Our approach excels in low-data scenarios. We evaluate our methods on different datasets, demonstrating that the common space is subject and dataset-agnostic.

Paper number 65:
Title: SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems
Authors: Almoatssimbillah Saifaldawla, Eva Lagunas, Flor Ortiz, Abuzar B. M. Adam, Symeon Chatzinotas
Abstract: In this paper, we investigate downlink co-frequency interference (CFI) mitigation in non-geostationary satellites orbits (NGSOs) co-existing systems. Traditional mitigation techniques, such as Zero-forcing (ZF), produce a null towards the direction of arrivals (DOAs) of the interfering signals, but they suffer from high computational complexity due to matrix inversions and required knowledge of the channel state information (CSI). Furthermore, adaptive beamformers, such as sample matrix inversion (SMI)-based minimum variance, provide poor performance when the available snapshots are limited. We propose a Mamba-based beamformer (MambaBF) that leverages an unsupervised deep learning (DL) approach and can be deployed on the user terminal (UT) antenna array, for assisting downlink beamforming and CFI mitigation using only a limited number of available array snapshots as input, and without CSI knowledge. Simulation results demonstrate that MambaBF consistently outperforms conventional beamforming techniques in mitigating interference and maximizing the signal-to-interference-plus-noise ratio (SINR), particularly under challenging conditions characterized by low SINR, limited snapshots, and imperfect CSI.

Paper number 66:
Title: SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with in-Context Enhancement
Authors: Kuan-Yu Chen, Jeng-Lin Li, Jian-Jiun Ding
Abstract: With the fast development of zero-shot text-to-speech technologies, it is possible to generate high-quality speech signals that are indistinguishable from the real ones. Speech editing, including speech insertion and replacement, appeals to researchers due to its potential applications. However, existing studies only considered clean speech scenarios. In real-world applications, the existence of environmental noise could significantly degrade the quality of generation. In this study, we propose a noise-resilient speech editing framework, SeamlessEdit, for noisy speech editing. SeamlessEdit adopts a frequency-band-aware noise suppression module and an in-content refinement strategy. It can well address the scenario where the frequency bands of voice and background noise are not separated. The proposed SeamlessEdit framework outperforms state-of-the-art approaches in multiple quantitative and qualitative evaluations.

Paper number 67:
Title: MAMBO: High-Resolution Generative Approach for Mammography Images
Authors: Milica kipina, Nikola Jovii, Nicola Dall'Asen, Vanja venda, Anil Osman Tur, Slobodan Ili, Elisa Ricci, Dubravko ulibrk
Abstract: Mammography is the gold standard for the detection and diagnosis of breast cancer. This procedure can be significantly enhanced with Artificial Intelligence (AI)-based software, which assists radiologists in identifying abnormalities. However, training AI systems requires large and diverse datasets, which are often difficult to obtain due to privacy and ethical constraints. To address this issue, the paper introduces MAMmography ensemBle mOdel (MAMBO), a novel patch-based diffusion approach designed to generate full-resolution mammograms. Diffusion models have shown breakthrough results in realistic image generation, yet few studies have focused on mammograms, and none have successfully generated high-resolution outputs required to capture fine-grained features of small lesions. To achieve this, MAMBO integrates separate diffusion models to capture both local and global (image-level) contexts. The contextual information is then fed into the final model, significantly aiding the noise removal process. This design enables MAMBO to generate highly realistic mammograms of up to 3840x3840 pixels. Importantly, this approach can be used to enhance the training of classification models and extended to anomaly segmentation. Experiments, both numerical and radiologist validation, assess MAMBO's capabilities in image generation, super-resolution, and anomaly segmentation, highlighting its potential to enhance mammography analysis for more accurate diagnoses and earlier lesion detection. The source code used in this study is publicly available at: this https URL.

Paper number 68:
Title: Papanicolaou Stain Unmixing for RGB Image Using Weighted Nucleus Sparsity and Total Variation Regularization
Authors: Nanxin Gong, Saori Takeyama, Masahiro Yamaguchi, Takumi Urata, Fumikazu Kimura, Keiko Ishii
Abstract: The Papanicolaou stain, consisting of five dyes, provides extensive color information essential for cervical cancer cytological screening. The visual observation of these colors is subjective and difficult to characterize. Direct RGB quantification is unreliable because RGB intensities vary with staining and imaging conditions. Stain unmixing offers a promising alternative by quantifying dye amounts. In previous work, multispectral imaging was utilized to estimate the dye amounts of Papanicolaou stain. However, its application to RGB images presents a challenge since the number of dyes exceeds the three RGB channels. This paper proposes a novel training-free Papanicolaou stain unmixing method for RGB images. This model enforces (i) nonnegativity, (ii) weighted nucleus sparsity for hematoxylin, and (iii) total variation smoothness, resulting in a convex optimization problem. Our method achieved excellent performance in stain quantification when validated against the results of multispectral imaging. We further used it to distinguish cells in lobular endocervical glandular hyperplasia (LEGH), a precancerous gastric-type adenocarcinoma lesion, from normal endocervical cells. Stain abundance features clearly separated the two groups, and a classifier based on stain abundance achieved 98.0% accuracy. By converting subjective color impressions into numerical markers, this technique highlights the strong promise of RGB-based stain unmixing for quantitative diagnosis.

Paper number 69:
Title: Towards Frame-level Quality Predictions of Synthetic Speech
Authors: Michael Kuhlmann, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach
Abstract: While automatic subjective speech quality assessment has witnessed much progress, an open question is whether an automatic quality assessment at frame resolution is possible. This would be highly desirable, as it adds explainability to the assessment of speech synthesis systems. Here, we take first steps towards this goal by identifying issues of existing quality predictors that prevent sensible frame-level prediction. Further, we define criteria that a frame-level predictor should fulfill. We also suggest a chunk-based processing that avoids the impact of a localized distortion on the score of neighboring frames. Finally, we measure in experiments with localized artificial distortions the localization performance of a set of frame-level quality predictors and show that they can outperform detection performance of human annotations obtained from a crowd-sourced perception experiment.

Paper number 70:
Title: Revisiting Functional Derivatives in Multi-object Tracking
Authors: Jan Krej, Ondej Straka, Petr Girg, Ji Benedikt
Abstract: Probability generating functionals (PGFLs) are efficient and powerful tools for tracking independent objects in clutter. It was shown that PGFLs could be used for the elegant derivation of practical multi-object tracking algorithms, e.g., the probability hypothesis density (PHD) filter. However, derivations using PGFLs use the so-called functional derivatives whose definitions usually appear too complicated or heuristic, involving Dirac delta ``functions''. This paper begins by comparing different definitions of functional derivatives and exploring their relationships and implications for practical applications. It then proposes a rigorous definition of the functional derivative, utilizing straightforward yet precise mathematics for clarity. Key properties of the functional derivative are revealed and discussed.

Paper number 71:
Title: Recursive Aperture Decoded Ultrasound Imaging (READI) With Estimated Motion-Compensated Compounding (EMC2)
Authors: Tyler Keith Henry, Darren Dahunsi, Randy Palamar, Negar Majidi, Mohammad Rahim Sobhani, Afshin Kashani Ilkhechi, Roger Zemp
Abstract: Fast Orthogonal Row-Column Electronic Scanning (FORCES) is a Hadamard-encoded Synthetic Transmit Aperture (STA) imaging sequence using bias-sensitive Top-Orthogonal to Bottom Electrode (TOBE) arrays. It produces images with a higher Signal-to-Noise Ratio (SNR) and improved penetration depth compared to traditional STA techniques, but suffers from motion sensitivity due to ensemble size and aperture encoding. This work presents Recursive Aperture Decoded Ultrasound Imaging (READI), a novel decoding and beamforming technique for FORCES that produces multiple low-resolution images out of subsets of the FORCES sequence that are less susceptible to motion, but sum to form the complete FORCES image. Estimated Motion-Compensated Compounding (EMC2) describes the process of comparing these low-resolution images to estimate the underlying motion, then warping them to align before coherent compounding. READI with EMC2 is shown to fully recover images corrupted by probe motion, and restore tissue speckle and sharpness to an image of a beating heart. READI low-resolution images by themselves are demonstrated to be a marked improvement over sparse STA schemes with the same transmit count, and are shown to recover blood speckle at a flow rate of 42 cm/s.

Paper number 72:
Title: FireGNN: Neuro-Symbolic Graph Neural Networks with Trainable Fuzzy Rules for Interpretable Medical Image Classification
Authors: Prajit Sengupta, Islem Rekik
Abstract: Medical image classification requires not only high predictive performance but also interpretability to ensure clinical trust and adoption. Graph Neural Networks (GNNs) offer a powerful framework for modeling relational structures within datasets; however, standard GNNs often operate as black boxes, limiting transparency and usability, particularly in clinical settings. In this work, we present an interpretable graph-based learning framework named FireGNN that integrates trainable fuzzy rules into GNNs for medical image classification. These rules embed topological descriptors - node degree, clustering coefficient, and label agreement - using learnable thresholds and sharpness parameters to enable intrinsic symbolic reasoning. Additionally, we explore auxiliary self-supervised tasks (e.g., homophily prediction, similarity entropy) as a benchmark to evaluate the contribution of topological learning. Our fuzzy-rule-enhanced model achieves strong performance across five MedMNIST benchmarks and the synthetic dataset MorphoMNIST, while also generating interpretable rule-based explanations. To our knowledge, this is the first integration of trainable fuzzy rules within a GNN. Source Code: this https URL

Paper number 73:
Title: Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control
Authors: Max Studt, Georg Schildbach
Abstract: Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control.

Paper number 74:
Title: Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing
Authors: Mengqi Wang, Zhan Liu, Zengrui Jin, Guangzhi Sun, Chao Zhang, Philip C. Woodland
Abstract: Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements.

Paper number 75:
Title: How We Won BraTS-SSA 2025: Brain Tumor Segmentation in the Sub-Saharan African Population Using Segmentation-Aware Data Augmentation and Model Ensembling
Authors: Claudia Takyi Ankomah, Livingstone Eli Ayivor, Ireneaus Nyame, Leslie Wambo, Patrick Yeboah Bonsu, Aondona Moses Iorumbur, Raymond Confidence, Toufiq Musah
Abstract: Brain tumors, particularly gliomas, pose significant chall-enges due to their complex growth patterns, infiltrative nature, and the variability in brain structure across individuals, which makes accurate diagnosis and monitoring difficult. Deep learning models have been developed to accurately delineate these tumors. However, most of these models were trained on relatively homogenous high-resource datasets, limiting their robustness when deployed in underserved regions. In this study, we performed segmentation-aware offline data augmentation on the BraTS-Africa dataset to increase the data sample size and diversity to enhance generalization. We further constructed an ensemble of three distinct architectures, MedNeXt, SegMamba, and Residual-Encoder U-Net, to leverage their complementary strengths. Our best-performing model, MedNeXt, was trained on 1000 epochs and achieved the highest average lesion-wise dice and normalized surface distance scores of 0.86 and 0.81 respectively. However, the ensemble model trained for 500 epochs produced the most balanced segmentation performance across the tumour subregions. This work demonstrates that a combination of advanced augmentation and model ensembling can improve segmentation accuracy and robustness on diverse and underrepresented datasets. Code available at: this https URL

Paper number 76:
Title: Resilient Multi-Dimensional Consensus and Distributed Optimization against Agent-Based and Denial-of-Service Attacks
Authors: Hongjian Chen, Changyun Wen, Xiaolei Li, Jiaqi Yan
Abstract: In this paper, we consider the resilient multi-dimensional consensus and distributed optimization problems of multi-agent systems (MASs) in the presence of both agent-based and denial-of-service (DoS) attacks. The considered agent-based attacks can cover malicious, Byzantine, and stubborn agents. The links between agents in the network can be blocked by DoS attacks, which may lead the digraph to be time-varying and even disconnected. The objective is to ensure that the remaining benign agents achieve consensus. To this end, an "auxiliary point"-based resilient control algorithm is proposed for MASs. Under the proposed algorithm, each healthy agent constructs a "safe kernel" utilizing the states of its in-neighbors and updates its state toward a specific point within this kernel at each iteration. If an agent cannot receive its neighbors' states owing to DoS attacks, it will use the states received immediately before the DoS period. Moreover, a resilient multi-dimensional distributed optimization (RMDO) algorithm is also proposed. Theoretical proofs and numerical examples are presented to demonstrate the effectiveness of the proposed algorithms.

Paper number 77:
Title: Identification and optimal control strategies for the transversal splitting of ultra--cold Bose gases
Authors: Nikolaus Wrkner, Yevhenii Kuriatnikov, Karthikeyan Kumaran, M Venkat Ramana, Jrg Schmiedmayer, Andreas Kugi, Maximilian Prfer, Andreas Deutschmann-Olek
Abstract: Splitting a Bose--Einstein condensate (BEC) is a key operation in fundamental physics experiments and emerging quantum technologies, where precise preparation of well--defined initial states requires fast yet coherent control of the condensate's nonlinear dynamics. This work formulates the BEC splitting process as an optimal feedforward control problem based on a physically interpretable, reduced--order model identified from limited experimental data. We introduce a systematic calibration strategy that combines optimal experiment selection and constrained nonlinear parameter estimation, enabling accurate system identification with minimal experimental overhead. Using this calibrated model, we compute energy--optimal trajectories via indirect optimal control to realize shortcuts to adiabaticity (STAs), achieving rapid transitions to the ground state of a double--well potential while suppressing excitations. Experiments confirm that the proposed control framework yields high--fidelity state transfers across multiple configurations, demonstrating its robustness and scalability for quantum control applications.

Paper number 78:
Title: Panoramic Voltage-Sensitive Optical Mapping of Contracting Hearts using Cooperative Multi-View Motion Tracking with 12 to 24 Cameras
Authors: Shrey Chowdhary, Jan Lebert, Shai Dickman, Charles Gordon, Jan Christoph
Abstract: Voltage-sensitive fluorescence imaging is widely used to image action potential waves in the heart. However, while the electrical waves trigger mechanical contraction, imaging needs to be performed with pharmacologically contraction-inhibited hearts, limiting studies of the coupling between cardiac electrophysiology and tissue mechanics. Here, we introduce a high-resolution multi-camera optical mapping system with which we image action potential waves at high resolutions across the entire ventricular surface of the beating and strongly deforming heart. We imaged intact isolated rabbit hearts inside a soccer-ball shaped imaging chamber facilitating even illumination and panoramic imaging. Using 12 high-speed cameras, ratiometric voltage-sensitive imaging, and three-dimensional (3D) multi-view motion tracking, we reconstructed the entire 3D deforming ventricular surface and performed corresponding voltage-sensitive measurements during sinus rhythm, paced rhythm, and ventricular fibrillation. Our imaging setup defines a new state-of-the-art in the field and can be used to study the heart's electromechanical physiology during health and disease at unprecedented resolutions. For instance, we measured electrical activation times and observed mechanical strain waves following electrical activation fronts during pacing, observed electromechanical vortices during ventricular fibrillation, and measured action potential duration and contractile changes in response to pharmacological blockage of potassium ion channels.

Paper number 79:
Title: Optimal control of continuous-time symmetric systems with unknown dynamics and noisy measurements
Authors: Hamed Taghavian, Florian Dorfler, Mikael Johansson
Abstract: An iterative learning algorithm is presented for continuous-time linear-quadratic optimal control problems where the system is externally symmetric with unknown dynamics. Both finite-horizon and infinite-horizon problems are considered. It is shown that the proposed algorithm is globally convergent to the optimal solution and has some advantages over adaptive dynamic programming, including being unbiased under noisy measurements and having a relatively low computational burden. Numerical experiments show the effectiveness of the results.

Paper number 80:
Title: Foundation Models for Structural Health Monitoring
Authors: Luca Benfenati, Daniele Jahier Pagliari, Luca Zanatta, Yhorman Alexander Bedoya Velez, Andrea Acquaviva, Massimo Poncino, Enrico Macii, Luca Benini, Alessio Burrello
Abstract: Structural Health Monitoring (SHM) is a critical task for ensuring the safety and reliability of civil infrastructures, typically realized on bridges and viaducts by means of vibration monitoring. In this paper, we propose for the first time the use of Transformer neural networks, with a Masked Auto-Encoder architecture, as Foundation Models for SHM. We demonstrate the ability of these models to learn generalizable representations from multiple large datasets through self-supervised pre-training, which, coupled with task-specific fine-tuning, allows them to outperform state-of-the-art traditional methods on diverse tasks, including Anomaly Detection (AD) and Traffic Load Estimation (TLE). We then extensively explore model size versus accuracy trade-offs and experiment with Knowledge Distillation (KD) to improve the performance of smaller Transformers, enabling their embedding directly into the SHM edge nodes. We showcase the effectiveness of our foundation models using data from three operational viaducts. For AD, we achieve a near-perfect 99.9% accuracy with a monitoring time span of just 15 windows. In contrast, a state-of-the-art method based on Principal Component Analysis (PCA) obtains its first good result (95.03% accuracy), only considering 120 windows. On two different TLE tasks, our models obtain state-of-the-art performance on multiple evaluation metrics (R$^2$ score, MAE% and MSE%). On the first benchmark, we achieve an R$^2$ score of 0.97 and 0.90 for light and heavy vehicle traffic, respectively, while the best previous approach (a Random Forest) stops at 0.91 and 0.84. On the second one, we achieve an R$^2$ score of 0.54 versus the 0.51 of the best competitor method, a Long-Short Term Memory network.

Paper number 81:
Title: Objective Features Extracted from Motor Activity Time Series for Food Addiction Analysis Using Machine Learning -- A Pilot Study
Authors: Mikhail Borisenkov, Maksim Belyaev, Nithya Rekha Sivakumar, Murugappan Murugappan, Andrei Velichko, Dmitry Korzun, Tatyana Tserne, Larisa Bakutova, Denis Gubin
Abstract: Wearable sensors and IoT/IoMT platforms enable continuous, real-time monitoring, but objective digital markers for eating disorders are limited. In this study, we examined whether actimetry and machine learning (ML) could provide objective criteria for food addiction (FA) and symptom counts (SC). In 78 participants (mean age 22.1 +/- 9.5 y; 73.1% women), one week of non-dominant wrist actimetry and psychometric data (YFAS, DEBQ, ZSDS) were collected. The time series were segmented into daytime activity and nighttime rest, and statistical and entropy descriptors (FuzzyEn, DistEn, SVDEn, PermEn, PhaseEn; 256 features) were calculated. The mean Matthews correlation coefficient (MCC) was used as the primary metric in a K-nearest neighbors (KNN) pipeline with five-fold stratified cross-validation (one hundred repetitions; 500 evaluations); SHAP was used to assist in interpretation. For binary FA, activity-segment features performed best (MCC = 0.78 +/- 0.02; Accuracy ~ 95.3% +/- 0.5; Sensitivity ~ 0.77 +/- 0.03; Specificity ~ 0.98 +/- 0.004), exceeding OaS (Objective and Subjective Features) (MCC = 0.69 +/- 0.03) and rest-only (MCC = 0.50 +/- 0.03). For SC (four classes), OaS slightly surpassed actimetry (MCC = 0.40 +/- 0.01 vs 0.38 +/- 0.01; Accuracy ~ 58.1% vs 56.9%). Emotional and restrained eating were correlated with actimetric features. These findings support wrist-worn actimetry as a digital biomarker of FA that complements questionnaires and may facilitate privacy-preserving clinical translation.

Paper number 82:
Title: Scalable analysis of stop-and-go waves: Representation, measurements and insights
Authors: Junyi Ji, Derek Gloudemans, Yanbing Wang, Gergely Zachr, William Barbour, Jonathan Sprinkle, Benedetto Piccoli, Daniel B. Work
Abstract: Analyzing stop-and-go waves at the scale of miles and hours of data is an emerging challenge in traffic research. The past 5 years have seen an explosion in the availability of large-scale traffic data containing traffic waves and complex congestion patterns, making existing approaches unsuitable for repeatable and scalable analysis of traffic waves in these data. This paper makes a first step towards addressing this challenge by introducing an automatic and scalable stop-and-go wave identification method capable of capturing wave generation, propagation, dissipation, as well as bifurcation and merging, which have previously been observed only very rarely. Using a concise and simple critical-speed based definition of a stop-and-go wave, the proposed method identifies all wave boundaries that encompass spatio-temporal points where vehicle speed is below a chosen critical speed. The method is built upon a graph representation of the spatio-temporal points associated with stop-and-go waves, specifically wave front (start) points and wave tail (end) points, and approaches the solution as a graph component identification problem. It enables the measurement of wave properties at scale. The method is implemented in Python and demonstrated on a large-scale dataset, I-24 MOTION INCEPTION. Our results show insights on the complexity of traffic waves. Traffic waves can bifurcate and merge at a scale that has never been observed or described before. The clustering analysis of all the identified wave components reveals the different topological structures of traffic waves. We explored that the wave merge or bifurcation points can be explained by spatial features. The gallery of all the identified wave topologies is demonstrated at this https URL.

Paper number 83:
Title: Characterizing and Optimizing Real-Time Optimal Control for Embedded SoCs
Authors: Kris Shengjun Dong, Dima Nikiforov, Widyadewi Soedarmadji, Minh Nguyen, Vikram Jain, Christopher W. Fletcher, Yakun Sophia Shao
Abstract: Resource-limited robots face significant challenges in executing computationally intensive tasks, such as locomotion and manipulation, particularly for real-time optimal control algorithms like Model Predictive Control (MPC). This paper provides a comprehensive design space exploration to identify optimal hardware computation architectures for these demanding model-based control algorithms. We profile and optimize representative architectural designs, including general-purpose scalar CPUs, vector processors, and specialized accelerators. By characterizing kernel-level benchmarks and end-to-end robotic scenarios, including a hardware-in-the-loop evaluation on a fabricated RISC-V multi-core vector SoC, we present a quantitative comparison of performance, area, and utilization across distinct architectural design points. Our findings demonstrate that targeted architectural modifications, coupled with deep software and system optimizations, enable up to 3.71x speedups for MPC, resulting in up to 27% system-level power reductions while completing robotic tasks. Finally, we propose a code generation flow designed to simplify the complex engineering effort required for mapping robotic workloads onto specialized architectures.

Paper number 84:
Title: Performance Analysis of STAR-RIS-Assisted Cell-Free Massive MIMO Systems with Electromagnetic Interference and Phase Errors
Authors: Jun Qian, Ross Murch, Khaled B. Letaief
Abstract: Simultaneous Transmitting and Reflecting Reconfigurable Intelligent Surfaces (STAR-RISs) are being explored for sixth-generation (6G) wireless networks. A promising configuration for their deployment is within cell-free massive multiple-input multiple-output (MIMO) systems. However, despite the advantages that STAR-RISs could bring, challenges such as electromagnetic interference (EMI) and phase errors may lead to significant performance degradation. In this paper, we investigate the impact of EMI and phase errors on STAR-RIS-assisted cell-free massive MIMO systems and propose techniques to mitigate these effects. We introduce a tailored projected gradient descent (GD) algorithm for STAR-RIS coefficient matrix design by minimizing the local channel estimation normalized mean square error (NMSE). We also derive the novel closed-form expressions of the uplink and downlink spectral efficiency (SE) to analyze system performance with EMI and phase errors, in which fractional power control methods are introduced for performance improvement. The results reveal that the projected GD algorithm can effectively tackle EMI and phase errors to improve estimation accuracy and compensate for performance degradation with nearly 30% NMSE improvement and over 10% SE improvement. Moreover, increasing the number of access points (APs), antennas per AP, and STAR-RIS elements can also improve SE performance. However, the advantages of employing STAR-RIS are reduced when EMI and phase errors are severe. Notably, compared to conventional RISs, the incorporation of STAR-RIS in the proposed system yields better performance and presents less performance degradation in highly impaired environments.

Paper number 85:
Title: BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response
Authors: Hongruixuan Chen, Jian Song, Olivier Dietrich, Clifford Broni-Bediako, Weihao Xuan, Junjue Wang, Xinlei Shao, Yimin Wei, Junshi Xia, Cuiling Lan, Konrad Schindler, Naoto Yokoya
Abstract: Disaster events occur around the world and cause significant damage to human life and property. Earth observation (EO) data enables rapid and comprehensive building damage assessment (BDA), an essential capability in the aftermath of a disaster to reduce human casualties and to inform disaster relief efforts. Recent research focuses on the development of AI models to achieve accurate mapping of unseen disaster events, mostly using optical EO data. However, solutions based on optical data are limited to clear skies and daylight hours, preventing a prompt response to disasters. Integrating multimodal (MM) EO data, particularly the combination of optical and SAR imagery, makes it possible to provide all-weather, day-and-night disaster responses. Despite this potential, the development of robust multimodal AI models has been constrained by the lack of suitable benchmark datasets. In this paper, we present a BDA dataset using veRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based all-weather disaster response. To the best of our knowledge, BRIGHT is the first open-access, globally distributed, event-diverse MM dataset specifically curated to support AI-based disaster response. It covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries where external assistance is most needed. The optical and SAR imagery in BRIGHT, with a spatial resolution between 0.3-1 meters, provides detailed representations of individual buildings, making it ideal for precise BDA. In our experiments, we have tested seven advanced AI models trained with our BRIGHT to validate the transferability and robustness. The dataset and code are available at this https URL. BRIGHT also serves as the official dataset for the 2025 IEEE GRSS Data Fusion Contest.

Paper number 86:
Title: Carleman-Fourier linearization of nonlinear real dynamical systems with quasi-periodic fields
Authors: Nader Motee, Qiyu Sun
Abstract: This paper presents Carleman-Fourier linearization for analyzing nonlinear real dynamical systems with periodic vector fields. Using Fourier basis functions, this novel framework transforms such dynamical systems into equivalent infinite-dimensional linear dynamical systems. In this paper, we establish the exponential convergence of the primary block in the finite-section approximation of this linearized system to the state vector of the original nonlinear system. To showcase the efficacy of our approach, we apply it to the Kuramoto model, a prominent model for coupled oscillators. The results demonstrate promising accuracy in approximating the original system's behavior.

Paper number 87:
Title: Learn to Bid as a Price-Maker Wind Power Producer
Authors: Shobhit Singhal, Marta Fochesato, Liviu Aolaritei, Florian Drfler
Abstract: Wind power producers (WPPs) participating in short-term power markets face significant imbalance costs due to their non-dispatchable and variable production. While some WPPs have a large enough market share to influence prices with their bidding decisions, existing optimal bidding methods rarely account for this aspect. Price-maker approaches typically model bidding as a bilevel optimization problem, but these methods require complex market models, estimating other participants' actions, and are computationally demanding. To address these challenges, we propose an online learning algorithm that leverages contextual information to optimize WPP bids in the price-maker setting. We formulate the strategic bidding problem as a contextual multi-armed bandit, ensuring provable regret minimization. The algorithm's performance is evaluated against various benchmark strategies using a numerical simulation of the German day-ahead and real-time markets.

Paper number 88:
Title: Autonomy Architectures for Safe Planning in Unknown Environments Under Budget Constraints
Authors: Daniel M. Cherenson, Devansh R. Agrawal, Dimitra Panagou
Abstract: Mission planning can often be formulated as a constrained control problem under multiple path constraints (i.e., safety constraints) and budget constraints (i.e., resource expenditure constraints). In a priori unknown environments, verifying that an offline solution will satisfy the constraints for all time can be difficult, if not impossible. We present ReRoot, a novel sampling-based framework that enforces safety and budget constraints for nonlinear systems in unknown environments. The main idea is that ReRoot grows multiple reverse RRT* trees online, starting from renewal sets, i.e., sets where the budget constraints are renewed. The dynamically feasible backup trajectories guarantee safety and reduce resource expenditure, which provides a principled backup policy when integrated into the gatekeeper safety verification architecture. We demonstrate our approach in simulation with a fixed-wing UAV in a GNSS-denied environment with a budget constraint on localization error that can be renewed at visual landmarks.

Paper number 89:
Title: Fast Online Adaptive Neural MPC via Meta-Learning
Authors: Yu Mei, Xinyu Zhou, Shuyang Yu, Vaibhav Srivastava, Xiaobo Tan
Abstract: Data-driven model predictive control (MPC) has demonstrated significant potential for improving robot control performance in the presence of model uncertainties. However, existing approaches often require extensive offline data collection and computationally intensive training, limiting their ability to adapt online. To address these challenges, this paper presents a fast online adaptive MPC framework that leverages neural networks integrated with Model-Agnostic Meta-Learning (MAML). Our approach focuses on few-shot adaptation of residual dynamics - capturing the discrepancy between nominal and true system behavior - using minimal online data and gradient steps. By embedding these meta-learned residual models into a computationally efficient L4CasADi-based MPC pipeline, the proposed method enables rapid model correction, enhances predictive accuracy, and improves real-time control performance. We validate the framework through simulation studies on a Van der Pol oscillator, a Cart-Pole system, and a 2D quadrotor. Results show significant gains in adaptation speed and prediction accuracy over both nominal MPC and nominal MPC augmented with a freshly initialized neural network, underscoring the effectiveness of our approach for real-time adaptive robot control.

Paper number 90:
Title: STOPA: A Database of Systematic VariaTion Of DeePfake Audio for Open-Set Source Tracing and Attribution
Authors: Anton Firc, Manasi Chhibber, Jagabandhu Mishra, Vishwanath Pratap Singh, Tomi Kinnunen, Kamil Malinka
Abstract: A key research area in deepfake speech detection is source tracing - determining the origin of synthesised utterances. The approaches may involve identifying the acoustic model (AM), vocoder model (VM), or other generation-specific parameters. However, progress is limited by the lack of a dedicated, systematically curated dataset. To address this, we introduce STOPA, a systematically varied and metadata-rich dataset for deepfake speech source tracing, covering 8 AMs, 6 VMs, and diverse parameter settings across 700k samples from 13 distinct synthesisers. Unlike existing datasets, which often feature limited variation or sparse metadata, STOPA provides a systematically controlled framework covering a broader range of generative factors, such as the choice of the vocoder model, acoustic model, or pretrained weights, ensuring higher attribution reliability. This control improves attribution accuracy, aiding forensic analysis, deepfake detection, and generative model transparency.

Paper number 91:
Title: A Survey of Foundation Models for IoT: Taxonomy and Criteria-Based Analysis
Authors: Hui Wei, Dong Yoon Lee, Shubham Rohal, Zhizhang Hu, Ryan Rossi, Shiwei Fang, Shijia Pan
Abstract: Foundation models have gained growing interest in the IoT domain due to their reduced reliance on labeled data and strong generalizability across tasks, which address key limitations of traditional machine learning approaches. However, most existing foundation model based methods are developed for specific IoT tasks, making it difficult to compare approaches across IoT domains and limiting guidance for applying them to new tasks. This survey aims to bridge this gap by providing a comprehensive overview of current methodologies and organizing them around four shared performance objectives by different domains: efficiency, context-awareness, safety, and security & privacy. For each objective, we review representative works, summarize commonly-used techniques and evaluation metrics. This objective-centric organization enables meaningful cross-domain comparisons and offers practical insights for selecting and designing foundation model based solutions for new IoT tasks. We conclude with key directions for future research to guide both practitioners and researchers in advancing the use of foundation models in IoT applications.

Paper number 92:
Title: I$^2$RF-TFCKD: Intra-Inter Representation Fusion with Time-Frequency Calibration Knowledge Distillation for Speech Enhancement
Authors: Jiaming Cheng, Ruiyu Liang, Ye Ni, Chao Xu, Jing Li, Wei Zhou, Rui Liu, Bjrn W. Schuller, Xiaoshuai Hao
Abstract: In this paper, we propose an intra-inter representation fusion knowledge distillation (KD) framework with time-frequency calibration (I$^2$RF-TFCKD) for SE, which achieves distillation through the fusion of multi-layer teacher-student feature flows. Different from previous distillation strategies for SE, the proposed framework fully utilizes the time-frequency differential information of speech while promoting global knowledge flow. Firstly, we construct a collaborative distillation paradigm for intra-set and inter-set correlations. Within a correlated set, multi-layer teacher-student features are pairwise matched for calibrated distillation. Subsequently, we generate representative features from each correlated set through residual fusion to form the fused feature set that enables inter-set knowledge interaction. Secondly, we propose a multi-layer interactive distillation based on dual-stream time-frequency cross-calibration, which calculates the teacher-student similarity calibration weights in the time and frequency domains respectively and performs cross-weighting, thus enabling refined allocation of distillation contributions across different layers according to speech characteristics. The proposed distillation strategy is applied to the dual-path dilated convolutional recurrent network (DPDCRN) that ranked first in the SE track of the L3DAS23 challenge. To evaluate the effectiveness of I$^2$RF-TFCKD, we conduct experiments on both single-channel and multi-channel SE datasets. Objective evaluations demonstrate that the proposed KD strategy consistently and effectively improves the performance of the low-complexity student model and outperforms other distillation schemes.

Paper number 93:
Title: Evaluating Sound Similarity Metrics for Differentiable, Iterative Sound-Matching
Authors: Amir Salimi, Abram Hindle, Osmar R. Zaiane
Abstract: Manual sound design with a synthesizer is inherently iterative: an artist compares the synthesized output to a mental target, adjusts parameters, and repeats until satisfied. Iterative sound-matching automates this workflow by continually programming a synthesizer under the guidance of a loss function (or similarity measure) toward a target sound. Prior comparisons of loss functions have typically favored one metric over another, but only within narrow settings: limited synthesis methods, few loss types, often without blind listening tests. This leaves open the question of whether a universally optimal loss exists, or the choice of loss remains a creative decision conditioned on the synthesis method and the sound designer's preference. We propose differentiable iterative sound-matching as the natural extension of the available literature, since it combines the manual approach to sound design with modern advances in machine learning. To analyze the variability of loss function performance across synthesizers, we implemented a mix of four novel and established differentiable loss functions, and paired them with differentiable subtractive, additive, and AM synthesizers. For each of the sixteen synthesizer--loss combinations, we ran 300 randomized sound-matching trials. Performance was measured using parameter differences, spectrogram-distance metrics, and manually assigned listening scores. We observed a moderate level of consistency among the three performance measures. Our post-hoc analysis shows that the loss function performance is highly dependent on the synthesizer. These findings underscore the value of expanding the scope of sound-matching experiments and developing new similarity metrics tailored to specific synthesis techniques rather than pursuing one-size-fits-all solutions.

Paper number 94:
Title: TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation
Authors: Keunwoo Choi, Seungheon Doh, Juhan Nam
Abstract: We present TalkPlayData 2, a synthetic dataset for multimodal conversational music recommendation generated by an agentic data pipeline. In the proposed pipeline, multiple large language model (LLM) agents are created under various roles with specialized prompts and access to different parts of information, and the chat data is acquired by logging the conversation between the Listener LLM and the Recsys LLM. To cover various conversation scenarios, for each conversation, the Listener LLM is conditioned on a finetuned conversation goal. Finally, all the LLMs are multimodal with audio and images, allowing a simulation of multimodal recommendation and conversation. In the LLM-as-a-judge and subjective evaluation experiments, TalkPlayData 2 achieved the proposed goal in various aspects related to training a generative recommendation model for music. TalkPlayData 2 and its generation code are released at this https URL.

Paper number 95:
Title: MARLIN: Multi-Agent Reinforcement Learning with Murmuration Intelligence and LLM Guidance for Reservoir Management
Authors: Heming Fu, Guojun Xiong, Shan Lin
Abstract: As climate change intensifies extreme weather events, water disasters pose growing threats to global communities, making adaptive reservoir management critical for protecting vulnerable populations and ensuring water security. Modern water resource management faces unprecedented challenges from cascading uncertainties propagating through interconnected reservoir networks. These uncertainties, rooted in physical water transfer losses and environmental variability, make precise control difficult. For example, sending 10 tons downstream may yield only 8-12 tons due to evaporation and seepage. Traditional centralized optimization approaches suffer from exponential computational complexity and cannot effectively handle such real-world uncertainties, while existing multi-agent reinforcement learning (MARL) methods fail to achieve effective coordination under uncertainty. To address these challenges, we present MARLIN, a decentralized reservoir management framework inspired by starling murmurations intelligence. Integrating bio-inspired alignment, separation, and cohesion rules with MARL, MARLIN enables individual reservoirs to make local decisions while achieving emergent global coordination. In addition, a LLM provides real-time reward shaping signals, guiding agents to adapt to environmental changes and human-defined preferences. Experiments on real-world USGS data show that MARLIN improves uncertainty handling by 23\%, cuts computation by 35\%, and accelerates flood response by 68\%, exhibiting super-linear coordination, with complexity scaling 5.4x from 400 to 10,000 nodes. These results demonstrate MARLIN's potential for disaster prevention and protecting communities through intelligent, scalable water resource management.

Paper number 96:
Title: OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction
Authors: Lujie Yang, Xiaoyu Huang, Zhen Wu, Angjoo Kanazawa, Pieter Abbeel, Carmelo Sferrazza, C. Karen Liu, Rocky Duan, Guanya Shi
Abstract: A dominant paradigm for teaching humanoid robots complex skills is to retarget human motions as kinematic references to train reinforcement learning (RL) policies. However, existing retargeting pipelines often struggle with the significant embodiment gap between humans and robots, producing physically implausible artifacts like foot-skating and penetration. More importantly, common retargeting methods neglect the rich human-object and human-environment interactions essential for expressive locomotion and loco-manipulation. To address this, we introduce OmniRetarget, an interaction-preserving data generation engine based on an interaction mesh that explicitly models and preserves the crucial spatial and contact relationships between an agent, the terrain, and manipulated objects. By minimizing the Laplacian deformation between the human and robot meshes while enforcing kinematic constraints, OmniRetarget generates kinematically feasible trajectories. Moreover, preserving task-relevant interactions enables efficient data augmentation, from a single demonstration to different robot embodiments, terrains, and object configurations. We comprehensively evaluate OmniRetarget by retargeting motions from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour trajectories that achieve better kinematic constraint satisfaction and contact preservation than widely used baselines. Such high-quality data enables proprioceptive RL policies to successfully execute long-horizon (up to 30 seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained with only 5 reward terms and simple domain randomization shared by all tasks, without any learning curriculum.

Paper number 97:
Title: Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell
Authors: Sara Strakosova, Petr Novak, Petr Kadera
Abstract: Current products, especially in the automotive sector, pose complex technical systems having a multi-disciplinary mechatronic nature. Industrial standards supporting system engineering and production typically (i) address the production phase only, but do not cover the complete product life cycle, and (ii) focus on production processes and resources rather than the products themselves. The presented approach is motivated by incorporating the impacts of the end-of-life phase of the product life cycle into the engineering phase. This paper proposes a modeling approach coming up from the Product-Process-Resource (PPR) modeling paradigm. It combines requirements on (i) respecting the product structure as a basis for the model, and (ii) incorporates repairing, remanufacturing, or upcycling within cyber-physical production systems. The proposed model called PoPAN should accompany the product during the entire life cycle as a digital shadow encapsulated within the Asset Administration Shell of a product. To facilitate the adoption of the proposed paradigm, the paper also proposes serialization of the model in the AutomationML data format. The model is demonstrated on a use-case for disassembling electric vehicle batteries to support their remanufacturing for stationary battery applications.

Paper number 98:
Title: Optimization via a Control-Centric Framework
Authors: Liraz Mudrik, Isaac Kaminer, Sean Kragelund, Abram H. Clark
Abstract: Optimization plays a central role in intelligent systems and cyber-physical technologies, where the speed and reliability of convergence directly impact performance. In control theory, optimization-centric methods are standard: controllers are designed by repeatedly solving optimization problems, as in linear quadratic regulation, $H_\infty$ control, and model predictive control. In contrast, this paper develops a control-centric framework for optimization itself, where algorithms are constructed directly from Lyapunov stability principles rather than being proposed first and analyzed afterward. A key element is the stationarity vector, which encodes first-order optimality conditions and enables Lyapunov-based convergence analysis. By pairing a Lyapunov function with a selectable decay law, we obtain continuous-time dynamics with guaranteed exponential, finite-time, fixed-time, or prescribed-time convergence. Within this framework, we introduce three feedback realizations of increasing restrictiveness: the Hessian-gradient, Newton, and gradient dynamics. Each realization shapes the decay of the stationarity vector to achieve the desired rate. These constructions unify unconstrained optimization, extend naturally to constrained problems via Lyapunov-consistent primal-dual dynamics, and broaden the results for minimax and generalized Nash equilibrium seeking problems beyond exponential stability. The framework provides systematic design tools for optimization algorithms in control and game-theoretic problems.

Paper number 99:
Title: Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation
Authors: Vaibhav Srivastav, Steven Zheng, Eric Bezzam, Eustache Le Bihan, Nithin Koluguri, Piotr elasko, Somshubra Majumdar, Adel Moumen, Sanchit Gandhi
Abstract: Despite rapid progress, ASR evaluation remains saturated with short-form English, and efficiency is rarely reported. We present the Open ASR Leaderboard, a fully reproducible benchmark and interactive leaderboard comparing 60+ open-source and proprietary systems across 11 datasets, including dedicated multilingual and long-form tracks. We standardize text normalization and report both word error rate (WER) and inverse real-time factor (RTFx), enabling fair accuracy-efficiency comparisons. For English transcription, Conformer encoders paired with LLM decoders achieve the best average WER but are slower, while CTC and TDT decoders deliver much better RTFx, making them attractive for long-form and offline use. Whisper-derived encoders fine-tuned for English improve accuracy but often trade off multilingual coverage. All code and dataset loaders are open-sourced to support transparent, extensible evaluation.
    