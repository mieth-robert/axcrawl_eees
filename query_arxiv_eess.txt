
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: UAV-Assisted MEC for Disaster Response: Stackelberg Game-Based Resource Optimization
Authors: Yafei Guo, Ziye Jia, Lei Zhang, Jia He, Yu Zhang, Qihui Wu
Abstract: The unmanned aerial vehicle assisted multi-access edge computing (UAV-MEC) technology has been widely applied in the sixth-generation era. However, due to the limitations of energy and computing resources in disaster areas, how to efficiently offload the tasks of damaged user equipments (UEs) to UAVs is a key issue. In this work, we consider a multiple UAVMECs assisted task offloading scenario, which is deployed inside the three-dimensional corridors and provide computation services for UEs. In detail, a ground UAV controller acts as the central decision-making unit for deploying the UAV-MECs and allocates the computational resources. Then, we model the relationship between the UAV controller and UEs based on the Stackelberg game. The problem is formulated to maximize the utility of both the UAV controller and UEs. To tackle the problem, we design a K-means based UAV localization and availability response mechanism to pre-deploy the UAV-MECs. Then, a chess-like particle swarm optimization probability based strategy selection learning optimization algorithm is proposed to deal with the resource allocation. Finally, extensive simulation results verify that the proposed scheme can significantly improve the utility of the UAV controller and UEs in various scenarios compared with baseline schemes.

Paper number 2:
Title: GIGA: Generalizable Sparse Image-driven Gaussian Avatars
Authors: Anton Zubekhin, Heming Zhu, Paulo Gotardo, Thabo Beeler, Marc Habermann, Christian Theobalt
Abstract: Driving a high-quality and photorealistic full-body human avatar, from only a few RGB cameras, is a challenging problem that has become increasingly relevant with emerging virtual reality technologies. To democratize such technology, a promising solution may be a generalizable method that takes sparse multi-view images of an unseen person and then generates photoreal free-view renderings of such identity. However, the current state of the art is not scalable to very large datasets and, thus, lacks in diversity and photorealism. To address this problem, we propose a novel, generalizable full-body model for rendering photoreal humans in free viewpoint, as driven by sparse multi-view video. For the first time in literature, our model can scale up training to thousands of subjects while maintaining high photorealism. At the core, we introduce a MultiHeadUNet architecture, which takes sparse multi-view images in texture space as input and predicts Gaussian primitives represented as 2D texels on top of a human body mesh. Importantly, we represent sparse-view image information, body shape, and the Gaussian parameters in 2D so that we can design a deep and scalable architecture entirely based on 2D convolutions and attention mechanisms. At test time, our method synthesizes an articulated 3D Gaussian-based avatar from as few as four input views and a tracked body template for unseen identities. Our method excels over prior works by a significant margin in terms of cross-subject generalization capability as well as photorealism.

Paper number 3:
Title: Examining Joint Demosaicing and Denoising for Single-, Quad-, and Nona-Bayer Patterns
Authors: SaiKiran Tedla, Abhijith Punnappurath, Luxi Zhao, Michael S. Brown
Abstract: Camera sensors have color filters arranged in a mosaic layout, traditionally following the Bayer pattern. Demosaicing is a critical step camera hardware applies to obtain a full-channel RGB image. Many smartphones now have multiple sensors with different patterns, such as Quad-Bayer or Nona-Bayer. Most modern deep network-based models perform joint demosaicing and denoising with the current strategy of training a separate network per pattern. Relying on individual models per pattern requires additional memory overhead and makes it challenging to switch quickly between cameras. In this work, we are interested in analyzing strategies for joint demosaicing and denoising for the three main mosaic layouts (1x1 Single-Bayer, 2x2 Quad-Bayer, and 3x3 Nona-Bayer). We found that concatenating a three-channel mosaic embedding to the input image and training with a unified demosaicing architecture yields results that outperform existing Quad-Bayer and Nona-Bayer models and are comparable to Single-Bayer models. Additionally, we describe a maskout strategy that enhances the model performance and facilitates dead pixel correction -- a step often overlooked by existing AI-based demosaicing models. As part of this effort, we captured a new demosaicing dataset of 638 RAW images that contain challenging scenes with patches annotated for training, validation, and testing.

Paper number 4:
Title: VideoSPatS: Video SPatiotemporal Splines for Disentangled Occlusion, Appearance and Motion Modeling and Editing
Authors: Juan Luis Gonzalez Bello, Xu Yao, Alex Whelan, Kyle Olszewski, Hyeongwoo Kim, Pablo Garrido
Abstract: We present an implicit video representation for occlusions, appearance, and motion disentanglement from monocular videos, which we call Video SPatiotemporal Splines (VideoSPatS). Unlike previous methods that map time and coordinates to deformation and canonical colors, our VideoSPatS maps input coordinates into Spatial and Color Spline deformation fields $D_s$ and $D_c$, which disentangle motion and appearance in videos. With spline-based parametrization, our method naturally generates temporally consistent flow and guarantees long-term temporal consistency, which is crucial for convincing video editing. Using multiple prediction branches, our VideoSPatS model also performs layer separation between the latent video and the selected occluder. By disentangling occlusions, appearance, and motion, our method enables better spatiotemporal modeling and editing of diverse videos, including in-the-wild talking head videos with challenging occlusions, shadows, and specularities while maintaining an appropriate canonical space for editing. We also present general video modeling results on the DAVIS and CoDeF datasets, as well as our own talking head video dataset collected from open-source web videos. Extensive ablations show the combination of $D_s$ and $D_c$ under neural splines can overcome motion and appearance ambiguities, paving the way for more advanced video editing models.

Paper number 5:
Title: Q-Agent: Quality-Driven Chain-of-Thought Image Restoration Agent through Robust Multimodal Large Language Model
Authors: Yingjie Zhou, Jiezhang Cao, Zicheng Zhang, Farong Wen, Yanwei Jiang, Jun Jia, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai
Abstract: Image restoration (IR) often faces various complex and unknown degradations in real-world scenarios, such as noise, blurring, compression artifacts, and low resolution, etc. Training specific models for specific degradation may lead to poor generalization. To handle multiple degradations simultaneously, All-in-One models might sacrifice performance on certain types of degradation and still struggle with unseen degradations during training. Existing IR agents rely on multimodal large language models (MLLM) and a time-consuming rolling-back selection strategy neglecting image quality. As a result, they may misinterpret degradations and have high time and computational costs to conduct unnecessary IR tasks with redundant order. To address these, we propose a Quality-Driven agent (Q-Agent) via Chain-of-Thought (CoT) restoration. Specifically, our Q-Agent consists of robust degradation perception and quality-driven greedy restoration. The former module first fine-tunes MLLM, and uses CoT to decompose multi-degradation perception into single-degradation perception tasks to enhance the perception of MLLMs. The latter employs objective image quality assessment (IQA) metrics to determine the optimal restoration sequence and execute the corresponding restoration algorithms. Experimental results demonstrate that our Q-Agent achieves superior IR performance compared to existing All-in-One models.

Paper number 6:
Title: Multi-Agent Trustworthy Consensus under Random Dynamic Attacks
Authors: Orhan Eren Akgün, Sarper Aydın, Stephanie Gil, Angelia Nedić
Abstract: In this work, we study the consensus problem in which legitimate agents send their values over an undirected communication network in the presence of an unknown subset of malicious or faulty agents. In contrast to former works, we generalize and characterize the properties of consensus dynamics with dependent sequences of malicious transmissions with dynamic (time-varying) rates, based on not necessarily independent trust observations. We consider a detection algorithm utilizing stochastic trust observations available to legitimate agents. Under these conditions, legitimate agents almost surely classify their neighbors and form their trusted neighborhoods correctly with decaying misclassification probabilities. We further prove that the consensus process converges almost surely despite the existence of malicious agents. For a given value of failure probability, we characterize the deviation from the nominal consensus value ideally occurring when there are no malicious agents in the system. We also examine the convergence rate of the process in finite time. Numerical simulations show the convergence among agents and indicate the deviation under different attack scenarios.

Paper number 7:
Title: Compositional design for time-varying and nonlinear coordination
Authors: Jonas Hansson, Emma Tegling
Abstract: This work addresses the design of multi-agent coordination through high-order consensus protocols. While first-order consensus strategies are well-studied -- with known robustness to uncertainties such as time delays, time-varying weights, and nonlinearities like saturations -- the theoretical guarantees for high-order consensus are comparatively limited. We propose a compositional control framework that generates high-order consensus protocols by serially connecting stable first-order consensus operators. Under mild assumptions, we establish that the resulting high-order system inherits stability properties from its components. The proposed design is versatile and supports a wide range of real-world constraints. This is demonstrated through applications inspired by vehicular formation control, including protocols with time-varying weights, bounded time-varying delays, and saturated inputs. We derive theoretical guarantees for these settings using the proposed compositional approach and demonstrate the advantages gained compared to conventional protocols in simulations.

Paper number 8:
Title: Dual Deep Learning Approach for Non-invasive Renal Tumour Subtyping with VERDICT-MRI
Authors: Snigdha Sen, Lorna Smith, Lucy Caselton, Joey Clemente, Maxine Tran, Shonit Punwani, David Atkinson, Richard L Hesketh, Eleftheria Panagiotaki
Abstract: This work aims to characterise renal tumour microstructure using diffusion MRI (dMRI); via the Vascular, Extracellular and Restricted Diffusion for Cytometry in Tumours (VERDICT)-MRI framework with self-supervised learning. Comprehensive datasets were acquired from 14 patients with 15 biopsy-confirmed renal tumours, with nine b-values in the range b=[0,2500]s/mm2. A three-compartment VERDICT model for renal tumours was fitted to the dMRI data using a self-supervised deep neural network, and ROIs were drawn by an experienced uroradiologist. An economical acquisition protocol for future studies with larger patient cohorts was optimised using a recursive feature selection approach. The VERDICT model described the diffusion data in renal tumours more accurately than IVIM or ADC. Combined with self-supervised deep learning, VERDICT identified significant differences in the intracellular volume fraction between cancerous and normal tissue, and in the vascular volume fraction between vascular and non-vascular. The feature selector yields a 4 b-value acquisition of b = [70,150,1000,2000], with a duration of 14 minutes.

Paper number 9:
Title: Can Carbon-Aware Electric Load Shifting Reduce Emissions? An Equilibrium-Based Analysis
Authors: Wenqian Jiang, Olivier Huber, Michael C. Ferris, Line Roald
Abstract: An increasing number of electric loads, such as hydrogen producers or data centers, can be characterized as carbon-sensitive, meaning that they are willing to adapt the timing and/or location of their electricity usage in order to minimize carbon footprints. However, the emission reduction efforts of these carbon-sensitive loads rely on carbon intensity information such as average carbon emissions, and it is unclear whether load shifting based on these signals effectively reduces carbon emissions. To address this open question, we investigate the impact of carbon-sensitive consumers using equilibrium analysis. Specifically, we expand the commonly used equilibrium model for electricity market clearing to include carbon-sensitive consumers that adapt their consumption based on an average carbon intensity signal. This analysis represents an idealized situation for carbon-sensitive loads, where their carbon preferences are reflected directly in the market clearing, and contrasts with current practice where carbon intensity signals only become known to consumers aposteriori (i.e. after the market has already been cleared). We include both illustrative examples and larger numerical simulations, including benchmarking with other methods, to illuminate the contributions and limitations of carbon-sensitive loads in power system emission reductions.

Paper number 10:
Title: MoEDiff-SR: Mixture of Experts-Guided Diffusion Model for Region-Adaptive MRI Super-Resolution
Authors: Zhe Wang, Yuhua Ru, Aladine Chetouani, Fang Chen, Fabian Bauer, Liping Zhang, Didier Hans, Rachid Jennane, Mohamed Jarraya, Yung Hsin Chen
Abstract: Magnetic Resonance Imaging (MRI) at lower field strengths (e.g., 3T) suffers from limited spatial resolution, making it challenging to capture fine anatomical details essential for clinical diagnosis and neuroimaging research. To overcome this limitation, we propose MoEDiff-SR, a Mixture of Experts (MoE)-guided diffusion model for region-adaptive MRI Super-Resolution (SR). Unlike conventional diffusion-based SR models that apply a uniform denoising process across the entire image, MoEDiff-SR dynamically selects specialized denoising experts at a fine-grained token level, ensuring region-specific adaptation and enhanced SR performance. Specifically, our approach first employs a Transformer-based feature extractor to compute multi-scale patch embeddings, capturing both global structural information and local texture details. The extracted feature embeddings are then fed into an MoE gating network, which assigns adaptive weights to multiple diffusion-based denoisers, each specializing in different brain MRI characteristics, such as centrum semiovale, sulcal and gyral cortex, and grey-white matter junction. The final output is produced by aggregating the denoised results from these specialized experts according to dynamically assigned gating probabilities. Experimental results demonstrate that MoEDiff-SR outperforms existing state-of-the-art methods in terms of quantitative image quality metrics, perceptual fidelity, and computational efficiency. Difference maps from each expert further highlight their distinct specializations, confirming the effective region-specific denoising capability and the interpretability of expert contributions. Additionally, clinical evaluation validates its superior diagnostic capability in identifying subtle pathological features, emphasizing its practical relevance in clinical neuroimaging. Our code is available at this https URL.

Paper number 11:
Title: Identifying regions of interest in whole slide images of renal cell carcinoma
Authors: Mohammed Lamine Benomar, Nesma Settouti, Eric Debreuve, Xavier Descombes, Damien Ambrosetti
Abstract: The histopathological images contain a huge amount of information, which can make diagnosis an extremely timeconsuming and tedious task. In this study, we developed a completely automated system to detect regions of interest (ROIs) in whole slide images (WSI) of renal cell carcinoma (RCC), to reduce time analysis and assist pathologists in making more accurate decisions. The proposed approach is based on an efficient texture descriptor named dominant rotated local binary pattern (DRLBP) and color transformation to reveal and exploit the immense texture variability at the microscopic high magnifications level. Thereby, the DRLBPs retain the structural information and utilize the magnitude values in a local neighborhood for more discriminative power. For the classification of the relevant ROIs, feature extraction of WSIs patches was performed on the color channels separately to form the histograms. Next, we used the most frequently occurring patterns as a feature selection step to discard non-informative features. The performances of different classifiers on a set of 1800 kidney cancer patches originating from 12 whole slide images were compared and evaluated. Furthermore, the small size of the image dataset allows to investigate deep learning approach based on transfer learning for image patches classification by using deep features and fine-tuning methods. High recognition accuracy was obtained and the classifiers are efficient, the best precision result was 99.17% achieved with SVM. Moreover, transfer learning models perform well with comparable performance, and the highest precision using ResNet-50 reached 98.50%. The proposed approach results revealed a very efficient image classification and demonstrated efficacy in identifying ROIs. This study presents an automatic system to detect regions of interest relevant to the diagnosis of kidney cancer in whole slide histopathology images.

Paper number 12:
Title: Diffusion Augmented Complex Maximum Total Correntropy Algorithm for Power System Frequency Estimation
Authors: Haiquan Zhao, Yi Peng, Jinsong Chen, Jinhui Hu
Abstract: Currently, adaptive filtering algorithms have been widely applied in frequency estimation for power systems. However, research on diffusion tasks remains insufficient. Existing diffusion adaptive frequency estimation algorithms exhibit certain limitations in handling input noise and lack robustness against impulsive noise. Moreover, traditional adaptive filtering algorithms designed based on the strictly-linear (SL) model fail to effectively address frequency estimation challenges in unbalanced three-phase power systems. To address these issues, this letter proposes an improved diffusion augmented complex maximum total correntropy (DAMTCC) algorithm based on the widely linear (WL) model. The proposed algorithm not only significantly enhances the capability to handle input noise but also demonstrates superior robustness to impulsive noise. Furthermore, it successfully resolves the critical challenge of frequency estimation in unbalanced three-phase power systems, offering an efficient and reliable solution for diffusion power system frequency estimation. Finally, we analyze the stability of the algorithm and computer simulations verify the excellent performance of the algorithm.

Paper number 13:
Title: WK-Pnet: FM-Based Positioning via Wavelet Packet Decomposition and Knowledge Distillation
Authors: Shilian Zheng, Quan Lin, Peihan Qi, Luxin Zhang, Xinjiang Qiu, Zhijin Zhao, Xiaoniu Yang
Abstract: Accurate and efficient positioning in complex environments is critical for applications where traditional satellite-based systems face limitations, such as indoors or urban canyons. This paper introduces WK-Pnet, an FM-based indoor positioning framework that combines wavelet packet decomposition (WPD) and knowledge distillation. WK-Pnet leverages WPD to extract rich time-frequency features from FM signals, which are then processed by a deep learning model for precise position estimation. To address computational demands, we employ knowledge distillation, transferring insights from a high-capacity model to a streamlined student model, achieving substantial reductions in complexity without sacrificing accuracy. Experimental results across diverse environments validate WK-Pnet's superior positioning accuracy and lower computational requirements, making it a viable solution for positioning in real-time resource-constraint applications.

Paper number 14:
Title: Secure Directional Modulation with Movable Antenna Array Aided by RIS
Authors: Maolin Li, Jingdie Xin, Feng Shu, Xuehui Wang, Yongpeng Wu, Cunhua Pan
Abstract: In this paper, to fully exploit the performance gains from moveable antennas (MAs) and reconfigurable intelligent surface (RIS), a RIS-aided directional modulation \textcolor{blue}{(DM)} network with movable antenna at base station (BS) is established Based on the principle of DM, a BS equipped with MAs transmits legitimate information to a single-antenna user (Bob) while exploiting artificial noise (AN) to degrade signal reception at the eavesdropper (Eve). The combination of AN and transmission beamforming vectors is modeled as joint beamforming vector (JBV) to achieve optimal power allocation. The objective is to maximize the achievable secrecy rate (SR) by optimizing MAs antenna position, phase shift matrix (PSM) of RIS, and JBV. The limited movable range (MR) and discrete candidate positions of the MAs at the BS are considered, which renders the optimization problem non-convex. To address these challenges, an optimization method under perfect channel state information (CSI) is firstly designed, in which the MAs antenna positions are obtained using compressive sensing (CS) technology, and JBV and PSM are iteratively optimized. Then, the design method and SR performance under imperfect CSI is investigated. The proposed algorithms have fewer iterations and lower complexity. Simulation results demonstrate that MAs outperform fixed-position antennas in SR performance when there is an adequately large MR available.

Paper number 15:
Title: Deep Learning-Based Wideband Spectrum Sensing with Dual-Representation Inputs and Subband Shuffling Augmentation
Authors: Shilian Zheng, Zhihao Ye, Luxin Zhang, Keqiang Yue, Zhijin Zhao
Abstract: The widespread adoption of mobile communication technology has led to a severe shortage of spectrum resources, driving the development of cognitive radio technologies aimed at improving spectrum utilization, with spectrum sensing being the key enabler. This paper presents a novel deep learning-based wideband spectrum sensing framework that leverages multi-taper power spectral inputs to achieve high-precision and sample-efficient sensing. To enhance sensing accuracy, we incorporate a feature fusion strategy that combines multiple power spectrum representations. To tackle the challenge of limited sample sizes, we propose two data augmentation techniques designed to expand the training set and improve the network's detection probability. Comprehensive simulation results demonstrate that our method outperforms existing approaches, particularly in low signal-to-noise ratio conditions, achieving higher detection probabilities and lower false alarm rates. The method also exhibits strong robustness across various scenarios, highlighting its significant potential for practical applications in wireless communication systems.

Paper number 16:
Title: DS-Pnet: FM-Based Positioning via Downsampling
Authors: Shilian Zheng, Xinjiang Qiu, Luxin Zhang, Quan Lin, Zhijin Zhao, Xiaoniu Yang
Abstract: In this paper we present DS-Pnet, a novel framework for FM signal-based positioning that addresses the challenges of high computational complexity and limited deployment in resource-constrained environments. Two downsampling methods-IQ signal downsampling and time-frequency representation downsampling-are proposed to reduce data dimensionality while preserving critical positioning features. By integrating with the lightweight MobileViT-XS neural network, the framework achieves high positioning accuracy with significantly reduced computational demands. Experiments on real-world FM signal datasets demonstrate that DS-Pnet achieves superior performance in both indoor and outdoor scenarios, with space and time complexity reductions of approximately 87% and 99.5%, respectively, compared to an existing method, FM-Pnet. Despite the high compression, DS-Pnet maintains robust positioning accuracy, offering an optimal balance between efficiency and precision.

Paper number 17:
Title: Improved AFSA-Based Beam Training Without CSI for RIS-Assisted ISAC Systems
Authors: Yunxiang Shi, Lixin Li, Wensheng Lin, Wei Liang, Zhu Han
Abstract: In this paper, we consider transmit beamforming and reflection patterns design in reconfigurable intelligent surface (RIS)-assisted integrated sensing and communication (ISAC) systems, where the dual-function base station (DFBS) lacks channel state information (CSI). To address the high overhead of cascaded channel estimation, we propose an improved artificial fish swarm algorithm (AFSA) combined with a feedback-based joint active and passive beam training scheme. In this approach, we consider the interference caused by multipath user echo signals on target detection and propose a beamforming design method that balances both communication and sensing performance. Numerical simulations show that the proposed AFSA outperforms other optimization algorithms, particularly in its robustness against echo interference under different communication signal-to-noise ratio (SNR) constraints.

Paper number 18:
Title: RIS-Aided Integrated Sensing and Communication Waveform Design With Tunable PAPR
Authors: Jinlong Wu, Lixin Li, Wensheng Lin, Wei Liang, Decan Zhao, Zhu Han
Abstract: Low peak-to-average power ratio (PAPR) transmission is an important and favorable requirement prevalent in radar and communication systems, especially in transmission links integrated with high power amplifiers. Meanwhile, motivated by the advantages of reconfigurable intelligent surface (RIS) in mitigating multi-user interference (MUI) to enhance the communication rate, this paper investigates the design problem of joint waveform and passive beamforming with PAPR constraint for integrated sensing and communication (ISAC) systems, where RIS is deployed for downlink communication. We first construct a trade-off optimization problem for the MUI and beampattern similarity under PAPR constraint. Then, in order to solve this multivariate problem, an iterative optimization algorithm based on alternating direction method of multipliers (ADMM) and manifold optimization is proposed. Finally, the simulation results show that the designed waveforms can well satisfy the PAPR requirement of the ISAC systems and achieve a trade-off between radar and communication performance. Under high signal-to-noise ratio (SNR) conditions, compared to systems without RIS, RIS-aided ISAC systems have a performance improvement of about 50\% in communication rate and at least 1 dB in beampatterning error.

Paper number 19:
Title: Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected PET for Whole-Body PET Attenuation Correction
Authors: Weijie Chen, James Wang, Alan McMillan
Abstract: Positron Emission Tomography (PET) imaging requires accurate attenuation correction (AC) to account for photon loss due to tissue density variations. In PET/MR systems, computed tomography (CT), which offers a straightforward estimation of AC is not available. This study presents a deep learning approach to generate synthetic CT (sCT) images directly from Time-of-Flight (TOF) non-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first evaluated models pre-trained on large-scale natural image datasets for a CT-to-CT reconstruction task, finding that the pre-trained model outperformed those trained solely on medical datasets. The pre-trained model was then fine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume pairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest peak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region. Visual assessments demonstrated improved reconstruction of both bone and soft tissue structures from TOF NAC PET images. This work highlights the effectiveness of using pre-trained deep learning models for medical image translation tasks. Future work will assess the impact of sCT on PET attenuation correction and explore additional neural network architectures and datasets to further enhance performance and practical applications in PET imaging.

Paper number 20:
Title: Personalized and Demand-Based Education Concept: Practical Tools for Control Engineers
Authors: Balint Varga, Lars Fischer, Levente Kovacs
Abstract: This paper presents a personalized lecture concept using educational blocks and its demonstrative application in a new university lecture. Higher education faces daily challenges: deep and specialized knowledge is available from everywhere and accessible to almost everyone. University lecturers of specialized master courses confront the problem that their lectures are either too boring or too complex for the attending students. Additionally, curricula are changing more rapidly than they have in the past 10-30 years. The German education system comprises different educational forms, with universities providing less practical content. Consequently, many university students do not obtain the practical skills they should ideally gain through university lectures. Therefore, in this work, a new lecture concept is proposed based on the extension of the just-in-time teaching paradigm: Personalized and Demand-Based Education. This concept includes: 1) an initial assessment of students' backgrounds, 2) selecting the appropriate educational blocks, and 3) collecting ongoing feedback during the semester. The feedback was gathered via Pingo, ensuring anonymity for the students. Our concept was exemplarily tested in the new lecture "Practical Tools for Control Engineers" at the Karlsruhe Institute of Technology. The initial results indicate that our proposed concept could be beneficial in addressing the current challenges in higher education.

Paper number 21:
Title: Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from Imbalanced Chest X-Ray Datasets
Authors: Santanu Roy, Ashvath Suresh, Palak Sahu, Tulika Rudra Gupta
Abstract: This paper proposes a novel pooling-based VGG-Lite model in order to mitigate class imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia detection from CXR images by deep learning model has emerged as a prominent and dynamic area of research, since the inception of the new Covid-19 variant in 2020. However, the standard Convolutional Neural Network (CNN) models encounter challenges associated with class imbalance, a prevalent issue found in many medical datasets. The innovations introduced in the proposed model architecture include: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base model, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this base model, we leverage an ``Edge Enhanced Module (EEM)" through a parallel branch, consisting of a ``negative image layer", and a novel custom pooling layer ``2Max-Min Pooling". This 2Max-Min Pooling layer is entirely novel in this investigation, providing more attention to edge components within pneumonia CXR images. Thus, it works as an efficient spatial attention module (SAM). We have implemented the proposed framework on two separate CXR datasets. The first dataset is obtained from a readily available source on the internet, and the second dataset is a more challenging CXR dataset, assembled by our research team from three different sources. Experimental results reveal that our proposed framework has outperformed pre-trained CNN models, and three recent trend existing models ``Vision Transformer", ``Pooling-based Vision Transformer (PiT)'' and ``PneuNet", by substantial margins on both datasets. The proposed framework VGG-Lite with EEM, has achieved a macro average of 95% accuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia Imbalance CXR dataset", without employing any pre-processing technique.

Paper number 22:
Title: Quickest change detection for UAV-based sensing
Authors: Saqib Abbas, Anurag Kumar, Arpan Chattopadhyay
Abstract: This paper addresses the problem of quickest change detection (QCD) at two spatially separated locations monitored by a single unmanned aerial vehicle (UAV) equipped with a sensor. At any location, the UAV observes i.i.d. data sequentially in discrete time instants. The distribution of the observation data changes at some unknown, arbitrary time and the UAV has to detect this change in the shortest possible time. Change can occur at most at one location over the entire infinite time horizon. The UAV switches between these two locations in order to quickly detect the change. To this end, we propose Location Switching and Change Detection (LS-CD) algorithm which uses a repeated one-sided sequential probability ratio test (SPRT) based mechanism for observation-driven location switching and change detection. The primary goal is to minimize the worst-case average detection delay (WADD) while meeting constraints on the average run length to false alarm (ARL2FA) and the UAV's time-averaged energy consumption. We provide a rigorous theoretical analysis of the algorithm's performance by using theory of random walk. Specifically, we derive tight upper and lower bounds to its ARL2FA and a tight upper bound to its WADD. In the special case of a symmetrical setting, our analysis leads to a new asymptotic upper bound to the ARL2FA of the standard CUSUM algorithm, a novel contribution not available in the literature, to our knowledge. Numerical simulations demonstrate the efficacy of LS-CD.

Paper number 23:
Title: Modular Control of Discrete Event System for Modeling and Mitigating Power System Cascading Failures
Authors: Wasseem Al-Rousan, Caisheng Wang, Feng Lin
Abstract: Cascading failures in power systems caused by sequential tripping of components are a serious concern as they can lead to complete or partial shutdowns, disrupting vital services and causing damage and inconvenience. In prior work, we developed a new approach for identifying and preventing cascading failures in power systems. The approach uses supervisory control technique of discrete event systems (DES) by incorporating both on-line lookahead control and forcible events. In this paper, we use modular supervisory control of DES to reduce computation complexity and increase the robustness and reliability of control. Modular supervisory control allows us to predict and mitigate cascading failures in power systems more effectively. We implemented the proposed control technique on a simulation platform developed in MATLAB and applied the proposed DES controller. The calculations of modular supervisory control of DES are performed using an external tool and imported into the MATLAB platform. We conduct simulation studies for the IEEE 30-bus, 118-bus and 300-bus systems, and the results demonstrate the effectiveness of our proposed approach.

Paper number 24:
Title: Learning Joint Source-Channel Encoding in IRS-assisted Multi-User Semantic Communications
Authors: Haidong Wang, Songhan Zhao, Lanhua Li, Bo Gu, Jing Xu, Shimin Gong, Jiawen Kang
Abstract: In this paper, we investigate a joint source-channel encoding (JSCE) scheme in an intelligent reflecting surface (IRS)-assisted multi-user semantic communication system. Semantic encoding not only compresses redundant information, but also enhances information orthogonality in a semantic feature space. Meanwhile, the IRS can adjust the spatial orthogonality, enabling concurrent multi-user semantic communication in densely deployed wireless networks to improve spectrum efficiency. We aim to maximize the users' semantic throughput by jointly optimizing the users' scheduling, the IRS's passive beamforming, and the semantic encoding strategies. To tackle this non-convex problem, we propose an explainable deep neural network-driven deep reinforcement learning (XD-DRL) framework. Specifically, we employ a deep neural network (DNN) to serve as a joint source-channel semantic encoder, enabling transmitters to extract semantic features from raw images. By leveraging structural similarity, we assign some DNN weight coefficients as the IRS's phase shifts, allowing simultaneous optimization of IRS's passive beamforming and DNN training. Given the IRS's passive beamforming and semantic encoding strategies, user scheduling is optimized using the DRL method. Numerical results validate that our JSCE scheme achieves superior semantic throughput compared to the conventional schemes and efficiently reduces the semantic encoder's mode size in multi-user scenarios.

Paper number 25:
Title: Strategic learning for disturbance rejection in multi-agent systems: Nash and Minmax in graphical games
Authors: Xinyang Wang, Martin Guay, Shimin Wang, Hongwei Zhang
Abstract: This article investigates the optimal control problem with disturbance rejection for discrete-time multi-agent systems under cooperative and non-cooperative graphical games frameworks. Given the practical challenges of obtaining accurate models, Q-function-based policy iteration methods are proposed to seek the Nash equilibrium solution for the cooperative graphical game and the distributed minmax solution for the non-cooperative graphical game. To implement these methods online, two reinforcement learning frameworks are developed, an actor-disturber-critic structure for the cooperative graphical game and an actor-adversary-disturber-critic structure for the non-cooperative graphical game. The stability of the proposed methods is rigorously analyzed, and simulation results are provided to illustrate the effectiveness of the proposed methods.

Paper number 26:
Title: Topology optimization of decoupling feeding networks for antenna arrays
Authors: Pan Lu, Eddie Wadbro, Jonas Starck, Martin Berggren, Emadeldeen Hassan
Abstract: Near-field and radiation coupling between nearby radiating elements is unavoidable, and it is considered a limiting factor for applications in wireless communications and active sensing. This article proposes a density-based topology optimization approach to design decoupling networks for such systems. The decoupling networks are designed based on a multi-objective optimization problem with the radiating elements replaced by their time-domain impulse response for efficient computations and to enable the solution of the design problem using gradient-based optimization methods. We use the adjoint-field method to compute the gradients of the optimization objectives. Additionally, nonlinear filters are applied during the optimization procedure to impose minimum-size control on the optimized designs. We demonstrate the concept by designing the decoupling network for a two-element planar antenna array; the antenna is designed in a separate optimization problem. The optimized decoupling networks provide a signal path that destructively interferes with the coupling between the radiating elements while preserving their individual matching to the feeding ports. Compact decoupling networks capable of suppressing the mutual coupling by more than 10 dB between two closely separated planar antennas operating around 2.45 GHz are presented and validated experimentally.

Paper number 27:
Title: PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data Generation
Authors: Moritz Rempe, Fabian Hörst, Helmut Becker, Marco Schlimbach, Lukas Rotkopf, Kevin Kröninger, Jens Kleesiek
Abstract: Magnetic resonance imaging (MRI) raw data, or k-Space data, is complex-valued, containing both magnitude and phase information. However, clinical and existing Artificial Intelligence (AI)-based methods focus only on magnitude images, discarding the phase data despite its potential for downstream tasks, such as tumor segmentation and classification. In this work, we introduce $\textit{PhaseGen}$, a novel complex-valued diffusion model for generating synthetic MRI raw data conditioned on magnitude images, commonly used in clinical practice. This enables the creation of artificial complex-valued raw data, allowing pretraining for models that require k-Space information. We evaluate PhaseGen on two tasks: skull-stripping directly in k-Space and MRI reconstruction using the publicly available FastMRI dataset. Our results show that training with synthetic phase data significantly improves generalization for skull-stripping on real-world data, with an increased segmentation accuracy from $41.1\%$ to $80.1\%$, and enhances MRI reconstruction when combined with limited real-world data. This work presents a step forward in utilizing generative AI to bridge the gap between magnitude-based datasets and the complex-valued nature of MRI raw data. This approach allows researchers to leverage the vast amount of avaliable image domain data in combination with the information-rich k-Space data for more accurate and efficient diagnostic tasks. We make our code publicly $\href{this https URL}{\text{available here}}$.

Paper number 28:
Title: Controlling Complex Systems
Authors: Marco Coraggio, Davide Salzano, Mario di Bernardo
Abstract: This chapter provides a comprehensive overview of controlling collective behavior in complex systems comprising large ensembles of interacting dynamical agents. Building upon traditional control theory's foundation in individual systems, we introduce tools designed to address the unique challenges of coordinating networks that exhibit emergent phenomena, including consensus, synchronization, and pattern formation. We analyze how local agent interactions generate macroscopic behaviors and investigate the fundamental role of network topology in determining system dynamics. Inspired by natural systems, we emphasize control strategies that achieve global coordination through localized interventions while considering practical implementation challenges. The chapter concludes by presenting novel frameworks for managing very large agent ensembles and leveraging interacting networks for control purposes.

Paper number 29:
Title: System Concept and Demonstration of Bistatic MIMO-OFDM-based ISAC
Authors: Lucas Giroto de Oliveira, Xueyun Long, Christian Karle, Umut Utku Erdem, Taewon Jeong, Elizabeth Bekker, Yueheng Li, Thomas Zwick, Benjamin Nuss
Abstract: In future sixth-generation (6G) mobile networks, radar sensing is expected to be offered as an additional service to its original purpose of communication. Merging these two functions results in integrated sensing and communication (ISAC) systems. In this context, bistatic ISAC appears as a possibility to exploit the distributed nature of cellular networks while avoiding highly demanding hardware requirements such as full-duplex operation. Recent studies have introduced strategies to perform required synchronization and data exchange between nodes for bistatic ISAC operation, based on orthogonal frequency-division multiplexing (OFDM), however, only for single-input single-output architectures. In this article, a system concept for a bistatic multiple-input multiple-output (MIMO)-OFDM-based ISAC system with beamforming at both transmitter and receiver is proposed, and a distribution synchronization concept to ensure coherence among the different receive channels for direction-of-arrival estimation is presented. After a discussion on the ISAC processing chain, including relevant aspects for practical deployments such as transmitter digital pre-distortion and receiver calibration, a 4x8 MIMO measurement setup at 27.5 GHz and results are presented to validate the proposed system and distribution synchronization concepts.

Paper number 30:
Title: Heart Failure Prediction using Modal Decomposition and Masked Autoencoders for Scarce Echocardiography Databases
Authors: Andrés Bell-Navas, María Villalba-Orero, Enrique Lara-Pezzi, Jesús Garicano-Mena, Soledad Le Clainche
Abstract: Heart diseases constitute the main cause of international human defunction. According to the World Health Organization (WHO), approximately 18 million deaths happen each year due to precisely heart diseases. In particular, heart failures (HF) press the healthcare industry to develop systems for their early, rapid and effective prediction. In this work, an automatic system which analyses in real-time echocardiography video sequences is proposed for the challenging and more specific task of prediction of heart failure times. This system is based on a novel deep learning framework, and works in two stages. The first one transforms the data included in a database of echocardiography video sequences into a machine learning-compatible collection of annotated images which can be used in the training phase of any kind of machine learning-based framework, including a deep learning one. This initial stage includes the use of the Higher Order Dynamic Mode Decomposition (HODMD) algorithm for both data augmentation and feature extraction. The second stage is focused on building and training a Vision Transformer (ViT). Self-supervised learning (SSL) methods, which have been so far barely explored in the literature about heart failure prediction, are applied to effectively train the ViT from scratch, even with scarce databases of echocardiograms. The designed neural network analyses images from echocardiography sequences to estimate the time in which a heart failure will happen. The results obtained show the efficacy of the HODMD algorithm and the superiority of the proposed system with respect to several established ViT and Convolutional Neural Network (CNN) architectures.

Paper number 31:
Title: Robustness of Online Identification-based Policy Iteration to Noisy Data
Authors: Bowen Song, Andrea Iannelli
Abstract: This article investigates the core mechanisms of indirect data-driven control for unknown systems, focusing on the application of policy iteration (PI) within the context of the linear quadratic regulator (LQR) optimal control problem. Specifically, we consider a setting where data is collected sequentially from a linear system subject to exogenous process noise, and is then used to refine estimates of the optimal control policy. We integrate recursive least squares (RLS) for online model estimation within a certainty-equivalent framework, and employ PI to iteratively update the control policy. In this work, we investigate first the convergence behavior of RLS under two different models of adversarial noise, namely point-wise and energy bounded noise, and then we provide a closed-loop analysis of the combined model identification and control design process. This iterative scheme is formulated as an algorithmic dynamical system consisting of the feedback interconnection between two algorithms expressed as discrete-time systems. This system theoretic viewpoint on indirect data-driven control allows us to establish convergence guarantees to the optimal controller in the face of uncertainty caused by noisy data. Simulations illustrate the theoretical results.

Paper number 32:
Title: Categorical Unsupervised Variational Acoustic Clustering
Authors: Luan Vinícius Fiorio, Ivana Nikoloska, Ronald M. Aarts
Abstract: We propose a categorical approach for unsupervised variational acoustic clustering of audio data in the time-frequency domain. The consideration of a categorical distribution enforces sharper clustering even when data points strongly overlap in time and frequency, which is the case for most datasets of urban acoustic scenes. To this end, we use a Gumbel-Softmax distribution as a soft approximation to the categorical distribution, allowing for training via backpropagation. In this settings, the softmax temperature serves as the main mechanism to tune clustering performance. The results show that the proposed model can obtain impressive clustering performance for all considered datasets, even when data points strongly overlap in time and frequency.

Paper number 33:
Title: Integrated Sensing, Computing, and Semantic Communication with Fluid Antenna for Metaverse
Authors: Yinchao Yang, Jingxuan Zhou, Zhaohui Yang
Abstract: The integration of sensing and communication (ISAC) is pivotal for the Metaverse but faces challenges like high data volume and privacy concerns. This paper proposes a novel integrated sensing, computing, and semantic communication (ISCSC) framework, which uses semantic communication to transmit only contextual information, reducing data overhead and enhancing efficiency. To address the sensitivity of semantic communication to channel conditions, fluid antennas (FAs) are introduced, enabling dynamic adaptability. The FA-enabled ISCSC framework considers multiple users and extended targets composed of a series of scatterers, formulating a joint optimization problem to maximize the data rate while ensuring sensing accuracy and meeting computational and power constraints. An alternating optimization (AO) method decomposes the problem into subproblems for ISAC beamforming, FA positioning, and semantic extraction. Simulations confirm the framework's effectiveness in improving data rates and sensing performance.

Paper number 34:
Title: Distributed Fault-Tolerant Control for Heterogeneous MAS with Prescribed Performance under Communication Failures
Authors: Yongkang Zhang, Bin Jiang, Yajie Ma
Abstract: This paper presents a novel approach employing prescribed performance control to address the distributed fault-tolerant formation control problem in a heterogeneous UAV-UGV cooperative system under a directed interaction topology and communication link failures. The proposed distributed fault-tolerant control scheme enables UAVs to accurately track a virtual leader's trajectory and achieve the desired formation, while ensuring UGVs converge within the convex hull formed by leader UAVs. By accounting for differences in system parameters and state dimensions between UAVs and UGVs, the method leverages performance functions to guarantee predefined transient and steady-state behavior. Additionally, a variable prescribed performance boundary control strategy with an adaptive learning rate is introduced to tackle actuator saturation, ensuring reliable formation tracking in real-world scenarios. Simulation results demonstrate the effectiveness and robustness of the proposed approach.

Paper number 35:
Title: Cross-Laplacians Based Topological Signal Processing over Cell MultiComplexes
Authors: Stefania Sardellitti, Breno C. Bispo, Fernando A. N. Santos, Juliano B. Lima
Abstract: The study of the interactions among different types of interconnected systems in complex networks has attracted significant interest across many research fields. However, effective signal processing over layered networks requires topological descriptors of the intra- and cross-layers relationships that are able to disentangle the homologies of different domains, at different scales, according to the specific learning task. In this paper, we present Cell MultiComplex (CMC) spaces, which are novel topological domains for representing multiple higher-order relationships among interconnected complexes. We introduce cross-Laplacians matrices, which are algebraic descriptors of CMCs enabling the extraction of topological invariants at different scales, whether global or local, inter-layer or intra-layer. Using the eigenvectors of these cross-Laplacians as signal bases, we develop topological signal processing tools for CMC spaces. In this first study, we focus on the representation and filtering of noisy flows observed over cross-edges between different layers of CMCs to identify cross-layer hubs, i.e., key nodes on one layer controlling the others.

Paper number 36:
Title: Low-Complexity Optimization of Antenna Switching Schemes for Dynamic Channel Sounding
Authors: Juan Sanchez, Xuesong Cai, Ali Al-Ameri, Fredrik Tufvesson
Abstract: Understanding wireless channels is crucial for the design of wireless systems. For mobile communication, sounders and antenna arrays with short measurement times are required to simultaneously capture the dynamic and spatial channel characteristics. Switched antenna arrays are an attractive option that can overcome the high cost of real arrays and the long measurement times of virtual arrays. Optimization of the switching sequences is then essential to avoid aliasing and increase the accuracy of channel parameter estimates. This paper provides a novel and comprehensive analysis of the design of switching sequences. We first review the conventional spatio-temporal ambiguity function, extend it to dual-polarized antenna arrays, and analyze its prohibitive complexity when designing for ultra-massive antenna arrays. We thus propose a new method that uses the Fisher information matrix to tackle the estimation accuracy. We also propose to minimize the ambiguity by choosing a switching sequence that minimizes side lobes in its Fourier spectrum. In this sense, we divide the sequence design problem into Fourier-based ambiguity reduction and Fisher-based accuracy improvement, and coin the resulting design approach as Fourier-Fisher. Simulations and measurements show that the Fourier-Fisher approach achieves identical performance and significantly lower computational complexity than that of the conventional ambiguity-based approach.

Paper number 37:
Title: Learning Higher-Order Interactions in Brain Networks via Topological Signal Processing
Authors: Breno C. Bispo, Stefania Sardellitti, Fernando A. N. Santos, Juliano B. Lima
Abstract: Our goal in this paper is to leverage the potential of the topological signal processing (TSP) framework for analyzing brain networks. Representing brain data as signals over simplicial complexes allows us to capture higher-order relationships within brain regions of interest (ROIs). Here, we focus on learning the underlying brain topology from observed neural signals using two distinct inference strategies. The first method relies on higher-order statistical metrics to infer multiway relationships among ROIs. The second method jointly learns the brain topology and sparse signal representations, of both the solenoidal and harmonic components of the signals, by minimizing the total variation along triangles and the data-fitting errors. Leveraging the properties of solenoidal and irrotational signals, and their physical interpretations, we extract functional connectivity features from brain topologies and uncover new insights into functional organization patterns. This allows us to associate brain functional connectivity (FC) patterns of conservative signals with well-known functional segregation and integration properties. Our findings align with recent neuroscience research, suggesting that our approach may offer a promising pathway for characterizing the higher-order brain functional connectivities.

Paper number 38:
Title: Conformalized Generative Bayesian Imaging: An Uncertainty Quantification Framework for Computational Imaging
Authors: Canberk Ekmekci, Mujdat Cetin
Abstract: Uncertainty quantification plays an important role in achieving trustworthy and reliable learning-based computational imaging. Recent advances in generative modeling and Bayesian neural networks have enabled the development of uncertainty-aware image reconstruction methods. Current generative model-based methods seek to quantify the inherent (aleatoric) uncertainty on the underlying image for given measurements by learning to sample from the posterior distribution of the underlying image. On the other hand, Bayesian neural network-based approaches aim to quantify the model (epistemic) uncertainty on the parameters of a deep neural network-based reconstruction method by approximating the posterior distribution of those parameters. Unfortunately, an ongoing need for an inversion method that can jointly quantify complex aleatoric uncertainty and epistemic uncertainty patterns still persists. In this paper, we present a scalable framework that can quantify both aleatoric and epistemic uncertainties. The proposed framework accepts an existing generative model-based posterior sampling method as an input and introduces an epistemic uncertainty quantification capability through Bayesian neural networks with latent variables and deep ensembling. Furthermore, by leveraging the conformal prediction methodology, the proposed framework can be easily calibrated to ensure rigorous uncertainty quantification. We evaluated the proposed framework on magnetic resonance imaging, computed tomography, and image inpainting problems and showed that the epistemic and aleatoric uncertainty estimates produced by the proposed framework display the characteristic features of true epistemic and aleatoric uncertainties. Furthermore, our results demonstrated that the use of conformal prediction on top of the proposed framework enables marginal coverage guarantees consistent with frequentist principles.

Paper number 39:
Title: Optimal Frequency Support from Virtual Power Plants: Minimal Reserve and Allocation
Authors: Xiang Zhu, Guangchun Ruan, Hua Geng
Abstract: This paper proposes a novel reserve-minimizing and allocation strategy for virtual power plants (VPPs) to deliver optimal frequency support. The proposed strategy enables VPPs, acting as aggregators for inverter-based resources (IBRs), to provide optimal frequency support economically. The proposed strategy captures time-varying active power injections, reducing the unnecessary redundancy compared to traditional fixed reserve schemes. Reserve requirements for the VPPs are determined based on system frequency response and safety constraints, ensuring efficient grid support. Furthermore, an energy-based allocation model decomposes power injections for each IBR, accounting for their specific limitations. Numerical experiments validate the feasibility of the proposed approach, highlighting significant financial gains for VPPs, especially as system inertia decreases due to higher renewable energy integration.

Paper number 40:
Title: Filtering through a topological lens: homology for point processes on the time-frequency plane
Authors: Juan Manuel Miramont, Kin Aun Tan, Soumendu Sundar Mukherjee, Rémi Bardenet, Subhroshekhar Ghosh
Abstract: We introduce a very general approach to the analysis of signals from their noisy measurements from the perspective of Topological Data Analysis (TDA). While TDA has emerged as a powerful analytical tool for data with pronounced topological structures, here we demonstrate its applicability for general problems of signal processing, without any a-priori geometric feature. Our methods are well-suited to a wide array of time-dependent signals in different scientific domains, with acoustic signals being a particularly important application. We invoke time-frequency representations of such signals, focusing on their zeros which are gaining salience as a signal processing tool in view of their stability properties. Leveraging state-of-the-art topological concepts, such as stable and minimal volumes, we develop a complete suite of TDA-based methods to explore the delicate stochastic geometry of these zeros, capturing signals based on the disruption they cause to this rigid, hyperuniform spatial structure. Unlike classical spatial data tools, TDA is able to capture the full spectrum of the stochastic geometry of the zeros, thereby leading to powerful inferential outcomes that are underpinned by a principled statistical foundation. This is reflected in the power and versatility of our applications, which include competitive performance in processing. a wide variety of audio signals (esp. in low SNR regimes), effective detection and reconstruction of gravitational wave signals (a reputed signal processing challenge with non-Gaussian noise), and medical time series data from EEGs, indicating a wide horizon for the approach and methods introduced in this paper.

Paper number 41:
Title: Adaptive Robust Unscented Kalman Filter for Dynamic State Estimation of Power System
Authors: Duc Viet Nguyen, Haiquan Zhao, Jinhui Hu, Le Ngoc Giang
Abstract: Non-Gaussian noise and the uncertainty of noise distribution are the common factors that reduce accuracy in dynamic state estimation of power systems (PS). In addition, the optimal value of the free coefficients in the unscented Kalman filter (UKF) based on information theoretic criteria is also an urgent problem. In this paper, a robust adaptive UKF (AUKF) under generalized minimum mixture error entropy with fiducial points (GMMEEF) over improve Snow Geese algorithm (ISGA) (ISGA-GMMEEF-AUKF) is proposed to overcome the above difficulties. The estimation process of the proposed algorithm is based on several key steps including augmented regression error model (AREM) construction, adaptive state estimation, and free coefficients optimization. Specifically, an AREM consisting of state prediction and measurement errors is established at the first step. Then, GMMEEF-AUKF is developed by solving the optimization problem based on GMMEEF, which uses a generalized Gaussian kernel combined with mixture correntropy to enhance the flexibility further and resolve the data problem with complex attributes and update the noise covariance matrix according to the AREM framework. Finally, the ISGA is designed to automatically calculate the optimal value of coefficients such as the shape coefficients of the kernel in the GMMEEF criterion, the coefficients selection sigma points in unscented transform, and the update coefficient of the noise covariance matrices fit with the PS model. Simulation results on the IEEE 14, 30, and 57-bus test systems in complex scenarios have confirmed that the proposed algorithm outperforms the MEEF-UKF and UKF by an average efficiency of 26% and 65%, respectively.

Paper number 42:
Title: On-Chip and Off-Chip TIA Amplifiers for Nanopore Signal Readout Design, Performance and Challenges: A Review
Authors: K.Ashoka Deepthi, Manoj Varma, Arup Polley
Abstract: Advancements in biomedical research have driven continuous innovations in sensing and diagnostic technologies. Among these, nanopore based single molecule sensing and sequencing is rapidly emerging as a powerful and versatile sensing methodology. Advancements in nanopore based approaches require concomitant improvements in the electronic readout methods employed, from the point of low noise, bandwidth and form factor. This article focuses on current sensing circuits designed and employed for ultra low noise nanopore signal readout, addressing the fundamental limitations of traditional off chip transimpedance amplifiers (TIAs), which suffer from high input parasitic capacitance, bandwidth constraints, and increased noise at high frequencies. This review explores the latest design schemes and circuit structures classified into on-chip and off-chip TIA designs, highlighting their design implementation, performance, respective challenges and explores the interplay between noise performance, capacitance, and bandwidth across diverse transimpedance amplifier (TIA) configurations. Emphasis is placed on characterizing noise response under varying parasitic capacitance and operational frequencies, a systematic evaluation not extensively addressed in prior literature while also considering the allowable input current compliance range limitations. The review also compares the widely used Axopatch 200B system to the designs reported in literature. The findings offer valuable insights into optimizing TIA designs for enhanced signal integrity in high speed and high sensitivity applications focusing on noise reduction, impedance matching, DC blocking, and offset cancellation techniques.

Paper number 43:
Title: Virtual-mask Informed Prior for Sparse-view Dual-Energy CT Reconstruction
Authors: Zini Chen, Yao Xiao, Junyan Zhang, Shaoyu Wang, Liu Shi, Qiegen Liu
Abstract: Sparse-view sampling in dual-energy computed tomography (DECT) significantly reduces radiation dose and increases imaging speed, yet is highly prone to artifacts. Although diffusion models have demonstrated potential in effectively handling incomplete data, most existing methods in this field focus on the image do-main and lack global constraints, which consequently leads to insufficient reconstruction quality. In this study, we propose a dual-domain virtual-mask in-formed diffusion model for sparse-view reconstruction by leveraging the high inter-channel correlation in DECT. Specifically, the study designs a virtual mask and applies it to the high-energy and low-energy data to perform perturbation operations, thus constructing high-dimensional tensors that serve as the prior information of the diffusion model. In addition, a dual-domain collaboration strategy is adopted to integrate the information of the randomly selected high-frequency components in the wavelet domain with the information in the projection domain, for the purpose of optimizing the global struc-tures and local details. Experimental results indicated that the present method exhibits excellent performance across multiple datasets.

Paper number 44:
Title: PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model Development
Authors: Zhenhuan Zhou, Yuchen Zhang, Ruihong Xu, Xuansen Zhao, Tao Li
Abstract: Deep learning (DL), a pivotal technology in artificial intelligence, has recently gained substantial traction in the domain of dental auxiliary diagnosis. However, its application has predominantly been confined to imaging modalities such as panoramic radiographs and Cone Beam Computed Tomography, with limited focus on auxiliary analysis specifically targeting Periapical Radiographs (PR). PR are the most extensively utilized imaging modality in endodontics and periodontics due to their capability to capture detailed local lesions at a low cost. Nevertheless, challenges such as resolution limitations and artifacts complicate the annotation and recognition of PR, leading to a scarcity of publicly available, large-scale, high-quality PR analysis datasets. This scarcity has somewhat impeded the advancement of DL applications in PR analysis. In this paper, we present PRAD-10K, a dataset for PR analysis. PRAD-10K comprises 10,000 clinical periapical radiograph images, with pixel-level annotations provided by professional dentists for nine distinct anatomical structures, lesions, and artificial restorations or medical devices, We also include classification labels for images with typical conditions or lesions. Furthermore, we introduce a DL network named PRNet to establish benchmarks for PR segmentation tasks. Experimental results demonstrate that PRNet surpasses previous state-of-the-art medical image segmentation models on the PRAD-10K dataset. The codes and dataset will be made publicly available.

Paper number 45:
Title: Focal Cortical Dysplasia Type II Detection Using Cross Modality Transfer Learning and Grad-CAM in 3D-CNNs for MRI Analysis
Authors: Lorenzo Lasagni, Antonio Ciccarone, Renzo Guerrini, Matteo Lenge, Ludovico D'incerti
Abstract: Focal cortical dysplasia (FCD) type II is a major cause of drug-resistant epilepsy, often curable only by surgery. Despite its clinical importance, the diagnosis of FCD is very difficult in MRI because of subtle abnormalities, leading to misdiagnosis. This study investigates the use of 3D convolutional neural networks (3D-CNNs) for FCD detection, using a dataset of 170 subjects (85 FCD patients and 85 controls) composed of T1-weighted and FLAIR MRI scans. In particular, it investigates the benefits obtained from cross-modality transfer learning and explainable artificial intelligence (XAI) techniques, in particular Gradient-weighted Class Activation Mapping (Grad-CAM). ResNet architectures (ResNet-18, -34, and -50) were implemented, employing transfer learning strategies that used pre-trained weights from segmentation tasks. Results indicate that transfer learning significantly enhances classification accuracy (up to 80.3%) and interpretability, as measured by a novel Heat-Score metric, which evaluates the model's focus on clinically relevant regions. Improvements in the Heat-Score metric underscore the model's seizure zone localization capabilities, bringing AI predictions and clinical insights closer together. These results highlight the importance of transfer learning, including cross-modality, and XAI in advancing AI-based medical diagnostics, especially for difficult-to-diagnose pathologies such as FCD.

Paper number 46:
Title: Generalized Passivity Sensitivity Methodology for Small-Signal Stability Analysis
Authors: Dongyeong Lee, Francisco Javier Cifuentes Garcia, Jef Beerten
Abstract: This paper proposes a generalized passivity sensitivity analysis for power system stability studies. The method uncovers the most effective instability mitigation actions for both device-level and system-level investigations. The particular structure of the admittance and nodal models is exploited in the detailed derivation of the passivity sensitivity expressions. These proposed sensitivities are validated for different parameters at device-level and at system-level. Compared to previous stability and sensitivity methods, it does not require detailed system information, such as exact system eigenvalues, while it provides valuable information for a less conservative stable system design. In addition, we demonstrate how to utilize the proposed method through case studies with different converter controls and system-wide insights showing its general applicability.

Paper number 47:
Title: HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature Fusion and Growth-Suppression Balanced Loss
Authors: Yi Huang, Ke Zhang, Wei Liu, Yuanyuan Wang, Vishal M. Patel, Le Lu, Xu Han, Dakai Jin, Ke Yan
Abstract: Accurate segmentation of tubular structures in medical images, such as vessels and airway trees, is crucial for computer-aided diagnosis, radiotherapy, and surgical planning. However, significant challenges exist in algorithm design when faced with diverse sizes, complex topologies, and (often) incomplete data annotation of these structures. We address these difficulties by proposing a new tubular structure segmentation framework named HarmonySeg. First, we design a deep-to-shallow decoder network featuring flexible convolution blocks with varying receptive fields, which enables the model to effectively adapt to tubular structures of different scales. Second, to highlight potential anatomical regions and improve the recall of small tubular structures, we incorporate vesselness maps as auxiliary information. These maps are aligned with image features through a shallow-and-deep fusion module, which simultaneously eliminates unreasonable candidates to maintain high precision. Finally, we introduce a topology-preserving loss function that leverages contextual and shape priors to balance the growth and suppression of tubular structures, which also allows the model to handle low-quality and incomplete annotations. Extensive quantitative experiments are conducted on four public datasets. The results show that our model can accurately segment 2D and 3D tubular structures and outperform existing state-of-the-art methods. External validation on a private dataset also demonstrates good generalizability.

Paper number 48:
Title: Episodically adapted network-based controllers
Authors: Sruti Mallik, ShiNung Ching
Abstract: We consider the problem of distributing a control policy across a network of interconnected units. Distributing controllers in this way has a number of potential advantages, especially in terms of robustness, as the failure of a single unit can be compensated by the activity of others. However, it is not obvious a priori how such network-based controllers should be constructed for any given system and control objective. Here, we propose a synthesis procedure for obtaining dynamical networks that enact well-defined control policies in a model-free manner. We specifically consider an augmented state space consisting of both the plant state and the network states. Solution of an optimization problem in this augmented state space produces a desired objective and specification of the network dynamics. Because of the analytical tractability of this method, we are able to provide convergence and robustness assessments

Paper number 49:
Title: The Efficacy of Semantics-Preserving Transformations in Self-Supervised Learning for Medical Ultrasound
Authors: Blake VanBerlo, Alexander Wong, Jesse Hoey, Robert Arntfield
Abstract: Data augmentation is a central component of joint embedding self-supervised learning (SSL). Approaches that work for natural images may not always be effective in medical imaging tasks. This study systematically investigated the impact of data augmentation and preprocessing strategies in SSL for lung ultrasound. Three data augmentation pipelines were assessed: (1) a baseline pipeline commonly used across imaging domains, (2) a novel semantic-preserving pipeline designed for ultrasound, and (3) a distilled set of the most effective transformations from both pipelines. Pretrained models were evaluated on multiple classification tasks: B-line detection, pleural effusion detection, and COVID-19 classification. Experiments revealed that semantics-preserving data augmentation resulted in the greatest performance for COVID-19 classification - a diagnostic task requiring global image context. Cropping-based methods yielded the greatest performance on the B-line and pleural effusion object classification tasks, which require strong local pattern recognition. Lastly, semantics-preserving ultrasound image preprocessing resulted in increased downstream performance for multiple tasks. Guidance regarding data augmentation and preprocessing strategies was synthesized for practitioners working with SSL in ultrasound.

Paper number 50:
Title: Zero-Shot Low-dose CT Denoising via Sinogram Flicking
Authors: Yongyi Shi, Ge Wang
Abstract: Many low-dose CT imaging methods rely on supervised learning, which requires a large number of paired noisy and clean images. However, obtaining paired images in clinical practice is challenging. To address this issue, zero-shot self-supervised methods train denoising networks using only the information within a single image, such as ZS-N2N. However, these methods often employ downsampling operations that degrade image resolution. Additionally, the training dataset is inherently constrained to the image itself. In this paper, we propose a zero-shot low-dose CT imaging method based on sinogram flicking, which operates within a single image but generates many copies via random conjugate ray matching. Specifically, two conjugate X-ray pencil beams measure the same path; their expected values should be identical, while their noise levels vary during measurements. By randomly swapping portions of the conjugate X-rays in the sinogram domain, we generate a large set of sinograms with consistent content but varying noise patterns. When displayed dynamically, these sinograms exhibit a flickering effect due to their identical structural content but differing noise patterns-hence the term sinogram flicking. We train the network on pairs of sinograms with the same content but different noise distributions using a lightweight model adapted from ZS-NSN. This process is repeated to obtain the final results. A simulation study demonstrates that our method outperforms state-of-the-art approaches such as ZS-N2N.

Paper number 51:
Title: Visual-Aware Speech Recognition for Noisy Scenarios
Authors: Lakshmipathi Balaji, Karan Singla
Abstract: Humans have the ability to utilize visual cues, such as lip movements and visual scenes, to enhance auditory perception, particularly in noisy environments. However, current Automatic Speech Recognition (ASR) or Audio-Visual Speech Recognition (AVSR) models often struggle in noisy scenarios. To solve this task, we propose a model that improves transcription by correlating noise sources to visual cues. Unlike works that rely on lip motion and require the speaker's visibility, we exploit broader visual information from the environment. This allows our model to naturally filter speech from noise and improve transcription, much like humans do in noisy scenarios. Our method re-purposes pretrained speech and visual encoders, linking them with multi-headed attention. This approach enables the transcription of speech and the prediction of noise labels in video inputs. We introduce a scalable pipeline to develop audio-visual datasets, where visual cues correlate to noise in the audio. We show significant improvements over existing audio-only models in noisy scenarios. Results also highlight that visual cues play a vital role in improved transcription accuracy.

Paper number 52:
Title: Unit-Vector Control Design under Saturating Actuators
Authors: Andevaldo da Encarnação Vitório, Pedro Henrique Silva Coutinho, Iury Bessa, Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira
Abstract: This paper deals with unit vector control design for multivariable polytopic uncertain systems under saturating actuators. For that purpose, we propose LMI-based conditions to design the unit vector control gain such that the origin of the closed-loop system is finite-time stable. Moreover, an optimization problem is provided to obtain an enlarged estimate of the region of attraction of the equilibrium point for the closed-loop system, where the convergence of trajectories is ensured even in the presence of saturation functions. Numerical simulations illustrate the effectiveness of the proposed approach.

Paper number 53:
Title: Multivariable Extremum Seeking Unit-Vector Control Design
Authors: Enzo Ferreira Tomaz Silva, Pedro Henrique Silva Coutinho, Tiago Roux Oliveira, Miroslav Krstić
Abstract: This paper investigates multivariable extremum seeking using unit-vector control. By employing the gradient algorithm and a polytopic embedding of the unknown Hessian matrix, we establish sufficient conditions, expressed as linear matrix inequalities, for designing the unit-vector control gain that ensures finite-time stability of the origin of the average closed-loop error system. Notably, these conditions enable the design of non-diagonal control gains, which provide extra degrees of freedom to the solution. The convergence of the actual closed-loop system to a neighborhood of the unknown extremum point is rigorously proven through averaging analysis for systems with discontinuous right-hand sides. Numerical simulations illustrate the efficacy of the proposed extremum seeking control algorithm.

Paper number 54:
Title: Enabling Continuous 5G Connectivity in Aircraft through Low Earth Orbit Satellites
Authors: Raúl Parada, Victor Monzon Baeza, Carlos Horcajo Fernández de Gamboa, Rocío Serrano Camacho, Carlos Monzo
Abstract: As air travel demand increases, uninterrupted high-speed internet access becomes essential. However, current satellite-based systems face latency and connectivity challenges. While prior research has focused on terrestrial 5G and geostationary satellites, there is a gap in optimizing Low Earth Orbit (LEO)-based 5G systems for aircraft. This study evaluates the feasibility of deployment strategies and improving signal quality with LEO satellites for seamless in-flight 5G connectivity. Using Matlab and Simulink, we model satellite trajectories, aircraft movement, and handover mechanisms, complemented by ray-tracing techniques for in-cabin signal analysis. Results show that proposed LEO satellite configurations enhance coverage and reduce latency, with sequential handovers minimizing service interruptions. These findings contribute to advancing in-flight 5G networks, improving passenger experience, and supporting real-time global connectivity solutions.

Paper number 55:
Title: Data-Enabled Neighboring Extremal: Case Study on Model-Free Trajectory Tracking for Robotic Arm
Authors: Amin Vahidi-Moghaddam, Keyi Zhu, Kaixiang Zhang, Ziyou Song, Zhaojian Li
Abstract: Data-enabled predictive control (DeePC) has recently emerged as a powerful data-driven approach for efficient system controls with constraints handling capabilities. It performs optimal controls by directly harnessing input-output (I/O) data, bypassing the process of explicit model identification that can be costly and time-consuming. However, its high computational complexity, driven by a large-scale optimization problem (typically in a higher dimension than its model-based counterpart--Model Predictive Control), hinders real-time applications. To overcome this limitation, we propose the data-enabled neighboring extremal (DeeNE) framework, which significantly reduces computational cost while preserving control performance. DeeNE leverages first-order optimality perturbation analysis to efficiently update a precomputed nominal DeePC solution in response to changes in initial conditions and reference trajectories. We validate its effectiveness on a 7-DoF KINOVA Gen3 robotic arm, demonstrating substantial computational savings and robust, data-driven control performance.

Paper number 56:
Title: Quantum-Inspired Genetic Algorithm for Robust Source Separation in Smart City Acoustics
Authors: Minh K. Quan, Mayuri Wijayasundara, Sujeeva Setunge, Pubudu N. Pathirana
Abstract: The cacophony of urban sounds presents a significant challenge for smart city applications that rely on accurate acoustic scene analysis. Effectively analyzing these complex soundscapes, often characterized by overlapping sound sources, diverse acoustic events, and unpredictable noise levels, requires precise source separation. This task becomes more complicated when only limited training data is available. This paper introduces a novel Quantum-Inspired Genetic Algorithm (p-QIGA) for source separation, drawing inspiration from quantum information theory to enhance acoustic scene analysis in smart cities. By leveraging quantum superposition for efficient solution space exploration and entanglement to handle correlated sources, p-QIGA achieves robust separation even with limited data. These quantum-inspired concepts are integrated into a genetic algorithm framework to optimize source separation parameters. The effectiveness of our approach is demonstrated on two datasets: the TAU Urban Acoustic Scenes 2020 Mobile dataset, representing typical urban soundscapes, and the Silent Cities dataset, capturing quieter urban environments during the COVID-19 pandemic. Experimental results show that the p-QIGA achieves accuracy comparable to state-of-the-art methods while exhibiting superior resilience to noise and limited training data, achieving up to 8.2 dB signal-to-distortion ratio (SDR) in noisy environments and outperforming baseline methods by up to 2 dB with only 10% of the training data. This research highlights the potential of p-QIGA to advance acoustic signal processing in smart cities, particularly for noise pollution monitoring and acoustic surveillance.

Paper number 57:
Title: Electronic Warfare Cyberattacks, Countermeasures and Modern Defensive Strategies of UAV Avionics: A Survey
Authors: Aaron Yu, Iuliia Kolotylo, Hashim A. Hashim, A. E.E. Eltoukhy
Abstract: Unmanned Aerial Vehicles (UAVs) play a pivotal role in modern autonomous air mobility, and the reliability of UAV avionics systems is critical to ensuring mission success, sustainability practices, and public safety. The success of UAV missions depends on effectively mitigating various aspects of electronic warfare, including non-destructive and destructive cyberattacks, transponder vulnerabilities, and jamming threats, while rigorously implementing countermeasures and defensive aids. This paper provides a comprehensive review of UAV cyberattacks, countermeasures, and defensive strategies. It explores UAV-to-UAV coordination attacks and their associated features, such as dispatch system attacks, Automatic Dependent Surveillance-Broadcast (ADS-B) attacks, Traffic Alert and Collision Avoidance System (TCAS)-induced collisions, and TCAS attacks. Additionally, the paper examines UAV-to-command center coordination attacks, as well as UAV functionality attacks. The review also covers various countermeasures and defensive aids designed for UAVs. Lastly, a comparison of common cyberattacks and countermeasure approaches is conducted, along with a discussion of future trends in the field. Keywords: Electronic warfare, UAVs, Avionics Systems, cyberattacks, coordination attacks, functionality attacks, countermeasure, defensive-aids.

Paper number 58:
Title: Towards Generalizability to Tone and Content Variations in the Transcription of Amplifier Rendered Electric Guitar Audio
Authors: Yu-Hua Chen, Yuan-Chiao Cheng, Yen-Tung Yeh, Jui-Te Wu, Jyh-Shing Roger Jang, Yi-Hsuan Yang
Abstract: Transcribing electric guitar recordings is challenging due to the scarcity of diverse datasets and the complex tone-related variations introduced by amplifiers, cabinets, and effect pedals. To address these issues, we introduce EGDB-PG, a novel dataset designed to capture a wide range of tone-related characteristics across various amplifier-cabinet configurations. In addition, we propose the Tone-informed Transformer (TIT), a Transformer-based transcription model enhanced with a tone embedding mechanism that leverages learned representations to improve the model's adaptability to tone-related nuances. Experiments demonstrate that TIT, trained on EGDB-PG, outperforms existing baselines across diverse amplifier types, with transcription accuracy improvements driven by the dataset's diversity and the tone embedding technique. Through detailed benchmarking and ablation studies, we evaluate the impact of tone augmentation, content augmentation, audio normalization, and tone embedding on transcription performance. This work advances electric guitar transcription by overcoming limitations in dataset diversity and tone modeling, providing a robust foundation for future research.

Paper number 59:
Title: Enabling Gigantic MIMO Beamforming with Analog Computing
Authors: Matteo Nerini, Bruno Clerckx
Abstract: In our previous work, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic multiple-input multiple-output (MIMO) beamforming entirely in the analog domain. MiLAC-aided beamforming can implement regularized zero-forcing beamforming (R-ZFBF) at the transmitter and minimum mean square error (MMSE) detection at the receiver, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of R-ZFBF, which scales quadratically with the number of antennas instead of cubically. Numerical results show that it can perform R-ZFBF with a computational complexity reduction of up to 7400 times compared to digital beamforming.

Paper number 60:
Title: Joint Travel Route Optimization Framework for Platooning
Authors: Akif Adas, Stefano Arrigoni, Mattia Brambilla, Monica Barbara Nicoli, Edoardo Sabbioni
Abstract: Platooning represents an advanced driving technology designed to assist drivers in traffic convoys of varying lengths, enhancing road safety, reducing driver fatigue, and improving fuel efficiency. Sophisticated automated driving assistance systems have facilitated this innovation. Recent advancements in platooning emphasize cooperative mechanisms within both centralized and decentralized architectures enabled by vehicular communication technologies. This study introduces a cooperative route planning optimization framework aimed at promoting the adoption of platooning through a centralized platoon formation strategy at the system level. This approach is envisioned as a transitional phase from individual (ego) driving to fully collaborative driving. Additionally, this research formulates and incorporates travel cost metrics related to fuel consumption, driver fatigue, and travel time, considering regulatory constraints on consecutive driving durations. The performance of these cost metrics has been evaluated using Dijkstra's and A* shortest path algorithms within a network graph framework. The results indicate that the proposed architecture achieves an average cost improvement of 14 % compared to individual route planning for long road trips.

Paper number 61:
Title: UWB Anchor Based Localization of a Planetary Rover
Authors: Andreas Nüchter, Lennart Werner, Martin Hesse, Dorit Borrmann, Thomas Walter, Sergio Montenegro, Gernot Grömer
Abstract: Localization of an autonomous mobile robot during planetary exploration is challenging due to the unknown terrain, the difficult lighting conditions and the lack of any global reference such as satellite navigation systems. We present a novel approach for robot localization based on ultra-wideband (UWB) technology. The robot sets up its own reference coordinate system by distributing UWB anchor nodes in the environment via a rocket-propelled launcher system. This allows the creation of a localization space in which UWB measurements are employed to supplement traditional SLAM-based techniques. The system was developed for our involvement in the ESA-ESRIC challenge 2021 and the AMADEE-24, an analog Mars simulation in Armenia by the Austrian Space Forum (ÖWF).

Paper number 62:
Title: PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution
Authors: Shuangfan Zhou, Chu Zhou, Youwei Lyu, Heng Guo, Zhanyu Ma, Boxin Shi, Imari Sato
Abstract: Polarization cameras can capture multiple polarized images with different polarizer angles in a single shot, bringing convenience to polarization-based downstream tasks. However, their direct outputs are color-polarization filter array (CPFA) raw images, requiring demosaicing to reconstruct full-resolution, full-color polarized images; unfortunately, this necessary step introduces artifacts that make polarization-related parameters such as the degree of polarization (DoP) and angle of polarization (AoP) prone to error. Besides, limited by the hardware design, the resolution of a polarization camera is often much lower than that of a conventional RGB camera. Existing polarized image demosaicing (PID) methods are limited in that they cannot enhance resolution, while polarized image super-resolution (PISR) methods, though designed to obtain high-resolution (HR) polarized images from the demosaicing results, tend to retain or even amplify errors in the DoP and AoP introduced by demosaicing artifacts. In this paper, we propose PIDSR, a joint framework that performs complementary Polarized Image Demosaicing and Super-Resolution, showing the ability to robustly obtain high-quality HR polarized images with more accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments show our PIDSR not only achieves state-of-the-art performance on both synthetic and real data, but also facilitates downstream tasks.

Paper number 63:
Title: Event-Triggered Source Seeking Control for Nonholonomic Systems
Authors: Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krstic
Abstract: This paper introduces an event-triggered source seeking control (ET-SSC) for autonomous vehicles modeled as the nonholonomic unicycle. The classical source seeking control is enhanced with static-triggering conditions to enable aperiodic and less frequent updates of the system's input signals, offering a resource-aware control design. Our convergence analysis is based on time-scaling combined with Lyapunov and averaging theories for systems with discontinuous right-hand sides. ET-SSC ensures exponentially stable behavior for the resulting average system, leading to practical asymptotic convergence to a small neighborhood of the source point. We guarantee the avoidance of Zeno behavior by establishing a minimum dwell time to prevent infinitely fast switching. The performance optimization is aligned with classical continuous-time source seeking algorithms while balancing system performance with actuation resource consumption. Our ET-SSC algorithm, the first of its kind, allows for arbitrarily large inter-sampling times, overcoming the limitations of classical sampled-data implementations for source seeking control.

Paper number 64:
Title: Open Datasets for Grid Modeling and Visualization: An Alberta Power Network Case
Authors: Ben Cheng, Yize Chen
Abstract: In the power and energy industry, multiple entities in grid operational logs are frequently recorded and updated. Thanks to recent advances in IT facilities and smart metering services, a variety of datasets such as system load, generation mix, and grid connection are often publicly available. While these resources are valuable in evaluating power grid's operational conditions and system resilience, the lack of fine-grained, accurate locational information constrain the usage of current data, which further hinders the development of smart grid and renewables integration. For instance, electricity end users are not aware of nodal generation mix or carbon emissions, while the general public have limited understanding about the effect of demand response or renewables integration if only the whole system's demands and generations are available. In this work, we focus on recovering power grid topology and line flow directions from open public dataset. Taking the Alberta grid as a working example, we start from mapping multi-modal power system datasets to the grid topology integrated with geographical information. By designing a novel optimization-based scheme to recover line flow directions, we are able to analyze and visualize the interactions between generations and demand vectors in an efficient manner. Proposed research is fully open-sourced and highly generalizable, which can help model and visualize grid information, create synthetic dataset, and facilitate analytics and decision-making framework for clean energy transition.

Paper number 65:
Title: Multi-view Hybrid Graph Convolutional Network for Volume-to-mesh Reconstruction in Cardiovascular MRI
Authors: Nicolás Gaggion, Benjamin A. Matheson, Yan Xia, Rodrigo Bonazzola, Nishant Ravikumar, Zeike A. Taylor, Diego H. Milone, Alejandro F. Frangi, Enzo Ferrante
Abstract: Cardiovascular magnetic resonance imaging is emerging as a crucial tool to examine cardiac morphology and function. Essential to this endeavour are anatomical 3D surface and volumetric meshes derived from CMR images, which facilitate computational anatomy studies, biomarker discovery, and in-silico simulations. Traditional approaches typically follow complex multi-step pipelines, first segmenting images and then reconstructing meshes, making them time-consuming and prone to error propagation. In response, we introduce HybridVNet, a novel architecture for direct image-to-mesh extraction seamlessly integrating standard convolutional neural networks with graph convolutions, which we prove can efficiently handle surface and volumetric meshes by encoding them as graph structures. To further enhance accuracy, we propose a multi-view HybridVNet architecture which processes both long axis and short axis CMR, showing that it can increase the performance of cardiac MR mesh generation. Our model combines traditional convolutional networks with variational graph generative models, deep supervision and mesh-specific regularisation. Experiments on a comprehensive dataset from the UK Biobank confirm the potential of HybridVNet to significantly advance cardiac imaging and computational cardiology by efficiently generating high-fidelity meshes from CMR images. Multi-view HybridVNet outperforms the state-of-the-art, achieving improvements of up to $\sim$27\% reduction in Mean Contour Distance (from 1.86 mm to 1.35 mm for the LV Myocardium), up to $\sim$18\% improvement in Hausdorff distance (from 4.74 mm to 3.89mm, for the LV Endocardium), and up to $\sim$8\% in Dice Coefficient (from 0.78 to 0.84, for the LV Myocardium), highlighting its superior accuracy.

Paper number 66:
Title: Machine Learning-based Near-field Emitter Location Sensing via Grouped Hybrid Analog and Digital XL-MIMO Receive Array
Authors: Jiatong Bai, Yifan Li, Feng Shu, Kang Wei, Cunhua Pan, Yongpeng Wu, Yaoliang Song, Jiangzhou Wang
Abstract: As a green MIMO structure, the partially-connected hybrid analog and digital (PC-HAD) structure has been widely used in the far-field (FF) scenario for it can significantly reduce the hardware cost and complexity of large-scale or extremely large-scale MIMO (XL-MIMO) array. Recently, near-field (NF) emitter localization including direction-of-arrival (DOA) and range estimations has drawn a lot of attention, but is rarely explored via PC-HAD structure. In this paper, we first analyze the impact of PC-HAD structure on the NF emitter localization and observe that the phase ambiguity (PA) problem caused by PC-HAD structure can be removed inherently with low-latency in the NF scenario. To obtain the exact NF DOA estimation results, we propose a grouped PC-HAD structure, which is capable of dividing the NF DOA estimation problem into multiple FF DOA estimation problems via partitioning the large-scale PC-HAD array into small-scale groups. An angle calibration method is developed to address the inconsistency among these FF DOA estimation problems. Then, to eliminate PA and improve the NF emitter localization performance, we develop three machine learning (ML)-based methods, i.e., two low-complexity data-driven clustering-based methods and one model-driven regression method, namely RegNet. Furthermore, the Cramer-Rao lower bound (CRLB) of NF emitter localization for the proposed grouped PC-HAD structure is derived and reveals that localization performance will decrease with the increasing of the number of groups. The simulation results show that the proposed methods can achieve CRLB at different SNR regions, the RegNet has great performance advantages at low SNR regions and the clustering-based methods have much lower computation complexity.

Paper number 67:
Title: Robust, positive and exact model reduction via monotone matrices
Authors: Marco Cortese, Tommaso Grigoletto, Francesco Ticozzi, Augusto Ferrante
Abstract: This work focuses on the problem of exact model reduction of positive linear systems, by leveraging minimal realization theory. While determining the existence of a positive reachable realization remains in general an open problem, we are able to fully characterize the cases in which the new model is obtained with non-negative reduction matrices, and hence positivity of the reduced model is robust with respect to small perturbations of the original system. The characterization is obtained by specializing monotone matrix theory to positive matrices. In addition, we provide a systematic method to construct positive reductions also when minimal ones are not available, by exploiting algebraic techniques.

Paper number 68:
Title: Enhancing Cell Instance Segmentation in Scanning Electron Microscopy Images via a Deep Contour Closing Operator
Authors: Florian Robert, Alexia Calovoulos, Laurent Facq, Fanny Decoeur, Etienne Gontier, Christophe F. Grosset, Baudouin Denis de Senneville
Abstract: Accurately segmenting and individualizing cells in SEM images is a highly promising technique for elucidating tissue architecture in oncology. While current AI-based methods are effective, errors persist, necessitating time-consuming manual corrections, particularly in areas where the quality of cell contours in the image is poor and requires gap filling. This study presents a novel AI-driven approach for refining cell boundary delineation to improve instance-based cell segmentation in SEM images, also reducing the necessity for residual manual correction. A CNN COp-Net is introduced to address gaps in cell contours, effectively filling in regions with deficient or absent information. The network takes as input cell contour probability maps with potentially inadequate or missing information and outputs corrected cell contour delineations. The lack of training data was addressed by generating low integrity probability maps using a tailored PDE. We showcase the efficacy of our approach in augmenting cell boundary precision using both private SEM images from PDX hepatoblastoma tissues and publicly accessible images datasets. The proposed cell contour closing operator exhibits a notable improvement in tested datasets, achieving respectively close to 50% (private data) and 10% (public data) increase in the accurately-delineated cell proportion compared to state-of-the-art methods. Additionally, the need for manual corrections was significantly reduced, therefore facilitating the overall digitalization process. Our results demonstrate a notable enhancement in the accuracy of cell instance segmentation, particularly in highly challenging regions where image quality compromises the integrity of cell boundaries, necessitating gap filling. Therefore, our work should ultimately facilitate the study of tumour tissue bioarchitecture in onconanotomy field.

Paper number 69:
Title: A Hierarchical View of Structured Sparsity in Kronecker Compressive Sensing
Authors: Yanbin He, Geethu Joseph
Abstract: Kronecker compressed sensing refers to using Kronecker product matrices as sparsifying bases and measurement matrices in compressed sensing. This work focuses on the Kronecker compressed sensing problem, encompassing three sparsity structures: $(i)$ a standard sparsity model with arbitrarily positioned nonzero entries, $(ii)$ a hierarchical sparsity model where nonzero entries are concentrated in a few blocks, each with only a subset of nonzero entries, and $(iii)$ a Kronecker-supported sparsity model where the support vector is a Kronecker product of smaller vectors. We present a hierarchal view of Kronecker compressed sensing that explicitly reveals a multiple-level sparsity pattern. This framework allows us to utilize the Kronecker structure of dictionaries and design a two-stage sparse recovery algorithm for different sparsity models. Further, we analyze the restricted isometry property of Kronecker-structured matrices under different sparsity models. Simulations show that our algorithm offers comparable recovery performance to state-of-the-art methods while significantly reducing runtime.

Paper number 70:
Title: Balanced Truncation via Tangential Interpolation
Authors: Umair Zulfiqar, Zhi-Hua Xiao, Qiu-yan Song, Victor Sreeram
Abstract: This paper examines the construction of rth-order truncated balanced realizations via tangential interpolation at r specified interpolation points. It is demonstrated that when the truncated Hankel singular values are negligible-that is, when the discarded states are nearly uncontrollable and unobservable-balanced truncation simplifies to a bi-tangential Hermite interpolation problem at r interpolation points. In such cases, the resulting truncated balanced realization is nearly H2-optimal and thus interpolates the original model at the mirror images of its poles along its residual directions. Like standard H2-optimal model reduction, where the interpolation points and tangential directions that yield a local optimum are not known, in balanced truncation as well, the interpolation points and tangential directions required to produce a truncated balanced realization remain unknown. To address this, we propose an iterative tangential interpolation-based algorithm for balanced truncation. Upon convergence, the algorithm yields a low-rank truncated balanced realization that accurately preserves the r largest Hankel singular values of the original system. An adaptive scheme to automatically select the order r of the reduced model is also proposed. The algorithm is fully automatic, choosing both the interpolation data and the model order without user intervention. Additionally, an adaptive low-rank solver for Lyapunov equations based on tangential interpolation is proposed, automatically selecting both the interpolation data and the rank without user intervention. The performance of the proposed algorithms is evaluated on benchmark models, confirming their efficacy.

Paper number 71:
Title: Energy-Efficient Multi-UAV-Enabled MEC Systems over Space-Air-Ground Integrated Networks
Authors: Wenchao Liu, Xuhui Zhang, Jinke Ren, Yanyan Shen, Shuqiang Wang, Bo Yang, Xinping Guan, Shuguang Cui
Abstract: With the development of artificial intelligence integrated next-generation communication networks, mobile users (MUs) are increasingly demanding the efficient processing of computation-intensive and latency-sensitive tasks. However, existing mobile computing networks struggle to support the rapidly growing computational needs of the MUs. Fortunately, space-air-ground integrated network (SAGIN) supported mobile edge computing (MEC) is regarded as an effective solution, offering the MUs multi-tier and efficient computing services. In this paper, we consider an SAGIN supported MEC system, where a low Earth orbit satellite and multiple unmanned aerial vehicles (UAVs) are dispatched to provide computing services for MUs. An energy efficiency maximization problem is formulated, with the joint optimization of the MU-UAV association, the UAV trajectory, the task offloading decision, the computing frequency, and the transmission power control. Since the problem is non-convex, we decompose it into four subproblems, and propose an alternating optimization based algorithm to solve it. Simulation results confirm that the proposed algorithm outperforms the benchmarks.

Paper number 72:
Title: Crowd Size Estimation for Non-Uniform Spatial Distributions with mmWave Radar
Authors: Anurag Pallaprolu, Aaditya Prakash Kattekola, Winston Hurst, Upamanyu Madhow, Ashutosh Sabharwal, Yasamin Mostofi
Abstract: In this paper, we present a novel methodology for crowd size estimation using monostatic mmWave radar. Our aim is to accurately count large crowds that follow a non-uniform spatial distribution. Our estimation approach relies on the rigorous derivation of occlusion probabilities, which are then used to mathematically characterize the probability distributions that describe the number of agents visible to the radar as a function of the crowd size. We then estimate the true crowd size by comparing these derived mathematical models to the empirical distribution of the number of visible agents detected by the radar. This method requires minimal sensing capabilities (e.g., angle-of-arrival information is not needed), thus being well suited for either a dedicated mmWave radar or an integrated sensing and communication (ISAC) system. Extensive numerical simulations validate our methodology, demonstrating strong performance across diverse spatial distributions and for crowd sizes of up to (and including) 30 agents. We achieve a mean absolute error (MAE) of 0.48 agents, significantly outperforming a baseline which assumes that the agents are uniformly distributed in the area. Overall, our approach holds significant promise for a variety of applications including network resource allocation, crowd management, and urban planning.

Paper number 73:
Title: Attitude Estimation via Matrix Fisher Distributions on SO(3) Using Non-Unit Vector Measurements
Authors: Shijie Wang, Haichao Gui, Rui Zhong
Abstract: This note presents a novel Bayesian attitude estimator with the matrix Fisher distribution on the special orthogonal group, which can smoothly accommodate both unit and non-unit vector measurements. The posterior attitude distribution is proven to be a matrix Fisher distribution with the assumption that non-unit vector measurement errors follow the isotropic Gaussian distributions and unit vector measurements follow the von-Mises Fisher distributions. Next, a global unscented transformation is proposed to approximate the full likelihood distribution with a matrix Fisher distribution for more generic cases of vector measurement errors following the non-isotropic Gaussian distributions. Following these, a Bayesian attitude estimator with the matrix Fisher distribution is constructed. Numerical examples are then presented. The proposed estimator exhibits advantageous performance compared with the previous attitude estimator with matrix Fisher distributions and the classic multiplicative extended Kalman filter in the case of non-unit vector measurements.

Paper number 74:
Title: Convergence and Robustness of Value and Policy Iteration for the Linear Quadratic Regulator
Authors: Bowen Song, Chenxuan Wu, Andrea Iannelli
Abstract: This paper revisits and extends the convergence and robustness properties of value and policy iteration algorithms for discrete-time linear quadratic regulator problems. In the model-based case, we extend current results concerning the region of exponential convergence of both algorithms. In the case where there is uncertainty on the value of the system matrices, we provide input-to-state stability results capturing the effect of model parameter uncertainties. Our findings offer new insights into these algorithms at the heart of several approximate dynamic programming schemes, highlighting their convergence and robustness behaviors. Numerical examples illustrate the significance of some of the theoretical results.

Paper number 75:
Title: Demonstrating Remote Synchronization: An Experimental Approach with Nonlinear Oscillators
Authors: Sanjeev Kumar Pandey, Neetish Patel
Abstract: This study investigates remote synchronization in arbitrary network clusters of coupled nonlinear oscillators, a phenomenon inspired by neural synchronization in the brain. Employing a multi-faceted approach encompassing analytical, numerical, and experimental methodologies, we leverage the Master Stability Function (MSF) to analyze network stability. We provide experimental evidence of remote synchronization between two clusters of nonlinear oscillators, where oscillators within each cluster are also remotely connected. This observation parallels the thalamus-mediated synchronization of neuronal populations in the brain. An electronic circuit testbed, supported by nonlinear ODE modeling and LT Spice simulation, was developed to validate our theoretical predictions. Future work will extend this investigation to encompass diverse network topologies and explore potential applications in neuroscience, communication networks, and power systems.

Paper number 76:
Title: Amplitude response and square wave describing functions
Authors: Thomas Chaffey, Fulvio Forni
Abstract: An analog of the describing function method is developed using square waves rather than sinusoids. Static nonlinearities map square waves to square waves, and their behavior is characterized by their response to square waves of varying amplitude - their amplitude response. The output of an LTI system to a square wave input is approximated by a square wave, to give an analog of the describing function. The classical describing function method for predicting oscillations in feedback interconnections is generalized to this square wave setting, and gives accurate predictions when oscillations are approximately square.

Paper number 77:
Title: Mode Switching-Induced Instability of Multi-source Feed DC Microgrid
Authors: Shanshan Jiang, Zelin Sun, Jiankun Zhang, Hua Geng
Abstract: In DC microgrids (DCMGs), DC-bus signaling based control strategy is extensively used for power management, where mode switching plays a crucial role in achieving multi-source coordination. However, few studies have noticed the impact of mode switching and switching strategies on system voltage stability. To fill this gap, this paper aims to provide a general analysis framework for mode switching-induced instability in multi-source DCMGs. First, manifold theory is employed to analyze the stability of the DCMG switched system. Subsequently, the instability mechanism and its physical interpretation are explored. The positive feedback activated by the decreasing DC bus voltage during the switching process leads to instability. Switching strategy may inadvertently contribute to this instability. To improve stability, a novel control method based on mode scheduling is proposed, by adjusting switching strategy and thereby correcting the system trajectory. Finally, both real-time simulations and experimental tests on a DCMG system verify the correctness and effectiveness of theoretical analysis results.

Paper number 78:
Title: Decentralized Parametric Stability Certificates for Grid-Forming Converter Control
Authors: Verena Häberle, Xiuqiang He, Linbin Huang, Florian Dörfler, Steven Low
Abstract: We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.

Paper number 79:
Title: T-Parameters Based Modeling for Stacked Intelligent Metasurfaces: Tractable and Physically Consistent Model
Authors: Hamad Yahya, Matteo Nerini, Bruno Clerckx, Merouane Debbah
Abstract: This work develops a physically consistent model for stacked intelligent metasurfaces (SIM) using multiport network theory and transfer scattering parameters (T-parameters). Unlike the scattering parameters (S-parameters) model, the developed T-parameters model is simpler and more tractable. Moreover, the T-parameters constraints for lossless reciprocal reconfigurable intelligent surfaces (RISs) are derived. Additionally, a gradient descent algorithm (GDA) is introduced to maximize sum-rate in SIM-aided multiuser scenarios, demonstrating that mutual coupling and feedback between consecutive layers enhance performance. However, increasing SIM layers with a fixed total number of elements typically degrades sum-rate, unless the simplified channel model employing Rayleigh-Sommerfeld diffraction coefficients is utilized.

Paper number 80:
Title: A Unifying Complexity-Certification Framework for Branch-and-Bound Algorithms for Mixed-Integer Linear and Quadratic Programming
Authors: Shamisa Shoja, Daniel Arnström, Daniel Axehill
Abstract: In model predictive control (MPC) for hybrid systems, solving optimization problems efficiently and with guarantees on worst-case computational complexity is critical to satisfy the real-time constraints in these applications. These optimization problems often take the form of mixed-integer linear programs (MILPs) or mixed-integer quadratic programs (MIQPs) that depend on system parameters. A common approach for solving such problems is the branch-and-bound (B&B) method. This paper extends existing complexity certification methods by presenting a unified complexity-certification framework for B&B-based MILP and MIQP solvers, specifically for the family of multi-parametric MILP and MIQP problems that arise in, e.g., hybrid MPC applications. The framework provides guarantees on worst-case computational measures, including the maximum number of iterations or relaxations B&B algorithms require to reach optimality. It systematically accounts for different branching and node selection strategies, as well as heuristics integrated into B&B, ensuring a comprehensive certification framework. By offering theoretical guarantees and practical insights for solver customization, the proposed framework enhances the reliability of B&B for real-time application. The usefulness of the proposed framework is demonstrated through numerical experiments on both random MILPs and MIQPs, as well as on MIQPs arising from a hybrid MPC problem.

Paper number 81:
Title: Parallel Domain-Decomposition Algorithms for Complexity Certification of Branch-and-Bound Algorithms for Mixed-Integer Linear and Quadratic Programming
Authors: Shamisa Shoja, Daniel Arnström, Daniel Axehill
Abstract: When implementing model predictive control (MPC) for hybrid systems with a linear or a quadratic performance measure, a mixed-integer linear program (MILP) or a mixed-integer quadratic program (MIQP) needs to be solved, respectively, at each sampling instant. Recent work has introduced the possibility to certify the computational complexity of branch-and-bound (B&B) algorithms when solving MILP and MIQP problems formulated as multi-parametric MILPs (mp-MILPs) and mp-MIQPs. Such a framework allows for computing the worst-case computational complexity of standard B&B-based MILP and MIQP solvers, quantified by metrics such as the total number of LP/QP iterations and B&B nodes. These results are highly relevant for real-time hybrid MPC applications. In this paper, we extend this framework by developing parallel, domain-decomposition versions of the previously proposed algorithm, allowing it to scale to larger problem sizes and enable the use of high-performance computing (HPC) resources. Furthermore, to reduce peak memory consumption, we introduce two novel modifications to the existing (serial) complexity certification framework, integrating them into the proposed parallel algorithms. Numerical experiments show that the parallel algorithms significantly reduce computation time while maintaining the correctness of the original framework.

Paper number 82:
Title: Automated Video-EEG Analysis in Epilepsy Studies: Advances and Challenges
Authors: Valerii A. Zuev, Elena G. Salmagambetova, Stepan N. Djakov, Lev V. Utkin
Abstract: Epilepsy is typically diagnosed through electroencephalography (EEG) and long-term video-EEG (vEEG) monitoring. The manual analysis of vEEG recordings is time-consuming, necessitating automated tools for seizure detection. Recent advancements in machine learning have shown promise in real-time seizure detection and prediction using EEG and video data. However, diversity of seizure symptoms, markup ambiguities, and limited availability of multimodal datasets hinder progress. This paper reviews the latest developments in automated video-EEG analysis and discusses the integration of multimodal data. We also propose a novel pipeline for treatment effect estimation from vEEG data using concept-based learning, offering a pathway for future research in this domain.

Paper number 83:
Title: Perturbation-Based Pinning Control Strategy for Enhanced Synchronization in Complex Networks
Authors: Ziang Mao, Tianlong Fan, Linyuan Lü
Abstract: Synchronization is essential for the stability and coordinated operation of complex networked systems. Pinning control, which selectively controls a subset of nodes, provides a scalable solution to enhance network synchronizability. However, existing strategies face key limitations: heuristic centrality-based methods lack a direct connection to synchronization dynamics, while spectral approaches, though effective, are computationally intensive. To address these challenges, we propose a perturbation-based optimized strategy (PBO) that dynamically evaluates each node's spectral impact on the Laplacian matrix, achieving improved synchronizability with significantly reduced computational costs (with complexity O(kM)). Extensive experiments demonstrate that the proposed method outperforms traditional strategies in synchronizability, convergence rate, and pinning robustness to node failures. Notably, in all the empirical networks tested and some generated networks, PBO significantly outperforms the brute-force greedy strategy, demonstrating its ability to avoid local optima and adapt to complex connectivity patterns. Our study establishes the theoretical relationship between network synchronizability and convergence rate, offering new insights into efficient synchronization strategies for large-scale complex networks.

Paper number 84:
Title: Hybrid Control Barrier Functions for Nonholonomic Multi-Agent Systems
Authors: Aurora Haraldsen, Josef Matous, Kristin Y. Pettersen
Abstract: This paper addresses the problem of guaranteeing safety of multiple coordinated agents moving in dynamic environments. It has recently been shown that this problem can be efficiently solved through the notion of Control Barrier Functions (CBFs). However, for nonholonomic vehicles that are required to keep positive speeds, existing CBFs lose their validity. To overcome this limitation, we propose a hybrid formulation based on synergistic CBFs (SCBFs), which leverages a discrete switching mechanism to avoid configurations that would render the CBF invalid. Unlike existing approaches, our method ensures safety in the presence of moving obstacles and inter-agent interactions while respecting nonzero speed restrictions. We formally analyze the feasibility of the constraints with respect to actuation limits, and the efficacy of the solution is demonstrated in simulation of a multi-agent coordination problem in the presence of moving obstacles.

Paper number 85:
Title: Subjective Visual Quality Assessment for High-Fidelity Learning-Based Image Compression
Authors: Mohsen Jenadeleh, Jon Sneyers, Panqi Jia, Shima Mohammadi, Joao Ascenso, Dietmar Saupe
Abstract: Learning-based image compression methods have recently emerged as promising alternatives to traditional codecs, offering improved rate-distortion performance and perceptual quality. JPEG AI represents the latest standardized framework in this domain, leveraging deep neural networks for high-fidelity image reconstruction. In this study, we present a comprehensive subjective visual quality assessment of JPEG AI-compressed images using the JPEG AIC-3 methodology, which quantifies perceptual differences in terms of Just Noticeable Difference (JND) units. We generated a dataset of 50 compressed images with fine-grained distortion levels from five diverse sources. A large-scale crowdsourced experiment collected 96,200 triplet responses from 459 participants. We reconstructed JND-based quality scales using a unified model based on boosted and plain triplet comparisons. Additionally, we evaluated the alignment of multiple objective image quality metrics with human perception in the high-fidelity range. The CVVDP metric achieved the overall highest performance; however, most metrics including CVVDP were overly optimistic in predicting the quality of JPEG AI-compressed images. These findings emphasize the necessity for rigorous subjective evaluations in the development and benchmarking of modern image codecs, particularly in the high-fidelity range. Another technical contribution is the introduction of the well-known Meng-Rosenthal-Rubin statistical test to the field of Quality of Experience research. This test can reliably assess the significance of difference in performance of quality metrics in terms of correlation between metrics and ground truth. The complete dataset, including all subjective scores, is publicly available at this https URL.

Paper number 86:
Title: Deep Generative Models for Physiological Signals: A Systematic Literature Review
Authors: Nour Neifar, Afef Mdhaffar, Achraf Ben-Hamadou, Mohamed Jmaiel
Abstract: In this paper, we present a systematic literature review on deep generative models for physiological signals, particularly electrocardiogram (ECG), electroencephalogram (EEG), photoplethysmogram (PPG) and electromyogram (EMG). Compared to the existing review papers, we present the first review that summarizes the recent state-of-the-art deep generative models. By analyzing the state-of-the-art research related to deep generative models along with their main applications and challenges, this review contributes to the overall understanding of these models applied to physiological signals. Additionally, by highlighting the employed evaluation protocol and the most used physiological databases, this review facilitates the assessment and benchmarking of deep generative models.

Paper number 87:
Title: SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in HuBERT
Authors: Cheol Jun Cho, Abdelrahman Mohamed, Shang-Wen Li, Alan W Black, Gopala K. Anumanchipalli
Abstract: Data-driven unit discovery in self-supervised learning (SSL) of speech has embarked on a new era of spoken language processing. Yet, the discovered units often remain in phonetic space and the units beyond phonemes are largely underexplored. Here, we demonstrate that a syllabic organization emerges in learning sentence-level representation of speech. In particular, we adopt "self-distillation" objective to fine-tune the pretrained HuBERT with an aggregator token that summarizes the entire sentence. Without any supervision, the resulting model draws definite boundaries in speech, and the representations across frames exhibit salient syllabic structures. We demonstrate that this emergent structure largely corresponds to the ground truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating sentence-level representation of speech. When compared to previous models, our model outperforms in both unsupervised syllable discovery and learning sentence-level representation. Together, we demonstrate that the self-distillation of HuBERT gives rise to syllabic organization without relying on external labels or modalities, and potentially provides novel data-driven units for spoken language modeling.

Paper number 88:
Title: Potential Field Based Deep Metric Learning
Authors: Shubhang Bhatnagar, Narendra Ahuja
Abstract: Deep metric learning (DML) involves training a network to learn a semantically meaningful representation space. Many current approaches mine n-tuples of examples and model interactions within each tuplets. We present a novel, compositional DML model that instead of in tuples, represents the influence of each example (embedding) by a continuous potential field, and superposes the fields to obtain their combined global potential field. We use attractive/repulsive potential fields to represent interactions among embeddings from images of the same/different classes. Contrary to typical learning methods, where mutual influence of samples is proportional to their distance, we enforce reduction in such influence with distance, leading to a decaying field. We show that such decay helps improve performance on real world datasets with large intra-class variations and label noise. Like other proxy-based methods, we also use proxies to succinctly represent sub-populations of examples. We evaluate our method on three standard DML benchmarks- Cars-196, CUB-200-2011, and SOP datasets where it outperforms state-of-the-art baselines.

Paper number 89:
Title: Accelerating Ill-conditioned Hankel Matrix Recovery via Structured Newton-like Descent
Authors: HanQin Cai, Longxiu Huang, Xiliang Lu, Juntao You
Abstract: This paper studies the robust Hankel recovery problem, which simultaneously removes the sparse outliers and fulfills missing entries from the partial observation. We propose a novel non-convex algorithm, coined Hankel Structured Newton-Like Descent (HSNLD), to tackle the robust Hankel recovery problem. HSNLD is highly efficient with linear convergence, and its convergence rate is independent of the condition number of the underlying Hankel matrix. The recovery guarantee has been established under some mild conditions. Numerical experiments on both synthetic and real datasets show the superior performance of HSNLD against state-of-the-art algorithms.

Paper number 90:
Title: Neural Approximate Mirror Maps for Constrained Diffusion Models
Authors: Berthy T. Feng, Ricardo Baptista, Katherine L. Bouman
Abstract: Diffusion models excel at creating visually-convincing images, but they often struggle to meet subtle constraints inherent in the training data. Such constraints could be physics-based (e.g., satisfying a PDE), geometric (e.g., respecting symmetry), or semantic (e.g., including a particular number of objects). When the training data all satisfy a certain constraint, enforcing this constraint on a diffusion model makes it more reliable for generating valid synthetic data and solving constrained inverse problems. However, existing methods for constrained diffusion models are restricted in the constraints they can handle. For instance, recent work proposed to learn mirror diffusion models (MDMs), but analytical mirror maps only exist for convex constraints and can be challenging to derive. We propose neural approximate mirror maps (NAMMs) for general, possibly non-convex constraints. Our approach only requires a differentiable distance function from the constraint set. We learn an approximate mirror map that transforms data into an unconstrained space and a corresponding approximate inverse that maps data back to the constraint set. A generative model, such as an MDM, can then be trained in the learned mirror space and its samples restored to the constraint set by the inverse map. We validate our approach on a variety of constraints, showing that compared to an unconstrained diffusion model, a NAMM-based MDM substantially improves constraint satisfaction. We also demonstrate how existing diffusion-based inverse-problem solvers can be easily applied in the learned mirror space to solve constrained inverse problems.

Paper number 91:
Title: Taming Data and Transformers for Scalable Audio Generation
Authors: Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez
Abstract: The scalability of ambient sound generators is hindered by data scarcity, insufficient caption quality, and limited scalability in model architecture. This work addresses these challenges by advancing both data and model scaling. First, we propose an efficient and scalable dataset collection pipeline tailored for ambient audio generation, resulting in AutoReCap-XL, the largest ambient audio-text dataset with over 47 million clips. To provide high-quality textual annotations, we propose AutoCap, a high-quality automatic audio captioning model. By adopting a Q-Former module and leveraging audio metadata, AutoCap substantially enhances caption quality, reaching a CIDEr score of $83.2$, a $3.2\%$ improvement over previous captioning models. Finally, we propose GenAu, a scalable transformer-based audio generation architecture that we scale up to 1.25B parameters. We demonstrate its benefits from data scaling with synthetic captions as well as model size scaling. When compared to baseline audio generators trained at similar size and data scale, GenAu obtains significant improvements of $4.7\%$ in FAD score, $11.1\%$ in IS, and $13.5\%$ in CLAP score. Our code, model checkpoints, and dataset are publicly available.

Paper number 92:
Title: SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning
Authors: Jianye Xu, Pan Hu, Bassam Alrifaee
Abstract: This paper introduces an open-source, decentralized framework named SigmaRL, designed to enhance both sample efficiency and generalization of multi-agent Reinforcement Learning (RL) for motion planning of connected and automated vehicles. Most RL agents exhibit a limited capacity to generalize, often focusing narrowly on specific scenarios, and are usually evaluated in similar or even the same scenarios seen during training. Various methods have been proposed to address these challenges, including experience replay and regularization. However, how observation design in RL affects sample efficiency and generalization remains an under-explored area. We address this gap by proposing five strategies to design information-dense observations, focusing on general features that are applicable to most traffic scenarios. We train our RL agents using these strategies on an intersection and evaluate their generalization through numerical experiments across completely unseen traffic scenarios, including a new intersection, an on-ramp, and a roundabout. Incorporating these information-dense observations reduces training times to under one hour on a single CPU, and the evaluation results reveal that our RL agents can effectively zero-shot generalize. Code: this http URL

Paper number 93:
Title: Performance Analysis of Physical Layer Security: From Far-Field to Near-Field
Authors: Boqun Zhao, Chongjun Ouyang, Xingqi Zhang, Yuanwei Liu
Abstract: The secrecy performance in both near-field and far-field communications is analyzed using two fundamental metrics: the secrecy capacity under a power constraint and the minimum power requirement to achieve a specified secrecy rate target. 1) For the secrecy capacity, a closed-form expression is derived under a discrete-time memoryless setup. This expression is further analyzed under several far-field and near-field channel models, and the capacity scaling law is revealed by assuming an infinitely large transmit array and an infinitely high power. A novel concept of "depth of insecurity" is proposed to evaluate the secrecy performance achieved by near-field beamfocusing. It is demonstrated that increasing the number of transmit antennas reduces this depth and thus improves the secrecy performance. 2) Regarding the minimum required power, a closed-form expression is derived and analyzed within far-field and near-field scenarios. Asymptotic analyses are performed by setting the number of transmit antennas to infinity to unveil the power scaling law. Numerical results are provided to demonstrate that: i) compared to far-field communications, near-field communications expand the areas where secure transmission is feasible, specifically when the eavesdropper is located in the same direction as the intended receiver; ii) as the number of transmit antennas increases, neither the secrecy capacity nor the minimum required power scales or vanishes unboundedly, adhering to the principle of energy conservation.

Paper number 94:
Title: Scheduling Policies in a Multi-Source Status Update System with Dedicated and Shared Servers
Authors: Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar
Abstract: Use of multi-path network topologies has become a prominent technique to assert timeliness in terms of age of information (AoI) and to improve resilience to link disruptions in communication systems. However, establishing multiple dedicated communication links among network nodes is a costly endeavor. Therefore, quite often, these secondary communication links are shared among multiple entities. Moreover, these multi-path networks come with the added challenge of out-of-order transmissions. In this paper, we study an amalgamation of the above two aspects, i.e., multi-path transmissions and link sharing. In contrast to the existing literature where the main focus has been scheduling multiple sources on a single shared server, we delve into the realm where each source sharing the shared server is also supplemented with its dedicated server so as to improve its timeliness. In this multi-path link sharing setting with generate-at-will transmissions, we first present the optimal probabilistic scheduler, and then propose several heuristic-based cyclic scheduling algorithms for the shared server, to minimize the weighted average age of information of the sources.

Paper number 95:
Title: EveGuard: Defeating Vibration-based Side-Channel Eavesdropping with Audio Adversarial Perturbations
Authors: Jung-Woo Chang, Ke Sun, David Xia, Xinyu Zhang, Farinaz Koushanfar
Abstract: Vibrometry-based side channels pose a significant privacy risk, exploiting sensors like mmWave radars, light sensors, and accelerometers to detect vibrations from sound sources or proximate objects, enabling speech eavesdropping. Despite various proposed defenses, these involve costly hardware solutions with inherent physical limitations. This paper presents EveGuard, a software-driven defense framework that creates adversarial audio, protecting voice privacy from side channels without compromising human perception. We leverage the distinct sensing capabilities of side channels and traditional microphones, where side channels capture vibrations and microphones record changes in air pressure, resulting in different frequency responses. EveGuard first proposes a perturbation generator model (PGM) that effectively suppresses sensor-based eavesdropping while maintaining high audio quality. Second, to enable end-to-end training of PGM, we introduce a new domain translation task called Eve-GAN for inferring an eavesdropped signal from a given audio. We further apply few-shot learning to mitigate the data collection overhead for Eve-GAN training. Our extensive experiments show that EveGuard achieves a protection rate of more than 97 percent from audio classifiers and significantly hinders eavesdropped audio reconstruction. We further validate the performance of EveGuard across three adaptive attack mechanisms. We have conducted a user study to verify the perceptual quality of our perturbed audio.

Paper number 96:
Title: SGSST: Scaling Gaussian Splatting StyleTransfer
Authors: Bruno Galerne, Jianling Wang, Lara Raad, Jean-Michel Morel
Abstract: Applying style transfer to a full 3D environment is a challenging task that has seen many developments since the advent of neural rendering. 3D Gaussian splatting (3DGS) has recently pushed further many limits of neural rendering in terms of training speed and reconstruction quality. This work introduces SGSST: Scaling Gaussian Splatting Style Transfer, an optimization-based method to apply style transfer to pretrained 3DGS scenes. We demonstrate that a new multiscale loss based on global neural statistics, that we name SOS for Simultaneously Optimized Scales, enables style transfer to ultra-high resolution 3D scenes. Not only SGSST pioneers 3D scene style transfer at such high image resolutions, it also produces superior visual quality as assessed by thorough qualitative, quantitative and perceptual comparisons.

Paper number 97:
Title: Exact Model Reduction for Continuous-Time Open Quantum Dynamics
Authors: Tommaso Grigoletto, Yukuan Tao, Francesco Ticozzi, Lorenza Viola
Abstract: We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.

Paper number 98:
Title: Coordinated vehicle dispatching and charging scheduling for an electric ride-hailing fleet under charging congestion and dynamic prices
Authors: Tai-Yu Ma, Richard D. Connors, Francesco Viti
Abstract: Effective utilization of charging station capacity plays an important role in enhancing the profitability of ride-hailing systems using electric vehicles. Existing studies assume constant energy prices and uncapacitated charging stations or do not explicitly consider vehicle queueing at charging stations, resulting in over-optimistic charging infrastructure utilization. In this study, we develop a dynamic charging scheduling method (named CongestionAware) that anticipates vehicles' energy needs and coordinates their charging operations with real-time energy prices to avoid long waiting time at charging stations and increase the total profit of the system. A sequential mixed integer linear programming model is proposed to devise vehicles' day-ahead charging plans based on their experienced charging waiting times and energy consumption. The obtained charging plans are adapted within the day in response to vehicles' energy needs and charging station congestion. The developed charging policy is tested using NYC yellow taxi data in a Manhattan-like study area with a fleet size of 100 vehicles given the scenarios of 3000 and 4000 customers per day. The computational results show that our CongestionAware policy outperforms different benchmark policies with up to +15.06% profit and +19.16% service rate for 4000 customers per day. Sensitivity analysis is conducted with different system parameters and managerial insights are discussed.

Paper number 99:
Title: autrainer: A Modular and Extensible Deep Learning Toolkit for Computer Audition Tasks
Authors: Simon Rampp, Andreas Triantafyllopoulos, Manuel Milling, Björn W. Schuller
Abstract: This work introduces the key operating principles for autrainer, our new deep learning training framework for computer audition tasks. autrainer is a PyTorch-based toolkit that allows for rapid, reproducible, and easily extensible training on a variety of different computer audition tasks. Concretely, autrainer offers low-code training and supports a wide range of neural networks as well as preprocessing routines. In this work, we present an overview of its inner workings and key capabilities.

Paper number 100:
Title: TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization
Authors: Chia-Yu Hung, Navonil Majumder, Zhifeng Kong, Ambuj Mehrish, Amir Ali Bagherzadeh, Chuan Li, Rafael Valle, Bryan Catanzaro, Soujanya Poria
Abstract: We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks structured mechanisms like verifiable rewards or gold-standard answers available for Large Language Models (LLMs). To address this, we propose CLAP-Ranked Preference Optimization (CRPO), a novel framework that iteratively generates and optimizes preference data to enhance TTA alignment. We demonstrate that the audio preference dataset generated using CRPO outperforms existing alternatives. With this framework, TangoFlux achieves state-of-the-art performance across both objective and subjective benchmarks. We open source all code and models to support further research in TTA generation.

Paper number 101:
Title: Reachability-Guaranteed Optimal Control for the Interception of Dynamic Targets under Uncertainty
Authors: Tommaso Faraci, Roberto Lampariello
Abstract: Intercepting dynamic objects in uncertain environments involves a significant unresolved challenge in modern robotic systems. Current control approaches rely solely on estimated information, and results lack guarantees of robustness and feasibility. In this work, we introduce a novel method to tackle the interception of targets whose motion is affected by known and bounded uncertainty. Our approach introduces new techniques of reachability analysis for rigid bodies, leveraged to guarantee feasibility of interception under uncertain conditions. We then propose a Reachability-Guaranteed Optimal Control Problem, ensuring robustness and guaranteed reachability to a target set of configurations. We demonstrate the methodology in the case study of an interception maneuver of a tumbling target in space.

Paper number 102:
Title: Learning-Based Approximate Nonlinear Model Predictive Control Motion Cueing
Authors: Camilo Gonzalez Arango (1), Houshyar Asadi (1), Mohammad Reza Chalak Qazani (2), Chee Peng Lim (3) ((1) Institute for Intelligent Systems Research and Innovation, Deakin University, Waurn Ponds, Victoria, 3216, Australia. (2) Sohar University, Sohar, 311, Oman. (3) Swinburne University, Hawthorn, Victoria, 3122, Australia.)
Abstract: Motion Cueing Algorithms (MCAs) encode the movement of simulated vehicles into movement that can be reproduced with a motion simulator to provide a realistic driving experience within the capabilities of the machine. This paper introduces a novel learning-based MCA for serial robot-based motion simulators. Building on the differentiable predictive control framework, the proposed method merges the advantages of Nonlinear Model Predictive Control (NMPC) - notably nonlinear constraint handling and accurate kinematic modeling - with the computational efficiency of machine learning. By shifting the computational burden to offline training, the new algorithm enables real-time operation at high control rates, thus overcoming the key challenge associated with NMPC-based motion cueing. The proposed MCA incorporates a nonlinear joint-space plant model and a policy network trained to mimic NMPC behavior while accounting for joint acceleration, velocity, and position limits. Simulation experiments across multiple motion cueing scenarios showed that the proposed algorithm performed on par with a state-of-the-art NMPC-based alternative in terms of motion cueing quality as quantified by the RMSE and correlation coefficient with respect to reference signals. However, the proposed algorithm was on average 400 times faster than the NMPC baseline. In addition, the algorithm successfully generalized to unseen operating conditions, including motion cueing scenarios on a different vehicle and real-time physics-based simulations.
    