
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Going beyond explainability in multi-modal stroke outcome prediction models
Authors: Jonas Brändli, Maurice Schneeberger, Lisa Herzog, Loran Avci, Nordin Dari, Martin Häansel, Hakim Baazaoui, Pascal Bühler, Susanne Wegener, Beate Sick
Abstract: Aim: This study aims to enhance interpretability and explainability of multi-modal prediction models integrating imaging and tabular patient data. Methods: We adapt the xAI methods Grad-CAM and Occlusion to multi-modal, partly interpretable deep transformation models (dTMs). DTMs combine statistical and deep learning approaches to simultaneously achieve state-of-the-art prediction performance and interpretable parameter estimates, such as odds ratios for tabular features. Based on brain imaging and tabular data from 407 stroke patients, we trained dTMs to predict functional outcome three months after stroke. We evaluated the models using different discriminatory metrics. The adapted xAI methods were used to generated explanation maps for identification of relevant image features and error analysis. Results: The dTMs achieve state-of-the-art prediction performance, with area under the curve (AUC) values close to 0.8. The most important tabular predictors of functional outcome are functional independence before stroke and NIHSS on admission, a neurological score indicating stroke severity. Explanation maps calculated from brain imaging dTMs for functional outcome highlighted critical brain regions such as the frontal lobe, which is known to be linked to age which in turn increases the risk for unfavorable outcomes. Similarity plots of the explanation maps revealed distinct patterns which give insight into stroke pathophysiology, support developing novel predictors of stroke outcome and enable to identify false predictions. Conclusion: By adapting methods for explanation maps to dTMs, we enhanced the explainability of multi-modal and partly interpretable prediction models. The resulting explanation maps facilitate error analysis and support hypothesis generation regarding the significance of specific image regions in outcome prediction.

Paper number 2:
Title: Subjective Visual Quality Assessment for High-Fidelity Learning-Based Image Compression
Authors: Mohsen Jenadeleh, Jon Sneyers, Panqi Jia, Shima Mohammadi, Joao Ascenso, Dietmar Saupe
Abstract: Learning-based image compression methods have recently emerged as promising alternatives to traditional codecs, offering improved rate-distortion performance and perceptual quality. JPEG AI represents the latest standardized framework in this domain, leveraging deep neural networks for high-fidelity image reconstruction. In this study, we present a comprehensive subjective visual quality assessment of JPEG AI-compressed images using the JPEG AIC-3 methodology, which quantifies perceptual differences in terms of Just Noticeable Difference (JND) units. We generated a dataset of 50 compressed images with fine-grained distortion levels from five diverse sources. A large-scale crowdsourced experiment collected 96,200 triplet responses from 459 participants. We reconstructed JND-based quality scales using a unified model based on boosted and plain triplet comparisons. Additionally, we evaluated the alignment of multiple objective image quality metrics with human perception in the high-fidelity range. The CVVDP metric achieved the overall highest performance; however, most metrics including CVVDP were overly optimistic in predicting the quality of JPEG AI-compressed images. These findings emphasize the necessity for rigorous subjective evaluations in the development and benchmarking of modern image codecs, particularly in the high-fidelity range. Another technical contribution is the introduction of the well-known Meng-Rosenthal-Rubin statistical test to the field of Quality of Experience research. This test can reliably assess the significance of difference in performance of quality metrics in terms of correlation between metrics and ground truth. The complete dataset, including all subjective scores, is publicly available at this https URL.

Paper number 3:
Title: Restoring Feasibility in Power Grid Optimization: A Counterfactual ML Approach
Authors: Mostafa Mohammadian, Anna Van Boven, Kyri Baker
Abstract: Electric power grids are essential components of modern life, delivering reliable power to end-users while adhering to a multitude of engineering constraints and requirements. In grid operations, the Optimal Power Flow problem plays a key role in determining cost-effective generator dispatch that satisfies load demands and operational limits. However, due to stressed operating conditions, volatile demand profiles, and increased generation from intermittent energy sources, this optimization problem may become infeasible, posing risks such as voltage instability and line overloads. This study proposes a learning framework that combines machine learning with counterfactual explanations to automatically diagnose and restore feasibility in the OPF problem. Our method provides transparent and actionable insights by methodically identifying infeasible conditions and suggesting minimal demand response actions. We evaluate the proposed approach on IEEE 30-bus and 300-bus systems, demonstrating its capability to recover feasibility with high success rates and generating diverse corrective options, appropriate for real-time decision-making. These preliminary findings illustrate the potential of combining classical optimization with explainable AI techniques to enhance grid reliability and resilience.

Paper number 4:
Title: A Metropolis-Adjusted Langevin Algorithm for Sampling Jeffreys Prior
Authors: Yibo Shi, Braghadeesh Lakshminarayanan, Cristian R. Rojas
Abstract: Inference and estimation are fundamental aspects of statistics, system identification and machine learning. For most inference problems, prior knowledge is available on the system to be modeled, and Bayesian analysis is a natural framework to impose such prior information in the form of a prior distribution. However, in many situations, coming out with a fully specified prior distribution is not easy, as prior knowledge might be too vague, so practitioners prefer to use a prior distribution that is as `ignorant' or `uninformative' as possible, in the sense of not imposing subjective beliefs, while still supporting reliable statistical analysis. Jeffreys prior is an appealing uninformative prior because it offers two important benefits: (i) it is invariant under any re-parameterization of the model, (ii) it encodes the intrinsic geometric structure of the parameter space through the Fisher information matrix, which in turn enhances the diversity of parameter samples. Despite these benefits, drawing samples from Jeffreys prior is a challenging task. In this paper, we propose a general sampling scheme using the Metropolis-Adjusted Langevin Algorithm that enables sampling of parameter values from Jeffreys prior, and provide numerical illustrations of our approach through several examples.

Paper number 5:
Title: Review, Definition and Challenges of Electrical Energy Hubs
Authors: Giacomo Bastianel, Jan Kircheis, Merijn Van Deyck, Dongyeong Lee, Geraint Chaffey, Marta Vanin, Hakan Ergun, Jef Beerten, Dirk Van Hertem
Abstract: To transition towards a carbon-neutral power system, considerable amounts of renewable energy generation capacity are being installed in the North Sea area. Consequently, projects aggregating many gigawatts of power generation capacity and transmitting renewable energy to the main load centers are being developed. Given the electrical challenges arising from having bulk power capacity in a compact geographical area with several connections to the main grid, and a lack of a robust definition identifying the type of system under study, this paper proposes a general technical definition of such projects introducing the term Electrical Energy Hub (EEH). The concept, purpose, and functionalities of EEHs are introduced in the text, emphasizing the importance of a clear technical definition for future planning procedures, grid codes, regulations, and support schemes for EEHs and multiterminal HVDC (MTDC) grids in general. Furthermore, the unique electrical challenges associated with integrating EEHs into the power system are discussed. Three research areas of concern are identified, namely control, planning, and protection. Through this analysis, insights are provided into the effective implementation of multi-GW scale EEH projects and their integration into the power grid through multiple interconnections. Finally, a list of ongoing and planned grid development projects is evaluated to assess whether they fall within the EEH category

Paper number 6:
Title: A Scalable Automatic Model Generation Tool for Cyber-Physical Network Topologies and Data Flows for Large-Scale Synthetic Power Grid Models
Authors: Samantha Israel, Sanjana Kunkolienkar, Ana Goulart, Kate Davis, Thomas Overbye
Abstract: Power grids and their cyber infrastructure are classified as Critical Energy Infrastructure/Information (CEII) and are not publicly accessible. While realistic synthetic test cases for power systems have been developed in recent years, they often lack corresponding cyber network models. This work extends synthetic grid models by incorporating cyber-physical representations. To address the growing need for realistic and scalable models that integrate both cyber and physical layers in electric power systems, this paper presents the Scalable Automatic Model Generation Tool (SAM-GT). This tool enables the creation of large-scale cyber-physical topologies for power system models. The resulting cyber-physical network models include power system switches, routers, and firewalls while accounting for data flows and industrial communication protocols. Case studies demonstrate the tool's application to synthetic grid models of 500, 2,000, and 10,000 buses, considering three distinct network topologies. Results from these case studies include network metrics on critical nodes, hops, and generation times, showcasing effectiveness, adaptability, and scalability of SAM-GT.

Paper number 7:
Title: Panoptic: True Joint mmWave Communication and Sensing with Compressive Sidelobe Forming
Authors: Heyu Guo, Ruiyi Shen, Florian Kosterhon, Yasaman Ghasempour
Abstract: The integration of communication and sensing functions within mmWave systems has gained attention due to the potential for enhanced passive sensing and improved communication reliability. State-of-the-art techniques separate these two functions in frequency, use of hardware, or time, i.e., sending known preambles for channel sensing or unknown symbols for communications. In this paper, we introduce Panoptic, a novel system architecture for integrated communication and sensing sharing the same hardware, frequency, and time resources. Panoptic jointly detects unknown symbols and channel components from data-modulated signals. The core idea is a new beam manipulation technique, which we call compressive sidelobe forming, that maintains a directional mainlobe toward the intended communication nodes while acquiring unique spatial information through pseudorandom sidelobe perturbations. We implemented Panoptic on 60 GHz mmWave radios and conducted extensive over-the-air experiments. Our results show that Panoptic achieves reflector angular localization error of less than 2°while at the same time supporting mmWave data communication with a negligible BER penalty when compared with conventional communication-only mmWave systems.

Paper number 8:
Title: Leveraging Non-Steady-State Frequency-Domain Data in Willems' Fundamental Lemma
Authors: T.J. Meijer, M. Wind, V.S. Dolk, W.P.M.H. Heemels
Abstract: Willems' fundamental lemma enables data-driven analysis and control by characterizing an unknown system's behavior directly in terms of measured data. In this work, we extend a recent frequency-domain variant of this result--previously limited to steady-state data--to incorporate non-steady-state data including transient phenomena. This approach eliminates the need to wait for transients to decay during data collection, significantly reducing the experiment duration. Unlike existing frequency-domain system identification methods, our approach integrates transient data without preprocessing, making it well-suited for direct data-driven analysis and control. We demonstrate its effectiveness by isolating transients in the collected data and performing FRF evaluation at arbitrary frequencies in a numerical case study including noise.

Paper number 9:
Title: Physical spline for denoising object trajectory data by combining splines, ML feature regression and model knowledge
Authors: Jonas Torzewski
Abstract: This article presents a method for estimating the dynamic driving states (position, velocity, acceleration and heading) from noisy measurement data. The proposed approach is effective with both complete and partial observations, producing refined trajectory signals with kinematic consistency, ensuring that velocity is the integral of acceleration and position is the integral of velocity. Additionally, the method accounts for the constraint that vehicles can only move in the direction of their orientation. The method is implemented as a configurable python library that also enables trajectory estimation solely based on position data. Regularization is applied to prevent extreme state variations. A key application is enhancing recorded trajectory data for use as reference inputs in machine learning models. At the end, the article presents the results of the method along with a comparison to ground truth data.

Paper number 10:
Title: Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open Source AI
Authors: Adam McArthur, Stephanie Wichuk, Stephen Burnside, Andrew Kirby, Alexander Scammon, Damian Sol, Abhilash Hareendranathan, Jacob L. Jaremko
Abstract: Developmental dysplasia of the hip (DDH) poses significant diagnostic challenges, hindering timely intervention. Current screening methodologies lack standardization, and AI-driven studies suffer from reproducibility issues due to limited data and code availability. To address these limitations, we introduce Retuve, an open-source framework for multi-modality DDH analysis, encompassing both ultrasound (US) and X-ray imaging. Retuve provides a complete and reproducible workflow, offering open datasets comprising expert-annotated US and X-ray images, pre-trained models with training code and weights, and a user-friendly Python Application Programming Interface (API). The framework integrates segmentation and landmark detection models, enabling automated measurement of key diagnostic parameters such as the alpha angle and acetabular index. By adhering to open-source principles, Retuve promotes transparency, collaboration, and accessibility in DDH research. This initiative has the potential to democratize DDH screening, facilitate early diagnosis, and ultimately improve patient outcomes by enabling widespread screening and early intervention. The GitHub repository/code can be found here: this https URL

Paper number 11:
Title: Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach
Authors: Zihao Song, Panos J. Antsaklis, Hai Lin
Abstract: In this paper, we consider the distributed optimal control problem for linear networked systems. In particular, we are interested in learning distributed optimal controllers using graph recurrent neural networks (GRNNs). Most of the existing approaches result in centralized optimal controllers with offline training processes. However, as the increasing demand of network resilience, the optimal controllers are further expected to be distributed, and are desirable to be trained in an online distributed fashion, which are also the main contributions of our work. To solve this problem, we first propose a GRNN-based distributed optimal control method, and we cast the problem as a self-supervised learning problem. Then, the distributed online training is achieved via distributed gradient computation, and inspired by the (consensus-based) distributed optimization idea, a distributed online training optimizer is designed. Furthermore, the local closed-loop stability of the linear networked system under our proposed GRNN-based controller is provided by assuming that the nonlinear activation function of the GRNN-based controller is both local sector-bounded and slope-restricted. The effectiveness of our proposed method is illustrated by numerical simulations using a specifically developed simulator.

Paper number 12:
Title: ZETA: a library for Zonotope-based EsTimation and fAult diagnosis of discrete-time systems
Authors: Brenner S. Rego, Joseph K. Scott, Davide M. Raimondo, Marco H. Terra, Guilherme V. Raffo
Abstract: This paper introduces ZETA, a new MATLAB library for Zonotope-based EsTimation and fAult diagnosis of discrete-time systems. It features user-friendly implementations of set representations based on zonotopes, namely zonotopes, constrained zonotopes, and line zonotopes, in addition to a basic implementation of interval arithmetic. This library has capabilities starting from the basic set operations with these sets, including propagations through nonlinear functions using various approximation methods. The features of ZETA allow for reachability analysis and state estimation of discrete-time linear, nonlinear, and descriptor systems, in addition to active fault diagnosis of linear systems. Efficient order reduction methods are also implemented for the respective set representations. Some examples are presented in order to illustrate the functionalities of the new library.

Paper number 13:
Title: Data-driven Fuzzy Control for Time-Optimal Aggressive Trajectory Following
Authors: August Phelps, Juan Augusto Paredes Salazar, Ankit Goel
Abstract: Optimal trajectories that minimize a user-defined cost function in dynamic systems require the solution of a two-point boundary value problem. The optimization process yields an optimal control sequence that depends on the initial conditions and system parameters. However, the optimal sequence may result in undesirable behavior if the system's initial conditions and parameters are erroneous. This work presents a data-driven fuzzy controller synthesis framework that is guided by a time-optimal trajectory for multicopter tracking problems. In particular, we consider an aggressive maneuver consisting of a mid-air flip and generate a time-optimal trajectory by numerically solving the two-point boundary value problem. A fuzzy controller consisting of a stabilizing controller near hover conditions and an autoregressive moving average (ARMA) controller, trained to mimic the time-optimal aggressive trajectory, is constructed using the Takagi-Sugeno fuzzy framework.

Paper number 14:
Title: Sensing With Random Communication Signals
Authors: Shihang Lu, Fan Liu, Yifeng Xiong, Zhen Du, Yuanhao Cui, Shuangyang Li, Weijie Yuan, Jie Yang, Shi Jin
Abstract: Communication-centric Integrated Sensing and Communication (ISAC) has been recognized as a promising methodology to implement wireless sensing functionality over existing network architectures, due to its cost-effectiveness and backward compatibility to legacy cellular systems. However, the inherent randomness of the communication signal may incur huge fluctuations in sensing capabilities, leading to unfavorable detection and estimation performance. To address this issue, we elaborate on random ISAC signal processing methods in this article, aiming at improving the sensing performance without unduly deteriorating the communication functionality. Specifically, we commence by discussing the fundamentals of sensing with random communication signals, including the performance metrics and optimal ranging waveforms. Building on these concepts, we then present a general framework for random ISAC signal transmission, followed by an in-depth exploration of time-domain pulse shaping, frequency-domain constellation shaping, and spatial-domain precoding methods. We provide a comprehensive overview of each of these topics, including models, results, and design guidelines. Finally, we conclude this article by identifying several promising research directions for random ISAC signal transmission.

Paper number 15:
Title: Data-Driven Reachability with Scenario Optimization and the Holdout Method
Authors: Elizabeth Dietrich, Rosalyn Devonport, Stephen Tu, Murat Arcak
Abstract: Reachability analysis is an important method in providing safety guarantees for systems with unknown or uncertain dynamics. Due to the computational intractability of exact reachability analysis for general nonlinear, high-dimensional systems, recent work has focused on the use of probabilistic methods for computing approximate reachable sets. In this work, we advocate for the use of a general purpose, practical, and sharp method for data-driven reachability: the holdout method. Despite the simplicity of the holdout method, we show -- on several numerical examples including scenario-based reach tubes -- that the resulting probabilistic bounds are substantially sharper and require fewer samples than existing methods for data-driven reachability. Furthermore, we complement our work with a discussion on the necessity of probabilistic reachability bounds. We argue that any method that attempts to de-randomize the bounds, by converting the guarantees to hold deterministically, requires (a) an exponential in state-dimension amount of samples to achieve non-vacuous guarantees, and (b) extra assumptions on the dynamics.

Paper number 16:
Title: A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in Mixed Near-field and Far-field Scenarios
Authors: Yirui Luo, Yong Liang Guan, Yao Ge, David González G., Chau Yuen
Abstract: The recently proposed multi-chirp waveform, affine frequency division multiplexing (AFDM), is considered as a potential candidate for integrated sensing and communication (ISAC). However, acquiring accurate target sensing parameter information becomes challenging due to fractional delay and Doppler shift occurrence, as well as effects introduced by the coexistence of near-field (NF) and far-field (FF) targets associated with large-scale antenna systems. In this paper, we propose a novel angle-delay-Doppler estimation scheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we model the received ISAC signals as a third-order tensor that admits a low-rank CANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the factor matrix and the spatial smoothing technique, we develop a structured CP decomposition method that guarantees the condition for uniqueness. We further propose a low-complexity estimation scheme to acquire target sensing parameters with fractional values, including angle of arrival/departure (AoA/AoD), delay and Doppler shift accurately. We also derive the Cramér-Rao Lower Bound (CRLB) as a benchmark and analyze the complexity of our proposed scheme. Finally, simulation results are provided to demonstrate the effectiveness and superiority of our proposed scheme.

Paper number 17:
Title: A Digital Twin of an Electrical Distribution Grid: SoCal 28-Bus Dataset
Authors: Yiheng Xie, Lucien Werner, Kaibo Chen, Thuy-Linh Le, Christine Ortega, Steven Low
Abstract: We provide an open-access dataset of phasor & waveform measurement units (PMUs/WMUs) of a real-world electrical distribution network. The network consists of diverse sets of generation resources (including solar panels, fuel cells, natural gas generators, and utility interconnections), loads (including large-scale electric vehicle charging, data centers, central cooling, offices), topology changes (such as line outages and load transfers), as well as a mixture of single- and three-phase networks. We describe a densely deployed PMU sensor network in a distribution grid, in which all buses with non-zero power injections are measured. This approach enables a range of applications such as state estimation, system identification, power flow optimization, and feedback control, several of which are discussed in this paper. Additionally, we provide a synchronized waveform dataset which allows the analysis of harmonics, transient events, dynamic grid impedance, and stability. Data collection started in 2023 while new data is generated continuously and made available online. A characterization of measurement error is provided. Finally, we provide circuit topology and parameters as a part of the dataset. Together, the circuit and timeseries data offer an opportunity for researchers to develop and test algorithms on a real-world system.

Paper number 18:
Title: Sensing-Oriented Adaptive Resource Allocation Designs for OFDM-ISAC Systems
Authors: Peishi Li, Ming Li, Rang Liu, Qian Liu, A. Lee Swindlehurst
Abstract: Orthogonal frequency division multiplexing - integrated sensing and communication (OFDM-ISAC) has emerged as a key enabler for future wireless networks, leveraging the widely adopted OFDM waveform to seamlessly integrate wireless communication and radar sensing within a unified framework. In this paper, we propose adaptive resource allocation strategies for OFDM-ISAC systems to achieve optimal trade-offs between diverse sensing requirements and communication quality-of-service (QoS). We first develop a comprehensive resource allocation framework for OFDM-ISAC systems, deriving closed-form expressions for key sensing performance metrics, including delay resolution, Doppler resolution, delay-Doppler peak sidelobe level (PSL), and received signal-to-noise ratio (SNR). Building on this theoretical foundation, we introduce two novel resource allocation algorithms tailored to distinct sensing objectives. The resolution-oriented algorithm aims to maximize the weighted delay-Doppler resolution while satisfying constraints on PSL, sensing SNR, communication sum-rate, and transmit power. The sidelobe-oriented algorithm focuses on minimizing delay-Doppler PSL while satisfying resolution, SNR, and communication constraints. To efficiently solve the resulting non-convex optimization problems, we develop two adaptive resource allocation algorithms based on Dinkelbach's transform and majorization-minimization (MM). Extensive simulations validate the effectiveness of the proposed sensing-oriented adaptive resource allocation strategies in enhancing resolution and sidelobe suppression. Remarkably, these strategies achieve sensing performance nearly identical to that of a radar-only scheme, which dedicates all resources to sensing. These results highlight the superior performance of the proposed methods in optimizing the trade-off between sensing and communication objectives within OFDM-ISAC systems.

Paper number 19:
Title: Reliability Assessment of Low-Cost PM Sensors under High Humidity and High PM Level Outdoor Conditions
Authors: Gulshan Kumar, Prasannaa Kumar D, Jay Dhariwal, Seshan Srirangarajan
Abstract: Low-cost particulate matter (PM) sensors have become increasingly popular due to their compact size, low power consumption, and cost-effective installation and maintenance. While several studies have explored the effects of meteorological conditions and pollution exposure on low-cost sensor (LCS) performance, few have addressed the combined impact of high PM concentration and high humidity levels. In contrast to most evaluation studies, which generally report $\text{PM}_{2.5}$ levels below $150~\mu\text{g/m}^3$, our study observed hourly average $\text{PM}_{2.5}$ concentrations ranging from $6-611~\mu\text{g/m}^3$ (mean value of $137~\mu\text{g/m}^3$), with relative humidity between $25-95\%$ (mean value of $72\%$), and temperature varying from $6-29^\circ$C (mean value of $16^\circ$C). We evaluate three LCS models (SPS30, PMS7003, HPMA115C0-004) in outdoor conditions during the winter season in New Delhi, India, deployed alongside a reference-grade beta attenuation monitor (BAM). The results indicate a strong correlation between LCS and BAM measurements (${R^2} > 90\%$). The RMSE increases with increasing PM concentration and humidity levels but the narrow $95\%$ confidence interval range of LCS as a function of the reference BAM suggests the importance of LCS in air pollution monitoring. Among the evaluated LCS models, SPS30 showed the highest overall accuracy. Overall, the study demonstrates that LCS can effectively monitor air quality in regions with high PM and high humidity levels, provided appropriate correction models are applied.

Paper number 20:
Title: Learning-Inspired Fuzzy Logic Algorithms for Enhanced Control of Oscillatory Systems
Authors: Vuong Anh Trung, Thanh Son Pham, Truc Thanh Tran, Tran le Thang Dong, Tran Thuan Hoang
Abstract: The transportation of sensitive equipment often suffers from vibrations caused by terrain, weather, and motion speed, leading to inefficiencies and potential damage. To address this challenge, this paper explores an intelligent control framework leveraging fuzzy logic, a foundational AI technique, to suppress oscillations in suspension systems. Inspired by learning based methodologies, the proposed approach utilizes fuzzy inference and Gaussian membership functions to emulate adaptive, human like decision making. By minimizing the need for explicit mathematical models, the method demonstrates robustness in both linear and nonlinear systems. Experimental validation highlights the controllers ability to adapt to varying suspension lengths, reducing oscillation amplitudes and improving stability under dynamic conditions. This research bridges the gap between traditional control systems and learning inspired techniques, offering a scalable, data efficient solution for modern transportation challenges

Paper number 21:
Title: A Survey of New Mid-Band/FR3 for 6G: Channel Measurement, Characterization and Modeling in Outdoor Environment
Authors: Haiyang Miao, Jianhua Zhang, Pan Tang, Jie Meng, Qi Zhen, Ximan Liu, Enrui Liu, Peijie Liu, Lei Tian, Guangyi Liu
Abstract: The new mid-band (6-24 GHz) has attracted significant attention from both academia and industry, which is the spectrum with continuous bandwidth that combines the coverage benefits of low frequency with the capacity advantages of high frequency. Since outdoor environments represent the primary application scenario for mobile communications, this paper presents the first comprehensive review and summary of multi-scenario and multi-frequency channel characteristics based on extensive outdoor new mid-band channel measurement data, including UMa, UMi, and O2I. Specifically, a survey of the progress of the channel characteristics is presented, such as path loss, delay spread, angular spread, channel sparsity, capacity and near-field spatial non-stationary characteristics. Then, considering that satellite communication will be an important component of future communication systems, we examine the impact of clutter loss in air-ground communications. Our analysis of the frequency dependence of mid-band clutter loss suggests that its impact is not significant. Additionally, given that penetration loss is frequency-dependent, we summarize its variation within the FR3 band. Based on experimental results, comparisons with the standard model reveal that while the 3GPP TR 38.901 model remains a useful reference for penetration loss in wood and glass, it shows significant deviations for concrete and glass, indicating the need for further refinement. In summary, the findings of this survey provide both empirical data and theoretical support for the deployment of mid-band in future communication systems, as well as guidance for optimizing mid-band base station deployment in the outdoor environment. This survey offers the reference for improving standard models and advancing channel modeling.

Paper number 22:
Title: Optimal Duration of Reserve Capacity Ancillary Services for Distributed Energy Resources
Authors: Lorenzo Zapparoli, Blazhe Gjorgiev, Giovanni Sansavini
Abstract: The increasing integration of distributed energy resources (DERs) into power systems presents opportunities and challenges for ancillary services (AS) provision. Technical requirements of existing AS (i.e., duration, reliability, ramp rate, and lead time) have been designed for traditional generating units, making their provision by DER aggregates particularly challenging. This paper proposes a method to design the duration of reserve capacity AS products considering the operational constraints of DERs and the temporal dynamics of system imbalances. The optimal product duration is determined by maximizing product availability and aligning the supply profile with the system's balancing needs. We apply the methodology to a realistic Swiss low-voltage network with a diverse DER portfolio. The results reveal that (i) shorter product durations maximize average availability and (ii) long product durations improve the alignment with system balancing needs. This paper offers valuable insights for system operators to design AS products tailored for DER participation.

Paper number 23:
Title: FJ-MM: The Friedkin-Johnsen Opinion Dynamics Model with Memory and Higher-Order Neighbors
Authors: Roberta Raineri, Lorenzo Zino, Anton Proskurnikov
Abstract: The Friedkin-Johnsen (FJ) model has been extensively explored and validated, spanning applications in social science, systems and control, game theory, and algorithmic research. In this paper, we introduce an advanced generalization of the FJ model, termed FJ-MM which incorporates both memory effects and multi-hop (higher-order neighbor) influence. This formulation allows agents to naturally incorporate both current and previous opinions at each iteration stage. Our numerical results demonstrate that incorporating memory and multi-hop influence significantly reshapes the opinion landscape; for example, the final opinion profile can exhibit reduced polarization. We analyze the stability and equilibrium properties of the FJ-MM model, showing that these properties can be reduced to those of a comparison model--namely, the standard FJ model with a modified influence matrix. This reduction enables us to leverage established stability results from FJ dynamics. Additionally, we examine the convergence rate of the FJ-MM model and demonstrate that, as can be expected, the time lags introduced by memory and higher-order neighbor influences result in slower convergence.

Paper number 24:
Title: DIMA: DIffusing Motion Artifacts for unsupervised correction in brain MRI images
Authors: Paolo Angella, Luca Balbi, Fabrizio Ferrando, Paolo Traverso, Rosario Varriale, Vito Paolo Pastore, Matteo Santacesaria
Abstract: Motion artifacts remain a significant challenge in Magnetic Resonance Imaging (MRI), compromising diagnostic quality and potentially leading to misdiagnosis or repeated scans. Existing deep learning approaches for motion artifact correction typically require paired motion-free and motion-affected images for training, which are rarely available in clinical settings. To overcome this requirement, we present DIMA (DIffusing Motion Artifacts), a novel framework that leverages diffusion models to enable unsupervised motion artifact correction in brain MRI. Our two-phase approach first trains a diffusion model on unpaired motion-affected images to learn the distribution of motion artifacts. This model then generates realistic motion artifacts on clean images, creating paired datasets suitable for supervised training of correction networks. Unlike existing methods, DIMA operates without requiring k-space manipulation or detailed knowledge of MRI sequence parameters, making it adaptable across different scanning protocols and hardware. Comprehensive evaluations across multiple datasets and anatomical planes demonstrate that our method achieves comparable performance to state-of-the-art supervised approaches while offering superior generalizability to real clinical data. DIMA represents a significant advancement in making motion artifact correction more accessible for routine clinical use, potentially reducing the need for repeat scans and improving diagnostic accuracy.

Paper number 25:
Title: Variable Metric Splitting Methods for Neuromorphic Circuits Simulation
Authors: Amir Shahhosseini, Thomas Burger, Rodolphe Sepulchre
Abstract: This paper proposes a variable metric splitting algorithm to solve the electrical behavior of neuromorphic circuits made of capacitors, memristive elements, and batteries. The gradient property of the memristive elements is exploited to split the current to voltage operator as the sum of the derivative operator, a Riemannian gradient operator, and a nonlinear residual operator that is linearized at each step of the algorithm. The diagonal structure of the three operators makes the variable metric forward-backward splitting algorithm scalable and amenable to the simulation of large-scale neuromorphic circuits.

Paper number 26:
Title: Deep Neural Koopman Operator-based Economic Model Predictive Control of Shipboard Carbon Capture System
Authors: Minghao Han, Xunyuan Yin
Abstract: Shipboard carbon capture is a promising solution to help reduce carbon emissions in international shipping. In this work, we propose a data-driven dynamic modeling and economic predictive control approach within the Koopman framework. This integrated modeling and control approach is used to achieve safe and energy-efficient process operation of shipboard post-combustion carbon capture plants. Specifically, we propose a deep neural Koopman operator modeling approach, based on which a Koopman model with time-varying model parameters is established. This Koopman model predicts the overall economic operational cost and key system outputs, based on accessible partial state measurements. By leveraging this learned model, a constrained economic predictive control scheme is developed. Despite time-varying parameters involved in the formulated model, the formulated optimization problem associated with the economic predictive control design is convex, and it can be solved efficiently during online control implementations. Extensive tests are conducted on a high-fidelity simulation environment for shipboard post-combustion carbon capture processes. Four ship operational conditions are taken into account. The results show that the proposed method significantly improves the overall economic operational performance and carbon capture rate. Additionally, the proposed method guarantees safe operation by ensuring that hard constraints on the system outputs are satisfied.

Paper number 27:
Title: Integrated Sensing and Communications Over the Years: An Evolution Perspective
Authors: Di Zhang, Yuanhao Cui, Xiaowen Cao, Nanchi Su, Fan Liu, Xiaojun Jing, J. Andrew Zhang, Jie Xu, Christos Masouros, Dusit Niyato, Marco Di Renzo
Abstract: Integrated Sensing and Communications (ISAC) enables efficient spectrum utilization and reduces hardware costs for beyond 5G (B5G) and 6G networks, facilitating intelligent applications that require both high-performance communication and precise sensing capabilities. This survey provides a comprehensive review of the evolution of ISAC over the years. We examine the expansion of the spectrum across RF and optical ISAC, highlighting the role of advanced technologies, along with key challenges and synergies. We further discuss the advancements in network architecture from single-cell to multi-cell systems, emphasizing the integration of collaborative sensing and interference mitigation strategies. Moreover, we analyze the progress from single-modal to multi-modal sensing, with a focus on the integration of edge intelligence to enable real-time data processing, reduce latency, and enhance decision-making. Finally, we extensively review standardization efforts by 3GPP, IEEE, and ITU, examining the transition of ISAC-related technologies and their implications for the deployment of 6G networks.

Paper number 28:
Title: Interference Mitigation and Spectral Efficiency Enhancement in a Multi-BD Symbiotic Radio
Authors: Fikiri Salum Uledi, Muhammad Bilal Janjua, Çagrı Özgenç Etemoglu, Hüseyin Arslan
Abstract: This study presents a framework designed to mitigate direct-link interference (DLI) and inter-backscatter device interference (IBDI) in multi-backscatter orthogonal frequency division multiplexing (OFDM)-based symbiotic radio (SR) systems. The framework employs OFDM signal designs with strategic allocation of null subcarriers and incorporates two backscatter modulation techniques: on-off frequency shift keying (OFSK) and multiple frequency shift keying (MFSK) for symbiotic backscatter communication (SBC). Additionally, we propose Fully-Orthogonal and Semi-Orthogonal multiple access schemes to facilitate SBC alongside primary communication. The Fully-Orthogonal scheme maintains orthogonality between direct link and SBC signals, thereby ensuring interference-free SBC, albeit at a reduced spectral efficiency. In contrast, the Semi-Orthogonal schemes eliminate IBDI but permit partial DLI, striking a balance between reliability and spectral efficiency. To address the partial DLI inherent in Semi-Orthogonal schemes, successive interference cancellation (SIC) is employed at the receiver, enhancing SBC reliability. To tackle channel estimation challenges in SBC within the SR system, we implement non-coherent detection techniques at the receiver. The performance of the proposed system is evaluated based on average bit error rate (BER) and sum-rate metrics, demonstrating the effectiveness of our schemes. We provide analytical results for the system's detection performance under both proposed modulation techniques and multiple access schemes, which are subsequently validated through extensive simulations. These simulations indicate a notable error-rate reduction of up to $10^{-3}$ at $20$ dB with the Fully-Orthogonal scheme with MFSK.

Paper number 29:
Title: xApp Conflict Mitigation with Scheduler
Authors: Idris Cinemre, Toktam Mahmoodi
Abstract: Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven control but simultaneously introduces the challenge of managing pre-trained xApps that can produce conflicting actions. Although O-RAN specifications mandate offline training and validation to prevent untrained models, operational conflicts remain likely under dynamic, context-dependent conditions. This work proposes a scheduler-based conflict mitigation framework to address these challenges without requiring training xApps together or further xApp re-training. By examining an indirect conflict involving power and resource block allocation xApps and employing an Advantage Actor-Critic (A2C) approach to train both xApps and the scheduler, we illustrate that a straightforward A2C-based scheduler improves performance relative to independently deployed xApps and conflicting cases. Notably, augmenting the system with baseline xApps and allowing the scheduler to select from a broader pool yields the best results, underscoring the importance of adaptive scheduling mechanisms. These findings highlight the context-dependent nature of conflicts in automated network management, as two xApps may conflict under certain conditions but coexist under others. Consequently, the ability to dynamically update and adapt the scheduler to accommodate diverse operational intents is vital for future network deployments. By offering dynamic scheduling without re-training xApps, this framework advances practical conflict resolution solutions while supporting real-world scalability.

Paper number 30:
Title: Controlling a Social Network of Individuals with Coevolving Actions and Opinions
Authors: Roberta Raineri, Giacomo Como, Fabio Fagnani, Mengbin Ye, Lorenzo Zino
Abstract: In this paper, we consider a population of individuals who have actions and opinions, which coevolve, mutually influencing one another on a complex network structure. In particular, we formulate a control problem for this social network, in which we assume that we can inject into the network a committed minority -- a set of stubborn nodes -- with the objective of steering the population, initially at a consensus, to a different consensus state. Our study focuses on two main objectives: i) determining the conditions under which the committed minority succeeds in its goal, and ii) identifying the optimal placement for such a committed minority. After deriving general monotone convergence result for the controlled dynamics, we leverage these results to build a computationally-efficient algorithm to solve the first problem and an effective heuristics for the second problem, which we prove to be NP-complete. The proposed methodology is illustrated though academic examples, and demonstrated on a real-world case study.

Paper number 31:
Title: Leveraging Anatomical Priors for Automated Pancreas Segmentation on Abdominal CT
Authors: Anisa V. Prasad, Tejas Sudharshan Mathai, Pritam Mukherjee, Jianfei Liu, Ronald M. Summers
Abstract: An accurate segmentation of the pancreas on CT is crucial to identify pancreatic pathologies and extract imaging-based biomarkers. However, prior research on pancreas segmentation has primarily focused on modifying the segmentation model architecture or utilizing pre- and post-processing techniques. In this article, we investigate the utility of anatomical priors to enhance the segmentation performance of the pancreas. Two 3D full-resolution nnU-Net models were trained, one with 8 refined labels from the public PANORAMA dataset, and another that combined them with labels derived from the public TotalSegmentator (TS) tool. The addition of anatomical priors resulted in a 6\% increase in Dice score ($p < .001$) and a 36.5 mm decrease in Hausdorff distance for pancreas segmentation ($p < .001$). Moreover, the pancreas was always detected when anatomy priors were used, whereas there were 8 instances of failed detections without their use. The use of anatomy priors shows promise for pancreas segmentation and subsequent derivation of imaging biomarkers.

Paper number 32:
Title: Longitudinal Assessment of Lung Lesion Burden in CT
Authors: Tejas Sudharshan Mathai, Benjamin Hou, Ronald M. Summers
Abstract: In the U.S., lung cancer is the second major cause of death. Early detection of suspicious lung nodules is crucial for patient treatment planning, management, and improving outcomes. Many approaches for lung nodule segmentation and volumetric analysis have been proposed, but few have looked at longitudinal changes in total lung tumor burden. In this work, we trained two 3D models (nnUNet) with and without anatomical priors to automatically segment lung lesions and quantified total lesion burden for each patient. The 3D model without priors significantly outperformed ($p < .001$) the model trained with anatomy priors. For detecting clinically significant lesions $>$ 1cm, a precision of 71.3\%, sensitivity of 68.4\%, and F1-score of 69.8\% was achieved. For segmentation, a Dice score of 77.1 $\pm$ 20.3 and Hausdorff distance error of 11.7 $\pm$ 24.1 mm was obtained. The median lesion burden was 6.4 cc (IQR: 2.1, 18.1) and the median volume difference between manual and automated measurements was 0.02 cc (IQR: -2.8, 1.2). Agreements were also evaluated with linear regression and Bland-Altman plots. The proposed approach can produce a personalized evaluation of the total tumor burden for a patient and facilitate interval change tracking over time.

Paper number 33:
Title: Conformal Robust Beamforming via Generative Channel Models
Authors: Xin Su, Qiushuo Hou, Ruisi He, Osvaldo Simeone
Abstract: Traditional approaches to outage-constrained beamforming optimization rely on statistical assumptions about channel distributions and estimation errors. However, the resulting outage probability guarantees are only valid when these assumptions accurately reflect reality. This paper tackles the fundamental challenge of providing outage probability guarantees that remain robust regardless of specific channel or estimation error models. To achieve this, we propose a two-stage framework: (i) construction of a channel uncertainty set using a generative channel model combined with conformal prediction, and (ii) robust beamforming via the solution of a min-max optimization problem. The proposed method separates the modeling and optimization tasks, enabling principled uncertainty quantification and robust decision-making. Simulation results confirm the effectiveness and reliability of the framework in achieving model-agnostic outage guarantees.

Paper number 34:
Title: RNN-Transducer-based Losses for Speech Recognition on Noisy Targets
Authors: Vladimir Bataev
Abstract: Training speech recognition systems on noisy transcripts is a significant challenge in industrial pipelines, where datasets are enormous and ensuring accurate transcription for every instance is difficult. In this work, we introduce novel loss functions to mitigate the impact of transcription errors in RNN-Transducer models. Our Star-Transducer loss addresses deletion errors by incorporating "skip frame" transitions in the loss lattice, restoring over 90% of the system's performance compared to models trained with accurate transcripts. The Bypass-Transducer loss uses "skip token" transitions to tackle insertion errors, recovering more than 60% of the quality. Finally, the Target-Robust Transducer loss merges these approaches, offering robust performance against arbitrary errors. Experimental results demonstrate that the Target-Robust Transducer loss significantly improves RNN-T performance on noisy data by restoring over 70% of the quality compared to well-transcribed data.

Paper number 35:
Title: LCL Resonance Analysis and Damping in Single-Loop Grid-Forming Wind Turbines
Authors: Meng Chen, Yufei Xi, Frede Blaabjerg, Lin Cheng, Ioannis Lestas
Abstract: A dynamic phenomenon known as LCL resonance is often neglected when stability analysis is carried out for grid-forming (GFM) control schemes by wind turbine systems, due to its high frequency. This paper shows that this simplification is not always valid for single-loop (SL) control schemes. A detailed small-signal analysis reveals that reactive power (RAP) control significantly influences the resonant modes, which may be dominant in determining overall system stability, even if the resonant frequency is high. The underlying mechanism via which the LCL resonance may dominate the overall system stability is systematically analyzed. Furthermore, various RAP control strategies are compared to assess their different effects on resonant modes. An active damping (AD) strategy favorable for SL-GFM control is then designed. We also provide a comparison between SL-GFM and well-studied grid-following control schemes, highlighting quite different resonance features between them. Finally, case studies associated with a 14-bus, 5-machine IEEE test system are presented. These show that instability originates from the LCL resonance rather than low-frequency interactions among multiple machines, validating the theoretical analysis and the proposed AD strategy.

Paper number 36:
Title: BIA Transmission in Rate Splitting-based Optical Wireless Networks
Authors: Ahmad Adnan Qidan, Khulood Alazwary, Taisir El-Gorashi, Majid Safari, Harald Haas, Richard V. Penty, Ian H. White, Jaafar M. H. Elmirghani
Abstract: Optical wireless communication (OWC) has recently received massive interest as a new technology that can support the enormous data traffic increasing on daily basis. In particular, laser-based OWC networks can provide terabits per second (Tbps) aggregate data rates. However, the emerging OWC networks require a high number of optical access points (APs), each AP corresponding to an optical cell, to provide uniform coverage for multiple users. Therefore, inter-cell interference (ICI) and multi-user interference (MUI) are crucial issues that must be managed efficiently to provide high spectral efficiency. In radio frequency (RF) networks, rate splitting (RS) is proposed as a transmission scheme to serve multiple users simultaneously following a certain strategy. It was shown that RS provides high data rates compared to orthogonal and non-orthogonal interference management schemes. Considering the high density of OWC networks, the application of RS within each optical cell might not be practical due to severe ICI. In this paper, a new strategy is derived referred to as blind interference alignment-rate splitting (BIA-RS) to fully coordinate the transmission among the optical APs, while determining the precoding matrices of multiple groups of users formed beforehand. Therefore, RS can be implemented within each group to manage MUI. The proposed BIA-RS scheme requires two layers of power allocation to achieve high performance. Given that, a max-min fractional optimization problem is formulated to optimally distribute the power budget among the groups and the messages intended to the users of each group. Finally, a power allocation algorithm is designed with multiple Lagrangian multipliers to provide practical and sub-optimal solutions. The results show the high performance of the proposed scheme compared to other counterpart schemes.

Paper number 37:
Title: Data-driven Optimization and Transfer Learning for Cellular Network Antenna Configurations
Authors: Mohamed Benzaghta, Giovanni Geraci, David López-Pérez, Alvaro Valcarce
Abstract: We propose a data-driven approach for large-scale cellular network optimization, using a production cellular network in London as a case study and employing Sionna ray tracing for site-specific channel propagation modeling. We optimize base station antenna tilts and half-power beamwidths, resulting in more than double the 10\%-worst user rates compared to a 3GPP baseline. In scenarios involving aerial users, we identify configurations that increase their median rates fivefold without compromising ground user performance. We further demonstrate the efficacy of model generalization through transfer learning, leveraging available data from a scenario source to predict the optimal solution for a scenario target within a similar number of iterations, without requiring a new initial dataset, and with a negligible performance loss.

Paper number 38:
Title: Data-Driven Design of 3GPP Handover Parameters with Bayesian Optimization and Transfer Learning
Authors: Mohamed Benzaghta, Sahar Ammar, David López-Pérez, Basem Shihada, Giovanni Geraci
Abstract: Mobility management in dense cellular networks is challenging due to varying user speeds and deployment conditions. Traditional 3GPP handover (HO) schemes, relying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to balance radio link failures (RLFs) and ping-pongs. We propose a data-driven HO optimization framework based on high-dimensional Bayesian optimization (HD-BO) and enhanced with transfer learning to reduce training time and improve generalization across different user speeds. Evaluations on a real-world deployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while transfer learning enables rapid adaptation without loss in performance. This highlights the potential of data-driven, site-specific mobility management in large-scale networks.

Paper number 39:
Title: Cellular Network Design for UAV Corridors via Data-driven High-dimensional Bayesian Optimization
Authors: Mohamed Benzaghta, Giovanni Geraci, David López-Pérez, Alvaro Valcarce
Abstract: We address the challenge of designing cellular networks for uncrewed aerial vehicles (UAVs) corridors through a novel data-driven approach. We assess multiple state-of-the-art high-dimensional Bayesian optimization (HD-BO) techniques to jointly optimize the cell antenna tilts and half-power beamwidth (HPBW). We find that some of these approaches achieve over 20dB gains in median SINR along UAV corridors, with negligible degradation to ground user performance. Furthermore, we explore the HD-BO's capabilities in terms of model generalization via transfer learning, where data from a previously observed scenario source is leveraged to predict the optimal solution for a new scenario target. We provide examples of scenarios where such transfer learning is successful and others where it fails. Moreover, we demonstrate that HD-BO enables multi-objective optimization, identifying optimal design trade-offs between data rates on the ground versus UAV coverage reliability. We observe that aiming to provide UAV coverage across the entire sky can lower the rates for ground users compared to setups specifically optimized for UAV corridors. Finally, we validate our approach through a case study in a real-world cellular network, where HD-BO identifies optimal and non-obvious antenna configurations that result in more than double the rates along 3D UAV corridors with negligible ground performance loss.

Paper number 40:
Title: A Cascaded Architecture for Extractive Summarization of Multimedia Content via Audio-to-Text Alignment
Authors: Tanzir Hossain, Ar-Rafi Islam, Md. Sabbir Hossain, Annajiat Alim Rasel
Abstract: This study presents a cascaded architecture for extractive summarization of multimedia content via audio-to-text alignment. The proposed framework addresses the challenge of extracting key insights from multimedia sources like YouTube videos. It integrates audio-to-text conversion using Microsoft Azure Speech with advanced extractive summarization models, including Whisper, Pegasus, and Facebook BART XSum. The system employs tools such as Pytube, Pydub, and SpeechRecognition for content retrieval, audio extraction, and transcription. Linguistic analysis is enhanced through named entity recognition and semantic role labeling. Evaluation using ROUGE and F1 scores demonstrates that the cascaded architecture outperforms conventional summarization methods, despite challenges like transcription errors. Future improvements may include model fine-tuning and real-time processing. This study contributes to multimedia summarization by improving information retrieval, accessibility, and user experience.

Paper number 41:
Title: Efficient Simulation of Singularly Perturbed Systems Using a Stabilized Multirate Explicit Scheme
Authors: Yibo Shi, Cristian R. Rojas
Abstract: Singularly perturbed systems (SPSs) are prevalent in engineering applications, where numerically solving their initial value problems (IVPs) is challenging due to stiffness arising from multiple time scales. Classical explicit methods require impractically small time steps for stability, while implicit methods developed for SPSs are computationally intensive and less efficient for strongly nonlinear systems. This paper introduces a Stabilized Multirate Explicit Scheme (SMES) that stabilizes classical explicit methods without the need for small time steps or implicit formulations. By employing a multirate approach with variable time steps, SMES allows the fast dynamics to rapidly converge to their equilibrium manifold while slow dynamics evolve with larger steps. Analysis shows that SMES achieves numerical stability with significantly reduced computational effort and controlled error. Its effectiveness is illustrated with a numerical example.

Paper number 42:
Title: User-Centered Insights into Assistive Navigation Technologies for Individuals with Visual Impairment
Authors: Iman Soltani, Johnaton Schofield, Mehran Madani, Daniel Kish, Parisa Emami-Naeini
Abstract: Navigational challenges significantly impact the independence and mobility of Individuals with Visual Impairment (IVI). While numerous assistive technologies exist, their adoption remains limited due to usability challenges, financial constraints, and a lack of alignment with user needs. This study employs a mixed-methods approach, combining structured surveys and virtual workshops with 19 IVI to investigate their experiences, needs, and preferences regarding assistive technologies for navigation and daily living. The survey results provide insights into participants technological competence, preferences for assistive devices, and willingness to adopt new solutions. In parallel, workshop discussions offer qualitative perspectives on key navigation challenges, including difficulties in detecting overhead obstacles, navigating environments with complex layout, and the limitations of existing technologies. Findings highlight the need for assistive devices that integrate both navigational guidance and high-level spatial awareness, allowing users to build mental maps of their surroundings. Additionally, multimodal feedback, combining audio, haptic, and tactile cues, emerges as a crucial feature to accommodate diverse user preferences and environmental conditions. The study also underscores financial and training barriers that limit access to advanced assistive technologies. Based on these insights, we recommend the development of customizable, user-friendly, and most importantly affordable navigation aids that align with the daily needs of IVI. The findings from this study provide guidance for technology developers, researchers, and policymakers working toward more inclusive and effective assistive solutions.

Paper number 43:
Title: DBaS-Log-MPPI: Efficient and Safe Trajectory Optimization via Barrier States
Authors: Fanxin Wang, Haolong Jiang, Chuyuan Tao, Wenbin Wan, Yikun Cheng
Abstract: Optimizing trajectory costs for nonlinear control systems remains a significant challenge. Model Predictive Control (MPC), particularly sampling-based approaches such as the Model Predictive Path Integral (MPPI) method, has recently demonstrated considerable success by leveraging parallel computing to efficiently evaluate numerous trajectories. However, MPPI often struggles to balance safe navigation in constrained environments with effective exploration in open spaces, leading to infeasibility in cluttered conditions. To address these limitations, we propose DBaS-Log-MPPI, a novel algorithm that integrates Discrete Barrier States (DBaS) to ensure safety while enabling adaptive exploration with enhanced feasibility. Our method is efficiently validated through three simulation missions and one real-world experiment, involving a 2D quadrotor and a ground vehicle navigating through cluttered obstacles. We demonstrate that our algorithm surpasses both Vanilla MPPI and Log-MPPI, achieving higher success rates, lower tracking errors, and a conservative average speed.

Paper number 44:
Title: Solving Power System Problems using Adiabatic Quantum Computing
Authors: Zeynab Kaseb, Matthias Moller, Peter Palensky, Pedro P. Vergara
Abstract: This letter proposes a novel combinatorial optimization framework that reformulates existing power system problems into a format executable on quantum annealers. The proposed framework accommodates both normal and complex numbers and enables efficient handling of large-scale problems, thus ensuring broad applicability across power system problems. As a proof of concept, we demonstrate its applicability in two classical problems: (i) power system parameter identification, where we estimate the admittance matrix given voltage and current measurements, and (ii) power flow analysis, where we reformulate the nonlinear equations governing active and reactive power balance. The results show that the proposed framework effectively and efficiently solves both linear and nonlinear power system problems, and thus offers significant advantages in scenarios where traditional solvers face challenges, such as ill-conditioned systems and fault conditions.

Paper number 45:
Title: Holistic Fusion: Task- and Setup-Agnostic Robot Localization and State Estimation with Factor Graphs
Authors: Julian Nubert, Turcan Tuna, Jonas Frey, Cesar Cadena, Katherine J. Kuchenbecker, Shehryar Khattak, Marco Hutter
Abstract: Seamless operation of mobile robots in challenging environments requires low-latency local motion estimation (e.g., dynamic maneuvers) and accurate global localization (e.g., wayfinding). While most existing sensor-fusion approaches are designed for specific scenarios, this work introduces a flexible open-source solution for task- and setup-agnostic multimodal sensor fusion that is distinguished by its generality and usability. Holistic Fusion formulates sensor fusion as a combined estimation problem of i) the local and global robot state and ii) a (theoretically unlimited) number of dynamic context variables, including automatic alignment of reference frames; this formulation fits countless real-world applications without any conceptual modifications. The proposed factor-graph solution enables the direct fusion of an arbitrary number of absolute, local, and landmark measurements expressed with respect to different reference frames by explicitly including them as states in the optimization and modeling their evolution as random walks. Moreover, local smoothness and consistency receive particular attention to prevent jumps in the robot state belief. HF enables low-latency and smooth online state estimation on typical robot hardware while simultaneously providing low-drift global localization at the IMU measurement rate. The efficacy of this released framework is demonstrated in five real-world scenarios on three robotic platforms, each with distinct task requirements.

Paper number 46:
Title: NAPER: Fault Protection for Real-Time Resource-Constrained Deep Neural Networks
Authors: Rian Adam Rajagede, Muhammad Husni Santriaji, Muhammad Arya Fikriansyah, Hilal Hudan Nuha, Yanjie Fu, Yan Solihin
Abstract: Fault tolerance in Deep Neural Networks (DNNs) deployed on resource-constrained systems presents unique challenges for high-accuracy applications with strict timing requirements. Memory bit-flips can severely degrade DNN accuracy, while traditional protection approaches like Triple Modular Redundancy (TMR) often sacrifice accuracy to maintain reliability, creating a three-way dilemma between reliability, accuracy, and timeliness. We introduce NAPER, a novel protection approach that addresses this challenge through ensemble learning. Unlike conventional redundancy methods, NAPER employs heterogeneous model redundancy, where diverse models collectively achieve higher accuracy than any individual model. This is complemented by an efficient fault detection mechanism and a real-time scheduler that prioritizes meeting deadlines by intelligently scheduling recovery operations without interrupting inference. Our evaluations demonstrate NAPER's superiority: 40% faster inference in both normal and fault conditions, maintained accuracy 4.2% higher than TMR-based strategies, and guaranteed uninterrupted operation even during fault recovery. NAPER effectively balances the competing demands of accuracy, reliability, and timeliness in real-time DNN applications

Paper number 47:
Title: Setup-Invariant Augmented Reality for Teaching by Demonstration with Surgical Robots
Authors: Alexandre Banks, Richard Cook, Septimiu E. Salcudean
Abstract: Augmented reality (AR) is an effective tool in robotic surgery education as it combines exploratory learning with three-dimensional guidance. However, existing AR systems require expert supervision and do not account for differences in the mentor and mentee robot configurations. To enable novices to train outside the operating room while receiving expert-informed guidance, we present dV-STEAR: an open-source system that plays back task-aligned expert demonstrations without assuming identical setup joint positions between expert and novice. Pose estimation was rigorously quantified, showing a registration error of 3.86 (SD=2.01)mm. In a user study (N=24), dV-STEAR significantly improved novice performance on tasks from the Fundamentals of Laparoscopic Surgery. In a single-handed ring-over-wire task, dV-STEAR increased completion speed (p=0.03) and reduced collision time (p=0.01) compared to dry-lab training alone. During a pick-and-place task, it improved success rates (p=0.004). Across both tasks, participants using dV-STEAR exhibited significantly more balanced hand use and reported lower frustration levels. This work presents a novel educational tool implemented on the da Vinci Research Kit, demonstrates its effectiveness in teaching novices, and builds the foundation for further AR integration into robot-assisted surgery.

Paper number 48:
Title: Robust Capacity Expansion Modelling for Renewable Energy Systems under Weather and Demand Uncertainty
Authors: Sebastian Kebrich, Felix Engelhardt, David Franzmann, Christina Büsing, Jochen Linßen, Heidi Heinrichs
Abstract: Future greenhouse gas neutral energy systems will be dominated by variable renewable energy technologies. However, renewable electricity generation from wind and solar technologies, as well as electricity demand, varies with the weather. This work addresses the problem of determining optimal capacities for renewable technologies in energy systems that ensure sufficient electricity supply when dealing with multi-year time-series data. An iterative algorithm is proposed that starts by optimising an arbitrary starting time-series, followed by adding additional constraints and reoptimising the modified optimisation problem until sufficient energy supply is provided for all time--series, i.e. the solution is robust to weather and demand variations. This is evaluated in a computational study on a German energy system this http URL results show that the iterative algorithm finds robust solutions for an increase of 2-2.5% in total annual cost for a simplified model in gurobipy and 2.9% for a model built in the model framework this http URL. Testing the feasibility for non robust solutions showed that supply gaps occurred in at least some of the remaining years. Based on the results of this work, ensuring feasibility within an energy system model for multiple time-series boils down to two factors: ensuring sufficient back-up capacity to overcome periods of high demand combined with low electricity generation from wind and photovoltaic, and enforcing sufficient total annual electricity generation. Our proposed open source iterative algorithm is able to ensure this. For general modelling, it is recommended to check for systematic effects of different years' time--series on energy system models especially for wind, but also for photovoltaics, include dark lull and cold period effects on generation and demand in time--series, and assess the feasibility of energy system models using different time-series.

Paper number 49:
Title: Controllable Automatic Foley Artist
Authors: Roi Benita, Michael Finkelson, Tavi Halperin, Gleb Sterkin, Yossi Adi
Abstract: Foley is a key element in video production, refers to the process of adding an audio signal to a silent video while ensuring semantic and temporal alignment. In recent years, the rise of personalized content creation and advancements in automatic video-to-audio models have increased the demand for greater user control in the process. One possible approach is to incorporate text to guide audio generation. While supported by existing methods, challenges remain in ensuring compatibility between modalities, particularly when the text introduces additional information or contradicts the sounds naturally inferred from the visuals. In this work, we introduce CAFA (Controllable Automatic Foley Artist) a video-and-text-to-audio model that generates semantically and temporally aligned audio for a given video, guided by text input. CAFA is built upon a text-to-audio model and integrates video information through a modality adapter mechanism. By incorporating text, users can refine semantic details and introduce creative variations, guiding the audio synthesis beyond the expected video contextual cues. Experiments show that besides its superior quality in terms of semantic alignment and audio-visual synchronization the proposed method enable high textual controllability as demonstrated in subjective and objective evaluations.

Paper number 50:
Title: Analog Computing with Microwave Networks
Authors: Matteo Nerini, Bruno Clerckx
Abstract: Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this paper, we investigate analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing for communications. We model a MiLAC as a multiport microwave network with tunable impedance components, which enables the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator, widely used in multiple-input multiple-output (MIMO) communications beamforming and detection, with remarkably low computational complexity, unachievable through digital computing. Specifically, the LMMSE estimator can be computed with complexity growing with the square of its input size, rather than the cube, with revolutionary applications to gigantic MIMO beamforming and detection.

Paper number 51:
Title: Maximizing Battery Storage Profits via High-Frequency Intraday Trading
Authors: David Schaurecker, David Wozabal, Nils Löhndorf, Thorsten Staake
Abstract: Maximizing revenue for grid-scale battery energy storage systems in continuous intraday electricity markets requires strategies that are able to seize trading opportunities as soon as new information arrives. This paper introduces and evaluates an automated high-frequency trading strategy for battery energy storage systems trading on the intraday market for power while explicitly considering the dynamics of the limit order book, market rules, and technical parameters. The standard rolling intrinsic strategy is adapted for continuous intraday electricity markets and solved using a dynamic programming approximation that is two to three orders of magnitude faster than an exact mixed-integer linear programming solution. A detailed backtest over a full year of German order book data demonstrates that the proposed dynamic programming formulation does not reduce trading profits and enables the policy to react to every relevant order book update, enabling realistic rapid backtesting. Our results show the significant revenue potential of high-frequency trading: our policy earns 58% more than when re-optimizing only once every hour and 14% more than when re-optimizing once per minute, highlighting that profits critically depend on trading speed. Furthermore, we leverage the speed of our algorithm to train a parametric extension of the rolling intrinsic, increasing yearly revenue by 8.4% out of sample.

Paper number 52:
Title: Parametric Reachable Sets Via Controlled Dynamical Embeddings
Authors: Akash Harapanahalli, Samuel Coogan
Abstract: In this work, we propose a new framework for reachable set computation through continuous evolution of a set of parameters and offsets which define a parametope, through the intersection of constraints. This results in a dynamical approach towards nonlinear reachability analysis: a single trajectory of an embedding system provides a parametope reachable set for the original system, and uncertainties are accounted for through continuous parameter evolution. This is dual to most existing computational strategies, which define sets through some combination of generator vectors, and usually discretize the system dynamics. We show how, under some regularity assumptions of the dynamics and the set considered, any desired parameter evolution can be accommodated as long as the offset dynamics are set accordingly, providing a virtual "control input" for reachable set computation. In a special case of the theory, we demonstrate how closing the loop for the parameter dynamics using the adjoint of the linearization results in a desirable first-order cancellation of the original system dynamics. Using interval arithmetic in JAX, we demonstrate the efficiency and utility of reachable parametope computation through two numerical examples.

Paper number 53:
Title: TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling
Authors: Liang-Hsuan Tseng, Yi-Chang Chen, Kuan-Yi Lee, Da-Shan Shiu, Hung-yi Lee
Abstract: Large Language Models (LLMs) excel in text-based natural language processing tasks but remain constrained by their reliance on textual inputs and outputs. To enable more natural human-LLM interaction, recent progress have focused on deriving a spoken language model (SLM) that can not only listen but also generate speech. To achieve this, a promising direction is to conduct speech-text joint modeling. However, recent SLM still lag behind text LLM due to the modality mismatch. One significant mismatch can be the sequence lengths between speech and text tokens. To address this, we introduce Text-Aligned Speech Tokenization and Embedding (TASTE), a method that directly addresses the modality gap by aligning speech token with the corresponding text transcription during the tokenization stage. We propose a method that can achieve this through the special aggregation mechanism and with speech reconstruction as the training objective. We conduct extensive experiments and show that TASTE can preserve essential paralinguistic information while dramatically reducing the token sequence length. Furthermore, by leveraging TASTE, we can adapt text-based LLMs into effective SLMs with parameter-efficient fine-tuning techniques such as Low-Rank Adaptation (LoRA). Experimental results on benchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based SLMs perform similarly to previous full-finetuning methods. To our knowledge, TASTE is the first end-to-end approach that utilizes a reconstruction objective to automatically learn a text-aligned speech tokenization and embedding suitable for spoken language modeling. Our demo, code, and models are publicly available at this https URL.

Paper number 54:
Title: PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems
Authors: Amir Arslan Haghrah, Sehraneh Ghaemi
Abstract: Fuzzy logic is an accepted and well-developed approach for constructing verbal models. Fuzzy based methods are getting more popular, while the engineers deal with more daily life tasks. This paper presents a new Python toolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing software tools is an important issue for facilitating the practical use of theoretical results. There are limited tools for implementing IT2FLSs in Python. The developed PyIT2FLS is providing a set of tools for fast and easy modeling of fuzzy systems. This paper includes a brief description of how developed toolkit can be used. Also, three examples are given showing the usage of the developed toolkit for simulating IT2FLSs. First, a simple rule-based system is developed and it's codes are presented in the paper. The second example is the prediction of the Mackey-Glass chaotic time series using IT2FLS. In this example, the Particle Swarm Optimization (PSO) algorithm is used for determining system parameters while minimizing the mean square error. In the last example, an IT2FPID is designed and used for controlling a linear time-delay system. The code for the examples are available on toolkit's GitHub page: this https URL. The simulations and their results confirm the ability of the developed toolkit to be used in a wide range of the applications.

Paper number 55:
Title: Bi-Linear Homogeneity Enforced Calibration for Pipelined ADCs
Authors: Matthias Wagner, Oliver Lang, Esmaeil Kavousi Ghafi, Arianit Preniqi, Andreas Schwarz, Mario Huemer
Abstract: Pipelined analog-to-digital converters (ADCs) are key enablers in many state-of-the-art signal processing systems with high sampling rates. In addition to high sampling rates, such systems often demand a high linearity. To meet these challenging linearity requirements, ADC calibration techniques were heavily investigated throughout the past decades. One limitation in ADC calibration is the need for a precisely known test signal. In our previous work, we proposed the homogeneity enforced calibration (HEC) approach, which circumvents this need by consecutively feeding a test signal and a scaled version of it into the ADC. The calibration itself is performed using only the corresponding output samples, such that the test signal can remain unknown. On the downside, the HEC approach requires to accurately scale the test signal, impeding an on-chip implementation. In this work, we provide a thorough analysis of the HEC approach, including limitations such as the effects of an inaccurately scaled test signal. Furthermore, the bi-linear homogeneity enforced calibration (BL-HEC) approach is introduced and suggested to account for an inaccurate scaling and, therefore, to facilitate an on-chip implementation. In addition, a comprehensive stability analysis of the BL-HEC approach is carried out. Finally, we verify our concept with behavioral Matlab simulations and measurements conducted on 24 integrated ADCs.

Paper number 56:
Title: A Crosstalk-Aware Timing Prediction Method in Routing
Authors: Leilei Jin, Jiajie Xu, Wenjie Fu, Hao Yan, Longxing Shi
Abstract: With shrinking interconnect spacing in advanced technology nodes, existing timing predictions become less precise due to the challenging quantification of crosstalk-induced delay. During the routing, the crosstalk effect is typically modeled by predicting coupling capacitance with congestion information. However, the timing estimation tends to be overly pessimistic, as the crosstalk-induced delay depends not only on the coupling capacitance but also on the signal arrival time. This work presents a crosstalk-aware timing estimation method using a two-step machine learning approach. Interconnects that are physically adjacent and overlap in signal timing windows are filtered first. Crosstalk delay is predicted by integrating physical topology and timing features without relying on post-routing results and the parasitic extraction. Experimental results show a match rate of over 99% for identifying crosstalk nets compared to the commercial tool on the OpenCores benchmarks, with prediction results being more accurate than those of other state-of-the-art methods.

Paper number 57:
Title: Assessing the risk of recurrence in early-stage breast cancer through H&E stained whole slide images
Authors: Geongyu Lee, Joonho Lee, Tae-Yeong Kwak, Sun Woo Kim, Youngmee Kwon, Chungyeul Kim, Hyeyoon Chang
Abstract: Accurate prediction of the likelihood of recurrence is important in the selection of postoperative treatment for patients with early-stage breast cancer. In this study, we investigated whether deep learning algorithms can predict patients' risk of recurrence by analyzing the pathology images of their cancer this http URL analyzed 125 hematoxylin and eosin-stained whole slide images (WSIs) from 125 patients across two institutions (National Cancer Center and Korea University Medical Center Guro Hospital) to predict breast cancer recurrence risk using deep learning. Sensitivity reached 0.857, 0.746, and 0.529 for low, intermediate, and high-risk categories, respectively, with specificity of 0.816, 0.803, and 0.972, and a Pearson correlation of 0.61 with histological grade. Class activation maps highlighted features like tubule formation and mitotic rate, suggesting a cost-effective approach to risk stratification, pending broader validation. These findings suggest that deep learning models trained exclusively on hematoxylin and eosin stained whole slide images can approximate genomic assay results, offering a cost-effective and scalable tool for breast cancer recurrence risk assessment. However, further validation using larger and more balanced datasets is needed to confirm the clinical applicability of our approach.

Paper number 58:
Title: Performance Analysis and Low-Complexity Beamforming Design for Near-Field Physical Layer Security
Authors: Yunpu Zhang, Yuan Fang, Changsheng You, Ying-Jun Angela Zhang, Hing Cheung So
Abstract: Extremely large-scale arrays (XL-arrays) have emerged as a key enabler in achieving the unprecedented performance requirements of future wireless networks, leading to a significant increase in the range of the near-field region. This transition necessitates the spherical wavefront model for characterizing the wireless propagation rather than the far-field planar counterpart, thereby introducing extra degrees of freedom (DoFs) to wireless system design. In this paper, we explore the beam focusing-based physical layer security (PLS) in the near field, where multiple legitimate users and one eavesdropper are situated in the near-field region of the XL-array base station (BS). First, we consider a special case with one legitimate user and one eavesdropper to shed useful insights into near-field PLS. In particular, it is shown that 1) Artificial noise (AN) is crucial to near-field security provisioning, transforming an insecure system to a secure one; 2) AN can yield numerous security gains, which considerably enhances PLS in the near field as compared to the case without AN taken into account. Next, for the general case with multiple legitimate users, we propose an efficient low-complexity approach to design the beamforming with AN to guarantee near-field secure transmission. Specifically, the low-complexity approach is conceived starting by introducing the concept of interference domain to capture the inter-user interference level, followed by a three-step identification framework for designing the beamforming. Finally, numerical results reveal that 1) the PLS enhancement in the near field is pronounced thanks to the additional spatial DoFs; 2) the proposed approach can achieve close performance to that of the computationally-extensive conventional approach yet with a significantly lower computational complexity.

Paper number 59:
Title: Robust 3D Multi-Source Localization with a Movable Antenna Array via Sparse Signal Processing
Authors: Amir Mansourian, Alireza Fadakar, Saeed Akhavan, Behrouz Maham
Abstract: Accurately localizing multiple sources is a critical task with various applications in wireless communications, such as emergency services, including natural post-disaster search and rescue operations. However, scenarios where the receiver is moving have not been sufficiently addressed in recent studies. This paper tackles the angle of arrival (AOA) 3D-localization problem for multiple sparse signal sources with a moving receiver, which has a limited number of antennas that may be outnumbered by the sources. First, an energy detector algorithm is proposed to leverage signal sparsity for eliminating noisy samples. Subsequently, an iterative algorithm is developed to refine and estimate the AOAs accurately, initialized with previously estimated source locations and coarse elevation and azimuth AOAs obtained via the two-dimensional multiple signal classification (2D-MUSIC) method. To this end, we introduce a sparse recovery algorithm to exploit signal sparsity, followed by a phase smoothing algorithm to refine the estimates. The K-SVD algorithm is then applied to the smoothed output to accurately determine the elevation and azimuth AOAs of the sources. For localization, a new multi-source 3D-localization algorithm is proposed to estimate source positions using the refined AOA estimates over a sequence of time windows. Extensive simulations are carried out to demonstrate the effectiveness of the proposed framework.

Paper number 60:
Title: A Novel Massive Random Access in Cell-Free Massive MIMO Systems for High-Speed Mobility with OTFS Modulation
Authors: Yanfeng Hu, Dongming Wang, Xinjiang Xia, Jiamin Li, Pengcheng Zhu, Xiaohu You
Abstract: In the research of next-generation wireless communication technologies, orthogonal time frequency space (OTFS) modulation is emerging as a promising technique for high-speed mobile environments due to its superior efficiency and robustness in doubly selective channels. Additionally, the cell-free architecture, which eliminates the issues associated with cell boundaries, offers broader coverage for radio access networks. By combining cell-free network architecture with OTFS modulation, the system may meet the demands of massive random access required by machine-type communication devices in high-speed scenarios. This paper explores a massive random access scheme based on OTFS modulation within a cell-free architecture. A transceiver model for uplink OTFS signals involving multiple access points (APs) is developed, where channel estimation with fractional channel parameters is approximated as a block sparse matrix recovery problem. Building on existing superimposed and embedded preamble schemes, a hybrid preamble scheme is proposed. This scheme leverages superimposed and embedded preambles to respectively achieve rough and accurate active user equipment (UEs) detection (AUD), as well as precise channel estimation, under the condition of supporting a large number of access UEs. Moreover, this study introduces a generalized approximate message passing and pattern coupling sparse Bayesian learning with Laplacian prior (GAMP-PCSBL-La) algorithm, which effectively captures block sparse features after discrete cosine transform (DCT), delivering precise estimation results with reduced computational complexity. Simulation results demonstrate that the proposed scheme is effective and provides superior performance compared to other existing schemes.

Paper number 61:
Title: A Deep Generative Learning Approach for Two-stage Adaptive Robust Optimization
Authors: Aron Brenner, Rahman Khorramfar, Jennifer Sun, Saurabh Amin
Abstract: Two-stage adaptive robust optimization (ARO) is a powerful approach for planning under uncertainty, balancing first-stage decisions with recourse decisions made after uncertainty is realized. To account for uncertainty, modelers typically define a simple uncertainty set over which potential outcomes are considered. However, classical methods for defining these sets unintentionally capture a wide range of unrealistic outcomes, resulting in overly-conservative and costly planning in anticipation of unlikely contingencies. In this work, we introduce AGRO, a solution algorithm that performs adversarial generation for two-stage adaptive robust optimization using a variational autoencoder. AGRO generates high-dimensional contingencies that are simultaneously adversarial and realistic, improving the robustness of first-stage decisions at a lower planning cost than standard methods. To ensure generated contingencies lie in high-density regions of the uncertainty distribution, AGRO defines a tight uncertainty set as the image of "latent" uncertainty sets under the VAE decoding transformation. Projected gradient ascent is then used to maximize recourse costs over the latent uncertainty sets by leveraging differentiable optimization methods. We demonstrate the cost-efficiency of AGRO by applying it to both a synthetic production-distribution problem and a real-world power system expansion setting. We show that AGRO outperforms the standard column-and-constraint algorithm by up to 1.8% in production-distribution planning and up to 11.6% in power system expansion.

Paper number 62:
Title: Distribution Grids May Be a Barrier To Residential Electrification
Authors: Priyadarshan, Constance Crozier, Kyri Baker, Kevin Kircher
Abstract: Replacing fossil-fueled appliances and vehicles with electric alternatives can reduce greenhouse gas emissions and air pollution in many settings. However, residential electrification can also raise electricity demand beyond the safe limits of electrical infrastructure. This can increase the risk of blackouts or require grid reinforcement that is often slow and expensive. Here, we estimate the physical and economic impacts on distribution grids of electrifying all housing and personal vehicles in each county of the lower 48 United States. We find that space heating is the main driver of grid impacts, with the coldest regions seeing demand peaks up to five times higher than today's peaks. Accommodating electrification of all housing and personal vehicles is estimated to require 600 GW of distribution grid reinforcement nationally, at a cost of \$350 to \$790 billion, or \$2,800 to \$6,400 per household (95% confidence intervals). However, demand-side management could eliminate three-quarters of grid reinforcement costs.

Paper number 63:
Title: Inverter Output Impedance Estimation in Power Networks: A Variable Direction Forgetting Recursive-Least-Square Algorithm Based Approach
Authors: Jaesang Park, Alireza Askarian, Srinivasa Salapaka
Abstract: As inverter-based loads and energy sources become increasingly prevalent, accurate estimation of line impedance between inverters and the grid is essential for optimizing performance and enhancing control strategies. This paper presents a non-invasive method for estimating output-line impedance using measurements local to the inverter. It provides a specific method for signal conditioning of signals measured at the inverter, which makes the measured data better suited to estimation algorithms. An algorithm based on the Variable Direction Forgetting Recursive Least Squares (VDF-RLS) method is introduced, which leverages these conditioned signals for precise impedance estimation. The signal conditioning process transforms measurements into the direct-quadrature (dq) coordinate frame, where the rotating frame frequency is determined to facilitate a simpler and more accurate estimation. This frequency is implemented using a secondary Phase-Locked Loop (PLL) to attenuate grid voltage measurement variations. By isolating the variation-sensitive q-axis and relying solely on the less sensitive d-axis, the method further minimizes the impact of variations. The VDF-RLS estimation method achieves rapid adaptation while ensuring stability in the absence of persistent excitation by selectively discarding outdated data during updates. Proposed conditioning and estimation methods are non-invasive; estimations are solely done using measured outputs, and no signal is injected into the power network. Simulation results demonstrate a significant improvement in impedance estimation stability, particularly in low-excitation conditions, where the VDF-RLS method achieves more than three time lower error compared to existing approaches such as constant forgetting RLS and the Kalman filter.

Paper number 64:
Title: Control Node Placement and Structural Controllability of Water Quality Dynamics in Drinking Networks
Authors: Salma M. Elsherif, Ahmad F. Taha
Abstract: Chlorine, the most widely used disinfectant, needs to be adequately distributed in water distribution networks (WDNs) to maintain consistent residual levels and ensure water safety. This is performed through control node injections at the treatment plant via booster stations scattered in WDNs. While previous studies have applied various optimization metrics for booster station placement, many have failed to consider the coverage of the station injections and the dynamic nature of WDNs. In particular, variations in hydraulics and demand significantly impact the reachability and efficacy of chlorine injections which then impact optimal placement of booster stations. This study introduces a novel formulation that combines control- and graph-theoretic approaches to solve the booster station placement problem. Unlike traditional methods, our approach emphasizes maximizing the system's ability to control disinfectant levels with minimal energy, taking into account the time-varying hydraulic profiles that lead to different optimal station placements. We propose a simple weighting technique to determine the placements by assessing the structural controllability of each configuration, based on the network's topology and independent of specific parameters like decay rates or pipe roughness. This method ensures effective chlorine coverage across the network. Our approach is validated on different networks, demonstrating its operational effectiveness, scalability, and practicality.

Paper number 65:
Title: Zero-Order Control Barrier Functions for Sampled-Data Systems with State and Input Dependent Safety Constraints
Authors: Xiao Tan, Ersin Das, Aaron D. Ames, Joel W. Burdick
Abstract: We propose a novel zero-order control barrier function (ZOCBF) for sampled-data systems to ensure system safety. Our formulation generalizes conventional control barrier functions and straightforwardly handles safety constraints with high-relative degrees or those that explicitly depend on both system states and inputs. The proposed ZOCBF condition does not require any differentiation operation. Instead, it involves computing the difference of the ZOCBF values at two consecutive sampling instants. We propose three numerical approaches to enforce the ZOCBF condition, tailored to different problem settings and available computational resources. We demonstrate the effectiveness of our approach through a collision avoidance example and a rollover prevention example on uneven terrains.

Paper number 66:
Title: Dissipative iFIR filters for data-driven design
Authors: Zixing Wang, Yi Zhang, Fulvio Forni
Abstract: We tackle the problem of providing closed-loop stability guarantees with a scalable data-driven design. We combine virtual reference feedback tuning with dissipativity constraints on the controller for closed-loop stability. The constraints are formulated as a set of linear inequalities in the frequency domain. This leads to a convex problem that is scalable with respect to the length of the data and the complexity of the controller. An extension of virtual reference feedback tuning to include disturbance dynamics is also discussed. The proposed data-driven control design is illustrated by a soft gripper impedance control example.

Paper number 67:
Title: Hilbert Transform on Graphs: Let There Be Phase
Authors: Chun Hei Michael Chan, Alexandre Cionca, Dimitri Van De Ville
Abstract: In the past years, many signal processing operations have been successfully adapted to the graph setting. One elegant and effective approach is to exploit the eigendecomposition of a graph shift operator (GSO), such as the adjacency or Laplacian operator, to define a graph Fourier transform when projecting graph signals on the corresponding basis. However, the extension of this scheme to directed graphs is challenging since the associated GSO is non-symmetric and, in general, not diagonalizable. Here, we build upon a recent framework that adds a minimal number of edges to allow diagonalization of the GSO and thus provide a proper graph Fourier transform. Furthermore, we show that such minimal addition of edges creates a cycle cover and that it is essential for the phase analysis of a signal throughout the graph. Concurrently, we propose a generalization of the Hilbert transform interpreted over the newfound cycle cover, which re-establishes intuitions from traditional Hilbert Transform, equivalent to the generalized Hilbert Transform on a single cycle. This generalization leads to a number of simple and elegant recipes to effectively exploit the phase information of graph signals provided by the graph Fourier transform. The feasibility of the approach is demonstrated on several examples.

Paper number 68:
Title: Digital Twin Aided Channel Estimation: Zone-Specific Subspace Prediction and Calibration
Authors: Sadjad Alikhani, Ahmed Alkhateeb
Abstract: Effective channel estimation in sparse and high-dimensional environments is essential for next-generation wireless systems, particularly in large-scale MIMO deployments. This paper introduces a novel framework that leverages digital twins (DTs) as priors to enable efficient zone-specific subspace-based channel estimation (CE). Subspace-based CE significantly reduces feedback overhead by focusing on the dominant channel components, exploiting sparsity in the angular domain while preserving estimation accuracy. While DT channels may exhibit inaccuracies, their coarse-grained subspaces provide a powerful starting point, reducing the search space and accelerating convergence. The framework employs a two-step clustering process on the Grassmann manifold, combined with reinforcement learning (RL), to iteratively calibrate subspaces and align them with real-world counterparts. Simulations show that digital twins not only enable near-optimal performance but also enhance the accuracy of subspace calibration through RL, highlighting their potential as a step towards learnable digital twins.

Paper number 69:
Title: Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations
Authors: Peiyan Yue, Die Cai, Chu Guo, Mengxing Liu, Jun Xia, Yi Wang
Abstract: Accurate automated segmentation of tibial plateau fractures (TPF) from computed tomography (CT) requires large amounts of annotated data to train deep learning models, but obtaining such annotations presents unique challenges. The process demands expert knowledge to identify diverse fracture patterns, assess severity, and account for individual anatomical variations, making the annotation process highly time-consuming and expensive. Although semi-supervised learning methods can utilize unlabeled data, existing approaches often struggle with the complexity and variability of fracture morphologies, as well as limited generalizability across datasets. To tackle these issues, we propose an effective training strategy based on masked autoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages MAE pretraining to capture global skeletal structures and fine-grained fracture details from unlabeled data, followed by fine-tuning with a small set of labeled data. This strategy reduces the dependence on extensive annotations while enhancing the model's ability to learn generalizable and transferable features. The proposed method is evaluated on an in-house dataset containing 180 CT scans with TPF. Experimental results demonstrate that our method consistently outperforms semi-supervised methods, achieving an average Dice similarity coefficient (DSC) of 95.81%, average symmetric surface distance (ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20 annotated cases. Moreover, our method exhibits strong transferability when applying to another public pelvic CT dataset with hip fractures, highlighting its potential for broader applications in fracture segmentation tasks.

Paper number 70:
Title: Lifted Frequency-Domain Identification of Closed-Loop Multirate Systems: Applied to Dual-Stage Actuator Hard Disk Drives
Authors: Max van Haren, Masahiro Mae, Lennart Blanken, Tom Oomen
Abstract: Frequency-domain representations are crucial for the design and performance evaluation of controllers in multirate systems, specifically to address intersample performance. The aim of this paper is to develop an effective frequency-domain system identification technique for closed-loop multirate systems using solely slow-rate output measurements. By indirect identification of multivariable time-invariant representations through lifting, in combination with local modeling techniques, the multirate system is effectively identified. The developed method is capable of accurate identification of closed-loop multirate systems within a single identification experiment, using fast-rate excitation and inputs, and slow-rate outputs. Finally, the developed framework is validated using a benchmark problem consisting of a multivariable dual-stage actuator from a hard disk drive, demonstrating its applicability and accuracy.

Paper number 71:
Title: A 2-6 GHz Ultra-Wideband CMOS Transceiver for Radar Applications
Authors: Alin Thomas Tharakan, Prince Philip, Gokulan T., Sumit Kumar, Gaurab Banerjee
Abstract: This paper presents a low power, low cost transceiver architecture to implement radar-on-a-chip. The transceiver comprises of a full ultra-wideband (UWB) transmitter and a full UWB band receiver. A design methodology to maximize the tuning range of the voltage-controlled oscillator (VCO) is presented. At the transmitter side, a sub-harmonic mixer is used for signal up-conversion. The receiver low noise amplifier (LNA) has a 2 to 6 GHz input matching bandwidth with a power gain of 9 dB and a noise figure of 2.5 dB. The transceiver is implemented in Cadence EDA tools using 65nm CMOS technology. The system achieves a total dc power consumption of 50 mW. Good noise figure performance; good wide-band matching; gain; high level of integration; low power; low cost of the proposed UWB radar transceiver front-end make it a highly competitive SoC solution for low power UWB transceivers.

Paper number 72:
Title: Accurate Control under Voltage Drop for Rotor Drones
Authors: Yuhang Liu, Jindou Jia, Zihan Yang, Kexin Guo
Abstract: This letter proposes an anti-disturbance control scheme for rotor drones to counteract voltage drop (VD) disturbance caused by voltage drop of the battery, which is a common case for long-time flight or aggressive maneuvers. Firstly, the refined dynamics of rotor drones considering VD disturbance are presented. Based on the dynamics, a voltage drop observer (VDO) is developed to accurately estimate the VD disturbance by decoupling the disturbance and state information of the drone, reducing the conservativeness of conventional disturbance observers. Subsequently, the control scheme integrates the VDO within the translational loop and a fixed-time sliding mode observer (SMO) within the rotational loop, enabling it to address force and torque disturbances caused by voltage drop of the battery. Sufficient real flight experiments are conducted to demonstrate the effectiveness of the proposed control scheme under VD disturbance.

Paper number 73:
Title: A Simple BER Expression for FSO Systems with Weak Turbulence and Pointing Errors
Authors: C. Álvarez Roa, Y. C. Gültekin, K. Wu, C. W. Korevaar, A. Alvarado
Abstract: We develop a simple approximation for the average BER for an FSO system impacted by weak turbulence and pointing errors. Numerical results show that the proposed expression accurately predicts the true BER.

Paper number 74:
Title: Optimal Sensor Placement Using Combinations of Hybrid Measurements for Source Localization
Authors: Kang Tang, Sheng Xu, Yuqi Yang, He Kong, Yongsheng Ma
Abstract: This paper focuses on static source localization employing different combinations of measurements, including time-difference-of-arrival (TDOA), received-signal-strength (RSS), angle-of-arrival (AOA), and time-of-arrival (TOA) measurements. Since sensor-source geometry significantly impacts localization accuracy, the strategies of optimal sensor placement are proposed systematically using combinations of hybrid measurements. Firstly, the relationship between sensor placement and source estimation accuracy is formulated by a derived Cramér-Rao bound (CRB). Secondly, the A-optimality criterion, i.e., minimizing the trace of the CRB, is selected to calculate the smallest reachable estimation mean-squared-error (MSE) in a unified manner. Thirdly, the optimal sensor placement strategies are developed to achieve the optimal estimation bound. Specifically, the specific constraints of the optimal geometries deduced by specific measurement, i.e., TDOA, AOA, RSS, and TOA, are found and discussed theoretically. Finally, the new findings are verified by simulation studies.

Paper number 75:
Title: Learning Flatness-Preserving Residuals for Pure-Feedback Systems
Authors: Fengjun Yang, Jake Welde, Nikolai Matni
Abstract: We study residual dynamics learning for differentially flat systems, where a nominal model is augmented with a learned correction term from data. A key challenge is that generic residual parameterizations may destroy flatness, limiting the applicability of flatness-based planning and control methods. To address this, we propose a framework for learning flatness-preserving residual dynamics in systems whose nominal model admits a pure-feedback form. We show that residuals with a lower-triangular structure preserve both the flatness of the system and the original flat outputs. Moreover, we provide a constructive procedure to recover the flatness diffeomorphism of the augmented system from that of the nominal model. We then introduce a learning algorithm that fits such residuals from trajectory data using smooth function approximators. Our approach is validated in simulation on a 2D quadrotor subject to unmodeled aerodynamic effects. We demonstrate that the resulting learned flat model enables tracking performance comparable to nonlinear model predictive control ($5\times$ lower tracking error than the nominal flat model) while also achieving over a $20\times$ speedup in computation.

Paper number 76:
Title: A Control-Oriented Simplified Single Particle Model with Grouped Parameter and Sensitivity Analysis for Lithium-Ion Batteries
Authors: Feng Guo, Luis D. Couto
Abstract: Lithium-ion batteries are widely used in transportation, energy storage, and consumer electronics, driving the need for reliable battery management systems (BMS) for state estimation and control. The Single Particle Model (SPM) balances computational efficiency and accuracy but faces challenges in parameter estimation due to numerous parameters. Current SPM models using parabolic approximation introduce intermediate variables and hard to do parameter grouping. This study presents a control-oriented SPM reformulation that employs parameter grouping and parabolic approximation to simplify model parameters while using average and surface lithium-ion concentrations as model output. By parameter grouping, the original 17 parameters were reduced to 9 grouped parameters. The reformulated model achieves a reduced-order ordinary differential equation form while maintaining mathematical accuracy equivalent to the pre-grouped discretized SPM. Through Sobol sensitivity analysis under various current profiles, the grouped parameters were reduced from 9 to 6 highly sensitive parameters. Results demonstrate that estimating these 6 parameters achieves comparable practical accuracy to estimating all 9 parameters, with faster convergence. This control-oriented SPM enhances BMS applications by facilitating state estimation and control while reducing parameter estimation requirements.

Paper number 77:
Title: On the Loewner framework, the Kolmogorov superposition theorem, and the curse of dimensionality
Authors: Athanasios C. Antoulas, Ion Victor Gosea, Charles Poussot-Vassal
Abstract: The Loewner framework is an interpolatory approach for the approximation of linear and nonlinear systems. The purpose here is to extend this framework to linear parametric systems with an arbitrary number n of parameters. To achieve this, a new generalized multivariate rational function realization is proposed. Then, we introduce the n-dimensional multivariate Loewner matrices and show that they can be computed by solving a set of coupled Sylvester equations. The null space of these Loewner matrices allows the construction of the multivariate barycentric rational function. The principal result of this work is to show how the null space of the n-dimensional Loewner matrix can be computed using a sequence of 1-dimensional Loewner matrices, leading to a drastic reduction of the computational burden. Equally importantly, this burden is alleviated by avoiding the explicit construction of large-scale n-dimensional Loewner matrices of size $N \times N$. Instead, the proposed methodology achieves decoupling of variables, leading to (i) a complexity reduction from $O(N^3)$ to below $O(N^{1.5})$ when $n > 5$ and (ii) to memory storage bounded by the largest variable dimension rather than their product, thus taming the curse of dimensionality and making the solution scalable to very large data sets. This decoupling of the variables leads to a result similar to the Kolmogorov superposition theorem for rational functions. Thus, making use of barycentric representations, every multivariate rational function can be computed using the composition and superposition of single-variable functions. Finally, we suggest two algorithms (one direct and one iterative) to construct, directly from data, multivariate (or parametric) realizations ensuring (approximate) interpolation. Numerical examples highlight the effectiveness and scalability of the method.

Paper number 78:
Title: Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems
Authors: Yilie Huang, Yanwei Jia, Xun Yu Zhou
Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.

Paper number 79:
Title: A Simple but Strong Baseline for Sounding Video Generation: Effective Adaptation of Audio and Video Diffusion Models for Joint Generation
Authors: Masato Ishii, Akio Hayakawa, Takashi Shibuya, Yuki Mitsufuji
Abstract: In this work, we build a simple but strong baseline for sounding video generation. Given base diffusion models for audio and video, we integrate them with additional modules into a single model and train it to make the model jointly generate audio and video. To enhance alignment between audio-video pairs, we introduce two novel mechanisms in our model. The first one is timestep adjustment, which provides different timestep information to each base model. It is designed to align how samples are generated along with timesteps across modalities. The second one is a new design of the additional modules, termed Cross-Modal Conditioning as Positional Encoding (CMC-PE). In CMC-PE, cross-modal information is embedded as if it represents temporal position information, and the embeddings are fed into the model like positional encoding. Compared with the popular cross-attention mechanism, CMC-PE provides a better inductive bias for temporal alignment in the generated data. Experimental results validate the effectiveness of the two newly introduced mechanisms and also demonstrate that our method outperforms existing methods.

Paper number 80:
Title: Approximate Feedback Nash Equilibria with Sparse Inter-Agent Dependencies
Authors: Xinjie Liu, Jingqi Li, Filippos Fotiadis, Mustafa O. Karabag, Jesse Milzman, David Fridovich-Keil, Ufuk Topcu
Abstract: Feedback Nash equilibrium strategies in multi-agent dynamic games require availability of all players' state information to compute control actions. However, in real-world scenarios, sensing and communication limitations between agents make full state feedback expensive or impractical, and such strategies can become fragile when state information from other agents is inaccurate. To this end, we propose a regularized dynamic programming approach for finding sparse feedback policies that selectively depend on the states of a subset of agents in dynamic games. The proposed approach solves convex adaptive group Lasso problems to compute sparse policies approximating Nash equilibrium solutions. We prove the regularized solutions' asymptotic convergence to a neighborhood of Nash equilibrium policies in linear-quadratic (LQ) games. Further, we extend the proposed approach to general non-LQ games via an iterative algorithm. Simulation results in multi-robot interaction scenarios show that the proposed approach effectively computes feedback policies with varying sparsity levels. When agents have noisy observations of other agents' states, simulation results indicate that the proposed regularized policies consistently achieve lower costs than standard Nash equilibrium policies by up to 77% for all interacting agents whose costs are coupled with other agents' states.

Paper number 81:
Title: Surface data imputation with stochastic processes
Authors: Arsalan Jawaid, Samuel Schmidt, Marvin Lotz, Jörg Seewig
Abstract: Spurious measurements frequently occur in surface data from technical components. Excluding or ignoring these spurious points may lead to incorrect surface characterization if these points inherit features of the surface. Therefore, data imputation must be applied to ensure that the estimated data points at spurious measurements do not deviate strongly from the true surface and its characteristics. Traditional surface data imputation methods rely on simple assumptions and ignore existing knowledge of the surface, resulting in suboptimal estimates. In this paper, we propose the use of stochastic processes for data imputation. This approach, which originates from surface texture simulation, allows a straightforward integration of a priori knowledge. We employ Gaussian processes with both stationary and non-stationary covariance structures to address missing values in surface data. In addition, we apply the method to a real-world scenario in which a spurious turned profile is obtained from an actual measurement. Our results demonstrate that the proposed method fills the missing values by maintaining the surface characteristics, particularly when surface features are missing.

Paper number 82:
Title: Symmetrizable systems
Authors: Hamed Taghavian, Jens Sjölund
Abstract: Transforming an asymmetric system into a symmetric system makes it possible to exploit the simplifying properties of symmetry in control problems. We define and characterize the family of symmetrizable systems, which can be transformed into symmetric systems by a linear transformation of their inputs and outputs. In the special case of complete symmetry, the set of symmetrizable systems is convex and verifiable by a semidefinite program. We show that a Khatri-Rao rank needs to be satisfied for a system to be symmetrizable and conclude that linear systems are generically neither symmetric nor symmetrizable.

Paper number 83:
Title: Quantized symbolic time series approximation
Authors: Erin Carson, Xinye Chen, Cheng Kang
Abstract: Time series are ubiquitous in numerous science and engineering domains, e.g., signal processing, bioinformatics, and astronomy. Previous work has verified the efficacy of symbolic time series representation in a variety of engineering applications due to its storage efficiency and numerosity reduction. The most recent symbolic aggregate approximation technique, ABBA, has been shown to preserve essential shape information of time series and improve downstream applications, e.g., neural network inference regarding prediction and anomaly detection in time series. Motivated by the emergence of high-performance hardware which enables efficient computation for low bit-width representations, we present a new quantization-based ABBA symbolic approximation technique, QABBA, which exhibits improved storage efficiency while retaining the original speed and accuracy of symbolic reconstruction. We prove an upper bound for the error arising from quantization and discuss how the number of bits should be chosen to balance this with other errors. An application of QABBA with large language models (LLMs) for time series regression is also presented, and its utility is investigated. By representing the symbolic chain of patterns on time series, QABBA not only avoids the training of embedding from scratch, but also achieves a new state-of-the-art on Monash regression dataset. The symbolic approximation to the time series offers a more efficient way to fine-tune LLMs on the time series regression task which contains various application domains. We further present a set of extensive experiments performed across various well-established datasets to demonstrate the advantages of the QABBA method for symbolic approximation.

Paper number 84:
Title: Task-Parameter Nexus: Task-Specific Parameter Learning for Model-Based Control
Authors: Sheng Cheng, Ran Tao, Yuliang Gu, Shenlong Wang, Xiaofeng Wang, Naira Hovakimyan
Abstract: This paper presents the Task-Parameter Nexus (TPN), a learning-based approach for online determination of the (near-)optimal control parameters of model-based controllers (MBCs) for tracking tasks. In TPN, a deep neural network is introduced to predict the control parameters for any given tracking task at runtime, especially when optimal parameters for new tasks are not immediately available. To train this network, we constructed a trajectory bank with various speeds and curvatures that represent different motion characteristics. Then, for each trajectory in the bank, we auto-tune the optimal control parameters offline and use them as the corresponding ground truth. With this dataset, the TPN is trained by supervised learning. We evaluated the TPN on the quadrotor platform. In simulation experiments, it is shown that the TPN can predict near-optimal control parameters for a spectrum of tracking tasks, demonstrating its robust generalization capabilities to unseen tasks.

Paper number 85:
Title: Prompt-Enabled Large AI Models for CSI Feedback
Authors: Jiajia Guo, Yiming Cui, Chao-Kai Wen, Shi Jin
Abstract: Artificial intelligence (AI) has emerged as a promising tool for channel state information (CSI) feedback. While recent research primarily focuses on improving feedback accuracy on a specific dataset through novel architectures, the underlying mechanism of AI-based CSI feedback remains unclear. This study explores the mechanism through analyzing performance across diverse datasets, with findings suggesting that superior feedback performance stems from AI models' strong fitting capabilities and their ability to leverage environmental knowledge. Building on these findings, we propose a prompt enabled large AI model (LAM) for CSI feedback. The LAM employs powerful transformer blocks and is trained on extensive datasets from various scenarios. Meanwhile, the channel distribution (environmental knowledge) -- represented as the mean of channel magnitude in the angular-delay domain -- is incorporated as a prompt within the decoder to further enhance reconstruction quality. Simulation results confirm that the proposed prompt-enabled LAM significantly improves feedback accuracy and generalization performance while reducing data collection requirements in new scenarios.

Paper number 86:
Title: Multispectral Demosaicing via Dual Cameras
Authors: SaiKiran Tedla, Junyong Lee, Beixuan Yang, Mahmoud Afifi, Michael S. Brown
Abstract: Multispectral (MS) images capture detailed scene information across a wide range of spectral bands, making them invaluable for applications requiring rich spectral data. Integrating MS imaging into multi camera devices, such as smartphones, has the potential to enhance both spectral applications and RGB image quality. A critical step in processing MS data is demosaicing, which reconstructs color information from the mosaic MS images captured by the camera. This paper proposes a method for MS image demosaicing specifically designed for dual-camera setups where both RGB and MS cameras capture the same scene. Our approach leverages co-captured RGB images, which typically have higher spatial fidelity, to guide the demosaicing of lower-fidelity MS images. We introduce the Dual-camera RGB-MS Dataset - a large collection of paired RGB and MS mosaiced images with ground-truth demosaiced outputs - that enables training and evaluation of our method. Experimental results demonstrate that our method achieves state-of-the-art accuracy compared to existing techniques.

Paper number 87:
Title: A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots
Authors: Shuqing Liu, Rong Su, Karl H.Johansson
Abstract: Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.

Paper number 88:
Title: ShieldGemma 2: Robust and Tractable Image Content Moderation
Authors: Wenjun Zeng, Dana Kurniawan, Ryan Mullins, Yuchi Liu, Tamoghna Saha, Dirichi Ike-Njoku, Jindong Gu, Yiwen Song, Cai Xu, Jingjing Zhou, Aparna Joshi, Shravan Dheep, Mani Malek, Hamid Palangi, Joon Baek, Rick Pereira, Karthik Narasimhan
Abstract: We introduce ShieldGemma 2, a 4B parameter image content moderation model built on Gemma 3. This model provides robust safety risk predictions across the following key harm categories: Sexually Explicit, Violence \& Gore, and Dangerous Content for synthetic images (e.g. output of any image generation model) and natural images (e.g. any image input to a Vision-Language Model). We evaluated on both internal and external benchmarks to demonstrate state-of-the-art performance compared to LlavaGuard \citep{helff2024llavaguard}, GPT-4o mini \citep{hurst2024gpt}, and the base Gemma 3 model \citep{gemma_2025} based on our policies. Additionally, we present a novel adversarial data generation pipeline which enables a controlled, diverse, and robust image generation. ShieldGemma 2 provides an open image moderation tool to advance multimodal safety and responsible AI development.

Paper number 89:
Title: F5R-TTS: Improving Flow-Matching based Text-to-Speech with Group Relative Policy Optimization
Authors: Xiaohui Sun, Ruitong Xiao, Jianye Mo, Bowen Wu, Qun Yu, Baoxun Wang
Abstract: We present F5R-TTS, a novel text-to-speech (TTS) system that integrates Gradient Reward Policy Optimization (GRPO) into a flow-matching based architecture. By reformulating the deterministic outputs of flow-matching TTS into probabilistic Gaussian distributions, our approach enables seamless integration of reinforcement learning algorithms. During pretraining, we train a probabilistically reformulated flow-matching based model which is derived from F5-TTS with an open-source dataset. In the subsequent reinforcement learning (RL) phase, we employ a GRPO-driven enhancement stage that leverages dual reward metrics: word error rate (WER) computed via automatic speech recognition and speaker similarity (SIM) assessed by verification models. Experimental results on zero-shot voice cloning demonstrate that F5R-TTS achieves significant improvements in both speech intelligibility (a 29.5% relative reduction in WER) and speaker similarity (a 4.6% relative increase in SIM score) compared to conventional flow-matching based TTS systems. Audio samples are available at this https URL.

Paper number 90:
Title: STAGE: Stemmed Accompaniment Generation through Prefix-Based Conditioning
Authors: Giorgio Strano, Chiara Ballanti, Donato Crisostomi, Michele Mancusi, Luca Cosmo, Emanuele Rodolà
Abstract: Recent advances in generative models have made it possible to create high-quality, coherent music, with some systems delivering production-level output. Yet, most existing models focus solely on generating music from scratch, limiting their usefulness for musicians who want to integrate such models into a human, iterative composition workflow. In this paper we introduce STAGE, our STemmed Accompaniment GEneration model, fine-tuned from the state-of-the-art MusicGen to generate single-stem instrumental accompaniments conditioned on a given mixture. Inspired by instruction-tuning methods for language models, we extend the transformer's embedding matrix with a context token, enabling the model to attend to a musical context through prefix-based conditioning. Compared to the baselines, STAGE yields accompaniments that exhibit stronger coherence with the input mixture, higher audio quality, and closer alignment with textual prompts. Moreover, by conditioning on a metronome-like track, our framework naturally supports tempo-constrained generation, achieving state-of-the-art alignment with the target rhythmic structure--all without requiring any additional tempo-specific module. As a result, STAGE offers a practical, versatile tool for interactive music creation that can be readily adopted by musicians in real-world workflows.

Paper number 91:
Title: Robo-taxi Fleet Coordination at Scale via Reinforcement Learning
Authors: Luigi Tresca, Carolin Schmidt, James Harrison, Filipe Rodrigues, Gioele Zardini, Daniele Gammelli, Marco Pavone
Abstract: Fleets of robo-taxis offering on-demand transportation services, commonly known as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise for societal benefits, such as reducing pollution, energy consumption, and urban congestion. However, orchestrating these systems at scale remains a critical challenge, with existing coordination algorithms often failing to exploit the systems' full potential. This work introduces a novel decision-making framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement learning and propose a graph network-based framework that exploits the main strengths of graph representation learning, reinforcement learning, and classical operations research tools. Extensive evaluations across diverse simulation fidelities and scenarios demonstrate the flexibility of our approach, achieving superior system performance, computational efficiency, and generalizability compared to prior methods. Finally, motivated by the need to democratize research efforts in this area, we release publicly available benchmarks, datasets, and simulators for network-level coordination alongside an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies. Code available at: this https URL
    