
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Explainable Dual-Attention Tabular Transformer for Soil Electrical Resistivity Prediction: A Decision Support Framework for High-Voltage Substation Construction
Authors: Warat Kongkitkul, Sompote Youwai, Warut Sakulpojworachai
Abstract: This research introduces a novel dual-attention transformer architecture for predicting soil electrical resistivity, a critical parameter for high-voltage substation construction. Our model employs attention mechanisms operating across both features and data batches, enhanced by feature embedding layers that project inputs into higher-dimensional spaces. We implements Particle Swarm Optimization for hyperparameter tuning, systematically optimizing embedding dimensions, attention heads, and neural network architecture. The proposed architecture achieves superior predictive performance (Mean Absolute Percentage Error: 0.63%) compared to recent state of the art models for tabular data. Crucially, our model maintains explainability through SHapley Additive exPlanations value analysis, revealing that fine particle content and dry density are the most influential parameters affecting soil resistivity. We developes a web-based application implementing this model to provide engineers with an accessible decision support framework that bridges geotechnical and electrical engineering requirements for the Electricity Generating Authority of Thailand. This integrated approach satisfies both structural stability and electrical safety standards, improving construction efficiency and safety compliance in high-voltage infrastructure implementation.

Paper number 2:
Title: Enhanced ECG Arrhythmia Detection Accuracy by Optimizing Divergence-Based Data Fusion
Authors: Baozhuo Su, Qingli Dou, Kang Liu, Zhengxian Qu, Jerry Deng, Ting Tan, Yanan Gu
Abstract: AI computation in healthcare faces significant challenges when clinical datasets are limited and heterogeneous. Integrating datasets from multiple sources and different equipments is critical for effective AI computation but is complicated by their diversity, complexity, and lack of representativeness, so we often need to join multiple datasets for analysis. The currently used method is fusion after normalization. But when using this method, it can introduce redundant information, decreasing the signal-to-noise ratio and reducing classification accuracy. To tackle this issue, we propose a feature-based fusion algorithm utilizing Kernel Density Estimation (KDE) and Kullback-Leibler (KL) divergence. Our approach involves initially preprocessing and continuous estimation on the extracted features, followed by employing the gradient descent method to identify the optimal linear parameters that minimize the KL divergence between the feature distributions. Using our in-house datasets consisting of ECG signals collected from 2000 healthy and 2000 diseased individuals by different equipments and verifying our method by using the publicly available PTB-XL dataset which contains 21,837 ECG recordings from 18,885 patients. We employ a Light Gradient Boosting Machine (LGBM) model to do the binary classification. The results demonstrate that the proposed fusion method significantly enhances feature-based classification accuracy for abnormal ECG cases in the merged datasets, compared to the normalization method. This data fusion strategy provides a new approach to process heterogeneous datasets for the optimal AI computation results.

Paper number 3:
Title: Drone Remote Identification Based on Zadoff-Chu Sequences and Time-Frequency Images
Authors: Jie Li, Jing Li, Lu Lv, Peixin Zhang, Fengkui Gong
Abstract: We propose an algorithm based on Zadoff-Chu (ZC) sequences and time-frequency images (TFI) to achieve drone remote identification (RID). Specifically, by analyzing the modulation parameters and frame structures of drone ratio-frequency (RF) signals in the DroneRFa dataset, we extract prior information about ZC sequences with surprising correlation properties and robustness. Cross-correlation is performed between locally generated ZC sequences and drone signals to derive ZC sequence-based features. Then, these ZF sequence features are fused with TFI features containing communication protocol information to achieve drone RID. To reduce computational costs, data reduction of the cross-correlation features is performed by analyzing the frame structures and modulation parameters, ensuring that the feature performance remained unaffected. Three feature fusion methods, namely probability-weighted addition, feature vector addition, and feature vector concatenation, are analyzed. Simulation results demonstrate that the proposed algorithm improves the average accuracy by at least 2.5\% compared to existing methods, which also indicate robust RID performance under burst interference and background noise. For RF sampling signals at varying flight distances, the proposed algorithm achieves a maximum accuracy of 99.11\%.

Paper number 4:
Title: Precision yield estimation and mapping in manual strawberry harvesting with instrumented picking carts and a robust data processing pipeline
Authors: Uddhav Bhattarai, Rajkishan Arikapudi, Chen Peng, Steven A. Fennimore, Frank N Martin, Stavros G. Vougioukas
Abstract: High-resolution yield maps for manually harvested crops are impractical to generate on commercial scales because yield monitors are available only for mechanical harvesters. However, precision crop management relies on accurately determining spatial and temporal yield variability. This study presents the development of an integrated system for precision yield estimation and mapping for manually harvested strawberries. Conventional strawberry picking carts were instrumented with a Global Positioning System (GPS) receiver, an Inertial Measurement Unit (IMU), and load cells to record real-time geo-tagged harvest data and cart motion. Extensive data were collected in two strawberry fields in California, USA, during a harvest season. To address the inconsistencies and errors caused by the sensors and the manual harvesting process, a robust data processing pipeline was developed by integrating supervised deep learning models with unsupervised algorithms. The pipeline was used to estimate the yield distribution and generate yield maps for season-long harvests at the desired grid resolution. The estimated yield distributions were used to calculate two metrics: the total mass harvested over specific row segments and the total mass of trays harvested. The metrics were compared to ground truth and achieved accuracies of 90.48% and 94.05%, respectively. Additionally, the accuracy of the estimated yield based on the number of trays harvested per cart for season-long harvest was better than 94%. It showed a strong correlation (Pearson r = 0.99) with the actual number of counted trays in both fields. The proposed system provides a scalable and practical solution for specialty crops, assisting in efficient yield estimation and mapping, field management, and labor management for sustainable crop production.

Paper number 5:
Title: Integrating Notch Filtering and Statistical Methods for Improved Cardiac Diagnostics Using MATLAB
Authors: Lohit Bibar, Samali bose, Tribeni Prasad Banerjee
Abstract: A Notch Filter is essential in ECG signal processing to eliminate narrowband noise, especially powerline interference at 50 Hz or 60 Hz. This interference overlaps with vital ECG signal features, affecting the accuracy of downstream classification tasks (e.g., arrhythmia detection). A properly designed notch filter enhances signal quality, preserves essential ECG components (P, QRS, T waves), and improves the performance of machine learning or deep learning models used for ECG classification.

Paper number 6:
Title: A Class of Hierarchical Sliding Mode Control based on Extended Kalman filter for Quadrotor UAVs
Authors: Van Chung Nguyen, Hung Manh La
Abstract: This study introduces a novel methodology for controlling Quadrotor Unmanned Aerial Vehicles, focusing on Hierarchical Sliding Mode Control strategies and an Extended Kalman Filter. Initially, an EKF is proposed to enhance robustness in estimating UAV states, thereby reducing the impact of measured noises and external disturbances. By locally linearizing UAV systems, the EKF can mitigate the disadvantages of the Kalman filter and reduce the computational cost of other nonlinear observers. Subsequently, in comparison to other related work in terms of stability and computational cost, the HSMC framework shows its outperformance in allowing the quadrotor UAVs to track the references. Three types of HSMC Aggregated HSMC, Incremental HSMC, and Combining HSMC are investigated for their effectiveness in tracking reference trajectories. Moreover, the stability of the quadrotor UAVs is rigorously analyzed using the Lyapunov stability principle. Finally, experimental results and comparative analyses demonstrate the efficacy and feasibility of the proposed methodologies.

Paper number 7:
Title: Curvature-Constrained Vector Field for Motion Planning of Nonholonomic Robots
Authors: Yike Qiao, Xiaodong He, An Zhuo, Zhiyong Sun, Weimin Bao, Zhongkui Li
Abstract: Vector fields are advantageous in handling nonholonomic motion planning as they provide reference orientation for robots. However, additionally incorporating curvature constraints becomes challenging, due to the interconnection between the design of the curvature-bounded vector field and the tracking controller under underactuation. In this paper, we present a novel framework to co-develop the vector field and the control laws, guiding the nonholonomic robot to the target configuration with curvature-bounded trajectory. First, we formulate the problem by introducing the target positive limit set, which allows the robot to converge to or pass through the target configuration, depending on different dynamics and tasks. Next, we construct a curvature-constrained vector field (CVF) via blending and distributing basic flow fields in workspace and propose the saturated control laws with a dynamic gain, under which the tracking error's magnitude decreases even when saturation occurs. Under the control laws, kinematically constrained nonholonomic robots are guaranteed to track the reference CVF and converge to the target positive limit set with bounded trajectory curvature. Numerical simulations show that the proposed CVF method outperforms other vector-field-based algorithms. Experiments on Ackermann UGVs and semi-physical fixed-wing UAVs demonstrate that the method can be effectively implemented in real-world scenarios.

Paper number 8:
Title: Exploration of Multi-Element Collaborative Research and Application for Modern Power System Based on Generative Large Models
Authors: Lu Cheng, Qixiu Zhang, Beibei Xu, Zhiwei Huang, Cirun Zhang, Yanan Lyu, Fan Zhang
Abstract: The transition to intelligent, low-carbon power systems necessitates advanced optimization strategies for managing renewable energy integration, energy storage, and carbon emissions. Generative Large Models (GLMs) provide a data-driven approach to enhancing forecasting, scheduling, and market operations by processing multi-source data and capturing complex system dynamics. This paper explores the role of GLMs in optimizing load-side management, energy storage utilization, and electricity carbon, with a focus on Smart Wide-area Hybrid Energy Systems with Storage and Carbon (SGLSC). By leveraging spatiotemporal modeling and reinforcement learning, GLMs enable dynamic energy scheduling, improve grid stability, enhance carbon trading strategies, and strengthen resilience against extreme weather events. The proposed framework highlights the transformative potential of GLMs in achieving efficient, adaptive, and low-carbon power system operations.

Paper number 9:
Title: AI-Enhanced Resilience in Power Systems: Adversarial Deep Learning for Robust Short-Term Voltage Stability Assessment under Cyber-Attacks
Authors: Yang Li, Shitu Zhang, Yuanzheng Li
Abstract: In the era of Industry 4.0, ensuring the resilience of cyber-physical systems against sophisticated cyber threats is increasingly critical. This study proposes a pioneering AI-based control framework that enhances short-term voltage stability assessments (STVSA) in power systems under complex composite cyber-attacks. First, by incorporating white-box and black-box adversarial attacks with Denial-of-Service (DoS) perturbations during training, composite adversarial attacks are implemented. Second, the application of Spectral Normalized Conditional Wasserstein Generative Adversarial Network with Gradient Penalty (SNCWGAN-GP) and Fast Gradient Sign Method (FGSM) strengthens the model's resistance to adversarial disturbances, improving data quality and training stability. Third, an assessment model based on Long Short-Term Memory (LSTM)-enhanced Graph Attention Network (L-GAT) is developed to capture dynamic relationships between the post-fault dynamic trajectories and electrical grid topology. Experimental results on the IEEE 39-bus test system demonstrate the efficacy and superiority of the proposed method in composite cyber-attack scenarios. This contribution is pivotal to advancing AI-based resilient control strategies for nonlinear dynamical systems, marking a substantial enhancement in the security of cyber-physical systems.

Paper number 10:
Title: Machine Learning Prediction of Cardiovascular Risk in Type 1 Diabetes Mellitus Using Radiomics Features from Multimodal Retinal Images
Authors: Ariadna Tohà-Dalmau (1), Josep Rosinés-Fonoll (2), Enrique Romero (1 and 3), Ferran Mazzanti (4), Ruben Martin-Pinardel (5), Sonia Marias-Perez (2), Carolina Bernal-Morales (2, 5 and 6), Rafael Castro-Dominguez (2), Andrea Mendez (2), Emilio Ortega (5, 6 and 7), Irene Vinagre (5, 6 and 7), Marga Gimenez (5, 6 and 7), Alfredo Vellido (1 and 3), Javier Zarranz-Ventura (2, 5, 6 and 7) ((1) Department of Computer Science, Universitat Politècnica de Catalunya (2) Institut Clínic d'Oftalmología, Hospital Clínic de Barcelona (3) Intelligent Data Science and Artificial Intelligence Research Center (4) Department of Physics, Universitat Politècnica de Catalunya (5) August Pi i Sunyer Biomedical Research Institute (6) Diabetes Unit, Hospital Clínic de Barcelona (7) School of Medicine, Universitat de Barcelona)
Abstract: This study aimed to develop a machine learning (ML) algorithm capable of determining cardiovascular risk in multimodal retinal images from patients with type 1 diabetes mellitus, distinguishing between moderate, high, and very high-risk levels. Radiomic features were extracted from fundus retinography, optical coherence tomography (OCT), and OCT angiography (OCTA) images. ML models were trained using these features either individually or combined with clinical data. A dataset of 597 eyes (359 individuals) was analyzed, and models trained only with radiomic features achieved AUC values of (0.79 $\pm$ 0.03) for identifying moderate risk cases from high and very high-risk cases, and (0.73 $\pm$ 0.07) for distinguishing between high and very high-risk cases. The addition of clinical variables improved all AUC values, reaching (0.99 $\pm$ 0.01) for identifying moderate risk cases and (0.95 $\pm$ 0.02) for differentiating between high and very high-risk cases. For very high CV risk, radiomics combined with OCT+OCTA metrics and ocular data achieved an AUC of (0.89 $\pm$ 0.02) without systemic data input. These results demonstrate that radiomic features obtained from multimodal retinal images are useful for discriminating and classifying CV risk labels, highlighting the potential of this oculomics approach for CV risk assessment.

Paper number 11:
Title: Global Rice Multi-Class Segmentation Dataset (RiceSEG): A Comprehensive and Diverse High-Resolution RGB-Annotated Images for the Development and Benchmarking of Rice Segmentation Algorithms
Authors: Junchi Zhou, Haozhou Wang, Yoichiro Kato, Tejasri Nampally, P. Rajalakshmi, M. Balram, Keisuke Katsura, Hao Lu, Yue Mu, Wanneng Yang, Yangmingrui Gao, Feng Xiao, Hongtao Chen, Yuhao Chen, Wenjuan Li, Jingwen Wang, Fenghua Yu, Jian Zhou, Wensheng Wang, Xiaochun Hu, Yuanzhu Yang, Yanfeng Ding, Wei Guo, Shouyang Liu
Abstract: Developing computer vision-based rice phenotyping techniques is crucial for precision field management and accelerating breeding, thereby continuously advancing rice production. Among phenotyping tasks, distinguishing image components is a key prerequisite for characterizing plant growth and development at the organ scale, enabling deeper insights into eco-physiological processes. However, due to the fine structure of rice organs and complex illumination within the canopy, this task remains highly challenging, underscoring the need for a high-quality training dataset. Such datasets are scarce, both due to a lack of large, representative collections of rice field images and the time-intensive nature of annotation. To address this gap, we established the first comprehensive multi-class rice semantic segmentation dataset, RiceSEG. We gathered nearly 50,000 high-resolution, ground-based images from five major rice-growing countries (China, Japan, India, the Philippines, and Tanzania), encompassing over 6,000 genotypes across all growth stages. From these original images, 3,078 representative samples were selected and annotated with six classes (background, green vegetation, senescent vegetation, panicle, weeds, and duckweed) to form the RiceSEG dataset. Notably, the sub-dataset from China spans all major genotypes and rice-growing environments from the northeast to the south. Both state-of-the-art convolutional neural networks and transformer-based semantic segmentation models were used as baselines. While these models perform reasonably well in segmenting background and green vegetation, they face difficulties during the reproductive stage, when canopy structures are more complex and multiple classes are involved. These findings highlight the importance of our dataset for developing specialized segmentation models for rice and other crops.

Paper number 12:
Title: Dynamical Simulation Model of the Pyro-Process in Cement Clinker Production
Authors: Jan Lorenz Svensen, Wilson Ricardo Leal da Silva, Zhanhao Zhang, Steen Hørsholt, John Bagterp Jørgensen
Abstract: This study presents a dynamic simulation model for the pyro-process of clinker production in cement plants. The study aims to construct a simulation model capable of replicating the real-world dynamics of the pyro-process to facilitate research into the improvements of operation, i.e., the development of alternative strategies for reducing CO2 emissions and ensuring clinker quality, production, and lowering fuel consumption. The presented model is an index-1 differential-algebraic equation (DAE) model based on first engineering principles and modular approaches. Using a systematic approach, the model is described on a detailed level that integrates geometric aspects, thermo-physical properties, transport phenomena, stoichiometry and kinetics, mass and energy balances, and algebraic volume and energy conservations. By manually calibrating the model to a steady-state reference, we provide dynamic simulation results that match the expected reference performance and the expected dynamic behavior from the industrial practices.

Paper number 13:
Title: Distributionally Robust Predictive Runtime Verification under Spatio-Temporal Logic Specifications
Authors: Yiqi Zhao, Emily Zhu, Bardh Hoxha, Georgios Fainekos, Jyotirmoy V. Deshmukh, Lars Lindemann
Abstract: Cyber-physical systems designed in simulators, often consisting of multiple interacting agents, behave differently in the real-world. We would like to verify these systems during runtime when they are deployed. Thus, we propose robust predictive runtime verification (RPRV) algorithms for: (1) general stochastic CPS under signal temporal logic (STL) tasks, and (2) stochastic multi-agent systems (MAS) under spatio-temporal logic tasks. The RPRV problem presents the following challenges: (1) there may not be sufficient data on the behavior of the deployed CPS, (2) predictive models based on design phase system trajectories may encounter distribution shift during real-world deployment, and (3) the algorithms need to scale to the complexity of MAS and be applicable to spatio-temporal logic tasks. To address these challenges, we assume knowledge of an upper bound on the statistical distance (in terms of an f-divergence) between the trajectory distributions of the system at deployment and design time. We are motivated by our prior work [1, 2] where we proposed an accurate and an interpretable RPRV algorithm for general CPS, which we here extend to the MAS setting and spatio-temporal logic tasks. Specifically, we use a learned predictive model to estimate the system behavior at runtime and robust conformal prediction to obtain probabilistic guarantees by accounting for distribution shifts. Building on [1], we perform robust conformal prediction over the robust semantics of spatio-temporal reach and escape logic (STREL) to obtain centralized RPRV algorithms for MAS. We empirically validate our results in a drone swarm simulator, where we show the scalability of our RPRV algorithms to MAS and analyze the impact of different trajectory predictors on the verification result. To the best of our knowledge, these are the first statistically valid algorithms for MAS under distribution shift.

Paper number 14:
Title: Route Recommendations for Traffic Management Under Learned Partial Driver Compliance
Authors: Heeseung Bang, Jung-Hoon Cho, Cathy Wu, Andreas A. Malikopoulos
Abstract: In this paper, we aim to mitigate congestion in traffic management systems by guiding travelers along system-optimal (SO) routes. However, we recognize that most theoretical approaches assume perfect driver compliance, which often does not reflect reality, as drivers tend to deviate from recommendations to fulfill their personal objectives. Therefore, we propose a route recommendation framework that explicitly learns partial driver compliance and optimizes traffic flow under realistic adherence. We first compute an SO edge flow through flow optimization techniques. Next, we train a compliance model based on historical driver decisions to capture individual responses to our recommendations. Finally, we formulate a stochastic optimization problem that minimizes the gap between the target SO flow and the realized flow under conditions of imperfect adherence. Our simulations conducted on a grid network reveal that our approach significantly reduces travel time compared to baseline strategies, demonstrating the practical advantage of incorporating learned compliance into traffic management.

Paper number 15:
Title: Online Learning for Nonlinear Dynamical Systems without the I.I.D. Condition
Authors: Lantian Zhang, Silun Zhang
Abstract: This paper investigates online identification and prediction for nonlinear stochastic dynamical systems. In contrast to offline learning methods, we develop online algorithms that learn unknown parameters from a single trajectory. A key challenge in this setting is handling the non-independent data generated by the closed-loop system. Existing theoretical guarantees for such systems are mostly restricted to the assumption that inputs are independently and identically distributed (i.i.d.), or that the closed-loop data satisfy a persistent excitation (PE) condition. However, these assumptions are often violated in applications such as adaptive feedback control. In this paper, we propose an online projected Newton-type algorithm for parameter estimation in nonlinear stochastic dynamical systems, and develop an online predictor for system outputs based on online parameter estimates. By using both the stochastic Lyapunov function and martingale estimation methods, we demonstrate that the average regret converges to zero without requiring traditional persistent excitation (PE) conditions. Furthermore, we establish a novel excitation condition that ensures global convergence of the online parameter estimates. The proposed excitation condition is applicable to a broader class of system trajectories, including those violating the PE condition.

Paper number 16:
Title: Moving Target Defense Against Adversarial False Data Injection Attacks In Power Grids
Authors: Yexiang Chen, Subhash Lakshminarayana, H. Vincent Poor
Abstract: Machine learning (ML)-based detectors have been shown to be effective in detecting stealthy false data injection attacks (FDIAs) that can bypass conventional bad data detectors (BDDs) in power systems. However, ML models are also vulnerable to adversarial attacks. A sophisticated perturbation signal added to the original BDD-bypassing FDIA can conceal the attack from ML-based detectors. In this paper, we develop a moving target defense (MTD) strategy to defend against adversarial FDIAs in power grids. We first develop an MTD-strengthened deep neural network (DNN) model, which deploys a pool of DNN models rather than a single static model that cooperate to detect the adversarial attack jointly. The MTD model pool introduces randomness to the ML model's decision boundary, thereby making the adversarial attacks detectable. Furthermore, to increase the effectiveness of the MTD strategy and reduce the computational costs associated with developing the MTD model pool, we combine this approach with the physics-based MTD, which involves dynamically perturbing the transmission line reactance and retraining the DNN-based detector to adapt to the new system topology. Simulations conducted on IEEE test bus systems demonstrate that the MTD-strengthened DNN achieves up to 94.2% accuracy in detecting adversarial FDIAs. When combined with a physics-based MTD, the detection accuracy surpasses 99%, while significantly reducing the computational costs of updating the DNN models. This approach requires only moderate perturbations to transmission line reactances, resulting in minimal increases in OPF cost.

Paper number 17:
Title: Single-Satellite Navigation on Lunar North Pole
Authors: Tim Gong, Andrew Dempster
Abstract: The Moon is a primary focus of space exploration. Current navigation methods face significant limitations in providing precise location data for lunar missions. In particular, existing methods often require direct Line of Sight to Earth, have limited capacity, and suffer from long signal travel times. This paper aims to tackle these challenges through a novel single satellite navigation system at the lunar North Pole. By utilising the Doppler effect, this system facilitates 3D geolocation of a stationary receiver on the lunar surface. Key findings include choosing a Low Lunar Orbit (LLO) suitable for North Pole coverage, designing a 3-step geolocation algorithm tailored to lunar conditions, constructing a comprehensive error budget, and evaluating the system performance through Dilution of Position (DOP).

Paper number 18:
Title: Oscillatory Associative Memory with Exponential Capacity
Authors: Taosha Guo, Arie Ogranovich, Arvind R. Venkatakrishnan, Madelyn R. Shapiro, Francesco Bullo, Fabio Pasqualetti
Abstract: The slowing of Moore's law and the increasing energy demands of machine learning present critical challenges for both the hardware and machine learning communities, and drive the development of novel computing paradigms. Of particular interest is the challenge of incorporating memory efficiently into the learning process. Inspired by how human brains store and retrieve information, associative memory mechanisms provide a class of computational methods that can store and retrieve patterns in a robust, energy-efficient manner. Existing associative memory architectures, such as the celebrated Hopfield model and oscillatory associative memory networks, store patterns as stable equilibria of network dynamics. However, the capacity (i.e. the number of patterns that a network can memorize normalized by their number of nodes) of existing oscillatory models have been shown to decrease with the size of the network, making them impractical for large-scale, real-world applications. In this paper, we propose a novel associative memory architecture based on Kuramoto oscillators. We show that the capacity of our associative memory network increases exponentially with network size and features no spurious memories. In addition, we present algorithms and numerical experiments to support these theoretical findings, providing guidelines for the hardware implementation of the proposed associative memory networks.

Paper number 19:
Title: Distributed Resilience-Aware Control in Multi-Robot Networks
Authors: Haejoon Lee, Dimitra Panagou
Abstract: Ensuring resilient consensus in multi-robot systems with misbehaving agents remains a challenge, as many existing network resilience properties are inherently combinatorial and globally defined. While previous works have proposed control laws to enhance or preserve resilience in multi-robot networks, they often assume a fixed topology with known resilience properties, or require global state knowledge. These assumptions may be impractical in physically-constrained environments, where safety and resilience requirements are conflicting, or when misbehaving agents corrupt the shared information. In this work, we propose a distributed control law that enables each robot to guarantee resilient consensus and safety during its navigation without fixed topologies using only locally available information. To this end, we establish a new sufficient condition for resilient consensus in time-varying networks based on the degree of non-misbehaving or normal agents. Using this condition, we design a Control Barrier Function (CBF)-based controller that guarantees resilient consensus and collision avoidance without requiring estimates of global state and/or control actions of all other robots. Finally, we validate our method through simulations.

Paper number 20:
Title: Event-Triggered Nonlinear Model Predictive Control for Cooperative Cable-Suspended Payload Transportation with Multi-Quadrotors
Authors: Tohid Kargar Tasooji, Sakineh Khodadadi, Guangjun Liu
Abstract: Autonomous Micro Aerial Vehicles (MAVs), particularly quadrotors, have shown significant potential in assisting humans with tasks such as construction and package delivery. These applications benefit greatly from the use of cables for manipulation mechanisms due to their lightweight, low-cost, and simple design. However, designing effective control and planning strategies for cable-suspended systems presents several challenges, including indirect load actuation, nonlinear configuration space, and highly coupled system dynamics. In this paper, we introduce a novel event-triggered distributed Nonlinear Model Predictive Control (NMPC) method specifically designed for cooperative transportation involving multiple quadrotors manipulating a cable-suspended payload. This approach addresses key challenges such as payload manipulation, inter-robot separation, obstacle avoidance, and trajectory tracking, all while optimizing the use of computational and communication resources. By integrating an event-triggered mechanism, our NMPC method reduces unnecessary computations and communication, enhancing energy efficiency and extending the operational range of MAVs. The proposed method employs a lightweight state vector parametrization that focuses on payload states in all six degrees of freedom, enabling efficient planning of trajectories on the SE(3) manifold. This not only reduces planning complexity but also ensures real-time computational feasibility. Our approach is validated through extensive simulation, demonstrating its efficacy in dynamic and resource-constrained environments.

Paper number 21:
Title: Event-Based Distributed Linear Quadratic Gaussian for Multi-Robot Coordination with Localization Uncertainty
Authors: Tohid Kargar Tasooji, Sakineh Khodadadi
Abstract: This paper addresses the problem of event-based distributed Linear Quadratic Gaussian (LQG) control for multirobot coordination under localization uncertainty. An event-triggered LQG rendezvous control strategy is proposed to ensure coordinated motion while reducing communication overhead. The design framework decouples the LQG controller from the event-triggering mechanism, although the scheduler parameters critically influence rendezvous performance. We establish stochastic stability for the closed-loop multi-robot system and demonstrate that a carefully tuned event-triggering scheduler can effectively balance rendezvous accuracy with communication efficiency by limiting the upper bound of the rendezvous error while minimizing the average transmission rate. Experimental results using a group of Robotarium mobile robots validate the proposed approach, confirming its efficacy in achieving robust coordination under uncertainty.

Paper number 22:
Title: Distributed Linear Quadratic Gaussian for Multi-Robot Coordination with Localization Uncertainty
Authors: Tohid Kargar Tasooji, Sakineh Khodadadi
Abstract: This paper addresses the problem of distributed coordination control for multi-robot systems (MRSs) in the presence of localization uncertainty using a Linear Quadratic Gaussian (LQG) approach. We introduce a stochastic LQG control strategy that ensures the coordination of mobile robots while optimizing a performance criterion. The proposed control framework accounts for the inherent uncertainty in localization measurements, enabling robust decision-making and coordination. We analyze the stability of the system under the proposed control protocol, deriving conditions for the convergence of the multi-robot network. The effectiveness of the proposed approach is demonstrated through experimental validation using Robotrium simulation experiments, showcasing the practical applicability of the control strategy in real-world scenarios with localization uncertainty.

Paper number 23:
Title: Comparative Analysis of Unsupervised and Supervised Autoencoders for Nuclei Classification in Clear Cell Renal Cell Carcinoma Images
Authors: Fatemeh Javadian, Zahra Aminparast, Johannes Stegmaier, Abin Jose
Abstract: This study explores the application of supervised and unsupervised autoencoders (AEs) to automate nuclei classification in clear cell renal cell carcinoma (ccRCC) images, a diagnostic task traditionally reliant on subjective visual grading by pathologists. We evaluate various AE architectures, including standard AEs, contractive AEs (CAEs), and discriminative AEs (DAEs), as well as a classifier-based discriminative AE (CDAE), optimized using the hyperparameter tuning tool Optuna. Bhattacharyya distance is selected from several metrics to assess class separability in the latent space, revealing challenges in distinguishing adjacent grades using unsupervised models. CDAE, integrating a supervised classifier branch, demonstrated superior performance in both latent space separation and classification accuracy. Given that CDAE-CNN achieved notable improvements in classification metrics, affirming the value of supervised learning for class-specific feature extraction, F1 score was incorporated into the tuning process to optimize classification performance. Results show significant improvements in identifying aggressive ccRCC grades by leveraging the classification capability of AE through latent clustering followed by fine-grained classification. Our model outperforms the current state of the art, CHR-Network, across all evaluated metrics. These findings suggest that integrating a classifier branch in AEs, combined with neural architecture search and contrastive learning, enhances grading automation in ccRCC pathology, particularly in detecting aggressive tumor grades, and may improve diagnostic accuracy.

Paper number 24:
Title: Performance-Aware Control of Modular Batteries For Fast Frequency Response
Authors: Yutong He, Guangchun Ruan, Haiwang Zhong
Abstract: Modular batteries can be aggregated to deliver frequency regulation services for power grids. Although utilizing the idle capacity of battery modules is financially attractive, it remains challenging to consider the heterogeneous module-level characteristics such as dynamic operational efficiencies and battery degradation. In addition, real-time decision making within seconds is required to enable fast frequency response. In order to address these issues, this paper proposes a performance-aware scheduling approach for battery modules to deliver fast frequency response (FFR) support. In particular, the conduction loss and switching loss of battery packs as well as converters are captured within a mix-integer quadratic constrained program (MIQCP). The cycle-based aging model identifies the aging cost of battery modules during frequent cycling by introducing the aging subgradient calculation and linearization. Case studies based on real-world battery data show that the proposed scheduling approach can effectively reduce power loss cost by nearly 28%-57% and battery aging cost by 4%-15% compared to conventional methods, which can also enhance the SoC balance.

Paper number 25:
Title: Taming High-Dimensional Dynamics: Learning Optimal Projections onto Spectral Submanifolds
Authors: Hugo Buurmeijer, Luis A. Pabon, John Irvin Alora, Roshan S. Kaundinya, George Haller, Marco Pavone
Abstract: High-dimensional nonlinear systems pose considerable challenges for modeling and control across many domains, from fluid mechanics to advanced robotics. Such systems are typically approximated with reduced order models, which often rely on orthogonal projections, a simplification that may lead to large prediction errors. In this work, we derive optimality of fiber-aligned projections onto spectral submanifolds, preserving the nonlinear geometric structure and minimizing long-term prediction error. We propose a computationally tractable procedure to approximate these projections from data, and show how the effect of control can be incorporated. For a 180-dimensional robotic system, we demonstrate that our reduced-order models outperform previous state-of-the-art approaches by up to fivefold in trajectory tracking accuracy under model predictive control.

Paper number 26:
Title: Mitigating the Impact of Electrode Shift on Classification Performance in Electromyography-Based Motion Prediction Using Sliding-Window Normalization
Authors: Taichi Tanaka, Isao Nambu, Yasuhiro Wada
Abstract: Electromyography (EMG) signals are used in many applications, including prosthetic hands, assistive suits, and rehabilitation. Recent advances in motion estimation have improved performance, yet challenges remain in cross-subject generalization, electrode shift, and daily variations. When electrode shift occurs, both transfer learning and adversarial domain adaptation improve classification performance by reducing the performance gap to -1\% (eight-class scenario). However, additional data are needed for re-training in transfer learning or for training in adversarial domain adaptation. To address this issue, we investigated a sliding-window normalization (SWN) technique in a real-time prediction scenario. This method combines z-score normalization with a sliding-window approach to reduce the decline in classification performance caused by electrode shift. We validated the effectiveness of SWN using experimental data from a target trajectory tracking task involving the right arm. For three motions classification (rest, flexion, and extension of the elbow) obtained from EMG signals, our offline analysis showed that SWN reduced the differential classification accuracy to -1.0\%, representing a 6.6\% improvement compared to the case without normalization (-7.6\%). Furthermore, when SWN was combined with a strategy that uses a mixture of multiple electrode positions, classification accuracy improved by an additional 2.4\% over the baseline. These results suggest that SWN can effectively reduce the performance degradation caused by electrode shift, thereby enhancing the practicality of EMG-based motion estimation systems.

Paper number 27:
Title: A Robust Method for Fault Detection and Severity Estimation in Mechanical Vibration Data
Authors: Youngjae Jeon, Eunho Heo, Jinmo Lee, Taewon Uhm, Dongjin Lee
Abstract: This paper proposes a robust method for fault detection and severity estimation in multivariate time-series data to enhance predictive maintenance of mechanical systems. We use the Temporal Graph Convolutional Network (T-GCN) model to capture both spatial and temporal dependencies among variables. This enables accurate future state predictions under varying operational conditions. To address the challenge of fluctuating anomaly scores that reduce fault severity estimation accuracy, we introduce a novel fault severity index based on the mean and standard deviation of anomaly scores. This generates a continuous and reliable severity measurement. We validate the proposed method using two experimental datasets: an open IMS bearing dataset and data collected from a fanjet electric propulsion system. Results demonstrate that our method significantly reduces abrupt fluctuations and inconsistencies in anomaly scores. This provides a more dependable foundation for maintenance planning and risk management in safety-critical applications.

Paper number 28:
Title: Data-Driven Hamiltonian for Direct Construction of Safe Set from Trajectory Data
Authors: Jason J. Choi, Christopher A. Strong, Koushil Sreenath, Namhoon Cho, Claire J. Tomlin
Abstract: In continuous-time optimal control, evaluating the Hamiltonian requires solving a constrained optimization problem using the system's dynamics model. Hamilton-Jacobi reachability analysis for safety verification has demonstrated practical utility only when efficient evaluation of the Hamiltonian over a large state-time grid is possible. In this study, we introduce the concept of a data-driven Hamiltonian (DDH), which circumvents the need for an explicit dynamics model by relying only on mild prior knowledge (e.g., Lipschitz constants), thus enabling the construction of reachable sets directly from trajectory data. Recognizing that the Hamiltonian is the optimal inner product between a given costate and realizable state velocities, the DDH estimates the Hamiltonian using the worst-case realization of the velocity field based on the observed state trajectory data. This formulation ensures a conservative approximation of the true Hamiltonian for uncertain dynamics. The reachable set computed based on the DDH is also ensured to be a conservative approximation of the true reachable set. Next, we propose a data-efficient safe experiment framework for gradual expansion of safe sets using the DDH. This is achieved by iteratively conducting experiments within the computed data-driven safe set and updating the set using newly collected trajectory data. To demonstrate the capabilities of our approach, we showcase its effectiveness in safe flight envelope expansion for a tiltrotor vehicle transitioning from near-hover to forward flight.

Paper number 29:
Title: On Differential Controllability and Observability Functions
Authors: Yu Kawano, Bart Besselink, Jacquelien M.A. Scherpen
Abstract: Differential balancing theory for nonlinear model reduction relies on differential controllability and observability functions. In this paper, we further investigate them from two different perspectives. First, we establish novel connections between these differential energy functions and their incremental counterparts by assuming the existence of the corresponding optimal state feedback for each controllability function. Specifically, an upper bound on the incremental controllability/observability function is provided by the corresponding differential energy function. Conversely, an upper bound on the differential controllability function can be estimated from the incremental controllability function. Furthermore, the differential observability function can be constructed from the incremental observability function. Second, we explore the positive definiteness of the differential controllability/observability function in the context of controllability/observability and stability.

Paper number 30:
Title: A Modular Energy Aware Framework for Multicopter Modeling in Control and Planning Applications
Authors: Sebastian Gasche, Christian Kallies, Andreas Himmel, Rolf Findeisen
Abstract: Unmanned aerial vehicles (UAVs), especially multicopters, have recently gained popularity for use in surveillance, monitoring, inspection, and search and rescue missions. Their maneuverability and ability to operate in confined spaces make them particularly useful in cluttered environments. For advanced control and mission planning applications, accurate and resource-efficient modeling of UAVs and their capabilities is essential. This study presents a modular approach to multicopter modeling that considers vehicle dynamics, energy consumption, and sensor integration. The power train model includes detailed descriptions of key components such as the lithium-ion battery, electronic speed controllers, and brushless DC motors. Their models are validated with real test flight data. In addition, sensor models, including LiDAR and cameras, are integrated to describe the equipment often used in surveillance and monitoring missions. The individual models are combined into an energy-aware multicopter model, which provide the basis for a companion study on path planning for unmanned aircaft system (UAS) swarms performing search and rescue missions in cluttered and dynamic environments. The flexible modeling approach enables easy description of different UAVs in a heterogeneous UAS swarm, allowing for energy-efficient operations and autonomous decision making for a reliable mission performance.

Paper number 31:
Title: Non-parametric B-spline decoupling of multivariate functions
Authors: Joppe De Jonghe, Mariya Ishteva
Abstract: Many scientific fields and applications require compact representations of multivariate functions. For this problem, decoupling methods are powerful techniques for representing the multivariate functions as a combination of linear transformations and nonlinear univariate functions. This work introduces an efficient decoupling algorithm that leverages the use of B-splines to allow a non-parametric estimation of the decoupling's internal functions. The use of B-splines alleviates the problem of choosing an appropriate basis, as in parametric methods, but still allows an intuitive way to tweak the flexibility of the estimated functions. Besides the non-parametric property, the use of B-spline representations allows for easy integration of nonnegativity or monotonicity constraints on the function shapes, which is not possible for the currently available (non-)parametric decoupling methods. The proposed algorithm is illustrated on synthetic examples that highlight the flexibility of the B-spline representation and the ease with which a monotonicity constraint can be added. The examples also show that if monotonic functions are required, enforcing the constraint is necessary.

Paper number 32:
Title: Energy Aware and Safe Path Planning for Unmanned Aircraft Systems
Authors: Sebastian Gasche, Christian Kallies, Andreas Himmel, Rolf Findeisen
Abstract: This paper proposes a path planning algorithm for multi-agent unmanned aircraft systems (UASs) to autonomously cover a search area, while considering obstacle avoidance, as well as the capabilities and energy consumption of the employed unmanned aerial vehicles. The path planning is optimized in terms of energy efficiency to prefer low energy-consuming maneuvers. In scenarios where a UAS is low on energy, it autonomously returns to its initial position for a safe landing, thus preventing potential battery damage. To accomplish this, an energy-aware multicopter model is integrated into a path planning algorithm based on model predictive control and mixed integer linear programming. Besides factoring in energy consumption, the planning is improved by dynamically defining feasible regions for each UAS to prevent obstacle corner-cutting or over-jumping.

Paper number 33:
Title: Verification of Autonomous Neural Car Control with KeYmaera X
Authors: Enguerrand Prebet, Samuel Teuber, André Platzer
Abstract: This article presents a formal model and formal safety proofs for the ABZ'25 case study in differential dynamic logic (dL). The case study considers an autonomous car driving on a highway avoiding collisions with neighbouring cars. Using KeYmaera X's dL implementation, we prove absence of collision on an infinite time horizon which ensures that safety is preserved independently of trip length. The safety guarantees hold for time-varying reaction time and brake force. Our dL model considers the single lane scenario with cars ahead or behind. We demonstrate that dL with its tools is a rigorous foundation for runtime monitoring, shielding, and neural network verification. Doing so sheds light on inconsistencies between the provided specification and simulation environment highway-env of the ABZ'25 study. We attempt to fix these inconsistencies and uncover numerous counterexamples which also indicate issues in the provided reinforcement learning environment.

Paper number 34:
Title: Learning-Based Conformal Tube MPC for Safe Control in Interactive Multi-Agent Systems
Authors: Shuqi Wang, Yue Gao, Xiang Yin
Abstract: Safety assurance in multi-agent systems with coupled dynamics is a fundamental yet challenging problem, especially when agents exhibit uncertain and state-dependent behaviors. Classical robust control often assumes worst-case disturbances, leading to overly conservative actions. In this work, we propose a learning-based framework that combines conformal prediction with model predictive control (MPC) to ensure probabilistic safety under action-level uncertainty. Unlike prior approaches that predict future states, we directly model the control action of the uncontrollable agent as a stochastic function of the joint state, trained via neural networks and calibrated using conformal prediction. This enables us to construct dynamic, probabilistically guaranteed reachable tubes for the uncontrollable agent. These tubes are then embedded into an MPC formulation to synthesize control actions for the controllable agent that ensure safe interactions over a finite planning horizon. We provide formal stepwise and cumulative safety guarantees, and demonstrate the effectiveness of our approach through a pedestrian-vehicle interaction scenario. Compared to baseline methods, our framework achieves higher safety rates while maintaining high performance in terms of speed and responsiveness.

Paper number 35:
Title: Controllability Analysis of Multi-Modal Acoustic Particle Manipulation in One-Dimensional Standing Waves
Authors: Dongjun Wu, Guilherme Perticarari, Thierry Baasch
Abstract: Acoustic manipulation in microfluidic devices enables contactless handling of biological cells for Lab-on-Chip applications. This paper analyzes the controllability of multi-particle systems in a one-dimensional acoustic standing wave system using multi-modal actuation. By modeling the system as a nonlinear control system, we analyze its global and local controllability, quantifying these properties in terms of mode numbers. Our results show that sufficient modes enable dense reachability sets, while mode mixing with 10 modes grants a strict notion of controllability to 80\% of the state space in a two-particle system. These findings offer theoretical insights for designing acoustic manipulation algorithms, supporting efficient control in biomedical applications.

Paper number 36:
Title: Probabilistic State Estimation of Timed Probabilistic Discrete Event Systems via Artificial Neural Networks [Draft Version]
Authors: Omar Amri, Carla Seatzu, Alessandro Giua, Dimitri Lefebvre
Abstract: This paper is about the state estimation of timed probabilistic discrete event systems. The main contribution is to propose general procedures for developing state estimation approaches based on artificial neural networks. It is assumed that no formal model of the system exists but a data set is available, which contains the history of the timed behaviour of the systems. This dataset will be exploited to develop a neural network model that uses both logical and temporal information gathered during the functioning of the system as inputs and provides the state probability vector as output. Two main approaches are successively proposed (i) state estimation of timed probabilistic discrete event systems over observations: in this case the state estimate is reconstructed at the occurrence of each new observation; (ii) state estimation of timed probabilistic discrete event systems over time: in this case the state estimate is reconstructed at each clock time increment. For each approach, the paper outlines the process of data preprocessing, model building and implementation. This paper not only proposes groundbreaking approaches but also opens the door to further exploitation of artificial neural networks for the benefit of discrete event systems.

Paper number 37:
Title: Policy Optimization Algorithms in a Unified Framework
Authors: Shuang Wu
Abstract: Policy optimization algorithms are crucial in many fields but challenging to grasp and implement, often due to complex calculations related to Markov decision processes and varying use of discount and average reward setups. This paper presents a unified framework that applies generalized ergodicity theory and perturbation analysis to clarify and enhance the application of these algorithms. Generalized ergodicity theory sheds light on the steady-state behavior of stochastic processes, aiding understanding of both discounted and average rewards. Perturbation analysis provides in-depth insights into the fundamental principles of policy optimization algorithms. We use this framework to identify common implementation errors and demonstrate the correct approaches. Through a case study on Linear Quadratic Regulator problems, we illustrate how slight variations in algorithm design affect implementation outcomes. We aim to make policy optimization algorithms more accessible and reduce their misuse in practice.

Paper number 38:
Title: Mind the Prompt: Prompting Strategies in Audio Generations for Improving Sound Classification
Authors: Francesca Ronchini, Ho-Hsiang Wu, Wei-Cheng Lin, Fabio Antonacci
Abstract: This paper investigates the design of effective prompt strategies for generating realistic datasets using Text-To-Audio (TTA) models. We also analyze different techniques for efficiently combining these datasets to enhance their utility in sound classification tasks. By evaluating two sound classification datasets with two TTA models, we apply a range of prompt strategies. Our findings reveal that task-specific prompt strategies significantly outperform basic prompt approaches in data generation. Furthermore, merging datasets generated using different TTA models proves to enhance classification performance more effectively than merely increasing the training dataset size. Overall, our results underscore the advantages of these methods as effective data augmentation techniques using synthetic data.

Paper number 39:
Title: Point Cloud Objective Quality: Benchmarking Features and Quality Evaluation
Authors: Joao Prazeres, Rafael Rodrigues, Manuela Pereira, Antonio M. G. Pinheiro
Abstract: Full-reference point cloud objective metrics are currently providing very accurate representations of perceptual quality. These metrics are usually composed of a set of features that are somehow combined, resulting in a final quality value. In this study, the different features of the best-performing metrics are analyzed. For that, different objective quality metrics are compared between them, and the differences in their quality representation are studied. This provided a selection of the set of metrics used in this study, namely the point-to-plane, point-to-attribute, Point Cloud Structural Similarity, Point Cloud Quality Metric and Multiscale Graph Similarity. The features defined in those metrics are examined based on their contribution to the objective estimation using recursive feature elimination. To employ the recursive feature selection algorithm, both the support vector regression and the ridge regression algorithms were employed. For this study, the Broad Quality Assessment of Static Point Clouds in Compression Scenario database was used for both training and validation of the models. According to the recursive feature elimination, several features were selected and then combined using the regression method used to select those features. The best combination models were then evaluated across five different publicly available subjective quality assessment datasets, targeting different point cloud characteristics and distortions. It was concluded that a combination of features selected from the Point Cloud Quality Metric, Multiscale Graph Similarity and PSNR MSE D2, combined with Ridge Regression, results in the best performance. This model leads to the definition of the Feature Selection Model.

Paper number 40:
Title: Leveraging Network Topology in a Two-way Competition for Influence in the Friedkin-Johnsen Model
Authors: Aashi Shrinate, Twinkle Tripathy
Abstract: In this paper, we consider two stubborn agents who compete for `influence' over a strongly connected group of agents. This framework represents real-world contests, such as competition among firms, two-party elections, and sports rivalries, among others. Considering stubbornness of agents to be an immutable property, we utilise the network topology alone to increase the influence of a preferred stubborn agent. We demonstrate this on a special class of strongly connected networks by identifying the supporters of each of the stubborn agents in such networks. Thereafter, we present sufficient conditions under which a network perturbation always increases the influence of the preferred stubborn agent. A key advantage of the proposed topology-based conditions is that they hold independent of the edge weights in the network. Most importantly, we assert that there exists a sequence of perturbations that can make the lesser influential stubborn agent more influential. Finally, we demonstrate our results over the Sampson's Monastery dataset.

Paper number 41:
Title: Bifurcation analysis of an opinion dynamics model coupled with an environmental dynamics
Authors: Anthony Couthures, Anastasia Bizyaeva, Vineeth S. Varma, Alessio Franci, Irinel-Constantin Morarescu
Abstract: We consider an opinion dynamics model coupled with an environmental dynamics. Based on a forward invariance argument, we can simplify the analysis of the asymptotic behavior to the case when all the opinions in the social network are synchronized. Our goal is to emphasize the role of the trust given to the environmental signal in the asymptotic behavior of the opinion dynamics and implicitly of the coupled system. To do that, we conduct a bifurcation analysis of the system around the origin when the trust parameter is varying. Specific conditions are presented for both pitchfork and Hopf bifurcation. Numerical illustration completes the theoretical findings.

Paper number 42:
Title: Fair and Energy-Efficient Activation Control Mechanisms for Repeater-Assisted Massive MIMO
Authors: Ozan Alp Topal, Özlem Tuğfe Demir, Emil Björnson, Cicek Cavdar
Abstract: Massive multiple-input multiple-output (mMIMO) has been the core of 5G due to its ability to improve spectral efficiency and spatial multiplexing significantly; however, cell-edge users still experience performance degradation due to inter-cell interference and uneven signal distribution. While cell-free mMIMO (cfmMIMO) addresses this issue by providing uniform coverage through distributed antennas, it requires significantly more deployment cost due to the fronthaul and tight synchronization requirements. Alternatively, repeater-assisted massive MIMO (RA-MIMO) has recently been proposed to extend the coverage of cellular mMIMO by densely deploying low-cost single-antenna repeaters capable of amplifying and forwarding signals. In this work, we investigate amplification control for the repeaters for two different goals: (i) providing a fair performance among users, and (ii) reducing the extra energy consumption by the deployed repeaters. We propose a max-min amplification control algorithm using the convex-concave procedure for fairness and a joint sleep mode and amplification control algorithm for energy efficiency, comparing long- and short-term strategies. Numerical results show that RA-MIMO, with maximum amplification, improves signal-to-interference-plus-noise ratio (SINR) by over 20 dB compared to mMIMO and performs within 1 dB of cfmMIMO when deploying the same number of repeaters as access points in cfmMIMO. Additionally, our majority-rule-based long-term sleep mechanism reduces repeater power consumption by 70% while maintaining less than 1% spectral efficiency outage.

Paper number 43:
Title: Early detection of diabetes through transfer learning-based eye (vision) screening and improvement of machine learning model performance and advanced parameter setting algorithms
Authors: Mohammad Reza Yousefi, Ali Bakrani, Amin Dehghani
Abstract: Diabetic Retinopathy (DR) is a serious and common complication of diabetes, caused by prolonged high blood sugar levels that damage the small retinal blood vessels. If left untreated, DR can progress to retinal vein occlusion and stimulate abnormal blood vessel growth, significantly increasing the risk of blindness. Traditional diabetes diagnosis methods often utilize convolutional neural networks (CNNs) to extract visual features from retinal images, followed by classification algorithms such as decision trees and k-nearest neighbors (KNN) for disease detection. However, these approaches face several challenges, including low accuracy and sensitivity, lengthy machine learning (ML) model training due to high data complexity and volume, and the use of limited datasets for testing and evaluation. This study investigates the application of transfer learning (TL) to enhance ML model performance in DR detection. Key improvements include dimensionality reduction, optimized learning rate adjustments, and advanced parameter tuning algorithms, aimed at increasing efficiency and diagnostic accuracy. The proposed model achieved an overall accuracy of 84% on the testing dataset, outperforming prior studies. The highest class-specific accuracy reached 89%, with a maximum sensitivity of 97% and an F1-score of 92%, demonstrating strong performance in identifying DR cases. These findings suggest that TL-based DR screening is a promising approach for early diagnosis, enabling timely interventions to prevent vision loss and improve patient outcomes.

Paper number 44:
Title: Physics-informed 4D X-ray image reconstruction from ultra-sparse spatiotemporal data
Authors: Zisheng Yao, Yuhe Zhang, Zhe Hu, Robert Klöfkorn, Tobias Ritschel, Pablo Villanueva-Perez
Abstract: The unprecedented X-ray flux density provided by modern X-ray sources offers new spatiotemporal possibilities for X-ray imaging of fast dynamic processes. Approaches to exploit such possibilities often result in either i) a limited number of projections or spatial information due to limited scanning speed, as in time-resolved tomography, or ii) a limited number of time points, as in stroboscopic imaging, making the reconstruction problem ill-posed and unlikely to be solved by classical reconstruction approaches. 4D reconstruction from such data requires sample priors, which can be included via deep learning (DL). State-of-the-art 4D reconstruction methods for X-ray imaging combine the power of AI and the physics of X-ray propagation to tackle the challenge of sparse views. However, most approaches do not constrain the physics of the studied process, i.e., a full physical model. Here we present 4D physics-informed optimized neural implicit X-ray imaging (4D-PIONIX), a novel physics-informed 4D X-ray image reconstruction method combining the full physical model and a state-of-the-art DL-based reconstruction method for 4D X-ray imaging from sparse views. We demonstrate and evaluate the potential of our approach by retrieving 4D information from ultra-sparse spatiotemporal acquisitions of simulated binary droplet collisions, a relevant fluid dynamic process. We envision that this work will open new spatiotemporal possibilities for various 4D X-ray imaging modalities, such as time-resolved X-ray tomography and more novel sparse acquisition approaches like X-ray multi-projection imaging, which will pave the way for investigations of various rapid 4D dynamics, such as fluid dynamics and composite testing.

Paper number 45:
Title: State estimation for gas purity monitoring and control in water electrolysis systems
Authors: Lucas Cammann, Johannes Jäschke
Abstract: Green hydrogen, produced via water electrolysis using renewable energy, is seen as a cornerstone of the energy transition. Coupling of renewable power supplies to water electrolysis processes is, however, challenging, as explosive gas mixtures (hydrogen in oxygen) might form at low loads. This has prompted research into gas purity control of such systems. While these attempts have shown to be successful in theoretical and practical studies, they are currently limited in that they only consider the gas purity at locations where composition measurements are available. As these locations are generally positioned downstream of the disturbance origin, this incurs considerable delays and can lead to undetected critical conditions. In this work, we propose the use of an Extended Kalman Filter (EKF) in combination with a simple process model to estimate and control the gas composition at locations where measurements are not available. The model uses noise-driven states for the gas impurity and is hence agnostic towards any mechanistic disturbance model. We show in simulations that this simple approach performs well under various disturbance types and can reduce the time spent in potentially hazardous conditions by up to one order of magnitude.

Paper number 46:
Title: The Limits of "Fairness" of the Variational Generalized Nash Equilibrium
Authors: Sophie Hall, Florian Dörfler, Heinrich H. Nax, Saverio Bolognani
Abstract: Generalized Nash equilibrum (GNE) problems are commonly used to model strategic interactions between self-interested agents who are coupled in cost and constraints. Specifically, the variational GNE, a refinement of the GNE, is often selected as the solution concept due to it's non-discriminatory treatment of agents by charging a uniform ``shadow price" for shared resources. We study the fairness concept of v-GNEs from a comparability perspective and show that it makes an implicit assumption of unit comparability of agent's cost functions, one of the strongest comparability notions. Further, we introduce a new solution concept, f-GNE in which a fairness metric is chosen a priori which is compatible with the comparability at hand. We introduce an electric vehicle charging game to demonstrate the fragility of v-GNE fairness and compare it to the f-GNE under various fairness metrics.

Paper number 47:
Title: Lambda/6 Suspended Patch Antenna
Authors: Luca Giangrande
Abstract: This work introduces a novel, compact antenna design based on a lambda-6th suspended patch configuration that is particularly suited for small-size wireless sensor nodes. The proposed design meets key requirements such as compactness, omnidirectionality, robust source matching over a designated bandwidth, interference immunity, and low costs by evolving the conventional square patch antenna. With a footprint of only 20-by-20 mm, the antenna incorporates a grounded metal shield to both reduce its effective dimensions below one-half wavelength and mitigate interference from nearby circuitry. Simulation results, conducted on a cost-effective FR4 substrate, demonstrate a resonance at 2.45 GHz with a return loss of -32.5 dB and a bandwidth of 50 MHz (at the -10 dB level), making this design an attractive candidate for integration into densely populated wireless sensor networks.

Paper number 48:
Title: AdaViT: Adaptive Vision Transformer for Flexible Pretrain and Finetune with Variable 3D Medical Image Modalities
Authors: Badhan Kumar Das, Gengyan Zhao, Han Liu, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier
Abstract: Pretrain techniques, whether supervised or self-supervised, are widely used in deep learning to enhance model performance. In real-world clinical scenarios, different sets of magnetic resonance (MR) contrasts are often acquired for different subjects/cases, creating challenges for deep learning models assuming consistent input modalities among all the cases and between pretrain and finetune. Existing methods struggle to maintain performance when there is an input modality/contrast set mismatch with the pretrained model, often resulting in degraded accuracy. We propose an adaptive Vision Transformer (AdaViT) framework capable of handling variable set of input modalities for each case. We utilize a dynamic tokenizer to encode different input image modalities to tokens and take advantage of the characteristics of the transformer to build attention mechanism across variable length of tokens. Through extensive experiments, we demonstrate that this architecture effectively transfers supervised pretrained models to new datasets with different input modality/contrast sets, resulting in superior performance on zero-shot testing, few-shot finetuning, and backward transferring in brain infarct and brain tumor segmentation tasks. Additionally, for self-supervised pretrain, the proposed method is able to maximize the pretrain data and facilitate transferring to diverse downstream tasks with variable sets of input modalities.

Paper number 49:
Title: MedSAM2: Segment Anything in 3D Medical Images and Videos
Authors: Jun Ma, Zongxin Yang, Sumin Kim, Bihui Chen, Mohammed Baharoon, Adibvafa Fallahpour, Reza Asakereh, Hongwei Lyu, Bo Wang
Abstract: Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos with comprehensive user studies. Here, we present MedSAM2, a promptable segmentation foundation model for 3D image and video segmentation. The model is developed by fine-tuning the Segment Anything Model 2 on a large medical dataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming previous models across a wide range of organs, lesions, and imaging modalities. Furthermore, we implement a human-in-the-loop pipeline to facilitate the creation of large-scale datasets resulting in, to the best of our knowledge, the most extensive user study to date, involving the annotation of 5,000 CT lesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames, demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is also integrated into widely used platforms with user-friendly interfaces for local and cloud deployment, making it a practical tool for supporting efficient, scalable, and high-quality segmentation in both research and healthcare environments.

Paper number 50:
Title: A New Statistical Approach to Calibration-Free Localization Using Unlabeled Crowdsourced Data
Authors: Haozhou Hu, Harpreet S. Dhillon, R. Michael Buehrer
Abstract: Fingerprinting-based indoor localization methods typically require labor-intensive site surveys to collect signal measurements at known reference locations and frequent recalibration, which limits their scalability. This paper addresses these challenges by presenting a novel approach for indoor localization that utilizes crowdsourced data {\em without location labels}. We leverage the statistical information of crowdsourced data and propose a cumulative distribution function (CDF) based distance estimation method that maps received signal strength (RSS) to distances from access points. This approach overcomes the limitations of conventional distance estimation based on the empirical path loss model by efficiently capturing the impacts of shadow fading and multipath. Compared to fingerprinting, our {\em unsupervised} statistical approach eliminates the need for signal measurements at known reference locations. The estimated distances are then integrated into a three-step framework to determine the target location. The localization performance of our proposed method is evaluated using RSS data generated from ray-tracing simulations. Our results demonstrate significant improvements in localization accuracy compared to methods based on the empirical path loss model. Furthermore, our statistical approach, which relies on unlabeled data, achieves localization accuracy comparable to that of the {\em supervised} approach, the $k$-Nearest Neighbor ($k$NN) algorithm, which requires fingerprints with location labels. For reproducibility and future research, we make the ray-tracing dataset publicly available at [2].

Paper number 51:
Title: Modeling Charging Demand and Quantifying Flexibility Bounds for Large-Scale BEV Fleets
Authors: Maria Parajeles Herrera, Gabriela Hug
Abstract: This paper presents a bottom-up method to model baseline charging power demand and quantify available flexibility for large-scale BEV fleets. The method utilizes geographic and sociodemographic information to represent the fleet's mobility and driving energy needs. It models the charging decisions of drivers based on their driving energy needs and range comfort level using real-world data. The flexibility quantification provides an hourly maximum and minimum bound for the charging power and limits the amount of daily flexible charging energy. We apply the methodology to the future fully electrified fleet of Switzerland as a case study and compare the spatio-temporal characteristics of the charging demand and flexibility of different geographic areas and urbanization levels.

Paper number 52:
Title: On Word-of-Mouth and Private-Prior Sequential Social Learning
Authors: Andrea Da Col, Cristian R. Rojas, Vikram Krishnamurthy
Abstract: Social learning provides a fundamental framework in economics and social sciences for studying interactions among rational agents who observe each other's actions but lack direct access to individual beliefs. This paper investigates a specific social learning paradigm known as Word-of-Mouth (WoM), where a series of agents seeks to estimate the state of a dynamical system. The first agent receives noisy measurements of the state, while each subsequent agent relies solely on a degraded version of her predecessor's estimate. A defining feature of WoM is that the final agent's belief is publicly broadcast and adopted by all agents, in place of their own. We analyze this setting both theoretically and through numerical simulations, showing that some agents benefit from using the public belief broadcast by the last agent, while others suffer from performance deterioration.

Paper number 53:
Title: Low-Complexity Permutational Index Modulation for Noncoherent Massive SIMO Communications
Authors: Marc Vilà-Insa, Aniol Martí, Meritxell Lamarca, Jaume Riba
Abstract: This work presents a massive SIMO scheme for wireless communications with one-shot noncoherent detection. It is based on permutational index modulation over OFDM. Its core principle is to convey information on the ordering in which a fixed collection of values is mapped onto a set of OFDM subcarriers. A spherical code is obtained which provides improved robustness against channel impairments. A simple detector based on the sorting of quadratic metrics of data is proposed. By exploiting statistical channel state information and hardening, it reaches a near-ML error performance with a low-complexity implementation.

Paper number 54:
Title: High-resolution and ultra-low power nonlinear image processing with passive high-quality factor metasurfaces
Authors: Bo Zhao, Lin Lin, Ameyaw Samuel, Mark Lawrence
Abstract: Image processing is both one of the most exciting domains for applying artificial intelligence and the most computationally expensive. Nanostructured metasurfaces have opened the door to the ultimate energy saving by directly processing ambient image data via ultra-thin layers before detection. However, a key ingredient of universal computation - nonlinear thresholding functions - have yet to be demonstrated for low intensities without an external power source. Here, we present a passive, all-optical method for nonlinear image processing using Silicon nanoantenna arrays. We experimentally demonstrate an intensity thresholding filter capable of processing one-dimensional images with only Watt-level power. By leveraging the opto-thermal Kerr nonlinearity through high-Q guided mode resonance, we achieve an experimental threshold as low as 0.1 mW/{\mu}m^2 with a spatial resolution of 1.85 {\mu}m. Additional simulations indicate that the threshold can be further reduced while maintaining high spatial selectivity. Analog, pixel-wise, smoothed leaky ReLU activation filters promise to revolutionize image sensing.

Paper number 55:
Title: Generating Diverse Audio-Visual 360 Soundscapes for Sound Event Localization and Detection
Authors: Adrian S. Roman, Aiden Chang, Gerardo Meza, Iran R. Roman
Abstract: We present SELDVisualSynth, a tool for generating synthetic videos for audio-visual sound event localization and detection (SELD). Our approach incorporates real-world background images to improve realism in synthetic audio-visual SELD data while also ensuring audio-visual spatial alignment. The tool creates 360 synthetic videos where objects move matching synthetic SELD audio data and its annotations. Experimental results demonstrate that a model trained with this data attains performance gains across multiple metrics, achieving superior localization recall (56.4 LR) and competitive localization error (21.9deg LE). We open-source our data generation tool for maximal use by members of the SELD research community.

Paper number 56:
Title: Autonomy Architectures for Safe Planning in Unknown Environments Under Budget Constraints
Authors: Daniel M. Cherenson, Devansh R. Agrawal, Dimitra Panagou
Abstract: Mission planning can often be formulated as a constrained control problem under multiple path constraints (i.e., safety constraints) and budget constraints (i.e., resource expenditure constraints). In a priori unknown environments, verifying that an offline solution will satisfy the constraints for all time can be difficult, if not impossible. Our contributions are as follows: 1) We propose an online method, building on our previous work "gatekeeper", to guarantee safety and satisfy budget constraints of the system trajectory at all times throughout a mission. 2) Next, we prove that our algorithm is recursively feasible and correct. 3) Finally, instead of using a heuristically designed backup controller, we propose a sampling-based method to construct backup trajectories that both minimize resource expenditure and reach budget renewal sets, in which path constraints are satisfied and the constrained resources are renewed. We demonstrate our approach in simulation with a fixed-wing UAV in a GNSS-denied environment with a budget constraint on localization error that can be renewed at visual landmarks.

Paper number 57:
Title: How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane
Authors: Taekyung Kim, Randal W. Beard, Dimitra Panagou
Abstract: In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.

Paper number 58:
Title: Statics of continuum planar grasping
Authors: Udit Halder
Abstract: Continuum robotic grasping, inspired by biological appendages such as octopus arms and elephant trunks, provides a versatile and adaptive approach to object manipulation. Unlike conventional rigid-body grasping, continuum robots leverage distributed compliance and whole-body contact to achieve robust and dexterous grasping. This paper presents a control-theoretic framework for analyzing the statics of continuous contact with a planar object. The governing equations of static equilibrium of the object are formulated as a linear control system, where the distributed contact forces act as control inputs. To optimize the grasping performance, a constrained optimal control problem is posed to minimize contact forces required to achieve a static grasp, with solutions derived using the Pontryagin Maximum Principle. Furthermore, two optimization problems are introduced: (i) for assigning a measure to the quality of a particular grasp, which generalizes a (rigid-body) grasp quality metric in the continuum case, and (ii) for finding the best grasping configuration that maximizes the continuum grasp quality. Several numerical results are also provided to elucidate our methods.

Paper number 59:
Title: GraphSeg: Segmented 3D Representations via Graph Edge Addition and Contraction
Authors: Haozhan Tang, Tianyi Zhang, Oliver Kroemer, Matthew Johnson-Roberson, Weiming Zhi
Abstract: Robots operating in unstructured environments often require accurate and consistent object-level representations. This typically requires segmenting individual objects from the robot's surroundings. While recent large models such as Segment Anything (SAM) offer strong performance in 2D image segmentation. These advances do not translate directly to performance in the physical 3D world, where they often over-segment objects and fail to produce consistent mask correspondences across views. In this paper, we present GraphSeg, a framework for generating consistent 3D object segmentations from a sparse set of 2D images of the environment without any depth information. GraphSeg adds edges to graphs and constructs dual correspondence graphs: one from 2D pixel-level similarities and one from inferred 3D structure. We formulate segmentation as a problem of edge addition, then subsequent graph contraction, which merges multiple 2D masks into unified object-level segmentations. We can then leverage \emph{3D foundation models} to produce segmented 3D representations. GraphSeg achieves robust segmentation with significantly fewer images and greater accuracy than prior methods. We demonstrate state-of-the-art performance on tabletop scenes and show that GraphSeg enables improved performance on downstream robotic manipulation tasks. Code available at this https URL.

Paper number 60:
Title: The Ground Cost for Optimal Transport of Angular Velocity
Authors: Karthik Elamvazhuthi, Abhishek Halder
Abstract: We revisit the optimal transport problem over angular velocity dynamics given by the controlled Euler equation. The solution of this problem enables stochastic guidance of spin states of a rigid body (e.g., spacecraft) over hard deadline constraint by transferring a given initial state statistics to a desired terminal state statistics. This is an instance of generalized optimal transport over a nonlinear dynamical system. While prior work has reported existence-uniqueness and numerical solution of this dynamical optimal transport problem, here we present structural results about the equivalent Kantorovich a.k.a. optimal coupling formulation. Specifically, we focus on deriving the ground cost for the associated Kantorovich optimal coupling formulation. The ground cost equals to the cost of transporting unit amount of mass from a specific realization of the initial or source joint probability measure to a realization of the terminal or target joint probability measure, and determines the Kantorovich formulation. Finding the ground cost leads to solving a structured deterministic nonlinear optimal control problem, which is shown to be amenable to an analysis technique pioneered by Athans et. al. We show that such techniques have broader applicability in determining the ground cost (thus Kantorovich formulation) for a class of generalized optimal mass transport problems involving nonlinear dynamics with translated norm-invariant drift.

Paper number 61:
Title: BondMatcher: H-Bond Stability Analysis in Molecular Systems
Authors: Thomas Daniel, Malgorzata Olejniczak, Julien Tierny
Abstract: This application paper investigates the stability of hydrogen bonds (H-bonds), as characterized by the Quantum Theory of Atoms in Molecules (QTAIM). First, we contribute a database of 4544 electron densities associated to four isomers of water hexamers (the so-called Ring, Book, Cage and Prism), generated by distorting their equilibrium geometry under various structural perturbations, modeling the natural dynamic behavior of molecular systems. Second, we present a new stability measure, called bond occurrence rate, associating each bond path present at equilibrium with its rate of occurrence within the input ensemble. We also provide an algorithm, called BondMatcher, for its automatic computation, based on a tailored, geometry-aware partial isomorphism estimation between the extremum graphs of the considered electron densities. Our new stability measure allows for the automatic identification of densities lacking H-bond paths, enabling further visual inspections. Specifically, the topological analysis enabled by our framework corroborates experimental observations and provides refined geometrical criteria for characterizing the disappearance of H-bond paths. Our electron density database and our C++ implementation are available at this address: this https URL.

Paper number 62:
Title: Linear Stability Analysis of a Constant Quaternion Difference Attitude Controller
Authors: Yujendra Mitikiri
Abstract: It is quite often claimed, and correctly so, that linear methods cannot achieve global stability results for attitude control, and conversely that nonlinear control is essential in order to achieve (almost) globally stable tracking of general attitude trajectories. On account of this definitive result, and also because of the existence of powerful nonlinear control techniques, there has been relatively very little work analyzing the limits and performance of linear attitude control. It is the purpose of this paper to provide a characterization of the stability achievable for one class of linear attitude control problems, namely those leading to a constant quaternion difference. In this paper, we analytically derive a critical error angle below which linearized dynamics lead to natural marginal stability for such a system, and above which the system is unstable. The dynamics are then used to derive a locally stable linear attitude controller whose performance is validated using simulations.

Paper number 63:
Title: Space-Time Encoded Modulation for High-Fidelity Diffuse Optical Imaging
Authors: Ben Wiesel, Shlomi Arnon
Abstract: Diffuse optical imaging (DOI) offers valuable insights into scattering mediums, but the quest for high-resolution imaging often requires dense sampling strategies, leading to higher imaging errors and lengthy acquisition times. This work introduces Space-Time Encoded Modulation (STEM), a novel light modulation scheme enabling low-noise, high-resolution imaging with single-pixel detectors. In STEM, a laser illuminates the sample, and the transmitted light is detected using a single pixel detector. The detected image is partitioned into a two-dimensional array of sub-images, each encoded with a unique quasi-orthogonal code. These coded sub-images represent light transmission at specific locations along the sample boundary. A single-pixel detector then measures their combined transmission. By virtue of their quasi-orthogonality, the relative strength of each sub-image can be measured, enabling image formation. In this paper, we present a comprehensive mathematical description and experimental validation of the STEM method. Compared to traditional raster scanning, STEM significantly enhances imaging quality, reducing imaging errors by up to 60% and yielding a 3.5-fold increase in reconstruction contrast.

Paper number 64:
Title: Gradient Field-Based Dynamic Window Approach for Collision Avoidance in Complex Environments
Authors: Ze Zhang, Yifan Xue, Nadia Figueroa, Knut Åkesson
Abstract: For safe and flexible navigation in multi-robot systems, this paper presents an enhanced and predictive sampling-based trajectory planning approach in complex environments, the Gradient Field-based Dynamic Window Approach (GF-DWA). Building upon the dynamic window approach, the proposed method utilizes gradient information of obstacle distances as a new cost term to anticipate potential collisions. This enhancement enables the robot to improve awareness of obstacles, including those with non-convex shapes. The gradient field is derived from the Gaussian process distance field, which generates both the distance field and gradient field by leveraging Gaussian process regression to model the spatial structure of the environment. Through several obstacle avoidance and fleet collision avoidance scenarios, the proposed GF-DWA is shown to outperform other popular trajectory planning and control methods in terms of safety and flexibility, especially in complex environments with non-convex obstacles.

Paper number 65:
Title: Dynamic Objective MPC for Motion Planning of Seamless Docking Maneuvers
Authors: Oliver Schumann, Michael Buchholz, Klaus Dietmayer
Abstract: Automated vehicles and logistics robots must often position themselves in narrow environments with high precision in front of a specific target, such as a package or their charging station. Often, these docking scenarios are solved in two steps: path following and rough positioning followed by a high-precision motion planning algorithm. This can generate suboptimal trajectories caused by bad positioning in the first phase and, therefore, prolong the time it takes to reach the goal. In this work, we propose a unified approach, which is based on a Model Predictive Control (MPC) that unifies the advantages of Model Predictive Contouring Control (MPCC) with a Cartesian MPC to reach a specific goal pose. The paper's main contributions are the adaption of the dynamic weight allocation method to reach path ends and goal poses inside driving corridors, and the development of the so-called dynamic objective MPC. The latter is an improvement of the dynamic weight allocation method, which can inherently switch state-dependent from an MPCC to a Cartesian MPC to solve the path-following problem and the high-precision positioning tasks independently of the location of the goal pose seamlessly by one algorithm. This leads to foresighted, feasible, and safe motion plans, which can decrease the mission time and result in smoother trajectories.

Paper number 66:
Title: RWKVTTS: Yet another TTS based on RWKV-7
Authors: Lin yueyu, Liu Xiao
Abstract: Human-AI interaction thrives on intuitive and efficient interfaces, among which voice stands out as a particularly natural and accessible modality. Recent advancements in transformer-based text-to-speech (TTS) systems, such as Fish-Speech, CosyVoice, and MegaTTS 3, have delivered remarkable improvements in quality and realism, driving a significant evolution in the TTS domain. In this paper, we introduce RWKV-7 \cite{peng2025rwkv}, a cutting-edge RNN-based architecture tailored for TTS applications. Unlike traditional transformer models, RWKV-7 leverages the strengths of recurrent neural networks to achieve greater computational efficiency and scalability, while maintaining high-quality output. Our comprehensive benchmarks demonstrate that RWKV-7 outperforms transformer-based models across multiple key metrics, including synthesis speed, naturalness of speech, and resource efficiency. Furthermore, we explore its adaptability to diverse linguistic contexts and low-resource environments, showcasing its potential to democratize TTS technology. These findings position RWKV-7 as a powerful and innovative alternative, paving the way for more accessible and versatile voice synthesis solutions in real-world this http URL code and weights are this https URL, this https URL

Paper number 67:
Title: An Efficient GPU-based Implementation for Noise Robust Sound Source Localization
Authors: Zirui Lin, Masayuki Takigahira, Naoya Terakado, Haris Gulzar, Monikka Roslianna Busto, Takeharu Eda, Katsutoshi Itoyama, Kazuhiro Nakadai, Hideharu Amano
Abstract: Robot audition, encompassing Sound Source Localization (SSL), Sound Source Separation (SSS), and Automatic Speech Recognition (ASR), enables robots and smart devices to acquire auditory capabilities similar to human hearing. Despite their wide applicability, processing multi-channel audio signals from microphone arrays in SSL involves computationally intensive matrix operations, which can hinder efficient deployment on Central Processing Units (CPUs), particularly in embedded systems with limited CPU resources. This paper introduces a GPU-based implementation of SSL for robot audition, utilizing the Generalized Singular Value Decomposition-based Multiple Signal Classification (GSVD-MUSIC), a noise-robust algorithm, within the HARK platform, an open-source software suite. For a 60-channel microphone array, the proposed implementation achieves significant performance improvements. On the Jetson AGX Orin, an embedded device powered by an NVIDIA GPU and ARM Cortex-A78AE v8.2 64-bit CPUs, we observe speedups of 4645.1x for GSVD calculations and 8.8x for the SSL module, while speedups of 2223.4x for GSVD calculation and 8.95x for the entire SSL module on a server configured with an NVIDIA A100 GPU and AMD EPYC 7352 CPUs, making real-time processing feasible for large-scale microphone arrays and providing ample capacity for real-time processing of potential subsequent machine learning or deep learning tasks.

Paper number 68:
Title: Probabilistic Reachable Set Estimation for Saturated Systems with Unbounded Additive Disturbances
Authors: Carlo Karam, Matteo Tacchi-Bénard, Mirko Fiacchini
Abstract: In this paper, we present an analytical approach for the synthesis of ellipsoidal probabilistic reachable sets of saturated systems subject to unbounded additive noise. Using convex optimization methods, we compute a contraction factor of the saturated error dynamics that allows us to tightly bound its evolution and therefore construct accurate reachable sets. The proposed approach is applicable to independent, zero mean disturbances with a known covariance. A numerical example illustrates the applicability and effectiveness of the proposed design.

Paper number 69:
Title: MultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation
Authors: Khai Le-Duc, Tuyen Tran, Bach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo, Nguyen X. Khanh, Thanh Nguyen-Tang
Abstract: Multilingual speech translation (ST) in the medical domain enhances patient care by enabling efficient communication across language barriers, alleviating specialized workforce shortages, and facilitating improved diagnosis and treatment, particularly during pandemics. In this work, we present the first systematic study on medical ST, to our best knowledge, by releasing MultiMed-ST, a large-scale ST dataset for the medical domain, spanning all translation directions in five languages: Vietnamese, English, German, French, Traditional Chinese and Simplified Chinese, together with the models. With 290,000 samples, our dataset is the largest medical machine translation (MT) dataset and the largest many-to-many multilingual ST among all domains. Secondly, we present the most extensive analysis study in ST research to date, including: empirical baselines, bilingual-multilingual comparative study, end-to-end vs. cascaded comparative study, task-specific vs. multi-task sequence-to-sequence (seq2seq) comparative study, code-switch analysis, and quantitative-qualitative error analysis. All code, data, and models are available online: this https URL.

Paper number 70:
Title: Scalable Hypergraph Structure Learning with Diverse Smoothness Priors
Authors: Benjamin T. Brown, Haoxiang Zhang, Daniel L. Lau, Gonzalo R. Arce
Abstract: In graph signal processing, learning the weighted connections between nodes from a set of sample signals is a fundamental task when the underlying relationships are not known a priori. This task is typically addressed by finding a graph Laplacian on which the observed signals are smooth. With the extension of graphs to hypergraphs - where edges can connect more than two nodes - graph learning methods have similarly been generalized to hypergraphs. However, the absence of a unified framework for calculating total variation has led to divergent definitions of smoothness and, consequently, differing approaches to hyperedge recovery. We confront this challenge through generalization of several previously proposed hypergraph total variations, subsequently allowing ease of substitution into a vector based optimization. To this end, we propose a novel hypergraph learning method that recovers a hypergraph topology from time-series signals based on a smoothness prior. Our approach addresses key limitations in prior works, such as hyperedge selection and convergence issues, by formulating the problem as a convex optimization solved via a forward-backward-forward algorithm, ensuring guaranteed convergence. Additionally, we introduce a process that simultaneously limits the span of the hyperedge search and maintains a valid hyperedge selection set. In doing so, our method becomes scalable in increasingly complex network structures. The experimental results demonstrate improved performance, in terms of accuracy, over other state-of-the-art hypergraph inference methods; furthermore, we empirically show our method to be robust to total variation terms, biased towards global smoothness, and scalable to larger hypergraphs.

Paper number 71:
Title: Reciprocity-Aware Convolutional Neural Networks for Map-Based Path Loss Prediction
Authors: Ryan G. Dempsey, Jonathan Ethier, Halim Yanikomeroglu
Abstract: Path loss modeling is a widely used technique for estimating point-to-point losses along a communications link from transmitter (Tx) to receiver (Rx). Accurate path loss predictions can optimize use of the radio frequency spectrum and minimize unwanted interference. Modern path loss modeling often leverages data-driven approaches, using machine learning to train models on drive test measurement datasets. Drive tests primarily represent downlink scenarios, where the Tx is located on a building and the Rx is located on a moving vehicle. Consequently, trained models are frequently reserved for downlink coverage estimation, lacking representation of uplink scenarios. In this paper, we demonstrate that data augmentation can be used to train a path loss model that is generalized to uplink, downlink, and backhaul scenarios, training using only downlink drive test measurements. By adding a small number of synthetic samples representing uplink scenarios to the training set, root mean squared error is reduced by >8 dB on uplink examples in the test set.

Paper number 72:
Title: Event-Triggered Polynomial Control for Trajectory Tracking by Unicycle Robots
Authors: Harini V, Anusree Rajan, Bharadwaj Amrutur, Pavankumar Tallapragada
Abstract: This paper proposes an event-triggered polynomial control method for trajectory tracking by unicycle robots. In this method, each control input between two consecutive events is a polynomial and its coefficients are chosen to minimize the error in approximating a continuous-time control signal. We design an event-triggering rule that guarantees uniform ultimate boundedness of the tracking error and non-Zeno behavior of inter-event times. We illustrate our results through a suite of numerical simulations and experiments, which indicate that the number of events generated by the proposed controller is significantly less compared to that by a time-triggered controller or a event-triggered controller based on zero-order hold while guaranteeing similar tracking performance.

Paper number 73:
Title: Virtual Lung Screening Trial (VLST): An In Silico Study Inspired by the National Lung Screening Trial for Lung Cancer Detection
Authors: Fakrul Islam Tushar, Liesbeth Vancoillie, Cindy McCabe, Amareswararao Kavuri, Lavsen Dahal, Brian Harrawood, Milo Fryling, Mojtaba Zarei, Saman Sotoudeh-Paima, Fong Chi Ho, Dhrubajyoti Ghosh, Michael R. Harowicz, Tina D. Tailor, Sheng Luo, W. Paul Segars, Ehsan Abadi, Kyle J. Lafata, Joseph Y. Lo, Ehsan Samei
Abstract: Clinical imaging trials play a crucial role in advancing medical innovation but are often costly, inefficient, and ethically constrained. Virtual Imaging Trials (VITs) present a solution by simulating clinical trial components in a controlled, risk-free environment. The Virtual Lung Screening Trial (VLST), an in silico study inspired by the National Lung Screening Trial (NLST), illustrates the potential of VITs to expedite clinical trials, minimize risks to participants, and promote optimal use of imaging technologies in healthcare. This study aimed to show that a virtual imaging trial platform could investigate some key elements of a major clinical trial, specifically the NLST, which compared Computed tomography (CT) and chest radiography (CXR) for lung cancer screening. With simulated cancerous lung nodules, a virtual patient cohort of 294 subjects was created using XCAT human models. Each virtual patient underwent both CT and CXR imaging, with deep learning models, the AI CT-Reader and AI CXR-Reader, acting as virtual readers to perform recall patients with suspicion of lung cancer. The primary outcome was the difference in diagnostic performance between CT and CXR, measured by the Area Under the Curve (AUC). The AI CT-Reader showed superior diagnostic accuracy, achieving an AUC of 0.92 (95% CI: 0.90-0.95) compared to the AI CXR-Reader's AUC of 0.72 (95% CI: 0.67-0.77). Furthermore, at the same 94% CT sensitivity reported by the NLST, the VLST specificity of 73% was similar to the NLST specificity of 73.4%. This CT performance highlights the potential of VITs to replicate certain aspects of clinical trials effectively, paving the way toward a safe and efficient method for advancing imaging-based diagnostics.

Paper number 74:
Title: Showcasing Automated Vehicle Prototypes: A Collaborative Release Process to Manage and Communicate Risk
Authors: Marvin Loba, Robert Graubohm, Markus Maurer
Abstract: The development and deployment of automated vehicles pose major challenges for manufacturers to this day. Whilst central questions, like the issue of ensuring a sufficient level of safety, remain unanswered, prototypes are increasingly finding their way into public traffic in urban areas. Although safety concepts for prototypes are addressed in literature, published work hardly contains any dedicated considerations on a systematic release for their operation. In this paper, we propose an incremental release process for public demonstrations of prototypes' automated driving functionality. We explicate release process requirements, derive process design decisions, and define stakeholder tasks. Furthermore, we reflect on practical insights gained through implementing the release process as part of the UNICAR$agil$ research project, in which four prototypes based on novel vehicle concepts were built and demonstrated to the public. One observation is the improved quality of internal risk communication, achieved by dismantling information asymmetries between stakeholders. Design conflicts are disclosed - providing a contribution to nurture transparency and, thereby, supporting a valid basis for release decisions. We argue that our release process meets two important requirements, as the results suggest its applicability to the domain of automated driving and its scalability to different vehicle concepts and organizational structures.

Paper number 75:
Title: Semi-Supervised Model-Free Bayesian State Estimation from Compressed Measurements
Authors: Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee
Abstract: We consider data-driven Bayesian state estimation from compressed measurements (BSCM) of a model-free process. The dimension of the temporal measurement vector is lower than that of the temporal state vector to be estimated, leading to an under-determined inverse problem. The underlying dynamical model of the state's evolution is unknown for a 'model-free process.' Hence, it is difficult to use traditional model-driven methods, for example, Kalman and particle filters. Instead, we consider data-driven methods. We experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem in a model-free process. The methods are -- data-driven nonlinear state estimation (DANSE) and deep Markov model (DMM). While DANSE provides good predictive/forecasting performance to model the temporal measurement data as a time series, its unsupervised learning lacks suitable regularization for tackling the BSCM task. We then propose a semi-supervised learning approach and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a large amount of unlabelled data along with a limited amount of labelled data, i.e., pairwise measurement-and-state data, which provides the desired regularization. Using three benchmark dynamical systems, we show that the data-driven SemiDANSE provides competitive state estimation performance for BSCM against a hybrid method called KalmanNet and two model-driven methods (extended Kalman filter and unscented Kalman filter) that know the dynamical models exactly.

Paper number 76:
Title: A Unified Model for Compressed Sensing MRI Across Undersampling Patterns
Authors: Armeet Singh Jatyani, Jiayun Wang, Aditi Chandrashekar, Zihui Wu, Miguel Liu-Schiaffini, Bahareh Tolooshams, Anima Anandkumar
Abstract: Compressed Sensing MRI reconstructs images of the body's internal anatomy from undersampled measurements, thereby reducing scan time. Recently, deep learning has shown great potential for reconstructing high-fidelity images from highly undersampled measurements. However, one needs to train multiple models for different undersampling patterns and desired output image resolutions, since most networks operate on a fixed discretization. Such approaches are highly impractical in clinical settings, where undersampling patterns and image resolutions are frequently changed to accommodate different real-time imaging and diagnostic requirements. We propose a unified MRI reconstruction model robust to various measurement undersampling patterns and image resolutions. Our approach uses neural operators, a discretization-agnostic architecture applied in both image and measurement spaces, to capture local and global features. Empirically, our model improves SSIM by 11% and PSNR by 4 dB over a state-of-the-art CNN (End-to-End VarNet), with 600$\times$ faster inference than diffusion methods. The resolution-agnostic design also enables zero-shot super-resolution and extended field-of-view reconstruction, offering a versatile and efficient solution for clinical MR imaging. Our unified model offers a versatile solution for MRI, adapting seamlessly to various measurement undersampling and imaging resolutions, making it highly effective for flexible and reliable clinical imaging. Our code is available at this https URL.

Paper number 77:
Title: Deep Learning-Assisted Jamming Mitigation with Movable Antenna Array
Authors: Xiao Tang, Yudan Jiang, Jinxin Liu, Qinghe Du, Dusit Niyato, Zhu Han
Abstract: This paper reveals the potential of movable antennas in enhancing anti-jamming communication. We consider a legitimate communication link in the presence of multiple jammers and propose deploying a movable antenna array at the receiver to combat jamming attacks. We formulate the problem as a signal-to-interference-plus-noise ratio maximization, by jointly optimizing the receive beamforming and antenna element positioning. Due to the non-convexity and multi-fold difficulties from an optimization perspective, we develop a deep learning-based framework where beamforming is tackled as a Rayleigh quotient problem, while antenna positioning is addressed through multi-layer perceptron training. The neural network parameters are optimized using stochastic gradient descent to achieve effective jamming mitigation strategy, featuring offline training with marginal complexity for online inference. Numerical results demonstrate that the proposed approach achieves near-optimal anti-jamming performance thereby significantly improving the efficiency in strategy determination.

Paper number 78:
Title: HeartBERT: A Self-Supervised ECG Embedding Model for Efficient and Effective Medical Signal Analysis
Authors: Saedeh Tahery, Fatemeh Hamid Akhlaghi, Termeh Amirsoleimani
Abstract: The HeartBert model is introduced with three primary objectives: reducing the need for labeled data, minimizing computational resources, and simultaneously improving performance in machine learning systems that analyze Electrocardiogram (ECG) signals. Inspired by Bidirectional Encoder Representations from Transformers (BERT) in natural language processing and enhanced with a self-supervised learning approach, the HeartBert model-built on the RoBERTa architecture-generates sophisticated embeddings tailored for ECG-based projects in the medical domain. To demonstrate the versatility, generalizability, and efficiency of the proposed model, two key downstream tasks have been selected: sleep stage detection and heartbeat classification. HeartBERT-based systems, utilizing bidirectional LSTM heads, are designed to address complex challenges. A series of practical experiments have been conducted to demonstrate the superiority and advancements of HeartBERT, particularly in terms of its ability to perform well with smaller training datasets, reduced learning parameters, and effective performance compared to rival models. The code and data are publicly available at this https URL.

Paper number 79:
Title: Rethinking domain generalization in medical image segmentation: One image as one domain
Authors: Jin Hong, Bo Liu, Guoli Long, Siyue Li, Khan Muhammad
Abstract: Domain shifts in medical image segmentation, particularly when data comes from different centers, pose significant challenges. Intra-center variability, such as differences in scanner models or imaging protocols, can cause domain shifts as large as, or even larger than, those between centers. To address this, we propose the "one image as one domain" (OIOD) hypothesis, which treats each image as a unique domain, enabling flexible and robust domain generalization. Based on this hypothesis, we develop a unified disentanglement-based domain generalization (UniDDG) framework, which simultaneously handles both multi-source and single-source domain generalization without requiring explicit domain labels. This approach simplifies training with a fixed architecture, independent of the number of source domains, reducing complexity and enhancing scalability. We decouple each input image into content representation and style code, then exchange and combine these within the batch for segmentation, reconstruction, and further disentanglement. By maintaining distinct style codes for each image, our model ensures thorough decoupling of content representations and style codes, improving domain invariance of the content representations. Additionally, we enhance generalization with expansion mask attention (EMA) for boundary preservation and style augmentation (SA) to simulate diverse image styles, improving robustness to domain shifts. Extensive experiments show that our method achieves Dice scores of 84.43% and 88.91% for multi-source to single-center and single-center generalization in optic disc and optic cup segmentation, respectively, and 86.96% and 88.56% for prostate segmentation, outperforming current state-of-the-art domain generalization methods, offering superior performance and adaptability across clinical settings.

Paper number 80:
Title: A 2-6 GHz Ultra-Wideband CMOS Transceiver for Radar Applications
Authors: Alin Thomas Tharakan, Prince Phillip, Gokulan T, Sumit Kumar, Gaurab Banerjee
Abstract: This paper presents a low power, low cost transceiver architecture to implement radar-on-a-chip. The transceiver comprises of a full ultra-wideband (UWB) transmitter and a full UWB band receiver. A design methodology to maximize the tuning range of the voltage-controlled oscillator (VCO) is presented. At the transmitter side, a sub-harmonic mixer is used for signal up-conversion. The receiver low noise amplifier (LNA) has a 2 to 6 GHz input matching bandwidth with a power gain of 9 dB and a noise figure of 2.5 dB. The transceiver is implemented in Cadence EDA tools using 65nm CMOS technology. The system achieves a total dc power consumption of 50 mW. Good noise figure performance; good wide-band matching; gain; high level of integration; low power; low cost of the proposed UWB radar transceiver front-end make it a highly competitive SoC solution for low power UWB transceivers.

Paper number 81:
Title: Lightweight Learning for Grant-Free Activity Detection in Cell-Free Massive MIMO Networks
Authors: Ali Elkeshawy, Haifa Fares, Amor Nafkha
Abstract: Grant-free random access (GF-RA) is a promising access technique for massive machine-type communications (mMTC) in future wireless networks, particularly in the context of 5G and beyond (6G) systems. Within the context of GF-RA, this study investigates the efficiency of employing supervised machine learning techniques to tackle the challenges on the device activity detection (AD). GF-RA addresses scalability by employing non-orthogonal pilot sequences, which provides an efficient alternative comparing to conventional grant-based random access (GB-RA) technique that are constrained by the scarcity of orthogonal preamble resources. In this paper, we propose a novel lightweight data-driven algorithmic framework specifically designed for activity detection in GF-RA for mMTC in cell-free massive multiple-input multiple-output (CF-mMIMO) networks. We propose two distinct framework deployment strategies, centralized and decentralized, both tailored to streamline the proposed approach implementation across network infrastructures. Moreover, we introduce optimized post-detection methodologies complemented by a clustering stage to enhance overall detection performances. Our 3GPP-compliant simulations have validated that the proposed algorithm achieves state-of-the-art model-based activity detection accuracy while significantly reducing complexity. Achieving 99% accuracy, it demonstrates real-world viability and effectiveness.

Paper number 82:
Title: Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life
Authors: Jingyuan Xue, Longfei Wei, Fang Sheng, Jianfei Zhang
Abstract: Battery degradation significantly impacts the reliability and efficiency of energy storage systems, particularly in electric vehicles (EVs) and industrial applications. Predicting the remaining useful life (RUL) of lithium-ion (Li-ion) batteries is crucial for optimizing maintenance schedules, reducing costs, and improving safety. Traditional RUL prediction methods often struggle with nonlinear degradation patterns and uncertainty quantification. To address these challenges, we propose a hybrid survival analysis framework integrating both statistical and machine-learning-based models for RUL estimation. Our approach transforms time-series battery data into time-to-failure data using path signatures, enabling effective survival modeling. We apply five models, including Cox-based survival models and machine-learning-based methods such as DeepHit and MTLR, to estimate failure-free probabilities over time. Experiments conducted on 362 Toyota battery datasets demonstrate the effectiveness of our approach, achieving high time-dependent AUC and concordance index while maintaining a low integrated Brier score. The proposed methodology provides actionable insights for battery manufacturers and engineers, supporting dynamic maintenance strategies and optimized lifecycle management.

Paper number 83:
Title: Quattro: Transformer-Accelerated Iterative Linear Quadratic Regulator Framework for Fast Trajectory Optimization
Authors: Yue Wang, Haoyu Wang, Zhaoxing Li
Abstract: Real-time optimal control remains a fundamental challenge in robotics, especially for nonlinear systems with stringent performance requirements. As one of the representative trajectory optimization algorithms, the iterative Linear Quadratic Regulator (iLQR) faces limitations due to their inherently sequential computational nature, which restricts the efficiency and applicability of real-time control for robotic systems. While existing parallel implementations aim to overcome the above limitations, they typically demand additional computational iterations and high-performance hardware, leading to only modest practical improvements. In this paper, we introduce Quattro, a transformer-accelerated iLQR framework employing an algorithm-hardware co-design strategy to predict intermediate feedback and feedforward matrices. It facilitates effective parallel computations on resource-constrained devices without sacrificing accuracy. Experiments on cart-pole and quadrotor systems show an algorithm-level acceleration of up to 5.3$\times$ and 27$\times$ per iteration, respectively. When integrated into a Model Predictive Control (MPC) framework, Quattro achieves overall speedups of 2.8$\times$ for the cart-pole and 17.8$\times$ for the quadrotor compared to the one that applies traditional iLQR. Transformer inference is deployed on FPGA to maximize performance, achieving further up to 20.8$\times$ speedup over prevalent embedded CPUs with over 11$\times$ power reduction than GPU and low hardware resource overhead.

Paper number 84:
Title: Controlled Social Learning: Altruism vs. Bias
Authors: Raghu Arghal, Kevin He, Shirin Saeedi Bidokhti, Saswati Sarkar
Abstract: We introduce a model of controlled sequential social learning in which a planner may pay a cost to adjust the private information structure of agents. The planner may seek to induce correct actions that are consistent with an unknown true state of the world (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates. This sheds light on practical policy questions, such as how the socially optimal level of ad personalization changes according to current beliefs or how a political campaign may selectively illuminate or obfuscate the winning potential of its candidate among voters. We then prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from the choices they induce in the agents. Even for a planner who has equivalent knowledge to an individual, cannot lie or cherry-pick information, and is fully observable, we demonstrate that it is possible to dramatically influence social welfare in both positive and negative directions.

Paper number 85:
Title: Asymptotically efficient adaptive identification under saturated output observation
Authors: Lantian Zhang, Lei Guo
Abstract: As saturated output observations are ubiquitous in practice, identifying stochastic systems with such nonlinear observations is a fundamental problem across various fields. This paper investigates the asymptotically efficient identification problem for stochastic dynamical systems with saturated output observations. In contrast to most of the existing results, our results do not need the commonly used but stringent conditions such as periodic or independent assumptions on the system signals, and thus do not exclude applications to stochastic feedback systems. To be specific, we introduce a new adaptive Newton-type algorithm on the negative log-likelihood of the partially observed samples using a two-step design technique. Under some general excitation data conditions, we show that the parameter estimate is strongly consistent and asymptotically normal by employing the stochastic Lyapunov function method and limit theories for martingales. Furthermore, we show that the mean square error of the estimates can achieve the Cramer-Rao bound asymptotically without resorting to i.i.d data assumptions. This indicates that the performance of the proposed algorithm is the best possible that one can expect in general. A numerical example is provided to illustrate the superiority of our new adaptive algorithm over the existing related ones in the literature.

Paper number 86:
Title: VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain
Authors: Khai Le-Duc
Abstract: Due to privacy restrictions, there's a shortage of publicly available speech recognition datasets in the medical domain. In this work, we present VietMed - a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. To our best knowledge, VietMed is by far the world's largest public medical speech recognition dataset in 7 aspects: total duration, number of speakers, diseases, recording conditions, speaker roles, unique medical terms and accents. VietMed is also by far the largest public Vietnamese speech dataset in terms of total duration. Additionally, we are the first to present a medical ASR dataset covering all ICD-10 disease groups and all accents within a country. Moreover, we release the first public large-scale pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with the first public large-scale fine-tuned models for medical ASR. Even without any medical data in unsupervised pre-training, our best pre-trained model XLSR-53-Viet generalizes very well to the medical domain by outperforming state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative reduction of more than 40%). All code, data and models are made publicly available: this https URL.

Paper number 87:
Title: Real-time Speech Summarization for Medical Conversations
Authors: Khai Le-Duc, Khai-Nguyen Nguyen, Long Vo-Dang, Truong-Son Hy
Abstract: In doctor-patient conversations, identifying medically relevant information is crucial, posing the need for conversation summarization. In this work, we propose the first deployable real-time speech summarization system for real-world applications in industry, which generates a local summary after every N speech utterances within a conversation and a global summary after the end of a conversation. Our system could enhance user experience from a business standpoint, while also reducing computational costs from a technical perspective. Secondly, we present VietMed-Sum which, to our knowledge, is the first speech summarization dataset for medical conversations. Thirdly, we are the first to utilize LLM and human annotators collaboratively to create gold standard and synthetic summaries for medical conversation summarization. Finally, we present baseline results of state-of-the-art models on VietMed-Sum. All code, data (English-translated and Vietnamese) and models are available online: this https URL

Paper number 88:
Title: Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant
Authors: Alan Dao (Gia Tuan Dao), Dinh Bach Vu, Huy Hoang Ha
Abstract: Large Language Models (LLMs) have revolutionized natural language processing, but their application to speech-based tasks remains challenging due to the complexities of integrating audio and text modalities. This paper introduces Ichigo, a mixed-modal model that seamlessly processes interleaved sequences of speech and text. Utilizing a tokenized early-fusion approach, Ichigo quantizes speech into discrete tokens and employs a uniform transformer-based architecture for both speech and text modalities. This method enables joint reasoning and generation across modalities without the need for separate adapters. We present a comprehensive training methodology, including pre-training on multilingual speech recognition datasets and fine-tuning on a curated instruction dataset. Ichigo demonstrates state-of-the-art performance on speech question-answering benchmarks, outperforming existing open-source speech language models and achieving comparable results to cascaded systems. Notably, Ichigo exhibits a latency of just 111 ms to first token generation, significantly lower than current models. Our approach not only advances the field of multimodal AI but also provides a framework for smaller research teams to contribute effectively to open-source speech-language models.

Paper number 89:
Title: Quantifying Knowledge Distillation Using Partial Information Decomposition
Authors: Pasan Dissanayake, Faisal Hamman, Barproda Halder, Ilia Sucholutsky, Qiuyi Zhang, Sanghamitra Dutta
Abstract: Knowledge distillation deploys complex machine learning models in resource-constrained environments by training a smaller student model to emulate internal representations of a complex teacher model. However, the teacher's representations can also encode nuisance or additional information not relevant to the downstream task. Distilling such irrelevant information can actually impede the performance of a capacity-limited student model. This observation motivates our primary question: What are the information-theoretic limits of knowledge distillation? To this end, we leverage Partial Information Decomposition to quantify and explain the transferred knowledge and knowledge left to distill for a downstream task. We theoretically demonstrate that the task-relevant transferred knowledge is succinctly captured by the measure of redundant information about the task between the teacher and student. We propose a novel multi-level optimization to incorporate redundant information as a regularizer, leading to our framework of Redundant Information Distillation (RID). RID leads to more resilient and effective distillation under nuisance teachers as it succinctly quantifies task-relevant knowledge rather than simply aligning student and teacher representations.

Paper number 90:
Title: FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation
Authors: Tianyun Zhong, Chao Liang, Jianwen Jiang, Gaojie Lin, Jiaqi Yang, Zhou Zhao
Abstract: Diffusion-based audio-driven talking avatar methods have recently gained attention for their high-fidelity, vivid, and expressive results. However, their slow inference speed limits practical applications. Despite the development of various distillation techniques for diffusion models, we found that naive diffusion distillation methods do not yield satisfactory results. Distilled models exhibit reduced robustness with open-set input images and a decreased correlation between audio and video compared to teacher models, undermining the advantages of diffusion models. To address this, we propose FADA (Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation). We first designed a mixed-supervised loss to leverage data of varying quality and enhance the overall model capability as well as robustness. Additionally, we propose a multi-CFG distillation with learnable tokens to utilize the correlation between audio and reference image conditions, reducing the threefold inference runs caused by multi-CFG with acceptable quality degradation. Extensive experiments across multiple datasets show that FADA generates vivid videos comparable to recent diffusion model-based methods while achieving an NFE speedup of 4.17-12.5 times. Demos are available at our webpage this http URL.

Paper number 91:
Title: Supervised contrastive learning from weakly-labeled audio segments for musical version matching
Authors: Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji
Abstract: Detecting musical versions (different renditions of the same piece) is a challenging task with important applications. Because of the ground truth nature, existing approaches match musical versions at the track level (e.g., whole song). However, most applications require to match them at the segment level (e.g., 20s chunks). In addition, existing approaches resort to classification and triplet losses, disregarding more recent losses that could bring meaningful improvements. In this paper, we propose a method to learn from weakly annotated segments, together with a contrastive loss variant that outperforms well-studied alternatives. The former is based on pairwise segment distance reductions, while the latter modifies an existing loss following decoupling, hyper-parameter, and geometric considerations. With these two elements, we do not only achieve state-of-the-art results in the standard track-level evaluation, but we also obtain a breakthrough performance in a segment-level evaluation. We believe that, due to the generality of the challenges addressed here, the proposed methods may find utility in domains beyond audio or musical version matching.

Paper number 92:
Title: The Price of Simplicity: Analyzing Decoupled Policies for Multi-Location Inventory Control
Authors: Yohan John, Vade Shah, James A. Preiss, Mahnoosh Alizadeh, Jason R. Marden
Abstract: What is the performance cost of using simple, decoupled control policies in inherently coupled systems? Motivated by industrial refrigeration systems, where centralized compressors exhibit economies of scale yet traditional control employs decoupled room-by-room temperature regulation, we address this question through the lens of multi-location inventory control. Here, a planner manages multiple inventories to meet stochastic demand while minimizing costs that are coupled through nonlinear ordering functions reflecting economies of scale. Our main contributions are: (i) a surprising equivalence result showing that optimal stationary base-stock levels for individual locations remain unchanged despite the coupling when restricting attention to decoupled strategies; (ii) tight performance bounds for simple decoupled policies relative to optimal coupled policies, revealing that the worst-case ratio depends primarily on the degree of nonlinearity in the cost function and scales with the number of locations for systems with fixed costs; and (iii) analysis of practical online algorithms that achieve competitive performance without solving complex dynamic programs. Numerical simulations demonstrate that while decoupled policies significantly outperform their worst-case guarantees in typical scenarios, they still exhibit meaningful suboptimality compared to fully coordinated strategies. These results provide actionable guidance for system operators navigating the trade-off between control complexity and operational efficiency in coupled systems.

Paper number 93:
Title: Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions
Authors: Declan Jagt, Sergei Chernyshenko, Matthew Peet
Abstract: PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, solutions to these PDEs often do not converge to a unique equilibrium, but instead converge to non-stationary trajectories existing in the nullspace of the spatial differential operator (e.g. $\frac{\partial^2}{\partial x^2}$). To analyse this convergence behaviour, in this paper, it is shown how such trajectories can be modeled for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any PDE state satisfying these boundary conditions can be uniquely expressed in terms of two components, existing in the image and the nullspace of the differential operator $\frac{\partial^2}{\partial x^2}$, respectively. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both state components. Finally, a notion of exponential stability is defined that requires only one of the state components to converge to zero, and it is shown how this stability notion can be tested by solving a linear operator inequality. The proposed methodology is applied to two examples, demonstrating that exponential stability can be verified with tight bounds on the rate of decay.

Paper number 94:
Title: Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale Problems
Authors: Xinliang Dai, Yuning Jiang, Yi Guo, Colin N. Jones, Moritz Diehl, Veit Hagenmeyer
Abstract: This paper introduces a novel distributed optimization framework for large-scale AC Optimal Power Flow (OPF) problems, offering both theoretical convergence guarantees and rapid convergence in practice. By integrating smoothing techniques and the Schur complement, the proposed approach addresses the scalability challenges and reduces communication overhead in distributed AC OPF. Additionally, optimal network decomposition enables efficient parallel processing under the single program multiple data (SPMD) paradigm. Extensive simulations on large-scale benchmarks across various operating scenarios indicate that the proposed framework outperforms the state-of-the-art centralized solver IPOPT on modest hardware. This paves the way for more scalable and efficient distributed optimization in future power system applications.

Paper number 95:
Title: Robust Control of General Linear Delay Systems under Dissipativity: Part I -- A KSD based Framework
Authors: Qian Feng, Wei Xing Zheng, Xiaoyu Wang, Feng Xiao
Abstract: This paper introduces an effective framework for designing memoryless dissipative full-state feedbacks for general linear delay systems via the Krasovskiĭ functional (KF) approach, where an unlimited number of pointwise and general distributed delays (DDs) exists in the state, input and output. To handle the infinite dimensionality of DDs, we employ the Kronecker-Seuret Decomposition (KSD) which we recently proposed for analyzing matrix-valued functions in the context of delay systems. The KSD enables factorization or least-squares approximation of any number of $\mathcal{L}^2$ DD kernels from any number of DDs without introducing conservatism. This also facilitates the construction of a complete-type KF with flexible integral kernels, following from an application of a novel integral inequality derived from the least-squares principle. Our solution includes two theorems and an iterative algorithm to compute controller gains without relying on nonlinear solvers. A challenging numerical example, intractable for existing methods, underscores the efficacy of this approach.
    