
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Adaptive and Robust Image Processing on CubeSats
Authors: Robert Bayer, Julian Priest, Daniel Kjellberg, Jeppe Lindhard, Nikolaj Sørenesen, Nicolaj Valsted, Ívar Óli, Pınar Tözün
Abstract: CubeSats offer a low-cost platform for space research, particularly for Earth observation. However, their resource-constrained nature and being in space, challenge the flexibility and complexity of the deployed image processing pipelines and their orchestration. This paper introduces two novel systems, DIPP and DISH, to address these challenges. DIPP is a modular and configurable image processing pipeline framework that allows for adaptability to changing mission goals even after deployment, while preserving robustness. DISH is a domain-specific language (DSL) and runtime system designed to schedule complex imaging workloads on low-power and memory-constrained processors. Our experiments demonstrate that DIPP's decomposition of the processing pipelines adds negligible overhead, while significantly reducing the network requirements of updating pipelines and being robust against erroneous module uploads. Furthermore, we compare DISH to Lua, a general purpose scripting language, and demonstrate its comparable expressiveness and lower memory requirement.

Paper number 2:
Title: Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view
Authors: Youshen Xiao, Yiling Shi, Ruixi Sun, Hongjiang Wei, Fei Gao, Yuyao Zhang
Abstract: Dynamic Photoacoustic Computed Tomography (PACT) is an important imaging technique for monitoring physiological processes, capable of providing high-contrast images of optical absorption at much greater depths than traditional optical imaging methods. However, practical instrumentation and geometric constraints limit the number of acoustic sensors available around the imaging target, leading to sparsity in sensor data. Traditional photoacoustic (PA) image reconstruction methods, when directly applied to sparse PA data, produce severe artifacts. Additionally, these traditional methods do not consider the inter-frame relationships in dynamic imaging. Temporal resolution is crucial for dynamic photoacoustic imaging, which is fundamentally limited by the low repetition rate (e.g., 20 Hz) and high cost of high-power laser technology. Recently, Implicit Neural Representation (INR) has emerged as a powerful deep learning tool for solving inverse problems with sparse data, by characterizing signal properties as continuous functions of their coordinates in an unsupervised manner. In this work, we propose an INR-based method to improve dynamic photoacoustic image reconstruction from sparse-views and enhance temporal resolution, using only spatiotemporal coordinates as input. Specifically, the proposed INR represents dynamic photoacoustic images as implicit functions and encodes them into a neural network. The weights of the network are learned solely from the acquired sparse sensor data, without the need for external training datasets or prior images. Benefiting from the strong implicit continuity regularization provided by INR, as well as explicit regularization for low-rank and sparsity, our proposed method outperforms traditional reconstruction methods under two different sparsity conditions, effectively suppressing artifacts and ensuring image quality.

Paper number 3:
Title: Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population
Authors: Isarun Chamveha, Supphanut Chaiyungyuen, Sasinun Worakriangkrai, Nattawadee Prasawang, Warasinee Chaisangmongkon, Pornpim Korpraphong, Voraparee Suvannarerg, Shanigarn Thiravit, Chalermdej Kannawat, Kewalin Rungsinaporn, Suwara Issaragrisil, Payia Chadbunchachai, Pattiya Gatechumpol, Chawiporn Muktabhant, Patarachai Sereerat
Abstract: This study presents a deep learning system for breast cancer detection in mammography, developed using a modified EfficientNetV2 architecture with enhanced attention mechanisms. The model was trained on mammograms from a major Thai medical center and validated on three distinct datasets: an in-domain test set (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain generalizability set (761 cases) collected from two different hospitals. For cancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the respective datasets. The system's lesion localization capability, evaluated using metrics including Lesion Localization Fraction (LLF) and Non-Lesion Localization Fraction (NLF), demonstrated robust performance in identifying suspicious regions. Clinical validation through concordance tests showed strong agreement with radiologists: 83.5% classification and 84.0% localization concordance for biopsy-confirmed cases, and 78.1% classification and 79.6% localization concordance for out-of-domain cases. Expert radiologists' acceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for out-of-domain cases. The system achieved a System Usability Scale score of 74.17 for source hospital, and 69.20 for validation hospitals, indicating good clinical acceptance. These results demonstrate the model's effectiveness in assisting mammogram interpretation, with the potential to enhance breast cancer screening workflows in clinical practice.

Paper number 4:
Title: LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning
Authors: Md. Zihad Bin Jahangir, Muhammad Ashad Kabir, Sumaiya Akter, Israt Jahan, Minh Chau
Abstract: Automated radiology report generation holds significant potential to reduce radiologists' workload and enhance diagnostic accuracy. However, generating precise and clinically meaningful reports from chest radiographs remains challenging due to the complexity of medical language and the need for contextual understanding. Existing models often struggle with maintaining both accuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel framework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings and Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves improved coherence and clinical accuracy while maintaining computational efficiency. This efficiency is driven by an optimization strategy that enhances parameter utilization and reduces memory overhead, enabling faster report generation with lower computational resource demands. Extensive experiments conducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR outperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L score of 0.433 and a METEOR score of 0.336, establishing new performance benchmarks in the domain. These results underscore LLaMA-XR's potential as an effective and efficient AI system for automated radiology reporting, offering enhanced clinical utility and reliability.

Paper number 5:
Title: Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning
Authors: Wangting Zhou, Jiangshan He, Tong Cai, Lin Wang, Zhen Yuan, Xunbin Wei, Xueli Chen
Abstract: Photoacoustic microscopy holds the potential to measure biomarkers' structural and functional status without labels, which significantly aids in comprehending pathophysiological conditions in biomedical research. However, conventional optical-resolution photoacoustic microscopy (OR-PAM) is hindered by a limited depth-of-field (DoF) due to the narrow depth range focused on a Gaussian beam. Consequently, it fails to resolve sufficient details in the depth direction. Herein, we propose a decision-level constrained end-to-end multi-focus image fusion (Dc-EEMF) to push DoF limit of PAM. The DC-EEMF method is a lightweight siamese network that incorporates an artifact-resistant channel-wise spatial frequency as its feature fusion rule. The meticulously crafted U-Net-based perceptual loss function for decision-level focus properties in end-to-end fusion seamlessly integrates the complementary advantages of spatial domain and transform domain methods within Dc-EEMF. This approach can be trained end-to-end without necessitating post-processing procedures. Experimental results and numerical analyses collectively demonstrate our method's robust performance, achieving an impressive fusion result for PAM images without a substantial sacrifice in lateral resolution. The utilization of Dc-EEMF-powered PAM has the potential to serve as a practical tool in preclinical and clinical studies requiring extended DoF for various applications.

Paper number 6:
Title: Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study
Authors: Yaşar Utku Alçalar, Yu Cao, Mehmet Akçakaya
Abstract: Physics-driven artificial intelligence (PD-AI) reconstruction methods have emerged as the state-of-the-art for accelerating MRI scans, enabling higher spatial and temporal resolutions. However, the high resolution of these scans generates massive data volumes, leading to challenges in transmission, storage, and real-time processing. This is particularly pronounced in functional MRI, where hundreds of volumetric acquisitions further exacerbate these demands. Edge computing with FPGAs presents a promising solution for enabling PD-AI reconstruction near the MRI sensors, reducing data transfer and storage bottlenecks. However, this requires optimization of PD-AI models for hardware efficiency through quantization and bypassing traditional FFT-based approaches, which can be a limitation due to their computational demands. In this work, we propose a novel PD-AI computational MRI approach optimized for FPGA-based edge computing devices, leveraging 8-bit complex data quantization and eliminating redundant FFT/IFFT operations. Our results show that this strategy improves computational efficiency while maintaining reconstruction quality comparable to conventional PD-AI methods, and outperforms standard clinical methods. Our approach presents an opportunity for high-resolution MRI reconstruction on resource-constrained devices, highlighting its potential for real-world deployment.

Paper number 7:
Title: DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset
Authors: Liangrui Pan, Xingchen Li, Zhongyi Chen, Ling Chu, Shaoliang Peng
Abstract: Pathologists comprehensive evaluation of donor liver biopsies provides crucial information for accepting or discarding potential grafts. However, rapidly and accurately obtaining these assessments intraoperatively poses a significant challenge for pathologists. Features in donor liver biopsies, such as portal tract fibrosis, total steatosis, macrovesicular steatosis, and hepatocellular ballooning are correlated with transplant outcomes, yet quantifying these indicators suffers from substantial inter- and intra-observer variability. To address this, we introduce DLiPath, the first benchmark for comprehensive donor liver assessment based on a histopathology image dataset. We collected and publicly released 636 whole slide images from 304 donor liver patients at the Department of Pathology, the Third Xiangya Hospital, with expert annotations for key pathological features (including cholestasis, portal tract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis, and hepatocellular ballooning). We selected nine state-of-the-art multiple-instance learning (MIL) models based on the DLiPath dataset as baselines for extensive comparative analysis. The experimental results demonstrate that several MIL models achieve high accuracy across donor liver assessment indicators on DLiPath, charting a clear course for future automated and intelligent donor liver assessment research. Data and code are available at this https URL.

Paper number 8:
Title: Lightweight Convolutional Neural Networks for Retinal Disease Classification
Authors: Duaa Kareem Qasim, Sabah Abdulazeez Jebur, Lafta Raheem Ali, Abdul Jalil M. Khalaf, Abir Jaafar Hussain
Abstract: Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) significantly impact vision and affect millions worldwide. Early detection is crucial, as DR, a complication of diabetes, damages retinal blood vessels, potentially leading to blindness, while MH disrupts central vision, affecting tasks like reading and facial recognition. This paper employed two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images. The models were trained on the RFMiD dataset, consisting of 3,200 fundus images, after undergoing preprocessing steps such as resizing, normalization, and augmentation. To address data scarcity, this study leveraged transfer learning and data augmentation techniques, enhancing model generalization and performance. The experimental results demonstrate that MobileNetV2 achieved the highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.

Paper number 9:
Title: Multi-Analyte, Swab-based Automated Wound Monitor with AI
Authors: Madhu Babu Sikha, Lalith Appari, Gurudatt Nanjanagudu Ganesh, Amay Bandodkar, Imon Banerjee
Abstract: Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000 individuals every year in the US alone and identifying non-healing DFUs that develop to chronic wounds early can drastically reduce treatment costs and minimize risks of amputation. There is therefore a pressing need for diagnostic tools that can detect non-healing DFUs early. We develop a low cost, multi-analyte 3D printed assays seamlessly integrated on swabs that can identify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile application developed for the controlled acquisition and automated analysis of wound sensor data. By comparing both the original base image (before exposure to the wound) and the wound-exposed image, we developed automated computer vision techniques to compare density changes between the two assay images, which allow us to automatically determine the severity of the wound. The iOS app ensures accurate data collection and presents actionable insights, despite challenges such as variations in camera configurations and ambient conditions. The proposed integrated sensor and iOS app will allow healthcare professionals to monitor wound conditions real-time, track healing progress, and assess critical parameters related to wound care.

Paper number 10:
Title: Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers
Authors: Basudha Pal, Rama Chellappa, Muhammad Umair
Abstract: While echocardiography and MRI are clinical standards for evaluating cardiac structure, their use is limited by cost and this http URL introduce a direct classification framework that predicts severe left ventricular hypertrophy from chest X-rays, without relying on anatomical measurements or demographic inputs. Our approach achieves high AUROC and AUPRC, and employs Mutual Information Neural Estimation to quantify feature expressivity. This reveals clinically meaningful attribute encoding and supports transparent model interpretation.

Paper number 11:
Title: A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction
Authors: Itxasne Antúnez Sáenz, Ane Alberdi Aramendi, David Dunaway, Juling Ong, Lara Deliège, Amparo Sáenz, Anita Ahmadi Birjandi, Noor UI Owase Jeelani, Silvia Schievano, Alessandro Borghi
Abstract: Craniosynostosis is a medical condition that affects the growth of babies' heads, caused by an early fusion of cranial sutures. In recent decades, surgical treatments for craniosynostosis have significantly improved, leading to reduced invasiveness, faster recovery, and less blood loss. At Great Ormond Street Hospital (GOSH), the main surgical treatment for patients diagnosed with sagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This procedure involves a 15x15 mm2 osteotomy, where two springs are inserted to induce distraction. Despite the numerous advantages of this surgical technique for patients, the outcome remains unpredictable due to the lack of efficient preoperative planning tools. The surgeon's experience and the baby's age are currently relied upon to determine the osteotomy location and spring selection. Previous tools for predicting the surgical outcome of SC relied on finite element modeling (FEM), which involved computed tomography (CT) imaging and required engineering expertise and lengthy calculations. The main goal of this research is to develop a real-time prediction tool for the surgical outcome of patients, eliminating the need for CT scans to minimise radiation exposure during preoperative planning. The proposed methodology involves creating personalised synthetic skulls based on three-dimensional (3D) photographs, incorporating population average values of suture location, skull thickness, and soft tissue properties. A machine learning (ML) surrogate model is employed to achieve the desired surgical outcome. The resulting multi-output support vector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13. Furthermore, in the future, this model could not only simulate various surgical scenarios but also provide optimal parameters for achieving a maximum cranial index (CI).

Paper number 12:
Title: A Survey of Deep Learning Video Super-Resolution
Authors: Arbind Agrahari Baniya, Tsz-Kwan Lee, Peter Eklund, Sunil Aryal
Abstract: Video super-resolution (VSR) is a prominent research topic in low-level computer vision, where deep learning technologies have played a significant role. The rapid progress in deep learning and its applications in VSR has led to a proliferation of tools and techniques in the literature. However, the usage of these methods is often not adequately explained, and decisions are primarily driven by quantitative improvements. Given the significance of VSR's potential influence across multiple domains, it is imperative to conduct a comprehensive analysis of the elements and deep learning methodologies employed in VSR research. This methodical analysis will facilitate the informed development of models tailored to specific application needs. In this paper, we present an overarching overview of deep learning-based video super-resolution models, investigating each component and discussing its implications. Furthermore, we provide a synopsis of key components and technologies employed by state-of-the-art and earlier VSR models. By elucidating the underlying methodologies and categorising them systematically, we identified trends, requirements, and challenges in the domain. As a first-of-its-kind survey of deep learning-based VSR models, this work also establishes a multi-level taxonomy to guide current and future VSR research, enhancing the maturation and interpretation of VSR practices for various practical applications.

Paper number 13:
Title: petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI
Authors: Pierrick Coupé, Boris Mansencal, Floréal Morandat, Sergio Morell-Ortega, Nicolas Villain, Jose V. Manjón, Vincent Planche
Abstract: INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles (T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's disease (AD) diagnosis and prognosis. Existing pipelines face limitations regarding processing time, variability in tracer types, and challenges in multimodal integration. METHODS: We developed petBrain, a novel end-to-end processing pipeline for amyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based segmentation, standardized biomarker quantification (Centiloid, CenTauR, HAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is implemented as a web-based platform, requiring no local computational infrastructure or specialized software knowledge. RESULTS: petBrain provides reliable and rapid biomarker quantification, with results comparable to existing pipelines for A and T2. It shows strong concordance with data processed in ADNI databases. The staging and quantification of A/T2/N by petBrain demonstrated good agreement with CSF/plasma biomarkers, clinical status, and cognitive performance. DISCUSSION: petBrain represents a powerful and openly accessible platform for standardized AD biomarker analysis, facilitating applications in clinical research.

Paper number 14:
Title: Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach
Authors: Ziheng Zhao, Lisong Dai, Ya Zhang, Yanfeng Wang, Weidi Xie
Abstract: Automated interpretation of CT images-particularly localizing and describing abnormal findings across multi-plane and whole-body scans-remains a significant challenge in clinical radiology. This work aims to address this challenge through four key contributions: (i) On taxonomy, we collaborate with senior radiologists to propose a comprehensive hierarchical classification system, with 404 representative abnormal findings across all body regions; (ii) On data, we contribute a dataset containing over 14.5K CT images from multiple planes and all human body regions, and meticulously provide grounding annotations for over 19K abnormalities, each linked to the detailed description and cast into the taxonomy; (iii) On model development, we propose OminiAbnorm-CT, which can automatically ground and describe abnormal findings on multi-plane and whole-body CT images based on text queries, while also allowing flexible interaction through visual prompts; (iv) On benchmarks, we establish three representative evaluation tasks based on real clinical scenarios. Through extensive experiments, we show that OminiAbnorm-CT can significantly outperform existing methods on all the tasks and metrics.

Paper number 15:
Title: Online Detection and Mitigation of Robust Zero Dynamics Anomaly Behavior in MIMO Nonlinear Control Systems
Authors: Kosar Behnia, H.A. Talebi, Farzaneh Abdollahi
Abstract: This paper presents a methodology to detect robust zero dynamics anomaly behavior and mitigate the impacts in general multi-input multi-output (MIMO) nonlinear systems. The proposed method guarantees the resiliency and stability of the closed-loop system without relying on an accurate dynamical model. The presented method operates in two stages. First, it measures the difference between the system input and that of the model as a residual signal to detect the anomaly behavior. After detecting the attack, a recovery signal is generated to restore the system to its nominal condition. In this stage, a neural network model is used to estimate the anomaly signal and recover the closed-loop system. The weights of the neural network model are updated online using adaptation rules without needing prior data for training. The accuracy and performance of the proposed methods are verified by simulating various scenarios on a fourtank system.

Paper number 16:
Title: Spatial Association Between Near-Misses and Accident Blackspots in Sydney, Australia: A Getis-Ord $G_i^*$ Analysis
Authors: Artur Grigorev, David Lillo-Trynes, Adriana-Simona Mihaita
Abstract: Road safety management teams utilize on historical accident logs to identify blackspots, which are inherently rare and sparse in space and time. Near-miss events captured through vehicle telematics and transmitted in real-time by connected vehicles reveal a unique potential of prevention due to their high frequency nature and driving engagement on the road. There is currently a lack of understanding of the high potential of near-miss data in real-time to proactively detect potential risky driving areas, in advance of a fatal collision. This paper aims to spatially identify clusters of reported accidents (A) versus high-severity near-misses (High-G) within an urban environment (Sydney, Australia) and showcase how the presence of near-misses can significantly lead to future crashes in identified risky hotspots. First, by utilizing a 400m grid framework, we identify significant crash hotspots using the Getis-Ord $G_i^*$ statistical approach. Second, we employ a Bivariate Local Moran's I (LISA) approach to assess and map the spatial concordance and discordance between official crash counts (A) and High-G counts from nearmiss data (High-G). Third, we classify areas based on their joint spatial patterns into: a) High-High (HH) as the most riskiest areas in both historical logs and nearmiss events, High-Low (HL) for high crash logs but low nearmiss records, c) Low-High (LH) for low past crash records but high nearmiss events, and d) Low-Low (LL) for safe areas. Finally, we run a feature importance ranking on all area patterns by using a contextual Point of Interest (POI) count features and we showcase which factors are the most critical to the occurrence of crash blackspots.

Paper number 17:
Title: Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models
Authors: Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Priyabrata Mallick, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma
Abstract: In this work, we introduce the task of singing voice deepfake source attribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs) such as ImageBind, LanguageBind will be most effective for SVDSA as they are better equipped for capturing subtle source-specific characteristics-such as unique timbre, pitch manipulation, or synthesis artifacts of each singing voice deepfake source due to their cross-modality pre-training. Our experiments with MMFMs, speech foundation models and music foundation models verify the hypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspired from related research, we also explore fusion of foundation models (FMs) for improved SVDSA. To this end, we propose a novel framework, COFFE which employs Chernoff Distance as novel loss function for effective fusion of FMs. Through COFFE with the symphony of MMFMs, we attain the topmost performance in comparison to all the individual FMs and baseline fusion methods.

Paper number 18:
Title: Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing
Authors: Artur Grigorev, Adriana-Simona Mihaita
Abstract: Effective placement of Out-of-Home advertising and street furniture requires accurate identification of locations offering maximum visual exposure to target audiences, particularly vehicular traffic. Traditional site selection methods often rely on static traffic counts or subjective assessments. This research introduces a data-driven methodology to objectively quantify location visibility by analyzing large-scale connected vehicle trajectory data (sourced from Compass IoT) within urban environments. We model the dynamic driver field-of-view using a forward-projected visibility area for each vehicle position derived from interpolated trajectories. By integrating this with building vertex locations extracted from OpenStreetMap, we quantify the cumulative visual exposure, or ``visibility count'', for thousands of potential points of interest near roadways. The analysis reveals that visibility is highly concentrated, identifying specific ``visual hotspots'' that receive disproportionately high exposure compared to average locations. The core technical contribution involves the construction of a BallTree spatial index over building vertices. This enables highly efficient (O(logN) complexity) radius queries to determine which vertices fall within the viewing circles of millions of trajectory points across numerous trips, significantly outperforming brute-force geometric checks. Analysis reveals two key findings: 1) Visibility is highly concentrated, identifying distinct 'visual hotspots' receiving disproportionately high exposure compared to average locations. 2) The aggregated visibility counts across vertices conform to a Log-Normal distribution.

Paper number 19:
Title: SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer
Authors: Orchid Chetia Phukan, Mohd Mujtaba Akhtar, Girish, Swarup Ranjan Behera, Abu Osama Siddiqui, Sarthak Jain, Priyabrata Mallick, Jaya Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma
Abstract: As video-sharing platforms have grown over the past decade, child viewership has surged, increasing the need for precise detection of harmful content like violence or explicit scenes. Malicious users exploit moderation systems by embedding unsafe content in minimal frames to evade detection. While prior research has focused on visual cues and advanced such fine-grained detection, audio features remain underexplored. In this study, we embed audio cues with visual for fine-grained child harmful content detection and introduce SNIFR, a novel framework for effective alignment. SNIFR employs a transformer encoder for intra-modality interaction, followed by a cascaded cross-transformer for inter-modality alignment. Our approach achieves superior performance over unimodal and baseline fusion methods, setting a new state-of-the-art.

Paper number 20:
Title: Automated Traffic Incident Response Plans using Generative Artificial Intelligence: Part 1 -- Building the Incident Response Benchmark
Authors: Artur Grigorev, Khaled Saleh, Jiwon Kim, Adriana-Simona Mihaita
Abstract: Traffic incidents remain a critical public safety concern worldwide, with Australia recording 1,300 road fatalities in 2024, which is the highest toll in 12 years. Similarly, the United States reports approximately 6 million crashes annually, raising significant challenges in terms of a fast reponse time and operational management. Traditional response protocols rely on human decision-making, which introduces potential inconsistencies and delays during critical moments when every minute impacts both safety outcomes and network performance. To address this issue, we propose a novel Incident Response Benchmark that uses generative artificial intelligence to automatically generate response plans for incoming traffic incidents. Our approach aims to significantly reduce incident resolution times by suggesting context-appropriate actions such as variable message sign deployment, lane closures, and emergency resource allocation adapted to specific incident characteristics. First, the proposed methodology uses real-world incident reports from the Performance Measurement System (PeMS) as training and evaluation data. We extract historically implemented actions from these reports and compare them against AI-generated response plans that suggest specific actions, such as lane closures, variable message sign announcements, and/or dispatching appropriate emergency resources. Second, model evaluations reveal that advanced generative AI models like GPT-4o and Grok 2 achieve superior alignment with expert solutions, demonstrated by minimized Hamming distances (averaging 2.96-2.98) and low weighted differences (approximately 0.27-0.28). Conversely, while Gemini 1.5 Pro records the lowest count of missed actions, its extremely high number of unnecessary actions (1547 compared to 225 for GPT-4o) indicates an over-triggering strategy that reduces the overall plan efficiency.

Paper number 21:
Title: Occlusion-Aware Ground Target Tracking by a Dubins Vehicle Using Visibility Volumes
Authors: Collin Hague, Artur Wolek
Abstract: This paper considers the problem of tracking a point of interest (POI) moving along a known trajectory on the ground with an uncrewed aerial vehicle (UAV) modeled as a Dubins vehicle using a line-of-sight (LOS) sensor through an urban environment that may occlude the POI. A visibility volume (VV) encodes a time-varying, three-dimensional representation of the sensing constraints for a particular POI position. A constant-altitude, translating, and radially time-varying circular standoff orbit is then inscribed within the dynamically changing VV centered at the POI position. The time-varying VV is approximated by placing static VVs along the POI's trajectory using an adaptive metric that restricts the volume change of consecutive visibility volumes to below a specified rate. The time-varying circular standoff orbit is proven to be feasible for a Dubins vehicle and is approximated with a piecewise set of linearly interpolated circular orbits inside the static VVs. A steering controller is derived that drives the UAV to converge to the time-varying standoff orbit. Numerical simulations and a flight test illustrate the proposed approach.

Paper number 22:
Title: HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition
Authors: Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma
Abstract: Compression-based representations (CBRs) from neural audio codecs such as EnCodec capture intricate acoustic features like pitch and timbre, while representation-learning-based representations (RLRs) from pre-trained models trained for speech representation learning such as WavLM encode high-level semantic and prosodic information. Previous research on Speech Emotion Recognition (SER) has explored both, however, fusion of CBRs and RLRs haven't been explored yet. In this study, we solve this gap and investigate the fusion of RLRs and CBRs and hypothesize they will be more effective by providing complementary information. To this end, we propose, HYFuse, a novel framework that fuses the representations by transforming them to hyperbolic space. With HYFuse, through fusion of x-vector (RLR) and Soundstream (CBR), we achieve the top performance in comparison to individual representations as well as the homogeneous fusion of RLRs and CBRs and report SOTA.

Paper number 23:
Title: An iterative tangential interpolation framework for model reduction of MIMO systems
Authors: Jared Jonas, Bassam Bamieh
Abstract: We consider model reduction of large-scale MIMO systems using tangential interpolation in the frequency domain. Our scheme is related to the recently-developed Adaptive Antoulas--Anderson (AAA) algorithm, which is an iterative algorithm that uses concepts from the Loewner framework. Our algorithm uses low-rank interpolation and iteratively adds interpolation points based on several criteria including minimizing maximum errors. We show there is freedom in the interpolation point selection method, leading to multiple algorithms that have trade-offs between computational complexity and approximation performance. We prove that a weighted \(H_2\) norm of a representative error system is monotonically decreasing as interpolation points are added. Finally, we provide computational results and some comparisons with prior works, demonstrating performance on par with standard model reduction methods.

Paper number 24:
Title: Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images
Authors: Muhammad Zubair Hasan, Fahmida Yasmin Rifat
Abstract: Skin cancer is among the most prevalent and life-threatening diseases worldwide, with early detection being critical to patient outcomes. This work presents a hybrid machine and deep learning-based approach for classifying malignant and benign skin lesions using the SLICE-3D dataset from ISIC 2024, which comprises 401,059 cropped lesion images extracted from 3D Total Body Photography (TBP), emulating non-dermoscopic, smartphone-like conditions. Our method combines vision transformers (EVA02) and our designed convolutional ViT hybrid (EdgeNeXtSAC) to extract robust features, employing a segmentation-assisted classification pipeline to enhance lesion localization. Predictions from these models are fused with a gradient-boosted decision tree (GBDT) ensemble enriched by engineered features and patient-specific relational metrics. To address class imbalance and improve generalization, we augment malignant cases with Stable Diffusion-generated synthetic lesions and apply a diagnosis-informed relabeling strategy to harmonize external datasets into a 3-class format. Using partial AUC (pAUC) above 80 percent true positive rate (TPR) as the evaluation metric, our approach achieves a pAUC of 0.1755 -- the highest among all configurations. These results underscore the potential of hybrid, interpretable AI systems for skin cancer triage in telemedicine and resource-constrained settings.

Paper number 25:
Title: On Loss-Minimal Radial Topologies in MV Systems
Authors: Anton Hinneck, Mathias Duckheim, Michael Metzger, Stefan Niessen
Abstract: Distribution system reconfiguration (DSR) means optimizing the topology of a distribution grid using switching actions. Switching actions are a degrees of freedom available to distribution system operators, e.g. to manage planned and unplanned outages. DSR is a NP-hard combinatorial problem. Finding good or even optimal solutions is computationally expensive. While transmission and high-voltage grids are generally operated in a meshed state, MV distribution systems are commonly operated as radial networks even though meshed operation would be supported. This improves resilience because faults can be isolated more easily keeping the rest of the system operational and minimizing impact on customers. We propose an AC DSR formulation and benchmark it against a common formulation from the literature. Our results indicate that additional acyclicity constraints can significantly improve solver performance.

Paper number 26:
Title: Sub-Scalp EEG for Sensorimotor Brain-Computer Interface
Authors: Timothy B Mahoney, David B Grayden, Sam E John
Abstract: Objective: To establish sub-scalp electroencephalography (EEG) as a viable option for brain-computer interface (BCI) applications, particularly for chronic use, by demonstrating its effectiveness in recording and classifying sensorimotor neural activity. Approach: Two experiments were conducted in this study. The first aim was to demonstrate the high spatial resolution of sub-scalp EEG through analysis of somatosensory evoked potentials in sheep models. The second focused on the practical application of sub-scalp EEG, classifying motor execution using data collected during a sheep behavioural experiment. Main Results: We successfully demonstrated the recording of sensorimotor rhythms using sub-scalp EEG in sheep models. Important spatial, temporal, and spectral features of these signals were identified, and we were able to classify motor execution with above-chance performance. These results are comparable to previous work that investigated signal quality and motor execution classification using ECoG and endovascular arrays in sheep models. Significance: These results suggest that sub-scalp EEG may provide signal quality that approaches that of more invasive neural recording methods such as ECoG and endovascular arrays, and support the use of sub-scalp EEG for chronic BCI applications.

Paper number 27:
Title: A Data-Driven Diffusion-based Approach for Audio Deepfake Explanations
Authors: Petr Grinberg, Ankur Kumar, Surya Koppisetti, Gaurav Bharaj
Abstract: Evaluating explainability techniques, such as SHAP and LRP, in the context of audio deepfake detection is challenging due to lack of clear ground truth annotations. In the cases when we are able to obtain the ground truth, we find that these methods struggle to provide accurate explanations. In this work, we propose a novel data-driven approach to identify artifact regions in deepfake audio. We consider paired real and vocoded audio, and use the difference in time-frequency representation as the ground-truth explanation. The difference signal then serves as a supervision to train a diffusion model to expose the deepfake artifacts in a given vocoded audio. Experimental results on the VocV4 and LibriSeVoc datasets demonstrate that our method outperforms traditional explainability techniques, both qualitatively and quantitatively.

Paper number 28:
Title: Two-Stage Bidirectional Inverter Equivalent Circuit Model for Distribution Grid Steady-State Analysis and Optimization
Authors: Emmanuel O. Badmus, Amritanshu Pandey
Abstract: This paper presents a \textit{physics-based} steady-state equivalent circuit model of a two-stage bidirectional inverter. These inverters connect distributed energy resources (DERs), such as photovoltaic (PV) and battery systems, to distribution grids. Existing inverter models have technical gaps on three fronts: i) inadequate modeling of inverter losses, ii) use of mathematical abstractions for bidirectional flow of power, and iii) inability to integrate different control modes into nonlinear solvers without loss of generality. We propose a physics-first model that explicitly captures losses in passive circuit components based on circuit-level principles. We enable bidirectional power flow without binary or complementarity constraints by formulating loss terms as smooth, sign-aware expressions of current. We introduce and parameterize controlled current sources with twice-differentiable continuous functions to enable inverter control modes without loss of generality. We integrate DERs with the proposed inverter model at the load buses of distribution networks to perform power flow and optimization studies on real-world distribution networks with over 20,000 nodes. We demonstrate that the proposed model is more accurate, integrates seamlessly with various control modes without loss of generality, and scales robustly to large optimization problems. Index Terms: bidirectional inverter model, circuit-based modeling, DERs, inverter efficiency, power control, steady-state analysis.

Paper number 29:
Title: Interference-Aware Multiuser Hybrid Precoding for Coexistence with LEO Satellite Communication
Authors: Nima Razavi, Murat Bayraktar, Nuria Gonzalez Prelcic, Robert W. Heath Jr
Abstract: Interference from terrestrial networks can reduce the communication rate for low Earth orbit (LEO) satellites in the upper mid-band. To coexist in frequency, MIMO precoding can be used to reduce the signal that impinges on the LEO satellite. We present a beamforming algorithm designed for the hybrid architecture that incorporates a satellite interference penalty while optimizing the analog and digital precoders. Our algorithm optimizes the precoding at the base station (BS) within the set of precoders that null the interference to the satellite. Simulations demonstrate that our algorithm reduces the interference at the satellites and lowers the probability of violating prescribed LEO satellite protection thresholds, outperforming prior hybrid nulling algorithms. Results indicate that the algorithm maintains sum-rate within 3\% of the existing hybrid solutions, while effectively improving interference to noise power by 22.4 dB.

Paper number 30:
Title: Optimizing Software Defined Battery Systems for Transformer Protection
Authors: Sonia Martin, Obidike Nnorom Jr., Philip Levis, Ram Rajagopal
Abstract: Residential electric vehicle charging causes large spikes in electricity demand that risk violating neighborhood transformer power limits. Battery energy storage systems reduce these transformer limit violations, but operating them individually is not cost-optimal. Instead of individual optimization, aggregating, or sharing, these batteries leads to cost-optimal performance, but homeowners must relinquish battery control. This paper leverages virtualization to propose battery sharing optimization schemes to reduce electricity costs, extend the lifetime of a residential transformer, and maintain homeowner control over the battery. A case study with simulated home loads, solar generation, and electric vehicle charging profiles demonstrates that joint, or shared, optimization reduces consumer bills by 56% and transformer aging by 48% compared to individual optimization. Hybrid and dynamic optimization schemes that provide owners with autonomy have similar transformer aging reduction but are slightly less cost-effective. These results suggest that controlling shared batteries with virtualization is an effective way to delay transformer upgrades in the face of growing residential electric vehicle charging penetration.

Paper number 31:
Title: StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology
Authors: William G. Coon, Preston Peranich, Griffin Milsap
Abstract: The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention. Utilizing the compact DCM biosignal device, StARS captures electrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data using the ezmsg real-time software framework. StARS supports interventions such as closed-loop auditory stimulation and dynamic thermal modulation guided by sleep-stage decoding via advanced neural network models and transfer learning. Configurable with a lightweight EEG forehead patch or wearable sensors like smart rings, StARS offers flexible, low-burden solutions for EEG, BCI, and sleep-enhancement research and applications. The open-source DCM patch further enables customizable EEG device development.

Paper number 32:
Title: Minimally Invasive Brain Computer Interfaces: Evaluating the Impact of Tissue Layers on Signal Quality of Sub-Scalp EEG
Authors: Timothy B Mahoney, JingYang Liu, Huakun Xin, David B Grayden, Sam E John
Abstract: Individuals with severe physical disabilities often experience diminished quality of life stemming from limited ability to engage with their surroundings. Brain-Computer Interface (BCI) technology aims to bridge this gap by enabling direct technology interaction. However, current BCI systems require invasive procedures, such as craniotomy or implantation of electrodes through blood vessels, posing significant risks to patients. Sub-scalp electroencephalography (EEG) offers a lower risk alternative. This study investigates the signal quality of sub-scalp EEG recordings from various depths in a sheep model, and compares results with other methods: ECoG and endovascular arrays. A computational model was also constructed to investigate the factors underlying variations in electrode performance. We demonstrate that peg electrodes placed within the sub-scalp space can achieve visual evoked potential signal-to-noise ratios (SNRs) approaching that of ECoG. Endovascular arrays exhibited SNR comparable to electrodes positioned on the periosteum. Furthermore, sub-scalp recordings captured high gamma neural activity, with maximum bandwidth ranging from 120 Hz to 180 Hz depending on electrode depth. These findings support the use of sub-scalp EEG for BCI applications, and provide valuable insights for future sub-scalp electrode design. This data lays the groundwork for human trials, ultimately paving the way for chronic, in-home BCIs that empower individuals with physical disabilities.

Paper number 33:
Title: Nonlinear Optimal Control of DC Microgrids with Safety and Stability Guarantees
Authors: Muratkhan Abdirash, Xiaofan Cui
Abstract: A DC microgrid is a promising alternative to the traditional AC power grid, since it can efficiently integrate distributed and renewable energy resources. However, as an emerging framework, it lacks the rigorous theoretical guarantees of its AC counterpart. In particular, safe stabilization of the DC microgrid has been a non-trivial task in power electronics. To address that, we take a control theoretic perspective in designing the feedback controller with provable guarantees. We present a systematic way to construct Control Lyapunov Functions (CLF) to stabilize the microgrid, and, independently, Control Barrier Functions (CBF) to enforce its safe operation at all times. The safety-critical controller (SCC) proposed in this work integrates the two control objectives, with safety prioritized, into a quadratic program (QP) as linear constraints, which allows for its online deployment using off-the-shelf convex optimization solvers. The SCC is compared against a robust version of the conventional droop control through numerical experiments whose results indicate the SCC outperforms the droop controller in guaranteeing safety and retaining stability at the same time.

Paper number 34:
Title: Topology-Aware Graph Neural Network-based State Estimation for PMU-Unobservable Power Systems
Authors: Shiva Moshtagh, Behrouz Azimian, Mohammad Golgol, Anamitra Pal
Abstract: Traditional optimization-based techniques for time-synchronized state estimation (SE) often suffer from high online computational burden, limited phasor measurement unit (PMU) coverage, and presence of non-Gaussian measurement noise. Although conventional learning-based models have been developed to overcome these challenges, they are negatively impacted by topology changes and real-time data loss. This paper proposes a novel deep geometric learning approach based on graph neural networks (GNNs) to estimate the states of PMU-unobservable power systems. The proposed approach combines graph convolution and multi-head graph attention layers inside a customized end-to-end learning framework to handle topology changes and real-time data loss. An upper bound on SE error as a function of topology change is also derived. Experimental results for different test systems demonstrate superiority of the proposed customized GNN-SE (CGNN-SE) over traditional optimization-based techniques as well as conventional learning-based models in presence of topology changes, PMU failures, bad data, non-Gaussian measurement noise, and large system implementation.

Paper number 35:
Title: High-Speed Ultra-Energy-Efficient Memristor-Based Massive MIMO SIC Detector Circuit with Hybrid Analog-Digital Computing Architecture
Authors: Jia-Hui Bi, Shaoshi Yang, Sheng Chen, Ping Zhang
Abstract: The emerging memristor crossbar array based computing circuits exhibit computing speeds and energy efficiency far surpassing those of traditional digital processors. This type of circuits can complete high-dimensional matrix operations in an extremely short time through analog computing, making it naturally applicable to linear detection and maximum likelihood detection in massive multiple-input multiple-output (MIMO) systems. However, the challenge of employing memristor crossbar arrays to efficiently implement other nonlinear detection algorithms, such as the successive interference cancellation (SIC) algorithm, remains unresolved. In this paper we propose a memristor-based circuit design for massive MIMO SIC detector. The proposed circuit comprises several judiciously designed analog matrix computing modules and hybrid analog-digital slicers, which enables the proposed circuit to perform the SIC algorithm with a hybrid analog-digital computing architecture. We show that the computing speed and the computational energy-efficiency of the proposed detector circuit are 43 times faster and 110 times higher, respectively, than those of a traditional 8-core digital signal processor (DSP), and also advantageous over the benchmark high-performance field programmable gate array (FPGA) and graphics processing unit (GPU).

Paper number 36:
Title: A Generalized Graph Signal Processing Framework for Multiple Hypothesis Testing over Networks
Authors: Xingchao Jian, Martin Gölz, Feng Ji, Wee Peng Tay, Abdelhak M. Zoubir
Abstract: We consider the multiple hypothesis testing (MHT) problem over the joint domain formed by a graph and a measure space. On each sample point of this joint domain, we assign a hypothesis test and a corresponding $p$-value. The goal is to make decisions for all hypotheses simultaneously, using all available $p$-values. In practice, this problem resembles the detection problem over a sensor network during a period of time. To solve this problem, we extend the traditional two-groups model such that the prior probability of the null hypothesis and the alternative distribution of $p$-values can be inhomogeneous over the joint domain. We model the inhomogeneity via a generalized graph signal. This more flexible statistical model yields a more powerful detection strategy by leveraging the information from the joint domain.

Paper number 37:
Title: BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing
Authors: Masaya Kawamura, Takuya Hasumi, Yuma Shirahata, Ryuichi Yamamoto
Abstract: This paper proposes a highly compact, lightweight text-to-speech (TTS) model for on-device applications. To reduce the model size, the proposed model introduces two techniques. First, we introduce quantization-aware training (QAT), which quantizes model parameters during training to as low as 1.58-bit. In this case, most of 32-bit model parameters are quantized to ternary values {-1, 0, 1}. Second, we propose a method named weight indexing. In this method, we save a group of 1.58-bit weights as a single int8 index. This allows for efficient storage of model parameters, even on hardware that treats values in units of 8-bit. Experimental results demonstrate that the proposed method achieved 83 % reduction in model size, while outperforming the baseline of similar model size without quantization in synthesis quality.

Paper number 38:
Title: Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models
Authors: Parismita Gogoi, Sishir Kalita, Wendy Lalhminghlui, Viyazonuo Terhiija, Moakala Tzudir, Priyankoo Sarmah, S. R. M. Prasanna
Abstract: This study explores the use of self-supervised learning (SSL) models for tone recognition in three low-resource languages from North Eastern India: Angami, Ao, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on both tonal and non-tonal languages. We analyze tone-wise performance across the layers for all three languages and compare the different models. Our results show that tone recognition works best for Mizo and worst for Angami. The middle layers of the SSL models are the most important for tone recognition, regardless of the pre-training language, i.e. tonal or non-tonal. We have also found that the tone inventory, tone types, and dialectal variations affect tone recognition. These findings provide useful insights into the strengths and weaknesses of SSL-based embeddings for tonal languages and highlight the potential for improving tone recognition in low-resource settings. The source code is available at GitHub 1 .

Paper number 39:
Title: Fast Sampling for System Identification: Overcoming Noise, Offsets, and Closed-Loop Challenges with State Variable Filter
Authors: Ichiro Maruta, Toshiharu Sugie
Abstract: This paper investigates the effects of setting the sampling frequency significantly higher than conventional guidelines in system identification. Although continuous-time identification methods resolve the numerical difficulties encountered in discrete-time approaches when employing fast sampling (e.g., the problems caused by all poles approaching unity), the potential benefits of using sampling frequencies that far exceed traditional rules like the "ten times the bandwidth" guideline remained largely unexplored. We show that using a state variable filter (SVF)-like least squares approach, the variance of the estimation error scales as $O(h)$ with the sampling interval $h$. Importantly, this scaling holds even with colored noise or noise correlations between variables. Thus, increasing the sampling frequency and applying the SVF method offers a novel solution for challenging problems such as closed-loop system identification and measurements with offsets. Theoretical findings are supported by numerical examples, including the closed-loop identification of unstable multi-input multi-output (MIMO) systems.

Paper number 40:
Title: Spatiotemporal Prediction of Electric Vehicle Charging Load Based on Large Language Models
Authors: Hang Fan, Mingxuan Li, Jingshi Cui, Zuhan Zhang, Wencai Run, Dunnan Liu
Abstract: The rapid growth of EVs and the subsequent increase in charging demand pose significant challenges for load grid scheduling and the operation of EV charging stations. Effectively harnessing the spatiotemporal correlations among EV charging stations to improve forecasting accuracy is complex. To tackle these challenges, we propose EV-LLM for EV charging loads based on LLMs in this paper. EV-LLM integrates the strengths of Graph Convolutional Networks (GCNs) in spatiotemporal feature extraction with the generalization capabilities of fine-tuned generative LLMs. Also, EV-LLM enables effective data mining and feature extraction across multimodal and multidimensional datasets, incorporating historical charging data, weather information, and relevant textual descriptions to enhance forecasting accuracy for multiple charging stations. We validate the effectiveness of EV-LLM by using charging data from 10 stations in California, demonstrating its superiority over the other traditional deep learning methods and potential to optimize load grid scheduling and support vehicle-to-grid interactions.

Paper number 41:
Title: Frame-Level Real-Time Assessment of Stroke Rehabilitation Exercises from Video-Level Labeled Data: Task-Specific vs. Foundation Models
Authors: Gonçalo Mesquita, Ana Rita Cóias, Artur Dubrawski, Alexandre Bernardino
Abstract: The growing demands of stroke rehabilitation have increased the need for solutions to support autonomous exercising. Virtual coaches can provide real-time exercise feedback from video data, helping patients improve motor function and keep engagement. However, training real-time motion analysis systems demands frame-level annotations, which are time-consuming and costly to obtain. In this work, we present a framework that learns to classify individual frames from video-level annotations for real-time assessment of compensatory motions in rehabilitation exercises. We use a gradient-based technique and a pseudo-label selection method to create frame-level pseudo-labels for training a frame-level classifier. We leverage pre-trained task-specific models - Action Transformer, SkateFormer - and a foundation model - MOMENT - for pseudo-label generation, aiming to improve generalization to new patients. To validate the approach, we use the \textit{SERE} dataset with 18 post-stroke patients performing five rehabilitation exercises annotated on compensatory motions. MOMENT achieves better video-level assessment results (AUC = $73\%$), outperforming the baseline LSTM (AUC = $58\%$). The Action Transformer, with the Integrated Gradient technique, leads to better outcomes (AUC = $72\%$) for frame-level assessment, outperforming the baseline trained with ground truth frame-level labeling (AUC = $69\%$). We show that our proposed approach with pre-trained models enhances model generalization ability and facilitates the customization to new patients, reducing the demands of data labeling.

Paper number 42:
Title: Multiuser Beamformig for Pinching-Antenna Systems: An Element-wise Optimization Framework
Authors: Mingjun Sun, Chongjun Ouyang, Shaochuan Wu, Yuanwei Liu
Abstract: The pinching-antenna system (PASS) reconstructs wireless channels through pinching beamforming, i.e., optimizing the activated locations of pinching antennas (PAs) along the waveguide. The aim of this article is to investigate the joint design of baseband beamforming and pinching beamforming. A low-complexity element-wise sequential optimization framework is proposed to address the sum-rate maximization problem in PASS-enabled downlink and uplink channels. i) For the downlink scenario, maximum ratio transmission (MRT), zero-forcing (ZF), and minimum mean square error (MMSE) beamforming schemes are employed as baseband beamformers. For each beamformer, a closed-form expression for the downlink sum-rate is derived as a single-variable function with respect to the pinching beamformer. Based on this, a sequential optimization method is proposed, where the positions of the PAs are updated element-wise using a low-complexity one-dimensional search. ii) For the uplink scenario, signal detection is performed using maximum ratio combining (MRC), ZF, and MMSE combiners. A closed-form sum-rate expression is derived for each linear combiner, and a similar element-wise design is applied to optimize the pinching beamforming. Numerical results are provided to validate the effectiveness of the proposed method and demonstrate that: (i) For all considered linear beamformers, the proposed PASS architecture outperforms conventional fixed-antenna systems in terms of sum-rate performance; (ii) in both downlink and uplink channels, ZF achieves performance close to that of MMSE and significantly outperforms MRT or MRC; and (iii) the proposed element-wise design eliminates the need for alternating updates between the baseband and pinching beamformers, thereby ensuring low computational complexity.

Paper number 43:
Title: Nonlinear Sparse Bayesian Learning Methods with Application to Massive MIMO Channel Estimation with Hardware Impairments
Authors: Arttu Arjas, Italo Atzeni
Abstract: Accurate channel estimation is critical for realizing the performance gains of massive multiple-input multiple-output (MIMO) systems. Traditional approaches to channel estimation typically assume ideal receiver hardware and linear signal models. However, practical receivers suffer from impairments such as nonlinearities in the low-noise amplifiers and quantization errors, which invalidate standard model assumptions and degrade the estimation accuracy. In this work, we propose a nonlinear channel estimation framework that models the distortion function arising from hardware impairments using Gaussian process (GP) regression while leveraging the inherent sparsity of massive MIMO channels. First, we form a GP-based surrogate of the distortion function, employing pseudo-inputs to reduce the computational complexity. Then, we integrate the GP-based surrogate of the distortion function into newly developed enhanced sparse Bayesian learning (SBL) methods, enabling distortion-aware sparse channel estimation. Specifically, we propose two nonlinear SBL methods based on distinct optimization objectives, each offering a different trade-off between estimation accuracy and computational complexity. Numerical results demonstrate significant gains over the Bussgang linear minimum mean squared error estimator and linear SBL, particularly under strong distortion and at high signal-to-noise ratio.

Paper number 44:
Title: Discrete Element Parameter Calibration of Livestock Salt Based on Particle Scaling
Authors: Lulu Nie, Baoqin Wen, Jingbin Li, Shufeng Li, Yali Li, Zhaokun Zhang, Zhiyuan Wang, Zhihao Fan
Abstract: In order to obtain accurate contact parameters for the discrete element simulation of salt particles used in animal husbandry, the principle of particle contact scaling and dimensional analysis were used for particle scaling. Firstly, the Plackett Burman experiment was used to screen the parameters that significantly affect the angle of repose: salt salt rolling friction coefficient, salt salt recovery coefficient, and salt steel rolling friction coefficient. Considering the influence of other parameters, a combination of bench and simulation experiments was used to calibrate the contact parameters between salt particles and steel plates used in animal husbandry in EDEM. Finally, through the stacking test, steepest climbing test, and orthogonal rotation combination test, the salt salt rolling friction coefficient was obtained to be 0.23, the salt salt recovery coefficient was 0.544, and the salt steel rolling friction coefficient was 0.368, which were verified through bench tests. The experimental results show that the relative error between the actual value of the stacking angle and the simulation results is 0.6%. The results indicate that the calibrated contact parameters can be used for discrete element simulation of salt particles for animal husbandry, providing reference for the design of quantitative feeding screws and silos.

Paper number 45:
Title: An OTFS-based Random Access Scheme for GNSS Independent Operation in NTN
Authors: Marius Caus, Musbah Shaat
Abstract: This paper investigates the random access procedure for non-terrestrial networks operating without global navigation satellite system (GNSS) support. In such scenarios, positioning uncertainties can reach several kilometers, which directly impacts the open-loop compensation mechanisms employed by the user equipment. To ensure that the resulting time and carrier frequency offsets can be handled by the network, the robustness of the standardized random access signal design and detection scheme must be enhanced. To extend radio access capabilities, identical Zadoff Chu (ZC) sequences are concatenated and then modulated into the orthogonal time frequency space (OTFS) modulation. Thanks to the specific characteristics of the OTFS-based random access signal, the received sequences are coherently combined, thereby maximizing the desired signal strength. Additionally, the proposed preamble minimizes the overhead associated with the cyclic prefix (CP) transmission. Numerical evaluations in a regenerative low-Earth-orbit (LEO) satellite scenario show that, despite significant positioning errors, the proposed OTFS random access design attains comparable peak-to-average power ratio (PAPR) and missed detection probability (MDP) to OFDM-based solutions, while improving spectral confinement and reducing overhead. These results demonstrate that the proposed OTFS-based random access design offers a robust and spectrally efficient alternative to OFDM for GNSS-independent NTN access.

Paper number 46:
Title: Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering
Authors: Christian Tinauer, Maximilian Sackl, Stefan Ropele, Christian Langkammer
Abstract: Deep learning models have shown strong performance in classifying Alzheimer's disease (AD) from R2* maps, but their decision-making remains opaque, raising concerns about interpretability. Previous studies suggest biases in model decisions, necessitating further analysis. This study uses Layer-wise Relevance Propagation (LRP) and spectral clustering to explore classifier decision strategies across preprocessing and training configurations using R2* maps. We trained a 3D convolutional neural network on R2* maps, generating relevance heatmaps via LRP and applied spectral clustering to identify dominant patterns. t-Stochastic Neighbor Embedding (t-SNE) visualization was used to assess clustering structure. Spectral clustering revealed distinct decision patterns, with the relevance-guided model showing the clearest separation between AD and normal control (NC) cases. The t-SNE visualization confirmed that this model aligned heatmap groupings with the underlying subject groups. Our findings highlight the significant impact of preprocessing and training choices on deep learning models trained on R2* maps, even with similar performance metrics. Spectral clustering offers a structured method to identify classification strategy differences, emphasizing the importance of explainability in medical AI.

Paper number 47:
Title: Stabilization of Linear Switched Systems with Long Input Delay via Average or Averaging Predictor Feedbacks
Authors: Andreas Katsanikakis, Nikolaos Bekiaris-Liberis
Abstract: We develop delay-compensating feedback laws for linear switched systems with time-dependent switching. Because the future values of the switching signal, which are needed for constructing an exact predictor-feedback law, may be unavailable at current time, the key design challenge is how to construct a proper predictor state. We resolve this challenge constructing two alternative, average predictor-based feedback laws. The first is viewed as a predictor-feedback law for a particular average system, properly modified to provide exact state predictions over a horizon that depends on a minimum dwell time of the switching signal (when it is available). The second is, essentially, a modification of an average of predictor feedbacks, each one corresponding to the fixed-mode predictor-feedback law. We establish that under the control laws introduced, the closed-loop systems are (uniformly) exponentially stable, provided that the differences among system's matrices and among (nominal stabilizing) controller's gains are sufficiently small, with a size that is inversely proportional to the delay length. Since no restriction is imposed on the delay, such a limitation is inherent to the problem considered (in which the future switching signal values are unavailable), and thus, it cannot be removed. The stability proof relies on multiple Lyapunov functionals constructed via backstepping and derivation of solutions' estimates for quantifying the difference between average and exact predictor states. We present consistent numerical simulation results, which illustrate the necessity of employing the average predictor-based laws and demonstrate the performance improvement when the knowledge of a minimum dwell time is properly utilized for improving state prediction accuracy.

Paper number 48:
Title: Sound Field Reconstruction Using Physics-Informed Boundary Integral Networks
Authors: Stefano Damiano, Toon van Waterschoot
Abstract: Sound field reconstruction refers to the problem of estimating the acoustic pressure field over an arbitrary region of space, using only a limited set of measurements. Physics-informed neural networks have been adopted to solve the problem by incorporating in the training loss function the governing partial differential equation, either the Helmholtz or the wave equation. In this work, we introduce a boundary integral network for sound field reconstruction. Relying on the Kirchhoff-Helmholtz boundary integral equation to model the sound field in a given region of space, we employ a shallow neural network to retrieve the pressure distribution on the boundary of the considered domain, enabling to accurately retrieve the acoustic pressure inside of it. Assuming the positions of measurement microphones are known, we train the model by minimizing the mean squared error between the estimated and measured pressure at those locations. Experimental results indicate that the proposed model outperforms existing physics-informed data-driven techniques.

Paper number 49:
Title: SVD-Based Graph Fractional Fourier Transform on Directed Graphs and Its Application
Authors: Lu Li, Haiye Huo
Abstract: Graph fractional Fourier transform (GFRFT) is an extension of graph Fourier transform (GFT) that provides an additional fractional analysis tool for graph signal processing (GSP) by generalizing temporal-vertex domain Fourier analysis to fractional orders. In recent years, a large number of studies on GFRFT based on undirected graphs have emerged, but there are very few studies on directed graphs. Therefore, in this paper, one of our main contributions is to introduce two novel GFRFTs defined on Cartesian product graph of two directed graphs, by performing singular value decomposition on graph fractional Laplacian matrices. We prove that two proposed GFRFTs can effectively express spatial-temporal data sets on directed graphs with strong correlation. Moreover, we extend the theoretical results to a generalized Cartesian product graph, which is constructed by $m$ directed graphs. Finally, the denoising performance of our proposed two GFRFTs are testified through simulation by processing hourly temperature data sets collected from 32 weather stations in the Brest region of France.

Paper number 50:
Title: Uniqueness of phase retrieval from offset linear canonical transform
Authors: Jing Liu, Haiye Huo
Abstract: The classical phase retrieval refers to the recovery of an unknown signal from its Fourier magnitudes, which is widely used in fields such as quantum mechanics, signal processing, optics, etc. The offset linear canonical transform (OLCT), which is a more general type of linear integral transform including Fourier transform (FT), fractional Fourier transform (FrFT), and linear canonical transform (LCT) as its special cases. Hence, in this paper, we focus on the uniqueness problem of phase retrieval in the framework of OLCT. First, we prove that all the nontrivial ambiguities in continuous OLCT phase retrieval can be represented by convolution operators, and demonstrate that a continuous compactly supported signal can be uniquely determined up to a global phase from its multiple magnitude-only OLCT measurements. Moreover, we investigate the nontrivial ambiguities in the discrete OLCT phase retrieval case. Furthermore, we demenstrate that a nonseparable function can be uniquely recovered from its magnitudes of short-time OLCT (STOLCT) up to a global phase. Finally, we show that signals which are bandlimited in FT or OLCT domain can be reconstructed from its sampled STOLCT magnitude measurements, up to a global phase, providing the ambiguity function of window function satisfies some mild conditions.

Paper number 51:
Title: MudiNet: Task-guided Disentangled Representation Learning for 5G Indoor Multipath-assisted Positioning
Authors: Ye Tian, Xueting Xu, Ao Peng
Abstract: In the fifth-generation communication system (5G), multipath-assisted positioning (MAP) has emerged as a promising approach. With the enhancement of signal resolution, multipath component (MPC) are no longer regarded as noise but rather as valuable information that can contribute to positioning. However, existing research often treats reflective surfaces as ideal reflectors, while being powerless in the face of indistinguishable multipath caused by diffuse reflectors. This study approaches diffuse reflectors from the perspective of uncertainty, investigating the statistical distribution characteristics of indoor diffuse and specular reflectors. Based on these insights, a task-guided disentangled representation learning method leveraging multi-time channel impulse response (CIR) observations is designed to directly map CIRs to positions, while mitigating the adverse effects of components that contribute minimally to localization accuracy (e.g., diffuse multipath).In this semi-supervised learning framework, a global feature extraction architecture based on self-attention is proposed to capture location-independent wireless environmental information, while an MLP is employed to extract the time-varying features related to user equipment (UE) positions. Variational inference based on a latent variable model (LVM) is applied to separate independent features within the CIR, with position labels guiding the LVM to express components more beneficial for localization. Additionally, we provide a feasibility proof for the separability of diffuse and specular environmental features in CIRs. Simulation results demonstrate that the proposed method achieves higher localization accuracy compared to conventional search-based localization methods, with enhanced robustness against indistinguishable multipath from diffuse reflectors.

Paper number 52:
Title: An Improved Finite Element Modeling Method for Triply Periodic Minimal Surface Structures Based on Element Size and Minimum Jacobian
Authors: Siqi Wang, Chuangyu Jiang, Xiaodong Zhang, Yilong Zhang, Baoqiang Zhang, Huageng Luo
Abstract: Triply periodic minimal surface (TPMS) structures, a type of lattice structure, have garnered significant attention due to their lightweight nature, controllability, and excellent mechanical properties. Voxel-based modeling is a widely used method for investigating the mechanical behavior of such lattice structures through finite element simulations. This study proposes a two-parameter voxel method that incorporates joint control of element size and minimum Jacobian (MJ). Numerical results indicate that the simulation outcomes tend to stabilize when the MJ reaches 0.3. The grid convergence index (GCI), based on Richardson extrapolation, is introduced to systematically assess the numerical convergence behavior of both voxel models and the proposed two-parameter voxel models. This provides a systematic and objective framework for evaluating discretization errors and mesh convergence in TPMS modeling. Compared with traditional voxel method, the proposed method exhibits superior mesh convergence, solution accuracy, and computational efficiency. Furthermore, the two-parameter voxel method also shows excellent applicability in the analysis of graded TPMS structures, exhibiting even better convergence behavior than in uniform structures.

Paper number 53:
Title: Conformal coronary calcification volume estimation with conditional coverage via histogram clustering
Authors: Olivier Jaubert, Salman Mohammadi, Keith A. Goatman, Shadia S. Mikhael, Conor Bradley, Rebecca Hughes, Richard Good, John H. Hipwell, Sonia Dahdouh
Abstract: Incidental detection and quantification of coronary calcium in CT scans could lead to the early introduction of lifesaving clinical interventions. However, over-reporting could negatively affect patient wellbeing and unnecessarily burden the medical system. Therefore, careful considerations should be taken when automatically reporting coronary calcium scores. A cluster-based conditional conformal prediction framework is proposed to provide score intervals with calibrated coverage from trained segmentation networks without retraining. The proposed method was tuned and used to calibrate predictive intervals for 3D UNet models (deterministic, MCDropout and deep ensemble) reaching similar coverage with better triage metrics compared to conventional conformal prediction. Meaningful predictive intervals of calcium scores could help triage patients according to the confidence of their risk category prediction.

Paper number 54:
Title: Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays
Authors: Bulat Maksudov, Kathleen Curran, Alessandra Mileo
Abstract: An essential step in deploying medical imaging models is ensuring alignment with clinical knowledge and interpretability. We focus on mapping clinical concepts into the latent space of generative models to identify Concept Activation Vectors (CAVs). Using a simple reconstruction autoencoder, we link user-defined concepts to image-level features without explicit label training. The extracted concepts are stable across datasets, enabling visual explanations that highlight clinically relevant features. By traversing latent space along concept directions, we produce counterfactuals that exaggerate or reduce specific clinical features. Preliminary results on chest X-rays show promise for large pathologies like cardiomegaly, while smaller pathologies remain challenging due to reconstruction limits. Although not outperforming baselines, this approach offers a path toward interpretable, concept-based explanations aligned with clinical knowledge.

Paper number 55:
Title: Model Splitting Enhanced Communication-Efficient Federated Learning for CSI Feedback
Authors: Yanjie Dong, Haijun Zhang, Gaojie Chen, Xiaoyi Fan, Victor C. M. Leung, Xiping Hu
Abstract: Recent advancements have introduced federated machine learning-based channel state information (CSI) compression before the user equipments (UEs) upload the downlink CSI to the base transceiver station (BTS). However, most existing algorithms impose a high communication overhead due to frequent parameter exchanges between UEs and BTS. In this work, we propose a model splitting approach with a shared model at the BTS and multiple local models at the UEs to reduce communication overhead. Moreover, we implant a pipeline module at the BTS to reduce training time. By limiting exchanges of boundary parameters during forward and backward passes, our algorithm can significantly reduce the exchanged parameters over the benchmarks during federated CSI feedback training.

Paper number 56:
Title: A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging
Authors: Xuanru Zhou, Jiarun Liu, Shoujun Yu, Hao Yang, Cheng Li, Tao Tan, Shanshan Wang
Abstract: In medical imaging, 4D MRI enables dynamic 3D visualization, yet the trade-off between spatial and temporal resolution requires prolonged scan time that can compromise temporal fidelity--especially during rapid, large-amplitude motion. Traditional approaches typically rely on registration-based interpolation to generate intermediate frames. However, these methods struggle with large deformations, resulting in misregistration, artifacts, and diminished spatial consistency. To address these challenges, we propose TSSC-Net, a novel framework that generates intermediate frames while preserving spatial consistency. To improve temporal fidelity under fast motion, our diffusion-based temporal super-resolution network generates intermediate frames using the start and end frames as key references, achieving 6x temporal super-resolution in a single inference step. Additionally, we introduce a novel tri-directional Mamba-based module that leverages long-range contextual information to effectively resolve spatial inconsistencies arising from cross-slice misalignment, thereby enhancing volumetric coherence and correcting cross-slice errors. Extensive experiments were performed on the public ACDC cardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results demonstrate that TSSC-Net can generate high-resolution dynamic MRI from fast-motion data while preserving structural fidelity and spatial consistency.

Paper number 57:
Title: A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks
Authors: Loan Dao, Ngoc Quoc Ly
Abstract: Over the past decade, Medical Image Segmentation (MIS) using Deep Neural Networks (DNNs) has achieved significant performance improvements and holds great promise for future developments. This paper presents a comprehensive study on MIS based on DNNs. Intelligent Vision Systems are often evaluated based on their output levels, such as Data, Information, Knowledge, Intelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at these levels are the focus of research. Additionally, Explainable Artificial Intelligence (XAI) has become an important research direction, as it aims to uncover the "black box" nature of previous DNN architectures to meet the requirements of transparency and ethics. The study emphasizes the importance of MIS in disease diagnosis and early detection, particularly for increasing the survival rate of cancer patients through timely diagnosis. XAI and early prediction are considered two important steps in the journey from "intelligence" to "wisdom." Additionally, the paper addresses existing challenges and proposes potential solutions to enhance the efficiency of implementing DNN-based MIS.

Paper number 58:
Title: Identification of RIS-Assisted Paths for Wireless Integrated Sensing and Communication
Authors: Zeyu Huang, Stefan Schwarz, Bashar Tahir, Markus Rupp
Abstract: Distinguishing between reconfigurable intelligent surface (RIS) assisted paths and non-line-of-sight (NLOS) paths is a fundamental problem for RIS-assisted integrated sensing and communication. In this work, we propose a pattern alternation scheme for the RIS response that uses part of the RIS as a dynamic part to modulate the estimated channel power, which can considerably help the user equipments (UEs) to identify the RIS-assisted paths. Under such a dynamic setup, we formulate the detection framework for a single UE, where we develop a statistical model of the estimated channel power, allowing us to analytically evaluate the performance of the system. We investigate our method under two critical factors: the number of RIS elements allocated for the dynamic part and the allocation of RIS elements among different users. Simulation results verify the accuracy of our analysis.

Paper number 59:
Title: Recent Advances in Medical Image Classification
Authors: Loan Dao, Ngoc Quoc Ly
Abstract: Medical image classification is crucial for diagnosis and treatment, benefiting significantly from advancements in artificial intelligence. The paper reviews recent progress in the field, focusing on three levels of solutions: basic, specific, and applied. It highlights advances in traditional methods using deep learning models like Convolutional Neural Networks and Vision Transformers, as well as state-of-the-art approaches with Vision Language Models. These models tackle the issue of limited labeled data, and enhance and explain predictive results through Explainable Artificial Intelligence.

Paper number 60:
Title: HiFiTTS-2: A Large-Scale High Bandwidth Speech Dataset
Authors: Ryan Langman, Xuesong Yang, Paarth Neekhara, Shehzeen Hussain, Edresson Casanova, Evelina Bakhturina, Jason Li
Abstract: This paper introduces HiFiTTS-2, a large-scale speech dataset designed for high-bandwidth speech synthesis. The dataset is derived from LibriVox audiobooks, and contains approximately 36.7k hours of English speech for 22.05 kHz training, and 31.7k hours for 44.1 kHz training. We present our data processing pipeline, including bandwidth estimation, segmentation, text preprocessing, and multi-speaker detection. The dataset is accompanied by detailed utterance and audiobook metadata generated by our pipeline, enabling researchers to apply data quality filters to adapt the dataset to various use cases. Experimental results demonstrate that our data pipeline and resulting dataset can facilitate the training of high-quality, zero-shot text-to-speech (TTS) models at high bandwidths.

Paper number 61:
Title: Synthetic multi-inversion time magnetic resonance images for visualization of subcortical structures
Authors: Savannah P. Hays, Lianrui Zuo, Anqi Feng, Yihao Liu, Blake E. Dewey, Jiachen Zhuo, Ellen M. Mowry, Scott D. Newsome Jerry L. Prince, Aaron Carass
Abstract: Purpose: Visualization of subcortical gray matter is essential in neuroscience and clinical practice, particularly for disease understanding and surgical this http URL multi-inversion time (multi-TI) T$_1$-weighted (T$_1$-w) magnetic resonance (MR) imaging improves visualization, it is rarely acquired in clinical settings. Approach: We present SyMTIC (Synthetic Multi-TI Contrasts), a deep learning method that generates synthetic multi-TI images using routinely acquired T$_1$-w, T$_2$-weighted (T$_2$-w), and FLAIR images. Our approach combines image translation via deep neural networks with imaging physics to estimate longitudinal relaxation time (T$_1$) and proton density (PD) maps. These maps are then used to compute multi-TI images with arbitrary inversion times. Results: SyMTIC was trained using paired MPRAGE and FGATIR images along with T$_2$-w and FLAIR images. It accurately synthesized multi-TI images from standard clinical inputs, achieving image quality comparable to that from explicitly acquired multi-TI this http URL synthetic images, especially for TI values between 400-800 ms, enhanced visualization of subcortical structures and improved segmentation of thalamic nuclei. Conclusion: SyMTIC enables robust generation of high-quality multi-TI images from routine MR contrasts. It generalizes well to varied clinical datasets, including those with missing FLAIR images or unknown parameters, offering a practical solution for improving brain MR image visualization and analysis.

Paper number 62:
Title: Causal Discovery in Dynamic Fading Wireless Networks
Authors: Oluwaseyi Giwa
Abstract: Dynamic causal discovery in wireless networks is essential due to evolving interference, fading, and mobility, which complicate traditional static causal models. This paper addresses causal inference challenges in dynamic fading wireless environments by proposing a sequential regression-based algorithm with a novel application of the NOTEARS acyclicity constraint, enabling efficient online updates. We derive theoretical lower and upper bounds on the detection delay required to identify structural changes, explicitly quantifying their dependence on network size, noise variance, and fading severity. Monte Carlo simulations validate these theoretical results, demonstrating linear increases in detection delay with network size, quadratic growth with noise variance, and inverse-square dependence on the magnitude of structural changes. Our findings provide rigorous theoretical insights and practical guidelines for designing robust online causal inference mechanisms to maintain network reliability under nonstationary wireless conditions.

Paper number 63:
Title: Video Quality Monitoring for Remote Autonomous Vehicle Control
Authors: Dimitrios Kafetzis, Nikos Fotiou, Savvas Argyropoulos, Jad Nasreddine, Iordanis Koutsopoulos
Abstract: The delivery of high-quality, low-latency video streams is critical for remote autonomous vehicle control, where operators must intervene in real time. However, reliable video delivery over Fourth/Fifth-Generation (4G/5G) mobile networks is challenging due to signal variability, mobility-induced handovers, and transient congestion. In this paper, we present a comprehensive blueprint for an integrated video quality monitoring system, tailored to remote autonomous vehicle operation. Our proposed system includes subsystems for data collection onboard the vehicle, video capture and compression, data transmission to edge servers, real-time streaming data management, Artificial Intelligence (AI) model deployment and inference execution, and proactive decision-making based on predicted video quality. The AI models are trained on a hybrid dataset that combines field-trial measurements with synthetic stress segments and covers Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and encoder-only Transformer architectures. As a proof of concept, we benchmark 20 variants from these model classes together with feed-forward Deep Neural Network (DNN) and linear-regression baselines, reporting accuracy and inference latency. Finally, we study the trade-offs between onboard and edge-based inference. We further discuss the use of explainable AI techniques to enhance transparency and accountability during critical remote-control interventions. Our proactive approach to network adaptation and Quality of Experience (QoE) monitoring aims to enhance remote vehicle operation over next-generation wireless networks.

Paper number 64:
Title: Dynamics and Control of Vision-Aided Multi-UAV-tethered Netted System Capturing Non-Cooperative Target
Authors: Runhan Liu, Hui Ren, Wei Fan
Abstract: As the number of Unmanned Aerial Vehicles (UAVs) operating in low-altitude airspace continues to increase, non-cooperative targets pose growing challenges to low-altitude operations. To address this issue, this paper proposes a multi-UAV-tethered netted system as a non-lethal solution for capturing non-cooperative targets. To validate the proposed system, we develop mySim, a multibody dynamics-based UAV simulation environment that integrates high-precision physics modeling, vision-based motion tracking, and reinforcement learning-driven control strategies. In mySim, the spring-damper model is employed to simulate the dynamic behavior of the tethered net, while the dynamics of the entire system is modeled using multibody dynamics (MBD) to achieve accurate representations of system interactions. The motion of the UAVs and the target are estimated using VINS-MONO and DETR, and the system autonomously executes the capture strategy through MAPPO. Simulation results demonstrate that mySim accurately simulates dynamics and control of the system, successfully enabling the multi-UAV-tethered netted system to capture both non-propelled and maneuvering non-cooperative targets. By providing a high-precision simulation platform that integrates dynamics modeling with perception and learning-based control, mySim enables efficient testing and optimization of UAV-based control policies before real-world deployment. This approach offers significant advantages for simulating complex UAVs coordination tasks and has the potential to be applied to the design of other UAV-based systems.

Paper number 65:
Title: Relay Selection and User Equipment Admission in Resource-Efficient NextG Sidelink Communications
Authors: Yalin E. Sagduyu, Tugba Erpek, Sastry Kompella, Kemal Davaslioglu
Abstract: 5G/6G sidelink communications addresses the challenge of connecting outer UEs, which are unable to directly access a base station (gNodeB), through inner UEs that act as relays to connect to the gNodeB. The key performance indicators include the achievable rates, the number of outer UEs that can connect to a gNodeB, and the latency experienced by outer UEs in establishing connections. We consider problem of determining the assignment of outer UEs to inner UEs based on the channel, interference, and traffic characteristics. We formulate an optimization problem to maximize a weighted sum rate of UEs, where weights can represent priority, waiting time, and queue length. This optimization accommodates constraints related to channel and interference characteristics that influence the rates at which links can successfully carry assigned traffic. While an exhaustive search can establish an upper bound on achievable rates by this non-convex optimization problem, it becomes impractical for larger number of outer UEs due to scalability issues related to high computational complexity. To address this, we present a greedy algorithm that incrementally selects links to maximize the sum rate, considering already activated links. This algorithm, although effective in achieving high sum rates, may inadvertently overlook some UEs, raising concerns about fairness. To mitigate this, we introduce a fairness-oriented algorithm that adjusts weights based on waiting time or queue length, ensuring that UEs with initially favorable conditions do not unduly disadvantage others over time. We show that this strategy not only improves the average admission ratio of UEs but also ensures a more equitable distribution of service among them, thereby providing a balanced and fair solution to sidelink communications.

Paper number 66:
Title: Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons
Authors: Aref Ghoreishee, Abhishek Mishra, John Walsh, Anup Das, Nagarajan Kandasamy
Abstract: We propose a new ternary spiking neuron model to improve the representation capacity of binary spiking neurons in deep Q-learning. Although a ternary neuron model has recently been introduced to overcome the limited representation capacity offered by the binary spiking neurons, we show that its performance is worse than that of binary models in deep Q-learning tasks. We hypothesize gradient estimation bias during the training process as the underlying potential cause through mathematical and empirical analysis. We propose a novel ternary spiking neuron model to mitigate this issue by reducing the estimation bias. We use the proposed ternary spiking neuron as the fundamental computing unit in a deep spiking Q-learning network (DSQN) and evaluate the network's performance in seven Atari games from the Gym environment. Results show that the proposed ternary spiking neuron mitigates the drastic performance degradation of ternary neurons in Q-learning tasks and improves the network performance compared to the existing binary neurons, making DSQN a more practical solution for on-board autonomous decision-making tasks.

Paper number 67:
Title: Maximum Likelihood for Logistic Regression Model with Incomplete and Hybrid-Type Covariates
Authors: Mohamed Cherifi, Xujia Zhu, Mohammed Nabil El Korso, Ammar Mesloub
Abstract: Logistic regression is a fundamental and widely used statistical method for modeling binary outcomes based on covariates. However, the presence of missing data, particularly in settings involving hybrid covariates (a mix of discrete and continuous variables), poses significant challenges. In this paper, we propose a novel Expectation-Maximization based algorithm tailored for parameter estimation in logistic regression models with missing hybrid covariates. The proposed method is specifically designed to handle these complexities, delivering efficient parameter estimates. Through comprehensive simulations and real-world application, we demonstrate that our approach consistently outperforms traditional methods, achieving superior accuracy and reliability.

Paper number 68:
Title: Differentially Private Distribution Release of Gaussian Mixture Models via KL-Divergence Minimization
Authors: Hang Liu, Anna Scaglione, Sean Peisert
Abstract: Gaussian Mixture Models (GMMs) are widely used statistical models for representing multi-modal data distributions, with numerous applications in data mining, pattern recognition, data simulation, and machine learning. However, recent research has shown that releasing GMM parameters poses significant privacy risks, potentially exposing sensitive information about the underlying data. In this paper, we address the challenge of releasing GMM parameters while ensuring differential privacy (DP) guarantees. Specifically, we focus on the privacy protection of mixture weights, component means, and covariance matrices. We propose to use Kullback-Leibler (KL) divergence as a utility metric to assess the accuracy of the released GMM, as it captures the joint impact of noise perturbation on all the model parameters. To achieve privacy, we introduce a DP mechanism that adds carefully calibrated random perturbations to the GMM parameters. Through theoretical analysis, we quantify the effects of privacy budget allocation and perturbation statistics on the DP guarantee, and derive a tractable expression for evaluating KL divergence. We formulate and solve an optimization problem to minimize the KL divergence between the released and original models, subject to a given $(\epsilon, \delta)$-DP constraint. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach achieves strong privacy guarantees while maintaining high utility.

Paper number 69:
Title: CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model
Authors: Yuxuan Chen, Haipeng Xie
Abstract: The denoising diffusion probabilistic model has become a mainstream generative model, achieving significant success in various computer vision tasks. Recently, there has been initial exploration of applying diffusion models to time series tasks. However, existing studies still face challenges in multi-scale feature alignment and generative capabilities across different entities and long-time scales. In this paper, we propose CHIME, a conditional hallucination and integrated multi-scale enhancement framework for time series diffusion models. By employing multi-scale decomposition and adaptive integration, CHIME captures the decomposed features of time series, achieving in-domain distribution alignment between generated and original samples. In addition, we introduce a feature hallucination module in the conditional denoising process, enabling the transfer of temporal features through the training of category-independent transformation layers. Experimental results on publicly available real-world datasets demonstrate that CHIME achieves state-of-the-art performance and exhibits excellent generative generalization capabilities in few-shot scenarios.

Paper number 70:
Title: Local Equivariance Error-Based Metrics for Evaluating Sampling-Frequency-Independent Property of Neural Network
Authors: Kanami Imamura, Tomohiko Nakamura, Norihiro Takamune, Kohei Yatabe, Hiroshi Saruwatari
Abstract: Audio signal processing methods based on deep neural networks (DNNs) are typically trained only at a single sampling frequency (SF) and therefore require signal resampling to handle untrained SFs. However, recent studies have shown that signal resampling can degrade performance with untrained SFs. This problem has been overlooked because most studies evaluate only the performance at trained SFs. In this paper, to assess the robustness of DNNs to SF changes, which we refer to as the SF-independent (SFI) property, we propose three metrics to quantify the SFI property on the basis of local equivariance error (LEE). LEE measures the robustness of DNNs to input transformations. By using signal resampling as input transformation, we extend LEE to measure the robustness of audio source separation methods to signal resampling. The proposed metrics are constructed to quantify the SFI property in specific network components responsible for predicting time-frequency masks. Experiments on music source separation demonstrated a strong correlation between the proposed metrics and performance degradation at untrained SFs.

Paper number 71:
Title: Comparative Analysis of Fast and High-Fidelity Neural Vocoders for Low-Latency Streaming Synthesis in Resource-Constrained Environments
Authors: Reo Yoneyama, Masaya Kawamura, Ryo Terashima, Ryuichi Yamamoto, Tomoki Toda
Abstract: In real-time speech synthesis, neural vocoders often require low-latency synthesis through causal processing and streaming. However, streaming introduces inefficiencies absent in batch synthesis, such as limited parallelism, inter-frame dependency management, and parameter loading overhead. This paper proposes multi-stream Wavehax (MS-Wavehax), an efficient neural vocoder for low-latency streaming, by extending the aliasing-free neural vocoder Wavehax with multi-stream decomposition. We analyze the latency-throughput trade-off in a CPU-only environment and identify key bottlenecks in streaming neural vocoders. Our findings provide practical insights for optimizing chunk sizes and designing vocoders tailored to specific application demands and hardware constraints. Furthermore, our subjective evaluations show that MS-Wavehax delivers high speech quality under causal and non-causal conditions while being remarkably compact and easily deployable in resource-constrained environments.

Paper number 72:
Title: Beamforming for Secure RSMA-Aided ISAC Systems
Authors: Qian Dan, Hongjiang Lei, Ki-Hong Park, Gaofeng Pan
Abstract: This work investigates the physical layer security of rate-splitting multiple access (RSMA)-aided integrated communication and sensing (ISAC) systems. The ISAC base station (BS) transmits signals to communicate with users in an eavesdropped scenario and to estimate the parameters of the sensed targets. The research considers different sensing signals under RSMA technology and the Cram{é}r-Rao bound of the parameter estimation is utilized as the sensing metric. With the channel state information (CSI) of eavesdroppers known, the transmitting beam of the BS is optimized to maximize the energy efficiency in terms of the minimum user rate and secrecy capacity, considering the fairness among users and ensuring the sensing performance and communication security. With the CSI of eavesdroppers unknown, the transmitting beam of the BS is designed to minimize the energy consumption for sensing and communication, and the residual power is utilized for artificial noise, which is isotropically emitted to achieve interference with potential eavesdroppers. To solve the non-convex problems, three iterative algorithms based on successive convex approximation and penalty function are proposed. The simulation results illustrate the effectiveness of the proposed schemes.

Paper number 73:
Title: YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency
Authors: Hansen Feng, Lizhi Wang, Yiqi Huang, Tong Li, Lin Zhu, Hua Huang
Abstract: The rapid advancement of photography has created a growing demand for a practical blind raw image denoising method. Recently, learning-based methods have become mainstream due to their excellent performance. However, most existing learning-based methods suffer from camera-specific data dependency, resulting in performance drops when applied to data from unknown cameras. To address this challenge, we introduce a novel blind raw image denoising method named YOND, which represents You Only Need a Denoiser. Trained solely on synthetic data, YOND can generalize robustly to noisy raw images captured by diverse unknown cameras. Specifically, we propose three key modules to guarantee the practicality of YOND: coarse-to-fine noise estimation (CNE), expectation-matched variance-stabilizing transform (EM-VST), and SNR-guided denoiser (SNR-Net). Firstly, we propose CNE to identify the camera noise characteristic, refining the estimated noise parameters based on the coarse denoised image. Secondly, we propose EM-VST to eliminate camera-specific data dependency, correcting the bias expectation of VST according to the noisy image. Finally, we propose SNR-Net to offer controllable raw image denoising, supporting adaptive adjustments and manual fine-tuning. Extensive experiments on unknown cameras, along with flexible solutions for challenging cases, demonstrate the superior practicality of our method. The source code will be publicly available at the \href{this https URL}{project homepage}.

Paper number 74:
Title: Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering
Authors: Pradeep Rangappa, Andres Carofilis, Jeena Prakash, Shashi Kumar, Sergio Burdisso, Srikanth Madikeri, Esau Villatoro-Tello, Bidisha Sharma, Petr Motlicek, Kadri Hacioglu, Shankar Venkatesan, Saurabh Vyas, Andreas Stolcke
Abstract: Fine-tuning pretrained ASR models for specific domains is challenging for small organizations with limited labeled data and computational resources. Here, we explore different data selection pipelines and propose a robust approach that improves ASR adaptation by filtering pseudo-labels generated using Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach integrates multiple selection strategies -- including word error rate (WER) prediction, named entity recognition (NER), and character error rate (CER) analysis -- to extract high-quality training segments. We evaluate our method on Whisper and Zipformer using a 7500-hour baseline, comparing it to a CER-based approach relying on hypotheses from three ASR systems. Fine-tuning on 7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our filtering reduces the dataset to 100 hours (1.4%) with similar performance; a similar trend is observed on Fisher English.

Paper number 75:
Title: MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition
Authors: Yinfeng Xia, Huiyan Li, Chenyang Le, Manhong Wang, Yutao Sun, Xingyang Ma, Yanmin Qian
Abstract: Applying large pre-trained speech models like Whisper has shown promise in reducing training costs for various speech tasks. However, integrating these models into streaming systems remains a challenge. This paper presents a novel prefix-to-prefix training framework for streaming recognition by fine-tuning the Whisper. We introduce the Continuous Integrate-and-Fire mechanism to establish a quasi-monotonic alignment between continuous speech sequences and discrete text tokens. Additionally, we design Monotonic Finite Look-ahead Attention, allowing each token to attend to infinite left-context and finite right-context from the speech sequences. We also employ the wait-k decoding strategy to simplify the decoding process while ensuring consistency between training and testing. Our theoretical analysis and experiments demonstrate that this approach achieves a controllable trade-off between latency and quality, making it suitable for various streaming applications.

Paper number 76:
Title: 3D Holographic Flow Cytometry Measurements of Microalgae: Strategies for Angle Recovery in Complex Rotation Patterns
Authors: Francesca Borrelli, Giusy Giugliano, Emilie Houliez, Jaromir Behal, Daniele Pirone, Leonilde Roselli, Angela Sardo, Valerio Zupo, Maria Costantini, Lisa Miccio, Pasquale Memmolo, Vittorio Bianco, Pietro Ferraro
Abstract: Marine ecosystems are in the spotlight, because environmental changes are threatening biodiversity and ecological functions. In this context, microalgae play key ecological roles both in planktonic and benthic ecosystems. Consequently, they are considered indispensable targets for global monitoring programs. However, due to a high spatial and temporal variability and to difficulties of species identification (still relying on microscopy observations), the assessment of roles played by these components of marine ecosystems is demanding. In addition, technologies for a 3D assessment of their complex morphology are scarcely available. Here, we present a comprehensive workflow for retrieving 3D information on microalgae with diverse geometries through holographic microscopy operating in flow-cytometry mode. Depending on the rotation patterns of samples, a tailored approach is used to retrieve their rolling angles. We demonstrate the feasibility of measuring 3D data of various microalgae, contingent to the intrinsic optical properties of cells. Specifically, we show that for quasi-transparent and low-scattering microorganisms, the retrieved angles permit to achieve quantitative 3D tomographic Refractive Index (RI) mapping, providing a full characterization of the alga in terms of its inner structure and the outer shape. Moreover, even in the most challenging scenarios, where microalgae exhibit high light absorption or strong scattering, quantitative 3D shape reconstructions of diatoms and dinoflagellates can be at least achieved. Finally, we compare our direct 3D measurements with 2D inferences of 3D properties, obtained using a commercially available microscopy system. The ability to non-invasively obtain 3D information on microalgae marks a fundamental advancement in the field, unlocking a wealth of novel biological insights for characterizing aquatic ecosystems.

Paper number 77:
Title: Feedback stabilization of switched systems under arbitrary switching: A convex characterization
Authors: Thiago Alves Lima, Matteo Della Rossa, Antoine Girard
Abstract: In this paper, we study stabilizability of discrete-time switched linear systems where the switching signal is considered as an arbitrary disturbance (and not a control variable). We characterize feedback stabilization via necessary and sufficient linear matrix inequalities (LMIs) conditions based on novel graph structures. We analyze both the cases in which the controller has (or has not) access to the current switching mode, the so-called mode-dependent and mode-independent settings, providing specular results. Moreover, our approach provides explicit piecewise-linear and memory-dependent linear controllers, highlighting the connections with existing stabilization approaches. The effectiveness of the proposed technique is finally illustrated with the help of some numerical examples.

Paper number 78:
Title: Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks
Authors: Lili Chen, Changyang She, Jingge Zhu, Jamie Evans
Abstract: As the number of mobile devices continues to grow, interference has become a major bottleneck in improving data rates in wireless networks. Efficient joint channel and power allocation (JCPA) is crucial for managing interference. In this paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve the JCPA problem in multi-channel wireless networks. To reduce the computational complexity of iterative optimization, we further introduce JCPGNN-M, a graph neural network-based solution that enables simultaneous multi-channel allocation for each user. We reformulate the problem as a Lagrangian function, which allows us to enforce the total power constraints systematically. Our solution involves combining this Lagrangian framework with GNNs and iteratively updating the Lagrange multipliers and resource allocation scheme. Unlike existing GNN-based methods that limit each user to a single channel, JCPGNN-M supports efficient spectrum reuse and scales well in dense network scenarios. Simulation results show that JCPGNN-M achieves better data rate compared to eWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, and it can generalize well to larger networks.

Paper number 79:
Title: Quasioptic, Calibrated, Full 2-port Measurements of Cryogenic Devices under Vacuum in the 220-330 GHz Band
Authors: Maxim Masyukov, Aleksi Tamminen, Irina Nefedova, Andrey Generalov, Samu-Ville Pälli, Roman Grigorev, Pouyan Rezapoor, Rui Silva, Juha Mallat, Juha Ala-Laurinaho, Zachary Taylor
Abstract: A quasi-optical (QO) test bench was designed, simulated, and calibrated for characterizing S-parameters of devices in the 220-330 GHz (WR-3.4) frequency range, from room temperature down to 4.8 K. The devices were measured through vacuum windows via focused beam radiation. A de-embedding method employing line-reflect-match (LRM) calibration was established to account for the effects of optical components and vacuum windows. The setup provides all four S-parameters with the reference plane located inside the cryostat, and achieves a return loss of 30 dB with an empty holder. System validation was performed with measurements of cryogenically cooled devices, such as bare silicon wafers and stainless-steel frequency-selective surface (FSS) bandpass filters, and superconducting bandpass FSS fabricated in niobium. A permittivity reduction of Si based on 4-GHz resonance shift was observed concomitant with a drop in temperature from 296 K to 4.8 K. The stainless steel FSS measurements revealed a relatively temperature invariant center frequency and return loss level of 263 GHz and 35 dB on average, respectively. Finally, a center frequency of 257 GHz was measured with the superconducting filters, with return loss improved by 7 dB on average at 4.8 K. To the best of our knowledge, this is the first reported attempt to scale LRM calibration to 330 GHz and use it to de-embed the impact of optics and cryostat from cryogenically cooled device S-parameters.

Paper number 80:
Title: Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain
Authors: Omer Moussa, Mariya Toneva
Abstract: Pretrained self-supervised speech models excel in speech tasks but do not reflect the hierarchy of human speech processing, as they encode rich semantics in middle layers and poor semantics in late layers. Recent work showed that brain-tuning (fine-tuning models using human brain recordings) improves speech models' semantic understanding. Here, we examine how well brain-tuned models further reflect the brain's intermediate stages of speech processing. We find that late layers of brain-tuned models substantially improve over pretrained models in their alignment with semantic language regions. Further layer-wise probing reveals that early layers remain dedicated to low-level acoustic features, while late layers become the best at complex high-level tasks. These findings show that brain-tuned models not only perform better but also exhibit a well-defined hierarchical processing going from acoustic to semantic representations, making them better model organisms for human speech processing.

Paper number 81:
Title: Control Signaling for Reconfigurable Intelligent Surfaces: How Many Bits are Needed?
Authors: Anders Enqvist, Özlem Tuğfe Demir, Cicek Cavdar, Emil Björnson
Abstract: Reconfigurable intelligent surfaces (RISs) can greatly improve the signal quality of future communication systems by reflecting transmitted signals toward the receiver. However, even when the base station (BS) has perfect channel knowledge and can compute the optimal RIS phase-shift configuration, implementing this configuration requires feedback signaling over a control channel from the BS to the RIS. This feedback must be kept minimal, as it is transmitted wirelessly every time the channel changes. In this paper, we examine how the feedback load, measured in bits, affects the performance of an RIS-aided system. Specifically, we investigate the trade-offs between codebook-based and element-wise feedback schemes, and how these influence the signal-to-noise ratio (SNR). We propose a novel quantization codebook tailored for line-of-sight (LoS) that guarantees a minimal SNR loss using a number of feedback bits that scale logarithmically with the number of RIS elements. We demonstrate the codebook's usefulness over Rician fading channels and how to extend it to handle a non-zero static path. Numerical simulations and analytical analysis are performed to quantify the performance degradation that results from a reduced feedback load, shedding light on how efficiently RIS configurations can be fed back in practical systems.

Paper number 82:
Title: Large Deviations for Sequential Tests of Statistical Sequence Matching
Authors: Lin Zhou, Qianyun Wang, Yun Wei, Jingjing Wang
Abstract: We revisit the problem of statistical sequence matching initiated by Unnikrishnan (TIT 2015) and derive theoretical performance guarantees for sequential tests that have bounded expected stopping times. Specifically, in this problem, one is given two databases of sequences and the task is to identify all matched pairs of sequences. In each database, each sequence is generated i.i.d. from a distinct distribution and a pair of sequences is said matched if they are generated from the same distribution. The generating distribution of each sequence is \emph{unknown}. We first consider the case where the number of matches is known and derive the exact exponential decay rate of the mismatch (error) probability, a.k.a. the mismatch exponent, under each hypothesis for optimal sequential tests. Our results reveal the benefit of sequentiality by showing that optimal sequential tests have larger mismatch exponent than fixed-length tests by Zhou \emph{et al.} (TIT 2024). Subsequently, we generalize our achievability result to the case of unknown number of matches. In this case, two additional error probabilities arise: false alarm and false reject probabilities. We propose a corresponding sequential test, show that the test has bounded expected stopping time under certain conditions, and characterize the tradeoff among the exponential decay rates of three error probabilities. Furthermore, we reveal the benefit of sequentiality over the two-step fixed-length test by Zhou \emph{et al.} (TIT 2024) and propose an one-step fixed-length test that has no worse performance than the fixed-length test by Zhou \emph{et al.} (TIT 2024). When specialized to the case where either database contains a single sequence, our results specialize to large deviations of sequential tests for statistical classification, the binary case of which was recently studied by Hsu, Li and Wang (ITW 2022).

Paper number 83:
Title: Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach
Authors: Haoxuan Chen, Yinuo Ren, Martin Renqiang Min, Lexing Ying, Zachary Izzo
Abstract: Diffusion models (DMs) have proven to be effective in modeling high-dimensional distributions, leading to their widespread adoption for representing complex priors in Bayesian inverse problems (BIPs). However, current DM-based posterior sampling methods proposed for solving common BIPs rely on heuristic approximations to the generative process. To exploit the generative capability of DMs and avoid the usage of such approximations, we propose an ensemble-based algorithm that performs posterior sampling without the use of heuristic approximations. Our algorithm is motivated by existing works that combine DM-based methods with the sequential Monte Carlo (SMC) method. By examining how the prior evolves through the diffusion process encoded by the pre-trained score function, we derive a modified partial differential equation (PDE) governing the evolution of the corresponding posterior distribution. This PDE includes a modified diffusion term and a reweighting term, which can be simulated via stochastic weighted particle methods. Theoretically, we prove that the error between the true posterior distribution can be bounded in terms of the training error of the pre-trained score function and the number of particles in the ensemble. Empirically, we validate our algorithm on several inverse problems in imaging to show that our method gives more accurate reconstructions compared to existing DM-based methods.

Paper number 84:
Title: Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion
Authors: Seymanur Akti, Tuan Nam Nguyen, Alexander Waibel
Abstract: Expressive voice conversion aims to transfer both speaker identity and expressive attributes from a target speech to a given source speech. In this work, we improve over a self-supervised, non-autoregressive framework with a conditional variational autoencoder, focusing on reducing source timbre leakage and improving linguistic-acoustic disentanglement for better style transfer. To minimize style leakage, we use multilingual discrete speech units for content representation and reinforce embeddings with augmentation-based similarity loss and mix-style layer normalization. To enhance expressivity transfer, we incorporate local F0 information via cross-attention and extract style embeddings enriched with global pitch and energy features. Experiments show our model outperforms baselines in emotion and speaker similarity, demonstrating superior style adaptation and reduced source style leakage.

Paper number 85:
Title: The mutual exclusivity bias of bilingual visually grounded speech models
Authors: Dan Oneata, Leanne Nortje, Yevgen Matusevych, Herman Kamper
Abstract: Mutual exclusivity (ME) is a strategy where a novel word is associated with a novel object rather than a familiar one, facilitating language learning in children. Recent work has found an ME bias in a visually grounded speech (VGS) model trained on English speech with paired images. But ME has also been studied in bilingual children, who may employ it less due to cross-lingual ambiguity. We explore this pattern computationally using bilingual VGS models trained on combinations of English, French, and Dutch. We find that bilingual models generally exhibit a weaker ME bias than monolingual models, though exceptions exist. Analyses show that the combined visual embeddings of bilingual models have a smaller variance for familiar data, partly explaining the increase in confusion between novel and familiar concepts. We also provide new insights into why the ME bias exists in VGS models in the first place. Code and data: this https URL

Paper number 86:
Title: A Statistics-Driven Differentiable Approach for Sound Texture Synthesis and Analysis
Authors: Esteban Gutiérrez, Frederic Font, Xavier Serra, Lonce Wyse
Abstract: In this work, we introduce TexStat, a novel loss function specifically designed for the analysis and synthesis of texture sounds characterized by stochastic structure and perceptual stationarity. Drawing inspiration from the statistical and perceptual framework of McDermott and Simoncelli, TexStat identifies similarities between signals belonging to the same texture category without relying on temporal structure. We also propose using TexStat as a validation metric alongside Frechet Audio Distances (FAD) to evaluate texture sound synthesis models. In addition to TexStat, we present TexEnv, an efficient, lightweight and differentiable texture sound synthesizer that generates audio by imposing amplitude envelopes on filtered noise. We further integrate these components into TexDSP, a DDSP-inspired generative model tailored for texture sounds. Through extensive experiments across various texture sound types, we demonstrate that TexStat is perceptually meaningful, time-invariant, and robust to noise, features that make it effective both as a loss function for generative tasks and as a validation metric. All tools and code are provided as open-source contributions and our PyTorch implementations are efficient, differentiable, and highly configurable, enabling its use in both generative tasks and as a perceptually grounded evaluation metric.

Paper number 87:
Title: Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems
Authors: Jhen-Ke Lin, Hao-Chien Lu, Chung-Chun Wang, Hong-Yun Lin, Berlin Chen
Abstract: Verbatim transcription for automatic speaking assessment demands accurate capture of disfluencies, crucial for downstream tasks like error analysis and feedback. However, many ASR systems discard or generalize hesitations, losing important acoustic details. We fine-tune Whisper models on the Speak & Improve 2025 corpus using low-rank adaptation (LoRA), without recourse to external audio training data. We compare three annotation schemes: removing hesitations (Pure), generic tags (Rich), and acoustically precise fillers inferred by Gemini 2.0 Flash from existing audio-transcript pairs (Extra). Our challenge system achieved 6.47% WER (Pure) and 5.81% WER (Extra). Post-challenge experiments reveal that fine-tuning Whisper Large V3 Turbo with the "Extra" scheme yielded a 5.5% WER, an 11.3% relative improvement over the "Pure" scheme (6.2% WER). This demonstrates that explicit, realistic filled-pause labeling significantly enhances ASR accuracy for verbatim L2 speech transcription.

Paper number 88:
Title: A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions
Authors: Chung-Chun Wang, Jhen-Ke Lin, Hao-Chien Lu, Hong-Yun Lin, Berlin Chen
Abstract: Automated speaking assessment (ASA) on opinion expressions is often hampered by the scarcity of labeled recordings, which restricts prompt diversity and undermines scoring reliability. To address this challenge, we propose a novel training paradigm that leverages a large language models (LLM) to generate diverse responses of a given proficiency level, converts responses into synthesized speech via speaker-aware text-to-speech synthesis, and employs a dynamic importance loss to adaptively reweight training instances based on feature distribution differences between synthesized and real speech. Subsequently, a multimodal large language model integrates aligned textual features with speech signals to predict proficiency scores directly. Experiments conducted on the LTTC dataset show that our approach outperforms methods relying on real data or conventional augmentation, effectively mitigating low-resource constraints and enabling ASA on opinion expressions with cross-modal information.

Paper number 89:
Title: UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation
Authors: Jinting Wang, Shan Yang, Li Liu
Abstract: Cued Speech (CS) enhances lipreading through hand coding, providing precise speech perception support for the hearing-impaired. CS Video-to-Speech generation (CSV2S) task aims to convert the CS visual expressions (CS videos) of hearing-impaired individuals into comprehensible speech signals. Direct generation of speech from CS video (called single CSV2S) yields poor performance due to insufficient CS data. Current research mostly focuses on CS Recognition (CSR), which convert video content into linguistic text. Based on this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech system. This combined architecture relies on text as an intermediate medium for stepwise cross-modal alignment, which may lead to error propagation and temporal misalignment between speech and video dynamics. To address these challenges, we propose a novel approach that directly generates speech from CS videos without relying on intermediate text. Building upon this, we propose UniCUE, the first unified framework for CSV2S, whose core innovation lies in the integration of the CSR task that provides fine-grained visual-semantic information to facilitate speech generation from CS videos. More precisely, (1) a novel fine-grained semantic alignment pool to ensure precise mapping between visual features and speech contents; (2) a VisioPhonetic adapter to bridge cross-task representations, ensuring seamless compatibility between two distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is introduced to enhance fine-grained spatiotemporal correlations between lip and hand movements in CS video. Experiments on our new established Chinese CS dataset (14 cuers1: 8 hearing-impaired and 6 normal-hearing) show that our UniCUE significantly reduces Word Error Rate by 78.3% and improves lip-speech synchronization by 32% compared to the single CSV2S.

Paper number 90:
Title: Sounding that Object: Interactive Object-Aware Image to Audio Generation
Authors: Tingle Li, Baihe Huang, Xiaobin Zhuang, Dongya Jia, Jiawei Chen, Yuping Wang, Zhuo Chen, Gopala Anumanchipalli, Yuxuan Wang
Abstract: Generating accurate sounds for complex audio-visual scenes is challenging, especially in the presence of multiple objects and sound sources. In this paper, we propose an {\em interactive object-aware audio generation} model that grounds sound generation in user-selected visual objects within images. Our method integrates object-centric learning into a conditional latent diffusion model, which learns to associate image regions with their corresponding sounds through multi-modal attention. At test time, our model employs image segmentation to allow users to interactively generate sounds at the {\em object} level. We theoretically validate that our attention mechanism functionally approximates test-time segmentation masks, ensuring the generated audio aligns with selected objects. Quantitative and qualitative evaluations show that our model outperforms baselines, achieving better alignment between objects and their associated sounds. Project page: this https URL

Paper number 91:
Title: Object-centric 3D Motion Field for Robot Learning from Human Videos
Authors: Zhao-Heng Yin, Sherry Yang, Pieter Abbeel
Abstract: Learning robot control policies from human videos is a promising direction for scaling up robot learning. However, how to extract action knowledge (or action representations) from videos for policy learning remains a key challenge. Existing action representations such as video frames, pixelflow, and pointcloud flow have inherent limitations such as modeling complexity or loss of information. In this paper, we propose to use object-centric 3D motion field to represent actions for robot learning from human videos, and present a novel framework for extracting this representation from videos for zero-shot control. We introduce two novel components in its implementation. First, a novel training pipeline for training a ''denoising'' 3D motion field estimator to extract fine object 3D motions from human videos with noisy depth robustly. Second, a dense object-centric 3D motion field prediction architecture that favors both cross-embodiment transfer and policy generalization to background. We evaluate the system in real world setups. Experiments show that our method reduces 3D motion estimation error by over 50% compared to the latest method, achieve 55% average success rate in diverse tasks where prior approaches fail~($\lesssim 10$\%), and can even acquire fine-grained manipulation skills like insertion.

Paper number 92:
Title: Optimal Transmission Switching: Improving Solver Performance Using Heuristics
Authors: Anton Hinneck, David Pozo
Abstract: The optimal transmission switching problem (OTSP) is an established problem of changing a power grid's topology to obtain an improved operation by controlling the switching status of transmission lines. This problem was proven to be NP-hard. Proposed solution techniques based on mixed-integer formulations can guarantee globally optimal solutions but are potentially intractable in realistic power grids. Heuristics methods cannot guarantee global optimality but can provide tractable solution approaches. This paper proposes solving the OTSP using exact formulations alongside parallel heuristics that generate good candidate solutions to speed up conventional branch-and-bound algorithms. The innovative aspect of this work is a new asynchronous parallel algorithmic architecture. A solver instance solving the full OTSP formulation is run in parallel to another process that asynchronously generates solutions to be injected into the full OTSP solution procedure during run time. Our method is tested on 14 instances of the pglib-opf library: The largest problem consisting of 13659 buses and 20467 branches. Our results show a good performance for large problem instances, with consistent improvements over off-the-shelf solver performance. We find that the method scales well with an increase in parallel processors.

Paper number 93:
Title: Direct closed-loop identification of continuous-time systems using fixed-pole observer model
Authors: Ichiro Maruta, Toshiharu Sugie
Abstract: This paper provides a method for obtaining a continuous-time model of a target system in closed-loop from input-output data alone, in the case where no knowledge of the controllers nor excitation signals is available and I/O data may suffer from unknown offsets. The proposed method is based on a fixed-pole observer model, which is a reasonable continuous-time version corresponding to the innovation model in discrete-time and allows the identification of unstable target systems. Furthermore, it is shown that the proposed method can be attributed to a convex optimization problem by fixing the observer poles. The method is within the framework of the stabilized output error method and shares usability advantages such as robustness to noise with complex dynamics and applicability to a wide class of models. The effectiveness of the method is illustrated through numerical examples.

Paper number 94:
Title: Learning Tube-Certified Control using Robust Contraction Metrics
Authors: Vivek Sharma, Pan Zhao, Naira Hovakimyan
Abstract: Control design for general nonlinear robotic systems with guaranteed stability and/or safety in the presence of model uncertainties is a challenging problem. Recent efforts attempt to learn a controller and a certificate (e.g., a Lyapunov function or a contraction metric) jointly using neural networks (NNs), in which model uncertainties are generally ignored during the learning process. In this paper, for nonlinear systems subject to bounded disturbances, we present a framework for jointly learning a robust nonlinear controller and a contraction metric using a novel disturbance rejection objective that certifies a tube bound using NNs for user-specified variables (e.g. control inputs). The learned controller aims to minimize the effect of disturbances on the actual trajectories of state and/or input variables from their nominal counterparts while providing certificate tubes around nominal trajectories that are guaranteed to contain actual trajectories in the presence of disturbances. Experimental results demonstrate that our framework can generate tighter (smaller) tubes and a controller that is computationally efficient to implement.

Paper number 95:
Title: RIS-Enabled NLoS Near-Field Joint Position and Velocity Estimation under User Mobility
Authors: Moustafa Rahal, Benoit Denis, Musa Furkan Keskin, Bernard Uguen, Henk Wymeersch
Abstract: In the context of single-base station (BS) non-line-of-sight (NLoS) single-epoch localization with the aid of a reflective reconfigurable intelligent surface (RIS), this paper introduces a novel three-step algorithm that jointly estimates the position and velocity of a mobile user equipment (UE), while compensating for the Doppler effects observed in near-field (NF) at the RIS elements over the short transmission duration of a sequence of downlink (DL) pilot symbols. First, a low-complexity initialization procedure is proposed, relying in part on far-field (FF) approximation and a static user assumption. Then, an alternating optimization procedure is designed to iteratively refine the velocity and position estimates, as well as the channel gain. The refinement routines leverage small angle approximations and the linearization of the RIS response, accounting for both NF and mobility effects. We evaluate the performance of the proposed algorithm through extensive simulations under diverse operating conditions with regard to signal-to-noise ratio (SNR), UE mobility, uncontrolled multipath and RIS-UE distance. Our results reveal remarkable performance improvements over the state-of-the-art (SoTA) mobility-agnostic benchmark algorithm, while indicating convergence of the proposed algorithm to respective theoretical bounds on position and velocity estimation.

Paper number 96:
Title: Language-Codec: Bridging Discrete Codec Representations and Speech Language Models
Authors: Shengpeng Ji, Minghui Fang, Jialong Zuo, Ziyue Jiang, Dingdong Wang, Hanting Wang, Hai Huang, Zhou Zhao
Abstract: In recent years, large language models have achieved significant success in generative tasks related to speech, audio, music, and other signal domains. A crucial element of these models is the discrete acoustic codecs, which serve as an intermediate representation replacing the mel-spectrogram. However, there exist several gaps between discrete codecs and downstream speech language models. Specifically, 1) Due to the reconstruction paradigm of the Codec model and the structure of residual vector quantization, the initial channel of the codebooks contains excessive information, making it challenging to directly generate acoustic tokens from weakly supervised signals such as text in downstream tasks. 2) numerous codebooks increases the burden on downstream speech language models. Consequently, leveraging the characteristics of speech language models, we propose Language-Codec. In the Language-Codec, we introduce a Masked Channel Residual Vector Quantization (MCRVQ) mechanism along with improved fourier transform structures and attention blocks, refined discriminator design to address the aforementioned gaps. We compare our method with competing audio compression algorithms and observe significant outperformance across extensive evaluations. Furthermore, we also validate the efficiency of the Language-Codec on downstream speech language models. The source code and pre-trained models can be accessed at this https URL .

Paper number 97:
Title: ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control
Authors: Shengpeng Ji, Qian Chen, Wen Wang, Jialong Zuo, Minghui Fang, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Siqi Zheng, Zhou Zhao
Abstract: In this paper, we present ControlSpeech, a text-to-speech (TTS) system capable of fully cloning the speaker's voice and enabling arbitrary control and adjustment of speaking style. Prior zero-shot TTS models only mimic the speaker's voice without further control and adjustment capabilities while prior controllable TTS models cannot perform speaker-specific voice generation. Therefore, ControlSpeech focuses on a more challenging task: a TTS system with controllable timbre, content, and style at the same time. ControlSpeech takes speech prompts, content prompts, and style prompts as inputs and utilizes bidirectional attention and mask-based parallel decoding to capture codec representations corresponding to timbre, content, and style in a discrete decoupling codec space. Moreover, we analyze the many-to-many issue in textual style control and propose the Style Mixture Semantic Density (SMSD) module, which is based on Gaussian mixture density networks, to resolve this problem. To facilitate empirical validations, we make available a new style controllable dataset called VccmDataset. Our experimental results demonstrate that ControlSpeech exhibits comparable or state-of-the-art (SOTA) performance in terms of controllability, timbre similarity, audio quality, robustness, and generalizability. The relevant code and demo are available at this https URL .

Paper number 98:
Title: Spectral Codecs: Improving Non-Autoregressive Speech Synthesis with Spectrogram-Based Audio Codecs
Authors: Ryan Langman, Ante Jukić, Kunal Dhawan, Nithin Rao Koluguri, Jason Li
Abstract: Historically, most speech models in machine-learning have used the mel-spectrogram as a speech representation. Recently, discrete audio tokens produced by neural audio codecs have become a popular alternate speech representation for speech synthesis tasks such as text-to-speech (TTS). However, the data distribution produced by such codecs is too complex for some TTS models to predict, typically requiring large autoregressive models to get good quality. Most existing audio codecs use Residual Vector Quantization (RVQ) to compress and reconstruct the time-domain audio signal. We propose a spectral codec which uses Finite Scalar Quantization (FSQ) to compress the mel-spectrogram and reconstruct the time-domain audio signal. A study of objective audio quality metrics and subjective listening tests suggests that our spectral codec has comparable perceptual quality to equivalent audio codecs. We show that FSQ, and the use of spectral speech representations, can both improve the performance of parallel TTS models.

Paper number 99:
Title: Expanding Over-the-Air Computation with Frequency Modulations
Authors: Marc Martinez-Gost, Ana Pérez-Neira, Miguel Ángel Lagunas
Abstract: In this study we introduce Logarithmic Frequency Shift Keying (Log-FSK), a novel frequency modulation for over-the-air computation (AirComp). Log-FSK leverages non-linear signal processing to produce AirComp in the frequency domain, this is, the maximum frequency of the received signal corresponds to the sum of the individual transmitted frequencies. The demodulation procedure relies on the inverse Discrete Cosine Transform (DCT) and the extraction of the maximum frequency component. Log-FSK enables the computation of functions beyond the sum by incorporating nomographic function representation. Furthermore, unlike existing AirComp modulations, Log-FSK allows to compute several functions in a single transmission. We evaluate the capabilities of the scheme in an additive white Gaussian noise (AWGN) and flat-fading channels. To demonstrate its practicality, we present specific applications and experimental results showcasing the effectiveness of Log-FSK AirComp within linear Wireless Sensor Networks (WSN). Our numerical results show that Log-FSK outperform linear analog modulations in terms of MSE and power consumption.

Paper number 100:
Title: Distributed Framework Construction for Affine Formation Control
Authors: Huiming Li, Hao Chen, Xiangke Wang, Zhongkui Li, Lincheng Shen
Abstract: In affine formation control problems, the construction of the framework with universal rigidity and affine localizability is a critical prerequisite, but it has not yet been well addressed, especially when additional agents join the formation or link/agent failures emerge. Motivated by this observation, we investigate the problem of constructing affine frameworks in three scenarios, including vertex addition, edge deletion and vertex deletion. Our approach starts from the original affine formation and uses geometric methods to locally adjust the structure of the weighted graph to describe the topology, so that the modified framework maintains the universal rigidity and affine localizability. Notably, the developed strategies only utilize local measurements and exhibit distributed characteristics, laying the foundation for applications in multi-agent systems. To demonstrate the compatibility with affine formation control proposals, we present a case study on affine formation tracking in a multi-UAV formation, demonstrating the effectiveness of our algorithms in constructing eligible frameworks in aforementioned scenarios. Moreover, a comparative simulation is also conducted to highlight the low time complexity of our distributed algorithm relative to the centralized optimization-based method.

Paper number 101:
Title: UltraBones100k: A reliable automated labeling method and large-scale dataset for ultrasound-based bone surface extraction
Authors: Luohong Wu, Nicola A. Cavalcanti, Matthias Seibold, Giuseppe Loggia, Lisa Reissner, Jonas Hein, Silvan Beeler, Arnd Viehöfer, Stephan Wirth, Lilian Calvet, Philipp Fürnstahl
Abstract: Ultrasound-based bone surface segmentation is crucial in computer-assisted orthopedic surgery. However, ultrasound images have limitations, including a low signal-to-noise ratio, and acoustic shadowing, which make interpretation difficult. Existing deep learning models for bone segmentation rely primarily on costly manual labeling by experts, limiting dataset size and model generalizability. Additionally, the complexity of ultrasound physics and acoustic shadow makes the images difficult for humans to interpret, leading to incomplete labels in anechoic regions and limiting model performance. To advance ultrasound bone segmentation and establish effective model benchmarks, larger and higher-quality datasets are needed. We propose a methodology for collecting ex-vivo ultrasound datasets with automatically generated bone labels, including anechoic regions. The proposed labels are derived by accurately superimposing tracked bone CT models onto the tracked ultrasound images. These initial labels are refined to account for ultrasound physics. A clinical evaluation is conducted by an expert physician specialized on orthopedic sonography to assess the quality of the generated bone labels. A neural network for bone segmentation is trained on the collected dataset and its predictions are compared to expert manual labels, evaluating accuracy, completeness, and F1-score. We collected the largest known dataset of 100k ultrasound images of human lower limbs with bone labels, called UltraBones100k. A Wilcoxon signed-rank test with Bonferroni correction confirmed that the bone alignment after our method significantly improved the quality of bone labeling (p < 0.001). The model trained on UltraBones100k consistently outperforms manual labeling in all metrics, particularly in low-intensity regions (320% improvement in completeness at a distance threshold of 0.5 mm).

Paper number 102:
Title: Feedback-Free Resource Scheduling for Flexible Multi-BS Cooperation in FD-RAN
Authors: Jingbo Liu, Jiacheng Chen, Zeyu Sun, Bo Qian, Haibo Zhou
Abstract: Flexible cooperation among base stations (BSs) is critical to improve resource utilization efficiency and meet personalized user demands. However, its practical implementation is hindered by the current radio access network (RAN), which relies on the coupling of uplink and downlink transmissions and channel state information feedback with inherent issues such as overheads and delays. To overcome these limitations, we consider the fully-decoupled RAN (FD-RAN), in which uplink and downlink functionalities are independent, and feedback-free MIMO transmission is adopted at the physical layer. To further deliver flexible cooperation in FD-RAN, we study feedback-free downlink multi-BS resource scheduling under the practical scheduling process. The problem is considered based on network load conditions. In heavy-load states where it is impossible for all user demands to be met, an optimal greedy algorithm is proposed, maximizing the weighted sum of user demand satisfaction rates. In light-load states where at least one solution exists to satisfy all user demands, an optimal two-stage resource allocation algorithm is designed to further minimize network energy consumption by leveraging the flexibility of cooperation. Extensive simulations validate the superiority of proposed algorithms in performance and running time, and highlight the potential for realizing flexible cooperation in practice.

Paper number 103:
Title: Rapid Bone Scintigraphy Enhancement via Semantic Prior Distillation from Segment Anything Model
Authors: Pengchen Liang, Leijun Shi, Huiping Yao, Bin Pu, Jianguo Chen, Lei Zhao, Haishan Huang, Zhuangzhuang Chen, Zhaozhao Xu, Lite Xu, Qing Chang, Yiwei Li
Abstract: Rapid bone scintigraphy is crucial for diagnosing skeletal disorders and detecting tumor metastases in children, as it shortens scan duration and reduces discomfort. However, accelerated acquisition often degrades image quality, impairing the visibility of fine anatomical details and potentially compromising diagnosis. To overcome this limitation, we introduce the first application of SAM-based semantic priors for medical image restoration, utilizing the Segment Anything Model (SAM) to enhance pediatric rapid bone scintigraphy. Our approach employs two cascaded networks, $f^{IR1}$ and $f^{IR2}$, supported by three specialized modules: a Semantic Prior Integration (SPI) module, a Semantic Knowledge Distillation (SKD) module, and a Semantic Consistency Module (SCM). The SPI and SKD modules inject domain-specific semantic cues from a fine-tuned SAM, while the SCM preserves coherent semantic feature representations across both cascaded stages. Moreover, we present RBS, a novel Rapid Bone Scintigraphy dataset comprising paired standard (20 cm/min) and rapid (40 cm/min) scans from 137 pediatric patients aged 0.5 - 16 years, making it the first dataset tailored for pediatric rapid bone scintigraphy restoration. Extensive experiments on both a public endoscopic dataset and our RBS dataset demonstrate that our method consistently surpasses existing techniques in PSNR, SSIM, FID, and LPIPS metrics.

Paper number 104:
Title: Equiripple MIMO Beampattern Synthesis using Chebyshev Approximation
Authors: David A. Hague, David G. Felton
Abstract: This letter presents a method for synthesizing equiripple MIMO transmit beampatterns using Chebyshev approximation. The MIMO beampattern is represented as a non-negative real-valued trigonometric polynomial where the $\ell^{\text{th}}$ order polynomial coefficient is the sum of the $\ell^{\text{th}}$ order diagonal of the waveform correlation matrix. The optimal coefficients for a given equiripple beampattern design is then posed as a Chebyshev approximation problem which is efficiently solved using the Parks-McClellan algorithm from optimal Finite Impulse Response (FIR) filter design theory. The unique advantage of this synthesis method is that it provides a closed form method to generating MIMO correlation matrices that realize the desired equiripple beampattern. This correspondingly facilitates the design of waveform sets that closely approximate those correlation matrices. This method is demonstrated via two illustrative design examples; the first using traditional partial signal correlation methods and the second using transmit beamspace processing. Both examples realize equiripple beampatterns using constant envelope and spectrally compact waveform sets.

Paper number 105:
Title: Benchmarking Audio Deepfake Detection Robustness in Real-world Communication Scenarios
Authors: Haohan Shi, Xiyu Shi, Safak Dogan, Saif Alzubi, Tianjin Huang, Yunxiao Zhang
Abstract: Existing Audio Deepfake Detection (ADD) systems often struggle to generalise effectively due to the significantly degraded audio quality caused by audio codec compression and channel transmission effects in real-world communication scenarios. To address this challenge, we developed a rigorous benchmark to evaluate the performance of the ADD system under such scenarios. We introduced ADD-C, a new test dataset to evaluate the robustness of ADD systems under diverse communication conditions, including different combinations of audio codecs for compression and packet loss rates. Benchmarking three baseline ADD models on the ADD-C dataset demonstrated a significant decline in robustness under such conditions. A novel Data Augmentation (DA) strategy was proposed to improve the robustness of ADD systems. Experimental results demonstrated that the proposed approach significantly enhances the performance of ADD systems on the proposed ADD-C dataset. Our benchmark can assist future efforts towards building practical and robustly generalisable ADD systems.

Paper number 106:
Title: Towards a deep learning approach for classifying treatment response in glioblastomas
Authors: Ana Matoso, Catarina Passarinho, Marta P. Loureiro, José Maria Moreira, Patrícia Figueiredo, Rita G. Nunes
Abstract: Glioblastomas are the most aggressive type of glioma, having a 5-year survival rate of 6.9%. Treatment typically involves surgery, followed by radiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI) scans to monitor disease progression. To assess treatment response, radiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to categorize the tumor into one of four labels based on imaging and clinical features: complete response, partial response, stable disease, and progressive disease. This assessment is very complex and time-consuming. Since deep learning (DL) has been widely used to tackle classification problems, this work aimed to implement the first DL pipeline for the classification of RANO criteria based on two consecutive MRI acquisitions. The models were trained and tested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction of input images, 2) different combinations of modalities, 3) different model architectures, 4) different pretraining tasks, and 5) adding clinical data. The pipeline that achieved the best performance used a Densenet264 considering only T1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR) images as input without any pretraining. A median Balanced Accuracy of 50.96% was achieved. Additionally, explainability methods were applied. Using Saliency Maps, the tumor region was often successfully highlighted. In contrast, Grad-CAM typically failed to highlight the tumor region, with some exceptions observed in the Complete Response and Progressive Disease classes, where it effectively identified the tumor region. These results set a benchmark for future studies on glioblastoma treatment response assessment based on the RANO criteria while emphasizing the heterogeneity of factors that might play a role when assessing the tumor's response to treatment.

Paper number 107:
Title: Nonconvex Linear System Identification with Minimal State Representation
Authors: Uday Kiran Reddy Tadipatri, Benjamin D. Haeffele, Joshua Agterberg, Ingvar Ziemann, René Vidal
Abstract: Low-order linear System IDentification (SysID) addresses the challenge of estimating the parameters of a linear dynamical system from finite samples of observations and control inputs with minimal state representation. Traditional approaches often utilize Hankel-rank minimization, which relies on convex relaxations that can require numerous, costly singular value decompositions (SVDs) to optimize. In this work, we propose two nonconvex reformulations to tackle low-order SysID (i) Burer-Monterio (BM) factorization of the Hankel matrix for efficient nuclear norm minimization, and (ii) optimizing directly over system parameters for real, diagonalizable systems with an atomic norm style decomposition. These reformulations circumvent the need for repeated heavy SVD computations, significantly improving computational efficiency. Moreover, we prove that optimizing directly over the system parameters yields lower statistical error rates, and lower sample complexities that do not scale linearly with trajectory length like in Hankel-nuclear norm minimization. Additionally, while our proposed formulations are nonconvex, we provide theoretical guarantees of achieving global optimality in polynomial time. Finally, we demonstrate algorithms that solve these nonconvex programs and validate our theoretical claims on synthetic data.

Paper number 108:
Title: Analyzing the Impact of Accent on English Speech: Acoustic and Articulatory Perspectives
Authors: Gowtham Premananth, Vinith Kugathasan, Carol Espy-Wilson
Abstract: Advancements in AI-driven speech-based applications have transformed diverse industries ranging from healthcare to customer service. However, the increasing prevalence of non-native accented speech in global interactions poses significant challenges for speech-processing systems, which are often trained on datasets dominated by native speech. This study investigates accented English speech through articulatory and acoustic analysis, identifying simpler coordination patterns and higher average pitch than native speech. Using eigenspectra and Vocal Tract Variable-based coordination features, we establish an efficient method for quantifying accent strength without relying on resource-intensive phonetic transcriptions. Our findings provide a new avenue for research on the impacts of accents on speech intelligibility and offer insights for developing inclusive, robust speech processing systems that accommodate diverse linguistic communities.

Paper number 109:
Title: Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation
Authors: Gowtham Premananth, Philip Resnik, Sonia Bansal, Deanna L.Kelly, Carol Espy-Wilson
Abstract: Studies on schizophrenia assessments using deep learning typically treat it as a classification task to detect the presence or absence of the disorder, oversimplifying the condition and reducing its clinical applicability. This traditional approach overlooks the complexity of schizophrenia, limiting its practical value in healthcare settings. This study shifts the focus to individual symptom severity estimation using a multimodal approach that integrates speech, video, and text inputs. We develop unimodal models for each modality and a multimodal framework to improve accuracy and robustness. By capturing a more detailed symptom profile, this approach can help in enhancing diagnostic precision and support personalized treatment, offering a scalable and objective tool for mental health assessment.

Paper number 110:
Title: Accelerating Flow-Matching-Based Text-to-Speech via Empirically Pruned Step Sampling
Authors: Qixi Zheng, Yushen Chen, Zhikang Niu, Ziyang Ma, Xiaofei Wang, Kai Yu, Xie Chen
Abstract: Flow-matching-based text-to-speech (TTS) models, such as Voicebox, E2 TTS, and F5-TTS, have attracted significant attention in recent years. These models require multiple sampling steps to reconstruct speech from noise, making inference speed a key challenge. Reducing the number of sampling steps can greatly improve inference efficiency. To this end, we introduce Fast F5-TTS, a training-free approach to accelerate the inference of flow-matching-based TTS models. By inspecting the sampling trajectory of F5-TTS, we identify redundant steps and propose Empirically Pruned Step Sampling (EPSS), a non-uniform time-step sampling strategy that effectively reduces the number of sampling steps. Our approach achieves a 7-step generation with an inference RTF of 0.030 on an NVIDIA RTX 3090 GPU, making it 4 times faster than the original F5-TTS while maintaining comparable performance. Furthermore, EPSS performs well on E2 TTS models, demonstrating its strong generalization ability.

Paper number 111:
Title: ABCDEFGH: An Adaptation-Based Convolutional Neural Network-CycleGAN Disease-Courses Evolution Framework Using Generative Models in Health Education
Authors: Ruiming Min, Minghao Liu
Abstract: With the advancement of modern medicine and the development of technologies such as MRI, CT, and cellular analysis, it has become increasingly critical for clinicians to accurately interpret various diagnostic images. However, modern medical education often faces challenges due to limited access to high-quality teaching materials, stemming from privacy concerns and a shortage of educational resources (Balogh et al., 2015). In this context, image data generated by machine learning models, particularly generative models, presents a promising solution. These models can create diverse and comparable imaging datasets without compromising patient privacy, thereby supporting modern medical education. In this study, we explore the use of convolutional neural networks (CNNs) and CycleGAN (Zhu et al., 2017) for generating synthetic medical images. The source code is available at this https URL.

Paper number 112:
Title: React to Surprises: Stable-by-Design Neural Feedback Control and the Youla-REN
Authors: Nicholas H. Barbara, Ruigang Wang, Alexandre Megretski, Ian R. Manchester
Abstract: We study parameterizations of stabilizing nonlinear policies for learning-based control. We propose a structure based on a nonlinear version of the Youla-Kucera parameterization combined with robust neural networks such as the recurrent equilibrium network (REN). The resulting parameterizations are unconstrained, and hence can be searched over with first-order optimization methods, while always ensuring closed-loop stability by construction. We study the combination of (a) nonlinear dynamics, (b) partial observation, and (c) incremental closed-loop stability requirements (contraction and Lipschitzness). We find that with any two of these three difficulties, a contracting and Lipschitz Youla parameter always leads to contracting and Lipschitz closed loops. However, if all three hold, then incremental stability can be lost with exogenous disturbances. Instead, a weaker condition is maintained, which we call d-tube contraction and Lipschitzness. We further obtain converse results showing that the proposed parameterization covers all contracting and Lipschitz closed loops for certain classes of nonlinear systems. Numerical experiments illustrate the utility of our parameterization when learning controllers with built-in stability certificates for: (i) "economic" rewards without stabilizing effects; (ii) short training horizons; and (iii) uncertain systems.

Paper number 113:
Title: NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution
Authors: Marcos V. Conde, Radu Timofte, Zihao Lu, Xiangyu Kong, Xiaoxia Xing, Fan Wang, Suejin Han, MinKyu Park, Tianyu Zhang, Xin Luo, Yeda Chen, Dong Liu, Li Pang, Yuhang Yang, Hongzhong Wang, Xiangyong Cao, Ruixuan Jiang, Senyan Xu, Siyuan Jiang, Xueyang Fu, Zheng-Jun Zha, Tianyu Hao, Yuhong He, Ruoqi Li, Yueqi Yang, Xiang Yu, Guanlan Hong, Minmin Yi, Yuanjia Chen, Liwen Zhang, Zijie Jin, Cheng Li, Lian Liu, Wei Song, Heng Sun, Yubo Wang, Jinghua Wang, Jiajie Lu, Watchara Ruangsan
Abstract: This paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution Challenge, highlighting the proposed solutions and results. New methods for RAW Restoration and Super-Resolution could be essential in modern Image Signal Processing (ISP) pipelines, however, this problem is not as explored as in the RGB domain. The goal of this challenge is two fold, (i) restore RAW images with blur and noise degradations, (ii) upscale RAW Bayer images by 2x, considering unknown noise and blur. In the challenge, a total of 230 participants registered, and 45 submitted results during thee challenge period. This report presents the current state-of-the-art in RAW Restoration.

Paper number 114:
Title: Differentially Private Distributed Mismatch Tracking Algorithm for Constraint-Coupled Resource Allocation Problems
Authors: Wenwen Wu, Shanying Zhu, Shuai Liu, Xinping Guan
Abstract: This paper considers privacy-concerned distributed constraint-coupled resource allocation problems over an undirected network, where each agent holds a private cost function and obtains the solution via only local communication. With privacy concerns, we mask the exchanged information with independent Laplace noise against a potential attacker with potential access to all network communications. We propose a differentially private distributed mismatch tracking algorithm (diff-DMAC) to achieve cost-optimal distribution of resources while preserving privacy. Adopting constant stepsizes, the linear convergence property of diff-DMAC in mean square is established under the standard assumptions of Lipschitz gradients and strong convexity. Moreover, it is theoretically proven that the proposed algorithm is {\epsilon}-differentially this http URL we also show the trade-off between convergence accuracy and privacy level. Finally, a numerical example is provided for verification.

Paper number 115:
Title: Data-driven stabilization of switched and constrained linear systems
Authors: Mattia Bianchi, Sergio Grammatico, Jorge Cortés
Abstract: We consider the design of state feedback control laws for both the switching signal and the continuous input of an unknown switched linear system, given past noisy input-state trajectories measurements. Based on Lyapunov-Metzler inequalities, we derive data-dependent bilinear programs whose solution directly returns a provably stabilizing controller and ensures $\mathcal{H}_2$ or $\mathcal{H}_{\infty}$ performance. We further present relaxations that considerably reduce the computational cost, still without requiring stabilizability of any of the switching modes. Finally, we showcase the flexibility of our approach on the constrained stabilization problem for a perturbed linear system. We validate our theoretical findings numerically, demonstrating the favourable trade-off between conservatism and tractability achieved by the proposed relaxations.

Paper number 116:
Title: Transformers in Speech Processing: A Survey
Authors: Siddique Latif, Aun Zaidi, Heriberto Cuayahuitl, Fahad Shamshad, Moazzam Shoukat, Muhammad Usama, Junaid Qadir
Abstract: The remarkable success of transformers in the field of natural language processing has sparked the interest of the speech-processing community, leading to an exploration of their potential for modeling long-range dependencies within speech sequences. Recently, transformers have gained prominence across various speech-related domains, including automatic speech recognition, speech synthesis, speech translation, speech para-linguistics, speech enhancement, spoken dialogue systems, and numerous multimodal applications. In this paper, we present a comprehensive survey that aims to bridge research studies from diverse subfields within speech technology. By consolidating findings from across the speech technology landscape, we provide a valuable resource for researchers interested in harnessing the power of transformers to advance the field. We identify the challenges encountered by transformers in speech processing while also offering insights into potential solutions to address these issues.

Paper number 117:
Title: Equivariant Symmetries for Inertial Navigation Systems
Authors: Alessandro Fornasier, Yixiao Ge, Pieter van Goor, Robert Mahony, Stephan Weiss
Abstract: This paper investigates the problem of inertial navigation system (INS) filter design through the lens of symmetry. The extended Kalman filter (EKF) and its variants have been the staple of INS filtering for 50 years. However, recent advances in inertial navigation systems have exploited matrix Lie group structure to design stochastic filters and state observers that have been shown to display superior performance compared to classical solutions. In this work, we explore various symmetries of inertial navigation system, including two novel symmetries that have not been considered in the prior literature, and provide a discussion of the relative strengths and weaknesses of these symmetries in the context of filter design. We show that all the modern variants of the EKF for inertial navigation can be interpreted as the recently proposed equivariant filter (EqF) design methodology applied to different choices of symmetry group for the INS problem. As a direct application of the symmetries presented, we address the filter design problem for a vehicle equipped with an inertial measurement unit (IMU) and a global navigation satellite system (GNSS) receiver, providing a comparative analysis of different modern filter solutions. We believe the collection of symmetries that we present here capture all the sensible choices of symmetry for this problem, and that the analysis provided is indicative of the relative real-world performance potential of the different algorithms for trajectories ensuring full state observability.

Paper number 118:
Title: Safe, Out-of-Distribution-Adaptive MPC with Conformalized Neural Network Ensembles
Authors: Jose Leopoldo Contreras, Ola Shorinwa, Mac Schwager
Abstract: We present SODA-MPC, a Safe, Out-of-Distribution-Adaptive Model Predictive Control algorithm, which uses an ensemble of learned models for prediction, with a runtime monitor to flag unreliable out-of-distribution (OOD) predictions. When an OOD situation is detected, SODA-MPC triggers a safe fallback control strategy based on reachability, yielding a control framework that achieves the high performance of learning-based models while preserving the safety of reachability-based control. We demonstrate the method in the context of an autonomous vehicle, driving among dynamic pedestrians, where SODA-MPC uses a neural network ensemble for pedestrian prediction. We calibrate the OOD signal using conformal prediction to derive an OOD detector with probabilistic guarantees on the false-positive rate, given a user-specified confidence level. During in-distribution operation, the MPC controller avoids collisions with a pedestrian based on the trajectory predicted by the mean of the ensemble. When OOD conditions are detected, the MPC switches to a reachability-based controller to avoid collisions with the reachable set of the pedestrian assuming a maximum pedestrian speed, to guarantee safety under the worst-case actions of the pedestrian. We verify SODA-MPC in extensive autonomous driving simulations in a pedestrian-crossing scenario. Our model ensemble is trained and calibrated with real pedestrian data, showing that our OOD detector obtains the desired accuracy rate within a theoretically-predicted range. We empirically show improved safety and improved task completion compared with two state-of-the-art MPC methods that also use conformal prediction, but without OOD adaptation. Further, we demonstrate the effectiveness of our method with the large-scale multi-agent predictor Trajectron++, using large-scale traffic data from the nuScenes dataset for training and calibration.

Paper number 119:
Title: CMAR-Net: Accurate Cross-Modal 3D SAR Reconstruction of Vehicle Targets with Sparse-Aspect Multi-Baseline Data
Authors: Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao
Abstract: Sparse-aspect multi-baseline Synthetic Aperture Radar (SAR) three-dimensional (3D) tomography is a crucial remote sensing technique. Compared to full-aspect observation, it needs only a few observation aspects to achieve a sufficiently clear 3D scene reconstruction, providing a cost-effective alternative. In the past, compressive sensing (CS) was the mainstream approach for sparse 3D SAR imaging. Recently, deep learning (DL) revolutionizes this field through its powerful data-driven representation capabilities and efficient inference characteristics. However, existing DL methods primarily depend on high-resolution radar images for supervising the training of deep neural networks (DNNs). This unimodal approach precludes the incorporation of complementary information from other data sources, thereby limiting potential improvements in imaging performance. In this paper, we propose a Cross-Modal 3D-SAR Reconstruction Network (CMAR-Net) that enhances 3D SAR imaging by fusing heterogeneous information. Leveraging cross-modal supervision from 2D optical images and error transfer guaranteed by differentiable rendering, CMAR-Net achieves efficient training and reconstructs highly sparse-aspect multi-baseline SAR image into visually structured and accurate 3D images, particularly for vehicle targets. Extensive experiments on simulated and real-world datasets demonstrate that CMAR-Net significantly outperforms state-of-the-art sparse reconstruction algorithms based on CS and DL, with average improvements of 75.83% in PSNR and 47.85% in SSIM. Furthermore, our method eliminates the need for time-consuming full-aperture data preprocessing and relies solely on computer-rendered optical images, significantly reducing dataset construction costs. This work highlights the potential of cross-modal learning for multi-baseline SAR 3D imaging and introduces a novel framework for radar imaging research.

Paper number 120:
Title: Neural Scoring: A Refreshed End-to-End Approach for Speaker Recognition in Complex Conditions
Authors: Wan Lin, Junhui Chen, Tianhao Wang, Zhenyu Zhou, Lantian Li, Dong Wang
Abstract: Modern speaker verification systems primarily rely on speaker embeddings and cosine similarity. While effective, these methods struggle with multi-talker speech due to the unidentifiability of embedding vectors. We propose Neural Scoring (NS), a novel end-to-end framework that directly estimates verification posterior probabilities without relying on test-side embeddings, making it more powerful and robust to complex conditions, e.g., with multiple talkers. To address the challenge of training such end-to-end models, we introduce a multi-enrollment training strategy, which pairs each test utterance with multiple enrolled speakers and proves essential to the model's success. Experiments on the VoxCeleb dataset demonstrate that NS consistently outperforms both the baseline and several competitive methods, achieving an overall 70.36% reduction in Equal Error Rate (EER) compared to the baseline.

Paper number 121:
Title: Sonic: Shifting Focus to Global Audio Perception in Portrait Animation
Authors: Xiaozhong Ji, Xiaobin Hu, Zhihong Xu, Junwei Zhu, Chuming Lin, Qingdong He, Jiangning Zhang, Donghao Luo, Yi Chen, Qin Lin, Qinglin Lu, Chengjie Wang
Abstract: The study of talking face generation mainly explores the intricacies of synchronizing facial movements and crafting visually appealing, temporally-coherent animations. However, due to the limited exploration of global audio perception, current approaches predominantly employ auxiliary visual and spatial knowledge to stabilize the movements, which often results in the deterioration of the naturalness and temporal this http URL the essence of audio-driven animation, the audio signal serves as the ideal and unique priors to adjust facial expressions and lip movements, without resorting to interference of any visual signals. Based on this motivation, we propose a novel paradigm, dubbed as Sonic, to {s}hift f{o}cus on the exploration of global audio per{c}ept{i}o{n}.To effectively leverage global audio knowledge, we disentangle it into intra- and inter-clip audio perception and collaborate with both aspects to enhance overall this http URL the intra-clip audio perception, 1). \textbf{Context-enhanced audio learning}, in which long-range intra-clip temporal audio knowledge is extracted to provide facial expression and lip motion priors implicitly expressed as the tone and speed of speech. 2). \textbf{Motion-decoupled controller}, in which the motion of the head and expression movement are disentangled and independently controlled by intra-audio clips. Most importantly, for inter-clip audio perception, as a bridge to connect the intra-clips to achieve the global perception, \textbf{Time-aware position shift fusion}, in which the global inter-clip audio information is considered and fused for long-audio inference via through consecutively time-aware shifted windows. Extensive experiments demonstrate that the novel audio-driven paradigm outperform existing SOTA methodologies in terms of video quality, temporally consistency, lip synchronization precision, and motion diversity.

Paper number 122:
Title: A Comprehensive Survey of Agents for Computer Use: Foundations, Challenges, and Future Directions
Authors: Pascal J. Sager, Benjamin Meyer, Peng Yan, Rebekka von Wartburg-Kottler, Layan Etaiwi, Aref Enayati, Gabriel Nobel, Ahmed Abdulkadir, Benjamin F. Grewe, Thilo Stadelmann
Abstract: Agents for computer use (ACUs) are an emerging class of systems capable of executing complex tasks on digital devices - such as desktops, mobile phones, and web platforms - given instructions in natural language. These agents can automate tasks by controlling software via low-level actions like mouse clicks and touchscreen gestures. However, despite rapid progress, ACUs are not yet mature for everyday use. In this survey, we investigate the state-of-the-art, trends, and research gaps in the development of practical ACUs. We provide a comprehensive review of the ACU landscape, introducing a unifying taxonomy spanning three dimensions: (I) the domain perspective, characterizing agent operating contexts; (II) the interaction perspective, describing observation modalities (e.g., screenshots, HTML) and action modalities (e.g., mouse, keyboard, code execution); and (III) the agent perspective, detailing how agents perceive, reason, and learn. We review 87 ACUs and 33 datasets across foundation model-based and classical approaches through this taxonomy. Our analysis identifies six major research gaps: insufficient generalization, inefficient learning, limited planning, low task complexity in benchmarks, non-standardized evaluation, and a disconnect between research and practical conditions. To address these gaps, we advocate for: (a) vision-based observations and low-level control to enhance generalization; (b) adaptive learning beyond static prompting; (c) effective planning and reasoning methods and models; (d) benchmarks that reflect real-world task complexity; (e) standardized evaluation based on task success; (f) aligning agent design with real-world deployment constraints. Together, our taxonomy and analysis establish a foundation for advancing ACU research toward general-purpose agents for robust and scalable computer use.

Paper number 123:
Title: ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors
Authors: Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou
Abstract: Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. We theoretically analyze the inconsistency in terms of both multilingual modal alignment direction error and weight error, and propose the theoretical weight error upper bound for quantifying the inconsistency. Based on the analysis of the weight error upper bound, we find that the inconsistency problem stems from the data distribution error caused by random sampling of languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at this https URL.

Paper number 124:
Title: InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training
Authors: Dingdong Wang, Jin Xu, Ruihang Chu, Zhifang Guo, Xiong Wang, Jincenzi Wu, Dongchao Yang, Shengpeng Ji, Junyang Lin
Abstract: Recent advancements in speech large language models (SpeechLLMs) have attracted considerable attention. Nonetheless, current methods exhibit suboptimal performance in adhering to speech instructions. Notably, the intelligence of models significantly diminishes when processing speech-form input as compared to direct text-form input. Prior work has attempted to mitigate this semantic inconsistency between speech and text representations through techniques such as representation and behavior alignment, which involve the meticulous design of data pairs during the post-training phase. In this paper, we introduce a simple and scalable training method called InSerter, which stands for Interleaved Speech-Text Representation Pre-training. InSerter is designed to pre-train large-scale unsupervised speech-text sequences, where the speech is synthesized from randomly selected segments of an extensive text corpus using text-to-speech conversion. Consequently, the model acquires the ability to generate textual continuations corresponding to the provided speech segments, obviating the need for intensive data design endeavors. To systematically evaluate speech instruction-following capabilities, we introduce SpeechInstructBench, the first comprehensive benchmark specifically designed for speech-oriented instruction-following tasks. Our proposed InSerter achieves SOTA performance in SpeechInstructBench and demonstrates superior or competitive results across diverse speech processing tasks.

Paper number 125:
Title: Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities
Authors: Guan-Ting Lin, Jiachen Lian, Tingle Li, Qirui Wang, Gopala Anumanchipalli, Alexander H. Liu, Hung-yi Lee
Abstract: Spoken dialogue modeling poses challenges beyond text-based language modeling, requiring real-time interaction, turn-taking, and backchanneling. While most Spoken Dialogue Models (SDMs) operate in half-duplex mode-processing one turn at a time - emerging full-duplex SDMs can listen and speak simultaneously, enabling more natural conversations. However, current evaluations remain limited, focusing mainly on turn-based metrics or coarse corpus-level analyses. To address this, we introduce Full-Duplex-Bench, a benchmark that systematically evaluates key interactive behaviors: pause handling, backchanneling, turn-taking, and interruption management. Our framework uses automatic metrics for consistent, reproducible assessment and provides a fair, fast evaluation setup. By releasing our benchmark and code, we aim to advance spoken dialogue modeling and foster the development of more natural and engaging SDMs.

Paper number 126:
Title: Enhancing Fourier Neural Operators with Local Spatial Features
Authors: Chaoyu Liu, Davide Murari, Lihao Liu, Yangming Li, Chris Budd, Carola-Bibiane Schönlieb
Abstract: Partial Differential Equation (PDE) problems often exhibit strong local spatial structures, and effectively capturing these structures is critical for approximating their solutions. Recently, the Fourier Neural Operator (FNO) has emerged as an efficient approach for solving these PDE problems. By using parametrization in the frequency domain, FNOs can efficiently capture global patterns. However, this approach inherently overlooks the critical role of local spatial features, as frequency-domain parameterized convolutions primarily emphasize global interactions without encoding comprehensive localized spatial dependencies. Although several studies have attempted to address this limitation, their extracted Local Spatial Features (LSFs) remain insufficient, and computational efficiency is often compromised. To address this limitation, we introduce a convolutional neural network (CNN)-based feature pre-extractor to capture LSFs directly from input data, resulting in a hybrid architecture termed \textit{Conv-FNO}. Furthermore, we introduce two novel resizing schemes to make our Conv-FNO resolution invariant. In this work, we focus on demonstrating the effectiveness of incorporating LSFs into FNOs by conducting both a theoretical analysis and extensive numerical experiments. Our findings show that this simple yet impactful modification enhances the representational capacity of FNOs and significantly improves performance on challenging PDE benchmarks.

Paper number 127:
Title: Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis
Authors: Matthew B. Webster, Dongheon Lee, Joonnyong Lee
Abstract: Biosignals can be viewed as mixtures measuring particular physiological events, and blind source separation (BSS) aims to extract underlying source signals from mixtures. This paper proposes a self-supervised multi-encoder autoencoder (MEAE) to separate heartbeat-related source signals from photoplethysmogram (PPG), enhancing heart rate (HR) detection in noisy PPG data. The MEAE is trained on PPG signals from a large open polysomnography database without any pre-processing or data selection. The trained network is then applied to a noisy PPG dataset collected during the daily activities of nine subjects. The extracted heartbeat-related source signal significantly improves HR detection as compared to the original PPG. The absence of pre-processing and the self-supervised nature of the proposed method, combined with its strong performance, highlight the potential of MEAE for BSS in biosignal analysis.

Paper number 128:
Title: CIVIL: Causal and Intuitive Visual Imitation Learning
Authors: Yinlong Dai, Robert Ramirez Sanchez, Ryan Jeronimus, Shahabedin Sagheb, Cara M. Nunez, Heramb Nemlekar, Dylan P. Losey
Abstract: Today's robots learn new tasks by imitating human examples. However, this standard approach to visual imitation learning is fundamentally limited: the robot observes what the human does, but not why the human chooses those behaviors. Without understanding the features that factor into the human's decisions, robot learners often misinterpret the data and fail to perform the task when the environment changes. We therefore propose a shift in perspective: instead of asking human teachers just to show what actions the robot should take, we also enable humans to indicate task-relevant features using markers and language prompts. Our proposed algorithm, CIVIL, leverages this augmented data to filter the robot's visual observations and extract a feature representation that causally informs human actions. CIVIL then applies these causal features to train a transformer-based policy that emulates human behaviors without being confused by visual distractors. Our simulations, real-world experiments, and user study demonstrate that robots trained with CIVIL can learn from fewer human demonstrations and perform better than state-of-the-art baselines, especially in previously unseen scenarios. See videos at our project website: this https URL

Paper number 129:
Title: Statistical Channel Based Low-Complexity Rotation and Position Optimization for 6D Movable Antennas Enabled Wireless Communication
Authors: Qijun Jiang, Xiaodan Shao, Rui Zhang
Abstract: Six-dimensional movable antenna (6DMA) is a promising technology to fully exploit spatial variation in wireless channels by allowing flexible adjustment of three-dimensional (3D) positions and rotations of antennas at the transceiver. In this paper, we investigate the practical low-complexity design of 6DMA-enabled communication systems, including transmission protocol, statistical channel information (SCI) acquisition, and joint position and rotation optimization of 6DMA surfaces based on the SCI of users. Specifically, an orthogonal matching pursuit (OMP)-based algorithm is proposed for the estimation of SCI of users at all possible position-rotation pairs of 6DMA surfaces based on the channel measurements at a small subset of position-rotation pairs. Then, the average sum logarithmic rate of all users is maximized by jointly designing the positions and rotations of 6DMA surfaces based on their SCI acquired. Different from prior works on 6DMA which adopt alternating optimization to design 6DMA positions/rotations with iterations, we propose a new sequential optimization approach that first determines 6DMA rotations and then finds their feasible positions to realize the optimized rotations subject to practical antenna placement constraints. Simulation results show that the proposed sequential optimization significantly reduces the computational complexity of conventional alternating optimization, while achieving comparable communication performance. It is also shown that the proposed SCI-based 6DMA design can effectively enhance the communication throughput of wireless networks over existing fixed (position and rotation) antenna arrays, yet with a practically appealing low-complexity implementation.

Paper number 130:
Title: Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction
Authors: Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut Åkesson
Abstract: This paper proposes an integrated approach for the safe and efficient control of mobile robots in dynamic and uncertain environments. The approach consists of two key steps: one-shot multimodal motion prediction to anticipate motions of dynamic obstacles and model predictive control to incorporate these predictions into the motion planning process. Motion prediction is driven by an energy-based neural network that generates high-resolution, multi-step predictions in a single operation. The prediction outcomes are further utilized to create geometric shapes formulated as mathematical constraints. Instead of treating each dynamic obstacle individually, predicted obstacles are grouped by proximity in an unsupervised way to improve performance and efficiency. The overall collision-free navigation is handled by model predictive control with a specific design for proactive dynamic obstacle avoidance. The proposed approach allows mobile robots to navigate effectively in dynamic environments. Its performance is accessed across various scenarios that represent typical warehouse settings. The results demonstrate that the proposed approach outperforms other existing dynamic obstacle avoidance methods.

Paper number 131:
Title: Digital-physical testbed for ship autonomy studies in the Marine Cybernetics Laboratory basin
Authors: Emir Cem Gezer, Mael Korentin Ivan Moreau, Anders Sandneseng Høgden, Dong Trong Nguyen, Roger Skjetne, Asgeir Sørensen
Abstract: The algorithms developed for Maritime Autonomous Surface Ships (MASS) are often challenging to test on actual vessels due to high operational costs and safety considerations. Simulations offer a cost-effective alternative and eliminate risks, but they may not accurately represent real-world dynamics for the given tasks. Utilizing small-scale model ships and robotic vessels in conjunction with a laboratory basin provides an accessible testing environment for the early stages of validation processes. However, designing and developing a model vessel for a single test can be costly and cumbersome, and researchers often lack access to such infrastructure. To address these challenges and enable streamlined testing, we have developed an in-house testbed that facilitates the development, testing, verification, and validation of MASS algorithms in a digital-physical laboratory. This infrastructure includes a set of small-scale model vessels, a simulation environment for each vessel, a comprehensive testbed environment, and a digital twin in Unity. With this, we aim to establish a full design and verification pipeline that starts with high-fidelity simulation models of each model vessel, to the model-scale testing in the laboratory basin, allowing possibilities for moving towards semi-fullscale validation with R/V milliAmpere1 and full-scale validation with R/V Gunnerus. In this work, we present our progress on the development of this testbed environment and its components, demonstrating its effectiveness in enabling ship guidance, navigation, and control (GNC), including autonomy.

Paper number 132:
Title: Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets
Authors: Ahmet Bilican, M. Akın Yılmaz, A. Murat Tekalp, R. Gökberk Cinbiş
Abstract: Efficiently adapting large foundation models is critical, especially with tight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA offer limited granularity and effectiveness in few-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT method that learns highly sparse updates in the wavelet domain of residual matrices. WaveFT allows precise control of trainable parameters, offering fine-grained capacity adjustment and excelling with remarkably low parameter count, potentially far fewer than LoRA's minimum, ideal for extreme parameter-efficient scenarios. Evaluated on personalized text-to-image generation using Stable Diffusion XL as baseline, WaveFT significantly outperforms LoRA and other PEFT methods, especially at low parameter counts; achieving superior subject fidelity, prompt alignment, and image diversity.

Paper number 133:
Title: PAST: Phonetic-Acoustic Speech Tokenizer
Authors: Nadav Har-Tuv, Or Tal, Yossi Adi
Abstract: We present PAST, a novel end-to-end framework that jointly models phonetic information alongside signal reconstruction, eliminating the need for external pretrained models. Unlike previous approaches that rely on pretrained self-supervised models, PAST employs supervised phonetic data, directly integrating domain knowledge into the tokenization process via auxiliary tasks. Additionally, we introduce a streamable, causal variant of PAST, enabling real-time speech applications. Results demonstrate that PAST surpasses existing evaluated baseline tokenizers across common evaluation metrics, including phonetic representation and speech reconstruction. Notably, PAST also achieves superior performance when serving as a speech representation for speech language models, further highlighting its effectiveness as a foundation for spoken language generation. To foster further research, we release the full implementation. For code, model checkpoints, and samples see: this https URL

Paper number 134:
Title: Signed Angle Rigid Graphs for Network Localization and Formation Control
Authors: Jinpeng Huang, Gangshan Jing
Abstract: Graph rigidity theory studies the capability of a graph embedded in the Euclidean space to constrain its global geometric shape via local constraints among nodes and edges, and has been widely exploited in network localization and formation control. In recent years, the traditional rigidity theory has been extended by considering new types of local constraints such as bearing, angle, ratio of distance, etc. Among them, the signed angle constraint has received extensive attention, since it is practically measurable and independent of the global coordinate frame. However, the relevant studies always consider special graph structures, which are sufficient but not necessary for signed angle rigidity. This paper presents a comprehensive combinatorial analysis in terms of graphs and angle index sets for signed angle rigidity. We show that Laman graphs equivalently characterize minimally signed angle rigid graphs. Moreover, we propose a method to construct the minimal set of signed angle constraints in a Laman graph to effectively ensure signed angle rigidity. These results are finally applied to distributed network localization and formation stabilization problems, respectively, where each agent only has access to signed angle measurements.

Paper number 135:
Title: Dirty and Clean-Label attack detection using GAN discriminators
Authors: John W. Smutny
Abstract: Gathering enough images to train a deep computer vision model is a constant challenge. Unfortunately, collecting images from unknown sources can leave your model s behavior at risk of being manipulated by a dirty-label or clean-label attack unless the images are properly inspected. Manually inspecting each image-label pair is impractical and common poison-detection methods that involve re-training your model can be time consuming. This research uses GAN discriminators to protect a single class against mislabeled and different levels of modified images. The effect of said perturbation on a basic convolutional neural network classifier is also included for reference. The results suggest that after training on a single class, GAN discriminator s confidence scores can provide a threshold to identify mislabeled images and identify 100% of the tested poison starting at a perturbation epsilon magnitude of 0.20, after decision threshold calibration using in-class samples. Developers can use this report as a basis to train their own discriminators to protect high valued classes in their CV models.

Paper number 136:
Title: Investigating Timing-Based Information Leakage in Data Flow-Driven Real-Time Systems
Authors: Mohammad Fakhruddin Babar, Zain A. H. Hammadeh, Mohammad Hamad, Monowar Hasan
Abstract: Leaking information about the execution behavior of critical real-time tasks may lead to serious consequences, including violations of temporal constraints and even severe failures. We study information leakage for a special class of real-time tasks that have two execution modes, namely, typical execution (which invokes the majority of times) and critical execution (to tackle exceptional conditions). The data flow-driven applications inherit such a multimode execution model. In this paper, we investigate whether a low-priority "observer" task can infer the execution patterns of a high-priority "victim" task (especially the critical executions). We develop a new statistical analysis technique and show that by analyzing the response times of the low-priority task, it becomes possible to extract the execution behavior of the high-priority task. We test our approach against a random selection technique that arbitrarily classifies a job as critical. We find that correlating the observer's response times with the victim's jobs can result in higher precision in identifying critical invocations compared to a random guess. We conduct extensive evaluations with systemically generated workloads, including a case study using a UAV autopilot (ArduPilot) taskset parameters. We found that our inference algorithm can achieve relatively low false positive rates (less than 25%) with relatively low footprint (1 MB memory and 50 ms timing overhead on a Raspberry Pi 4 platform). We further demonstrate the feasibility of inference on two cyber-physical platforms: an off-the-shelf manufacturing robot and a custom-built surveillance system.
    