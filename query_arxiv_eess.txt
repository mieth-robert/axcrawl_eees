
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Physical foundations for trustworthy medical imaging: a review for artificial intelligence researchers
Authors: Miriam Cobo, David Corral Fontecha, Wilson Silva, Lara Lloret Iglesias
Abstract: Artificial intelligence in medical imaging has seen unprecedented growth in the last years, due to rapid advances in deep learning and computing resources. Applications cover the full range of existing medical imaging modalities, with unique characteristics driven by the physics of each technique. Yet, artificial intelligence professionals entering the field, and even experienced developers, often lack a comprehensive understanding of the physical principles underlying medical image acquisition, which hinders their ability to fully leverage its potential. The integration of physics knowledge into artificial intelligence algorithms enhances their trustworthiness and robustness in medical imaging, especially in scenarios with limited data availability. In this work, we review the fundamentals of physics in medical images and their impact on the latest advances in artificial intelligence, particularly, in generative models and reconstruction algorithms. Finally, we explore the integration of physics knowledge into physics-inspired machine learning models, which leverage physics-based constraints to enhance the learning of medical imaging features.

Paper number 2:
Title: Antenna Activation and Resource Allocation in Multi-Waveguide Pinching-Antenna Systems
Authors: Kaidi Wang, Zhiguo Ding, George K. Karagiannidis
Abstract: Pinching antennas, as a novel flexible-antenna technology capable of establishing line of sight (LoS) connections and effectively mitigating large-scale path loss, have recently attracted considerable research interests. However, the implementation of ideal pinching-antenna systems involves determining and adjusting pinching antennas to an arbitrary position on waveguides, which presents challenges to both practical deployment and related optimization. This paper investigates a practical pinching-antennas system in multi-waveguide scenarios, where pinching antennas are installed at pre-configured discrete positions to serve downlink users with non-orthogonal multiple access (NOMA). To improve system throughput, a sophisticated optimization problem is formulated by jointly considering waveguide assignment, antenna activation, successive interference cancellation (SIC) decoding order design, and power allocation. By treating waveguide assignment and antenna activation as two coalition-formation games, a novel game-theoretic algorithm is developed, in which the optimal decoding order is derived and incorporated. For power allocation, monotonic optimization and successive convex approximation (SCA) are employed to construct global optimal and low-complexity solutions, respectively. Simulation results demonstrate that the NOMA-based pinching-antenna system exhibits superior performance compared to the considered benchmark systems, and the proposed solutions provide significant improvement in terms of sum rate and outage probability.

Paper number 3:
Title: A Practical Approach Towards Inertia Estimation Using Ambient Synchrophasor Data
Authors: Anushka Sharma, Anamitra Pal, Rajasekhar Anguluri, Tamojit Chakraborty
Abstract: Real-time tracking of inertia is important because it reflects the power system's ability to withstand contingencies and maintain frequency security. This paper proposes a practical approach to estimate inertia using ambient phasor measurement unit (PMU) data and a partitioned form of the swing equation. The approach accounts for (bounded) uncertainties in network parameters and PMU measurements, enabling precise estimation of inertia and damping constants, as well as mechanical power inputs. Instead of assuming constant mechanical power input throughout, the approach leverages knowledge of power system operations to determine intervals when it is actually constant to maintain estimation consistency. Simulation results on the IEEE 14-bus system and IEEE 39 bus system integrated with renewable energy sources affirm the method's accuracy and applicability.

Paper number 4:
Title: Dual Prompting for Diverse Count-level PET Denoising
Authors: Xiaofeng Liu, Yongsong Huang, Thibault Marin, Samira Vafay Eslahi, Tiss Amal, Yanis Chemli, Keith Johnson, Georges El Fakhri, Jinsong Ouyang
Abstract: The to-be-denoised positron emission tomography (PET) volumes are inherent with diverse count levels, which imposes challenges for a unified model to tackle varied cases. In this work, we resort to the recently flourished prompt learning to achieve generalizable PET denoising with different count levels. Specifically, we propose dual prompts to guide the PET denoising in a divide-and-conquer manner, i.e., an explicitly count-level prompt to provide the specific prior information and an implicitly general denoising prompt to encode the essential PET denoising knowledge. Then, a novel prompt fusion module is developed to unify the heterogeneous prompts, followed by a prompt-feature interaction module to inject prompts into the features. The prompts are able to dynamically guide the noise-conditioned denoising process. Therefore, we are able to efficiently train a unified denoising model for various count levels, and deploy it to different cases with personalized prompts. We evaluated on 1940 low-count PET 3D volumes with uniformly randomly selected 13-22\% fractions of events from 97 $^{18}$F-MK6240 tau PET studies. It shows our dual prompting can largely improve the performance with informed count-level and outperform the count-conditional model.

Paper number 5:
Title: Robustly Invertible Nonlinear Dynamics and the BiLipREN: Contracting Neural Models with Contracting Inverses
Authors: Yurui Zhang, Ruigang Wang, Ian R. Manchester
Abstract: We study the invertibility of nonlinear dynamical systems from the perspective of contraction and incremental stability analysis and propose a new invertible recurrent neural model: the BiLipREN. In particular, we consider a nonlinear state space model to be robustly invertible if an inverse exists with a state space realisation, and both the forward model and its inverse are contracting, i.e. incrementally exponentially stable, and Lipschitz, i.e. have bounded incremental gain. This property of bi-Lipschitzness implies both robustness in the sense of sensitivity to input perturbations, as well as robust distinguishability of different inputs from their corresponding outputs, i.e. the inverse model robustly reconstructs the input sequence despite small perturbations to the initial conditions and measured output. Building on this foundation, we propose a parameterization of neural dynamic models: bi-Lipschitz recurrent equilibrium networks (biLipREN), which are robustly invertible by construction. Moreover, biLipRENs can be composed with orthogonal linear systems to construct more general bi-Lipschitz dynamic models, e.g., a nonlinear analogue of minimum-phase/all-pass (inner/outer) factorization. We illustrate the utility of our proposed approach with numerical examples.

Paper number 6:
Title: The Search for Squawk: Agile Modeling in Bioacoustics
Authors: Vincent Dumoulin, Otilia Stretcu, Jenny Hamer, Lauren Harrell, Rob Laber, Hugo Larochelle, Bart van MerriÃ«nboer, Amanda Navine, Patrick Hart, Ben Williams, Timothy A.C. Lamont, Tries B. Rasak, Mars Coral Restoration Team, Sheryn Brodie, Brendan Doohan, Phil Eichinski, Paul Roe, Lin Schwarzkopf, Tom Denton
Abstract: Passive acoustic monitoring (PAM) has shown great promise in helping ecologists understand the health of animal populations and ecosystems. However, extracting insights from millions of hours of audio recordings requires the development of specialized recognizers. This is typically a challenging task, necessitating large amounts of training data and machine learning expertise. In this work, we introduce a general, scalable and data-efficient system for developing recognizers for novel bioacoustic problems in under an hour. Our system consists of several key components that tackle problems in previous bioacoustic workflows: 1) highly generalizable acoustic embeddings pre-trained for birdsong classification minimize data hunger; 2) indexed audio search allows the efficient creation of classifier training datasets, and 3) precomputation of embeddings enables an efficient active learning loop, improving classifier quality iteratively with minimal wait time. Ecologists employed our system in three novel case studies: analyzing coral reef health through unidentified sounds; identifying juvenile Hawaiian bird calls to quantify breeding success and improve endangered species monitoring; and Christmas Island bird occupancy modeling. We augment the case studies with simulated experiments which explore the range of design decisions in a structured way and help establish best practices. Altogether these experiments showcase our system's scalability, efficiency, and generalizability, enabling scientists to quickly address new bioacoustic challenges.

Paper number 7:
Title: Global Task-aware Fault Detection, Identification For On-Orbit Multi-Spacecraft Collaborative Inspection
Authors: Akshita Gupta, Yashwanth Kumar Nakka, Changrak Choi, Amir Rahmani
Abstract: In this paper, we present a global-to-local task-aware fault detection and identification algorithm to detect failures in a multi-spacecraft system performing a collaborative inspection (referred to as global) task. The inspection task is encoded as a cost functional $\costH$ that informs global (task allocation and assignment) and local (agent-level) decision-making. The metric $\costH$ is a function of the inspection sensor model, and the agent full-pose. We use the cost functional $\costH$ to design a metric that compares the expected and actual performance to detect the faulty agent using a threshold. We use higher-order cost gradients $\costH$ to derive a new metric to identify the type of fault, including task-specific sensor fault, an agent-level actuator, and sensor faults. Furthermore, we propose an approach to design adaptive thresholds for each fault mentioned above to incorporate the time dependence of the inspection task. We demonstrate the efficacy of the proposed method empirically, by simulating and detecting faults (such as inspection sensor faults, actuators, and sensor faults) in a low-Earth orbit collaborative spacecraft inspection task using the metrics and the threshold designed using the global task cost $\costH$.

Paper number 8:
Title: The ISAC systems aided by MIMO, RIS and with Beamforming Techniques
Authors: Rafael Augusto Pedriali, Isadora Martines Ferreira, Jose Carlos Marinello, Taufik Abrao
Abstract: This paper explores the integration of communication and sensing in modern wireless systems through the configuration of BS and RIS antenna elements. By leveraging time multiplexing for both communication and sensing, the proposed system optimizes spectral efficiency and operational performance. The use of static RIS configurations tailored to specific environments eliminates the need for dynamic reconfigurations, enhancing system agility, reducing processing complexity, and improving sensing accuracy. The system incorporates trilateration, angle of arrival, and time of arrival techniques to enable precise user localization by combining signals reflected along multiple paths. This method helps choose the best connections and lowers sensing costs while preventing interference with communication data, highlighting the need to bring together new technologies like passive and adaptive beamforming in one system.

Paper number 9:
Title: USF Spectral Estimation: Prevalence of Gaussian CramÃ©r-Rao Bounds Despite Modulo Folding
Authors: Ruiming Guo, Ayush Bhandari
Abstract: Spectral Estimation (SpecEst) is a core area of signal processing with a history spanning two centuries and applications across various fields. With the advent of digital acquisition, SpecEst algorithms have been widely applied to tasks like frequency super-resolution. However, conventional digital acquisition imposes a trade-off: for a fixed bit budget, one can optimize either signal dynamic range or digital resolution (noise floor), but not both simultaneously. The Unlimited Sensing Framework (USF) overcomes this limitation using modulo non-linearity in analog hardware, enabling a novel approach to SpecEst (USF-SpecEst). However, USF-SpecEst requires new theoretical and algorithmic developments to handle folded samples effectively. In this paper, we derive the CramÃ©r-Rao Bounds (CRBs) for SpecEst with noisy modulo-folded samples and reveal a surprising result: the CRBs for USF-SpecEst are scaled versions of the Gaussian CRBs for conventional samples. Numerical experiments validate these bounds, providing a benchmark for USF-SpecEst and facilitating its practical deployment.

Paper number 10:
Title: STG: Spatiotemporal Graph Neural Network with Fusion and Spatiotemporal Decoupling Learning for Prognostic Prediction of Colorectal Cancer Liver Metastasis
Authors: Yiran Zhu, Wei Yang, Yan su, Zesheng Li, Chengchang Pan, Honggang Qi
Abstract: We propose a multimodal spatiotemporal graph neural network (STG) framework to predict colorectal cancer liver metastasis (CRLM) progression. Current clinical models do not effectively integrate the tumor's spatial heterogeneity, dynamic evolution, and complex multimodal data relationships, limiting their predictive accuracy. Our STG framework combines preoperative CT imaging and clinical data into a heterogeneous graph structure, enabling joint modeling of tumor distribution and temporal evolution through spatial topology and cross-modal edges. The framework uses GraphSAGE to aggregate spatiotemporal neighborhood information and leverages supervised and contrastive learning strategies to enhance the model's ability to capture temporal features and improve robustness. A lightweight version of the model reduces parameter count by 78.55%, maintaining near-state-of-the-art performance. The model jointly optimizes recurrence risk regression and survival analysis tasks, with contrastive loss improving feature representational discriminability and cross-modal consistency. Experimental results on the MSKCC CRLM dataset show a time-adjacent accuracy of 85% and a mean absolute error of 1.1005, significantly outperforming existing methods. The innovative heterogeneous graph construction and spatiotemporal decoupling mechanism effectively uncover the associations between dynamic tumor microenvironment changes and prognosis, providing reliable quantitative support for personalized treatment decisions.

Paper number 11:
Title: Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications
Authors: Qingliang Li, Bo Chang, Weidong Mei, Zhi Chen
Abstract: In the upcoming industrial internet of things (IIoT) era, a surge of task-oriented applications will rely on real-time wireless control systems (WCSs). For these systems, ultra-reliable and low-latency wireless communication will be crucial to ensure the timely transmission of control information. To achieve this purpose, we propose a novel time-sequence-based semantic communication paradigm, where an integrated sensing, computing, communication, and control (ISC3) architecture is developed to make sensible semantic inference (SI) for the control information over time sequences, enabling adaptive control of the robot. However, due to the causal correlations in the time sequence, the control information does not present the Markov property. To address this challenge, we compute the mutual information of the control information sensed at the transmitter (Tx) over different time and identify their temporal semantic correlation via a semantic feature extractor (SFE) module. By this means, highly correlated information transmission can be avoided, thus greatly reducing the communication overhead. Meanwhile, a semantic feature reconstructor (SFR) module is employed at the receiver (Rx) to reconstruct the control information based on the previously received one if the information transmission is not activated at the Tx. Furthermore, a control gain policy is also employed at the Rx to adaptively adjust the control gain for the controlled target based on several practical aspects such as the quality of the information transmission from the Tx to the Rx. We design the neural network structures of the above modules/policies and train their parameters by a novel hybrid reward multi-agent deep reinforcement learning framework. On-site experiments are conducted to evaluate the performance of our proposed method in practice, which shows significant gains over other baseline schemes.

Paper number 12:
Title: Non-linear dynamics of multibody systems: a system-based approach
Authors: Daniel Alazard, Francesco Sanfedino, Ervan Kassarian
Abstract: This paper presents causal block-diagram models to represent the equations of motion of multi-body systems in a very compact and simple closed form. Both the forward dynamics (from the forces and torques imposed at the various degrees-of-freedom to the motions of these degrees-of-freedom) or the inverse dynamics (from the motions imposed at the degrees-of-freedom to the resulting forces and torques) can be considered and described by a block diagram model. This work extends the Two-Input Two-Output Port (TITOP) theory by including all non-linear terms and uniform or gravitational acceleration fields. Connection among different blocks is possible through the definition of the motion vector. The model of a system composed of a floating base, rigid bodies, revolute and prismatic joints, working under gravity is developed to illustrate the methodology. The proposed model is validated by simulation and cross-checking with a model built using an alternative modeling tool on a scenario where the nonlinear terms are determining.

Paper number 13:
Title: Model Predictive Fuzzy Control: A Hierarchical Multi-Agent Control Architecture for Outdoor Search-and-Rescue Robots
Authors: Craig Maxwell, Mirko Baglioni, Anahita Jamshidnejad
Abstract: Autonomous robots deployed in unknown search-and-rescue (SaR) environments can significantly improve the efficiency of the mission by assisting in fast localisation and rescue of the trapped victims. We propose a novel integrated hierarchical control architecture, called model predictive fuzzy control (MPFC), for autonomous mission planning of multi-robot SaR systems that should efficiently map an unknown environment: We combine model predictive control (MPC) and fuzzy logic control (FLC), where the robots are locally controlled by computationally efficient FLC controllers, and the parameters of these local controllers are tuned via a centralised MPC controller, in a regular or event-triggered manner. The proposed architecture provides three main advantages: (1) The control decisions are made by the FLC controllers, thus the real-time computation time is affordable. (2) The centralised MPC controller optimises the performance criteria with a global and predictive vision of the system dynamics, and updates the parameters of the FLC controllers accordingly. (3) FLC controllers are heuristic by nature and thus do not take into account optimality in their decisions, while the tuned parameters via the MPC controller can indirectly incorporate some level of optimality in local decisions of the robots. A simulation environment for victim detection in a disaster environment was designed in MATLAB using discrete, 2-D grid-based models. While being comparable from the point of computational efficiency, the integrated MPFC architecture improves the performance of the multi-robot SaR system compared to decentralised FLC controllers. Moreover, the performance of MPFC is comparable to the performance of centralised MPC for path planning of SaR robots, whereas MPFC requires significantly less computational resources, since the number of the optimisation variables in the control problem are reduced.

Paper number 14:
Title: GNN-enabled Precoding for Massive MIMO LEO Satellite Communications
Authors: Huibin Zhou, Xinrui Gong, Christos G. Tsinos, Li You, Xiqi Gao, BjÃ¶rn Ottersten
Abstract: Low Earth Orbit (LEO) satellite communication is a critical component in the development of sixth generation (6G) networks. The integration of massive multiple-input multiple-output (MIMO) technology is being actively explored to enhance the performance of LEO satellite communications. However, the limited power of LEO satellites poses a significant challenge in improving communication energy efficiency (EE) under constrained power conditions. Artificial intelligence (AI) methods are increasingly recognized as promising solutions for optimizing energy consumption while enhancing system performance, thus enabling more efficient and sustainable communications. This paper proposes approaches to address the challenges associated with precoding in massive MIMO LEO satellite communications. First, we introduce an end-to-end graph neural network (GNN) framework that effectively reduces the computational complexity of traditional precoding methods. Next, we introduce a deep unfolding of the Dinkelbach algorithm and the weighted minimum mean square error (WMMSE) approach to achieve enhanced EE, transforming iterative optimization processes into a structured neural network, thereby improving convergence speed and computational efficiency. Furthermore, we incorporate the Taylor expansion method to approximate matrix inversion within the GNN, enhancing both the interpretability and performance of the proposed method. Numerical experiments demonstrate the validity of our proposed method in terms of complexity and robustness, achieving significant improvements over state-of-the-art methods.

Paper number 15:
Title: Hybrid NOMA Assisted Heterogeneous Semantic and Bit Users Communication
Authors: Ishtiaque Ahmed, Leila Musavian
Abstract: In this paper, we utilize a downlink hybrid Non-Orthogonal Multiple Access (NOMA) framework to support multiple semantic and bit users within the communication network. The hybrid NOMA setup exploits both NOMA and Orthogonal Multiple Access (OMA) which has the benefit of enhancing Spectral Efficiency (SE) by allowing users to dynamically access the resources in multiple heterogeneous slots. This enables integrating semantic and bit users based on their channel gains, while adopting bit-to-semantic decoding order in slots including heterogeneous users. An optimization problem for the power allocation is formulated with the aim of maximizing the equivalent ergodic semantic SE with a constraint on the total available power of the Access Point (AP). The proposed algorithm uses NOMA in shared slots and OMA in bit-user-only slots. Simulation results validate the benefits of heterogeneous users hybrid NOMA setup in comparison to OMA-only for heterogeneous users.

Paper number 16:
Title: Memory-Efficient Distributed Unlearning
Authors: Natalie Lang, Alon Helvitz, Nir Shlezinger
Abstract: Machine unlearning considers the removal of the contribution of a set of data points from a trained model. In a distributed setting, where a server orchestrates training using data available at a set of remote users, unlearning is essential to cope with late-detected malicious or corrupted users. Existing distributed unlearning algorithms require the server to store all model updates observed in training, leading to immense storage overhead for preserving the ability to unlearn. In this work we study lossy compression schemes for facilitating distributed server-side unlearning with limited memory footprint. We propose memory-efficient distributed unlearning (MEDU), a hierarchical lossy compression scheme tailored for server-side unlearning, that integrates user sparsification, differential thresholding, and random lattice coding, to substantially reduce memory footprint. We rigorously analyze MEDU, deriving an upper bound on the difference between the desired model that is trained from scratch and the model unlearned from lossy compressed stored updates. Our bound outperforms the state-of-the-art known bounds for non-compressed decentralized server-side unlearning, even when lossy compression is incorporated. We further provide a numerical study, which shows that suited lossy compression can enable distributed unlearning with notably reduced memory footprint at the server while preserving the utility of the unlearned model.

Paper number 17:
Title: Multi-Class Stackelberg Games for the Co-Design of Networked Systems
Authors: Julian Barreiro-Gomez, Ye Wang
Abstract: We investigate a co-design problem, encompassing simultaneous design of system infrastructure and control, through a game-theoretical framework. To this end, we propose the co-design problem as a two-layer hierarchical strategic interaction. At the upper layer, a leader (or multiple leaders) determines system design parameters, while at the lower layer, a follower (or multiple followers) optimizes the control strategy. To capture this hierarchy, we propose four novel classes of Stackelberg games that integrate diverse strategic behaviors, including combinations of cooperative and non-cooperative interactions across two different layers. Notably, the leaders' interactions are represented using a normal-form game, whereas the followers' interactions are modeled by different games (dynamic games in discrete time). These distinct game structures result in a Stackelberg game that accommodates different game types per layer, and/or supports heterogeneous strategic behaviors involving cooperation and non-cooperation simultaneously. Learning algorithms using the best-response dynamics are used to solve the game problems when considering a discrete strategic space for the leaders. The efficacy of the proposed approach is demonstrated through an application to the co-design of the Barcelona drinking water network.

Paper number 18:
Title: Learning-based Homothetic Tube MPC
Authors: Yulong Gao, Shuhao Yan, Jian Zhou, Mark Cannon
Abstract: In this paper, we study homothetic tube model predictive control (MPC) of discrete-time linear systems subject to bounded additive disturbance and mixed constraints on the state and input. Different from most existing work on robust MPC, we assume that the true disturbance set is unknown but a conservative surrogate is available a priori. Leveraging the real-time data, we develop an online learning algorithm to approximate the true disturbance set. This approximation and the corresponding constraints in the MPC optimisation are updated online using computationally convenient linear programs. We provide statistical gaps between the true and learned disturbance sets, based on which, probabilistic recursive feasibility of homothetic tube MPC problems is discussed. Numerical simulations are provided to demonstrate the efficacy of our proposed algorithm and compare with state-of-the-art MPC algorithms.

Paper number 19:
Title: Power Loss and Temperature Distribution in Coil of PFC Inductor with Air Gap for Multimode Operation
Authors: Rafal Kasikowski
Abstract: Power converters inherently display non-linear load characteristics, resulting in a high level of mains harmonics, and hence the necessity of implementing Power Factor Correction (PFC). Active PFC circuitry typically comprises an inductor and a power switch to control and alter the input current so that it matches, in shape and phase, the input voltage. This modelling of the waveforms can be performed by means of distinct conduction modes of the PFC inductor. The digital controller implemented in the constructed and investigated boost-type PFC converter can be programmed to operate in discontinuous conduction mode (DCM), continuous conduction mode (CCM), or a combination of the two. The individual modes of operation, via distinct PFC inductor current waveforms, impact the overall efficiency of power conversion and, by extension, temperature distribution in the magnetic component. This paper investigates how the examined conduction modes bear on distinct power-loss mechanisms present in the PFC inductor, including high-frequency eddy-current-generating phenomena, and the fringing effect in particular. As demonstrated herein, the DCM operation, for the set output power level, exhibits exacerbated power dissipation in the winding of the inductor due to the somewhat increased RSM value of the current and the intensified fringing magnetic flux at an air gap. The latter assertion will undergo further, more quantitatively focused research. Finally, the construction of the coil was optimised to reduce power loss by diminishing eddy-current mechanisms.

Paper number 20:
Title: Sequentially learning regions of attraction from data
Authors: Oumayma Khattabi, Matteo Tacchi-BÃ©nard, Sorin Olaru
Abstract: The paper is dedicated to data-driven analysis of dynamical systems. It deals with certifying the basin of attraction of a stable equilibrium for an unknown dynamical system. It is supposed that point-wise evaluation of the right-hand side of the ordinary differential equation governing the system is available for a set of points in the state space. Technically, a Piecewise Affine Lyapunov function will be constructed iteratively using an optimisation-based technique for the effective validation of the certificates. As a main contribution, whenever those certificates are violated locally, a refinement of the domain and the associated tessellation is produced, thus leading to an improvement in the description of the domain of attraction.

Paper number 21:
Title: Event-Triggered GAT-LSTM Framework for Attack Detection in Heating, Ventilation, and Air Conditioning Systems
Authors: Zhenan Feng, Ehsan Nekouei
Abstract: Heating, Ventilation, and Air Conditioning (HVAC) systems are essential for maintaining indoor environmental quality, but their interconnected nature and reliance on sensor networks make them vulnerable to cyber-physical attacks. Such attacks can interrupt system operations and risk leaking sensitive personal information through measurement data. In this paper, we propose a novel attack detection framework for HVAC systems, integrating an Event-Triggering Unit (ETU) for local monitoring and a cloud-based classification system using the Graph Attention Network (GAT) and the Long Short-Term Memory (LSTM) network. The ETU performs a binary classification to identify potential anomalies and selectively triggers encrypted data transmission to the cloud, significantly reducing communication cost. The cloud-side GAT module models the spatial relationships among HVAC components, while the LSTM module captures temporal dependencies across encrypted state sequences to classify the attack type. Our approach is evaluated on datasets that simulate diverse attack scenarios. Compared to GAT-only (94.2% accuracy) and LSTM-only (91.5%) ablations, our full GAT-LSTM model achieves 98.8% overall detection accuracy and reduces data transmission to 15%. These results demonstrate that the proposed framework achieves high detection accuracy while preserving data privacy by using the spatial-temporal characteristics of HVAC systems and minimizing transmission costs through event-triggered communication.

Paper number 22:
Title: Design and Development of a Robust Tolerance Optimisation Framework for Automated Optical Inspection in Semiconductor Manufacturing
Authors: Shruthi Kogileru, Mark McBride, Yaxin Bi, Kok Yew Ng
Abstract: Automated Optical Inspection (AOI) is widely used across various industries, including surface mount technology in semiconductor manufacturing. One of the key challenges in AOI is optimising inspection tolerances. Traditionally, this process relies heavily on the expertise and intuition of engineers, making it subjective and prone to inconsistency. To address this, we are developing an intelligent, data-driven approach to optimise inspection tolerances in a more objective and consistent manner. Most existing research in this area focuses primarily on minimising false calls, often at the risk of allowing actual defects to go undetected. This oversight can compromise product quality, especially in critical sectors such as medical, defence, and automotive industries. Our approach introduces the use of percentile rank, amongst other logical strategies, to ensure that genuine defects are not overlooked. With continued refinement, our method aims to reach a point where every flagged item is a true defect, thereby eliminating the need for manual inspection. Our proof of concept achieved an 18% reduction in false calls at the 80th percentile rank, while maintaining a 100% recall rate. This makes the system both efficient and reliable, offering significant time and cost savings.

Paper number 23:
Title: Affine Filter Bank Modulation: A New Waveform for High Mobility Communications
Authors: Henrique L. Senger, Gustavo P. GonÃ§alves, Bruno S. Chang, Hyeon Seok Rou, Kuranage Roche Rayan Ranasinghe, Giuseppe Thadeu Freitas de Abreu, Didier Le Ruyet
Abstract: We propose a new waveform suitable for integrated sensing and communications (ISAC) systems facing doubly-dispersive (DD) channel conditions, as typically encountered in high mobility scenarios. Dubbed Affine Filter Bank Modulation (AFBM), this novel waveform is designed based on a filter-bank structure, known for its ability to suppress out-of-band emissions (OOBE), while integrating a discrete affine Fourier transform (DAFT) precoding stage which yields low peak-to-average power ratio (PAPR) and robustness to DD distortion, as well as other features desirable for ISAC. Analytical and simulation results demonstrate that AFBM maintains quasi-orthogonality similar to that of affine frequency division multiplexing (AFDM) in DD channels, while achieving PAPR levels 3 dB lower, in addition to OOBE as low as -100 dB when implemented with PHYDYAS prototype filters.

Paper number 24:
Title: Artificial Potential Field and Sliding Mode Control for Spacecraft Attitude Maneuver with Actuation and Pointing Constraints
Authors: Mauro Mancini, Dario Ruggiero
Abstract: This study investigates the combination of guidance and control strategies for rigid spacecraft attitude reorientation, while dealing with forbidden pointing constraints, actuator limitations, and system uncertainties. These constraints arise due to the presence of bright objects in space that may damage sensitive payloads onboard the spacecraft, and the risk that actuator saturations may compromise closed-loop system stability. Furthermore, spacecraft attitude dynamics are typically affected by parametric uncertainties, external disturbances, and system nonlinearities, which cannot be neglected. In this article, the problem of spacecraft reorientation under pointing and actuation constraints is addressed using a strategy that combines Artificial Potential Field (APF) and Sliding Mode Control (SMC). A rigorous Lyapunov-based analysis yields closed-form expressions for APF/SMC gains, providing explicit mathematical formulas for gain values without the need for iterative computations. These expressions account for angular velocity and control torque limitations, external disturbances, and inertia uncertainties. The robustness of the proposed control strategy is demonstrated through Monte Carlo simulations using a high-fidelity attitude dynamics simulator. Additionally, mu-analysis is employed to assess local stability properties and quantify robustness margins. The results confirm the practical feasibility of the proposed method in real-world space scenarios, highlighting its effectiveness in uncertain and constrained environments.

Paper number 25:
Title: Dynamic load balancing for cloud systems under heterogeneous setup delays
Authors: Fernando Paganini, Diego Goldsztajn
Abstract: We consider a distributed cloud service deployed at a set of distinct server pools. Arriving jobs are classified into heterogeneous types, in accordance with their setup times which are differentiated at each of the pools. A dispatcher for each job type controls the balance of load between pools, based on decentralized feedback. The system of rates and queues is modeled by a fluid differential equation system, and analyzed via convex optimization. A first, myopic policy is proposed, based on task delay-to-service. Under a simplified dynamic fluid queue model, we prove global convergence to an equilibrium point which minimizes the mean setup time; however queueing delays are incurred with this method. A second proposal is then developed based on proximal optimization, which explicitly models the setup queue and is proved to reach an optimal equilibrium, devoid of queueing delay. Results are demonstrated through a simulation example.

Paper number 26:
Title: Backstepping Reach-avoid Controller Synthesis for Multi-input Multi-output Systems with Mixed Relative Degrees
Authors: Jianqiang Ding, Dingran Yuan, Shankar A. Deka
Abstract: Designing controllers with provable formal guarantees has become an urgent requirement for cyber-physical systems in safety-critical scenarios. Beyond addressing scalability in high-dimensional implementations, controller synthesis methodologies separating safety and reachability objectives may risk optimization infeasibility due to conflicting constraints, thereby significantly undermining their applicability in practical applications. In this paper, by leveraging feedback linearization and backstepping techniques, we present a novel framework for constructing provable reach-avoid formal certificates tailored to multi-input multi-output systems. Based on this, we developed a systematic synthesis approach for controllers with reach-avoid guarantees, which ensures that the outputs of the system eventually enter the predefined target set while staying within the required safe set. Finally, we demonstrate the effectiveness of our method through simulations.

Paper number 27:
Title: Stabilizing 3D EPI time series by servo navigation and phase equalization exploiting repeated shots (PEERS)
Authors: Malte Riedel, Thomas Ulrich, Samuel Bianchi, Klaas P. Pruessmann
Abstract: Purpose: To enable run-time head motion control and robust frequency corrections for 3D EPI fMRI. Methods: A short 3D orbital navigator (3 ms) is inserted into a 3D EPI sequence. A linear perturbation model is calibrated to estimate rigid motion and frequency parameters per shot. Rigid motion is corrected by scan geometry updates in run-time, while several techniques are investigated to stabilize navigator-based frequency corrections in the reconstruction. An additional method termed PEERS is proposed that exploits the repetitive structure of fMRI scans to fine-tune shot-wise phase and frequency estimates using the motion-corrected EPI data itself. Results: Servo navigation effectively reduces motion in the raw data of in-vivo fMRI scans in six subjects. PEERS provides high-precision frequency parameters for robust phase-corrected reconstructions in the phantom and in-vivo accounting for scanner drifts and slice encoding-related effects on EPI. In combination, servo navigation and PEERS achieve successful intra-volume corrections and consistent tSNR improvements of 8% on average throughout the brain. The two methods prove to be highly synergetic. Conclusion: Servo navigation achieves high-precision motion correction for 3D-EPI fMRI in run-time and, in synergy with PEERS, provides stable frequency corrections with short navigators even for long echo times. With its automatic self-calibration and no hardware requirements, servo navigation and PEERS enable effective plug-and-play motion correction for 3D fMRI.

Paper number 28:
Title: Optimal Droop Control Strategy for Coordinated Voltage Regulation and Power Sharing in Hybrid AC-MTDC Systems
Authors: Hongjin Du, Tuanku Badzlin Hashfi, Rashmi Prasad, Pedro P. Vergara, Peter Palensky, Aleksandra LekiÄ
Abstract: With the growing integration of modular multilevel converters (MMCs) in Multi-Terminal Direct Current (MTDC) transmission systems, there is an increasing need for control strategies that ensure both economic efficiency and robust dynamic performance. This paper presents an enhanced Optimal Power Flow (OPF) framework for hybrid AC-MTDC systems, integrating a novel droop control strategy that coordinates DC voltage and AC frequency regulation. By embedding frequency control loops into the MMCs, the method enables system-wide coordination, enhancing power sharing and improving system resilience under disturbances. The proposed strategy dynamically adjusts converter operating points to minimize generation costs and DC voltage deviations, thus balancing economic objectives with system stability. A modified Nordic test system integrated with a four-terminal MTDC grid is used to validate the approach. Optimization is performed using Julia, while the system's dynamic performance is evaluated through electromagnetic transient simulations with the EMTP software. Case studies across multiple scenarios demonstrate that the proposed method consistently achieves lower generation costs than active power control and adaptive droop control strategy while maintaining stable control characteristics. The results highlight the method's capability to deliver cost-effective operation without compromising performance, offering a promising solution for the coordinated control of future hybrid AC-DC transmission networks.

Paper number 29:
Title: Fairness of Automatic Speech Recognition in Cleft Lip and Palate Speech
Authors: Susmita Bhattacharjee, Jagabandhu Mishra, H.S. Shekhawat, S. R. Mahadeva Prasanna
Abstract: Speech produced by individuals with cleft lip and palate (CLP) is often highly nasalized and breathy due to structural anomalies, causing shifts in formant structure that affect automatic speech recognition (ASR) performance and fairness. This study hypothesizes that publicly available ASR systems exhibit reduced fairness for CLP speech and confirms this through experiments. Despite formant disruptions, mild and moderate CLP speech retains some spectro-temporal alignment with normal speech, motivating augmentation strategies to enhance fairness. The study systematically explores augmenting CLP speech with normal speech across severity levels and evaluates its impact on ASR fairness. Three ASR models-GMM-HMM, Whisper, and XLS-R-were tested on AIISH and NMCPC datasets. Results indicate that training with normal speech and testing on mixed data improves word error rate (WER). Notably, WER decreased from $22.64\%$ to $18.76\%$ (GMM-HMM, AIISH) and $28.45\%$ to $18.89\%$ (Whisper, NMCPC). The superior performance of GMM-HMM on AIISH may be due to its suitability for Kannada children's speech, a challenge for foundation models like XLS-R and Whisper. To assess fairness, a fairness score was introduced, revealing improvements of $17.89\%$ (AIISH) and $47.50\%$ (NMCPC) with augmentation.

Paper number 30:
Title: Toward a Harmonized Approach -- Requirement-based Structuring of a Safety Assurance Argumentation for Automated Vehicles
Authors: M. Loba, N. F. Salem, M. Nolte, A. Dotzler, M. Maurer
Abstract: Despite increasing testing operation on public roads, media reports on incidents show that safety issues remain to this day. One major cause factoring into this circumstance is high development uncertainty that manufacturers face when deploying these systems in an open context. In particular, one challenge is establishing a valid argument at design time that the vehicle will exhibit reasonable residual risk when operating in its intended operational design domain. Regulations, such as the European Implementing Regulation 2022/1426, require manufacturers to provide a safety assurance argumentation for SAE-Level-4 automated vehicles. While there is extensive literature on assurance cases for safety-critical systems, the domain of automated driving lacks explicit requirements regarding the creation of safety assurance argumentations. In this paper, we aim to narrow this gap by elaborating a requirement-based approach. We derive structural requirements for an argumentation from literature and supplement these with requirements derived from stakeholder concerns. We implement the requirements, yielding a proposal for an overall argumentation structure. The resulting "safety arguments" argue over four topic complexes: The developed product, the underlying process including its conformance/compliance to standards/laws, as well as the argumentations' context and soundness. Finally, we instantiate this structure with respect to domain-specific needs and principles.

Paper number 31:
Title: Evaluation of Coordination Strategies for Underground Automated Vehicle Fleets in Mixed Traffic
Authors: Olga Mironenko, Hadi Banaee, Amy Loutfi
Abstract: This study investigates the efficiency and safety outcomes of implementing different adaptive coordination models for automated vehicle (AV) fleets, managed by a centralized coordinator that dynamically responds to human-controlled vehicle behavior. The simulated scenarios replicate an underground mining environment characterized by narrow tunnels with limited connectivity. To address the unique challenges of such settings, we propose a novel metric - Path Overlap Density (POD) - to predict efficiency and potentially the safety performance of AV fleets. The study also explores the impact of map features on AV fleets performance. The results demonstrate that both AV fleet coordination strategies and underground tunnel network characteristics significantly influence overall system performance. While map features are critical for optimizing efficiency, adaptive coordination strategies are essential for ensuring safe operations.

Paper number 32:
Title: Floating Car Observers in Intelligent Transportation Systems: Detection Modeling and Temporal Insights
Authors: Jeremias Gerner, Klaus Bogenberger, Stefanie Schmidtner
Abstract: Floating Car Observers (FCOs) extend traditional Floating Car Data (FCD) by integrating onboard sensors to detect and localize other traffic participants, providing richer and more detailed traffic data. In this work, we explore various modeling approaches for FCO detections within microscopic traffic simulations to evaluate their potential for Intelligent Transportation System (ITS) applications. These approaches range from 2D raytracing to high-fidelity co-simulations that emulate real-world sensors and integrate 3D object detection algorithms to closely replicate FCO detections. Additionally, we introduce a neural network-based emulation technique that effectively approximates the results of high-fidelity co-simulations. This approach captures the unique characteristics of FCO detections while offering a fast and scalable solution for modeling. Using this emulation method, we investigate the impact of FCO data in a digital twin of a traffic network modeled in SUMO. Results demonstrate that even at a 20% penetration rate, FCOs using LiDAR-based detections can identify 65% of vehicles across various intersections and traffic demand scenarios. Further potential emerges when temporal insights are integrated, enabling the recovery of previously detected but currently unseen vehicles. By employing data-driven methods, we recover over 80% of these vehicles with minimal positional deviations. These findings underscore the potential of FCOs for ITS, particularly in enhancing traffic state estimation and monitoring under varying penetration rates and traffic conditions.

Paper number 33:
Title: Allocation of Heterogeneous Resources in General Lotto Games
Authors: Keith Paarporn, Adel Aghajan, Jason R. Marden
Abstract: The allocation of resources plays an important role in the completion of system objectives and tasks, especially in the presence of strategic adversaries. Optimal allocation strategies are becoming increasingly more complex, given that multiple heterogeneous types of resources are at a system planner's disposal. In this paper, we focus on deriving optimal strategies for the allocation of heterogeneous resources in a well-known competitive resource allocation model known as the General Lotto game. In standard formulations, outcomes are determined solely by the players' allocation strategies of a common, single type of resource across multiple contests. In particular, a player wins a contest if it sends more resources than the opponent. Here, we propose a multi-resource extension where the winner of a contest is now determined not only by the amount of resources allocated, but also by the composition of resource types that are allocated. We completely characterize the equilibrium payoffs and strategies for two distinct formulations. The first consists of a weakest-link/best-shot winning rule, and the second considers a winning rule based on a weighted linear combination of the allocated resources. We then consider a scenario where the resource types are costly to purchase, and derive the players' equilibrium investments in each of the resource types.

Paper number 34:
Title: Multi-Antenna Users in Cell-Free Massive MIMO: Stream Allocation and Necessity of Downlink Pilots
Authors: Eren Berk Kama, Junbeom Kim, Emil BjÃ¶rnson
Abstract: We consider a cell-free massive multiple-input multiple-output (MIMO) system with multiple antennas on the users and access points (APs). In previous works, the downlink spectral efficiency (SE) has been evaluated using the hardening bound that requires no downlink pilots. This approach works well for single-antenna users. In this paper, we show that much higher SEs can be achieved if downlink pilots are sent when having multi-antenna users. The reason is that the effective channel matrix does not harden. We propose a pilot-based downlink estimation scheme, derive a new SE expression, and show numerically that it yields substantially higher performance when having correlated Rayleigh fading channels. In cases with multi-antenna users, the APs can either transmit the same or different data streams. The latter reduces the fronthaul signaling but comes with a SE loss. We propose precoding and combining schemes for these cases and consider whether channel knowledge is shared between the APs. Finally, we show numerically how the number of users, APs, and the number of antennas on users and APs affect the SE.

Paper number 35:
Title: Computing in Integrated Terrestrial and Non-Terrestrial Networks: A Comprehensive Survey
Authors: Hoe Ziet Wong, Insaf Rzig, Safwan Alfattani, Wael Jaafar
Abstract: The rapid growth of Internet-of-things (IoT) devices, smart vehicles, and other connected objects is driving demand for ubiquitous connectivity and intensive computing capacity. 5G and upcoming 6G networks are crucial to meeting these demands and the fast-evolving services and applications. However, traditional terrestrial networks face limitations in coverage and capacity. Integrated Terrestrial and Non-Terrestrial Networks (ITNTN) are emerging to address these challenges. In essence, ITNTN combines ground-based infrastructure with aerial, space, and water surface networks to provide seamless connectivity and computing resources anytime, anywhere. Given the stringent quality-of-service (QoS) of future services, edge computing will be an inseparable component of ITNTN. Consequently, we dive in this survey into current efforts of integrating cloud/fog/edge computing into ITNTN layers to facilitate stringent QoS services and address the data processing needs of modern applications. Since there have been only limited and partial efforts in integrating computing functionalities within ITNTN, we aim to extend the discussion to the full integration of computing and identifying the challenges and future research directions to achieve it.

Paper number 36:
Title: BLAB: Brutally Long Audio Bench
Authors: Orevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora, Shuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah Bennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, Sachin Kumar
Abstract: Developing large audio language models (LMs) capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations. Recent work on audio LMs has primarily evaluated their performance on short audio segments, typically under 30 seconds, with limited exploration of long-form conversational speech segments that more closely reflect natural user interactions with these models. We introduce Brutally Long Audio Bench (BLAB), a challenging long-form audio benchmark that evaluates audio LMs on localization, duration estimation, emotion, and counting tasks using audio segments averaging 51 minutes in length. BLAB consists of 833+ hours of diverse, full-length audio clips, each paired with human-annotated, text-based natural language questions and answers. Our audio data were collected from permissively licensed sources and underwent a human-assisted filtering process to ensure task compliance. We evaluate six open-source and proprietary audio LMs on BLAB and find that all of them, including advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the tasks in BLAB. Our comprehensive analysis reveals key insights into the trade-offs between task difficulty and audio duration. In general, we find that audio LMs struggle with long-form speech, with performance declining as duration increases. They perform poorly on localization, temporal reasoning, counting, and struggle to understand non-phonemic information, relying more on prompts than audio content. BLAB serves as a challenging evaluation framework to develop audio LMs with robust long-form audio understanding capabilities.

Paper number 37:
Title: $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation
Authors: Sean Reiter, Ion Victor Gosea, Igor Pontes Duff, Serkan Gugercin
Abstract: This paper addresses the $\mathcal{H}_2$-optimal approximation of linear dynamical systems with quadratic-output functions, also known as linear quadratic-output systems. Our major contributions are threefold. First, we derive interpolation-based first-order optimality conditions for the linear quadratic-output $\mathcal{H}_2$ minimization problem. These conditions correspond to the mixed-multipoint tangential interpolation of the full-order linear- and quadratic-output transfer functions, and generalize the Meier-Luenberger optimality framework for the $\mathcal{H}_2$-optimal model reduction of linear time-invariant systems. Second, given the interpolation data, we show how to enforce these mixed-multipoint tangential interpolation conditions explicitly by Petrov-Galerkin projection of the full-order model matrices. Third, to find the optimal interpolation data, we build on this projection framework and propose a generalization of the iterative rational Krylov algorithm for the $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces a reduced linear quadratic-output system that satisfies the interpolatory optimality conditions. The method only requires solving shifted linear systems and matrix-vector products, thus making it suitable for large-scale problems. Numerical examples are included to illustrate the effectiveness of the proposed method.

Paper number 38:
Title: Coupling the Heart to Musical Machines
Authors: Eric Easthope
Abstract: Biofeedback is being used more recently as a general control paradigm for human-computer interfaces (HCIs). While biofeedback especially from breath has seen increasing uptake as a controller for novel musical interfaces, new interfaces for musical expression (NIMEs), the community has not given as much attention to the heart. The heart is just as intimate a part of music as breath and it is argued that the heart determines our perception of time and so indirectly our perception of music. Inspired by this I demonstrate a photoplethysmogram (PPG)-based NIME controller using heart rate as a 1D control parameter to transform the qualities of sounds in real-time over a Bluetooth wireless HCI. I apply time scaling to "warp" audio buffers inbound to the sound card, and play these transformed audio buffers back to the listener wearing the PPG sensor, creating a hypothetical perceptual biofeedback loop: changes in sound change heart rate to change PPG measurements to change sound. I discuss how a sound-heart-PPG biofeedback loop possibly affords greater control and/or variety of movements with a 1D controller, how controlling the space and/or time scale of sound playback with biofeedback makes for possibilities in performance ambience, and I briefly discuss generative latent spaces as a possible way to extend a 1D PPG control space.

Paper number 39:
Title: Coevolution of Actions and Opinions in Networks of Coordinating and Anti-Coordinating Agents
Authors: Hong Liang, Mengbin Ye, Lorenzo Zino, Weiguo Xia
Abstract: In this paper, we investigate the dynamics of coordinating and anti-coordinating agents in a coevolutionary model for actions and opinions. In the model, the individuals of a population interact on a two-layer network, sharing their opinions and observing others' action, while revising their own opinions and actions according to a game-theoretic mechanism, grounded in the social psychology literature. First, we consider the scenario of coordinating agents, where convergence to a Nash equilibrium (NE) is guaranteed. We identify conditions for reaching consensus configurations and establish regions of attraction for these equilibria. Second, we study networks of anti-coordinating agents. In this second scenario, we prove that all trajectories converge to a NE by leveraging potential game theory. Then, we establish analytical conditions on the network structure and model parameters to guarantee the existence of consensus and polarized equilibria, characterizing their regions of attraction.

Paper number 40:
Title: Edge Large AI Models: Collaborative Deployment and IoT Applications
Authors: Zixin Wang, Yuanming Shi, Khaled. B. Letaief
Abstract: Large artificial intelligence models (LAMs) emulate human-like problem-solving capabilities across diverse domains, modalities, and tasks. By leveraging the communication and computation resources of geographically distributed edge devices, edge LAMs enable real-time intelligent services at the network edge. Unlike conventional edge AI, which relies on small or moderate-sized models for direct feature-to-prediction mappings, edge LAMs leverage the intricate coordination of modular components to enable context-aware generative tasks and multi-modal inference. We shall propose a collaborative deployment framework for edge LAM by characterizing the LAM intelligent capabilities and limited edge network resources. Specifically, we propose a collaborative training framework over heterogeneous edge networks that adaptively decomposes LAMs according to computation resources, data modalities, and training objectives, reducing communication and computation overheads during the fine-tuning process. Furthermore, we introduce a microservice-based inference framework that virtualizes the functional modules of edge LAMs according to their architectural characteristics, thereby improving resource utilization and reducing inference latency. The developed edge LAM will provide actionable solutions to enable diversified Internet-of-Things (IoT) applications, facilitated by constructing mappings from diverse sensor data to token representations and fine-tuning based on domain knowledge.

Paper number 41:
Title: CoGenAV: Versatile Audio-Visual Representation Learning via Contrastive-Generative Synchronization
Authors: Detao Bai, Zhiheng Ma, Xihan Wei, Liefeng Bo
Abstract: The inherent synchronization between a speaker's lip movements, voice, and the underlying linguistic content offers a rich source of information for improving speech processing tasks, especially in challenging conditions where traditional audio-only systems falter. We introduce CoGenAV, a powerful and data-efficient model designed to learn versatile audio-visual representations applicable across a wide range of speech and audio-visual tasks. CoGenAV is trained by optimizing a dual objective derived from natural audio-visual synchrony, contrastive feature alignment and generative text prediction, using only 223 hours of labeled data from the LRS2 dataset. This contrastive-generative synchronization strategy effectively captures fundamental cross-modal correlations. We showcase the effectiveness and versatility of the learned CoGenAV representations on multiple benchmarks. When utilized for Audio-Visual Speech Recognition (AVSR) on LRS2, these representations contribute to achieving a state-of-the-art Word Error Rate (WER) of 1.27. They also enable strong performance in Visual Speech Recognition (VSR) with a WER of 22.0 on LRS2, and significantly improve performance in noisy environments by over 70%. Furthermore, CoGenAV representations benefit speech reconstruction tasks, boosting performance in Speech Enhancement and Separation, and achieve competitive results in audio-visual synchronization tasks like Active Speaker Detection (ASD). Our model will be open-sourced to facilitate further development and collaboration within both academia and industry.

Paper number 42:
Title: A study on audio synchronous steganography detection and distributed guide inference model based on sliding spectral features and intelligent inference drive
Authors: Wei Meng
Abstract: With the rise of short video platforms in global communication, embedding steganographic data in audio synchronization streams has emerged as a new covert communication method. To address the limitations of traditional techniques in detecting synchronized steganography, this paper proposes a detection and distributed guidance reconstruction model based on short video "Yupan" samples released by China's South Sea Fleet on TikTok. The method integrates sliding spectrum feature extraction and intelligent inference mechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is used to extract the main frequency trajectory and construct the synchronization frame detection model (M1), identifying a frame flag "FFFFFFFFFFFFFFFFFF80". The subsequent 32-byte payload is decoded by a structured model (M2) to infer distributed guidance commands. Analysis reveals a low-entropy, repetitive byte sequence in the 36 to 45 second audio segment with highly concentrated spectral energy, confirming the presence of synchronization frames. Although plaintext semantics are not restored, the consistency in command field layout suggests features of military communication protocols. The multi-segment splicing model further shows cross-video embedding and centralized decoding capabilities. The proposed framework validates the effectiveness of sliding spectral features for synchronized steganography detection and builds an extensible inference model for covert communication analysis and tactical guidance simulation on open platforms.

Paper number 43:
Title: MGFF-TDNN: A Multi-Granularity Feature Fusion TDNN Model with Depth-Wise Separable Module for Speaker Verification
Authors: Ya Li, Bin Zhou, Bo Hu
Abstract: In speaker verification, traditional models often emphasize modeling long-term contextual features to capture global speaker characteristics. However, this approach can neglect fine-grained voiceprint information, which contains highly discriminative features essential for robust speaker embeddings. This paper introduces a novel model architecture, termed MGFF-TDNN, based on multi-granularity feature fusion. The MGFF-TDNN leverages a two-dimensional depth-wise separable convolution module, enhanced with local feature modeling, as a front-end feature extractor to effectively capture time-frequency domain features. To achieve comprehensive multi-granularity feature fusion, we propose the M-TDNN structure, which integrates global contextual modeling with fine-grained feature extraction by combining time-delay neural networks and phoneme-level feature pooling. Experiments on the VoxCeleb dataset demonstrate that the MGFF-TDNN achieves outstanding performance in speaker verification while remaining efficient in terms of parameters and computational resources.

Paper number 44:
Title: SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation
Authors: Yu-Ren Guo, Wen-Kai Tai
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing (NLP) and multimodal learning, with successful applications in text generation and speech synthesis, enabling a deeper understanding and generation of multimodal content. In the field of sound effects (SFX) generation, LLMs have been leveraged to orchestrate multiple models for audio synthesis. However, due to the scarcity of annotated datasets, and the complexity of temproal modeling. current SFX generation techniques still fall short in achieving high-fidelity audio. To address these limitations, this paper introduces a novel framework that integrates LLMs with existing sound effect databases, allowing for the retrieval, recombination, and synthesis of audio based on user requirements. By leveraging this approach, we enhance the diversity and quality of generated sound effects while eliminating the need for additional recording costs, offering a flexible and efficient solution for sound design and application.

Paper number 45:
Title: DiffVQA: Video Quality Assessment Using Diffusion Feature Extractor
Authors: Wei-Ting Chen, Yu-Jiet Vong, Yi-Tsung Lee, Sy-Yen Kuo, Qiang Gao, Sizhuo Ma, Jian Wang
Abstract: Video Quality Assessment (VQA) aims to evaluate video quality based on perceptual distortions and human preferences. Despite the promising performance of existing methods using Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), they often struggle to align closely with human perceptions, particularly in diverse real-world scenarios. This challenge is exacerbated by the limited scale and diversity of available datasets. To address this limitation, we introduce a novel VQA framework, DiffVQA, which harnesses the robust generalization capabilities of diffusion models pre-trained on extensive datasets. Our framework adapts these models to reconstruct identical input frames through a control module. The adapted diffusion model is then used to extract semantic and distortion features from a resizing branch and a cropping branch, respectively. To enhance the model's ability to handle long-term temporal dynamics, a parallel Mamba module is introduced, which extracts temporal coherence augmented features that are merged with the diffusion features to predict the final score. Experiments across multiple datasets demonstrate DiffVQA's superior performance on intra-dataset evaluations and its exceptional generalization across datasets. These results confirm that leveraging a diffusion model as a feature extractor can offer enhanced VQA performance compared to CNN and ViT backbones.

Paper number 46:
Title: Rapid diagnostics of reconfigurable intelligent surfaces using space-time-coding modulation
Authors: Yi Ning Zheng, Lei Zhang, Xiao Qing Chen, Marco Rossi, Giuseppe Castaldi, Shuo Liu, Tie Jun Cui, Vincenzo Galdi
Abstract: Reconfigurable intelligent surfaces (RISs) have emerged as a key technology for shaping smart wireless environments in next-generation wireless communication systems. To support the large-scale deployment of RISs, a reliable and efficient diagnostic method is essential to ensure optimal performance. In this work, a robust and efficient approach for RIS diagnostics is proposed using a space-time coding strategy with orthogonal codes. The method encodes the reflected signals from individual RIS elements into distinct code channels, enabling the recovery of channel power at the receiving terminals for fault identification. Theoretical analysis shows that the normally functioning elements generate high power in their respective code channels, whereas the faulty elements exhibit significantly lower power. This distinction enables rapid and accurate diagnostics of elements' operational states through simple signal processing techniques. Simulation results validate the effectiveness of the proposed method, even under high fault ratios and varying reception angles. Proof-of-principle experiments on two RIS prototypes are conducted, implementing two coding strategies: direct and segmented. Experimental results in a realistic scenario confirm the reliability of the diagnostic method, demonstrating its potential for large-scale RIS deployment in future wireless communication systems and radar applications.

Paper number 47:
Title: SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation
Authors: Zhaoxi Mu, Xinyu Yang, Gang Wang
Abstract: While contemporary speech separation technologies adeptly process lengthy mixed audio waveforms, they are frequently challenged by the intricacies of real-world environments, including noisy and reverberant settings, which can result in artifacts or distortions in the separated speech. To overcome these limitations, we introduce SepALM, a pioneering approach that employs audio language models (ALMs) to rectify and re-synthesize speech within the text domain following preliminary separation. SepALM comprises four core components: a separator, a corrector, a synthesizer, and an aligner. By integrating an ALM-based end-to-end error correction mechanism, we mitigate the risk of error accumulation and circumvent the optimization hurdles typically encountered in conventional methods that amalgamate automatic speech recognition (ASR) with large language models (LLMs). Additionally, we have developed Chain-of-Thought (CoT) prompting and knowledge distillation techniques to facilitate the reasoning and training processes of the ALM. Our experiments substantiate that SepALM not only elevates the precision of speech separation but also markedly bolsters adaptability in novel acoustic environments.

Paper number 48:
Title: Enabling Robots to Autonomously Search Dynamic Cluttered Post-Disaster Environments
Authors: Karlo Rado, Mirko Baglioni, Anahita Jamshidnejad
Abstract: Robots will bring search and rescue (SaR) in disaster response to another level, in case they can autonomously take over dangerous SaR tasks from humans. A main challenge for autonomous SaR robots is to safely navigate in cluttered environments with uncertainties, while avoiding static and moving obstacles. We propose an integrated control framework for SaR robots in dynamic, uncertain environments, including a computationally efficient heuristic motion planning system that provides a nominal (assuming there are no uncertainties) collision-free trajectory for SaR robots and a robust motion tracking system that steers the robot to track this reference trajectory, taking into account the impact of uncertainties. The control architecture guarantees a balanced trade-off among various SaR objectives, while handling the hard constraints, including safety. The results of various computer-based simulations, presented in this paper, showed significant out-performance (of up to 42.3%) of the proposed integrated control architecture compared to two commonly used state-of-the-art methods (Rapidly-exploring Random Tree and Artificial Potential Function) in reaching targets (e.g., trapped victims in SaR) safely, collision-free, and in the shortest possible time.

Paper number 49:
Title: Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation
Authors: Jincheng Zhang, GyÃ¶rgy Fazekas, Charalampos Saitis
Abstract: The recent surge in the popularity of diffusion models for image synthesis has attracted new attention to their potential for generation tasks in other domains. However, their applications to symbolic music generation remain largely under-explored because symbolic music is typically represented as sequences of discrete events and standard diffusion models are not well-suited for discrete data. We represent symbolic music as image-like pianorolls, facilitating the use of diffusion models for the generation of symbolic music. Moreover, this study introduces a novel diffusion model that incorporates our proposed Transformer-Mamba block and learnable wavelet transform. Classifier-free guidance is utilised to generate symbolic music with target chords. Our evaluation shows that our method achieves compelling results in terms of music quality and controllability, outperforming the strong baseline in pianoroll generation. Our code is available at this https URL.

Paper number 50:
Title: Very High-Resolution Forest Mapping with TanDEM-X InSAR Data and Self-Supervised Learning
Authors: JosÃ©-Luis Bueso-Bello, Benjamin Chauvel, Daniel Carcereri, Philipp Posovszky, Pietro Milillo, Jennifer Ruiz, Juan-Carlos FernÃ¡ndez-Diaz, Carolina GonzÃ¡lez, Michele Martone, Ronny HÃ¤nsch, Paola Rizzoli
Abstract: Deep learning models have shown encouraging capabilities for mapping accurately forests at medium resolution with TanDEM-X interferometric SAR data. Such models, as most of current state-of-the-art deep learning techniques in remote sensing, are trained in a fully-supervised way, which requires a large amount of labeled data for training and validation. In this work, our aim is to exploit the high-resolution capabilities of the TanDEM-X mission to map forests at 6 m. The goal is to overcome the intrinsic limitations posed by midresolution products, which affect, e.g., the detection of narrow roads within vegetated areas and the precise delineation of forested regions contours. To cope with the lack of extended reliable reference datasets at such a high resolution, we investigate self-supervised learning techniques for extracting highly informative representations from the input features, followed by a supervised training step with a significantly smaller number of reliable labels. A 1 m resolution forest/non-forest reference map over Pennsylvania, USA, allows for comparing different training approaches for the development of an effective forest mapping framework with limited labeled samples. We select the best-performing approach over this test region and apply it in a real-case forest mapping scenario over the Amazon rainforest, where only very few labeled data at high resolution are available. In this challenging scenario, the proposed self-supervised framework significantly enhances the classification accuracy with respect to fully-supervised methods, trained using the same amount of labeled data, representing an extremely promising starting point for large-scale, very high-resolution forest mapping with TanDEM-X data.

Paper number 51:
Title: The Inverse Drum Machine: Source Separation Through Joint Transcription and Analysis-by-Synthesis
Authors: Bernardo Torres (S2A, IDS), Geoffroy Peeters (S2A, IDS), Gael Richard (S2A, IDS)
Abstract: We introduce the Inverse Drum Machine (IDM), a novel approach to drum source separation that combines analysis-by-synthesis with deep learning. Unlike recent supervised methods that rely on isolated stems, IDM requires only transcription annotations. It jointly optimizes automatic drum transcription and one-shot drum sample synthesis in an end-to-end framework. By convolving synthesized one-shot samples with estimated onsets-mimicking a drum machine-IDM reconstructs individual drum stems and trains a neural network to match the original mixture. Evaluations on the StemGMD dataset show that IDM achieves separation performance on par with state-of-the-art supervised methods, while substantially outperforming matrix decomposition baselines.

Paper number 52:
Title: Reinforced Correlation Between Vision and Language for Precise Medical AI Assistant
Authors: Haonan Wang, Jiaji Mao, Lehan Wang, Qixiang Zhang, Marawan Elbatel, Yi Qin, Huijun Hu, Baoxun Li, Wenhui Deng, Weifeng Qin, Hongrui Li, Jialin Liang, Jun Shen, Xiaomeng Li
Abstract: Medical AI assistants support doctors in disease diagnosis, medical image analysis, and report generation. However, they still face significant challenges in clinical use, including limited accuracy with multimodal content and insufficient validation in real-world settings. We propose RCMed, a full-stack AI assistant that improves multimodal alignment in both input and output, enabling precise anatomical delineation, accurate localization, and reliable diagnosis through hierarchical vision-language grounding. A self-reinforcing correlation mechanism allows visual features to inform language context, while language semantics guide pixel-wise attention, forming a closed loop that refines both modalities. This correlation is enhanced by a color region description strategy, translating anatomical structures into semantically rich text to learn shape-location-text relationships across scales. Trained on 20 million image-mask-description triplets, RCMed achieves state-of-the-art precision in contextualizing irregular lesions and subtle anatomical boundaries, excelling in 165 clinical tasks across 9 modalities. It achieved a 23.5% relative improvement in cell segmentation from microscopy images over prior methods. RCMed's strong vision-language alignment enables exceptional generalization, with state-of-the-art performance in external validation across 20 clinically significant cancer types, including novel tasks. This work demonstrates how integrated multimodal models capture fine-grained patterns, enabling human-level interpretation in complex scenarios and advancing human-centric AI healthcare.

Paper number 53:
Title: Knowledge Distillation for Speech Denoising by Latent Representation Alignment with Cosine Distance
Authors: Diep Luong, Mikko Heikkinen, Konstantinos Drossos, Tuomas Virtanen
Abstract: Speech denoising is a generally adopted and impactful task, appearing in many common and everyday-life use cases. Although there are very powerful methods published, most of those are too complex for deployment in everyday and low-resources computational environments, like hand-held devices, intelligent glasses, hearing aids, etc. Knowledge distillation (KD) is a prominent way for alleviating this complexity mismatch and is based on the transferring/distilling of knowledge from a pre-trained complex model, the teacher, to another less complex one, the student. Existing KD methods for speech denoising are based on processes that potentially hamper the KD by bounding the learning of the student to the distribution, information ordering, and feature dimensionality learned by the teacher. In this paper, we present and assess a method that tries to treat this issue, by exploiting the well-known denoising-autoencoder framework, the linear inverted bottlenecks, and the properties of the cosine similarity. We use a public dataset and conduct repeated experiments with different mismatching scenarios between the teacher and the student, reporting the mean and standard deviation of the metrics of our method and another, state-of-the-art method that is used as a baseline. Our results show that with the proposed method, the student can perform better and can also retain greater mismatching conditions compared to the teacher.

Paper number 54:
Title: Panoramic Out-of-Distribution Segmentation
Authors: Mengfei Duan, Kailun Yang, Yuheng Zhang, Yihong Cao, Fei Teng, Kai Luo, Jiaming Zhang, Zhiyong Li, Shutao Li
Abstract: Panoramic imaging enables capturing 360Â° images with an ultra-wide Field-of-View (FoV) for dense omnidirectional perception. However, current panoramic semantic segmentation methods fail to identify outliers, and pinhole Out-of-distribution Segmentation (OoS) models perform unsatisfactorily in the panoramic domain due to background clutter and pixel distortions. To address these issues, we introduce a new task, Panoramic Out-of-distribution Segmentation (PanOoS), achieving OoS for panoramas. Furthermore, we propose the first solution, POS, which adapts to the characteristics of panoramic images through text-guided prompt distribution learning. Specifically, POS integrates a disentanglement strategy designed to materialize the cross-domain generalization capability of CLIP. The proposed Prompt-based Restoration Attention (PRA) optimizes semantic decoding by prompt guidance and self-adaptive correction, while Bilevel Prompt Distribution Learning (BPDL) refines the manifold of per-pixel mask embeddings via semantic prototype supervision. Besides, to compensate for the scarcity of PanOoS datasets, we establish two benchmarks: DenseOoS, which features diverse outliers in complex environments, and QuadOoS, captured by a quadruped robot with a panoramic annular lens system. Extensive experiments demonstrate superior performance of POS, with AuPRC improving by 34.25% and FPR95 decreasing by 21.42% on DenseOoS, outperforming state-of-the-art pinhole-OoS methods. Moreover, POS achieves leading closed-set segmentation capabilities. Code and datasets will be available at this https URL.

Paper number 55:
Title: Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and Low-Visibility Conditions
Authors: Lukas Schichler, Karin Festl, Selim Solmaz, Daniel Watzenig
Abstract: Despite significant progress in autonomous navigation, a critical gap remains in ensuring reliable localization in hazardous environments such as tunnels, urban disaster zones, and underground structures. Tunnels present a uniquely difficult scenario: they are not only prone to GNSS signal loss, but also provide little features for visual localization due to their repetitive walls and poor lighting. These conditions degrade conventional vision-based and LiDAR-based systems, which rely on distinguishable environmental features. To address this, we propose a novel sensor fusion framework that integrates a thermal camera with a LiDAR to enable robust localization in tunnels and other perceptually degraded environments. The thermal camera provides resilience in low-light or smoke conditions, while the LiDAR delivers precise depth perception and structural awareness. By combining these sensors, our framework ensures continuous and accurate localization across diverse and dynamic environments. We use an Extended Kalman Filter (EKF) to fuse multi-sensor inputs, and leverages visual odometry and SLAM (Simultaneous Localization and Mapping) techniques to process the sensor data, enabling robust motion estimation and mapping even in GNSS-denied environments. This fusion of sensor modalities not only enhances system resilience but also provides a scalable solution for cyber-physical systems in connected and autonomous vehicles (CAVs). To validate the framework, we conduct tests in a tunnel environment, simulating sensor degradation and visibility challenges. The results demonstrate that our method sustains accurate localization where standard approaches deteriorate due to the tunnels featureless geometry. The frameworks versatility makes it a promising solution for autonomous vehicles, inspection robots, and other cyber-physical systems operating in constrained, perceptually poor environments.

Paper number 56:
Title: Physics-Informed Sylvester Normalizing Flows for Bayesian Inference in Magnetic Resonance Spectroscopy
Authors: Julian P. Merkofer, Dennis M. J. van de Sande, Alex A. Bhogal, Ruud J. G. van Sloun
Abstract: Magnetic resonance spectroscopy (MRS) is a non-invasive technique to measure the metabolic composition of tissues, offering valuable insights into neurological disorders, tumor detection, and other metabolic dysfunctions. However, accurate metabolite quantification is hindered by challenges such as spectral overlap, low signal-to-noise ratio, and various artifacts. Traditional methods like linear-combination modeling are susceptible to ambiguities and commonly only provide a theoretical lower bound on estimation accuracy in the form of the CramÃ©r-Rao bound. This work introduces a Bayesian inference framework using Sylvester normalizing flows (SNFs) to approximate posterior distributions over metabolite concentrations, enhancing quantification reliability. A physics-based decoder incorporates prior knowledge of MRS signal formation, ensuring realistic distribution representations. We validate the method on simulated 7T proton MRS data, demonstrating accurate metabolite quantification, well-calibrated uncertainties, and insights into parameter correlations and multi-modal distributions.

Paper number 57:
Title: BURNS: Backward Underapproximate Reachability for Neural-Feedback-Loop Systems
Authors: Chelsea Sidrane, Jana Tumova
Abstract: Learning-enabled planning and control algorithms are increasingly popular, but they often lack rigorous guarantees of performance or safety. We introduce an algorithm for computing underapproximate backward reachable sets of nonlinear discrete time neural feedback loops. We then use the backward reachable sets to check goal-reaching properties. Our algorithm is based on overapproximating the system dynamics function to enable computation of underapproximate backward reachable sets through solutions of mixed-integer linear programs. We rigorously analyze the soundness of our algorithm and demonstrate it on a numerical example. Our work expands the class of properties that can be verified for learning-enabled systems.

Paper number 58:
Title: Frenet Corridor Planner: An Optimal Local Path Planning Framework for Autonomous Driving
Authors: Faizan M. Tariq, Zheng-Hang Yeh, Avinash Singh, David Isele, Sangjae Bae
Abstract: Motivated by the requirements for effectiveness and efficiency, path-speed decomposition-based trajectory planning methods have widely been adopted for autonomous driving applications. While a global route can be pre-computed offline, real-time generation of adaptive local paths remains crucial. Therefore, we present the Frenet Corridor Planner (FCP), an optimization-based local path planning strategy for autonomous driving that ensures smooth and safe navigation around obstacles. Modeling the vehicles as safety-augmented bounding boxes and pedestrians as convex hulls in the Frenet space, our approach defines a drivable corridor by determining the appropriate deviation side for static obstacles. Thereafter, a modified space-domain bicycle kinematics model enables path optimization for smoothness, boundary clearance, and dynamic obstacle risk minimization. The optimized path is then passed to a speed planner to generate the final trajectory. We validate FCP through extensive simulations and real-world hardware experiments, demonstrating its efficiency and effectiveness.

Paper number 59:
Title: Policy Gradient Adaptive Control for the LQR: Indirect and Direct Approaches
Authors: Feiran Zhao, Alessandro Chiuso, Florian DÃ¶rfler
Abstract: Motivated by recent advances of reinforcement learning and direct data-driven control, we propose policy gradient adaptive control (PGAC) for the linear quadratic regulator (LQR), which uses online closed-loop data to improve the control policy while maintaining stability. Our method adaptively updates the policy in feedback by descending the gradient of the LQR cost and is categorized as indirect, when gradients are computed via an estimated model, versus direct, when gradients are derived from data using sample covariance parameterization. Beyond the vanilla gradient, we also showcase the merits of the natural gradient and Gauss-Newton methods for the policy update. Notably, natural gradient descent bridges the indirect and direct PGAC, and the Gauss-Newton method of the indirect PGAC leads to an adaptive version of the celebrated Hewer's algorithm. To account for the uncertainty from noise, we propose a regularization method for both indirect and direct PGAC. For all the considered PGAC approaches, we show closed-loop stability and convergence of the policy to the optimal LQR gain. Simulations validate our theoretical findings and demonstrate the robustness and computational efficiency of PGAC.

Paper number 60:
Title: Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach
Authors: Jingwang Li, Vincent Lau
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms for solving this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, linear convergence is established under additional assumptions. By employing specialized saddle-point subproblem solvers, iD2A and MiD2A attain significantly lower communication and computational complexities than existing algorithms across various scenarios. Finally, we conduct several numerical experiments to validate our theoretical results and to showcase the superior performance of iD2A and MiD2A in practice.

Paper number 61:
Title: Quantifying the Aggregate Flexibility of Electric Vehicle Charging Stations for Market-based Congestion Management Services
Authors: Nanda Kishor Panda, Simon H. Tindemans
Abstract: Electric vehicles (EVs) play a crucial role in the transition towards sustainable modes of transportation and thus are critical to the energy transition. As their number grows, managing the aggregate power of EV charging is crucial to maintain grid stability and mitigate congestion. This study analyses more than 500 thousand real charging transactions in the Netherlands to explore the challenge and opportunity for the energy system presented by EV growth and smart charging flexibility. Specifically, it analyses the collective ability to provide congestion management services according to the specifications of those services in the Netherlands. In this study, a data-driven model of charging behaviour is created to explore the implications of delivering dependable congestion management services at various aggregation levels and types of service. The probabilistic ability to offer different flexibility products, namely, redispatch and capacity limitation, for congestion management, is assessed for different categories of charging stations (CS) and dispatch strategies. These probabilities can help EV aggregators, such as charging point operators, make informed decisions about offering congestion mitigation products per relevant regulations and distribution system operators to assess their potential. Further, it is shown how machine learning models can be incorporated to predict the day-ahead consumption, followed by operationally predicting redispatch flexibility. The findings demonstrate that the timing of EV arrivals, departures, and connections plays a crucial role in determining the feasibility of product offerings, and dependable services can generally be delivered using a sufficiently large number of CSs.

Paper number 62:
Title: Task-Oriented Mulsemedia Communication using Unified Perceiver and Conformal Prediction in 6G Wireless Systems
Authors: Hongzhi Guo, Ian F. Akyildiz
Abstract: The growing prominence of eXtended Reality (XR), holographic-type communications, and metaverse demands truly immersive user experiences by using many sensory modalities, including sight, hearing, touch, smell, taste, etc. Additionally, the widespread deployment of sensors in areas such as agriculture, manufacturing, and smart homes is generating diverse sensory data. A new media format known as multisensory media (mulsemedia) has emerged, which incorporates many sensory modalities beyond the traditional visual and auditory media. 6G wireless systems are envisioned to support the Internet of Senses, making it crucial to explore effective data fusion and communication strategies for mulsemedia. In this paper, we introduce a task-oriented multi-task mulsemedia communication system named MuSeCo, which is developed using unified Perceiver models and Conformal Prediction. This unified model can accept any sensory input and efficiently extract latent semantic features, making it adaptable for deployment across various Artificial Intelligence of Things (AIoT) devices. Conformal Prediction is employed for modality selection and combination, enhancing task accuracy while minimizing data communication overhead. The model is trained using six sensory modalities across four classification tasks. Simulations and experiments demonstrate that it can effectively fuse sensory modalities, significantly reduce end-to-end communication latency and energy consumption, and maintain high accuracy in communication-constrained systems.

Paper number 63:
Title: TTT: A Temporal Refinement Heuristic for Tenuously Tractable Discrete Time Reachability Problems
Authors: Chelsea Sidrane, Jana Tumova
Abstract: Reachable set computation is an important tool for analyzing control systems. Simulating a control system can show general trends, but a formal tool like reachability analysis can provide guarantees of correctness. Reachability analysis for complex control systems, e.g., with nonlinear dynamics and/or a neural network controller, is often either slow or overly conservative. To address these challenges, much literature has focused on spatial refinement, i.e., tuning the discretization of the input sets and intermediate reachable sets. This paper introduces the idea of temporal refinement: automatically choosing when along the horizon of the reachability problem to execute slow symbolic queries which incur less approximation error versus fast concrete queries which incur more approximation error. Temporal refinement can be combined with other refinement approaches as an additional tool to trade off tractability and tightness in approximate reachable set computation. We introduce a temporal refinement algorithm and demonstrate its effectiveness at computing approximate reachable sets for nonlinear systems with neural network controllers. We calculate reachable sets with varying computational budget and show that our algorithm can generate approximate reachable sets with a similar amount of error to the baseline in 20-70% less time.

Paper number 64:
Title: The statistical spread of transmission outages on a fast protection time scale based on utility data
Authors: Ian Dobson, D. Adrian Maldonado, Mihai Anitescu
Abstract: When there is a fault, the protection system automatically removes one or more transmission lines on a fast time scale of less than one minute. The outaged lines form a pattern in the transmission network. We extract these patterns from utility outage data, determine some key statistics of these patterns, and then show how to generate new patterns consistent with these statistics. The generated patterns provide a new and easily feasible way to model the overall effect of the protection system at the scale of a large transmission system. This new generative modeling of protection is expected to contribute to simulations of disturbances in large grids so that they can better quantify the risk of blackouts. Analysis of the pattern sizes suggests an index that describes how much outages spread in the transmission network at the fast timescale.

Paper number 65:
Title: radarODE: An ODE-Embedded Deep Learning Model for Contactless ECG Reconstruction from Millimeter-Wave Radar
Authors: Yuanyuan Zhang, Runwei Guan, Lingxiao Li, Rui Yang, Yutao Yue, Eng Gee Lim
Abstract: Radar-based contactless cardiac monitoring has become a popular research direction recently, but the fine-grained electrocardiogram (ECG) signal is still hard to reconstruct from millimeter-wave radar signal. The key obstacle is to decouple the cardiac activities in the electrical domain (i.e., ECG) from that in the mechanical domain (i.e., heartbeat), and most existing research only uses pure data-driven methods to map such domain transformation as a black box. Therefore, this work first proposes a signal model for domain transformation, and then a novel deep learning framework called radarODE is designed to fuse the temporal and morphological features extracted from radar signals and generate ECG. In addition, ordinary differential equations are embedded in radarODE as a decoder to provide morphological prior, helping the convergence of the model training and improving the robustness under body movements. After being validated on the dataset, the proposed radarODE achieves better performance compared with the benchmark in terms of missed detection rate, root mean square error, Pearson correlation coefficient with the improvement of 9%, 16% and 19%, respectively. The validation results imply that radarODE is capable of recovering ECG signals from radar signals with high fidelity and can be potentially implemented in real-life scenarios.

Paper number 66:
Title: Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records
Authors: Daeun Kyung, Junu Kim, Tackeun Kim, Edward Choi
Abstract: Chest X-ray (CXR) is an important diagnostic tool widely used in hospitals to assess patient conditions and monitor changes over time. Recently, generative models, specifically diffusion-based models, have shown promise in generating realistic synthetic CXRs. However, these models mainly focus on conditional generation using single-time-point data, i.e., generating CXRs conditioned on their corresponding reports from a specific time. This limits their clinical utility, particularly for capturing temporal changes. To address this limitation, we propose a novel framework, EHRXDiff, which predicts future CXR images by integrating previous CXRs with subsequent medical events, e.g., prescriptions, lab measures, etc. Our framework dynamically tracks and predicts disease progression based on a latent diffusion model, conditioned on the previous CXR image and a history of medical events. We comprehensively evaluate the performance of our framework across three key aspects, including clinical consistency, demographic consistency, and visual realism. Results show that our framework generates high-quality, realistic future images that effectively capture potential temporal changes. This suggests that our framework could be further developed to support clinical decision-making and provide valuable insights for patient monitoring and treatment planning in the medical field. The code is available at this https URL.

Paper number 67:
Title: radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction
Authors: Yuanyuan Zhang, Rui Yang, Yutao Yue, Eng Gee Lim
Abstract: Millimeter-wave radar is promising to provide robust and accurate vital sign monitoring in an unobtrusive manner. However, the radar signal might be distorted in propagation by ambient noise or random body movement, ruining the subtle cardiac activities and destroying the vital sign recovery. In particular, the recovery of electrocardiogram (ECG) signal heavily relies on the deep-learning model and is sensitive to noise. Therefore, this work creatively deconstructs the radar-based ECG recovery into three individual tasks and proposes a multi-task learning (MTL) framework, radarODE-MTL, to increase the robustness against consistent and abrupt noises. In addition, to alleviate the potential conflicts in optimizing individual tasks, a novel multi-task optimization strategy, eccentric gradient alignment (EGA), is proposed to dynamically trim the task-specific gradients based on task difficulties in orthogonal space. The proposed radarODE-MTL with EGA is evaluated on the public dataset with prominent improvements in accuracy, and the performance remains consistent under noises. The experimental results indicate that radarODE-MTL could reconstruct accurate ECG signals robustly from radar signals and imply the application prospect in real-life situations. The code is available at: this http URL.

Paper number 68:
Title: OSMamba: Omnidirectional Spectral Mamba with Dual-Domain Prior Generator for Exposure Correction
Authors: Gehui Li, Bin Chen, Chen Zhao, Lei Zhang, Jian Zhang
Abstract: Exposure correction is a fundamental problem in computer vision and image processing. Recently, frequency domain-based methods have achieved impressive improvement, yet they still struggle with complex real-world scenarios under extreme exposure conditions. This is due to the local convolutional receptive fields failing to model long-range dependencies in the spectrum, and the non-generative learning paradigm being inadequate for retrieving lost details from severely degraded regions. In this paper, we propose Omnidirectional Spectral Mamba (OSMamba), a novel exposure correction network that incorporates the advantages of state space models and generative diffusion models to address these limitations. Specifically, OSMamba introduces an omnidirectional spectral scanning mechanism that adapts Mamba to the frequency domain to capture comprehensive long-range dependencies in both the amplitude and phase spectra of deep image features, hence enhancing illumination correction and structure recovery. Furthermore, we develop a dual-domain prior generator that learns from well-exposed images to generate a degradation-free diffusion prior containing correct information about severely under- and over-exposed regions for better detail restoration. Extensive experiments on multiple-exposure and mixed-exposure datasets demonstrate that the proposed OSMamba achieves state-of-the-art performance both quantitatively and qualitatively.

Paper number 69:
Title: FedSynthCT-Brain: A Federated Learning Framework for Multi-Institutional Brain MRI-to-CT Synthesis
Authors: Ciro Benito Raggio, Mathias Krohmer Zabaleta, Nils Skupien, Oliver Blanck, Francesco Cicone, Giuseppe Lucio Cascini, Paolo Zaffino, Lucia Migliorelli, Maria Francesca Spadea
Abstract: The generation of Synthetic Computed Tomography (sCT) images has become a pivotal methodology in modern clinical practice, particularly in the context of Radiotherapy (RT) treatment planning. The use of sCT enables the calculation of doses, pushing towards Magnetic Resonance Imaging (MRI) guided radiotherapy treatments. Deep learning methods for MRI-to-sCT have shown promising results, but their reliance on single-centre training dataset limits generalisation capabilities to diverse clinical settings. Moreover, creating centralised multi-centre datasets may pose privacy concerns. To address the aforementioned issues, we introduced FedSynthCT-Brain, an approach based on the Federated Learning (FL) paradigm for MRI-to-sCT in brain imaging. This is among the first applications of FL for MRI-to-sCT, employing a cross-silo horizontal FL approach that allows multiple centres to collaboratively train a U-Net-based deep learning model. We validated our method using real multicentre data from four European and American centres, simulating heterogeneous scanner types and acquisition modalities, and tested its performance on an independent dataset from a centre outside the federation. In the case of the unseen centre, the federated model achieved a median Mean Absolute Error (MAE) of $102.0$ HU across 23 patients, with an interquartile range of $96.7-110.5$ HU. The median (interquartile range) for the Structural Similarity Index (SSIM) and the Peak Signal to Noise Ratio (PNSR) were $0.89 (0.86-0.89)$ and $26.58 (25.52-27.42)$, respectively. The analysis of the results showed acceptable performances of the federated approach, thus highlighting the potential of FL to enhance MRI-to-sCT to improve generalisability and advancing safe and equitable clinical applications while fostering collaboration and preserving data privacy.

Paper number 70:
Title: Linear Model of Aggregated Homogeneous Energy Storage Elements with Realizable Dispatch Guarantees
Authors: Mazen Elsaadany, Mads R. Almassalkhi, Simon H. Tindemans
Abstract: To optimize the dispatch of batteries, a model is required that can predict the state of charge (SOC) trajectory for a chosen open-loop power schedule to ensure admissibility (i.e., that schedule can be realized). However, battery dispatch optimization is inherently challenging since batteries cannot simultaneously charge and discharge, which begets a non-convex complementarity constraint. In this paper, we develop a novel composition of energy storage elements that can charge or discharge independently and provide a sufficient linear energy storage model of the composite battery. This permits convex optimization of the composite battery SOC trajectory while guaranteeing admissibility of the resulting (aggregated) power schedule and its disaggregation to the individual energy storage elements.

Paper number 71:
Title: Multi-channel Replay Speech Detection using an Adaptive Learnable Beamformer
Authors: Michael Neri, Tuomas Virtanen
Abstract: Replay attacks belong to the class of severe threats against voice-controlled systems, exploiting the easy accessibility of speech signals by recorded and replayed speech to grant unauthorized access to sensitive data. In this work, we propose a multi-channel neural network architecture called M-ALRAD for the detection of replay attacks based on spatial audio features. This approach integrates a learnable adaptive beamformer with a convolutional recurrent neural network, allowing for joint optimization of spatial filtering and classification. Experiments have been carried out on the ReMASC dataset, which is a state-of-the-art multi-channel replay speech detection dataset encompassing four microphones with diverse array configurations and four environments. Results on the ReMASC dataset show the superiority of the approach compared to the state-of-the-art and yield substantial improvements for challenging acoustic environments. In addition, we demonstrate that our approach is able to better generalize to unseen environments with respect to prior studies.

Paper number 72:
Title: Liver Cirrhosis Stage Estimation from MRI with Deep Learning
Authors: Jun Zeng, Debesh Jha, Ertugrul Aktas, Elif Keles, Alpay Medetalibeyoglu, Matthew Antalek, Amir A. Borhani, Daniela P. Ladner, Gorkem Durak, Ulas Bagci
Abstract: We present an end-to-end deep learning framework for automated liver cirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe scarring (fibrosis) of the liver and a common endpoint of various chronic liver diseases. Early diagnosis is vital to prevent complications such as decompensation and cancer, which significantly decreases life expectancy. However, diagnosing cirrhosis in its early stages is challenging, and patients often present with life-threatening complications. Our approach integrates multi-scale feature learning with sequence-specific attention mechanisms to capture subtle tissue variations across cirrhosis progression stages. Using CirrMRI600+, a large-scale publicly available dataset of 628 high-resolution MRI scans from 339 patients, we demonstrate state-of-the-art performance in three-stage cirrhosis classification. Our best model achieves 72.8% accuracy on T1W and 63.8% on T2W sequences, significantly outperforming traditional radiomics-based approaches. Through extensive ablation studies, we show that our architecture effectively learns stage-specific imaging biomarkers. We establish new benchmarks for automated cirrhosis staging and provide insights for developing clinically applicable deep learning systems. The source code will be available at this https URL.

Paper number 73:
Title: Heart Failure Prediction using Modal Decomposition and Masked Autoencoders for Scarce Echocardiography Databases
Authors: AndrÃ©s Bell-Navas, MarÃ­a Villalba-Orero, Enrique Lara-Pezzi, JesÃºs Garicano-Mena, Soledad Le Clainche
Abstract: Heart diseases constitute the main cause of international human defunction. According to the World Health Organization (WHO), approximately 18 million deaths happen each year due to precisely heart diseases. In particular, heart failures (HF) press the healthcare industry to develop systems for their early, rapid, and effective prediction. This work presents an automatic system based on a novel deep learning framework which analyses in real-time echocardiography video sequences for the challenging and more specific task of heart failure time prediction. This system works in two stages. The first one transforms the data from a database of echocardiography video sequences into a machine learning-compatible collection of annotated images which can be used in the training phase of any machine learning-based framework, including a deep learning-based one. This stage includes the use of the Higher Order Dynamic Mode Decomposition (HODMD) algorithm for both data augmentation and feature extraction. The second stage builds and trains a Vision Transformer (ViT). Self-supervised learning (SSL) methods, so far barely explored in the literature about heart failure prediction, are adopted to effectively train the ViT from scratch, even with scarce databases. The designed neural network analyses images from echocardiography sequences to estimate the time in which a heart failure will happen. The results obtained show the efficacy of the HODMD algorithm and the superiority of the proposed system with respect to several established ViT and Convolutional Neural Network (CNN) architectures. The source code will be incorporated into the next version release of the ModelFLOWs-app software (this https URL).

Paper number 74:
Title: Light Weight CNN for classification of Brain Tumors from MRI Images
Authors: Natnael Alemayehu
Abstract: This study presents a convolutional neural network (CNN)-based approach for the multi-class classification of brain tumors using magnetic resonance imaging (MRI) scans. We utilize a publicly available dataset containing MRI images categorized into four classes: glioma, meningioma, pituitary tumor, and no tumor. Our primary objective is to build a light weight deep learning model that can automatically classify brain tumor types with high accuracy. To achieve this goal, we incorporate image preprocessing steps, including normalization, data augmentation, and a cropping technique designed to reduce background noise and emphasize relevant regions. The CNN architecture is optimized through hyperparameter tuning using Keras Tuner, enabling systematic exploration of network parameters. To ensure reliable evaluation, we apply 5-fold cross-validation, where each hyperparameter configuration is evaluated across multiple data splits to mitigate overfitting. Experimental results demonstrate that the proposed model achieves a classification accuracy of 98.78%, indicating its potential as a diagnostic aid in clinical settings. The proposed method offers a low-complexity yet effective solution for assisting in early brain tumor diagnosis.

Paper number 75:
Title: A Decision-Focused Predict-then-Bid Framework for Strategic Energy Storage
Authors: Ming Yi, Yiqian Wu, Saud Alghumayjan, James Anderson, Bolun Xu
Abstract: This paper introduces a novel decision-focused framework for energy storage arbitrage bidding. Inspired by the bidding process for energy storage in electricity markets, we propose a predict-then-bid end-to-end method incorporating the storage arbitrage optimization and market clearing models. This is achieved through a tri-layer framework that combines a price prediction layer with a two-stage optimization problem: an energy storage optimization layer and a market-clearing optimization layer. We leverage the implicit function theorem for gradient computation in the first optimization layer and incorporate a perturbation-based approach into the decision-focused loss function to ensure differentiability in the market-clearing layer. Numerical experiments using electricity market data from New York demonstrate that our bidding design substantially outperforms existing methods, achieving the highest profits and showcasing the effectiveness of the proposed approach.

Paper number 76:
Title: Adversarial Robustness of Deep Learning Models for Inland Water Body Segmentation from SAR Images
Authors: Siddharth Kothari, Srinivasan Murali, Sankalp Kothari, Ujjwal Verma, Jaya Sreevalsan-Nair
Abstract: Inland water body segmentation from Synthetic Aperture Radar (SAR) images is an important task needed for several applications, such as flood mapping. While SAR sensors capture data in all-weather conditions as high-resolution images, differentiating water and water-like surfaces from SAR images is not straightforward. Inland water bodies, such as large river basins, have complex geometry, which adds to the challenge of segmentation. U-Net is a widely used deep learning model for land-water segmentation of SAR images. In practice, manual annotation is often used to generate the corresponding water masks as ground truth. Manual annotation of the images is prone to label noise owing to data poisoning attacks, especially due to complex geometry. In this work, we simulate manual errors in the form of adversarial attacks on the U-Net model and study the robustness of the model to human errors in annotation. Our results indicate that U-Net can tolerate a certain level of corruption before its performance drops significantly. This finding highlights the crucial role that the quality of manual annotations plays in determining the effectiveness of the segmentation model. The code and the new dataset, along with adversarial examples for robust training, are publicly available. (GitHub link - this https URL)

Paper number 77:
Title: Regression is all you need for medical image translation
Authors: Sebastian Rassmann, David KÃ¼gler, Christian Ewert, Martin Reuter
Abstract: The acquisition of information-rich images within a limited time budget is crucial in medical imaging. Medical image translation (MIT) can help enhance and supplement existing datasets by generating synthetic images from acquired data. While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have achieved remarkable success in natural image generation, their benefits - creativity and image realism - do not necessarily transfer to medical applications where highly accurate anatomical information is required. In fact, the imitation of acquisition noise or content hallucination hinder clinical utility. Here, we introduce YODA (You Only Denoise once - or Average), a novel 2.5D diffusion-based framework for volumetric MIT. YODA unites diffusion and regression paradigms to produce realistic or noise-free outputs. Furthermore, we propose Expectation-Approximation (ExpA) DM sampling, which draws inspiration from MRI signal averaging. ExpA-sampling suppresses generated noise and, thus, eliminates noise from biasing the evaluation of image quality. Through extensive experiments on four diverse multi-modal datasets - comprising multi-contrast brain MRI and pelvic MRI-CT - we show that diffusion and regression sampling yield similar results in practice. As such, the computational overhead of diffusion sampling does not provide systematic benefits in medical information translation. Building on these insights, we demonstrate that YODA outperforms several state-of-the-art GAN and DM methods. Notably, YODA-generated images are shown to be interchangeable with, or even superior to, physical acquisitions for several downstream tasks. Our findings challenge the presumed advantages of DMs in MIT and pave the way for the practical application of MIT in medical imaging.

Paper number 78:
Title: Characterizing Trust and Resilience in Distributed Consensus for Cyberphysical Systems
Authors: Michal Yemini, Angelia NediÄ, Andrea Goldsmith, Stephanie Gil
Abstract: This work considers the problem of resilient consensus where stochastic values of trust between agents are available. Specifically, we derive a unified mathematical framework to characterize convergence, deviation of the consensus from the true consensus value, and expected convergence rate, when there exists additional information of trust between agents. We show that under certain conditions on the stochastic trust values and consensus protocol: 1) almost sure convergence to a common limit value is possible even when malicious agents constitute more than half of the network connectivity, 2) the deviation of the converged limit, from the case where there is no attack, i.e., the true consensus value, can be bounded with probability that approaches 1 exponentially, and 3) correct classification of malicious and legitimate agents can be attained in finite time almost surely. Further, the expected convergence rate decays exponentially as a function of the quality of the trust observations between agents.

Paper number 79:
Title: Infrared Image Deturbulence Restoration Using Degradation Parameter-Assisted Wide & Deep Learning
Authors: Yi Lu, Yadong Wang, Xingbo Jiang, Xiangzhi Bai
Abstract: Infrared images captured under turbulent conditions are degraded by complex geometric distortions and blur. We address infrared deturbulence as an image restoration task, proposing DparNet, a parameter-assisted multi-frame network with a wide & deep architecture. DparNet learns a degradation prior (key parameter matrix) directly from degraded images without external knowledge. Its wide & deep architecture uses these learned parameters to directly modulate restoration, achieving spatially and intensity adaptive results. Evaluated on dedicated infrared deturbulence (49,744 images) and visible image denoising (109,536 images) datasets, DparNet significantly outperforms State-of-the-Art (SOTA) methods in restoration performance and efficiency. Notably, leveraging these parameters improves PSNR by 0.6-1.1 dB with less than 2% increase in model parameters and computational complexity. Our work demonstrates that degraded images hide key degradation information that can be learned and utilized to boost adaptive image restoration.

Paper number 80:
Title: Imitation-regularized Optimal Transport on Networks: Provable Robustness and Application to Logistics Planning
Authors: Koshi Oishi, Yota Hashizume, Tomohiko Jimbo, Hirotaka Kaji, Kenji Kashima
Abstract: Transport systems on networks are crucial in various applications, but face a significant risk of being adversely affected by unforeseen circumstances such as disasters. The application of entropy-regularized optimal transport (OT) on graph structures has been investigated to enhance the robustness of transport on such networks. In this study, we propose an imitation-regularized OT (I-OT) that mathematically incorporates prior knowledge into the robustness of OT. This method is expected to enhance interpretability by integrating human insights into robustness and to accelerate practical applications. Furthermore, we mathematically verify the robustness of I-OT and discuss how these robustness properties relate to real-world applications. The effectiveness of this method is validated through a logistics simulation using automotive parts data.

Paper number 81:
Title: Sensor-Based Distributionally Robust Control for Safe Robot Navigation in Dynamic Environments
Authors: Kehan Long, Yinzhuang Yi, Zhirui Dai, Sylvia Herbert, Jorge CortÃ©s, Nikolay Atanasov
Abstract: We introduce a novel method for mobile robot navigation in dynamic, unknown environments, leveraging onboard sensing and distributionally robust optimization to impose probabilistic safety constraints. Our method introduces a distributionally robust control barrier function (DR-CBF) that directly integrates noisy sensor measurements and state estimates to define safety constraints. This approach is applicable to a wide range of control-affine dynamics, generalizable to robots with complex geometries, and capable of operating at real-time control frequencies. Coupled with a control Lyapunov function (CLF) for path following, the proposed CLF-DR-CBF control synthesis method achieves safe, robust, and efficient navigation in challenging environments. We demonstrate the effectiveness and robustness of our approach for safe autonomous navigation under uncertainty in simulations and real-world experiments with differential-drive robots.

Paper number 82:
Title: AudioBench: A Universal Benchmark for Audio Large Language Models
Authors: Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen
Abstract: We introduce AudioBench, a universal benchmark designed to evaluate Audio Large Language Models (AudioLLMs). It encompasses 8 distinct tasks and 26 datasets, among which, 7 are newly proposed datasets. The evaluation targets three main aspects: speech understanding, audio scene understanding, and voice understanding (paralinguistic). Despite recent advancements, there lacks a comprehensive benchmark for AudioLLMs on instruction following capabilities conditioned on audio signals. AudioBench addresses this gap by setting up datasets as well as desired evaluation metrics. Besides, we also evaluated the capabilities of five popular models and found that no single model excels consistently across all tasks. We outline the research outlook for AudioLLMs and anticipate that our open-sourced evaluation toolkit, data, and leaderboard will offer a robust testbed for future model developments.

Paper number 83:
Title: CardioSyntax: end-to-end SYNTAX score prediction -- dataset, benchmark and method
Authors: Alexander Ponomarchuk, Ivan Kruzhilov, Galina Zubkova, Artem Shadrin, Ruslan Utegenov, Ivan Bessonov, Pavel Blinov
Abstract: The SYNTAX score has become a widely used measure of coronary disease severity, crucial in selecting the optimal mode of the revascularization procedure. This paper introduces a new medical regression and classification problem - automatically estimating SYNTAX score from coronary angiography. Our study presents a comprehensive CardioSYNTAX dataset of 3,018 patients for the SYNTAX score estimation and coronary dominance classification. The dataset features a balanced distribution of individuals with zero and non-zero scores. This dataset includes a first-of-its-kind, complete coronary angiography samples captured through a multi-view X-ray video, allowing one to observe coronary arteries from multiple perspectives. Furthermore, we present a novel, fully automatic end-to-end method for estimating the SYNTAX. For such a difficult task, we have achieved a solid coefficient of determination R2 of 0.51 in score value prediction and 77.3% accuracy for zero score classification.

Paper number 84:
Title: AI-Aided Kalman Filters
Authors: Nir Shlezinger, Guy Revach, Anubhab Ghosh, Saikat Chatterjee, Shuo Tang, Tales Imbiriba, Jindrich Dunik, Ondrej Straka, Pau Closas, Yonina C. Eldar
Abstract: The Kalman filter (KF) and its variants are among the most celebrated algorithms in signal processing. These methods are used for state estimation of dynamic systems by relying on mathematical representations in the form of simple state-space (SS) models, which may be crude and inaccurate descriptions of the underlying dynamics. Emerging data-centric artificial intelligence (AI) techniques tackle these tasks using deep neural networks (DNNs), which are model-agnostic. Recent developments illustrate the possibility of fusing DNNs with classic Kalman-type filtering, obtaining systems that learn to track in partially known dynamics. This article provides a tutorial-style overview of design approaches for incorporating AI in aiding KF-type algorithms. We review both generic and dedicated DNN architectures suitable for state estimation, and provide a systematic presentation of techniques for fusing AI tools with KFs and for leveraging partial SS modeling and data, categorizing design approaches into task-oriented and SS model-oriented. The usefulness of each approach in preserving the individual strengths of model-based KFs and data-driven DNNs is investigated in a qualitative and quantitative study, whose code is publicly available, illustrating the gains of hybrid model-based/data-driven designs. We also discuss existing challenges and future research directions that arise from fusing AI and Kalman-type algorithms.

Paper number 85:
Title: Polarization under the Channel Noise with Memory
Authors: Tianfu Qi, Jun Wang
Abstract: This paper presents a comprehensive study of channel polarization under noise with memory. By introducing a genie-aided channel model, we demonstrate that polarized subchannels still converge to extremal channels under the standard polar coding structure. Notably, the proportion of near-perfect subchannels can exceed the underlying channel capacity $I(W)$. However, we also show that the polarization rate is slower than that observed in the binary-input memoryless channel (BMC) scenario. In particular, the block error probability is upper-bounded by $\mathcal{O}(L^{-c_0})$, where $L$ denotes the block length and $c_0$ is a positive constant. Moreover, we investigate both upper and lower bounds on the gap between the channel capacity and the cutoff rate under finite block length, which offers greater relevance for practical implementations.

Paper number 86:
Title: A Quantitative Evaluation of Approximate Softmax Functions for Deep Neural Networks
Authors: Anthony Leiva-Valverde, Fabricio Elizondo-FernÃ¡ndez, Luis G. LeÃ³n-Vega, Cristina Meinhardt, Jorge Castro-GodÃ­nez
Abstract: The softmax function is a widely used activation function in the output layers of neural networks, responsible for converting raw scores into class probabilities while introducing essential non-linearity. Implementing Softmax efficiently poses challenges on low-end FPGAs due to limited hardware resources and the computational complexity of exponential and division operations. This work evaluates approximate computing techniques for softmax acceleration using Taylor series and interpolation methods using Look-Up Tables (LUTs). These approximations aim to reduce execution time and resource consumption while maintaining acceptable levels of numerical precision. Our findings show that quadratic interpolation with LUTs yields the lowest numerical error. In contrast, Taylor-based approximations offer significantly better performance in terms of execution time and resource efficiency due to their computational simplicity. When applied to real-world deep learning models such as LeNet-5 and MobileNet v2, the first- and second-order Taylor approximations provided substantial trade-offs between accuracy and resource savings, achieving up to 0.2% accuracy degradation and 14% resource reduction compared to exact implementations. These results highlight the effectiveness of approximate Softmax designs on resource-constrained FPGAs and lay the groundwork for their integration into larger models, including large language models (LLMs).

Paper number 87:
Title: Applications of Artificial Intelligence for Cross-language Intelligibility Assessment of Dysarthric Speech
Authors: Eunjung Yeo, Julie Liss, Visar Berisha, David Mortensen
Abstract: Purpose: Speech intelligibility is a critical outcome in the assessment and management of dysarthria, yet most research and clinical practices have focused on English, limiting their applicability across languages. This commentary introduces a conceptual framework--and a demonstration of how it can be implemented--leveraging artificial intelligence (AI) to advance cross-language intelligibility assessment of dysarthric speech. Method: We propose a two-tiered conceptual framework consisting of a universal speech model that encodes dysarthric speech into acoustic-phonetic representations, followed by a language-specific intelligibility assessment model that interprets these representations within the phonological or prosodic structures of the target language. We further identify barriers to cross-language intelligibility assessment of dysarthric speech, including data scarcity, annotation complexity, and limited linguistic insights into dysarthric speech, and outline potential AI-driven solutions to overcome these challenges. Conclusion: Advancing cross-language intelligibility assessment of dysarthric speech necessitates models that are both efficient and scalable, yet constrained by linguistic rules to ensure accurate and language-sensitive assessment. Recent advances in AI provide the foundational tools to support this integration, shaping future directions toward generalizable and linguistically informed assessment frameworks.

Paper number 88:
Title: Reward-Based Collision-Free Algorithm for Trajectory Planning of Autonomous Robots
Authors: Jose D. Hoyos, Tianyu Zhou, Zehui Lu, Shaoshuai Mou
Abstract: This paper proposes a novel mission planning algorithm for autonomous robots that selects an optimal waypoint sequence from a predefined set to maximize total reward while satisfying obstacle avoidance, state, input, derivative, mission time, and distance constraints. The formulation extends the prize-collecting traveling salesman problem. A tailored genetic algorithm evolves candidate solutions using a fitness function, crossover, and mutation, with constraint enforcement via a penalty method. Differential flatness and clothoid curves are employed to penalize infeasible trajectories efficiently, while the Euler spiral method ensures curvature-continuous trajectories with bounded curvature, enhancing dynamic feasibility and mitigating oscillations typical of minimum-jerk and snap parameterizations. Due to the discrete variable length optimization space, crossover is performed using a dynamic time-warping-based method and extended convex combination with projection. The algorithm's performance is validated through simulations and experiments with a ground vehicle, quadrotor, and quadruped, supported by benchmarking and time-complexity analysis.

Paper number 89:
Title: CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement
Authors: Lei Cheng, Lihao Guo, Tianya Zhang, Tam Bang, Austin Harris, Mustafa Hajij, Mina Sartipi, Siyang Cao
Abstract: Accurate multi-sensor calibration is essential for deploying robust perception systems in applications such as autonomous driving and intelligent transportation. Existing LiDAR-camera calibration methods often rely on manually placed targets, preliminary parameter estimates, or intensive data preprocessing, limiting their scalability and adaptability in real-world settings. In this work, we propose a fully automatic, targetless, and online calibration framework, CalibRefine, which directly processes raw LiDAR point clouds and camera images. Our approach is divided into four stages: (1) a Common Feature Discriminator that leverages relative spatial positions, visual appearance embeddings, and semantic class cues to identify and generate reliable LiDAR-camera correspondences, (2) a coarse homography-based calibration that uses the matched feature correspondences to estimate an initial transformation between the LiDAR and camera frames, serving as the foundation for further refinement, (3) an iterative refinement to incrementally improve alignment as additional data frames become available, and (4) an attention-based refinement that addresses non-planar distortions by leveraging a Vision Transformer and cross-attention mechanisms. Extensive experiments on two urban traffic datasets demonstrate that CalibRefine achieves high-precision calibration with minimal human input, outperforming state-of-the-art targetless methods and matching or surpassing manually tuned baselines. Our results show that robust object-level feature matching, combined with iterative refinement and self-supervised attention-based refinement, enables reliable sensor alignment in complex real-world conditions without ground-truth matrices or elaborate preprocessing. Code is available at this https URL

Paper number 90:
Title: Neural Configuration-Space Barriers for Manipulation Planning and Control
Authors: Kehan Long, Ki Myung Brian Lee, Nikola Raicevic, Niyas Attasseri, Melvin Leok, Nikolay Atanasov
Abstract: Planning and control for high-dimensional robot manipulators in cluttered, dynamic environments require both computational efficiency and robust safety guarantees. Inspired by recent advances in learning configuration-space distance functions (CDFs) as robot body representations, we propose a unified framework for motion planning and control that formulates safety constraints as CDF barriers. A CDF barrier approximates the local free configuration space, substantially reducing the number of collision-checking operations during motion planning. However, learning a CDF barrier with a neural network and relying on online sensor observations introduce uncertainties that must be considered during control synthesis. To address this, we develop a distributionally robust CDF barrier formulation for control that explicitly accounts for modeling errors and sensor noise without assuming a known underlying distribution. Simulations and hardware experiments on a 6-DoF xArm manipulator show that our neural CDF barrier formulation enables efficient planning and robust real-time safe control in cluttered and dynamic environments, relying only on onboard point-cloud observations.

Paper number 91:
Title: Content ARCs: Decentralized Content Rights in the Age of Generative AI
Authors: Kar Balan, Andrew Gilbert, John Collomosse
Abstract: The rise of Generative AI (GenAI) has sparked significant debate over balancing the interests of creative rightsholders and AI developers. As GenAI models are trained on vast datasets that often include copyrighted material, questions around fair compensation and proper attribution have become increasingly urgent. To address these challenges, this paper proposes a framework called Content ARCs (Authenticity, Rights, Compensation). By combining open standards for provenance and dynamic licensing with data attribution, and decentralized technologies, Content ARCs create a mechanism for managing rights and compensating creators for using their work in AI training. We characterize several nascent works in the AI data licensing space within Content ARCs and identify where challenges remain to fully implement the end-to-end framework.

Paper number 92:
Title: Coverage-Guaranteed Speech Emotion Recognition via Calibrated Uncertainty-Adaptive Prediction Sets
Authors: Zijun Jia
Abstract: Road rage, often triggered by emotional suppression and sudden outbursts, significantly threatens road safety by causing collisions and aggressive behavior. Speech emotion recognition technologies can mitigate this risk by identifying negative emotions early and issuing timely alerts. However, current SER methods, such as those based on hidden markov models and Long short-term memory networks, primarily handle one-dimensional signals, frequently experience overfitting, and lack calibration, limiting their safety-critical effectiveness. We propose a novel risk-controlled prediction framework providing statistically rigorous guarantees on prediction accuracy. This approach employs a calibration set to define a binary loss function indicating whether the true label is included in the prediction set. Using a data-driven threshold $\beta$, we optimize a joint loss function to maintain an expected test loss bounded by a user-specified risk level $\alpha$. Evaluations across six baseline models and two benchmark datasets demonstrate our framework consistently achieves a minimum coverage of $1 - \alpha$, effectively controlling marginal error rates despite varying calibration-test split ratios (e.g., 0.1). The robustness and generalizability of the framework are further validated through an extension to small-batch online calibration under a local exchangeability assumption. We construct a non-negative test martingale to maintain prediction validity even in dynamic and non-exchangeable environments. Cross-dataset tests confirm our method's ability to uphold reliable statistical guarantees in realistic, evolving data scenarios.

Paper number 93:
Title: Can Knowledge Improve Security? A Coding-Enhanced Jamming Approach for Semantic Communication
Authors: Weixuan Chen, Qianqian Yang, Shuo Shao, Zhiguo Shi, Jiming Chen, Xuemin (Sherman)Shen
Abstract: As semantic communication (SemCom) attracts growing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels has become a critical issue. However, traditional encryption methods often introduce significant additional communication overhead to maintain stability, and conventional learning-based secure SemCom methods typically rely on a channel capacity advantage for the legitimate receiver, which is challenging to guarantee in real-world scenarios. In this paper, we propose a coding-enhanced jamming method that eliminates the need to transmit a secret key by utilizing shared knowledge-potentially part of the training set of the SemCom system-between the legitimate receiver and the transmitter. Specifically, we leverage the shared private knowledge base to generate a set of private digital codebooks in advance using neural network (NN)-based encoders. For each transmission, we encode the transmitted data into digital sequence Y1 and associate Y1 with a sequence randomly picked from the private codebook, denoted as Y2, through superposition coding. Here, Y1 serves as the outer code and Y2 as the inner code. By optimizing the power allocation between the inner and outer codes, the legitimate receiver can reconstruct the transmitted data using successive decoding with the index of Y2 shared, while the eavesdropper' s decoding performance is severely degraded, potentially to the point of random guessing. Experimental results demonstrate that our method achieves comparable security to state-of-the-art approaches while significantly improving the reconstruction performance of the legitimate receiver by more than 1 dB across varying channel signal-to-noise ratios (SNRs) and compression ratios.

Paper number 94:
Title: Enhancing Privacy in Semantic Communication over Wiretap Channels leveraging Differential Privacy
Authors: Weixuan Chen, Shunpu Tang, Qianqian Yang, Zhiguo Shi, Dusit Niyato
Abstract: Semantic communication (SemCom) improves transmission efficiency by focusing on task-relevant information. However, transmitting semantic-rich data over insecure channels introduces privacy risks. This paper proposes a novel SemCom framework that integrates differential privacy (DP) mechanisms to protect sensitive semantic features. This method employs the generative adversarial network (GAN) inversion technique to extract disentangled semantic features and uses neural networks (NNs) to approximate the DP application and removal processes, effectively mitigating the non-invertibility issue of DP. Additionally, an NN-based encryption scheme is introduced to strengthen the security of channel inputs. Simulation results demonstrate that the proposed approach effectively prevents eavesdroppers from reconstructing sensitive information by generating chaotic or fake images, while ensuring high-quality image reconstruction for legitimate users. The system exhibits robust performance across various privacy budgets and channel conditions, achieving an optimal balance between privacy protection and reconstruction fidelity.
    