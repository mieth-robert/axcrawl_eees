
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Validation methodology on real data of reversible Kalman Filter for state estimation with Manifold
Authors: Svyatoslav Covanov, Cedric Pradalier
Abstract: This work extends a previous study that introduced an algorithm for state estimation on manifolds within the framework of the Kalman filter. Its objective is to address the limitations of the earlier approach. The reversible Kalman filter was designed to provide a methodology for evaluating the accuracy of existing Kalman filter variants with arbitrary precision on synthetic data. It has favorable numerical properties on synthetic data, achieving arbitrary precision without relying on the small-velocity assumption and depending only on sensor noise. However, its application to real data encountered difficulties related to measurement noise, which was mitigated using a heuristic. In particular, the heuristic involved an event detection step switching between reversible Kalman filter and classical Kalman variant at chosen moments. In the present work, we propose a study of this detection step and propose a methodology to prove at which moment the reversible Kalman approach improves on classical multiplicative variant. In particular, we propose a metric allowing one to discriminate situations in real-world scenarios where it behaves better than classical approach.

Paper number 2:
Title: UniFi: Combining Irregularly Sampled CSI from Diverse Communication Packets and Frequency Bands for Wi-Fi Sensing
Authors: Gaofeng Dong, Kang Yang, Mani Srivastava
Abstract: Existing Wi-Fi sensing systems rely on injecting high-rate probing packets to extract channel state information (CSI), leading to communication degradation and poor deployability. Although Integrated Sensing and Communication (ISAC) is a promising direction, existing solutions still rely on auxiliary packet injection because they exploit only CSI from data frames. We present UniFi, the first Wi-Fi-based ISAC framework that fully eliminates intrusive packet injection by directly exploiting irregularly sampled CSI from diverse communication packets across multiple frequency bands. UniFi integrates a CSI sanitization pipeline to harmonize heterogeneous packets and remove burst-induced redundancy, together with a time-aware attention model that learns directly from non-uniform CSI sequences without resampling. We further introduce CommCSI-HAR, the first dataset with irregularly sampled CSI from real-world dual-band communication traffic. Extensive evaluations on this dataset and four public benchmarks show that UniFi achieves state-of-the-art accuracy with a compact model size, while fully preserving communication throughput.

Paper number 3:
Title: EEG-to-Voice Decoding of Spoken and Imagined speech Using Non-Invasive EEG
Authors: Hanbeot Park, Yunjeong Cho, Hunhee Kim
Abstract: Restoring speech communication from neural signals is a central goal of brain-computer interface research, yet EEG-based speech reconstruction remains challenging due to limited spatial resolution, susceptibility to noise, and the absence of temporally aligned acoustic targets in imagined speech. In this study, we propose an EEG-to-Voice paradigm that directly reconstructs speech from non-invasive EEG signals without dynamic time warping (DTW) or explicit temporal alignment. The proposed pipeline generates mel-spectrograms from EEG in an open-loop manner using a subject-specific generator, followed by pretrained vocoder and automatic speech recognition (ASR) modules to synthesize speech waveforms and decode text. Separate generators were trained for spoken speech and imagined speech, and transfer learning-based domain adaptation was applied by pretraining on spoken speech and adapting to imagined speech. A minimal language model-based correction module was optionally applied to correct limited ASR errors while preserving semantic structure. The framework was evaluated under 2 s and 4 s speech conditions using acoustic-level metrics (PCC, RMSE, MCD) and linguistic-level metrics (CER, WER). Stable acoustic reconstruction and comparable linguistic accuracy were observed for both spoken speech and imagined speech. While acoustic similarity decreased for longer utterances, text-level decoding performance was largely preserved, and word-position analysis revealed a mild increase in decoding errors toward later parts of sentences. The language model-based correction consistently reduced CER and WER without introducing semantic distortion. These results demonstrate the feasibility of direct, open-loop EEG-to-Voice reconstruction for spoken speech and imagined speech without explicit temporal alignment.

Paper number 4:
Title: Machine Learning-Based Basil Yield Prediction in IoT-Enabled Indoor Vertical Hydroponic Farms
Authors: Emna Bouzid, Noura Baccar, Kamran Iqbal, Yassine Chaouch, Fares Ben Youssef, Amine Regayeg, Sarra Toumi, Houda Nsir, Amina Mseddi, Leila Costelle
Abstract: As agriculture faces increasing pressure from water scarcity, especially in regions like Tunisia, innovative, resource-efficient solutions are urgently needed. This work explores the integration of indoor vertical hydroponics with Machine Learning (ML) techniques to optimize basil yield while saving water. This research develops a prediction system that uses different ML models and assesses their performance. The models were systematically trained and tested using data collected from IoT sensors of various environmental parameters like CO2, light. The experimental setup features 21 basil crops and uses Raspberry Pi and Arduino. 10k data points were collected and used to train and evaluate three ML models: Linear Regression (LR), Long Short-Term Memory (LSTM), and Deep Neural Networks (DNN). The comparative analysis of the performance of each model revealed that, while LSTM showed high predictive capability and accuracy of 99%, its execution time was 10 times longer than LR and its RAM usage was about 3 times higher than DNN's when simulated on a standard CPU environment. Conversely, the DNN model had an accuracy rate of 98%. This proves an efficient balance between computational speed and prediction quality, which makes this model well-suited for real-life deployment. Moreover, LR excelled in fast processing of basic prediction with an execution time of 11 seconds. This makes the LR model more suitable for low-complexity or resource-limited applications. These performance trade-offs highlight the potential of DNN-based solutions for building responsive, high-accuracy decision-support systems tailored to agricultural environments, making it suitable for future edge-device deployment.

Paper number 5:
Title: PaperNet: Efficient Temporal Convolutions and Channel Residual Attention for EEG Epilepsy Detection
Authors: Md Shahriar Sajid, Abhijit Kumar Ghosh, Fariha Nusrat
Abstract: Electroencephalography (EEG) signals contain rich temporal-spectral structure but are difficult to model due to noise, subject variability, and multi-scale dynamics. Lightweight deep learning models have shown promise, yet many either rely solely on local convolutions or require heavy recurrent modules. This paper presents PaperNet, a compact hybrid architecture that combines temporal convolutions, a channel-wise residual attention module, and a lightweight bidirectional recurrent block which is used for short-window classification. Using the publicly available BEED: Bangalore EEG Epilepsy Dataset, we evaluate PaperNet under a clearly defined subject-independent training protocol and compare it against established and widely used lightweight baselines. The model achieves a macro-F1 of 0.96 on the held-out test set with approximately 0.6M parameters, while maintaining balanced performance across all four classes. An ablation study demonstrates the contribution of temporal convolutions, residual attention, and recurrent aggregation. Channel-wise attention weights further offer insights into electrode relevance. Computational profiling shows that PaperNet remains efficient enough for practical deployment on resource-constrained systems through out the whole process. These results indicate that carefully combining temporal filtering, channel reweighting, and recurrent context modeling can yield strong EEG classification performance without excessive computational cost.

Paper number 6:
Title: Field strength-dependent performance variability in deep learning-based analysis of magnetic resonance imaging
Authors: Muhammad Ibtsaam Qadir, Duane Schonlau, Ulrike Dydak, Fiona R. Kolbinger
Abstract: This study quantitatively evaluates the impact of MRI scanner magnetic field strength on the performance and generalizability of deep learning-based segmentation algorithms. Three publicly available MRI datasets (breast tumor, pancreas, and cervical spine) were stratified by scanner field strength (1.5T vs. 3.0T). For each segmentation task, three nnU-Net-based models were developed: A model trained on 1.5T data only (m-1.5T), a model trained on 3.0T data only (m-3.0T), and a model trained on pooled 1.5T and 3.0T data (m-combined). Each model was evaluated on both 1.5T and 3.0T validation sets. Field-strength-dependent performance differences were investigated via Uniform Manifold Approximation and Projection (UMAP)-based clustering and radiomic analysis, including 23 first-order and texture features. For breast tumor segmentation, m-3.0T (DSC: 0.494 [1.5T] and 0.433 [3.0T]) significantly outperformed m-1.5T (DSC: 0.411 [1.5T] and 0.289 [3.0T]) and m-combined (DSC: 0.373 [1.5T] and 0.268[3.0T]) on both validation sets (p<0.0001). Pancreas segmentation showed similar trends: m-3.0T achieved the highest DSC (0.774 [1.5T], 0.840 [3.0T]), while m-1.5T underperformed significantly (p<0.0001). For cervical spine, models performed optimally on same-field validation sets with minimal cross-field performance degradation (DSC>0.92 for all comparisons). Radiomic analysis revealed moderate field-strength-dependent clustering in soft tissues (silhouette scores 0.23-0.29) but minimal separation in osseous structures (0.12). These results indicate that magnetic field strength in the training data substantially influences the performance of deep learning-based segmentation models, particularly for soft-tissue structures (e.g., small lesions). This warrants consideration of magnetic field strength as a confounding factor in studies evaluating AI performance on MRI.

Paper number 7:
Title: AI-Enhanced Virtual Biopsies for Brain Tumor Diagnosis in Low Resource Settings
Authors: Areeb Ehsan
Abstract: Timely brain tumor diagnosis remains challenging in low-resource clinical environments where expert neuroradiology interpretation, high-end MRI hardware, and invasive biopsy procedures may be limited. Although deep learning has achieved strong performance in brain tumor analysis, real-world adoption is constrained by computational demands, dataset shift across scanners, and limited interpretability. This paper presents a prototype virtual biopsy pipeline for four-class classification of 2D brain MRI images using a lightweight convolutional neural network (CNN) and complementary radiomics-style handcrafted features. A MobileNetV2-based CNN is trained for classification, while an interpretable radiomics branch extracts eight features capturing lesion shape, intensity statistics, and gray-level co-occurrence matrix (GLCM) texture descriptors. A late fusion strategy concatenates CNN embeddings with radiomics features and trains a RandomForest classifier on the fused representation. Explainability is provided via Grad-CAM visualizations and radiomics feature importance analysis. Experiments on a public Kaggle brain tumor MRI dataset show improved validation performance for fusion relative to single-branch baselines, while robustness tests under reduced resolution and additive noise highlight sensitivity relevant to low-resource imaging conditions. The system is framed as decision support and not a substitute for clinical diagnosis or histopathology.

Paper number 8:
Title: Complex Swin Transformer for Accelerating Enhanced SMWI Reconstruction
Authors: Muhammad Usman, Sung-Min Gho
Abstract: Susceptibility Map Weighted Imaging (SMWI) is an advanced magnetic resonance imaging technique used to detect nigral hyperintensity in Parkinsons disease. However, full resolution SMWI acquisition is limited by long scan times. Efficient reconstruction methods are therefore required to generate high quality SMWI from reduced k space data while preserving diagnostic relevance. In this work, we propose a complex valued Swin Transformer based network for super resolution reconstruction of multi echo MRI data. The proposed method reconstructs high quality SMWI images from low resolution k space inputs. Experimental results demonstrate that the method achieves a structural similarity index of 0.9116 and a mean squared error of 0.076 when reconstructing SMWI from 256 by 256 k space data, while maintaining critical diagnostic features. This approach enables high quality SMWI reconstruction from reduced k space sampling, leading to shorter scan times without compromising diagnostic detail. The proposed method has the potential to improve the clinical applicability of SMWI for Parkinsons disease and support faster and more efficient neuroimaging workflows.

Paper number 9:
Title: Super-Resolution Enhancement of Medical Images Based on Diffusion Model: An Optimization Scheme for Low-Resolution Gastric Images
Authors: Haozhe Jia
Abstract: Capsule endoscopy has enabled minimally invasive gastrointestinal imaging, but its clinical utility is limited by the inherently low resolution of captured images due to hardware, power, and transmission constraints. This limitation hampers the identification of fine-grained mucosal textures and subtle pathological features essential for early diagnosis. This work investigates a diffusion-based super-resolution framework to enhance capsule endoscopy images in a data-driven and anatomically consistent manner. We adopt the SR3 (Super-Resolution via Repeated Refinement) framework built upon Denoising Diffusion Probabilistic Models (DDPMs) to learn a probabilistic mapping from low-resolution to high-resolution images. Unlike GAN-based approaches that often suffer from training instability and hallucination artifacts, diffusion models provide stable likelihood-based training and improved structural fidelity. The HyperKvasir dataset, a large-scale publicly available gastrointestinal endoscopy dataset, is used for training and evaluation. Quantitative results demonstrate that the proposed method significantly outperforms bicubic interpolation and GAN-based super-resolution methods such as ESRGAN, achieving PSNR of 27.5 dB and SSIM of 0.65 for a baseline model, and improving to 29.3 dB and 0.71 with architectural enhancements including attention mechanisms. Qualitative results show improved preservation of anatomical boundaries, vascular patterns, and lesion structures. These findings indicate that diffusion-based super-resolution is a promising approach for enhancing non-invasive medical imaging, particularly in capsule endoscopy where image resolution is fundamentally constrained.

Paper number 10:
Title: SemCovert: Secure and Covert Video Transmission via Deep Semantic-Level Hiding
Authors: Zhihan Cao, Xiao Yang, Gaolei Li, Jun Wu, Jianhua Li, Yuchen Liu
Abstract: Video semantic communication, praised for its transmission efficiency, still faces critical challenges related to privacy leakage. Traditional security techniques like steganography and encryption are challenging to apply since they are not inherently robust against semantic-level transformations and abstractions. Moreover, the temporal continuity of video enables framewise statistical modeling over extended periods, which increases the risk of exposing distributional anomalies and reconstructing hidden content. To address these challenges, we propose SemCovert, a deep semantic-level hiding framework for secure and covert video transmission. SemCovert introduces a pair of co-designed models, namely the semantic hiding model and the secret semantic extractor, which are seamlessly integrated into the semantic communication pipeline. This design enables authorized receivers to reliably recover hidden information, while keeping it imperceptible to regular users. To further improve resistance to analysis, we introduce a randomized semantic hiding strategy, which breaks the determinism of embedding and introduces unpredictable distribution patterns. The experimental results demonstrate that SemCovert effectively mitigates potential eavesdropping and detection risks while reliably concealing secret videos during transmission. Meanwhile, video quality suffers only minor degradation, preserving transmission fidelity. These results confirm SemCovert's effectiveness in enabling secure and covert transmission without compromising semantic communication performance.

Paper number 11:
Title: Simultaneous Source Separation, Synchronization, Localization and Mapping for 6G Systems
Authors: Alexander Venus, Erik Leitinger, Klaus Witrisal
Abstract: Multipath-based simultaneous localization and mapping (MP-SLAM) is a promising approach for future 6G networks to jointly estimate the positions of transmitters and receivers together with the propagation environment. In cooperative MP-SLAM, information collected by multiple mobile terminals (MTs) is fused to enhance accuracy and robustness. Existing methods, however, typically assume perfectly synchronized base stations (BSs) and orthogonal transmission sequences, rendering inter-BS interference at the MTs negligible. In this work, we relax these assumptions and address simultaneous source separation, synchronization, and mapping. A relevant example arises in modern 5G systems, where BSs employ muting patterns to mitigate interference, yet localization performance still degrades. We propose a novel BS-dependent data association and synchronization bias model, integrated into a joint Bayesian framework and inferred via the sum-product algorithm on a factor graph. The impact of joint synchronization and source separation is analyzed under various system configurations. Compared with state-of-the-art cooperative MP-SLAM assuming orthogonal and synchronized BSs, our statistical analysis shows no significant performance degradation.

Paper number 12:
Title: MEGA-PCC: A Mamba-based Efficient Approach for Joint Geometry and Attribute Point Cloud Compression
Authors: Kai-Hsiang Hsieh, Monyneath Yim, Wen-Hsiao Peng, Jui-Chiu Chiang
Abstract: Joint compression of point cloud geometry and attributes is essential for efficient 3D data representation. Existing methods often rely on post-hoc recoloring procedures and manually tuned bitrate allocation between geometry and attribute bitstreams in inference, which hinders end-to-end optimization and increases system complexity. To overcome these limitations, we propose MEGA-PCC, a fully end-to-end, learning-based framework featuring two specialized models for joint compression. The main compression model employs a shared encoder that encodes both geometry and attribute information into a unified latent representation, followed by dual decoders that sequentially reconstruct geometry and then attributes. Complementing this, the Mamba-based Entropy Model (MEM) enhances entropy coding by capturing spatial and channel-wise correlations to improve probability estimation. Both models are built on the Mamba architecture to effectively model long-range dependencies and rich contextual features. By eliminating the need for recoloring and heuristic bitrate tuning, MEGA-PCC enables data-driven bitrate allocation during training and simplifies the overall pipeline. Extensive experiments demonstrate that MEGA-PCC achieves superior rate-distortion performance and runtime efficiency compared to both traditional and learning-based baselines, offering a powerful solution for AI-driven point cloud compression.

Paper number 13:
Title: FARIS: Fluid-Active-RIS
Authors: Hong-Bae Jeon
Abstract: In this paper, we introduce a fluid-active reconfigurable intelligent surface (FARIS) that combines fluid-based port repositioning with per-element active amplification to enhance the performance of 6G network. To characterize the performance, we formulate an ergodic-rate maximization problem that jointly optimizes both the active amplification-reflection vector and the discrete selection of fluid active elements under practical hardware constraints. The problem is addressed via an alternating optimization (AO) framework, which progressively improves the rate. Complexity and convergence analyses that follow furnish deeper insight into the algorithmic operation and performance enhancement. Numerical results confirm that the proposed FARIS with AO framework consistently outperforms conventional FRIS/ARIS, delivering higher rates across diverse environments, often even when using fewer active elements or a smaller physical aperture.

Paper number 14:
Title: CoDS: Collaborative Perception via Digital Semantic Communication
Authors: Jipeng Gan, Le Liang, Hua Zhang, Chongtao Guo, Shi Jin
Abstract: Semantic communication has been introduced into collaborative perception systems for autonomous driving, offering a promising approach to enhancing data transmission efficiency and robustness. Despite its potential, existing semantic communication approaches predominantly rely on analog transmission models, rendering these systems fundamentally incompatible with the digital architecture of modern vehicle-to-everything (V2X) networks and posing a significant barrier to real-world deployment. To bridge this critical gap, we propose CoDS, a novel collaborative perception framework based on digital semantic communication, designed to realize semantic-level transmission efficiency within practical digital communication systems. Specifically, we develop a semantic compression codec that extracts and compresses task-oriented semantic features while preserving downstream perception accuracy. Building on this, we propose a novel semantic analog-to-digital converter that converts these continuous semantic features into a discrete bitstream, ensuring integration with existing digital communication pipelines. Furthermore, we develop an uncertainty-aware network (UAN) that assesses the reliability of each received feature and discards those corrupted by decoding failures, thereby mitigating the cliff effect of conventional channel coding schemes under low signal-to-noise ratio (SNR) conditions. Extensive experiments demonstrate that CoDS significantly outperforms existing semantic communication and traditional digital communication schemes, achieving state-of-the-art perception performance while ensuring compatibility with practical digital V2X systems.

Paper number 15:
Title: Compressive Toeplitz Covariance Estimation From Few-Bit Quantized Measurements With Applications to DOA Estimation
Authors: Hongwei Xu, Weichao Zheng, Zai Yang
Abstract: This paper addresses the problem of estimating the Hermitian Toeplitz covariance matrix under practical hardware constraints of sparse observations and coarse quantization. Within the triangular-dithered quantization framework, we propose an estimator called Toeplitz-projected sample covariance matrix (Q-TSCM) to compensate for the quantization-induced bias, together with its finite-bit counterpart termed the $2k$-bit Toeplitz-projected sample covariance matrix ($2k$-TSCM), obtained by truncating the pre-quantization observations. Under the complex Gaussian assumption, we derive non-asymptotic error bounds of the estimators that reveal a quadratic dependence on the quantization level and capture the effect of sparse sampling patterns through the so-called coverage coefficient. To further improve performance, we propose the quantized sparse and parametric approach (Q-SPA) based on a covariance-fitting criterion, which enforces additionally positive semidefiniteness at the cost of solving a semidefinite program. Numerical experiments are presented that corroborate our theoretical findings and demonstrate the effectiveness of the proposed estimators in the application to direction-of-arrival estimation.

Paper number 16:
Title: Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers
Authors: Atakan Işık, Selin Vulga Işık, Ahmet Feridun Işık, Mahşuk Taylan
Abstract: Respiratory sound classification is hindered by the limited size, high noise levels, and severe class imbalance of benchmark datasets like ICBHI 2017. While Transformer-based models offer powerful feature extraction capabilities, they are prone to overfitting and often converge to sharp minima in the loss landscape when trained on such constrained medical data. To address this, we introduce a framework that enhances the Audio Spectrogram Transformer (AST) using Sharpness-Aware Minimization (SAM). Instead of merely minimizing the training loss, our approach optimizes the geometry of the loss surface, guiding the model toward flatter minima that generalize better to unseen patients. We also implement a weighted sampling strategy to handle class imbalance effectively. Our method achieves a state-of-the-art score of 68.10% on the ICBHI 2017 dataset, outperforming existing CNN and hybrid baselines. More importantly, it reaches a sensitivity of 68.31%, a crucial improvement for reliable clinical screening. Further analysis using t-SNE and attention maps confirms that the model learns robust, discriminative features rather than memorizing background noise.

Paper number 17:
Title: A Novel Geometry-Aware GPR-Based Energy-Efficient and Low-Overhead Channel Estimation Scheme
Authors: Syed Luqman Shah, Nurul Huda Mahmood
Abstract: In this work, we model the wireless channel as a complex-valued Gaussian process (GP) over the transmit and receive antenna arrays. The channel covariance is characterized using an antenna-geometry-based spectral mixture covariance function (GB-SMCF), which captures the spatial structure of the antenna arrays. To address the problem of accurate channel state information (CSI) estimation from very few noisy observations, we develop a Gaussian process regression (GPR)-based channel estimation framework that employs the GB-SMCF as a prior covariance model with online hyperparameter optimization. In the proposed scheme, the full channel is learned by transmitting pilots from only a small subset of transmit antennas while receiving them at all receive antennas, resulting in noisy partial CSI at the receiver. These limited observations are then processed by the GPR framework, which updates the GB-SMCF hyperparameters online from incoming measurements and reconstructs the full CSI in real time. Simulation results demonstrate that the proposed GB-SMCF-based estimator outperforms baseline methods while reducing pilot overhead and training energy by up to 50$\%$ compared to conventional schemes.

Paper number 18:
Title: Real-Time Multi-Target Detection and Tracking with mmWave 5G NR Waveforms on RFSoC
Authors: Xinyang Li, Hian Zing Voon, Vlad C. Andrei, Alexander Sessler, Nunzio Sciammetta, Ullrich J. Mönich, Dominic A. Schupke, Holger Boche
Abstract: We demonstrate a real-time implementation of multi-target detection and tracking using 5G New Radio (NR) physical downlink shared channel (PDSCH) waveform with 400 MHz bandwidth at 28 GHz carrier frequency. The hardware platform is built on a radio frequency system-on-chip (RFSoC) 4x2 board connected with a pair of Sivers EVK02001 mmWave beamformers for transmission and reception. The entire sensing transceiver processing and fast beam control are realized purely in the programmable logic (PL) part of the RFSoC, enabling low-latency and fully hardware-accelerated operation. The continuously acquired sensing data constitute 3D range-angle (RA) tensors, which are processed on a host PC using adaptive background subtraction, cell-averaging constant false alarm rate (CA-CFAR) detection with density-based spatial clustering of applications with noise (DBSCAN) clustering, and extended Kalman filtering (EKF), to detect and track targets in the environment. Our software-defined radio (SDR) testbed integrates heterogeneous computing resources, including CPUs, GPUs, and FPGAs, thereby providing design flexibility for a wide range of tasks.

Paper number 19:
Title: Tree Meets Transformer: A Hybrid Architecture for Scalable Power Allocation in Cell-Free Networks
Authors: Irched Chafaa, Giacomo Bacci, Luca Sanguinetti
Abstract: Power allocation remains a fundamental challenge in wireless communication networks, particularly under dynamic user loads and large-scale deployments. While Transformerbased models have demonstrated strong performance, their computational cost scales poorly with the number of users. In this work, we propose a novel hybrid Tree-Transformer architecture that achieves scalable per-user power allocation. Our model compresses user features via a binary tree into a global root representation, applies a Transformer encoder solely to this root, and decodes per-user uplink and downlink powers through a shared decoder. This design achieves logarithmic depth and linear total complexity, enabling efficient inference across large and variable user sets without retraining or architectural changes. We evaluate our model on the max-min fairness problem in cellfree massive MIMO systems and demonstrate that it achieves near-optimal performance while significantly reducing inference time compared to full-attention baselines.

Paper number 20:
Title: On the Stealth of Unbounded Attacks Under Non-Negative-Kernel Feedback
Authors: Kamil Hassan, Henrik Sandberg
Abstract: The stealth of false data injection attacks (FDIAs) against feedback sensors in linear time-varying (LTV) control systems is investigated. In that regard, the following notions of stealth are pursued: For some finite $\epsilon > 0$, i) an FDIA is deemed $\epsilon$-stealthy if the deviation it produces in the signal that is monitored by the anomaly detector remains $\epsilon$-bounded for all time, and ii) the $\epsilon$-stealthy FDIA is further classified as untraceable if the bounded deviation dissipates over time (asymptotically). For LTV systems that contain a chain of $q \geq 1$ integrators and feedback controllers with non-negative impulse-response kernels, it is proved that polynomial (in time) FDIA signals of degree $a$ - growing unbounded over time - will remain i) $\epsilon$-stealthy, for some finite $\epsilon > 0$, if $a \leq q$, and ii) untraceable, if $a < q$. These results are obtained using the theory of linear Volterra integral equations.

Paper number 21:
Title: Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach
Authors: Arya Rashidinejad Meibodi, Mahbod Gholamali Sinaki, Khalil Alipour
Abstract: The State-Dependent Riccati Equation (SDRE) technique generalizes the classical algebraic Riccati formulation to nonlinear systems by designing an input to the system that optimally(suboptimally) regulates system states toward the origin while simultaneously optimizing a quadratic performance index. In the SDRE technique, we solve the State-Dependent Riccati Equation to determine the control for regulating a nonlinear input-affine system. Since an analytic solution to SDRE is not straightforward, one method is to linearize the system at every state, solve the corresponding Algebraic Riccati Equation (ARE), and apply optimal control until the next state of the system. Completing this task with high frequency gives a result like the original SDRE technique. Both approaches require a complete model; therefore, here we propose a method that solves ARE in every state of the system using a partially model-free approach that learns optimal control in every state of the system, without explicit knowledge of the drift dynamics, based on Integral Reinforcement Learning (IRL). To show the effectiveness of our proposed approach, we apply it to the second-order nonlinear system in simulation and compare its performance with the classical SDRE method, which relies on the system's model and solves the ARE at each state. Our simulation results demonstrate that, with sufficient iterations, the IRL-based approach achieves approximately the same performance as the conventional SDRE method, demonstrating its capability as a reliable alternative for nonlinear system control that does not require an explicit environmental model. Index Terms-Algebraic Riccati Equation (ARE), Integral Reinforcement Learning (IRL), Nonlinear Input-Affine Systems, Optimal Regulation, State-Dependent Riccati Equation (SDRE)

Paper number 22:
Title: Semantic contrastive learning for orthogonal X-ray computed tomography reconstruction
Authors: Jiashu Dong, Jiabing Xiang, Lisheng Geng, Suqing Tian, Wei Zhao
Abstract: X-ray computed tomography (CT) is widely used in medical imaging, with sparse-view reconstruction offering an effective way to reduce radiation dose. However, ill-posed conditions often result in severe streak artifacts. Recent advances in deep learning-based methods have improved reconstruction quality, but challenges still remain. To address these challenges, we propose a novel semantic feature contrastive learning loss function that evaluates semantic similarity in high-level latent spaces and anatomical similarity in shallow latent spaces. Our approach utilizes a three-stage U-Net-based architecture: one for coarse reconstruction, one for detail refinement, and one for semantic similarity measurement. Tests on a chest dataset with orthogonal projections demonstrate that our method achieves superior reconstruction quality and faster processing compared to other algorithms. The results show significant improvements in image quality while maintaining low computational complexity, making it a practical solution for orthogonal CT reconstruction.

Paper number 23:
Title: Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space
Authors: Sergey Salishev
Abstract: This thesis develops signal-processing algorithms and implementation schemes under constraints of minimal parallelism and memory space, with the goal of improving energy efficiency of low-power computing hardware. We propose (i) a power/energy consumption model for clocked CMOS logic that supports selecting optimal parallelism, (ii) integer-friendly approximation methods for elementary functions that reduce lookup-table size via constrained piecewise-polynomial (quasi-spline) constructions with accuracy guarantees, (iii) provably conflict-free data placement and execution order for mixed-radix streaming FFT on multi-bank and single-port memories, including a self-sorting FFT variant, and (iv) a parallelism/memory analysis of the fast Schur algorithm for superfast Toeplitz system solving, motivated by echo-cancellation workloads. The results provide constructive theorems, schedules, and design trade-offs enabling efficient specialized accelerators.

Paper number 24:
Title: From Electrochemical Energy Storage to Next-Generation Intelligent Battery Technologies for Electric Vehicles: A Survey
Authors: Abderaouf Bahi, Amel Ourici, Chaima Lagraa, Siham Lameche, Soundess Halimi, Inoussa Mouiche, Ylias Sabri, Waseem Haider, Mohamed Trari
Abstract: This study provides a comprehensive overview of recent advances in electrochemical energy storage, including Na+ -ion, metal-ion, and metal-air batteries, alongside innovations in electrode engineering, electrolytes, and solid-electrolyte interphase control. It also explores the integration of machine learning, digital twins, large language models and predictive analytics to enable intelligent battery management systems, enhancing performance, safety, and operational longevity. Key challenges, research gaps, and future prospects are addressed, highlighting opportunities presented by hybrid chemistry, scalable manufacturing, sustainability, and AI-driven optimization. This survey aims to provide researchers, engineers, and industry profesionnals with a comprehensive understanding of next-generation battery technologies for the evolving electric vehicles sector.

Paper number 25:
Title: Multistatic Radar Performance in the Presence of Distributed Wireless Synchronization
Authors: Kumar Sai Bondada, Daniel J. Jakubisin, R. Michael Buehrer
Abstract: This paper proposes a multistatic radar (MSR) system utilizing a distributed wireless synchronization protocol. The wireless synchronization protocol uses a two-tone waveform exchange for frequency synchronization and a bi-directional waveform exchange for time synchronization, independent of GPS. A Bayesian Cramer-Rao lower bound (BCRLB) framework is developed to quantify the impact of synchronization offsets on joint delay and Doppler estimation, and consequently, on target localization and velocity estimation accuracy. Simulation results derived from the analytical expressions establish the extent to which the residual synchronization offsets degrade the MSR's performance. The performance of the synchronization links primarily depends on the synchronization-link channel and transmit parameters; optimizing these parameters enables the MSR configuration to surpass the monostatic performance and approach the ideal case. Furthermore, the simulated synchronization-link parameters suggest that practical implementation is feasible.

Paper number 26:
Title: Instance Communication System for Intelligent Connected Vehicles: Bridging the Gap from Semantic to Instance-Level Transmission
Authors: Daiqi Zhang, Bizhu Wang, Wenqi Zhang, Chen Sun, Xiaodong Xu
Abstract: Intelligent Connected Vehicles (ICVs) rely on high-speed data transmission for efficient and safety-critical services. However, the scarcity of wireless resources limits the capabilities of ICVs. Semantic Communication (SemCom) systems can alleviate this issue by extracting and transmitting task-relevant information, termed semantic information, instead of the entire raw data. Despite this, we reveal that residual redundancy persists within SemCom systems, where not all instances under the same semantic category are equally critical for downstream tasks. To tackle this issue, we introduce Instance Communication (InsCom), which elevates communication from the semantic level to the instance level for ICVs. Specifically, InsCom uses a scene graph generation model to identify all image instances and analyze their inter-relationships, thus distinguishing between semantically identical instances. Additionally, it applies user-configurable, task-critical criteria based on subject semantics and relation-object pairs to filter recognized instances. Consequently, by transmitting only task-critical instances, InsCom significantly reduces data redundancy, substantially enhancing transmission efficiency within limited wireless resources. Evaluations across various datasets and wireless channel conditions show that InsCom achieves a data volume reduction of over 7.82 times and a quality improvement ranging from 1.75 to 14.03 dB compared to the state-of-the-art SemCom systems.

Paper number 27:
Title: SwinCCIR: An end-to-end deep network for Compton camera imaging reconstruction
Authors: Minghao Dong, Xinyang Luo, Xujian Ouyang, Yongshun Xiao
Abstract: Compton cameras (CCs) are a kind of gamma cameras which are designed to determine the directions of incident gammas based on the Compton scatter. However, the reconstruction of CCs face problems of severe artifacts and deformation due to the fundamental reconstruction principle of back-projection of Compton cones. Besides, a part of systematic errors originated from the performance of devices are hard to remove through calibration, leading to deterioration of imaging quality. Iterative algorithms and deep-learning based methods have been widely used to improve reconstruction. But most of them are optimization based on the results of back-projection. Therefore, we proposed an end-to-end deep learning framework, SwinCCIR, for CC imaging. Through adopting swin-transformer blocks and a transposed convolution-based image generation module, we established the relationship between the list-mode events and the radioactive source distribution. SwinCCIR was trained and validated on both simulated and practical dataset. The experimental results indicate that SwinCCIR effectively overcomes problems of conventional CC imaging, which are expected to be implemented in practical applications.

Paper number 28:
Title: A Time-Barrier Lyapunov Condition for Predefined-Time Stability
Authors: Özhan Bingöl
Abstract: Predefined-time stability enables convergence within a user-specified time independent of initial conditions. Existing results are predominantly based on autonomous Lyapunov inequalities, where the predefined-time is realized through integral bounds on state-dependent decay and therefore acts as an upper bound rather than a structurally enforced deadline. This paper introduces a time-barrier predefined-time stability concept in which convergence is enforced through a nonautonomous Lyapunov mechanism that intrinsically restricts the remaining available time. A sufficient Lyapunov-based condition is established, guaranteeing convergence before the predefined deadline via divergence of a time-dependent barrier. It is further shown that this mechanism cannot be reproduced by classical autonomous predefined-time stability formulations, thereby constituting a distinct stability notion. The proposed approach provides a concise and transparent means of enforcing hard convergence deadlines in nonlinear systems.

Paper number 29:
Title: Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach
Authors: Minh Bui, Simon Monckton, Mo Chen
Abstract: Reach-avoid (RA) games have significant applications in security and defense, particularly for unmanned aerial vehicles (UAVs). These problems are inherently challenging due to the need to consider obstacles, consider the adversarial nature of opponents, ensure optimality, and account for nonlinear dynamics. Hamilton-Jacobi (HJ) reachability analysis has emerged as a powerful tool for tackling these challenges; however, while it has been applied to games involving two spatial dimensions, directly extending this approach to three spatial dimensions is impossible due to high dimensionality. On the other hand, alternative approaches for solving RA games lack the generality to consider games with three spatial dimensions involving agents with non-trivial system dynamics. In this work, we propose a novel framework for dimensionality reduction by decomposing the problem into a horizontal RA sub-game and a vertical RA sub-game. We then solve each sub-game using HJ reachability analysis and consider second-order dynamics that account for the defender's acceleration. To reconstruct the solution to the original RA game from the sub-games, we introduce a HJ-based tracking control algorithm in each sub-game that not only guarantees capture of the attacker but also tracking of the attacker thereafter. We prove the conditions under which the capture guarantees are maintained. The effectiveness of our approach is demonstrated via numerical simulations, showing that the decomposition maintains optimality and guarantees in the original problem. Our methods are also validated in a Gazebo physics simulator, achieving successful capture of quadrotors in three spatial dimensions space for the first time to the best of our knowledge.

Paper number 30:
Title: On the Impact of Phase Errors in Phase-Dependent Amplitudes of Near-Field RISs
Authors: Ke Wang, Chan-Tong Lam, Benjamin K. Ng, Yue Liu
Abstract: This paper investigates mutual coupling between phase-dependent amplitudes (PDAs) and designed phase shifts within pixels of near-field (NF) reconfigurable intelligent surfaces (RISs) in the presence of phase errors (PEs). In contrast to existing research that treats phase shifts with errors (PSEs) and the PDAs separately, we introduce a remaining power (RP) metric to quantify the proportion of power preserved in the signals reflected by the RIS, and we prove its asymptotic convergence to theoretical values by leveraging extended Glivenko-Cantelli theorem. Then, the RP of signals passing through RIS pixels is jointly examined under combined phase and amplitude uncertainties. In addition, we propose four pixel reflection models to capture practical conditions, and we derive approximate polynomial upper bounds for the RP with error terms by applying Taylor expansion. Furthermore, based on Friis transmission formula and projected aperture, we propose a general NF channel model that incorporates the coupling between the PSEs and the PDAs. By using Cauchy-Bunyakovsky-Schwarz inequality and Riemann sums, we derive a closed-form upper bound on spectral efficiency, and the bound becomes tighter as the pixel area decreases. We reveal that as the RIS phase shifts approach the ends of their range, the RP under independent and identically distributed PEs is smaller than that under fully correlated PEs, whereas this relationship reverses when the phase shifts are near the middle of their range. Neglecting the PEs in the PDAs leads to an overestimation of the RIS performance gain, explaining the discrepancies between theoretical and measured results.

Paper number 31:
Title: Generalizable Learning for Massive MIMO CSI Feedback in Unseen Environments
Authors: Haoyu Wang, Zhi Sun, Shuangfeng Han, Xiaoyun Wang, Zhaocheng Wang
Abstract: Deep learning is promising to enhance the accuracy and reduce the overhead of channel state information (CSI) feedback, which can boost the capacity of frequency division duplex (FDD) massive multiple-input multiple-output (MIMO) systems. Nevertheless, the generalizability of current deep learning-based CSI feedback algorithms cannot be guaranteed in unseen environments, which induces a high deployment cost. In this paper, the generalizability of deep learning-based CSI feedback is promoted with physics interpretation. Firstly, the distribution shift of the cluster-based channel is modeled, which comprises the multi-cluster structure and single-cluster response. Secondly, the physics-based distribution alignment is proposed to effectively address the distribution shift of the cluster-based channel, which comprises multi-cluster decoupling and fine-grained alignment. Thirdly, the efficiency and robustness of physics-based distribution alignment are enhanced. Explicitly, an efficient multi-cluster decoupling algorithm is proposed based on the Eckart-Young-Mirsky (EYM) theorem to support real-time CSI feedback. Meanwhile, a hybrid criterion to estimate the number of decoupled clusters is designed, which enhances the robustness against channel estimation error. Fourthly, environment-generalizable neural network for CSI feedback (EG-CsiNet) is proposed as a novel learning framework with physics-based distribution alignment. Based on extensive simulations and sim-to-real experiments in various conditions, the proposed EG-CsiNet can robustly reduce the generalization error by more than 3 dB compared to the state-of-the-arts.

Paper number 32:
Title: Assessment of a Hybrid Energy System for Reliable and Sustainable Power Supply to Boru Meda Hospital in Ethiopia
Authors: Tegenu Argaw Woldegiyorgis, Hong Xian Li, Fekadu Chekol Admassu, Merkebu Gezahegne, Abdurohman Kebede, Tadese Abera, Haris Ishaq, Eninges Asmare
Abstract: This study aims to evaluate the techno-economic feasibility of hybrid energy systems (HES) including Grid for providing reliable and sustainable power to Boru Meda Hospital, Ethiopia. HOMER pro 3.11.2 was used to design and evaluate a novel, integrated optimization and comparative assessment of diverse HRES, specif ically adjusted to the energy consumptions and available resources of the Hospital. The scenario evaluation showed that interconnecting photovoltaic (PV), biomass generator (BG), wind power (WP), diesel generator (DG), battery, and converter can effectively provide the Hospital's daily energy consumption of 11,214.66 kWh while conforming reliability and reducing emissions. The PV/BG/batt/conv configuration emerged as the most cost-effective and sustainable alternative, attaining the lowest LCOE of \$0.339/kWh, an NPC of \$25.7 million, and a 100% renewable energy fraction with simple pay back of 7.26 yr. As a result, the operational cost associated with the consumption of 500.00 L of diesel per month can be entirely avoided. The DG-integrated hybrids exhibit advanced techno-economic capability with significant worth, strong ROI (20\%) and IRR (18\%), endorsed by fast capital recovery (7.21-8.71 years). Overall, the hybrid system offers an optimal balance of cost, reliability, and sustainability, making it a promising and scalable solution for electrification of energy scare institution and areas in Ethiopia, thereby contributing to national sustainable energy development goals.

Paper number 33:
Title: A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments
Authors: Si-Yu Xiao, Xin-Di Zhao, Xiang-Zhan Wang, Tian-Hao Mao, Ying-Kai Liao, Xing-Yu Liao, Yu-Qiao Chen, Jun-Jie Wang, Shuang Liu, Tu-Pei Chen, Yang Liu
Abstract: Accurate downhole positioning is critical in oil and gas operations but is often compromised by signal degradation in traditional surface-based Casing Collar Locator (CCL) monitoring. To address this, we present an in-situ, real-time collar recognition system using embedded neural network. We introduce lightweight "Collar Recognition Nets" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors. By leveraging temporal and depthwise separable convolutions, our most compact model reduces computational complexity to just 8,208 MACs while maintaining an F1 score of 0.972. Hardware validation confirms an average inference latency of 343.2 {\mu}s, demonstrating that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation.

Paper number 34:
Title: Distributed Fusion Estimation with Protecting Exogenous Inputs
Authors: Liping Guo, Jimin Wang, Yanlong Zhao, Ji-Feng Zhang
Abstract: In the context of distributed fusion estimation, directly transmitting local estimates to the fusion center may cause a privacy leakage concerning exogenous inputs. Thus, it is crucial to protect exogenous inputs against full eavesdropping while achieving distributed fusion estimation. To address this issue, a noise injection strategy is provided by injecting mutually independent noises into the local estimates transmitted to the fusion center. To determine the covariance matrices of the injected noises, a constrained minimization problem is constructed by minimizing the sum of mean square errors of the local estimates while ensuring ({\epsilon}, {\delta})-differential privacy. Suffering from the non-convexity of the minimization problem, an approach of relaxation is proposed, which efficiently solves the minimization problem without sacrificing differential privacy level. Then, a differentially private distributed fusion estimation algorithm based on the covariance intersection approach is developed. Further, by introducing a feedback mechanism, the fusion estimation accuracy is enhanced on the premise of the same ({\epsilon}, {\delta})-differential privacy. Finally, an illustrative example is provided to demonstrate the effectiveness of the proposed algorithms, and the trade-off between differential privacy level and fusion estimation accuracy.

Paper number 35:
Title: Spatial Interpolation of Room Impulse Responses based on Deeper Physics-Informed Neural Networks with Residual Connections
Authors: Ken Kurata, Gen Sato, Izumi Tsunokuni, Yusuke Ikeda
Abstract: The room impulse response (RIR) characterizes sound propagation in a room from a loudspeaker to a microphone under the linear time-invariant assumption. Estimating RIRs from a limited number of measurement points is crucial for sound propagation analysis and visualization. Physics-informed neural networks (PINNs) have recently been introduced for accurate RIR estimation by embedding governing physical laws into deep learning models; however, the role of network depth has not been systematically investigated. In this study, we developed a deeper PINN architecture with residual connections and analyzed how network depth affects estimation performance. We further compared activation functions, including tanh and sinusoidal activations. Our results indicate that the residual PINN with sinusoidal activations achieves the highest accuracy for both interpolation and extrapolation of RIRs. Moreover, the proposed architecture enables stable training as the depth increases and yields notable improvements in estimating reflection components. These results provide practical guidelines for designing deep and stable PINNs for acoustic-inverse problems.

Paper number 36:
Title: Weak state synchronization of homogeneous multi-agent systems with adaptive protocols
Authors: Anton A. Stoorvogel, Ali Saberi, Zhenwei Liu, Tayaba Yeasmin
Abstract: In this paper, we study scale-free weak synchronization for multi-agent systems (MAS). In other words, we design a protocol for the agents without using any knowledge about the network. We do not even require knowledge about the connectivity of the network. Each protocol contains an adaptive parameter to tune the protocol automatically to the demands of the network.

Paper number 37:
Title: Confidence analysis-based hybrid heartbeat detection for ballistocardiogram using template matching and deep learning
Authors: Dongli Cai, Xihe Chen, Yaosheng Chen, Hong Xian, Baoxian Yu, Han Zhang
Abstract: Heartbeat interval can be detected from ballistocardiogram (BCG) signals in a non-contact manner. Conventional methods achieved heartbeat detection from different perspectives, where template matching (TM) and deep learning (DL) were based on the similarity of neighboring heartbeat episodes and robust spatio-temporal characteristics, respectively, and thus, performed varied from case to case. Inspired by the above facts, we propose confidence analysis-based hybrid heartbeat detection using both TM and DL, and further explore the advantages of both methods in various scenarios. To be specific, the confidence of the heartbeat detection results was evaluated by the consistency of signal morphology and the variability of the detected heartbeat intervals, which could be formulated by the averaged correlation between each heartbeat episode and the detected template and the normalized standard deviation among detected heartbeat intervals, respectively, where the results with higher confidence were remained. In order to validate the effectiveness of the proposed hybrid method, we conducted experiments using practical clinical BCG dataset with 34 subjects including 924,235 heartbeats. Numerical results showed that the proposed hybrid method achieved an average absolute interval error of 20.73 ms, yielding a reduction of 29.28 ms and 10.13 ms compared to solo TM and DL methods, respectively. Besides, case study showed the robustness of heartbeat detection of TM and DL to individual differences and signal quality, respectively, and in turn, validated that the hybrid method could benefit from the complementary advantages of both methods, which demonstrated the superiority of the proposed hybrid method in practical BCG monitoring scenarios.

Paper number 38:
Title: A Bezier Curve Based Approach to the Convexification of the AC Optimal Power Flow Problem
Authors: Carlos Arturo Saldarriaga-Cortes, Carlos Adrian Correa-Florez, Maximiliano Bueno-Lopez, Maria Victoria Gasca-Segura
Abstract: The Alternating Current Optimal Power Flow (ACOPF) problem remains one of the most fundamental yet computationally challenging tasks in power systems operation and planning due to its nonconvex, nonlinear, and multimodal nature. This paper proposes a convex reformulation of the AC power flow problem by introducing auxiliary variables to isolate nonlinear terms, applying logarithmic transformations to exploit product-sum properties, and approximating with Bezier curves using a novel convexifying butterfly shaped function. This model is intended for assessing and operating weak power systems that face challenges with reactive power supply and overall network robustness. Its formulation closely mirrors the AC formulation, particularly regarding active and reactive power dispatch and network voltage levels. The proposed model achieves convergence on large test systems (e.g., IEEE 118 bus) in seconds and is validated against exact AC solutions. This convex formulation stands out not only for its mathematical transparency and intuitive structure but also for its ease of validation and implementation, making it an accessible and reliable tool for researchers and system operators for energy planning. The numerical analysis conducted on the IEEE 118 bus system yielded average percentage errors in the state variables specifically, the magnitudes and angles of nodal voltages of just 0.0008 percentage and 0.014 degree, respectively, when compared with the precise AC formulation. These results underscore the high accuracy and reliability of the proposed methodology.

Paper number 39:
Title: Masked Sequence Autoencoding for Enhanced Defect Visualization in Active Infrared Thermography
Authors: Mohammed Salah, Eman Ouda, Stefano Sfarra, Davor Svetinovic, Yusra Abdulrahman
Abstract: Active infrared thermography (AIRT) became a crucial tool in aerospace non-destructive testing (NDT), enabling the detection of hidden defects and anomalies in materials by capturing thermal responses over time. In AIRT, autoencoders are widely used to enhance defect detection by reducing the dimensionality of thermal data and improving the signal-to-noise ratio. However, traditional AIRT autoencoders often struggle to disentangle subtle defect features from dominant background responses, leading to suboptimal defect analysis under varying material and inspection conditions. To overcome this challenge, this work proposes a Masked CNN-Attention Autoencoder (AIRT-Masked-CAAE) that integrates convolutional feature extraction with attention mechanisms to capture both local thermal patterns and global contextual dependencies. The AIRT-Masked-CAAE introduces a masked sequence autoencoding strategy, where the network learns to infer missing thermal responses from surrounding contextual cues, while suppressing background redundancy. In addition, the proposed masked sequence autoencoding approach enables training on only a subset of the thermal sequence, while providing generalizable latent representations and reducing training time by a factor of 30. The AIRT-Masked-CAAE framework was evaluated using specimens made of PVC, CFRP, and PLA. The results demonstrate that the AIRT-Masked-CAAE surpasses state-of-the-art AIRT autoencoders in terms of contrast, signal-to-noise ratio (SNR), and metrics based on neural networks.

Paper number 40:
Title: Flexible Intelligent Metasurface for Downlink Communications under Statistical CSI
Authors: Vaibhav Kumar, Anastasios Papazafeiropoulos, Pandelis Kourtessis, John Senior, Marwa Chafii, Dimitra I. Kaklamani, Iakovos S. Venieris
Abstract: Flexible intelligent metasurface (FIM) is a recently developed, groundbreaking hardware technology with promising potential for 6G wireless systems. Unlike conventional rigid antenna array (RAA)-based transmitters, FIM-assisted transmitters can dynamically alter their physical surface through morphing, offering new degrees of freedom to enhance system performance. In this letter, we depart from prior works that rely on instantaneous channel state information (CSI) and instead address the problem of average sum spectral efficiency maximization under statistical CSI in a FIM-assisted downlink multiuser multiple-input single-output setting. To this end, we first derive the spatial correlation matrix for the FIM-aided transmitter and then propose an iterative FIM optimization algorithm based on the gradient projection method. Simulation results show that with statistical CSI, the FIM-aided system provides a significant performance gain over its RAA-based counterpart in scenarios with strong spatial channel correlation, whereas the gain diminishes when the channels are weakly correlated.

Paper number 41:
Title: Global Frequency Reference Tracking as an Oscillation Suppression Mechanism in VSM Primary Control: A Coupled-Oscillator Study
Authors: Taha Saeed Khan
Abstract: Synchronization in power systems is traditionally achieved through physical network coupling, whereby inverter-based resources (IBRs) and synchronous machines converge to a common frequency via oscillatory swing dynamics. In conventional operation, secondary control acts on a slow time scale and is typically engaged only after the primary dynamics have largely settled. As a result, in the absence of an explicit global reference, disturbances can induce prolonged transients and large phase excursions. This work considers a setting in which the total active power balance is known and maintained at all times, and proposes a control architecture for virtual synchronous machine (VSM) based inverters in which all units track a broadcast global frequency reference. Under this assumption, synchronization is transformed from a mutual oscillator locking problem into a reference tracking problem. Using a second order swing network model, we show that embedding a simple proportional integral (PI) frequency controller can significantly improves transient behavior. A washout mechanism ensures that the additional control action vanishes in steady state, thereby preserving network determined power sharing. Simulations on a three oscillator network demonstrate reduced frequency overshoot, elimination of underdamped oscillations, and lower angular stress compared to conventional open loop synchronization, highlighting the effectiveness of a global frequency reference as a coordination mechanism for grid-forming inverter networks.

Paper number 42:
Title: Real-Time Forward Kinematics and Jacobians for Control of an MRI-Guided Magnetically Actuated Robotic Catheter
Authors: Ran Hao, Yuttana Itsarachaiyot, Yen-Chun Chen, M. Cenk Çavuşoğlu
Abstract: This paper presents a forward kinematics and analytical Jacobian computation approach for real-time control of a novel magnetic resonance imaging (MRI)-actuated robotic catheter. The MRI-actuated robotic catheter is modeled as a series of rigid and flexible segments and actuated by magnetic torques generated on a set of current-carrying microcoils embedded on the catheter body by the magnetic field of the MRI scanner. First, a real-time forward kinematic modeling approach of the robotic catheter employing the static Cosserat-rod theory is presented. Second, the analytical calculation approach of the forward kinematic Jacobians of the proposed forward kinematic model is presented. The accuracy, reproducibility, and computational efficiency of the proposed methods are evaluated using a robotic catheter prototype with a single coil set, where catheter tip trajectories collected by a catadioptric stereo camera tracking system are validated using the desired tip trajectories. Experimental results demonstrate that the proposed method can successfully control the catheter in an open loop to perform complex trajectories with real-time computational efficiency, paving the way for accurate closed-loop control with real-time MR-imaging feedback.

Paper number 43:
Title: Unscented and Higher-Order Linear Covariance Fidelity Checks and Measures of Non-Gaussianity
Authors: Jackson Kulik, Braden Hastings, Keith A. LeGrand
Abstract: Linear covariance (LinCov) techniques have gained widespread traction in the modeling of uncertainty, including in the preliminary study of spacecraft navigation performance. While LinCov methods offer improved computational efficiency compared to Monte Carlo based uncertainty analysis, they inherently rely on linearization approximations. Understanding the fidelity of these approximations and identifying when they are deficient is critically important for spacecraft navigation and mission planning, especially when dealing with highly nonlinear systems and large state uncertainties. This work presents a number of computational techniques for assessing linear covariance performance. These new LinCov fidelity measures are formulated using higher-order statistics, constrained optimization, and the unscented transform.

Paper number 44:
Title: Breaking Symmetry-Induced Degeneracy in Multi-Agent Ergodic Coverage via Stochastic Spectral Control
Authors: Kooktae Lee, Julian Martinez
Abstract: Multi-agent ergodic coverage via Spectral Multiscale Coverage (SMC) provides a principled framework for driving a team of agents so that their collective time-averaged trajectories match a prescribed spatial distribution. While classical SMC has demonstrated empirical success, it can suffer from gradient cancellation, particularly when agents are initialized near symmetry points of the target distribution, leading to undesirable behaviors such as stalling or motion constrained along symmetry axes. In this work, we rigorously characterize the initial conditions and symmetry-induced invariant manifolds that give rise to such directional degeneracy in first-order agent dynamics. To address this, we introduce a stochastic perturbation combined with a contraction term and prove that the resulting dynamics ensure almost-sure escape from zero-gradient manifolds while maintaining mean-square boundedness of agent trajectories. Simulations on symmetric multi-modal reference distributions demonstrate that the proposed stochastic SMC effectively mitigates transient stalling and axis-constrained motion, while ensuring that all agent trajectories remain bounded within the domain.

Paper number 45:
Title: Learning-based data-enabled economic predictive control with convex optimization for nonlinear systems
Authors: Mingxue Yan, Xuewen Zhang, Kaixiang Zhang, Zhaojian Li, Xunyuan Yin
Abstract: In this article, we propose a data-enabled economic predictive control method for a class of nonlinear systems, which aims to optimize the economic operational performance while handling hard constraints on the system outputs. Two lifting functions are constructed via training neural networks, which generate mapped input and mapped output in a higher-dimensional space, where the nonlinear economic cost function can be approximated using a quadratic function of the mapped variables. The data-enabled predictive control framework is extended to address nonlinear dynamics by using the mapped input and the mapped output that belong to a virtual linear representation, which serves as an approximation of the original nonlinear system. Additionally, we reconstruct the system output variables from the mapped output, on which hard output constraints are imposed. The online control problem is formulated as a convex optimization problem, despite the nonlinearity of the system dynamics and the original economic cost function. Theoretical analysis is presented to justify the suitability of the proposed method for nonlinear systems. We evaluate the proposed method through two large-scale industrial case studies: (i) a biological water treatment process, and (ii) a solvent-based shipboard post-combustion carbon capture process. These studies demonstrate its effectiveness and advantages.

Paper number 46:
Title: EIR: Enhanced Image Representations for Medical Report Generation
Authors: Qiang Sun, Zongcheng Ji, Yinlong Xiao, Peng Chang, Jun Yu
Abstract: Generating medical reports from chest X-ray images is a critical and time-consuming task for radiologists, especially in emergencies. To alleviate the stress on radiologists and reduce the risk of misdiagnosis, numerous research efforts have been dedicated to automatic medical report generation in recent years. Most recent studies have developed methods that represent images by utilizing various medical metadata, such as the clinical document history of the current patient and the medical graphs constructed from retrieved reports of other similar patients. However, all existing methods integrate additional metadata representations with visual representations through a simple "Add and LayerNorm" operation, which suffers from the information asymmetry problem due to the distinct distributions between them. In addition, chest X-ray images are usually represented using pre-trained models based on natural domain images, which exhibit an obvious domain gap between general and medical domain images. To this end, we propose a novel approach called Enhanced Image Representations (EIR) for generating accurate chest X-ray reports. We utilize cross-modal transformers to fuse metadata representations with image representations, thereby effectively addressing the information asymmetry problem between them, and we leverage medical domain pre-trained models to encode medical images, effectively bridging the domain gap for image representation. Experimental results on the widely used MIMIC and Open-I datasets demonstrate the effectiveness of our proposed method.

Paper number 47:
Title: Multi-objective control strategy of Electro-Mechanical Transmission Based on Driving Pattern Division
Authors: Yanbo Li, Jinsong Li, Zongjue Liu, Riming Xu
Abstract: Based on the driving requirement and power balance of heavy-duty vehicle equipped with Electro-Mechanical Transmission (EMT), optimization goals under different driving patterns are put forward. The optimization objectives are changed into a comprehensive optimization target based on the method of weighting, which is calculated by using analytic hierarchy process (AHP) under different working conditions. According to theory of Dynamic Programming (DP), a multi-object control strategy of DP under different driving patterns is proposed. This strategy is verified by simulation and contrasted with rule strategy, the results show that comprehensive performance is significantly enhanced, and the fuel economy is highly improved especially.

Paper number 48:
Title: The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design
Authors: Zelin Zang, Yuhang Song, Bingo Wing-Kuen Ling, Aili Wang, Fuji Yang
Abstract: This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers.

Paper number 49:
Title: A Learning-Driven Stochastic Hybrid System Framework for Detecting Unobservable Contingencies in Power Systems
Authors: Hamid Varmazyari, Masoud H. Nazari
Abstract: This paper presents a new learning based Stochastic Hybrid System (LSHS) framework designed for the detection and classification of contingencies in modern power systems. Unlike conventional monitoring schemes, the proposed approach is capable of identifying unobservable events that remain hidden from standard sensing infrastructures, such as undetected protection system malfunctions. The framework operates by analyzing deviations in system outputs and behaviors, which are then categorized into three groups: physical, control, and measurement contingencies based on their impact on the SHS model. The SHS model integrates both system dynamics and observer-driven state estimation error dynamics. Within this architecture, machine learning classifiers are employed to achieve rapid and accurate categorization of contingencies. The effectiveness of the method is demonstrated through simulations on the IEEE 5-bus and 30-bus systems, where results indicate substantial improvements in both detection speed and accuracy compared with existing approaches.

Paper number 50:
Title: Ultra-Massive MIMO with Orthogonal Chirp Division Multiplexing for Near-Field Sensing and Communication Integration
Authors: Ziwei Wan, Zhen Gao, Fabien Heliot, Qu Luo, Pei Xiao, Haiyang Zhang, Christos Masouros, Yonina C. Eldar, Sheng Chen
Abstract: This paper integrates the emerging ultra-massive multiple-input multiple-output (UM-MIMO) technique with orthogonal chirp division multiplexing (OCDM) waveform to tackle the challenging near-field integrated sensing and communication (ISAC) problem. Specifically, we conceive a comprehensive ISAC architecture, where an UM-MIMO base station adopts OCDM waveform for communications and a co-located sensing receiver adopts the frequency-modulated continuous wave (FMCW) detection principle to simplify the associated hardware. For sensing tasks, several OCDM subcarriers, namely, dedicated sensing subcarriers (DSSs), are each transmitted through a dedicated sensing antenna (DSA) within the transmit antenna array. By judiciously designing the DSS selection scheme and optimizing receiver parameters, the FMCW-based sensing receiver can decouple the echo signals from different DSAs with significantly reduced hardware complexity. This setup enables the estimation of ranges and velocities of near-field targets in an antenna-pairwise manner. Moreover, by leveraging the spatial diversity of UM-MIMO, we introduce the concept of virtual bistatic sensing (VIBS), which incorporates the estimates from multiple antenna pairs to achieve high-accuracy target positioning and three-dimensional velocity measurement. The VIBS paradigm is immune to hostile channel environments characterized by spatial non-stationarity and uncorrelated multipath environment. Furthermore, the channel estimation of UM-MIMO OCDM systems enhanced by the sensing results is investigated. Simulation results demonstrate that the proposed ISAC scheme enhances sensing accuracy, and also benefits communication performance.

Paper number 51:
Title: Flow2GAN: Hybrid Flow Matching and GAN with Multi-Resolution Network for Few-step High-Fidelity Audio Generation
Authors: Zengwei Yao, Wei Kang, Han Zhu, Liyong Guo, Lingxuan Ye, Fangjun Kuang, Weiji Zhuang, Zhaoqing Li, Zhifeng Han, Long Lin, Daniel Povey
Abstract: Existing dominant methods for audio generation include Generative Adversarial Networks (GANs) and diffusion-based methods like Flow Matching. GANs suffer from slow convergence and potential mode collapse during training, while diffusion methods require multi-step inference that introduces considerable computational overhead. In this work, we introduce Flow2GAN, a two-stage framework that combines Flow Matching training for learning generative capabilities with GAN fine-tuning for efficient few-step inference. Specifically, given audio's unique properties, we first improve Flow Matching for audio modeling through: 1) reformulating the objective as endpoint estimation, avoiding velocity estimation difficulties when involving empty regions; 2) applying spectral energy-based loss scaling to emphasize perceptually salient quieter regions. Building on these Flow Matching adaptations, we demonstrate that a further stage of lightweight GAN fine-tuning enables us to obtain one-step generator that produces high-quality audio. In addition, we develop a multi-branch network architecture that processes Fourier coefficients at different time-frequency resolutions, which improves the modeling capabilities compared to prior single-resolution designs. Experimental results indicate that our Flow2GAN delivers high-fidelity audio generation from Mel-spectrograms or discrete audio tokens, achieving better quality-efficiency trade-offs than existing state-of-the-art GAN-based and Flow Matching-based methods. Online demo samples are available at this https URL, and the source code is released at this https URL.

Paper number 52:
Title: Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning
Authors: Mahdi Kchaou, Francesco Contino, Diederik Coppitters
Abstract: Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways.

Paper number 53:
Title: Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications
Authors: Haixiao Gao, Mengying Sun, Ruichen Zhang, Yanhan Wang, Xiaodong Xu, Nan Ma, Dusit Niyato, Ping Zhang
Abstract: Semantic communications (SemCom), as one of the key technologies for 6G, is shifting networks from bit transmission to semantic information exchange. On this basis, introducing agentic artificial intelligence (AI) with perception, memory, reasoning, and action capabilities provides a practicable path to intelligent communications. This paper provides a systematic exposition of how agentic AI empowers SemCom from the perspectives of research foundations, system architecture, and application scenarios. We first provide a comprehensive review of existing studies by agent types, covering embedded agents, large language model (LLM)/large vision model (LVM) agents, and reinforcement learning (RL) agents. Additionally, we propose a unified agentic AI-enhanced SemCom framework covering the application layer, the semantic layer, and the cloud-edge collaboration layer, forming a closed loop from intent to encoding to transmission to decoding to action to evaluation. We also present several typical scenarios, including multi-vehicle collaborative perception, multi-robot cooperative rescue, and agentic operations for intellicise (intelligent and concise) networks. Furthermore, we introduce an agentic knowledge base (KB)-based joint source-channel coding case study, AKB-JSCC, where the source KB and channel KB are built by LLM/LVM agents and RL agents, respectively. Experimental results show that AKB-JSCC achieves higher information reconstruction quality under different channel conditions. Finally, we discuss future evolution and research directions, providing a reference for portable, verifiable, and controllable research and deployment of agentic SemCom.

Paper number 54:
Title: Single Channel Blind Dereverberation of Speech Signals
Authors: Dhruv Nigam
Abstract: Dereverberation of recorded speech signals is one of the most pertinent problems in speech processing. In the present work, the objective is to understand and implement dereverberation techniques that aim at enhancing the magnitude spectrogram of reverberant speech signals to remove the reverberant effects introduced. An approach to estimate a clean speech spectrogram from the reverberant speech spectrogram is proposed. This is achieved through non-negative matrix factor deconvolution(NMFD). Further, this approach is extended using the NMF representation for speech magnitude spectrograms. To exploit temporal dependencies, a convolutive NMF-based representation and a frame-stacked model are incorporated into the NMFD framework for speech. A novel approach for dereverberation by applying NMFD to the activation matrix of the reverberated magnitude spectrogram is also proposed. Finally, a comparative analysis of the performance of the listed techniques, using sentence recordings from the TIMIT database and recorded room impulse responses from the Reverb 2014 challenge, is presented based on two key objective measures - PESQ and Cepstral Distortion.\\ Although we were qualitatively able to verify the claims made in literature regarding these techniques, exact results could not be matched. The novel approach, as it is suggested, provides improvement in quantitative metrics, but is not consistent

Paper number 55:
Title: On Signal Peak Power Constraint of Over-the-Air Federated Learning
Authors: Lorenz Bielefeld, Paul Zheng, Oner Hanay, Yao Zhu, Yulin Hu, Anke Schmeink
Abstract: Federated learning (FL) has been considered a promising privacy preserving distributed edge learning framework. Over-the-air computation (AirComp) technique leveraging analog transmission enables the aggregation of local updates directly over-the-air by exploiting the superposition properties of wireless multiple-access channel, thereby drastically reducing the communication bottleneck issues of FL compared with digital transmission schemes. This work points out that existing AirComp-FL overlooks a key practical constraint, the instantaneous peak-power constraints imposed by the non-linearity of radiofrequency power amplifiers. We present and analyze the effect of the classic method to deal with this issue, amplitude clipping combined with filtering. We investigate the effect of instantaneous peak-power constraints in AirComp-FL for both single-carrier and multi-carrier orthogonal frequency-division multiplexing (OFDM) systems. We highlight the specificity of AirComp-FL: the samples depend on the gradient value distribution, leading to a higher peak-to-average power ratio (PAPR) than that observed for uniformly distributed signals. Simulation results demonstrate that, in practical settings, the instantaneous transmit power regularly exceeds the power-amplifier limit; however, by applying clipping and filtering, the FL performance can be degraded. The degradation becomes pronounced especially in multi-carrier OFDM systems due to the in-band distortions caused by clipping and filtering.

Paper number 56:
Title: Control Co-design of systems with parabolic partial differential equation dynamics
Authors: Antika Yadav, Prasad Vilas Chanekar
Abstract: In this paper we study the control co-design (CCD) synthesis problem for a class of systems with parabolic partial differential equation (PDE) dynamics. We formulate CCD problem and finally derive an approximate CCD problem with matrix algebraic constraint. We then solve this approximate problem with gradient-based method and prove that the optimal solution also stabilizes the PDE system. We justify approach through numerical examples.

Paper number 57:
Title: NashOpt - A Python Library for Computing Generalized Nash Equilibria
Authors: Alberto Bemporad
Abstract: NashOpt is an open-source Python library for computing and designing generalized Nash equilibria (GNEs) in noncooperative games with shared constraints and real-valued decision variables. The library exploits the joint Karush-Kuhn-Tucker (KKT) conditions of all players to handle both general nonlinear GNEs and linear-quadratic games, including their variational versions. Nonlinear games are solved via nonlinear least-squares formulations, relying on JAX for automatic differentiation. Linear-quadratic GNEs are reformulated as mixed-integer linear programs, enabling efficient computation of multiple equilibria. The framework also supports inverse-game and Stackelberg game-design problems. The capabilities of NashOpt are demonstrated through several examples, including noncooperative game-theoretic control problems of linear quadratic regulation and model predictive control. The library is available at this https URL

Paper number 58:
Title: A Review of Community-Centric Power Systems Resilience Assessment and Enhancement Strategies
Authors: Masoud H. Nazaria, Hamid Varmazyari, Antar Kumar Biswas, Umit Cali, Hollis Belnap, Masood Parvania
Abstract: This paper presents a comprehensive review of resilience metrics, covering both engineering-based measures, such as fragility-curve modeling, and data-driven approaches, including triangular and trapezoidal representations. Next, the paper examines the interdependencies between power systems resilience and community resilience, addressing socioeconomic and behavioral dimensions, infrastructure interconnections, and the emerging role of resilience hubs. The review then synthesizes state-of-the-art strategies for enhancing power system resilience, including network hardening, resource allocation, optimal scheduling, and reconfiguration techniques. Special emphasis is placed on the integration of Artificial Intelligence (AI) methods and the techno-legal dimensions of resilient power systems and communities. In particular, the paper contrasts the regulatory landscapes of the European Union and the United States, highlighting key similarities and distinctions. By analyzing methodologies for mitigating the impacts of high-impact, low-probability (HILP) events, the review identifies critical research gaps and outlines promising directions for future investigation.

Paper number 59:
Title: An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator
Authors: Sheng Lu, Qianhou Qu, Sungyong Jung, Qilian Liang, Chenyun Pan
Abstract: Stochastic computing (SC) offers significant reductions in hardware complexity for traditional convolutional neural networks (CNNs), but stochastic computing neural networks (SCNNs) still suffer from high resource usage due to components such as stochastic number generators (SNGs) and accumulative parallel counters (APCs), which limit performance. This paper introduces a novel SCNN architecture based on reconfigurable field-effect transistors (RFETs), whose device-level reconfigurability enables the design of highly efficient and compact SNGs, APCs, and other core modules. A dedicated SCNN accelerator architecture is also developed for system-level simulation. Using publicly available open-source standard cell libraries, experimental results show that the proposed RFET-based SCNN accelerator achieves substantial reductions in area, latency, and energy consumption compared to a FinFET-based design at the same technology node.

Paper number 60:
Title: AudioGAN: A Compact and Efficient Framework for Real-Time High-Fidelity Text-to-Audio Generation
Authors: HaeChun Chung
Abstract: Text-to-audio (TTA) generation can significantly benefit the media industry by reducing production costs and enhancing work efficiency. However, most current TTA models (primarily diffusion-based) suffer from slow inference speeds and high computational costs. In this paper, we introduce AudioGAN, the first successful Generative Adversarial Networks (GANs)-based TTA framework that generates audio in a single pass, thereby reducing model complexity and inference time. To overcome the inherent difficulties in training GANs, we integrate multiple ,contrastive losses and propose innovative components Single-Double-Triple (SDT) Attention and Time-Frequency Cross-Attention (TF-CA). Extensive experiments on the AudioCaps dataset demonstrate that AudioGAN achieves state-of-the-art performance while using 90% fewer parameters and running 20 times faster, synthesizing audio in under one second. These results establish AudioGAN as a practical and powerful solution for real-time TTA.

Paper number 61:
Title: Characterizing Motion Encoding in Video Diffusion Timesteps
Authors: Vatsal Baherwani, Yixuan Ren, Abhinav Shrivastava
Abstract: Text-to-video diffusion models synthesize temporal motion and spatial appearance through iterative denoising, yet how motion is encoded across timesteps remains poorly understood. Practitioners often exploit the empirical heuristic that early timesteps mainly shape motion and layout while later ones refine appearance, but this behavior has not been systematically characterized. In this work, we proxy motion encoding in video diffusion timesteps by the trade-off between appearance editing and motion preservation induced when injecting new conditions over specified timestep ranges, and characterize this proxy through a large-scale quantitative study. This protocol allows us to factor motion from appearance by quantitatively mapping how they compete along the denoising trajectory. Across diverse architectures, we consistently identify an early, motion-dominant regime and a later, appearance-dominant regime, yielding an operational motion-appearance boundary in timestep space. Building on this characterization, we simplify current one-shot motion customization paradigm by restricting training and inference to the motion-dominant regime, achieving strong motion transfer without auxiliary debiasing modules or specialized objectives. Our analysis turns a widely used heuristic into a spatiotemporal disentanglement principle, and our timestep-constrained recipe can serve as ready integration into existing motion transfer and editing methods.

Paper number 62:
Title: Joint UAV-UGV Positioning and Trajectory Planning via Meta A3C for Reliable Emergency Communications
Authors: Ndagijimana Cyprien, Mehdi Sookhak, Hosein Zarini, Chandra N Sekharan, Mohammed Atiquzzaman
Abstract: Joint deployment of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) has been shown to be an effective method to establish communications in areas affected by disasters. However, ensuring good Quality of Services (QoS) while using as few UAVs as possible also requires optimal positioning and trajectory planning for UAVs and UGVs. This paper proposes a joint UAV-UGV-based positioning and trajectory planning framework for UAVs and UGVs deployment that guarantees optimal QoS for ground users. To model the UGVs' mobility, we introduce a road graph, which directs their movement along valid road segments and adheres to the road network constraints. To solve the sum rate optimization problem, we reformulate the problem as a Markov Decision Process (MDP) and propose a novel asynchronous Advantage Actor Critic (A3C) incorporated with meta-learning for rapid adaptation to new environments and dynamic conditions. Numerical results demonstrate that our proposed Meta-A3C approach outperforms A3C and DDPG, delivering 13.1\% higher throughput and 49\% faster execution while meeting the QoS requirements.

Paper number 63:
Title: Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening
Authors: Shaurya Gaur, Michel Vitale, Alessa Hering, Johan Kwisthout, Colin Jacobs, Lena Philipp, Fennie van der Graaf
Abstract: Lung cancer is the leading cause of cancer-related mortality in adults worldwide. Screening high-risk individuals with annual low-dose CT (LDCT) can support earlier detection and reduce deaths, but widespread implementation may strain the already limited radiology workforce. AI models have shown potential in estimating lung cancer risk from LDCT scans. However, high-risk populations for lung cancer are diverse, and these models' performance across demographic groups remains an open question. In this study, we drew on the considerations on confounding factors and ethically significant biases outlined in the JustEFAB framework to evaluate potential performance disparities and fairness in two deep learning risk estimation models for lung cancer screening: the Sybil lung cancer risk model and the Venkadesh21 nodule risk estimator. We also examined disparities in the PanCan2b logistic regression model recommended in the British Thoracic Society nodule management guideline. Both deep learning models were trained on data from the US-based National Lung Screening Trial (NLST), and assessed on a held-out NLST validation set. We evaluated AUROC, sensitivity, and specificity across demographic subgroups, and explored potential confounding from clinical risk factors. We observed a statistically significant AUROC difference in Sybil's performance between women (0.88, 95% CI: 0.86, 0.90) and men (0.81, 95% CI: 0.78, 0.84, p < .001). At 90% specificity, Venkadesh21 showed lower sensitivity for Black (0.39, 95% CI: 0.23, 0.59) than White participants (0.69, 95% CI: 0.65, 0.73). These differences were not explained by available clinical confounders and thus may be classified as unfair biases according to JustEFAB. Our findings highlight the importance of improving and monitoring model performance across underrepresented subgroups, and further research on algorithmic fairness, in lung cancer screening.

Paper number 64:
Title: Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware
Authors: Vesal Ahsani, Babak Hossein Khalaj
Abstract: In-cabin Driver Monitoring Systems (DMS) must recognize distraction- and drowsiness-related behaviors with low latency under strict constraints on compute, power, and cost. We present a single-camera in-cabin driver behavior recognition system designed for deployment on two low-cost edge platforms: Raspberry Pi 5 (CPU-only) and Google Coral Edge TPU. The proposed pipeline combines (i) a compact per-frame vision model, (ii) a confounder-aware label design to reduce visually similar false positives, and (iii) a temporal decision head that triggers alerts only when predictions are both confident and sustained. The system covers 17 behavior classes, including multiple phone-use modes, eating/drinking, smoking, reaching behind, gaze/attention shifts, passenger interaction, grooming, control-panel interaction, yawning, and eyes-closed sleep. Training and evaluation use licensed datasets spanning diverse drivers, vehicles, and lighting conditions (details in Section 6), and we further validate runtime behavior in real in-vehicle tests. The optimized deployments achieve about 16 FPS on Raspberry Pi 5 with INT8 inference (per-frame latency under 60 ms) and about 25 FPS on Coral Edge TPU, enabling real-time monitoring and stable alert generation on inexpensive hardware. Finally, we discuss how reliable in-cabin human-state perception can serve as an upstream input for human-centered vehicle intelligence, including emerging agentic vehicle concepts.

Paper number 65:
Title: A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow
Authors: Mohannad Alkhraijah, Devon Sigler, Daniel K. Molzahn
Abstract: Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average.

Paper number 66:
Title: JParc: Joint cortical surface parcellation with registration
Authors: Jian Li, Karthik Gopinath, Brian L. Edlow, Adrian V. Dalca, Bruce Fischl
Abstract: Cortical surface parcellation is a fundamental task in both basic neuroscience research and clinical applications, enabling more accurate mapping of brain regions. Model-based and learning-based approaches for automated parcellation alleviate the need for manual labeling. Despite the advancement in parcellation performance, learning-based methods shift away from registration and atlas propagation without exploring the reason for the improvement compared to traditional methods. In this study, we present JParc, a joint cortical registration and parcellation framework, that outperforms existing state-of-the-art parcellation methods. In rigorous experiments, we demonstrate that the enhanced performance of JParc is primarily attributable to accurate cortical registration and a learned parcellation atlas. By leveraging a shallow subnetwork to fine-tune the propagated atlas labels, JParc achieves a Dice score greater than 90% on the Mindboggle dataset, using only basic geometric features (sulcal depth, curvature) that describe cortical folding patterns. The superior accuracy of JParc can significantly increase the statistical power in brain mapping studies as well as support applications in surgical planning and many other downstream neuroscientific and clinical tasks.

Paper number 67:
Title: NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization
Authors: Edwin Vargas
Abstract: Ensuring the authenticity and ownership of digital images is increasingly challenging as modern editing tools enable highly realistic forgeries. Existing image protection systems mainly rely on digital watermarking, which is susceptible to sophisticated digital attacks. To address this limitation, we propose a hybrid optical-digital framework that incorporates physical authentication cues during image formation and preserves them through a learned reconstruction process. At the optical level, a phase mask in the camera aperture produces a Null-space Optical Watermark (NOWA) that lies in the Null Space of the imaging operator and therefore remains invisible in the captured image. Then, a Null-Space Network (NSN) performs measurement-consistent reconstruction that delivers high-quality protected images while preserving the NOWA signature. The proposed design enables tamper localization by projecting the image onto the camera's null space and detecting pixel-level inconsistencies. Our design preserves perceptual quality, resists common degradations such as compression, and establishes a structural security asymmetry: without access to the optical or NSN parameters, adversaries cannot forge the NOWA signature. Experiments with simulations and a prototype camera demonstrate competitive performance in terms of image quality preservation, and tamper localization accuracy compared to state-of-the-art digital watermarking and learning-based authentication methods.

Paper number 68:
Title: Experimental Multiport-Network Parameter Estimation for a Dynamic Metasurface Antenna
Authors: Jean Tapie, Philipp del Hougne
Abstract: Most use cases of reconfigurable antennas require an accurate forward model mapping configuration to radiated field (and reflections at feeds). Emerging dynamic metasurface antennas (DMAs) confront the conventional approach of extracting such a model from a numerical simulation with multiple challenges. First, the cost of accurately simulating an intricate and electrically large DMA architecture might be prohibitive. Second, the model-reality mismatch due to fabrication inaccuracies might be substantial, especially at higher frequencies and for DMA architectures leveraging strong inter-element mutual coupling (MC) to maximize their tunability. These considerations motivate an experimental parameter estimation for DMA forward models. The main challenge lies in the forward model's non-linearity due to inter-element MC. Multiport network theory (MNT) can accurately capture MC but the MC parameters cannot be measured directly. In this article, we demonstrate the experimental estimation of a high-accuracy proxy MNT model for a 19-GHz DMA with 7 feeds and 96 elements, where all feeds and elements are strongly coupled via a chaotic cavity. For a given DMA configuration and excitation, our proxy MNT model predicts the reflected field at the feeds and the radiated field with accuracies of 40.3 dB and 37.7 dB, respectively. A simpler, MC-unaware benchmark model only achieves 2.6 dB and 3.3 dB, respectively. We systematically examine the influence of the number of feeds and measured DMA configurations on the model accuracy, motivating the inclusion of "auxiliary calibration feeds" to facilitate the parameter estimation when the intended DMA operation is limited to a single feed. Finally, we measure DMA configurations optimized based on our proxy MNT model.

Paper number 69:
Title: Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback
Authors: Tomas Ortega, Chun-Yin Huang, Xiaoxiao Li, Hamid Jafarkhani
Abstract: Distributed learning, particularly Federated Learning (FL), faces a significant bottleneck in the communication cost, particularly the uplink transmission of client-to-server updates, which is often constrained by asymmetric bandwidth limits at the edge. Biased compression techniques are effective in practice, but require error feedback mechanisms to provide theoretical guarantees and to ensure convergence when compression is aggressive. Standard error feedback, however, relies on client-specific control variates, which violates user privacy and is incompatible with stateless clients common in large-scale FL. This paper proposes two novel frameworks that enable biased compression without client-side state or control variates. The first, Compressed Aggregate Feedback (CAFe), uses the globally aggregated update from the previous round as a shared control variate for all clients. The second, Server-Guided Compressed Aggregate Feedback (CAFe-S), extends this idea to scenarios where the server possesses a small private dataset; it generates a server-guided candidate update to be used as a more accurate predictor. We consider Distributed Gradient Descent (DGD) as a representative algorithm and analytically prove CAFe's superiority to Distributed Compressed Gradient Descent (DCGD) with biased compression in the non-convex regime with bounded gradient dissimilarity. We further prove that CAFe-S converges to a stationary point, with a rate that improves as the server's data become more representative. Experimental results in FL scenarios validate the superiority of our approaches over existing compression schemes.

Paper number 70:
Title: Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors
Authors: Antar Kumar Biswas, Masoud H. Nazari
Abstract: This paper presents a novel learning-based framework for predicting power outages caused by extreme events. The proposed approach specifically targets low-probability, high-consequence outage scenarios and leverages a comprehensive set of features derived from publicly available data sources. We integrate EAGLE-I outage records (2014-2024) with weather, socio-economic, infrastructure, and seasonal event data. Incorporating social and demographic indicators reveals underlying patterns of community vulnerability and provides a clearer understanding of outage risk during extreme conditions. Four machine learning models (Random Forest (RF), Support Vector Machine (SVM), Adaptive Boosting (AdaBoost), and Long Short-Term Memory (LSTM)) are evaluated. Experimental validation is performed on a large-scale dataset covering counties in the lower peninsula of Michigan. Among all models tested, the LSTM network achieves the lowest prediction error. Additionally, the results demonstrate that stronger economic conditions and more developed infrastructure are associated with lower outage occurrence.

Paper number 71:
Title: Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning
Authors: Youssef Megahed, Robin Ducharme, Inok Lee, Inbal Willner, Olivier X. Miguel, Kevin Dick, Adrian D. C. Chan, Mark Walker, Steven Hawken
Abstract: Cystic hygroma is a high-risk prenatal ultrasound finding that portends high rates of chromosomal abnormalities, structural malformations, and adverse pregnancy outcomes. Automated detection can increase reproducibility and support scalable early screening programs, but supervised deep learning methods are limited by small labelled datasets. This study assesses whether ultrasound-specific self-supervised pretraining can facilitate accurate, robust deep learning detection of cystic hygroma in first-trimester ultrasound images. We fine-tuned the Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), pretrained on over 370,000 unlabelled ultrasound images, for binary classification of normal controls and cystic hygroma cases used in this study. Performance was evaluated on the same curated ultrasound dataset, preprocessing pipeline, and 4-fold cross-validation protocol as for the DenseNet-169 baseline, using accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (ROC-AUC). Model interpretability was analyzed qualitatively using Score-CAM visualizations. USF-MAE outperformed the DenseNet-169 baseline on all evaluation metrics. The proposed model yielded a mean accuracy of 0.96, sensitivity of 0.94, specificity of 0.98, and ROC-AUC of 0.98 compared to 0.93, 0.92, 0.94, and 0.94 for the DenseNet-169 baseline, respectively. Qualitative Score-CAM visualizations of model predictions demonstrated clinical relevance by highlighting expected regions in the fetal neck for both positive and negative cases. Paired statistical analysis using a Wilcoxon signed-rank test confirmed that performance improvements achieved by USF-MAE were statistically significant (p = 0.0057).

Paper number 72:
Title: Active Constraint Learning in High Dimensions from Demonstrations
Authors: Zheng Qiu, Chih-Yuan Chiu, Glen Chou
Abstract: We present an iterative active constraint learning (ACL) algorithm, within the learning from demonstrations (LfD) paradigm, which intelligently solicits informative demonstration trajectories for inferring an unknown constraint in the demonstrator's environment. Our approach iteratively trains a Gaussian process (GP) on the available demonstration dataset to represent the unknown constraints, uses the resulting GP posterior to query start/goal states, and generates informative demonstrations which are added to the dataset. Across simulation and hardware experiments using high-dimensional nonlinear dynamics and unknown nonlinear constraints, our method outperforms a baseline, random-sampling based method at accurately performing constraint inference from an iteratively generated set of sparse but informative demonstrations.

Paper number 73:
Title: Plug In, Grade Right: Psychology-Inspired AGIQA
Authors: Zhicheng Liao, Baoliang Chen, Hanwei Zhu, Lingyu Zhu, Shiqi Wang, Weisi Lin
Abstract: Existing AGIQA models typically estimate image quality by measuring and aggregating the similarities between image embeddings and text embeddings derived from multi-grade quality descriptions. Although effective, we observe that such similarity distributions across grades usually exhibit multimodal patterns. For instance, an image embedding may show high similarity to both "excellent" and "poor" grade descriptions while deviating from the "good" one. We refer to this phenomenon as "semantic drift", where semantic inconsistencies between text embeddings and their intended descriptions undermine the reliability of text-image shared-space learning. To mitigate this issue, we draw inspiration from psychometrics and propose an improved Graded Response Model (GRM) for AGIQA. The GRM is a classical assessment model that categorizes a subject's ability across grades using test items with various difficulty levels. This paradigm aligns remarkably well with human quality rating, where image quality can be interpreted as an image's ability to meet various quality grades. Building on this philosophy, we design a two-branch quality grading module: one branch estimates image ability while the other constructs multiple difficulty levels. To ensure monotonicity in difficulty levels, we further model difficulty generation in an arithmetic manner, which inherently enforces a unimodal and interpretable quality distribution. Our Arithmetic GRM based Quality Grading (AGQG) module enjoys a plug-and-play advantage, consistently improving performance when integrated into various state-of-the-art AGIQA frameworks. Moreover, it also generalizes effectively to both natural and screen content image quality assessment, revealing its potential as a key component in future IQA models.

Paper number 74:
Title: SNM-Net: A Universal Framework for Robust Open-Set Gas Recognition via Spherical Normalization and Mahalanobis Distance
Authors: Shuai Chen, Chen Wang, Ziran Wang
Abstract: Electronic nose (E-nose) systems face dual challenges in open-set gas recognition: feature distribution shifts caused by signal drift and decision failures induced by unknown interference. Existing methods predominantly rely on Euclidean distance, failing to adequately account for anisotropic gas feature distributions and dynamic signal intensity variations. To address these issues, this study proposes SNM-Net, a universal deep learning framework for open-set gas recognition. The core innovation lies in a geometric decoupling mechanism achieved through cascaded batch normalization and L2 normalization, which projects high-dimensional features onto a unit hypersphere to eliminate signal intensity fluctuations. Additionally, Mahalanobis distance is introduced as the scoring mechanism, utilizing class-wise statistics to construct adaptive ellipsoidal decision boundaries. SNM-Net is architecture-agnostic and seamlessly integrates with CNN, RNN, and Transformer backbones. Systematic experiments on the Vergara dataset demonstrate that the Transformer+SNM configuration attains near-theoretical performance, achieving an AUROC of 0.9977 and an unknown gas detection rate of 99.57% (TPR at 5% FPR). This performance significantly outperforms state-of-the-art methods, showing a 3.0% improvement in AUROC and a 91.0% reduction in standard deviation compared to Class Anchor Clustering. The framework exhibits exceptional robustness across sensor positions with standard deviations below 0.0028. This work effectively resolves the trade-off between accuracy and stability, providing a solid technical foundation for industrial E-nose deployment.

Paper number 75:
Title: Hash Grid Feature Pruning
Authors: Yangzhi Ma, Bojun Liu, Jie Li, Li Li, Dong Liu
Abstract: Hash grids are widely used to learn an implicit neural field for Gaussian splatting, serving either as part of the entropy model or for inter-frame prediction. However, due to the irregular and non-uniform distribution of Gaussian splats in 3D space, numerous sparse regions exist, rendering many features in the hash grid invalid. This leads to redundant storage and transmission overhead. In this work, we propose a hash grid feature pruning method that identifies and prunes invalid features based on the coordinates of the input Gaussian splats, so that only the valid features are encoded. This approach reduces the storage size of the hash grid without compromising model performance, leading to improved rate-distortion performance. Following the Common Test Conditions (CTC) defined by the standardization committee, our method achieves an average bitrate reduction of 8% compared to the baseline approach.

Paper number 76:
Title: Covering in Hamming and Grassmann Spaces: New Bounds and Reed--Solomon-Based Constructions
Authors: Samin Riasat, Hessam Mahdavifar
Abstract: We study covering problems in Hamming and Grassmann spaces through a unified coding-theoretic and information-theoretic framework. Viewing covering as a form of quantization in general metric spaces, we introduce the notion of the average covering radius as a natural measure of average distortion, complementing the classical worst-case covering radius. By leveraging tools from one-shot rate-distortion theory, we derive explicit non-asymptotic random-coding bounds on the average covering radius in both spaces, which serve as fundamental performance benchmarks. On the construction side, we develop efficient puncturing-based covering algorithms for generalized Reed--Solomon (GRS) codes in the Hamming space and extend them to a new family of subspace codes, termed character-Reed--Solomon (CRS) codes, for Grassmannian quantization under the chordal distance. Our results reveal that, despite poor worst-case covering guarantees, these structured codes exhibit strong average covering performance. In particular, numerical results in the Hamming space demonstrate that RS-based constructions often outperform random codebooks in terms of average covering radius. In the one-dimensional Grassmann space, we numerically show that CRS codes over prime fields asymptotically achieve average covering radii within a constant factor of the random-coding bound in the high-rate regime. Together, these results provide new insights into the role of algebraic structure in covering problems and high-dimensional quantization.

Paper number 77:
Title: PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO
Authors: Mengyu Ji, Shiliang Guo, Zhengzhen Li, Jiahao Shen, Huazi Cao, Shiyu Zhao
Abstract: An aerial manipulator, comprising a multirotor base and a robotic arm, is subject to significant dynamic coupling between these two components. Therefore, achieving precise and robust motion control is a challenging yet important objective. Here, we propose a novel prescribed performance motion control framework based on variable-gain extended state observers (ESOs), referred to as PreGME. The method includes variable-gain ESOs for real-time estimation of dynamic coupling and a prescribed performance flight control that incorporates error trajectory constraints. Compared with existing methods, the proposed approach exhibits the following two characteristics. First, the adopted variable-gain ESOs can accurately estimate rapidly varying dynamic coupling. This enables the proposed method to handle manipulation tasks that require aggressive motion of the robotic arm. Second, by prescribing the performance, a preset error trajectory is generated to guide the system evolution along this trajectory. This strategy allows the proposed method to ensure the tracking error remains within the prescribed performance envelope, thereby achieving high-precision control. Experiments on a real platform, including aerial staff twirling, aerial mixology, and aerial cart-pulling experiments, are conducted to validate the effectiveness of the proposed method. Experimental results demonstrate that even under the dynamic coupling caused by rapid robotic arm motion (end-effector velocity: 1.02 m/s, acceleration: 5.10 m/s$^2$), the proposed method achieves high tracking performance.

Paper number 78:
Title: Wavelet-based Multi-View Fusion of 4D Radar Tensor and Camera for Robust 3D Object Detection
Authors: Runwei Guan, Jianan Liu, Shaofeng Liang, Fangqiang Ding, Shanliang Yao, Xiaokai Bai, Daizong Liu, Tao Huang, Guoqiang Mao, Hui Xiong
Abstract: 4D millimeter-wave (mmWave) radar has been widely adopted in autonomous driving and robot perception due to its low cost and all-weather robustness. However, its inherent sparsity and limited semantic richness significantly constrain perception capability. Recently, fusing camera data with 4D radar has emerged as a promising cost effective solution, by exploiting the complementary strengths of the two modalities. Nevertheless, point-cloud-based radar often suffer from information loss introduced by multi-stage signal processing, while directly utilizing raw 4D radar data incurs prohibitive computational costs. To address these challenges, we propose WRCFormer, a novel 3D object detection framework that fuses raw radar cubes with camera inputs via multi-view representations of the decoupled radar cube. Specifically, we design a Wavelet Attention Module as the basic module of wavelet-based Feature Pyramid Network (FPN) to enhance the representation of sparse radar signals and image data. We further introduce a two-stage query-based, modality-agnostic fusion mechanism termed Geometry-guided Progressive Fusion to efficiently integrate multi-view features from both modalities. Extensive experiments demonstrate that WRCFormer achieves state-of-the-art performance on the K-Radar benchmarks, surpassing the best model by approximately 2.4% in all scenarios and 1.6% in the sleet scenario, highlighting its robustness under adverse weather conditions.

Paper number 79:
Title: User-Centric Cell-Free Massive MIMO Enhanced by Fluid-Antenna Access Points: Uplink Analysis
Authors: Maryam Olyaee, Giovanni Interdonato, Stefano Buzzi
Abstract: In this paper, we investigate cell-free massive MIMO (CF-mMIMO) systems in which access points (APs) are equipped with fluid antennas (FAs) and develop a comprehensive framework for channel estimation, antenna port selection, and uplink spectral efficiency (SE) optimization. We propose a generalized LMMSE-based uplink channel estimation scheme that dynamically activates FA ports during pilot transmission, efficiently exploiting antenna reconfigurability under practical training constraints. Building on this, we design a distributed port selection strategy that minimizes per-AP channel estimation error by exploiting spatial correlation among FA ports. We systematically analyze the impact of antenna geometry and spatial correlation using the Jakes' channel model for different AP array configurations, including uniform linear and planar arrays. We then derive SINR expressions for centralized and distributed uplink processing and obtain a closed-form uplink SE expression for centralized maximum-ratio combining using the use-and-then-forget bound. Finally, we propose an alternating-optimization framework to select FA port configurations that maximize the uplink sum SE. Numerical results show that the proposed FA-aware channel estimation and port optimization strategies greatly reduce channel estimation error and significantly improve sum-SE over fixed-antenna and non-optimized FA baselines, confirming FAs as a key enabler for scalable, adaptive CF-mMIMO networks.

Paper number 80:
Title: Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use
Authors: Runzhi Zhou, Xi Luo
Abstract: Integrating non-Euclidean brain imaging data with Euclidean tabular data, such as clinical and demographic information, poses a substantial challenge for medical imaging analysis, particularly in forecasting future outcomes. While machine learning and deep learning techniques have been applied successfully to cross-sectional classification and prediction tasks, effectively forecasting outcomes in longitudinal imaging studies remains challenging. To address this challenge, we introduce a time-aware graph neural network model with transformer fusion (GNN-TF). This model flexibly integrates both tabular data and dynamic brain connectivity data, leveraging the temporal order of these variables within a coherent framework. By incorporating non-Euclidean and Euclidean sources of information from a longitudinal resting-state fMRI dataset from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA), the GNN-TF enables a comprehensive analysis that captures critical aspects of longitudinal imaging data. Comparative analyses against a variety of established machine learning and deep learning models demonstrate that GNN-TF outperforms these state-of-the-art methods, delivering superior predictive accuracy for predicting future tobacco usage. The end-to-end, time-aware transformer fusion structure of the proposed GNN-TF model successfully integrates multiple data modalities and leverages temporal dynamics, making it a valuable analytic tool for functional brain imaging studies focused on clinical outcome prediction.

Paper number 81:
Title: Robust Deep Learning Control with Guaranteed Performance for Safe and Reliable Robotization in Heavy-Duty Machinery
Authors: Mehdi Heydari Shahna
Abstract: Today's heavy-duty mobile machines (HDMMs) face two transitions: from diesel-hydraulic actuation to clean electric systems driven by climate goals, and from human supervision toward greater autonomy. Diesel-hydraulic systems have long dominated, so full electrification, via direct replacement or redesign, raises major technical and economic challenges. Although advanced artificial intelligence (AI) could enable higher autonomy, adoption in HDMMs is limited by strict safety requirements, and these machines still rely heavily on human supervision. This dissertation develops a control framework that (1) simplifies control design for electrified HDMMs through a generic modular approach that is energy-source independent and supports future modifications, and (2) defines hierarchical control policies that partially integrate AI while guaranteeing safety-defined performance and stability. Five research questions align with three lines of investigation: a generic robust control strategy for multi-body HDMMs with strong stability across actuation types and energy sources; control solutions that keep strict performance under uncertainty and faults while balancing robustness and responsiveness; and methods to interpret and trust black-box learning strategies so they can be integrated stably and verified against international safety standards. The framework is validated in three case studies spanning different actuators and conditions, covering heavy-duty mobile robots and robotic manipulators. Results appear in five peer-reviewed publications and one unpublished manuscript, advancing nonlinear control and robotics and supporting both transitions.

Paper number 82:
Title: Affine-Projection Recovery of Continuous Angular Power Spectrum: Geometry and Resolution
Authors: Shengsong Luo, Ruilin Wu, Chongbin Xu, Junjie Ma, Xiaojun Yuan, Xin Wang
Abstract: This paper considers recovering a continuous angular power spectrum (APS) from the channel covariance. Building on the projection-onto-linear-variety (PLV) algorithm, an affine-projection approach introduced by Miretti \emph{et. al.}, we analyze PLV in a well-defined \emph{weighted} Fourier-domain to emphasize its geometric interpretability. This yields an explicit fixed-dimensional trigonometric-polynomial representation and a closed-form solution via a positive-definite matrix, which directly implies uniqueness. We further establish an exact energy identity that yields the APS reconstruction error and leads to a sharp identifiability/resolution characterization: PLV achieves perfect recovery if and only if the ground-truth APS lies in the identified trigonometric-polynomial subspace; otherwise it returns the minimum-energy APS among all covariance-consistent spectra.

Paper number 83:
Title: Sidelobe Modification for an Offset Gregorian Reflector System using a Reconfigurable Intelligent Surface-Equipped Subreflector
Authors: S.W. Ellingson, A.J. Yip
Abstract: In past work, we described the use of a reconfigurable intelligent surface (RIS) mounted on the rim of an axisymmetric prime focus-fed reflector to create nulls in the close-in sidelobes. In this paper, we show that similar performance is possible in an offset Gregorian reflector system using a RIS on the rim of the subreflector. Applications include radio astronomy, where offset Gregorian reflectors are common and observations are subject to deleterious levels of interference from satellites entering through sidelobes. We show that an efficient RIS replacing the outer one-third of the subreflector surface, employing passive elements with 1-bit phase-only control, can create a null in the peak of the second sidelobe in the quiescent pattern. This is achieved using a simple unconstrained optimization algorithm to set the states of the RIS elements. The algorithm yields a deep null with just 0.2~dB reduction in main lobe directivity, despite lacking any constraints on main lobe pattern. Compared to our previous approach of mounting the RIS on the rim of the main reflector, the subreflector-based approach demonstrated in this paper requires a much smaller RIS and can implemented in existing systems by replacing the subreflector.

Paper number 84:
Title: Physical Limits of Proximal Tumor Detection via MAGE-A Extracellular Vesicles
Authors: A. Sila Okcu, M. Etem Bas, Ozgur B. Akan
Abstract: Early cancer detection relies on invasive tissue biopsies or liquid biopsies limited by biomarker dilution. In contrast, tumour-derived extracellular vesicles (EVs) carrying biomarkers like melanoma-associated antigen-A (MAGE-A) are highly concentrated in the peri-tumoral interstitial space, offering a promising near-field target. However, at micrometre scales, EV transport is governed by stochastic diffusion in a low copy number regime, increasing the risk of false negatives. We theoretically assess the feasibility of a smart-needle sensor detecting MAGE-A-positive microvesicles near a tumour. We use a hybrid framework combining particle-based Brownian dynamics (Smoldyn) to quantify stochastic arrival and false negative probabilities, and a reaction-diffusion PDE for mean concentration profiles. Formulating detection as a threshold-based binary hypothesis test, we find a maximum feasible detection radius of approximately 275 micrometers for a 6000 s sensing window. These results outline the physical limits of proximal EV-based detection and inform the design of minimally invasive peri-tumoral sensors.

Paper number 85:
Title: Unsupervised Learning for Detection of Rare Driving Scenarios
Authors: Dat Le, Thomas Manhardt, Moritz Venator, Johannes Betz
Abstract: The detection of rare and hazardous driving scenarios is a critical challenge for ensuring the safety and reliability of autonomous systems. This research explores an unsupervised learning framework for detecting rare and extreme driving scenarios using naturalistic driving data (NDD). We leverage the recently proposed Deep Isolation Forest (DIF), an anomaly detection algorithm that combines neural network-based feature representations with Isolation Forests (IFs), to identify non-linear and complex anomalies. Data from perception modules, capturing vehicle dynamics and environmental conditions, is preprocessed into structured statistical features extracted from sliding windows. The framework incorporates t-distributed stochastic neighbor embedding (t-SNE) for dimensionality reduction and visualization, enabling better interpretability of detected anomalies. Evaluation is conducted using a proxy ground truth, combining quantitative metrics with qualitative video frame inspection. Our results demonstrate that the proposed approach effectively identifies rare and hazardous driving scenarios, providing a scalable solution for anomaly detection in autonomous driving systems. Given the study's methodology, it was unavoidable to depend on proxy ground truth and manually defined feature combinations, which do not encompass the full range of real-world driving anomalies or their nuanced contextual dependencies.

Paper number 86:
Title: An extended method for Statistical Signal Characterization using moments and cumulants, as a fast and accurate pre-processing stage of simple ANNs applied to the recognition of pattern alterations in pulse-like waveforms
Authors: G. H. Bustos, H. H. Segnorile
Abstract: We propose a feature-extraction procedure based on the statistical characterization of waveforms, applied as a fast pre-processing stage in a pattern recognition task using simple artificial neural network models. This procedure involves measuring a set of 30 parameters, including moments and cumulants obtained from the waveform, its derivative, and its integral. The technique is presented as an extension of the Statistical Signal Characterization method, which is already established in the literature, and we referred to it as ESSC. As a testing methodology, we employed a procedure to distinguish a pulse-like signal from different versions of itself with altered or deformed frequency spectra, under various signal-to-noise ratio (SNR) conditions of Gaussian white noise. The recognition task was performed by machine learning networks using the proposed ESSC feature extraction method. Additionally, we compared the results with those obtained using raw data inputs in deep learning networks. The algorithms were trained and tested on cases involving Sinc-, Gaussian-, and Chirp-pulse waveforms. We measure accuracy and execution time for the different algorithms solving these pattern-recognition cases, and evaluate the architectural complexity of building such networks. We conclude that a simple multi-layer perceptron network using ESSC can achieve an accuracy of around 90%, comparable to that of deep learning algorithms, when solving pattern recognition tasks in practical scenarios with SNR above 20dB. Additionally, this approach offers an execution time approximately 4 times shorter and significantly lower network construction complexity, enabling its use in low-resource computational systems.

Paper number 87:
Title: NLCG-Net: A Model-Based Zero-Shot Learning Framework for Undersampled Quantitative MRI Reconstruction
Authors: Xinrui Jiang, Yohan Jun, Jaejin Cho, Mengze Gao, Xingwang Yong, Berkin Bilgic
Abstract: Typical quantitative MRI (qMRI) methods estimate parameter maps in a two-step pipeline that first reconstructs images from undersampled k-space data and then performs model fitting, which is prone to biases and error propagation. We propose NLCG-Net, a model-based nonlinear conjugate gradient (NLCG) framework for joint T2/T1 estimation that incorporates a U-Net regularizer trained in a scan-specific, zero-shot fashion. The method directly estimates qMRI maps from undersampled k-space using mono-exponential signal modeling with scan-specific neural network regularization, enabling high-fidelity T1 and T2 mapping. Experimental results on T2 and T1 mapping demonstrate that NLCG-Net improves estimation quality over subspace reconstruction at high acceleration factors.

Paper number 88:
Title: Image and Video Quality Assessment using Prompt-Guided Latent Diffusion Models for Cross-Dataset Generalization
Authors: Shankhanil Mitra, Diptanu De, Shika Rao, Rajiv Soundararajan
Abstract: The design of image and video quality assessment (QA) algorithms is extremely important to benchmark and calibrate user experience in modern visual systems. A major drawback of the state-of-the-art QA methods is their limited ability to generalize across diverse image and video datasets with reasonable distribution shifts. In this work, we leverage the denoising process of diffusion models for generalized image QA (IQA) and video QA (VQA) by understanding the degree of alignment between learnable quality-aware text prompts and images or video frames. In particular, we learn cross-attention maps from intermediate layers of the denoiser of latent diffusion models (LDMs) to capture quality-aware representations of images or video frames. Since applying text-to-image LDMs for every video frame is computationally expensive for videos, we only estimate the quality of a frame-rate sub-sampled version of the original video. To compensate for the loss in motion information due to frame-rate sub-sampling, we propose a novel temporal quality modulator. Our extensive cross-database experiments across various user-generated, synthetic, low-light, frame-rate variation, ultra high definition, and streaming content-based databases show that our model can achieve superior generalization in both IQA and VQA.

Paper number 89:
Title: Combined Learning of Linear Parameter-Varying Models and Robust Control Invariant Sets
Authors: Sampath Kumar Mulagaleti, Alberto Bemporad
Abstract: Dynamical models identified from data are frequently employed in control system design. However, decoupling system identification from controller synthesis can result in situations where no suitable controller exists after a model has been identified. In this work, we introduce a novel control-oriented regularization in the identification procedure to ensure the existence of a controller that can enforce constraints on system variables robustly. The combined identification algorithm includes: (i) the concurrent learning of an uncertain model and a nominal model using an observer; (ii) a regularization term on the model parameters defined as the size of the largest robust control invariant set for the uncertain model. To make the learning problem tractable, we consider nonlinear models in quasi Linear Parameter-Varying (qLPV) form, utilizing a novel scheduling function parameterization that facilitates the derivation of an associated uncertain linear model. The robust control invariant set is represented as a polytope, and we adopt novel results from polytope geometry to derive the regularization function as the optimal value of a convex quadratic program. Additionally, we present new model-reduction approaches that exploit the chosen model structure. Numerical examples on classical identification benchmarks demonstrate the efficacy of our approach. A simple control scheme is also derived to provide an example of data-driven control of a constrained nonlinear system.

Paper number 90:
Title: Re-Visible Dual-Domain Self-Supervised Deep Unfolding Network for MRI Reconstruction
Authors: Hao Zhang, Qi Wang, Jian Sun, Zhijie Wen, Jun Shi, Shihui Ying
Abstract: Magnetic Resonance Imaging (MRI) is widely used in clinical practice, but suffered from prolonged acquisition time. Although deep learning methods have been proposed to accelerate acquisition and demonstrate promising performance, they rely on high-quality fully-sampled datasets for training in a supervised manner. However, such datasets are time-consuming and expensive-to-collect, which constrains their broader applications. On the other hand, self-supervised methods offer an alternative by enabling learning from under-sampled data alone, but most existing methods rely on further partitioned under-sampled k-space data as model's input for training, resulting in a loss of valuable information. Additionally, their models have not fully incorporated image priors, leading to degraded reconstruction performance. In this paper, we propose a novel re-visible dual-domain self-supervised deep unfolding network to address these issues when only under-sampled datasets are available. Specifically, by incorporating re-visible dual-domain loss, all under-sampled k-space data are utilized during training to mitigate information loss caused by further partitioning. This design enables the model to implicitly adapt to all under-sampled k-space data as input. Additionally, we design a deep unfolding network based on Chambolle and Pock Proximal Point Algorithm (DUN-CP-PPA) to achieve end-to-end reconstruction, incorporating imaging physics and image priors to guide the reconstruction process. By employing a Spatial-Frequency Feature Extraction (SFFE) block to capture global and local feature representation, we enhance the model's efficiency to learn comprehensive image priors. Experiments conducted on the fastMRI and IXI datasets demonstrate that our method significantly outperforms state-of-the-art approaches in terms of reconstruction performance.

Paper number 91:
Title: Decoding EEG Speech Perception with Transformers and VAE-based Data Augmentation
Authors: Terrance Yu-Hao Chen, Yulin Chen, Pontus Soederhaell, Sadrishya Agrawal, Kateryna Shapovalenko
Abstract: Decoding speech from non-invasive brain signals, such as electroencephalography (EEG), has the potential to advance brain-computer interfaces (BCIs), with applications in silent communication and assistive technologies for individuals with speech impairments. However, EEG-based speech decoding faces major challenges, such as noisy data, limited datasets, and poor performance on complex tasks like speech perception. This study attempts to address these challenges by employing variational autoencoders (VAEs) for EEG data augmentation to improve data quality and applying a state-of-the-art (SOTA) sequence-to-sequence deep learning architecture, originally successful in electromyography (EMG) tasks, to EEG-based speech decoding. Additionally, we adapt this architecture for word classification tasks. Using the Brennan dataset, which contains EEG recordings of subjects listening to narrated speech, we preprocess the data and evaluate both classification and sequence-to-sequence models for EEG-to-words/sentences tasks. Our experiments show that VAEs have the potential to reconstruct artificial EEG data for augmentation. Meanwhile, our sequence-to-sequence model achieves more promising performance in generating sentences compared to our classification model, though both remain challenging tasks. These findings lay the groundwork for future research on EEG speech perception decoding, with possible extensions to speech production tasks such as silent or imagined speech.

Paper number 92:
Title: Signal Whisperers: Enhancing Wireless Reception Using DRL-Guided Reflector Arrays
Authors: Hieu Le, Oguz Bedir, Mostafa Ibrahim, Jian Tao, Sabit Ekin
Abstract: This paper presents a multi-agent reinforcement learning (MARL) approach for controlling adjustable metallic reflector arrays to enhance wireless signal reception in non-line-of-sight (NLOS) scenarios. Unlike conventional reconfigurable intelligent surfaces (RIS) that require complex channel estimation, our system employs a centralized training with decentralized execution (CTDE) paradigm where individual agents corresponding to reflector segments autonomously optimize reflector element orientation in three-dimensional space using spatial intelligence based on user location information. Through extensive ray-tracing simulations with dynamic user mobility, the proposed multi-agent beam-focusing framework demonstrates substantial performance improvements over single-agent reinforcement learning baselines, while maintaining rapid adaptation to user movement within one simulation step. Comprehensive evaluation across varying user densities and reflector configurations validates system scalability and robustness. The results demonstrate the potential of learning-based approaches for adaptive wireless propagation control.

Paper number 93:
Title: Stabilizing NMPC Approaches for Underactuated Mechanical Systems on the SE(3) Manifold
Authors: Jean C. Pereira, Valter J. S. Leite, Guilherme V. Raffo
Abstract: This paper addresses the motion control problem for underactuated mechanical systems with full attitude control and one translational force input to manage the six degrees of freedom involved in the three-dimensional Euclidean space. These systems are often classified as second-order nonholonomic due to their completely nonintegrable acceleration constraints. To tackle this complex control problem, we propose two nonlinear model predictive control (NMPC) schemes that ensure closed-loop stability and recursive feasibility without terminal conditions. The system dynamics are modeled on the SE(3) manifold for a globally and unique description of rigid body configurations. One NMPC scheme also aims to reduce mission time as an economic criterion. The controllers' effectiveness is validated through numerical experiments on a quadrotor UAV.

Paper number 94:
Title: UltraBoneUDF: Self-supervised Bone Surface Reconstruction from Ultrasound Based on Neural Unsigned Distance Functions
Authors: Luohong Wu, Matthias Seibold, Nicola A. Cavalcanti, Giuseppe Loggia, Lisa Reissner, Bastian Sigrist, Jonas Hein, Lilian Calvet, Arnd Viehöfer, Philipp Fürnstahl
Abstract: Bone surface reconstruction is an essential component of computer-assisted orthopedic surgery(CAOS), forming the foundation for both preoperative planning and intraoperative guidance. Compared to traditional imaging modalities such as computed tomography (CT) and magnetic resonance imaging (MRI),ultrasound, an emerging CAOS technology, provides a radiation-free, cost-effective, and portable alternative. While ultrasound offers new opportunities in CAOS, technical shortcomings continue to hinder its translation into surgery. In particular, due to the inherent limitations of ultrasound imaging, B-mode ultrasound typically captures only partial bone surfaces. The inter- and intra-operator variability in ultrasound scanning further increases the complexity of the data. Existing reconstruction methods struggle with such challenging data, leading to increased reconstruction errors and artifacts, such as holes and inflated structures. Effective techniques for accurately reconstructing open bone surfaces from real-world 3D ultrasound volumes remain lacking. We propose UltraBoneUDF, a self-supervised framework specifically designed for reconstructing open bone surfaces from ultrasound data. It learns unsigned distance functions (UDFs) from 3D ultrasound data. In addition, we present a novel loss function based on local tangent plane optimization that substantially improves surface reconstruction quality. UltraBoneUDF and competing models are benchmarked on three open-source datasets and further evaluated through ablation studies. Qualitative results demonstrate the limitations of the state-of-the-art methods. Quantitatively, UltraBoneUDF achieves comparable or lower bi-directional Chamfer distance across three datasets with fewer parameters: 1.60 mm on the UltraBones100k dataset (~25.5% improvement), 0.21 mm on the OpenBoneCT dataset, and 0.18 mm on the ClosedBoneCT dataset.

Paper number 95:
Title: Distinctive Feature Codec: An Adaptive Efficient Speech Representation for Depression Detection
Authors: Xiangyu Zhang, Fuming Fang, Peng Gao, Bin Qin, Beena Ahmed, Julien Epps
Abstract: Large Language Models (LLMs) have demonstrated remarkable success across diverse fields, establishing a powerful paradigm for complex information processing. This has inspired the integration of speech into LLM frameworks, often by tokenizing continuous audio via neural speech codecs, enabling powerful speech language models. However, this dominant tokenization strategy relies on uniform frame-based processing at fixed time intervals. This fixed-rate approach, while effective for linguistic content, destroys the temporal dynamics. These dynamics are not noise but are established as primary biomarkers in clinical applications such as depression detection. To address this gap, we introduce the Distinctive Feature Codec (DFC), an adaptive framework engineered to preserve this vital timing information. Drawing from linguistic theory, DFC abandons fixed-interval processing and instead learns to dynamically segment the signal at perceptually significant acoustic transitions. This generates variable-length tokens that efficiently encode the temporal structure. As a key contribution, this work is the first to integrate traditional distinctive features into a modern deep learning codec for a temporally sensitive task such as depression detection. We also introduce the Group-wise Scalar Quantization (GSQ) approach to stably quantize these variable-length segments. Our distinctive feature-based approach offers a promising alternative to conventional frame-based processing and advances interpretable representation learning in the modern deep learning speech depression detection framework.

Paper number 96:
Title: Higher-Order Tensor-Based Deferral of Gaussian Splitting for Orbit Uncertainty Propagation
Authors: G. Andrew Siciliano, Keith A. LeGrand, Jackson Kulik
Abstract: Accurate propagation of orbital uncertainty is essential for a range of applications within space domain awareness. Adaptive Gaussian mixture-based approaches offer tractable nonlinear uncertainty propagation through splitting mixands to increase resolution in areas of stronger nonlinearities, as well as by reducing mixands to prevent unnecessary computational effort. Recent work introduced principled heuristics that incorporate information from the system dynamics and initial uncertainty to determine optimal directions for splitting. This paper develops adaptive uncertainty propagation methods based on these robust splitting techniques. A deferred splitting algorithm tightly integrated with higher-order splitting techniques is proposed and shown to offer substantial gains in computational efficiency without sacrificing accuracy. Second-order propagation of mixand moments is also seen to improve accuracy while retaining significant computational savings from deferred splitting. Different immediate and deferred splitting methods are compared in four representative test cases, including a low Earth orbit, a geostationary orbit, a Molniya orbit, and a multi-body cislunar orbit.

Paper number 97:
Title: Structure from Noise: Confirmation Bias in Particle Picking in Structural Biology
Authors: Amnon Balanov, Alon Zabatani, Tamir Bendory
Abstract: The computational pipelines of single-particle cryo-electron microscopy (cryo-EM) and cryo-electron tomography (cryo-ET) include an early particle-picking stage, in which a micrograph or tomogram is scanned to extract candidate particles, typically via template matching or deep-learning-based techniques. The extracted particles are then passed to downstream tasks such as classification and 3D reconstruction. Although it is well understood empirically that particle picking can be sensitive to the choice of templates or learned priors, a quantitative theory of the bias introduced by this stage has been lacking. Here, we develop a mathematical framework for analyzing bias in template matching-based detection with concrete applications to cryo-EM and cryo-ET. We study this bias through two downstream tasks: (i) maximum-likelihood estimation of class means in a Gaussian mixture model (GMM) and (ii) 3D volume reconstruction from the extracted particle stack. We show that when template matching is applied to pure noise, then under broad noise models, the resulting maximum-likelihood estimates converge asymptotically to deterministic, noise-dependent transforms of the user-specified templates, yielding a structure from noise effect. We further characterize how the resulting bias depends on the noise statistics, sample size, dimension, and detection threshold. Finally, controlled experiments using standard cryo-EM software corroborate the theory, demonstrating reproducible structure from noise artifacts in low-SNR data.

Paper number 98:
Title: Optimization of Fractal Image Compression
Authors: Nastaran Pourshab Mohsen Bagheritabar
Abstract: Fractal Image Compression (FIC) is a lossy image compression technique that leverages self-similarity within an image to achieve high compression ratios. However, the process of compressing the image is computationally expensive. This paper investigates optimization techniques to improve the efficiency of FIC, focusing on increasing compression ratio and reducing computational time. The paper explores a novel approach named the Box Counting Method for estimating fractal dimensions, which is very simple to integrate into FIC compared to other algorithms. The results show that implementing these optimization techniques enhances both the compression ratio and the compression time.

Paper number 99:
Title: A Fingerprint Database Generation Method for RIS-Assisted Indoor Positioning
Authors: Xin Cheng, Yu He, Menglu Li, Ruoguang Li, Feng Shu, Guangjie Han
Abstract: Reconfigurable intelligent surface (RIS) has emerged as a promising technology to enhance indoor wireless communication and sensing performance. However, the construction of reliable received signal strength (RSS)-based fingerprint databases for RIS-assisted indoor positioning remains an open challenge due to the lack of realistic and spatially consistent channel modeling methods. In this paper, we propose a novel method with open-source code for generating RIS-assisted RSS fingerprint databases. Our method captures the complex RIS-assisted multipath behaviors by extended cluster-based channel modeling and the physical and electromagnetic properties of RIS and transmitter (Tx). And the spatial consistency is incorporated when simulating the fingerprint data collection across neighboring positions. Moreover, an effective sorting algorithm is proposed to solve the online synchronization issue, a closed-form RIS phase configuration strategy is proposed to improve the localization accuracy, and the modeling method of mutual coupling (MC) effect is provided. Extensive simulations are conducted to evaluate the fingerprint database generated by the proposed method. And the positioning performance on the database using different algorithms is analyzed, providing valuable insights for the system design.

Paper number 100:
Title: Sequential Operation of Residential Energy Hubs using Physics-Based Economic Nonlinear MPC
Authors: Darío Slaifstein (1), Gautham Ram Chandra Mouli (1), Laura Ramirez-Elizondo (1), Pavol Bauer (1) ((1) Delft University of Technology)
Abstract: The operation of residential energy hubs with multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to different carrier dynamics, hybrid storage coordination and high-dimensional action-spaces. Energy management systems oversee their operation, deciding the set points of the primary control layer. This paper presents a novel 2-stage economic model predictive controller for electrified buildings including physics-based models of the battery degradation and thermal systems. The hierarchical control operates in the Dutch sequential energy markets. In particular common assumptions regarding intra-day markets (auction and continuous-time) are discussed as well as the coupling of the different storage systems. The best control policy it is best to follow continuous time intra-day in the summer and the intra-day auction in the winter. This sequential operation comes at the expense of increased battery degradation. Lastly, under our controller, the realized short-term flexibility of the thermal energy storage is marginal compared to the flexibility delivered by stationary battery pack and electric vehicles with bidirectional charging.

Paper number 101:
Title: VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission
Authors: Ming Lyu, Hao Chen, Dan Wang, Chen Qiu, Guangyin Feng, Nan Ma, Xiaodong Xu
Abstract: Semantic communication (SemCom) significantly reduces redundant data and improves transmission efficiency by extracting the latent features of information. However, most of the conventional deep learning-based SemCom systems focus on analog transmission and lack in compatibility with practical digital communications. This paper proposes a vector quantized-variational autoencoder (VQ-VAE) based digital SemCom system that directly transmits the semantic features and incorporates the importance-aware orthogonal frequency division multiplexing (OFDM) transmission to enhance the SemCom performance, where the VQ-VAE generates a discrete codebook shared between the transmitter and receiver. At transmitter, the latent semantic features are firstly extracted by VQ-VAE, and then the shared codebook is adopted to match these features, which are subsequently transformed into a discrete version to adapt the digital transmission. To protect the semantic information, an importance-aware OFDM transmission strategy is proposed to allocate the key features near the OFDM reference signals, where the feature importance is derived from the gradient-based method. At the receiver, the features are rematched with the shared codebook to further correct errors. Finally, experimental results demonstrate that our proposed scheme outperforms the conventional DeepSC and achieves better reconstruction performance under low SNR region.

Paper number 102:
Title: An Adaptive Environment-Aware Transformer Autoencoder for UAV-FSO with Dynamic Complexity Control
Authors: Han Zeng, Haibo Wang, Kan Wang, Xutao Yu, Zaichen Zhang
Abstract: The rise of sixth-generation (6G) wireless networks sets high demands on UAV-assisted Free Space Optical (FSO) communications, where the channel environment becomes more complex and variable due to both atmospheric turbulence and UAV-induced vibrations. These factors increase the challenge of maintaining reliable communication and require adaptive processing methods. Autoencoders are promising as they learn optimal encodings from channel data. However, existing autoencoder designs are generic and lack the specific adaptability and computational flexibility needed for UAV-FSO scenarios. To address this, we propose AEAT-AE (Adaptive Environment-aware Transformer Autoencoder), a Transformer-based framework that integrates environmental parameters into both encoder and decoder via a cross-attention mechanism. Moreover, AEAT-AE incorporates a Deep Q-Network (DQN) that dynamically selects which layers of the Transformer autoencoder to activate based on real-time environmental inputs, effectively balancing performance and computational cost. Simulation results demonstrate that AEAT-AE outperforms conventional methods in bit error rate while maintaining efficient runtime, representing a novel tailored solution for next-generation UAV-FSO communications.

Paper number 103:
Title: Experimental Analysis of Biasing Voltage Generation in Wave-Controlled RIS
Authors: Miguel Saavedra-Melo, Benjamin Bradshaw, Vanessa Yao, Ender Ayanoglu, Lee Swindlehurst, Filippo Capolino
Abstract: Reconfigurable intelligent surfaces (RISs), an emerging technology proposed for inclusion in next generation wireless communication systems, are programmable surfaces that can adaptively reflect incident electromagnetic radiation in different desired directions. To reduce the complexity and physical profile of conventional RIS designs, a novel concept known as Wave-Controlled RIS has been proposed, in which standing waves along a transmission line are used to generate the required dc bias for reflective control. This paper shows the design of such a Wave-Controlled RIS and its biasing transmission line. The effectiveness of this approach in generating the correct dc bias from a single standing wave frequency is analyzed through both theoretical modeling and experimental validation, which uncovered a dependence on impedance matching not accounted for by the theory. Additionally, the potential for reflective control using only a single standing wave frequency on the biasing transmission line is explored, demonstrating the ability of single-beam steering toward angles near broadside.

Paper number 104:
Title: A Bidirectional Diode-Clamp Circuit Paradigm for Time-Resolved Measurement of Electrical Short-Circuits
Authors: Alex Mwololo Kimuya, Dickson Mwenda Kinyua
Abstract: Conventional electrical fault models, which rely on static thresholds and instantaneous trip mechanisms, fail to capture the time-evolving dynamics of real faults, creating vulnerabilities in modern power systems. This paper introduces a diode-clamp circuit architecture that reconceives short-circuits as governed, sustained processes and establishes a physics-consistent, measurement system. An Arduino-based data acquisition system recorded continuous fault evolution across multiple input voltages and durations. Multi-resolution sampling at 10ms, 50ms, and 100ms enabled high-fidelity capture of both transients and sustained-state dynamics. The clamped mechanism constrained the circuit to a bounded regime, enabling repeatable observation. Experiments yielded definitive, measurable minima and maxima for voltage, current, and resistance, empirically refuting the classical assumption of instantaneous, unbounded current. Newly introduced metrics quantify this performance: the Sustained-to-Capacitive Energy Ratio (SCER ~1.53x10^12) proves fault energy originates from sustained dynamics, not transient discharge. The Sustained Fault Efficiency (SFE>1) demonstrates that governed fault power can exceed nominal operating power. This work provides the first fully validated short-circuit quantification system, yielding empirical data for next-generation battery management, adaptive grid protection, and fault-tolerant electronics.

Paper number 105:
Title: Probabilistic Dynamic Line Rating with Line Graph Convolutional LSTM
Authors: Minsoo Kim, Vladimir Dvorkin, Jip Kim
Abstract: Dynamic line rating (DLR) is an effective approach to enhancing the utilization of existing transmission line infrastructure by adapting line ratings according to real-time weather conditions. Accurate DLR forecasts are essential for grid operators to effectively schedule generation, manage transmission congestion, and lower operating costs. As renewable generation becomes increasingly variable and weather-dependent, accurate DLR forecasts are also crucial for improving renewable utilization and reducing curtailment during congested periods. Deterministic forecasts, however, often inadequately represent actual line capacities under uncertain weather conditions, leading to operational risks and costly real-time adjustments. To overcome these limitations, we propose a novel network-wide probabilistic DLR forecasting model that leverages both spatial and temporal information, significantly reducing the operational risks and inefficiencies inherent in deterministic methods. Case studies on a synthetic Texas 123-bus system demonstrate that the proposed method not only enhances grid reliability by effectively capturing true DLR values, but also substantially reduces operational costs.

Paper number 106:
Title: Off-grid solar energy storage system with hybrid lithium iron phosphate (LFP) and lead-acid batteries in high mountains: a case report of Jiujiu Cabins in Taiwan
Authors: Hsien-Ching Chung
Abstract: Mountain huts are buildings located at high altitude, offering a place for hikers and providing shelter. Energy supply to mountain huts remains an ongoing issue. Using renewable energies could be an appropriate solution. Jiujiu Cabins, a famous mountain hut in Shei-Pa National Park, Taiwan, has operated an off-grid solar energy storage system (ESS) with lead-acid batteries. In 2021, a serious system failure took place, leading to no electricity. After a detailed on-site survey, a reorganization and repair project was implemented, and the energy system came back to operate normally. Meanwhile, an eco-friendly lithium iron phosphate battery (LFP battery) ESS replaces part of the lead-acid battery ESS, forming a hybrid ESS, making a better and greener off-grid solar ESS. In this case report, the energy architecture, detailed descriptions, and historical status of the system are provided. An on-site survey of the failed energy system, a system improvement project, and a future plan are listed.

Paper number 107:
Title: Resource-efficient medical image classification for edge devices
Authors: Mahsa Lavaei, Zahra Abadi, Salar Beigzad, Alireza Maleki
Abstract: Medical image classification is a critical task in healthcare, enabling accurate and timely diagnosis. However, deploying deep learning models on resource-constrained edge devices presents significant challenges due to computational and memory limitations. This research investigates a resource-efficient approach to medical image classification by employing model quantization techniques. Quantization reduces the precision of model parameters and activations, significantly lowering computational overhead and memory requirements without sacrificing classification accuracy. The study focuses on the optimization of quantization-aware training (QAT) and post-training quantization (PTQ) methods tailored for edge devices, analyzing their impact on model performance across medical imaging datasets. Experimental results demonstrate that quantized models achieve substantial reductions in model size and inference latency, enabling real-time processing on edge hardware while maintaining clinically acceptable diagnostic accuracy. This work provides a practical pathway for deploying AI-driven medical diagnostics in remote and resource-limited settings, enhancing the accessibility and scalability of healthcare technologies.

Paper number 108:
Title: CLIP Based Region-Aware Feature Fusion for Automated BBPS Scoring in Colonoscopy Images
Authors: Yujia Fu, Zhiyu Dong, Tianwen Qian, Chenye Zheng, Danian Ji, Linhai Zhuo
Abstract: Accurate assessment of bowel cleanliness is essential for effective colonoscopy procedures. The Boston Bowel Preparation Scale (BBPS) offers a standardized scoring system but suffers from subjectivity and inter-observer variability when performed manually. In this paper, to support robust training and evaluation, we construct a high-quality colonoscopy dataset comprising 2,240 images from 517 subjects, annotated with expert-agreed BBPS scores. We propose a novel automated BBPS scoring framework that leverages the CLIP model with adapter-based transfer learning and a dedicated fecal-feature extraction branch. Our method fuses global visual features with stool-related textual priors to improve the accuracy of bowel cleanliness evaluation without requiring explicit segmentation. Extensive experiments on both our dataset and the public NERTHU dataset demonstrate the superiority of our approach over existing baselines, highlighting its potential for clinical deployment in computer-aided colonoscopy analysis.

Paper number 109:
Title: Two Birds With One Stone: Beamforming Design for Target Sensing and Proactive Eavesdropping
Authors: Qian Dan, Hongjiang Lei, Ki-Hong Park, Gaofeng Pan, Mohamed-Slim Alouini
Abstract: This work studies the beamforming design in the joint proactive eavesdropping (PE) and target sensing (TS) systems. The base station (BS) wiretaps the information transmitted by the illegal transmitter and sends the waveform for TS. The shared waveform also serves as artificial noise to interfere with the illegal receiver, thereby achieving successful this http URL firstly optimize the transmitting beampattern of the BS only to maximize the eavesdropping rate or only to minimize the Cram{é}r-Rao bound, respectively. Then, the joint design of PE and TS is investigated by formulating the PE-centric, the TS-centric, and the normalized weighted optimization problems. The formulated problems are solved by the semi-definite relaxation technique and the sequential rank-one constraint relaxation method to address the complexity of the original problem. Furthermore, the scenario in which the quality of the eavesdropping channel is stronger than that of the illegal channel is considered. Numerical results demonstrate that the proposed algorithm can effectively realize PE and TS simultaneously.

Paper number 110:
Title: EM++: A parameter learning framework for stochastic switching systems
Authors: Renzi Wang, Alexander Bodard, Mathijs Schuurmans, Panagiotis Patrinos
Abstract: This paper proposes a general switching dynamical system model, and a custom majorization-minimization-based algorithm EM++ for identifying its parameters. For certain families of distributions, such as Gaussian distributions, this algorithm reduces to the well-known expectation-maximization method. We prove global convergence of the algorithm under suitable assumptions, thus addressing an important open issue in the switching system identification literature. The effectiveness of both the proposed model and algorithm is validated through extensive numerical experiments.

Paper number 111:
Title: A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs
Authors: Ehsan Kabir, Jason D. Bakos, David Andrews, Miaoqing Huang
Abstract: Transformer neural networks (TNN) excel in natural language processing (NLP), machine translation, and computer vision (CV) without relying on recurrent or convolutional layers. However, they have high computational and memory demands, particularly on resource-constrained devices like FPGAs. Moreover, transformer models vary in processing time across applications, requiring custom models with specific parameters. Designing custom accelerators for each model is complex and time-intensive. Some custom accelerators exist with no runtime adaptability, and they often rely on sparse matrices to reduce latency. However, hardware designs become more challenging due to the need for application-specific sparsity patterns. This paper introduces ADAPTOR, a runtime-adaptive accelerator for dense matrix computations in transformer encoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing elements and on-chip memory, enhancing parallelism and reducing latency. It incorporates efficient matrix tiling to distribute resources across FPGA platforms and is fully quantized for computational efficiency and portability. Evaluations on Xilinx Alveo U55C data center cards and embedded platforms like VC707 and ZCU102 show that our design is 1.2$\times$ and 2.87$\times$ more power efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively. Additionally, it achieves a speedup of 1.7 to 2.25$\times$ compared to some state-of-the-art FPGA-based accelerators.

Paper number 112:
Title: Unrolled Creative Adversarial Network For Generating Novel Musical Pieces
Authors: Pratik Nag
Abstract: Music generation has emerged as a significant topic in artificial intelligence and machine learning. While recurrent neural networks (RNNs) have been widely employed for sequence generation, generative adversarial networks (GANs) remain relatively underexplored in this domain. This paper presents two systems based on adversarial networks for music generation. The first system learns a set of music pieces without differentiating between styles, while the second system focuses on learning and deviating from specific composers' styles to create innovative music. By extending the Creative Adversarial Networks (CAN) framework to the music domain, this work introduces unrolled CAN to address mode collapse, evaluating both GAN and CAN in terms of creativity and variation.

Paper number 113:
Title: Improving Requirements Classification with SMOTE-Tomek Preprocessing
Authors: Barak Or
Abstract: This study emphasizes the domain of requirements engineering by applying the SMOTE-Tomek preprocessing technique, combined with stratified K-fold cross-validation, to address class imbalance in the PROMISE dataset. This dataset comprises 969 categorized requirements, classified into functional and non-functional types. The proposed approach enhances the representation of minority classes while maintaining the integrity of validation folds, leading to a notable improvement in classification accuracy. Logistic regression achieved 76.16\%, significantly surpassing the baseline of 58.31\%. These results highlight the applicability and efficiency of machine learning models as scalable and interpretable solutions.

Paper number 114:
Title: Steering Language Model to Stable Speech Emotion Recognition via Contextual Perception and Chain of Thought
Authors: Zhixian Zhao, Xinfa Zhu, Xinsheng Wang, Shuiyuan Wang, Xuelong Geng, Wenjie Tian, Lei Xie
Abstract: Large-scale audio language models (ALMs), such as Qwen2-Audio, are capable of comprehending diverse audio signal, performing audio analysis and generating textual responses. However, in speech emotion recognition (SER), ALMs often suffer from hallucinations, resulting in misclassifications or irrelevant outputs. To address these challenges, we propose C$^2$SER, a novel ALM designed to enhance the stability and accuracy of SER through Contextual perception and Chain of Thought (CoT). C$^2$SER integrates the Whisper encoder for semantic perception and Emotion2Vec-S for acoustic perception, where Emotion2Vec-S extends Emotion2Vec with semi-supervised learning to enhance emotional discrimination. Additionally, C$^2$SER employs a CoT approach, processing SER in a step-by-step manner while leveraging speech content and speaking styles to improve recognition. To further enhance stability, C$^2$SER introduces self-distillation from explicit CoT to implicit CoT, mitigating error accumulation and boosting recognition accuracy. Extensive experiments show that C$^2$SER outperforms existing popular ALMs, such as Qwen2-Audio and SECap, delivering more stable and precise emotion recognition. We release the training code, checkpoints, and test sets to facilitate further research.

Paper number 115:
Title: Anti-Slip AI-Driven Model-Free Control with Global Exponential Stability in Skid-Steering Robots
Authors: Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila
Abstract: Undesired lateral and longitudinal wheel slippage can disrupt a mobile robot's heading angle, traction, and, eventually, desired motion. This issue makes the robotization and accurate modeling of heavy-duty machinery very challenging because the application primarily involves off-road terrains, which are susceptible to uneven motion and severe slippage. As a step toward robotization in skid-steering heavy-duty robot (SSHDR), this paper aims to design an innovative robust model-free control system developed by neural networks to strongly stabilize the robot dynamics in the presence of a broad range of potential wheel slippages. Before the control design, the dynamics of the SSHDR are first investigated by mathematically incorporating slippage effects, assuming that all functional modeling terms of the system are unknown to the control system. Then, a novel tracking control framework to guarantee global exponential stability of the SSHDR is designed as follows: 1) the unknown modeling of wheel dynamics is approximated using radial basis function neural networks (RBFNNs); and 2) a new adaptive law is proposed to compensate for slippage effects and tune the weights of the RBFNNs online during execution. Simulation and experimental results verify the proposed tracking control performance of a 4,836 kg SSHDR operating on slippery terrain.

Paper number 116:
Title: Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative System for Underwater Tasks in Extreme Sea Conditions
Authors: Jingzehua Xu, Guanwen Xie, Jiwei Tang, Yimian Ding, Weiyi Liu, Junhao Huang, Shuai Zhang, Yi Li
Abstract: This paper develops a novel unmanned surface vehicle (USV)-autonomous underwater vehicle (AUV) collaborative system designed to enhance underwater task performance in extreme sea conditions. The system integrates a dual strategy: (1) high-precision multi-AUV localization enabled by Fisher information matrix-optimized USV path planning, and (2) reinforcement learning-based cooperative planning and control method for multi-AUV task execution. Extensive experimental evaluations in the underwater data collection task demonstrate the system's operational feasibility, with quantitative results showing significant performance improvements over baseline methods. The proposed system exhibits robust coordination capabilities between USV and AUVs while maintaining stability in extreme sea conditions. To facilitate reproducibility and community advancement, we provide an open-source simulation toolkit available at: this https URL .

Paper number 117:
Title: Dub-S2ST: Textless Speech-to-Speech Translation for Seamless Dubbing
Authors: Jeongsoo Choi, Jaehun Kim, Joon Son Chung
Abstract: This paper introduces a cross-lingual dubbing system that translates speech from one language to another while preserving key characteristics such as duration, speaker identity, and speaking speed. Despite the strong translation quality of existing speech translation approaches, they often overlook the transfer of speech patterns, leading to mismatches with source speech and limiting their suitability for dubbing applications. To address this, we propose a discrete diffusion-based speech-to-unit translation model with explicit duration control, enabling time-aligned translation. We then synthesize speech based on the translated units and source speaker's identity using a conditional flow matching model. Additionally, we introduce a unit-based speed adaptation mechanism that guides the translation model to produce speech at a rate consistent with the source, without relying on any text. Extensive experiments demonstrate that our framework generates natural and fluent translations that align with the original speech's duration and speaking pace, while achieving competitive translation performance. The code is available at this https URL.

Paper number 118:
Title: Assessing the economic benefits of space weather mitigation investment decisions: Evidence from Aotearoa New Zealand
Authors: Edward J. Oughton, Andrew Renton, Daniel Mac Marnus, Dennies Bor, Craig J. Rodger
Abstract: Space weather events pose a growing threat to modern economies, yet their macroeconomic consequences still remain underexplored. This study presents the first dedicated economic assessment of geomagnetic storm impacts on Aotearoa New Zealand, quantifying potential gross domestic product (GDP) losses across seven conservative disruption and mitigation scenarios due to an extreme coronal mass ejection (CME). The primary focus is upon the damaging impacts of geomagnetically induced currents (GICs) on the electrical power transmission network. We support space weather mitigation investments decisions by providing a first-order approximation of their potential economic benefits, using best-in-class scientific models. In the absence of mitigation, a severe but realistic storm could result in up to NZ\$8.36 billion in lost GDP, with more than half stemming from cascading supply chain effects. Yet, even less severe scenarios incur losses exceeding NZ\$3 billion. Importantly, even with conservative impact estimates we find that research-led operational strategies, such as optimized switching and islanding, can avoid up to NZ\$370 million in losses for as little as NZ\$0.5 million in expenditure, delivering a benefit-cost ratio of 740 to 1. Equally, physical protections such as GIC blocking devices achieve benefit-cost returns up to 80 to 1, highlighting the strong case for investment in space weather mitigation. When also acknowledging additional unmodelled impacts, including multi-billion losses in capital equipment and long-term revenue, the economic rationale for pre-emptive mitigation becomes even more pertinent. Future research needs to integrate the modelling of capital and revenue losses for strategically important industrial facilities.

Paper number 119:
Title: SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering
Authors: Jan Melechovsky, Ambuj Mehrish, Abhinaba Roy, Dorien Herremans
Abstract: Music recordings often suffer from audio quality issues such as excessive reverberation, distortion, clipping, tonal imbalances, and a narrowed stereo image, especially when created in non-professional settings without specialized equipment or expertise. These problems are typically corrected using separate specialized tools and manual adjustments. In this paper, we introduce SonicMaster, the first unified generative model for music restoration and mastering that addresses a broad spectrum of audio artifacts with text-based control. SonicMaster is conditioned on natural language instructions to apply targeted enhancements, or can operate in an automatic mode for general restoration. To train this model, we construct the SonicMaster dataset, a large dataset of paired degraded and high-quality tracks by simulating common degradation types with nineteen degradation functions belonging to five enhancements groups: equalization, dynamics, reverb, amplitude, and stereo. Our approach leverages a flow-matching generative training paradigm to learn an audio transformation that maps degraded inputs to their cleaned, mastered versions guided by text prompts. Objective audio quality metrics demonstrate that SonicMaster significantly improves sound quality across all artifact categories. Furthermore, subjective listening tests confirm that listeners prefer SonicMaster's enhanced outputs over other baselines.

Paper number 120:
Title: The CCF AATC 2025 Speech Restoration Challenge: A Retrospective
Authors: Junan Zhang, Mengyao Zhu, Xin Xu, Hui Bu, Zhenhua Ling, Zhizheng Wu
Abstract: Real-world speech communication is rarely affected by a single type of degradation. Instead, it suffers from a complex interplay of acoustic interference, codec compression, and, increasingly, secondary artifacts introduced by upstream enhancement algorithms. To bridge the gap between academic research and these realistic scenarios, we introduced the CCF AATC 2025 Challenge. This challenge targets universal blind speech restoration, requiring a single model to handle three distinct distortion categories: acoustic degradation, codec distortion, and secondary processing artifacts. In this paper, we provide a comprehensive retrospective of the challenge, detailing the dataset construction, task design, and a systematic analysis of the 25 participating systems. We report three key findings that define the current state of the field: (1) Efficiency vs. Scale: Contrary to the trend of massive generative models, top-performing systems demonstrated that lightweight discriminative architectures (<10M parameters) can achieve state-of-the-art performance, balancing restoration quality with deployment constraints. (2) Generative Trade-off: While generative and hybrid models excel in theoretical perceptual metrics, breakdown analysis reveals they suffer from "reconstruction bias" in high-SNR codec tasks and struggle with hallucination in complex secondary artifact scenarios. (3) Metric Gap: Most critically, our rank correlation analysis exposes a strong negative correlation (\r{ho}=-0.8) between widely-used reference-free metrics (e.g., DNSMOS) and human MOS when evaluating hybrid systems. This indicates that current metrics may over-reward artificial spectral smoothness at the expense of perceptual naturalness. This paper aims to serve as a reference for future research in robust speech restoration and calls for the development of next-generation evaluation metrics sensitive to generative artifacts.

Paper number 121:
Title: Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation
Authors: Mouhyemen Khan, Tatsuya Ibuki, Abhijit Chatterjee
Abstract: Level set methods underpin modern safety techniques such as control barrier functions (CBFs), while also serving as implicit surface representations for geometric shapes via distance fields. Inspired by these two paradigms, we propose a unified framework where the implicit surface itself acts as a CBF. We leverage Gaussian process (GP) implicit surface (GPIS) to represent the safety boundaries, using safety samples which are derived from sensor measurements to condition the GP. The GP posterior mean defines the implicit safety surface (safety belief), while the posterior variance provides a robust safety margin. Although GPs have favorable properties such as uncertainty estimation and analytical tractability, they scale cubically with data. To alleviate this issue, we develop a sparse solution called sparse Gaussian CBFs. To the best of our knowledge, GPIS have not been explicitly used to synthesize CBFs. We validate the approach on collision avoidance tasks in two settings: a simulated 7-DOF manipulator operating around the Stanford bunny, and a quadrotor navigating in 3D around a physical chair. In both cases, Gaussian CBFs (with and without sparsity) enable safe interaction and collision-free execution of trajectories that would otherwise intersect the objects.

Paper number 122:
Title: NVM-in-Cache: Repurposing Commodity 6T SRAM Cache into NVM Analog Processing-in-Memory Engine using a Novel Compute-on-Powerline Scheme
Authors: Subhradip Chakraborty, Ankur Singh, Xuming Chen, Gourav Datta, Akhilesh R. Jaiswal
Abstract: The rapid growth of deep neural network (DNN) workloads has significantly increased the demand for large-capacity on-chip SRAM in machine learning (ML) applications, with SRAM arrays now occupying a substantial fraction of the total die area. To address the dual challenges of storage density and computation efficiency, this paper proposes an NVM-in-Cache architecture that integrates resistive RAM (RRAM) devices into a conventional 6T-SRAM cell, forming a compact 6T-2R bit-cell. This hybrid cell enables Processing-in-Memory (PIM) mode, which performs massively parallel multiply-and-accumulate (MAC) operations directly on cache power lines while preserving stored cache data. By exploiting the intrinsic properties of the 6T-2R structure, the architecture achieves additional storage capability, high computational throughput without any bit-cell area overhead. Circuit- and array-level simulations in GlobalFoundries 22nm FDSOI technology demonstrate that the proposed design achieves a throughput of 0.4 TOPS and 452.34 TOPS/W. For 128 row-parallel operations, the CIFAR-10 classification is demonstrated by mapping a Resnet-18 neural network, achieving an accuracy of 91.76%. These results highlight the potential of the NVM-in-Cache approach to serve as a scalable, energy-efficient computing method by re-purposing existing 6T SRAM cache architecture for next-generation AI accelerators and general purpose processors.

Paper number 123:
Title: Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression
Authors: Cheng Yuan, Jiawei Shao, Chi Zhang, Xuelong Li
Abstract: Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further aggravates the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across different model sizes and architectures remains absent. Motivated by the correlation between compression and intelligence, we introduce information capacity, a measure of model efficiency based on text compression performance relative to computational complexity. Larger models can predict the next token more accurately, achieving greater compression gains but at higher computational costs. Empirical evaluations on mainstream open-source models show that models of varying sizes within a series exhibit consistent information capacity. This metric enables a fair efficiency comparison across model series and accurate performance prediction within a model series. A distinctive feature of information capacity is that it incorporates tokenizer efficiency, which affects both input and output token counts but is often neglected in LLM evaluations. We assess the information capacity of 52 models on 5 heterogeneous datasets and observe consistent results on the influences of tokenizer efficiency, pretraining data, and the mixture-of-experts architecture.

Paper number 124:
Title: MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems
Authors: Barak Or
Abstract: Reliability in multi-agent systems (MAS) built on large language models is increasingly limited by cognitive failures rather than infrastructure faults. Existing observability tools describe failures but do not quantify how quickly distributed reasoning recovers once coherence is lost. We introduce MTTR-A (Mean Time-to-Recovery for Agentic Systems), a runtime reliability metric that measures cognitive recovery latency in MAS. MTTR-A adapts classical dependability theory to agentic orchestration, capturing the time required to detect reasoning drift and restore coherent operation. We further define complementary metrics, including MTBF and a normalized recovery ratio (NRR), and establish theoretical bounds linking recovery latency to long-run cognitive uptime. Using a LangGraph-based benchmark with simulated drift and reflex recovery, we empirically demonstrate measurable recovery behavior across multiple reflex strategies. This work establishes a quantitative foundation for runtime cognitive dependability in distributed agentic systems.

Paper number 125:
Title: Movable Antenna Empowered Near-Field Sensing via Antenna Position Optimization
Authors: Yushen Wang, Weidong Mei, Xin Wei, Ya Fei Wu, Zhi Chen, Boyu Ning
Abstract: Movable antenna (MA) technology exhibits great promise for enhancing the sensing capabilities of future sixth-generation (6G) networks due to its capability to alter antenna array geometry. With the growing prevalence of near-field propagation at ultra-high frequencies, this paper focuses on the application of one-dimensional (1D) and two-dimensional (2D) MA arrays for near-field sensing to jointly estimate the angle and distance information about a target. First, for the 1D MA array scenario, to gain insights into MA-enhanced near-field sensing, we investigate two simplified cases with only angle-of-arrival (AoA) or distance estimation, respectively, assuming that the other information is already known. The worst-case Cramer-Rao bounds (CRBs) on the mean square errors (MSEs) of the AoA estimation and the distance estimation are derived in these two cases. Then, we jointly optimize the positions of the MAs within the 1D array to minimize these CRBs and derive their closed-form solutions, which yield an identical array geometry to MA-enhanced far-field sensing. For the more challenging joint AoA and distance estimation, since the associated worst-case CRB is a highly complex and non-convex function with respect to the MA positions, a discrete sampling-based approach is proposed to sequentially update the MA positions and obtain an efficient suboptimal solution. Furthermore, we investigate the worst-case CRB minimization problems for a 2D MA array under various conditions and extend our proposed algorithms to solve them efficiently. Numerical results demonstrate that the proposed MA-enhanced near-field sensing scheme dramatically outperforms conventional fixed-position antennas (FPAs). Moreover, the joint angle and distance estimation results in a different array geometry from that in the individual estimation of angle/distance or far-field sensing.

Paper number 126:
Title: A Data-Centric Approach to Generalizable Speech Deepfake Detection
Authors: Wen Huang, Yuchen Mao, Yanmin Qian
Abstract: Achieving robust generalization in speech deepfake detection (SDD) remains a primary challenge, as models often fail to detect unseen forgery methods. While research has focused on model-centric and algorithm-centric solutions, the impact of data composition is often underexplored. This paper proposes a data-centric approach, analyzing the SDD data landscape from two practical perspectives: constructing a single dataset and aggregating multiple datasets. To address the first perspective, we conduct a large-scale empirical study to characterize the data scaling laws for SDD, quantifying the impact of source and generator diversity. To address the second, we propose the Diversity-Optimized Sampling Strategy (DOSS), a principled framework for mixing heterogeneous data with two implementations: DOSS-Select (pruning) and DOSS-Weight (re-weighting). Our experiments show that DOSS-Select outperforms the naive aggregation baseline while using only 3% of the total available data. Furthermore, our final model, trained on a 12k-hour curated data pool using the optimal DOSS-Weight strategy, achieves state-of-the-art performance, outperforming large-scale baselines with greater data and model efficiency on both public benchmarks and a new challenge set of various commercial APIs.

Paper number 127:
Title: Multi Modal Attention Networks with Uncertainty Quantification for Automated Concrete Bridge Deck Delamination Detection
Authors: Alireza Moayedikia, Sattar Dorafshan
Abstract: Deteriorating civil infrastructure requires automated inspection techniques overcoming limitations of visual assessment. While Ground Penetrating Radar and Infrared Thermography enable subsurface defect detection, single modal approaches face complementary constraints radar struggles with moisture and shallow defects, while thermography exhibits weather dependency and limited depth. This paper presents a multi modal attention network fusing radar temporal patterns with thermal spatial signatures for bridge deck delamination detection. Our architecture introduces temporal attention for radar processing, spatial attention for thermal features, and cross modal fusion with learnable embeddings discovering complementary defect patterns invisible to individual sensors. We incorporate uncertainty quantification through Monte Carlo dropout and learned variance estimation, decomposing uncertainty into epistemic and aleatoric components for safety critical decisions. Experiments on five bridge datasets reveal that on balanced to moderately imbalanced data, our approach substantially outperforms baselines in accuracy and AUC representing meaningful improvements over single modal and concatenation based fusion. Ablation studies demonstrate cross modal attention provides critical gains beyond within modality attention, while multi head mechanisms achieve improved calibration. Uncertainty quantification reduces calibration error, enabling selective prediction by rejecting uncertain cases. However, under extreme class imbalance, attention mechanisms show vulnerability to majority class collapse. These findings provide actionable guidance: attention based architecture performs well across typical scenarios, while extreme imbalance requires specialized techniques. Our system maintains deployment efficiency, enabling real time inspection with characterized capabilities and limitations.

Paper number 128:
Title: Fun-Audio-Chat Technical Report
Authors: Tongyi Fun Team, Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou
Abstract: Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo, at this https URL .

Paper number 129:
Title: Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms
Authors: Georg Schildbach
Abstract: Cooperative collision avoidance between robots in swarm operations remains an open challenge. Assuming a decentralized architecture, each robot is responsible for making its own control decisions, including motion planning. To this end, most existing approaches mostly rely some form of (wireless) communication between the agents of the swarm. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, transmission faults, and is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC) as a communicationless alternative. It follows the implicit cooperation paradigm, under which the design of the robots is based on consensual (offline) rules, similar to traffic rules. They include the definition of a contingency trajectory for each robot, and a method for construction of mutual collision avoidance constraints. The setup is shown to guarantee the recursive feasibility and collision avoidance between all swarm members in closed-loop operation. Moreover, CMC naturally satisfies the Plug \& Play paradigm, i.e., for new robots entering the swarm. Two numerical examples demonstrate that the collision avoidance guarantee is intact and that the robot swarm operates smoothly under the CMC regime.

Paper number 130:
Title: Relative Localization System Design for SnailBot: A Modular Self-reconfigurable Robot
Authors: Shuhan Zhang, Tin Lun Lam
Abstract: This paper presents the design and implementation of a relative localization system for SnailBot, a modular self reconfigurable robot. The system integrates ArUco marker recognition, optical flow analysis, and IMU data processing into a unified fusion framework, enabling robust and accurate relative positioning for collaborative robotic tasks. Experimental validation demonstrates the effectiveness of the system in realtime operation, with a rule based fusion strategy ensuring reliability across dynamic scenarios. The results highlight the potential for scalable deployment in modular robotic systems.
    