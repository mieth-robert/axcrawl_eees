
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Deep Reinforcement Learning-Based Bidding Strategies for Prosumers Trading in Double Auction-Based Transactive Energy Market
Authors: Jun Jiang, Yuanliang Li, Luyang Hou, Mohsen Ghafouri, Peng Zhang, Jun Yan, Yuhong Liu
Abstract: With the large number of prosumers deploying distributed energy resources (DERs), integrating these prosumers into a transactive energy market (TEM) is a trend for the future smart grid. A community-based double auction market is considered a promising TEM that can encourage prosumers to participate and maximize social welfare. However, the traditional TEM is challenging to model explicitly due to the random bidding behavior of prosumers and uncertainties caused by the energy operation of DERs. Furthermore, although reinforcement learning algorithms provide a model-free solution to optimize prosumers' bidding strategies, their use in TEM is still challenging due to their scalability, stability, and privacy protection limitations. To address the above challenges, in this study, we design a double auction-based TEM with multiple DERs-equipped prosumers to transparently and efficiently manage energy transactions. We also propose a deep reinforcement learning (DRL) model with distributed learning and execution to ensure the scalability and privacy of the market environment. Additionally, the design of two bidding actions (i.e., bidding price and quantity) optimizes the bidding strategies for prosumers. Simulation results show that (1) the designed TEM and DRL model are robust; (2) the proposed DRL model effectively balances the energy payment and comfort satisfaction for prosumers and outperforms the state-of-the-art methods in optimizing the bidding strategies.

Paper number 2:
Title: TSS GAZ PTP: Towards Improving Gumbel AlphaZero with Two-stage Self-play for Multi-constrained Electric Vehicle Routing Problems
Authors: Hui Wang, Xufeng Zhang, Xiaoyu Zhang, Zhenhuan Ding, Chaoxu Mu
Abstract: Recently, Gumbel AlphaZero~(GAZ) was proposed to solve classic combinatorial optimization problems such as TSP and JSSP by creating a carefully designed competition model~(consisting of a learning player and a competitor player), which leverages the idea of self-play. However, if the competitor is too strong or too weak, the effectiveness of self-play training can be reduced, particularly in complex CO problems. To address this problem, we further propose a two-stage self-play strategy to improve the GAZ method~(named TSS GAZ PTP). In the first stage, the learning player uses the enhanced policy network based on the Gumbel Monte Carlo Tree Search~(MCTS), and the competitor uses the historical best trained policy network~(acts as a greedy player). In the second stage, we employ Gumbel MCTS for both players, which makes the competition fiercer so that both players can continuously learn smarter trajectories. We first investigate the performance of our proposed TSS GAZ PTP method on TSP since it is also used as a test problem by the original GAZ. The results show the superior performance of TSS GAZ PTP. Then we extend TSS GAZ PTP to deal with multi-constrained Electric Vehicle Routing Problems~(EVRP), which is a recently well-known real application research topic and remains challenging as a complex CO problem. Impressively, the experimental results show that the TSS GAZ PTP outperforms the state-of-the-art Deep Reinforcement Learning methods in all types of instances tested and outperforms the optimization solver in tested large-scale instances, indicating the importance and promising of employing more dynamic self-play strategies for complex CO problems.

Paper number 3:
Title: Feature Engineering Approach to Building Load Prediction: A Case Study for Commercial Building Chiller Plant Optimization in Tropical Weather
Authors: Zhan Wang, Chen Weidong, Huang Zhifeng, Md Raisul Islam, Chua Kian Jon
Abstract: In tropical countries with high humidity, air conditioning can account for up to 60% of a building's energy use. For commercial buildings with centralized systems, the efficiency of the chiller plant is vital, and model predictive control provides an effective strategy for optimizing operations through dynamic adjustments based on accurate load predictions. Artificial neural networks are effective for modelling nonlinear systems but are prone to overfitting due to their complexity. Effective feature engineering can mitigate this issue. While weather data are crucial for load prediction, they are often used as raw numerical inputs without advanced processing. Clustering features is a technique that can reduce model complexity and enhance prediction accuracy. Although previous studies have explored clustering algorithms for load prediction, none have applied them to multidimensional weather data, revealing a research gap. This study presents a cooling load prediction model that combines a neural network with Kalman filtering and K-means clustering. Applied to real world data from a commercial skyscraper in Singapore's central business district, the model achieved a 46.5% improvement in prediction accuracy. An optimal chiller sequencing strategy was also developed through genetic algorithm optimization of the predictive load, potentially saving 13.8% in energy. Finally, the study evaluated the integration of thermal energy storage into the chiller plant design, demonstrating potential reductions in capital and operational costs of 26% and 13%, respectively.

Paper number 4:
Title: Model-free system identification of surface ships in waves via Hankel dynamic mode decomposition with control
Authors: Giorgio Palma, Andrea Serani, Shawn Aram, David W. Wundrow, David Drazen, Matteo Diez
Abstract: This study introduces and compares the Hankel dynamic mode decomposition with control (Hankel-DMDc) and a novel Bayesian extension of Hankel-DMDc as model-free (i.e., data-driven and equation-free) approaches for system identification and prediction of free-running ship motions in irregular waves. The proposed DMDc methods create a reduced-order model using limited data from the system state and incoming wave elevation histories, with the latter and rudder angle serving as forcing inputs. The inclusion of delayed states of the system as additional dimensions per the Hankel-DMDc improves the representation of the underlying non-linear dynamics of the system by DMD. The approaches are statistically assessed using data from free-running simulations of a 5415M hull's course-keeping in irregular beam-quartering waves at sea state 7, a highly severe condition characterized by nonlinear responses near roll-resonance. The results demonstrate robust performance and remarkable computational efficiency. The results indicate that the proposed methods effectively identify the dynamic system in analysis. Furthermore, the Bayesian formulation incorporates uncertainty quantification and enhances prediction accuracy. Ship motions are predicted with good agreement with test data over a 15 encounter waves observation window. No significant accuracy degradation is noted along the test sequences, suggesting the method can support accurate and efficient maritime design and operational planning.

Paper number 5:
Title: Convergence of Iterative Water-Filling in Multi-User Non-Cooperative Power Control: A Comprehensive Analysis for Sequential, Simultaneous, and Asynchronous Schemes
Authors: Tong Wang
Abstract: Non-cooperative game theory provides a robust framework for analyzing distributed resource allocation in multi-user wireless networks, with \emph{Iterative Water-Filling} (IWF) emerging as a canonical solution for power control problems. Although classical fixed-point theorems guarantee the existence of a Nash Equilibrium (NE) under mild concavity and compactness conditions, the convergence of practical iterative algorithms to that equilibrium remains a challenging endeavor. This challenge intensifies under varying update schedules, interference regimes, and imperfections such as channel estimation errors or feedback delay. In this paper, we present an in-depth examination of IWF in multi-user systems under three different update schemes: (1) synchronous \emph{sequential} updates, (2) synchronous \emph{simultaneous} updates, and (3) \emph{totally asynchronous} updates. We first formulate the water-filling operator in a multi-carrier environment, then recast the iterative process as a fixed-point problem. Using contraction mapping principles, we demonstrate sufficient conditions under which IWF converges to a unique NE and highlight how spectral radius constraints, diagonal dominance, and careful step-size selection are pivotal for guaranteeing convergence. We further discuss robustness to measurement noise, partial updates, and network scaling to emphasize the practical viability of these schemes. This comprehensive analysis unifies diverse threads in the literature while offering novel insights into asynchronous implementations. Our findings enable network designers to ascertain system parameters that foster both stable convergence and efficient spectrum usage.

Paper number 6:
Title: From Target Tracking to Targeting Track -- Part I: A Metric for Spatio-Temporal Trajectory Evaluation
Authors: Tiancheng Li, Yan Song, Hongqi Fan, Jingdong Chen
Abstract: In the realm of target tracking, performance evaluation plays a pivotal role in the design, comparison, and analytics of trackers. Compared with the traditional trajectory composed of a set of point-estimates obtained by a tracker in the measurement time-series, the trajectory that our series of studies including this paper pursued is given by a curve function of time (FoT). The trajectory FoT provides complete information of the movement of the target over time and can be used to infer the state corresponding to arbitrary time, not only at the measurement time. However, there are no metrics available for comparing and evaluating the trajectory FoT. To address this lacuna, we propose a metric denominated as the spatiotemporal-aligned trajectory integral distance (Star-ID). The StarID associates and aligns the estimated and actual trajectories in the spatio-temporal domain and distinguishes between the time-aligned and unaligned segments in calculating the spatial divergence including false alarm, miss-detection and localization errors. The effectiveness of the proposed distance metric and the time-averaged version is validated through theoretical analysis and numerical examples of a single target or multiple targets.

Paper number 7:
Title: Parameter Estimation of the Network of FitzHugh-Nagumo Neurons Based on the Speed-Gradient and Filtering
Authors: Aleksandra Rybalko, Alexander Fradkov
Abstract: The paper addresses the problem of parameter estimation (or identification) in dynamical networks composed of an arbitrary number of FitzHugh-Nagumo neuron models with diffusive couplings between each other. It is assumed that only the membrane potential of each model is measured, while the other state variable and all derivatives remain unmeasured. Additionally, potential measurement errors in the membrane potential due to sensor imprecision are considered. To solve this problem, firstly, the original FitzHugh-Nagumo network is transformed into a linear regression model, where the regressors are obtained by applying a filter-differentiator to specific combinations of the measured variables. Secondly, the speed-gradient method is applied to this linear model, leading to the design of an identification algorithm for the FitzHugh-Nagumo neural network. Sufficient conditions for the asymptotic convergence of the parameter estimates to their true values are derived for the proposed algorithm. Parameter estimation for a network of five interconnected neurons is demonstrated through computer simulation. The results confirm that the sufficient conditions are satisfied in the numerical experiments conducted. Furthermore, the algorithm's capabilities for adjusting the identification accuracy and time are investigated. The proposed approach has potential applications in nervous system modeling, particularly in the context of human brain modeling. For instance, EEG signals could serve as the measured variables of the network, enabling the integration of mathematical neural models with empirical data collected by neurophysiologists.

Paper number 8:
Title: Impact Analysis of Utility-Scale Energy Storage on the ERCOT Grid in Reducing Renewable Generation Curtailments and Emissions
Authors: Cody Buehner, Sharaf K. Magableh, Oraib Dawaghreh, Caisheng Wang
Abstract: This paper explores the solutions for minimizing renewable energy (RE) curtailment in the Texas Electric Reliability Council of Texas (ERCOT) grid. By utilizing current and future planning data from ERCOT and the System Advisor Model from the National Renewable Energy Laboratory, we examine how future renewable energy (RE) initiatives, combined with utility-scale energy storage, can reduce CO2 emissions while reshaping Texas's energy mix. The study projects the energy landscape from 2023 to 2033, considering the planned phase-out of fossil fuel plants and the integration of new wind/solar projects. By comparing emissions under different load scenarios, with and without storage, we demonstrate storage's role in optimizing RE utilization. The findings of this paper provide actionable guidance for energy stakeholders, underscoring the need to expand wind and solar projects with strategic storage solutions to maximize Texas's RE capacity and substantially reduce CO2 emissions.

Paper number 9:
Title: From Target Tracking to Targeting Track -- Part II: Regularized Polynomial Trajectory Optimization
Authors: Tiancheng Li, Yan Song, Guchong Li, Hao Li
Abstract: Target tracking entails the estimation of the evolution of the target state over time, namely the target trajectory. Different from the classical state space model, our series of studies, including this paper, model the collection of the target state as a stochastic process (SP) that is further decomposed into a deterministic part which represents the trend of the trajectory and a residual SP representing the residual fitting error. Subsequently, the tracking problem is formulated as a learning problem regarding the trajectory SP for which a key part is to estimate a trajectory FoT (T-FoT) best fitting the measurements in time series. For this purpose, we consider the polynomial T-FoT and address the regularized polynomial T-FoT optimization employing two distinct regularization strategies seeking trade-off between the accuracy and simplicity. One limits the order of the polynomial and then the best choice is determined by grid searching in a narrow, bounded range while the other adopts $\ell_0$ norm regularization for which the hybrid Newton solver is employed. Simulation results obtained in both single and multiple maneuvering target scenarios demonstrate the effectiveness of our approaches.

Paper number 10:
Title: Patch Stitching Data Augmentation for Cancer Classification in Pathology Images
Authors: Jiamu Wang, Chang-Su Kim, Jin Tae Kwak
Abstract: Computational pathology, integrating computational methods and digital imaging, has shown to be effective in advancing disease diagnosis and prognosis. In recent years, the development of machine learning and deep learning has greatly bolstered the power of computational pathology. However, there still remains the issue of data scarcity and data imbalance, which can have an adversarial effect on any computational method. In this paper, we introduce an efficient and effective data augmentation strategy to generate new pathology images from the existing pathology images and thus enrich datasets without additional data collection or annotation costs. To evaluate the proposed method, we employed two sets of colorectal cancer datasets and obtained improved classification results, suggesting that the proposed simple approach holds the potential for alleviating the data scarcity and imbalance in computational pathology.

Paper number 11:
Title: Large Language Model for Lossless Image Compression with Visual Prompts
Authors: Junhao Du, Chuqin Zhou, Ning Cao, Gang Chen, Yunuo Chen, Zhengxue Cheng, Li Song, Guo Lu, Wenjun Zhang
Abstract: Recent advancements in deep learning have driven significant progress in lossless image compression. With the emergence of Large Language Models (LLMs), preliminary attempts have been made to leverage the extensive prior knowledge embedded in these pretrained models to enhance lossless image compression, particularly by improving the entropy model. However, a significant challenge remains in bridging the gap between the textual prior knowledge within LLMs and lossless image compression. To tackle this challenge and unlock the potential of LLMs, this paper introduces a novel paradigm for lossless image compression that incorporates LLMs with visual prompts. Specifically, we first generate a lossy reconstruction of the input image as visual prompts, from which we extract features to serve as visual embeddings for the LLM. The residual between the original image and the lossy reconstruction is then fed into the LLM along with these visual embeddings, enabling the LLM to function as an entropy model to predict the probability distribution of the residual. Extensive experiments on multiple benchmark datasets demonstrate our method achieves state-of-the-art compression performance, surpassing both traditional and learning-based lossless image codecs. Furthermore, our approach can be easily extended to images from other domains, such as medical and screen content images, achieving impressive performance. These results highlight the potential of LLMs for lossless image compression and may inspire further research in related directions.

Paper number 12:
Title: Orthogonality Analysis in LoRa Uplink Satellite Communications Affected by Doppler Effect
Authors: Jikang Deng, Fatma Benkhelifa, Mohamed-Slim Alouini
Abstract: This paper provides, for the first time, analytical expressions for the Long-Range (LoRa) waveform and cross-correlation in both continuous and discrete time domains under the Doppler effect in satellite communication. We propose the concept and formulas of the shared visibility window for satellites toward two ground devices. Our analysis covers cross-correlation results with varying spreading factors (SF) for no-Doppler and with-Doppler cases. We find the maximum cross-correlation with different SFs and the mean cross-correlation are immune to the Doppler effect. However, the maximum cross-correlation with the same SFs is only immune to high Doppler shift, with its value fluctuating between 0.6 and 1 under high Doppler rate. We interpret this fluctuation by introducing the relationship between transmission start time and cross-correlation. We provide a parameter analysis for orbit height, ground device distance, and inclination angle. Additionally, we analyze the bit error rate (BER) for LoRa signals and observe worse performance under high Doppler shift or interference with same SF. Increasing the SNR or the SIR improves the BER only when Doppler effect is below a frequency threshold. Notably, under Doppler effect, the performance behaviors of BER no longer align with those of maximum cross-correlation. Finally, our results lead to two recommendations: 1) To mitigate Doppler impact on cross-correlation, we recommend utilizing low SFs, high orbit height, short ground device distance, and the transmission start time with high Doppler shift; 2) To mitigate Doppler impact on BER, we recommend employing low SFs, high bandwidth, and transmission start time with high Doppler rate. These conflicting recommendations regarding transmission start time highlight the necessity of Doppler shift compensation techniques to help operate LoRa in space properly.

Paper number 13:
Title: Pseudo-Measurement Enhancement in Power Distribution Systems
Authors: Tao Xu, Kaiqi Wang, Jiadong Zhang, Ji Qiao, Zixuan Zhao, Hong Zhu, Kai Sun
Abstract: With the rapid development of smart distribution networks (DNs), the integrity and accuracy of grid measurement data are crucial to the safety and stability of the entire system. However, the quality of the user power consumption data cannot be guaranteed during the collection and transmission process. To this end, this paper proposes a low-rank tensor completion model based on CANDECOMP/PARAFAC decomposition (CPD-LRTC) to enhance the quality of the measurement data of the DNs. Firstly, the causes and the associated characteristics of the missing data are analyzed, and a third-order standard tensor is constructed as a mathematical model of the measurement data of the DN. Then, a completion model is established based on the characteristics of measurement data and the low rank of the completion tensor, and the alternating direction method of multipliers (ADMM) is used to solve it iteratively. Finally, the proposed model is verified through two case studies, the completion accuracy, the computational efficiency, and the memory usage are compared to traditional methods.

Paper number 14:
Title: Importance-Aware Source-Channel Coding for Multi-Modal Task-Oriented Semantic Communication
Authors: Yi Ma, Chunmei Xu, Zhenyu Liu, Siqi Zhang, Rahim Tafazolli
Abstract: This paper explores the concept of information importance in multi-modal task-oriented semantic communication systems, emphasizing the need for high accuracy and efficiency to fulfill task-specific objectives. At the transmitter, generative AI (GenAI) is employed to partition visual data objects into semantic segments, each representing distinct, task-relevant information. These segments are subsequently encoded into tokens, enabling precise and adaptive transmission control. Building on this frame work, we present importance-aware source and channel coding strategies that dynamically adjust to varying levels of significance at the segment, token, and bit levels. The proposed strategies prioritize high fidelity for essential information while permitting controlled distortion for less critical elements, optimizing overall resource utilization. Furthermore, we address the source-channel coding challenge in semantic multiuser systems, particularly in multicast scenarios, where segment importance varies among receivers. To tackle these challenges, we propose solutions such as rate-splitting coded progressive transmission, ensuring flexibility and robustness in task-specific semantic communication.

Paper number 15:
Title: Multizone sound field reproduction with direction-of-arrival-distribution-based regularization and its application to binaural-centered mode-matching
Authors: Ryo Matsuda, Makoto Otani
Abstract: In higher-order Ambisonics, a framework for sound field reproduction, secondary-source driving signals are generally obtained by regularized mode matching. The authors have proposed a regularization technique based on direction-of-arrival (DoA) distribution of wavefronts in the primary sound field. Such DoA-distribution-based regularization enables a suppression of excessively large driving signal gains for secondary sources that are in the directions far from the primary source direction. This improves the reproduction accuracy at regions away from the reproduction center. First, this study applies the DoA-distribution-based regularization to a multizone sound field reproduction based on the addition theorem. Furthermore, the regularized multizone sound field reproduction is extended to a binaural-centered mode matching (BCMM), which produces two reproduction points, one at each ear, to avoid a degraded reproduction accuracy due to a shrinking sweet spot at higher frequencies. Free-field and binaural simulations were numerically performed to examine the effectiveness of the DoA-distribution-based regularization on the multizone sound field reproduction and the BCMM.

Paper number 16:
Title: Speech Enhancement Using Continuous Embeddings of Neural Audio Codec
Authors: Haoyang Li, Jia Qi Yip, Tianyu Fan, Eng Siong Chng
Abstract: Recent advancements in Neural Audio Codec (NAC) models have inspired their use in various speech processing tasks, including speech enhancement (SE). In this work, we propose a novel, efficient SE approach by leveraging the pre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE methods, which process discrete speech tokens using Language Models (LMs), we perform SE within the continuous embedding space of the pretrained NAC, which is highly compressed along the time dimension for efficient representation. Our lightweight SE model, optimized through an embedding-level loss, delivers results comparable to SE baselines trained on larger datasets, with a significantly lower real-time factor of 0.005. Additionally, our method achieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer in a simulated cloud-based audio transmission environment. This work highlights a new, efficient NAC-based SE solution, particularly suitable for cloud applications where NAC is used to compress audio before transmission. Copyright 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.

Paper number 17:
Title: rECGnition_v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data using deep learning for effective Cardiac Diagnostics
Authors: Shreya Srivastava, Durgesh Kumar, Ram Jiwari, Sandeep Seth, Deepak Sharma
Abstract: The variability in ECG readings influenced by individual patient characteristics has posed a considerable challenge to adopting automated ECG analysis in clinical settings. A novel feature fusion technique termed SACC (Self Attentive Canonical Correlation) was proposed to address this. This technique is combined with DPN (Dual Pathway Network) and depth-wise separable convolution to create a robust, interpretable, and fast end-to-end arrhythmia classification model named rECGnition_v2.0 (robust ECG abnormality detection). This study uses MIT-BIH, INCARTDB and EDB dataset to evaluate the efficiency of rECGnition_v2.0 for various classes of arrhythmias. To investigate the influence of constituting model components, various ablation studies were performed, i.e. simple concatenation, CCA and proposed SACC were compared, while the importance of global and local ECG features were tested using DPN rECGnition_v2.0 model and vice versa. It was also benchmarked with state-of-the-art CNN models for overall accuracy vs model parameters, FLOPs, memory requirements, and prediction time. Furthermore, the inner working of the model was interpreted by comparing the activation locations in ECG before and after the SACC layer. rECGnition_v2.0 showed a remarkable accuracy of 98.07% and an F1-score of 98.05% for classifying ten distinct classes of arrhythmia with just 82.7M FLOPs per sample, thereby going beyond the performance metrics of current state-of-the-art (SOTA) models by utilizing MIT-BIH Arrhythmia dataset. Similarly, on INCARTDB and EDB datasets, excellent F1-scores of 98.01% and 96.21% respectively was achieved for AAMI classification. The compact architectural footprint of the rECGnition_v2.0, characterized by its lesser trainable parameters and diminished computational demands, unfurled several advantages including interpretability and scalability.

Paper number 18:
Title: A 2-bit Wideband 5G mm-Wave RIS with Low Side Lobe Levels and no Quantization Lobe
Authors: Ruiqi Wang, Yiming Yang, Atif Shamim
Abstract: Reconfigurable intelligent surface (RIS) with 1-bit phase resolution suffers from high side lobe levels (SLLs) in the near field and pronounced quantization lobe levels (QLLs) in the far field, which is detrimental for the quality of wireless communication. RIS design is further challenging in the mm-wave bands, where typically large bandwidths are required. To address these limitations, this work proposes a novel wideband 5G mm-Wave RIS with 2-bit phase quantization, capable of covering the entire 5G n258 band. The proposed unit cell design is a combination of a grounded main slot, a parasitic slot, and a coupling patch, utilizing only two PIN diodes. This design achieves a 2-bit bandwidth (BW) of 24.1--27.7 GHz (13.9\%) and an effective 1-bit BW of 20.0--28.9 GHz (36.4\%). The unit cell features a compact size of 0.39$\lambda$ $\times$ 0.39$\lambda$, providing decent angular stability of $\pm30^\circ$ as well as eliminating the grating lobes. Based on this unit cell design, a 20 $\times$ 20 RIS array has been designed, fabricated, and experimentally characterized. The measured results demonstrate that, within the 5G n258 band, the proposed 2-bit 5G mm-Wave RIS achieves an SLL of -15.4 dB in the near field, representing a 7.6 dB improvement compared to its 1-bit counterpart. Furthermore, it has almost negligible QLL (-14.6 dB) in the far field, providing a suppression of 13.3 dB relative to the 1-bit design. Thus, the proposed 2-bit mm-Wave RIS offers wideband performance, low SLL, negligible QLL, decent angular stability, and a broad beam scanning range of 50$^\circ$, making it a promising solution for high-resolution and low-interference mm-Wave wireless communication systems.

Paper number 19:
Title: A Multi-layer Non-Terrestrial Networks Architecture for 6G and Beyond under Realistic Conditions and with Practical Limitations
Authors: Faical Khennoufa, Khelil Abdellatif, Halim Yanikomeroglu, Metin Ozturk, Taissir Elganimi, Ferdi Kara, Khaled Rabie
Abstract: In order to bolster the next generation of wireless networks, there has been a great deal of interest in non-terrestrial networks (NTN), including satellites, high altitude platform stations (HAPS), and uncrewed aerial vehicles (UAV). To unlock their full potential, these platforms can integrate advanced technologies such as reconfigurable intelligent surfaces~(RIS) and next-generation multiple access (NGMA). However, in practical applications, transceivers often suffer from radio frequency (RF) impairments, which limit system performance. In this regard, this paper explores the potential of multi-layer NTN architecture to mitigate path propagation loss and improve network performance under hardware impairment limitations. First, we present current research activities in the NTN framework, including RIS, multiple access technologies, and hardware impairments. Next, we introduce a multi-layer NTN architecture with hardware limitations. This architecture includes HAPS super-macro base stations (HAPS-SMBS), UAVs--equipped with passive or active transmissive RIS--, and NGMA techniques, like non-orthogonal multiple access (NOMA), as the multiple access techniques to serve terrestrial devices. Additionally, we present and discuss potential use cases of the proposed multi-layer architecture considering hardware impairments. The multi-layer NTN architecture combined with advanced technologies, such as RIS and NGMA, demonstrates promising results; however, the performance degradation is attributed to RF impairments. Finally, we identify future research directions, including RF impairment mitigation, UAV power management, and antenna designs.

Paper number 20:
Title: voc2vec: A Foundation Model for Non-Verbal Vocalization
Authors: Alkis Koudounas, Moreno La Quatra, Marco Sabato Siniscalchi, Elena Baralis
Abstract: Speech foundation models have demonstrated exceptional capabilities in speech-related tasks. Nevertheless, these models often struggle with non-verbal audio data, such as vocalizations, baby crying, etc., which are critical for various real-world applications. Audio foundation models well handle non-speech data but also fail to capture the nuanced features of non-verbal human sounds. In this work, we aim to overcome the above shortcoming and propose a novel foundation model, termed voc2vec, specifically designed for non-verbal human data leveraging exclusively open-source non-verbal audio datasets. We employ a collection of 10 datasets covering around 125 hours of non-verbal audio. Experimental results prove that voc2vec is effective in non-verbal vocalization classification, and it outperforms conventional speech and audio foundation models. Moreover, voc2vec consistently outperforms strong baselines, namely OpenSmile and emotion2vec, on six different benchmark datasets. To the best of the authors' knowledge, voc2vec is the first universal representation model for vocalization tasks.

Paper number 21:
Title: Vision Transformer Accelerator ASIC for Real-Time, Low-Power Sleep Staging
Authors: Tristan Robitaille, Xilin Liu
Abstract: This paper introduces a lightweight vision transformer aimed at automatic sleep staging in a wearable device. The model is trained on the MASS SS3 dataset and achieves an accuracy of 82.9% on a 4-stage classification task with only 31.6k weights. The model is implemented in hardware and synthesized in 65nm CMOS. The accelerator consumes 6.54mW of dynamic power and 11.0mW of leakage power over 45.6ms. Using aggressive power gating while the accelerator is idle, it is calculated that the effective power consumption is 0.56mW. The accelerator uses only 0.754mm2 of silicon and has a clock frequency of 379MHz. These metrics are possible thanks to a layer-dependent fixed-point format and data width and a window average filter on the final softmax layer of the vision transformer.

Paper number 22:
Title: Revealing Microscopic Objects in Fluorescence Live Imaging by Video-to-video Translation Based on A Spatial-temporal Generative Adversarial Network
Authors: Yang Jiao, Mei Yang, Mo Weng
Abstract: In spite of being a valuable tool to simultaneously visualize multiple types of subcellular structures using spectrally distinct fluorescent labels, a standard fluoresce microscope is only able to identify a few microscopic objects; such a limit is largely imposed by the number of fluorescent labels available to the sample. In order to simultaneously visualize more objects, in this paper, we propose to use video-to-video translation that mimics the development process of microscopic objects. In essence, we use a microscopy video-to-video translation framework namely Spatial-temporal Generative Adversarial Network (STGAN) to reveal the spatial and temporal relationships between the microscopic objects, after which a microscopy video of one object can be translated to another object in a different domain. The experimental results confirm that the proposed STGAN is effective in microscopy video-to-video translation that mitigates the spectral conflicts caused by the limited fluorescent labels, allowing multiple microscopic objects be simultaneously visualized.

Paper number 23:
Title: Demand Forecasting for Electric Vehicle Charging Stations using Multivariate Time-Series Analysis
Authors: Saba Sanami, Hesam Mosalli, Yu Yang, Hen-Geul Yeh, Amir G. Aghdam
Abstract: As the number of electric vehicles (EVs) continues to grow, the demand for charging stations is also increasing, leading to challenges such as long wait times and insufficient infrastructure. High-precision forecasting of EV charging demand is crucial for efficient station management, to address some of these challenges. This paper presents an approach to predict the charging demand at 15-minute intervals for the day ahead using a multivariate long short-term memory (LSTM) network with an attention mechanism. Additionally, the model leverages explainable AI techniques to evaluate the influence of various factors on the predictions, including weather conditions, day of the week, month, and any holiday. SHapley Additive exPlanations (SHAP) are used to quantify the contribution of each feature to the final forecast, providing deeper insights into how these factors affect prediction accuracy. As a result, the framework offers enhanced decision-making for infrastructure planning. The efficacy of the proposed method is demonstrated by simulations using the test data collected from the EV charging stations at California State University, Long Beach.

Paper number 24:
Title: Software defined demodulation of multiple frequency shift keying with dense neural network for weak signal communications
Authors: Mykola Kozlenko, Vira Vialkova
Abstract: In this paper we present the symbol and bit error rate performance of the weak signal digital communications system. We investigate orthogonal multiple frequency shift keying modulation scheme with supervised machine learning demodulation approach using simple dense end-to-end artificial neural network. We focus on the interference immunity over an additive white Gaussian noise with average signal-to-noise ratios from -20 dB to 0 dB.

Paper number 25:
Title: Physics-Informed Gradient Estimation for Accelerating Deep Learning based AC-OPF
Authors: Kejun Chen, Shourya Bose, Yu Zhang
Abstract: The optimal power flow (OPF) problem can be rapidly and reliably solved by employing responsive online solvers based on neural networks. The dynamic nature of renewable energy generation and the variability of power grid conditions necessitate frequent neural network updates with new data instances. To address this need and reduce the time required for data preparation time, we propose a semi-supervised learning framework aided by data augmentation. In this context, ridge regression replaces the traditional solver, facilitating swift prediction of optimal solutions for the given input load demands. Additionally, to accelerate the backpropagation during training, we develop novel batch-mean gradient estimation approaches along with a reduced branch set to alleviate the complexity of gradient computation. Numerical simulations demonstrate that our neural network, equipped with the proposed gradient estimators, consistently achieves feasible and near-optimal solutions. These results underline the effectiveness of our approach for practical implementation in real-time OPF applications.

Paper number 26:
Title: Sensing-Assisted Channel Estimation for OFDM ISAC Systems: Framework, Algorithm, and Analysis
Authors: Shuhan Wang, Aimin Tang, Xudong Wang, Wenze Qu
Abstract: Integrated sensing and communication (ISAC) has garnered significant attention in recent years. In this paper, we delve into the topic of sensing-assisted communication within ISAC systems. More specifically, a novel sensing-assisted channel estimation scheme is proposed for bistatic orthogonal-frequency-division-multiplexing (OFDM) ISAC systems. A framework of sensing-assisted channel estimator is first developed, integrating a tailored low-complexity sensing algorithm to facilitate real-time channel estimation and decoding. To address the potential sensing errors caused by low-complexity sensing algorithms, a sensing-assisted linear minimum mean square error (LMMSE) estimation algorithm is then developed. This algorithm incorporates tolerance factors designed to account for deviations between estimated and true channel parameters, enabling the construction of robust correlation matrices for LMMSE estimation. Additionally, we establish a systematic mechanism for determining these tolerance factors. A comprehensive analysis of the normalized mean square error (NMSE) performance and computational complexity is finally conducted, providing valuable insights into the selection of the estimator's parameters. The effectiveness of our proposed scheme is validated by extensive simulations. Compared to existing methods, our proposed scheme demonstrates superior performance, particularly in high signal-to-noise ratio (SNR) regions or with large bandwidths, while maintaining low computational complexity.

Paper number 27:
Title: Deep learning approaches to surgical video segmentation and object detection: A Scoping Review
Authors: Devanish N. Kamtam, Joseph B. Shrager, Satya Deepya Malla, Nicole Lin, Juan J. Cardona, Jake J. Kim, Clarence Hu
Abstract: Introduction: Computer vision (CV) has had a transformative impact in biomedical fields such as radiology, dermatology, and pathology. Its real-world adoption in surgical applications, however, remains limited. We review the current state-of-the-art performance of deep learning (DL)-based CV models for segmentation and object detection of anatomical structures in videos obtained during surgical procedures. Methods: We conducted a scoping review of studies on semantic segmentation and object detection of anatomical structures published between 2014 and 2024 from 3 major databases - PubMed, Embase, and IEEE Xplore. The primary objective was to evaluate the state-of-the-art performance of semantic segmentation in surgical videos. Secondary objectives included examining DL models, progress toward clinical applications, and the specific challenges with segmentation of organs/tissues in surgical videos. Results: We identified 58 relevant published studies. These focused predominantly on procedures from general surgery [20(34.4%)], colorectal surgery [9(15.5%)], and neurosurgery [8(13.8%)]. Cholecystectomy [14(24.1%)] and low anterior rectal resection [5(8.6%)] were the most common procedures addressed. Semantic segmentation [47(81%)] was the primary CV task. U-Net [14(24.1%)] and DeepLab [13(22.4%)] were the most widely used models. Larger organs such as the liver (Dice score: 0.88) had higher accuracy compared to smaller structures such as nerves (Dice score: 0.49). Models demonstrated real-time inference potential ranging from 5-298 frames-per-second (fps). Conclusion: This review highlights the significant progress made in DL-based semantic segmentation for surgical videos with real-time applicability, particularly for larger organs. Addressing challenges with smaller structures, data availability, and generalizability remains crucial for future advancements.

Paper number 28:
Title: Robust Nonlinear Data-Driven Predictive Control for Mixed Vehicle Platoons via Koopman Operator and Reachability Analysis
Authors: Shuai Li, Jiawei Wang, Kaidi Yang, Qing Xu, Jianqiang Wang, Keqiang Li
Abstract: Mixed vehicle platoons, comprising connected and automated vehicles (CAVs) and human-driven vehicles (HDVs), hold significant potential for enhancing traffic performance. Most existing research assumes linear system dynamics and often ignores the impact of critical factors such as noise, disturbances, and attacks, which are inherent to real-world scenarios. To address these limitations, we propose a Robust Nonlinear Data-Driven Predictive Control (RNDDPC) framework that ensures safe and optimal control under uncertain and adverse conditions. By utilizing Koopman operator theory, we map the system's nonlinear dynamics into a higher-dimensional space, constructing a Koopman-based linear predictor that approximates the behavior of the original nonlinear system. To mitigate modeling errors associated with this predictor, we introduce a data-driven reachable set analysis technique that performs secondary learning using matrix zonotope sets, generating a reachable set predictor for over-approximation of the future states of the underlying system. Then, we formulate the RNDDPC optimization problem and solve it in a receding horizon manner for robust control inputs. Extensive simulations demonstrate that the proposed framework significantly outperforms baseline methods in tracking performance under noise, disturbances, and attacks.

Paper number 29:
Title: Predictive Modeling of Rat Brain Local Field Potentials using Single-Variable and Multivariable Approaches
Authors: AmirAli Kalbasi, Shole Jamali, Mahdi Aliyari Shoorehdeli, Abbas Haghparast
Abstract: Accurate prediction of neural dynamics in the brain's reward circuitry is crucial for elucidating how natural and pharmacological rewards influence neural activity and connectivity. Traditional linear models, such as autoregressive (AR) and vector autoregressive (VAR), often inadequately capture the inherent nonlinear interactions in neural data. This study develops and benchmarks both linear and advanced deep learning models for predicting local field potentials (LFPs) in the rat hippocampus (HIP) and nucleus accumbens (NAc) across morphine, food, and saline conditions. We compared AR, VAR, long short-term memory (LSTM), and wavelet-based deep learning model (WCLSA). Additionally, a novel wavelet coherence-enhanced model (WCOH CLSA) was introduced to capture cross-region connectivity. Results indicate that WCLSA achieves superior predictive accuracy (up to 0.97 for HIP in food, 0.96 for NAc in morphine), while VAR performs competitively in the food group due to significant HIP-NAc correlation. Wavelet coherence analysis reveals robust connectivity in natural reward contexts and disrupted or nonlinear relationships under pharmacological influence. These findings highlight the differential engagement of HIP and NAc in reward processing and underscore the importance of advanced nonlinear models for capturing complex neural dynamics. The study provides a robust framework for predictive neuroscience and elucidates functional interactions within the reward circuitry.

Paper number 30:
Title: Optimizing Antenna Activation for Even Power Distribution in Multi-Beam Satellite Systems Using Genetic Algorithm
Authors: Juan Andrés Vasquez-Peralvo, Aral Ertug Zorkun, Jorge Querol, Eva Lagunas, Flor Ortiz, Luis Manuel Garcés-Socarrás, Jorge Luis González-Rios, Symeon Chatzinotas
Abstract: Recent advancements in onboard satellite communication have significantly enhanced the ability to dynamically modify the radiation pattern of a Direct Radiating Array, which is essential for both conventional communication satellites like GEO and those in lower orbits such as LEO. This is particularly relevant for communication at 28 GHz, a key frequency in the mmWave spectrum, used for high-bandwidth satellite links and 5G communications. Critical design factors include the number of beams, beamwidth, and SLL for each beam. However, in multibeam scenarios, balancing these design factors can result in uneven power distribution, leading to over-saturation in centrally located antenna elements due to frequent activations. This paper introduces a GA-based approach to optimize beamforming coefficients by modulating the amplitude component of the weight matrix, while imposing a constraint on activation instances per element to avoid over-saturation in the RF chain. The proposed method, tested on an 16x16 DRA patch antenna array at 28 GHz for a CubeSat orbiting at 500 km, demonstrates how the algorithm efficiently meets beam pattern requirements and ensures uniform activation distribution. These findings are particularly relevant for emerging satellite systems and 5G networks operating in the mmWave spectrum.

Paper number 31:
Title: A Metasurface-based Cross-slot Aperture Coupled Antenna Array for Ku-band Satellites in Reception
Authors: Praveen Naidu Vummadisetty, Aral Ertug Zorkun, Juan Andres Vasquez Peralvo, Mehmet Abbak, Eva Lagunas, Symeon Chatzinotas
Abstract: The demand for cost-effective, low-profile user terminals for satellite communications supporting multicast services for Geostationary Orbit (GEO) satellites, has become a key focus for many Direct-to-Home (DTH) providers where the high data rates in the downlink are required. Planar antenna arrays with increased frequency bandwidth and improved ratio using meta-surfaces are considered as an effective solution for such systems. This paper presents a low-cost, aperture-coupled metasurface-enhanced patch antenna, operating within the 10.7-12.7 GHz frequency range. The antenna is designed to achieve a realized gain of at least 27 dBi across the band of interest using 32 x 32 array antennas distributed in a rectangular lattice. Initially configured for linear polarization, the antenna can be upgraded to support dual or circular polarization if required.

Paper number 32:
Title: Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures
Authors: Luis Lara, Lucia Eve Berger, Rajesh Raju, Shawn Whitfield
Abstract: The COVID-19 pandemic strained healthcare resources and prompted discussion about how machine learning can alleviate physician burdens and contribute to diagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but few studies predict the severity of a patient's condition from CXRs. In this study, we produce a large COVID severity dataset by merging three sources and investigate the efficacy of transfer learning using ImageNet- and CXR-pretrained models and vision transformers (ViTs) in both severity regression and classification tasks. A pretrained DenseNet161 model performed the best on the three class severity prediction problem, reaching 80% accuracy overall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases, respectively. The ViT had the best regression results, with a mean absolute error of 0.5676 compared to radiologist-predicted severity scores. The project's source code is publicly available.

Paper number 33:
Title: Near-Field Localization with Dynamic Metasurface Antennas at THz: A CRB Minimizing Approach
Authors: Ioannis Gavras, George C. Alexandropoulos
Abstract: The recent trend for extremely massive antenna arrays and high frequencies facilitates localization and sensing, offering increased angular and range resolution. In this letter, we focus on the emerging technology of Dynamic Metasurface Antennas (DMAs) and present a novel framework for the design of their analog beamforming weights, targeting high accuracy near-field localization at the THz frequency band. We derive the Cramér-Rao Bound (CRB) for the estimation of the positions of multiple users with a DMA-based receiver, which is then utilized as the optimization objective for the receiver's discrete tunable states of its metamaterials. Leveraging the DMA structure, we reformulate the localization objective into a constrained Rayleigh quotient maximization problem, which is efficiently solved via two schemes: one based on projection and a greedy one. Our simulation results verify the validity of our near-field localization analysis, showcasing the effectiveness of the proposed near-field localization designs over the optimum exhaustive search solution and state-of-the-art schemes.

Paper number 34:
Title: Equilibrium Unit Based Localized Affine Formation Maneuver for Multi-agent Systems
Authors: Cheng Zhu, Xiaotao Zhou, Bing Huang
Abstract: Current affine formation maneuver of multi-agent systems (MASs) relys on the affine localizability determined by generic assumption for nominal configuration and global construction manner. This does not live up to practical constraints of robot swarms. In this paper, an equilibrium unit based structure is proposed to achieve affine localizability. In an equilibrium unit, existence of non-zero weights between nodes is guaranteed and their summation is proved to be non-zero. To remove the generic assumption, a notion of layerable directed graph is introduced, based on which a sufficient condition associated equilibrium unit is presented to establish affine localizability condition. Within this framework, distributed local construction manner is performed by a designed equilibrium unit construction (EUC) method. With the help of localized communication criterion (LCC) and localized sensing based affine formation maneuver control (LSAFMC) protocol, self-reconstruction capability is possessed by MASs when nodes are added to or removed from the swarms.

Paper number 35:
Title: Holographic MIMO Multi-Cell Communications
Authors: Kangda Zhi, Tianyu Yang, Shuangyang Li, Yi Song, Tuo Wu, Giuseppe Caire
Abstract: Metamaterial antennas are appealing for next-generation wireless networks due to their simplified hardware and much-reduced size, power, and cost. This paper investigates the holographic multiple-input multiple-output (HMIMO)-aided multi-cell systems with practical per-radio frequency (RF) chain power constraints. With multiple antennas at both base stations (BSs) and users, we design the baseband digital precoder and the tuning response of HMIMO metamaterial elements to maximize the weighted sum user rate. Specifically, under the framework of block coordinate descent (BCD) and weighted minimum mean square error (WMMSE) techniques, we derive the low-complexity closed-form solution for baseband precoder without requiring bisection search and matrix inversion. Then, for the design of HMIMO metamaterial elements under binary tuning constraints, we first propose a low-complexity suboptimal algorithm with closed-form solutions by exploiting the hidden convexity (HC) in the quadratic problem and then further propose an accelerated sphere decoding (SD)-based algorithm which yields global optimal solution in the iteration. For HMIMO metamaterial element design under the Lorentzian-constrained phase model, we propose a maximization-minorization (MM) algorithm with closed-form solutions at each iteration step. Furthermore, in a simplified multiple-input single-output (MISO) scenario, we derive the scaling law of downlink single-to-noise (SNR) for HMIMO with binary and Lorentzian tuning constraints and theoretically compare it with conventional fully digital/hybrid arrays. Simulation results demonstrate the effectiveness of our algorithms compared to benchmarks and the benefits of HMIMO compared to conventional arrays.

Paper number 36:
Title: FedDA-TSformer: Federated Domain Adaptation with Vision TimeSformer for Left Ventricle Segmentation on Gated Myocardial Perfusion SPECT Image
Authors: Yehong Huang, Chen Zhao, Rochak Dhakal, Min Zhao, Guang-Uei Hung, Zhixin Jiang, Weihua Zhou
Abstract: Background and Purpose: Functional assessment of the left ventricle using gated myocardial perfusion (MPS) single-photon emission computed tomography relies on the precise extraction of the left ventricular contours while simultaneously ensuring the security of patient data. Methods: In this paper, we introduce the integration of Federated Domain Adaptation with TimeSformer, named 'FedDA-TSformer' for left ventricle segmentation using MPS. FedDA-TSformer captures spatial and temporal features in gated MPS images, leveraging spatial attention, temporal attention, and federated learning for improved domain adaptation while ensuring patient data security. In detail, we employed Divide-Space-Time-Attention mechanism to extract spatio-temporal correlations from the multi-centered MPS datasets, ensuring that predictions are spatio-temporally consistent. To achieve domain adaptation, we align the model output on MPS from three different centers using local maximum mean discrepancy (LMMD) loss. This approach effectively addresses the dual requirements of federated learning and domain adaptation, enhancing the model's performance during training with multi-site datasets while ensuring the protection of data from different hospitals. Results: Our FedDA-TSformer was trained and evaluated using MPS datasets collected from three hospitals, comprising a total of 150 subjects. Each subject's cardiac cycle was divided into eight gates. The model achieved Dice Similarity Coefficients (DSC) of 0.842 and 0.907 for left ventricular (LV) endocardium and epicardium segmentation, respectively. Conclusion: Our proposed FedDA-TSformer model addresses the challenge of multi-center generalization, ensures patient data privacy protection, and demonstrates effectiveness in left ventricular (LV) segmentation.

Paper number 37:
Title: Data-Driven Discrepancy Modeling in Higher-Dimensional State Space via Coprime Factorization
Authors: Sourav Sinha, Mazen Farhood
Abstract: This work provides a data-driven framework that combines coprime factorization with a lifting linearization technique to model the discrepancy between a nonlinear system and its nominal linear approximation using a linear time-invariant (LTI) state-space model in a higher-dimensional state space. In the proposed framework, the nonlinear system is represented in terms of the left coprime factors of the nominal linear system, along with perturbations modeled as stable, norm-bounded LTI systems in a higher-dimensional state space using a deep learning approach. Our method builds on a recently proposed parametrization for norm-bounded systems, enabling the simultaneous minimization of the H-infinity norm of the learned perturbations. We also provide a coprime factorization-based approach as an alternative to direct methods for learning lifted LTI approximations of nonlinear systems. In this approach, the LTI approximations are obtained by learning their left coprime factors, which remain stable even when the original system is unstable. The effectiveness of the proposed discrepancy modeling approach is demonstrated through multiple examples.

Paper number 38:
Title: Least Squares based Estimation of Thevenin Equivalent in Noisy Distribution Grid
Authors: Taha Saeed Khan
Abstract: This work presents a novel approach that synergizes the extremum seeking method with an online least squares estimation technique to accurately estimate Thevenin equivalent circuit being seen at each node in distribution grids. Thevenin's theorem offers a simplified representation of electrical networks, critical for the effective monitoring, control, and optimization of grid operations. However, real-time identification of Thevenin parameters, particularly impedance, poses significant challenges due to the dynamic nature of distribution grids. By integrating extremum seeking algorithms, which are adept at locating optima in dynamic systems without explicit model information, with the robustness of least squares estimation, we develop a novel methodology that continuously adapts to grid fluctuations. These fusion harnesses the strengths of both techniques: the extremum seeking method's non-model-based optimization capabilities and the least squares method's proficiency in estimating parameter value in a noisy environment. The result is a robust, adaptive algorithm capable of delivering reliable Thevenin parameter estimations in real-time. Our simulation results demonstrate the efficacy of the proposed method, showcasing its potential as a tool for enhanced grid management and resilience.

Paper number 39:
Title: Enhancing sensor attack detection in supervisory control systems modeled by probabilistic automata
Authors: Parastou Fahim, Samuel Oliveira, Rômulo Meira-Góes
Abstract: Sensor attacks compromise the reliability of cyber-physical systems (CPSs) by altering sensor outputs with the objective of leading the system to unsafe system states. This paper studies a probabilistic intrusion detection framework based on $\lambda$-sensor-attack detectability ($\lambda$-sa), a formal measure that evaluates the likelihood of a system being under attack based on observed behaviors. Our framework enhances detection by extending its capabilities to identify multiple sensor attack strategies using probabilistic information, which enables the detection of sensor attacks that were undetected by current detection methodologies. We develop a polynomial-time algorithm that verifies $\lambda$-sa detectability by constructing a weighted verifier automaton and solving the shortest path problem. Additionally, we propose a method to determine the maximum detection confidence level ($\lambda$*) achievable by the system, ensuring the highest probability of identifying attack-induced behaviors.

Paper number 40:
Title: DiffKAN-Inpainting: KAN-based Diffusion model for brain tumor inpainting
Authors: Tianli Tao, Ziyang Wang, Han Zhang, Theodoros N. Arvanitis, Le Zhang
Abstract: Brain tumors delay the standard preprocessing workflow for further examination. Brain inpainting offers a viable, although difficult, solution for tumor tissue processing, which is necessary to improve the precision of the diagnosis and treatment. Most conventional U-Net-based generative models, however, often face challenges in capturing the complex, nonlinear latent representations inherent in brain imaging. In order to accomplish high-quality healthy brain tissue reconstruction, this work proposes DiffKAN-Inpainting, an innovative method that blends diffusion models with the Kolmogorov-Arnold Networks architecture. During the denoising process, we introduce the RePaint method and tumor information to generate images with a higher fidelity and smoother margin. Both qualitative and quantitative results demonstrate that as compared to the state-of-the-art methods, our proposed DiffKAN-Inpainting inpaints more detailed and realistic reconstructions on the BraTS dataset. The knowledge gained from ablation study provide insights for future research to balance performance with computing cost.

Paper number 41:
Title: Joint Size and Placement Optimization for IRS-Aided Communications with Active and Passive Elements
Authors: Qiaoyan Peng, Qingqing Wu, Wen Chen, Chaoying Huang, Beixiong Zheng, Shaodan Ma, Mengnan Jian, Yijian Chen, Jun Yang
Abstract: Different types of intelligent reflecting surfaces (IRS) are exploited for assisting wireless communications. The joint use of passive IRS (PIRS) and active IRS (AIRS) emerges as a promising solution owing to their complementary advantages. They can be integrated into a single hybrid active-passive IRS (HIRS) or deployed in a distributed manner, which poses challenges in determining the IRS element allocation and placement for rate maximization. In this paper, we investigate the capacity of an IRS-aided wireless communication system with both active and passive elements. Specifically, we consider three deployment schemes: 1) base station (BS)-HIRS-user (BHU); 2) BS-AIRS-PIRS-user (BAPU); 3) BS-PIRS-AIRS-user (BPAU). Under the line-of-sight channel model, we formulate a rate maximization problem via a joint optimization of the IRS element allocation and placement. We first derive the optimized number of active and passive elements for BHU, BAPU, and BPAU schemes, respectively. Then, low-complexity HIRS/AIRS placement strategies are provided. To obtain more insights, we characterize the system capacity scaling orders for the three schemes with respect to the large total number of IRS elements, amplification power budget, and BS transmit power. Finally, simulation results are presented to validate our theoretical findings and show the performance difference among the BHU, BAPU, and BPAU schemes with the proposed joint design under various system setups.

Paper number 42:
Title: Fast Finite-Time Sliding Mode Control for Chattering-Free Trajectory Tracking of Robotic Manipulators
Authors: Momammad Ali Ranjbar
Abstract: Achieving precise and efficient trajectory tracking in robotic arms remains a key challenge due to system uncertainties and chattering effects in conventional sliding mode control (SMC). This paper presents a chattering-free fast terminal sliding mode control (FTSMC) strategy for a three-degree-of-freedom (3-DOF) robotic arm, designed to enhance tracking accuracy and robustness while ensuring finite-time convergence. The control framework is developed using Newton-Euler dynamics, followed by a state-space representation that captures the system's angular position and velocity. By incorporating an improved sliding surface and a Lyapunov-based stability analysis, the proposed FTSMC effectively mitigates chattering while preserving the advantages of SMC, such as fast response and strong disturbance rejection. The controller's performance is rigorously evaluated through comparisons with conventional PD sliding mode control (PDSMC) and terminal sliding mode control (TSMC). Simulation results demonstrate that the proposed approach achieves superior trajectory tracking performance, faster convergence, and enhanced stability compared to existing methods, making it a promising solution for high-precision robotic applications.

Paper number 43:
Title: Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM
Authors: Jiatong Shi, Chunlei Zhang, Jinchuan Tian, Junrui Ni, Hao Zhang, Shinji Watanabe, Dong Yu
Abstract: Recent efforts have extended textual LLMs to the speech domain. Yet, a key challenge remains, which is balancing speech understanding and generation while avoiding catastrophic forgetting when integrating acoustically rich codec-based representations into models originally trained on text. In this work, we propose a novel approach that leverages continual pre-training (CPT) on a pre-trained textual LLM to create a codec-based speech language model. This strategy mitigates the modality gap between text and speech, preserving the linguistic reasoning of the original model while enabling high-fidelity speech synthesis. We validate our approach with extensive experiments across multiple tasks, including automatic speech recognition, text-to-speech, speech-to-text translation, and speech-to-speech translation (S2ST), demonstrating that our model achieves superior TTS performance and, notably, the first end-to-end S2ST system based on neural codecs.

Paper number 44:
Title: Design of a communication system Images for identification of vehicle plates
Authors: Fabrizio Andre Farfán Prado, William César Pérez Campos, Steisy Anahi Carreño Tacuri, Favio David Cabrera Alva
Abstract: This work presents the design and implementation of a low-energy wireless image transmission system for vehicle plate recognition, using the ESP32-CAM and LoRa DXLR01 modules. The system captures images in real time, processes them locally and transmits them via UART2 to a second ESP32. Subsequently, the data is sent through the LoRa link and stored on the ThingSpeak platform for remote monitoring. The experimental results show that the system achieves a recognition rate of 92.4% under optimal lighting conditions and an average transmission latency of 3.2 seconds. The energy efficiency of the system makes it suitable for applications in access control, vehicular surveillance and infrastructure monitoring.

Paper number 45:
Title: 220 GHz RIS-Aided Multi-user Terahertz Communication System: Prototype Design and Over-the-Air Experimental Trials
Authors: Yanzhao Hou, Guoning Wang, Chen Chen, Gaoze Mu, Qimei Cui, Xiaofeng Tao, Yuanmu Yang
Abstract: Terahertz (THz) communication technology is regarded as a promising enabler for achieving ultra-high data rate transmission in next-generation communication systems. To mitigate the high path loss in THz systems, the transmitting beams are typically narrow and highly directional, which makes it difficult for a single beam to serve multiple users simultaneously. To address this challenge, reconfigurable intelligent surfaces (RIS), which can dynamically manipulate the wireless propagation environment, have been integrated into THz communication systems to extend coverage. Existing works mostly remain theoretical analysis and simulation, while prototype validation of RIS-assisted THz communication systems is scarce. In this paper, we designed a liquid crystal-based RIS operating at 220 GHz supporting both single-user and multi-user communication scenarios, followed by a RIS-aided THz communication system prototype. To enhance the system performance, we developed a beamforming method including a real-time power feedback control, which is compatible with both single-beam and multibeam modes. To support simultaneous multi-user transmission, we designed an OFDM-based resource allocation scheme. In our experiments, the received power gain with RIS is no less than 10 dB in the single-beam mode, and no less than 5 dB in the multi-beam mode. With the assistance of RIS, the achievable rate of the system could reach 2.341 Gbps with 3 users sharing 400 MHz bandwidth and the bit error rate (BER) of the system decreased sharply. Finally, an image transmission experiment was conducted to vividly show that the receiver could recover the transmitted information correctly with the help of RIS. The experimental results also demonstrated that the received signal quality was enhanced through power feedback adjustments.

Paper number 46:
Title: Engineering and Validating Cyber-Physical Energy Systems: Needs, Status Quo, and Research Trends
Authors: Thomas I. Strasser, Filip Pröstl Andrén
Abstract: A driving force for the realization of a sustainable energy supply is the integration of renewable energy resources. Due to their stochastic generation behaviour, energy utilities are confronted with a more complex operation of the underlying power grids. Additionally, due to technology developments, controllable loads, integration with other energy sources, changing regulatory rules, and the market liberalization, the systems operation needs adaptation. Proper operational concepts and intelligent automation provide the basis to turn the existing power system into an intelligent entity, a cyber-physical energy system. The electric energy system is therefore moving from a single system to a system of systems. While reaping the benefits with new intelligent behaviors, it is expected that system-level developments, architectural concepts, advanced automation and control as well as the validation and testing will play a significantly larger role in realizing future solutions and technologies. The implementation and deployment of these complex systems of systems are associated with increasing engineering complexity resulting also in increased engineering costs. Proper engineering and validation approaches, concepts, and tools are partly missing until now. Therefore, this paper discusses and summarizes the main needs and requirements as well as the status quo in research and development related to the engineering and validation of cyber-physical energy systems. Also research trends and necessary future activities are outlined.

Paper number 47:
Title: Latency-Aware Resource Allocation for Integrated Communications, Computation, and Sensing in Cell-Free mMIMO Systems
Authors: Qihao Peng, Qu Luo, Zheng Chu, Zihuai Lin, Maged Elkashlan, Pei Xiao, George K. Karagiannidis, Christos Masouros
Abstract: In this paper, we investigate a cell-free massive multiple-input and multiple-output (MIMO)-enabled integration communication, computation, and sensing (ICCS) system, aiming to minimize the maximum computation latency to guarantee the stringent sensing requirements. We consider a two-tier offloading framework, where each multi-antenna terminal can optionally offload its local tasks to either multiple mobile-edge servers for distributed computation or the cloud server for centralized computation while satisfying the sensing requirements and power constraint. The above offloading problem is formulated as a mixed-integer programming and non-convex problem, which can be decomposed into three sub-problems, namely, distributed offloading decision, beamforming design, and execution scheduling mechanism. First, the continuous relaxation and penalty-based techniques are applied to tackle the distributed offloading strategy. Then, the weighted minimum mean square error (WMMSE) and successive convex approximation (SCA)-based lower bound are utilized to design the integrated communication and sensing (ISAC) beamforming. Finally, the other resources can be judiciously scheduled to minimize the maximum latency. A rigorous convergence analysis and numerical results substantiate the effectiveness of our method. Furthermore, simulation results demonstrate that multi-point cooperation in cell-free massive MIMO-enabled ICCS significantly reduces overall computation latency, in comparison to the benchmark schemes.

Paper number 48:
Title: M3DA: Benchmark for Unsupervised Domain Adaptation in 3D Medical Image Segmentation
Authors: Boris Shirokikh, Anvar Kurmukov, Mariia Donskova, Valentin Samokhin, Mikhail Belyaev, Ivan Oseledets
Abstract: Domain shift presents a significant challenge in applying Deep Learning to the segmentation of 3D medical images from sources like Magnetic Resonance Imaging (MRI) and Computed Tomography (CT). Although numerous Domain Adaptation methods have been developed to address this issue, they are often evaluated under impractical data shift scenarios. Specifically, the medical imaging datasets used are often either private, too small for robust training and evaluation, or limited to single or synthetic tasks. To overcome these limitations, we introduce a M3DA /"mEd@/ benchmark comprising four publicly available, multiclass segmentation datasets. We have designed eight domain pairs featuring diverse and practically relevant distribution shifts. These include inter-modality shifts between MRI and CT and intra-modality shifts among various MRI acquisition parameters, different CT radiation doses, and presence/absence of contrast enhancement in images. Within the proposed benchmark, we evaluate more than ten existing domain adaptation methods. Our results show that none of them can consistently close the performance gap between the domains. For instance, the most effective method reduces the performance gap by about 62% across the tasks. This highlights the need for developing novel domain adaptation algorithms to enhance the robustness and scalability of deep learning models in medical imaging. We made our M3DA benchmark publicly available: this https URL.

Paper number 49:
Title: On Space-Filling Input Design for Nonlinear Dynamic Model Learning: A Gaussian Process Approach
Authors: Yuhan Liu, Máté Kiss, Roland Tóth, Maarten Schoukens
Abstract: While optimal input design for linear systems has been well-established, no systematic approach exists for nonlinear systems, where robustness to extrapolation/interpolation errors is prioritized over minimizing estimated parameter variance. To address this issue, we develop a novel identification-oriented space-filling input design strategy for efficient covering of a well-defined region of interest. By placing a Gaussian Process (GP) prior on the joint input-state space, the proposed strategy leverages the GP posterior variance to construct a space-filling promoting input design cost function from the Bayesian point of view. This accordingly enables maximization of the coverage in the region of interest, thereby facilitating the generation of informative datasets. Furthermore, we theoretically prove that minimization of the cost function indicates the spacefilling behavior. The effectiveness of the proposed strategy is demonstrated on both an academic example and a mass-spring-damper system, highlighting its potential practical impact on efficient exploration in identification scenarios for nonlinear dynamical systems

Paper number 50:
Title: Structure-Aware Matrix Pencil Method
Authors: Yehonatan-Itay Segman, Alon Amar, Ronen Talmon
Abstract: We address the problem of detecting the number of complex exponentials and estimating their parameters from a noisy signal using the Matrix Pencil (MP) method. We introduce the MP modes and present their informative spectral structure. We show theoretically that these modes can be divided into signal and noise modes, where the signal modes exhibit a perturbed Vandermonde structure. Leveraging this structure, we proposed a new MP algorithm, termed the SAMP algorithm, which has two novel components. First, we present a new and robust model order detection with theoretical guarantees. Second, we present an efficient estimation of signal amplitudes. We show empirically that the SAMP algorithm significantly outperforms the standard MP method, particularly in challenging conditions with closely-spaced frequencies and low Signal-to-Noise Ratio (SNR) values, approaching the Cramer-Rao lower bound (CRB) for a broad SNR range. Additionally, compared with prevalent information-based criteria, we show that SAMP is more computationally efficient and insensitive to noise distribution.

Paper number 51:
Title: Convergence Guarantees for Unmixing PSFs over a Manifold with Non-Convex Optimization
Authors: Santos Michelena, Maxime Ferreira Da Costa, José Picheral
Abstract: The problem of recovering the parameters of a mixture of spike signals convolved with different PSFs is considered. Herein, the spike support is assumed to be known, while the PSFs lie on a manifold. A non-linear least squares estimator of the mixture parameters is formulated. In the absence of noise, a lower bound on the radius of the strong basin of attraction i.e., the region of convergence, is derived. Key to the analysis is the introduction of coherence and interference functions, which capture the conditioning of the PSF manifold in terms of the minimal separation of the support. Numerical experiments validate the theoretical findings. Finally, the practicality and efficacy of the non-linear least squares approach are showcased on spectral data from laser-induced breakdown spectroscopy.

Paper number 52:
Title: Noise Modulation over Wireless Energy Transfer: JEIH-Noise Mod
Authors: Erkin Yapici, Yusuf Islam Tek, Mehmet Ertug Pihtili, M. Cagri Ilter, Ertugrul Basar
Abstract: This letter presents an innovative energy harvesting (EH) and communication scheme for Internet of Things (IoT) devices by utilizing the emerging noise modulation (Noise-Mod) technique. Our proposed approach embeds information into the mean value of real Gaussian noise samples, enabling simultaneous power transfer and data transmission. We analyze our system under the Rician fading channels with path loss and derive the bit error probability (BEP) expression. Our simulation results demonstrate that the proposed scheme outperforms conventional modulation schemes in terms of energy harvesting capability across various channel conditions. This scheme offers a novel solution by directly embedding data into the noise-modulated signal to enable information decoding through mean-based detection. Furthermore, it increases energy harvesting capability thanks to the utilized Gaussian waveform.

Paper number 53:
Title: Rotatable Antenna Enabled Wireless Communication System with Visual Recognition: A Prototype Implementation
Authors: Liang Dai, Beixiong Zheng, Yanhua Tan, Lipeng Zhu, Fangjiong Chen, Rui Zhang
Abstract: Rotatable antenna (RA) is an emerging technology possessing great potential to exploit additional spatial degrees of freedom (DoFs) by flexibly altering the three-dimensional (3D) orientation/boresight of each antenna. In this demonstration, we develop a prototype of RA-enabled wireless communication system with visual recognition module to evaluate the performance gains provided by the RA in practical environments. In particular, a mechanically-driven RA is developed by integrating a digital servo motor, a directional antenna, and a microcontroller, which enables the dynamic adjustment of the RA orientation. Moreover, the orientation adjustment of RA is guided by the target's direction provided by visual recognition module, thereby significantly enhancing system response speed and orientating accuracy. The experimental results demonstrate that the RA-enabled communication system achieves outstanding improvement in terms of communication coverage performance compared to conventional fixed antenna-based systems.

Paper number 54:
Title: A First Look at the Performance Enhancement Potential of Fluid Reconfigurable Intelligent Surface
Authors: Abdelhamid Salem, Kai-Kit Wong, George Alexandropoulos, Chan-Byoung Chae, Ross Murch
Abstract: The fluid antenna concept represents shape-flexible and position-flexible antenna technologies designed to enhance wireless communication applications. In this paper, we apply this concept to reconfigurable intelligent surfaces (RISs), introducing fluid RIS (FRIS), where each tunably reflecting element becomes a fluid element with additional position reconfigurability. This new paradigm is referred to as fluid RIS (FRIS). We investigate an FRIS-programmable wireless channel, where the fluid meta-surface is divided into non-overlapping subareas, each acting as a fluid element that can dynamically adjust both its position and phase shift of the reflected signal. We first analyze the single-user, single-input single-output (SU-SISO) channel, in which a single-antenna transmitter communicates with a single-antenna receiver via an FRIS. The achievable rate is maximized by optimizing the fluid elements using a particle swarm optimization (PSO)- based approach. Next, we extend our analysis to the multi-user, multiple-input single-output (MU-MISO) case, where a multi-antenna base station (BS) transmits individual data streams to multiple single-antenna users via an FRIS. In this case, the joint optimization of the positions and phase shifts of the FRIS element, as well as the BS precoding to maximize the sum-rate is studied. To solve the problem, a combination of techniques including PSO, semi-definite relaxation (SDR), and minimum mean square error (MMSE) is proposed. Numerical results demonstrate that the proposed FRIS approach significantly outperforms conventional RIS configurations in terms of achievable rate performance.

Paper number 55:
Title: Conditional Generative Adversarial Networks for Channel Estimation in RIS-Assisted ISAC Systems
Authors: Alice Faisal, Ibrahim Al-Nahhal, Kyesan Lee, Octavia A. Dobre, Hyundong Shin
Abstract: Integrated sensing and communication (ISAC) technology has been explored as a potential advancement for future wireless networks, striving to effectively use spectral resources for both communication and sensing. The integration of reconfigurable intelligent surfaces (RIS) with ISAC further enhances this capability by optimizing the propagation environment, thereby improving both the sensing accuracy and communication quality. Within this domain, accurate channel estimation is crucial to ensure a reliable deployment. Traditional deep learning (DL) approaches, while effective, can impose performance limitations in modeling the complex dynamics of wireless channels. This paper proposes a novel application of conditional generative adversarial networks (CGANs) to solve the channel estimation problem of an RIS-assisted ISAC system. The CGAN framework adversarially trains two DL networks, enabling the generator network to not only learn the mapping relationship from observed data to real channel conditions but also to improve its output based on the discriminator network feedback, thus effectively optimizing the training process and estimation accuracy. The numerical simulations demonstrate that the proposed CGAN-based method improves the estimation performance effectively compared to conventional DL techniques. The results highlight the CGAN's potential to revolutionize channel estimation, paving the way for more accurate and reliable ISAC deployments.

Paper number 56:
Title: SpikACom: A Neuromorphic Computing Framework for Green Communications
Authors: Yanzhen Liu, Zhijin Qin, Yongxu Zhu, Geoffrey Ye Li
Abstract: The ever-growing power consumption of wireless communication systems necessitates more energy-efficient algorithms. This paper introduces SpikACom ({Spik}ing {A}daptive {Com}munication), a neuromorphic computing-based framework for power-intensive wireless communication tasks. SpikACom leverages brain-inspired spiking neural networks (SNNs) for efficient signal processing. It is designed for dynamic wireless environments, helping to mitigate catastrophic forgetting and facilitate adaptation to new circumstances. Moreover, SpikACom is customizable, allowing flexibly integration of domain knowledge to enhance it interpretability and efficacy. We validate its performance on fundamental wireless communication tasks, including task-oriented semantic communication, multiple-input multiple-output (MIMO) beamforming, and orthogonal frequency-division multiplexing (OFDM) channel estimation. The simulation results show that SpikACom significantly reduces power consumption while matching or exceeding the performance of conventional algorithms. This study highlights the potential of SNNs for enabling greener and smarter wireless communication systems.

Paper number 57:
Title: Unsupervised Accelerated MRI Reconstruction via Ground-Truth-Free Flow Matching
Authors: Xinzhe Luo, Yingzhen Li, Chen Qin
Abstract: Accelerated magnetic resonance imaging involves reconstructing fully sampled images from undersampled k-space measurements. Current state-of-the-art approaches have mainly focused on either end-to-end supervised training inspired by compressed sensing formulations, or posterior sampling methods built on modern generative models. However, their efficacy heavily relies on large datasets of fully sampled images, which may not always be available in practice. To address this issue, we propose an unsupervised MRI reconstruction method based on ground-truth-free flow matching (GTF$^2$M). Particularly, the GTF$^2$M learns a prior denoising process of fully sampled ground-truth images using only undersampled data. Based on that, an efficient cyclic reconstruction algorithm is further proposed to perform forward and backward integration in the dual space of image-space signal and k-space measurement. We compared our method with state-of-the-art learning-based baselines on the fastMRI database of both single-coil knee and multi-coil brain MRIs. The results show that our proposed unsupervised method can significantly outperform existing unsupervised approaches, and achieve performance comparable to most supervised end-to-end and prior learning baselines trained on fully sampled MRI, while offering greater efficiency than the compared generative model-based approaches.

Paper number 58:
Title: AIRIS2 : a Smart Gateway Diversity Algorithm for Very High-Throughput Satellite Systems
Authors: Justin Cano, Jonathan Israël, Laurent Féral
Abstract: Satellite communication systems are shifting to higher frequency bands (Ka, Q/V, W) to support more data-intensive services and alleviate spectral congestion. However, the use of Extremely High Frequencies, typically above 20 GHz, causes significant tropospheric impairments, such as rain attenuation, which can causes system outages. To mitigate these effects, Smart Gateway Diversity (SGD) has emerged as a promising method for maximizing feeder link availability through an adaptive site diversity scheme. However, implementing such technique requires a decision-making policy to dynamically select the optimal set of gateways and prevent outages. This paper introduces AIRIS2, a deep learning algorithm that anticipates short-term rain events from rain attenuation measurement to enable efficient gateway switching. The approach is validated from five years of measured time series collected at Ka and Q/V bands at various sites and climatic conditions.

Paper number 59:
Title: Motion-Robust T2* Quantification from Gradient Echo MRI with Physics-Informed Deep Learning
Authors: Hannah Eichhorn, Veronika Spieker, Kerstin Hammernik, Elisa Saks, Lina Felsner, Kilian Weiss, Christine Preibisch, Julia A. Schnabel
Abstract: Purpose: T2* quantification from gradient echo magnetic resonance imaging is particularly affected by subject motion due to the high sensitivity to magnetic field inhomogeneities, which are influenced by motion and might cause signal loss. Thus, motion correction is crucial to obtain high-quality T2* maps. Methods: We extend our previously introduced learning-based physics-informed motion correction method, PHIMO, by utilizing acquisition knowledge to enhance the reconstruction performance for challenging motion patterns and increase PHIMO's robustness to varying strengths of magnetic field inhomogeneities across the brain. We perform comprehensive evaluations regarding motion detection accuracy and image quality for data with simulated and real motion. Results: Our extended version of PHIMO outperforms the learning-based baseline methods both qualitatively and quantitatively with respect to line detection and image quality. Moreover, PHIMO performs on-par with a conventional state-of-the-art motion correction method for T2* quantification from gradient echo MRI, which relies on redundant data acquisition. Conclusion: PHIMO's competitive motion correction performance, combined with a reduction in acquisition time by over 40% compared to the state-of-the-art method, make it a promising solution for motion-robust T2* quantification in research settings and clinical routine.

Paper number 60:
Title: A Two-step Linear Mixing Model for Unmixing under Hyperspectral Variability
Authors: Xander Haijen, Bikram Koirala, Xuanwen Tao, Paul Scheunders
Abstract: Spectral unmixing is an important task in the research field of hyperspectral image processing. It can be thought of as a regression problem, where the observed variable (i.e., an image pixel) is to be found as a function of the response variables (i.e., the pure materials in a scene, called endmembers). The Linear Mixing Model (LMM) has received a great deal of attention, due to its simplicity and ease of use in, e.g., optimization problems. Its biggest flaw is that it assumes that any pure material can be characterized by one unique spectrum throughout the entire scene. In many cases this is incorrect: the endmembers face a significant amount of spectral variability caused by, e.g., illumination conditions, atmospheric effects, or intrinsic variability. Researchers have suggested several generalizations of the LMM to mitigate this effect. However, most models lead to ill-posed and highly non-convex optimization problems, which are hard to solve and have hyperparameters that are difficult to tune. In this paper, we propose a two-step LMM that bridges the gap between model complexity and computational tractability. We show that this model leads to only a mildly non-convex optimization problem, which we solve with an interior-point solver. This method requires virtually no hyperparameter tuning, and can therefore be used easily and quickly in a wide range of unmixing tasks. We show that the model is competitive and in some cases superior to existing and well-established unmixing methods and algorithms. We do this through several experiments on synthetic data, real-life satellite data, and hybrid synthetic-real data.

Paper number 61:
Title: Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation
Authors: Bo Wang, Hashem Ashrafiuon, Sergey G. Nersesov
Abstract: This paper investigates extremum seeking control for a torque-controlled antenna pointing system without direct angular measurements. We consider a two-degree-of-freedom (2-DOF) antenna system that receives an unknown signal from its environment, where the signal strength varies with the orientation of the antenna. It is assumed that only real-time measurements of the signal are available. We develop an extremum seeking control strategy that enables the antenna to autonomously adjust its direction to maximize the received signal strength based on the symmetric product approximation. Under suitable assumptions on the signal function, we prove local practical uniform asymptotic stability for the closed-loop system.

Paper number 62:
Title: MDN: Mamba-Driven Dualstream Network For Medical Hyperspectral Image Segmentation
Authors: Shijie Lin, Boxiang Yun, Wei Shen, Qingli Li, Anqiang Yang, Yan Wang
Abstract: Medical Hyperspectral Imaging (MHSI) offers potential for computational pathology and precision medicine. However, existing CNN and Transformer struggle to balance segmentation accuracy and speed due to high spatial-spectral dimensionality. In this study, we leverage Mamba's global context modeling to propose a dual-stream architecture for joint spatial-spectral feature extraction. To address the limitation of Mamba's unidirectional aggregation, we introduce a recurrent spectral sequence representation to capture low-redundancy global spectral features. Experiments on a public Multi-Dimensional Choledoch dataset and a private Cervical Cancer dataset show that our method outperforms state-of-the-art approaches in segmentation accuracy while minimizing resource usage and achieving the fastest inference speed. Our code will be available at this https URL.

Paper number 63:
Title: RELICT: A Replica Detection Framework for Medical Image Generation
Authors: Orhun Utku Aydin (1), Alexander Koch (1), Adam Hilbert (1), Jana Rieger (1), Felix Lohrke (1), Fujimaro Ishida (2), Satoru Tanioka (1 and 3), Dietmar Frey (1 and 4) ((1) CLAIM - Charite Lab for AI in Medicine, Charite Universitatsmedizin Berlin, corporate member of Freie Universitat Berlin and Humboldt Universitat zu Berlin, Berlin, Germany (2) Department of Neurosurgery, Mie Chuo Medical Center, Hisai, Tsu, Japan (3) Department of Neurosurgery, Mie University Graduate School of Medicine, Tsu, Japan (4) Department of Neurosurgery, Charite Universitatsmedizin Berlin, corporate member of Freie Universitat Berlin and Humboldt Universitat zu Berlin, Berlin, Germany)
Abstract: Despite the potential of synthetic medical data for augmenting and improving the generalizability of deep learning models, memorization in generative models can lead to unintended leakage of sensitive patient information and limit model utility. Thus, the use of memorizing generative models in the medical domain can jeopardize patient privacy. We propose a framework for identifying replicas, i.e. nearly identical copies of the training data, in synthetic medical image datasets. Our REpLIca deteCTion (RELICT) framework for medical image generative models evaluates image similarity using three complementary approaches: (1) voxel-level analysis, (2) feature-level analysis by a pretrained medical foundation model, and (3) segmentation-level analysis. Two clinically relevant 3D generative modelling use cases were investigated: non-contrast head CT with intracerebral hemorrhage (N=774) and time-of-flight MR angiography of the Circle of Willis (N=1,782). Expert visual scoring was used as the reference standard to assess the presence of replicas. We report the balanced accuracy at the optimal threshold to assess replica classification performance. The reference visual rating identified 45 of 50 and 5 of 50 generated images as replicas for the NCCT and TOF-MRA use cases, respectively. Image-level and feature-level measures perfectly classified replicas with a balanced accuracy of 1 when an optimal threshold was selected for the NCCT use case. A perfect classification of replicas for the TOF-MRA case was not possible at any threshold, with the segmentation-level analysis achieving a balanced accuracy of 0.79. Replica detection is a crucial but neglected validation step for the development of generative models in medical imaging. The proposed RELICT framework provides a standardized, easy-to-use tool for replica detection and aims to facilitate responsible and ethical medical image synthesis.

Paper number 64:
Title: Distributed Coordination for Heterogeneous Non-Terrestrial Networks
Authors: Jikang Deng, Hui Zhou, Mohamed-Slim Alouini
Abstract: To guarantee global coverage and ubiquitous connectivity, the Non-terrestrial Network (NTN) technology has been regarded as a key enabling technology in the Six Generation (6G) network, which consists of the unmanned aerial vehicle (UAV), high-altitude platform (HAP), and satellite. It is noted that the unique characteristics of various NTN platforms directly impact the design and implementation of NTNs, which results in highly dynamic and heterogeneous networks. Even within the same tier, such as the space tier, the NTNs are developed based on different platforms including Low Earth Orbit (LEO), Medium Earth Orbit (MEO), and Geostationary Earth Orbit (GEO). Therefore, distributed coordination among heterogeneous NTNs remains an important challenge. Although distributed learning framework finds a wide range of applications by leveraging rich distributed data and computation resources. The explicit and systematic analysis of the individual layers' challenges, and corresponding distributed coordination solutions in heterogeneous NTNs has not been proposed yet. In this article, we first summarize the unique characteristics of each NTN platform, and analyze the corresponding impact on the design and implementation of the NTN. We then identify the communication challenges of heterogeneous NTNs in individual layers, where the potential coordinated solutions are identified. We further illustrate the multi-agent deep reinforcement learning (MADRL) algorithms tailored for coordinated solutions in heterogeneous NTNs. Last but not least, we present a case study of the user scheduling optimization problem in heterogeneous UAVs-based cellular networks, where the multi-agent deep deterministic policy gradient (MADDPG) technique is developed to validate the effectiveness of distributed coordination in heterogeneous NTNs.

Paper number 65:
Title: Enhancing CoMP-RSMA Performance with Movable Antennas: A Meta-Learning Optimization Framework
Authors: Ali Amhaz, Shreya Khisa, Mohamed Elhattab, Chadi Assi, Sanaa Sharafeddine
Abstract: This study investigates a downlink rate-splitting multiple access (RSMA) scenario in which multiple base stations (BSs), employing a coordinated multi-point (CoMP) transmission scheme, serve users equipped with movable antenna (MA) technology. Unlike traditional fixed-position antennas (FPAs), which are subject to random variations in wireless channels, MAs can be strategically repositioned to locations with more favorable channel conditions, thereby achieving enhanced spatial diversity this http URL leverage these advantages and maximize the achievable sum rate, we formulate an optimization problem that jointly determines the optimal transmit beamforming vectors at the BSs, the common stream allocation for different users, and the optimal positioning of the MAs, all while ensuring compliance with quality of service (QoS) constraints. However, the formulated problem is non-convex and computationally challenging due to the strong interdependence among the optimization variables. Traditional methods for solving large-scale optimization problems typically incur prohibitively high computational complexity. To address the above challenge, we propose a gradient-based meta-learning (GML) algorithm that operates without pre-training and is well-suited for handling large-scale optimization tasks. Numerical results demonstrate the effectiveness and accuracy of the proposed approach, achieving near-optimal performance (exceeding 97% compared to the optimal solution). Moreover, the MA-enabled CoMP-RSMA model significantly outperforms conventional benchmark schemes, yielding performance gains of up to 190% over the spatial division multiple access (SDMA) scheme and 80% over the RSMA FPA-based model. Finally, the proposed approach is shown to mitigate the sum-rate limitations imposed by interference in SDMA, achieving superior performance with fewer BSs.

Paper number 66:
Title: Joint Holographic Beamforming and User Scheduling with Individual QoS Constraints
Authors: Chandan Kumar Sheemar, Christo Kurisummoottil Thomas, George C. Alexandropoulos, Jorge Querol, Symeon Chatzinotas, Walid Saad
Abstract: Reconfigurable holographic surfaces (RHS) have emerged as a transformative material technology, enabling dynamic control of electromagnetic waves to generate versatile holographic beam patterns. This paper addresses the problem of joint hybrid holographic beamforming and user scheduling under per-user minimum quality-of-service (QoS) constraints, a critical challenge in resource-constrained networks. However, such a problem results in mixed-integer non-convex optimization, making it difficult to identify feasible solutions efficiently. To overcome this challenge, we propose a novel iterative optimization framework that jointly solves the problem to maximize the RHS-assisted network sum-rate, efficiently managing holographic beamforming patterns, dynamically scheduling users, and ensuring the minimum QoS requirements for each scheduled user. The proposed framework relies on zero-forcing digital beamforming, gradient-ascent-based holographic beamformer optimization, and a greedy user selection principle. Our extensive simulation results validate the effectiveness of the proposed scheme, demonstrating their superior performance compared to the benchmark algorithms in terms of sum-rate performance, while meeting the minimum per-user QoS constraints

Paper number 67:
Title: Joint Beamforming and 3D Location Optimization for Multi-User Holographic UAV Communications
Authors: Chandan Kumar Sheemar, Asad Mahmood, Christo Kurisummoottil Thomas, George C. Alexandropoulos, Jorge Querol, Symeon Chatzinotas, Walid Saad
Abstract: This paper pioneers the field of multi-user holographic unmanned aerial vehicle (UAV) communications, laying a solid foundation for future innovations in next-generation aerial wireless networks. The study focuses on the challenging problem of jointly optimizing hybrid holographic beamforming and 3D UAV positioning in scenarios where the UAV is equipped with a reconfigurable holographic surface (RHS) instead of conventional phased array antennas. Using the unique capabilities of RHSs, the system dynamically adjusts both the position of the UAV and its hybrid beamforming properties to maximize the sum rate of the network. To address this complex optimization problem, we propose an iterative algorithm combining zero-forcing digital beamforming and a gradient ascent approach for the holographic patterns and the 3D position optimization, while ensuring practical feasibility constraints. The algorithm is designed to effectively balance the trade-offs between power, beamforming, and UAV trajectory constraints, enabling adaptive and efficient communications, while assuring a monotonic increase in the sum-rate performance. Our numerical investigations demonstrate that the significant performance improvements with the proposed approach over the benchmark methods, showcasing enhanced sum rate and system adaptability under varying conditions.

Paper number 68:
Title: Benchmarking machine learning for bowel sound pattern classification from tabular features to pretrained models
Authors: Zahra Mansour, Verena Uslar, Dirk Weyhe, Danilo Hollosi, Nils Strodthoff
Abstract: The development of electronic stethoscopes and wearable recording sensors opened the door to the automated analysis of bowel sound (BS) signals. This enables a data-driven analysis of bowel sound patterns, their interrelations, and their correlation to different pathologies. This work leverages a BS dataset collected from 16 healthy subjects that was annotated according to four established BS patterns. This dataset is used to evaluate the performance of machine learning models to detect and/or classify BS patterns. The selection of considered models covers models using tabular features, convolutional neural networks based on spectrograms and models pre-trained on large audio datasets. The results highlight the clear superiority of pre-trained models, particularly in detecting classes with few samples, achieving an AUC of 0.89 in distinguishing BS from non-BS using a HuBERT model and an AUC of 0.89 in differentiating bowel sound patterns using a Wav2Vec 2.0 model. These results pave the way for an improved understanding of bowel sounds in general and future machine-learning-driven diagnostic applications for gastrointestinal examinations

Paper number 69:
Title: Multi-Failure Localization in High-Degree ROADM-based Optical Networks using Rules-Informed Neural Networks
Authors: Ruikun Wang, Qiaolun Zhang, Jiawei Zhang, Zhiqun Gu, Memedhe Ibrahimi, Hao Yu, Bojun Zhang, Francesco Musumeci, Yuefeng Ji, Massimo Tornatore
Abstract: To accommodate ever-growing traffic, network operators are actively deploying high-degree reconfigurable optical add/drop multiplexers (ROADMs) to build large-capacity optical networks. High-degree ROADM-based optical networks have multiple parallel fibers between ROADM nodes, requiring the adoption of ROADM nodes with a large number of inter-/intra-node components. However, this large number of inter-/intra-node optical components in high-degree ROADM networks increases the likelihood of multiple failures simultaneously, and calls for novel methods for accurate localization of multiple failed components. To the best of our knowledge, this is the first study investigating the problem of multi-failure localization for high-degree ROADM-based optical networks. To solve this problem, we first provide a description of the failures affecting both inter-/intra-node components, and we consider different deployments of optical power monitors (OPMs) to obtain information (i.e., optical power) to be used for automated multi-failure localization. Then, as our main and original contribution, we propose a novel method based on a rules-informed neural network (RINN) for multi-failure localization, which incorporates the benefits of both rules-based reasoning and artificial neural networks (ANN). Through extensive simulations and experimental demonstrations, we show that our proposed RINN algorithm can achieve up to around 20 higher localization accuracy compared to baseline algorithms, incurring only around 4.14 ms of average inference time.

Paper number 70:
Title: CacheMamba: Popularity Prediction for Mobile Edge Caching Networks via Selective State Spaces
Authors: Ghazaleh Kianfar, Zohreh Hajiakhondi-Meybodi, Arash Mohammadi
Abstract: Mobile Edge Caching (MEC) plays a pivotal role in mitigating latency in data-intensive services by dynamically caching frequently requested content on edge servers. This capability is critical for applications such as Augmented Reality (AR), Virtual Reality (VR), and Autonomous Vehicles (AV), where efficient content caching and accurate popularity prediction are essential for optimizing performance. In this paper, we explore the problem of popularity prediction in MEC by utilizing historical time-series request data of intended files, formulating this problem as a ranking task. To this aim, we propose CacheMamba model by employing Mamba, a state-space model (SSM)-based architecture, to identify the top-K files with the highest likelihood of being requested. We then benchmark the proposed model against a Transformer-based approach, demonstrating its superior performance in terms of cache-hit rate, Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (NDCG), and Floating-Point Operations Per Second (FLOPS), particularly when dealing with longer sequences.

Paper number 71:
Title: Anomaly Detection in Smart Power Grids with Graph-Regularized MS-SVDD: a Multimodal Subspace Learning Approach
Authors: Thomas Debelle, Fahad Sohrab, Pekka Abrahamsson, Moncef Gabbouj
Abstract: In this paper, we address an anomaly detection problem in smart power grids using Multimodal Subspace Support Vector Data Description (MS-SVDD). This approach aims to leverage better feature relations by considering the data as coming from different modalities. These data are projected into a shared lower-dimensionality subspace which aims to preserve their inner characteristics. To supplement the previous work on this subject, we introduce novel multimodal graph-embedded regularizers that leverage graph information for every modality to enhance the training process, and we consider an improved training equation that allows us to maximize or minimize each modality according to the specified criteria. We apply this regularized graph-embedded model on a 3-modalities dataset after having generalized MS-SVDD algorithms to any number of modalities. To set up our application, we propose a whole preprocessing procedure to extract One-Class Classification training instances from time-bounded event time series that are used to evaluate both the reliability and earliness of our model for Event Detection.

Paper number 72:
Title: Black Sheep in the Herd: Playing with Spuriously Correlated Attributes for Vision-Language Recognition
Authors: Xinyu Tian, Shu Zou, Zhaoyuan Yang, Mengqi He, Jing Zhang
Abstract: Few-shot adaptation for Vision-Language Models (VLMs) presents a dilemma: balancing in-distribution accuracy with out-of-distribution generalization. Recent research has utilized low-level concepts such as visual attributes to enhance generalization. However, this study reveals that VLMs overly rely on a small subset of attributes on decision-making, which co-occur with the category but are not inherently part of it, termed spuriously correlated attributes. This biased nature of VLMs results in poor generalization. To address this, 1) we first propose Spurious Attribute Probing (SAP), identifying and filtering out these problematic attributes to significantly enhance the generalization of existing attribute-based methods; 2) We introduce Spurious Attribute Shielding (SAS), a plug-and-play module that mitigates the influence of these attributes on prediction, seamlessly integrating into various Parameter-Efficient Fine-Tuning (PEFT) methods. In experiments, SAP and SAS significantly enhance accuracy on distribution shifts across 11 datasets and 3 generalization tasks without compromising downstream performance, establishing a new state-of-the-art benchmark.

Paper number 73:
Title: Slamming: Training a Speech Language Model on One GPU in a Day
Authors: Gallil Maimon, Avishai Elmakies, Yossi Adi
Abstract: We introduce Slam, a recipe for training high-quality Speech Language Models (SLMs) on a single academic GPU in 24 hours. We do so through empirical analysis of model initialisation and architecture, synthetic training data, preference optimisation with synthetic data and tweaking all other components. We empirically demonstrate that this training recipe also scales well with more compute getting results on par with leading SLMs in a fraction of the compute cost. We hope these insights will make SLM training and research more accessible. In the context of SLM scaling laws, our results far outperform predicted compute optimal performance, giving an optimistic view to SLM feasibility. See code, data, models, samples at - this https URL .

Paper number 74:
Title: LACTOSE: Linear Array of Conditions, TOpologies with Separated Error-backpropagation -- The Differentiable "IF" Conditional for Differentiable Digital Signal Processing
Authors: Christopher Johann Clarke
Abstract: There has been difficulty utilising conditional statements as part of the neural network graph (e.g. if input $> x$, pass input to network $N$). This is due to the inability to backpropagate through branching conditions. The Linear Array of Conditions, TOpologies with Separated Error-backpropagation (LACTOSE) Algorithm addresses this issue and allows the conditional use of available machine learning layers for supervised learning models. In this paper, the LACTOSE algorithm is applied to a simple use of DDSP, however, the main point is the development of the "if" conditional for DDSP use. The LACTOSE algorithm stores trained parameters for each user-specified numerical range and loads the parameters dynamically during prediction.

Paper number 75:
Title: Deriving Representative Structure from Music Corpora
Authors: Ilana Shapiro, Ruanqianqian (Lisa)Huang, Zachary Novack, Cheng-i Wang, Hao-Wen Dong, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Sorin Lerner
Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a dually NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.

Paper number 76:
Title: Computation Offloading Strategies in Integrated Terrestrial and Non-Terrestrial Networks
Authors: Muhammad Ahmed Mohsin, Muhammad Umer, Amara Umar, Hatem Abou-Zeid, Syed Ali Hassan
Abstract: The rapid growth of computation-intensive applications like augmented reality, autonomous driving, remote healthcare, and smart cities has exposed the limitations of traditional terrestrial networks, particularly in terms of inadequate coverage, limited capacity, and high latency in remote areas. This chapter explores how integrated terrestrial and non-terrestrial networks (IT-NTNs) can address these challenges and enable efficient computation offloading. We examine mobile edge computing (MEC) and its evolution toward multiple-access edge computing, highlighting the critical role computation offloading plays for resource-constrained devices. We then discuss the architecture of IT-NTNs, focusing on how terrestrial base stations, unmanned aerial vehicles (UAVs), high-altitude platforms (HAPs), and LEO satellites work together to deliver ubiquitous connectivity. Furthermore, we analyze various computation offloading strategies, including edge, cloud, and hybrid offloading, outlining their strengths and weaknesses. Key enabling technologies such as NOMA, mmWave/THz communication, and reconfigurable intelligent surfaces (RIS) are also explored as essential components of existing algorithms for resource allocation, task offloading decisions, and mobility management. Finally, we conclude by highlighting the transformative impact of computation offloading in IT-NTNs across diverse application areas and discuss key challenges and future research directions, emphasizing the potential of these networks to revolutionize communication and computation paradigms.

Paper number 77:
Title: Qubit-Efficient Quantum Annealing for Stochastic Unit Commitment
Authors: Wei Hong, Wangkun Xu, Fei Teng
Abstract: Stochastic Unit Commitment (SUC) has been proposed to manage the uncertainties driven by the integration of renewable energy sources. When solved by Benders Decomposition (BD), the master problem becomes a binary integer programming which is NP-hard and computationally demanding for classical computational methods. Quantum Annealing (QA), known for efficiently solving Quadratic Unconstrained Binary Optimization (QUBO) problems, presents a potential solution. However, existing quantum algorithms rely on slack variables to handle linear binary inequality constraints, leading to increased qubit consumption and reduced computational efficiency. To solve the problem, this paper introduces the Powell-Hestenes-Rockafellar Augmented Lagrangian Multiplier (PHR-ALM) method to eliminate the need for slack variables so that the qubit consumption becomes independent of the increasing number of bender's cuts. To further reduce the qubit overhead, quantum ADMM is applied to break large-scale SUC into smaller blocks and enables a sequential solution. Consequently, the Quantum-based PHR-ADMM (QPHR-ADMM) can significantly reduce qubit requirements and enhancing the applicability of QA in SUC problem. The simulation results demonstrate the feasibility of the proposed QPHR-ADMM algorithm, indicating its superior time efficiency over classical approaches for large scale QUBO problems under the D-Wave QPU showcases.

Paper number 78:
Title: Mind the Gap! Static and Interactive Evaluations of Large Audio Models
Authors: Minzhi Li, William Barr Held, Michael J Ryan, Kunat Pipatanakul, Potsawee Manakul, Hao Zhu, Diyi Yang
Abstract: As AI chatbots become ubiquitous, voice interaction presents a compelling way to enable rapid, high-bandwidth communication for both semantic and social signals. This has driven research into Large Audio Models (LAMs) to power voice-native experiences. However, aligning LAM development with user goals requires a clear understanding of user needs and preferences to establish reliable progress metrics. This study addresses these challenges by introducing an interactive approach to evaluate LAMs and collecting 7,500 LAM interactions from 484 participants. Through topic modeling of user queries, we identify primary use cases for audio interfaces. We then analyze user preference rankings and qualitative feedback to determine which models best align with user needs. Finally, we evaluate how static benchmarks predict interactive performance - our analysis reveals no individual benchmark strongly correlates with interactive results ($\tau \leq 0.33$ for all benchmarks). While combining multiple coarse-grained features yields modest predictive power ($R^2$=$0.30$), only two out of twenty datasets on spoken question answering and age prediction show significantly positive correlations. This suggests a clear need to develop LAM evaluations that better correlate with user preferences.

Paper number 79:
Title: Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G
Authors: Eduardo Baena, Paolo Testolina, Michele Polese, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia
Abstract: Non-terrestrial networks (NTNs) are essential for ubiquitous connectivity, providing coverage in remote and underserved areas. However, since NTNs are currently operated independently, they face challenges such as isolation, limited scalability, and high operational costs. Integrating satellite constellations with terrestrial networks offers a way to address these limitations while enabling adaptive and cost-efficient connectivity through the application of Artificial Intelligence (AI) models. This paper introduces Space-O-RAN, a framework that extends Open Radio Access Network (RAN) principles to NTNs. It employs hierarchical closed-loop control with distributed Space RAN Intelligent Controllers (Space-RICs) to dynamically manage and optimize operations across both domains. To enable adaptive resource allocation and network orchestration, the proposed architecture integrates real-time satellite optimization and control with AI-driven management and digital twin (DT) modeling. It incorporates distributed Space Applications (sApps) and dApps to ensure robust performance in in highly dynamic orbital environments. A core feature is dynamic link-interface mapping, which allows network functions to adapt to specific application requirements and changing link conditions using all physical links on the satellite. Simulation results evaluate its feasibility by analyzing latency constraints across different NTN link types, demonstrating that intra-cluster coordination operates within viable signaling delay bounds, while offloading non-real-time tasks to ground infrastructure enhances scalability toward sixth-generation (6G) networks.

Paper number 80:
Title: A convex variational principle for the necessary conditions of classical optimal control
Authors: Amit Acharya, Janusz Ginster
Abstract: A scheme for generating a family of convex variational principles is developed, the Euler- Lagrange equations of each member of the family formally corresponding to the necessary conditions of optimal control of a given system of ordinary differential equations (ODE) in a well-defined sense. The scheme is applied to the Quadratic-Quadratic Regulator problem for which an explicit form of the functional is derived, and existence of minimizers of the variational principle is rigorously shown. It is shown that the Linear-Quadratic Regulator problem with time-dependent forcing can be solved within the formalism without requiring any nonlinear considerations, in contrast to the use of a Riccati system in the classical methodology. Our work demonstrates a pathway for solving nonlinear control problems via convex optimization.

Paper number 81:
Title: Autonomous Agricultural Monitoring with Aerial Drones and RF Energy-Harvesting Sensor Tags
Authors: Paul S. Kudyba, Haijian Sun
Abstract: In precision agriculture and plant science, there is an increasing demand for wireless sensors that are easy to deploy, maintain, and monitor. This paper investigates a novel approach that leverages recent advances in extremely low-power wireless communication and sensing, as well as the rapidly increasing availability of unmanned aerial vehicle (UAV) platforms. By mounting a specialized wireless payload on a UAV, battery-less sensor tags can harvest wireless beacon signals emitted from the drone, dramatically reducing the cost per sensor. These tags can measure environmental information such as temperature and humidity, then encrypt and transmit the data in the range of several meters. An experimental implementation was constructed at AERPAW, an NSF-funded wireless aerial drone research platform. While ground-based tests confirmed reliable sensor operation and data collection, airborne trials encountered wireless interference that impeded successfully detecting tag data. Despite these challenges, our results suggest further refinements could improve reliability and advance precision agriculture and agrarian research.

Paper number 82:
Title: Single-Channel EEG Tokenization Through Time-Frequency Modeling
Authors: Jathurshan Pradeepkumar, Xihao Piao, Zheng Chen, Jimeng Sun
Abstract: We introduce TFM-Tokenizer, a novel tokenization framework tailored for EEG analysis that transforms continuous, noisy brain signals into a sequence of discrete, well-represented tokens for various EEG tasks. Conventional approaches typically rely on continuous embeddings and inter-channel dependencies, which are limited in capturing inherent EEG features such as temporally unpredictable patterns and diverse oscillatory waveforms. In contrast, we hypothesize that critical time-frequency features can be effectively captured from a single channel. By learning tokens that encapsulate these intrinsic patterns within a single channel, our approach yields a scalable tokenizer adaptable across diverse EEG settings. We integrate the TFM-Tokenizer with a transformer-based TFM-Encoder, leveraging established pretraining techniques from natural language processing, such as masked token prediction, followed by downstream fine-tuning for various EEG tasks. Experiments across four EEG datasets show that TFM-Token outperforms state-of-the-art methods. On TUEV, our approach improves balanced accuracy and Cohen's Kappa by 5% over baselines. Comprehensive analysis of the learned tokens demonstrates their ability to capture class-distinctive features, enhance frequency representation, and ability to encode time-frequency motifs into distinct tokens, improving interpretability.

Paper number 83:
Title: Understanding Zero-shot Rare Word Recognition Improvements Through LLM Integration
Authors: Haoxuan Wang
Abstract: In this study, we investigate the integration of a large language model (LLM) with an automatic speech recognition (ASR) system, specifically focusing on enhancing rare word recognition performance. Using a 190,000-hour dataset primarily sourced from YouTube, pre-processed with Whisper V3 pseudo-labeling, we demonstrate that the LLM-ASR architecture outperforms traditional Zipformer-Transducer models in the zero-shot rare word recognition task, after training on a large dataset. Our analysis reveals that the LLM contributes significantly to improvements in rare word error rate (R-WER), while the speech encoder primarily determines overall transcription performance (Orthographic Word Error Rate, O-WER, and Normalized Word Error Rate, N-WER). Through extensive ablation studies, we highlight the importance of adapter integration in aligning speech encoder outputs with the LLM's linguistic capabilities. Furthermore, we emphasize the critical role of high-quality labeled data in achieving optimal performance. These findings provide valuable insights into the synergy between LLM-based ASR architectures, paving the way for future advancements in large-scale LLM-based speech recognition systems.

Paper number 84:
Title: On Distributed Average Consensus Algorithms
Authors: Ricardo Merched
Abstract: Average consensus (AC) strategies play a key role in every system that employs cooperation by means of distributed computations. To promote consensus, an $N$-agent network can repeatedly combine certain node estimates until their mean value is reached. Such algorithms are typically formulated as (global) recursive matrix-vector products of size $N$, where consensus is attained either asymptotically or in finite time. We revisit some existing approaches in these directions and propose new iterative and exact solutions to the problem. Considering directed graphs, this is carried out by interplaying with standalone conterparts, while underpinned by the so-called eigenstep method of finite-time convergence. In particular, we focus on reducing complexity so as to require, overall, as little as ${\cal O}(N)$ additions to achieve the solution exactly. For undirected graphs, the latter compares favorably to existing schemes that require, in total, ${\cal O}(KN^2)$ multiplications to deliver the AC, where $K$ refers to the number of distinct eivenvalues of the underlying graph Laplacian matrix.

Paper number 85:
Title: Improving Speech Enhancement by Cross- and Sub-band Processing with State Space Model
Authors: Jizhen Li, Weiping Tu, Yuhong Yang, Xinmeng Xu, Yiqun Zhang, Yanzhen Ren
Abstract: Recently, the state space model (SSM) represented by Mamba has shown remarkable performance in long-term sequence modeling tasks, including speech enhancement. However, due to substantial differences in sub-band features, applying the same SSM to all sub-bands limits its inference capability. Additionally, when processing each time frame of the time-frequency representation, the SSM may forget certain high-frequency information of low energy, making the restoration of structure in the high-frequency bands challenging. For this reason, we propose Cross- and Sub-band Mamba (CSMamba). To assist the SSM in handling different sub-band features flexibly, we propose a band split block that splits the full-band into four sub-bands with different widths based on their information similarity. We then allocate independent weights to each sub-band, thereby reducing the inference burden on the SSM. Furthermore, to mitigate the forgetting of low-energy information in the high-frequency bands by the SSM, we introduce a spectrum restoration block that enhances the representation of the cross-band features from multiple perspectives. Experimental results on the DNS Challenge 2021 dataset demonstrate that CSMamba outperforms several state-of-the-art (SOTA) speech enhancement methods in three objective evaluation metrics with fewer parameters.

Paper number 86:
Title: Power Domain Sparse Dimensional Constellation Multiple Access (PD-SDCMA): A Novel PD-NOMA for More Access Users
Authors: Zihan Li, Youzhi Li, Chenyu Liuand Yuhao Lian
Abstract: With the advent of the 6G mobile communication network era, the existing non-orthogonal multiple-access (NOMA) technology faces the challenge of high successive interference in multi-user scenarios, which limits its ability to support more user access. To address this, this paper proposes a novel power-domain sparse-dimensional constellation multiple-access scheme (PD-SDCMA). Through the signal space dimension selection strategy (S2D-strategy), this scheme sparsely superposes low-dimensional constellations onto high-dimensional signal spaces, and reduces the high-order interference caused by SC by taking advantage of the non-correlation between dimensions. Specifically, PD-SDCMA reduces the successive interference between users by sparsifying the dimension allocation of constellation superposition and designs a sparse superposition method based on the theory of vector space signal representation. Simulation results show that, under the AWGN channel, PD-SDCMA significantly outperforms the traditional PD-NOMA in terms of the number of supported users under QPSK and 16QAM modulations, and also has better BER performance. This paper provides a new solution for efficient spectrum utilization in future scenarios with large-scale user access.

Paper number 87:
Title: Optimization-free Smooth Control Barrier Function for Polygonal Collision Avoidance
Authors: Shizhen Wu, Yongchun Fang, Ning Sun, Biao Lu, Xiao Liang, Yiming Zhao
Abstract: Polygonal collision avoidance (PCA) is short for the problem of collision avoidance between two polygons (i.e., polytopes in planar) that own their dynamic equations. This problem suffers the inherent difficulty in dealing with non-smooth boundaries and recently optimization-defined metrics, such as signed distance field (SDF) and its variants, have been proposed as control barrier functions (CBFs) to tackle PCA problems. In contrast, we propose an optimization-free smooth CBF method in this paper, which is computationally efficient and proved to be nonconservative. It is achieved by three main steps: a lower bound of SDF is expressed as a nested Boolean logic composition first, then its smooth approximation is established by applying the latest log-sum-exp method, after which a specified CBF-based safety filter is proposed to address this class of problems. To illustrate its wide applications, the optimization-free smooth CBF method is extended to solve distributed collision avoidance of two underactuated nonholonomic vehicles and drive an underactuated container crane to avoid a moving obstacle respectively, for which numerical simulations are also performed.

Paper number 88:
Title: Study of Constrained Precoding with Zero-Crossing Modulation for Channels with 1-Bit Quantization and Oversampling
Authors: D. Melo, L. Landau, R. de Lamare
Abstract: Future wireless communications systems are expected to operate at bands above 100GHz. The high energy consumption of analog-to-digital converters, due to their high resolution represents a bottleneck for future wireless communications systems which require low-energy consumption and low-complexity devices at the receiver. In this work, we derive a novel precoding method based on quality of service constraints for a multiuser multiple-input multiple-output downlink system with 1-bit quantization and oversampling. For this scenario, the time-instance zero-crossing modulation which conveys the information into the zero-crossings is considered. Unlike prior studies, the constraint is given regarding the symbol error probability related to the minimum distance to the decision threshold. Numerical results illustrate the performance of the proposed precoding method evaluated under different parameters

Paper number 89:
Title: Efficient Semantic-aware Encryption for Secure Communications in Intelligent Connected Vehicles
Authors: Bizhu Wang, Zhiqiang Bian, Yue Chen, Xiaodong Xu, Chen Sun, Wenqi Zhang, Ping Zhang
Abstract: Semantic communication (SemCom) significantly improves inter-vehicle interactions in intelligent connected vehicles (ICVs) within limited wireless spectrum. However, the open nature of wireless communications introduces eavesdropping risks. To mitigate this, we propose the Efficient Semantic-aware Encryption (ESAE) mechanism, integrating cryptography into SemCom to secure semantic transmission without complex key management. ESAE leverages semantic reciprocity between source and reconstructed information from past communications to independently generate session keys at both ends, reducing key transmission costs and associated security risks. Additionally, ESAE introduces a semantic-aware key pre-processing method (SA-KP) using the YOLO-v10 model to extract consistent semantics from bit-level diverse yet semantically identical content, ensuring key consistency. Experimental results validate ESAE's effectiveness and feasibility under various wireless conditions, with key performance factors discussed.

Paper number 90:
Title: DeProPose: Deficiency-Proof 3D Human Pose Estimation via Adaptive Multi-View Fusion
Authors: Jianbin Jiao, Xina Cheng, Kailun Yang, Xiangrong Zhang, Licheng Jiao
Abstract: 3D human pose estimation has wide applications in fields such as intelligent surveillance, motion capture, and virtual reality. However, in real-world scenarios, issues such as occlusion, noise interference, and missing viewpoints can severely affect pose estimation. To address these challenges, we introduce the task of Deficiency-Aware 3D Pose Estimation. Traditional 3D pose estimation methods often rely on multi-stage networks and modular combinations, which can lead to cumulative errors and increased training complexity, making them unable to effectively address deficiency-aware estimation. To this end, we propose DeProPose, a flexible method that simplifies the network architecture to reduce training complexity and avoid information loss in multi-stage designs. Additionally, the model innovatively introduces a multi-view feature fusion mechanism based on relative projection error, which effectively utilizes information from multiple viewpoints and dynamically assigns weights, enabling efficient integration and enhanced robustness to overcome deficiency-aware 3D Pose Estimation challenges. Furthermore, to thoroughly evaluate this end-to-end multi-view 3D human pose estimation model and to advance research on occlusion-related challenges, we have developed a novel 3D human pose estimation dataset, termed the Deficiency-Aware 3D Pose Estimation (DA-3DPE) dataset. This dataset encompasses a wide range of deficiency scenarios, including noise interference, missing viewpoints, and occlusion challenges. Compared to state-of-the-art methods, DeProPose not only excels in addressing the deficiency-aware problem but also shows improvement in conventional scenarios, providing a powerful and user-friendly solution for 3D human pose estimation. The source code will be available at this https URL.

Paper number 91:
Title: Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning
Authors: Haoran Su
Abstract: Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute. This dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles. Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%. Third, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs. These contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.

Paper number 92:
Title: Downlink Multiuser Communications Relying on Flexible Intelligent Metasurfaces
Authors: Jiancheng An, Chau Yuen, Marco Di Renzo, Mérouane Debbah, H. Vincent Poor, Lajos Hanzo
Abstract: A flexible intelligent metasurface (FIM) is composed of an array of low-cost radiating elements, each of which can independently radiate electromagnetic signals and flexibly adjust its position through a 3D surface-morphing process. In our system, an FIM is deployed at a base station (BS) that transmits to multiple single-antenna users. We formulate an optimization problem for minimizing the total downlink transmit power at the BS by jointly optimizing the transmit beamforming and the FIM's surface shape, subject to an individual signal-to-interference-plus-noise ratio (SINR) constraint for each user as well as to a constraint on the maximum morphing range of the FIM. To address this problem, an efficient alternating optimization method is proposed to iteratively update the FIM's surface shape and the transmit beamformer to gradually reduce the transmit power. Finally, our simulation results show that at a given data rate the FIM reduces the transmit power by about $3$ dB compared to conventional rigid 2D arrays.

Paper number 93:
Title: Flexible Intelligent Metasurfaces for Enhanced MIMO Communications
Authors: Jiancheng An, Chau Yuen, Mérouane Debbah, Lajos Hanzo
Abstract: Flexible intelligent metasurfaces (FIMs) constitute a promising technology that could significantly boost the wireless network capacity. An FIM is essentially a soft array made up of many low-cost radiating elements that can independently emit electromagnetic signals. What's more, each element can flexibly adjust its position, even perpendicularly to the surface, to morph the overall 3D shape. In this paper, we study the potential of FIMs in point-to-point multiple-input multiple-output (MIMO) communications, where two FIMs are used as transceivers. In order to characterize the capacity limits of FIM-aided narrowband MIMO transmissions, we formulate an optimization problem for maximizing the MIMO channel capacity by jointly optimizing the 3D surface shapes of the transmitting and receiving FIMs, as well as the transmit covariance matrix, subject to a specific total transmit power constraint and to the maximum morphing range of the FIM. To solve this problem, we develop an efficient block coordinate descent (BCD) algorithm. The BCD algorithm iteratively updates the 3D surface shapes of the FIMs and the transmit covariance matrix, while keeping the other fixed. Numerical results verify that FIMs can achieve higher MIMO capacity than traditional rigid arrays. In some cases, the MIMO channel capacity can be doubled by employing FIMs.

Paper number 94:
Title: Beyond Diagonal RIS in Multiuser MIMO: Graph Theoretic Modeling and Optimal Architectures with Low Complexity
Authors: Zheyu Wu, Bruno Clerckx
Abstract: Reconfigurable intelligent surfaces (RIS) is regarded as a key enabler of wave/analog-domain beamforming, processing, and computing in future wireless communication systems. Recently, Beyond Diagonal RIS (BD-RIS) has been proposed as a generalization of conventional RIS, offering enhanced design flexibility thanks to the presence of tunable impedances that connect RIS elements. However, increased interconnections lead to high circuit complexity, which poses a significant practical challenge. In this paper, we address the fundamental open question: What is the class of BD-RIS architectures that achieves the optimal performance in a RIS-aided multiuser multi-input multi-output (MIMO) system? By modeling BD-RIS architectures using graph theory, we identify a class of BD-RIS architectures that achieves the optimal performance--matching that of fully-connected RIS--while maintaining low circuit complexity. Our result holds for a broad class of performance metrics, including the commonly used sum channel gain/sum-rate/energy efficiency maximization, transmit power minimization, and the information-theoretic capacity region. The number of tunable impedances in the proposed class is ${O}(N\min\{D,N/2\})$, where $N$ denotes the number of RIS elements and $D$ is the degree of freedom of the multiuser MIMO channel, i.e., the minimum between the number of transmit antennas and the total number of received antennas across all users. Since $D$ is much smaller than $N$ in practice, the complexity scales as ${O}(ND)$, which is substantially lower than the ${O}(N^2)$ complexity of fully-connected RIS. We further introduce two novel BD-RIS architectures--band-connected RIS and stem-connected RIS--and show that they belong to the optimal architecture class under certain conditions. Simulation results validate the optimality and enhanced performance-complexity tradeoff of our proposed architecture.

Paper number 95:
Title: Gaussian Process Regression for Improved Underwater Navigation
Authors: Nadav Cohen, Itzik Klein
Abstract: Accurate underwater navigation is a challenging task due to the absence of global navigation satellite system signals and the reliance on inertial navigation systems that suffer from drift over time. Doppler velocity logs (DVLs) are typically used to mitigate this drift through velocity measurements, which are commonly estimated using a parameter estimation approach such as least squares (LS). However, LS works under the assumption of ideal conditions and does not account for sensor biases, leading to suboptimal performance. This paper proposes a data-driven alternative based on multi-output Gaussian process regression (MOGPR) to improve DVL velocity estimation. MOGPR provides velocity estimates and associated measurement covariances, enabling an adaptive integration within an error-state Extended Kalman Filter (EKF). We evaluate our proposed approach using real-world AUV data and compare it against LS and a state-of-the-art deep learning model, BeamsNet. Results demonstrate that MOGPR reduces velocity estimation errors by approximately 20% while simultaneously enhancing overall navigation accuracy, particularly in the orientation states. Additionally, the incorporation of uncertainty estimates from MOGPR enables an adaptive EKF framework, improving navigation robustness in dynamic underwater environments.

Paper number 96:
Title: Efficient Coordination and Synchronization of Multi-Robot Systems Under Recurring Linear Temporal Logic
Authors: Davide Peron, Victor Nan Fernandez-Ayala, Eleftherios E. Vlahakis, Dimos V. Dimarogonas
Abstract: We consider multi-robot systems under recurring tasks formalized as linear temporal logic (LTL) specifications. To solve the planning problem efficiently, we propose a bottom-up approach combining offline plan synthesis with online coordination, dynamically adjusting plans via real-time communication. To address action delays, we introduce a synchronization mechanism ensuring coordinated task execution, leading to a multi-agent coordination and synchronization framework that is adaptable to a wide range of multi-robot applications. The software package is developed in Python and ROS2 for broad deployment. We validate our findings through lab experiments involving nine robots showing enhanced adaptability compared to previous methods. Additionally, we conduct simulations with up to ninety agents to demonstrate the reduced computational complexity and the scalability features of our work.

Paper number 97:
Title: Color Information-Based Automated Mask Generation for Detecting Underwater Atypical Glare Areas
Authors: Mingyu Jeon, Yeonji Paeng, Sejin Lee
Abstract: Underwater diving assistance and safety support robots acquire real-time diver information through onboard underwater cameras. This study introduces a breath bubble detection algorithm that utilizes unsupervised K-means clustering, thereby addressing the high accuracy demands of deep learning models as well as the challenges associated with constructing supervised datasets. The proposed method fuses color data and relative spatial coordinates from underwater images, employs CLAHE to mitigate noise, and subsequently performs pixel clustering to isolate reflective regions. Experimental results demonstrate that the algorithm can effectively detect regions corresponding to breath bubbles in underwater images, and that the combined use of RGB, LAB, and HSV color spaces significantly enhances detection accuracy. Overall, this research establishes a foundation for monitoring diver conditions and identifying potential equipment malfunctions in underwater environments.

Paper number 98:
Title: Audio-FLAN: A Preliminary Release
Authors: Liumeng Xue, Ziya Zhou, Jiahao Pan, Zixuan Li, Shuai Fan, Yinghao Ma, Sitong Cheng, Dongchao Yang, Haohan Guo, Yujia Xiao, Xinsheng Wang, Zixuan Shen, Chuanbo Zhu, Xinshen Zhang, Tianchi Liu, Ruibin Yuan, Zeyue Tian, Haohe Liu, Emmanouil Benetos, Ge Zhang, Yike Guo, Wei Xue
Abstract: Recent advancements in audio tokenization have significantly enhanced the integration of audio capabilities into large language models (LLMs). However, audio understanding and generation are often treated as distinct tasks, hindering the development of truly unified audio-language models. While instruction tuning has demonstrated remarkable success in improving generalization and zero-shot learning across text and vision, its application to audio remains largely unexplored. A major obstacle is the lack of comprehensive datasets that unify audio understanding and generation. To address this, we introduce Audio-FLAN, a large-scale instruction-tuning dataset covering 80 diverse tasks across speech, music, and sound domains, with over 100 million instances. Audio-FLAN lays the foundation for unified audio-language models that can seamlessly handle both understanding (e.g., transcription, comprehension) and generation (e.g., speech, music, sound) tasks across a wide range of audio domains in a zero-shot manner. The Audio-FLAN dataset is available on HuggingFace and GitHub and will be continuously updated.

Paper number 99:
Title: Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments
Authors: Shitong Xu, Yiyuan Yang, Niki Trigoni, Andrew Markham
Abstract: Target speaker extraction focuses on isolating a specific speaker's voice from an audio mixture containing multiple speakers. To provide information about the target speaker's identity, prior works have utilized clean audio examples as conditioning inputs. However, such clean audio examples are not always readily available (e.g. It is impractical to obtain a clean audio example of a stranger's voice at a cocktail party without stepping away from the noisy environment). Limited prior research has explored extracting the target speaker's characteristics from noisy audio examples, which may include overlapping speech from disturbing speakers. In this work, we focus on target speaker extraction when multiple speakers are present during the enrollment stage, through leveraging differences between audio segments where the target speakers are speaking (Positive Enrollments) and segments where they are not (Negative Enrollments). Experiments show the effectiveness of our model architecture and the dedicated pretraining method for the proposed task. Our method achieves state-of-the-art performance in the proposed application settings and demonstrates strong generalizability across challenging and realistic scenarios.

Paper number 100:
Title: Pinching-Antenna System (PASS)-enabled Multicast Communications
Authors: Xidong Mu, Guangyu Zhu, Yuanwei Liu
Abstract: Pinching-antenna system (PASS) is a novel flexible-antenna technology, which employs long-spread waveguides to convey signals with negligible path loss and pinching antennas (PAs) with adjustable positions to radiate signals from the waveguide into the free space. Therefore, short-distance and strong line-of-sight transmission can be established. In this paper, a novel PASS-enabled multicast communication framework is proposed, where multiple PAs on a single waveguide radiate the broadcast signals to multiple users. The multicast performance maximization problem is formulated to optimize the positions of all PAs. To address this non-convex problem, a particle swarm optimization-based algorithm is developed. Numerical results show that PASS can significantly outperform the conventional multiple-antenna transmission.

Paper number 101:
Title: Resolving quantitative MRI model degeneracy in self-supervised machine learning
Authors: Giulio V. Minore, Louis Dwyer-Hemmings, Timothy J.P. Bray, Hui Zhang
Abstract: Quantitative MRI (qMRI) estimates tissue properties of interest from measured MRI signals. This process is conventionally achieved by computationally expensive model fitting, which limits qMRI's clinical use, motivating recent development based on machine learning. Self-supervised approaches are particularly popular as they avoid the pitfall of distributional shift that affects supervised methods. However, it is unknown how they would behave if similar signals can result from multiple tissue properties, a common challenge known as model degeneracy. Understanding this is crucial for ascertaining the scope within which self-supervised approaches may be applied. To this end, this work makes two contributions. First, we demonstrate that model degeneracy will compromise self-supervised approaches, motivating the development of mitigating strategies. Second, we propose such a mitigating solution based on applying appropriate constraining transforms on the output of the bottleneck layer of the autoencoder network typically employed in self-supervised approaches. We illustrate both contributions using the estimation of proton density fat fraction and $R_2^*$ from chemical shift-encoded MRI, an ideal exemplar due to its exhibition of degeneracy across the full parameter space. The results from both simulation and $\textit{in vivo}$ experiments demonstrate that the proposed strategy resolves model degeneracy.

Paper number 102:
Title: AAD-LLM: Neural Attention-Driven Auditory Scene Understanding
Authors: Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Adeen Flinker, Daniel Friedman, Nima Mesgarani
Abstract: Auditory foundation models, including auditory large language models (LLMs), process all sound inputs equally, independent of listener perception. However, human auditory perception is inherently selective: listeners focus on specific speakers while ignoring others in complex auditory scenes. Existing models do not incorporate this selectivity, limiting their ability to generate perception-aligned responses. To address this, we introduce Intention-Informed Auditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM (AAD-LLM), a prototype system that integrates brain signals to infer listener attention. AAD-LLM extends an auditory LLM by incorporating intracranial electroencephalography (iEEG) recordings to decode which speaker a listener is attending to and refine responses accordingly. The model first predicts the attended speaker from neural activity, then conditions response generation on this inferred attentional state. We evaluate AAD-LLM on speaker description, speech transcription and extraction, and question answering in multitalker scenarios, with both objective and subjective ratings showing improved alignment with listener intention. By taking a first step toward intention-aware auditory AI, this work explores a new paradigm where listener perception informs machine listening, paving the way for future listener-centered auditory systems. Demo and code available: this https URL.

Paper number 103:
Title: ENACT-Heart -- ENsemble-based Assessment Using CNN and Transformer on Heart Sounds
Authors: Jiho Han, Adnan Shaout
Abstract: This study explores the application of Vision Transformer (ViT) principles in audio analysis, specifically focusing on heart sounds. This paper introduces ENACT-Heart - a novel ensemble approach that leverages the complementary strengths of Convolutional Neural Networks (CNN) and ViT through a Mixture of Experts (MoE) framework, achieving a remarkable classification accuracy of 97.52%. This outperforms the individual contributions of ViT (93.88%) and CNN (95.45%), demonstrating the potential for enhanced diagnostic accuracy in cardiovascular health monitoring. These results demonstrate the potential of ensemble methods in enhancing classification performance for cardiovascular health monitoring and diagnosis.

Paper number 104:
Title: Supervised contrastive learning from weakly-labeled audio segments for musical version matching
Authors: Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji
Abstract: Detecting musical versions (different renditions of the same piece) is a challenging task with important applications. Because of the ground truth nature, existing approaches match musical versions at the track level (e.g., whole song). However, most applications require to match them at the segment level (e.g., 20s chunks). In addition, existing approaches resort to classification and triplet losses, disregarding more recent losses that could bring meaningful improvements. In this paper, we propose a method to learn from weakly annotated segments, together with a contrastive loss variant that outperforms well-studied alternatives. The former is based on pairwise segment distance reductions, while the latter modifies an existing loss following decoupling, hyper-parameter, and geometric considerations. With these two elements, we do not only achieve state-of-the-art results in the standard track-level evaluation, but we also obtain a breakthrough performance in a segment-level evaluation. We believe that, due to the generality of the challenges addressed here, the proposed methods may find utility in domains beyond audio or musical version matching.

Paper number 105:
Title: MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection
Authors: Farzad Beizaee, Gregory Lodygensky, Christian Desrosiers, Jose Dolz
Abstract: Unsupervised anomaly detection in brain images is crucial for identifying injuries and pathologies without access to labels. However, the accurate localization of anomalies in medical images remains challenging due to the inherent complexity and variability of brain structures and the scarcity of annotated abnormal data. To address this challenge, we propose a novel approach that incorporates masking within diffusion models, leveraging their generative capabilities to learn robust representations of normal brain anatomy. During training, our model processes only normal brain MRI scans and performs a forward diffusion process in the latent space that adds noise to the features of randomly-selected patches. Following a dual objective, the model learns to identify which patches are noisy and recover their original features. This strategy ensures that the model captures intricate patterns of normal brain structures while isolating potential anomalies as noise in the latent space. At inference, the model identifies noisy patches corresponding to anomalies and generates a normal counterpart for these patches by applying a reverse diffusion process. Our method surpasses existing unsupervised anomaly detection techniques, demonstrating superior performance in generating accurate normal counterparts and localizing anomalies. The code is available at hhttps://github.com/farzad-bz/MAD-AD.

Paper number 106:
Title: PQDAST: Depth-Aware Arbitrary Style Transfer for Games via Perceptual Quality-Guided Distillation
Authors: Eleftherios Ioannou, Steve Maddock
Abstract: Artistic style transfer is concerned with the generation of imagery that combines the content of an image with the style of an artwork. In the realm of computer games, most work has focused on post-processing video frames. Some recent work has integrated style transfer into the game pipeline, but it is limited to single styles. Integrating an arbitrary style transfer method into the game pipeline is challenging due to the memory and speed requirements of games. We present PQDAST, the first solution to address this. We use a perceptual quality-guided knowledge distillation framework and train a compressed model using the FLIP evaluator, which substantially reduces both memory usage and processing time with limited impact on stylisation quality. For better preservation of depth and fine details, we utilise a synthetic dataset with depth and temporal considerations during training. The developed model is injected into the rendering pipeline to further enforce temporal stability and avoid diminishing post-process effects. Quantitative and qualitative experiments demonstrate that our approach achieves superior performance in temporal consistency, with comparable style transfer quality, to state-of-the-art image, video and in-game methods.

Paper number 107:
Title: A Frequency-Domain Opportunistic Approach for Spectral-Efficient Cell-Free Massive MIMO
Authors: Wei Jiang, Hans Dieter Schotten
Abstract: Constrained by weak signal strength and significant inter-cell interference, users located at the cell edge in a cellular network suffer from inferior service quality. Recently, cell-free massive MIMO (CFmMIMO) has gained considerable attention due to its capability to offer uniform quality of service, alleviating the cell-edge problem. In contrast to previous studies focused on narrow-band CFmMIMO systems, this paper studies wideband CFmMIMO communications against channel frequency selectivity. By exploiting the frequency-domain flexibility offered by orthogonal frequency-division multiplexing (OFDM), and leveraging a particular spatial characteristic in the cell-free structure -- namely, the near-far effect among distributed access points (APs) -- we propose an opportunistic approach to boost spectral efficiency. The core concept lies in opportunistically activating nearby APs for certain users across their assigned OFDM subcarriers while deactivating distant APs to prevent power wastage and lower inter-user interference. Furthermore, this approach enables the use of downlink pilots by reducing the number of active APs per subcarrier to a small subset, thereby substantially improving downlink performance through coherent detection at the user receiver. Verified by numerical results, our proposed approach demonstrates considerable performance improvement compared to the two benchmark approaches.

Paper number 108:
Title: Pleno-Generation: A Scalable Generative Face Video Compression Framework with Bandwidth Intelligence
Authors: Bolin Chen, Hanwei Zhu, Shanzhi Yin, Lingyu Zhu, Jie Chen, Ru-Ling Liao, Shiqi Wang, Yan Ye
Abstract: Generative model based compact video compression is typically operated within a relative narrow range of bitrates, and often with an emphasis on ultra-low rate applications. There has been an increasing consensus in the video communication industry that full bitrate coverage should be enabled by generative coding. However, this is an extremely difficult task, largely because generation and compression, although related, have distinct goals and trade-offs. The proposed Pleno-Generation (PGen) framework distinguishes itself through its exceptional capabilities in ensuring the robustness of video coding by utilizing a wider range of bandwidth for generation via bandwidth intelligence. In particular, we initiate our research of PGen with face video coding, and PGen offers a paradigm shift that prioritizes high-fidelity reconstruction over pursuing compact bitstream. The novel PGen framework leverages scalable representation and layered reconstruction for Generative Face Video Compression (GFVC), in an attempt to imbue the bitstream with intelligence in different granularity. Experimental results illustrate that the proposed PGen framework can facilitate existing GFVC algorithms to better deliver high-fidelity and faithful face videos. In addition, the proposed framework can allow a greater space of flexibility for coding applications and show superior RD performance with a much wider bitrate range in terms of various quality evaluations. Moreover, in comparison with the latest Versatile Video Coding (VVC) codec, the proposed scheme achieves competitive Bjøntegaard-delta-rate savings for perceptual-level evaluations.

Paper number 109:
Title: Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics
Authors: Jiahe Li, Xin Chen, Fanqi Shen, Junru Chen, Yuxin Liu, Daoze Zhang, Zhizhang Yuan, Fang Zhao, Meng Li, Yang Yang
Abstract: Neurological disorders represent significant global health challenges, driving the advancement of brain signal analysis methods. Scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG) are widely used to diagnose and monitor neurological conditions. However, dataset heterogeneity and task variations pose challenges in developing robust deep learning solutions. This review systematically examines recent advances in deep learning approaches for EEG/iEEG-based neurological diagnostics, focusing on applications across 7 neurological conditions using 46 datasets. We explore trends in data utilization, model design, and task-specific adaptations, highlighting the importance of pre-trained multi-task models for scalable, generalizable solutions. To advance research, we propose a standardized benchmark for evaluating models across diverse datasets to enhance reproducibility. This survey emphasizes how recent innovations can transform neurological diagnostics and enable the development of intelligent, adaptable healthcare solutions.

Paper number 110:
Title: Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction
Authors: Tianpeng Li, Jun Liu, Tao Zhang, Yuanbo Fang, Da Pan, Mingrui Wang, Zheng Liang, Zehuan Li, Mingan Lin, Guosheng Dong, Jianhua Xu, Haoze Sun, Zenan Zhou, Weipeng Chen
Abstract: We introduce Baichuan-Audio, an end-to-end audio large language model that seamlessly integrates audio understanding and generation. It features a text-guided aligned speech generation mechanism, enabling real-time speech interaction with both comprehension and generation capabilities. Baichuan-Audio leverages a pre-trained ASR model, followed by multi-codebook discretization of speech at a frame rate of 12.5 Hz. This multi-codebook setup ensures that speech tokens retain both semantic and acoustic information. To further enhance modeling, an independent audio head is employed to process audio tokens, effectively capturing their unique characteristics. To mitigate the loss of intelligence during pre-training and preserve the original capabilities of the LLM, we propose a two-stage pre-training strategy that maintains language understanding while enhancing audio modeling. Following alignment, the model excels in real-time speech-based conversation and exhibits outstanding question-answering capabilities, demonstrating its versatility and efficiency. The proposed model demonstrates superior performance in real-time spoken dialogue and exhibits strong question-answering abilities. Our code, model and training data are available at this https URL

Paper number 111:
Title: Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework
Authors: Federico Vasile, Elisa Maiettini, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale
Abstract: Most control techniques for prosthetic grasping focus on dexterous fingers control, but overlook the wrist motion. This forces the user to perform compensatory movements with the elbow, shoulder and hip to adapt the wrist for grasping. We propose a computer vision-based system that leverages the collaboration between the user and an automatic system in a shared autonomy framework, to perform continuous control of the wrist degrees of freedom in a prosthetic arm, promoting a more natural approach-to-grasp motion. Our pipeline allows to seamlessly control the prosthetic wrist to follow the target object and finally orient it for grasping according to the user intent. We assess the effectiveness of each system component through quantitative analysis and finally deploy our method on the Hannes prosthetic arm. Code and videos: this https URL.

Paper number 112:
Title: Improving the Inclusivity of Dutch Speech Recognition by Fine-tuning Whisper on the JASMIN-CGN Corpus
Authors: Golshid Shekoufandeh, Paul Boersma, Antal van den Bosch
Abstract: We test and study the variation in speech recognition of fine-tuned versions of the Whisper model on child, elderly and non-native Dutch speech from the JASMIN-CGN corpus. Our primary goal is to evaluate how speakers' age and linguistic background influence Whisper's performance. Whisper achieves varying Word Error Rates (WER) when fine-tuned on subpopulations of specific ages and linguistic backgrounds. Fine-tuned performance is remarkably better than zero-shot performance, achieving a relative reduction in WER of 81% for native children, 72% for non-native children, 67% for non-native adults, and 65% for native elderly people. Our findings underscore the importance of training speech recognition models like Whisper on underrepresented subpopulations such as children, the elderly, and non-native speakers.

Paper number 113:
Title: Inverse Kinematics on Guiding Vector Fields for Robot Path Following
Authors: Yu Zhou, Jesús Bautista, Weijia Yao, Héctor García de Marina
Abstract: Inverse kinematics is a fundamental technique for motion and positioning control in robotics, typically applied to end-effectors. In this paper, we extend the concept of inverse kinematics to guiding vector fields for path following in autonomous mobile robots. The desired path is defined by its implicit equation, i.e., by a collection of points belonging to one or more zero-level sets. These level sets serve as a reference to construct an error signal that drives the guiding vector field toward the desired path, enabling the robot to converge and travel along the path by following such a vector field. We start with the formal exposition on how inverse kinematics can be applied to guiding vector fields for single-integrator robots in an m-dimensional Euclidean space. Then, we leverage inverse kinematics to ensure that the level-set error signal behaves as a linear system, facilitating control over the robot's transient motion toward the desired path and allowing for the injection of feed-forward signals to induce precise motion behavior along the path. We then propose solutions to the theoretical and practical challenges of applying this technique to unicycles with constant speeds to follow 2D paths with precise transient control. We finish by validating the predicted theoretical results through real flights with fixed-wing drones.

Paper number 114:
Title: Time series forecasting based on optimized LLM for fault prediction in distribution power grid insulators
Authors: João Pedro Matos-Carvalho, Stefano Frizzo Stefenon, Valderi Reis Quietinho Leithardt, Kin-Choong Yow
Abstract: Surface contamination on electrical grid insulators leads to an increase in leakage current until an electrical discharge occurs, which can result in a power system shutdown. To mitigate the possibility of disruptive faults resulting in a power outage, monitoring contamination and leakage current can help predict the progression of faults. Given this need, this paper proposes a hybrid deep learning (DL) model for predicting the increase in leakage current in high-voltage insulators. The hybrid structure considers a multi-criteria optimization using tree-structured Parzen estimation, an input stage filter for signal noise attenuation combined with a large language model (LLM) applied for time series forecasting. The proposed optimized LLM outperforms state-of-the-art DL models with a root-mean-square error equal to 2.24$\times10^{-4}$ for a short-term horizon and 1.21$\times10^{-3}$ for a medium-term horizon.

Paper number 115:
Title: Experimental validation of UAV search and detection system in real wilderness environment
Authors: Stella Dumenčić, Luka Lanča, Karlo Jakac, Stefan Ivić
Abstract: Search and rescue (SAR) missions require reliable search methods to locate survivors, especially in challenging or inaccessible environments. This is why introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the efficiency of SAR missions while simultaneously increasing the safety of everyone involved in the mission. Motivated by this, we design and experiment with autonomous UAV search for humans in a Mediterranean karst environment. The UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic control method according to known probability density and detection function. The implemented sensing framework consists of a probabilistic search model, motion control system, and computer vision object detection. It enables calculation of the probability of the target being detected in the SAR mission, and this paper focuses on experimental validation of proposed probabilistic framework and UAV control. The uniform probability density to ensure the even probability of finding the targets in the desired search area is achieved by assigning suitably thought-out tasks to 78 volunteers. The detection model is based on YOLO and trained with a previously collected ortho-photo image database. The experimental search is carefully planned and conducted, while as many parameters as possible are recorded. The thorough analysis consists of the motion control system, object detection, and the search validation. The assessment of the detection and search performance provides strong indication that the designed detection model in the UAV control algorithm is aligned with real-world results.

Paper number 116:
Title: A Concise Lyapunov Analysis of Nesterov's Accelerated Gradient Method
Authors: Jun Liu
Abstract: Convergence analysis of Nesterov's accelerated gradient method has attracted significant attention over the past decades. While extensive work has explored its theoretical properties and elucidated the intuition behind its acceleration, a simple and direct proof of its convergence rates is still lacking. We provide a concise Lyapunov analysis of the convergence rates of Nesterov's accelerated gradient method for both general convex and strongly convex functions.

Paper number 117:
Title: Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation
Authors: Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng
Abstract: Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation. Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages. While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility. To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead. LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility. Experimental results across a range of languages demonstrate that LoRS-Merging significantly outperforms conventional multi-lingual multi-task training baselines. Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications.

Paper number 118:
Title: Evaluation of Battery Energy Storage System to Provide Virtual Transmission Service
Authors: Qiushi Wang, Xingpeng Li
Abstract: An immediate need in the transmission system is to find alternative solutions that improve system operation and defer the need for new transmission lines. This study comprehensively evaluates the performance and economic benefits of short-term operation of using battery energy storage systems (BESS) as virtual transmission (VT) to promote power transfer across distant regions. Specifically, this work implements various day-ahead energy scheduling models to analyze the impact of VT on system operation cost, network congestion, model computational time, and market performance. The performance of VT is compared with three alternative network congestion mitigation methods, including building new high-voltage physical transmission lines, cost-driven battery energy storage systems, and network reconfiguration, as well as combinations of two of the aforementioned methods. The benchmark dayahead scheduling model is a traditional security-constrained unit commitment model without system upgrades or other network congestion mitigation. Numerical simulations conducted on the IEEE 24-bus system demonstrate that VT provides a 14% operational cost reduction and 34% congested line relief compared to the base case. Compared to other examined schemes, VT is the only one comparable to physical transmission lines that can provide satisfying congestion relief and operation cost reduction without significantly sacrificing computing time and load payment.

Paper number 119:
Title: MIML: Multiplex Image Machine Learning for High Precision Cell Classification via Mechanical Traits within Microfluidic Systems
Authors: Khayrul Islam, Ratul Paul, Shen Wang, Yuwen Zhao, Partho Adhikary, Qiying Li, Xiaochen Qin, Yaling Liu
Abstract: Label-free cell classification is advantageous for supplying pristine cells for further use or examination, yet existing techniques frequently fall short in terms of specificity and speed. In this study, we address these limitations through the development of a novel machine learning framework, Multiplex Image Machine Learning (MIML). This architecture uniquely combines label-free cell images with biomechanical property data, harnessing the vast, often underutilized morphological information intrinsic to each cell. By integrating both types of data, our model offers a more holistic understanding of the cellular properties, utilizing morphological information typically discarded in traditional machine learning models. This approach has led to a remarkable 98.3\% accuracy in cell classification, a substantial improvement over models that only consider a single data type. MIML has been proven effective in classifying white blood cells and tumor cells, with potential for broader application due to its inherent flexibility and transfer learning capability. It's particularly effective for cells with similar morphology but distinct biomechanical properties. This innovative approach has significant implications across various fields, from advancing disease diagnostics to understanding cellular behavior.

Paper number 120:
Title: Sample-based nonlinear detectability for discrete-time systems
Authors: Isabelle Krauss, Victor G. Lopez, Matthias A. Müller
Abstract: This paper introduces two sample-based formulations of incremental input/output-to-state stability (i-IOSS), a suitable detectability notion for general nonlinear systems. In this work we consider the case of limited output information, i.e., measurements are only infrequently and/or irregularly available. The output-dependent term of the sample-based i-IOSS bound is properly modified to yield a characterization for detectability in presence of incomplete output sequences. We provide both a non-timediscounted and a time-discounted formulation of samplebased i-IOSS. Furthermore, conditions for an i-IOSS system to be also sample-based i-IOSS are given and the relation between the two formulations of sample-based i-IOSS is shown.

Paper number 121:
Title: Nonlinear Distortion Radiated from Large Arrays and Active Reconfigurable Intelligent Surfaces
Authors: Nikolaos Kolomvakis, Alva Kosasih, Emil Björnson
Abstract: Extremely large aperture arrays (ELAAs) and reconfigurable intelligent surfaces (RISs) are candidate enablers to realize connectivity goals for the sixth-generation (6G) wireless networks. For instance, ELAAs can provide orders-of-magnitude higher area throughput compared to what massive multiple-input multiple-output (MIMO) can deliver through spatial multiplexing, while RISs can improve the propagation conditions over wireless channels but a passively reflecting RIS must be large to be effective. Active RIS with amplifiers can deal with this issue. In this paper, we analyze the distortion generated by nonlinear amplifiers in both ELAAs and active RIS. We derive analytical expressions for the angular directions and depth of nonlinear distortion in both near-field and far-field channels. These insights are then used in a distortion-aware scheduling scheme that predicts the beamforming directions of the distortion and strategically allocates users in frequency to minimize its impact. Numerical results validate our theoretical analysis and compare distortion-aware and distortion-unaware scheduling methods, highlighting the benefits of accounting for nonlinearities. We conclude that nonlinearities can both create in-band and out-of-band distortion that is beamformed in entirely new directions and distances from the transmitter.

Paper number 122:
Title: An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping with Applications to Multicomponent Diffusion and Relaxation MRI
Authors: Yunsong Liu, Debdut Mandal, Congyu Liao, Kawin Setsompop, Justin P. Haldar
Abstract: We introduce a new algorithm to solve a regularized spatial-spectral image estimation problem. Our approach is based on the linearized alternating directions method of multipliers (LADMM), which is a variation of the popular ADMM algorithm. Although LADMM has existed for some time, it has not been very widely used in the computational imaging literature. This is in part because there are many possible ways of mapping LADMM to a specific optimization problem, and it is nontrivial to find a computationally efficient implementation out of the many competing alternatives. We believe that our proposed implementation represents the first application of LADMM to the type of optimization problem considered in this work (involving a linear-mixture forward model, spatial regularization, and nonnegativity constraints). We evaluate our algorithm in a variety of multiparametric MRI partial volume mapping scenarios (diffusion-relaxation, relaxation-relaxation, relaxometry, and fingerprinting), where we consistently observe substantial ($\sim$3$\times$-50$\times$) speed improvements. We expect this to reduce barriers to using spatially-regularized partial volume compartment mapping methods. Further, the considerable improvements we observed also suggest the potential value of considering LADMM for a broader set of computational imaging problems.

Paper number 123:
Title: PFCM: Poisson flow consistency models for low-dose CT image denoising
Authors: Dennis Hein, Grant Stevens, Adam Wang, Ge Wang
Abstract: X-ray computed tomography (CT) is widely used for medical diagnosis and treatment planning; however, concerns about ionizing radiation exposure drive efforts to optimize image quality at lower doses. This study introduces Poisson Flow Consistency Models (PFCM), a novel family of deep generative models that combines the robustness of PFGM++ with the efficient single-step sampling of consistency models. PFCM are derived by generalizing consistency distillation to PFGM++ through a change-of-variables and an updated noise distribution. As a distilled version of PFGM++, PFCM inherit the ability to trade off robustness for rigidity via the hyperparameter $D \in (0,\infty)$. A fact that we exploit to adapt this novel generative model for the task of low-dose CT image denoising, via a ``task-specific'' sampler that ``hijacks'' the generative process by replacing an intermediate state with the low-dose CT image. While this ``hijacking'' introduces a severe mismatch -- the noise characteristics of low-dose CT images are different from that of intermediate states in the Poisson flow process -- we show that the inherent robustness of PFCM at small $D$ effectively mitigates this issue. The resulting sampler achieves excellent performance in terms of LPIPS, SSIM, and PSNR on the Mayo low-dose CT dataset. By contrast, an analogous sampler based on standard consistency models is found to be significantly less robust under the same conditions, highlighting the importance of a tunable $D$ afforded by our novel framework. To highlight generalizability, we show effective denoising of clinical images from a prototype photon-counting system reconstructed using a sharper kernel and at a range of energy levels.

Paper number 124:
Title: Adaptive LPD Radar Waveform Design with Generative Deep Learning
Authors: Matthew R. Ziemann, Christopher A. Metzler
Abstract: We propose a learning-based method for adaptively generating low probability of detection (LPD) radar waveforms that blend into their operating environment. Our waveforms are designed to follow a distribution that is indistinguishable from the ambient radio frequency (RF) background -- while still being effective at ranging and sensing. To do so, we use an unsupervised, adversarial learning framework; our generator network produces waveforms designed to confuse a critic network, which is optimized to differentiate generated waveforms from the background. To ensure our generated waveforms are still effective for sensing, we introduce and minimize an ambiguity function-based loss on the generated waveforms. We evaluate the performance of our method by comparing the single-pulse detectability of our generated waveforms with traditional LPD waveforms using a separately trained detection neural network. We find that our method can generate LPD waveforms that reduce detectability by up to 90% while simultaneously offering improved ambiguity function (sensing) characteristics. Our framework also provides a mechanism to trade-off detectability and sensing performance.

Paper number 125:
Title: VibNet: Vibration-Boosted Needle Detection in Ultrasound Images
Authors: Dianye Huang, Chenyang Li, Angelos Karlas, Xiangyu Chu, K. W. Samuel Au, Nassir Navab, Zhongliang Jiang
Abstract: Precise percutaneous needle detection is crucial for ultrasound (US)-guided interventions. However, inherent limitations such as speckles, needle-like artifacts, and low resolution make it challenging to robustly detect needles, especially when their visibility is reduced or imperceptible. To address this challenge, we propose VibNet, a learning-based framework designed to enhance the robustness and accuracy of needle detection in US images by leveraging periodic vibration applied externally to the needle shafts. VibNet integrates neural Short-Time Fourier Transform and Hough Transform modules to achieve successive sub-goals, including motion feature extraction in the spatiotemporal space, frequency feature aggregation, and needle detection in the Hough space. Due to the periodic subtle vibration, the features are more robust in the frequency domain than in the image intensity domain, making VibNet more effective than traditional intensity-based methods. To demonstrate the effectiveness of VibNet, we conducted experiments on distinct \textit{ex vivo} porcine and bovine tissue samples. The results obtained on porcine samples demonstrate that VibNet effectively detects needles even when their visibility is severely reduced, with a tip error of $1.61\pm1.56~mm$ compared to $8.15\pm9.98~mm$ for UNet and $6.63\pm7.58~mm$ for WNet, and a needle direction error of $1.64\pm1.86^{\circ}$ compared to $9.29\pm15.30^{\circ}$ for UNet and $8.54\pm17.92^{\circ}$ for WNet. Code: this https URL.

Paper number 126:
Title: Constant Modulus Waveform Design with Space-Time Sidelobe Reduction for DFRC Systems
Authors: Byunghyun Lee, Anindya Bijoy Das, David Love, Christopher Brinton, James Krogmeier
Abstract: Dual-function radar-communication (DFRC) is a key enabler of location-based services for next-generation communication systems. In this paper, we investigate the problem of designing constant modulus waveforms for DFRC systems. We consider the joint optimization of the spatial beam pattern and space-time correlation levels for better separating multiple targets in different angle and delay bins. In particular, we use the space-time correlation function to quantify the correlations between different angle and delay bins and formulate integrated sidelobe levels (ISLs). To serve communication users, we employ constructive interference (CI)-based precoding to modulate information symbols, which leverages distortion induced by multiuser multiple-input multiple-output (MU-MIMO) and radar transmission. We propose two solution algorithms based on the alternating direction method of multipliers (ADMM) and majorization-minimization (MM) principles, which are effective for small and large block sizes, respectively. The proposed ADMM-based solution decomposes the nonconvex formulated problem into multiple tractable subproblems, each of which admits a closed-form solution. To accelerate convergence of the MM-based solution, we propose a novel majorizing function for complex quadratic functions. After majorization, we decompose the approximated problem into independent subproblems for parallelization, mitigating the complexity that increases with block size. We evaluate the performance of the proposed algorithms in comparison to the existing DFRC algorithm. Simulation results demonstrate that the proposed methods can substantially enhance the detection and estimation performance due to reduced space-time correlation levels.

Paper number 127:
Title: Generative AI Enables EEG Super-Resolution via Spatio-Temporal Adaptive Diffusion Learning
Authors: Shuqiang Wang, Tong Zhou, Yanyan Shen, Ye Li, Guoheng Huang, Yong Hu
Abstract: Electroencephalogram (EEG) technology, particularly high-density EEG (HD EEG) devices, is widely used in fields such as neuroscience. HD EEG devices improve the spatial resolution of EEG by placing more electrodes on the scalp, which meet the requirements of clinical diagnostic applications such as epilepsy focus localization. However, this technique faces challenges, such as high acquisition costs and limited usage scenarios. In this paper, spatio-temporal adaptive diffusion models (STAD) are proposed to pioneer the use of diffusion models for achieving spatial SR reconstruction from low-resolution (LR, 64 channels or fewer) EEG to high-resolution (HR, 256 channels) EEG. Specifically, a spatio-temporal condition module is designed to extract the spatio-temporal features of LR EEG, which are then used as conditional inputs to direct the reverse denoising process. Additionally, a multi-scale Transformer denoising module is constructed to leverage multi-scale convolution blocks and cross-attention-based diffusion Transformer blocks for conditional guidance to generate subject-adaptive SR EEG. Experimental results demonstrate that the STAD significantly enhances the spatial resolution of LR EEG and quantitatively outperforms existing methods. Furthermore, STAD demonstrate their value by applying synthetic SR EEG to classification and source localization tasks, indicating their potential to substantially boost the spatial resolution of EEG.

Paper number 128:
Title: Dataset Distillation in Medical Imaging: A Feasibility Study
Authors: Muyang Li, Can Cui, Quan Liu, Ruining Deng, Tianyuan Yao, Marilyn Lionts, Yuankai Huo
Abstract: Data sharing in the medical image analysis field has potential yet remains underappreciated. The aim is often to share datasets efficiently with other sites to train models effectively. One possible solution is to avoid transferring the entire dataset while still achieving similar model performance. Recent progress in data distillation within computer science offers promising prospects for sharing medical data efficiently without significantly compromising model effectiveness. However, it remains uncertain whether these methods would be applicable to medical imaging, since medical and natural images are distinct fields. Moreover, it is intriguing to consider what level of performance could be achieved with these methods. To answer these questions, we conduct investigations on a variety of leading data distillation methods, in different contexts of medical imaging. We evaluate the feasibility of these methods with extensive experiments in two aspects: 1) Assess the impact of data distillation across multiple datasets characterized by minor or great variations. 2) Explore the indicator to predict the distillation performance. Our extensive experiments across multiple medical datasets reveal that data distillation can significantly reduce dataset size while maintaining comparable model performance to that achieved with the full dataset, suggesting that a small, representative sample of images can serve as a reliable indicator of distillation success. This study demonstrates that data distillation is a viable method for efficient and secure medical data sharing, with the potential to facilitate enhanced collaborative research and clinical applications.

Paper number 129:
Title: Can all variations within the unified mask-based beamformer framework achieve identical peak extraction performance?
Authors: Atsuo Hiroe, Katsutoshi Itoyama, Kazuhiro Nakadai
Abstract: This study investigates mask-based beamformers (BFs), which estimate filters for target sound extraction (TSE) using time-frequency masks. Although multiple mask-based BFs have been proposed, no consensus has been reached on which one offers the best target-extraction performance. Previously, we found that maximum signal-to-noise ratio and minimum mean square error (MSE) BFs can achieve the same extraction performance as the theoretical upper-bound performance, with each BF containing a different optimal mask. However, two issues remained unsolved: only two BFs were covered, excluding the minimum variance distortionless response BF, and ideal scaling (IS) was employed to ideally adjust the output scale, which is not applicable to realistic scenarios. To address these issues, this study proposes a unified framework for mask-based BFs comprising two processes: filter estimation that can cover all possible BFs and scaling applicable to realistic scenarios by employing a mask to generate a scaling reference. Based on the operators and covariance matrices used in BF formulas, all possible BFs can be classified into 12 variations, including two new ones. Optimal masks for both processes are obtained by minimizing the MSE between the target and BF output. The experimental results using the CHiME-4 dataset suggested that 1) all 12 variations can achieve the theoretical upper-bound performance, and 2) mask-based scaling can behave like IS, even when constraining the temporal mean of a non-negative mask to one. These results can be explained by considering the practical parameter count of the masks. These findings contribute to 1) designing a TSE system, 2) improving scaling accuracy through mask-based scaling, and 3) estimating the extraction performance of a BF.

Paper number 130:
Title: CL-DiffPhyCon: Closed-loop Diffusion Control of Complex Physical Systems
Authors: Long Wei, Haodong Feng, Yuchen Yang, Ruiqi Feng, Peiyan Hu, Xiang Zheng, Tao Zhang, Dixia Fan, Tailin Wu
Abstract: The control problems of complex physical systems have broad applications in science and engineering. Previous studies have shown that generative control methods based on diffusion models offer significant advantages for solving these problems. However, existing generative control approaches face challenges in both performance and efficiency when extended to the closed-loop setting, which is essential for effective control. In this paper, we propose an efficient Closed-Loop Diffusion method for Physical systems Control (CL-DiffPhyCon). By employing an asynchronous denoising framework for different physical time steps, CL-DiffPhyCon generates control signals conditioned on real-time feedback from the system with significantly reduced computational cost during sampling. Additionally, the control process could be further accelerated by incorporating fast sampling techniques, such as DDIM. We evaluate CL-DiffPhyCon on two tasks: 1D Burgers' equation control and 2D incompressible fluid control. The results demonstrate that CL-DiffPhyCon achieves superior control performance with significant improvements in sampling efficiency. The code can be found at this https URL.

Paper number 131:
Title: Prototyping and Experimental Results for ISAC-based Channel Knowledge Map
Authors: Chaoyue Zhang, Zhiwen Zhou, Xiaoli Xu, Yong Zeng, Zaichen Zhang, Shi Jin
Abstract: Channel knowledge map (CKM) is a novel approach for achieving environment-aware communication and sensing. This paper presents an integrated sensing and communication (ISAC)-based CKM prototype system, demonstrating the mutualistic relationship between ISAC and CKM. The system consists of an ISAC base station (BS), a user equipment (UE), and a server. By using a shared orthogonal frequency division multiplexing (OFDM) waveform over the millimeter wave (mmWave) band, the ISAC BS is able to communicate with the UE while simultaneously sensing the environment and acquiring the UE's location. The prototype showcases the complete process of the construction and application of the ISAC-based CKM. For CKM construction phase, the BS stores the UE's channel feedback information in a database indexed by the UE's location, including beam indices and channel gain. For CKM application phase, the BS looks up the best beam index from the CKM based on the UE's location to achieve training-free mmWave beam alignment. The experimental results show that ISAC can be used to construct or update CKM while communicating with UEs, and the pre-learned CKM can assist ISAC for training-free beam alignment.

Paper number 132:
Title: Robust 3D Multi-Source Localization with a Movable Antenna Array via Sparse Signal Processing
Authors: Amir Mansourian, Alireza Fadakar, Saeed Akhavan, Behrouz Maham
Abstract: Accurately localizing multiple sources is a critical task with various applications in wireless communications, such as emergency services, including natural post-disaster search and rescue operations. However, scenarios where the receiver is moving have not been sufficiently addressed in recent studies. This paper tackles the angle of arrival (AOA) 3D-localization problem for multiple sparse signal sources with a moving receiver, which has a limited number of antennas that may be outnumbered by the sources. First, an energy detector algorithm is proposed to leverage signal sparsity for eliminating noisy samples. Subsequently, elevation and azimuth AOAs of sources are roughly estimated using two dimensional multiple signal classification (2D-MUSIC) method. Next, an iterative algorithm is proposed to refine and estimate the AOAs more accurately. To this end, we introduce a sparse recovery algorithm to exploit signal sparsity, followed by a phase smoothing algorithm to refine the estimates. The K-SVD algorithm is then applied to the smoothed output to accurately determine the elevation and azimuth AOAs of the sources. For localization, a new multi-source 3D-localization algorithm is proposed to estimate the positions of sources using the refined AOA estimates over a sequence of time windows. Extensive simulations are carried out to demonstrate the effectiveness of the proposed framework.

Paper number 133:
Title: Data-driven Construction of Finite Abstractions for Interconnected Systems: A Compositional Approach
Authors: Daniel Ajeleye, Majid Zamani
Abstract: Finite-state abstractions (a.k.a. symbolic models) present a promising avenue for the formal verification and synthesis of controllers in continuous-space control systems. These abstractions provide simplified models that capture the fundamental behaviors of the original systems. However, the creation of such abstractions typically relies on the availability of precise knowledge concerning system dynamics, which might not be available in many real-world applications. In this work, we introduce a novel data-driven and compositional approach for constructing finite abstractions for interconnected systems comprised of discrete-time control subsystems with partially unknown dynamics. These subsystems interact through a partially unknown static interconnection map. Our methodology for abstracting the interconnected system involves constructing abstractions for individual subsystems and incorporating an abstraction of the interconnection map.

Paper number 134:
Title: Integration of Beyond Diagonal RIS and UAVs in 6G NTNs: Enhancing Aerial Connectivity
Authors: Wali Ullah Khan, Eva Lagunas, Asad Mahmood, Muhammad Asif, Manzoor Ahmed, Symeon Chatzinotas
Abstract: The reconfigurable intelligent surface (RIS) technology shows great potential in sixth-generation (6G) terrestrial and non-terrestrial networks (NTNs) since it can effectively change wireless settings to improve connectivity. Extensive research has been conducted on traditional RIS systems with diagonal phase response matrices. The straightforward RIS architecture, while cost-effective, has restricted capabilities in manipulating the wireless channels. The beyond diagonal reconfigurable intelligent surface (BD-RIS) greatly improves control over the wireless environment by utilizing interconnected phase response elements. This work proposes the integration of unmanned aerial vehicle (UAV) communications and BD-RIS in 6G NTNs, which has the potential to further enhance wireless coverage and spectral efficiency. We begin with the preliminaries of UAV communications and then discuss the fundamentals of BD-RIS technology. Subsequently, we discuss the potential of BD-RIS and UAV communications integration. We then proposed a case study based on UAV-mounted transmissive BD-RIS communication. Finally, we highlight future research directions and conclude this work.

Paper number 135:
Title: Conformal Distributed Remote Inference in Sensor Networks Under Reliability and Communication Constraints
Authors: Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Petar Popovski, Osvaldo Simeone
Abstract: This paper presents communication-constrained distributed conformal risk control (CD-CRC) framework, a novel decision-making framework for sensor networks under communication constraints. Targeting multi-label classification problems, such as segmentation, CD-CRC dynamically adjusts local and global thresholds used to identify significant labels with the goal of ensuring a target false negative rate (FNR), while adhering to communication capacity limits. CD-CRC builds on online exponentiated gradient descent to estimate the relative quality of the observations of different sensors, and on online conformal risk control (CRC) as a mechanism to control local and global thresholds. CD-CRC is proved to offer deterministic worst-case performance guarantees in terms of FNR and communication overhead, while the regret performance in terms of false positive rate (FPR) is characterized as a function of the key hyperparameters. Simulation results highlight the effectiveness of CD-CRC, particularly in communication resource-constrained environments, making it a valuable tool for enhancing the performance and reliability of distributed sensor networks.

Paper number 136:
Title: ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs for Audio, Music, and Speech
Authors: Jiatong Shi, Jinchuan Tian, Yihan Wu, Jee-weon Jung, Jia Qi Yip, Yoshiki Masuyama, William Chen, Yuning Wu, Yuxun Tang, Massa Baali, Dareen Alharhi, Dong Zhang, Ruifan Deng, Tejes Srivastava, Haibin Wu, Alexander H. Liu, Bhiksha Raj, Qin Jin, Ruihua Song, Shinji Watanabe
Abstract: Neural codecs have become crucial to recent speech and audio generation research. In addition to signal compression capabilities, discrete codecs have also been found to enhance downstream training efficiency and compatibility with autoregressive language models. However, as extensive downstream applications are investigated, challenges have arisen in ensuring fair comparisons across diverse applications. To address these issues, we present a new open-source platform ESPnet-Codec, which is built on ESPnet and focuses on neural codec training and evaluation. ESPnet-Codec offers various recipes in audio, music, and speech for training and evaluation using several widely adopted codec models. Together with ESPnet-Codec, we present VERSA, a standalone evaluation toolkit, which provides a comprehensive evaluation of codec performance over 20 audio evaluation metrics. Notably, we demonstrate that ESPnet-Codec can be integrated into six ESPnet tasks, supporting diverse applications.

Paper number 137:
Title: TV-based Deep 3D Self Super-Resolution for fMRI
Authors: Fernando Pérez-Bueno, Hongwei Bran Li, Matthew S. Rosen, Shahin Nasr, Cesar Caballero-Gaudes, Juan Eugenio Iglesias
Abstract: While functional Magnetic Resonance Imaging (fMRI) offers valuable insights into cognitive processes, its inherent spatial limitations pose challenges for detailed analysis of the fine-grained functional architecture of the brain. More specifically, MRI scanner and sequence specifications impose a trade-off between temporal resolution, spatial resolution, signal-to-noise ratio, and scan time. Deep Learning (DL) Super-Resolution (SR) methods have emerged as a promising solution to enhance fMRI resolution, generating high-resolution (HR) images from low-resolution (LR) images typically acquired with lower scanning times. However, most existing SR approaches depend on supervised DL techniques, which require training ground truth (GT) HR data, which is often difficult to acquire and simultaneously sets a bound for how far SR can go. In this paper, we introduce a novel self-supervised DL SR model that combines a DL network with an analytical approach and Total Variation (TV) regularization. Our method eliminates the need for external GT images, achieving competitive performance compared to supervised DL techniques and preserving the functional maps.

Paper number 138:
Title: Improving the Estimation of Attenuation in Q/V Band Systems with a Kalman-Based Scintillation Filter
Authors: Justin Cano, Julien Queyrel, Laurent Castanet, Michel Bousquet
Abstract: This paper presents the design and implementation of the Scintillation Filter by Kalman-colored algorithm (SciFi), which is used to remove tropospheric scintillation from Q/V bands total attenuation data series. In contrast to the classical methods using low-pass filters, the SciFi algorithm allows to estimate both the attenuation, its slope and a confidence interval. Moreover, the linear observer structure of the Kalman filter allows it to operate in real time. Therefore, the states and uncertainties estimated by SciFi can be used as input for Fade Mitigation Techniques (FMT) such as Adaptive Coding and Modulation (ACM) or Site Diversity (SD). In this article, we propose a method to tune the noise level based on recommendations approved by the ITU-R. Finally, some results of filtering on Alphasat experimental data are discussed.

Paper number 139:
Title: Simultaneous Diarization and Separation of Meetings through the Integration of Statistical Mixture Models
Authors: Tobias Cord-Landwehr, Christoph Boeddeker, Reinhold Haeb-Umbach
Abstract: We propose an approach for simultaneous diarization and separation of meeting data. It consists of a complex Angular Central Gaussian Mixture Model (cACGMM) for speech source separation, and a von-Mises-Fisher Mixture Model (VMFMM) for diarization in a joint statistical framework. Through the integration, both spatial and spectral information are exploited for diarization and separation. We also develop a method for counting the number of active speakers in a segment of a meeting to support block-wise processing. While the total number of speakers in a meeting may be known, it is usually not known on a per-segment level. With the proposed speaker counting, joint diarization and source separation can be done segment-by-segment, and the permutation problem across segments is solved, thus allowing for block-online processing in the future. Experimental results on the LibriCSS meeting corpus show that the integrated approach outperforms a cascaded approach of diarization and speech enhancement in terms of WER, both on a per-segment and on a per-meeting level.

Paper number 140:
Title: CT-Mamba: A Hybrid Convolutional State Space Model for Low-Dose CT Denoising
Authors: Linxuan Li, Wenjia Wei, Luyao Yang, Wenwen Zhang, Jiashu Dong, Yahua Liu, Wei Zhao
Abstract: Low-dose CT (LDCT) significantly reduces the radiation dose received by patients, however, dose reduction introduces additional noise and artifacts. Currently, denoising methods based on convolutional neural networks (CNNs) face limitations in long-range modeling capabilities, while Transformer-based denoising methods, although capable of powerful long-range modeling, suffer from high computational complexity. Furthermore, the denoised images predicted by deep learning-based techniques inevitably exhibit differences in noise distribution compared to normal-dose CT (NDCT) images, which can also impact the final image quality and diagnostic outcomes. This paper proposes CT-Mamba, a hybrid convolutional State Space Model for LDCT image denoising. The model combines the local feature extraction advantages of CNNs with Mamba's strength in capturing long-range dependencies, enabling it to capture both local details and global context. Additionally, we introduce an innovative spatially coherent 'Z'-shaped scanning scheme to ensure spatial continuity between adjacent pixels in the image. We design a Mamba-driven deep noise power spectrum (NPS) loss function to guide model training, ensuring that the noise texture of the denoised LDCT images closely resembles that of NDCT images, thereby enhancing overall image quality and diagnostic value. Experimental results have demonstrated that CT-Mamba performs excellently in reducing noise in LDCT images, enhancing detail preservation, and optimizing noise texture distribution, and exhibits higher statistical similarity with the radiomics features of NDCT images. The proposed CT-Mamba demonstrates outstanding performance in LDCT denoising and holds promise as a representative approach for applying the Mamba framework to LDCT denoising tasks. Our code will be made available after the paper is officially published: this https URL.

Paper number 141:
Title: J-Invariant Volume Shuffle for Self-Supervised Cryo-Electron Tomogram Denoising on Single Noisy Volume
Authors: Xiwei Liu, Mohamad Kassab, Min Xu, Qirong Ho
Abstract: Cryo-Electron Tomography (Cryo-ET) enables detailed 3D visualization of cellular structures in near-native states but suffers from low signal-to-noise ratio due to imaging constraints. Traditional denoising methods and supervised learning approaches often struggle with complex noise patterns and the lack of paired datasets. Self-supervised methods, which utilize noisy input itself as a target, have been studied; however, existing Cryo-ET self-supervised denoising methods face significant challenges due to losing information during training and the learned incomplete noise patterns. In this paper, we propose a novel self-supervised learning model that denoises Cryo-ET volumetric images using a single noisy volume. Our method features a U-shape J-invariant blind spot network with sparse centrally masked convolutions, dilated channel attention blocks, and volume unshuffle/shuffle technique. The volume-unshuffle/shuffle technique expands receptive fields and utilizes multi-scale representations, significantly improving noise reduction and structural preservation. Experimental results demonstrate that our approach achieves superior performance compared to existing methods, advancing Cryo-ET data processing for structural biology research

Paper number 142:
Title: JPPO: Joint Power and Prompt Optimization for Accelerated Large Language Model Services
Authors: Feiran You, Hongyang Du, Kaibin Huang, Abbas Jamalipour
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, leading to their increasing deployment in wireless networks for a wide variety of user services. However, the growing longer prompt setting highlights the crucial issue of computational resource demands and huge communication load. To address this challenge, we propose Joint Power and Prompt Optimization (JPPO), a framework that combines Small Language Model (SLM)-based prompt compression with wireless power allocation optimization. By deploying SLM at user devices for prompt compression and employing Deep Reinforcement Learning for joint optimization of compression ratio and transmission power, JPPO effectively balances service quality with resource efficiency. Experimental results demonstrate that our framework achieves high service fidelity and low bit error rates while optimizing power usage in wireless LLM services. The system reduces response time by about 17%, with the improvement varying based on the length of the original prompt.

Paper number 143:
Title: CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding
Authors: Jiquan Wang, Sha Zhao, Zhiling Luo, Yangxuan Zhou, Haiteng Jiang, Shijian Li, Tao Li, Gang Pan
Abstract: Electroencephalography (EEG) is a non-invasive technique to measure and record brain electrical activity, widely used in various BCI and healthcare applications. Early EEG decoding methods rely on supervised learning, limited by specific tasks and datasets, hindering model performance and generalizability. With the success of large language models, there is a growing body of studies focusing on EEG foundation models. However, these studies still leave challenges: Firstly, most of existing EEG foundation models employ full EEG modeling strategy. It models the spatial and temporal dependencies between all EEG patches together, but ignores that the spatial and temporal dependencies are heterogeneous due to the unique structural characteristics of EEG signals. Secondly, existing EEG foundation models have limited generalizability on a wide range of downstream BCI tasks due to varying formats of EEG data, making it challenging to adapt to. To address these challenges, we propose a novel foundation model called CBraMod. Specifically, we devise a criss-cross transformer as the backbone to thoroughly leverage the structural characteristics of EEG signals, which can model spatial and temporal dependencies separately through two parallel attention mechanisms. And we utilize an asymmetric conditional positional encoding scheme which can encode positional information of EEG patches and be easily adapted to the EEG with diverse formats. CBraMod is pre-trained on a very large corpus of EEG through patch-based masked EEG reconstruction. We evaluate CBraMod on up to 10 downstream BCI tasks (12 public datasets). CBraMod achieves the state-of-the-art performance across the wide range of tasks, proving its strong capability and generalizability. The source code is publicly available at this https URL.

Paper number 144:
Title: Towards Wireless-Native Big AI Model: Insights into Its Ambitions, Peculiarities and Methodologies
Authors: Zirui Chen, Zhaoyang Zhang, Chenyu Liu, Ziqing Xing
Abstract: Researches on leveraging big artificial intelligence model (BAIM) technology to drive the intelligent evolution of wireless networks are emerging. However, since the breakthrough in generalization brought about by BAIM techniques mainly occurs in natural language processing, there is still a lack of a clear technical roadmap on how to efficiently apply BAIM techniques to wireless systems with many additional peculiarities. To this end, this paper first reviews recent research works on BAIM for wireless and assesses the current research situation. Then, this paper analyzes and compares the differences between language intelligence and wireless intelligence on multiple levels, including scientific foundations, core usages, and technical details. It highlights the necessity and scientific significance of developing BAIM technology in a wireless-native way, as well as new issues that need to be considered in specific technical implementation. Finally, by synthesizing the evolutionary laws of language models with the particularities of wireless system, this paper provides several instructive methodologies for how to develop wireless-native BAIM.

Paper number 145:
Title: Rethink Delay Doppler Channels and Time-Frequency Coding
Authors: Xiang-Gen Xia
Abstract: In this paper, we rethink delay Doppler channels (also called doubly selective channels). We prove that no modulation schemes (including the current active VOFDM/OTFS) can compensate a non-trivial Doppler spread well. We then discuss some of the existing methods to deal with time-varying channels, in particular time-frequency (TF) coding in an OFDM system. TF coding is equivalent to space-time coding in the math part. We also summarize state of the art on space-time coding that was an active research topic over a decade ago.

Paper number 146:
Title: Intelligent Reflecting Surfaces for Wireless Networks: Deployment Architectures, Key Solutions, and Field Trials
Authors: Qingqing Wu, Guangji Chen, Qiaoyan Peng, Wen Chen, Yifei Yuan, Zhenqiao Cheng, Jianwu Dou, Zhiyong Zhao, Ping Li
Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a transformative technology for wireless networks by improving coverage, capacity, and energy efficiency through intelligent manipulation of wireless propagation environments. This paper provides a comprehensive study on the deployment and coordination of IRSs for wireless networks. By addressing both single- and multi-reflection IRS architectures, we examine their deployment strategies across diverse scenarios, including point-to-point, point-to-multipoint, and point-to-area setups. For the single-reflection case, we highlight the trade-offs between passive and active IRS architectures in terms of beamforming gain, coverage extension, and spatial multiplexing. For the multi-reflection case, we discuss practical strategies to optimize IRS deployment and element allocation, balancing cooperative beamforming gains and path loss. The paper further discusses practical challenges in IRS implementation, including environmental conditions, system compatibility, and hardware limitations. Numerical results and field tests validate the effectiveness of IRS-aided wireless networks and demonstrate their capacity and coverage improvements. Lastly, promising research directions, including movable IRSs, near-field deployments, and network-level optimization, are outlined to guide future investigations.

Paper number 147:
Title: Continual Test-Time Adaptation for Single Image Defocus Deblurring via Causal Siamese Networks
Authors: Shuang Cui, Yi Li, Jiangmeng Li, Xiongxin Tang, Bing Su, Fanjiang Xu, Hui Xiong
Abstract: Single image defocus deblurring (SIDD) aims to restore an all-in-focus image from a defocused one. Distribution shifts in defocused images generally lead to performance degradation of existing methods during out-of-distribution inferences. In this work, we gauge the intrinsic reason behind the performance degradation, which is identified as the heterogeneity of lens-specific point spread functions. Empirical evidence supports this finding, motivating us to employ a continual test-time adaptation (CTTA) paradigm for SIDD. However, traditional CTTA methods, which primarily rely on entropy minimization, cannot sufficiently explore task-dependent information for pixel-level regression tasks like SIDD. To address this issue, we propose a novel Siamese networks-based continual test-time adaptation framework, which adapts source models to continuously changing target domains only requiring unlabeled target data in an online manner. To further mitigate semantically erroneous textures introduced by source SIDD models under severe degradation, we revisit the learning paradigm through a structural causal model and propose Causal Siamese networks (CauSiam). Our method leverages large-scale pre-trained vision-language models to derive discriminative universal semantic priors and integrates these priors into Siamese networks, ensuring causal identifiability between blurry inputs and restored images. Extensive experiments demonstrate that CauSiam effectively improves the generalization performance of existing SIDD methods in continuously changing domains.

Paper number 148:
Title: FetDTIAlign: A Deep Learning Framework for Affine and Deformable Registration of Fetal Brain dMRI
Authors: Bo Li, Qi Zeng, Simon K. Warfield, Davood Karimi
Abstract: Diffusion MRI (dMRI) provides unique insights into fetal brain microstructure in utero. Longitudinal and cross-sectional fetal dMRI studies can reveal crucial neurodevelopmental changes but require precise spatial alignment across scans and subjects. This is challenging due to low data quality, rapid brain development, and limited anatomical landmarks. Existing registration methods, designed for high-quality adult data, struggle with these complexities. To address this, we introduce FetDTIAlign, a deep learning approach for fetal brain dMRI registration, enabling accurate affine and deformable alignment. FetDTIAlign features a dual-encoder architecture and iterative feature-based inference, reducing the impact of noise and low resolution. It optimizes network configurations and domain-specific features at each registration stage, enhancing both robustness and accuracy. We validated FetDTIAlign on data from 23 to 36 weeks gestation, covering 60 white matter tracts. It consistently outperformed two classical optimization-based methods and a deep learning pipeline, achieving superior anatomical correspondence. Further validation on external data from the Developing Human Connectome Project confirmed its generalizability across acquisition protocols. Our results demonstrate the feasibility of deep learning for fetal brain dMRI registration, providing a more accurate and reliable alternative to classical techniques. By enabling precise cross-subject and tract-specific analyses, FetDTIAlign supports new discoveries in early brain development.

Paper number 149:
Title: Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis
Authors: Zhen Ye, Xinfa Zhu, Chi-Min Chan, Xinsheng Wang, Xu Tan, Jiahe Lei, Yi Peng, Haohe Liu, Yizhu Jin, Zheqi Dai, Hongzhan Lin, Jianyi Chen, Xingjian Du, Liumeng Xue, Yunlin Chen, Zhifei Li, Lei Xie, Qiuqiang Kong, Yike Guo, Wei Xue
Abstract: Recent advances in text-based large language models (LLMs), particularly in the GPT series and the o1 model, have demonstrated the effectiveness of scaling both training-time and inference-time compute. However, current state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring separate models (e.g., diffusion models after LLM), complicating the decision of whether to scale a particular model during training or testing. This work makes the following contributions: First, we explore the scaling of train-time and inference-time compute for speech synthesis. Second, we propose a simple framework Llasa for speech synthesis that employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully align with standard LLMs such as Llama. Our experiments reveal that scaling train-time compute for Llasa consistently improves the naturalness of synthesized speech and enables the generation of more complex and accurate prosody patterns. Furthermore, from the perspective of scaling inference-time compute, we employ speech understanding models as verifiers during the search, finding that scaling inference-time compute shifts the sampling modes toward the preferences of specific verifiers, thereby improving emotional expressiveness, timbre consistency, and content accuracy. In addition, we released the checkpoint and training code for our TTS model (1B, 3B, 8B) and codec model publicly available.

Paper number 150:
Title: VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification
Authors: Pengyu Wang, Ying Fang, Xiaofei Li
Abstract: Reverberant speech, denoting the speech signal degraded by the process of reverberation, contains crucial knowledge of both anechoic source speech and room impulse response (RIR). This work proposes a variational Bayesian inference (VBI) framework with neural speech prior (VINP) for joint speech dereverberation and blind RIR identification. In VINP, a probabilistic signal model is constructed in the time-frequency (T-F) domain based on convolution transfer function (CTF) approximation. For the first time, we propose using an arbitrary discriminative dereverberation deep neural network (DNN) to predict the prior distribution of anechoic speech within a probabilistic model. By integrating both reverberant speech and the anechoic speech prior, VINP yields the maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the anechoic speech spectrum and CTF filter, respectively. After simple transformations, the waveforms of anechoic speech and RIR are estimated. Moreover, VINP is effective for automatic speech recognition (ASR) systems, which sets it apart from most deep learning (DL)-based single-channel dereverberation approaches. Experiments on single-channel speech dereverberation demonstrate that VINP reaches an advanced level in most metrics related to human perception and displays unquestionable state-of-the-art (SOTA) performance in ASR-related metrics. For blind RIR identification, experiments indicate that VINP attains the SOTA level in blind estimation of reverberation time at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio samples are available online.

Paper number 151:
Title: PainDECOG: Machine Learning-Based Identification of Pain Biomarkers from sEEG Signals
Authors: Sidharth Sidharth, Vishwas Sathish, Shweta Bansal, Samantha Sun, Timmy Pham, Kurt Weaver, Rajesh P. N. Rao, Jeffrey Herron
Abstract: This study presents a systematic machine-learning approach for classifying acute pain from raw electrophysiological signals. We address binary and ternary classification tasks, leveraging Power-In-Band (PIB) and signal coherence as distinguishing features. Our method evaluates the effectiveness of traditional machine learning algorithms on a manually curated electrophysiological dataset obtained from intracranial electroencephalography (iEEG), offering valuable insights into model performance for pain detection. Furthermore, we identify critical electrode pairings associated with acute pain, providing a clearer understanding of the neural markers that differentiate pain states. This work highlights the potential of targeted feature engineering in advancing pain classification, setting the stage for future enhancements in real-time and personalized pain assessment tools. Additionally, these findings have promising applications in neuromodulation and Deep Brain Stimulation (DBS), where adaptive and closed-loop systems could leverage identified pain markers to modulate pain-related brain regions more precisely, offering improved therapeutic options for chronic pain management

Paper number 152:
Title: Benchmarking Self-Supervised Methods for Accelerated MRI Reconstruction
Authors: Andrew Wang, Mike Davies
Abstract: Reconstructing MRI from highly undersampled measurements is crucial for accelerating medical imaging, but is challenging due to the ill-posedness of the inverse problem. While supervised deep learning approaches have shown remarkable success, they rely on fully-sampled ground truth data, which is often impractical or impossible to obtain. Recently, numerous self-supervised methods have emerged that do not require ground truth, however, the lack of systematic comparison and standard experimental setups have hindered research. We present the first comprehensive review of loss functions from all feedforward self-supervised methods and the first benchmark on accelerated MRI reconstruction without ground truth, showing that there is a wide range in performance across methods. In addition, we propose Multi-Operator Equivariant Imaging (MO-EI), a novel framework that builds on the imaging model considered in existing methods to outperform all state-of-the-art and approaches supervised performance. Finally, to facilitate reproducible benchmarking, we provide implementations of all methods in the DeepInverse library (this https URL) and easy-to-use demo code at this https URL.

Paper number 153:
Title: Near-Field Motion Parameter Estimation: A Variational Bayesian Approach
Authors: Chunwei Meng, Zhaolin Wang, Zhiqing Wei, Yuanwei Liu, Zhiyong Feng
Abstract: A near-field motion parameter estimation method is proposed. In contract to far-field sensing systems, the near-field sensing system leverages spherical-wave characteristics to enable full-vector location and velocity estimation. Despite promising advantages, the near-field sensing system faces a significant challenge, where location and velocity parameters are intricately coupled within the signal. To address this challenge, a novel subarray-based variational message passing (VMP) method is proposed for near-field joint location and velocity estimation. First, a factor graph representation is introduced, employing subarray-level directional and Doppler parameters as intermediate variables to decouple the complex location-velocity dependencies. Based on this, the variational Bayesian inference is employed to obtain closed-form posterior distributions of subarray-level parameters. Subsequently, the message passing technique is employed, enabling tractable computation of location and velocity marginal distributions. Two implementation strategies are proposed: 1) System-level fusion that aggregates all subarray posteriors for centralized estimation, or 2) Subarray-level fusion where locally processed estimates from subarrays are fused through Guassian product rule. Cramér-Rao bounds for location and velocity estimation are derived, providing theoretical performance limits. Numerical results demonstrate that the proposed VMP method outperforms existing approaches while achieving a magnitude lower complexity. Specifically, the proposed VMP method achieves centimeter-level location accuracy and sub-m/s velocity accuracy. It also demonstrates robust performance for high-mobility targets, making the proposed VMP method suitable for real-time near-field sensing and communication applications.

Paper number 154:
Title: Non-Linear Analog Processing in MIMO Systems with Coarse Quantization
Authors: Marian Temprana Alonso, Xuyang Liu, Hamidreza Aghasi, Farhad Shirani
Abstract: Analog to digital converters (ADCs) are a major contributor to the power consumption of multiple-input multiple-output (MIMO) receivers in large bandwidth millimeter-wave systems. Prior works have considered two mitigating solutions to reduce the ADC power consumption: i) decreasing the number of ADCs via analog and hybrid beamforming, and ii) decreasing the ADC resolution, i.e., utilizing one-bit and few-bit ADCs. These mitigating solutions lead to performance loss in terms of achievable rates due to increased quantization error. In this work, the use of nonlinear analog operators such as envelope detectors and polynomial operators, prior to sampling and quantization is considered, as a way to reduce the aforementioned rate-loss. The receiver architecture consists of linear combiners, nonlinear analog operators, and few-bit ADCs. The fundamental performance limits of the resulting communication system, in terms of achievable rates, are investigated under various assumptions on the set of implementable analog operators. Extensive numerical evaluations are provided to evaluate the set of achievable rates and the power consumption of the proposed receiver architectures. Circuit simulations and measurement results, based on both 22 nm FDSOI CMOS technology and 65 nm Bulk CMOS transistor technologies, are provided to justify the power efficiency of the proposed receiver architectures.

Paper number 155:
Title: Finite element hybridization of port-Hamiltonian systems
Authors: Andrea Brugnoli, Ramy Rashad, Yi Zhang, Stefano Stramigioli
Abstract: In this contribution, we extend the hybridization framework for the Hodge Laplacian [Awanou et al., Hybridization and postprocessing in finite element exterior calculus, 2023] to port-Hamiltonian systems describing linear wave propagation phenomena. To this aim, a dual field mixed Galerkin discretization is introduced, in which one variable is approximated via conforming finite element spaces, whereas the second is completely local. This scheme is equivalent to the second order mixed Galerkin formulation and retains a discrete power balance and discrete conservation laws. The mixed formulation is also equivalent to the hybrid formulation. The hybrid system can be efficiently solved using a static condensation procedure in discrete time. The size reduction achieved thanks to the hybridization is greater than the one obtained for the Hodge Laplacian as one field is completely discarded. Numerical experiments on the 3D wave and Maxwell equations show the convergence of the method and the size reduction achieved by the hybridization.

Paper number 156:
Title: ML-SUPERB: Multilingual Speech Universal PERformance Benchmark
Authors: Jiatong Shi, Dan Berrebbi, William Chen, Ho-Lam Chung, En-Pei Hu, Wei Ping Huang, Xuankai Chang, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Shinji Watanabe
Abstract: Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.

Paper number 157:
Title: BG-GAN: Generative AI Enable Representing Brain Structure-Function Connections for Alzheimer's Disease
Authors: Tong Zhou, Chen Ding, Changhong Jing, Feng Liu, Kevin Hung, Hieu Pham, Mufti Mahmud, Zhihan Lyu, Sibo Qiao, Shuqiang Wang, Kim-Fung Tsang
Abstract: The relationship between brain structure and function is critical for revealing the pathogenesis of brain disorders, including Alzheimer's disease (AD). However, mapping brain structure to function connections is a very challenging task. In this work, a bidirectional graph generative adversarial network (BG-GAN) is proposed to represent brain structure-function connections. Specifically, by designing a module incorporating inner graph convolution network (InnerGCN), the generators of BG-GAN can employ features of direct and indirect brain regions to learn the mapping function between the structural domain and the functional domain. Besides, a new module named Balancer is designed to counterpoise the optimization between generators and discriminators. By introducing the Balancer into BG-GAN, both the structural generator and functional generator can not only alleviate the issue of mode collapse but also learn complementarity of structural and functional features. Experimental results using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset show that both generated structure and function connections can improve the identification accuracy of AD. The experimental findings suggest that the relationship between brain structure and function is not a complete one-to-one correspondence. They also suggest that brain structure is the basis of brain function, and the strong structural connections are majorly accompanied by strong functional connections.

Paper number 158:
Title: Findings of the 2023 ML-SUPERB Challenge: Pre-Training and Evaluation over More Languages and Beyond
Authors: Jiatong Shi, William Chen, Dan Berrebbi, Hsiu-Hsuan Wang, Wei-Ping Huang, En-Pei Hu, Ho-Lam Chuang, Xuankai Chang, Yuxun Tang, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Shinji Watanabe
Abstract: The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification. The challenge comprises a research track focused on applying ML-SUPERB to specific multilingual subjects, a Challenge Track for model submissions, and a New Language Track where language resource researchers can contribute and evaluate their low-resource language data in the context of the latest progress in multilingual speech recognition. The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.

Paper number 159:
Title: Integrated lithium niobate photonic millimeter-wave radar
Authors: Sha Zhu, Yiwen Zhang, Jiaxue Feng, Yongji Wang, Kunpeng Zhai, Hanke Feng, Edwin Yue Bun Pun, Ning Hua Zhu, Cheng Wang
Abstract: Millimeter-wave (mmWave,>30 GHz) radars are the key enabler in the coming 6G era for high-resolution sensing and detection of targets. Photonic radar provides an effective approach to overcome the limitations of electronic radars thanks to the high frequency, broad bandwidth, and excellent reconfigurability of photonic systems. However, conventional photonic radars are mostly realized in tabletop systems composed of bulky discrete components, whereas the more compact integrated photonic radars are difficult to reach the mmWave bands due to the unsatisfactory bandwidths and signal integrity of the underlining electro-optic modulators. Here, we overcome these challenges and demonstrate a centimeter-resolution integrated photonic radar operating in the mmWave V band (40-50 GHz) based on a 4-inch wafer-scale thin-film lithium niobate (TFLN) technology. The fabricated TFLN mmWave photonic integrated circuit consists of a first electro-optic modulator capable of generating a broadband linear frequency modulated mmWave radar waveform through optical frequency multiplication of a low-frequency input signal, and a second electro-optic modulator responsible for frequency de-chirp of the received reflected echo wave, therefore greatly relieving the bandwidth requirements for the analog-to-digital converter in the receiver. Thanks to the absence of optical and electrical filters in the system, our integrated photonic mmWave radar features continuous on-demand tunability of the center frequency and bandwidth, currently only limited by the bandwidths of electrical amplifiers. We achieve multi-target ranging with a resolution of 1.50 cm and velocity measurement with a resolution of 0.067 m/s. Furthermore, we construct an inverse synthetic aperture radar (ISAR) and successfully demonstrate the imaging of targets with various shapes and postures with a two-dimensional resolution of 1.50 cm * 1.06 cm.

Paper number 160:
Title: LQG Information Design
Authors: Masaki Miyashita, Takashi Ui
Abstract: This paper addresses information design in a workhorse model of network games, where agents have linear best responses, the information designer optimizes a quadratic objective, and the payoff state follows a multivariate Gaussian distribution. We formulate the problem as semidefinite programming (SDP) and utilize the duality principle to characterize an optimal information structure. A Gaussian information structure is shown to be optimal among all information structures. A necessary and sufficient condition for optimality is that the induced equilibrium strategy profile and the state jointly satisfy a linear constraint derived from complementary slackness conditions. Consequently, the true state is typically revealed to the entire population of agents, even though individual agents remain only partially informed. In symmetric network games, an optimal information structure inherits the same degree of symmetry, which facilitates its computation.

Paper number 161:
Title: $\mathsf{QuITO}$ $\textsf{v.2}$: Trajectory Optimization with Uniform Error Guarantees under Path Constraints
Authors: Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a direct multiple shooting technique -- $\mathsf{QuITO}$ $\textsf{v.2}$ (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties, along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce, and make freely available, a new software package based on $\mathsf{QuITO}$ $\textsf{v.2}$ along with all its functionalities for completeness. The package is available at: this https URL.

Paper number 162:
Title: Deep Reinforcement Learning for Advanced Longitudinal Control and Collision Avoidance in High-Risk Driving Scenarios
Authors: Dianwei Chen, Yaobang Gong, Xianfeng Yang
Abstract: Existing Advanced Driver Assistance Systems primarily focus on the vehicle directly ahead, often overlooking potential risks from following vehicles. This oversight can lead to ineffective handling of high risk situations, such as high speed, closely spaced, multi vehicle scenarios where emergency braking by one vehicle might trigger a pile up collision. To overcome these limitations, this study introduces a novel deep reinforcement learning based algorithm for longitudinal control and collision avoidance. This proposed algorithm effectively considers the behavior of both leading and following vehicles. Its implementation in simulated high risk scenarios, which involve emergency braking in dense traffic where traditional systems typically fail, has demonstrated the algorithm ability to prevent potential pile up collisions, including those involving heavy duty vehicles.

Paper number 163:
Title: Enhanced Geological Prediction for Tunnel Excavation Using Full Waveform Inversion Integrating Sobolev Space Regularization with a Quadratic Penalty Method
Authors: Jiahang Li, Junichi Takekawa, Keisuke Kurihara, Karnallisa Desmy Halim, Kazuhiko Masumoto, Yasuyuki Miyajima
Abstract: In the process of tunnel excavation, advanced geological prediction technology has become indispensable for safe, economical, and efficient tunnel construction. Although traditional methods such as drilling and geological analysis are effective, they typically involve destructive processes, carry high risks, and incur significant costs. In contrast, non-destructive geophysical exploration offers a more convenient and economical alternative. However, the accuracy and precision of these non-destructive methods can be severely compromised by complex geological structures, restrictions on observation coverage and environmental noise. To address these challenges effectively, a novel approach using frequency domain full waveform inversion, based on a penalty method and Sobolev space regularization, has been proposed to enhance the performance of non-destructive predictions. The proposed method constructs a soft-constrained optimization problem by restructuring the misfit function into a combination of data misfit and wave equation drive terms to enhance convexity. Additionally, it semi-extends the search space to both the wavefield and the model parameters to mitigate the strong nonlinearity of the optimization, facilitating high-resolution inversion. Furthermore, a Sobolev space regularization algorithm is introduced to flexibly adjust the regularization path, addressing issues related to noise and artefacts to enhance the robustness of the algorithm. We evaluated the performance of the proposed full waveform inversion using several tunnel models with fault structures by comparing the results of the enhanced method with those of traditional least-squares-based Tikhonov regularization and total variation regularization full waveform inversion methods. The verification results confirm the superior capabilities of the proposed method as expected.

Paper number 164:
Title: Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates
Authors: Thom Badings, Wietze Koops, Sebastian Junges, Nils Jansen
Abstract: We consider the verification of neural network policies for discrete-time stochastic systems with respect to reach-avoid specifications. We use a learner-verifier procedure that learns a certificate for the specification, represented as a neural network. Verifying that this neural network certificate is a so-called reach-avoid supermartingale (RASM) proves the satisfaction of a reach-avoid specification. Existing approaches for such a verification task rely on computed Lipschitz constants of neural networks. These approaches struggle with large Lipschitz constants, especially for reach-avoid specifications with high threshold probabilities. We present two key contributions to obtain smaller Lipschitz constants than existing approaches. First, we introduce logarithmic RASMs (logRASMs), which take exponentially smaller values than RASMs and hence have lower theoretical Lipschitz constants. Second, we present a fast method to compute tighter upper bounds on Lipschitz constants based on weighted norms. Our empirical evaluation shows we can consistently verify the satisfaction of reach-avoid specifications with probabilities as high as 99.9999%.

Paper number 165:
Title: No-Reference Image Quality Assessment with Global-Local Progressive Integration and Semantic-Aligned Quality Transfer
Authors: Xiaoqi Wang, Yun Zhang
Abstract: Accurate measurement of image quality without reference signals remains a fundamental challenge in low-level visual perception applications. In this paper, we propose a global-local progressive integration model that addresses this challenge through three key contributions: 1) We develop a dual-measurement framework that combines vision Transformer (ViT)-based global feature extractor and convolutional neural networks (CNNs)-based local feature extractor to comprehensively capture and quantify image distortion characteristics at different granularities. 2) We propose a progressive feature integration scheme that utilizes multi-scale kernel configurations to align global and local features, and progressively aggregates them via an interactive stack of channel-wise self-attention and spatial interaction modules for multi-grained quality-aware representations. 3) We introduce a semantic-aligned quality transfer method that extends the training data by automatically labeling the quality scores of diverse image content with subjective opinion scores. Experimental results demonstrate that our model yields 5.04% and 5.40% improvements in Spearman's rank-order correlation coefficient (SROCC) for cross-authentic and cross-synthetic dataset generalization tests, respectively. Furthermore, the proposed semantic-aligned quality transfer further yields 2.26% and 13.23% performance gains in evaluations on single-synthetic and cross-synthetic datasets.

Paper number 166:
Title: On Stability in Optimistic Bilevel Optimization
Authors: Johannes O. Royset
Abstract: Solutions of bilevel optimization problems tend to suffer from instability under changes to problem data. In the optimistic setting, we construct a lifted formulation that exhibits desirable stability properties under mild assumptions that neither invoke convexity nor smoothness. The upper- and lower-level problems might involve integer restrictions and disjunctive constraints. In a range of results, we invoke at most pointwise and local calmness for the lower-level problem in a sense that holds broadly. The lifted formulation is computationally attractive with structural properties being brought out and an outer approximation algorithm becoming available.

Paper number 167:
Title: Efficient Multi-agent Navigation with Lightweight DRL Policy
Authors: Xingrong Diao, Jiankun Wang
Abstract: In this article, we present an end-to-end collision avoidance policy based on deep reinforcement learning (DRL) for multi-agent systems, demonstrating encouraging outcomes in real-world applications. In particular, our policy calculates the control commands of the agent based on the raw LiDAR observation. In addition, the number of parameters of the proposed basic model is 140,000, and the size of the parameter file is 3.5 MB, which allows the robot to calculate the actions from the CPU alone. We propose a multi-agent training platform based on a physics-based simulator to further bridge the gap between simulation and the real world. The policy is trained on a policy-gradients-based RL algorithm in a dense and messy training environment. A novel reward function is introduced to address the issue of agents choosing suboptimal actions in some common scenarios. Although the data used for training is exclusively from the simulation platform, the policy can be successfully transferred and deployed in real-world robots. Finally, our policy effectively responds to intentional obstructions and avoids collisions. The website is available at this https URL.

Paper number 168:
Title: HoloTile RGB: Ultra-fast single-shot, discretized, full-color computer-generated phase-only holography
Authors: Andreas Erik Gejl Madsen, Jesper Glückstad
Abstract: We demonstrate the first use of the HoloTile Computer-Generated Holography (CGH) modality on multi-wavelength targets. Taking advantage of the sub-hologram tiling and Point Spread Function (PSF) shaping of HoloTile allows for reconstruction of high-fidelity, pseudo-digital multi-wavelength images, with well-defined discrete output pixels, without the need for temporal averaging. For each wavelength, the target channels are scaled appropriately, using the same output pixel size. We employ a stochastic gradient descent (SGD) hologram generation algorithm for each wavelength, and display them sequentially on a HoloEye GAEA 2.1 Spatial Light Modulator (SLM) in Color Field Sequential (CFS) phase modulation mode. As such, we get full 8-bit phase modulation at 60 Hz for each wavelength. The reconstructions are projected onto a camera sensor where each RGB image is captured in a single shot. While these show impressive color reconstructions, the method can be adapted to any wavelength combination for use in a plethora of multi-wavelength application.

Paper number 169:
Title: GEFM: Graph-Enhanced EEG Foundation Model
Authors: Limin Wang, Toyotaro Suzumura, Hiroki Kanezashi
Abstract: Electroencephalography (EEG) signals provide critical insights for applications in disease diagnosis and healthcare. However, the scarcity of labeled EEG data poses a significant challenge. Foundation models offer a promising solution by leveraging large-scale unlabeled data through pre-training, enabling strong performance across diverse tasks. While both temporal dynamics and inter-channel relationships are vital for understanding EEG signals, existing EEG foundation models primarily focus on the former, overlooking the latter. To address this limitation, we propose Graph-Enhanced EEG Foundation Model (GEFM), a novel foundation model for EEG that integrates both temporal and inter-channel information. Our architecture combines Graph Neural Networks (GNNs), which effectively capture relational structures, with a masked autoencoder to enable efficient pre-training. We evaluated our approach using three downstream tasks and experimented with various GNN architectures. The results demonstrate that our proposed model, particularly when employing the GCN architecture with optimized configurations, consistently outperformed baseline methods across all tasks. These findings suggest that our model serves as a robust foundation model for EEG analysis.

Paper number 170:
Title: Zero-shot Musical Stem Retrieval with Joint-Embedding Predictive Architectures
Authors: Alain Riou, Antonin Gagneré, Gaëtan Hadjeres, Stefan Lattner, Geoffroy Peeters
Abstract: In this paper, we tackle the task of musical stem retrieval. Given a musical mix, it consists in retrieving a stem that would fit with it, i.e., that would sound pleasant if played together. To do so, we introduce a new method based on Joint-Embedding Predictive Architectures, where an encoder and a predictor are jointly trained to produce latent representations of a context and predict latent representations of a target. In particular, we design our predictor to be conditioned on arbitrary instruments, enabling our model to perform zero-shot stem retrieval. In addition, we discover that pretraining the encoder using contrastive learning drastically improves the model's performance. We validate the retrieval performances of our model using the MUSDB18 and MoisesDB datasets. We show that it significantly outperforms previous baselines on both datasets, showcasing its ability to support more or less precise (and possibly unseen) conditioning. We also evaluate the learned embeddings on a beat tracking task, demonstrating that they retain temporal structure and local information.

Paper number 171:
Title: Machine-Learning Enabled Multidimensional Data Utilization Through Multi-Resonance Architecture: A Pathway to Enhanced Accuracy in Biosensing
Authors: Majid Aalizadeh, Morteza Azmoudeh Afshar, Xudong Fan
Abstract: A novel framework is proposed that combines multi-resonance biosensors with machine learning (ML) to significantly enhance the accuracy of parameter prediction in biosensing. Unlike traditional single-resonance systems, which are limited to one-dimensional datasets, this approach leverages multi-dimensional data generated by a custom-designed nanostructure, a periodic array of silicon nanorods with a triangular cross-section over an aluminum reflector. High bulk sensitivity values are achieved for this multi-resonant structure, with certain resonant peaks reaching up to 1706 nm/RIU. The field analysis reveals Mie resonances as the physical reason behind the peaks. The predictive power of multiple resonant peaks from transverse magnetic (TM) and transverse electric (TE) polarizations is evaluated using Ridge Regression modeling. Systematic analysis reveals that incorporating multiple resonances yields up to three orders of magnitude improvement in refractive index detection precision compared to single-peak analyses. This precision enhancement is achieved without modifications to the biosensor hardware, highlighting the potential of data-centric strategies in biosensing. The findings establish a new paradigm in biosensing, demonstrating that the synergy between multi-resonance data acquisition and ML-based analysis can significantly enhance detection accuracy. This study provides a scalable pathway for advancing high-precision biosensing technologies.

Paper number 172:
Title: Algebraic Control: Complete Stable Inversion with Necessary and Sufficient Conditions
Authors: Burak Kürkçü, Masayoshi Tomizuka
Abstract: Recent advances in learning-based control have increased interest in stable inversion to meet growing performance demands. Here, we establish necessary and sufficient conditions for stable inversion, addressing challenges in non-minimum phase, non-square, and singular systems. An H-Infinity based algebraic approximation is introduced for near-perfect tracking without preview. Additionally, we propose a novel robust control strategy combining the nominal model with dual feedforward control to form a feedback structure. Numerical comparison demonstrates the approach's effectiveness.

Paper number 173:
Title: Ambient Denoising Diffusion Generative Adversarial Networks for Establishing Stochastic Object Models from Noisy Image Data
Authors: Xichen Xu, Wentao Chen, Weimin Zhou
Abstract: It is widely accepted that medical imaging systems should be objectively assessed via task-based image quality (IQ) measures that ideally account for all sources of randomness in the measured image data, including the variation in the ensemble of objects to be imaged. Stochastic object models (SOMs) that can randomly draw samples from the object distribution can be employed to characterize object variability. To establish realistic SOMs for task-based IQ analysis, it is desirable to employ experimental image data. However, experimental image data acquired from medical imaging systems are subject to measurement noise. Previous work investigated the ability of deep generative models (DGMs) that employ an augmented generative adversarial network (GAN), AmbientGAN, for establishing SOMs from noisy measured image data. Recently, denoising diffusion models (DDMs) have emerged as a leading DGM for image synthesis and can produce superior image quality than GANs. However, original DDMs possess a slow image-generation process because of the Gaussian assumption in the denoising steps. More recently, denoising diffusion GAN (DDGAN) was proposed to permit fast image generation while maintain high generated image quality that is comparable to the original DDMs. In this work, we propose an augmented DDGAN architecture, Ambient DDGAN (ADDGAN), for learning SOMs from noisy image data. Numerical studies that consider clinical computed tomography (CT) images and digital breast tomosynthesis (DBT) images are conducted. The ability of the proposed ADDGAN to learn realistic SOMs from noisy image data is demonstrated. It has been shown that the ADDGAN significantly outperforms the advanced AmbientGAN models for synthesizing high resolution medical images with complex textures.

Paper number 174:
Title: Dense Fixed-Wing Swarming using Receding-Horizon NMPC
Authors: Varun Madabushi, Yocheved Kopel, Adam Polevoy, Joseph Moore
Abstract: In this paper, we present an approach for controlling a team of agile fixed-wing aerial vehicles in close proximity to one another. Our approach relies on receding-horizon nonlinear model predictive control (NMPC) to plan maneuvers across an expanded flight envelope to enable inter-agent collision avoidance. To facilitate robust collision avoidance and characterize the likelihood of inter-agent collisions, we compute a statistical bound on the probability of the system leaving a tube around the planned nominal trajectory. Finally, we propose a metric for evaluating highly dynamic swarms and use this metric to evaluate our approach. We successfully demonstrated our approach through both simulation and hardware experiments, and to our knowledge, this the first time close-quarters swarming has been achieved with physical aerobatic fixed-wing vehicles.

Paper number 175:
Title: Learning-Based Design of LQG Controllers in Quantum Coherent Feedback
Authors: Chunxiang Song, Yanan Liu, Guofeng Zhang, Huadong Mo, Daoyi Dong
Abstract: In this paper, we propose a differential evolution (DE) algorithm specifically tailored for the design of Linear-Quadratic-Gaussian (LQG) controllers in quantum systems. Building upon the foundational DE framework, the algorithm incorporates specialized modules, including relaxed feasibility rules, a scheduled penalty function, adaptive search range adjustment, and the ``bet-and-run'' initialization strategy. These enhancements improve the algorithm's exploration and exploitation capabilities while addressing the unique physical realizability requirements of quantum systems. The proposed method is applied to a quantum optical system, where three distinct controllers with varying configurations relative to the plant are designed. The resulting controllers demonstrate superior performance, achieving lower LQG performance indices compared to existing approaches. Additionally, the algorithm ensures that the designs comply with physical realizability constraints, guaranteeing compatibility with practical quantum platforms. The proposed approach holds significant potential for application to other linear quantum systems in performance optimization tasks subject to physically feasible constraints.

Paper number 176:
Title: Dynamic Rolling Horizon Optimization for Network-Constrained V2X Value Stacking of Electric Vehicles Under Uncertainties
Authors: Canchen Jiang, Ariel Liebman, Bo Jie, Hao Wang
Abstract: Electric vehicle (EV) coordination can provide significant benefits through vehicle-to-everything (V2X) by interacting with the grid, buildings, and other EVs. This work aims to develop a V2X value-stacking framework, including vehicle-to-building (V2B), vehicle-to-grid (V2G), and energy trading, to maximize economic benefits for residential communities while maintaining distribution voltage. This work also seeks to quantify the impact of prediction errors related to building load, renewable energy, and EV arrivals. A dynamic rolling-horizon optimization (RHO) method is employed to leverage multiple revenue streams and maximize the potential of EV coordination. To address energy uncertainties, including hourly local building load, local photovoltaic (PV) generation, and EV arrivals, this work develops a Transformer-based forecasting model named Gated Recurrent Units-Encoder-Temporal Fusion Decoder (GRU-EN-TFD). The simulation results, using real data from Australia's National Electricity Market, and the Independent System Operators in New England and New York in the US, reveal that V2X value stacking can significantly reduce energy costs. The proposed GRU-EN-TFD model outperforms the benchmark forecast model. Uncertainties in EV arrivals have a more substantial impact on value-stacking performance, highlighting the significance of its accurate forecast. This work provides new insights into the dynamic interactions among residential communities, unlocking the full potential of EV batteries.

Paper number 177:
Title: A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems
Authors: Manan Tayal, Aditya Singh, Shishir Kolathaya, Somil Bansal
Abstract: As autonomous systems become more ubiquitous in daily life, ensuring high performance with guaranteed safety is crucial. However, safety and performance could be competing objectives, which makes their co-optimization difficult. Learning-based methods, such as Constrained Reinforcement Learning (CRL), achieve strong performance but lack formal safety guarantees due to safety being enforced as soft constraints, limiting their use in safety-critical settings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability Analysis and Control Barrier Functions (CBFs) provide rigorous safety assurances but often neglect performance, resulting in overly conservative controllers. To bridge this gap, we formulate the co-optimization of safety and performance as a state-constrained optimal control problem, where performance objectives are encoded via a cost function and safety requirements are imposed as state constraints. We demonstrate that the resultant value function satisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate efficiently using a novel physics-informed machine learning framework. In addition, we introduce a conformal prediction-based verification strategy to quantify the learning errors, recovering a high-confidence safety value function, along with a probabilistic error bound on performance degradation. Through several case studies, we demonstrate the efficacy of the proposed framework in enabling scalable learning of safe and performant controllers for complex, high-dimensional autonomous systems.

Paper number 178:
Title: A Supervised Machine-Learning Approach For Turboshaft Engine Dynamic Modeling Under Real Flight Conditions
Authors: Damiano Paniccia, Francesco Aldo Tucci, Joel Guerrero, Luigi Capone, Nicoletta Sanguini, Tommaso Benacchio, Luigi Bottasso
Abstract: Rotorcraft engines are highly complex, nonlinear thermodynamic systems that operate under varying environmental and flight conditions. Simulating their dynamics is crucial for design, fault diagnostics, and deterioration control phases, and requires robust and reliable control systems to estimate engine performance throughout flight envelope. However, the development of detailed physical models of the engine based on numerical simulations is a very challenging task due to the complex and entangled physics driving the engine. In this scenario, data-driven machine-learning techniques are of great interest to the aircraft engine community, due to their ability to describe nonlinear systems' dynamic behavior and enable online performance estimation, achieving excellent results with accuracy competitive with the state of the art. In this work, we explore different Neural Network architectures to model the turboshaft engine of Leonardo's AW189P4 prototype, aiming to predict the engine torque. The models are trained on an extensive database of real flight tests featuring a variety of operational maneuvers performed under different flight conditions, providing a comprehensive representation of the engine's performance. To complement the neural network approach, we apply Sparse Identification of Nonlinear Dynamics (SINDy) to derive a low-dimensional dynamical model from the available data, describing the relationship between fuel flow and engine torque. The resulting model showcases SINDy's capability to recover the actual physics underlying the engine dynamics and demonstrates its potential for investigating more complex aspects of the engine. The results prove that data-driven engine models can exploit a wider range of parameters than standard transfer function-based approaches, enabling the use of trained schemes to simulate nonlinear effects in different engines and helicopters.

Paper number 179:
Title: ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors
Authors: Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou
Abstract: Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. We theoretically analyze the inconsistency in terms of both multilingual modal alignment direction error and weight error, and propose the theoretical weight error upper bound for quantifying the inconsistency. Based on the analysis of the weight error upper bound, we find that the inconsistency problem stems from the data distribution error caused by random sampling of languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at this https URL.

Paper number 180:
Title: Online Resource Management for the Uplink of Wideband Hybrid Beamforming System
Authors: Yuan Quan, Haseen Rahman, Catherine Rosenberg
Abstract: This paper studies the radio resource management (RRM) for the uplink (UL) of a cellular system with codebook-based hybrid beamforming. We consider the often neglected but highly practical multi-channel case with fewer radio frequency chains in the base station than user equipment (UEs) in the cell, assuming one RF chain per UE. As for any UL RRM, a per-time slot solution is needed as the allocation of power to subchannels by a UE can only be done once it knows which subchannels it has been allocated. The RRM in this system comprises beam selection, user selection and power allocation, three steps that are intricately coupled and we will show that the order in which they are performed does impact performance and so does the amount of coupling that we take into account. Specifically, we propose 4 online sequential solutions with different orders in which the steps are called and of different complexities, i.e., different levels of coupling between the steps. Our extensive numerical campaign for a mmWave system shows how a well-designed heuristic that takes some level of couplings between the steps can make the performance exceedingly better than a benchmark.

Paper number 181:
Title: ESPnet-SpeechLM: An Open Speech Language Model Toolkit
Authors: Jinchuan Tian, Jiatong Shi, William Chen, Siddhant Arora, Yoshiki Masuyama, Takashi Maekaku, Yihan Wu, Junyi Peng, Shikhar Bharadwaj, Yiwen Zhao, Samuele Cornell, Yifan Peng, Xiang Yue, Chao-Han Huck Yang, Graham Neubig, Shinji Watanabe
Abstract: We present ESPnet-SpeechLM, an open toolkit designed to democratize the development of speech language models (SpeechLMs) and voice-driven agentic applications. The toolkit standardizes speech processing tasks by framing them as universal sequential modeling problems, encompassing a cohesive workflow of data preprocessing, pre-training, inference, and task evaluation. With ESPnet-SpeechLM, users can easily define task templates and configure key settings, enabling seamless and streamlined SpeechLM development. The toolkit ensures flexibility, efficiency, and scalability by offering highly configurable modules for every stage of the workflow. To illustrate its capabilities, we provide multiple use cases demonstrating how competitive SpeechLMs can be constructed with ESPnet-SpeechLM, including a 1.7B-parameter model pre-trained on both text and speech tasks, across diverse benchmarks. The toolkit and its recipes are fully transparent and reproducible at: this https URL.

Paper number 182:
Title: TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning
Authors: Giuseppe Paolo, Abdelhakim Benechehab, Hamza Cherkaoui, Albert Thomas, Balázs Kégl
Abstract: Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two levels or require centralized training, which limits their practical applicability. We introduce TAME Agent Framework (TAG), a framework for constructing fully decentralized hierarchical multi-agent this http URL enables hierarchies of arbitrary depth through a novel LevelEnv concept, which abstracts each hierarchy level as the environment for the agents above it. This approach standardizes information flow between levels while preserving loose coupling, allowing for seamless integration of diverse agent types. We demonstrate the effectiveness of TAG by implementing hierarchical architectures that combine different RL agents across multiple levels, achieving improved performance over classical multi-agent RL baselines on standard benchmarks. Our results show that decentralized hierarchical organization enhances both learning speed and final performance, positioning TAG as a promising direction for scalable multi-agent systems.
    