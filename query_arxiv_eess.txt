
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Investigation of Superdirectivity in Planar Holographic Arrays
Authors: Hang Lin, Liuxun Xue, Shu Sun, Ruifeng Gao, Jue Wang, Tengjiao Wang
Abstract: This paper studies the superdirectivity characteristics of uniform rectangular arrays (URAs) for holographic multiple-input multiple-output systems. By establishing a mathematical directivity model for the URA, an analytical expression for the maximum directivity is derived. Accordingly, systematic analysis is performed in conjunction with numerical simulations. Results show that the directivity can be significantly enhanced via rational utilization of coupling effects. However, this enhancement yields diminishing returns when antenna spacings transition to deep sub-wavelength scales. This study provides a theoretical basis for the design of superdirective URAs and offers valuable insights for holographic array optimization in 5G/6G communication systems.

Paper number 2:
Title: See the Speaker: Crafting High-Resolution Talking Faces from Speech with Prior Guidance and Region Refinement
Authors: Jinting Wang, Jun Wang, Hei Victor Cheng, Li Liu
Abstract: Unlike existing methods that rely on source images as appearance references and use source speech to generate motion, this work proposes a novel approach that directly extracts information from the speech, addressing key challenges in speech-to-talking face. Specifically, we first employ a speech-to-face portrait generation stage, utilizing a speech-conditioned diffusion model combined with statistical facial prior and a sample-adaptive weighting module to achieve high-quality portrait generation. In the subsequent speech-driven talking face generation stage, we embed expressive dynamics such as lip movement, facial expressions, and eye movements into the latent space of the diffusion model and further optimize lip synchronization using a region-enhancement module. To generate high-resolution outputs, we integrate a pre-trained Transformer-based discrete codebook with an image rendering network, enhancing video frame details in an end-to-end manner. Experimental results demonstrate that our method outperforms existing approaches on the HDTF, VoxCeleb, and AVSpeech datasets. Notably, this is the first method capable of generating high-resolution, high-quality talking face videos exclusively from a single speech input.

Paper number 3:
Title: Joint optimization of microphone array geometry, sensor directivity pattern, and beamforming parameters for linear superarrays
Authors: Yuanhang Qian, Xueqin Luo, Jilu Jin, Gongping Huang, Jingdong Chen, Jacob Benesty
Abstract: Linear superarrays (LSAs) have been proposed to address the limited steering capability of conventional linear differential microphone arrays (LDMAs) by integrating omnidirectional and directional microphones, enabling more flexible beamformer designs. However, existing approaches remain limited because array geometry and element directivity, both critical to beamforming performance, are not jointly optimized. This paper presents a generalized LSA optimization framework that simultaneously optimizes array geometry, element directivity, and the beamforming filter to minimize the approximation error between the designed beampattern and an ideal directivity pattern (IDP) over the full frequency band and all steering directions within the region of interest. The beamformer is derived by approximating the IDP using a Jacobi-Anger series expansion, while the array geometry and element directivity are optimized via a genetic algorithm. Simulation results show that the proposed optimized array achieves lower approximation error than conventional LSAs across the target frequency band and steering range. Additionally, its directivity factor and white noise gain demonstrate more stable and improved performance across frequencies and steering angles.

Paper number 4:
Title: UP2D: Uncertainty-aware Progressive Pseudo-label Denoising for Source-Free Domain Adaptive Medical Image Segmentation
Authors: Quang-Khai Bui-Tran, Thanh-Huy Nguyen, Manh D. Ho, Thinh B. Lam, Vi Vu, Hoang-Thien Nguyen, Phat Huynh, Ulas Bagci
Abstract: Medical image segmentation models face severe performance drops under domain shifts, especially when data sharing constraints prevent access to source images. We present a novel Uncertainty-aware Progressive Pseudo-label Denoising (UP2D) framework for source-free domain adaptation (SFDA), designed to mitigate noisy pseudo-labels and class imbalance during adaptation. UP2D integrates three key components: (i) a Refined Prototype Filtering module that suppresses uninformative regions and constructs reliable class prototypes to denoise pseudo-labels, (ii) an Uncertainty-Guided EMA (UG-EMA) strategy that selectively updates the teacher model based on spatially weighted boundary uncertainty, and (iii) a quantile-based entropy minimization scheme that focuses learning on ambiguous regions while avoiding overconfidence on easy pixels. This single-stage student-teacher framework progressively improves pseudo-label quality and reduces confirmation bias. Extensive experiments on three challenging retinal fundus benchmarks demonstrate that UP2D achieves state-of-the-art performance across both standard and open-domain settings, outperforming prior UDA and SFDA approaches while maintaining superior boundary precision.

Paper number 5:
Title: R3GAN-based Optimal Strategy for Augmenting Small Medical Dataset
Authors: Tsung-Wei Pan, Chang-Hong Wu, Jung-Hua Wang, Ming-Jer Chen, Yu-Chiao Yi, Tsung-Hsien Lee
Abstract: Medical image analysis often suffers from data scarcity and class imbalance, limiting the effectiveness of deep learning models in clinical applications. Using human embryo time-lapse imaging (TLI) as a case study, this work investigates how generative adversarial networks (GANs) can be optimized for small datasets to generate realistic and diagnostically meaningful images. Based on systematic experiments with R3GAN, we established effective training strategies and designed an optimized configuration for 256x256-resolution datasets, featuring a full burn-in phase and a low, gradually increasing gamma range (5 -> 40). The generated samples were used to balance an imbalanced embryo dataset, leading to substantial improvement in classification performance. The recall and F1-score of t3 increased from 0.06 to 0.69 and 0.11 to 0.60, respectively, without compromising other classes. These results demonstrate that tailored R3GAN training strategies can effectively alleviate data scarcity and improve model robustness in small-scale medical imaging tasks.

Paper number 6:
Title: Diffusion-Driven Generation of Minimally Preprocessed Brain MRI
Authors: Samuel W. Remedios, Aaron Carass, Jerry L. Prince, Blake E. Dewey
Abstract: The purpose of this study is to present and compare three denoising diffusion probabilistic models (DDPMs) that generate 3D $T_1$-weighted MRI human brain images. Three DDPMs were trained using 80,675 image volumes from 42,406 subjects spanning 38 publicly available brain MRI datasets. These images had approximately 1 mm isotropic resolution and were manually inspected by three human experts to exclude those with poor quality, field-of-view issues, and excessive pathology. The images were minimally preprocessed to preserve the visual variability of the data. Furthermore, to enable the DDPMs to produce images with natural orientation variations and inhomogeneity, the images were neither registered to a common coordinate system nor bias field corrected. Evaluations included segmentation, Frechet Inception Distance (FID), and qualitative inspection. Regarding results, all three DDPMs generated coherent MR brain volumes. The velocity and flow prediction models achieved lower FIDs than the sample prediction model. However, all three models had higher FIDs compared to real images across multiple cohorts. In a permutation experiment, the generated brain regional volume distributions differed statistically from real data. However, the velocity and flow prediction models had fewer statistically different volume distributions in the thalamus and putamen. In conclusion this work presents and releases the first 3D non-latent diffusion model for brain data without skullstripping or registration. Despite the negative results in statistical testing, the presented DDPMs are capable of generating high-resolution 3D $T_1$-weighted brain images. All model weights and corresponding inference code are publicly available at this https URL .

Paper number 7:
Title: Multi-Representation Attention Framework for Underwater Bioacoustic Denoising and Recognition
Authors: Amine Razig, Youssef Soulaymani, Loubna Benabbou, Pierre Cauchy
Abstract: Automated monitoring of marine mammals in the St. Lawrence Estuary faces extreme challenges: calls span low-frequency moans to ultrasonic clicks, often overlap, and are embedded in variable anthropogenic and environmental noise. We introduce a multi-step, attention-guided framework that first segments spectrograms to generate soft masks of biologically relevant energy and then fuses these masks with the raw inputs for multi-band, denoised classification. Image and mask embeddings are integrated via mid-level fusion, enabling the model to focus on salient spectrogram regions while preserving global context. Using real-world recordings from the Saguenay St. Lawrence Marine Park Research Station in Canada, we demonstrate that segmentation-driven attention and mid-level fusion improve signal discrimination, reduce false positive detections, and produce reliable representations for operational marine mammal monitoring across diverse environmental conditions and signal-to-noise ratios. Beyond in-distribution evaluation, we further assess the generalization of Mask-Guided Classification (MGC) under distributional shifts by testing on spectrograms generated with alternative acoustic transformations. While high-capacity baseline models lose accuracy in this Out-of-distribution (OOD) setting, MGC maintains stable performance, with even simple fusion mechanisms (gated, concat) achieving comparable results across distributions. This robustness highlights the capacity of MGC to learn transferable representations rather than overfitting to a specific transformation, thereby reinforcing its suitability for large-scale, real-world biodiversity monitoring. We show that in all experimental settings, the MGC framework consistently outperforms baseline architectures, yielding substantial gains in accuracy on both in-distribution and OOD data.

Paper number 8:
Title: Cooperative Integrated Estimation-Guidance for Simultaneous Interception of Moving Targets
Authors: Lohitvel Gopikannan, Shashi Ranjan Kumar, Abhinav Sinha
Abstract: This paper proposes a cooperative integrated estimation-guidance framework for simultaneous interception of a non-maneuvering target using a team of unmanned autonomous vehicles, assuming only a subset of vehicles are equipped with dedicated sensors to measure the target's states. Unlike earlier approaches that focus solely on either estimation or guidance design, the proposed framework unifies both within a cooperative architecture. To circumvent the limitation posed by heterogeneity in target observability, sensorless vehicles estimate the target's state by leveraging information exchanged with neighboring agents over a directed communication topology through a prescribed-time observer. The proposed approach employs true proportional navigation guidance (TPNG), which uses an exact time-to-go formulation and is applicable across a wide spectrum of target motions. Furthermore, prescribed-time observer and controller are employed to achieve convergence to true target's state and consensus in time-to-go within set predefined times, respectively. Simulations demonstrate the effectiveness of the proposed framework under various engagement scenarios.

Paper number 9:
Title: Ferrohydrodynamic Microfluidics for Bioparticle Separation and Single-Cell Phenotyping: Principles, Applications, and Emerging Directions
Authors: Yuhao Zhang, Yong Teng, Kenan Song, Xianqiao Wang, Xianyan Chen, Yuhua Liu, Yiping Zhao, He Li, Leidong Mao, Yang Liu
Abstract: Ferrohydrodynamic microfluidics relies on magnetic field gradients to manipulate diamagnetic particles in ferrofluid-filled microenvironments. It has emerged as a promising tool for label-free manipulation of bioparticles, including their separation and phenotyping. This perspective reviews recent progress in the development and applications of ferrofluid-based microfluidic platforms for multiscale bioparticle separation, ranging from micron-scale cells to submicron extracellular vesicles. We highlight the fundamental physical principles for ferrohydrodynamic manipulation, including the dominant magnetic buoyancy force resulting from the interaction of ferrofluids and particles. We then describe how these principles enable high-resolution size-based bioparticle separation, subcellular bioparticle enrichment, and phenotypic screening based on physical traits. We also discuss key challenges in ferrohydrodynamic microfluidics from the aspects of ferrofluid biocompatibility, system throughput, and nanoparticle depletion. Finally, we outline future research directions involving machine learning, 3D printing, and multiplexed detection. These insights chart a path for advancing ferrofluid-based technologies in precision biomedicine, diagnostics, and cellular engineering.

Paper number 10:
Title: Quantifying Grid-Forming Behavior: Bridging Device-level Dynamics and System-Level Strength
Authors: Kehao Zhuang, Huanhai Xin, Verena Häberle, Xiuqiang He, Linbin Huang, Florian Dörfler
Abstract: Grid-forming (GFM) technology is widely regarded as a promising solution for future power systems dominated by power electronics. However, a precise method for quantifying GFM converter behavior and a universally accepted GFM definition remain elusive. Moreover, the impact of GFM on system stability is not precisely quantified, creating a significant disconnect between device and system levels. To address these gaps from a small-signal perspective, at the device level, we introduce a novel metric, the Forming Index (FI) to quantify a converter's response to grid voltage fluctuations. Rather than enumerating various control architectures, the FI provides a metric for the converter's GFM ability by quantifying its sensitivity to grid variations. At the system level, we propose a new quantitative measure of system strength that captures the multi-bus voltage stiffness, which quantifies the voltage and phase angle responses of multiple buses to current or power disturbances. We further extend this concept to grid strength and bus strength to identify weak areas within the system. Finally, we bridge the device and system levels by formally proving that GFM converters enhance system strength. Our proposed framework provides a unified benchmark for GFM converter design, optimal placement, and system stability assessment.

Paper number 11:
Title: Adaptive Control for a Physics-Informed Model of a Thermal Energy Distribution System: Qualitative Analysis
Authors: Paul Seurin, Auradha Annaswamy, Linyu Lin
Abstract: Integrated energy systems (IES) are complex heterogeneous architectures that typically encompass power sources, hydrogen electrolyzers, energy storage, and heat exchangers. This integration is achieved through operating control strategy optimization. However, the lack of physical understanding as to how these systems evolve over time introduces uncertainties that hinder reliable application thereof. Techniques that can accommodate such uncertainties are fundamental for ensuring proper operation of these systems. Unfortunately, no unifying methodology exists for accommodating uncertainties in this regard. That being said, adaptive control (AC) is a discipline that may allow for accommodating such uncertainties in real-time. In the present work, we derive an AC formulation for linear systems in which all states are observable and apply it to the control of a glycol heat exchanger (GHX) in an IES. Based on prior research in which we quantified the uncertainties of the GHXs system dynamics, we introduced an error of 50% on four terms of the nominal model. In the case where a linear quadratic regulator is used as the nominal control for the reference system, we found that employing AC can reduce the mean absolute error and integral time absolute error by a factor of 30%-75%. This reduction is achieved with minimal computing overhead and control infrastructure, thus underscoring the strength of AC. However, the control effort induced is significant, therefore warranting further study in order to estimate its impact on a physical system. To address further challenges, including partially observable and non-linear dynamics, enhancements of the linear formulation are currently being developed.

Paper number 12:
Title: Quantitative Parameter Conditions for Stability and Coupling in GFM-GFL Converter Hybrid Systems from a Small-Signal Synchronous Perspective
Authors: Kehao Zhuang, Huanhai Xin, Hangyu Chen, Linbin Huang
Abstract: With the development of renewable energy sources, power systems are gradually evolving into a system comprising both grid-forming (GFM) and grid-following (GFL) converters. However, the dynamic interaction between the two types of converters, especially low-inertia GFM converters and GFL converters, remains unclear due to the substantial differences in their synchronization mechanisms. To address this gap, this paper develops a small-signal synchronous stability model for power systems containing GFM and GFL converters, which considers network line dynamics. Based on subspace perturbation theory, we reveal that GFM and GFL subsystems can be effectively decoupled when GFL converters operate near unity power factor or when GFM converters possess sufficiently large inertia or damping, and provide lower bound of control parameters ensuring decoupling. Under the decoupling condition, we propose decentralized and analytical parameter-based stability criteria which have clear physical interpretations: the positive damping of converters compensates for the negative damping of the network. In the case of coupling, we also propose decentralized stability criteria based on the small phase theorem. The effectiveness of the theoretical analysis is validated through simulations in MATLAB/Simulink.

Paper number 13:
Title: Dispatchable Current Source Virtual Oscillator Control Achieving Global Stability
Authors: Kehao Zhuang, Linbin Huang, Huanhai Xin, Xiuqiang He, Verena Häberle, Florian Dörfler
Abstract: This work introduces a novel dispatchable current source virtual oscillator control (dCVOC) scheme for grid-following (GFL) converters, which exhibits duality with dispatchable virtual oscillator control (dVOC) in two ways: a) the current frequency is generated through reactive power control, similar to a PLL ; b) the current magnitude reference is generated through active power control. We formally prove that our proposed control always admits a steady-state equilibrium and ensures global stability under reasonable conditions on grid and converter parameters, even when considering LVRT and current saturation constraints. Our approach avoids low-voltage transients and weak grid instability, which is not the case for conventional GFL control. The effectiveness of our proposed control is verified through high-fidelity electromagnetic transient simulations.

Paper number 14:
Title: GeoPep: A geometry-aware masked language model for protein-peptide binding site prediction
Authors: Dian Chen, Yunkai Chen, Tong Lin, Sijie Chen, Xiaolin Cheng
Abstract: Multimodal approaches that integrate protein structure and sequence have achieved remarkable success in protein-protein interface prediction. However, extending these methods to protein-peptide interactions remains challenging due to the inherent conformational flexibility of peptides and the limited availability of structural data that hinder direct training of structure-aware models. To address these limitations, we introduce GeoPep, a novel framework for peptide binding site prediction that leverages transfer learning from ESM3, a multimodal protein foundation model. GeoPep fine-tunes ESM3's rich pre-learned representations from protein-protein binding to address the limited availability of protein-peptide binding data. The fine-tuned model is further integrated with a parameter-efficient neural network architecture capable of learning complex patterns from sparse data. Furthermore, the model is trained using distance-based loss functions that exploit 3D structural information to enhance binding site prediction. Comprehensive evaluations demonstrate that GeoPep significantly outperforms existing methods in protein-peptide binding site prediction by effectively capturing sparse and heterogeneous binding patterns.

Paper number 15:
Title: Blind MIMO Semantic Communication via Parallel Variational Diffusion: A Completely Pilot-Free Approach
Authors: Hao Jiang, Xiaojun Yuan, Yinuo Huang, Qinghua Guo
Abstract: In this paper, we propose a novel blind multi-input multi-output (MIMO) semantic communication (SC) framework named Blind-MIMOSC that consists of a deep joint source-channel coding (DJSCC) transmitter and a diffusion-based blind receiver. The DJSCC transmitter aims to compress and map the source data into the transmitted signal by exploiting the structural characteristics of the source data, while the diffusion-based blind receiver employs a parallel variational diffusion (PVD) model to simultaneously recover the channel and the source data from the received signal without using any pilots. The PVD model leverages two pre-trained score networks to characterize the prior information of the channel and the source data, operating in a plug-and-play manner during inference. This design allows only the affected network to be retrained when channel conditions or source datasets change, avoiding the complicated full-network retraining required by end-to-end methods. This work presents the first fully pilot-free solution for joint channel estimation and source recovery in block-fading MIMO systems. Extensive experiments show that Blind-MIMOSC with PVD achieves superior channel and source recovery accuracy compared to state-of-the-art approaches, with drastically reduced channel bandwidth ratio.

Paper number 16:
Title: Distributed Precoding for Cell-free Massive MIMO in O-RAN: A Multi-agent Deep Reinforcement Learning Framework
Authors: Mohammad Hossein Shokouhi, Vincent W.S. Wong
Abstract: Cell-free massive multiple-input multiple-output (MIMO) is a key technology for next-generation wireless systems. The integration of cell-free massive MIMO within the open radio access network (O-RAN) architecture addresses the growing need for decentralized, scalable, and high-capacity networks that can support different use cases. Precoding is a crucial step in the operation of cell-free massive MIMO, where O-RUs steer their beams towards the intended users while mitigating interference to other users. Current precoding schemes for cell-free massive MIMO are either fully centralized or fully distributed. Centralized schemes are not scalable, whereas distributed schemes may lead to a high inter-O-RU interference. In this paper, we propose a distributed and scalable precoding framework for cell-free massive MIMO that uses limited information exchange among precoding agents to mitigate interference. We formulate an optimization problem for precoding that maximizes the aggregate throughput while guaranteeing the minimum data rate requirements of users. The formulated problem is nonconvex. We propose a multi-timescale framework that combines multi-agent deep reinforcement learning (DRL) with expert insights from an iterative algorithm to determine the precoding matrices efficiently. We conduct simulations and compare the proposed framework with the centralized precoding and distributed precoding methods for different numbers of O-RUs, users, and transmit antennas. The results show that the proposed framework achieves a higher aggregate throughput than the distributed regularized zero-forcing (D-RZF) scheme and the weighted minimum mean square error (WMMSE) algorithm. When compared with the centralized regularized zero-forcing (C-RZF) scheme, the proposed framework achieves similar aggregate throughput performance but with a lower signaling overhead.

Paper number 17:
Title: RFI Detection and Identification at OVRO Using Pseudonymetry
Authors: Meles Weldegebriel, Zihan Li, Greg Hellbourg, Ning Zhang, Neal Patwari
Abstract: Protecting radio astronomy observatories from unintended interference is critical as wireless transmissions increases near protected bands. While database-driven coordination frameworks and radio quiet zones exist, they cannot rapidly identify or suppress specific interfering transmitters, especially at low signal-to-noise ratio (SNR) levels. This paper presents the first over-the-air field demonstration of Pseudonymetry at the Owens Valley Radio Observatory (OVRO), illustrating cooperative spectrum sharing between heterogeneous wireless systems. In our experiment, a narrow-band secondary transmitter embeds a pseudonym watermark into its signal, while the wide-band radio telescope passively extracts the watermark from spectrogram data. Results show that interference can be reliably detected and the interfering device uniquely identified even at low SNR where conventional demodulation is infeasible. These findings validate that passive scientific receivers can participate in a lightweight feedback loop to trigger shutdown of harmful transmissions, demonstrating the potential of Pseudonymetry as a complementary enforcement tool for protecting radio astronomy environments.

Paper number 18:
Title: Unlimited Sampling of Multiband Signals: Single-Channel Acquisition and Recovery
Authors: Gal Shtendel, Ayush Bhandari
Abstract: In this paper, we address the problem of reconstructing multiband signals from modulo-folded, pointwise samples within the Unlimited Sensing Framework (USF). Focusing on a low-complexity, single-channel acquisition setup, we establish recovery guarantees demonstrating that sub-Nyquist sampling is achievable under the USF paradigm. In doing so, we also tighten the previous sampling theorem for bandpass signals. Our recovery algorithm demonstrates up to a 13x dynamic range improvement in hardware experiments with up to 6 spectral bands. These results enable practical high-dynamic-range multiband acquisition in scenarios previously limited by dynamic range and excessive oversampling.

Paper number 19:
Title: Beamforming in the Reproducing Kernel Domain Based on Spatial Differentiation
Authors: Takahiro Iwami, Naohisa Inoue, Akira Omoto
Abstract: This paper proposes a novel beamforming framework in the reproducing kernel domain, derived from a unified interpretation of directional response as spatial differentiation of the sound field. By representing directional response using polynomial differential operators, the proposed method enables the formulation of arbitrary beam patterns including non-axisymmetric. The derivation of the reproducing kernel associated with the interior fields is mathematically supported by Hobson's theorem, which allows concise analytical expressions. Furthermore, the proposed framework generalizes conventional spherical harmonic domain beamformers by reinterpreting them as spatial differential operators, thereby clarifying their theoretical structure and extensibility. Three numerical simulations conducted in two-dimensional space confirm the validity of the method.

Paper number 20:
Title: Solving Infinite-Horizon Optimal Control Problems using the Extreme Theory of Functional Connections
Authors: Tanay Raghunandan Srinivasa (1), Suraj Kumar (2) ((1) Plaksha University, (2) UR Rao Satellite Center, Indian Space Research Organization)
Abstract: This paper presents a physics-informed machine learning approach for synthesizing optimal feedback control policy for infinite-horizon optimal control problems by solving the Hamilton-Jacobi-Bellman (HJB) partial differential equation(PDE). The optimal control policy is derived analytically for affine dynamical systems with separable and strictly convex control costs, expressed as a function of the gradient of the value function. The resulting HJB-PDE is then solved by approximating the value function using the Extreme Theory of Functional Connections (X-TFC) - a hybrid approach that combines the Theory of Functional Connections (TFC) with the Extreme Learning Machine (ELM) algorithm. This approach ensures analytical satisfaction of boundary conditions and significantly reduces training cost compared to traditional Physics-Informed Neural Networks (PINNs). We benchmark the method on linear and non-linear systems with known analytical solutions as well as demonstrate its effectiveness on control tasks such as spacecraft optimal de-tumbling control.

Paper number 21:
Title: From OFDM to AFDM: Enabling Adaptive Integrated Sensing and Communication in High-Mobility Scenarios
Authors: Haoran Yin, Yanqun Tang, Jun Xiong, Fan Liu, Yuanhan Ni, Qu Luo, Roberto Bomfin, Marwa Chafii, Marios Kountouris, Christos Masouros
Abstract: Integrated sensing and communication (ISAC) is a key feature of next-generation wireless networks, enabling a wide range of emerging applications such as vehicle-to-everything (V2X) and unmanned aerial vehicles (UAVs), which operate in high-mobility scenarios. Notably, the wireless channels within these applications typically exhibit severe delay and Doppler spreads. The latter causes serious communication performance degradation in the Orthogonal Frequency-Division Multiplexing (OFDM) waveform that is widely adopted in current wireless networks. To address this challenge, the recently proposed Doppler-resilient affine frequency division multiplexing (AFDM) waveform, which uses flexible chirp signals as subcarriers, shows great potential for achieving adaptive ISAC in high-mobility scenarios. This article provides a comprehensive overview of AFDM-ISAC. We begin by presenting the fundamentals of AFDM-ISAC, highlighting its inherent frequency-modulated continuous-wave (FMCW)-like characteristics. Then, we explore its ISAC performance limits by analyzing its diversity order, ambiguity function (AF), and Cramer-Rao Bound (CRB). Finally, we present several effective sensing algorithms and opportunities for AFDM-ISAC, with the aim of sparking new ideas in this emerging field.

Paper number 22:
Title: Reference Microphone Selection for Guided Source Separation based on the Normalized L-p Norm
Authors: Anselm Lohmann, Tomohiro Nakatani, Rintaro Ikeshita, Marc Delcroix, Shoko Araki, Simon Doclo
Abstract: Guided Source Separation (GSS) is a popular front-end for distant automatic speech recognition (ASR) systems using spatially distributed microphones. When considering spatially distributed microphones, the choice of reference microphone may have a large influence on the quality of the output signal and the downstream ASR performance. In GSS-based speech enhancement, reference microphone selection is typically performed using the signal-to-noise ratio (SNR), which is optimal for noise reduction but may neglect differences in early-to-late-reverberant ratio (ELR) across microphones. In this paper, we propose two reference microphone selection methods for GSS-based speech enhancement that are based on the normalized $\ell_p$-norm, either using only the normalized $\ell_p$-norm or combining the normalized $\ell_p$-norm and the SNR to account for both differences in SNR and ELR across microphones. Experimental evaluation using a CHiME-8 distant ASR system shows that the proposed $\ell_p$-norm-based methods outperform the baseline method, reducing the macro-average word error rate.

Paper number 23:
Title: Joint Visible Light and Backscatter Communications for Proximity-Based Indoor Asset Tracking Enabled by Energy-Neutral Devices
Authors: Boxuan Xie, Lauri Mela, Alexis A. Dowhuszko, Yu Bai, Zehui Xiong, Zhu Han, Dusit Niyato, Riku Jäntti
Abstract: In next-generation wireless systems, providing location-based mobile computing services for energy-neutral devices has become a crucial objective for the provision of sustainable Internet of Things (IoT). Visible light positioning (VLP) has gained great research attention as a complementary method to radio frequency (RF) solutions since it can leverage ubiquitous lighting infrastructure. However, conventional VLP receivers often rely on photodetectors or cameras that are power-hungry, complex, and expensive. To address this challenge, we propose a hybrid indoor asset tracking system that integrates visible light communication (VLC) and backscatter communication (BC) within a simultaneous lightwave information and power transfer (SLIPT) framework. We design a low-complexity and energy-neutral IoT node, namely backscatter device (BD) which harvests energy from light-emitting diode (LED) access points, and then modulates and reflects ambient RF carriers to indicate its location within particular VLC cells. We present a multi-cell VLC deployment with frequency division multiplexing (FDM) method that mitigates interference among LED access points by assigning them distinct frequency pairs based on a four-color map scheduling principle. We develop a lightweight particle filter (PF) tracking algorithm at an edge RF reader, where the fusion of proximity reports and the received backscatter signal strength are employed to track the BD. Experimental results show that this approach achieves the positioning error of 0.318 m at 50th percentile and 0.634 m at 90th percentile, while avoiding the use of complex photodetectors and active RF synthesizing components at the energy-neutral IoT node. By demonstrating robust performance in multiple indoor trajectories, the proposed solution enables scalable, cost-effective, and energy-neutral indoor tracking for pervasive and edge-assisted IoT applications.

Paper number 24:
Title: SIM-Assisted End-to-End Co-Frequency Co-Time Full-Duplex System
Authors: Yida Zhang, Qiuyan Liu, Yuqi Xia, Guoxu Xia, Qiang Wang
Abstract: To further suppress the inherent self-interference (SI) in co-frequency and co-time full-duplex (CCFD) systems, we propose integrating a stacked intelligent metasurface (SIM) into the RF front-end to enhance signal processing in the wave domain. Furthermore, an end-to-end (E2E) learning-based signal processing method is adopted to control the metasurface. Specifically, the real metasurface is abstracted as hidden layers of a network, thereby constructing an electromagnetic neural network (EMNN) to enable driving control of the real communication system. Traditional communication tasks, such as channel coding, modulation, precoding, combining, demodulation, and channel decoding, are synchronously carried out during the electromagnetic (EM) forward propagation through the metasurface. Simulation results show that, benefiting from the additional wave-domain processing capability of the SIM, the SIM-assisted CCFD system achieves significantly reduced bit error rate (BER) compared with conventional CCFD systems. Our study fully demonstrates the potential applications of EMNN and SIM-assisted E2E CCFD systems in next-generation transceiver design.

Paper number 25:
Title: Simplifying Preference Elicitation in Local Energy Markets: Combinatorial Clock Exchange
Authors: Shobhit Singhal, Lesia Mitridati
Abstract: As distributed energy resources (DERs) proliferate, future power system will need new market platforms enabling prosumers to trade various electricity and grid-support products. However, prosumers often exhibit complex, product interdependent preferences and face limited cognitive and computational resources, hindering engagement with complex market structures and bid formats. We address this challenge by introducing a multi-product market that allows prosumers to express complex preferences through an intuitive format, by fusing combinatorial clock exchange and machine learning (ML) techniques. The iterative mechanism only requires prosumers to report their preferred package of products at posted prices, eliminating the need for forecasting product prices or adhering to complex bid formats, while the ML-aided price discovery speeds up convergence. The linear pricing rule further enhances transparency and interpretability. Finally, numerical simulations demonstrate convergence to clearing prices in approximately 15 clock iterations.

Paper number 26:
Title: A fragile zero-watermarking method based on dual quaternion matrix decomposition
Authors: Mingcui Zhang, Zhigang Jia
Abstract: Medical images play a crucial role in assisting diagnosis, remote consultation, and academic research. However, during the transmission and sharing process, they face serious risks of copyright ownership and content tampering. Therefore, protecting medical images is of great importance. As an effective means of image copyright protection, zero-watermarking technology focuses on constructing watermarks without modifying the original carrier by extracting its stable features, which provides an ideal approach for protecting medical images. This paper aims to propose a fragile zero-watermarking model based on dual quaternion matrix decomposition, which utilizes the operational relationship between the standard part and the dual part of dual quaternions to correlate the original carrier image with the watermark image, and generates zero-watermarking information based on the characteristics of dual quaternion matrix decomposition, ultimately achieving copyright protection and content tampering detection for medical images.

Paper number 27:
Title: Variational Bayesian Estimation of Low Earth Orbits for Satellite Communication
Authors: Anders Malthe Westerkam, Amélia Struyf, Dimitri Lederer, Troels Pedersen, François Quitin
Abstract: Low-earth-orbit (LEO) satellite communication systems that use millimeter-wave frequencies rely on large antenna arrays with hybrid analog-digital architectures for rapid beam steering. LEO satellites are only visible from the ground for short periods of times (a few tens of minutes) due to their high orbital speeds. This paper presents a variational message passing algorithm for joint localization and beam tracking of a LEO satellite from a ground station equipped with a hybrid transceiver architecture. The algorithm relies on estimating the parameters of the orbit, which is modelled as circular. Angles are then obtained from the orbit in a straightforward manner. Simulation results show that the proposed method is highly resilient to missed detections, enables reliable satellite tracking even near the horizon, and effectively alleviates the ambiguities inherent in hybrid architectures.

Paper number 28:
Title: Classification of Lower Limb Activities Based on Discrete Wavelet Transform Using On-Body Creeping Wave Propagation
Authors: Sagar Dutta, Banani Basu, Fazal Ahmed Talukdar
Abstract: This article investigates how the creeping wave propagation around the human thigh could be used to monitor the leg movements. The propagation path around the human thigh gives information regarding leg motions that can be used for the classification of activities. The variation of the transmission coefficient is measured between two on-body polyethylene terephthalate (PET) flexible antennas for six different leg-based activities that exhibit unique time-varying signatures. A discrete wavelet transform (DWT) along with different classifiers, such as support vector machine (SVM), decision trees, naive Bayes, and K-nearest neighbors (KNN), is applied for feature extraction and classification to evaluate the efficiency for classifying different activity signals. Additional algorithms, such as dynamic time warping (DTW) and deep convolutional neural network (DCNN), have also been implemented, and in each case, SVM with DWT outperforms the others. Simulation to evaluate a specific absorption rate (SAR) is carried out as the antenna is positioned on the human thigh leaving no gap. The results show that the SAR is within the threshold as per the Federal Communications Commission (FCC) standard.

Paper number 29:
Title: Classification of Induction Motor Fault and Imbalance Based on Vibration Signal Using Single Antenna's Reactive Near Field
Authors: Sagar Dutta, Banani Basu, Fazal Ahmed Talukdar
Abstract: Early fault diagnosis is imperative for the proper functioning of rotating machines. It can reduce economic losses in the industry due to unexpected failures. Existing fault analysis methods are either expensive or demand expertise for the installation of the sensors. This article proposes a novel method for the detection of bearing faults and imbalance in induction motors using an antenna as the sensor, which is noninvasive and cost-efficient. Time-varying S11 is measured using an omnidirectional antenna, and it is seen that the spectrogram of S11 shows unique characteristics for different fault conditions. The experimental setup has analytically evaluated the vibration frequencies due to fault and validated the characteristic fault frequency by applying FFT analysis on the captured S11 data. This article has evaluated the average power content of the detected signals at normal and different fault conditions. A deep learning model is used to classify the faults based on the reflection coefficient ( S11). It is found that classification accuracy of 98.2% is achieved using both magnitude and phase of S11, 96% using the magnitude of S11 and 92.1% using the phase of S11. The classification accuracy for different operating frequencies, antenna location, and time windows are also investigated.

Paper number 30:
Title: UNILocPro: Unified Localization Integrating Model-Based Geometry and Channel Charting
Authors: Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch
Abstract: In this paper, we propose a unified localization framework (called UNILocPro) that integrates model-based localization and channel charting (CC) for mixed line-of-sight (LoS)/non-line-of-sight (NLoS) scenarios. Specifically, based on LoS/NLoS identification, an adaptive activation between the model-based and CC-based methods is conducted. Aiming for unsupervised learning, information obtained from the model-based method is utilized to train the CC model, where a pairwise distance loss (involving a new dissimilarity metric design), a triplet loss (if timestamps are available), a LoS-based loss, and an optimal transport (OT)-based loss are jointly employed such that the global geometry can be well preserved. To reduce the training complexity of UNILocPro, we propose a low-complexity implementation (called UNILoc), where the CC model is trained with self-generated labels produced by a single pre-training OT transformation, which avoids iterative Sinkhorn updates involved in the OT-based loss computation. Extensive numerical experiments demonstrate that the proposed unified frameworks achieve significantly improved positioning accuracy compared to both model-based and CC-based methods. Notably, UNILocPro with timestamps attains performance on par with fully-supervised fingerprinting despite operating without labelled training data. It is also shown that the low-complexity UNILoc can substantially reduce training complexity with only marginal performance degradation.

Paper number 31:
Title: Estimation of aboveground biomass in a tropical dry forest: An intercomparison of airborne, unmanned, and space laser scanning
Authors: Nelson Mattié, Arturo Sanchez-Azofeifa, Pablo Crespo-Peremarch, Juan-Ygnacio López-Hernández
Abstract: According to the Paris Climate Change Agreement, all nations are required to submit reports on their greenhouse gas emissions and absorption every two years by 2024. Consequently, forests play a crucial role in reducing carbon emissions, which is essential for meeting these obligations. Recognizing the significance of forest conservation in the global battle against climate change, Article 5 of the Paris Agreement emphasizes the need for high-quality forest data. This study focuses on enhancing methods for mapping aboveground biomass in tropical dry forests. Tropical dry forests are considered one of the least understood tropical forest environments; therefore, there is a need for accurate approaches to estimate carbon pools. We employ a comparative analysis of AGB estimates, utilizing different discrete and full-waveform laser scanning datasets in conjunction with Ordinary Least Squares and Bayesian approaches SVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanning were used as independent variables for extracting forest metrics. Variable selection, SVM regression tuning, and cross-validation via a machine-learning approach were applied to account for overfitting and underfitting. The results indicate that six key variables primarily related to tree height: this http URL, Elev.L3, this http URL, this http URL, this http URL, and this http URL, are important for AGB estimation using ALSD and ULSD , while Leaf Area Index, canopy coverage and height, terrain elevation, and full-waveform signal energy emerged as the most vital variables. AGB values estimated from ten permanent tropical dry forest plots in Costa Rica Guanacaste province ranged from 26.02 Mg/ha to 175.43 Mg/ha . The SVM regressions demonstrated a 17.89 error across all laser scanning systems, with SLSF W exhibiting the lowest error 17.07 in estimating total biomass per plot.

Paper number 32:
Title: A Switching Strategy for Event-Trigger Control of Spacecraft Rendezvous
Authors: Tommaso Del Carro, Gerson Portilla, Alexandre Seuret, Rafael Vazquez
Abstract: This paper presents the design of a state-feedback control law for spacecraft rendezvous, formulated using the Hill-Clohessy-Wiltshire equations. The proposed method introduces an impulsive control strategy to regulate thruster operations. Specifically, a state-dependent switching framework is developed to determine both the control input magnitudes and the precise state conditions that trigger thruster activation. The nonlinear control law is derived using principles from automatic control theory, particularly Lyapunov stability analysis and the Linear Matrix Inequality framework. The resulting closed-loop system is proven to be stable, while simultaneously minimizing the total number of actuation events. The effectiveness of the proposed method is demonstrated through a numerical case study, which includes a comparative analysis with a standard Model Predictive Control scheme, highlighting the advantages and trade-offs of the developed control structure.

Paper number 33:
Title: Context-Aware Stochastic Modeling of Consumer Energy Resource Aggregators in Electricity Markets
Authors: Chatum Sankalpa, Ghulam Mohy-ud-din, Erik Weyer, Maria Vrakopoulou
Abstract: Aggregators of consumer energy resources (CERs) like rooftop solar and battery energy storage (BES) face challenges due to their inherent uncertainties. A sensible approach is to use stochastic optimization to handle such uncertainties, which can lead to infeasible problems or loss in revenues if not chosen appropriately. This paper presents three efficient two-stage stochastic optimization methods: risk-neutral, robust, and chance-constrained, to address the impact of CER uncertainties for aggregators who participate in energy and regulation services markets in the Australian National Electricity Market. Furthermore, these methods utilize the flexibility of BES, considering precise state-of-charge dynamics and complementarity constraints, aiming for scalable performance while managing uncertainty. The problems are formed as two-stage stochastic mixed-integer linear programs, with relaxations adopted for large scenario sets. The solution approach employs scenario-based methodologies and affine recourse policies to obtain tractable reformulations. These methods are evaluated across use cases reflecting diverse operational and market settings, uncertainty characteristics, and decision-making preferences, demonstrating their ability to mitigate uncertainty, enhance profitability, and provide context-aware guidance for aggregators in choosing the most appropriate stochastic optimization method.

Paper number 34:
Title: Towards robust quantitative photoacoustic tomography via learned iterative methods
Authors: Anssi Manninen, Janek Gröhl, Felix Lucka, Andreas Hauptmann
Abstract: Photoacoustic tomography (PAT) is a medical imaging modality that can provide high-resolution tissue images based on the optical absorption. Classical reconstruction methods for quantifying the absorption coefficients rely on sufficient prior information to overcome noisy and imperfect measurements. As these methods utilize computationally expensive forward models, the computation becomes slow, limiting their potential for time-critical applications. As an alternative approach, deep learning-based reconstruction methods have been established for faster and more accurate reconstructions. However, most of these methods rely on having a large amount of training data, which is not the case in practice. In this work, we adopt the model-based learned iterative approach for the use in Quantitative PAT (QPAT), in which additional information from the model is iteratively provided to the updating networks, allowing better generalizability with scarce training data. We compare the performance of different learned updates based on gradient descent, Gauss-Newton, and Quasi-Newton methods. The learning tasks are formulated as greedy, requiring iterate-wise optimality, as well as end-to-end, where all networks are trained jointly. The implemented methods are tested with ideal simulated data as well as against a digital twin dataset that emulates scarce training data and high modeling error.

Paper number 35:
Title: pDANSE: Particle-based Data-driven Nonlinear State Estimation from Nonlinear Measurements
Authors: Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee
Abstract: We consider the problem of designing a data-driven nonlinear state estimation (DANSE) method that uses (noisy) nonlinear measurements of a process whose underlying state transition model (STM) is unknown. Such a process is referred to as a model-free process. A recurrent neural network (RNN) provides parameters of a Gaussian prior that characterize the state of the model-free process, using all previous measurements at a given time point. In the case of DANSE, the measurement system was linear, leading to a closed-form solution for the state posterior. However, the presence of a nonlinear measurement system renders a closed-form solution infeasible. Instead, the second-order statistics of the state posterior are computed using the nonlinear measurements observed at the time point. We address the nonlinear measurements using a reparameterization trick-based particle sampling approach, and estimate the second-order statistics of the state posterior. The proposed method is referred to as particle-based DANSE (pDANSE). The RNN of pDANSE uses sequential measurements efficiently and avoids the use of computationally intensive sequential Monte-Carlo (SMC) and/or ancestral sampling. We describe the semi-supervised learning method for pDANSE, which transitions to unsupervised learning in the absence of labeled data. Using a stochastic Lorenz-$63$ system as a benchmark process, we experimentally demonstrate the state estimation performance for four nonlinear measurement systems. We explore cubic nonlinearity and a camera-model nonlinearity where unsupervised learning is used; then we explore half-wave rectification nonlinearity and Cartesian-to-spherical nonlinearity where semi-supervised learning is used. The performance of state estimation is shown to be competitive vis-à-vis particle filters that have complete knowledge of the STM of the Lorenz-$63$ system.

Paper number 36:
Title: Trends and Challenges in Next-Generation GNSS Interference Management
Authors: Leatile Marata, Mariona Jaramillo-Civill, Tales Imbiriba, Petri Välisuo, Heidi Kuusniemi, Elena Simona Lohan, Pau Closas
Abstract: The global navigation satellite system (GNSS) continues to evolve in order to meet the demands of emerging applications such as autonomous driving and smart environmental monitoring. However, these advancements are accompanied by a rise in interference threats, which can significantly compromise the reliability and safety of GNSS. Such interference problems are typically addressed through signal-processing techniques that rely on physics-based mathematical models. Unfortunately, solutions of this nature can often fail to fully capture the complex forms of interference. To address this, artificial intelligence (AI)-inspired solutions are expected to play a key role in future interference management solutions, thanks to their ability to exploit data in addition to physics-based models. This magazine paper discusses the main challenges and tasks required to secure GNSS and present a research vision on how AI can be leveraged towards achieving more robust GNSS-based positioning.

Paper number 37:
Title: Combined fluorescence and photoacoustic imaging of tozuleristide in muscle tissue in vitro -- toward optically-guided solid tumor surgery: feasibility studies
Authors: Ruibo Shang, Matthew Thompson, Matthew D. Carson, Eric J. Seibel, Matthew O'Donnell, Ivan Pelivanov
Abstract: Near-infrared fluorescence (NIRF) can deliver high-contrast, video-rate, non-contact imaging of tumor-targeted contrast agents with the potential to guide surgeries excising solid tumors. However, it has been met with skepticism for wide-margin excision due to sensitivity and resolution limitations at depths larger than ~5 mm in tissue. To address this limitation, fast-sweep photoacoustic-ultrasound (PAUS) imaging is proposed to complement NIRF. In an exploratory in vitro feasibility study using dark-red bovine muscle tissue, we observed that PAUS scanning can identify tozuleristide, a clinical stage investigational imaging agent, at a concentration of 20 uM from the background at depths of up to ~34 mm, highly extending the capabilities of NIRF alone. The capability of spectroscopic PAUS imaging was tested by direct injection of 20 uM tozuleristide into bovine muscle tissue at a depth of ~ 8 mm. It is shown that laser-fluence compensation and strong clutter suppression enabled by the unique capabilities of the fast-sweep approach greatly improve spectroscopic accuracy and the PA detection limit, and strongly reduce image artifacts. Thus, the combined NIRF-PAUS approach can be promising for comprehensive pre- (with PA) and intra- (with NIRF) operative solid tumor detection and wide-margin excision in optically guided solid tumor surgery.

Paper number 38:
Title: Navigated hepatic tumor resection using intraoperative ultrasound imaging
Authors: Karin Olthof, Theo Ruers, Tiziano Natali, Lisanne Venix, Jasper Smit, Anne den Hartor, Niels Kok, Matteo Fusaglia, Koert Kuhlmann
Abstract: Purpose: This proof-of-concept study evaluates feasibility and accuracy of an ultrasound-based navigation system for open liver surgery. Unlike most conventional systems that rely on registration to preoperative imaging, the proposed system provides navigation-guided resection using 3D models generated from intraoperative ultrasound. Methods: A pilot study was conducted in 25 patients undergoing resection of liver metastases. The first five cases served to optimize the workflow. Intraoperatively, an electromagnetic sensor compensated for organ motion, after which an ultrasound volume was acquired. Vasculature was segmented automatically and tumors semi-automatically using region-growing (n=15) or a deep learning algorithm (n=5). The resulting 3D model was visualized alongside tracked surgical instruments. Accuracy was assessed by comparing the distance between surgical clips and tumors in the navigation software with the same distance on a postoperative CT of the resected specimen. Results: Navigation was successfully established in all 20 patients. However, four cases were excluded from accuracy assessment due to intraoperative sensor detachment (n=3) or incorrect data recording (n=1). The complete navigation workflow was operational within 5-10 minutes. In 16 evaluable patients, 78 clip-to-tumor distances were analyzed. The median navigation accuracy was 3.2 mm [IQR: 2.8-4.8 mm], and an R0 resection was achieved in 15/16 (93.8%) patients and one patient had an R1 vascular resection. Conclusion: Navigation based solely on intra-operative ultrasound is feasible and accurate for liver surgery. This registration-free approach paves the way for simpler and more accurate image guidance systems.

Paper number 39:
Title: Bayesian model selection and misspecification testing in imaging inverse problems only from noisy and partial measurements
Authors: Tom Sprunck, Marcelo Pereyra, Tobias Liaudat
Abstract: Modern imaging techniques heavily rely on Bayesian statistical models to address difficult image reconstruction and restoration tasks. This paper addresses the objective evaluation of such models in settings where ground truth is unavailable, with a focus on model selection and misspecification diagnosis. Existing unsupervised model evaluation methods are often unsuitable for computational imaging due to their high computational cost and incompatibility with modern image priors defined implicitly via machine learning models. We herein propose a general methodology for unsupervised model selection and misspecification detection in Bayesian imaging sciences, based on a novel combination of Bayesian cross-validation and data fission, a randomized measurement splitting technique. The approach is compatible with any Bayesian imaging sampler, including diffusion and plug-and-play samplers. We demonstrate the methodology through experiments involving various scoring rules and types of model misspecification, where we achieve excellent selection and detection accuracy with a low computational cost.

Paper number 40:
Title: Technical Report for Dissipativity Learning in Reproducing Kernel Hilbert Space
Authors: Xiuzhen Ye, Wentao Tang
Abstract: This work presents a nonparametric framework for dissipativity learning in reproducing kernel Hilbert spaces, which enables data-driven certification of stability and performance properties for unknown nonlinear systems without requiring an explicit dynamic model. Dissipativity is a fundamental system property that generalizes Lyapunov stability, passivity, and finite L2 gain conditions through an energy balance inequality between a storage function and a supply rate. Unlike prior parametric formulations that approximate these functions using quadratic forms with fixed matrices, the proposed method represents them as Hilbert Schmidt operators acting on canonical kernel features, thereby capturing nonlinearities implicitly while preserving convexity and analytic tractability. The resulting operator optimization problem is formulated in the form of a one-class support vector machine and reduced, via the representer theorem, to a finite dimensional convex program expressed through kernel Gram matrices. Furthermore, statistical learning theory is applied to establish generalization guarantees, including confidence bounds on the dissipation rate and the L2 gain. Numerical results demonstrate that the proposed RKHS based dissipativity learning method effectively identifies nonlinear dissipative behavior directly from input output data, providing a powerful and interpretable framework for model free control analysis and synthesis.

Paper number 41:
Title: Oral Tradition-Encoded NanyinHGNN: Integrating Nanyin Music Preservation and Generation through a Pipa-Centric Dataset
Authors: Jianbing Xiahou, Weixi Zhai, Xu Cui
Abstract: We propose NanyinHGNN, a heterogeneous graph network model for generating Nanyin instrumental music. As a UNESCO-recognized intangible cultural heritage, Nanyin follows a heterophonic tradition centered around the pipa, where core melodies are notated in traditional notation while ornamentations are passed down orally, presenting challenges for both preservation and contemporary innovation. To address this, we construct a Pipa-Centric MIDI dataset, develop NanyinTok as a specialized tokenization method, and convert symbolic sequences into graph structures using a Graph Converter to ensure that key musical features are preserved. Our key innovation reformulates ornamentation generation as the creation of ornamentation nodes within a heterogeneous graph. First, a graph neural network generates melodic outlines optimized for ornamentations. Then, a rule-guided system informed by Nanyin performance practices refines these outlines into complete ornamentations without requiring explicit ornamentation annotations during training. Experimental results demonstrate that our model successfully generates authentic heterophonic ensembles featuring four traditional instruments. These findings validate that integrating domain-specific knowledge into model architecture can effectively mitigate data scarcity challenges in computational ethnomusicology.

Paper number 42:
Title: GACA-DiT: Diffusion-based Dance-to-Music Generation with Genre-Adaptive Rhythm and Context-Aware Alignment
Authors: Jinting Wang, Chenxing Li, Li Liu
Abstract: Dance-to-music (D2M) generation aims to automatically compose music that is rhythmically and temporally aligned with dance movements. Existing methods typically rely on coarse rhythm embeddings, such as global motion features or binarized joint-based rhythm values, which discard fine-grained motion cues and result in weak rhythmic alignment. Moreover, temporal mismatches introduced by feature downsampling further hinder precise synchronization between dance and music. To address these problems, we propose \textbf{GACA-DiT}, a diffusion transformer-based framework with two novel modules for rhythmically consistent and temporally aligned music generation. First, a \textbf{genre-adaptive rhythm extraction} module combines multi-scale temporal wavelet analysis and spatial phase histograms with adaptive joint weighting to capture fine-grained, genre-specific rhythm patterns. Second, a \textbf{context-aware temporal alignment} module resolves temporal mismatches using learnable context queries to align music latents with relevant dance rhythm features. Extensive experiments on the AIST++ and TikTok datasets demonstrate that GACA-DiT outperforms state-of-the-art methods in both objective metrics and human evaluation. Project page: this https URL.

Paper number 43:
Title: Cross-Corpus Validation of Speech Emotion Recognition in Urdu using Domain-Knowledge Acoustic Features
Authors: Unzela Talpur, Zafi Sherhan Syed, Muhammad Shehram Shah Syed, Abbas Shah Syed
Abstract: Speech Emotion Recognition (SER) is a key affective computing technology that enables emotionally intelligent artificial intelligence. While SER is challenging in general, it is particularly difficult for low-resource languages such as Urdu. This study investigates Urdu SER in a cross-corpus setting, an area that has remained largely unexplored. We employ a cross-corpus evaluation framework across three different Urdu emotional speech datasets to test model generalization. Two standard domain-knowledge based acoustic feature sets, eGeMAPS and ComParE, are used to represent speech signals as feature vectors which are then passed to Logistic Regression and Multilayer Perceptron classifiers. Classification performance is assessed using unweighted average recall (UAR) whilst considering class-label imbalance. Results show that Self-corpus validation often overestimates performance, with UAR exceeding cross-corpus evaluation by up to 13%, underscoring that cross-corpus evaluation offers a more realistic measure of model robustness. Overall, this work emphasizes the importance of cross-corpus validation for Urdu SER and its implications contribute to advancing affective computing research for underrepresented language communities.

Paper number 44:
Title: Audio-Visual Speech Enhancement In Complex Scenarios With Separation And Dereverberation Joint Modeling
Authors: Jiarong Du, Zhan Jin, Peijun Yang, Juan Liu, Zhuo Li, Xin Liu, Ming Li
Abstract: Audio-visual speech enhancement (AVSE) is a task that uses visual auxiliary information to extract a target speaker's speech from mixed audio. In real-world scenarios, there often exist complex acoustic environments, accompanied by various interfering sounds and reverberation. Most previous methods struggle to cope with such complex conditions, resulting in poor perceptual quality of the extracted speech. In this paper, we propose an effective AVSE system that performs well in complex acoustic environments. Specifically, we design a "separation before dereverberation" pipeline that can be extended to other AVSE networks. The 4th COGMHEAR Audio-Visual Speech Enhancement Challenge (AVSEC) aims to explore new approaches to speech processing in multimodal complex environments. We validated the performance of our system in AVSEC-4: we achieved excellent results in the three objective metrics on the competition leaderboard, and ultimately secured first place in the human subjective listening test.

Paper number 45:
Title: Multi-hop Parallel Image Semantic Communication for Distortion Accumulation Mitigation
Authors: Bingyan Xie, Jihong Park, Yongpeng Wu, Wenjun Zhang, Tony Quek
Abstract: Existing semantic communication schemes primarily focus on single-hop scenarios, overlooking the challenges of multi-hop wireless image transmission. As semantic communication is inherently lossy, distortion accumulates over multiple hops, leading to significant performance degradation. To address this, we propose the multi-hop parallel image semantic communication (MHPSC) framework, which introduces a parallel residual compensation link at each hop against distortion accumulation. To minimize the associated transmission bandwidth overhead, a coarse-to-fine residual compression scheme is designed. A deep learning-based residual compressor first condenses the residuals, followed by the adaptive arithmetic coding (AAC) for further compression. A residual distribution estimation module predicts the prior distribution for the AAC to achieve fine compression performances. This approach ensures robust multi-hop image transmission with only a minor increase in transmission bandwidth. Experimental results confirm that MHPSC outperforms both existing semantic communication and traditional separated coding schemes.

Paper number 46:
Title: Electromagnetic Investigation of Crosstalk in Bent Microstrip Lines with Partial and Apertured Shielding: Simulations and Measurements
Authors: Mohammad Eskandari, Mojtaba Joodaki
Abstract: This paper presents an electromagnetic investigation of the crosstalk between two bent microstrip lines (MLs) separated by a perforated planar shield. As an extension of our previous study, the effects of various discontinuities in either the MLs or the shield along the coupling path are analyzed through numerical simulations and validated by measurements. The underlying electromagnetic mechanisms are also discussed. Furthermore, multimodal wave theory in a rectangular waveguide is applied to predict crosstalk behavior when the shield contains an aperture. This study aims to conceptually elucidate complex crosstalk phenomena that are difficult to model using circuit theory, and successful predictions of crosstalk behavior are presented for different problem cases.

Paper number 47:
Title: Finite Sample MIMO System Identification with Multisine Excitation: Nonparametric, Direct, and Two-step Parametric Estimators
Authors: Rodrigo A. González, Koen Classens, Cristian R. Rojas, Tom Oomen, Håkan Hjalmarsson
Abstract: Multisine excitations are widely used for identifying multi-input multi-output systems due to their periodicity, data compression properties, and control over the input spectrum. Despite their popularity, the finite sample statistical properties of frequency-domain estimators under multisine excitation, for both nonparametric and parametric settings, remain insufficiently understood. This paper develops a finite-sample statistical framework for least-squares estimation of the frequency response function (FRF) and its implications for parametric modeling. First, we derive exact distributional and covariance properties of the FRF estimator, explicitly accounting for aliasing effects under slow sampling regimes, and establish conditions for unbiasedness, uncorrelatedness, and consistency across multiple experiments. Second, we show that the FRF estimate is a sufficient statistic for any parametric model under Gaussian noise, leading to an exact equivalence between optimal two stage frequency-domain methods and time-domain prediction error and maximum likelihood estimation. This equivalence is shown to yield finite-sample concentration bounds for parametric maximum likelihood estimators, enabling rigorous uncertainty quantification, and closed-form prediction error method estimators without iterative optimization. The theoretical results are demonstrated in a representative case study.

Paper number 48:
Title: SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions
Authors: Md. Mehedi Hassan, Shafqat Alam, Shahriar Ahmed Seam, Maruf Ahmed
Abstract: Automated segmentation of heterogeneous brain lesions from multi-modal MRI remains a critical challenge in clinical neuroimaging. Current deep learning models are typically specialized `point solutions' that lack generalization and high performance variance, limiting their clinical reliability. To address these gaps, we propose the Unified Multi-Stream SYNAPSE-Net, an adaptive framework designed for both generalization and robustness. The framework is built on a novel hybrid architecture integrating multi-stream CNN encoders, a Swin Transformer bottleneck for global context, a dynamic cross-modal attention fusion (CMAF) mechanism, and a hierarchical gated decoder for high-fidelity mask reconstruction. The architecture is trained with a variance reduction strategy that combines pathology specific data augmentation and difficulty-aware sampling method. The model was evaluated on three different challenging public datasets: the MICCAI 2017 WMH Challenge, the ISLES 2022 Challenge, and the BraTS 2020 Challenge. Our framework attained a state-of-the-art DSC value of 0.831 with the HD95 value of 3.03 in the WMH dataset. For ISLES 2022, it achieved the best boundary accuracy with a statistically significant difference (HD95 value of 9.69). For BraTS 2020, it reached the highest DSC value for the tumor core region (0.8651). These experimental findings suggest that our unified adaptive framework achieves state-of-the-art performance across multiple brain pathologies, providing a robust and clinically feasible solution for automated segmentation. The source code and the pre-trained models are available at this https URL.

Paper number 49:
Title: Practical Timing Closure in FPGA and ASIC Designs: Methods, Challenges, and Case Studies
Authors: Mostafa Darvishi
Abstract: This paper presents an in-depth analysis of timing closure challenges and constraints in Field Programmable Gate Arrays (FPGAs) and Application Specific Integrated Circuits (ASICs). We examine core timing principles, architectural distinctions, and design methodologies influencing timing behavior in both technologies. A case study comparing the Xilinx Kintex UltraScale+ FPGA (XCKU040) with a 7nm ASIC highlights practical timing analysis and performance trade-offs. Experimental results show ASICs achieve superior timing of 45ps setup and 35ps hold, while modern FPGAs remain competitive with 180ps setup and 120ps hold times, validating their suitability for high-performance designs.

Paper number 50:
Title: SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation
Authors: Agorakis Bompotas, Konstantinos Koutras, Nikitas Rigas Kalogeropoulos, Panagiotis Kechagias, Dimitra Gariza, Athanasios P. Kalogeras, Christos Alexakos
Abstract: The global agricultural sector is undergoing a transformative shift, driven by increasing food demands, climate variability and the need for sustainable practices. SUSTAINABLE is a smart farming platform designed to integrate IoT, AI, satellite imaging, and role-based task orchestration to enable efficient, traceable, and sustainable agriculture with a pilot usecase in viticulture. This paper explores current smart agriculture solutions, presents a comparative evaluation, and introduces SUSTAINABLE's key features, including satellite index integration, real-time environmental data, and role-aware task management tailored to Mediterranean vineyards.

Paper number 51:
Title: Functional embeddings enable Aggregation of multi-area SEEG recordings over subjects and sessions
Authors: Sina Javadzadeh, Rahil Soroushmojdehi, S. Alireza Seyyed Mousavi, Mehrnaz Asadi, Sumiko Abe, Terence D. Sanger
Abstract: Aggregating intracranial recordings across subjects is challenging since electrode count, placement, and covered regions vary widely. Spatial normalization methods like MNI coordinates offer a shared anatomical reference, but often fail to capture true functional similarity, particularly when localization is imprecise; even at matched anatomical coordinates, the targeted brain region and underlying neural dynamics can differ substantially between individuals. We propose a scalable representation-learning framework that (i) learns a subject-agnostic functional identity for each electrode from multi-region local field potentials using a Siamese encoder with contrastive objectives, inducing an embedding geometry that is locality-sensitive to region-specific neural signatures, and (ii) tokenizes these embeddings for a transformer that models inter-regional relationships with a variable number of channels. We evaluate this framework on a 20-subject dataset spanning basal ganglia-thalamic regions collected during flexible rest/movement recording sessions with heterogeneous electrode layouts. The learned functional space supports accurate within-subject discrimination and forms clear, region-consistent clusters; it transfers zero-shot to unseen channels. The transformer, operating on functional tokens without subject-specific heads or supervision, captures cross-region dependencies and enables reconstruction of masked channels, providing a subject-agnostic backbone for downstream decoding. Together, these results indicate a path toward large-scale, cross-subject aggregation and pretraining for intracranial neural data where strict task structure and uniform sensor placement are unavailable.

Paper number 52:
Title: Expressive Range Characterization of Open Text-to-Audio Models
Authors: Jonathan Morse, Azadeh Naderi, Swen Gaudl, Mark Cartwright, Amy K. Hoover, Mark J. Nelson
Abstract: Text-to-audio models are a type of generative model that produces audio output in response to a given textual prompt. Although level generators and the properties of the functional content that they create (e.g., playability) dominate most discourse in procedurally generated content (PCG), games that emotionally resonate with players tend to weave together a range of creative and multimodal content (e.g., music, sounds, visuals, narrative tone), and multimodal models have begun seeing at least experimental use for this purpose. However, it remains unclear what exactly such models generate, and with what degree of variability and fidelity: audio is an extremely broad class of output for a generative system to target. Within the PCG community, expressive range analysis (ERA) has been used as a quantitative way to characterize generators' output space, especially for level generators. This paper adapts ERA to text-to-audio models, making the analysis tractable by looking at the expressive range of outputs for specific, fixed prompts. Experiments are conducted by prompting the models with several standardized prompts derived from the Environmental Sound Classification (ESC-50) dataset. The resulting audio is analyzed along key acoustic dimensions (e.g., pitch, loudness, and timbre). More broadly, this paper offers a framework for ERA-based exploratory evaluation of generative audio models.

Paper number 53:
Title: Analytical Model of NR-V2X Mode 2 with Re-Evaluation Mechanism
Authors: Shuo Zhu, Siyu Lin
Abstract: Massive message transmissions, unpredictable aperiodic messages, and high-speed moving vehicles contribute to the complex wireless environment, resulting in inefficient resource collisions in Vehicle to Everything (V2X). In order to achieve better medium access control (MAC) layer performance, 3GPP introduced several new features in NR-V2X. One of the most important is the re-evaluation mechanism. It allows the vehicle to continuously sense resources before message transmission to avoid resource collisions. So far, only a few articles have studied the re-evaluation mechanism of NR-V2X, and they mainly focus on network simulator that do not consider variable traffic, which makes analysis and comparison difficult. In this paper, an analytical model of NR-V2X Mode 2 is established, and a message generator is constructed by using discrete time Markov chain (DTMC) to simulate the traffic pattern recommended by 3GPP advanced V2X services. Our study shows that the re-evaluation mechanism improves the reliability of NR-V2X transmission, but there are still local improvements needed to reduce latency.

Paper number 54:
Title: Nonasymptotic Convergence Rates for Plug-and-Play Methods With MMSE Denoisers
Authors: Henry Pritchard, Rahul Parhi
Abstract: It is known that the minimum-mean-squared-error (MMSE) denoiser under Gaussian noise can be written as a proximal operator, which suffices for asymptotic convergence of plug-and-play (PnP) methods but does not reveal the structure of the induced regularizer or give convergence rates. We show that the MMSE denoiser corresponds to a regularizer that can be written explicitly as an upper Moreau envelope of the negative log-marginal density, which in turn implies that the regularizer is 1-weakly convex. Using this property, we derive (to the best of our knowledge) the first sublinear convergence guarantee for PnP proximal gradient descent with an MMSE denoiser. We validate the theory with a one-dimensional synthetic study that recovers the implicit regularizer. We also validate the theory with imaging experiments (deblurring and computed tomography), which exhibit the predicted sublinear behavior.

Paper number 55:
Title: Value of Multi-pursuer Single-evader Pursuit-evasion Game with Terminal Cost of Evader's Position: Relaxation of Convexity Condition
Authors: Weiwen Huang, Li Liang, Ningsheng Xu, Fang Deng
Abstract: In this study, we consider a multi-pursuer single-evader quantitative pursuit-evasion game with payoff function that includes only the terminal cost. The terminal cost is a function related only to the terminal position of the evader. This problem has been extensively studied in target defense games. Here, we prove that a candidate for the value function generated by geometric method is the viscosity solution of the corresponding Hamilton-Jacobi-Isaacs partial differential equation (HJI PDE) Dirichlet problem. Therefore, the value function of the game at each point can be computed by a mathematical program. In our work, the convexity of the terminal cost or the target is not required. The terminal cost only needs to be locally Lipschitz continuous. The cases in which the terminal costs or the targets are not convex are covered. Therefore, our result is more universal than those of previous studies, and the complexity of the proof is improved. We also discuss the optimal strategies in this game and present an intuitive explanation of this value function.

Paper number 56:
Title: Inferring trust in recommendation systems from brain, behavioural, and physiological data
Authors: Vincent K.M. Cheung, Pei-Cheng Shih, Masato Hirano, Masataka Goto, Shinichi Furuya
Abstract: As people nowadays increasingly rely on artificial intelligence (AI) to curate information and make decisions, assigning the appropriate amount of trust in automated intelligent systems has become ever more important. However, current measurements of trust in automation still largely rely on self-reports that are subjective and disruptive to the user. Here, we take music recommendation as a model to investigate the neural and cognitive processes underlying trust in automation. We observed that system accuracy was directly related to users' trust and modulated the influence of recommendation cues on music preference. Modelling users' reward encoding process with a reinforcement learning model further revealed that system accuracy, expected reward, and prediction error were related to oscillatory neural activity recorded via EEG and changes in pupil diameter. Our results provide a neurally grounded account of calibrating trust in automation and highlight the promises of a multimodal approach towards developing trustable AI systems.

Paper number 57:
Title: Risk-constrained stochastic scheduling of multi-market energy storage systems
Authors: Gabriel D. Patrón, Di Zhang, Lavinia M.P. Ghilardi, Evelin Blom, Maldon Goodridge, Erik Solis, Hamidreza Jahangir, Jorge Angarita, Nandhini Ganesan, Kevin West, Nilay Shah, Calvin Tsay
Abstract: Energy storage can promote the integration of renewables by operating with charge and discharge policies that balance an intermittent power supply. This study investigates the scheduling of energy storage assets under energy price uncertainty, with a focus on electricity markets. A two-stage stochastic risk-constrained approach is employed, whereby electricity price trajectories or specific power markets are observed, allowing for recourse in the schedule. Conditional value-at-risk is used to quantify tail risk in the optimization problems; this allows for the explicit specification of a probabilistic risk limit. The proposed approach is tested in an integrated hydrogen system (IHS) and a battery energy storage system (BESS). In the joint design and operation context for the IHS, the risk constraint results in larger installed unit capacities, increasing capital cost but enabling more energy inventory to buffer price uncertainty. As shown in both case studies, there is an operational trade-off between risk and expected reward; this is reflected in higher expected costs (or lower expected profits) with increasing levels of risk aversion. Despite the decrease in expected reward, both systems exhibit substantial benefits of increasing risk aversion. This work provides a general method to address uncertainties in energy storage scheduling, allowing operators to input their level of risk tolerance on asset decisions.

Paper number 58:
Title: SpecAttn: Speculating Sparse Attention
Authors: Harsh Shah
Abstract: Large Language Models (LLMs) face significant computational bottlenecks during inference due to the quadratic complexity of self-attention mechanisms, particularly as context lengths increase. We introduce SpecAttn, a novel training-free approach that seamlessly integrates with existing speculative decoding techniques to enable efficient sparse attention in pre-trained transformers. Our key insight is to exploit the attention weights already computed by the draft model during speculative decoding to identify important tokens for the target model, eliminating redundant computation while maintaining output quality. SpecAttn employs three core techniques: KL divergence-based layer alignment between draft and target models, a GPU-optimized sorting-free algorithm for top-p token selection from draft attention patterns, and dynamic key-value cache pruning guided by these predictions. By leveraging the computational work already performed in standard speculative decoding pipelines, SpecAttn achieves over 75% reduction in key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19 dataset, significantly outperforming existing sparse attention methods. Our approach demonstrates that speculative execution can be enhanced to provide approximate verification without significant performance degradation.

Paper number 59:
Title: Dark-Field X-Ray Imaging Significantly Improves Deep-Learning based Detection of Synthetic Early-Stage Lung Tumors in Preclinical Models
Authors: Joyoni Dey, Hunter C. Meyer, Murtuza S. Taqi
Abstract: Low-dose computed tomography (LDCT) is the current standard for lung cancer screening, yet its adoption and accessibility remain limited. Many regions lack LDCT infrastructure, and even among those screened, early-stage cancer detection often yield false positives, as shown in the National Lung Screening Trial (NLST) with a sensitivity of 93.8 percent and a false-positive rate of 26.6 percent. We aim to investigate whether X-ray dark-field imaging (DFI) radiograph, a technique sensitive to small-angle scatter from alveolar microstructure and less susceptible to organ shadowing, can significantly improve early-stage lung tumor detection when coupled with deep-learning segmentation. Using paired attenuation (ATTN) and DFI radiograph images of euthanized mouse lungs, we generated realistic synthetic tumors with irregular boundaries and intensity profiles consistent with physical lung contrast. A U-Net segmentation network was trained on small patches using either ATTN, DFI, or a combination of ATTN and DFI this http URL show that the DFI-only model achieved a true-positive detection rate of 83.7 percent, compared with 51 percent for ATTN-only, while maintaining comparable specificity (90.5 versus 92.9 percent). The combined ATTN and DFI input achieved 79.6 percent sensitivity and 97.6 percent specificity. In conclusion, DFI substantially improves early-tumor detectability in comparison to standard attenuation radiography and shows potential as an accessible, low-cost, low-dose alternative for pre-clinical or limited-resource screening where LDCT is unavailable.

Paper number 60:
Title: Privacy Preservation by Local Design in Cooperative Networked Control Systems
Authors: Chao Yang, Yuqing Ni, Wen Yang, Hongbo Shi
Abstract: In this paper, we study the privacy preservation problem in a cooperative networked control system, which has closed-loop dynamics, working for the task of linear quadratic Guassian (LQG) control. The system consists of a user and a server: the user owns the plant to control, while the server provides computation capability, and the user employs the server to compute control inputs for it. To enable the server's computation, the user needs to provide the measurements of the plant states to the server, who then calculates estimates of the states, based on which the control inputs are computed. However, the user regards the states as privacy, and makes an interesting request: the user wants the server to have "incorrect" knowledge of the state estimates rather than the true values. Regarding that, we propose a novel design methodology for the privacy preservation, in which the privacy scheme is locally equipped at the user side not open to the server, which manages to create a deviation in the server's knowledge of the state estimates from the true values. However, this methodology also raises significant challenges: in a closed-loop dynamic system, when the server's seized knowledge is incorrect, the system's behavior becomes complex to analyze; even the stability of the system becomes questionable, as the incorrectness will accumulate through the closed loop as time evolves. In this paper, we succeed in showing that the performance loss in LQG control caused by the proposed privacy scheme is bounded by rigorous mathematical proofs, which convinces the availability of the proposed design methodology. We also propose an associated novel privacy metric and obtain the analytical result on evaluating the privacy performance. Finally, we study the performance trade-off between privacy and control, where the accordingly proposed optimization problems are solved by numerical methods efficiently.

Paper number 61:
Title: On the Detection of Shared Data Manipulation in Distributed Optimization
Authors: Mohannad Alkhraijah, Rachel Harris, Samuel Litchfield, David Huggins, Daniel K. Molzahn
Abstract: This paper investigates the vulnerability of the Alternating Direction Method of Multipliers (ADMM) algorithm to shared data manipulation, with a focus on solving optimal power flow (OPF) problems. Deliberate data manipulation may cause the ADMM algorithm to converge to suboptimal solutions. We derive a sufficient condition for detecting data manipulation based on the theoretical convergence trajectory of the ADMM algorithm. We evaluate the performance of the detection condition on three data manipulation strategies with various levels of complexity and stealth. The simplest attack sends the target values and each iteration, the second attack uses a feedback loop to find the next target values, and the last attack uses a bilevel optimization to find the target values. We then extend the three data manipulation strategies to avoid detection by the detection conditions and a neural network (NN) detection model. We also propose an adversarial NN training framework to detect shared data manipulation. We illustrate the performance of our data manipulation strategy and detection framework on OPF problems. The results show that the proposed detection condition successfully detects most of the data manipulation attacks. However, the bilevel optimization attack strategy that incorporates the detection methods may avoid being detected. Countering this, our proposed adversarial training framework detects all the instances of the bilevel optimization attack.

Paper number 62:
Title: ESTformer: Transformer utilising spatiotemporal dependencies for electroencephalogram super-resolution
Authors: Dongdong Li, Zhongliang Zeng, Zhe Wang, Hai Yang
Abstract: Towards practical applications of Electroencephalography (EEG), lightweight acquisition devices garner significant attention. However, EEG channel selection methods are commonly data-sensitive and cannot establish a unified sound paradigm for EEG acquisition devices. Through reverse conceptualisation, we formulated EEG applications in an EEG super-resolution (SR) manner, but suffered from high computation costs, extra interpolation bias, and few insights into spatiotemporal dependency modelling. To this end, we propose ESTformer, an EEG SR framework that utilises spatiotemporal dependencies based on the transformer. ESTformer applies positional encoding methods and a multihead self-attention mechanism to the space and time dimensions, which can learn spatial structural correlations and temporal functional variations. ESTformer, with the fixed mask strategy, adopts a mask token to upsample low-resolution (LR) EEG data in the case of disturbance from mathematical interpolation methods. On this basis, we designed various transformer blocks to construct a spatial interpolation module (SIM) and a temporal reconstruction module (TRM). Finally, ESTformer cascades the SIM and TRM to capture and model the spatiotemporal dependencies for EEG SR with fidelity. Extensive experimental results on two EEG datasets show the effectiveness of ESTformer against previous state-of-the-art methods, demonstrating the versatility of the Transformer for EEG SR tasks. The superiority of the SR data was verified in an EEG-based person identification and emotion recognition task, achieving a 2% to 38% improvement compared with the LR data at different sampling scales.

Paper number 63:
Title: FAST: Flexible and Adaptive Semantic Transmission for Resource-constrained Multi-user Generative Semantic Communication
Authors: Yiru Wang, Wanting Yang, Fangli Mou, Zehui Xiong, Zide Fan, Shiwen Mao, Tony Q. S. Quek
Abstract: The rapid advancement of generative artificial intelligence has spurred innovative approaches to semantic communication, giving rise to a new paradigm known as generative semantic communication (GSC). The integration of flexible cross-modal semantic extraction with generative capability-driven semantic inference substantially enhances semantic compression efficiency, demonstrating significant promise under communication resource constraints. Nonetheless, the stringent dependence on high computational power and the resulting latency continue to present major challenges, thereby limiting the feasibility of large-scale deployment. To address these challenges, we propose a novel GSC framework named FAST, which stands for flexible and adaptive semantic transmission. To accommodate limited computational resources, we propose a sequential semantic extraction method, where a temporal prompt engineering module orchestrates the distillation and transmission of key semantic units. Correspondingly, we introduce a sequential conditional denoising module at the receiver, which adapts the diffusion-based reconstruction to the progressively received input. To enhance overall task performance in multi-user semantic transmission, we propose a semantic-aware resource allocation method that optimizes bandwidth dynamically based on a joint consideration of semantic dependencies, user-level task priorities, and instantaneous channel conditions. Extensive experiments demonstrate that the proposed architecture achieves system precision comparable to conventional GSC systems while significantly reducing transmission latency and improving overall efficiency. These results confirm its enhanced potential for deployment in multi-user GSC scenarios with stringent communication and computational constraints.

Paper number 64:
Title: Prescribed-Time Convergent Distributed Multiobjective Optimization With Dynamic Event-Triggered Communication
Authors: Tengyang Gong, Zhongguo Li, Yiqiao Xu, Zhengtao Ding
Abstract: This paper addresses distributed constrained multiobjective resource allocation problems (DCMRAPs) in multi-agent networks, where agents face multiple conflicting local objectives under local and global constraints. By reformulating DCMRAPs as single-objective weighted $L_p$ problems, the proposed approach enables distributed solutions without relying on predefined weighting coefficients or centralized decision-making. Leveraging prescribed-time control and dynamic event-triggered mechanisms (ETMs), a novel distributed algorithm is proposed within a prescribed time through sampled communication. Using generalized time-based generators (TBGs), the algorithm provides more flexibility in optimizing solution accuracy and trajectory smoothness without the constraints of initial conditions. Novel dynamic ETMs, integrated with generalized TBGs, improve communication efficiency by adapting to local error metrics and network-based disagreements, while providing enhanced flexibility in balancing solution accuracy and communication frequency. The Zeno behavior is excluded. Validated by Lyapunov analysis and simulation experiments, our method demonstrates superior control performance and efficiency compared to existing methods, advancing distributed optimization across diverse applications.

Paper number 65:
Title: LV-UNet: A Lightweight and Vanilla Model for Medical Image Segmentation
Authors: Juntao Jiang, Mengmeng Wang, Huizhong Tian, Lingbo Cheng, Yong Liu
Abstract: While large models have achieved significant progress in computer vision, challenges such as optimization complexity, the intricacy of transformer architectures, computational constraints, and practical application demands highlight the importance of simpler model designs in medical image segmentation. This need is particularly pronounced in mobile medical devices, which require lightweight, deployable models with real-time performance. However, existing lightweight models often suffer from poor robustness across datasets, limiting their widespread adoption. To address these challenges, this paper introduces LV-UNet, a lightweight and vanilla model that leverages pre-trained MobileNetv3-Large backbones and incorporates fusible modules. LV-UNet employs an enhanced deep training strategy and switches to a deployment mode during inference by re-parametrization, significantly reducing parameter count and computational overhead. Experimental results on ISIC 2016, BUSI, CVC-ClinicDB, CVC-ColonDB, and Kvair-SEG datasets demonstrate a better trade-off between performance and the computational load. The code will be released at this https URL.

Paper number 66:
Title: Downlink Performance of Cell-Free Massive MIMO for LEO Satellite Mega-Constellation
Authors: Xiangyu Li, Bodong Shang
Abstract: Low-earth orbit (LEO) satellite communication (SatCom) has emerged as a promising technology to improve wireless connectivity in global areas. Cell-free massive multiple-input multiple-output (CF-mMIMO), an architecture proposed for next-generation networks, has yet to be fully explored for LEO satellites. In this paper, we investigate the downlink performance of a CF-mMIMO LEO SatCom network, where multiple satellite access points (SAPs) simultaneously serve the corresponding ground user terminals (UTs). Using tools from stochastic geometry, we model the locations of SAPs and UTs on surfaces of concentric spheres using Poisson point processes (PPPs) and present expressions on transmit and received signals, signal-to-interference-plus-noise ratio (SINR). Then, we derive the coverage probabilities in fading scenarios, considering significant system parameters such as the Nakagami fading parameter, the number of UTs, the number of SAPs, the orbital altitude, and the service range affected by the dome angle. Finally, the analytical model is verified by extensive Monte Carlo simulations. Simulation results indicate that stronger line-of-sight (LoS) effects and a more comprehensive service range of the UT result in a higher coverage probability, despite the presence of multi-user interference (MUI). Moreover, we found that there exist optimal numbers of UTs that maximize system capacity for different orbital altitudes and dome angles, providing valuable insights for system design.

Paper number 67:
Title: Kernel Mean Embedding Topology: Weak and Strong Forms for Stochastic Kernels and Implications for Model Learning
Authors: Naci Saldi, Serdar Yuksel
Abstract: We introduce a novel topology, called Kernel Mean Embedding Topology, for stochastic kernels, in a weak and strong form. This topology, defined on the spaces of Bochner integrable functions from a signal space to a space of probability measures endowed with a Hilbert space structure, allows for a versatile formulation. This construction allows one to obtain both a strong and weak formulation. (i) For its weak formulation, we highlight the utility on relaxed policy spaces, and investigate connections with the Young narrow topology and Borkar (or \( w^* \))-topology, and establish equivalence properties. We report that, while both the \( w^* \)-topology and kernel mean embedding topology are relatively compact, they are not closed. Conversely, while the Young narrow topology is closed, it lacks relative compactness. (ii) We show that the strong form provides an appropriate formulation for placing topologies on spaces of models characterized by stochastic kernels with explicit robustness and learning theoretic implications on optimal stochastic control under discounted or average cost criteria. (iii) We thus show that this topology possesses several properties making it ideal to study optimality and approximations (under the weak formulation) and robustness (under the strong formulation) for many applications.

Paper number 68:
Title: On-device Computation of Single-lead ECG Parameters for Real-time Remote Cardiac Health Assessment: A Real-world Validation Study
Authors: Sumei Fan, Deyun Zhang, Yue Wang, Shijia Geng, Kun Lu, Meng Sang, Weilun Xu, Haixue Wang, Qinghao Zhao, Chuandong Cheng, Peng Wang, Shenda Hong
Abstract: Accurate, continuous out-of-hospital electrocardiogram (ECG) parameter measurement is vital for real-time cardiac health monitoring and telemedicine. On-device computation of single-lead ECG parameters enables timely assessment without reliance on centralized data processing, advancing personalized, ubiquitous cardiac care-yet comprehensive validation across heterogeneous real-world populations remains limited. This study validated the on-device algorithm FeatureDB (this https URL) using two datasets: HeartVoice-ECG-lite (369 participants with single-lead ECGs annotated by two physicians) and PTB-XL/PTB-XL+ (21,354 patients with 12-lead ECGs and physicians' diagnostic annotations). FeatureDB computed PR, QT, and QTc intervals, with accuracy evaluated against physician annotations via mean absolute error (MAE), correlation analysis, and Bland-Altman analysis. Diagnostic performance for first-degree atrioventricular block (AVBI, PR-based) and long QT syndrome (LQT, QTc-based) was benchmarked against commercial 12-lead systems (12SL, Uni-G) and open-source algorithm Deli, using AUC, accuracy, sensitivity, and specificity. Results showed high concordance with expert annotations (Pearson correlations: 0.836-0.960), MAEs matching inter-observer variability, and minimal bias. AVBI AUC reached 0.787 (12SL: 0.859; Uni-G: 0.812; Deli: 0.501); LQT AUC was 0.684 (12SL: 0.716; Uni-G: 0.605; Deli: 0.569)-comparable to commercial tools and superior to open-source alternatives. FeatureDB delivers physician-level parameter accuracy and commercial-grade abnormality detection via single-lead devices, supporting scalable telemedicine, decentralized cardiac screening, and continuous monitoring in community and outpatient settings.

Paper number 69:
Title: Augmented Reality-based Guidance with Deformable Registration in Head and Neck Tumor Resection
Authors: Qingyun Yang, Fangjie Li, Jiayi Xu, Zixuan Liu, Sindhura Sridhar, Whitney Jin, Jennifer Du, Jon Heiselman, Michael Miga, Michael Topf, Jie Ying Wu
Abstract: Head and neck squamous cell carcinoma (HNSCC) has one of the highest rates of recurrence cases among solid malignancies. Recurrence rates can be reduced by improving positive margins localization. Frozen section analysis (FSA) of resected specimens is the gold standard for intraoperative margin assessment. However, because of the complex 3D anatomy and the significant shrinkage of resected specimens, accurate margin relocation from specimen back onto the resection site based on FSA results remains challenging. We propose a novel deformable registration framework that uses both the pre-resection upper surface and the post-resection site of the specimen to incorporate thickness information into the registration process. The proposed method significantly improves target registration error (TRE), demonstrating enhanced adaptability to thicker specimens. In tongue specimens, the proposed framework improved TRE by up to 33% as compared to prior deformable registration. Notably, tongue specimens exhibit complex 3D anatomies and hold the highest clinical significance compared to other head and neck specimens from the buccal and skin. We analyzed distinct deformation behaviors in different specimens, highlighting the need for tailored deformation strategies. To further aid intraoperative visualization, we also integrated this framework with an augmented reality-based auto-alignment system. The combined system can accurately and automatically overlay the deformed 3D specimen mesh with positive margin annotation onto the resection site. With a pilot study of the AR guided framework involving two surgeons, the integrated system improved the surgeons' average target relocation error from 9.8 cm to 4.8 cm.

Paper number 70:
Title: Is Limited Participant Diversity Impeding EEG-based Machine Learning?
Authors: Philipp Bomatter, Henry Gouk
Abstract: The application of machine learning (ML) to electroencephalography (EEG) has great potential to advance both neuroscientific research and clinical applications. However, the generalisability and robustness of EEG-based ML models often hinge on the amount and diversity of training data. It is common practice to split EEG recordings into small segments, thereby increasing the number of samples substantially compared to the number of individual recordings or participants. We conceptualise this as a multi-level data generation process and investigate the scaling behaviour of model performance with respect to the overall sample size and the participant diversity through large-scale empirical studies. We then use the same framework to investigate the effectiveness of different ML strategies designed to address limited data problems: data augmentations and self-supervised learning. Our findings show that model performance scaling can be severely constrained by participant distribution shifts and provide actionable guidance for data collection and ML research. The code for our experiments is publicly available online.

Paper number 71:
Title: Climate Science and Control Engineering: Insights, Parallels, and Connections
Authors: Salma M. Elsherif, Ahmad F. Taha
Abstract: Climate science is the multidisciplinary field that studies the Earth's climate and its evolution. At the very core of climate science are indispensable climate models that predict future climate scenarios, inform policy decisions, and dictate how a country's economy should change in light of the changing climate. Climate models capture a wide range of interacting dynamic processes via extremely complex ordinary and partial differential equations. To model these large-scale complex processes, climate science leverages supercomputers, advanced simulations, and statistical methods to predict future climate. An area of engineering that is rarely studied in climate science is control engineering. Given that climate systems are inherently dynamic, it is intuitive to analyze them within the framework of dynamic system science. This perspective has been underexplored in the literature. In this manuscript, we provide a tutorial that: (i) introduces the control engineering community to climate dynamics and modeling, including spatiotemporal scales and challenges in climate modeling; (ii) offers a fresh perspective on climate models from a control systems viewpoint; and (iii) explores the relevance and applicability of various advanced graph and network control-based approaches in building a physics-informed framework for learning, control and estimation in climate systems. We also present simple and then more complex climate models, depicting fundamental ideas and processes that are instrumental in building climate change projections. This tutorial also builds parallels and observes connections between various contemporary problems at the forefront of climate science and their control theoretic counterparts. We specifically observe that an abundance of climate science problems can be linguistically reworded and mathematically framed as control theoretic ones.

Paper number 72:
Title: Highly Undersampled MRI Reconstruction via a Single Posterior Sampling of Diffusion Models
Authors: Jin Liu, Qing Lin, Zhuang Xiong, Shanshan Shan, Chunyi Liu, Min Li, Feng Liu, G. Bruce Pike, Hongfu Sun, Yang Gao
Abstract: Incoherent k-space undersampling and deep learning-based reconstruction methods have shown great success in accelerating MRI. However, the performance of most previous methods will degrade dramatically under high acceleration factors, e.g., 8$\times$ or higher. Recently, denoising diffusion models (DM) have demonstrated promising results in solving this issue; however, one major drawback of the DM methods is the long inference time due to a dramatic number of iterative reverse posterior sampling steps. In this work, a Single Step Diffusion Model-based reconstruction framework, namely SSDM-MRI, is proposed for restoring MRI images from highly undersampled k-space. The proposed method achieves one-step reconstruction by first training a conditional DM and then iteratively distilling this model four times using an iterative selective distillation algorithm, which works synergistically with a shortcut reverse sampling strategy for model inference. Comprehensive experiments were carried out on both publicly available fastMRI brain and knee images, as well as an in-house multi-echo GRE (QSM) subject. Overall, the results showed that SSDM-MRI outperformed other methods in terms of numerical metrics (e.g., PSNR and SSIM), error maps, image fine details, and latent susceptibility information hidden in MRI phase images. In addition, the reconstruction time for a 320$\times$320 brain slice of SSDM-MRI is only 0.45 second, which is only comparable to that of a simple U-net, making it a highly effective solution for MRI reconstruction tasks.

Paper number 73:
Title: Partitioning and Observability in Linear Systems via Submodular Optimization
Authors: Mohamad H. Kazma, Ahmad F. Taha
Abstract: Network partitioning has gained recent attention as a pathway to enable decentralized operation and control in large-scale systems. This paper addresses the interplay between partitioning, observability, and sensor placement (SP) in dynamic networks. The problem, being computationally intractable at scale, is a largely unexplored, open problem in the literature. To that end, the paper's objective is designing scalable partitioning of linear systems while maximizing observability metrics of the subsystems. We show that the partitioning problem can be posed as a submodular maximization problem -- and the SP problem can subsequently be solved over the partitioned network. Consequently, theoretical bounds are derived to compare observability metrics of the original network with those of the resulting partitions, highlighting the impact of partitioning on system observability. Case studies on networks of varying sizes corroborate the derived theoretical bounds.

Paper number 74:
Title: Faulty RIS-aided Integrated Sensing and Communication: Modeling and Optimization
Authors: Lu Wang, Gui Zhou, Changheng Li, Luis F. Abanto-Leon, Nairy Moghadas Gholian, Matthias Hollick, Arash Asadi
Abstract: This work investigates a practical reconfigurable intelligent surface (RIS)-aided integrated sensing and communication (ISAC) system, where a subset of RIS elements fail to function properly and reflect incident signals randomly towards unintended directions, thereby degrading system performance. To date, no study has addressed such impairments caused by faulty RIS elements in ISAC systems. This work aims to fill the gap. First, to quantify the impact of faulty elements on ISAC performance, we derive the misspecified Cramér-Rao bound (MCRB) for sensing parameter estimation and signal-to-interference-and-noise ratio (SINR) for communication quality. Then, to mitigate the performance loss caused by faulty elements, we jointly design the remaining functional RIS phase shifts and transmit beamforming to minimize the MCRB, subject to the communication SINR and transmit power constraints. The resulting optimization problem is highly non-convex due to the intricate structure of the MCRB expression and constant-modulus constraint imposed on RIS. To address this, we reformulate it into a more tractable form and propose a block coordinate descent (BCD) algorithm that incorporates majorization-minimization (MM), successive convex approximation (SCA), and penalization techniques. Simulation results demonstrate that our proposed approach reduces the MCRB performance loss by 21.25% on average compared to the case where the presence of faulty elements is ignored. Furthermore, the performance gain becomes more evident as the number of faulty elements increases.

Paper number 75:
Title: Poisson Informed Retinex Network for Extreme Low-Light Image Enhancement
Authors: Isha Rao, Ratul Chakraborty, Sanjay Ghosh
Abstract: Low-light image denoising and enhancement are challenging, especially when traditional noise assumptions, such as Gaussian noise, do not hold in majority. In many real-world scenarios, such as low-light imaging, noise is signal-dependent and is better represented as Poisson noise. In this work, we address the problem of denoising images degraded by Poisson noise under extreme low-light conditions. We introduce a light-weight deep learning-based method that integrates Retinex based decomposition with Poisson denoising into a unified encoder-decoder network. The model simultaneously enhances illumination and suppresses noise by incorporating a Poisson denoising loss to address signal-dependent noise. Without prior requirement for reflectance and illumination, the network learns an effective decomposition process while ensuring consistent reflectance and smooth illumination without causing any form of color distortion. The experimental results demonstrate the effectiveness and practicality of the proposed low-light illumination enhancement method. Our method significantly improves visibility and brightness in low-light conditions, while preserving image structure and color constancy under ambient illumination.

Paper number 76:
Title: Near-Field SWIPT with gMIMO in the Upper Mid-Band: Opportunities, Challenges, and the Way Forward
Authors: Özlem Tugfe Demir, Mustafa Ozger, Ferdi Kara, Woong-Hee Lee, Emil Björnson
Abstract: This paper explores the integration of simultaneous wireless information and power transfer (SWIPT) with gigantic multiple-input multiple-output (gMIMO) technology operating in the upper mid-band frequency range (7-24 GHz). The near-field propagation achieved by gMIMO introduces unique opportunities for energy-efficient, high-capacity communication systems that cater to the demands of 6G wireless networks. Exploiting spherical wave propagation, near-field SWIPT with gMIMO enables precise energy and data delivery, enhancing spectral efficiency through beam focusing and massive spatial multiplexing. This paper discusses theoretical principles, design challenges, and enabling solutions, including advanced channel estimation techniques, precoding strategies, and dynamic array configurations such as sparse and modular arrays. Through analytical insights and a case study, this paper demonstrates the feasibility of achieving optimized energy harvesting and data throughput in dense and dynamic environments. These findings contribute to advancing energy-autonomous Internet-of-Everything (IoE) deployments, smart factory networks, and other energy-autonomous applications aligned with the goals of next-generation wireless technologies.

Paper number 77:
Title: Position and Velocity Estimation Accuracy in MIMO-OFDM ISAC Networks: A Fisher Information Analysis
Authors: Lorenzo Pucci, Luca Arcangeloni, Andrea Giorgetti
Abstract: This paper presents a theoretical framework to derive information-theoretic bounds on the estimation accuracy of target position and velocity in orthogonal frequency division multiplexing (OFDM)-based integrated sensing and communication (ISAC) networks composed of multiple cooperative and distributed multiple-input multiple-output (MIMO) base stations (BSs). Leveraging Fisher information analysis, we derive closed-form expressions for the Cramér-Rao lower bounds (CRLBs) in both monostatic and bistatic configurations. The framework is then extended to cooperative settings, including networks with multiple coordinated monostatic sensors and multistatic configurations, enabling joint estimation of target position and velocity. We systematically examine how estimation accuracy depends on key system parameters such as the number of BSs, bandwidth, antenna configuration, and network geometry. Numerical results highlight the performance gains enabled by cooperative sensing and provide insights to guide the design of future ISAC systems.

Paper number 78:
Title: Design and Analysis of Phase Conjugation-Based Self-Alignment Beamforming for RIS-Assisted Terahertz SWIPT
Authors: Jiayuan Wei, Qingwei Jiang, Wen Fang, Mingqing Liu, Qingwen Liu, Wen Chen, Qingqing Wu
Abstract: Terahertz (THz) simultaneous wireless information and power transfer (SWIPT) is a promising technology for enabling ultra-high-rate and low-latency communications in massive battery-free Internet of Things (IoT) deployments for 6G networks. However, conventional THz systems rely on narrow directional beams that necessitate precise alignment, typically achieved through high-overhead beam scanning procedures, which fundamentally at odds with the energy constraints of battery-free IoT devices. In this paper, we propose a novel self-alignment architecture for THz SWIPT leveraging a reconfigurable intelligent surface (RIS) to eliminate complex beam scanning. By integrating phase conjugate circuits at both the base station and user equipment, the RIS facilitates a resonance-based bidirectional retro-reflection mechanism, enabling the system to autonomously converge to an aligned state without manual intervention. We develop an analytical channel transfer model and a power cycle model to characterize the resonance-assisted beam alignment process and power transfer efficiency. Simulation results demonstrate that the RIS-enabled system achieves effective spatial power concentration with significant sidelobe suppression, leading to a communication capacity of 127.84 Gbit/s and a received power of 13.62 mW over a 2.2-meter link.

Paper number 79:
Title: Integrated Learning and Optimization to Control Load Demand and Wind Generation for Minimizing Ramping Cost in Real-Time Electricity Market
Authors: Imran Pervez, Omar Knio
Abstract: We developed a new integrated learning and optimization (ILO) methodology to predict context-aware unknown parameters in economic dispatch (ED), a crucial problem in power systems solved to generate optimal power dispatching decisions to serve consumer load. The ED formulation in the current study consists of load and renewable generation as unknown parameters in its constraints predicted using contextual information (e.g., prior load, temperature). The ILO framework train a neural network (NN) to estimate ED parameters by minimizing an application-specific regret function which is a difference between ground truth and NN-driven decisions favouring better ED decisions. We thoroughly analyze the feasible region of ED formulation to understand the impact of load and renewable learning together on the ED decisions. Corresponding to that we developed a new regret function to capture real-time electricity market operations where differences in predicted and true loads are corrected by ramping generators in real-time but at a higher cost than the market price. The proposed regret function when minimized using ILO framework train the NN to guide the load and renewable predictions to generate ED decisions favouring minimum generator ramping costs. This is unlike conventional sequential learning and optimization (SLO) framework which train NN to accurately estimate load and renewable instead of better ED decisions. The combined training of load and renewable using ILO is a new concept and lead to significantly improved ramping costs when compared with SLO based training of load and renewable and SLO trained load with 100% accurate renewable proving its decision-focused capability.

Paper number 80:
Title: Game Theoretic Resilience Recommendation Framework for CyberPhysical Microgrids Using Hypergraph MetaLearning
Authors: S Krishna Niketh, Prasanta K Panigrahi, V Vignesh, Mayukha Pal
Abstract: This paper presents a physics-aware cyberphysical resilience framework for radial microgrids under coordinated cyberattacks. The proposed approach models the attacker through a hypergraph neural network (HGNN) enhanced with model agnostic metalearning (MAML) to rapidly adapt to evolving defense strategies and predict high-impact contingencies. The defender is modeled via a bi-level Stackelberg game, where the upper level selects optimal tie-line switching and distributed energy resource (DER) dispatch using an Alternating Direction Method of Multipliers (ADMM) coordinator embedded within the Non-dominated Sorting Genetic Algorithm II (NSGA-II). The framework simultaneously optimizes load served, operational cost, and voltage stability, ensuring all post-defense states satisfy network physics constraints. The methodology is first validated on the IEEE 69-bus distribution test system with 12 DERs, 8 critical loads, and 5 tie-lines, and then extended to higher bus systems including the IEEE 123-bus feeder and a synthetic 300-bus distribution system. Results show that the proposed defense strategy restores nearly full service for 90% of top-ranked attacks, mitigates voltage violations, and identifies Feeder 2 as the principal vulnerability corridor. Actionable operating rules are derived, recommending pre-arming of specific tie-lines to enhance resilience, while higher bus system studies confirm scalability of the framework on the IEEE 123-bus and 300-bus systems.

Paper number 81:
Title: Adaptive and robust smartphone-based step detection in multiple sclerosis
Authors: Lorenza Angelini, Dimitar Stanev, Marta Płonka, Rafał Klimas, Natan Napiórkowski, Gabriela González Chan, Lisa Bunn, Paul S Glazier, Richard Hosking, Jenny Freeman, Jeremy Hobart, Jonathan Marsden, Licinio Craveiro, Mike D Rinderknecht, Mattia Zanon
Abstract: Background: Many attempts to validate gait pipelines that process sensor data to detect gait events have focused on the detection of initial contacts only in supervised settings using a single sensor. Objective: To evaluate the performance of a gait pipeline in detecting initial/final contacts using a step detection algorithm adaptive to different test settings, smartphone wear locations, and gait impairment levels. Methods: In GaitLab (ISRCTN15993728), healthy controls (HC) and people with multiple sclerosis (PwMS; Expanded Disability Status Scale 0.0-6.5) performed supervised Two-Minute Walk Test [2MWT] (structured in-lab overground and treadmill 2MWT) during two on-site visits carrying six smartphones and unsupervised walking activities (structured and unstructured real-world walking) daily for 10-14 days using a single smartphone. Reference gait data were collected with a motion capture system or Gait Up sensors. The pipeline's performance in detecting initial/final contacts was evaluated through F1 scores and absolute temporal error with respect to reference measurement systems. Results: We studied 35 HC and 93 PwMS. Initial/final contacts were accurately detected across all smartphone wear locations. Median F1 scores for initial/final contacts on in-lab 2MWT were >=99.0%/>=97.6% in HC and >=99.0%/98.2% in PwMS. F1 scores remained high on structured (HC: 100%/100%; PwMS: 99.9%/99.5%) and unstructured real-world walking (HC: 97.8%/97.8%; PwMS: 94.4%/94.0%). Median temporal errors were <=0.08 s. Neither age, sex, disease severity, walking aid use, nor setting (outdoor/indoor) impacted pipeline performance (all p>0.05). Conclusion: This gait pipeline accurately and consistently detects initial and final contacts in PwMS across different smartphone locations and environments, highlighting its potential for real-world gait assessment.

Paper number 82:
Title: Revealing Chaotic Dependence and Degree-Structure Mechanisms in Optimal Pinning Control of Complex Networks
Authors: Qingyang Liu (1), Tianlong Fan (1), Liming Pan (1), Linyuan Lü (1) ((1) University of Science and Technology of China)
Abstract: Identifying an optimal set of driver nodes to achieve synchronization via pinning control is a fundamental challenge in complex network science, limited by computational intractability and the lack of general theory. Here, leveraging a degree-based mean-field (annealed) approximation from statistical physics, we analytically reveal how the structural degree distribution systematically governs synchronization performance, and derive an analytic characterization of the globally optimal pinning set and constructive algorithms with linear complexity (dominated by degree sorting, O(N+M). The optimal configuration exhibits a chaotic dependence--a discontinuous sensitivity--on its cardinality, whereby adding a single node can trigger abrupt changes in node composition and control effectiveness. This structural transition fundamentally challenges traditional heuristics that assume monotonic performance gains with budget. Systematic experiments on synthetic and empirical networks confirm that the proposed approach consistently outperforms degree-, betweenness-, and other centrality-based baselines. Furthermore, we quantify how key degree-distribution features--low-degree saturation, high-degree cutoff, and the power-law exponent--govern achievable synchronizability and shape the form of optimal sets. These results offer a systematic understanding of how degree heterogeneity shapes the network controllability. Our work establishes a unified link between degree heterogeneity and spectral controllability, offering both mechanistic insights and practical design rules for optimal driver-node selection in diverse complex systems.

Paper number 83:
Title: Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning
Authors: Yogesh Thakku Suresh, Vishwajeet Shivaji Hogale, Luca-Alexandru Zamfira, Anandavardhana Hegde
Abstract: We present a transformer-based multimodal framework for generating clinically relevant captions for MRI scans. Our system combines a DEiT-Small vision transformer as an image encoder, MediCareBERT for caption embedding, and a custom LSTM-based decoder. The architecture is designed to semantically align image and textual embeddings, using hybrid cosine-MSE loss and contrastive inference via vector similarity. We benchmark our method on the MultiCaRe dataset, comparing performance on filtered brain-only MRIs versus general MRI images against state-of-the-art medical image captioning methods including BLIP, R2GenGPT, and recent transformer-based approaches. Results show that focusing on domain-specific data improves caption accuracy and semantic alignment. Our work proposes a scalable, interpretable solution for automated medical image reporting.

Paper number 84:
Title: Competitive Equilibrium for Electricity Markets with Spatially Flexible Loads
Authors: Nan Gu, Junjie Qin
Abstract: Electric vehicle charging and geo-distributed datacenters introduce spatially flexible loads (FLs) that couple power, transportation, and datacenter networks. These couplings create a closed-loop feedback between locational marginal prices (LMPs) and decisions of the FL systems, challenging the foundations of conventional competitive equilibrium (CE) in electricity markets. This paper studies a notion of generalized competitive equilibrium (GCE) that aims to capture such price-demand interactions across the interconnected infrastructures. We establish structural conditions under which the GCE preserves key properties of the conventional CE, including existence, uniqueness, and efficiency, without requiring detailed knowledge of decision processes for individual FL systems. The framework generalizes to settings where the grid is coupled with multiple FL systems. Stylized examples and case studies on the New York ISO grid, coupled with the Sioux Falls transportation and distributed datacenter networks, demonstrate the use of our theoretical framework and illustrate the mutual influence among the grid and the studied FL systems.

Paper number 85:
Title: Understanding the Application of Utility Theory in Robotics and Artificial Intelligence: A Survey
Authors: Qin Yang, Rui Liu
Abstract: As a unifying concept in economics, game theory, and operations research, even in the Robotics and AI field, the utility is used to evaluate the level of individual needs, preferences, and interests. Especially for decision-making and learning in multi-agent/robot systems (MAS/MRS), a suitable utility model can guide agents in choosing reasonable strategies to achieve their current needs and learning to cooperate and organize their behaviors, optimizing the system's utility, building stable and reliable relationships, and guaranteeing each group member's sustainable development, similar to the human society. Although these systems' complex, large-scale, and long-term behaviors are strongly determined by the fundamental characteristics of the underlying relationships, there has been less discussion on the theoretical aspects of mechanisms and the fields of applications in Robotics and AI. This paper introduces a utility-orient needs paradigm to describe and evaluate inter and outer relationships among agents' interactions. Then, we survey existing literature in relevant fields to support it and propose several promising research directions along with some open problems deemed necessary for further investigations.

Paper number 86:
Title: Data-Driven Stochastic Optimal Control in Reproducing Kernel Hilbert Spaces
Authors: Nicolas Hoischen, Petar Bevanda, Stefan Sosnowski, Sandra Hirche, Boris Houska
Abstract: This paper proposes a fully data-driven approach for optimal control of nonlinear control-affine systems represented by a stochastic diffusion. The focus is on the scenario where both the nonlinear dynamics and stage cost functions are unknown, while only a control penalty function and constraints are provided. To this end, we embed state probability densities into a reproducing kernel Hilbert space (RKHS) to leverage recent advances in operator regression, thereby identifying Markov transition operators associated with controlled diffusion processes. This operator learning approach integrates naturally with convex operator-theoretic Hamilton-Jacobi-Bellman recursions that scale linearly with state dimensionality, effectively solving a wide range of nonlinear optimal control problems. Numerical results demonstrate its ability to address diverse nonlinear control tasks, including the depth regulation of an autonomous underwater vehicle.

Paper number 87:
Title: Spatially Regularized Super-Resolved Constrained Spherical Deconvolution (SR$^2$-CSD) of Diffusion MRI Data
Authors: Ekin Taskin, Gabriel Girard, Juan Luis Villarreal Haro, Jonathan Rafael-Patiño, Eleftherios Garyfallidis, Jean-Philippe Thiran, Erick Jorge Canales-Rodríguez
Abstract: Constrained Spherical Deconvolution (CSD) is widely used to estimate the white matter fiber orientation distribution (FOD) from diffusion MRI data. Its angular resolution depends on the maximum spherical harmonic order ($l_{max}$): low $l_{max}$ yields smooth but poorly resolved FODs, while high $l_{max}$, as in Super-CSD, enables resolving fiber crossings with small inter-fiber angles but increases sensitivity to noise. In this proof-of-concept study, we introduce Spatially Regularized Super-Resolved CSD (SR$^2$-CSD), a novel method that regularizes Super-CSD using a spatial FOD prior estimated via a self-calibrated total variation denoiser. We evaluated SR$^2$-CSD against CSD and Super-CSD across four datasets: (i) the HARDI-2013 challenge numerical phantom, assessing angular and peak number errors across multiple signal-to-noise ratio (SNR) levels and CSD variants (single-/multi-shell, single-/multi-tissue); (ii) the Sherbrooke in vivo dataset, evaluating spatial coherence of FODs; (iii) a six-subject test-retest dataset acquired with both full (96 gradient directions) and subsampled (45 directions) protocols, assessing reproducibility; and (iv) the DiSCo phantom, evaluating tractography accuracy under varying SNR levels and multiple noise repetitions. Across all evaluations, SR$^2$-CSD consistently reduced angular and peak number errors, improved spatial coherence, enhanced test-retest reproducibility, and yielded connectivity matrices more strongly correlated with ground-truth. Most improvements were statistically significant under multiple-comparison correction. These results demonstrate that incorporating spatial priors into CSD is feasible, mitigates estimation instability, and improves FOD reconstruction accuracy.

Paper number 88:
Title: Transformers as Implicit State Estimators: In-Context Learning in Dynamical Systems
Authors: Usman Akram, Haris Vikalo
Abstract: Predicting the behavior of a dynamical system from noisy observations of its past outputs is a classical problem encountered across engineering and science. For linear systems with Gaussian inputs, the Kalman filter -- the best linear minimum mean-square error estimator of the state trajectory -- is optimal in the Bayesian sense. For nonlinear systems, Bayesian filtering is typically approached using suboptimal heuristics such as the Extended Kalman Filter (EKF), or numerical methods such as particle filtering (PF). In this work, we show that transformers, employed in an in-context learning (ICL) setting, can implicitly infer hidden states in order to predict the outputs of a wide family of dynamical systems, without test-time gradient updates or explicit knowledge of the system model. Specifically, when provided with a short context of past input-output pairs and, optionally, system parameters, a frozen transformer accurately predicts the current output. In linear-Gaussian regimes, its predictions closely match those of the Kalman filter; in nonlinear regimes, its performance approaches that of EKF and PF. Moreover, prediction accuracy degrades gracefully when key parameters, such as the state-transition matrix, are withheld from the context, demonstrating robustness and implicit parameter inference. These findings suggest that transformer in-context learning provides a flexible, non-parametric alternative for output prediction in dynamical systems, grounded in implicit latent-state estimation.

Paper number 89:
Title: Panoramic Out-of-Distribution Segmentation for Autonomous Driving
Authors: Mengfei Duan, Yuheng Zhang, Yihong Cao, Fei Teng, Kai Luo, Jiaming Zhang, Kailun Yang, Zhiyong Li
Abstract: Panoramic imaging enables capturing 360° images with an ultra-wide Field-of-View (FoV) for dense omnidirectional perception, which is critical to applications, such as autonomous driving and augmented reality, etc. However, current panoramic semantic segmentation methods fail to identify outliers, and pinhole Out-of-distribution Segmentation (OoS) models perform unsatisfactorily in the panoramic domain due to background clutter and pixel distortions. To address these issues, we introduce a new task, Panoramic Out-of-distribution Segmentation (PanOoS), with the aim of achieving comprehensive and safe scene understanding. Furthermore, we propose the first solution, POS, which adapts to the characteristics of panoramic images through text-guided prompt distribution learning. Specifically, POS integrates a disentanglement strategy designed to materialize the cross-domain generalization capability of CLIP. The proposed Prompt-based Restoration Attention (PRA) optimizes semantic decoding by prompt guidance and self-adaptive correction, while Bilevel Prompt Distribution Learning (BPDL) refines the manifold of per-pixel mask embeddings via semantic prototype supervision. Besides, to compensate for the scarcity of PanOoS datasets, we establish two benchmarks: DenseOoS, which features diverse outliers in complex environments, and QuadOoS, captured by a quadruped robot with a panoramic annular lens system. Extensive experiments demonstrate superior performance of POS, with AuPRC improving by 34.25% and FPR95 decreasing by 21.42% on DenseOoS, outperforming state-of-the-art pinhole-OoS methods. Moreover, POS achieves leading closed-set segmentation capabilities and advances the development of panoramic understanding. Code and datasets will be available at this https URL.

Paper number 90:
Title: Absorb and Converge: Provable Convergence Guarantee for Absorbing Discrete Diffusion Models
Authors: Yuchen Liang, Renxiang Huang, Lifeng Lai, Ness Shroff, Yingbin Liang
Abstract: Discrete state space diffusion models have shown significant advantages in applications involving discrete data, such as text and image generation. It has also been observed that their performance is highly sensitive to the choice of rate matrices, particularly between uniform and absorbing rate matrices. While empirical results suggest that absorbing rate matrices often yield better generation quality compared to uniform rate matrices, existing theoretical works have largely focused on the uniform rate matrices case. Notably, convergence guarantees and error analyses for absorbing diffusion models are still missing. In this work, we provide the first finite-time error bounds and convergence rate analysis for discrete diffusion models using absorbing rate matrices. We begin by deriving an upper bound on the KL divergence of the forward process, introducing a surrogate initialization distribution to address the challenge posed by the absorbing stationary distribution, which is a singleton and causes the KL divergence to be ill-defined. We then establish the first convergence guarantees for both the $\tau$-leaping and uniformization samplers under absorbing rate matrices, demonstrating improved rates over their counterparts using uniform rate matrices. Furthermore, under suitable assumptions, we provide convergence guarantees without early stopping. Our analysis introduces several new technical tools to address challenges unique to absorbing rate matrices. These include a Jensen-type argument for bounding forward process convergence, novel techniques for bounding absorbing score functions, and a non-divergent upper bound on the score near initialization that removes the need of early-stopping.

Paper number 91:
Title: PoLAR: Polar-Decomposed Low-Rank Adapter Representation
Authors: Kai Lion, Liang Zhang, Bingcong Li, Niao He
Abstract: We show that low-rank adaptation of large-scale models suffers from a low stable rank that is well below the linear algebraic rank of the subspace, degrading fine-tuning performance. To mitigate the underutilization of the allocated subspace, we propose PoLAR, a parameterization inspired by the polar decomposition that factorizes the low-rank update into two direction matrices constrained to Stiefel manifolds and an unconstrained scale matrix. Our theory shows that PoLAR yields an exponentially faster convergence rate on a canonical low-rank adaptation problem. Pairing the parameterization with Riemannian optimization leads to consistent gains on three different benchmarks testing general language understanding, commonsense reasoning, and mathematical problem solving with base model sizes ranging from 350M to 27B.

Paper number 92:
Title: Graph Semi-Supervised Learning for Point Classification on Data Manifolds
Authors: Caio F. Deberaldini Netto, Zhiyang Wang, Luana Ruiz
Abstract: We propose a graph semi-supervised learning framework for classification tasks on data manifolds. Motivated by the manifold hypothesis, we model data as points sampled from a low-dimensional manifold $\mathcal{M} \subset \mathbb{R}^F$. The manifold is approximated in an unsupervised manner using a variational autoencoder (VAE), where the trained encoder maps data to embeddings that represent their coordinates in $\mathbb{R}^F$. A geometric graph is constructed with Gaussian-weighted edges inversely proportional to distances in the embedding space, transforming the point classification problem into a semi-supervised node classification task on the graph. This task is solved using a graph neural network (GNN). Our main contribution is a theoretical analysis of the statistical generalization properties of this data-to-manifold-to-graph pipeline. We show that, under uniform sampling from $\mathcal{M}$, the generalization gap of the semi-supervised task diminishes with increasing graph size, up to the GNN training error. Leveraging a training procedure which resamples a slightly larger graph at regular intervals during training, we then show that the generalization gap can be reduced even further, vanishing asymptotically. Finally, we validate our findings with numerical experiments on image classification benchmarks, demonstrating the empirical effectiveness of our approach.

Paper number 93:
Title: Online Adaptation for Flying Quadrotors in Tight Formations
Authors: Pei-An Hsieh, Kong Yao Chee, M. Ani Hsieh
Abstract: The task of flying in tight formations is challenging for teams of quadrotors because the complex aerodynamic wake interactions can destabilize individual team members as well as the team. Furthermore, these aerodynamic effects are highly nonlinear and fast-paced, making them difficult to model and predict. To overcome these challenges, we present L1 KNODE-DW MPC, an adaptive, mixed expert learning based control framework that allows individual quadrotors to accurately track trajectories while adapting to time-varying aerodynamic interactions during formation flights. We evaluate L1 KNODE-DW MPC in two different three-quadrotor formations and show that it outperforms several MPC baselines. Our results show that the proposed framework is capable of enabling the three-quadrotor team to remain vertically aligned in close proximity throughout the flight. These findings show that the L1 adaptive module compensates for unmodeled disturbances most effectively when paired with an accurate dynamics model. A video showcasing our framework and the physical experiments is available here: this https URL

Paper number 94:
Title: Action Chunking and Exploratory Data Collection Yield Exponential Improvements in Behavior Cloning for Continuous Control
Authors: Thomas T. Zhang, Daniel Pfrommer, Chaoyi Pan, Nikolai Matni, Max Simchowitz
Abstract: This paper presents a theoretical analysis of two of the most impactful interventions in modern learning from demonstration in robotics and continuous control: the practice of action-chunking (predicting sequences of actions in open-loop) and exploratory augmentation of expert demonstrations. Though recent results show that learning from demonstration, also known as imitation learning (IL), can suffer errors that compound exponentially with task horizon in continuous settings, we demonstrate that action chunking and exploratory data collection circumvent exponential compounding errors in different regimes. Our results identify control-theoretic stability as the key mechanism underlying the benefits of these interventions. On the empirical side, we validate our predictions and the role of control-theoretic stability through experimentation on popular robot learning benchmarks. On the theoretical side, we demonstrate that the control-theoretic lens provides fine-grained insights into how compounding error arises, leading to tighter statistical guarantees on imitation learning error when these interventions are applied than previous techniques based on information-theoretic considerations alone.

Paper number 95:
Title: Intelligent Software System for Low-Cost, Brightfield Segmentation: Algorithmic Implementation for Cytometric Auto-Analysis
Authors: Surajit Das, Pavel Zun
Abstract: Bright-field microscopy, a cost-effective solution for live-cell culture, is often the only resource available, along with standard CPUs, for many low-budget labs. The inherent challenges of bright-field images -- their noisiness, low contrast, and dynamic morphology -- coupled with a lack of GPU resources and complex software interfaces, hinder the desired research output. This article presents a novel microscopy image analysis framework designed for low-budget labs equipped with a standard CPU desktop. The Python-based program enables cytometric analysis of live, unstained cells in culture through an advanced computer vision and machine learning pipeline. Crucially, the framework operates on label-free data, requiring no manually annotated training data or training phase. It is accessible via a user-friendly, cross-platform GUI that requires no programming skills, while also providing a scripting interface for programmatic control and integration by developers. The end-to-end workflow performs semantic and instance segmentation, feature extraction, analysis, evaluation, and automated report generation. Its modular architecture supports easy maintenance and flexible integration while supporting both single-image and batch processing. Validated on several unstained cell types from the public dataset of livecells, the framework demonstrates superior accuracy and reproducibility compared to contemporary tools like Cellpose and StarDist. Its competitive segmentation speed on a CPU-based platform highlights its significant potential for basic research and clinical applications -- particularly in cell transplantation for personalised medicine and muscle regeneration therapies. The access to the application is available for reproducibility

Paper number 96:
Title: Discrete Diffusion Models: Novel Analysis and New Sampler Guarantees
Authors: Yuchen Liang, Yingbin Liang, Lifeng Lai, Ness Shroff
Abstract: Discrete diffusion models have recently gained significant prominence in applications involving natural language and graph data. A key factor influencing their effectiveness is the efficiency of discretized samplers. Among these, $\tau$-leaping samplers have become particularly popular due to their theoretical and empirical success. However, existing theoretical analyses of $\tau$-leaping often rely on somewhat restrictive and difficult-to-verify regularity assumptions, and their convergence bounds contain quadratic dependence on the vocabulary size. In this work, we introduce a new analytical approach for discrete diffusion models that removes the need for such assumptions. For the standard $\tau$-leaping method, we establish convergence guarantees in KL divergence that scale linearly with vocabulary size, improving upon prior results with quadratic dependence. Our approach is also more broadly applicable: it provides the first convergence guarantees for other widely used samplers, including the Euler method and Tweedie $\tau$-leaping. Central to our approach is a novel technique based on differential inequalities, offering a more flexible alternative to the traditional Girsanov change-of-measure methods. This technique may also be of independent interest for the analysis of other stochastic processes.

Paper number 97:
Title: Analysis and Synthesis of Switched Optimization Algorithms
Authors: Jared Miller, Fabian Jakob, Carsten Scherer, Andrea Iannelli
Abstract: Deployment of optimization algorithms on networked systems face challenges associated with time delays and corruptions. One particular instance is the presence of time-varying delays arising from factors such as packet drops and irregular sampling. Fixed time delays can destabilize gradient descent algorithms, and this degradation is exacerbated by time-varying delays. This work concentrates on the analysis and creation of discrete-time optimization algorithms with certified exponential convergence rates that are robust against switched uncertainties between the optimizer and the gradient oracle. These optimization algorithms are implemented by a switch-scheduled output feedback controllers. Rate variation and sawtooth behavior (packet drops) in time-varying delays can be imposed through constraining switching sequences. Analysis is accomplished by bisection in the convergence rate to find Zames-Falb filter coefficents. Synthesis is performed by alternating between a filter coefficient search for a fixed controller, and a controller search for fixed multipliers.

Paper number 98:
Title: Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off
Authors: Muhammad Faraz Ul Abrar, Nicolò Michelusi
Abstract: Over-the-air (OTA) federated learning (FL) has been well recognized as a scalable paradigm that exploits the waveform superposition of the wireless multiple-access channel to aggregate model updates in a single use. Existing OTA-FL designs largely enforce zero-bias model updates by either assuming \emph{homogeneous} wireless conditions (equal path loss across devices) or forcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous} wireless scenarios, however, such designs are constrained by the weakest device and inflate the update variance. Moreover, prior analyses of biased OTA-FL largely address convex objectives, while most modern AI models are highly non-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient descent (SGD) for general smooth non-convex objectives under wireless heterogeneity. We develop novel OTA-FL SGD updates that allow a structured, time-invariant model bias while facilitating reduced variance updates. We derive a finite-time stationarity bound (expected time average squared gradient norm) that explicitly reveals a bias-variance trade-off. To optimize this trade-off, we pose a non-convex joint OTA power-control design and develop an efficient successive convex approximation (SCA) algorithm that requires only statistical CSI at the base station. Experiments on a non-convex image classification task validate the approach: the SCA-based design accelerates convergence via an optimized bias and improves generalization over prior OTA-FL baselines.
    