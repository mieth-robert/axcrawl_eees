
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation
Authors: Feiya Zhu, Tarun Pati, Sze Zheng Yong
Abstract: This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems.

Paper number 2:
Title: Ultra-Strong Gradient Diffusion MRI with Self-Supervised Learning for Prostate Cancer Characterization
Authors: Tanishq Patil, Snigdha Sen, Malwina Molendowska, Kieran G. Foley, Fabrizio Fasano, Mara Cercignani, Marco Palombo, Paddy J. Slator, Eleftheria Panagiotaki
Abstract: Diffusion MRI (dMRI) enables non-invasive assessment of prostate microstructure but conventional metrics such as the Apparent Diffusion Coefficient in multiparametric MRI lack specificity to underlying histology. Integrating dMRI with the compartment-based biophysical VERDICT (Vascular, Extracellular, and Restricted Diffusion for Cytometry in Tumours) framework offers richer microstructural insights, though clinical gradient systems (40-80 mT/m) suffer from poor signal-to-noise ratio (SNR) at stronger diffusion weightings due to prolonged echo times. Ultra-strong gradients (up to 300 mT/m) can mitigate these limitations by improving SNR and contrast-to-noise ratios (CNR) but their adoption has until recently been limited to research environments due to challenges with peripheral nerve stimulation thresholds and gradient non-uniformity. This study investigates whether physics-informed self-supervised VERDICT (ssVERDICT) fitting applied to ultra-strong gradients enhances prostate cancer characterization relative to current clinical acquisitions. We developed enhanced ssVERDICT fitting approaches using dense multilayer perceptron (Dense MLP) and convolutional U-Net architectures, benchmarking them against non-linear least-squares (NLLS) fitting and Diffusion Kurtosis Imaging across clinical- to ultra-strong gradient systems. Dense ssVERDICT at ultra-strong gradient notably outperformed NLLS VERDICT, boosting median CNR by 47%, cutting inter-patient Coefficient of Variation by 52%, and reducing pooled f_ic variation by 50%. Overall, it delivered the highest CNR, the most stable parameter estimates, and the clearest tumour-normal contrast compared with conventional methods and clinical gradient systems. These findings highlight the potential of advanced gradient systems and deep learning-based modelling to improve non-invasive prostate cancer characterization and reduce unnecessary biopsies.

Paper number 3:
Title: Quality assurance of the Federal Interagency Traumatic Brain Injury Research (FITBIR) MRI database to enable integrated multi-site analysis
Authors: Adam M. Saunders, Michael E. Kim, Gaurav Rudravaram, Elyssa M. McMaster, Chloe Scholten, Simon Vandekar, Tonia S. Rex, François Rheault, Bennett A. Landman
Abstract: The Federal Interagency Traumatic Brain Injury Research (FITBIR) database is a centralized data repository for traumatic brain injury (TBI) research. It includes over 45,529 magnetic resonance images (MRI) from 6,211 subjects (9,229 imaging sessions) across 26 studies with heterogeneous organization formats, contrasts, acquisition parameters, and demographics. In this work, we organized all available structural and diffusion MRI from FITBIR along with relevant demographic information into the Brain Imaging Data Structure. We analyzed whole-brain mean fractional anisotropy, mean diffusivity, total intracranial volume, and the volumes of 132 regions of interest using UNesT segmentations. There were 4,868 subjects (7,035 sessions) with structural MRI and 2,666 subjects (3,763 sessions) with diffusion MRI following quality assurance and harmonization. We modeled profiles for these metrics across ages with generalized additive models for location, scale, and shape (GAMLSS) and found significant differences in subjects with TBI compared to controls in volumes of 54 regions of the brain (q<0.05, likelihood ratio test with false discovery rate correction).

Paper number 4:
Title: Comparing Unsupervised and Supervised Semantic Speech Tokens: A Case Study of Child ASR
Authors: Mohan Shi, Natarajan Balaji Shankar, Kaiyuan Zhang, Zilai Wang, Abeer Alwan
Abstract: Discrete speech tokens have gained attention for their storage efficiency and integration with Large Language Models (LLMs). They are commonly categorized into acoustic and semantic tokens, with the latter being more advantageous for Automatic Speech Recognition (ASR). Traditionally, unsupervised K-means clustering has been used to extract semantic speech tokens from Speech Foundation Models (SFMs). Recently, supervised methods, such as finite scalar quantization (FSQ) trained with ASR loss, have emerged for speech generation. Both approaches leverage pre-trained SFMs, benefiting low-resource tasks such as child ASR. This paper systematically compares supervised and unsupervised semantic speech tokens for child ASR. Results show that supervised methods not only outperform unsupervised ones but even unexpectedly surpass continuous representations, and they perform well even in ultra-low bitrate settings. These findings highlight the advantages of supervised semantic tokens and offer insights for improving discrete speech tokenization.

Paper number 5:
Title: Optimizing ISAC MIMO Systems with Reconfigurable Pixel Antennas
Authors: Ataher Sams, Yu-Cheng Hsiao, Muhammad Talha, Besma Smida, Ashutosh Sabharwal
Abstract: The integration of sensing and communication demands architectures that can flexibly exploit spatial and electromagnetic (EM) degrees of freedom (DoF). This paper proposes an Integrated Sensing and Communication (ISAC) MIMO framework that uses Reconfigurable Pixel Antenna (RPixA), which introduces additional EM-domain DoF that are electronically controlled through binary antenna coder switch networks. We introduce a beamforming architecture combining this EM and digital precoding to jointly optimize Sensing and Communication. Based on full-wave simulation of pixel antenna, we formulate a non-convex joint optimization problem to maximize sensing rate under user-specific constraints on communication rate. We utilize an Alternating Optimization framework incorporating genetic algorithm for port states of Pixel antennas, and semi-definite relaxation (SDR) for digital beamforming. Numerical results demonstrate that the proposed EM-aware design achieves considerably higher sensing rate compared to conventional arrays and enables considerable antenna reduction for equivalent ISAC performance. These findings highlight the potential of reconfigurable pixel antennas to realize efficient and scalable EM-aware ISAC systems for future 6G networks.

Paper number 6:
Title: A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses
Authors: Maryam Maghsoudi, Mohsen Rezaeizadeh, Shihab Shamma
Abstract: Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.

Paper number 7:
Title: Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion
Authors: Hidaka Asai, Tomoyuki Noda, Jun Morimoto
Abstract: Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.

Paper number 8:
Title: A Universal Harmonic Discriminator for High-quality GAN-based Vocoder
Authors: Nan Xu, Zhaolong Huang, Xiao Zeng
Abstract: With the emergence of GAN-based vocoders, the discriminator, as a crucial component, has been developed recently. In our work, we focus on improving the time-frequency based discriminator. Particularly, Short-Time Fourier Transform (STFT) representation is usually used as input of time-frequency based discriminator. However, the STFT spectrogram has the same frequency resolution at different frequency bins, which results in an inferior performance, especially for singing voices. Motivated by this, we propose a universal harmonic discriminator for dynamic frequency resolution modeling and harmonic tracking. Specifically, we design a harmonic filter with learnable triangular band-pass filter banks, where each frequency bin has a flexible bandwidth. Additionally, we add a half-harmonic to capture fine-grained harmonic relationships at low-frequency band. Experiments on speech and singing datasets validate the effectiveness of the proposed discriminator on both subjective and objective metrics.

Paper number 9:
Title: Resource Allocation for Pinching-Antenna Systems (PASS)-enabled NOMA Communications
Authors: Songtao Xue, Jingjing Zhao, Kaiquan Cai, Xidong Mu, Zhenyu Xiao, Yuanwei Liu
Abstract: Pinching-antenna systems (PASS) have emerged as a promising technology due to their ability to dynamically reconfigure wireless propagation environments. A novel PASS-based multi-user non-orthogonal multiple access (NOMA) framework is proposed by exploiting the waveguide-division (WD) transmission characteristic. Specifically, each NOMA user cluster is served by one dedicated waveguide, and the corresponding pinching beamforming is exploited to enhance the intra-cluster performance while mitigating the inter-cluster interference. Based on this framework, a sum-rate maximization problem is formulated for jointly optimizing power allocation, pinching beamforming, and user scheduling. To solve this problem, a two-step algorithm is developed, which decomposes the original problem into two subproblems. For the joint power allocation and pinching beamforming design, a penalty dual decomposition (PDD) algorithm is proposed to obtain the locally optimal solutions. Specifically, the coupling constraints are alleviated through augmented Lagrangian relaxation, and the resulting augmented Lagrangian (AL) problem is decomposed into four subproblems, which are solved by the block coordinate descent (BCD) method. For the user scheduling, a low-complexity matching algorithm is developed to solve the user-to-waveguide assignment problem. Simulation results demonstrate that 1) the proposed PASS-based NOMA framework under the WD transmission structure achieves significant sum-rate gain over conventional fixed-position antenna systems and orthogonal multiple access (OMA) scheme; and 2) the proposed matching-based user scheduling algorithm achieves near-optimal user-waveguide association with low computational complexity.

Paper number 10:
Title: A Comprehensive Survey of 3GPP Release 19 ISAC Channel Modeling: From Empirical Features to Unified Methodology and Standardized Simulator
Authors: Yameng Liu, Yuxiang Zhang, Jianhua Zhang, Yuanpeng Pei, Changsheng Zhao, Shilin Luo, Lei Tian, Yingyang Li, Wei Hong, Jianming Wu, Guangyi Liu, Yan Li, Tao Jiang, Chuangxin Jiang, Junchen Liu, Yongqiang Fei, Woo-Suk Ko, Jing Xu, Bin Liang, Takahiro Tomie
Abstract: Integrated Sensing and Communication (ISAC) has been identified as a key 6G application by ITU and 3GPP. Channel measurement and modeling is a prerequisite for ISAC system design and has attracted widespread attention from both academia and industry. 3GPP Release 19 initiated the ISAC channel study item in December 2023 and finalized its modeling specification in May 2025 after extensive technical discussions. However, a comprehensive survey that provides a systematic overview,from empirical channel features to modeling methodologies and standardized simulators,remains unavailable. In this paper, the key requirements and challenges in ISAC channel research are first analyzed, followed by a structured overview of the standardization workflow throughout the 3GPP Release 19 process. Then, critical aspects of ISAC channels, including physical objects, target channels, and background channels, are examined in depth, together with additional features such as spatial consistency, environment objects, Doppler characteristics, and shared clusters, supported by measurement-based analysis. To establish a unified ISAC channel modeling framework, an Extended Geometry-based Stochastic Model (E-GBSM) is proposed, incorporating all the aforementioned ISAC channel characteristics. Finally, a standardized simulator is developed based on E-GBSM, and a two-phase calibration procedure aligned with 3GPP Release 19 is conducted to validate both the model and the simulator, demonstrating close agreement with industrial reference results. Overall, this paper provides a systematic survey of 3GPP Release 19 ISAC channel standardization and offers insights into best practices for new feature characterization, unified modeling methodology, and standardized simulator implementation, which can effectively supporting ISAC technology evaluation and future 6G standardization.

Paper number 11:
Title: Resilient AFE Drive Control using Neural Networks with Tracking Guarantees
Authors: Nicolas Kirsch, Catalin Arghir, Silvia Mastellone, Giancarlo Ferrari-Trecate
Abstract: Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events.

Paper number 12:
Title: Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control
Authors: Abbas Tariverdi
Abstract: Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\|e\| \le \sigma \|x\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\% fewer events than optimally tuned isotropic methods while achieving $2.1\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints.

Paper number 13:
Title: A Perception-feedback position-tracking control for quadrotors
Authors: Eduardo Espindola, Yu Tang
Abstract: In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties.

Paper number 14:
Title: Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach
Authors: Kaouther Moussa, Dimitri Peaucelle
Abstract: This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration.

Paper number 15:
Title: Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes
Authors: Dawei Zhao, Kai Wang, Xianglong Zhou, Xin Ma, Lei Jia
Abstract: This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness.

Paper number 16:
Title: Scalable Pixel-based Reconfigurable Beamforming Networks for Designing Fluid Antenna Systems
Authors: Jichen Zhang, Junhui Rao, Tianqu Kang, Zhaoyang Ming, Yijun Chen, Alikhan Umirbayev, Chi-Yuk Chiu, Ross Murch
Abstract: A novel scalable pixel-based reconfigurable beamforming network (PRBFN) that can be used to form a Fluid Antenna System (FAS), referred to as a PRBFN-FAS, is introduced. The concept of FAS has emerged as an attractive new technology for use in sixth-generation (6G) wireless systems, but most implementations of FAS rely on mechanically reconfigurable antennas which are hindered by inertia, and are therefore too slow to be useful. Using the insight that changing an antenna's physical position is equivalent to switching the excitation current vector of a multi-port antenna, a novel beamformer is proposed with a scalable methodology for incorporating into FAS to form a PRBFN-FAS. Key novelties in creating the PRBFN include selecting the required current vectors and concatenating beamforming networks together to form the desired PRBFN. Two PRBFN-FAS design examples are demonstrated with FAS equivalent physical movements of 0.5 and 1.5 wavelengths. Measurements demonstrate that the PRBFN-FAS provides good matching and Bessel correlation across the desired bandwidth, satisfying FAS requirements. System-level experiments confirm the viability of PRBFN-FAS in practical communication scenarios.

Paper number 17:
Title: A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF
Authors: Sary Yehia, Alessandra Parisio
Abstract: This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks.

Paper number 18:
Title: A BTR-Based Approach for Detection of Infrared Small Targets
Authors: Ke-Xin Li
Abstract: Infrared small target detection plays a crucial role in military reconnaissance and air defense systems. However,existing low-rank sparse based methods still face high computational complexity when dealing with low-contrast small targets and complex dynamic backgrounds mixed with target-like interference. To address this limitation, we reconstruct the data into a fourth-order tensor and propose a new infrared small target detection model based on bilateral tensor ring decomposition, called BTR-ISTD. The approach begins by constructing a four-dimensional infrared tensor from an image sequence, then utilizes BTR decomposition to effectively distinguish weak spatial correlations from strong temporal-patch correlations while simultaneously capturing interactions between these two components. This model is efficiently solved under the proximal alternating minimization (PAM) framework. Experimental results demonstrate that the proposed approach outperforms several state-of-the-art methods in terms of detection accuracy, background suppression capability, and computational speed.

Paper number 19:
Title: Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression
Authors: Bowen Song, Sebastien Gros, Andrea Iannelli
Abstract: Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms.

Paper number 20:
Title: CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond
Authors: Bo Qian, Hanlin Wu, Jiacheng Chen, Yunting Xu, Xiaoyu Wang, Haibo Zhou, Yusheng Ji
Abstract: The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.

Paper number 21:
Title: Exact and Parametric Dynamical System Representation of Nonlinear Functions
Authors: Toshiyuki Ohtsuka
Abstract: Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation.

Paper number 22:
Title: Doppler Robust Vortex Wavefront Design for Integrated Sensing and Communication
Authors: Yuan Liu, Wen-Xuan Long, M. R. Bhavani Shankar, Marco Moretti, Rui Chen, Björn Ottersten
Abstract: Integrated sensing and communication (ISAC) is a promising paradigm for future wireless systems due to spectrum reuse, hardware sharing, and joint waveform design. In dynamic scenes, Doppler shifts degrade both sensing and communication, which is particularly critical for beam-sensitive orbital angular momentum (OAM) wavefronts. To address this, we propose a Doppler-robust ISAC framework, which first senses and then communicates. Specifically, in the sensing phase, multiple vortex modes are simultaneously transmitted via code-division mode-multiplexing (CDMM). To solve Doppler-induced inter-mode interference, we propose a velocity-consistency matching (VCM)-expectation maximization (EM) algorithm that jointly decodes the sensing matrix and estimates range, azimuth, elevation, and velocity for multiple moving targets. In the communication phase, the joint transmitter (Tx) beamforming and receiver (Rx) beam steering are configured from the estimated channel state information (CSI). We further quantify the sensing-communication allocation trade-off by evaluating how pilot length affects estimation accuracy, beam alignment, and spectral efficiency (SE). Simulation results show that the proposed VCM-EM and ISAC designs achieve higher sensing accuracy and communication SE than baseline schemes in dynamic scenarios.

Paper number 23:
Title: Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN
Authors: Ghoshana Bista, Abbas Bradai, Emmanuel Moulay, Abdulhalim Dandoush
Abstract: The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks.

Paper number 24:
Title: Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN
Authors: Mojtaba Fanoodi, Farzaneh Abdollahi, Mahdi Aliyari Shoorehdeli
Abstract: This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation. The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency. Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss. This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults.

Paper number 25:
Title: Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction
Authors: Evan Bell, Shijun Liang, Ismail Alkhouri, Saiprasad Ravishankar
Abstract: Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.

Paper number 26:
Title: An Information Theory of Finite Abstractions and their Fundamental Scalability Limits
Authors: Giannis Delimpaltadakis, Gabriel Gleizer
Abstract: Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.

Paper number 27:
Title: Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder
Authors: Soha Ilbeigi, Ashkan Bagherzadeh, Alireza Sharifi
Abstract: Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV.

Paper number 28:
Title: Kaleidoscopic Scintillation Event Imaging
Authors: Alex Bocchieri, John Mamish, David Appleyard, Andreas Velten
Abstract: Scintillators are transparent materials that interact with high-energy particles and emit visible light as a result. They are used in state of the art methods of measuring high-energy particles and radiation sources. Most existing methods use fast single-pixel detectors to detect and time scintillation events. Cameras provide spatial resolution but can only capture an average over many events, making it difficult to image the events associated with an individual particle. Emerging single-photon avalanche diode cameras combine speed and spatial resolution to enable capturing images of individual events. This allows us to use machine vision techniques to analyze events, enabling new types of detectors. The main challenge is the very low brightness of the events. Techniques have to work with a very limited number of photons. We propose a kaleidoscopic scintillator to increase light collection in a single-photon camera while preserving the event's spatial information. The kaleidoscopic geometry creates mirror reflections of the event in known locations for a given event location that are captured by the camera. We introduce theory for imaging an event in a kaleidoscopic scintillator and an algorithm to estimate the event's 3D position. We find that the kaleidoscopic scintillator design provides sufficient light collection to perform high-resolution event measurements for advanced radiation imaging techniques using a commercial CMOS single-photon camera. Code and data are available at this https URL.

Paper number 29:
Title: Learning Network Sheaves for AI-native Semantic Communication
Authors: Enrico Grimaldi, Mario Edoardo Pandolfo, Gabriele D'Acunto, Sergio Barbarossa, Paolo Di Lorenzo
Abstract: Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.

Paper number 30:
Title: Quantum Encrypted Control of Networked Systems
Authors: Zihao Ren, Daniel Quevedo, Salah Sukkarieh, Guodong Shi
Abstract: Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources.

Paper number 31:
Title: PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers
Authors: Davood Soleymanzadeh, Xiao Liang, Minghui Zheng
Abstract: Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.

Paper number 32:
Title: Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems
Authors: Ben Larwood (1), Oliver J. Sutton (1), Callum Cockburn (1) ((1) Synoptix)
Abstract: Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects. A key tenet of Systems Engineering and acquisition engineering is centred around a "left-shift" in test and evaluation activities to earlier in the system lifecycle, to allow for "accelerated delivery of [systems] that work". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.

Paper number 33:
Title: Market share maximizing strategies of CAV fleet operators may cause chaos in our cities
Authors: Grzegorz Jamróz, Rafał Kucharski, David Watling
Abstract: We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.

Paper number 34:
Title: Real-Time Control and Automation Framework for Acousto-Holographic Microscopy
Authors: Hasan Berkay Abdioğlu, Yağmur Işık, Mustafa İsmail İnal, Nehir Serin, Kerem Bayer, Muhammed Furkan Koşar, Taha Ünal, Hüseyin Üvet
Abstract: Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks.

Paper number 35:
Title: Head, posture, and full-body gestures in interactive communication
Authors: Ľuboš Hládek, Bernhard U. Seeber
Abstract: When face-to-face communication becomes effortful due to background noise or interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively examined head or hand movements, here we explore movements of the whole body in acoustically adverse conditions. We hypothesized that increasing background noise in conversations would lead to increased gesture frequency in hand, head, trunk, and leg movements typical of conversation. Increased use of hand movements should support the speaker's role, while increased head and trunk movements may help the listener. We conducted a free dyadic conversation experiment with normal-hearing participants (n=8) in a virtual acoustic environment. Conversational movements were described with a newly developed labeling system for typical conversational actions, and the frequency of individual types was analyzed. In addition, we analyzed gesture quality by assessing hand-speech synchrony, with the hypothesis that higher levels of background noise would lead to a loss of synchrony according to an interactive coupling model. Higher noise levels led to increased hand-gesture complexity during speaking and listening, more pronounced up-down head movements, and contrary to expectations, head movements during listening generally decreased relative to speaking. Synchrony and peak velocity were unaffected by noise, while gesture quality scaled only modestly. The results support previous findings regarding gesturing frequency, but we found only limited evidence for changes in speech-gesture synchrony. This work reveals communication patterns of the whole body and illustrates multimodal adaptation to communication demands.

Paper number 36:
Title: Colored Markov Random Fields for Probabilistic Topological Modeling
Authors: Lorenzo Marinucci, Leonardo Di Nino, Gabriele D'Acunto, Mario Edoardo Pandolfo, Paolo Di Lorenzo, Sergio Barbarossa
Abstract: Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.

Paper number 37:
Title: Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing
Authors: Samantha Chapin, Kenneth Stewart, Roxana Leontie, Carl Glen Henshaw
Abstract: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

Paper number 38:
Title: Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control
Authors: Kenneth Stewart, Samantha Chapin, Roxana Leontie, Carl Glen Henshaw
Abstract: Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.

Paper number 39:
Title: Deep Unfolding: Recent Developments, Theory, and Design Guidelines
Authors: Nir Shlezinger, Santiago Segarra, Yi Zhang, Dvir Avrahami, Zohar Davidov, Tirza Routtenberg, Yonina C. Eldar
Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

Paper number 40:
Title: Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control
Authors: Gabriele Fadini, Deepak Ingole, Tong Duy Son, Alisa Rupenyan
Abstract: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

Paper number 41:
Title: Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics
Authors: Christos Kolomvakis, Thomas Bobille, Arnaud Vandaele, Nicolas Gillis
Abstract: Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.

Paper number 42:
Title: Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices
Authors: Matteo Nerini, Bruno Clerckx
Abstract: This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.

Paper number 43:
Title: A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments
Authors: Brais Fontan-Costas, M. Diaz-Cacho, Ruben Fernandez-Boullon, Manuel Alonso-Carracedo, Javier Perez-Robles
Abstract: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

Paper number 44:
Title: Ultra-lightweight Neural Video Representation Compression
Authors: Ho Man Kwan, Tianhao Peng, Ge Gao, Fan Zhang, Mike Nilsson, Andrew Gower, David Bull
Abstract: Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.

Paper number 45:
Title: Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization
Authors: Ismail Cosandal, Sennur Ulukus, Nail Akar
Abstract: For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).

Paper number 46:
Title: Reconfigurable Intelligent Surface Deployments for Mars: Communication and Localization Across Diverse Terrains
Authors: Enes Koktas, Recep A. Tasci, Ibrahim Yildirim, Ertugrul Basar
Abstract: Space exploration has witnessed a steady increase since the 1960s, with Mars playing a significant role in our quest for further knowledge. As the ambition to colonize Mars becomes a reality through the collaboration of private companies and space agencies, the need for reliable and robust communication infrastructures in the Martian environment becomes paramount. In this context, reconfigurable intelligent surface (RIS)-empowered communication emerges as a promising technology to enhance the coverage due to lack of multipath components in line-of-sight (LOS) dominated Martian environments. By considering various Martian scenarios such as canyons, craters, mountains, and plateaus, this article explores of the potential of RISs in increasing the coverage in Martian environments. The article also provides an overview of RIS-assisted localization in both LOS and non-line-of-sight (NLOS) scenarios, presenting a general framework for accurate user angle estimation in challenging Martian conditions. The findings and presented framework of this article provide a promising research direction for integrating RISs in deep space communication as well as paving the way for future improvements in interplanetary communication networks.

Paper number 47:
Title: Robust Physics-based Deep MRI Reconstruction Via Diffusion Purification
Authors: Ismail Alkhouri, Shijun Liang, Rongrong Wang, Qing Qu, Saiprasad Ravishankar
Abstract: Deep learning (DL) techniques have been extensively employed in magnetic resonance imaging (MRI) reconstruction, delivering notable performance enhancements over traditional non-DL methods. Nonetheless, recent studies have identified vulnerabilities in these models during testing, namely, their susceptibility to (\textit{i}) worst-case measurement perturbations and to (\textit{ii}) variations in training/testing settings like acceleration factors and k-space sampling locations. This paper addresses the robustness challenges by leveraging diffusion models. In particular, we present a robustification strategy that improves the resilience of DL-based MRI reconstruction methods by utilizing pretrained diffusion models as noise purifiers. In contrast to conventional robustification methods for DL-based MRI reconstruction, such as adversarial training (AT), our proposed approach eliminates the need to tackle a minimax optimization problem. It only necessitates fine-tuning on purified examples. Our experimental results highlight the efficacy of our approach in mitigating the aforementioned instabilities when compared to leading robustification approaches for deep MRI reconstruction, including AT and randomized smoothing.

Paper number 48:
Title: Anti-bullying Adaptive Cruise Control: A proactive right-of-way protection approach
Authors: Jia Hu, Zhexi Lian, Haoran Wang, Zihan Zhang, Ruoxi Qian, Duo Li, Jaehyun (Jason)So, Junnian Zheng
Abstract: Adaptive Cruise Control (ACC) systems have been widely commercialized in recent years. However, existing ACC systems remain vulnerable to close-range cut-ins, a behavior that resembles "road bullying". To address this issue, this research proposes an Anti-bullying Adaptive Cruise Control (AACC) approach, which is capable of proactively protecting right-of-way against such "road bullying" cut-ins. To handle diverse "road bullying" cut-in scenarios smoothly, the proposed approach first leverages an online Inverse Optimal Control (IOC) based algorithm for individual driving style identification. Then, based on Stackelberg competition, a game-theoretic-based motion planning framework is presented in which the identified individual driving styles are utilized to formulate cut-in vehicles' reaction functions. By integrating such reaction functions into the ego vehicle's motion planning, the ego vehicle could consider cut-in vehicles' all possible reactions to find its optimal right-of-way protection maneuver. To the best of our knowledge, this research is the first to model vehicles' interaction dynamics and develop an interactive planner that adapts cut-in vehicle's various driving styles. Simulation results show that the proposed approach can prevent "road bullying" cut-ins and be adaptive to different cut-in vehicles' driving styles. It can improve safety and comfort by up to 79.8% and 20.4%. The driving efficiency has benefits by up to 19.33% in traffic flow. The proposed approach can also adopt more flexible driving strategies. Furthermore, the proposed approach can support real-time field implementation by ensuring less than 50 milliseconds computation time.

Paper number 49:
Title: A Tractable Two-Step Linear Mixing Model Solved with Second-Order Optimization for Spectral Unmixing under Variability
Authors: Xander Haijen, Bikram Koirala, Xuanwen Tao, Paul Scheunders
Abstract: In this paper, we propose a Two-Step Linear Mixing Model (2LMM) that bridges the gap between model complexity and computational tractability. The model achieves this by introducing two distinct scaling steps: an endmember scaling step across the image, and another for pixel-wise scaling. We show that this model leads to only a mildly non-convex optimization problem, which we solve with an optimization algorithm that incorporates second-order information. To the authors' knowledge, this work represents the first application of second-order optimization techniques to solve a spectral unmixing problem that models endmember variability. Our method is highly robust, as it requires virtually no hyperparameter tuning and can therefore be used easily and quickly in a wide range of unmixing tasks. We show through extensive experiments on both simulated and real data that the new model is competitive and in some cases superior to the state of the art in unmixing. The model also performs very well in challenging scenarios, such as blind unmixing.

Paper number 50:
Title: Understanding Untrained Deep Models for Inverse Problems: Algorithms and Theory
Authors: Ismail Alkhouri, Evan Bell, Avrajit Ghosh, Shijun Liang, Rongrong Wang, Saiprasad Ravishankar
Abstract: In recent years, deep learning methods have been extensively developed for inverse imaging problems (IIPs), encompassing supervised, self-supervised, and generative approaches. Most of these methods require large amounts of labeled or unlabeled training data to learn effective models. However, in many practical applications, such as medical image reconstruction, extensive training datasets are often unavailable or limited. A significant milestone in addressing this challenge came in 2018 with the work of Ulyanov et al., which introduced the Deep Image Prior (DIP)--the first training-data-free neural network method for IIPs. Unlike conventional deep learning approaches, DIP requires only a convolutional neural network, the noisy measurements, and a forward operator. By leveraging the implicit regularization of deep networks initialized with random noise, DIP can learn and restore image structures without relying on external datasets. However, a well-known limitation of DIP is its susceptibility to overfitting, primarily due to the over-parameterization of the network. In this tutorial paper, we provide a comprehensive review of DIP, including a theoretical analysis of its training dynamics. We also categorize and discuss recent advancements in DIP-based methods aimed at mitigating overfitting, including techniques such as regularization, network re-parameterization, and early stopping. Furthermore, we discuss approaches that combine DIP with pre-trained neural networks, present empirical comparison results against data-centric methods, and highlight open research questions and future directions.

Paper number 51:
Title: Computationally Efficient Signal Detection with Unknown Bandwidths
Authors: Ali Rasteh, Sundeep Rangan
Abstract: Signal detection in environments with unknown signal bandwidth and time intervals is a fundamental problem in adversarial and spectrum-sharing scenarios. This paper addresses the problem of detecting signals occupying unknown degrees of freedom from non-coherent power measurements, where the signal is constrained to an interval in one dimension or a hyper-cube in multiple dimensions. A GLRT is derived, resulting in a straightforward metric involving normalized average signal energy for each candidate signal set. We present bounds on false alarm and missed detection probabilities, demonstrating their dependence on SNR and signal set sizes. To overcome the inherent computational complexity of exhaustive searches, we propose a computationally efficient binary search method, reducing the complexity from O(N^2) to O(N) for one-dimensional cases. Simulations indicate that the method maintains performance near exhaustive searches and achieves asymptotic consistency, with interval-of-overlap converging to one under constant SNR as measurement size increases. The simulation studies also demonstrate superior performance and reduced complexity compared to contemporary neural network-based approaches, specifically outperforming custom-trained U-Net models in spectrum detection tasks.

Paper number 52:
Title: Nonlinear Oscillatory Response of Automated Vehicle Car-following: Theoretical Analysis with Traffic State and Control Input Limits
Authors: Sixu Li, Yang Zhou
Abstract: This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control input. While prevailing approaches largely ignore these limits (i.e., saturation of acceleration/deceleration and speed) and focus on linear string stability analysis, this framework establishes a basis for theoretically analyzing the frequency response of AV systems with nonlinearities imposed by these limits. To this end, trajectories of CF pairs are decomposed into nominal and oscillatory trajectories, subsequently, the controlled AV system is repositioned within the oscillatory trajectory coordinates. Built on this base, DFs are employed to approximate the frequency responses of nonlinear saturation components by using their first harmonic output, thereby capturing the associated amplification ratio and phase shift. Considering the closed-loop nature of AV control systems, where system states and control input mutually influence each other, amplification ratios and phase shifts are balanced within the loop to ensure consistency. This balancing process may render multiple solutions, hence the incremental-input DF is further applied to identify the reasonable ones. The proposed method is validated by estimations from Simulink, and further comparisons with prevailing methods are conducted. Results confirm the alignment of our framework with Simulink results and exhibit its superior accuracy in analysis compared to the prevailing methods. Furthermore, the framework proves valuable in string stability analysis, especially when conventional linear methods offer misleading insights.

Paper number 53:
Title: PixCell: A generative foundation model for digital histopathology images
Authors: Srikar Yellapragada, Alexandros Graikos, Zilinghan Li, Kostas Triaridis, Varun Belagali, Tarak Nath Nandi, Karen Bai, Beatrice S. Knudsen, Tahsin Kurc, Rajarsi R. Gupta, Prateek Prasanna, Ravi K Madduri, Joel Saltz, Dimitris Samaras
Abstract: The digitization of histology slides has revolutionized pathology, providing massive datasets for cancer diagnosis and research. Self-supervised and vision-language models have been shown to effectively mine large pathology datasets to learn discriminative representations. On the other hand, there are unique problems in pathology, such as annotated data scarcity, privacy regulations in data sharing, and inherently generative tasks like virtual staining. Generative models, capable of synthesizing realistic and diverse images, present a compelling solution to address these problems through image synthesis. We introduce PixCell, the first generative foundation model for histopathology images. PixCell is a diffusion model trained on PanCan-30M, a large, diverse dataset derived from 69,184 H&E-stained whole slide images of various cancer types. We employ a progressive training strategy and a self-supervision-based conditioning that allows us to scale up training without any human-annotated data. By conditioning on real slides, the synthetic images capture the properties of the real data and can be used as data augmentation for small-scale datasets to boost classification performance. We prove the foundational versatility of PixCell by applying it to two generative downstream tasks: privacy-preserving synthetic data generation and virtual IHC staining. PixCell's high-fidelity conditional generation enables institutions to use their private data to synthesize highly realistic, site-specific surrogate images that can be shared in place of raw patient data. Furthermore, using datasets of roughly paired H&E-IHC tiles, we learn to translate PixCell's conditioning from H&E to multiple IHC stains, allowing the generation of IHC images from H&E inputs. Our trained models are publicly released to accelerate research in computational pathology.

Paper number 54:
Title: Spectral Derivatives
Authors: Pavel Komarov
Abstract: One of the happiest accidents in all math is the ease of transforming a function to and taking derivatives in the Fourier frequency domain. But in order to exploit this extraordinary fact without serious artefacting, and in order to be able to use a computer, we need quite a bit of extra knowledge and care. This document sets out the math behind the spectral-derivatives Python package. I touch on fundamental signal processing and calculus concepts as necessary and build upwards.

Paper number 55:
Title: Design of 3D Beamforming and Deployment Strategies for ISAC-based HAPS Systems
Authors: Xue Zhang, Bang Huang, Mohamed-Slim Alouini
Abstract: This paper explores high-altitude platform station (HAPS) systems enabled by integrated sensing and communication (ISAC), in which a HAPS simultaneously transmits communication signals and synthetic aperture radar (SAR) imaging signals to support multi-user communication while performing ground target sensing. Taking into account the operational characteristics of SAR imaging, we consider two HAPS deployment strategies: (i) a quasi-stationary HAPS that remains fixed at an optimized location during SAR operation, following the stop-and-go scanning model; and (ii) a dynamic HAPS that continuously adjusts its flight trajectory along a circular path. For each strategy, we aim at maximizing the weighted sum-rate throughput for communication users while ensuring that SAR imaging requirements, such as beampattern gain and signal-to-noise ratio (SNR), are satisfied. This is achieved by jointly optimizing the HAPS deployment strategy, i.e., its placement or trajectory, along with three-dimensional (3D) transmit beamforming, under practical constraints including transmit power limits, energy consumption, and flight dynamics. Nevertheless, the formulated optimization problems corresponding to the two deployment strategies are inherently non-convex. To address the issue, we propose efficient algorithms that leverage both convex and non-convex optimization techniques to obtain high-quality suboptimal solutions. Numerical results demonstrate the effectiveness and advantages of the proposed approaches over benchmark schemes.

Paper number 56:
Title: Channel Estimation for Downlink Communications Based on Dynamic Metasurface Antennas
Authors: Amarilton L. Magalhães, Fazal E-Asim, André L. F. de Almeida, A. Lee Swindlehurst
Abstract: Dynamic metasurface antennas (DMAs) are emerging as a promising technology to enable energy-efficient, large array-based multi-antenna systems. This paper presents a simple channel estimation scheme for the downlink of a multiple-input single-output orthogonal frequency division multiplexing (MISO-OFDM) communication system exploiting DMAs. The proposed scheme extracts separate estimates of the wireless channel and the unknown waveguide propagation vector using a simple iterative algorithm based on the parallel factor (PARAFAC) decomposition. Obtaining decoupled estimates of the wireless channel and inner waveguide vector enables the isolation and compensation for its effect when designing the DMA beamformer, regardless of the wireless channel state, which evolves much faster due to its shorter coherence time and bandwidth. Additionally, our solution operates in a data-aided manner, delivering estimates of useful data symbols jointly with channel estimates, without requiring sequential pilot and data stages. To the best of our knowledge, this is the first work to explore this CE approach. Numerical results corroborate the notable performance of the proposed scheme.

Paper number 57:
Title: Localization-Based Beam Focusing in Near-Field Communications
Authors: Nima Mozaffarikhosravi, Prathapasinghe Dharmawansa, Italo Atzeni
Abstract: Shifting 6G-and-beyond wireless systems to higher frequency bands and the utilization of massive multiple-input multiple-output arrays will extend the near-field region, affecting beamforming and user localization schemes. In this paper, we propose a localization-based beam-focusing design, in which the receive combiners are directly constructed from the steering vectors corresponding to the estimated user locations. To support this approach, we analyze the 2D-MUSIC algorithm by examining its spectrum in simplified, tractable setups with minimal numbers of antennas and users. Lastly, we compare the proposed localization-based beam focusing, with locations estimated via 2D-MUSIC, with pilot-based zero forcing in terms of uplink sum spectral efficiency. Our results show significant gains under dominant line-of-sight propagation, short coherence blocks, and high noise power typical of high-frequency systems.

Paper number 58:
Title: TransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation
Authors: Akwasi Asare, Mary Sagoe, Justice Williams Asare, Stephen Edward Moore
Abstract: Automated segmentation of diabetic foot ulcers (DFUs) plays a critical role in clinical diagnosis, therapeutic planning, and longitudinal wound monitoring. However, this task remains challenging due to the heterogeneous appearance, irregular morphology, and complex backgrounds associated with ulcer regions in clinical photographs. Traditional convolutional neural networks (CNNs), such as U-Net, provide strong localization capabilities but struggle to model long-range spatial dependencies due to their inherently limited receptive fields. To address this, we employ the TransUNet architecture, a hybrid framework that integrates the global attention mechanism of Vision Transformers (ViTs) into the U-Net structure. This combination allows the model to extract global contextual features while maintaining fine-grained spatial resolution. We trained the model on the public Foot Ulcer Segmentation Challenge (FUSeg) dataset using a robust augmentation pipeline and a hybrid loss function to mitigate class imbalance. On the validation set, the model achieved a Dice Similarity Coefficient (F1-score) of 0.8799 using an optimized threshold of 0.4389. To ensure clinical transparency, we integrated Grad-CAM visualizations to highlight model focus areas. Furthermore, a clinical utility analysis demonstrated a strong correlation (Pearson r = 0.9631) between predicted and ground-truth wound areas. These outcomes demonstrate that our approach effectively integrates global and local feature extraction, offering a reliable, effective, and explainable solution for automated foot ulcer assessment.

Paper number 59:
Title: A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler
Authors: Wenxuan Zhang (1), Shuai Li (1), Xinyi Wang (1), Yu Sun (1), Hongyu Kang (1), Pui Yuk Chryste Wan (1), Jing Qin (2), Yuanpeng Zhang (3), Yong-Ping Zheng (1 and 4), Sai-Kit Lam (1 and 4) ((1), Department of Biomedical Engineering, The Hong Kong Polytechnic University, Hong Kong SAR, China, (2), the Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong SAR, China, (3), the Department of Medical Informatics, Nantong University, Nantong, China, (4), the Research Institute of Smart Ageing, The Hong Kong Polytechnic University, Hong Kong SAR, China)
Abstract: The Circle of Willis (CoW), vital for ensuring consistent blood flow to the brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is important for identifying individuals at risk and guiding appropriate clinical management. Among existing imaging methods, Transcranial Color-coded Doppler (TCCD) offers unique advantages due to its radiation-free nature, affordability, and accessibility. However, reliable TCCD assessments depend heavily on operator expertise for identifying anatomical landmarks and performing accurate angle correction, which limits its widespread adoption. To address this challenge, we propose an AI-powered, real-time CoW auto-segmentation system capable of efficiently capturing cerebral arteries. No prior studies have explored AI-driven cerebrovascular segmentation using TCCD. In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO) network tailored for TCCD data, designed to provide real-time guidance for brain vessel segmentation in the CoW. We prospectively collected TCCD data comprising 738 annotated frames and 3,419 labeled artery instances to establish a high-quality dataset for model training and evaluation. The proposed AAW-YOLO demonstrated strong performance in segmenting both ipsilateral and contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of 0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame inference speed of 14.199 ms. This system offers a practical solution to reduce reliance on operator experience in TCCD-based cerebrovascular screening, with potential applications in routine clinical workflows and resource-constrained settings. Future research will explore bilateral modeling and larger-scale validation.

Paper number 60:
Title: MACS: Measurement-Aware Consistency Sampling for Inverse Problems
Authors: Amirreza Tanevardi, Pooria Abbas Rad Moghadam, Seyed Mohammad Eshtehardian, Sajjad Amini, Babak Khalaj
Abstract: Diffusion models have emerged as powerful generative priors for solving inverse imaging problems. However, their practical deployment is hindered by the substantial computational cost of slow, multi-step sampling. Although Consistency Models (CMs) address this limitation by enabling high-quality generation in only one or a few steps, their direct application to inverse problems has remained largely unexplored. This paper introduces a modified consistency sampling framework specifically designed for inverse problems. The proposed approach regulates the sampler's stochasticity through a measurement-consistency mechanism that leverages the degradation operator, thereby enforcing fidelity to the observed data while preserving the computational efficiency of consistency-based generation. Comprehensive experiments on the Fashion-MNIST and LSUN Bedroom datasets demonstrate consistent improvements across both perceptual and pixel-level metrics, including the Fréchet Inception Distance (FID), Kernel Inception Distance (KID), peak signal-to-noise ratio (PSNR), and structural similarity index measure (SSIM), compared with baseline consistency and diffusion-based sampling methods. The proposed method achieves competitive or superior reconstruction quality with only a small number of sampling steps.

Paper number 61:
Title: Robust Sensor Placement for Poisson Arrivals with False Alarm Aware Spatiotemporal Sensing
Authors: Mingyu Kim, Pronoy Sarker, Seungmo Kim, Daniel J. Stilwell, Jorge Jimenez
Abstract: This paper studies sensor placement when detection performance varies stochastically due to environmental factors over space and time and false alarms are present, but a filter is used to attenuate the effect. We introduce a unified model that couples detection and false alarms through an availability function, which captures how false alarms reduce effective sensing and filtering responses to the disturbance. Building on this model, we give a sufficient condition under which filtering improves detection. In addition, we derive a coverage-based lower bound on the void probability. Furthermore, we prove robustness guarantees showing that performance remains stable when detection probabilities are learned from limited data. We validate the approach with numerical studies using AIS vessel-traffic data and synthetic maritime scenarios. Together, these results provide theory and practical guidance for deploying sensors in dynamic, uncertain environments.

Paper number 62:
Title: Pricing Problems in Adoption of New Technologies
Authors: Yijin Wang, Subhonmesh Bose
Abstract: We propose a generalization of the Bass diffusion model in discrete-time that explicitly models the effect of price in adoption. Our model is different from earlier price-incorporated models and fits well to adoption data for various products. We then utilize this model to study two decision-making problems. First, we provide a series of structural results on optimal pricing strategies to maximize profits from product sales by a monopolist over a finite horizon. We fully characterize the optimal pricing strategy in the single-period problem, and establish several structural properties of the same for the multi-period counterpart. Second, we study a Stackelberg game between a policy-maker and a monopolist, where the former seeks to maximize adoption through rebates, while the latter focuses on profits. For this problem, we analytically characterize crucial properties of the equilibrium path of the single-period game, and demonstrate how they carry over to the multi-period variant.

Paper number 63:
Title: Eye Movement Analysis in Simulated Driving Scenarios
Authors: Smilja Stokanović, Jaka Sodnik, Nadica Miljković
Abstract: This study investigates eye movement behaviour during three conditions: Baseline, Ride (simulated drive under normal visibility), and Fog (simulated drive under reduced visibility). Eye tracking data are analyzed using 31 parameters, organized into three groups: (1) saccade features, (2) Bivariate Contour Ellipse Area (BCEA), and (3) blinking features. Specifically, the analysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all feature groups, numerous statistically significant differences emerge between Baseline and the driving conditions, particularly between Baseline and Ride or Fog. Between Ride and Fog, saccade features show minimal changes (four out of 13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced differences, highlighting the strong impact of reduced visibility on gaze stability and blinking behaviour. In addition to conventional measures such as Mean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index (GI), is introduced to quantify fixation asymmetry along the major axis of the BCEA. This index utilizes eye tracking data to enhance the understanding of eye movement dynamics during driving conditions. Separately from GI, other parameters elicit the largest deviations compared to Ride (e.g., number of saccades: Cliff's {\delta} = 0.98, BCEA: Cohen's d = 0.89, and standard deviation of blink duration: Cliff's {\delta} = 0.80), underscoring the influence of reduced visibility on visual attention. Overall, these findings demonstrate that combining BCEA with saccade and blink parameters provides a comprehensive understanding of visual attention and gaze stability, while GI offers additional insights into fixation asymmetry under varying visibility conditions.

Paper number 64:
Title: IDMap: A Pseudo-Speaker Generator Framework Based on Speaker Identity Index to Vector Mapping
Authors: Zeyan Liu, Liping Chen, Kong Aik Lee, Zhenhua Ling
Abstract: Facilitated by the speech generation framework that disentangles speech into content, speaker, and prosody, voice anonymization is accomplished by substituting the original speaker embedding vector with that of a pseudo-speaker. In this framework, the pseudo-speaker generation forms a fundamental challenge. Current pseudo-speaker generation methods demonstrate limitations in the uniqueness of pseudo-speakers, consequently restricting their effectiveness in voice privacy protection. Besides, existing model-based methods suffer from heavy computation costs. Especially, in the large-scale scenario where a huge number of pseudo-speakers are generated, the limitations of uniqueness and computational inefficiency become more significant. To this end, this paper proposes a framework for pseudo-speaker generation, which establishes a mapping from speaker identity index to speaker vector in the feedforward architecture, termed IDMap. Specifically, the framework is specified into two models: IDMap-MLP and IDMap-Diff. Experiments were conducted on both small- and large-scale evaluation datasets. Small-scale evaluations on the LibriSpeech dataset validated the effectiveness of the proposed IDMap framework in enhancing the uniqueness of pseudo-speakers, thereby improving voice privacy protection, while at a reduced computational cost. Large-scale evaluations on the MLS and Common Voice datasets further justified the superiority of the IDMap framework regarding the stability of the voice privacy protection capability as the number of pseudo-speakers increased. Audio samples and open-source code can be found in this https URL.

Paper number 65:
Title: SSMRadNet : A Sample-wise State-Space Framework for Efficient and Ultra-Light Radar Segmentation and Object Detection
Authors: Anuab Sen, Mir Sayeed Mohammad, Saibal Mukhopadhyay
Abstract: We introduce SSMRadNet, the first multi-scale State Space Model (SSM) based detector for Frequency Modulated Continuous Wave (FMCW) radar that sequentially processes raw ADC samples through two SSMs. One SSM learns a chirp-wise feature by sequentially processing samples from all receiver channels within one chirp, and a second SSM learns a representation of a frame by sequentially processing chirp-wise features. The latent representations of a radar frame are decoded to perform segmentation and detection tasks. Comprehensive evaluations on the RADIal dataset show SSMRadNet has 10-33x fewer parameters and 60-88x less computation (GFLOPs) while being 3.7x faster than state-of-the-art transformer and convolution-based radar detectors at competitive performance for segmentation tasks.

Paper number 66:
Title: Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming
Authors: Vitor Gelsleichter Probst Curtarelli, Stephan Paul, Anderson Wedderhoff Spengler
Abstract: We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.

Paper number 67:
Title: First Deep Learning Approach to Hammering Acoustics for Stem Stability Assessment in Total Hip Arthroplasty
Authors: Dongqi Zhu, Zhuwen Xu, Youyuan Chen, Minghao Jin, Wan Zheng, Yi Zhou, Huiwu Li, Yongyun Chang, Feng Hong, Zanjing Zhai
Abstract: Audio event classification has recently emerged as a promising approach in medical applications. In total hip arthroplasty (THA), intra-operative hammering acoustics provide critical cues for assessing the initial stability of the femoral stem, yet variability due to femoral morphology, implant size, and surgical technique constrains conventional assessment methods. We propose the first deep learning framework for this task, employing a TimeMIL model trained on Log-Mel Spectrogram features and enhanced with pseudo-labeling. On intra-operative recordings, the method achieved 91.17 % +/- 2.79 % accuracy, demonstrating reliable estimation of stem stability. Comparative experiments further show that reducing the diversity of femoral stem brands improves model performance, although limited dataset size remains a bottleneck. These results establish deep learning-based audio event classification as a feasible approach for intra-operative stability assessment in THA.

Paper number 68:
Title: RIS-Aided Localization and Sensing
Authors: Dimitris Kompostiotis, Dimitris Vordonis, Konstantinos D. Katsanos, Florin-Catalin Grec, Vassilis Paliouras, George C. Alexandropoulos
Abstract: High-precision localization and environmental sensing are essential for a new wave of applications, ranging from industrial automation and autonomous systems to augmented reality and remote healthcare. Conventional wireless methods, however, often face limitations in accuracy, reliability, and coverage, especially in complex non-line-of-sight (NLoS) environments. Reconfigurable Intelligent Surfaces (RISs) have emerged as a key enabling technology, offering dynamic control over the radio propagation environment to overcome these challenges. This chapter provides a comprehensive overview of RIS-aided localization and sensing, bridging fundamental theory with practical implementation. The core principles of the RIS technology are first described detailing how programmable metasurfaces can intelligently combat blockages, enhance signal diversity, and create virtual line-of-sight (LoS) links. The chapter then reviews a range of application scenarios where RISs can offer significant improvements. A significant portion of the chapter is dedicated to algorithmic methodologies, covering beam sweeping protocols, codebook-based techniques, and advanced optimization and machine learning strategies for both localization and sensing. To validate the theoretical concepts in real-world conditions, recent experimental results using an RIS prototype are detailed, showcasing the technology's efficacy and illustrating key performance trade-offs.

Paper number 69:
Title: A Unified Bayesian Framework for Stochastic Data-Driven Smoothing, Prediction, and Control
Authors: Mingzhou Yin, Andrea Iannelli, Seyed Ali Nazari, Matthias A. Müller
Abstract: Extending data-driven algorithms based on Willems' fundamental lemma to stochastic data often requires empirical and customized workarounds. This work presents a unified Bayesian framework that provides a systematic and general method for handling stochastic data-driven tasks, including smoothing, prediction, and control, via maximum a posteriori estimation. This framework formulates a unified trajectory estimation problem for the three tasks by specifying different types of trajectory knowledge. Then, a Bayesian problem is solved that optimally combines trajectory knowledge with a data-driven characterization of the trajectory from offline data for a general class of stochastic disturbances. Under specific conditions, this problem is shown to generalize existing data-driven prediction and control algorithms. Numerical examples demonstrate the performance of the unified approach for all three tasks against other data-driven and system identification approaches.

Paper number 70:
Title: Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers
Authors: Farhang Motallebi Araghi, Armin Abdolmohammadi, Navid Mojahed, Shima Nazari
Abstract: The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.

Paper number 71:
Title: Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks
Authors: Chung-Hsuan Hu, Zheng Chen, Erik G. Larsson
Abstract: Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.

Paper number 72:
Title: Capacity Bounds and Low-Complexity Constellation Shaping under Mixed Gaussian-Impulsive Noise
Authors: Tianfu Qi, Jun Wang
Abstract: This paper investigates the bounds on channel capacity and constellation shaping under memoryless mixed noise, which is composed of impulsive noise (IN) and white Gaussian noise (WGN). The capacity bounds are derived using the entropy power inequality and the dual expression of capacity. It is then shown that the proposed lower and upper bounds asymptotically converge to the true channel capacity, and the analytic asymptotic capacity expression is obtained. Leveraging this property, we design a low-complexity constellation shaping method that operates without iterative procedures. Simulation results demonstrate that the derived bounds are remarkably tight, and the shaped constellation achieves the highest mutual information among all considered baseline schemes.

Paper number 73:
Title: Marginalize, Rather than Impute: Probabilistic Wind Power Forecasting with Incomplete Data
Authors: Honglin Wen, Pierre Pinson, Jie Gu, Zhijian Jin
Abstract: Machine learning methods are widely and successfully used for probabilistic wind power forecasting, yet the pervasive issue of missing values (e.g., due to sensor faults or communication outages) has received limited attention. The prevailing practice is impute-then-predict, but conditioning on point imputations biases parameter estimates and fails to propagate uncertainty from missing features. Our approach treats missing features and forecast targets uniformly: we learn a joint generative model of features and targets from incomplete data and, at operational deployment, condition on the observed features and marginalize the unobserved ones to produce forecasts. This imputation-free procedure avoids error introduced by imputation and preserves uncertainty aroused from missing features. In experiments, it improves forecast quality in terms of continuous ranked probability score relative to impute-then-predict baselines while incurring substantially lower computational cost than common alternatives.

Paper number 74:
Title: Quaternion-Based Sliding Mode Control for Six Degrees of Freedom Flight Control of Quadrotors
Authors: Amin Yazdanshenas, Reza Faieghi
Abstract: Despite extensive research on sliding mode control (SMC) design for quadrotors, the existing approaches suffer from certain limitations. Euler angle-based SMC formulations suffer from poor performance in high-pitch or -roll maneuvers. Quaternion-based SMC approaches have unwinding issues and complex architecture. Coordinate-free methods are slow and only almost globally stable. This paper presents a new six degrees of freedom SMC flight controller to address the above limitations. We use a cascaded architecture with a position controller in the outer loop and a quaternion-based attitude controller in the inner loop. The position controller generates the desired trajectory for the attitude controller using a coordinate-free approach. The quaternion-based attitude controller uses the natural characteristics of the quaternion hypersphere, featuring a simple structure while providing global stability and avoiding unwinding issues. We compare our controller with three other common control methods conducting challenging maneuvers like flip-over and high-speed trajectory tracking in the presence of model uncertainties and disturbances. Our controller consistently outperforms the benchmark approaches with less control effort and actuator saturation, offering highly effective and efficient flight control.

Paper number 75:
Title: NVRC: Neural Video Representation Compression
Authors: Ho Man Kwan, Ge Gao, Fan Zhang, Andrew Gower, David Bull
Abstract: Recent advances in implicit neural representation (INR)-based video coding have demonstrated its potential to compete with both conventional and other learning-based approaches. With INR methods, a neural network is trained to overfit a video sequence, with its parameters compressed to obtain a compact representation of the video content. However, although promising results have been achieved, the best INR-based methods are still out-performed by the latest standard codecs, such as VVC VTM, partially due to the simple model compression techniques employed. In this paper, rather than focusing on representation architectures as in many existing works, we propose a novel INR-based video compression framework, Neural Video Representation Compression (NVRC), targeting compression of the representation. Based on the novel entropy coding and quantization models proposed, NVRC, for the first time, is able to optimize an INR-based video codec in a fully end-to-end manner. To further minimize the additional bitrate overhead introduced by the entropy models, we have also proposed a new model compression framework for coding all the network, quantization and entropy model parameters hierarchically. Our experiments show that NVRC outperforms many conventional and learning-based benchmark codecs, with a 24% average coding gain over VVC VTM (Random Access) on the UVG dataset, measured in PSNR. As far as we are aware, this is the first time an INR-based video codec achieving such performance. The implementation of NVRC will be released.

Paper number 76:
Title: Concentration of Cumulative Reward in Markov Decision Processes
Authors: Borna Sayedana, Peter E. Caines, Aditya Mahajan
Abstract: In this paper, we investigate the concentration properties of cumulative reward in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings. We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting. Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms. Additionally, we explore two key implications of our results. First, we analyze the sample path behavior of the difference in rewards between any two stationary policies. Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent. Our proof techniques rely on a martingale decomposition of cumulative reward, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences.

Paper number 77:
Title: Implicit Generative Modeling by Kernel Similarity Matching
Authors: Shubham Choudhary, Paul Masset, Demba Ba
Abstract: Understanding how the brain encodes stimuli has been a fundamental problem in computational neuroscience. Insights into this problem have led to the design and development of artificial neural networks that learn representations by incorporating brain-like learning abilities. Recently, learning representations by capturing similarity between input samples has been studied to tackle this problem. This approach, however, has thus far been used to only learn downstream features from an input and has not been studied in the context of a generative paradigm, where one can map the representations back to the input space, incorporating not only bottom-up interactions (stimuli to latent) but also learning features in a top-down manner (latent to stimuli). We investigate a kernel similarity matching framework for generative modeling. Starting with a modified sparse coding objective for learning representations proposed in prior work, we demonstrate that representation learning in this context is equivalent to maximizing similarity between the input kernel and a latent kernel. We show that an implicit generative model arises from learning the kernel structure in the latent space and show how the framework can be adapted to learn manifold structures, potentially providing insights as to how task representations can be encoded in the brain. To solve the objective, we propose a novel Alternate Direction Method of Multipliers (ADMM) based algorithm and discuss the interpretation of the optimization process. Finally, we discuss how this representation learning problem can lead towards a biologically plausible architecture to learn the model parameters that ties together representation learning using similarity matching (a bottom-up approach) with predictive coding (a top-down approach).

Paper number 78:
Title: Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?
Authors: Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio Bolognani
Abstract: Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.

Paper number 79:
Title: Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks
Authors: Matteo Nerini, Bruno Clerckx
Abstract: Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.

Paper number 80:
Title: Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming
Authors: Matteo Nerini, Bruno Clerckx
Abstract: Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\times 10^4$ and $4.0\times 10^7$ times, respectively, compared to digital beamforming.

Paper number 81:
Title: MROP: Modulated Rank-One Projections for compressive radio interferometric imaging
Authors: Olivier Leblanc, Chung San Chu, Laurent Jacques, Yves Wiaux
Abstract: The emerging generation of radio-interferometric (RI) arrays are set to form images of the sky with a new regime of sensitivity and resolution. This implies a significant increase in visibility data volumes, which for single-frequency observations will scale as $\mathcal{O}(Q^2B)$ for $Q$ antennas and $B$ short-time integration intervals (or batches), calling for efficient data dimensionality reduction techniques. This paper proposes a new approach to data compression during acquisition, coined modulated rank-one projection (MROP). MROP compresses the $Q\times Q$ batchwise covariance matrix into a smaller number $P$ of random rank-one projections and compresses across time by trading $B$ for a smaller number $M$ of random modulations of the ROP measurement vectors. Firstly, we introduce a dual perspective on the MROP acquisition, which can either be understood as random beamforming, or as a post-correlation compression. Secondly, we analyse the noise statistics of MROPs and demonstrate that the random projections induce a uniform noise level across measurements independently of the visibility-weighting scheme used. Thirdly, we propose a detailed analysis of the memory and computational cost requirements across the data acquisition and image reconstruction stages, with comparison to state-of-the-art dimensionality reduction approaches. Finally, the MROP model is validated for monochromatic intensity imaging both in simulation and from real data, with comparison to the classical and baseline-dependent averaging (BDA) models, and using the uSARA optimisation algorithm for image formation. Our results suggest that the data size necessary to preserve imaging quality using MROPs is reduced to the order of image size, well below the original and BDA data sizes.

Paper number 82:
Title: Mutual Information Bounds for Lossy Common Information
Authors: Anderson de Andrade
Abstract: We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and Gács-Körner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).

Paper number 83:
Title: Improving Wi-Fi Network Performance Prediction with Deep Learning Models
Authors: Gabriele Formis, Amanda Ericson, Stefan Forsstrom, Kyi Thar, Gianluca Cena, Stefano Scanzio
Abstract: The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.

Paper number 84:
Title: MathBode: Measuring the Stability of LLM Reasoning using Frequency Response
Authors: Charles L. Wang
Abstract: This paper presents MathBode, a dynamic diagnostic for mathematical reasoning in large language models (LLMs). Instead of one-shot accuracy, MathBode treats each parametric problem as a system: we drive a single parameter sinusoidally and fit first-harmonic responses of model outputs and exact solutions. This yields interpretable, frequency-resolved metrics -- gain (amplitude tracking) and phase (lag) -- that form Bode-style fingerprints. Across five closed-form families (linear solve, ratio/saturation, compound interest, 2x2 linear systems, similar triangles), the diagnostic surfaces systematic low-pass behavior and growing phase lag that accuracy alone obscures. We compare several models against a symbolic baseline that calibrates the instrument ($G \approx 1$, $\phi \approx 0$). Results separate frontier from mid-tier models on dynamics, providing a compact, reproducible protocol that complements standard benchmarks with actionable measurements of reasoning fidelity and consistency. We open-source the dataset and code to enable further research and adoption.

Paper number 85:
Title: Musical consonance: a review of theory and evidence on perception and preference of auditory roughness in humans and other animals
Authors: John M. McBride
Abstract: The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.
    