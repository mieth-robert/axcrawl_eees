
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition
Authors: Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin
Abstract: Recently, end-to-end automatic speech recognition has become the mainstream approach in both industry and academia. To optimize system performance in specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively used to integrate acoustic and language models, leveraging its capacity to implicitly fuse language models within static graphs, thereby ensuring robust recognition while also facilitating rapid error correction. However, WFST necessitates a frame-by-frame search of CTC posterior probabilities through autoregression, which significantly hampers inference speed. In this work, we thoroughly investigate the spike property of CTC outputs and further propose the conjecture that adjacent frames to non-blank spikes carry semantic information beneficial to the model. Building on this, we propose the Spike Window Decoding algorithm, which greatly improves the inference speed by making the number of frames decoded in WFST linearly related to the number of spiking frames in the CTC output, while guaranteeing the recognition performance. Our method achieves SOTA recognition accuracy with significantly accelerates decoding speed, proven across both AISHELL-1 and large-scale In-House datasets, establishing a pioneering approach for integrating CTC output with WFST.

Paper number 2:
Title: K-space Diffusion Model Based MR Reconstruction Method for Simultaneous Multislice Imaging
Authors: Ting Zhao, Zhuoxu Cui, Congcong Liu, Xingyang Wu, Yihang Zhou, Dong Liang, Haifeng Wang
Abstract: Simultaneous Multi-Slice(SMS) is a magnetic resonance imaging (MRI) technique which excites several slices concurrently using multiband radiofrequency pulses to reduce scanning time. However, due to its variable data structure and difficulty in acquisition, it is challenging to integrate SMS data as training data into deep learning this http URL study proposed a novel k-space diffusion model of SMS reconstruction that does not utilize SMS data for training. Instead, it incorporates Slice GRAPPA during the sampling process to reconstruct SMS data from different acquisition this http URL results demonstrated that this method outperforms traditional SMS reconstruction methods and can achieve higher acceleration factors without in-plane aliasing.

Paper number 3:
Title: Global network control from local information
Authors: Aleksandar Haber, Ferenc Molnar, Adilson E. Motter
Abstract: In the classical control of network systems, the control actions on a node are determined as a function of the states of all nodes in the network. Motivated by applications where the global state cannot be reconstructed in real time due to limitations in the collection, communication, and processing of data, here we introduce a control approach in which the control actions can be computed as a function of the states of the nodes within a limited state information neighborhood. The trade-off between the control performance and the size of this neighborhood is primarily determined by the condition number of the controllability Gramian. Our theoretical results are supported by simulations on regular and random networks and are further illustrated by an application to the control of power-grid synchronization. We demonstrate that for well-conditioned Gramians, there is no significant loss of control performance as the size of the state information neighborhood is reduced, allowing efficient control of large networks using only local information.

Paper number 4:
Title: Placement, Orientation, and Resource Allocation Optimization for Cell-Free OIRS-aided OWC Network
Authors: Jalal Jalali, Hina Tabassum, Jeroen Famaey, Walid Saad, Murat Uysal
Abstract: The emergence of optical intelligent reflecting surface (OIRS) technologies marks a milestone in optical wireless communication (OWC) systems, enabling enhanced control over light propagation in indoor environments. This capability allows for the customization of channel conditions to achieve specific performance goals. This paper presents an enhancement in downlink cell-free OWC networks through the integration of OIRS. The key focus is on fine-tuning crucial parameters, including transmit power, receiver orientations, OIRS elements allocation, and strategic placement. In particular, a multi-objective optimization problem (MOOP) aimed at simultaneously improving the network's spectral efficiency (SE) and energy efficiency (EE) while adhering to the network's quality of service (QoS) constraints is formulated. The problem is solved by employing the $\epsilon$-constraint method to convert the MOOP into a single-objective optimization problem and solving it through successive convex approximation. Simulation results show the significant impact of OIRS on SE and EE, confirming its effectiveness in improving OWC network performance.

Paper number 5:
Title: A Self-supervised Diffusion Bridge for MRI Reconstruction
Authors: Harry Gao, Weijie Gan, Yuyang Hu, Hongyu An, Ulugbek S. Kamilov
Abstract: Diffusion bridges (DBs) are a class of diffusion models that enable faster sampling by interpolating between two paired image distributions. Training traditional DBs for image reconstruction requires high-quality reference images, which limits their applicability to settings where such references are unavailable. We propose SelfDB as a novel self-supervised method for training DBs directly on available noisy measurements without any high-quality reference images. SelfDB formulates the diffusion process by further sub-sampling the available measurements two additional times and training a neural network to reverse the corresponding degradation process by using the available measurements as the training targets. We validate SelfDB on compressed sensing MRI, showing its superior performance compared to the denoising diffusion models.

Paper number 6:
Title: ProtoBeam: Generalizing Deep Beam Prediction to Unseen Antennas using Prototypical Networks
Authors: Omar Mashaal, Elsayed Mohammed, Alec Digby, Lorne Swersky, Ashkan Eshaghbeigi, Hatem Abou-Zeid
Abstract: Deep learning techniques have recently emerged to efficiently manage mmWave beam transmissions without requiring time consuming beam sweeping strategies. A fundamental challenge in these methods is their dependency on hardware-specific training data and their limited ability to generalize. Large drops in performance are reported in literature when DL models trained in one antenna environment are applied in another. This paper proposes the application of Prototypical Networks to address this challenge and utilizes the DeepBeam real-world dataset to validate the developed solutions. Prototypical Networks excel in extracting features to establish class-specific prototypes during the training, resulting in precise embeddings that encapsulate the defining features of the data. We demonstrate the effectiveness of PN to enable generalization of deep beam predictors across unseen antennas. Our approach, which integrates data normalization and prototype normalization with the PN, achieves an average beam classification accuracy of 74.11 percent when trained and tested on different antenna datasets. This is an improvement of 398 percent compared to baseline performances reported in literature that do not account for such domain shifts. To the best of our knowledge, this work represents the first demonstration of the value of Prototypical Networks for domain adaptation in wireless networks, providing a foundation for future research in this area.

Paper number 7:
Title: Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation
Authors: Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang
Abstract: X-ray image based medical report generation achieves significant progress in recent years with the help of the large language model, however, these models have not fully exploited the effective information in visual image regions, resulting in reports that are linguistically sound but insufficient in describing key diseases. In this paper, we propose a novel associative memory-enhanced X-ray report generation model that effectively mimics the process of professional doctors writing medical reports. It considers both the mining of global and local visual information and associates historical report information to better complete the writing of the current report. Specifically, given an X-ray image, we first utilize a classification model along with its activation maps to accomplish the mining of visual regions highly associated with diseases and the learning of disease query tokens. Then, we employ a visual Hopfield network to establish memory associations for disease-related tokens, and a report Hopfield network to retrieve report memory information. This process facilitates the generation of high-quality reports based on a large language model and achieves state-of-the-art performance on multiple benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The source code of this work is released on \url{this https URL}.

Paper number 8:
Title: DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation
Authors: Bo Liu, Yudong Zhang, Shuihua Wang, Siyue Li, Jin Hong
Abstract: Retinal vascular morphology is crucial for diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and style augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to implement random photometric augmentations and introduce uncertainty perturbations, thereby enriching stylistic diversity and significantly enhancing the model's adaptability to varying imaging conditions. Our framework has been rigorously evaluated on four challenging datasets-DRIVE, CHASEDB, HRF, and STARE-demonstrating state-of-the-art performance that surpasses existing methods. This validates the effectiveness of our proposed approach, highlighting its potential for clinical application in automated retinal vessel analysis.

Paper number 9:
Title: A Unified Attack Detection Strategy for Multi-Agent Systems over Transient and Steady Stages
Authors: Jinming Gao, Yijing Wang, Wentao Zhang, Rui Zhao, Yang Shi, Zhiqiang Zuo
Abstract: This paper proposes a unified detection strategy against three kinds of attacks for multi-agent systems (MASs) which is applicable to both transient and steady stages. For attacks on the communication layer, a watermarking-based detection scheme with KullbackLeibler (KL) divergence is designed. Different from traditional communication schemes, each agent transmits a message set containing two state values with different types of watermarking. It is found that the detection performance is determined by the relevant parameters of the watermarking signal. Unlike the existing detection manoeuvres, such a scheme is capable of transient and steady stages. For attacks on the agent layer, a convergence rate related detection approach is put forward. It is shown that the resilience of the considered system is characterized by the coefficient and offset of the envelope. For hybrid attacks, based on the above detection mechanisms, a general framework resorting to trusted agents is presented, which requires weaker graph conditions and less information transmission. Finally, an example associated with the platooning of connected vehicles is given to support the theoretical results.

Paper number 10:
Title: Resilient Distributed Control for Uncertain Nonlinear Interconnected Systems under Network Anomaly
Authors: Youqing Wang, Ying Li, Thomas Parisini, Dong Zhao
Abstract: We address a distributed adaptive control methodology for nonlinear interconnected systems possibly affected by network anomalies. In the framework of adaptive approximation, the distributed controller and parameter estimator are designed by exploiting a backstepping approach. The stability of the distributed control system under anomalies is analyzed, where both local and neighboring anomaly effects are considered. To quantify the resilience of the interconnected system under the action of network anomalies, we derive bounds on the duration of each anomaly and the resting time between two consecutive anomalies. Specifically, when each anomaly duration is smaller than our designed upper bound, the interconnected system controlled by the distributed approximation-based controller remains asymptotically stable. Moreover, if the resting time between two consecutive anomalies is larger than the proposed bound, then all signals of the control system are guaranteed to be bounded. In the paper, we show that under the action of the proposed distributed adaptive controller, the interconnected system remains stable in the presence of network anomalies, with both the qualitative and quantitative resilient conditions. Extensive simulation results show the effectiveness of our theoretical results.

Paper number 11:
Title: Salient Region Matching for Fully Automated MR-TRUS Registration
Authors: Zetian Feng, Dong Ni, Yi Wang
Abstract: Prostate cancer is a leading cause of cancer-related mortality in men. The registration of magnetic resonance (MR) and transrectal ultrasound (TRUS) can provide guidance for the targeted biopsy of prostate cancer. In this study, we propose a salient region matching framework for fully automated MR-TRUS registration. The framework consists of prostate segmentation, rigid alignment and deformable registration. Prostate segmentation is performed using two segmentation networks on MR and TRUS respectively, and the predicted salient regions are used for the rigid alignment. The rigidly-aligned MR and TRUS images serve as initialization for the deformable registration. The deformable registration network has a dual-stream encoder with cross-modal spatial attention modules to facilitate multi-modality feature learning, and a salient region matching loss to consider both structure and intensity similarity within the prostate region. Experiments on a public MR-TRUS dataset demonstrate that our method achieves satisfactory registration results, outperforming several cutting-edge methods. The code is publicly available at this https URL.

Paper number 12:
Title: A generative approach for lensless imaging in low-light conditions
Authors: Ziyang Liu, Tianjiao Zeng, Xu Zhan, Xiaoling Zhang, Edmund Y. Lam
Abstract: Lensless imaging offers a lightweight, compact alternative to traditional lens-based systems, ideal for exploration in space-constrained environments. However, the absence of a focusing lens and limited lighting in such environments often result in low-light conditions, where the measurements suffer from complex noise interference due to insufficient capture of photons. This study presents a robust reconstruction method for high-quality imaging in low-light scenarios, employing two complementary perspectives: model-driven and data-driven. First, we apply a physic-model-driven perspective to reconstruct in the range space of the pseudo-inverse of the measurement model as a first guidance to extract information in the noisy measurements. Then, we integrate a generative-model based perspective to suppress residual noises as the second guidance to suppress noises in the initial noisy results. Specifically, a learnable Wiener filter-based module generates an initial noisy reconstruction. Then, for fast and, more importantly, stable generation of the clear image from the noisy version, we implement a modified conditional generative diffusion module. This module converts the raw image into the latent wavelet domain for efficiency and uses modified bidirectional training processes for stabilization. Simulations and real-world experiments demonstrate substantial improvements in overall visual quality, advancing lensless imaging in challenging low-light environments.

Paper number 13:
Title: FgC2F-UDiff: Frequency-guided and Coarse-to-fine Unified Diffusion Model for Multi-modality Missing MRI Synthesis
Authors: Xiaojiao Xiao, Qinmin Vivian Hu, Guanghui Wang
Abstract: Multi-modality magnetic resonance imaging (MRI) is essential for the diagnosis and treatment of brain tumors. However, missing modalities are commonly observed due to limitations in scan time, scan corruption, artifacts, motion, and contrast agent intolerance. Synthesis of missing MRI has been a means to address the limitations of modality insufficiency in clinical practice and research. However, there are still some challenges, such as poor generalization, inaccurate non-linear mapping, and slow processing speeds. To address the aforementioned issues, we propose a novel unified synthesis model, the Frequency-guided and Coarse-to-fine Unified Diffusion Model (FgC2F-UDiff), designed for multiple inputs and outputs. Specifically, the Coarse-to-fine Unified Network (CUN) fully exploits the iterative denoising properties of diffusion models, from global to detail, by dividing the denoising process into two stages, coarse and fine, to enhance the fidelity of synthesized images. Secondly, the Frequency-guided Collaborative Strategy (FCS) harnesses appropriate frequency information as prior knowledge to guide the learning of a unified, highly non-linear mapping. Thirdly, the Specific-acceleration Hybrid Mechanism (SHM) integrates specific mechanisms to accelerate the diffusion model and enhance the feasibility of many-to-many synthesis. Extensive experimental evaluations have demonstrated that our proposed FgC2F-UDiff model achieves superior performance on two datasets, validated through a comprehensive assessment that includes both qualitative observations and quantitative metrics, such as PSNR SSIM, LPIPS, and FID.

Paper number 14:
Title: Deep Learning for Pathological Speech: A Survey
Authors: Shakeel A. Sheikh, Md. Sahidullah, Ina Kodrasi
Abstract: Advancements in spoken language technologies for neurodegenerative speech disorders are crucial for meeting both clinical and technological needs. This overview paper is vital for advancing the field, as it presents a comprehensive review of state-of-the-art methods in pathological speech detection, automatic speech recognition, pathological speech intelligibility enhancement, intelligibility and severity assessment, and data augmentation approaches for pathological speech. It also high-lights key challenges, such as ensuring robustness, privacy, and interpretability. The paper concludes by exploring promising future directions, including the adoption of multimodal approaches and the integration of graph neural networks and large language models to further advance speech technology for neurodegenerative speech disorders

Paper number 15:
Title: Efficient and Accurate Tuberculosis Diagnosis: Attention Residual U-Net and Vision Transformer Based Detection Framework
Authors: Greeshma K, Vishnukumar S
Abstract: Tuberculosis (TB), an infectious disease caused by Mycobacterium tuberculosis, continues to be a major global health threat despite being preventable and curable. This burden is particularly high in low and middle income countries. Microscopy remains essential for diagnosing TB by enabling direct visualization of Mycobacterium tuberculosis in sputum smear samples, offering a cost effective approach for early detection and effective treatment. Given the labour-intensive nature of microscopy, automating the detection of bacilli in microscopic images is crucial to improve both the expediency and reliability of TB diagnosis. The current methodologies for detecting tuberculosis bacilli in bright field microscopic sputum smear images are hindered by limited automation capabilities, inconsistent segmentation quality, and constrained classification precision. This paper proposes a twostage deep learning methodology for tuberculosis bacilli detection, comprising bacilli segmentation followed by classification. In the initial phase, an advanced U-Net model employing attention blocks and residual connections is proposed to segment microscopic sputum smear images, enabling the extraction of Regions of Interest (ROIs). The extracted ROIs are then classified using a Vision Transformer, which we specifically customized as TBViT to enhance the precise detection of bacilli within the images. For the experiments, a newly developed dataset of microscopic sputum smear images derived from Ziehl-Neelsen-stained slides is used in conjunction with existing public datasets. The qualitative and quantitative evaluation of the experiments using various metrics demonstrates that the proposed model achieves significantly improved segmentation performance, higher classification accuracy, and a greater level of automation, surpassing existing methods.

Paper number 16:
Title: Enhanced Tuberculosis Bacilli Detection using Attention-Residual U-Net and Ensemble Classification
Authors: Greeshma K, Vishnukumar S
Abstract: Tuberculosis (TB), caused by Mycobacterium tuberculosis, remains a critical global health issue, necessitating timely diagnosis and treatment. Current methods for detecting tuberculosis bacilli from bright field microscopic sputum smear images suffer from low automation, inadequate segmentation performance, and limited classification accuracy. This paper proposes an efficient hybrid approach that combines deep learning for segmentation and an ensemble model for classification. An enhanced U-Net model incorporating attention blocks and residual connections is introduced to precisely segment microscopic sputum smear images, facilitating the extraction of Regions of Interest (ROIs). These ROIs are subsequently classified using an ensemble classifier comprising Support Vector Machine (SVM), Random Forest, and Extreme Gradient Boost (XGBoost), resulting in an accurate identification of bacilli within the images. Experiments conducted on a newly created dataset, along with public datasets, demonstrate that the proposed model achieves superior segmentation performance, higher classification accuracy, and enhanced automation compared to existing methods.

Paper number 17:
Title: The generalized phase retrieval problem over compact groups
Authors: Tamir Bendory, Dan Edidin
Abstract: The classical phase retrieval problem involves estimating a signal from its Fourier magnitudes (power spectrum) by leveraging prior information about the desired signal. This paper extends the problem to compact groups, addressing the recovery of a set of matrices from their Gram matrices. In this broader context, the missing phases in Fourier space are replaced by missing unitary or orthogonal matrices arising from the action of a compact group on a finite-dimensional vector space. This generalization is driven by applications in multi-reference alignment and single-particle cryo-electron microscopy, a pivotal technology in structural biology. We define the generalized phase retrieval problem over compact groups and explore its underlying algebraic structure. We survey recent results on the uniqueness of solutions, focusing on the significant class of semialgebraic priors. Furthermore, we present a family of algorithms inspired by classical phase retrieval techniques. Finally, we propose a conjecture on the stability of the problem based on bi-Lipschitz analysis, supported by numerical experiments.

Paper number 18:
Title: Proxy Control Barrier Functions: Integrating Barrier-Based and Lyapunov-Based Safety-Critical Control Design
Authors: Yujie Wang, Xiangru Xu
Abstract: This work introduces a novel Proxy Control Barrier Function (PCBF) scheme that integrates barrier-based and Lyapunov-based safety-critical control strategies for strict-feedback systems with potentially unknown dynamics. The proposed method employs a modular design procedure, decomposing the original system into a proxy subsystem and a virtual tracking subsystem that are controlled by the control barrier function (CBF)-based and Lyapunov-based controllers, respectively. By integrating these separately designed controllers, the overall system's safety is ensured. Moreover, a new filter-based disturbance observer is utilized to design a PCBF-based safe controller for strict-feedback systems subject to mismatched disturbances. This approach broadens the class of systems to which CBF-based methods can be applied and significantly simplifies CBF construction by requiring only the model of the proxy subsystem. The effectiveness of the proposed method is demonstrated through numerical simulations.

Paper number 19:
Title: Wireless Channel Measurements and Characterization in Industrial IoT Scenarios
Authors: Li Zhang, Cheng-Xiang Wang, Zihao Zhou, Yuxiao Li, Jie Huang, Lijian Xin, Chun Pan, Dabo Zheng, Xiping Wu
Abstract: Wireless Fidelity (Wi-Fi) communication technologies hold significant potential for realizing the Industrial Internet of Things (IIoT). In this paper, both Single-Input Single-Output (SISO) and polarized Multiple-Input Multiple-Output (MIMO) channel measurements are conducted in an IIoT scenario at the less congested Wi-Fi band, i.e., 5.5~GHz. The purpose is to investigate wireless characteristics of communications between access points and terminals mounted on automated guided vehicles as well as those surrounding manufacturing areas. For SISO channel measurements, statistical properties including the delay Power Spectral Density (PSD), path loss, shadowing fading, delay spread, excess delay, K-factor, and amplitude distribution of small-scale fading are analyzed and compared with those observed in an office scenario. For MIMO channel measurements, results show that there are multiple Dense Multipath Component (DMC) processes in the delay PSD. An estimation algorithm based on the algorithm for a single DMC process is proposed to effectively process the multi-processes data. Moreover, delay, angular, power, and polarization properties of DMCs are investigated and compared with those of specular multipath components. Furthermore, effects of DMCs on Singular Values (SVs) and channel capacities are explored. Ignoring DMCs can overestimate SVs and underestimate channel capacities.

Paper number 20:
Title: Towards a Generalizable Speech Marker for Parkinson's Disease Diagnosis
Authors: Maksim Siniukov, Ellie Xing, Sanaz, Attaripour Isfahani, Mohammad Soleymani
Abstract: Parkinson's Disease (PD) is a neurodegenerative disorder characterized by motor symptoms, including altered voice production in the early stages. Early diagnosis is crucial not only to improve PD patients' quality of life but also to enhance the efficacy of potential disease-modifying therapies during early neurodegeneration, a window often missed by current diagnostic tools. In this paper, we propose a more generalizable approach to PD recognition through domain adaptation and self-supervised learning. We demonstrate the generalization capabilities of the proposed approach across diverse datasets in different languages. Our approach leverages HuBERT, a large deep neural network originally trained for speech recognition and further trains it on unlabeled speech data from a population that is similar to the target group, i.e., the elderly, in a self-supervised manner. The model is then fine-tuned and adapted for use across different datasets in multiple languages, including English, Italian, and Spanish. Evaluations on four publicly available PD datasets demonstrate the model's efficacy, achieving an average specificity of 92.1% and an average sensitivity of 91.2%. This method offers objective and consistent evaluations across large populations, addressing the variability inherent in human assessments and providing a non-invasive, cost-effective and accessible diagnostic option.

Paper number 21:
Title: A Value Mapping Virtual Staining Framework for Large-scale Histological Imaging
Authors: Junjia Wang, Bo Xiong, You Zhou, Xun Cao, Zhan Ma
Abstract: The emergence of virtual staining technology provides a rapid and efficient alternative for researchers in tissue pathology. It enables the utilization of unlabeled microscopic samples to generate virtual replicas of chemically stained histological slices, or facilitate the transformation of one staining type into another. The remarkable performance of generative networks, such as CycleGAN, offers an unsupervised learning approach for virtual coloring, overcoming the limitations of high-quality paired data required in supervised learning. Nevertheless, large-scale color transformation necessitates processing large field-of-view images in patches, often resulting in significant boundary inconsistency and artifacts. Additionally, the transformation between different colorized modalities typically needs further efforts to modify loss functions and tune hyperparameters for independent training of networks. In this study, we introduce a general virtual staining framework that is adaptable to various conditions. We propose a loss function based on the value mapping constraint to ensure the accuracy of virtual coloring between different pathological modalities, termed the Value Mapping Generative Adversarial Network (VM-GAN). Meanwhile, we present a confidence-based tiling method to address the challenge of boundary inconsistency arising from patch-wise processing. Experimental results on diverse data with varying staining protocols demonstrate that our method achieves superior quantitative indicators and improved visual perception.

Paper number 22:
Title: A 3D Continuous-Space Electromagnetic Channel Model for 6G Tri-Polarized Multi-user Communications
Authors: Yue Yang, Cheng-Xiang Wang, Jie Huang, John Thompson, H. Vincent Poor
Abstract: It is envisioned that the sixth generation (6G) and beyond 6G (B6G) wireless communication networks will enable global coverage in space, air, ground, and sea. In this case, both base stations and users can be mobile and will tend to move continuously in three-dimensional (3D) space. Therefore, obtaining channel state information (CSI) in 3D continuous-space is crucial for the design and performance evaluation of future 6G and B6G wireless systems. On the other hand, new 6G technologies such as integrated sensing and communications (ISAC) will also require prior knowledge of CSI in 3D continuous-space. In this paper, a 3D continuous-space electromagnetic channel model is proposed for tri-polarized multi-user communications, taking into account scatterers and spherical wavefronts. Scattered fields are calculated using the method of moments (MoM) with high accuracy. Spherical wave functions are utilized to decompose the dyadic Green's functions that connect the transmitted source currents and the received electric fields. Simulation results demonstrate that transmit power, apertures, scatterers, and sample intervals have significant impacts on statistical properties and channel capacities, providing insights into the performance of continuous-space electromagnetic channel models and the design of future wireless systems.

Paper number 23:
Title: Universal Speaker Embedding Free Target Speaker Extraction and Personal Voice Activity Detection
Authors: Bang Zeng, Ming Li
Abstract: Determining 'who spoke what and when' remains challenging in real-world applications. In typical scenarios, Speaker Diarization (SD) is employed to address the problem of 'who spoke when,' while Target Speaker Extraction (TSE) or Target Speaker Automatic Speech Recognition (TSASR) techniques are utilized to resolve the issue of 'who spoke what.' Although some works have achieved promising results by combining SD and TSE systems, inconsistencies remain between SD and TSE regarding both output inconsistency and scenario mismatch. To address these limitations, we propose a Universal Speaker Embedding Free Target Speaker Extraction and Personal Voice Activity Detection (USEF-TP) model that jointly performs TSE and Personal Voice Activity Detection (PVAD). USEF-TP leverages frame-level features obtained through a cross-attention mechanism as speaker-related features instead of using speaker embeddings as in traditional approaches. Additionally, a multi-task learning algorithm with a scenario-aware differentiated loss function is applied to ensure robust performance across various levels of speaker overlap. The experimental results show that our proposed USEF-TP model achieves superior performance in TSE and PVAD tasks on the LibriMix and SparseLibriMix datasets.

Paper number 24:
Title: Study of Frictional and Impact Transients in Active-Passive Mechanical Pair
Authors: Michael Ruderman, Francesco De Rito
Abstract: We consider an active-passive mechanical pair in which the relative motion of the latter is constrained by the mechanical impact. The system dynamics is described by the previously introduced modeling frameworks of force transition and dissipation through the nonlinear Coulomb friction and structural damping, the later in accord with Hertzian contact theory. The focus of the recent study is on combining both interaction mechanisms, and the detailed experimental evaluation which discloses validity of the modeling assumptions. Such mechanical pair interactions can be found in various mechatronic systems and mechanisms, like for example clutches, backlash elements, sliding items on the shaking and inclining surfaces, conveyor belts and others. This practical study demonstrates and discusses the transients of a vibro-impact dynamics and shows theoretical developments in line with experimental evaluation.

Paper number 25:
Title: Imitation Learning of MPC with Neural Networks: Error Guarantees and Sparsification
Authors: Hendrik Alsmeier, Lukas Theiner, Anton Savchenko, Ali Mesbah, Rolf Findeisen
Abstract: This paper presents a framework for bounding the approximation error in imitation model predictive controllers utilizing neural networks. Leveraging the Lipschitz properties of these neural networks, we derive a bound that guides dataset design to ensure the approximation error remains at chosen limits. We discuss how this method can be used to design a stable neural network controller with performance guarantees employing existing robust model predictive control approaches for data generation. Additionally, we introduce a training adjustment, which is based on the sensitivities of the optimization problem and reduces dataset density requirements based on the derived bounds. We verify that the proposed augmentation results in improvements to the network's predictive capabilities and a reduction of the Lipschitz constant. Moreover, on a simulated inverted pendulum problem, we show that the approach results in a closer match of the closed-loop behavior between the imitation and the original model predictive controller.

Paper number 26:
Title: Detecting Neurocognitive Disorders through Analyses of Topic Evolution and Cross-modal Consistency in Visual-Stimulated Narratives
Authors: Jinchao Li, Yuejiao Wang, Junan Li, Jiawen Kang, Bo Zheng, Simon Wong, Brian Mak, Helene Fung, Jean Woo, Man-Wai Mak, Timothy Kwok, Vincent Mok, Xianmin Gong, Xixin Wu, Xunying Liu, Patrick Wong, Helen Meng
Abstract: Early detection of neurocognitive disorders (NCDs) is crucial for timely intervention and disease management. Speech analysis offers a non-intrusive and scalable screening method, particularly through narrative tasks in neuropsychological assessment tools. Traditional narrative analysis often focuses on local indicators in microstructure, such as word usage and syntax. While these features provide insights into language production abilities, they often fail to capture global narrative patterns, or microstructures. Macrostructures include coherence, thematic organization, and logical progressions, reflecting essential cognitive skills potentially critical for recognizing NCDs. Addressing this gap, we propose to investigate specific cognitive and linguistic challenges by analyzing topical shifts, temporal dynamics, and the coherence of narratives over time, aiming to reveal cognitive deficits by identifying narrative impairments, and exploring their impact on communication and cognition. The investigation is based on the CU-MARVEL Rabbit Story corpus, which comprises recordings of a story-telling task from 758 older adults. We developed two approaches: the Dynamic Topic Models (DTM)-based temporal analysis to examine the evolution of topics over time, and the Text-Image Temporal Alignment Network (TITAN) to evaluate the coherence between spoken narratives and visual stimuli. DTM-based approach validated the effectiveness of dynamic topic consistency as a macrostructural metric (F1=0.61, AUC=0.78). The TITAN approach achieved the highest performance (F1=0.72, AUC=0.81), surpassing established microstructural and macrostructural feature sets. Cross-comparison and regression tasks further demonstrated the effectiveness of proposed dynamic macrostructural modeling approaches for NCD detection.

Paper number 27:
Title: Re-Visible Dual-Domain Self-Supervised Deep Unfolding Network for MRI Reconstruction
Authors: Hao Zhang, Qi Wang, Jian Sun, Zhijie Wen, Jun Shi, Shihui Ying
Abstract: Magnetic Resonance Imaging (MRI) is widely used in clinical practice, but suffered from prolonged acquisition time. Although deep learning methods have been proposed to accelerate acquisition and demonstrate promising performance, they rely on high-quality fully-sampled datasets for training in a supervised manner. However, such datasets are time-consuming and expensive-to-collect, which constrains their broader applications. On the other hand, self-supervised methods offer an alternative by enabling learning from under-sampled data alone, but most existing methods rely on further partitioned under-sampled k-space data as model's input for training, resulting in a loss of valuable information. Additionally, their models have not fully incorporated image priors, leading to degraded reconstruction performance. In this paper, we propose a novel re-visible dual-domain self-supervised deep unfolding network to address these issues when only under-sampled datasets are available. Specifically, by incorporating re-visible dual-domain loss, all under-sampled k-space data are utilized during training to mitigate information loss caused by further partitioning. This design enables the model to implicitly adapt to all under-sampled k-space data as input. Additionally, we design a deep unfolding network based on Chambolle and Pock Proximal Point Algorithm (DUN-CP-PPA) to achieve end-to-end reconstruction, incorporating imaging physics and image priors to guide the reconstruction process. By employing a Spatial-Frequency Feature Extraction (SFFE) block to capture global and local feature representation, we enhance the model's efficiency to learn comprehensive image priors. Experiments conducted on the fastMRI and IXI datasets demonstrate that our method significantly outperforms state-of-the-art approaches in terms of reconstruction performance.

Paper number 28:
Title: Pseudo Strong Labels from Frame-Level Predictions for Weakly Supervised Sound Event Detection
Authors: Yuliang Zhang, Defeng (David)Huang, Roberto Togneri
Abstract: Weakly Supervised Sound Event Detection (WSSED), which relies on audio tags without precise onset and offset times, has become prevalent due to the scarcity of strongly labeled data that includes exact temporal boundaries for events. This study introduces Frame-level Pseudo Strong Labeling (FPSL) to overcome the lack of temporal information in WSSED by generating pseudo strong labels from frame-level predictions. This enhances temporal localization during training and addresses the limitations of clip-wise weak supervision. We validate our approach across three benchmark datasets (DCASE2017 Task 4, DCASE2018 Task 4, and UrbanSED) and demonstrate significant improvements in key metrics such as the Polyphonic Sound Detection Scores (PSDS), event-based F1 scores, and intersection-based F1 scores. For example, Convolutional Recurrent Neural Networks (CRNNs) trained with FPSL outperform baseline models by 4.9% in PSDS1 on DCASE2017, 7.6% on DCASE2018, and 1.8% on UrbanSED, confirming the effectiveness of our method in enhancing model performance.

Paper number 29:
Title: SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment
Authors: Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou
Abstract: In practical sleep stage classification, a key challenge is the variability of EEG data across different subjects and environments. Differences in physiology, age, health status, and recording conditions can lead to domain shifts between data. These domain shifts often result in decreased model accuracy and reliability, particularly when the model is applied to new data with characteristics different from those it was originally trained on, which is a typical manifestation of negative transfer. To address this, we propose SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi Resolution Convolutional Neural Network (MRCNN) to extract EEG features, capturing the distinctive characteristics of different sleep stages. To mitigate the effect of domain shifts, we introduce a domain aligning mechanism that employs Earth Mover Distance (EMD) to evaluate and select source domain data closely matching the target domain. By finetuning the model with selective source data, our SelectiveFinetuning enhances the model's performance on target domain that exhibits domain shifts compared to the data used for training. Experimental results show that our method outperforms existing baselines, offering greater robustness and adaptability in practical scenarios where data distributions are often unpredictable.

Paper number 30:
Title: Convergent Primal-Dual Plug-and-Play Image Restoration: A General Algorithm and Applications
Authors: Yodai Suzuki, Ryosuke Isono, Shunsuke Ono
Abstract: We propose a general deep plug-and-play (PnP) algorithm with a theoretical convergence guarantee. PnP strategies have demonstrated outstanding performance in various image restoration tasks by exploiting the powerful priors underlying Gaussian denoisers. However, existing PnP methods often lack theoretical convergence guarantees under realistic assumptions due to their ad-hoc nature, resulting in inconsistent behavior. Moreover, even when convergence guarantees are provided, they are typically designed for specific settings or require a considerable computational cost in handling non-quadratic data-fidelity terms and additional constraints, which are key components in many image restoration scenarios. To tackle these challenges, we integrate the PnP paradigm with primal-dual splitting (PDS), an efficient proximal splitting methodology for solving a wide range of convex optimization problems, and develop a general convergent PnP framework. Specifically, we establish theoretical conditions for the convergence of the proposed PnP algorithm under a reasonable assumption. Furthermore, we show that the problem solved by the proposed PnP algorithm is not a standard convex optimization problem but a more general monotone inclusion problem, where we provide a mathematical representation of the solution set. Our approach efficiently handles a broad class of image restoration problems with guaranteed theoretical convergence. Numerical experiments on specific image restoration tasks validate the practicality and effectiveness of our theoretical results.

Paper number 31:
Title: STAR-RIS Aided Dynamic Scatterers Tracking for Integrated Sensing and Communications
Authors: Muye Li, Shun Zhang, Yao Ge, Chau Yuen
Abstract: Integrated sensing and communication (ISAC) has become an attractive technology for future wireless networks. In this paper, we propose a simultaneous transmission and reflection reconfigurable intelligent surface (STAR-RIS) aided dynamic scatterers tracking scheme for ISAC in high mobility millimeter wave communication systems, where the STAR-RIS is employed to provide communication service for indoor user with the base station (BS) and simultaneously sense and track the interested outdoor dynamic scatterers. Specifically, we resort to an active STAR-RIS to respectively receive and further deal with the impinging signal from its double sides at the same time. Then, we develop a transmission strategy with the activation scheme of the STAR-RIS elements, and construct the signal models within the system. After acquiring the channel parameters related to the BS-RIS channel, the dynamic paths can be identified from all the scattering paths, and the dynamic targets can be classified with respect to their radar cross sections. We further track the outdoor scatterers at STAR-RIS by resorting to the Gaussian mixture-probability hypothesis density filter. With the tracked locations of the outdoor scatterers, a beam prediction strategy for both the precoder of BS and the refraction phase shift vector of STAR-RIS is developed to enhance the communication performance of the indoor user. Besides, a target mismatch detection and path collision prediction mechanism is proposed to reduce the training overhead and improve the transmission performance. Finally, the feasibility and effectiveness of our proposed STAR-RIS aided dynamic scatterers tracking scheme for ISAC are demonstrated and verified via simulation results.

Paper number 32:
Title: Use Cases for Terahertz Communications: An Industrial Perspective
Authors: Tommaso Zugno, Cristina Ciochina, Sharad Sambhwani, Patrick Svedman, Luis M. Pessoa, Ben Chen, Per Hjalmar Lehne, Mate Boban, Thomas Kürner
Abstract: Thanks to the vast amount of available resources and unique propagation properties, terahertz (THz) frequency bands are viewed as a key enabler for achieving ultrahigh communication performance and precise sensing capabilities in future wireless systems. Recently, the European Telecommunications Standards Institute (ETSI) initiated an Industry Specification Group (ISG) on THz which aims at establishing the technical foundation for subsequent standardization of this technology, which is pivotal for its successful integration into future networks. Starting from the work recently finalized within this group, this paper provides an industrial perspective on potential use cases and frequency bands of interest for THz communication systems. We first identify promising frequency bands in the 100 GHz - 1 THz range, offering over 500 GHz of available spectrum that can be exploited to unlock the full potential of THz communications. Then, we present key use cases and application areas for THz communications, emphasizing the role of this technology and its advantages over other frequency bands. We discuss their target requirements and show that some applications demand for multi-Tbps data rates, latency below 0.5 ms, and sensing accuracy down to 0.5 cm. Additionally, we identify the main deployment scenarios and outline other enabling technologies crucial for overcoming the challenges faced by THz system. Finally, we summarize the past and ongoing standardization efforts focusing on THz communications, while also providing an outlook towards the inclusion of this technology as an integral part of the future sixth generation (6G) and beyond communication networks.

Paper number 33:
Title: Deep Sylvester Posterior Inference for Adaptive Compressed Sensing in Ultrasound Imaging
Authors: Simon W. Penninga, Hans van Gorp, Ruud J.G. van Sloun
Abstract: Ultrasound images are commonly formed by sequential acquisition of beam-steered scan-lines. Minimizing the number of required scan-lines can significantly enhance frame rate, field of view, energy efficiency, and data transfer speeds. Existing approaches typically use static subsampling schemes in combination with sparsity-based or, more recently, deep-learning-based recovery. In this work, we introduce an adaptive subsampling method that maximizes intrinsic information gain in-situ, employing a Sylvester Normalizing Flow encoder to infer an approximate Bayesian posterior under partial observation in real-time. Using the Bayesian posterior and a deep generative model for future observations, we determine the subsampling scheme that maximizes the mutual information between the subsampled observations, and the next frame of the video. We evaluate our approach using the EchoNet cardiac ultrasound video dataset and demonstrate that our active sampling method outperforms competitive baselines, including uniform and variable-density random sampling, as well as equidistantly spaced scan-lines, improving mean absolute reconstruction error by 15%. Moreover, posterior inference and the sampling scheme generation are performed in just 0.015 seconds (66Hz), making it fast enough for real-time 2D ultrasound imaging applications.

Paper number 34:
Title: Spectral-Aware Low-Rank Adaptation for Speaker Verification
Authors: Zhe Li, Man-wai Mak, Mert Pilanci, Hung-yi Lee, Helen Meng
Abstract: Previous research has shown that the principal singular vectors of a pre-trained model's weight matrices capture critical knowledge. In contrast, those associated with small singular values may contain noise or less reliable information. As a result, the LoRA-based parameter-efficient fine-tuning (PEFT) approach, which does not constrain the use of the spectral space, may not be effective for tasks that demand high representation capacity. In this study, we enhance existing PEFT techniques by incorporating the spectral information of pre-trained weight matrices into the fine-tuning process. We investigate spectral adaptation strategies with a particular focus on the additive adjustment of top singular vectors. This is accomplished by applying singular value decomposition (SVD) to the pre-trained weight matrices and restricting the fine-tuning within the top spectral space. Extensive speaker verification experiments on VoxCeleb1 and CN-Celeb1 demonstrate enhanced tuning performance with the proposed approach. Code is released at this https URL.

Paper number 35:
Title: SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis
Authors: Runci Bai
Abstract: Brain tumors can result in neurological dysfunction, alterations in cognitive and psychological states, increased intracranial pressure, and the occurrence of seizures, thereby presenting a substantial risk to human life and health. The You Only Look Once(YOLO) series models have demonstrated superior accuracy in object detection for medical imaging. In this paper, we develop a novel SCC-YOLO architecture by integrating the SCConv attention mechanism into YOLOv9. The SCConv module reconstructs an efficient convolutional module by reducing spatial and channel redundancy among features, thereby enhancing the learning of image features. We investigate the impact of intergrating different attention mechanisms with the YOLOv9 model on brain tumor image detection using both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset). Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3% improvement in mAp50 compared to YOLOv9, while on our self-made dataset, SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached state-of-the-art performance in brain tumor detection. Source code is available at : this https URL

Paper number 36:
Title: MedFocusCLIP : Improving few shot classification in medical datasets using pixel wise attention
Authors: Aadya Arora, Vinay Namboodiri
Abstract: With the popularity of foundational models, parameter efficient fine tuning has become the defacto approach to leverage pretrained models to perform downstream tasks. Taking inspiration from recent advances in large language models, Visual Prompt Tuning, and similar techniques, learn an additional prompt to efficiently finetune a pretrained vision foundational model. However, we observe that such prompting is insufficient for fine-grained visual classification tasks such as medical image classification, where there is large inter-class variance, and small intra-class variance. Hence, in this paper we propose to leverage advanced segmentation capabilities of Segment Anything Model 2 (SAM2) as a visual prompting cue to help visual encoder in the CLIP (Contrastive Language-Image Pretraining) by guiding the attention in CLIP visual encoder to relevant regions in the image. This helps the model to focus on highly discriminative regions, without getting distracted from visually similar background features, an essential requirement in a fewshot, finegrained classification setting. We evaluate our method on diverse medical datasets including X-rays, CT scans, and MRI images, and report an accuracy of (71%, 81%, 86%, 58%) from the proposed approach on (COVID, lung-disease, brain-tumor, breast-cancer) datasets against (66%, 70%, 68%, 29%) from a pretrained CLIP model after fewshot training. The proposed approach also allows to obtain interpretable explanation for the classification performance through the localization obtained using segmentation.

Paper number 37:
Title: Semise: Semi-supervised learning for severity representation in medical image
Authors: Dung T. Tran, Hung Vu, Anh Tran, Hieu Pham, Hong Nguyen, Phong Nguyen
Abstract: This paper introduces SEMISE, a novel method for representation learning in medical imaging that combines self-supervised and supervised learning. By leveraging both labeled and augmented data, SEMISE addresses the challenge of data scarcity and enhances the encoder's ability to extract meaningful features. This integrated approach leads to more informative representations, improving performance on downstream tasks. As result, our approach achieved a 12% improvement in classification and a 3% improvement in segmentation, outperforming existing methods. These results demonstrate the potential of SIMESE to advance medical image analysis and offer more accurate solutions for healthcare applications, particularly in contexts where labeled data is limited.

Paper number 38:
Title: SELMA3D challenge: Self-supervised learning for 3D light-sheet microscopy image segmentation
Authors: Ying Chen, Rami Al-Maskari, Izabela Horvath, Mayar Ali, Luciano Höher, Kaiyuan Yang, Zengming Lin, Zhiwei Zhai, Mengzhe Shen, Dejin Xun, Yi Wang, Tony Xu, Maged Goubran, Yunheng Wu, Ali Erturk, Johannes C. Paetzold
Abstract: Recent innovations in light sheet microscopy, paired with developments in tissue clearing techniques, enable the 3D imaging of large mammalian tissues with cellular resolution. Combined with the progress in large-scale data analysis, driven by deep learning, these innovations empower researchers to rapidly investigate the morphological and functional properties of diverse biological samples. Segmentation, a crucial preliminary step in the analysis process, can be automated using domain-specific deep learning models with expert-level performance. However, these models exhibit high sensitivity to domain shifts, leading to a significant drop in accuracy when applied to data outside their training distribution. To address this limitation, and inspired by the recent success of self-supervised learning in training generalizable models, we organized the SELMA3D Challenge during the MICCAI 2024 conference. SELMA3D provides a vast collection of light-sheet images from cleared mice and human brains, comprising 35 large 3D images-each with over 1000^3 voxels-and 315 annotated small patches for finetuning, preliminary testing and final testing. The dataset encompasses diverse biological structures, including vessel-like and spot-like structures. Five teams participated in all phases of the challenge, and their proposed methods are reviewed in this paper. Quantitative and qualitative results from most participating teams demonstrate that self-supervised learning on large datasets improves segmentation model performance and generalization. We will continue to support and extend SELMA3D as an inaugural MICCAI challenge focused on self-supervised learning for 3D microscopy image segmentation.

Paper number 39:
Title: Robust Moving-horizon Estimation for Nonlinear Systems: From Perfect to Imperfect Optimization
Authors: Angelo Alessandri
Abstract: Robust stability of moving-horizon estimators is investigated for nonlinear discrete-time systems that are detectable in the sense of incremental input/output-to-state stability and are affected by disturbances. The estimate of a moving-horizon estimator stems from the on-line solution of a least-squares minimization problem at each time instant. The resulting stability guarantees depend on the optimization tolerance in solving such minimization problems. Specifically, two main contributions are established: (i) the robust stability of the estimation error, while supposing to solve exactly the on-line minimization problem; (ii) the practical robust stability of the estimation error with state estimates obtained by an imperfect minimization. Finally, the construction of such robust moving-horizon estimators and the performances resulting from the design based on the theoretical findings are showcased with two numerical examples.

Paper number 40:
Title: Bridging Auditory Perception and Language Comprehension through MEG-Driven Encoding Models
Authors: Matteo Ciferri, Matteo Ferrante, Nicola Toschi
Abstract: Understanding the neural mechanisms behind auditory and linguistic processing is key to advancing cognitive neuroscience. In this study, we use Magnetoencephalography (MEG) data to analyze brain responses to spoken language stimuli. We develop two distinct encoding models: an audio-to-MEG encoder, which uses time-frequency decompositions (TFD) and wav2vec2 latent space representations, and a text-to-MEG encoder, which leverages CLIP and GPT-2 embeddings. Both models successfully predict neural activity, demonstrating significant correlations between estimated and observed MEG signals. However, the text-to-MEG model outperforms the audio-based model, achieving higher Pearson Correlation (PC) score. Spatially, we identify that auditory-based embeddings (TFD and wav2vec2) predominantly activate lateral temporal regions, which are responsible for primary auditory processing and the integration of auditory signals. In contrast, textual embeddings (CLIP and GPT-2) primarily engage the frontal cortex, particularly Broca's area, which is associated with higher-order language processing, including semantic integration and language production, especially in the 8-30 Hz frequency range. The strong involvement of these regions suggests that auditory stimuli are processed through more direct sensory pathways, while linguistic information is encoded via networks that integrate meaning and cognitive control. Our results reveal distinct neural pathways for auditory and linguistic information processing, with higher encoding accuracy for text representations in the frontal regions. These insights refine our understanding of the brain's functional architecture in processing auditory and textual information, offering quantitative advancements in the modelling of neural responses to complex language stimuli.

Paper number 41:
Title: A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based on Large Language Models Enhanced by Domain Knowledge Retrieval
Authors: Shuo Tong, Runyuan Guo, Wenqing Wang, Xueqiong Tian, Lingyun Wei, Lin Zhang, Huayong Wu, Ding Liu, Youmin Zhang
Abstract: Data-driven soft sensors are crucial in predicting key performance indicators in industrial systems. However, current methods predominantly rely on the supervised learning paradigms of parameter updating, which inherently faces challenges such as high development costs, poor robustness, training instability, and lack of interpretability. Recently, large language models (LLMs) have demonstrated significant potential across various domains, notably through In-Context Learning (ICL), which enables high-performance task execution with minimal input-label demonstrations and no prior training. This paper aims to replace supervised learning with the emerging ICL paradigm for soft sensor modeling to address existing challenges and explore new avenues for advancement. To achieve this, we propose a novel framework called the Few-shot Uncertainty-aware and self-Explaining Soft Sensor (LLM-FUESS), which includes the Zero-shot Auxiliary Variable Selector (LLM-ZAVS) and the Uncertainty-aware Few-shot Soft Sensor (LLM-UFSS). The LLM-ZAVS retrieves from the Industrial Knowledge Vector Storage to enhance LLMs' domain-specific knowledge, enabling zero-shot auxiliary variable selection. In the LLM-UFSS, we utilize text-based context demonstrations of structured data to prompt LLMs to execute ICL for predicting and propose a context sample retrieval augmentation strategy to improve performance. Additionally, we explored LLMs' AIGC and probabilistic characteristics to propose self-explanation and uncertainty quantification methods for constructing a trustworthy soft sensor. Extensive experiments demonstrate that our method achieved state-of-the-art predictive performance, strong robustness, and flexibility, effectively mitigates training instability found in traditional methods. To the best of our knowledge, this is the first work to establish soft sensor utilizing LLMs.

Paper number 42:
Title: Quantum Feature-Empowered Deep Classification for Fast Mangrove Mapping
Authors: Chia-Hsiang Lin, Po-Wei Tang, Alfredo R. Huete
Abstract: A mangrove mapping (MM) algorithm is an essential classification tool for environmental monitoring. The recent literature shows that compared with other index-based MM methods that treat pixels as spatially independent, convolutional neural networks (CNNs) are crucial for leveraging spatial continuity information, leading to improved classification performance. In this work, we go a step further to show that quantum features provide radically new information for CNN to further upgrade the classification results. Simply speaking, CNN computes affine-mapping features, while quantum neural network (QNN) offers unitary-computing features, thereby offering a fresh perspective in the final decision-making (classification). To address the challenging MM problem, we design an entangled spatial-spectral quantum feature extraction module. Notably, to ensure that the quantum features contribute genuinely novel information (unaffected by traditional CNN features), we design a separate network track consisting solely of quantum neurons with built-in interpretability. The extracted pure quantum information is then fused with traditional feature information to jointly make the final decision. The proposed quantum-empowered deep network (QEDNet) is very lightweight, so the improvement does come from the cooperation between CNN and QNN (rather than parameter augmentation). Extensive experiments will be conducted to demonstrate the superiority of QEDNet.

Paper number 43:
Title: Power System Steady-State Estimation Revisited
Authors: Pavel Rytir, Ales Wodecki, Martin Malachov, Pavel Baxant, Premysl Vorac, Miloslava Chladova, Jakub Marecek
Abstract: In power system steady-state estimation (PSSE), one needs to consider (1) the need for robust statistics, (2) the nonconvex transmission constraints, (3) the fast-varying nature of the inputs, and the corresponding need to track optimal trajectories as closely as possible. In combination, these challenges have not been considered, yet. In this paper, we address all three challenges. The need for robustness (1) is addressed by using an approach based on the so-called Huber model. The non-convexity (2) of the problem, which results in first order methods failing to find global minima, is dealt with by applying global methods. One of these methods is based on a mixed integer quadratic formulation, which provides results of several orders of magnitude better than conventional gradient descent. Lastly, the trajectory tracking (3) is discussed by showing under which conditions the trajectory tracking of the SDP relaxations has meaning.

Paper number 44:
Title: TinySense: A Lighter Weight and More Power-efficient Avionics System for Flying Insect-scale Robots
Authors: Zhitao Yu, Joshua Tran, Claire Li, Aaron Weber, Yash P.Talwekar, Sawyer Fuller
Abstract: In this paper, we investigate the prospects and challenges of sensor suites in achieving autonomous control for flying insect robots (FIRs) weighing less than a gram. FIRs, owing to their minuscule weight and size, offer unparalleled advantages in terms of material cost and scalability. However, their size introduces considerable control challenges, notably high-speed dynamics, restricted power, and limited payload capacity. While there have been notable advancements in developing lightweight sensors, often drawing inspiration from biological systems, no sub-gram aircraft has been able to attain sustained hover without relying on feedback from external sensing such as a motion capture system. The lightest vehicle capable of sustained hover -- the first level of "sensor autonomy" -- is the much larger 28 g Crazyflie. Previous work reported a reduction in size of that vehicle's avionics suite to 187 mg and 21 mW. Here, we report a further reduction in mass and power to only 78.4 mg and 15 mW. We replaced the laser rangefinder with a lighter and more efficient pressure sensor, and built a smaller optic flow sensor around a global-shutter imaging chip. A Kalman Filter (KF) fuses these measurements to estimate the state variables that are needed to control hover: pitch angle, translational velocity, and altitude. Our system achieved performance comparable to that of the Crazyflie's estimator while in flight, with root mean squared errors of 1.573 degrees, 0.186 m/s, and 0.139 m, respectively, relative to motion capture.

Paper number 45:
Title: Feasibility of short blocklength Reed-Muller codes for coset coding over real environment
Authors: Md Munibun Billah, Tyler Sweat, Willie K. Harrison
Abstract: In this paper, we investigate the application of Reed-Muller (RM) codes for Physical-layer security in a real world wiretap channel scenario. Utilizing software-defined radios (SDRs) in a real indoor environment, we implement a coset coding scheme that leverages the hierarchical structure of RM codes to secure data transmission. The generator matrix of the RM code is used to partition codewords into cosets in the usual way, where each message corresponds to a unique coset, and auxiliary bits select specific codewords within each coset. This approach enables the legitimate receiver (Bob) can decode the transmitted message with minimal bit error rate (BER), while an eavesdropper (Eve) experiences a high BER, thus protecting the confidentiality of the communication. Mutual Information Neural Estimation (MINE) is employed to quantify the information leakage and validate the effectiveness of the scheme. Experimental results indicate that RM codes can achieve robust security even in practical environments affected by real-world channel impairments. These findings demonstrate the potential of RM codes as an efficient solution for physical-layer security, particularly for applications that require low latency and short blocklengths.

Paper number 46:
Title: Radar Signal Recognition through Self-Supervised Learning and Domain Adaptation
Authors: Zi Huang, Akila Pemasiri, Simon Denman, Clinton Fookes, Terrence Martin
Abstract: Automatic radar signal recognition (RSR) plays a pivotal role in electronic warfare (EW), as accurately classifying radar signals is critical for informing decision-making processes. Recent advances in deep learning have shown significant potential in improving RSR performance in domains with ample annotated data. However, these methods fall short in EW scenarios where annotated RF data are scarce or impractical to obtain. To address these challenges, we introduce a self-supervised learning (SSL) method which utilises masked signal modelling and RF domain adaption to enhance RSR performance in environments with limited RF samples and labels. Specifically, we investigate pre-training masked autoencoders (MAE) on baseband in-phase and quadrature (I/Q) signals from various RF domains and subsequently transfer the learned representation to the radar domain, where annotated data are limited. Empirical results show that our lightweight self-supervised ResNet model with domain adaptation achieves up to a 17.5\% improvement in 1-shot classification accuracy when pre-trained on in-domain signals (i.e., radar signals) and up to a 16.31\% improvement when pre-trained on out-of-domain signals (i.e., comm signals), compared to its baseline without SSL. We also provide reference results for several MAE designs and pre-training strategies, establishing a new benchmark for few-shot radar signal classification.

Paper number 47:
Title: LHGNN: Local-Higher Order Graph Neural Networks For Audio Classification and Tagging
Authors: Shubhr Singh, Emmanouil Benetos, Huy Phan, Dan Stowell
Abstract: Transformers have set new benchmarks in audio processing tasks, leveraging self-attention mechanisms to capture complex patterns and dependencies within audio data. However, their focus on pairwise interactions limits their ability to process the higher-order relations essential for identifying distinct audio objects. To address this limitation, this work introduces the Local- Higher Order Graph Neural Network (LHGNN), a graph based model that enhances feature understanding by integrating local neighbourhood information with higher-order data from Fuzzy C-Means clusters, thereby capturing a broader spectrum of audio relationships. Evaluation of the model on three publicly available audio datasets shows that it outperforms Transformer-based models across all benchmarks while operating with substantially fewer parameters. Moreover, LHGNN demonstrates a distinct advantage in scenarios lacking ImageNet pretraining, establishing its effectiveness and efficiency in environments where extensive pretraining data is unavailable.

Paper number 48:
Title: Extending Internet Access Over LoRa for Internet of Things and Critical Applications
Authors: Atonu Ghosh, Devadeep Misra, Hirdesh Mewada
Abstract: LoRa bridges the gap between remote locations and mainstream networks, enabling large-scale Internet of Things (IoT) deployments. Despite the recent advancements around LoRa, Internet access over this technology is still largely unexplored. Most existing solutions only handle packets within the local LoRa network and do not interact with web applications. This limits the scalability and the ability to deliver essential web services in disconnected regions. This work proposes and implements ILoRa to extend the public Internet to disconnected areas for essential service delivery. ILoRa enables accessing Application Programming Interfaces (APIs) and web pages on the Internet over a LoRa backbone network. It comprises a ILoRa coordinator code (ICN) and access point nodes (APNs). The ICN interfaces the LoRa network with the public Internet and interprets content. The APN tethers a WiFi hotspot to which devices connect and access the web content. This work further proposes data handling methods for ICNs and APNs. An actual hardware-based implementation validates the proposed system. The implementation achieves a throughput of 1.06 kbps tested for an Internet-based API returning JSON data of 930 B. Furthermore, the APN consumed approximately $0.162$A current, and the resource utilization on the ICN was minimal.

Paper number 49:
Title: Vocal Tract Length Warped Features for Spoken Keyword Spotting
Authors: Achintya kr. Sarkar, Priyanka Dwivedi, Zheng-Hua Tan
Abstract: In this paper, we propose several methods that incorporate vocal tract length (VTL) warped features for spoken keyword spotting (KWS). The first method, VTL-independent KWS, involves training a single deep neural network (DNN) that utilizes VTL features with various warping factors. During training, a specific VTL feature is randomly selected per epoch, allowing the exploration of VTL variations. During testing, the VTL features with different warping factors of a test utterance are scored against the DNN and combined with equal weight. In the second method scores the conventional features of a test utterance (without VTL warping) against the DNN. The third method, VTL-concatenation KWS, concatenates VTL warped features to form high-dimensional features for KWS. Evaluations carried out on the English Google Command dataset demonstrate that the proposed methods improve the accuracy of KWS.

Paper number 50:
Title: Distributionally Robust Joint Chance-Constrained Optimal Power Flow using Relative Entropy
Authors: Eli Brock, Haixiang Zhang, Javad Lavaei, Somayeh Sojoudi
Abstract: Designing robust algorithms for the optimal power flow (OPF) problem is critical for the control of large-scale power systems under uncertainty. The chance-constrained OPF (CCOPF) problem provides a natural formulation of the trade-off between the operating cost and the constraint satisfaction rate. In this work, we propose a new data-driven algorithm for the CCOPF problem, based on distributionally robust optimization (DRO). \revise{We show that the proposed reformulation of the distributionally robust chance constraints is exact, whereas other approaches in the CCOPF literature rely on conservative approximations. We establish out-of-sample robustness guarantees for the distributionally robust solution and prove that the solution is the most efficient among all approaches enjoying the same guarantees.} We apply the proposed algorithm to the the CCOPF problem and compare the performance of our approach with existing methods using simulations on IEEE benchmark power systems.

Paper number 51:
Title: AADNet: Exploring EEG Spatiotemporal Information for Fast and Accurate Orientation and Timbre Detection of Auditory Attention Based on A Cue-Masked Paradigm
Authors: Keren Shi, Xu Liu, Xue Yuan, Haijie Shang, Ruiting Dai, Hanbin Wang, Yunfa Fu, Ning Jiang, Jiayuan He
Abstract: Auditory attention decoding from electroencephalogram (EEG) could infer to which source the user is attending in noisy environments. Decoding algorithms and experimental paradigm designs are crucial for the development of technology in practical applications. To simulate real-world scenarios, this study proposed a cue-masked auditory attention paradigm to avoid information leakage before the experiment. To obtain high decoding accuracy with low latency, an end-to-end deep learning model, AADNet, was proposed to exploit the spatiotemporal information from the short time window of EEG signals. The results showed that with a 0.5-second EEG window, AADNet achieved an average accuracy of 93.46% and 91.09% in decoding auditory orientation attention (OA) and timbre attention (TA), respectively. It significantly outperformed five previous methods and did not need the knowledge of the original audio source. This work demonstrated that it was possible to detect the orientation and timbre of auditory attention from EEG signals fast and accurately. The results are promising for the real-time multi-property auditory attention decoding, facilitating the application of the neuro-steered hearing aids and other assistive listening devices.

Paper number 52:
Title: ConcealGS: Concealing Invisible Copyright Information in 3D Gaussian Splatting
Authors: Yifeng Yang, Hengyu Liu, Chenxin Li, Yining Sun, Wuyang Li, Yifan Liu, Yiyang Lin, Yixuan Yuan, Nanyang Ye
Abstract: With the rapid development of 3D reconstruction technology, the widespread distribution of 3D data has become a future trend. While traditional visual data (such as images and videos) and NeRF-based formats already have mature techniques for copyright protection, steganographic techniques for the emerging 3D Gaussian Splatting (3D-GS) format have yet to be fully explored. To address this, we propose ConcealGS, an innovative method for embedding implicit information into 3D-GS. By introducing the knowledge distillation and gradient optimization strategy based on 3D-GS, ConcealGS overcomes the limitations of NeRF-based models and enhances the robustness of implicit information and the quality of 3D reconstruction. We evaluate ConcealGS in various potential application scenarios, and experimental results have demonstrated that ConcealGS not only successfully recovers implicit information but also has almost no impact on rendering quality, providing a new approach for embedding invisible and recoverable information into 3D models in the future.

Paper number 53:
Title: A Novel Approach to Real-Time Short-Term Traffic Prediction based on Distributed Fiber-Optic Sensing and Data Assimilation with a Stochastic Cell-Automata Model
Authors: Yoshiyuki Yajima, Hemant Prasad, Daisuke Ikefuji, Takemasa Suzuki, Shin Tominaga, Hitoshi Sakurai, Manabu Otani
Abstract: This paper demonstrates real-time short-term traffic flow prediction through distributed fiber-optic sensing (DFOS) and data assimilation with a stochastic cell-automata-based traffic model. Traffic congestion on expressways is a severe issue. To alleviate its negative impacts, it is necessary to optimize traffic flow prior to becoming serious congestion. For this purpose, real-time short-term traffic flow prediction is promising. However, conventional traffic monitoring apparatus used in prediction methods faces a technical issue due to the sparsity in traffic flow data. To overcome the issue for realizing real-time traffic prediction, this paper employs DFOS, which enables to obtain spatially continuous and real-time traffic flow data along the road without dead zones. Using mean velocities derived from DFOS data as a feature extraction, this paper proposes a real-time data assimilation method for the short-term prediction. As the theoretical model, the stochastic Nishinari-Fukui-Schadschneider model is adopted. Future traffic flow is simulated with the optimal values of model parameters estimated from observed mean velocities and the initial condition estimated as the latest microscopic traffic state. This concept is validated using two congestion scenarios obtained in Japanese expressways. The results show that the mean absolute error of the predicted mean velocities is 10-15 km/h in the prediction horizon of 30 minutes. Furthermore, the prediction error in congestion length and travel time decreases by 40-84% depending on congestion scenarios when compared with conventional methods with traffic counters. This paper concludes that real-time data assimilation using DFOS enables an accurate short-term traffic prediction.

Paper number 54:
Title: Effective and Efficient Mixed Precision Quantization of Speech Foundation Models
Authors: Haoning Xu, Zhaoqing Li, Zengrui Jin, Huimeng Wang, Youjun Chen, Guinan Li, Mengzhe Geng, Shujie Hu, Jiajun Deng, Xunying Liu
Abstract: This paper presents a novel mixed-precision quantization approach for speech foundation models that tightly integrates mixed-precision learning and quantized model parameter estimation into one single model compression stage. Experiments conducted on LibriSpeech dataset with fine-tuned wav2vec2.0-base and HuBERT-large models suggest the resulting mixed-precision quantized models increased the lossless compression ratio by factors up to 1.7x and 1.9x over the respective uniform-precision and two-stage mixed-precision quantized baselines that perform precision learning and model parameters quantization in separate and disjointed stages, while incurring no statistically word error rate (WER) increase over the 32-bit full-precision models. The system compression time of wav2vec2.0-base and HuBERT-large models is reduced by up to 1.9 and 1.5 times over the two-stage mixed-precision baselines, while both produce lower WERs. The best-performing 3.5-bit mixed-precision quantized HuBERT-large model produces a lossless compression ratio of 8.6x over the 32-bit full-precision system.

Paper number 55:
Title: MAJL: A Model-Agnostic Joint Learning Framework for Music Source Separation and Pitch Estimation
Authors: Haojie Wei, Jun Yuan, Rui Zhang, Quanyu Dai, Yueguo Chen
Abstract: Music source separation and pitch estimation are two vital tasks in music information retrieval. Typically, the input of pitch estimation is obtained from the output of music source separation. Therefore, existing methods have tried to perform these two tasks simultaneously, so as to leverage the mutually beneficial relationship between both tasks. However, these methods still face two critical challenges that limit the improvement of both tasks: the lack of labeled data and joint learning optimization. To address these challenges, we propose a Model-Agnostic Joint Learning (MAJL) framework for both tasks. MAJL is a generic framework and can use variant models for each task. It includes a two-stage training method and a dynamic weighting method named Dynamic Weights on Hard Samples (DWHS), which addresses the lack of labeled data and joint learning optimization, respectively. Experimental results on public music datasets show that MAJL outperforms state-of-the-art methods on both tasks, with significant improvements of 0.92 in Signal-to-Distortion Ratio (SDR) for music source separation and 2.71% in Raw Pitch Accuracy (RPA) for pitch estimation. Furthermore, comprehensive studies not only validate the effectiveness of each component of MAJL, but also indicate the great generality of MAJL in adapting to different model architectures.

Paper number 56:
Title: Stabilization of Strictly Pre-Dissipative Receding Horizon Linear Quadratic Control by Terminal Costs
Authors: Mario Zanon, Lars Grüne
Abstract: Asymptotic stability in receding horizon control is obtained under a strict pre-dissipativity assumption, in the presence of suitable state constraints. In this paper we analyze how terminal constraints can be replaced by suitable terminal costs. We restrict to the linear-quadratic setting as that allows us to obtain stronger results, while we analyze the full nonlinear case in a separate contribution.

Paper number 57:
Title: Unsupervised Speech Segmentation: A General Approach Using Speech Language Models
Authors: Avishai Elmakies, Omri Abend, Yossi Adi
Abstract: In this paper, we introduce an unsupervised approach for Speech Segmentation, which builds on previously researched approaches, e.g., Speaker Diarization, while being applicable to an inclusive set of acoustic-semantic distinctions, paving a path towards a general Unsupervised Speech Segmentation approach. Unlike traditional speech and audio segmentation, which mainly focuses on spectral changes in the input signal, e.g., phone segmentation, our approach tries to segment the spoken utterance into chunks with differing acoustic-semantic styles, focusing on acoustic-semantic information that does not translate well into text, e.g., emotion or speaker. While most Speech Segmentation tasks only handle one style change, e.g., emotion diarization, our approach tries to handle multiple acoustic-semantic style changes. Leveraging recent advances in Speech Language Models (SLMs), we propose a simple unsupervised method to segment a given speech utterance. We empirically demonstrate the effectiveness of the proposed approach by considering several setups. Results suggest that the proposed method is superior to the evaluated baselines on boundary detection, segment purity, and over-segmentation. Code is available at this https URL.

Paper number 58:
Title: Guitar-TECHS: An Electric Guitar Dataset Covering Techniques, Musical Excerpts, Chords and Scales Using a Diverse Array of Hardware
Authors: Hegel Pedroza, Wallace Abreu, Ryan M. Corey, Iran R. Roman
Abstract: Guitar-related machine listening research involves tasks like timbre transfer, performance generation, and automatic transcription. However, small datasets often limit model robustness due to insufficient acoustic diversity and musical content. To address these issues, we introduce Guitar-TECHS, a comprehensive dataset featuring a variety of guitar techniques, musical excerpts, chords, and scales. These elements are performed by diverse musicians across various recording settings. Guitar-TECHS incorporates recordings from two stereo microphones: an egocentric microphone positioned on the performer's head and an exocentric microphone placed in front of the performer. It also includes direct input recordings and microphoned amplifier outputs, offering a wide spectrum of audio inputs and recording qualities. All signals and MIDI labels are properly synchronized. Its multi-perspective and multi-modal content makes Guitar-TECHS a valuable resource for advancing data-driven guitar research, and to develop robust guitar listening algorithms. We provide empirical data to demonstrate the dataset's effectiveness in training robust models for Guitar Tablature Transcription.

Paper number 59:
Title: A Multimodal Lightweight Approach to Fault Diagnosis of Induction Motors in High-Dimensional Dataset
Authors: Usman Ali
Abstract: An accurate AI-based diagnostic system for induction motors (IMs) holds the potential to enhance proactive maintenance, mitigating unplanned downtime and curbing overall maintenance costs within an industrial environment. Notably, among the prevalent faults in IMs, a Broken Rotor Bar (BRB) fault is frequently encountered. Researchers have proposed various fault diagnosis approaches using signal processing (SP), machine learning (ML), deep learning (DL), and hybrid architectures for BRB faults. One limitation in the existing literature is the training of these architectures on relatively small datasets, risking overfitting when implementing such systems in industrial environments. This paper addresses this limitation by implementing large-scale data of BRB faults by using a transfer-learning-based lightweight DL model named ShuffleNetV2 for diagnosing one, two, three, and four BRB faults using current and vibration signal data. Spectral images for training and testing are generated using a Short-Time Fourier Transform (STFT). The dataset comprises 57,500 images, with 47,500 used for training and 10,000 for testing. Remarkably, the ShuffleNetV2 model exhibited superior performance, in less computational cost as well as accurately classifying 98.856% of spectral images. To further enhance the visualization of harmonic sidebands resulting from broken bars, Fast Fourier Transform (FFT) is applied to current and vibration data. The paper also provides insights into the training and testing times for each model, contributing to a comprehensive understanding of the proposed fault diagnosis methodology. The findings of our research provide valuable insights into the performance and efficiency of different ML and DL models, offering a foundation for the development of robust fault diagnosis systems for induction motors in industrial settings.

Paper number 60:
Title: NeuroIncept Decoder for High-Fidelity Speech Reconstruction from Neural Activity
Authors: Owais Mujtaba Khanday, José L. Pérez-Córdoba, Mohd Yaqub Mir, Ashfaq Ahmad Najar, Jose A. Gonzalez-Lopez
Abstract: This paper introduces a novel algorithm designed for speech synthesis from neural activity recordings obtained using invasive electroencephalography (EEG) techniques. The proposed system offers a promising communication solution for individuals with severe speech impairments. Central to our approach is the integration of time-frequency features in the high-gamma band computed from EEG recordings with an advanced NeuroIncept Decoder architecture. This neural network architecture combines Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRUs) to reconstruct audio spectrograms from neural patterns. Our model demonstrates robust mean correlation coefficients between predicted and actual spectrograms, though inter-subject variability indicates distinct neural processing mechanisms among participants. Overall, our study highlights the potential of neural decoding techniques to restore communicative abilities in individuals with speech disorders and paves the way for future advancements in brain-computer interface technologies.

Paper number 61:
Title: Image Segmentation: Inducing graph-based learning
Authors: Aryan Singh, Pepijn Van de Ven, Ciarán Eising, Patrick Denny
Abstract: This study explores the potential of graph neural networks (GNNs) to enhance semantic segmentation across diverse image modalities. We evaluate the effectiveness of a novel GNN-based U-Net architecture on three distinct datasets: PascalVOC, a standard benchmark for natural image segmentation, WoodScape, a challenging dataset of fisheye images commonly used in autonomous driving, introducing significant geometric distortions; and ISIC2016, a dataset of dermoscopic images for skin lesion segmentation. We compare our proposed UNet-GNN model against established convolutional neural networks (CNNs) based segmentation models, including U-Net and U-Net++, as well as the transformer-based SwinUNet. Unlike these methods, which primarily rely on local convolutional operations or global self-attention, GNNs explicitly model relationships between image regions by constructing and operating on a graph representation of the image features. This approach allows the model to capture long-range dependencies and complex spatial relationships, which we hypothesize will be particularly beneficial for handling geometric distortions present in fisheye imagery and capturing intricate boundaries in medical images. Our analysis demonstrates the versatility of GNNs in addressing diverse segmentation challenges and highlights their potential to improve segmentation accuracy in various applications, including autonomous driving and medical image analysis.

Paper number 62:
Title: Multi-label Cross-lingual automatic music genre classification from lyrics with Sentence BERT
Authors: Tiago Fernandes Tavares, Fabio José Ayres
Abstract: Music genres are shaped by both the stylistic features of songs and the cultural preferences of artists' audiences. Automatic classification of music genres using lyrics can be useful in several applications such as recommendation systems, playlist creation, and library organization. We present a multi-label, cross-lingual genre classification system based on multilingual sentence embeddings generated by sBERT. Using a bilingual Portuguese-English dataset with eight overlapping genres, we demonstrate the system's ability to train on lyrics in one language and predict genres in another. Our approach outperforms the baseline approach of translating lyrics and using a bag-of-words representation, improving the genrewise average F1-Score from 0.35 to 0.69. The classifier uses a one-vs-all architecture, enabling it to assign multiple genre labels to a single lyric. Experimental results reveal that dataset centralization notably improves cross-lingual performance. This approach offers a scalable solution for genre classification across underrepresented languages and cultural domains, advancing the capabilities of music information retrieval systems.

Paper number 63:
Title: Detecting the Undetectable: Assessing the Efficacy of Current Spoof Detection Methods Against Seamless Speech Edits
Authors: Sung-Feng Huang, Heng-Cheng Kuo, Zhehuai Chen, Xuesong Yang, Chao-Han Huck Yang, Yu Tsao, Yu-Chiang Frank Wang, Hung-yi Lee, Szu-Wei Fu
Abstract: Neural speech editing advancements have raised concerns about their misuse in spoofing attacks. Traditional partially edited speech corpora primarily focus on cut-and-paste edits, which, while maintaining speaker consistency, often introduce detectable discontinuities. Recent methods, like A\textsuperscript{3}T and Voicebox, improve transitions by leveraging contextual information. To foster spoofing detection research, we introduce the Speech INfilling Edit (SINE) dataset, created with Voicebox. We detailed the process of re-implementing Voicebox training and dataset creation. Subjective evaluations confirm that speech edited using this novel technique is more challenging to detect than conventional cut-and-paste methods. Despite human difficulty, experimental results demonstrate that self-supervised-based detectors can achieve remarkable performance in detection, localization, and generalization across different edit methods. The dataset and related models will be made publicly available.

Paper number 64:
Title: Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media
Authors: Ning Zhang, Timothy Shea, Arto Nurmikko
Abstract: Tracking and acquiring simultaneous optical images of randomly moving targets obscured by scattering media remains a challenging problem of importance to many applications that require precise object localization and identification. In this work we develop an end-to-end neuromorphic optical engineering and computational approach to demonstrate how to track and image normally invisible objects by combining an event detecting camera with a multistage neuromorphic deep learning strategy. Photons emerging from dense scattering media are detected by the event camera and converted to pixel-wise asynchronized spike trains - a first step in isolating object-specific information from the dominant uninformative background. Spiking data is fed into a deep spiking neural network (SNN) engine where object tracking and image reconstruction are performed by two separate yet interconnected modules running in parallel in discrete time steps over the event duration. Through benchtop experiments we demonstrate tracking and imaging randomly moving objects in dense turbid media as well as image reconstruction of spatially stationary but optically dynamic objects. Standardized character sets serve as representative proxies for geometrically complex objects, underscoring the method's generality. The results highlight the advantages of a fully neuromorphic approach in meeting a major imaging technology with high computational efficiency and low power consumption.

Paper number 65:
Title: Channel Coding based on Skew Polynomials and Multivariate Polynomials
Authors: Hedongliang Liu
Abstract: This dissertation considers new constructions and decoding approaches for error-correcting codes based on non-conventional polynomials, with the objective of providing new coding solutions to the applications mentioned above. With skew polynomials, we construct codes that are dual-containing, which is a desired property of quantum error-correcting codes. By considering evaluation codes based on skew polynomials, a condition on the existence of optimal support-constrained codes is derived and an application of such codes in the distributed multi-source networks is proposed. For a class of multicast networks, the advantage of vector network coding compared to scalar network coding is investigated. Multivariate polynomials have been attracting increasing interest in constructing codes with repair capabilities by accessing only a small amount of available symbols, which is required to build failure-resistant distributed storage systems. A new class of bivariate evaluation codes and their local recovery capability are studied. Interestingly, the well-known Reed-Solomon codes are used in a class of locally recoverable codes with availability (multiple disjoint recovery sets) via subspace design. Aside from new constructions, decoding approaches are considered in order to increase the error correction capability in the case where the code is fixed. In particular, new lower and upper bounds on the success probability of joint decoding interleaved alternant codes by a syndrome-based decoder are derived, where alternant codes are an important class of algebraic codes containing Goppa codes, BCH codes, and Reed-Muller codes as sub-classes.

Paper number 66:
Title: Resilient Control of Dynamic Flow Networks Subject to Stochastic Cyber-Physical Disruptions
Authors: Yu Tang, Li Jin
Abstract: Modern network systems, such as transportation and communication systems, are prone to cyber-physical disruptions and thus suffer efficiency loss. This paper studies network resiliency, in terms of throughput, and develops resilient control to improve throughput. We consider single-commodity networks that admit congestion propagation. We also apply a Markov process to model disruption switches. For throughput analysis, we first use insights into congestion spillback to propose novel Lyapunov functions and then exploit monotone network dynamics to reduce computational costs of verifying stability conditions. For control design, we show that (i) for a network with infinite link storage space, there exists an open-loop control that attains the min-expected-cut capacity; (ii) for a network with observable disruptions that restrict maximum sending and/or receiving flows, there exists a mode-dependent control that attains the expected-min-cut capacity; (iii) for general networks, there exists a closed-loop control with throughput guarantees. We also derive lower bounds of resiliency scores for a set of numerical examples and verify resiliency improvement with our method.

Paper number 67:
Title: Optimal Time-Invariant Distributed Formation Tracking for Second-Order Multi-Agent Systems
Authors: Marco Fabris, Giulio Fattore, Angelo Cenedese
Abstract: This paper addresses the optimal time-invariant formation tracking problem with the aim of providing a distributed solution for multi-agent systems with second-order integrator dynamics. In the literature, most of the results related to multi-agent formation tracking do not consider energy issues while investigating distributed feedback control laws. In order to account for this crucial design aspect, we contribute by formalizing and proposing a solution to an optimization problem that encapsulates trajectory tracking, distance-based formation control and input energy minimization, through a specific and key choice of potential functions in the optimization cost. To this end, we show how to compute the inverse dynamics in a centralized fashion by means of the Projector-Operator-based Newton's method for Trajectory Optimization (PRONTO) and, more importantly, we exploit such an offline solution as a general reference to devise a stabilizing online distributed control law. Finally, numerical examples involving a cubic formation following a chicane-like path in the 3D space are provided to validate the proposed control strategies.

Paper number 68:
Title: Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model in End-to-End Speech Recognition
Authors: Yosuke Higuchi, Tetsuji Ogawa, Tetsunori Kobayashi
Abstract: We propose to utilize an instruction-tuned large language model (LLM) for guiding the text generation process in automatic speech recognition (ASR). Modern large language models (LLMs) are adept at performing various text generation tasks through zero-shot learning, prompted with instructions designed for specific objectives. This paper explores the potential of LLMs to derive linguistic information that can facilitate text generation in end-to-end ASR models. Specifically, we instruct an LLM to correct grammatical errors in an ASR hypothesis and use the LLM-derived representations to refine the output further. The proposed model is built on the joint CTC and attention architecture, with the LLM serving as a front-end feature extractor for the decoder. The ASR hypothesis, subject to correction, is obtained from the encoder via CTC decoding and fed into the LLM along with a specific instruction. The decoder subsequently takes as input the LLM output to perform token predictions, combining acoustic information from the encoder and the powerful linguistic information provided by the LLM. Experimental results show that the proposed LLM-guided model achieves a relative gain of approximately 13\% in word error rates across major benchmarks.

Paper number 69:
Title: Understanding Concepts in Graph Signal Processing for Neurophysiological Signal Analysis
Authors: Stephan Goerttler, Fei He, Min Wu
Abstract: Multivariate signals, which are measured simultaneously over time and acquired by sensor networks, are becoming increasingly common. The emerging field of graph signal processing (GSP) promises to analyse spectral characteristics of these multivariate signals, while at the same time taking the spatial structure between the time signals into account. A central idea in GSP is the graph Fourier transform, which projects a multivariate signal onto frequency-ordered graph Fourier modes, and can therefore be regarded as a spatial analog of the temporal Fourier transform. This chapter derives and discusses key concepts in GSP, with a specific focus on how the various concepts relate to one another. The experimental section focuses on the role of graph frequency in data classification, with applications to neuroimaging. To address the limited sample size of neurophysiological datasets, we introduce a minimalist simulation framework that can generate arbitrary amounts of data. Using this artificial data, we find that lower graph frequency signals are less suitable for classifying neurophysiological data as compared to higher graph frequency signals. Finally, we introduce a baseline testing framework for GSP. Employing this framework, our results suggest that GSP applications may attenuate spectral characteristics in the signals, highlighting current limitations of GSP for neuroimaging.

Paper number 70:
Title: Harnessing Uncertainty for a Separation Principle in Direct Data-Driven Predictive Control
Authors: Alessandro Chiuso, Marco Fabris, Valentina Breschi, Simone Formentin
Abstract: Model Predictive Control (MPC) is a powerful method for complex system regulation, but its reliance on an accurate model poses many limitations in real-world applications. Data-driven predictive control (DDPC) aims at overcoming this limitation, by relying on historical data to provide information on the plant to be controlled. In this work, we present a unified stochastic framework for direct DDPC, where control actions are obtained by optimizing the Final Control Error (FCE), which is directly computed from available data only and automatically weighs the impact of uncertainty on the control objective. Our framework allows us to establish a separation principle for Predictive Control, elucidating the role that predictive models and their uncertainty play in DDPC. Moreover, it generalizes existing DDPC methods, like regularized Data-enabled Predictive Control (DeePC) and $\gamma$-DDPC, providing a path toward noise-tolerant data-based control with rigorous optimality guarantees. The theoretical investigation is complemented by a series of experiments (code available on GitHub: this https URL), revealing that the proposed method consistently outperforms or, at worst, matches existing techniques without requiring tuning regularization parameters as other methods do.

Paper number 71:
Title: Predicting risk of cardiovascular disease using retinal OCT imaging
Authors: Cynthia Maldonado-Garcia, Rodrigo Bonazzola, Enzo Ferrante, Thomas H Julian, Panagiotis I Sergouniotis, Nishant Ravikumara, Alejandro F Frangi
Abstract: Cardiovascular diseases (CVD) are the leading cause of death globally. Non-invasive, cost-effective imaging techniques play a crucial role in early detection and prevention of CVD. Optical coherence tomography (OCT) has gained recognition as a potential tool for early CVD risk prediction, though its use remains underexplored. In this study, we investigated the potential of OCT as an additional imaging technique to predict future CVD events. We analysed retinal OCT data from the UK Biobank. The dataset included 612 patients who suffered a myocardial infarction (MI) or stroke within five years of imaging and 2,234 controls without CVD (total: 2,846 participants). A self-supervised deep learning approach based on Variational Autoencoders (VAE) was used to extract low-dimensional latent representations from high-dimensional 3D OCT images, capturing distinct features of retinal layers. These latent features, along with clinical data, were used to train a Random Forest (RF) classifier to differentiate between patients at risk of future CVD events (MI or stroke) and healthy controls. Our model achieved an AUC of 0.75, sensitivity of 0.70, specificity of 0.70, and accuracy of 0.70, outperforming the QRISK3 score (the third version of the QRISK cardiovascular disease risk prediction algorithm; AUC = 0.60, sensitivity = 0.60, specificity = 0.55, accuracy = 0.55). The choroidal layer in OCT images was identified as a key predictor of future CVD events, revealed through a novel model explainability approach. This study demonstrates that retinal OCT imaging is a cost-effective, non-invasive alternative for predicting CVD risk, offering potential for widespread application in optometry practices and hospitals.

Paper number 72:
Title: Deep Learning-based Accelerated MR Cholangiopancreatography without Fully-sampled Data
Authors: Jinho Kim, Marcel Dominik Nickel, Florian Knoll
Abstract: The purpose of this study was to accelerate MR cholangiopancreatography (MRCP) acquisitions using deep learning-based (DL) reconstruction at 3T and 0.55T. A total of 35 healthy volunteers underwent conventional two-fold accelerated MRCP scans at field strengths of 3T and 0.55T. We trained DL reconstructions using two different training strategies, supervised (SV) and self-supervised (SSV), with retrospectively six-fold undersampled data obtained at 3T. We then evaluated the DL reconstructions against standard techniques, parallel imaging (PI) and compressed sensing (CS), focusing on peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) as metrics. We also tested DL reconstructions with prospectively accelerated acquisitions and evaluated their robustness when changing fields strengths from 3T to 0.55T. DL reconstructions demonstrated a reduction in average acquisition time from 599/542 to 255/180 seconds for MRCP at 3T/0.55T. In both retrospective and prospective undersampling, PSNR and SSIM of DL reconstructions were higher than those of PI and CS. At the same time, DL reconstructions preserved the image quality of undersampled data, including sharpness and the visibility of hepatobiliary ducts. In addition, both DL approaches produced high-quality reconstructions at 0.55T. In summary, DL reconstructions trained for highly accelerated MRCP enabled a reduction in acquisition time by a factor of 2.4/3.0 at 3T/0.55T while maintaining the image quality of conventional acquisitions.

Paper number 73:
Title: Achieving Distributed MIMO Performance with Repeater-Assisted Cellular Massive MIMO
Authors: Sara Willhammar, Hiroki Iimori, Joao Vieira, Lars Sundström, Fredrik Tufvesson, Erik G. Larsson
Abstract: In what ways could cellular massive MIMO be improved? This technology has already been shown to bring huge performance gains. However, coverage holes and difficulties to transmit multiple streams to multi-antenna users because of insufficient channel rank remain issues. Distributed MIMO, also known as cell-free massive MIMO, might be the ultimate solution. However, while being a powerful technology, it is expensive to install backhaul, and it is a difficult problem to achieve accurate phase alignment for coherent multi-user beamforming on downlink. Another option is reflective intelligent surfaces - but they have large form factors and require a lot of training and control overhead, and probably, in practice, some form of active filtering to make them sufficiently band-selective. We propose a new approach to densification of cellular systems, envisioning repeater-assisted cellular massive MIMO, where a large numbers of physically small and cheap wireless repeaters are deployed. They receive and retransmit signals instantaneously, appearing as active scatterers. Meaning that they appear as ordinary channel scatterers but with amplification. We elaborate on the requirements of such repeaters, show that the performance of these systems could potentially approach that of distributed MIMO, and outline future research directions.

Paper number 74:
Title: Joint Observer Gain and Input Design for Asymptotic Active Fault Diagnosis
Authors: Feng Xu, Yiming Wan, Ye Wang, Vicenc Puig
Abstract: This paper proposes a joint gain and input design method for observer-based asymptotic active fault diagnosis, which is based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a single gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.

Paper number 75:
Title: ImageFlowNet: Forecasting Multiscale Image-Level Trajectories of Disease Progression with Irregularly-Sampled Longitudinal Medical Images
Authors: Chen Liu, Ke Xu, Liangbo L. Shen, Guillaume Huguet, Zilong Wang, Alexander Tong, Danilo Bzdok, Jay Stewart, Jay C. Wang, Lucian V. Del Priore, Smita Krishnaswamy
Abstract: Advances in medical imaging technologies have enabled the collection of longitudinal images, which involve repeated scanning of the same patients over time, to monitor disease progression. However, predictive modeling of such data remains challenging due to high dimensionality, irregular sampling, and data sparsity. To address these issues, we propose ImageFlowNet, a novel model designed to forecast disease trajectories from initial images while preserving spatial details. ImageFlowNet first learns multiscale joint representation spaces across patients and time points, then optimizes deterministic or stochastic flow fields within these spaces using a position-parameterized neural ODE/SDE framework. The model leverages a UNet architecture to create robust multiscale representations and mitigates data scarcity by combining knowledge from all patients. We provide theoretical insights that support our formulation of ODEs, and motivate our regularizations involving high-level visual features, latent space organization, and trajectory smoothness. We validate ImageFlowNet on three longitudinal medical image datasets depicting progression in geographic atrophy, multiple sclerosis, and glioblastoma, demonstrating its ability to effectively forecast disease progression and outperform existing methods. Our contributions include the development of ImageFlowNet, its theoretical underpinnings, and empirical validation on real-world datasets. The official implementation is available at this https URL.

Paper number 76:
Title: Robust Backstepping Control of a Quadrotor Unmanned Aerial Vehicle Under Colored Noises
Authors: Mehmet Karahan
Abstract: Advances in software and hardware technologies have facilitated the production of quadrotor unmanned aerial vehicles (UAVs). Nowadays, people actively use quadrotor UAVs in essential missions such as search and rescue, counter-terrorism, firefighting, surveillance, and cargo transportation. While performing these tasks, quadrotors must operate in noisy environments. Therefore, a robust controller design that can control the altitude and attitude of the quadrotor in noisy environments is of great importance. Many researchers have focused only on white Gaussian noise in their studies, whereas researchers need to consider the effects of all colored noises during the operation of the quadrotor. This study aims to design a robust controller that is resistant to all colored noises. Firstly, a nonlinear quadrotor model was created with MATLAB. Then, a backstepping controller resistant to colored noises was designed. The designed backstepping controller was tested under Gaussian white, pink, brown, blue, and purple noises. PID and Lyapunov-based controller designs were also carried out, and their time responses (rise time, overshoot, settling time) were compared with those of the backstepping controller. In the simulations, time was in seconds, altitude was in meters, and roll, pitch, and yaw references were in radians. Rise and settling time values were in seconds, and overshoot value was in percent. When the obtained values are examined, simulations prove that the proposed backstepping controller has the least overshoot and the shortest settling time under all noise types.

Paper number 77:
Title: Flemme: A Flexible and Modular Learning Platform for Medical Images
Authors: Guoqing Zhang, Jingyun Yang, Yang Li
Abstract: As the rapid development of computer vision and the emergence of powerful network backbones and architectures, the application of deep learning in medical imaging has become increasingly significant. Unlike natural images, medical images lack huge volumes of data but feature more modalities, making it difficult to train a general model that has satisfactory performance across various datasets. In practice, practitioners often suffer from manually creating and testing models combining independent backbones and architectures, which is a laborious and time-consuming process. We propose Flemme, a FLExible and Modular learning platform for MEdical images. Our platform separates encoders from the model architectures so that different models can be constructed via various combinations of supported encoders and architectures. We construct encoders using building blocks based on convolution, transformer, and state-space model (SSM) to process both 2D and 3D image patches. A base architecture is implemented following an encoder-decoder style, with several derived architectures for image segmentation, reconstruction, and generation tasks. In addition, we propose a general hierarchical architecture incorporating a pyramid loss to optimize and fuse vertical features. Experiments demonstrate that this simple design leads to an average improvement of 5.60% in Dice score and 7.81% in mean interaction of units (mIoU) for segmentation models, as well as an enhancement of 5.57% in peak signal-to-noise ratio (PSNR) and 8.22% in structural similarity (SSIM) for reconstruction models. We further utilize Flemme as an analytical tool to assess the effectiveness and efficiency of various encoders across different tasks. Code is available at this https URL.

Paper number 78:
Title: Fast Structured Orthogonal Dictionary Learning using Householder Reflections
Authors: Anirudh Dash, Aditya Siripuram
Abstract: In this paper, we propose and investigate algorithms for the structured orthogonal dictionary learning problem. First, we investigate the case when the dictionary is a Householder matrix. We give sample complexity results and show theoretically guaranteed approximate recovery (in the $l_{\infty}$ sense) with optimal computational complexity. We then attempt to generalize these techniques when the dictionary is a product of a few Householder matrices. We numerically validate these techniques in the sample-limited setting to show performance similar to or better than existing techniques while having much improved computational complexity.

Paper number 79:
Title: Improving Speech Emotion Recognition in Under-Resourced Languages via Speech-to-Speech Translation with Bootstrapping Data Selection
Authors: Hsi-Che Lin, Yi-Cheng Lin, Huang-Cheng Chou, Hung-yi Lee
Abstract: Speech Emotion Recognition (SER) is a crucial component in developing general-purpose AI agents capable of natural human-computer interaction. However, building robust multilingual SER systems remains challenging due to the scarcity of labeled data in languages other than English and Chinese. In this paper, we propose an approach to enhance SER performance in low SER resource languages by leveraging data from high-resource languages. Specifically, we employ expressive Speech-to-Speech translation (S2ST) combined with a novel bootstrapping data selection pipeline to generate labeled data in the target language. Extensive experiments demonstrate that our method is both effective and generalizable across different upstream models and languages. Our results suggest that this approach can facilitate the development of more scalable and robust multilingual SER systems.

Paper number 80:
Title: Enhancing the automatic segmentation and analysis of 3D liver vasculature models
Authors: Yassine Machta, Omar Ali, Kevin Hakkakian, Ana Vlasceanu, Amaury Facque, Nicolas Golse, Irene Vignon-Clementel
Abstract: Surgical assessment of liver cancer patients requires identification of the vessel trees from medical images. Specifically, the venous trees - the portal (perfusing) and the hepatic (draining) trees are important for understanding the liver anatomy and disease state, and perform surgery planning. This research aims to improve the 3D segmentation, skeletonization, and subsequent analysis of vessel trees, by creating an automatic pipeline based on deep learning and image processing techniques. The first part of this work explores the impact of differentiable skeletonization methods such as ClDice and morphological skeletonization loss, on the overall liver vessel segmentation performance. To this aim, it studies how to improve vessel tree connectivity. The second part of this study converts a single class vessel segmentation into multi-class ones, separating the two venous trees. It builds on the previous two-class vessel segmentation model, which vessel tree outputs might be entangled, and on connected components and skeleton analyses of the trees. After providing sub-labeling of the specific anatomical branches of each venous tree, these algorithms also enable a morphometric analysis of the vessel trees by extracting various geometrical markers. In conclusion, we propose a method that successfully improves current skeletonization methods, for extensive vascular trees that contain vessels of different calibers. The separation algorithm creates a clean multi-class segmentation of the vessels, validated by surgeons to provide low error. A new, publicly shared high-quality liver vessel dataset of 77 cases is thus created. Finally a method to annotate vessel trees according to anatomy is provided, enabling a unique liver vessel morphometry analysis.

Paper number 81:
Title: GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution
Authors: Qiwei Zhu, Kai Li, Guojing Zhang, Xiaoying Wang, Jianqiang Huang, Xilai Li
Abstract: In recent years, deep neural networks, including Convolutional Neural Networks, Transformers, and State Space Models, have achieved significant progress in Remote Sensing Image (RSI) Super-Resolution (SR). However, existing SR methods typically overlook the complementary relationship between global and local dependencies. These methods either focus on capturing local information or prioritize global information, which results in models that are unable to effectively capture both global and local features simultaneously. Moreover, their computational cost becomes prohibitive when applied to large-scale RSIs. To address these challenges, we introduce the novel application of Receptance Weighted Key Value (RWKV) to RSI-SR, which captures long-range dependencies with linear complexity. To simultaneously model global and local features, we propose the Global-Detail dual-branch structure, GDSR, which performs SR reconstruction by paralleling RWKV and convolutional operations to handle large-scale RSIs. Furthermore, we introduce the Global-Detail Reconstruction Module (GDRM) as an intermediary between the two branches to bridge their complementary roles. In addition, we propose Wavelet Loss, a loss function that effectively captures high-frequency detail information in images, thereby enhancing the visual quality of SR, particularly in terms of detail reconstruction. Extensive experiments on several benchmarks, including AID, AID_CDM, RSSRD-QH, and RSSRD-QH_CDM, demonstrate that GSDR outperforms the state-of-the-art Transformer-based method HAT by an average of 0.05 dB in PSNR, while using only 63% of its parameters and 51% of its FLOPs, achieving an inference speed 2.9 times faster. Furthermore, the Wavelet Loss shows excellent generalization across various architectures, providing a novel perspective for RSI-SR enhancement.

Paper number 82:
Title: Diff-Lung: Diffusion-Based Texture Synthesis for Enhanced Pathological Tissue Segmentation in Lung CT Scans
Authors: Rezkellah Noureddine Khiati, Pierre-Yves Brillet, Radu Ispas, Catalin Fetita
Abstract: Accurate quantification of the extent of lung pathological patterns (fibrosis, ground-glass opacity, emphysema, consolidation) is prerequisite for diagnosis and follow-up of interstitial lung diseases. However, segmentation is challenging due to the significant class imbalance between healthy and pathological tissues. This paper addresses this issue by leveraging a diffusion model for data augmentation applied during training an AI model. Our approach generates synthetic pathological tissue patches while preserving essential shape characteristics and intricate details specific to each tissue type. This method enhances the segmentation process by increasing the occurence of underrepresented classes in the training data. We demonstrate that our diffusion-based augmentation technique improves segmentation accuracy across all pathological tissue types, particularly for the less common patterns. This advancement contributes to more reliable automated analysis of lung CT scans, potentially improving clinical decision-making and patient outcomes

Paper number 83:
Title: A Volumetric Approach to Privacy of Dynamical Systems
Authors: Chuanghong Weng, Ehsan Nekouei
Abstract: Information-theoretic metrics, such as mutual information, have been widely used to evaluate privacy leakage in dynamic systems. However, these approaches are typically limited to stochastic systems and face computational challenges. In this paper, we introduce a novel volumetric framework for analyzing privacy in systems affected by unknown but bounded noise. Our model considers a dynamic system comprising public and private states, where an observation set of the public state is released. An adversary utilizes the observed public state to infer an uncertainty set of the private state, referred to as the inference attack. We define the evolution dynamics of these inference attacks and quantify the privacy level of the private state using the volume of its uncertainty sets. For linear scalar systems, we derive an explicit formulation of the uncertainty set. For multi-dimensional linear systems, we develop an approximate computation method leveraging interval analysis. We investigate the properties of the proposed volumetric privacy measure and demonstrate that it is bounded by the information gain derived from the observation set. Furthermore, we propose an optimization approach to designing privacy filter using randomization and linear programming based on the proposed privacy measure. The effectiveness of the optimal privacy filter design is evaluated through a production-inventory case study, illustrating its robustness against the inference attack.

Paper number 84:
Title: Constrained Stochastic Recursive Momentum Successive Convex Approximation
Authors: Basil M. Idrees, Lavish Arora, Ketan Rajawat
Abstract: We consider stochastic optimization problems with non-convex functional constraints, such as those arising in trajectory generation, sparse approximation, and robust classification. To this end, we put forth a recursive momentum-based accelerated successive convex approximation (SCA) algorithm. At each iteration, the proposed algorithm entails constructing convex surrogates of the stochastic objective and the constraint functions, and solving the resulting convex optimization problem. A recursive update rule is employed to track the gradient of the stochastic objective function, which contributes to variance reduction and hence accelerates the algorithm convergence. A key ingredient of the proof is a new parameterized version of the standard Mangasarian-Fromowitz Constraints Qualification, that allows us to bound the dual variables and hence obtain problem-dependent bounds on the rate at which the iterates approach an $\epsilon$-stationary point. Remarkably, the proposed algorithm achieves near-optimal stochastic first-order (SFO) complexity with adaptive step sizes and optimal SFO complexity with non-adaptive step sizes at par with that achieved by state-of-the-art stochastic optimization algorithms for solving unconstrained problems. As an example, we detail a obstacle-avoiding trajectory optimization problem that can be solved using the proposed algorithm and show that its performance is superior to that of the existing algorithms used for trajectory optimization. The performance of the proposed algorithm is also shown to be comparable to that of a specialized sparse classification algorithm applied to a binary classification problem.

Paper number 85:
Title: Neural Speech and Audio Coding: Modern AI Technology Meets Traditional Codecs
Authors: Minje Kim, Jan Skoglund
Abstract: This paper explores the integration of model-based and data-driven approaches within the realm of neural speech and audio coding systems. It highlights the challenges posed by the subjective evaluation processes of speech and audio codecs and discusses the limitations of purely data-driven approaches, which often require inefficiently large architectures to match the performance of model-based methods. The study presents hybrid systems as a viable solution, offering significant improvements to the performance of conventional codecs through meticulously chosen design enhancements. Specifically, it introduces a neural network-based signal enhancer designed to post-process existing codecs' output, along with the autoencoder-based end-to-end models and LPCNet--hybrid systems that combine linear predictive coding (LPC) with neural networks. Furthermore, the paper delves into predictive models operating within custom feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and examines the use of psychoacoustically calibrated loss functions to train end-to-end neural audio codecs. Through these investigations, the paper demonstrates the potential of hybrid systems to advance the field of speech and audio coding by bridging the gap between traditional model-based approaches and modern data-driven techniques.

Paper number 86:
Title: Intelligent Router for LLM Workloads: Improving Performance Through Workload-Aware Load Balancing
Authors: Kunal Jain, Anjaly Parayil, Ankur Mallick, Esha Choukse, Xiaoting Qin, Jue Zhang, Íñigo Goiri, Rujia Wang, Chetan Bansal, Victor Rühle, Anoop Kulkarni, Steve Kofsky, Saravan Rajmohan
Abstract: Large Language Model (LLM) workloads have distinct prefill and decode phases with different compute and memory requirements which should ideally be accounted for when scheduling input queries across different LLM instances in a cluster. However existing scheduling algorithms treat LLM workloads as monolithic jobs without considering the distinct characteristics of the two phases in each workload. This leads to sub-optimal scheduling and increased response latency. In this work, we start by characterizing factors affecting the response latency during LLM inference serving. We establish that better load balancing of inference requests across the available LLM instances can improve the end-to-end latency to a larger extent than merely focusing on optimizing the instance-level scheduler. Motivated by our findings, we propose a heuristic-guided reinforcement learning-based intelligent router for data-driven and workload-aware scheduling. Our router schedules queries across LLM instances by leveraging a trainable response-length predictor, and a novel formulation for estimating the impact of mixing different workloads and achieves over 11% lower end-to-end latency than existing approaches on a mix of public datasets and 7.8% lower end-to-end latency on real workload data with diverse input and output trends from Cloud Provider X. Additionally, the proposed framework can also serve as a standard for benchmarking different LLM inference schedulers since it provides the best latency for a given model, hardware, and instance-level scheduler combination.

Paper number 87:
Title: Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer
Authors: Michele Mancusi, Yurii Halychanskyi, Kin Wai Cheuk, Eloi Moliner, Chieh-Hsin Lai, Stefan Uhlich, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Yuki Mitsufuji
Abstract: Music timbre transfer is a challenging task that involves modifying the timbral characteristics of an audio signal while preserving its melodic structure. In this paper, we propose a novel method based on dual diffusion bridges, trained using the CocoChorales Dataset, which consists of unpaired monophonic single-instrument audio data. Each diffusion model is trained on a specific instrument with a Gaussian prior. During inference, a model is designated as the source model to map the input audio to its corresponding Gaussian prior, and another model is designated as the target model to reconstruct the target audio from this Gaussian prior, thereby facilitating timbre transfer. We compare our approach against existing unsupervised timbre transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental results demonstrate that our method achieves both better Fréchet Audio Distance (FAD) and melody preservation, as reflected by lower pitch distances (DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise level from the Gaussian prior, $\sigma$, can be adjusted to control the degree of melody preservation and amount of timbre transferred.

Paper number 88:
Title: The Faetar Benchmark: Speech Recognition in a Very Under-Resourced Language
Authors: Michael Ong, Sean Robertson, Leo Peckham, Alba Jorquera Jimenez de Aberasturi, Paula Arkhangorodsky, Robin Huo, Aman Sakhardande, Mark Hallap, Naomi Nagy, Ewan Dunbar
Abstract: We introduce the Faetar Automatic Speech Recognition Benchmark, a benchmark corpus designed to push the limits of current approaches to low-resource speech recognition. Faetar, a Franco-Provençal variety spoken primarily in Italy, has no standard orthography, has virtually no existing textual or speech resources other than what is included in the benchmark, and is quite different from other forms of Franco-Provençal. The corpus comes from field recordings, most of which are noisy, for which only 5 hrs have matching transcriptions, and for which forced alignment is of variable quality. The corpus contains an additional 20 hrs of unlabelled speech. We report baseline results from state-of-the-art multilingual speech foundation models with a best phone error rate of 30.4%, using a pipeline that continues pre-training on the foundation model using the unlabelled set.

Paper number 89:
Title: Apollo: Band-sequence Modeling for High-Quality Audio Restoration
Authors: Kai Li, Yi Luo
Abstract: Audio restoration has become increasingly significant in modern society, not only due to the demand for high-quality auditory experiences enabled by advanced playback devices, but also because the growing capabilities of generative audio models necessitate high-fidelity audio. Typically, audio restoration is defined as a task of predicting undistorted audio from damaged input, often trained using a GAN framework to balance perception and distortion. Since audio degradation is primarily concentrated in mid- and high-frequency ranges, especially due to codecs, a key challenge lies in designing a generator capable of preserving low-frequency information while accurately reconstructing high-quality mid- and high-frequency content. Inspired by recent advancements in high-sample-rate music separation, speech enhancement, and audio codec models, we propose Apollo, a generative model designed for high-sample-rate audio restoration. Apollo employs an explicit frequency band split module to model the relationships between different frequency bands, allowing for more coherent and higher-quality restored audio. Evaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistently outperforms existing SR-GAN models across various bit rates and music genres, particularly excelling in complex scenarios involving mixtures of multiple instruments and vocals. Apollo significantly improves music restoration quality while maintaining computational efficiency. The source code for Apollo is publicly available at this https URL.

Paper number 90:
Title: Frequency-Dependent F-Numbers Suppress Grating Lobes and Improve the Lateral Resolution in Line-by-Line Scanning
Authors: Martin F. Schiffner
Abstract: Line-by-line scanning with linear arrays is a standard image formation method in clinical ultrasound. This method examines progressively a given region of interest by conducting focused pulse-echo measurements with dynamic transmit and receive apertures. Such apertures widen with the focal length as a function of a given F-number and improve the image quality by extending the depth of field (DOF) and suppressing grating lobes. Fixed F-numbers, however, limit the lateral resolution. Herein, frequency dependence of the F-number is incorporated into both the transmit and the receive focusing to widen the apertures for low frequencies and improve the lateral resolution. Frequency-dependent transmit and receive F-numbers are proposed. These F-numbers, which can be expressed in closed form, maximize the lateral resolution under constraints on the DOF and the grating lobes. A phantom experiment showed that the proposed F-numbers eliminate grating lobe artifacts and improve both image uniformity and contrast to a similar extent as fixed F-numbers. These metrics, compared to the usage of the full apertures, improved by up to 14.1 % and 8.3 %, respectively. The proposed F-numbers, however, improved the lateral resolution by up to 24 % compared to the fixed F-numbers.

Paper number 91:
Title: A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation
Authors: M.M.A. Valiuddin, R.J.G. van Sloun, C.G.A. Viviers, P.H.N. de With, F. van der Sommen
Abstract: Advancements in image segmentation play an integral role within the broad scope of Deep Learning-based Computer Vision. Furthermore, their widespread applicability in critical real-world tasks has resulted in challenges related to the reliability of such algorithms. Hence, uncertainty quantification has been extensively studied within this context, enabling the expression of model ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to prevent uninformed decision-making. Due to the rapid adoption of Convolutional Neural Network (CNN)-based segmentation models in high-stake applications, a substantial body of research has been published on this very topic, causing its swift expansion into a distinct field. This work provides a comprehensive overview of probabilistic segmentation, by discussing fundamental concepts of uncertainty quantification, governing advancements in the field as well as the application to various tasks. Moreover, literature on both types of uncertainties trace back to four key applications: (1) to quantify statistical inconsistencies in the annotation process due ambiguous images, (2) correlating prediction error with uncertainty, (3) expanding the model hypothesis space for better generalization, and (4) Active Learning. An extensive discussion follows that includes an overview of utilized datasets for each of the applications and evaluation of the available methods. We also highlight challenges related to architectures, uncertainty quantification methods, standardization and benchmarking, and finally end with recommendations for future work such as methods based on single forward passes and models that appropriately leverage volumetric data.

Paper number 92:
Title: Soft Adaptive Feet for Legged Robots: An Open-Source Model for Locomotion Simulation
Authors: Matteo Crotti, Luca Rossini, Balint K. Hodossy, Anna Pace, Giorgio Grioli, Antonio Bicchi, Manuel G. Catalano
Abstract: In recent years, artificial feet based on soft robotics and under-actuation principles emerged to improve mobility on challenging terrains. This paper presents the application of the MuJoCo physics engine to realize a digital twin of an adaptive soft foot developed for use with legged robots. We release the MuJoCo soft foot digital twin as open source to allow users and researchers to explore new approaches to locomotion. The work includes the system modeling techniques along with the kinematic and dynamic attributes involved. Validation is conducted through a rigorous comparison with bench tests on a physical prototype, replicating these experiments in simulation. Results are evaluated based on sole deformation and contact forces during foot-obstacle interaction. The foot model is subsequently integrated into simulations of the humanoid robot COMAN+, replacing its original flat feet. Results show an improvement in the robot's ability to negotiate small obstacles without altering its control strategy. Ultimately, this study offers a comprehensive modeling approach for adaptive soft feet, supported by qualitative comparisons of bipedal locomotion with state of the art robotic feet.

Paper number 93:
Title: KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment
Authors: Zijian Zhao, Zhijie Cai, Tingwei Chen, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu
Abstract: Wireless sensing has recently found widespread applications in diverse environments, including homes, offices, and public spaces. By analyzing patterns in channel state information (CSI), it is possible to infer human actions for tasks such as person identification, gesture recognition, and fall detection. However, CSI is highly sensitive to environmental changes, where even minor alterations can significantly distort the CSI patterns. This sensitivity often leads to performance degradation or outright failure when applying wireless sensing models trained in one environment to another. To address this challenge, Domain Alignment (DAL) has been widely adopted for cross-domain classification tasks, as it focuses on aligning the global distributions of the source and target domains in feature space. Despite its popularity, DAL often neglects inter-category relationships, which can lead to misalignment between categories across domains, even when global alignment is achieved. To overcome these limitations, we propose K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD), a novel few-shot method for cross-domain wireless sensing. Our approach begins by constructing a help set using KNN from the target domain, enabling local alignment between the source and target domains within each category using MMD. Additionally, we address a key instability issue commonly observed in cross-domain methods, where model performance fluctuates sharply between epochs. Further, most existing methods struggle to determine an optimal stopping point during training due to the absence of labeled data from the target domain. Our method resolves this by excluding the support set from the target domain during training and employing it as a validation set to determine the stopping criterion.

Paper number 94:
Title: Driving Innovation in 6G Wireless Technologies: The OpenAirInterface Approach
Authors: Florian Kaltenberger, Tommaso Melodia, Irfan Ghauri, Michele Polese, Raymond Knopp, Tien Thinh Nguyen, Sakthivel Velumani, Davide Villa, Leonardo Bonati, Robert Schmidt, Sagar Arora, Mikel Irazabal, Navid Nikaein
Abstract: The development of 6G wireless technologies is rapidly advancing, with the 3rd Generation Partnership Project (3GPP) entering the pre-standardization phase and aiming to deliver the first specifications by 2028. This paper explores the OpenAirInterface (OAI) project, an open-source initiative that plays a crucial role in the evolution of 5G and the future 6G networks. OAI provides a comprehensive implementation of 3GPP and O-RAN compliant networks, including Radio Access Network (RAN), Core Network (CN), and software-defined User Equipment (UE) components. The paper details the history and evolution of OAI, its licensing model, and the various projects under its umbrella, such as RAN, the CN, as well as the Operations, Administration and Maintenance (OAM) projects. It also highlights the development methodology, Continuous Integration/Continuous Delivery (CI/CD) processes, and end-to-end systems powered by OAI. Furthermore, the paper discusses the potential of OAI for 6G research, focusing on spectrum, reflective intelligent surfaces, and Artificial Intelligence (AI)/Machine Learning (ML) integration. The open-source approach of OAI is emphasized as essential for tackling the challenges of 6G, fostering community collaboration, and driving innovation in next-generation wireless technologies.

Paper number 95:
Title: Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach
Authors: Eric Hirsch, Christian Friedrich
Abstract: Accurate tool wear prediction is essential for maintaining productivity and minimizing costs in machining. However, the complex nature of the tool wear process poses significant challenges to achieving reliable predictions. This study explores data-driven methods, in particular deep learning, for tool wear prediction. Traditional data-driven approaches often focus on a single process, relying on multi-sensor setups and extensive data generation, which limits generalization to new settings. Moreover, multi-sensor integration is often impractical in industrial environments. To address these limitations, this research investigates the transferability of predictive models using minimal training data, validated across two processes. Furthermore, it uses a simple setup with a single acceleration sensor to establish a low-cost data generation approach that facilitates the generalization of models to other processes via transfer learning. The study evaluates several machine learning models, including convolutional neural networks (CNN), long short-term memory networks (LSTM), support vector machines (SVM) and decision trees, trained on different input formats such as feature vectors and short-time Fourier transform (STFT). The performance of the models is evaluated on different amounts of training data, including scenarios with significantly reduced datasets, providing insight into their effectiveness under constrained data conditions. The results demonstrate the potential of specific models and configurations for effective tool wear prediction, contributing to the development of more adaptable and efficient predictive maintenance strategies in machining. Notably, the ConvNeXt model has an exceptional performance, achieving an 99.1% accuracy in identifying tool wear using data from only four milling tools operated until they are worn.

Paper number 96:
Title: AdaptVC: High Quality Voice Conversion with Adaptive Learning
Authors: Jaehun Kim, Ji-Hoon Kim, Yeunju Choi, Tan Dat Nguyen, Seongkyu Mun, Joon Son Chung
Abstract: The goal of voice conversion is to transform the speech of a source speaker to sound like that of a reference speaker while preserving the original content. A key challenge is to extract disentangled linguistic content from the source and voice style from the reference. While existing approaches leverage various methods to isolate the two, a generalization still requires further attention, especially for robustness in zero-shot scenarios. In this paper, we achieve successful disentanglement of content and speaker features by tuning self-supervised speech features with adapters. The adapters are trained to dynamically encode nuanced features from rich self-supervised features, and the decoder fuses them to produce speech that accurately resembles the reference with minimal loss of content. Moreover, we leverage a conditional flow matching decoder with cross-attention speaker conditioning to further boost the synthesis quality and efficiency. Subjective and objective evaluations in a zero-shot scenario demonstrate that the proposed method outperforms existing models in speech quality and similarity to the reference speech.

Paper number 97:
Title: MusicGen-Stem: Multi-stem music generation and edition through autoregressive modeling
Authors: Simon Rouard, Robin San Roman, Yossi Adi, Axel Roebel
Abstract: While most music generation models generate a mixture of stems (in mono or stereo), we propose to train a multi-stem generative model with 3 stems (bass, drums and other) that learn the musical dependencies between them. To do so, we train one specialized compression algorithm per stem to tokenize the music into parallel streams of tokens. Then, we leverage recent improvements in the task of music source separation to train a multi-stream text-to-music language model on a large dataset. Finally, thanks to a particular conditioning method, our model is able to edit bass, drums or other stems on existing or generated songs as well as doing iterative composition (e.g. generating bass on top of existing drums). This gives more flexibility in music generation algorithms and it is to the best of our knowledge the first open-source multi-stem autoregressive music generation model that can perform good quality generation and coherent source editing. Code and model weights will be released and samples are available on this https URL.

Paper number 98:
Title: Rotatable Antenna Enabled Wireless Communication: Modeling and Optimization
Authors: Beixiong Zheng, Qingjie Wu, Rui Zhang
Abstract: Fluid antenna system (FAS) and movable antenna (MA) have recently emerged as promising technologies to exploit new spatial degrees of freedom (DoFs), which have attracted growing attention in wireless communication. In this paper, we propose a new rotatable antenna (RA) model to improve the performance of wireless communication systems. Different from conventional fixed antennas, the proposed RA system can flexibly alter the three-dimensional (3D) boresight direction of each antenna independently by adjusting its deflection angles to achieve a desired array directional gain pattern. Specifically, we investigate an RA-enabled uplink communication system, where the receive beamforming and the deflection angles of all RAs at the base station (BS) are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal deflection angles of RAs are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the BS. Moreover, we analyze the asymptotic performance with an infinite number of antennas based on this solution, which theoretically proves that the RA system can achieve a higher array gain as compared to the fixed-antenna system. In the general multi-user and multi-path channel setup, we first propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the deflection angles of RAs in an iterative manner. Then, a two-stage algorithm that solves the formulated problem without the need for iteration is further proposed to reduce computational complexity. Simulation results are provided to validate our analytical results and demonstrate that the proposed RA system can significantly outperform other benchmark schemes.

Paper number 99:
Title: Samba-ASR: State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models
Authors: Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi
Abstract: We propose Samba ASR,the first state of the art Automatic Speech Recognition(ASR)model leveraging the novel Mamba architecture as both encoder and decoder,built on the foundation of state space models(SSMs).Unlike transformerbased ASR models,which rely on self-attention mechanisms to capture dependencies,Samba ASR effectively models both local and global temporal dependencies using efficient statespace dynamics,achieving remarkable performance this http URL addressing the limitations of transformers,such as quadratic scaling with input length and difficulty in handling longrange dependencies,Samba ASR achieves superior accuracy and this http URL results demonstrate that Samba ASR surpasses existing opensource transformerbased ASR models across various standard benchmarks,establishing it as the new state of theart in this http URL evaluations on the benchmark dataset show significant improvements in Word Error Rate(WER),with competitive performance even in lowresource this http URL,the inherent computational efficiency and parameter optimization of the Mamba architecture make Samba ASR a scalable and robust solution for diverse ASR this http URL contributions include the development of a new Samba ASR architecture for automatic speech recognition(ASR),demonstrating the superiority of structured statespace models(SSMs)over transformer based models for speech sequence this http URL provide a comprehensive evaluation on public benchmarks,showcasing stateoftheart(SOTA)performance,and present an indepth analysis of computational efficiency,robustness to noise,and sequence this http URL work highlights the viability of Mamba SSMs as a transformerfree alternative for efficient and accurate this http URL leveraging the advancements of statespace modeling,Samba ASR redefines ASR performance standards and sets a new benchmark for future research in this field.

Paper number 100:
Title: Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders
Authors: Dichucheng Li, Yongyi Zang, Qiuqiang Kong
Abstract: Automatic Music Transcription (AMT), aiming to get musical notes from raw audio, typically uses frame-level systems with piano-roll outputs or language model (LM)-based systems with note-level predictions. However, frame-level systems require manual thresholding, while the LM-based systems struggle with long sequences. In this paper, we propose a hybrid method combining pre-trained roll-based encoders with an LM decoder to leverage the strengths of both methods. Besides, our approach employs a hierarchical prediction strategy, first predicting onset and pitch, then velocity, and finally offset. The hierarchical prediction strategy reduces computational costs by breaking down long sequences into different hierarchies. Evaluated on two benchmark roll-based encoders, our method outperforms traditional piano-roll outputs 0.01 and 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a performance-enhancing plug-in for arbitrary roll-based music transcription encoder.

Paper number 101:
Title: Multimodal Machine Learning Can Predict Videoconference Fluidity and Enjoyment
Authors: Andrew Chang, Viswadruth Akkaraju, Ray McFadden Cogliano, David Poeppel, Dustin Freeman
Abstract: Videoconferencing is now a frequent mode of communication in both professional and informal settings, yet it often lacks the fluidity and enjoyment of in-person conversation. This study leverages multimodal machine learning to predict moments of negative experience in videoconferencing. We sampled thousands of short clips from the RoomReader corpus, extracting audio embeddings, facial actions, and body motion features to train models for identifying low conversational fluidity, low enjoyment, and classifying conversational events (backchanneling, interruption, or gap). Our best models achieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, with domain-general audio features proving most critical. This work demonstrates that multimodal audio-video signals can effectively predict high-level subjective conversational outcomes. In addition, this is a contribution to research on videoconferencing user experience by showing that multimodal machine learning can be used to identify rare moments of negative user experience for further study or mitigation.
    