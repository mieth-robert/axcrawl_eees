
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Cooperative Multi-Agent Assignment over Stochastic Graphs via Constrained Reinforcement Learning
Authors: Leopoldo Agorio, Sean Van Alen, Santiago Paternain, Miguel Calvo-Fullana, Juan Andres Bazerque
Abstract: Constrained multi-agent reinforcement learning offers the framework to design scalable and almost surely feasible solutions for teams of agents operating in dynamic environments to carry out conflicting tasks. We address the challenges of multi-agent coordination through an unconventional formulation in which the dual variables are not driven to convergence but are free to cycle, enabling agents to adapt their policies dynamically based on real-time constraint satisfaction levels. The coordination relies on a light single-bit communication protocol over a network with stochastic connectivity. Using this gossiped information, agents update local estimates of the dual variables. Furthermore, we modify the local dual dynamics by introducing a contraction factor, which lets us use finite communication buffers and keep the estimation error bounded. Under this model, we provide theoretical guarantees of almost sure feasibility and corroborate them with numerical experiments in which a team of robots successfully patrols multiple regions, communicating under a time-varying ad-hoc network.

Paper number 2:
Title: Leveraging Convex Relaxation to Identify the Feasibility of Conducting AC False Data Injection Attack in Power Systems
Authors: Mohammadreza Iranpour, Mohammad Rasoul Narimani
Abstract: FDI (False Data Injection) attacks are critical to address as they can compromise the integrity and reliability of data in cyber-physical systems, leading to potentially severe consequences in sectors such as power systems. The feasibility of FDI attacks has been extensively studied from various perspectives, including access to measurements and sensors, knowledge of the system, and design considerations using residual-based detection methods. Most research has focused on DC-based FDI attacks; however, designing AC FDI attacks involves solving a nonlinear optimization problem, presenting additional challenges in assessing their feasibility. Specifically, it is often unclear whether the infeasibility of some designed AC FDI attacks is due to the nonconvexity and nonlinearity inherent to AC power flows or if it stems from inherent infeasibility in specific cases, with local solvers returning infeasibility. This paper addresses this issue by leveraging the principle that if a convexified AC FDI attack design problem is infeasible, the attack design itself is infeasible, irrespective of nonlinear solution challenges. We propose an AC FDI attack design based on convexified power flow equations and assess the feasibility of the proposed attack by examining the extent of the attackable region. This approach utilizes a Quadratic Convex (QC) relaxation technique to convexify AC power flows. To evaluate the proposed method, we implement it on the IEEE 118-bus test system and assess the feasibility of an AC FDI attack across various attack zones.

Paper number 3:
Title: Towards a Molecular Computer: Enabling Arithmetic Operations in Molecular Communication
Authors: Jianqiao Long, Lei Zhang, Miaowen Wen, Kezhi Wang, Natalio Krasnogor, Jichun Li
Abstract: In current molecular communication (MC) systems, performing computational operations at the nanoscale remains challenging, restricting their applicability in complex scenarios such as adaptive biochemical control and advanced nanoscale sensing. To overcome this challenge, this paper proposes a novel framework that seamlessly integrates computation into the molecular communication process. The system enables arithmetic operations, namely addition, subtraction, multiplication, and division, by encoding numerical values into two types of molecules emitted by each transmitter to represent positive and negative values, respectively. Specifically, addition is achieved by transmitting non-reactive molecules, while subtraction employs reactive molecules that interact during propagation. The receiver demodulates molecular counts to directly compute the desired results. Theoretical analysis for an upper bound on the bit error rate (BER), and computational simulations confirm the system's robustness in performing complex arithmetic tasks. Compared to conventional MC methods, the proposed approach not only enables fundamental computational operations at the nanoscale but also lays the groundwork for intelligent, autonomous molecular networks.

Paper number 4:
Title: An Integrated Deep Learning Framework Leveraging NASNet and Vision Transformer with MixProcessing for Accurate and Precise Diagnosis of Lung Diseases
Authors: Sajjad Saleem, Muhammad Imran Sharif
Abstract: The lungs are the essential organs of respiration, and this system is significant in the carbon dioxide and exchange between oxygen that occurs in human life. However, several lung diseases, which include pneumonia, tuberculosis, COVID-19, and lung cancer, are serious healthiness challenges and demand early and precise diagnostics. The methodological study has proposed a new deep learning framework called NASNet-ViT, which effectively incorporates the convolution capability of NASNet with the global attention mechanism capability of Vision Transformer ViT. The proposed model will classify the lung conditions into five classes: Lung cancer, COVID-19, pneumonia, TB, and normal. A sophisticated multi-faceted preprocessing strategy called MixProcessing has been used to improve diagnostic accuracy. This preprocessing combines wavelet transform, adaptive histogram equalization, and morphological filtering techniques. The NASNet-ViT model performs at state of the art, achieving an accuracy of 98.9%, sensitivity of 0.99, an F1-score of 0.989, and specificity of 0.987, outperforming other state of the art architectures such as MixNet-LD, D-ResNet, MobileNet, and ResNet50. The model's efficiency is further emphasized by its compact size, 25.6 MB, and a low computational time of 12.4 seconds, hence suitable for real-time, clinically constrained environments. These results reflect the high-quality capability of NASNet-ViT in extracting meaningful features and recognizing various types of lung diseases with very high accuracy. This work contributes to medical image analysis by providing a robust and scalable solution for diagnostics in lung diseases.

Paper number 5:
Title: Predicting Nonlinear Interference for Short-Blocklength 4D Probabilistic Shaping
Authors: Jingxin Deng, Bin Chen, Zhiwei Liang, Yi Lei, Gabriele Liga
Abstract: We derive a heuristic nonlinear interference model for 4D probabilistic shaping considering the polarization and time correlation of the 4D symbols. We demonstrate an average SNR prediction gap from split-step Fourier simulations of 0.15~dB.

Paper number 6:
Title: Style Content Decomposition-based Data Augmentation for Domain Generalizable Medical Image Segmentation
Authors: Zhiqiang Shen, Peng Cao, Jinzhu Yang, Osmar R. Zaiane, Zhaolin Chen
Abstract: Due to the domain shifts between training and testing medical images, learned segmentation models often experience significant performance degradation during deployment. In this paper, we first decompose an image into its style code and content map and reveal that domain shifts in medical images involve: \textbf{style shifts} (\emph{i.e.}, differences in image appearance) and \textbf{content shifts} (\emph{i.e.}, variations in anatomical structures), the latter of which has been largely overlooked. To this end, we propose \textbf{StyCona}, a \textbf{sty}le \textbf{con}tent decomposition-based data \textbf{a}ugmentation method that innovatively augments both image style and content within the rank-one space, for domain generalizable medical image segmentation. StyCona is a simple yet effective plug-and-play module that substantially improves model generalization without requiring additional training parameters or modifications to the segmentation model architecture. Experiments on cross-sequence, cross-center, and cross-modality medical image segmentation settings with increasingly severe domain shifts, demonstrate the effectiveness of StyCona and its superiority over state-of-the-arts. The code is available at this https URL.

Paper number 7:
Title: Reducing Complexity of Data-Aided Channel Estimation in RIS-Assisted Communications
Authors: Amarilton Lopes Magalhães, André Lima Férrer de Almeida, Gilderlan Tavares de Araújo
Abstract: We consider the data-aided channel estimation (CE) problem in a reconfigurable intelligent surface (RIS)-assisted wireless communication system, where the channel and information symbols are estimated jointly during the CE phase, differently from pure pilot-aided methods. We propose a two-stage semi-blind receiver that jointly estimates the combined channel and the data symbols, followed by channel decoupling. To this end, we derive a new modeling framework whose first stage recasts the received signal to allow for the joint estimation of the combined channel and transmitted symbols. In the second stage, channel decoupling is easily achieved via Khatri-Rao factorization, yielding a refined channel estimate. Our solution yields accurate estimates of the cascaded channel at lower computational complexity. Simulation results reveal a similar performance of the proposed method to that of the competitor while providing a substantially reduced computational cost.

Paper number 8:
Title: Linear Model of RIS-Aided High-Mobility Communication System
Authors: Shuaijun Li, Jie Tang, Beixiong Zheng, Xiaokai Song, Guixin Pan, Kai-Kit Wong
Abstract: Reconfigurable intelligent surface (RIS)-aided vehicle-to-everything (V2X) communication has emerged as a crucial solution for providing reliable data services to vehicles on the road. However, in delay-sensitive or high-mobility communications, the rapid movement of vehicles can lead to random scattering in the environment and time-selective fading in the channel. In view of this, we investigate in this paper an innovative linear model with low-complexity transmitter signal design and receiver detection methods, which boost stability in fast-fading environments and reduce channel training overhead. Specifically, considering the differences in hardware design and signal processing at the receiving end between uplink and downlink communication systems, distinct solutions are proposed. Accordingly, we first integrate the Rician channel introduced by the RIS with the corresponding signal processing algorithms to model the RIS-aided downlink communication system as a Doppler-robust linear model. Inspired by this property, we design a precoding scheme based on the linear model to reduce the complexity of precoding. Then, by leveraging the linear model and the large-scale antenna array at the base station (BS) side, we improve the linear model for the uplink communication system and derive its asymptotic performance in closed-form. Simulation results demonstrate the performance advantages of the proposed RIS-aided high-mobility communication system compared to other benchmark schemes.

Paper number 9:
Title: Multi-model Stochastic Particle-based Variational Bayesian Inference for Multiband Delay Estimation
Authors: Zhixiang Hu, An Liu, Minjian Zhao
Abstract: Joint utilization of multiple discrete frequency bands can enhance the accuracy of delay estimation. Although some unique challenges of multiband fusion, such as phase distortion, oscillation phenomena, and high-dimensional search, have been partially addressed, further challenges remain. Specifically, under conditions of low signal-to-noise ratio (SNR), insufficient data, and closely spaced delay paths, accurately determining the model order-the number of delay paths-becomes difficult. Misestimating the model order can significantly degrade the estimation performance of traditional methods. To address joint model selection and parameter estimation under such harsh conditions, we propose a multi-model stochastic particle-based variational Bayesian inference (MM-SPVBI) framework, capable of exploring multiple high-dimensional parameter spaces. Initially, we split potential overlapping primary delay paths based on coarse estimates, generating several parallel candidate models. Then, an auto-focusing sampling strategy is employed to quickly identify the optimal model. Additionally, we introduce a hybrid posterior approximation to improve the original single-model SPVBI, ensuring overall complexity does not increase significantly with parallelism. Simulations demonstrate that our algorithm offers substantial advantages over existing methods.

Paper number 10:
Title: Differentially Private Recursive Least Squares Estimation for ARX Systems with Multi-Participants
Authors: Jianwei Tan, Jimin Wang, Ji-Feng Zhang
Abstract: This paper proposes a differentially private recursive least squares algorithm to estimate the parameter of autoregressive systems with exogenous inputs and multi-participants (MP-ARX systems) and protect each participant's sensitive information from potential attackers. We first give a rigorous differential privacy analysis of the algorithm, and establish the quantitative relationship between the added noises and the privacy-preserving level when the system is asymptotically stable. The asymptotic stability of the system is necessary for ensuring the differential privacy of the algorithm. We then give an estimation error analysis of the algorithm under the general and possible weakest excitation condition without requiring the boundedness, independence and stationarity on the regression vectors. Particularly, when there is no regression term in the system output and the differential privacy only on the system output is considered, $\varepsilon$-differential privacy and almost sure convergence of the algorithm can be established simultaneously. To minimize the estimation error of the algorithm with $\varepsilon$-differential privacy, the existence of the noise intensity is proved. Finally, two examples are given to show the efficiency of the algorithm.

Paper number 11:
Title: A Quantum-Empowered SPEI Drought Forecasting Algorithm Using Spatially-Aware Mamba Network
Authors: Po-Wei Tang, Chia-Hsiang Lin, Jian-Kai Huang, Alfredo R. Huete
Abstract: Due to the intensifying impacts of extreme climate changes, drought forecasting (DF), which aims to predict droughts from historical meteorological data, has become increasingly critical for monitoring and managing water resources. Though drought conditions often exhibit spatial climatic coherence among neighboring regions, benchmark deep learning-based DF methods overlook this fact and predict the conditions on a region-by-region basis. Using the Standardized Precipitation Evapotranspiration Index (SPEI), we designed and trained a novel and transformative spatially-aware DF neural network, which effectively captures local interactions among neighboring regions, resulting in enhanced spatial coherence and prediction accuracy. As DF also requires sophisticated temporal analysis, the Mamba network, recognized as the most accurate and efficient existing time-sequence modeling, was adopted to extract temporal features from short-term time frames. We also adopted quantum neural networks (QNN) to entangle the spatial features of different time instances, leading to refined spatiotemporal features of seven different meteorological variables for effectively identifying short-term climate fluctuations. In the last stage of our proposed SPEI-driven quantum spatially-aware Mamba network (SQUARE-Mamba), the extracted spatiotemporal features of seven different meteorological variables were fused to achieve more accurate DF. Validation experiments across El Niño, La Niña, and normal years demonstrated the superiority of the proposed SQUARE-Mamba, remarkably achieving an average improvement of more than 9.8% in the coefficient of determination index (R^2) compared to baseline methods, thereby illustrating the promising roles of the temporal quantum entanglement and Mamba temporal analysis to achieve more accurate DF.

Paper number 12:
Title: Computationally Efficient Safe Control of Linear Systems under Severe Sensor Attacks
Authors: Xiao Tan, Pio Ong, Paulo Tabuada, Aaron D. Ames
Abstract: Cyber-physical systems are prone to sensor attacks that can compromise safety. A common approach to synthesizing controllers robust to sensor attacks is secure state reconstruction (SSR) -- but this is computationally expensive, hindering real-time control. In this paper, we take a safety-critical perspective on mitigating severe sensor attacks, leading to a computationally efficient solution. Namely, we design feedback controllers that ensure system safety by directly computing control actions from past input-output data. Instead of fully solving the SSR problem, we use conservative bounds on a control barrier function (CBF) condition, which we obtain by extending the recent eigendecomposition-based SSR approach to severe sensor attack settings. Additionally, we present an extended approach that solves a smaller-scale subproblem of the SSR problem, taking on some computational burden to mitigate the conservatism in the main approach. Numerical comparisons confirm that the traditional SSR approaches suffer from combinatorial issues, while our approach achieves safety guarantees with greater computational efficiency.

Paper number 13:
Title: SemiSAM+: Rethinking Semi-Supervised Medical Image Segmentation in the Era of Foundation Models
Authors: Yichi Zhang, Bohao Lv, Le Xue, Wenbo Zhang, Yuchen Liu, Yu Fu, Yuan Cheng, Yuan Qi
Abstract: Deep learning-based medical image segmentation typically requires large amount of labeled data for training, making it less applicable in clinical settings due to high annotation cost. Semi-supervised learning (SSL) has emerged as an appealing strategy due to its less dependence on acquiring abundant annotations from experts compared to fully supervised methods. Beyond existing model-centric advancements of SSL by designing novel regularization strategies, we anticipate a paradigmatic shift due to the emergence of promptable segmentation foundation models with universal segmentation capabilities using positional prompts represented by Segment Anything Model (SAM). In this paper, we present SemiSAM+, a foundation model-driven SSL framework to efficiently learn from limited labeled data for medical image segmentation. SemiSAM+ consists of one or multiple promptable foundation models as generalist models, and a trainable task-specific segmentation model as specialist model. For a given new segmentation task, the training is based on the specialist-generalist collaborative learning procedure, where the trainable specialist model delivers positional prompts to interact with the frozen generalist models to acquire pseudo-labels, and then the generalist model output provides the specialist model with informative and efficient supervision which benefits the automatic segmentation and prompt generation in turn. Extensive experiments on two public datasets and one in-house clinical dataset demonstrate that SemiSAM+ achieves significant performance improvement, especially under extremely limited annotation scenarios, and shows strong efficiency as a plug-and-play strategy that can be easily adapted to different specialist and generalist models.

Paper number 14:
Title: Towards Practical Real-Time Neural Video Compression
Authors: Zhaoyang Jia, Bin Li, Jiahao Li, Wenxuan Xie, Linfeng Qi, Houqiang Li, Yan Lu
Abstract: We introduce a practical real-time neural video codec (NVC) designed to deliver high compression ratio, low latency and broad versatility. In practice, the coding speed of NVCs depends on 1) computational costs, and 2) non-computational operational costs, such as memory I/O and the number of function calls. While most efficient NVCs prioritize reducing computational cost, we identify operational cost as the primary bottleneck to achieving higher coding speed. Leveraging this insight, we introduce a set of efficiency-driven design improvements focused on minimizing operational costs. Specifically, we employ implicit temporal modeling to eliminate complex explicit motion modules, and use single low-resolution latent representations rather than progressive downsampling. These innovations significantly accelerate NVC without sacrificing compression quality. Additionally, we implement model integerization for consistent cross-device coding and a module-bank-based rate control scheme to improve practical adaptability. Experiments show our proposed DCVC-RT achieves an impressive average encoding/decoding speed at 125.2/112.8 fps (frames per second) for 1080p video, while saving an average of 21% in bitrate compared to H.266/VTM. The code is available at this https URL.

Paper number 15:
Title: Autoregressive Medical Image Segmentation via Next-Scale Mask Prediction
Authors: Tao Chen, Chenhui Wang, Zhihao Chen, Hongming Shan
Abstract: While deep learning has significantly advanced medical image segmentation, most existing methods still struggle with handling complex anatomical regions. Cascaded or deep supervision-based approaches attempt to address this challenge through multi-scale feature learning but fail to establish sufficient inter-scale dependencies, as each scale relies solely on the features of the immediate predecessor. To this end, we propose the AutoRegressive Segmentation framework via next-scale mask prediction, termed AR-Seg, which progressively predicts the next-scale mask by explicitly modeling dependencies across all previous scales within a unified architecture. AR-Seg introduces three innovations: (1) a multi-scale mask autoencoder that quantizes the mask into multi-scale token maps to capture hierarchical anatomical structures, (2) a next-scale autoregressive mechanism that progressively predicts next-scale masks to enable sufficient inter-scale dependencies, and (3) a consensus-aggregation strategy that combines multiple sampled results to generate a more accurate mask, further improving segmentation robustness. Extensive experimental results on two benchmark datasets with different modalities demonstrate that AR-Seg outperforms state-of-the-art methods while explicitly visualizing the intermediate coarse-to-fine segmentation process.

Paper number 16:
Title: Denoising bivariate signals via smoothing and polarization priors
Authors: Yusuf Yigit Pilavci (CRIStAL), Jérémie Boulanger (CRIStAL), Pierre-Antoine Thouvenin (CRIStAL), Pierre Chainais (CRISTAL)
Abstract: We propose two formulations to leverage the geometric properties of bivariate signals for dealing with the denoising problem. In doing so, we use the instantaneous Stokes parameters to incorporate the polarization state of the signal. While the first formulation exploits the statistics of the Stokes representation in a Bayesian setting, the second uses a kernel regression formulation to impose locally smooth time-varying polarization properties. In turn, we obtain two formulations that allow us to use both signal and polarization domain regularization for denoising a bivariate signal. The solutions to them exploit the polarization information efficiently as demonstrated in the numerical simulations

Paper number 17:
Title: Delta-WKV: A Novel Meta-in-Context Learner for MRI Super-Resolution
Authors: Rongchang Lu, Bingcheng Liao, Haowen Hou, Jiahang Lv, Xin Hai
Abstract: Magnetic Resonance Imaging (MRI) Super-Resolution (SR) addresses the challenges such as long scan times and expensive equipment by enhancing image resolution from low-quality inputs acquired in shorter scan times in clinical settings. However, current SR techniques still have problems such as limited ability to capture both local and global static patterns effectively and efficiently. To address these limitations, we propose Delta-WKV, a novel MRI super-resolution model that combines Meta-in-Context Learning (MiCL) with the Delta rule to better recognize both local and global patterns in MRI images. This approach allows Delta-WKV to adjust weights dynamically during inference, improving pattern recognition with fewer parameters and less computational effort, without using state-space modeling. Additionally, inspired by Receptance Weighted Key Value (RWKV), Delta-WKV uses a quad-directional scanning mechanism with time-mixing and channel-mixing structures to capture long-range dependencies while maintaining high-frequency details. Tests on the IXI and fastMRI datasets show that Delta-WKV outperforms existing methods, improving PSNR by 0.06 dB and SSIM by 0.001, while reducing training and inference times by over 15\%. These results demonstrate its efficiency and potential for clinical use with large datasets and high-resolution imaging.

Paper number 18:
Title: Movable Antenna Aided Multiuser Communications: Antenna Position Optimization Based on Statistical Channel Information
Authors: Ge Yan, Lipeng Zhu, Rui Zhang
Abstract: The movable antenna (MA) technology has attracted great attention recently due to its promising capability in improving wireless channel conditions by flexibly adjusting antenna positions. To reap maximal performance gains of MA systems, existing works mainly focus on MA position optimization to cater to the instantaneous channel state information (CSI). However, the resulting real-time antenna movement may face challenges in practical implementation due to the additional time overhead and energy consumption required, especially in fast time-varying channel scenarios. To address this issue, we propose in this paper a new approach to optimize the MA positions based on the users' statistical CSI over a large timescale. In particular, we propose a general field response based statistical channel model to characterize the random channel variations caused by the local movement of users. Based on this model, a two-timescale optimization problem is formulated to maximize the ergodic sum rate of multiple users, where the precoding matrix and the positions of MAs at the base station (BS) are optimized based on the instantaneous and statistical CSI, respectively. To solve this non-convex optimization problem, a log-barrier penalized gradient ascent algorithm is developed to optimize the MA positions, where two methods are proposed to approximate the ergodic sum rate and its gradients with different complexities. Finally, we present simulation results to evaluate the performance of the proposed design and algorithms based on practical channels generated by ray-tracing. The results verify the performance advantages of MA systems compared to their fixed-position antenna (FPA) counterparts in terms of long-term rate improvement, especially for scenarios with more diverse channel power distributions in the angular domain.

Paper number 19:
Title: JiTTER: Jigsaw Temporal Transformer for Event Reconstruction for Self-Supervised Sound Event Detection
Authors: Hyeonuk Nam, Yong-Hwa Park
Abstract: Sound event detection (SED) has significantly benefited from self-supervised learning (SSL) approaches, particularly masked audio transformer for SED (MAT-SED), which leverages masked block prediction to reconstruct missing audio segments. However, while effective in capturing global dependencies, masked block prediction disrupts transient sound events and lacks explicit enforcement of temporal order, making it less suitable for fine-grained event boundary detection. To address these limitations, we propose JiTTER (Jigsaw Temporal Transformer for Event Reconstruction), an SSL framework designed to enhance temporal modeling in transformer-based SED. JiTTER introduces a hierarchical temporal shuffle reconstruction strategy, where audio sequences are randomly shuffled at both the block-level and frame-level, forcing the model to reconstruct the correct temporal order. This pretraining objective encourages the model to learn both global event structures and fine-grained transient details, improving its ability to detect events with sharp onset-offset characteristics. Additionally, we incorporate noise injection during block shuffle, providing a subtle perturbation mechanism that further regularizes feature learning and enhances model robustness. Experimental results on the DESED dataset demonstrate that JiTTER outperforms MAT-SED, achieving a 5.89% improvement in PSDS, highlighting the effectiveness of explicit temporal reasoning in SSL-based SED. Our findings suggest that structured temporal reconstruction tasks, rather than simple masked prediction, offer a more effective pretraining paradigm for sound event representation learning.

Paper number 20:
Title: Guiding Quantitative MRI Reconstruction with Phase-wise Uncertainty
Authors: Haozhong Sun, Zhongsen Li, Chenlin Du, Haokun Li, Yajie Wang, Huijun Chen
Abstract: Quantitative magnetic resonance imaging (qMRI) requires multi-phase acqui-sition, often relying on reduced data sampling and reconstruction algorithms to accelerate scans, which inherently poses an ill-posed inverse problem. While many studies focus on measuring uncertainty during this process, few explore how to leverage it to enhance reconstruction performance. In this paper, we in-troduce PUQ, a novel approach that pioneers the use of uncertainty infor-mation for qMRI reconstruction. PUQ employs a two-stage reconstruction and parameter fitting framework, where phase-wise uncertainty is estimated during reconstruction and utilized in the fitting stage. This design allows uncertainty to reflect the reliability of different phases and guide information integration during parameter fitting. We evaluated PUQ on in vivo T1 and T2 mapping datasets from healthy subjects. Compared to existing qMRI reconstruction methods, PUQ achieved the state-of-the-art performance in parameter map-pings, demonstrating the effectiveness of uncertainty guidance. Our code is available at this https URL.

Paper number 21:
Title: Geometric Reachability for Attitude Control Systems via Contraction Theory
Authors: Chencheng Xu, Saber Jafarpour, Chengcheng Zhao, Zhiguo Shi, Jiming Chen
Abstract: In this paper, we present a geometric framework for the reachability analysis of attitude control systems. We model the attitude dynamics on the product manifold $\mathrm{SO}(3) \times \mathbb{R}^3$ and introduce a novel parametrized family of Riemannian metrics on this space. Using contraction theory on manifolds, we establish reliable upper bounds on the Riemannian distance between nearby trajectories of the attitude control systems. By combining these trajectory bounds with numerical simulations, we provide a simulation-based algorithm to over-approximate the reachable sets of attitude systems. We show that the search for optimal metrics for distance bounds can be efficiently performed using semidefinite programming. Additionally, we introduce a practical and effective representation of these over-approximations on manifolds, enabling their integration with existing Euclidean tools and software. Numerical experiments validate the effectiveness of the proposed approach.

Paper number 22:
Title: Data-Importance-Aware Waterfilling for Adaptive Real-Time Communication in Computer Vision Applications
Authors: Chunmei Xu, Yi Ma, Rahim Tafazolli
Abstract: This paper presents a novel framework for importance-aware adaptive data transmission, designed specifically for real-time computer vision (CV) applications where task-specific fidelity is critical. An importance-weighted mean square error (IMSE) metric is introduced, assigning data importance based on bit positions within pixels and semantic relevance within visual segments, thus providing a task-oriented measure of reconstruction this http URL minimize IMSE under the total power constraint, a data-importance-aware waterfilling approach is proposed to optimally allocate transmission power according to data importance and channel conditions. Simulation results demonstrate that the proposed approach significantly outperforms margin-adaptive waterfilling and equal power allocation strategies, achieving more than $7$ dB and $10$ dB gains in normalized IMSE at high SNRs ($> 10$ dB), respectively. These results highlight the potential of the proposed framework to enhance data efficiency and robustness in real-time CV applications, especially in bandwidth-limited and resource-constrained environments.

Paper number 23:
Title: Goal-Oriented Semantic Communication for Wireless Video Transmission via Generative AI
Authors: Nan Li, Yansha Deng, Dusit Niyato
Abstract: Efficient video transmission is essential for seamless communication and collaboration within the visually-driven digital landscape. To achieve low latency and high-quality video transmission over a bandwidth-constrained noisy wireless channel, we propose a stable diffusion (SD)-based goal-oriented semantic communication (GSC) framework. In this framework, we first design a semantic encoder that effectively identify the keyframes from video and extract the relevant semantic information (SI) to reduce the transmission data size. We then develop a semantic decoder to reconstruct the keyframes from the received SI and further generate the full video from the reconstructed keyframes using frame interpolation to ensure high-quality reconstruction. Recognizing the impact of wireless channel noise on SI transmission, we also propose an SD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain to remove the channel noise from the received noisy SI under a known channel. For scenarios with an unknown channel, we further propose a parallel SD denoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains and denoise the received SI. It is shown that, with the known channel, our proposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe and DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%, reducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing Fréchet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the unknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29% reduction in MSE, and a 19% reduction in FVD compared to MMSE equalizer-enhanced SD-GSC. These significant performance improvements demonstrate the robustness and superiority of our proposed methods in enhancing video transmission quality and efficiency under various channel conditions.

Paper number 24:
Title: Adaptive Input Design for Nonlinear System Identification with Operational Constraints
Authors: Jingwei Hu, Dave Zachariah, Torbjörn Wigren, Petre Stoica
Abstract: We consider the problem of joint input design and parameter estimation for identifying nonlinear system models through the sequential acquisition of measurements while adhering to system constraints. We utilize a receding horizon approach and propose a new scale-invariant input design criterion, which is tailored to continuously updated parameter estimates, along with a new sequential parameter estimator. We demonstrate the ability of the method to design informative experiments online, while steering the system within operational constraints.

Paper number 25:
Title: Optimality and Suboptimality of MPPI Control in Stochastic and Deterministic Settings
Authors: Hannes Homburger, Florian Messerer, Moritz Diehl, Johannes Reuter
Abstract: Model predictive path integral (MPPI) control has recently received a lot of attention, especially in the robotics and reinforcement learning communities. This letter aims to make the MPPI control framework more accessible to the optimal control community. We present three classes of optimal control problems and their solutions by MPPI. Further, we investigate the suboptimality of MPPI to general deterministic nonlinear discrete-time systems. Here, suboptimality is defined as the deviation between the control provided by MPPI and the optimal solution to the deterministic optimal control problem. Our findings are that in a smooth and unconstrained setting, the growth of suboptimality in the control input trajectory is second-order with the scaling of uncertainty. The results indicate that the suboptimality of the MPPI solution can be modulated by appropriately tuning the hyperparameters. We illustrate our findings using numerical examples.

Paper number 26:
Title: Target Tracking using Robust Sensor Motion Control
Authors: Jingwei Hu, Dave Zachariah, Petre Stoica
Abstract: We consider the problem of tracking moving targets using mobile wireless sensors (of possibly different types). This is a joint estimation and control problem in which a tracking system must take into account both target and sensor dynamics. We make minimal assumptions about the target dynamics, namely only that their accelerations are bounded. We develop a control law that determines the sensor motion control signals so as to maximize target resolvability as the target dynamics evolve. The method is given a tractable formulation that is amenable to an efficient search method and is evaluated in a series of experiments involving both round-trip time based ranging and Doppler frequency shift measurements

Paper number 27:
Title: A Demo of Radar Sensing Aided Rotatable Antenna for Wireless Communication System
Authors: Qi Dai, Beixiong Zheng, Qiyao Wang, Xue Xiong, Xiaodan Shao, Lipeng Zhu, Rui Zhang
Abstract: Rotatable antenna (RA) represents a novel antenna architecture that enhances wireless communication system performance by independently or collectively adjusting each antenna's boresight/orientation. In this demonstration, we develop a prototype of radar sensing-aided rotatable antenna that integrates radar sensing with dynamic antenna orientation to enhance wireless communication performance while maintaining low hardware costs. The proposed prototype consists of a transmitter (TX) module and a receiver (RX) module, both of which employ universal software radio peripherals (USRPs) for transmitting and receiving signals. Specifically, the TX utilizes a laser radar to detect the RX's location and conveys the angle of arrival (AoA) information to its antenna servo, which enables the RA to align its boresight direction with the identified RX. Experimental results examine the effectiveness of the proposed prototype and indicate that the RA significantly outperforms the traditional fixed-antenna system in terms of increasing received signal-to-noise ratio (SNR).

Paper number 28:
Title: Lifted Frequency-Domain Identification of Closed-Loop Multirate Systems: Applied to Dual-Stage Actuator Hard Disk Drives
Authors: Max van Haren, Masahiro Mae, Lennart Blanken, Tom Oomen
Abstract: Frequency-domain representations are crucial for the design and performance evaluation of controllers in multirate systems, specifically to address intersample performance. The aim of this paper is to develop an effective frequency-domain system identification technique for closed-loop multirate systems using solely slow-rate output measurements. By indirect identification of multivariable time-invariant representations through lifting, in combination with local modeling techniques, the multirate system is effectively identified. The developed method is capable of accurate identification of closed-loop multirate systems within a single identification experiment, using fast-rate excitation and inputs, and slow-rate outputs. Finally, the developed framework is validated using a benchmark problem consisting of a multivariable dual-stage actuator from a hard disk drive, demonstrating its applicability and accuracy.

Paper number 29:
Title: System Identification Beyond the Nyquist Frequency: A Kernel-Regularized Approach
Authors: Max van Haren, Roy S. Smith, Tom Oomen
Abstract: Models that contain intersample behavior are important for control design of systems with slow-rate outputs. The aim of this paper is to develop a system identification technique for fast-rate models of systems where only slow-rate output measurements are available, e.g., vision-in-the-loop systems. In this paper, the intersample response is estimated by identifying fast-rate models through least-squares criteria, and the limitations of these models are determined. In addition, a method is developed that surpasses these limitations and is capable of estimating unique fast-rate models of arbitrary order by regularizing the least-squares estimate. The developed method utilizes fast-rate inputs and slow-rate outputs and identifies fast-rate models accurately in a single identification experiment. Finally, both simulation and experimental validation on a prototype wafer stage demonstrate the effectiveness of the framework.

Paper number 30:
Title: Minimal positive Markov realizations
Authors: Hamed Taghavian, Jens Sjölund
Abstract: Finding a positive state-space realization with the minimum dimension for a given transfer function is an open problem in control theory. In this paper, we focus on positive realizations in Markov form and propose a linear programming approach that computes them with a minimum dimension. Such minimum dimension of positive Markov realizations is an upper bound of the minimal positive realization dimension. However, we show that these two dimensions are equal for certain systems.

Paper number 31:
Title: Parameter-Varying Feedforward Control: A Kernel-Based Learning Approach
Authors: Max van Haren, Lennart Blanken, Tom Oomen
Abstract: The increasing demands for high accuracy in mechatronic systems necessitate the incorporation of parameter variations in feedforward control. The aim of this paper is to develop a data-driven approach for direct learning of parameter-varying feedforward control to increase tracking performance. The developed approach is based on kernel-regularized function estimation in conjunction with iterative learning to directly learn parameter-varying feedforward control from data. This approach enables high tracking performance for feedforward control of linear parameter-varying dynamics, providing flexibility to varying reference tasks. The developed framework is validated on a benchmark industrial experimental setup featuring a belt-driven carriage.

Paper number 32:
Title: A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma Triage
Authors: Youngjin Yoo, Bogdan Georgescu, Yanbo Zhang, Sasa Grbic, Han Liu, Gabriela D. Aldea, Thomas J. Re, Jyotipriya Das, Poikavila Ullaskrishnan, Eva Eibenberger, Andrei Chekkoury, Uttam K. Bodanapally, Savvas Nicolaou, Pina C. Sanelli, Thomas J. Schroeppel, Yvonne W. Lui, Eli Gibson
Abstract: Recent advancements in AI and medical imaging offer transformative potential in emergency head CT interpretation for reducing assessment times and improving accuracy in the face of an increasing request of such scans and a global shortage in radiologists. This study introduces a 3D foundation model for detecting diverse neuro-trauma findings with high accuracy and efficiency. Using large language models (LLMs) for automatic labeling, we generated comprehensive multi-label annotations for critical conditions. Our approach involved pretraining neural networks for hemorrhage subtype segmentation and brain anatomy parcellation, which were integrated into a pretrained comprehensive neuro-trauma detection network through multimodal fine-tuning. Performance evaluation against expert annotations and comparison with CT-CLIP demonstrated strong triage accuracy across major neuro-trauma findings, such as hemorrhage and midline shift, as well as less frequent critical conditions such as cerebral edema and arterial hyperdensity. The integration of neuro-specific features significantly enhanced diagnostic capabilities, achieving an average AUC of 0.861 for 16 neuro-trauma conditions. This work advances foundation models in medical imaging, serving as a benchmark for future AI-assisted neuro-trauma diagnostics in emergency radiology.

Paper number 33:
Title: "No negatives needed": weakly-supervised regression for interpretable tumor detection in whole-slide histopathology images
Authors: Marina D'Amato, Jeroen van der Laak, Francesco Ciompi
Abstract: Accurate tumor detection in digital pathology whole-slide images (WSIs) is crucial for cancer diagnosis and treatment planning. Multiple Instance Learning (MIL) has emerged as a widely used approach for weakly-supervised tumor detection with large-scale data without the need for manual annotations. However, traditional MIL methods often depend on classification tasks that require tumor-free cases as negative examples, which are challenging to obtain in real-world clinical workflows, especially for surgical resection specimens. We address this limitation by reformulating tumor detection as a regression task, estimating tumor percentages from WSIs, a clinically available target across multiple cancer types. In this paper, we provide an analysis of the proposed weakly-supervised regression framework by applying it to multiple organs, specimen types and clinical scenarios. We characterize the robustness of our framework to tumor percentage as a noisy regression target, and introduce a novel concept of amplification technique to improve tumor detection sensitivity when learning from small tumor regions. Finally, we provide interpretable insights into the model's predictions by analyzing visual attention and logit maps. Our code is available at this https URL.

Paper number 34:
Title: A general partitioning strategy for non-centralized control
Authors: Alessandro Riccardi, Luca Laurenti, Bart De Schutter
Abstract: Partitioning is a fundamental challenge for non-centralized control of large-scale systems, such as hierarchical, decentralized, distributed, and coalitional strategies. The problem consists of finding a decomposition of a network of dynamical systems into system units for which local controllers can be designed. Unfortunately, despite its critical role, a generalized approach to partitioning applicable to every system is still missing from the literature. This paper introduces a novel partitioning framework that integrates an algorithmic selection of fundamental system units (FSUs), considered indivisible entities, with an aggregative procedure, either algorithmic or optimization-based, to select composite system units (CSUs) made of several FSUs. A key contribution is the introduction of a global network metric, the partition index, which quantitatively balances intra- and inter-CSU interactions, with a granularity parameter accounting for the size of CSUs, allowing for their selection at different levels of aggregation. The proposed method is validated through case studies in distributed model predictive control (DMPC) for linear and hybrid systems, showing significant reductions in computation time and cost while maintaining or improving control performance w.r.t. conventional strategies.

Paper number 35:
Title: Unmasking Stealthy Attacks on Nonlinear DAE Models of Power Grids
Authors: Abdallah Alalem Albustami, Ahmad F. Taha, Elias Bou-Harb
Abstract: Smart grids are inherently susceptible to various types of malicious cyberattacks that have all been documented in the recent literature. Traditional cybersecurity research on power systems often utilizes simplified models that fail to capture the interactions between dynamic and steady-state behaviors, potentially underestimating the impact of cyber threats. This paper presents the first attempt to design and assess stealthy false data injection attacks (FDIAs) against nonlinear differential algebraic equation (NDAE) models of power networks. NDAE models, favored in industry for their ability to accurately capture both dynamic and steady-state behaviors, provide a more accurate representation of power system behavior by coupling dynamic and algebraic states. We propose novel FDIA strategies that simultaneously evade both dynamic and static intrusion detection systems while respecting the algebraic power flow and operational constraints inherent in NDAE models. We demonstrate how the coupling between dynamic and algebraic states in NDAE models significantly restricts the attacker's ability to manipulate state estimates while maintaining stealthiness. This highlights the importance of using more comprehensive power system models in cybersecurity analysis and reveals potential vulnerabilities that may be overlooked in simplified representations. The proposed attack strategies are validated through simulations on the IEEE 39-bus system.

Paper number 36:
Title: CONSeg: Voxelwise Glioma Conformal Segmentation
Authors: Danial Elyassirad, Benyamin Gheiji, Mahsa Vatanparast, Amir Mahmoud Ahmadzadeh, Shahriar Faghani
Abstract: Background and Purpose: Glioma segmentation is crucial for clinical decisions and treatment planning. Uncertainty quantification methods, including conformal prediction (CP), can enhance segmentation models reliability. This study aims to use CP in glioma segmentation. Methods: We used the UCSF and UPenn glioma datasets, with the UCSF dataset split into training (70%), validation (10%), calibration (10%), and test (10%) sets, and the UPenn dataset divided into external calibration (30%) and external test (70%) sets. A UNet model was trained, and its optimal threshold was set to 0.5 using prediction normalization. To apply CP, the conformal threshold was selected based on the internal/external calibration nonconformity score, and CP was subsequently applied to the internal/external test sets, with coverage reported for all. We defined the uncertainty ratio (UR) and assessed its correlation with the Dice score coefficient (DSC). Additionally, we categorized cases into certain and uncertain groups based on UR and compared their DSC. We also evaluate the correlation between UR and DSC of the BraTS fusion model segmentation (BFMS), and compare DSC in the certain and uncertain subgroups. Results: The base model achieved a DSC of 0.8628 and 0.8257 on the internal and external test sets, respectively. The CP coverage was 0.9982 for the internal test set and 0.9977 for the external test set. Statistical analysis showed a significant negative correlation between UR and DSC for test sets (p<0.001). UR was also linked to significantly lower DSCs in the BFMS (p<0.001). Additionally, certain cases had significantly higher DSCs than uncertain cases in test sets and the BFMS (p<0.001). Conclusion: CP effectively quantifies uncertainty in glioma segmentation. Using CONSeg improves the reliability of segmentation models and enhances human-computer interaction.

Paper number 37:
Title: Reproducible Optical Tracking Precision: Evaluating a Static, Near-Parallel Support Structure for OptiTrack PrimeX22 Cameras
Authors: Oliver Krumpek, Ole Kroeger, Sebastian Mohr
Abstract: This paper presents the design and evaluation of a physical support structure for the OptiTrack X22 tracking systems, constructed from carbon fiber-reinforced polymer (CFRP) and Invar steel. These materials were chosen for their low thermal expansion, ensuring geometric stability and rigidity necessary for accurate spatial measurements. The support system is scalable and adaptable for various applications and setups. The study further investigates the effects of camera placement and separation in near-parallel configurations on measurement accuracy and precision. Experimental results show a significant correlation between camera distance and measurement precision - closer camera setups yield higher precision. The optimized camera arrangement allowed the prototype to achieve accuracies of +/-0.74 mm along the camera's line of sight and +/-0.12 mm in orthogonal directions. The experiments show that the standard deviation of the noise on a single measurement plane orthogonal to the camera's line of sight vary between 0.02 and 0.07, indicating that the measurement noise is not constant for every point on that specific plane in the meanurement space. Details of the system's design and validation are provided to enhance reproducibility and encourage further development in areas like industrial automation and medical device tracking. By delivering a modular solution with validated accuracy, this work aims to promote innovation and practical application in precision tracking technology, facilitating broader adoption and iterative improvements. This approach enhances the accessibility and versatility of high-precision tracking technology, supporting future progress in the field.

Paper number 38:
Title: Joint Near-Field Sensing and Visibility Region Detection with Extremely Large Aperture Arrays
Authors: Huiping Huang, Alireza Pourafzal, Hui Chen, Musa Furkan Keskin, Mengting Li, Yu Ge, Fredrik Tufvesson, Henk Wymeersch, Xuesong Cai
Abstract: In this paper, we consider near-field localization and sensing with an extremely large aperture array under partial blockage of array antennas, where spherical wavefront and spatial non-stationarity are accounted for. We propose an Ising model to characterize the clustered sparsity feature of the blockage pattern, develop an algorithm based on alternating optimization for joint channel parameter estimation and visibility region detection, and further estimate the locations of the user and environmental scatterers. The simulation results confirm the effectiveness of the proposed algorithm compared to conventional methods.

Paper number 39:
Title: An Adaptive Multiparameter Penalty Selection Method for Multiconstraint and Multiblock ADMM
Authors: Luke Lozenski, Michael T. McCann, Brendt Wohlberg
Abstract: This work presents a new method for online selection of multiple penalty parameters for the alternating direction method of multipliers (ADMM) algorithm applied to optimization problems with multiple constraints or functionals with block matrix components. ADMM is widely used for solving constrained optimization problems in a variety of fields, including signal and image processing. Implementations of ADMM often utilize a single hyperparameter, referred to as the penalty parameter, which needs to be tuned to control the rate of convergence. However, in problems with multiple constraints, ADMM may demonstrate slow convergence regardless of penalty parameter selection due to scale differences between constraints. Accounting for scale differences between constraints to improve convergence in these cases requires introducing a penalty parameter for each constraint. The proposed method is able to adaptively account for differences in scale between constraints, providing robustness with respect to problem transformations and initial selection of penalty parameters. It is also simple to understand and implement. Our numerical experiments demonstrate that the proposed method performs favorably compared to a variety of existing penalty parameter selection methods.

Paper number 40:
Title: End-to-End Deep Learning in Phase Noisy Coherent Optical Link
Authors: Omar Alnaseri, Yassine Himeur
Abstract: In coherent optical orthogonal frequency-division multiplexing (CO-OFDM) fiber communications, a novel end-to-end learning framework to mitigate Laser Phase Noise (LPN) impairments is proposed in this paper. Inspired by Autoencoder (AE) principles, the proposed approach trains a model to learn robust symbol sequences capable of combat LPN, even from low-cost distributed feedback (DFB) lasers with linewidths up to 2 MHz. This allows for the use of high-level modulation formats and large-scale Fast Fourier Transform (FFT) processing, maximizing spectral efficiency in CO-OFDM systems. By eliminating the need for complex traditional techniques, this approach offers a potentially more efficient and streamlined solution for CO-OFDM systems. The most significant achievement of this study is the demonstration that the proposed AE-based model can enhance system performance by reducing the bit error rate (BER) to below the threshold of forward error correction (FEC), even under severe phase noise conditions, thus proving its effectiveness and efficiency in practical deployment scenarios.

Paper number 41:
Title: PET Image Denoising via Text-Guided Diffusion: Integrating Anatomical Priors through Text Prompts
Authors: Boxiao Yu, Savas Ozdemir, Jiong Wu, Yizhou Chen, Ruogu Fang, Kuangyu Shi, Kuang Gong
Abstract: Low-dose Positron Emission Tomography (PET) imaging presents a significant challenge due to increased noise and reduced image quality, which can compromise its diagnostic accuracy and clinical utility. Denoising diffusion probabilistic models (DDPMs) have demonstrated promising performance for PET image denoising. However, existing DDPM-based methods typically overlook valuable metadata such as patient demographics, anatomical information, and scanning parameters, which should further enhance the denoising performance if considered. Recent advances in vision-language models (VLMs), particularly the pre-trained Contrastive Language-Image Pre-training (CLIP) model, have highlighted the potential of incorporating text-based information into visual tasks to improve downstream performance. In this preliminary study, we proposed a novel text-guided DDPM for PET image denoising that integrated anatomical priors through text prompts. Anatomical text descriptions were encoded using a pre-trained CLIP text encoder to extract semantic guidance, which was then incorporated into the diffusion process via the cross-attention mechanism. Evaluations based on paired 1/20 low-dose and normal-dose 18F-FDG PET datasets demonstrated that the proposed method achieved better quantitative performance than conventional UNet and standard DDPM methods at both the whole-body and organ levels. These results underscored the potential of leveraging VLMs to integrate rich metadata into the diffusion framework to enhance the image quality of low-dose PET scans.

Paper number 42:
Title: Bilevel Optimized Implicit Neural Representation for Scan-Specific Accelerated MRI Reconstruction
Authors: Hongze Yu, Jeffrey A. Fessler, Yun Jiang
Abstract: Deep Learning (DL) methods can reconstruct highly accelerated magnetic resonance imaging (MRI) scans, but they rely on application-specific large training datasets and often generalize poorly to out-of-distribution data. Self-supervised deep learning algorithms perform scan-specific reconstructions, but still require complicated hyperparameter tuning based on the acquisition and often offer limited acceleration. This work develops a bilevel-optimized implicit neural representation (INR) approach for scan-specific MRI reconstruction. The method automatically optimizes the hyperparameters for a given acquisition protocol, enabling a tailored reconstruction without training data. The proposed algorithm uses Gaussian process regression to optimize INR hyperparameters, accommodating various acquisitions. The INR includes a trainable positional encoder for high-dimensional feature embedding and a small multilayer perceptron for decoding. The bilevel optimization is computationally efficient, requiring only a few minutes per typical 2D Cartesian scan. On scanner hardware, the subsequent scan-specific reconstruction-using offline-optimized hyperparameters-is completed within seconds and achieves improved image quality compared to previous model-based and self-supervised learning methods.

Paper number 43:
Title: State-Dependent Conformal Perception Bounds for Neuro-Symbolic Verification of Autonomous Systems
Authors: Thomas Waite, Yuang Geng, Trevor Turnquist, Ivan Ruchkin, Radoslav Ivanov
Abstract: It remains a challenge to provide safety guarantees for autonomous systems with neural perception and control. A typical approach obtains symbolic bounds on perception error (e.g., using conformal prediction) and performs verification under these bounds. However, these bounds can lead to drastic conservatism in the resulting end-to-end safety guarantee. This paper proposes an approach to synthesize symbolic perception error bounds that serve as an optimal interface between perception performance and control verification. The key idea is to consider our error bounds to be heteroskedastic with respect to the system's state -- not time like in previous approaches. These bounds can be obtained with two gradient-free optimization algorithms. We demonstrate that our bounds lead to tighter safety guarantees than the state-of-the-art in a case study on a mountain car.

Paper number 44:
Title: AutoComb: Automated Comb Sign Detector for 3D CTE Scans
Authors: Shashwat Gupta, Sarthak Gupta, Akshan Agrawal, Mahim Naaz, Rajanikanth Yadav, Priyanka Bagade
Abstract: Comb Sign is an important imaging biomarker to detect multiple gastrointestinal diseases. It shows up as increased blood flow along the intestinal wall indicating potential abnormality, which helps doctors diagnose inflammatory conditions. Despite its clinical significance, current detection methods are manual, time-intensive, and prone to subjective interpretation due to the need for multi-planar image-orientation. To the best of our knowledge, we are the first to propose a fully automated technique for the detection of Comb Sign from CTE scans. Our novel approach is based on developing a probabilistic map that shows areas of pathological hypervascularity by identifying fine vascular bifurcations and wall enhancement via processing through stepwise algorithmic modules. These modules include utilising deep learning segmentation model, a Gaussian Mixture Model (GMM), vessel extraction using vesselness filter, iterative probabilistic enhancement of vesselness via neighborhood maximization and a distance-based weighting scheme over the vessels. Experimental results demonstrate that our pipeline effectively identifies Comb Sign, offering an objective, accurate, and reliable tool to enhance diagnostic accuracy in Crohn's disease and related hypervascular conditions where Comb Sign is considered as one of the important biomarkers.

Paper number 45:
Title: TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning for Sparse-Angle CT Reconstruction
Authors: Tatiana A. Bubba, Matteo Santacesaria, Andrea Sebastiani
Abstract: Deep learning has emerged as a powerful tool for solving inverse problems in imaging, including computed tomography (CT). However, most approaches require paired training data with ground truth images, which can be difficult to obtain, e.g., in medical applications. We present TomoSelfDEQ, a self-supervised Deep Equilibrium (DEQ) framework for sparse-angle CT reconstruction that trains directly on undersampled measurements. We establish theoretical guarantees showing that, under suitable assumptions, our self-supervised updates match those of fully-supervised training with a loss including the (possibly non-unitary) forward operator like the CT forward map. Numerical experiments on sparse-angle CT data confirm this finding, also demonstrating that TomoSelfDEQ outperforms existing self-supervised methods, achieving state-of-the-art results with as few as 16 projection angles.

Paper number 46:
Title: Accurate 3D Grapevine Structure Extraction from High-Resolution Point Clouds
Authors: Harry Dobbs, Casey Peat, Oliver Batchelor, James Atlas, Richard Green
Abstract: Accurate 3D modelling of grapevines is crucial for precision viticulture, particularly for informed pruning decisions and automated management techniques. However, the intricate structure of grapevines poses significant challenges for traditional skeletonization algorithms. This paper presents an adaptation of the Smart-Tree algorithm for 3D grapevine modelling, addressing the unique characteristics of grapevine structures. We introduce a graph-based method for disambiguating skeletonization. Our method delineates individual cane skeletons, which are crucial for precise analysis and management. We validate our approach using annotated real-world grapevine point clouds, demonstrating improvement of 15.8% in the F1 score compared to the original Smart-Tree algorithm. This research contributes to advancing 3D grapevine modelling techniques, potentially enhancing both the sustainability and profitability of grape production through more precise and automated viticulture practices

Paper number 47:
Title: DeePen: Penetration Testing for Audio Deepfake Detection
Authors: Nicolas Müller, Piotr Kawa, Adriana Stan, Thien-Phuc Doan, Souhwan Jung, Wei Herng Choong, Philip Sperl, Konstantin Böttinger
Abstract: Deepfakes - manipulated or forged audio and video media - pose significant security risks to individuals, organizations, and society at large. To address these challenges, machine learning-based classifiers are commonly employed to detect deepfake content. In this paper, we assess the robustness of such classifiers through a systematic penetration testing methodology, which we introduce as DeePen. Our approach operates without prior knowledge of or access to the target deepfake detection models. Instead, it leverages a set of carefully selected signal processing modifications - referred to as attacks - to evaluate model vulnerabilities. Using DeePen, we analyze both real-world production systems and publicly available academic model checkpoints, demonstrating that all tested systems exhibit weaknesses and can be reliably deceived by simple manipulations such as time-stretching or echo addition. Furthermore, our findings reveal that while some attacks can be mitigated by retraining detection systems with knowledge of the specific attack, others remain persistently effective. We release all associated code.

Paper number 48:
Title: APIKS: A Modular ROS2 Framework for Rapid Prototyping and Validation of Automated Driving Systems
Authors: João-Vitor Zacchi, Edoardo Clementi, Núria Mata
Abstract: Automated driving technologies promise substantial improvements in transportation safety, efficiency, and accessibility. However, ensuring the reliability and safety of Autonomous Vehicles in complex, real-world environments remains a significant challenge, particularly during the early stages of software development. Existing software development environments and simulation platforms often either focus narrowly on specific functions or are too complex, hindering the rapid prototyping of small proofs of concept. To address this challenge, we have developed the APIKS automotive platform, a modular framework based on ROS2. APIKS is designed for the efficient testing and validation of autonomous vehicle software within software-defined vehicles. It offers a simplified, standards-based architecture designed specifically for small-scale proofs of concept. This enables rapid prototyping without the overhead associated with comprehensive platforms. We demonstrate the capabilities of APIKS through an exemplary use case involving a Construction Zone Assist system, illustrating its effectiveness in facilitating the development and testing of autonomous vehicle functionalities.

Paper number 49:
Title: Toward Fully Autonomous Flexible Chunk-Based Aerial Additive Manufacturing: Insights from Experimental Validation
Authors: Marios-Nektarios Stamatopoulos, Jakub Haluska, Elias Small, Jude Marroush, Avijit Banerjee, George Nikolakopoulos
Abstract: A novel autonomous chunk-based aerial additive manufacturing framework is presented, supported with experimental demonstration advancing aerial 3D printing. An optimization-based decomposition algorithm transforms structures into sub-components, or chunks, treated as individual tasks coordinated via a dependency graph, ensuring sequential assignment to UAVs considering inter-dependencies and printability constraints for seamless execution. A specially designed hexacopter equipped with a pressurized canister for lightweight expandable foam extrusion is utilized to deposit the material in a controlled manner. To further enhance precise execution of the printing, an offset-free Model Predictive Control mechanism is considered compensating reactively for disturbances and ground effect during execution. Additionally, an interlocking mechanism is introduced in the chunking process to enhance structural cohesion and improve layer adhesion. Extensive experiments demonstrate the framework's effectiveness in constructing precise structures of various shapes while seamlessly adapting to practical challenges, proving its potential for a transformative leap in aerial robotic capability for autonomous construction.

Paper number 50:
Title: Close-Proximity Satellite Operations through Deep Reinforcement Learning and Terrestrial Testing Environments
Authors: Henry Lei, Joshua Aurand, Zachary S. Lippay, Sean Phillips
Abstract: With the increasingly congested and contested space environment, safe and effective satellite operation has become increasingly challenging. As a result, there is growing interest in autonomous satellite capabilities, with common machine learning techniques gaining attention for their potential to address complex decision-making in the space domain. However, the "black-box" nature of many of these methods results in difficulty understanding the model's input/output relationship and more specifically its sensitivity to environmental disturbances, sensor noise, and control intervention. This paper explores the use of Deep Reinforcement Learning (DRL) for satellite control in multi-agent inspection tasks. The Local Intelligent Network of Collaborative Satellites (LINCS) Lab is used to test the performance of these control algorithms across different environments, from simulations to real-world quadrotor UAV hardware, with a particular focus on understanding their behavior and potential degradation in performance when deployed beyond the training environment.

Paper number 51:
Title: LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation
Authors: Keisuke Kamahori, Jungo Kasai, Noriyuki Kojima, Baris Kasikci
Abstract: Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper, rely on deep encoder-decoder architectures, and their encoders are a critical bottleneck for efficient deployment due to high computational intensity. We introduce LiteASR, a low-rank compression scheme for ASR encoders that significantly reduces inference costs while maintaining transcription accuracy. Our approach leverages the strong low-rank properties observed in intermediate activations: by applying principal component analysis (PCA) with a small calibration dataset, we approximate linear transformations with a chain of low-rank matrix multiplications, and further optimize self-attention to work in the reduced dimension. Evaluation results show that our method can compress Whisper large-v3's encoder size by over 50%, matching Whisper medium's size with better transcription accuracy, thereby establishing a new Pareto-optimal frontier of efficiency and performance. The code of LiteASR is available at this https URL.

Paper number 52:
Title: Delayed-Decision Motion Planning in the Presence of Multiple Predictions
Authors: David Isele, Alexandre Miranda Anon, Faizan M. Tariq, Goro Yeh, Avinash Singh, Sangjae Bae
Abstract: Reliable automated driving technology is challenged by various sources of uncertainties, in particular, behavioral uncertainties of traffic agents. It is common for traffic agents to have intentions that are unknown to others, leaving an automated driving car to reason over multiple possible behaviors. This paper formalizes a behavior planning scheme in the presence of multiple possible futures with corresponding probabilities. We present a maximum entropy formulation and show how, under certain assumptions, this allows delayed decision-making to improve safety. The general formulation is then turned into a model predictive control formulation, which is solved as a quadratic program or a set of quadratic programs. We discuss implementation details for improving computation and verify operation in simulation and on a mobile robot.

Paper number 53:
Title: OpenEarthSensing: Large-Scale Fine-Grained Benchmark for Open-World Remote Sensing
Authors: Xiang Xiang, Zhuo Xu, Yao Deng, Qinhao Zhou, Yifan Liang, Ke Chen, Qingfang Zheng, Yaowei Wang, Xilin Chen, Wen Gao
Abstract: In open-world remote sensing, deployed models must continuously adapt to a steady influx of new data, which often exhibits various shifts compared to what the model encountered during the training phase. To effectively handle the new data, models are required to detect semantic shifts, adapt to covariate shifts, and continuously update themselves. These challenges give rise to a variety of open-world tasks. However, existing open-world remote sensing studies typically train and test within a single dataset to simulate open-world conditions. Currently, there is a lack of large-scale benchmarks capable of evaluating multiple open-world tasks. In this paper, we introduce OpenEarthSensing, a large-scale fine-grained benchmark for open-world remote sensing. OpenEarthSensing includes 189 scene and objects categories, covering the vast majority of potential semantic shifts that may occur in the real world. Additionally, OpenEarthSensing encompasses five data domains with significant covariate shifts, including two RGB satellite domians, one RGB aerial domian, one MS RGB domian, and one infrared domian. The various domains provide a more comprehensive testbed for evaluating the generalization performance of open-world models. We conduct the baseline evaluation of current mainstream open-world tasks and methods on OpenEarthSensing, demonstrating that it serves as a challenging benchmark for open-world remote sensing.

Paper number 54:
Title: MFSR-GAN: Multi-Frame Super-Resolution with Handheld Motion Modeling
Authors: Fadeel Sher Khan, Joshua Ebenezer, Hamid Sheikh, Seok-Jun Lee
Abstract: Smartphone cameras have become ubiquitous imaging tools, yet their small sensors and compact optics often limit spatial resolution and introduce distortions. Combining information from multiple low-resolution (LR) frames to produce a high-resolution (HR) image has been explored to overcome the inherent limitations of smartphone cameras. Despite the promise of multi-frame super-resolution (MFSR), current approaches are hindered by datasets that fail to capture the characteristic noise and motion patterns found in real-world handheld burst images. In this work, we address this gap by introducing a novel synthetic data engine that uses multi-exposure static images to synthesize LR-HR training pairs while preserving sensor-specific noise characteristics and image motion found during handheld burst photography. We also propose MFSR-GAN: a multi-scale RAW-to-RGB network for MFSR. Compared to prior approaches, MFSR-GAN emphasizes a "base frame" throughout its architecture to mitigate artifacts. Experimental results on both synthetic and real data demonstrates that MFSR-GAN trained with our synthetic engine yields sharper, more realistic reconstructions than existing methods for real-world MFSR.

Paper number 55:
Title: Weakly Supervised Multiple Instance Learning for Whale Call Detection and Localization in Long-Duration Passive Acoustic Monitoring
Authors: Ragib Amin Nihal, Benjamin Yen, Runwu Shi, Kazuhiro Nakadai
Abstract: Marine ecosystem monitoring via Passive Acoustic Monitoring (PAM) generates vast data, but deep learning often requires precise annotations and short segments. We introduce DSMIL-LocNet, a Multiple Instance Learning framework for whale call detection and localization using only bag-level labels. Our dual-stream model processes 2-30 minute audio segments, leveraging spectral and temporal features with attention-based instance selection. Tests on Antarctic whale data show longer contexts improve classification (F1: 0.8-0.9) while medium instances ensure localization precision (0.65-0.70). This suggests MIL can enhance scalable marine monitoring. Code: this https URL

Paper number 56:
Title: AARC: Automated Affinity-aware Resource Configuration for Serverless Workflows
Authors: Lingxiao Jin, Zinuo Cai, Zebin Chen, Hongyu Zhao, Ruhui Ma
Abstract: Serverless computing is increasingly adopted for its ability to manage complex, event-driven workloads without the need for infrastructure provisioning. However, traditional resource allocation in serverless platforms couples CPU and memory, which may not be optimal for all functions. Existing decoupling approaches, while offering some flexibility, are not designed to handle the vast configuration space and complexity of serverless workflows. In this paper, we propose AARC, an innovative, automated framework that decouples CPU and memory resources to provide more flexible and efficient provisioning for serverless workloads. AARC is composed of two key components: Graph-Centric Scheduler, which identifies critical paths in workflows, and Priority Configurator, which applies priority scheduling techniques to optimize resource allocation. Our experimental evaluation demonstrates that AARC achieves substantial improvements over state-of-the-art methods, with total search time reductions of 85.8% and 89.6%, and cost savings of 49.6% and 61.7%, respectively, while maintaining SLO compliance.

Paper number 57:
Title: BadRefSR: Backdoor Attacks Against Reference-based Image Super Resolution
Authors: Xue Yang, Tao Chen, Lei Guo, Wenbo Jiang, Ji Guo, Yongming Li, Jiaming He
Abstract: Reference-based image super-resolution (RefSR) represents a promising advancement in super-resolution (SR). In contrast to single-image super-resolution (SISR), RefSR leverages an additional reference image to help recover high-frequency details, yet its vulnerability to backdoor attacks has not been explored. To fill this research gap, we propose a novel attack framework called BadRefSR, which embeds backdoors in the RefSR model by adding triggers to the reference images and training with a mixed loss function. Extensive experiments across various backdoor attack settings demonstrate the effectiveness of BadRefSR. The compromised RefSR network performs normally on clean input images, while outputting attacker-specified target images on triggered input images. Our study aims to alert researchers to the potential backdoor risks in RefSR. Codes are available at this https URL.

Paper number 58:
Title: Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport
Authors: Jingru Fu, Yuqi Zheng, Neel Dey, Daniel Ferreira, Rodrigo Moreno
Abstract: Simulating prospective magnetic resonance imaging (MRI) scans from a given individual brain image is challenging, as it requires accounting for canonical changes in aging and/or disease progression while also considering the individual brain's current status and unique characteristics. While current deep generative models can produce high-resolution anatomically accurate templates for population-wide studies, their ability to predict future aging trajectories for individuals remains limited, particularly in capturing subject-specific neuroanatomical variations over time. In this study, we introduce Individualized Brain Synthesis (InBrainSyn), a framework for synthesizing high-resolution subject-specific longitudinal MRI scans that simulate neurodegeneration in both Alzheimer's disease (AD) and normal aging. InBrainSyn uses a parallel transport algorithm to adapt the population-level aging trajectories learned by a generative deep template network, enabling individualized aging synthesis. As InBrainSyn uses diffeomorphic transformations to simulate aging, the synthesized images are topologically consistent with the original anatomy by design. We evaluated InBrainSyn both quantitatively and qualitatively on AD and healthy control cohorts from the Open Access Series of Imaging Studies - version 3 dataset. Experimentally, InBrainSyn can also model neuroanatomical transitions between normal aging and AD. An evaluation of an external set supports its generalizability. Overall, with only a single baseline scan, InBrainSyn synthesizes realistic 3D spatiotemporal T1w MRI scans, producing personalized longitudinal aging trajectories. The code for InBrainSyn is available at: this https URL.

Paper number 59:
Title: HoloMine: A Synthetic Dataset for Buried Landmines Recognition using Microwave Holographic Imaging
Authors: Emanuele Vivoli, Lorenzo Capineri, Marco Bertini
Abstract: The detection and removal of landmines is a complex and risky task that requires advanced remote sensing techniques to reduce the risk for the professionals involved in this task. In this paper, we propose a novel synthetic dataset for buried landmine detection to provide researchers with a valuable resource to observe, measure, locate, and address issues in landmine detection. The dataset consists of 41,800 microwave holographic images (2D) and their holographic inverted scans (3D) of different types of buried objects, including landmines, clutter, and pottery objects, and is collected by means of a microwave holography sensor. We evaluate the performance of several state-of-the-art deep learning models trained on our synthetic dataset for various classification tasks. While the results do not yield yet high performances, showing the difficulty of the proposed task, we believe that our dataset has significant potential to drive progress in the field of landmine detection thanks to the accuracy and resolution obtainable using holographic radars. To the best of our knowledge, our dataset is the first of its kind and will help drive further research on computer vision methods to automatize mine detection, with the overall goal of reducing the risks and the costs of the demining process.

Paper number 60:
Title: Deep learning-based filtering of cross-spectral matrices using generative adversarial networks
Authors: Christof Puhle
Abstract: In this paper, we present a deep-learning method to filter out effects such as ambient noise, reflections, or source directivity from microphone array data represented as cross-spectral matrices. Specifically, we focus on a generative adversarial network (GAN) architecture designed to transform fixed-size cross-spectral matrices. Theses models were trained using sound pressure simulations of varying complexity developed for this purpose. Based on the results from applying these methods in a hyperparameter optimization of an auto-encoding task, we trained the optimized model to perform five distinct transformation tasks derived from different complexities inherent in our sound pressure simulations.

Paper number 61:
Title: CurviTrack: Curvilinear Trajectory Tracking for High-speed Chase of a USV
Authors: Parakh M. Gupta, Ondřej Procházka, Tiago Nascimento, Martin Saska
Abstract: Heterogeneous robot teams used in marine environments incur time-and-energy penalties when the marine vehicle has to halt the mission to allow the autonomous aerial vehicle to land for recharging. In this paper, we present a solution for this problem using a novel drag-aware model formulation which is coupled with MPC, and therefore, enables tracking and landing during high-speed curvilinear trajectories of an USV without any communication. Compared to the state-of-the-art, our approach yields 40% decrease in prediction errors, and provides a 3-fold increase in certainty of predictions. Consequently, this leads to a 30% improvement in tracking performance and 40% higher success in landing on a moving USV even during aggressive turns that are unfeasible for conventional marine missions. We test our approach in two different real-world scenarios with marine vessels of two different sizes and further solidify our results through statistical analysis in simulation to demonstrate the robustness of our method.

Paper number 62:
Title: Knowledge Transfer based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis
Authors: Arun K. Sharma, Nishchal K. Verma
Abstract: A faster response with commendable accuracy in intelligent systems is essential for the reliability and smooth operations of industrial machines. Two main challenges affect the design of such intelligent systems: (i) the selection of a suitable model and (ii) domain adaptation if there is a continuous change in operating conditions. Therefore, we propose an evolutionary Net2Net transformation (EvoN2N) that finds the best suitable DNN architecture with limited availability of labeled data samples. Net2Net transformation-based quick learning algorithm has been used in the evolutionary framework of Non-dominated sorting genetic algorithm II to obtain the best DNN architecture. Net2Net transformation-based quick learning algorithm uses the concept of knowledge transfer from one generation to the next for faster fitness evaluation. The proposed framework can obtain the best model for intelligent fault diagnosis without a long and time-consuming search process. The proposed framework has been validated on the Case Western Reserve University dataset, the Paderborn University dataset, and the gearbox fault detection dataset under different operating conditions. The best models obtained are capable of demonstrating an excellent diagnostic performance and classification accuracy of almost up to 100% for most of the operating conditions.

Paper number 63:
Title: Generalized Graph Signal Sampling by Difference-of-Convex Optimization
Authors: Keitaro Yamashita, Kazuki Naganuma, Shunsuke Ono
Abstract: We propose a desigining method of a flexible sampling operator for graph signals via a difference-of-convex (DC) optimization algorithm. A fundamental challenge in graph signal processing is sampling, especially for graph signals that are not bandlimited. In order to sample beyond bandlimited graph signals, there are studies to expand the generalized sampling theory for the graph setting. Vertex-wise sampling and flexible sampling are two main strategies to sample graph signals. Recovery accuracy of existing vertex-wise sampling methods is highly dependent on specific vertices selected to generate a sampled graph signal that may compromise the accurary especially when noise is generated at the vertices. In contrast, a flexible sampling mixes values at multiple vertices to generate a sampled signal for robust sampling; however, existing flexible sampling methods impose strict assumptions and aggressive relaxations. To address these limitations, we aim to design a flexible sampling operator without such strict assumptions and aggressive relaxations by introducing DC optimization. By formulating the problem of designing a flexible sampling operator as a DC optimization problem, our method ensures robust sampling for graph signals under arbitrary priors based on generalized sampling theory. We develop an efficient solver based on the general double-proximal gradient DC algorithm, which guarantees convergence to a critical point. Experimental results demonstrate the superiority of our method in sampling and recovering beyond bandlimited graph signals compared to existing approaches.

Paper number 64:
Title: Exergetic Port-Hamiltonian Systems Modeling Language
Authors: Markus Lohmayer, Owen Lynch, Sigrid Leyendecker
Abstract: Mathematical modeling of real-world physical systems requires the consistent combination of a multitude of physical laws and phenomenological models. This challenging task can be greatly simplified by hierarchically decomposing systems into ultimately simple components. Moreover, the use of diagrams for expressing the decomposition helps make the process more intuitive and facilitates communication, even with non-experts. As an important requirement, models have to respect fundamental physical laws such as the first and the second law of thermodynamics. While some existing modeling frameworks make such guarantees based on structural properties of their models, they lack a formal graphical syntax. We present a compositional and thermodynamically consistent modeling language with a graphical syntax. In terms of its semantics, we essentially endow port-Hamiltonian systems with additional structural properties and a fixed physical interpretation, ensuring thermodynamic consistency in a manner closely related to the metriplectic or GENERIC formalism. While port-Hamiltonian systems are inspired by graphical modeling with bond graphs, neither the link between the two, nor bond graphs themselves, can be easily formalized. In contrast, our syntax is based on a refinement of the well-studied operad of undirected wiring diagrams. By combining a compositional, graphical syntax with an energy-based, thermodynamic approach, the presented modeling language simplifies the understanding, reuse, and modification of complex physical models.

Paper number 65:
Title: A Deep Learning Approach to Multi-Fiber Parameter Estimation and Uncertainty Quantification in Diffusion MRI
Authors: William Consagra, Lipeng Ning, Yogesh Rathi
Abstract: Diffusion MRI (dMRI) is the primary imaging modality used to study brain microstructure in vivo. Reliable and computationally efficient parameter inference for common dMRI biophysical models is a challenging inverse problem, due to factors such as variable dimensionalities (reflecting the unknown number of distinct white matter fiber populations in a voxel), low signal-to-noise ratios, and non-linear forward models. These challenges have led many existing methods to use biologically implausible simplified models to stabilize estimation, for instance, assuming shared microstructure across all fiber populations within a voxel. In this work, we introduce a novel sequential method for multi-fiber parameter inference that decomposes the task into a series of manageable subproblems. These subproblems are solved using deep neural networks tailored to problem-specific structure and symmetry, and trained via simulation. The resulting inference procedure is largely amortized, enabling scalable parameter estimation and uncertainty quantification across all model parameters. Simulation studies and real imaging data analysis using the Human Connectome Project (HCP) demonstrate the advantages of our method over standard alternatives. In the case of the standard model of diffusion, our results show that under HCP-like acquisition schemes, estimates for extra-cellular parallel diffusivity are highly uncertain, while those for the intra-cellular volume fraction can be estimated with relatively high precision.

Paper number 66:
Title: Goal-Oriented Semantic Communication for Wireless Image Transmission via Stable Diffusion
Authors: Nan Li, Yansha Deng
Abstract: Efficient image transmission is essential for seamless communication and collaboration within the visually-driven digital landscape. To achieve low latency and high-quality image reconstruction over a bandwidth-constrained noisy wireless channel, we propose a stable diffusion (SD)-based goal-oriented semantic communication (GSC) framework. In this framework, we design a semantic autoencoder that effectively extracts semantic information (SI) from images to reduce the transmission data size while ensuring high-quality reconstruction. Recognizing the impact of wireless channel noise on SI transmission, we propose an SD-based denoiser for GSC (SD-GSC) conditional on an instantaneous channel gain to remove the channel noise from the received noisy SI under known channel. For scenarios with unknown channel, we further propose a parallel SD denoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains and denoise the received SI. It is shown that, with the known channel, our SD-GSC outperforms state-of-the-art ADJSCC and Latent-Diff DNSC, improving Peak Signal-to-Noise Ratio (PSNR) by 32% and 21%, and reducing Fréchet Inception Distance (FID) by 40% and 35%, respectively. With the unknown channel, our PSD-GSC improves PSNR by 8% and reduces FID by 17% compared to MMSE equalizer-enhanced SD-GSC.

Paper number 67:
Title: Deep Learning Autoencoders for Reducing PAPR in Coherent Optical Systems
Authors: Omar Alnaseri, Ibtesam R. K. Al-Saedi, Yassine Himeur, Hongxiang Li
Abstract: This paper presents an innovative approach to mitigating the peak-to-average power ratio (PAPR). The proposed method uses a deep learning model called autoencoders (AEs) to simplify the process and avoid the complex calculations of traditional methods such as selective mapping (SLM). Unlike SLM, our approach does not need side information about the PAPR distribution. Through simulations of coherent optical orthogonal frequency division multiplexing (CO-OFDM) systems, the AE-based model offers substantial enhancements in both PAPR reduction and bit error rate (BER) performance when compared to conventional techniques. An error-free transmission can be acheived with a reduction in PAPR exceeding 10 dB compared to the original signal and a 1 dB advantage over SLM. In particular, the AE model achieves the best BER performance of \(2 \times 10^{-6}\) at 44 dB OSNR, surpassing traditional methods. Furthermore, the model demonstrates robustness against noise and nonlinear distortions, making it appropriate for optical channels experiencing diverse levels of impairment. This innovative technique has the potential to revolutionize next-generation optical communication systems by enabling efficient and reliable data transmission.

Paper number 68:
Title: Discrete-time Indirect Adaptive Control for Systems with Disturbances via Directional Forgetting: Concurrent Learning Approach
Authors: Satoshi Tsuruhara, Kazuhisa Ito
Abstract: Recently, adaptive control systems with relaxed persistent excitation (PE) conditions have been proposed to guarantee true parameter convergence and improve the transient response. However, in some cases, sufficient control performance and parameter convergence cannot be easily achieved, with stability demonstrated only under ideal conditions, such as the absence of disturbances and matching conditions required. In this study, we propose a novel adaptive control method for discrete-time systems with disturbances, which is not under an ideal case, that combines directional forgetting and concurrent learning. The proposed method does not require the PE condition, information on disturbances, unknown parameters, or matching conditions, and it guarantees uniformly ultimately bounded (UUB). It was also theoretically demonstrated that the ultimate bound can be designed based on the forgetting factor, which is a design parameter. In addition, the upper bound decreases with time step, which is independent of the system order and/or target trajectory due to forgetting factor. This also implies stronger stability than a normal UUB. Numerical simulation results illustrate the effectiveness of the proposed method.

Paper number 69:
Title: EndoPerfect: High-Accuracy Monocular Depth Estimation and 3D Reconstruction for Endoscopic Surgery via NeRF-Stereo Fusion
Authors: Pengcheng Chen, Wenhao Li, Nicole Gunderson, Jeremy Ruthberg, Randall Bly, Zhenglong Sun, Waleed M. Abuzeid, Eric J. Seibel
Abstract: In endoscopic sinus surgery (ESS), intraoperative CT (iCT) offers valuable intraoperative assessment but is constrained by slow deployment and radiation exposure, limiting its clinical utility. Endoscope-based monocular 3D reconstruction is a promising alternative; however, existing techniques often struggle to achieve the submillimeter precision required for dense reconstruction. In this work, we propose an iterative online learning approach that leverages Neural Radiance Fields (NeRF) as an intermediate representation, enabling monocular depth estimation and 3D reconstruction without relying on prior medical data. Our method attains a point-to-point accuracy below 0.5 mm, with a demonstrated theoretical depth accuracy of 0.125 $\pm$ 0.443 mm. We validate our approach across synthetic, phantom, and real endoscopic scenarios, confirming its accuracy and reliability. These results underscore the potential of our pipeline as an iCT alternative, meeting the demanding submillimeter accuracy standards required in ESS.

Paper number 70:
Title: Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs
Authors: Haolin Li, Haoyu Wang, Luana Ruiz
Abstract: Graph Neural Networks (GNNs) excel in many graph machine learning tasks but face challenges when scaling to large networks. GNN transferability allows training on smaller graphs and applying the model to larger ones, but existing methods often rely on random subsampling, leading to disconnected subgraphs and reduced model expressivity. We propose a novel graph sampling algorithm that leverages feature homophily to preserve graph structure. By minimizing the trace of the data correlation matrix, our method better preserves the graph Laplacian trace -- a proxy for the graph connectivity -- than random sampling, while achieving lower complexity than spectral methods. Experiments on citation networks show improved performance in preserving Laplacian trace and GNN transferability compared to random sampling.

Paper number 71:
Title: Progressive Curriculum Learning with Scale-Enhanced U-Net for Continuous Airway Segmentation
Authors: Bingyu Yang, Qingyao Tian, Huai Liao, Xinyan Huang, Jinlin Wu, Jingdi Hu, Hongbin Liu
Abstract: Continuous and accurate segmentation of airways in chest CT images is essential for preoperative planning and real-time bronchoscopy navigation. Despite advances in deep learning for medical image segmentation, maintaining airway continuity remains a challenge, particularly due to intra-class imbalance between large and small branches and blurred CT scan details. To address these challenges, we propose a progressive curriculum learning pipeline and a Scale-Enhanced U-Net (SE-UNet) to enhance segmentation continuity. Specifically, our progressive curriculum learning pipeline consists of three stages: extracting main airways, identifying small airways, and repairing discontinuities. The cropping sampling strategy in each stage reduces feature interference between airways of different scales, effectively addressing the challenge of intra-class imbalance. In the third training stage, we present an Adaptive Topology-Responsive Loss (ATRL) to guide the network to focus on airway continuity. The progressive training pipeline shares the same SE-UNet, integrating multi-scale inputs and Detail Information Enhancers (DIEs) to enhance information flow and effectively capture the intricate details of small airways. Additionally, we propose a robust airway tree parsing method and hierarchical evaluation metrics to provide more clinically relevant and precise analysis. Experiments on both in-house and public datasets demonstrate that our method outperforms existing approaches, significantly improving the accuracy of small airways and the completeness of the airway tree. The code will be released upon publication.

Paper number 72:
Title: Distributed Blind Source Separation based on FastICA
Authors: Cem Ates Musluoglu, Alexander Bertrand
Abstract: With the emergence of wireless sensor networks (WSNs), many traditional signal processing tasks are required to be computed in a distributed fashion, without transmissions of the raw data to a centralized processing unit, due to the limited energy and bandwidth resources available to the sensors. In this paper, we propose a distributed independent component analysis (ICA) algorithm, which aims at identifying the original signal sources based on observations of their mixtures measured at various sensor nodes. One of the most commonly used ICA algorithms is known as FastICA, which requires a spatial pre-whitening operation in the first step of the algorithm. Such a pre-whitening across all nodes of a WSN is impossible in a bandwidth-constrained distributed setting as it requires to correlate each channel with each other channel in the WSN. We show that an explicit network-wide pre-whitening step can be circumvented by leveraging the properties of the so-called Distributed Adaptive Signal Fusion (DASF) framework. Despite the lack of such a network-wide pre-whitening, we can still obtain the $Q$ least Gaussian independent components of the centralized ICA solution, where $Q$ scales linearly with the required communication load.

Paper number 73:
Title: Duality of Stochastic Observability and Constructability and Links to Fisher Information
Authors: Burak Boyacıoğlu, Floris van Breugel
Abstract: Given a set of measurements, observability characterizes the distinguishability of a system's initial state, whereas constructability focuses on the final state in a trajectory. In the presence of process and/or measurement noise, the Fisher information matrices with respect to the initial and final states$\unicode{x2013}$equivalent to the stochastic observability and constructability Gramians$\unicode{x2013}$bound the performance of corresponding estimators through the Cramér-Rao inequality. This letter establishes a connection between stochastic observability and constructability of discrete-time linear systems and provides a more numerically robust way for calculating the stochastic observability Gramian. We define a dual system and show that the dual system's stochastic constructability is equivalent to the original system's stochastic observability, and vice versa. This duality enables the interchange of theorems and tools for observability and constructability. For example, we use this result to translate an existing recursive formula for the stochastic constructability Gramian into a formula for recursively calculating the stochastic observability Gramian for both time-varying and time-invariant systems, where this sequence converges for the latter. Finally, we illustrate the robustness of our formula compared to existing (non-recursive) formulas through a numerical example.

Paper number 74:
Title: Advancing Hybrid Quantum Neural Network for Alternative Current Optimal Power Flow
Authors: Ze Hu, Ziqing Zhu, Linghua Zhu, Xiang Wei, Siqi Bu, Ka Wing Chan
Abstract: Alternative Current Optimal Power Flow (AC-OPF) is essential for efficient power system planning and real-time operation but remains an NP-hard and non-convex optimization problem with significant computational challenges. This paper proposes a novel hybrid classical-quantum deep learning framework for AC-OPF problem, integrating parameterized quantum circuits (PQCs) for feature extraction with classical deep learning for data encoding and decoding. The proposed framework integrates two types of residual connection structures to mitigate the ``barren plateau" problem in quantum circuits, enhancing training stability and convergence. Furthermore, a physics-informed neural network (PINN) module is incorporated to guarantee tolerable constraint violation, improving the physical consistency and reliability of AC-OPF solutions. Experimental evaluations on multiple IEEE test systems demonstrate that the proposed approach achieves superior accuracy, generalization, and robustness to quantum noise while requiring minimal quantum resources.

Paper number 75:
Title: Hybrid deep learning-based strategy for the hepatocellular carcinoma cancer grade classification of H&E stained liver histopathology images
Authors: Ajinkya Deshpande, Deep Gupta, Ankit Bhurane, Nisha Meshram, Sneha Singh, Petia Radeva
Abstract: Hepatocellular carcinoma (HCC) is a common type of liver cancer whose early-stage diagnosis is a common challenge, mainly due to the manual assessment of hematoxylin and eosin-stained whole slide images, which is a time-consuming process and may lead to variability in decision-making. For accurate detection of HCC, we propose a hybrid deep learning-based architecture that uses transfer learning to extract the features from pre-trained convolutional neural network (CNN) models and a classifier made up of a sequence of fully connected layers. This study uses a publicly available The Cancer Genome Atlas Hepatocellular Carcinoma (TCGA-LIHC)database (n=491) for model development and database of Kasturba Gandhi Medical College (KMC), India for validation. The pre-processing step involves patch extraction, colour normalization, and augmentation that results in 3920 patches for the TCGA dataset. The developed hybrid deep neural network consisting of a CNN-based pre-trained feature extractor and a customized artificial neural network-based classifier is trained using five-fold cross-validation. For this study, eight different state-of-the-art models are trained and tested as feature extractors for the proposed hybrid model. The proposed hybrid model with ResNet50-based feature extractor provided the sensitivity, specificity, F1-score, accuracy, and AUC of 100.00%, 100.00%, 100.00%, 100.00%, and 1.00, respectively on the TCGA database. On the KMC database, EfficientNetb3 resulted in the optimal choice of the feature extractor giving sensitivity, specificity, F1-score, accuracy, and AUC of 96.97, 98.85, 96.71, 96.71, and 0.99, respectively. The proposed hybrid models showed improvement in accuracy of 2% and 4% over the pre-trained models in TCGA-LIHC and KMC databases.

Paper number 76:
Title: Equivariant Denoisers for Image Restoration
Authors: Marien Renaud, Arthur Leclaire, Nicolas Papadakis
Abstract: One key ingredient of image restoration is to define a realistic prior on clean images to complete the missing information in the observation. State-of-the-art restoration methods rely on a neural network to encode this prior. Moreover, typical image distributions are invariant to some set of transformations, such as rotations or flips. However, most deep architectures are not designed to represent an invariant image distribution. Recent works have proposed to overcome this difficulty by including equivariance properties within a Plug-and-Play paradigm. In this work, we propose a unified framework named Equivariant Regularization by Denoising (ERED) based on equivariant denoisers and stochastic optimization. We analyze the convergence of this algorithm and discuss its practical benefit.

Paper number 77:
Title: Convergence Analysis of a Proximal Stochastic Denoising Regularization Algorithm
Authors: Marien Renaud, Julien Hermant, Nicolas Papadakis
Abstract: Plug-and-Play methods for image restoration are iterative algorithms that solve a variational problem to recover a clean image from a degraded observation. These algorithms are known to be flexible to changes of degradation and to perform state-of-the-art restoration. Recently, significant efforts have been made to explore new stochastic algorithms based on the Plug-and-Play or REgularization by Denoising (RED) frameworks, such as SNORE, which is a convergent stochastic gradient descent algorithm. A variant of this algorithm, named SNORE Prox, reaches state-of-the-art performances, especially for inpainting tasks. However, the convergence of SNORE Prox, that can be seen as a stochastic proximal gradient descent, has not been analyzed so far. In this paper, we prove the convergence of SNORE Prox under non convex assumptions.

Paper number 78:
Title: In-context learning for medical image segmentation
Authors: Eichi Takaya, Shinnosuke Yamamoto
Abstract: Annotation of medical images, such as MRI and CT scans, is crucial for evaluating treatment efficacy and planning radiotherapy. However, the extensive workload of medical professionals limits their ability to annotate large image datasets, posing a bottleneck for AI applications in medical imaging. To address this, we propose In-context Cascade Segmentation (ICS), a novel method that minimizes annotation requirements while achieving high segmentation accuracy for sequential medical images. ICS builds on the UniverSeg framework, which performs few-shot segmentation using support images without additional training. By iteratively adding the inference results of each slice to the support set, ICS propagates information forward and backward through the sequence, ensuring inter-slice consistency. We evaluate the proposed method on the HVSMR dataset, which includes segmentation tasks for eight cardiac regions. Experimental results demonstrate that ICS significantly improves segmentation performance in complex anatomical regions, particularly in maintaining boundary consistency across slices, compared to baseline methods. The study also highlights the impact of the number and position of initial support slices on segmentation accuracy. ICS offers a promising solution for reducing annotation burdens while delivering robust segmentation results, paving the way for its broader adoption in clinical and research applications.

Paper number 79:
Title: Fundamental Techniques for Optimal Control of Reconfigurable Battery Systems: System Modeling and Feasible Search Space Construction
Authors: Changyou Geng, Dezhi Ren, Enkai Mao, Changfu Zou, Mario Vašak, Xinyi Zheng, Weiji Han
Abstract: Reconfigurable battery systems (RBSs) are emerging as a promising solution to improving fault tolerance, charge and thermal balance, energy delivery, etc. To optimize these performance metrics of RBSs, high-dimensional nonlinear integer programming problems need to be formulated and solved. To accomplish this, it is necessary to address several critical challenges stemming from nonlinear battery characteristics, discrete switch states, dynamic system configurations, as well as the curse of dimensionality inherent in large-scale RBSs. Thus, we propose a unified modeling framework to accommodate various possible configurations of an RBS and even to cover different RBS designs and their hybrid combinations, enabling the problem formulation for the RBS optimal control and facilitating the RBS topology this http URL, to solve the formulated RBS optimal control problems, the search space is narrowed to encompass only the feasible solutions, thereby ensuring safe battery connections while substantially curtailing search efforts. These proposed techniques, focusing on unifying the system modeling and narrowing the search space, lay a solid foundation for effectively formulating and efficiently solving RBS optimal control problems. The accuracy and effectiveness of the proposed techniques are demonstrated by both simulation and experimental tests.

Paper number 80:
Title: Rydberg Atomic Quantum Receivers for the Multi-User MIMO Uplink
Authors: Tierui Gong, Chau Yuen, Chong Meng Samson See, Mérouane Debbah, Lajos Hanzo
Abstract: Rydberg atomic quantum receivers exhibit great potential in assisting classical wireless communications due to their outstanding advantages in detecting radio frequency signals. To realize this potential, we integrate a Rydberg atomic quantum receiver into a classical multi-user multiple-input multiple-output (MIMO) scheme to form a multi-user Rydberg atomic quantum MIMO (RAQ-MIMO) system for the uplink. To study this system, we first construct an equivalent baseband signal model, which facilitates convenient system design, signal processing and optimizations. We then study the ergodic achievable rates under both the maximum ratio combining (MRC) and zero-forcing (ZF) schemes by deriving their tight lower bounds. We next compare the ergodic achievable rates of the RAQ-MIMO and the conventional massive MIMO schemes by offering a closed-form expression for the difference of their ergodic achievable rates, which allows us to directly compare the two systems. Our results show that RAQ-MIMO allows the average transmit power of users to be $> 25$ dBm lower than that of the conventional massive MIMO. Viewed from a different perspective, an extra $\sim 8.8$ bits/s/Hz/user rate becomes achievable by ZF RAQ-MIMO.

Paper number 81:
Title: ReMiDi: Reconstruction of Microstructure Using a Differentiable Diffusion MRI Simulator
Authors: Prathamesh Pradeep Khole, Zahra Kais Petiwala, Shri Prathaa Magesh, Ehsan Mirafzali, Utkarsh Gupta, Jing-Rebecca Li, Andrada Ianus, Razvan Marinescu
Abstract: We propose ReMiDi, a novel method for inferring neuronal microstructure as arbitrary 3D meshes using a differentiable diffusion Magnetic Resonance Imaging (dMRI) simulator. We first implemented in PyTorch a differentiable dMRI simulator that simulates the forward diffusion process using a finite-element method on an input 3D microstructure mesh. To achieve significantly faster simulations, we solve the differential equation semi-analytically using a matrix formalism approach. Given a reference dMRI signal $S_{ref}$, we use the differentiable simulator to iteratively update the input mesh such that it matches $S_{ref}$ using gradient-based learning. Since directly optimizing the 3D coordinates of the vertices is challenging, particularly due to ill-posedness of the inverse problem, we instead optimize a lower-dimensional latent space representation of the mesh. The mesh is first encoded into spectral coefficients, which are further encoded into a latent $\textbf{z}$ using an auto-encoder, and are then decoded back into the true mesh. We present an end-to-end differentiable pipeline that simulates signals that can be tuned to match a reference signal by iteratively updating the latent representation $\textbf{z}$. We demonstrate the ability to reconstruct microstructures of arbitrary shapes represented by finite-element meshes, with a focus on axonal geometries found in the brain white matter, including bending, fanning and beading fibers. Our source code is available online.

Paper number 82:
Title: Distributed Prescribed-Time Observer for Nonlinear Systems
Authors: Vincent de Heij, M. Umar B. Niazi, Karl H. Johansson, Saeed Ahmed
Abstract: This paper proposes a distributed prescribed-time observer for nonlinear systems representable in a block-triangular observable canonical form. Using a weighted average of neighbor estimates exchanged over a strongly connected digraph, each observer estimates the system state despite limited local sensor measurements. The proposed design guarantees that distributed state estimation errors converge to zero at a user-specified convergence time, irrespective of observers' initial conditions. To achieve this prescribed-time convergence, distributed observers implement time-varying local output injection gains that asymptotically approach infinity as the prescribed time is approached. The theoretical convergence is rigorously proven and validated through numerical simulations.

Paper number 83:
Title: Exploiting Non-uniform Quantization for Enhanced ILC in Wideband Digital Pre-distortion
Authors: Jinfei Wang, Yi Ma, Fei Tong, Ziming He
Abstract: In this paper, it is identified that lowering the reference level at the vector signal analyzer can significantly improve the performance of iterative learning control (ILC). We present a mathematical explanation for this phenomenon, where the signals experience logarithmic transform prior to analogue-to-digital conversion, resulting in non-uniform quantization. This process reduces the quantization noise of low-amplitude signals that constitute a substantial portion of orthogonal frequency division multiplexing (OFDM) signals, thereby improving ILC performance. Measurement results show that compared to setting the reference level to the peak amplitude, lowering the reference level achieves 3 dB improvement on error vector magnitude (EVM) and 15 dB improvement on normalized mean square error (NMSE) for 320 MHz WiFi OFDM signals.

Paper number 84:
Title: ResiComp: Loss-Resilient Image Compression via Dual-Functional Masked Visual Token Modeling
Authors: Sixian Wang, Jincheng Dai, Xiaoqi Qin, Ke Yang, Kai Niu, Ping Zhang
Abstract: Recent advancements in neural image codecs (NICs) are of significant compression performance, but limited attention has been paid to their error resilience. These resulting NICs tend to be sensitive to packet losses, which are prevalent in real-time communications. In this paper, we investigate how to elevate the resilience ability of NICs to combat packet losses. We propose ResiComp, a pioneering neural image compression framework with feature-domain packet loss concealment (PLC). Motivated by the inherent consistency between generation and compression, we advocate merging the tasks of entropy modeling and PLC into a unified framework focused on latent space context modeling. To this end, we take inspiration from the impressive generative capabilities of large language models (LLMs), particularly the recent advances of masked visual token modeling (MVTM). During training, we integrate MVTM to mirror the effects of packet loss, enabling a dual-functional Transformer to restore the masked latents by predicting their missing values and conditional probability mass functions. Our ResiComp jointly optimizes compression efficiency and loss resilience. Moreover, ResiComp provides flexible coding modes, allowing for explicitly adjusting the efficiency-resilience trade-off in response to varying Internet or wireless network conditions. Extensive experiments demonstrate that ResiComp can significantly enhance the NIC's resilience against packet losses, while exhibits a worthy trade-off between compression efficiency and packet loss resilience.

Paper number 85:
Title: Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures
Authors: Luis Lara, Lucia Eve Berger, Rajesh Raju
Abstract: The COVID-19 pandemic strained healthcare resources and prompted discussion about how machine learning can alleviate physician burdens and contribute to diagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but few studies predict the severity of a patient's condition from CXRs. In this study, we produce a large COVID severity dataset by merging three sources and investigate the efficacy of transfer learning using ImageNet- and CXR-pretrained models and vision transformers (ViTs) in both severity regression and classification tasks. A pretrained DenseNet161 model performed the best on the three class severity prediction problem, reaching 80% accuracy overall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases, respectively. The ViT had the best regression results, with a mean absolute error of 0.5676 compared to radiologist-predicted severity scores. The project's source code is publicly available.

Paper number 86:
Title: Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid Self-Supervised Learning Framework
Authors: Cheol-Hui Lee, Hakseung Kim, Byung C. Yoon, Dong-Joo Kim
Abstract: Sleep is essential for maintaining human health and quality of life. Analyzing physiological signals during sleep is critical in assessing sleep quality and diagnosing sleep disorders. However, manual diagnoses by clinicians are time-intensive and subjective. Despite advances in deep learning that have enhanced automation, these approaches remain heavily dependent on large-scale labeled datasets. This study introduces SynthSleepNet, a multimodal hybrid self-supervised learning framework designed for analyzing polysomnography (PSG) data. SynthSleepNet effectively integrates masked prediction and contrastive learning to leverage complementary features across multiple modalities, including electroencephalogram (EEG), electrooculography (EOG), electromyography (EMG), and electrocardiogram (ECG). This approach enables the model to learn highly expressive representations of PSG data. Furthermore, a temporal context module based on Mamba was developed to efficiently capture contextual information across signals. SynthSleepNet achieved superior performance compared to state-of-the-art methods across three downstream tasks: sleep-stage classification, apnea detection, and hypopnea detection, with accuracies of 89.89%, 99.75%, and 89.60%, respectively. The model demonstrated robust performance in a semi-supervised learning environment with limited labels, achieving accuracies of 87.98%, 99.37%, and 77.52% in the same tasks. These results underscore the potential of the model as a foundational tool for the comprehensive analysis of PSG data. SynthSleepNet demonstrates comprehensively superior performance across multiple downstream tasks compared to other methodologies, making it expected to set a new standard for sleep disorder monitoring and diagnostic systems.

Paper number 87:
Title: Non-Parametric Learning of Stochastic Differential Equations with Non-asymptotic Fast Rates of Convergence
Authors: Riccardo Bonalli, Alessandro Rudi
Abstract: We propose a novel non-parametric learning paradigm for the identification of drift and diffusion coefficients of multi-dimensional non-linear stochastic differential equations, which relies upon discrete-time observations of the state. The key idea essentially consists of fitting a RKHS-based approximation of the corresponding Fokker-Planck equation to such observations, yielding theoretical estimates of non-asymptotic learning rates which, unlike previous works, become increasingly tighter when the regularity of the unknown drift and diffusion coefficients becomes higher. Our method being kernel-based, offline pre-processing may be profitably leveraged to enable efficient numerical implementation, offering excellent balance between precision and computational complexity.

Paper number 88:
Title: KEEC: Koopman Embedded Equivariant Control
Authors: Xiaoyuan Cheng, Yiming Yang, Xiaohang Tang, Wei Jiang, Yukun Hu
Abstract: An efficient way to control systems with unknown nonlinear dynamics is to find an appropriate embedding or representation for simplified approximation (e.g. linearization), which facilitates system identification and control synthesis. Nevertheless, there has been a lack of embedding methods that can guarantee (i) embedding the dynamical system comprehensively, including the vector fields (ODE form) of the dynamics, and (ii) preserving the consistency of control effect between the original and latent space. To address these challenges, we propose Koopman Embedded Equivariant Control (KEEC) to learn an embedding of the states and vector fields such that a Koopman operator is approximated as the latent dynamics. Due to the Koopman operator's linearity, learning the latent vector fields of the dynamics becomes simply solving linear equations. Thus in KEEC, the analytical form of the greedy control policy, which is dependent on the learned differential information of the dynamics and value function, is also simplified. Meanwhile, KEEC preserves the effectiveness of the control policy in the latent space by preserving the metric in two spaces. Our algorithm achieves superior performances in the experiments conducted on various control domains, including the image-based Pendulum, Lorenz-63 and the wave equation. The code is available at this https URL.

Paper number 89:
Title: Timely Status Updates in Slotted ALOHA Networks With Energy Harvesting
Authors: Khac-Hoang Ngo, Giuseppe Durisi, Andrea Munari, Francisco Lázaro, Alexandre Graell i Amat
Abstract: We investigate the age of information (AoI) in a scenario where energy-harvesting devices send status updates to a gateway following the slotted ALOHA protocol and receive no feedback. We let the devices adjust the transmission probabilities based on their current battery level. Using a Markovian analysis, we derive analytically the average AoI. We further provide an approximate analysis for accurate and easy-to-compute approximations of both the average AoI and the age-violation probability (AVP), i.e., the probability that the AoI exceeds a given threshold. We also analyze the average throughput. Via numerical results, we investigate two baseline strategies: transmit a new update whenever possible to exploit every opportunity to reduce the AoI, and transmit only when sufficient energy is available to increase the chance of successful decoding. The two strategies are beneficial for low and high update-generation rates, respectively. We show that an optimized policy that balances the two strategies outperforms them significantly in terms of both AoI metrics and throughput. Finally, we show the benefit of decoding multiple packets in a slot using successive interference cancellation and adapting the transmission probability based on both the current battery level and the time elapsed since the last transmission.

Paper number 90:
Title: WHALE-FL: Wireless and Heterogeneity Aware Latency Efficient Federated Learning over Mobile Devices via Adaptive Subnetwork Scheduling
Authors: Huai-an Su, Jiaxiang Geng, Liang Li, Xiaoqi Qin, Yanzhao Hou, Hao Wang, Xin Fu, Miao Pan
Abstract: As a popular distributed learning paradigm, federated learning (FL) over mobile devices fosters numerous applications, while their practical deployment is hindered by participating devices' computing and communication heterogeneity. Some pioneering research efforts proposed to extract subnetworks from the global model, and assign as large a subnetwork as possible to the device for local training based on its full computing and communications capacity. Although such fixed size subnetwork assignment enables FL training over heterogeneous mobile devices, it is unaware of (i) the dynamic changes of devices' communication and computing conditions and (ii) FL training progress and its dynamic requirements of local training contributions, both of which may cause very long FL training delay. Motivated by those dynamics, in this paper, we develop a wireless and heterogeneity aware latency efficient FL (WHALE-FL) approach to accelerate FL training through adaptive subnetwork scheduling. Instead of sticking to the fixed size subnetwork, WHALE-FL introduces a novel subnetwork selection utility function to capture device and FL training dynamics, and guides the mobile device to adaptively select the subnetwork size for local training based on (a) its computing and communication capacity, (b) its dynamic computing and/or communication conditions, and (c) FL training status and its corresponding requirements for local training contributions. Our evaluation shows that, compared with peer designs, WHALE-FL effectively accelerates FL training without sacrificing learning accuracy.

Paper number 91:
Title: Immunocto: a massive immune cell database auto-generated for histopathology
Authors: Mikaël Simard, Zhuoyan Shen, Konstantin Bräutigam, Rasha Abu-Eid, Maria A. Hawkins, Charles-Antoine Collins-Fekete
Abstract: With the advent of novel cancer treatment options such as immunotherapy, studying the tumour immune micro-environment (TIME) is crucial to inform on prognosis and understand potential response to therapeutic agents. A key approach to characterising the TIME may be through combining (1) digitised microscopic high-resolution optical images of hematoxylin and eosin (H&E) stained tissue sections obtained in routine histopathology examinations with (2) automated immune cell detection and classification methods. In this work, we introduce a workflow to automatically generate robust single cell contours and labels from dually stained tissue sections with H&E and multiplexed immunofluorescence (IF) markers. The approach harnesses the Segment Anything Model and requires minimal human intervention compared to existing single cell databases. With this methodology, we create Immunocto, a massive, multi-million automatically generated database of 6,848,454 human cells and objects, including 2,282,818 immune cells distributed across 4 subtypes: CD4$^+$ T cell lymphocytes, CD8$^+$ T cell lymphocytes, CD20$^+$ B cell lymphocytes, and CD68$^+$/CD163$^+$ macrophages. For each cell, we provide a 64$\times$64 pixels$^2$ H&E image at $\mathbf{40}\times$ magnification, along with a binary mask of the nucleus and a label. The database, which is made publicly available, can be used to train models to study the TIME on routine H&E slides. We show that deep learning models trained on Immunocto result in state-of-the-art performance for lymphocyte detection. The approach demonstrates the benefits of using matched H&E and IF data to generate robust databases for computational pathology applications.

Paper number 92:
Title: Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?
Authors: Kailas Dayanandan, Nikhil Kumar, Anand Sinha, Brejesh Lall
Abstract: The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments.

Paper number 93:
Title: Discrete Shortest Paths in Optimal Power Flow Feasible Regions
Authors: Daniel Turizo, Diego Cifuentes, Anton Leykin, Daniel K. Molzahn
Abstract: Optimal power flow (OPF) is a critical optimization problem for power systems to operate at points where cost or other operational objectives are optimized. Due to the non-convexity of the set of feasible OPF operating points, it is non-trivial to transition the power system from its current operating point to the optimal one without violating constraints. On top of that, practical considerations dictate that the transition should be achieved using a small number of small-magnitude control actions. To solve this problem, this paper proposes an algorithm for computing a transition path by framing it as a shortest path problem. This problem is formulated in terms of a discretized piece-wise linear path, where the number of pieces is fixed a priori in order to limit the number of control actions. This formulation yields a nonlinear optimization problem (NLP) with a sparse block tridiagonal structure, which we leverage by utilizing a specialized interior point method. An initial feasible path for our method is generated by solving a sequence of relaxations which are then tightened in a homotopy-like procedure. Numerical experiments illustrate the effectiveness of the algorithm.

Paper number 94:
Title: Disentangling Uncertainty for Safe Social Navigation using Deep Reinforcement Learning
Authors: Daniel Flögel, Marcos Gómez Villafañe, Joshua Ransiek, Sören Hohmann
Abstract: Autonomous mobile robots are increasingly used in pedestrian-rich environments where safe navigation and appropriate human interaction are crucial. While Deep Reinforcement Learning (DRL) enables socially integrated robot behavior, challenges persist in novel or perturbed scenarios to indicate when and why the policy is uncertain. Unknown uncertainty in decision-making can lead to collisions or human discomfort and is one reason why safe and risk-aware navigation is still an open problem. This work introduces a novel approach that integrates aleatoric, epistemic, and predictive uncertainty estimation into a DRL navigation framework for policy distribution uncertainty estimates. We, therefore, incorporate Observation-Dependent Variance (ODV) and dropout into the Proximal Policy Optimization (PPO) algorithm. For different types of perturbations, we compare the ability of deep ensembles and Monte-Carlo dropout (MC-dropout) to estimate the uncertainties of the policy. In uncertain decision-making situations, we propose to change the robot's social behavior to conservative collision avoidance. The results show improved training performance with ODV and dropout in PPO and reveal that the training scenario has an impact on the generalization. In addition, MC-dropout is more sensitive to perturbations and correlates the uncertainty type to the perturbation better. With the safe action selection, the robot can navigate in perturbed environments with fewer collisions.

Paper number 95:
Title: ReMatching Dynamic Reconstruction Flow
Authors: Sara Oblak, Despoina Paschalidou, Sanja Fidler, Matan Atzmon
Abstract: Reconstructing a dynamic scene from image inputs is a fundamental computer vision task with many downstream applications. Despite recent advancements, existing approaches still struggle to achieve high-quality reconstructions from unseen viewpoints and timestamps. This work introduces the ReMatching framework, designed to improve reconstruction quality by incorporating deformation priors into dynamic reconstruction models. Our approach advocates for velocity-field based priors, for which we suggest a matching procedure that can seamlessly supplement existing dynamic reconstruction pipelines. The framework is highly adaptable and can be applied to various dynamic representations. Moreover, it supports integrating multiple types of model priors and enables combining simpler ones to create more complex classes. Our evaluations on popular benchmarks involving both synthetic and real-world dynamic scenes demonstrate that augmenting current state-of-the-art methods with our approach leads to a clear improvement in reconstruction accuracy.

Paper number 96:
Title: CAT-ORA: Collision-Aware Time-Optimal Formation Reshaping for Efficient Robot Coordination in 3D Environments
Authors: Vit Kratky, Robert Penicka, Jiri Horyna, Petr Stibinger, Tomas Baca, Matej Petrlik, Petr Stepan, Martin Saska
Abstract: In this paper, we introduce an algorithm designed to address the problem of time-optimal formation reshaping in three-dimensional environments while preventing collisions between agents. The utility of the proposed approach is particularly evident in mobile robotics, where agents benefit from being organized and navigated in formation for a variety of real-world applications requiring frequent alterations in formation shape for efficient navigation or task completion. Given the constrained operational time inherent to battery-powered mobile robots, the time needed to complete the formation reshaping process is crucial for their efficient operation, especially in case of multi-rotor Unmanned Aerial Vehicles (UAVs). The proposed Collision-Aware Time-Optimal formation Reshaping Algorithm (CAT-ORA) builds upon the Hungarian algorithm for the solution of the robot-to-goal assignment implementing the inter-agent collision avoidance through direct constraints on mutually exclusive robot-goal pairs combined with a trajectory generation approach minimizing the duration of the reshaping process. Theoretical validations confirm the optimality of CAT-ORA, with its efficacy further showcased through simulations, and a real-world outdoor experiment involving 19 UAVs. Thorough numerical analysis shows the potential of CAT-ORA to decrease the time required to perform complex formation reshaping tasks by up to 49%, and 12% on average compared to commonly used methods in randomly generated scenarios.

Paper number 97:
Title: AI-driven Inverse Design of Band-Tunable Mechanical Metastructures for Tailored Vibration Mitigation
Authors: Tanuj Gupta, Arun Kumar Sharma, Ankur Dwivedi, Vivek Gupta, Subhadeep Sahana, Suryansh Pathak, Ashish Awasthi, Bishakh Bhattacharya
Abstract: On-demand vibration mitigation in a mechanical system needs the suitable design of multiscale metastructures, involving complex unit cells. In this study, immersing in the world of patterns and examining the structural details of some interesting motifs are extracted from the mechanical metastructure perspective. Nine interlaced metastructures are fabricated using additive manufacturing, and corresponding vibration characteristics are studied experimentally and numerically. Further, the band-gap modulation with metallic inserts in the honeycomb interlaced metastructures is also studied. AI-driven inverse design of such complex metastructures with a desired vibration mitigation profile can pave the way for addressing engineering challenges in high-precision manufacturing. The current inverse design methodologies are limited to designing simple periodic structures based on limited variants of unit cells. Therefore, a novel forward analysis model with multi-head FEM-inspired spatial attention (FSA) is proposed to learn the complex geometry of the metastructures and predict corresponding transmissibility. Subsequently, a multiscale Gaussian self-attention (MGSA) based inverse design model with Gaussian function for 1D spectrum position encoding is developed to produce a suitable metastructure for the desired vibration transmittance. The proposed AI framework demonstrated outstanding performance corresponding to the expected locally resonant bandgaps in a targeted frequency range.

Paper number 98:
Title: Open-Source Manually Annotated Vocal Tract Database for Automatic Segmentation from 3D MRI Using Deep Learning: Benchmarking 2D and 3D Convolutional and Transformer Networks
Authors: Subin Erattakulangara, Karthika Kelat, Katie Burnham, Rachel Balbi, Sarah E. Gerard, David Meyer, Sajan Goud Lingala
Abstract: Accurate segmentation of the vocal tract from magnetic resonance imaging (MRI) data is essential for various voice and speech applications. Manual segmentation is time intensive and susceptible to errors. This study aimed to evaluate the efficacy of deep learning algorithms for automatic vocal tract segmentation from 3D MRI.

Paper number 99:
Title: Sample Motion for Structured Illumination Fluorescence Microscopy
Authors: Ruiming Cao, Guanghan Meng, Laura Waller
Abstract: Structured illumination microscopy (SIM) uses a set of images captured with different illumination patterns to computationally reconstruct resolution beyond the diffraction limit. Here, we propose an alternative approach using a single speckle illumination pattern and relying on inherent sample motion to encode the super-resolved information in multiple raw images. From a set of raw fluorescence images captured as the sample moves, we jointly estimate both the sample motion and the super-resolved image. We demonstrate the feasibility of the proposed method both in simulation and in experiment.

Paper number 100:
Title: Time series forecasting based on optimized LLM for fault prediction in distribution power grid insulators
Authors: João Pedro Matos-Carvalho, Stefano Frizzo Stefenon, Valderi Reis Quietinho Leithardt, Kin-Choong Yow
Abstract: Surface contamination on electrical grid insulators leads to an increase in leakage current until an electrical discharge occurs, which can result in a power system shutdown. To mitigate the possibility of disruptive faults resulting in a power outage, monitoring contamination and leakage current can help predict the progression of faults. Given this need, this paper proposes a hybrid deep learning (DL) model for predicting the increase in leakage current in high-voltage insulators. The hybrid structure considers a multi-criteria optimization using tree-structured Parzen estimation, an input stage filter for signal noise attenuation combined with a large language model (LLM) applied for time series forecasting. The proposed optimized LLM outperforms state-of-the-art DL models with a root-mean-square error equal to 2.24$\times10^{-4}$ for a short-term horizon and 1.21$\times10^{-3}$ for a medium-term horizon.
    