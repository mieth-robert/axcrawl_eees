
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: From Failure Modes to Reliability Awareness in Generative and Agentic AI System
Authors: Janet (Jing)Lin, Liangwei Zhang
Abstract: This chapter bridges technical analysis and organizational preparedness by tracing the path from layered failure modes to reliability awareness in generative and agentic AI systems. We first introduce an 11-layer failure stack, a structured framework for identifying vulnerabilities ranging from hardware and power foundations to adaptive learning and agentic reasoning. Building on this, the chapter demonstrates how failures rarely occur in isolation but propagate across layers, creating cascading effects with systemic consequences. To complement this diagnostic lens, we develop the concept of awareness mapping: a maturity-oriented framework that quantifies how well individuals and organizations recognize reliability risks across the AI stack. Awareness is treated not only as a diagnostic score but also as a strategic input for AI governance, guiding improvement and resilience planning. By linking layered failures to awareness levels and further integrating this into Dependability-Centred Asset Management (DCAM), the chapter positions awareness mapping as both a measurement tool and a roadmap for trustworthy and sustainable AI deployment across mission-critical domains.

Paper number 2:
Title: AIRMap - AI-Generated Radio Maps for Wireless Digital Twins
Authors: Ali Saeizadeh, Miead Tehrani-Moayyed, Davide Villa, J. Gordon Beattie Jr., Pedram Johari, Stefano Basagni, Tommaso Melodia
Abstract: Accurate, low-latency channel modeling is essential for real-time wireless network simulation and digital-twin applications. Traditional modeling methods like ray tracing are however computationally demanding and unsuited to model dynamic conditions. In this paper, we propose AIRMap, a deep-learning framework for ultra-fast radio-map estimation, along with an automated pipeline for creating the largest radio-map dataset to date. AIRMap uses a single-input U-Net autoencoder that processes only a 2D elevation map of terrain and building heights. Trained and evaluated on 60,000 Boston-area samples, spanning coverage areas from 500 m to 3 km per side, AIRMap predicts path gain with under 5 dB RMSE in 4 ms per inference on an NVIDIA L40S -over 7000x faster than GPU-accelerated ray tracing based radio maps. A lightweight transfer learning calibration using just 20% of field measurements reduces the median error to approximately 10%, significantly outperforming traditional simulators, which exceed 50% error. Integration into the Colosseum emulator and the Sionna SYS platform demonstrate near-zero error in spectral efficiency and block-error rate compared to measurement-based channels. These findings validate AIRMap's potential for scalable, accurate, and real-time radio map estimation in wireless digital twins.

Paper number 3:
Title: Bridging Accuracy and Explainability in EEG-based Graph Attention Network for Depression Detection
Authors: Soujanya Hazra, Sanjay Ghosh
Abstract: Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results.

Paper number 4:
Title: Well-Designed k-Space Coverage is Important for Good MRI Denoising
Authors: Jiayang Wang, Justin P. Haldar
Abstract: Object: Modern computational MRI denoising approaches are often designed assuming fixed k-space coverage. This contrasts with earlier acquisition-design literature that leveraged k-space coverage modifications (e.g., reducing spatial resolution) to improve SNR. This work investigates whether the performance of modern computational denoising methods can be further enhanced by k-space coverage modifications. Materials and Methods: Using realistic simulations of noisy data, k-space coverage and averaging patterns were optimized for two advanced image denoising/reconstruction approaches: parallel imaging with total variation regularization and a U-Net neural network. For reference, comparisons against classical linear filtering/apodization methods were also performed. Performance was quantified using normalized root-mean-squared error (NRMSE) and structural similarity (SSIM) metrics. Results: Advanced computational denoising methods can be substantially enhanced, both quantitatively and qualitatively, by reducing the spatial resolution of the acquisition to improve SNR. Indeed, even simple linear filtering/apodization with optimized k-space coverage can rival advanced methods using naive higher-resolution coverage. Discussion: Classical acquisition design principles that allow spatial resolution to be traded for SNR enhancement are still very relevant for modern computational denoising techniques. However, the optimization of k-space coverage and denoising/reconstruction methods can also be somewhat confounded because the NRMSE and SSIM metrics have low sensitivity to spatial resolution.

Paper number 5:
Title: Zero-Shot Function Encoder-Based Differentiable Predictive Control
Authors: Hassan Iqbal, Xingjian Li, Tyler Ingebrand, Adam Thorpe, Krishna Kumar, Ufuk Topcu, Ján Drgoňa
Abstract: We introduce a differentiable framework for zero-shot adaptive control over parametric families of nonlinear dynamical systems. Our approach integrates a function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a differentiable predictive control (DPC) for offline self-supervised learning of explicit control policies. The FE-NODE captures nonlinear behaviors in state transitions and enables zero-shot adaptation to new systems without retraining, while the DPC efficiently learns control policies across system parameterizations, thus eliminating costly online optimization common in classical model predictive control. We demonstrate the efficiency, accuracy, and online adaptability of the proposed method across a range of nonlinear systems with varying parametric scenarios, highlighting its potential as a general-purpose tool for fast zero-shot adaptive control.

Paper number 6:
Title: Environment-Aware MIMO Channel Estimation in Pilot-Constrained Upper Mid-Band Systems
Authors: Seyed Alireza Javid, Nuria González-Prelcic
Abstract: Accurate multiple-input multiple-output (MIMO) channel estimation is critical for next-generation wireless systems, enabling enhanced communication and sensing performance. Traditional model-based channel estimation methods suffer, however, from performance degradation in complex environments with a limited number of pilots, while purely data-driven approaches lack physical interpretability, require extensive data collection, and are usually site-specific. This paper presents a novel physics-informed neural network (PINN) framework that combines model-based channel estimation with a deep network to exploit prior information about the propagation environment and achieve superior performance under pilot-constrained scenarios. The proposed approach employs an enhanced U-Net architecture with cross-attention mechanisms to fuse initial channel estimates with received signal strength (RSS) maps to provide refined channel estimates. Comprehensive evaluation using realistic ray-tracing data from urban environments demonstrates significant performance improvements, achieving over 5 dB gain in normalized mean squared error (NMSE) compared to state-of-the-art methods, with particularly strong performance in pilot-limited scenarios and robustness across different frequencies and environments with only minimal fine-tuning. The proposed framework maintains practical computational complexity, making it viable for massive MIMO systems in upper mid-band frequencies.

Paper number 7:
Title: Log-linear Backstepping control on $SE_2(3)$
Authors: Li-Yu Lin, Benjamin Perseghetti, James Goppert
Abstract: Most of the rigid-body systems which evolve on nonlinear Lie groups where Euclidean control designs lose geometric meaning. In this paper, we introduce a log-linear backstepping control law on SE2(3) that preserves full rotational-translational coupling. Leveraging a class of mixed-invariant system, which is a group-affine dynamic model, we derive exact logarithmic error dynamics that are linear in the Lie algebra. The closed-form expressions for the left- and right-Jacobian inverses of SE2(3) are expressed in the paper, which provides us the exact error dynamics without local approximations. A log-linear backstepping control design ensures exponential stability for our error dynamics; since our error dynamics is a block-triangular structure, this allows us to use Linear Matrix Inequality (LMI) formulation or $H_\infty$ gain performance design. This work establishes the exact backstepping framework for a class of mixed-invariant system, providing a geometrically consistent foundation for future Unmanned Aerial Vehicle (UAV) and spacecraft control design.

Paper number 8:
Title: Autonomous and Distributed Synchronization and Restoration of an Islanded Network of Microgrids
Authors: Ahmed Saad Al-Karsani, Maryam Khanbaghi
Abstract: The transition towards clean energy and the introduction of Inverter-Based Resources (IBRs) are leading to the formation of Microgrids (MGs) and Network of MGs (NMGs). MGs and NMGs can operate autonomously in islanded mode, which requires Grid-Forming (GFM) IBRs that can perform black start, synchronization, restoration and regulation. However, such IBRs face synchronization instability issues, which might be worsened by inadequate secondary level frequency and voltage regulation. Accordingly, we propose an autonomous and distributed synchronization and restoration scheme using Distributed-Averaging Proportional-Integral (DAPI) control. To validate the proposed method, we model and simulate a high-fidelity islanded and modified IEEE 123 bus system, modeled as an NMG consisting of 7 MGs. The simulation results demonstrate an effective autonomous soft-start, synchronization, connection and regulation procedure using DAPI control and distributed breaker operation logic.

Paper number 9:
Title: Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions
Authors: Sayak Mukherjee, Ramij R. Hossain, Kaustav Chatterjee, Sameer Nekkalapu, Marcelo Elizondo
Abstract: This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations.

Paper number 10:
Title: Learning-Based Multi-Stage Strategy for a Fixed-Wing Aircraft to Evade a Missile Detected at a Short Distance
Authors: Zhiguan Niu, Xiaochao Zhou, Hao Xiong
Abstract: Missiles pose a major threat to aircraft in modern air combat. Advances in technology make them increasingly difficult to detect until they are close to the target and highly resistant to jamming. The evasion maneuver is the last line of defense for an aircraft. However, conventional rule-based evasion strategies are limited by computational demands and aerodynamic constraints, and existing learning-based approaches remain unconvincing for manned aircraft against modern missiles. To enhance aircraft survivability, this study investigates missile evasion inspired by the pursuit-evasion game between a gazelle and a cheetah and proposes a multi-stage reinforcement learning-based evasion strategy. The strategy learns a large azimuth policy to turn to evade, a small azimuth policy to keep moving away, and a short distance policy to perform agile aggressive maneuvers to avoid. One of the three policies is activated at each stage based on distance and azimuth. To evaluate performance, a high-fidelity simulation environment modeling an F-16 aircraft and missile under various conditions is used to compare the proposed approach with baseline strategies. Experimental results show that the proposed method achieves superior performance, enabling the F-16 aircraft to successfully avoid missiles with a probability of 80.89 percent for velocities ranging from 800 m/s to 1400 m/s, maximum overloads from 40 g to 50 g, detection distances from 5000 m to 15000 m, and random azimuths. When the missile is detected beyond 8000 m, the success ratio increases to 85.06 percent.

Paper number 11:
Title: Training-Free Adaptive Quantization for Variable Rate Image Coding for Machines
Authors: Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe
Abstract: Image Coding for Machines (ICM) has become increasingly important with the rapid integration of computer vision into real-world applications. However, most ICM frameworks utilize learned image compression (LIC) models that operate at a fixed rate and require separate training for each target bitrate, which may limit their practical applications. Existing variable rate LIC approaches mitigate this limitation but typically depend on training, increasing computational cost and deployment complexity. Moreover, variable rate control has not been thoroughly explored for ICM. To address these challenges, we propose a training-free, adaptive quantization step size control scheme that enables flexible bitrate adjustment. By leveraging both channel-wise entropy dependencies and spatial scale parameters predicted by the hyperprior network, the proposed method preserves semantically important regions while coarsely quantizing less critical areas. The bitrate can be continuously controlled through a single parameter. Experimental results demonstrate the effectiveness of our proposed method, achieving up to 11.07% BD-rate savings over the non-adaptive variable rate method.

Paper number 12:
Title: HarmoQ: Harmonized Post-Training Quantization for High-Fidelity Image
Authors: Hongjun Wang, Jiyuan Chen, Xuan Song, Yinqiang Zheng
Abstract: Post-training quantization offers an efficient pathway to deploy super-resolution models, yet existing methods treat weight and activation quantization independently, missing their critical interplay. Through controlled experiments on SwinIR, we uncover a striking asymmetry: weight quantization primarily degrades structural similarity, while activation quantization disproportionately affects pixel-level accuracy. This stems from their distinct roles--weights encode learned restoration priors for textures and edges, whereas activations carry input-specific intensity information. Building on this insight, we propose HarmoQ, a unified framework that harmonizes quantization across components through three synergistic steps: structural residual calibration proactively adjusts weights to compensate for activation-induced detail loss, harmonized scale optimization analytically balances quantization difficulty via closed-form solutions, and adaptive boundary refinement iteratively maintains this balance during optimization. Experiments show HarmoQ achieves substantial gains under aggressive compression, outperforming prior art by 0.46 dB on Set5 at 2-bit while delivering 3.2x speedup and 4x memory reduction on A100 GPUs. This work provides the first systematic analysis of weight-activation coupling in super-resolution quantization and establishes a principled solution for efficient high-quality image restoration.

Paper number 13:
Title: EndoIR: Degradation-Agnostic All-in-One Endoscopic Image Restoration via Noise-Aware Routing Diffusion
Authors: Tong Chen, Xinyu Ma, Long Bai, Wenyang Wang, Sun Yue, Luping Zhou
Abstract: Endoscopic images often suffer from diverse and co-occurring degradations such as low lighting, smoke, and bleeding, which obscure critical clinical details. Existing restoration methods are typically task-specific and often require prior knowledge of the degradation type, limiting their robustness in real-world clinical use. We propose EndoIR, an all-in-one, degradation-agnostic diffusion-based framework that restores multiple degradation types using a single model. EndoIR introduces a Dual-Domain Prompter that extracts joint spatial-frequency features, coupled with an adaptive embedding that encodes both shared and task-specific cues as conditioning for denoising. To mitigate feature confusion in conventional concatenation-based conditioning, we design a Dual-Stream Diffusion architecture that processes clean and degraded inputs separately, with a Rectified Fusion Block integrating them in a structured, degradation-aware manner. Furthermore, Noise-Aware Routing Block improves efficiency by dynamically selecting only noise-relevant features during denoising. Experiments on SegSTRONG-C and CEC datasets demonstrate that EndoIR achieves state-of-the-art performance across multiple degradation scenarios while using fewer parameters than strong baselines, and downstream segmentation experiments confirm its clinical utility.

Paper number 14:
Title: Disentangled Control of Multi-Agent Systems
Authors: Ruoyu Lin, Gennaro Notomista, Magnus Egerstedt
Abstract: This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments.

Paper number 15:
Title: Fast Time-Varying mmWave MIMO Channel Estimation and Reconstruction: An Efficient Rank-Aware Matrix Completion Method
Authors: Tianyu Jiang, Yan Yang, Hongjin Liu, Runyu Han, Bo Ai, Mohsen Guizani
Abstract: We address the problem of fast time-varying channel estimation in millimeter-wave (mmWave) MIMO systems with imperfect channel state information (CSI) and facilitate efficient channel reconstruction. Specifically, leveraging the low-rank and sparse characteristics of the mmWave channel matrix, a two-phase rank-aware compressed sensing framework is proposed for efficient channel estimation and reconstruction. In the first phase, a robust rank-one matrix completion (R1MC) algorithm is used to reconstruct part of the observed channel matrix through low-rank matrix completion (LRMC). To address abrupt rank changes caused by user mobility, a discrete-time autoregressive (AR) model is established that leverages temporal rank correlations across consecutive time instances to enable adaptive observation matrix completion, thereby improving estimation accuracy under dynamic conditions. In the second phase, a rank-aware block orthogonal matching pursuit (RA-BOMP) algorithm is developed for sparse channel recovery with low computational complexity. Furthermore, a rank-aware measurement matrix design is introduced to improve angle estimation accuracy. Simulation results demonstrate that, compared with existing benchmark algorithms, the proposed approach achieves superior channel estimation performance while significantly reducing computational complexity and training overhead.

Paper number 16:
Title: RadioSim Agent: Combining Large Language Models and Deterministic EM Simulators for Interactive Radio Map Analysis
Authors: Sajjad Hussain, Conor Brennan
Abstract: Deterministic electromagnetic (EM) simulators provide accurate radio propagation modeling but often require expert configuration and lack interactive flexibility. We present RadioSim Agent, an agentic framework that integrates large language models (LLMs) with physics-based EM solvers and vision-enabled reasoning to enable interactive and explainable radio map generation. The framework encapsulates ray-tracing models as callable simulation tools, orchestrated by an LLM capable of interpreting natural language objectives, managing simulation workflows, and visually analyzing resulting radio maps. Demonstrations in urban UAV communication scenarios show that the agent autonomously selects appropriate propagation mechanisms, executes deterministic simulations, and provides semantic and visual summaries of pathloss behavior. The results indicate that RadioSim Agent provides multimodal interpretability and intuitive user interaction, paving the way for intelligent EM simulation assistants in next-generation wireless system design.

Paper number 17:
Title: Near-field Anchor-free Localization using Reconfigurable Intelligent Surfaces
Authors: Srikar Sharma Sadhu, Praful D. Mankar, Santosh Nannuru
Abstract: Near-field localization is expected to play a crucial role in enabling a plethora of applications under the paradigm of 6G networks. The conventional localization methods rely on complex infrastructure for providing cooperative anchor nodes that often contribute to higher network overload and energy consumption. To address this, the passive reconfigurable intelligent surfaces (RISs) can be leveraged as perfectly synced reference nodes for developing anchor-free localization. This work proposes a two-stage framework for localizing user equipment (UE) equipped with multiple antennas. At first, we show that the optimal RIS phase shift matrix maximizing the received signal-to-noise ratio (SNR) for RIS-assisted anchor-free localization is independent of UE location, making the proposed framework scalable without increasing the overhead to control RIS. The proposed two-stage framework first obtains a coarse estimate of UE's location by correlating the received RIS-reflected signal with a dictionary constructed using line-of-sight (LoS) components at a few reference positions. Next, the coarse estimate is refined using Newton's refinement. The numerical results show that the small-sized dictionary, constructed using fewer reference positions, can be employed for accurate localization with a slight increase in the required number of refinement iterations.

Paper number 18:
Title: Parameter Recovery from Tangential Interpolations for Systems with an LFT Structure
Authors: Tong Zhou, Yubing Li
Abstract: This paper investigates how to recover parameters of a linear time invariant system from values and derivatives of its transfer function matrix, along several particular directions at a prescribed set of points in the complex plane, in which system matrices depend on these parameters through a linear fractional transformation. A necessary and sufficient condition is derived for a unique determination of these system parameters, which is expressed by a vector inequality. Under some particular situations, this condition reduces to a full column rank requirement on a constant matrix. Moreover, a method is given to recover system parameters from these values and derivatives, which is expressed by a vector linear equation with some rank constraints, for which various methods exist for finding its solutions. Robustness of the suggested recovery method is also clarified. A numerical example is given to illustrate characteristics of the suggested method, as well as effectiveness of derivative information introduction in parameter recovery, in which natural frequency and damping ratio are to be recovered for a transfer function.

Paper number 19:
Title: Probe-and-Release Coordination of Platoons at Highway Bottlenecks with Unknown Parameters
Authors: Yi Gao, Xi Xiong, Karl H. Johansson, Li Jin
Abstract: This paper considers coordination of platoons of connected and autonomous vehicles (CAVs) at mixed-autonomy bottlenecks in the face of three practically important factors, viz. time-varying traffic demand, random CAV platoon sizes, and capacity breakdowns. Platoon coordination is essential to smoothen the interaction between CAV platoons and non-CAV traffic. Based on a fluid queuing model, we develop a "probe-and-release" algorithm that simultaneously estimates environmental parameters and coordinates CAV platoons for traffic stabilization. We show that this algorithm ensures bounded estimation errors and bounded traffic queues. The proof builds on a Lyapunov function that jointly penalizes estimation errors and traffic queues and a drift argument for an embedded Markov process. We validate the proposed algorithm in a standard micro-simulation environment and compare against a representative deep reinforcement learning method in terms of control performance and computational efficiency.

Paper number 20:
Title: Invariants in Eddy Current Testing via Dimensional Analysis
Authors: Vincenzo Mottola, Alessandro Sardellitti, Filippo Milano, Luigi Ferrigno, Marco Laracca, Antonello Tamburrino
Abstract: The Buckingham's $\pi$, theorem has been recently introduced in the context of Non destructive Testing \& Evaluation (NdT\&E) , giving a theoretical basis for developing simple but effective methods for multi-parameter estimation via dimensional analysis. Dimensional groups, or $\pi-$groups, allow for the reduction of the number of parameters affecting the dimensionless measured quantities. In many real-world applications, the main interest is in estimating only a subset of the variables affecting the measurements. An example is estimating the thickness and electrical conductivity of a plate from Eddy Current Testing data, regardless of the lift-off of the probe, which may be either uncertain and/or variable. Alternatively, one may seek to estimate thickness and lift-off while neglecting the influence of the electrical conductivity, or to estimate the electrical conductivity and the lift-off, neglecting the thickness. This is where the concept of invariants becomes crucial. An invariant transformation is a mathematical mapping that makes the measured signal independent of one or more of these uncertain parameters. Invariant transformations provide a way to isolate useful signals from uncertain ones, improving the accuracy and reliability of the NdT results. The main contribution of this paper is a systematic method to derive \emph{invariant} transformations for frequency domain Eddy Current Testing data, via dimensional analysis. The proposed method is compatible with real-time and in-line operations. After its theoretical foundation is introduced, the method is validated by means of experimental data, with reference to configurations consisting of plates with different thicknesses, electrical conductivity, and lift-off. The experimental validation proves the effectiveness of the method in achieving excellent accuracy on a wide range of parameters of interest.

Paper number 21:
Title: Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook
Authors: Hassan Hizeh, Rim Chighri, Muhammad Mahboob Ur Rahman, Mohamed A. Bahloul, Ali Muqaibel, Tareq Y. Al-Naffouri
Abstract: The current body of research on Parkinson's disease (PD) screening, monitoring, and management has evolved along two largely independent trajectories. The first research community focuses on multimodal sensing of PD-related biomarkers using noninvasive technologies such as inertial measurement units (IMUs), force/pressure insoles, electromyography (EMG), electroencephalography (EEG), speech and acoustic analysis, and RGB/RGB-D motion capture systems. These studies emphasize data acquisition, feature extraction, and machine learning-based classification for PD screening, diagnosis, and disease progression modeling. In parallel, a second research community has concentrated on robotic intervention and rehabilitation, employing socially assistive robots (SARs), robot-assisted rehabilitation (RAR) systems, and virtual reality (VR)-integrated robotic platforms for improving motor and cognitive function, enhancing social engagement, and supporting caregivers. Despite the complementary goals of these two domains, their methodological and technological integration remains limited, with minimal data- level or decision-level coupling between the two. With the advent of advanced artificial intelligence (AI), including large language models (LLMs), agentic AI systems, a unique opportunity now exists to unify these research streams. We envision a closed-loop sensor-AI-robot framework in which multimodal sensing continuously guides the interaction between the patient, caregiver, humanoid robot (and physician) through AI agents that are powered by a multitude of AI models such as robotic and wearables foundation models, LLM-based reasoning, reinforcement learning, and continual learning. Such closed-loop system enables personalized, explainable, and context-aware intervention, forming the basis for digital twin of the PD patient that can adapt over time to deliver intelligent, patient-centered PD care.

Paper number 22:
Title: Online Learning of Modular Bayesian Deep Receivers: Single-Step Adaptation with Streaming Data
Authors: Yakov Gusakov, Osvaldo Simeone, Tirza Routtenberg, Nir Shlezinger
Abstract: Deep neural network (DNN)-based receivers offer a powerful alternative to classical model-based designs for wireless communication, especially in complex and nonlinear propagation environments. However, their adoption is challenged by the rapid variability of wireless channels, which makes pre-trained static DNN-based receivers ineffective, and by the latency and computational burden of online stochastic gradient descent (SGD)-based learning. In this work, we propose an online learning framework that enables rapid low-complexity adaptation of DNN-based receivers. Our approach is based on two main tenets. First, we cast online learning as Bayesian tracking in parameter space, enabling a single-step adaptation, which deviates from multi-epoch SGD . Second, we focus on modular DNN architectures that enable parallel, online, and localized variational Bayesian updates. Simulations with practical communication channels demonstrate that our proposed online learning framework can maintain a low error rate with markedly reduced update latency and increased robustness to channel dynamics as compared to traditional gradient descent based method.

Paper number 23:
Title: Positioning Using LEO Satellite Communication Signals Under Orbital Errors
Authors: Jie Ma, Pinjun Zheng, Xing Liu, Yuchen Zhang, Ali A. Nasir, Tareq Y. Al-Naffouri
Abstract: Low Earth orbit (LEO) satellites offer a promising alternative to global navigation satellite systems for precise positioning; however, their relatively low altitudes make them more susceptible to orbital perturbations, which in turn degrade positioning accuracy. In this work, we study LEO-based positioning under orbital errors within a signal-of-opportunity framework. First, we introduce a LEO orbit model that accounts for Earth's non-sphericity and derive a wideband communication model that captures fast- and slow-time Doppler effects and multipath propagation. Subsequently, we perform a misspecified Cramér-Rao bound (MCRB) analysis to evaluate the impact of orbital errors on positioning performance. Then, we propose a two-stage positioning method starting with a (i) MCRB-based weighted orbit calibration, followed by (ii) least-squares user positioning using the corrected orbit. The MCRB analysis indicates that orbital errors can induce kilometer-level position biases. Extensive simulations show that the proposed estimator can considerably enhance the positioning accuracy relative to the orbit-mismatched baseline, yielding errors on the order of a few meters.

Paper number 24:
Title: Koopman Operator for Stability Analysis: Theory with a Linear--Radial Product Reproducing Kernel
Authors: Wentao Tang, Xiuzhen Ye
Abstract: Koopman operator, as a fully linear representation of nonlinear dynamical systems, if well-defined on a reproducing kernel Hilbert space (RKHS), can be efficiently learned from data. For stability analysis and control-related problems, it is desired that the defining RKHS of the Koopman operator should account for both the stability of an equilibrium point (as a local property) and the regularity of the dynamics on the state space (as a global property). To this end, we show that by using the product kernel formed by the linear kernel and a Wendland radial kernel, the resulting RKHS is invariant under the action of Koopman operator (under certain smoothness conditions). Furthermore, when the equilibrium is asymptotically stable, the spectrum of Koopman operator is provably confined inside the unit circle, and escapes therefrom upon bifurcation. Thus, the learned Koopman operator with provable probabilistic error bound provides a stability certificate. In addition to numerical verification, we further discuss how such a fundamental spectrum--stability relation would be useful for Koopman-based control.

Paper number 25:
Title: Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam
Authors: Juan Augusto Paredes Salazar, Ankit Goel
Abstract: This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements.

Paper number 26:
Title: A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization
Authors: Luca Ambrosino, Khai Manh Nguyen, Minh Binh Vu, Riadh Zorgati, Laurent El Ghaoui, Giuseppe C. Calafiore
Abstract: In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies.

Paper number 27:
Title: BSCodec: A Band-Split Neural Codec for High-Quality Universal Audio Reconstruction
Authors: Haoran Wang, Jiatong Shi, Jinchuan Tian, Bohan Li, Kai Yu, Shinji Watanabe
Abstract: Neural audio codecs have recently enabled high-fidelity reconstruction at high compression rates, especially for speech. However, speech and non-speech audio exhibit fundamentally different spectral characteristics: speech energy concentrates in narrow bands around pitch harmonics (80-400 Hz), while non-speech audio requires faithful reproduction across the full spectrum, particularly preserving higher frequencies that define timbre and texture. This poses a challenge: speech-optimized neural codecs suffer degradation on music or sound. Treating the full spectrum holistically is suboptimal: frequency bands have vastly different information density and perceptual importance by content type, yet full-band approaches apply uniform capacity across frequencies without accounting for these acoustic structures. To address this gap, we propose BSCodec (Band-Split Codec), a novel neural audio codec architecture that splits the spectral dimension into separate bands and compresses each band independently. Experimental results demonstrate that BSCodec achieves superior reconstruction over baselines across sound and music, while maintaining competitive quality in the speech domain, when trained on the same combined dataset of speech, music and sound. Downstream benchmark tasks further confirm that BSCodec shows strong potential for use in downstream applications.

Paper number 28:
Title: Cross-Modal Fine-Tuning of 3D Convolutional Foundation Models for ADHD Classification with Low-Rank Adaptation
Authors: Jyun-Ping Kao, Shinyeong Rho, Shahar Lazarev, Hyun-Hae Cho, Fangxu Xing, Taehoon Shin, C.-C. Jay Kuo, Jonghye Woo
Abstract: Early diagnosis of attention-deficit/hyperactivity disorder (ADHD) in children plays a crucial role in improving outcomes in education and mental health. Diagnosing ADHD using neuroimaging data, however, remains challenging due to heterogeneous presentations and overlapping symptoms with other conditions. To address this, we propose a novel parameter-efficient transfer learning approach that adapts a large-scale 3D convolutional foundation model, pre-trained on CT images, to an MRI-based ADHD classification task. Our method introduces Low-Rank Adaptation (LoRA) in 3D by factorizing 3D convolutional kernels into 2D low-rank updates, dramatically reducing trainable parameters while achieving superior performance. In a five-fold cross-validated evaluation on a public diffusion MRI database, our 3D LoRA fine-tuning strategy achieved state-of-the-art results, with one model variant reaching 71.9% accuracy and another attaining an AUC of 0.716. Both variants use only 1.64 million trainable parameters (over 113x fewer than a fully fine-tuned foundation model). Our results represent one of the first successful cross-modal (CT-to-MRI) adaptations of a foundation model in neuroimaging, establishing a new benchmark for ADHD classification while greatly improving efficiency.

Paper number 29:
Title: Hierarchically Block-Sparse Recovery With Prior Support Information
Authors: Liyang Lu, Haochen Wu, Wenbo Xu, Zhaocheng Wang, H. Vincent Poor
Abstract: We provide new recovery bounds for hierarchical compressed sensing (HCS) based on prior support information (PSI). A detailed PSI-enabled reconstruction model is formulated using various forms of PSI. The hierarchical block orthogonal matching pursuit with PSI (HiBOMP-P) algorithm is designed in a recursive form to reliably recover hierarchically block-sparse signals. We derive exact recovery conditions (ERCs) measured by the mutual incoherence property (MIP), wherein hierarchical MIP concepts are proposed, and further develop reconstructible sparsity levels to reveal sufficient conditions for ERCs. Leveraging these MIP analyses, we present several extended insights, including reliable recovery conditions in noisy scenarios and the optimal hierarchical structure for cases where sparsity is not equal to zero. Our results further confirm that HCS offers improved recovery performance even when the prior information does not overlap with the true support set, whereas existing methods heavily rely on this overlap, thereby compromising performance if it is absent.

Paper number 30:
Title: Meta-Learning-Driven GFlowNets for 3D Directional Modulation in Mobile Wireless Systems
Authors: Zhihao Tao, Athina P. Petropulu
Abstract: In our prior work we have proposed the use of GFlowNets, a generative AI (GenAI) framework, for designing a secure communication system comprising a time-modulated intelligent reflecting surface (TM-IRS). However, GFlowNet-based approaches assume static environments, limiting their applicability in mobile wireless networks. In this paper, we proposes a novel Meta-GFlowNet framework that achieves rapid adaptation to dynamic conditions using model-agnostic meta-learning. As the communication user is moving, the framework learns a direction-general prior across user directions via inner trajectory-balance updates and outer meta-updates, enabling quick convergence to new user directions. The approach requires no labeled data, employing a pseudo-supervised consistency objective derived from the learned reward by GFlowNet and the actual sum-rate reward of the TM-IRS system. Simulation results show that the proposed method attains faster adaptation and higher secrecy performance than retrained GFlowNets, offering an efficient GenAI framework for dynamic wireless environments. Although the scenario considered here focuses on directional modulation-based physical-layer security, the proposed framework can also be applied to other mobile wireless systems, such as joint sensing-communication networks, that utilize GFlowNets.

Paper number 31:
Title: A Passive Software-Defined Radio-based mmWave Sensing System for Blind Integrated Communication and Sensing
Authors: Shiqi Liu, Hang Song, Bo Wei, Nopphon Keerativoranan, Jun-ichi Takada
Abstract: Integrated Sensing and Communication (ISAC) is considered as a key component of future 6G technologies, especially in the millimeter-wave (mmWave) bands. Recently, the performances of ISAC were experimentally evaluated and demonstrated in various scenarios by developing ISAC systems. These systems generally consist of coherent transmitting (Tx) and receiving (Rx) modules. However, actively transmitting radio waves for experiments is not easy due to regulatory restrictions of radio. Meanwhile, the Tx/Rx should be synchronized and Rx need the information of Tx. In this paper, a fully passive mmWave sensing system is developed with software-defined radio for blind ISAC. It only consists of a passive Rx module which does not depend on the Tx. Since the proposed system is not synchronized with Tx and has no knowledge of the transmitted signals, a differential structure with two oppositely-oriented receivers is introduced to realize the sensing function. This structure can mitigate the influences of unknown source signals and other distortions. With the proposed sensing system, the ambient mmWave communication signals are leveraged for sensing without interrupting the existing systems. It can be deployed for field applications such as signal detection and dynamic human activity recognition since it does not emit signals. The efficacy of the developed system is first verified with a metallic plate with known motion pattern. The measured Doppler spectrogram shows good agreement with the simulation results, demonstrating the correctness of the sensing results. Further, the system is evaluated in complex scenarios, including handwaving, single- and multi-person motion detection. The sensing results successfully reflect the corresponding motions, demonstrating that the proposed sensing system can be utilized for blind ISAC in various applications.

Paper number 32:
Title: SPASHT: An image-enhancement method for sparse-view MPI SPECT
Authors: Zezhang Yang, Zitong Yu, Nuri Choi, Janice Tania, Wenxuan Xue, Barry A. Siegel, Abhinav K. Jha
Abstract: Single-photon emission computed tomography for myocardial perfusion imaging (MPI SPECT) is a widely used diagnostic tool for coronary artery disease. However, the procedure requires considerable scanning time, leading to patient discomfort and the potential for motion-induced artifacts. Reducing the number of projection views while keeping the time per view unchanged provides a mechanism to shorten the scanning time. However, this approach leads to increased sampling artifacts, higher noise, and hence limited image quality. To address these issues, we propose sparseview SPECT image enhancement (SPASHT), inherently training the algorithm to improve performance on defect-detection tasks. We objectively evaluated SPASHT on the clinical task of detecting perfusion defects in a retrospective clinical study using data from patients who underwent MPI SPECT, where the defects were clinically realistic and synthetically inserted. The study was conducted for different numbers of fewer projection views, including 1/6, 1/3, and 1/2 of the typical projection views for MPI SPECT. Performance on the detection task was quantified using area under the receiver operating characteristic curve (AUC). Images obtained with SPASHT yielded significantly improved AUC compared to those obtained with the sparse-view protocol for all the considered numbers of fewer projection views. To further assess performance, a human observer study on the task of detecting perfusion defects was conducted. Results from the human observer study showed improved detection performance with images reconstructed using SPASHT compared to those from the sparse-view protocol. The results provide evidence of the efficacy of SPASHT in improving the quality of sparse-view MPI SPECT images and motivate further clinical validation.

Paper number 33:
Title: Learning-Based Robust Bayesian Persuasion with Conformal Prediction Guarantees
Authors: Heeseung Bang, Andreas A. Malikopoulos
Abstract: Classical Bayesian persuasion assumes that senders fully understand how receivers form beliefs and make decisions--an assumption that rarely holds when receivers possess private information or exhibit non-Bayesian behavior. In this paper, we develop a learning-based framework that integrates neural networks with conformal prediction to achieve robust persuasion under uncertainty about receiver belief formation. The proposed neural architecture learns end-to-end mappings from receiver observations and sender signals to action predictions, eliminating the need to identify belief mechanisms explicitly. Conformal prediction constructs finite-sample valid prediction sets with provable marginal coverage, enabling principled, distribution-free robust optimization. We establish exact coverage guarantees for the data-generating policy and derive bounds on coverage degradation under policy shifts. Furthermore, we provide neural network approximation and estimation error bounds, with sample complexity $O(d \log(|\mathcal{U}||\mathcal{Y}||\mathcal{S}|)/\varepsilon^2)$, where $d$ denotes the effective network dimension, and finite-sample lower bounds on the sender's expected utility. Numerical experiments on smart-grid energy management illustrate the framework's robustness.

Paper number 34:
Title: IDMap: A Pseudo-Speaker Generator Framework Based on Speaker Identity Index to Vector Mapping
Authors: Zeyan Liu, Liping Chen, Kong Aik Lee, Zhenhua Ling
Abstract: Facilitated by the speech generation framework that disentangles speech into content, speaker, and prosody, voice anonymization is accomplished by substituting the original speaker embedding vector with that of a pseudo-speaker. In this framework, the pseudo-speaker generation forms a fundamental challenge. Current pseudo-speaker generation methods demonstrate limitations in the uniqueness of pseudo-speakers, consequently restricting their effectiveness in voice privacy protection. Besides, existing model-based methods suffer from heavy computation costs. Especially, in the large-scale scenario where a huge number of pseudo-speakers are generated, the limitations of uniqueness and computational inefficiency become more significant. To this end, this paper proposes a framework for pseudo-speaker generation, which establishes a mapping from speaker identity index to speaker vector in the feedforward architecture, termed IDMap. Specifically, the framework is specified into two models: IDMap-MLP and IDMap-Diff. Experiments were conducted on both small- and large-scale evaluation datasets. Small-scale evaluations on the LibriSpeech dataset validated the effectiveness of the proposed IDMap framework in enhancing the uniqueness of pseudo-speakers, thereby improving voice privacy protection, while at a reduced computational cost. Large-scale evaluations on the MLS and Common Voice datasets further justified the superiority of the IDMap framework regarding the stability of the voice privacy protection capability as the number of pseudo-speakers increased. Audio samples and open-source code can be found in this https URL.

Paper number 35:
Title: Fast Reconstruction of Motion-Corrupted Data with Mobile-GRAPPA: Motion and dB0 Inhomogeneity Correction Leveraging Efficient GRAPPA
Authors: Yimeng Lin, Nan Wang, Daniel Abraham, Daniel Polak, Xiaozhi Cao, Stephen Cauley, Kawin Setsompop
Abstract: Advanced motion navigations now enable rapid tracking of subject motion and dB0-induced phase, but accurately incorporating this high-temporal-resolution information into SENSE (Aligned-SENSE) is often computationally prohibitive. We propose "Mobile-GRAPPA", a k-space "cleaning" approach that uses local GRAPPA operators to remove motion and dB0 related corruption so that the resulting data can be reconstructed with standard SENSE. We efficiently train a family of k-space-position-specific Mobile-GRAPPA kernels via a lightweight multilayer perceptron (MLP) and apply them across k-space to generate clean data. In experiments on highly motion-corrupted 1-mm whole-brain GRE (Tacq = 10 min; 1,620 motion/dB0 trackings) and EPTI (Tacq = 2 min; 544 trackings), Mobile-GRAPPA enabled accurate reconstruction with negligible time penalty, whereas full Aligned-SENSE was impractical (reconstruction times > 10 h for GRE and > 10 days for EPTI). These results show that Mobile-GRAPPA incorporates detailed motion and dB0 tracking into SENSE with minimal computational overhead, enabling fast, high-quality reconstructions of challenging data.

Paper number 36:
Title: Blocker-Aware Beamforming and Dynamic Power Allocation for Multicarrier ISAC-NOMA Systems
Authors: Abdulahi Abiodun Badrudeen, Nakyung Lee, Adam Dubs, Sunwoo Kim
Abstract: This paper proposes a blocker-aware multicarrier integrated sensing and communication (ISAC)-non orthogonal multiple access (NOMA) system, leveraging hybrid beamforming and dynamic power allocation to enhance spectrum efficiency in 6G networks. Recognizing the performance degradation caused by environmental blockers, the system introduces a joint waveform design that ensures robust operation under varying channel conditions. A channel switching mechanism is deployed to reroute communication through alternative non-line-of-sight paths when the primary line-of-sight links are obstructed. Moreover, a dynamic power allocation strategy enforces a minimum rate constraint for the weak NOMA user, ensuring consistent quality of service. Extensive simulations over multiple blockage scenarios and signal to noise (SNR) conditions validate the effectiveness of the proposed solution. Notably, under severe blockage, the system achieves up to a 400% sensing rate enhancement at 15 dB SNR, with only a 20% reduction in communication rate. These results corroborate the system's ability to adapt and optimize joint sensing-communication performance in practical deployment environments.

Paper number 37:
Title: Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach
Authors: Yixuan Liu, Yingzhu Liu, Pengcheng You
Abstract: Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results.

Paper number 38:
Title: Partial-Power Flow Controller, Voltage Regulator, and Energy Router for Hybrid AC-DC Grids
Authors: Ehsan Asadi, Davood Keshavarzi, Alexander Koehler, Nima Tashakor, Stefan Goetz
Abstract: The share of electronically converted power from renewable sources, loads, and storage is continuously growing in the low- and medium-voltage grids. These sources and loads typically rectify the grid AC to DC, e.g., for a DC link, so that a DC grid could eliminate hardware and losses of these conversion stages. However, extended DC grids lack the stabilizing nature of AC impedances so that the voltage is more fragile and power flows may need active control, particularly if redundancy as known from AC, such as rings and meshing, is desired. Furthermore, a DC infrastructure will not replace but will need to interface with the existing AC grid. This paper presents a partial-power energy router architecture that can interface multiple AC and DC lines to enable precise control of voltages and both active as well as reactive power flows. The proposed system uses modular low-voltage high-current series modules supplied through dual active bridges. These modules only need to process a small share of the voltage to control large power flows. The topology reduces component size, cost, energy losses, and reliability more than three times compared to conventional technology. The optional integration of battery energy storage can furthermore eliminate the need for the sum of the power flows of all inputs to be zero at all times. Through dynamic voltage injection relative to the line voltage, the modules effectively balance feeder currents, regulate reactive power, and improve the power factor in AC grids. Real-time hardware-in-the-loop and prototype measurements validate the proposed energy router's performance under diverse operating conditions. Experimental results confirm the series module's functionality in both AC and DC grids as an effective solution for controlling extended grids, including power sharing, voltage, and power quality.

Paper number 39:
Title: Sum Rate and Worst Case SINR Optimization in Multi HAPS Ground Integrated Networks
Authors: Shasha Liu, Hayssam Dahrouj, Abla Kammoun, Mohamed-Slim Alouini
Abstract: Balancing throughput and fairness promises to be a key enabler for achieving large-scale digital inclusion in future vertical heterogeneous networks (VHetNets). In an attempt to address the global digital divide problem, this paper explores a multi-high-altitude platform system (HAPS)-ground integrated network, in which multiple HAPSs collaborate with ground base stations (BSs) to enhance the users' quality of service on the ground to achieve the highly sought-after digital equity. To this end, this paper considers maximizing both the network-wide weighted sum rate function and the worst-case signal-to-interference-plus-noise ratio (SINR) function subject to the same system level constraints. More specifically, the paper tackles the two different optimization problems so as to balance throughput and fairness, by accounting for the individual HAPS payload connectivity constraints, HAPS and BS distinct power limitations, and per-user rate requirements. This paper solves the considered problems using techniques from optimization theory by adopting a generalized assignment problem (GAP)-based methodology to determine the user association variables, jointly with successive convex approximation (SCA)-based iterative algorithms for optimizing the corresponding beamforming vectors. One of the main advantages of the proposed algorithms is their amenability for distributed implementation across the multiple HAPSs and BSs. The simulation results particularly validate the performance of the presented algorithms, demonstrating the capability of multi-HAPS networks to boost-up the overall network digital inclusion toward democratizing future digital services.

Paper number 40:
Title: Stackelberg Game-Driven Defense for ISAC Against Channel Attacks in Low-Altitude Networks
Authors: Jiacheng Wang, Changyuan Zhao, Dusit Niyato, Geng Sun, Weijie Yuan, Abbas Jamalipour, Tao Xiang
Abstract: The increasing saturation of terrestrial resources has driven economic activities into low-altitude airspace. These activities, such as air taxis, rely on low-altitude wireless networks, and one key enabling technology is integrated sensing and communication (ISAC). However, in low-altitude airspace, ISAC is vulnerable to channel-access attacks, thereby degrading performance and threatening safety. To address this, we propose a defense framework based on a Stackelberg game. Specifically, we first model the system under attack, deriving metrics for the communication and the sensing to quantify performance. Then, we formulate the interaction as a three-player game where a malicious attacker acts as the leader, while the legitimate drone and ground base station act as followers. Using a backward induction algorithm, we obtain the Stackelberg equilibrium, allowing the defenders to dynamically adjust their strategies to mitigate the attack. Simulation results verify that the proposed algorithm converges to a stable solution and outperforms existing baselines, ensuring reliable ISAC performance for critical low-altitude applications.

Paper number 41:
Title: Optical Network Digital Twin - Commercialization Barriers, Value Proposition, Early Use Cases, and Challenges
Authors: Hideki Nishizawa, Toru Mano, Kazuya Anazawa, Tatsuya Matsumura, Takeo Sasai, Masatoshi Namiki, Dmitrii Briantcev, Renato Ambrosone, Esther Le Rouzic, Stefan Melin, Oscar Gonzalez-de-Dios, Juan Pedro Fernandez-Palacios, Xiaocheng Zhang, Keigo Akahoshi, Gert Grammel, Andrea D'Amico, Giacomo Borraccini, Marco Ruffini, Daniel Kilper, Vittorio Curri
Abstract: With the widespread adoption of AI, machine-to-machine communications are rapidly increasing, reshaping the requirements for optical networks. Recent advances in Gaussian noise modeling for digital coherent transmission have raised expectations for digital-twin-based operation. However, unlike digital twins in wireless communication, which are already well established, significant barriers remain for commercialization in optical networks. This paper discusses the evolving requirements of optical networks in the AI era and proposes an Optical Network Digital Twin architecture that enables flexible end-to-end light path operation beyond conventional management. The value propositions of the proposed architecture, its evolutionary steps toward commercialization, and key research challenges for practical deployment are presented.

Paper number 42:
Title: CSIT-Free Multi-Group Multicast Transmission in Overloaded mmWave Systems
Authors: Wonseok Choi, Jeongjae Lee, Songnam Hong
Abstract: In this paper, we investigate the downlink multi-group multicast (MGM) transmission problem in overloaded mmWave systems. In particular, the conventional MGM beamforming requires substantial computational complexity and feedback (or pilot) overhead for acquisition of channel state information at the transmitter (CSIT), while simultaneous interference management and multicast beamforming optimization across multi-group inevitably incurs a significant rate loss. To address this, we propose a CSIT-free MGM (CF-MGM) transmission that eliminates the need for a complex CSIT acquisition. A deterministic CSIT-free precoding and proposed closed-form power allocation based on max-min fairness (MMF) allow each user to detect the common multicast stream completely canceling the inter-group interference with a significantly low complexity. Simulation results demonstrate the superiority and scalability of the proposed CF-MGM for the achievable rate and increase of users in a group outperforming the existing CSIT-based methods.

Paper number 43:
Title: Near-Field Velocity Estimation and Predictive Beamforming with Modular Linear Array
Authors: Khalid A. Alshumayri, Mudassir Masood, Ali. A. Nasir (Electrical Engineering Department and Interdisciplinary Research Center for Communication Systems and Sensing (IRC-CSS), King Fahd University of Petroleum and Minerals, Dhahran 31261, Saudi Arabia)
Abstract: Velocity estimation is a cornerstone of recently introduced near-field predictive beamforming. This paper derives the closed-form Cramer-Rao bounds (CRBs) for joint velocity estimation using a modular linear array (MLA) within a predictive-beamforming framework. The analysis shows that increasing inter-module separation enlarges the effective aperture and reduces the transverse-velocity CRB, whereas the radial-velocity CRB is largely insensitive to separation. We further obtain a simple closed-form relation linking the achievable antenna savings to the inter-module separation while preserving the same transverse accuracy of a uniform linear array (ULA). We further investigate how velocity mismatch affects array gain and show that transverse-velocity errors cause more severe performance degradation than radial-velocity errors. Simulations show that predictive beamforming with MLAs maintains high localization accuracy for target tracking.

Paper number 44:
Title: A Visual Perception-Based Tunable Framework and Evaluation Benchmark for H.265/HEVC ROI Encryption
Authors: Xiang Zhang, Geng Wu, Wenbin Huang, Daoyong Fu, Fei Peng, Zhangjie Fu
Abstract: ROI selective encryption, as an efficient privacy protection technique, encrypts only the key regions in the video, thereby ensuring security while minimizing the impact on coding efficiency. However, existing ROI-based video encryption methods suffer from insufficient flexibility and lack of a unified evaluation system. To address these issues, we propose a visual perception-based tunable framework and evaluation benchmark for H.265/HEVC ROI encryption. Our scheme introduces three key contributions: 1) A ROI region recognition module based on visual perception network is proposed to accurately identify the ROI region in videos. 2) A three-level tunable encryption strategy is implemented while balancing security and real-time performance. 3) A unified ROI encryption evaluation benchmark is developed to provide a standardized quantitative platform for subsequent research. This triple strategy provides new solution and significant unified performance evaluation methods for ROI selective encryption field. Experimental results indicate that the proposed benchmark can comprehensively measure the performance of the ROI selective encryption. Compared to existing ROI encryption algorithms, our proposed enhanced and advanced level encryption exhibit superior performance in multiple performance metrics. In general, the proposed framework effectively meets the privacy protection requirements in H.265/HEVC and provides a reliable solution for secure and efficient processing of sensitive video content.

Paper number 45:
Title: UAV-Assisted Downlink Satellite Covert Communication
Authors: Hung D. Nguyen, Jeongseok Ha
Abstract: This paper investigates the use of an unmanned aerial vehicle (UAV) to assist covert communication between a low-Earth orbit (LEO) satellite and a ground user under the surveillance of a passive warden. The UAV simultaneously serves its own ground network and acts as a friendly jammer to enhance the covertness of satellite transmissions. We derive a closed-form lower bound on the warden's average minimum detection error probability which is then used to define the covert constraint. Building on this, we formulate an optimization problem to jointly design the UAV's 3D placement, its power allocation, and the satellite's transmit power to maximize the system's covert rate. To solve the resulting non-convex problem, we propose an algorithm based on the block coordinate descent (BCD) and successive convex approximation (SCA) techniques, and further develop a Dinkelbach's algorithm for a special case. Numerical results validate the tightness of the derived bound and demonstrate the effectiveness of the proposed algorithms in configuring optimal system parameters.

Paper number 46:
Title: Dynamic Electric Vehicle Charging Pricing for Load Balancing in Power Distribution Networks based on Collaborative DDPG Agents
Authors: Leloko J. Lepolesa, Kayode E. Adetunji, Khmaies Ouahada, Zhenqing Liu, Ling Cheng
Abstract: The transition from the Internal Combustion Engine Vehicles (ICEVs) to the Electric Vehicles (EVs) is globally recommended to combat the unfavourable environmental conditions caused by reliance on fossil fuels. However, it has been established that the charging of EVs can destabilize the grid when they penetrate the market in large numbers, especially in grids that were not initially built to handle the load from the charging of EVs. In this work, we present a dynamic EV charging pricing strategy that fulfills the following three objectives: distribution network-level load peak-shaving, valley-filling, and load balancing across distribution networks. Based on historical environmental variables such as temperature, humidity, wind speed, EV charging prices and distribution of vehicles in different areas in different times of the day, we first forecast the distribution network load demand, and then use deep reinforcement learning approach to set the optimal dynamic EV charging price. While most research seeks to achieve load peak-shaving and valley-filling to stabilize the grid, our work goes further into exploring the load-balancing between the distribution networks in the close vicinity to each other. We compare the performance of Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms for this purpose. The best algorithm is used for dymamic EV pricing. Simulation results show an improved utilization of the grid at the distribution network level, leading to the optimal usage of the grid on a larger scale.

Paper number 47:
Title: Sensor Importance towards Observability Degree via Shapley Values
Authors: Vishal Cholapadi Ravindra
Abstract: Sensor selection is an often under-appreciated aspect of state estimator or Kalman filter design. The basic minimum requirement for the choice of a sensor set while designing Kalman filters is that all states are observable. In addition, the sensors should be chosen with a view towards estimating the states with a desired accuracy. Often observability is treated as true/false check during filter design. Beyond observability -- the observability degree -- which measures \emph{how observable} the states are, has been used as the metric of choice to for sensor selection or placement applications. The higher the degree of observability, the better the possibility of designing Kalman filters that achieve the desired state estimation accuracy and consistency requirements. When a wide variety of sensors are available, sometimes with cost and physical constraints involved, sensor selection plays a crucial role in filter design. In such situations it is important to know the expected contribution of each sensor towards observability degree. Shapley values, developed in cooperative game theory for fair allocation of the payout of a multi-player game to individual players, are widely used in machine learning to assess feature importance. This paper shows that Shapley values can indeed be leveraged to quantify the expected marginal contribution of each sensor in any given sensor set towards the observability degree. This quantification of the fair contribution of each sensor towards the observability degree can be leveraged by filter designers for sensor selection, placement and filter (state estimator) design.

Paper number 48:
Title: Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression
Authors: Amit Vaisman, Guy Ohayon, Hila Manor, Michael Elad, Tomer Michaeli
Abstract: While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme.

Paper number 49:
Title: Distributed MIMO Positioning: Fundamental Limit Analysis and User Tracking Framework Design
Authors: Yingjie Xu, Xuesong Cai, Ali Al-Ameri, Sara Willhammar, Fredrik Tufvesson
Abstract: This paper presents a comprehensive study on the 3D positioning capabilities of users in distributed multiple-input multiple-output (MIMO) systems. Unlike previous studies that mainly rely on idealized isotropic antenna models, we adopt a polarimetric model that takes advantage of effective aperture distribution functions to characterize realistic antenna patterns, placements, and polarization effects. Based on this model, we analyze the fundamental limits of UE positioning using the Fisher information matrix (FIM) and the position error bound (PEB). The FIM is shown to be expressed as a weighted sum of the information contributions from individual access point (AP)-UE pairs, with each contribution interpreted geometrically across distance, azimuth, and elevation dimensions. The impact of the UE tilt and the spatial distribution of APs on the PEBs is further analyzed. As a further advancement, we propose a complete positioning framework from a UE tracking perspective. By integrating a global probability hypothesis density filter and a PEB-aware AP management strategy, the framework enables accurate tracking while optimizing AP scheduling. Finally, we present a distributed MIMO channel measurement campaign to validate the proposed framework. The results demonstrate a centimeter-level tracking accuracy. In addition, the PEB-aware AP management strategy is shown to maintain robust tracking performance while significantly reducing the number of concurrently active APs, thus lowering the overall system overhead.

Paper number 50:
Title: Optimal Rank-1 Directional State Transition Tensors
Authors: Grace E. Calkins, Jay W. McMahon, Jackson Kulik
Abstract: An optimal rank-1 approximation of state transition tensors was developed as an efficient alternative to state transition tensors for nonlinear uncertainty quantification. While previous directional state transition tensors used the dominant right singular subspace of the state transition matrix to construct a reduced-dimension representation of the state transition tensors, optimal directional state transition tensors are constructed to maximize the information retained in a rank-1 approximation of the state transition tensors in the Frobenius-norm sense. The optimal rank-1 directional state transition tensor is found by solving a tensor z-eigenpair problem of the "square" of the state transition tensor. This construct leads to increased approximation accuracy of the state transition tensors and improved Gaussian moment propagation for nonlinear flight scenarios like aerocapture.

Paper number 51:
Title: Verification of low-frequency signal injection method for earth-fault detection
Authors: Nina Stipetic, Bozidar Filipovic-Grcic, Igor Ziger, Silvio Jancin, Bruno Jurisic, Dalibor Filipovic-Grcic, Alain Xémard
Abstract: Unearthed neutral is commonly used in networks which require continuous power supply. This is common in MV circuits of industrial and power plants. Unearthed networks can remain in operation during an earth-fault, but fast determination of the faulty line is key for prevention of further fault escalation. Signal injection is one of the fault location methods often used in LV unearthed networks. The possibility of applying this method in MV networks depends on how to inject the signal into unearthed phases. In such networks, it is possible to use a group of three inductive voltage transformers (IVTs) for signal injection. After the simulations have shown promising results of signal injection and earth-fault detection in MV network, an experimental test was performed. This paper describes the experimental setup and shows the measurement results of signal injection method at MV level supported by EMT simulations.

Paper number 52:
Title: Investigation of lightning effects on solar power plants connected to transmission networks
Authors: Selma Grebovic, Abdulah Aksamovic, Bozidar Filipovic-Grcic, Samim Konjicija
Abstract: The increasing integration of solar power plants into transmission grids has raised concerns about their vulnerability to disturbances, particularly lightning strokes. Solar energy, while offering significant environmental and economic benefits, faces challenges when connected to transmission lines that are prone to lightning discharges. This paper investigates the impact of lightning events on solar power plants, focusing on overvoltage effects. Lightning stroke simulations were conducted at various distances from the solar power plant along the transmission line, considering scenarios with and without surge arrester. Key lightning parameters such as peak current, front time, and tail time were varied to simulate different lightning strokes. The study also includes a Fourier transform analysis of the resulting overvoltages with and without a surge arrester, along with the Hilbert marginal spectrum of these overvoltages. The results provide insights into the effectiveness of surge arresters in mitigating lightning overvoltages and highlight the importance of proper protective measures for enhancing the reliability and safety of solar power plants connected to transmission networks.

Paper number 53:
Title: Input-Output Data-Driven Stabilization of Continuous-Time Linear MIMO Systems
Authors: Haihui Gao, Alessandro Bosso, Lei Wang, David Saussié, Bowen Yi
Abstract: In this paper, we address the problem of data-driven stabilization of continuous-time multi-input multi-output (MIMO) linear time-invariant systems using the input-output data collected from an experiment. Building on recent results for data-driven output-feedback control based on non-minimal realizations, we propose an approach that can be applied to a broad class of continuous-time MIMO systems without requiring a uniform observability index. The key idea is to show that Kreisselmeier's adaptive filter can be interpreted as an observer of a stabilizable non-minimal realization of the plant. Then, by postprocessing the input-output data with such a filter, we derive a linear matrix inequality that yields the feedback gain of a dynamic output-feedback stabilizer.

Paper number 54:
Title: Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage Collapses
Authors: Qinghua Ma, Seyyedali Hosseinalipour, Ming Shi, Jan Drgona, Shimiao Li
Abstract: This paper aims to proactively diagnose and manage the voltage collapse risks, i.e., the risk of bus voltages violating the safe operational bounds, which can be caused by extreme events and contingencies. We jointly answer two resilience-related research questions: (Q1) Survivability: Upon having an extreme event/contingency, will the system remain feasible with voltage staying within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage collapses, what are the dominant sources of system vulnerabilities responsible for the failure? This highlights some key locations worth paying attention to in the planning or decision-making process. To address these questions, we propose a voltage-regulated sparse optimization that finds a minimal set of bus locations along with quantified compensations (corrective actions) that can simultaneously enforce AC network balance and voltage bounds. Results on transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the proposed method effectively mitigates voltage collapses by compensating at only a few strategically identified nodes, while scaling efficiently to large systems, taking on average less than 4 min for 2000+ bus cases. This work can further serve as a backbone for more comprehensive and actionable decision-making, such as reactive power planning to fix voltage issues.

Paper number 55:
Title: Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids
Authors: Mohammad Javad Najafirad, Shirantha Welikala, Lei Wu, Panos J. Antsaklis
Abstract: This paper presents a novel dissipativity-based framework for co-designing distributed controllers and communication topologies in AC microgrids (MGs). Unlike existing methods that treat control synthesis and topology design separately, we propose a unified approach that simultaneously optimizes both aspects to achieve voltage and frequency regulation and proportional power sharing among distributed generators (DGs). We formulate the closed-loop AC MG as a networked system where DGs, distribution lines, and loads are interconnected subsystems characterized by their dissipative properties. Each DG employs a hierarchical architecture combining local controllers for voltage regulation and distributed controllers for droop-free power sharing through normalized power consensus. By leveraging dissipativity theory, we establish necessary and sufficient conditions for subsystem passivity and cast the co-design problem as a convex linear matrix inequality (LMI) optimization, enabling efficient computation and guaranteed stability. Our framework systematically synthesizes sparse communication topologies while handling the coupled dq-frame dynamics and dual power flow objectives inherent to AC MGs. Simulation results on a representative AC MG demonstrate the effectiveness of the proposed approach in achieving accurate voltage regulation, frequency synchronization, and proportional power sharing.

Paper number 56:
Title: Compressive Sensing Photoacoustic Imaging Receiver with Matrix-Vector-Multiplication SAR ADC
Authors: Huan-Cheng Liao, Shunyao Zhang, Yumin Su, Arvind Govinday, Yiwei Zou, Wei Wang, Vivek Boominathan, Ashok Veeraraghavan, Lei S. Li, Kaiyuan Yang
Abstract: Wearable photoacoustic imaging devices hold great promise for continuous health monitoring and point-of-care diagnostics. However, the large data volume generated by high-density transducer arrays presents a major challenge for realizing compact and power-efficient wearable systems. This paper presents a photoacoustic imaging receiver (RX) that embeds compressive sensing directly into the hardware to address this bottleneck. The RX integrates 16 AFEs and four matrix-vector-multiplication (MVM) SAR ADCs that perform energy- and area-efficient analog-domain compression. The architecture achieves a 4-8x reduction in output data rate while preserving low-loss full-array information. The MVM SAR ADC executes passive and accurate MVM using user-defined programmable ternary weights. Two signal reconstruction methods are implemented: (1) an optimization approach using the fast iterative shrinkage-thresholding algorithm, and (2) a learning-based approach employing implicit neural representation. Fabricated in 65 nm CMOS, the chip achieves an ADC's SNDR of 57.5 dB at 20.41 MS/s, with an AFE input-referred noise of 3.5 nV/sqrt(Hz). MVM linearity measurements show R^2 > 0.999 across a wide range of weights and input amplitudes. The system is validated through phantom imaging experiments, demonstrating high-fidelity image reconstruction under up to 8x compression. The RX consumes 5.83 mW/channel and supports a general ternary-weighted measurement matrix, offering a compelling solution for next-generation miniaturized, wearable PA imaging systems.

Paper number 57:
Title: On the Potential of Digital Twins for Distribution System State Estimation with Randomly Missing Data in Heterogeneous Measurements
Authors: Ying Zhang, Yihao Wang, Yuanshuo Zhang, Eric Larson, Di Shi, Fanping Sui
Abstract: Traditional statistical optimization-based state estimation (DSSE) algorithms rely on detailed grid parameters and mathematical assumptions of all possible uncertainties. Furthermore, random data missing due to communication failures, congestion, and cyberattacks, makes these methods easily infeasible. Inspired by recent advances in digital twins (DTs), this paper proposes an interactive attention-based DSSE model for robust grid monitoring by integrating three core components: physical entities, virtual modeling, and data fusion. To enable robustness against various data missing in heterogeneous measurements, we first propose physics-informed data augmentation and transfer. Moreover, a state-of-the-art attention-based spatiotemporal feature learning is proposed, followed by a novel cross-interaction feature fusion for robust voltage estimation. A case study in a real-world unbalanced 84-bus distribution system with raw data validates the accuracy and robustness of the proposed DT model in estimating voltage states, with random locational, arbitrary ratios (up to 40% of total measurements) of data missing.

Paper number 58:
Title: SPUR: A Plug-and-Play Framework for Integrating Spatial Audio Understanding and Reasoning into Large Audio-Language Models
Authors: S Sakshi, Vaibhavi Lokegaonkar, Neil Zhang, Ramani Duraiswami, Sreyan Ghosh, Dinesh Manocha, Lie Lu
Abstract: Spatial perception is central to auditory intelligence, enabling accurate understanding of real-world acoustic scenes and advancing human-level perception of the world around us. While recent large audio-language models (LALMs) show strong reasoning over complex audios, most operate on monaural inputs and lack the ability to capture spatial cues such as direction, elevation, and distance. We introduce SPUR, a lightweight, plug-in approach that equips LALMs with spatial perception through minimal architectural changes. SPUR consists of: (i) a First-Order Ambisonics (FOA) encoder that maps (W, X, Y, Z) channels to rotation-aware, listener-centric spatial features, integrated into target LALMs via a multimodal adapter; and (ii) SPUR-Set, a spatial QA dataset combining open-source FOA recordings with controlled simulations, emphasizing relative direction, elevation, distance, and overlap for supervised spatial reasoning. Fine-tuning our model on the SPUR-Set consistently improves spatial QA and multi-speaker attribution while preserving general audio understanding. SPUR provides a simple recipe that transforms monaural LALMs into spatially aware models. Extensive ablations validate the effectiveness of our approach.

Paper number 59:
Title: Spectrum and Physics-Informed Neural Networks (SaPINNs) for Input-State-Parameter Estimation in Dynamic Systems Subjected to Natural Hazards-Induced Excitation
Authors: Antonina Kosikova, Apostolos Psaros, Andrew Smyth
Abstract: System identification under unknown external excitation is an inherently ill-posed problem, typically requiring additional knowledge or simplifying assumptions to enable reliable state and parameter estimation. The difficulty of the problem is further amplified in structural systems subjected to natural hazards such as earthquakes or windstorms, where responses are often highly transient, nonlinear, and spatially distributed. To address this challenge, we introduce Spectrum and Physics-Informed Neural Networks (SaPINNs) for efficient input--state--parameter estimation in systems under complex excitations characteristic of natural hazards. The proposed model enhances the neural network with governing physics of the system dynamics and incorporates spectral information of natural hazards by using empirically derived spectra as priors on the unknown excitations. This integration improves inference of unmeasured inputs, system states, and parameters without imposing restrictive assumptions on their dynamics. The performance of the proposed framework is demonstrated through comparative studies on both linear and nonlinear systems under various types of excitation, including the El Centro earthquake, where the seismic spectrum is assumed to be not precisely known. To account for predictive uncertainty, the proposed architecture is embedded within a Deep Ensemble (DEns) networks architecture, providing distributions over possible solutions. The results demonstrate that the proposed approach outperforms conventional PINNs, as the incorporation of spectral information introduces an inductive bias that guides the network more effectively through the solution space and enhances its ability to recover physically consistent state and parameter estimates with realistic uncertainty levels.

Paper number 60:
Title: GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising
Authors: Yuhang Li, Yang Lu, Bo Ai, Zhiguo Ding, Dusit Niyato, Arumugam Nallanathan
Abstract: Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI.

Paper number 61:
Title: F2GAN: A Feature-Feedback Generative Framework for Reliable AI-Based Fault Diagnosis in Inverter-Dominated Microgrids
Authors: Swetha Rani Kasimalla, Kuchan Park, Junho Hong, Young-Jin Kim
Abstract: Enhancing the reliability of AI based fault diagnosis in inverter dominated microgrids requires diverse and statistically balanced datasets. However, the scarcity and imbalance of high fidelity fault data, especially for rare inverter malfunctions and extreme external line faults, limit dependable model training and validation. This paper introduces a unified framework that models a detailed inverter dominated microgrid and systematically generates multiple internal and external fault scenarios to mitigate data scarcity and class imbalance. An enhanced generative model called F2GAN (Feature Feedback GAN) is developed to synthesize high dimensional tabular fault data with improved realism and statistical alignment. Unlike conventional GANs, F2GAN integrates multi level feedback based on mean variance, correlation, and feature matching losses, enabling the generator to refine output distributions toward real fault feature spaces. The generated datasets are evaluated through quantitative and qualitative analyses. Train on Synthetic, Test on Real (TSTR) experiments demonstrate strong generalization of machine learning classifiers trained exclusively on F2GAN samples. The framework is validated on a hardware-in-the-loop (HIL) fault diagnosis platform integrated with a real time simulator and graphical interface, achieving 100 % diagnostic accuracy under real-time testing. Results confirm that F2GAN effectively bridges the gap between simulated and real world microgrid fault datasets

Paper number 62:
Title: Structure-Aware Near-Field Radio Map Recovery via RBF-Assisted Matrix Completion
Authors: Hao Sun, Xianghao Yu, Junting Chen
Abstract: This paper proposes a novel structure-aware matrix completion framework assisted by radial basis function (RBF) interpolation for near-field radio map construction in extremely large multiple-input multiple-output (XL-MIMO) systems. Unlike the far-field scenario, near-field wavefronts exhibit strong dependencies on both angle and distance due to spherical wave propagation, leading to complicated variations in received signal strength (RSS). To effectively capture the intricate spatial variations structure inherent in near-field environments, a regularized RBF interpolation method is developed to enhance radio map reconstruction accuracy. Leveraging theoretical insights from interpolation error analysis of RBF, an inverse {\mu}-law-inspired nonuniform sampling strategy is introduced to allocate measurements adaptively, emphasizing regions with rapid RSS variations near the transmitter. To further exploit the global low-rank structure in the near-field radio map, we integrate RBF interpolation with nuclear norm minimization (NNM)-based matrix completion. A robust Huberized leave-one-out cross-validation (LOOCV) scheme is then proposed for adaptive selection of the tolerance parameter, facilitating optimal fusion between RBF interpolation and matrix completion. The integration of local variation structure modeling via RBF interpolation and global low-rank structure exploitation via matrix completion yields a structure-aware framework that substantially improves the accuracy of near-field radio map reconstruction. Extensive simulations demonstrate that the proposed approach achieves over 10% improvement in normalized mean squared error (NMSE) compared to standard interpolation and matrix completion methods under varying sampling densities and shadowing conditions.

Paper number 63:
Title: Pareto-Improvement-Driven Opinion Dynamics Explaining the Emergence of Pluralistic Ignorance
Authors: Yuheng Luo, Chuanzhe Zhang, Qingsong Liu, Hai Zhu, Wenjun Mei
Abstract: Opinion dynamics has recently been modeled from a game-theoretic perspective, where opinion updates are captured by individuals' cost functions representing their motivations. Conventional formulations aggregate multiple motivations into a single objective, implicitly assuming that these motivations are interchangeable. This paper challenges that assumption and proposes an opinion dynamics model grounded in a multi-objective game framework. In the proposed model, each individual experiences two distinct costs: social pressure from disagreement with others and cognitive dissonance from deviation from the perceived truth. Opinion updates are modeled as Pareto improvements between these two costs. This fwork provides a parsimonious explanation for the emergence of pluralistic ignorance, where individuals may agree on something untrue even though they all know the underlying truth. We analytically characterize the model, derive conditions for the emrameergence and prevalence of the truth, and propose an initial-seeding strategy that ensures consensus on truth. Numerical simulations are conducted on how network density and clustering affect the expression of truth. Both theoretical and numerical results lead to clear and non-trivial sociological insights. For example, no network structure guarantees truthful consensus if no one initially express the truth; moderately sparse but well-mixed networks best mitigate pluralistic ignorance.

Paper number 64:
Title: The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks and Faults in Power Systems Using Ensemble and Machine Learning
Authors: Emad Abukhousa, Syed Sohail Feroz Syed Afroz, Fahad Alsaeed, Abdulaziz Qwbaiban, Saman Zonouz, A.P. Sakis Meliopoulos
Abstract: This paper presents a high-fidelity evaluation framework for machine learning (ML)-based classification of cyber-attacks and physical faults using electromagnetic transient simulations with digital substation emulation at 4.8 kHz. Twelve ML models, including ensemble algorithms and a multi-layer perceptron (MLP), were trained on labeled time-domain measurements and evaluated in a real-time streaming environment designed for sub-cycle responsiveness. The architecture incorporates a cycle-length smoothing filter and confidence threshold to stabilize decisions. Results show that while several models achieved near-perfect offline accuracies (up to 99.9%), only the MLP sustained robust coverage (98-99%) under streaming, whereas ensembles preserved perfect anomaly precision but abstained frequently (10-49% coverage). These findings demonstrate that offline accuracy alone is an unreliable indicator of field readiness and underscore the need for realistic testing and inference pipelines to ensure dependable classification in inverter-based resources (IBR)-rich networks.

Paper number 65:
Title: Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution Imaging
Authors: Tao Lv, Daoming Zhou, Chenglong Huang, Chongde Zi, Linsen Chen, Xun Cao
Abstract: Computational spectral imaging (CSI) achieves real-time hyperspectral imaging through co-designed optics and algorithms, but typical CSI methods suffer from a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution imaging (SDI) methods based on PSF engineering have been proposed to achieve high-fidelity compact CSI design recently. However, the composite convolution-integration operations of SDI render the normal-equation coefficient matrix scene-dependent, which hampers the efficient exploitation of imaging priors and poses challenges for accurate reconstruction. To tackle the inherent data-dependent operators in SDI, we introduce a Hierarchical Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing subproblems and projecting them into the frequency domain, HSFAUF transforms nonlinear processes into linear mappings, thereby enabling efficient solutions. Furthermore, to integrate spatial-spectral priors during iterative refinement, we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly aggregates information across spatial and frequency domains. By integrating SFAT into HSFAUF, we develop a Transformer-based deep unfolding method, \textbf{H}ierarchical \textbf{S}patial-\textbf{F}requency \textbf{A}ggregation \textbf{U}nfolding \textbf{T}ransformer (HSFAUT), to solve the inverse problem of SDI. Systematic simulated and real experiments show that HSFAUT surpasses SOTA methods with cheaper memory and computational costs, while exhibiting optimal performance on different SDI systems.

Paper number 66:
Title: RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research
Authors: Ridoy Chandra Shil, Ragib Abid, Tasnia Binte Mamun, Samiul Based Shuvo, Masfique Ahmed Bhuiyan, Jahid Ferdous
Abstract: Background and Objective: Colorectal cancer prevention relies on early detection of polyps during colonoscopy. Existing public datasets, such as CVC-ClinicDB and Kvasir-SEG, provide valuable benchmarks but are limited by small sample sizes, curated image selection, or lack of real-world artifacts. There remains a need for datasets that capture the complexity of clinical practice, particularly in resource-constrained settings. Methods: We introduce a dataset, BUET Polyp Dataset (BPD), of colonoscopy images collected using Olympus 170 and Pen- tax i-Scan series endoscopes under routine clinical conditions. The dataset contains images with corresponding expert-annotated binary masks, reflecting diverse challenges such as motion blur, specular highlights, stool artifacts, blood, and low-light frames. Annotations were manually reviewed by clinical experts to ensure quality. To demonstrate baseline performance, we provide bench- mark results for classification using VGG16, ResNet50, and InceptionV3, and for segmentation using UNet variants with VGG16, ResNet34, and InceptionV4 backbones. Results: The dataset comprises 1,288 images with polyps from 164 patients with corresponding ground-truth masks and 1,657 polyp-free images from 31 patients. Benchmarking experiments achieved up to 90.8% accuracy for binary classification (VGG16) and a maximum Dice score of 0.64 with InceptionV4-UNet for segmentation. Performance was lower compared to curated datasets, reflecting the real-world difficulty of images with artifacts and variable quality.

Paper number 67:
Title: Learning Performance Optimization for Edge AI System with Time and Energy Constraints
Authors: Zhiyuan Zhai, Wei Ni, Xin Wang
Abstract: Edge AI, which brings artificial intelligence to the edge of the network for real-time processing and decision-making, has emerged as a transformative technology across various applications. However, the deployment of Edge AI systems faces significant challenges due to high energy consumption and extended operation time. In this paper, we consider an Edge AI system which integrates the data acquisition, computation and communication processes, and focus on improving learning performance of this system. We model the time and energy consumption of different processes and perform a rigorous convergence analysis to quantify the impact of key system parameters, such as the amount of collected data and the number of training rounds, on the learning performance. Based on this analysis, we formulate a system-wide optimization problem that seeks to maximize learning performance under given time and energy constraints. We explore both homogeneous and heterogeneous device scenarios, developing low-complexity algorithms based on one-dimensional search and alternating optimization to jointly optimize data collection time and training rounds. Simulation results validate the accuracy of our convergence analysis and demonstrate the effectiveness of the proposed algorithms, providing valuable insights into designing energy-efficient Edge AI systems under real-world conditions.

Paper number 68:
Title: Learning stabilising policies for constrained nonlinear systems
Authors: Daniele Ravasio, Danilo Saccani, Marcello Farina, Giancarlo Ferrari-Trecate
Abstract: This work proposes a two-layered control scheme for constrained nonlinear systems represented by a class of recurrent neural networks and affected by additive disturbances. In particular, a base controller ensures global or regional closed-loop l_p-stability of the error in tracking a desired equilibrium and the satisfaction of input and output constraints within a robustly positive invariant set. An additional control contribution, derived by combining the internal model control principle with a stable operator, is introduced to improve system performance. This operator, implemented as a stable neural network, can be trained via unconstrained optimisation on a chosen performance metric, without compromising closed-loop equilibrium tracking or constraint satisfaction, even if the optimisation is stopped prematurely. In addition, we characterise the class of closed-loop stable behaviours that can be achieved with the proposed architecture. Simulation results on a pH-neutralisation benchmark demonstrate the effectiveness of the proposed approach.

Paper number 69:
Title: Joint Access Point Selection and Beamforming Design for Bistatic Backscatter Communication
Authors: Ahmet Kaplan, Diana P. M. Osorio, Erik G. Larsson
Abstract: Future Internet-of-Things networks are envisioned to use small and cheap sensor nodes with extremely low power consumption to avoid the extensive use of batteries. To provide connectivity to a massive number of these nodes, backscatter communication (BC) is emerging as an energy- and cost-efficient technology exploiting the reflection of radio frequency signals. However, challenges such as round-trip path loss and direct link interference (DLI) between the carrier emitter and the reader limit its performance. To tackle these limitations, this paper proposes a joint access point role selection and a novel beamforming technique for bistatic BC in a distributed multiple-input multiple- output setup. The proposed approach boosts the received backscattered energy while effectively mitigating DLI, thereby reducing the error probability. We also propose a channel estimation method tailored to operate under DLI conditions and propose a mismatch detector using estimated channel coefficients. Furthermore, we derive a closed-form expression for the probability of error for the detectors and model the quantization noise caused by DLI. Finally, comprehensive simulation results show that the proposed method with 1-bit analog-to-digital converters (ADCs) effectively mitigates DLI, reduces the quantization noise, and enhances backscattered signal energy, achieving performance comparable to the benchmark scenario with 8-bit ADCs.

Paper number 70:
Title: Correct-by-Design Control Synthesis of Stochastic Multi-agent Systems: a Robust Tensor-based Solution
Authors: Ruohan Wang, Siyuan Liu, Zhiyong Sun, Sofie Haesaert
Abstract: Discrete-time stochastic systems with continuous spaces are hard to verify and control, even with MDP abstractions due to the curse of dimensionality. We propose an abstraction-based framework with robust dynamic programming mappings that deliver control strategies with provable lower bounds on temporal-logic satisfaction, quantified via approximate stochastic simulation relations. Exploiting decoupled dynamics, we reveal a Canonical Polyadic Decomposition tensor structure in value functions that makes dynamic programming scalable. The proposed method provides correct-by-design probabilistic guarantees for temporal logic specifications. We validate our results on continuous-state linear stochastic systems.

Paper number 71:
Title: Radio-Coverage-Aware Path Planning for Cooperative Autonomous Vehicles
Authors: Giuseppe Baruffa, Luca Rugini, Francesco Binucci, Fabrizio Frescura, Paolo Banelli, Renzo Perfetti
Abstract: Fleets of autonomous vehicles (AV) often are at the core of intelligent transportation scenarios for smart cities, and may require a wireless Internet connection to offload computer vision tasks to data centers located either in the edge or the cloud section of the network. Cooperation among AVs is successful when the environment is unknown, or changes dynamically, so as to improve coverage and trip time, and minimize the traveled distance. The AVs, while mapping the environment with range-based sensors, move across the wireless coverage areas, with consequences on the achieved access bit rate, latency, and handover rate. In this paper, we propose to modify the cost of path planning algorithms such as Dijkstra and A*, so that not only the traveled distance is considered in the best path solution, but also the radio coverage experience. To this aim, several radio-related cost-weighting functions are introduced and tested, to assess the performance of the proposed techniques with extensive simulations. The proposed mapping algorithm can achieve a mapping error probability below 2%, while the proposed path-planning algorithms extend the experienced radio coverage of the AVs, with limited distance increase with respect to shortest-path existing methods, such as conventional Dijkstra and A* algorithms.

Paper number 72:
Title: Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models
Authors: Siddhartha Mahajan, Harsh Raj, Sonam Tanwar
Abstract: This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning.

Paper number 73:
Title: Real-Time Diverse Fiber Sensing Multi-Event Detection using Phase OTDR Measurements
Authors: Konstantinos Alexoudis, Jasper Müller, Sai Kireet Patri, Vincent A.J.M. Sleiffer, Vishal Chandraprakash Rai, André Sandmann, Sander Jansen, Thomas Bradley, Chigo Okonkwo
Abstract: We demonstrate an experimental phase optical time-domain reflectometry (OTDR) system capable of simultaneous detection and classification of various environmental events, such as wind-induced fiber movement, vehicle movement, and audio signatures, with real-time visualization.

Paper number 74:
Title: On the Redundant Distributed Observability of Mixed Traffic Transportation Systems
Authors: M. Doostmohammadian, U. A. Khan, N. Meskin
Abstract: In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach.

Paper number 75:
Title: MARBLE-Net: Learning to Localize in Multipath Environment with Adaptive Rainbow Beams
Authors: Qiushi Liang, Yeyue Cai, Jianhua Mo, Meixia Tao
Abstract: Integrated sensing and communication (ISAC) systems demand precise and efficient target localization, a task challenged by rich multipath propagation in complex wireless environments. This paper introduces MARBLE-Net (Multipath-Aware Rainbow Beam Learning Network), a deep learning framework that jointly optimizes the analog beamforming parameters of a frequency-dependent rainbow beam and a neural localization network for high-accuracy position estimation. By treating the phase-shifter (PS) and true-time-delay (TTD) parameters as learnable weights, the system adaptively refines its sensing beam to exploit environment-specific multipath characteristics. A structured multi-stage training strategy is proposed to ensure stable convergence and effective end-to-end optimization. Simulation results show that MARBLE-Net outperforms both a fixed-beam deep learning baseline (RaiNet) and a traditional k-nearest neighbors (k-NN) method, reducing localization error by more than 50\% in a multipath-rich scene. Moreover, the results reveal a nuanced interaction with multipath propagation: while confined uni-directional multipath degrades accuracy, structured and directional multipath can be effectively exploited to achieve performance surpassing even line-of-sight (LoS) conditions.

Paper number 76:
Title: Capacity Estimation of Lithium-ion Batteries Using Invariance Property in Open Circuit Voltage Relationship
Authors: Yang Wang, Marta Zagorowska, Riccardo M.G. Ferrari
Abstract: Lithium-ion (Li-ion) batteries are ubiquitous in electric vehicles (EVs) as efficient energy storage devices. The reliable operation of Li-ion batteries depends critically on the accurate estimation of battery capacity. However, conventional estimation methods require extensive training datasets from costly battery tests for modeling, and a full cycle of charge and discharge is often needed to estimate the capacity. To overcome these limitations, we propose a novel capacity estimation method that leverages only one cycle of the open-circuit voltage (OCV) test in modeling and allows for estimating the capacity from partial charge or discharge data. Moreover, by applying it with OCV identification algorithms, we can estimate the capacity from dynamic discharge data without requiring dedicated data collection tests. We observed an invariance property in the OCV versus state of charge relationship across aging cycles. Leveraging this invariance, the proposed method estimates the capacity by solving an OCV alignment problem using only the OCV and the discharge capacity data from the battery. Simulation results demonstrate the method's efficacy, achieving a mean absolute relative error of 0.85\% in capacity estimation across 12 samples from 344 aging cycles.

Paper number 77:
Title: Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation
Authors: Vitor Bueno, Ali Azarbahram, Marcello Farina, Lorenzo Fagiano
Abstract: This paper presents a Koopman-based model predictive control (MPC) framework for safe UAV navigation in dynamic environments using real-time LiDAR data. By leveraging the Koopman operator to linearly approximate the dynamics of surrounding objets, we enable efficient and accurate prediction of the position of moving obstacles. Embedding this into an MPC formulation ensures robust, collision-free trajectory planning suitable for real-time execution. The method is validated through simulation and ROS2-Gazebo implementation, demonstrating reliable performance under sensor noise, actuation delays, and environmental uncertainty.

Paper number 78:
Title: Beyond Phasors: Solving Non-Sinusoidal Electrical Circuits using Geometry
Authors: Javier Castillo-Martínez, Raul Baños, Francisco G. Montoya
Abstract: Classical phasor analysis is fundamentally limited to sinusoidal single-frequency conditions, which poses challenges when working in the presence of harmonics. Furthermore, the conventional solution, which consists of decomposing signals using Fourier series and applying superposition, is a fragmented process that does not provide a unified solution in the frequency domain. This paper overcomes this limitation by introducing a complete and direct approach for multi-harmonic AC circuits using Geometric Algebra (GA). In this way, all non-sinusoidal voltage and current waveforms are represented as simple vectors in a $2N$-dimensional Euclidean space. The relationship between these vectors is characterized by a single and unified geometric transformation termed the \textit{rotoflex}. This operator elevates the concept of impedance from a set of complex numbers per frequency to a single multivector that holistically captures the circuit response, while unifying the magnitude scale (flextance) and phase rotation (rotance) across all harmonics. Thus, this work establishes GA as a structurally unified and efficient alternative to phasor analysis, providing a more rigorous foundation for electrical circuit analysis. The methodology is validated through case studies that demonstrate perfect numerical consistency with traditional methods and superior performance.

Paper number 79:
Title: Design Principles of Zero-Shot Self-Supervised Unknown Emitter Detectors
Authors: Mikhail Krasnov, Ljupcho Milosheski, Mihael Mohorčič, Carolina Fortuna
Abstract: The proliferation of wireless devices necessitates more robust and reliable emitter detection and identification for critical tasks such as spectrum management and network security. Existing studies exploring methods for unknown emitters identification, however, are typically hindered by their dependence on labeled or proprietary datasets, unrealistic assumptions (e.g. all samples with identical transmitted messages), or deficiency of systematic evaluations across different architectures and design dimensions. In this work, we present a comprehensive evaluation of unknown emitter detection systems across key aspects of the design space, focusing on data modality, learning approaches, and feature learn- ing modules. We demonstrate that prior self-supervised, zero-shot emitter detection approaches commonly use datasets with identical transmitted messages. To address this limitation, we propose a 2D- Constellation data modality for scenarios with varying messages, achieving up to a 40\% performance improvement in ROC-AUC, NMI, and F1 metrics compared to conventional raw I/Q data. Furthermore, we introduce interpretable Kolmogorov--Arnold Net- works (KANs) to enhance model transparency, and a Singular Value Decomposition (SVD)-based initialization procedure for feature learning modules operating on sparse 2D-Constellation data, which improves the performance of Deep Clustering approaches by up to 40\% across the same metrics comparing to the modules without SVD initialization. We evaluate all data modalities and learning modules across three learning approaches: Deep Clustering, Auto Encoder and Contrastive Learning.

Paper number 80:
Title: Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT
Authors: Simone Bendazzoli, Antonios Tzortzakakis, Andreas Abrahamsson, Björn Engelbrekt Wahlin, Örjan Smedby, Maria Holstensson, Rodrigo Moreno
Abstract: Early cancer detection is crucial for improving patient outcomes, and 18F FDG PET/CT imaging plays a vital role by combining metabolic and anatomical information. Accurate lesion detection remains challenging due to the need to identify multiple lesions of varying sizes. In this study, we investigate the effect of adding anatomy prior information to deep learning-based lesion detection models. In particular, we add organ segmentation masks from the TotalSegmentator tool as auxiliary inputs to provide anatomical context to nnDetection, which is the state-of-the-art for lesion detection, and Swin Transformer. The latter is trained in two stages that combine self-supervised pre-training and supervised fine-tuning. The method is tested in the AutoPET and Karolinska lymphoma datasets. The results indicate that the inclusion of anatomical priors substantially improves the detection performance within the nnDetection framework, while it has almost no impact on the performance of the vision transformer. Moreover, we observe that Swin Transformer does not offer clear advantages over conventional convolutional neural network (CNN) encoders used in nnDetection. These findings highlight the critical role of the anatomical context in cancer lesion detection, especially in CNN-based models.

Paper number 81:
Title: Real-Time Co-Simulation for DC Microgrid Energy Management with Communication Delays
Authors: S. Gokul Krishnan, Mohd Asim Aftab, Shehab Ahmed, Charalambos Konstantinou
Abstract: The growing integration of renewable energy sources (RESs) in modern power systems has intensified the need for resilient and efficient microgrid solutions. DC microgrids have gained prominence due to their reduced conversion losses, simplified interfacing with DC-based RESs, and improved reliability. To manage the inherent variability of RESs and ensure stable operation, energy management systems (EMS) have become essential. While various EMS algorithms have been proposed and validated using real-time simulation platforms, most assume ideal communication conditions or rely on simplified network models, overlooking the impact of realistic communication delays on EMS performance. This paper presents a novel real-time cyber-physical system (CPS) testbed for evaluating EMS performance in DC microgrids under realistic communication delays. The proposed testbed integrates a DC microgrid modeled in OPAL-RT with an EMS controller implemented on a Raspberry Pi (RPi). The communication network is emulated using EXataCPS, enabling the exchange of actual power system traffic and the replication of realistic latency conditions. This comprehensive setup captures the interplay between power system dynamics, EMS control, and communication network behavior.

Paper number 82:
Title: Structural sign herdability of linear time-invariant systems:theory and design for arbitrary network structures
Authors: Pradeep M, Twinkle Tripathy
Abstract: The objective of this paper is to investigate graph-theoretic conditions for structural herdability of an LTI system. In particular, we are interested in the structural sign (SS) herdability of a system wherein the underlying digraph representing it is signed. Structural herdability finds applications in various domains like power networks, biological networks, opinion dynamics, multi-robot shepherding, etc. We begin the analysis by introducing a layered graph representation Gs of the signed digraph G; such a representation allows us to capture the signed distances between the nodes with ease. We construct a subgraph of G_s that characterizes paths of identical signs between layers and uniform path lengths, referred to as a layer-wise unisigned graph LUG(G_s). A special subgraph of an LUG(G_s), denoted as an LUG^H(G_s), is key to achieving SS herdability. This is because we prove that an LTI system is SS herdable if and only if there exists an LUG^H(G_s) which covers all the nodes of the given digraph. To the best of our knowledge, such a graphical test is one of the first methods which allows us to check SS herdability for arbitrary digraph topologies. Interestingly, the analysis also reveals that a system can be SS herdable even in the presence of (signed and layer) dilation in the associated digraph (note that such a behaviour has been shown to be impossible in directed trees). Additionally, we also extend these results to digraphs with multiple leader and driver nodes. In order to illustrate all the results, we present numerous examples throughout the paper.

Paper number 83:
Title: TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation
Authors: Zidong Chen, Fadratul Hafinaz Hassan
Abstract: Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to "slowly" process low-frequency backgrounds and "quickly" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%.

Paper number 84:
Title: Validation of Fully-Automated Deep Learning-Based Fibroglandular Tissue Segmentation for Efficient and Reliable Quantitation of Background Parenchymal Enhancement in Breast MRI
Authors: Yu-Tzu Kuo, Anum S. Kazerouni, Vivian Y. Park, Wesley Surento, Suleeporn Sujichantararat, Daniel S. Hippe, Habib Rahbar, Savannah C. Partridge
Abstract: Background parenchymal enhancement (BPE) on breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) shows potential as a breast cancer risk marker. Clinically, BPE is qualitatively assessed by radiologists, but quantitative BPE measures offer potential for more precise risk evaluation. This study evaluated an existing open-source, fully-automated deep learning-based (DL-based) method for segmenting fibroglandular tissue (FGT) to quantify BPE and compared it to a semi-automated fuzzy c-means method. Using breast MRI examinations from 100 women, we evaluated segmentation agreement, concordance across quantitative BPE metrics, and associations with qualitative BPE. The quality of FGT segmentations from both methods was scored by a radiologist. While the DL-based and semi-automated methods showed good agreement for quantitative BPE measurements, DL-based measures more strongly correlated with qualitative BPE assessments and DL-based segmentations were scored as higher quality by the radiologist. Our findings suggest that DL-based FGT segmentation enhances efficiency for objective BPE quantification and may improve standardized breast cancer risk assessment.

Paper number 85:
Title: Task-Adaptive Low-Dose CT Reconstruction
Authors: Necati Sefercioglu, Mehmet Ozan Unal, Metin Ertas, Isa Yildirim
Abstract: Deep learning-based low-dose computed tomography reconstruction methods already achieve high performance on standard image quality metrics like peak signal-to-noise ratio and structural similarity index measure. Yet, they frequently fail to preserve the critical anatomical details needed for diagnostic tasks. This fundamental limitation hinders their clinical applicability despite their high metric scores. We propose a novel task-adaptive reconstruction framework that addresses this gap by incorporating a frozen pre-trained task network as a regularization term in the reconstruction loss function. Unlike existing joint-training approaches that simultaneously optimize both reconstruction and task networks, and risk diverging from satisfactory reconstructions, our method leverages a pre-trained task model to guide reconstruction training while still maintaining diagnostic quality. We validate our framework on a liver and liver tumor segmentation task. Our task-adaptive models achieve Dice scores up to 0.707, approaching the performance of full-dose scans (0.874), and substantially outperforming joint-training approaches (0.331) and traditional reconstruction methods (0.626). Critically, our framework can be integrated into any existing deep learning-based reconstruction model through simple loss function modification, enabling widespread adoption for task-adaptive optimization in clinical practice. Our codes are available at: this https URL

Paper number 86:
Title: Characterisation and Quantification of Data Centre Flexibility for Power System Support
Authors: Mehmet Turker Takci, James Day, Meysam Qadrdan
Abstract: The rapid growth of data centres poses an evolving challenge for power systems with high variable renewable energy. Traditionally operated as passive electrical loads, data centres, have the potential to become active participants that provide flexibility to the grid. However, quantifying and utilising this flexibility have not yet been fully explored. This paper presents an integrated, whole facility optimisation model to investigate the least cost operating schedule of data centres and characterise the aggregate flexibility available from data centres to the power system. The model accounts for IT workload shifting, UPS energy storage, and cooling system. Motivated by the need to alleviate the increasing strain on power systems while leveraging their untapped flexibility potential, this study makes two primary contributions: (i) an operational optimisation model that integrates IT scheduling, UPS operation, and cooling dynamics to establish a cost optimal baseline operation, and (ii) a duration-aware flexibility assessment that, for any given start time and power deviation, computes the maximum feasible duration from this baseline while respecting all operational, thermal, and recovery constraints. This method characterises the aggregate flexibility envelope. Results reveal a clear temporal structure and a notable asymmetry in flexibility provision: upward flexibility (electricity load reduction) is driven by deferring IT workload, which allows for a secondary reduction in cooling power. Downward flexibility (electricity load increase) relies on increasing power consumption of the cooling system, supported by the TES buffer, and charging the UPS. This framework translates abstract flexibility potential into quantified flexibility magnitude and duration that system operators could investigate for use in services such as reserve, frequency response, and price responsive demand.

Paper number 87:
Title: Beyond Gaussian Assumptions: A General Fractional HJB Control Framework for Lévy-Driven Heavy-Tailed Channels in 6G
Authors: Mengqi Li, Lixin Li, Wensheng Lin, Zhu Han, Tamer Başar
Abstract: Emerging 6G wireless systems suffer severe performance degradation in challenging environments like high-speed trains traversing dense urban corridors and Unmanned Aerial Vehicles (UAVs) links over mountainous terrain. These scenarios exhibit non-Gaussian, non-stationary channels with heavy-tailed fading and abrupt signal fluctuations. To address these challenges, this paper proposes a novel wireless channel model based on symmetric $\alpha$-stable Lévy processes, thereby enabling continuous-time state-space characterization of both long-term and short-term fading. Building on this model, a generalized optimal control framework is developed via a fractional Hamilton-Jacobi-Bellman (HJB) equation that incorporates the Riesz fractional operator to capture non-local spatial effects and memory-dependent dynamics. The existence and uniqueness of viscosity solutions to the fractional HJB equation are rigorously established, thus ensuring the theoretical validity of the proposed control formulation. Numerical simulations conducted in a multi-cell, multi-user downlink setting demonstrate the effectiveness of the fractional HJB-based strategy in optimizing transmission power under heavy-tailed co-channel and multi-user interference.

Paper number 88:
Title: Trajectory Design for UAV-Assisted Logistics Collection in Low-Altitude Economy
Authors: Zhiyuan Zhai, Yuan Gao, Wei Ni, Xiaojun Yuan, Xin Wang
Abstract: Low-altitude economy (LAE) is rapidly emerging as a key driver of innovation, encompassing economic activities taking place in airspace below 500 meters. Unmanned aerial vehicles (UAVs) provide valuable tools for logistics collection within LAE systems, offering the ability to navigate through complex environments, avoid obstacles, and improve operational efficiency. However, logistics collection tasks involve UAVs flying through complex three-dimensional (3D) environments while avoiding obstacles, where traditional UAV trajectory design methods,typically developed under free-space conditions without explicitly accounting for obstacles, are not applicable. This paper presents, we propose a novel algorithm that combines the Lin-Kernighan-Helsgaun (LKH) and Deep Deterministic Policy Gradient (DDPG) methods to minimize the total collection time. Specifically, the LKH algorithm determines the optimal order of item collection, while the DDPG algorithm designs the flight trajectory between collection points. Simulations demonstrate that the proposed LKH-DDPG algorithm significantly reduces collection time by approximately 49 percent compared to baseline approaches, thereby highlighting its effectiveness in optimizing UAV trajectories and enhancing operational efficiency for logistics collection tasks in the LAE paradigm.

Paper number 89:
Title: Neural Directional Filtering Using a Compact Microphone Array
Authors: Weilong Huang, Srikanth Raj Chetupalli, Mhd Modar Halimeh, Oliver Thiergart, Emanuël Habets
Abstract: Beamforming with desired directivity patterns using compact microphone arrays is essential in many audio applications. Directivity patterns achievable using traditional beamformers depend on the number of microphones and the array aperture. Generally, their effectiveness degrades for compact arrays. To overcome these limitations, we propose a neural directional filtering (NDF) approach that leverages deep neural networks to enable sound capture with a predefined directivity pattern. The NDF computes a single-channel complex mask from the microphone array signals, which is then applied to a reference microphone to produce an output that approximates a virtual directional microphone with the desired directivity pattern. We introduce training strategies and propose data-dependent metrics to evaluate the directivity pattern and directivity factor. We show that the proposed method: i) achieves a frequency-invariant directivity pattern even above the spatial aliasing frequency, ii) can approximate diverse and higher-order patterns, iii) can steer the pattern in different directions, and iv) generalizes to unseen conditions. Lastly, experimental comparisons demonstrate superior performance over conventional beamforming and parametric approaches.

Paper number 90:
Title: Fair and Efficient allocation of Mobility-on-Demand resources through a Karma Economy
Authors: Matteo Cederle, Saverio Bolognani, Gian Antonio Susto
Abstract: Mobility-on-demand systems like ride-hailing have transformed urban transportation, but they have also exacerbated socio-economic inequalities in access to these services, also due to surge pricing strategies. Although several fairness-aware frameworks have been proposed in smart mobility, they often overlook the temporal and situational variability of user urgency that shapes real-world transportation demands. This paper introduces a non-monetary, Karma-based mechanism that models endogenous urgency, allowing user time-sensitivity to evolve in response to system conditions as well as external factors. We develop a theoretical framework maintaining the efficiency and fairness guarantees of classical Karma economies, while accommodating this realistic user behavior modeling. Applied to a simulated mobility-on-demand scenario we show that our framework is able to achieve high levels of system efficiency, guaranteeing at the same time equitable resource allocation for the users.

Paper number 91:
Title: Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models
Authors: Umberto Cappellazzo, Xubo Liu, Pingchuan Ma, Stavros Petridis, Maja Pantic
Abstract: Large language models (LLMs) have recently achieved impressive results in speech recognition across multiple modalities, including Auditory Speech Recognition (ASR), Visual Speech Recognition (VSR), and Audio-Visual Speech Recognition (AVSR). Despite this progress, current LLM-based approaches typically address each task independently, training separate models that raise computational and deployment resource use while missing potential cross-task synergies. They also rely on fixed-rate token compression, which restricts flexibility in balancing accuracy with efficiency. These limitations highlight the need for a unified framework that can support ASR, VSR, and AVSR while enabling elastic inference. To this end, we present Omni-AVSR, a unified audio-visual LLM that combines efficient multi-granularity training with parameter-efficient adaptation. Specifically, we adapt the matryoshka representation learning paradigm to efficiently train across multiple audio and visual granularities, reducing its inherent training resource use. Furthermore, we explore three LoRA-based strategies for adapting the backbone LLM, balancing shared and task-specific specialization. Experiments on LRS2 and LRS3 show that Omni-AVSR achieves comparable or superior accuracy to state-of-the-art baselines while training a single model at substantially lower training and deployment resource use. The model also remains robust under acoustic noise, and we analyze its scaling behavior as LLM size increases, providing insights into the trade-off between performance and efficiency.

Paper number 92:
Title: CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video
Authors: Xinyi Wang, Angeliki Katsenou, Junxiao Shen, David Bull
Abstract: The prevalence of user-generated content (UGC) on platforms such as YouTube and TikTok has rendered no-reference (NR) perceptual video quality assessment (VQA) vital for optimizing video delivery. Nonetheless, the characteristics of non-professional acquisition and the subsequent transcoding of UGC video on sharing platforms present significant challenges for NR-VQA. Although NR-VQA models attempt to infer mean opinion scores (MOS), their modeling of subjective scores for compressed content remains limited due to the absence of fine-grained perceptual annotations of artifact types. To address these challenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits the semantic understanding capabilities of large vision-language models. Our approach introduces a quality-aware prompting mechanism that integrates video metadata (e.g., resolution, frame rate, bitrate) with key fragments extracted from inter-frame variations to guide the BLIP-2 pretraining approach in generating fine-grained quality captions. A unified architecture has been designed to model perceptual quality across three dimensions: semantic alignment, temporal characteristics, and spatial characteristics. These multimodal features are extracted and fused, then regressed to video quality scores. Extensive experiments on a wide variety of UGC datasets demonstrate that our model consistently outperforms existing NR-VQA methods, achieving improved accuracy without the need for costly manual fine-grained annotations. Our method achieves the best performance in terms of average rank and linear correlation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods. The source code and trained models, along with a user-friendly demo, are available at: this https URL.

Paper number 93:
Title: Low-Complexity ADMM-Based Multicast Beamforming in Cell-Free Massive MIMO Systems
Authors: Mahmoud Zaher, Emil Björnson
Abstract: The growing demand for efficient delivery of common content to multiple user equipments (UEs) has motivated significant research in physical-layer multicasting. By exploiting the beamforming capabilities of massive MIMO, multicasting provides a spectrum-efficient solution that avoids unnecessary intra-group interference. A key challenge, however, is solving the max-min fair (MMF) and quality-of-service (QoS) multicast beamforming optimization problems, which are NP-hard due to the non-convex structure and the requirement for rank-1 solutions. Traditional approaches based on semidefinite relaxation (SDR) followed by randomization exhibit poor scalability with system size, while state-of-the-art successive convex approximation (SCA) methods only guarantee convergence to stationary points. In this paper, we propose an alternating direction method of multipliers (ADMM)-based framework for MMF and QoS multicast beamforming in cell-free massive MIMO networks. The algorithm leverages SDR but incorporates a novel iterative elimination strategy within the ADMM updates to efficiently obtain near-global optimal rank-1 beamforming solutions with reduced computational complexity compared to standard SDP solvers and randomization methods. Numerical evaluations demonstrate that the proposed ADMM-based procedure not only achieves superior spectral efficiency but also scales favorably with the number of antennas and UEs compared to state-of-the-art SCA-based algorithms, making it a practical tool for next-generation multicast systems.

Paper number 94:
Title: Beyond Prime Farmland: Solar Siting Tradeoffs for Cost-Effective Decarbonization
Authors: Papa Yaw Owusu-Obeng, Mai Shi, Max Vanatta, Michael T. Craig
Abstract: The feasibility and cost-effectiveness of continued growth in solar photovoltaics are closely tied to siting decisions. But trade-offs between costs and technical potential between land categories, especially brownfields and rooftop sites, have not been quantified, despite increasing resistance to and policy interest in reducing use of greenfield sites (e.g., prime agricultural lands). We examine the effect of siting decisions across land types for utility-scale and rooftop PV on the feasibility and cost of meeting solar deployment targets across the Eastern U.S. We build a database of solar PV supply curves by land type for each county in the Eastern Interconnect (EI) region (~2,400 counties). Our supply curves quantify technical potential versus levelized cost across greenfield, brownfield, and rooftop land types. With these supply curves and a 2035 solar deployment target (435 GW) aligned with a decarbonized power system, we quantify cost and capacity trade-offs using scenarios that prioritize solar PV deployment on different land types. We find greenfield, particularly prime agriculture, sites offer the lowest levelized costs for meeting capacity targets, of 39 to 57 $/MWh. Contaminated lands, often prioritized in policy to reduce land use conflict, have limited technical potential and impose a cost premium of 14-33% relative to greenfield sites. Rooftop PV provides enough technical potential for meeting capacity targets but comes at consistently higher costs, with minimum LCOEs of roughly 70 $/MWh or well above the highest-cost greenfield sites. Our results detail heterogeneous siting trade-offs across the Eastern United States, enabling targeted policy design to meet deployment targets while balancing costs and land use conflicts.

Paper number 95:
Title: Robust Linear Design for Flight Control Systems with Operational Constraints
Authors: Marcel Menner, Eugene Lavretsky
Abstract: This paper presents a systematic approach for designing robust linear proportional-integral (PI) servo-controllers that effectively manage control input and output constraints in flight control systems. The control design leverages the Nagumo Theorem and the Comparison Lemma to prove constraint satisfaction, while employing min-norm optimal controllers in a manner akin to Control Barrier Functions. This results in a continuous piecewise-linear state feedback policy that maintains the analyzability of the closed-loop system through the principles of linear systems theory. Additionally, we derive multi-input multi-output (MIMO) robustness margins, demonstrating that our approach enables robust tracking of external commands even in the presence of operational constraints. Moreover, the proposed control design offers a systematic approach for anti-windup protection. Through flight control trade studies, we illustrate the applicability of the proposed framework to real-world safety-critical aircraft control scenarios. Notably, MIMO margin analysis with active constraints reveals that our method preserves gain and phase margins comparable to those of the unconstrained case, in contrast to controllers that rely on hard saturation heuristics, which suffer significant performance degradation under active constraints. Simulation results using a nonlinear six-degree-of-freedom rigid body aircraft model further validate the effectiveness of our method in achieving constraint satisfaction, robustness, and effective anti-windup protection.

Paper number 96:
Title: When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates
Authors: Cayetana Salinas Rodriguez, Jonathan Rogers, Sarah H.Q. Li
Abstract: We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game.

Paper number 97:
Title: Enhanced GCD through ORBGRAND-AI: Exploiting Partial and Total Correlation in Noise
Authors: Jiewei Feng, Ken R. Duffy, Muriel Médard
Abstract: There have been significant advances in recent years in the development of forward error correction decoders that can decode codes of any structure, including practical realizations in synthesized circuits and taped out chips. While essentially all soft-decision decoders assume that bits have been impacted independently on the channel, for one of these new approaches it has been established that channel dependencies can be exploited to achieve superior decoding accuracy, resulting in Ordered Reliability Bits Guessing Random Additive Noise Decoding Approximate Independence (ORBGRAND-AI). Building on that capability, here we consider the integration of ORBGRAND-AI as a pattern generator for Guessing Codeword Decoding (GCD). We first establish that a direct approach delivers mildly degraded block error rate (BLER) but with reduced number of queried patterns when compared to ORBGRAND-AI. We then show that with a more nuanced approach it is possible to leverage total correlation to deliver an additional BLER improvement of around 0.75 dB while retaining reduced query numbers.

Paper number 98:
Title: The Role of High-Performance GPU Resources in Large Language Model Based Radiology Imaging Diagnosis
Authors: Jyun-Ping Kao
Abstract: Large-language models (LLMs) are rapidly being applied to radiology, enabling automated image interpretation and report generation tasks. Their deployment in clinical practice requires both high diagnostic accuracy and low inference latency, which in turn demands powerful hardware. High-performance graphical processing units (GPUs) provide the necessary compute and memory throughput to run large LLMs on imaging data. We review modern GPU architectures (e.g. NVIDIA A100/H100, AMD Instinct MI250X/MI300) and key performance metrics of floating-point throughput, memory bandwidth, VRAM capacity. We show how these hardware capabilities affect radiology tasks: for example, generating reports or detecting findings on CheXpert and MIMIC-CXR images is computationally intensive and benefits from GPU parallelism and tensor-core acceleration. Empirical studies indicate that using appropriate GPU resources can reduce inference time and improve throughput. We discuss practical challenges including privacy, deployment, cost, power and optimization strategies: mixed-precision, quantization, compression, and multi-GPU scaling. Finally, we anticipate that next-generation features (8-bit tensor cores, enhanced interconnect) will further enable on-premise and federated radiology AI. Advancing GPU infrastructure is essential for safe, efficient LLM-based radiology diagnostics.

Paper number 99:
Title: Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation
Authors: Canxiang Yan, Chunxiang Jin, Dawei Huang, Haibing Yu, Han Peng, Hui Zhan, Jie Gao, Jing Peng, Jingdong Chen, Jun Zhou, Kaimeng Ren, Ming Yang, Mingxue Yang, Qiang Xu, Qin Zhao, Ruijie Xiong, Shaoxiong Lin, Xuezhi Wang, Yi Yuan, Yifei Wu, Yongjie Lyu, Zhengyu He, Zhihao Qiu, Zhiqiang Fang, Ziyuan Huang
Abstract: Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.

Paper number 100:
Title: sMRI-based Brain Age Estimation in MCI using Persistent Homology
Authors: Debanjali Bhattacharya, Neelam Sinha
Abstract: In this study, we propose the use of persistent homology- specifically Betti curves for brain age prediction and for distinguishing between healthy and pathological aging. The proposed framework is applied to 100 structural MRI scans from the publicly available ADNI dataset. Our results indicate that Betti curve features, particularly those from dimension-1 (connected components) and dimension-2 (1D holes), effectively capture structural brain alterations associated with aging. Furthermore, clinical features are grouped into three categories based on their correlation, or lack thereof, with (i) predicted brain age and (ii) chronological age. The findings demonstrate that this approach successfully differentiates normal from pathological aging and provides a novel framework for understanding how structural brain changes relate to cognitive impairment. The proposed method serves as a foundation for developing potential biomarkers for early detection and monitoring of cognitive decline.

Paper number 101:
Title: Selection and Stability of Functional Connectivity Features for Classification of Brain Disorders
Authors: Aniruddha Saha, Soujanya Hazra, Sanjay Ghosh
Abstract: Brain disorders are an umbrella term for a group of neurological and psychiatric conditions that have a major effect on thinking, feeling, and acting. These conditions encompass a wide range of conditions. The illnesses in question pose significant difficulties not only for individuals, but also for healthcare systems all across the world. In this study, we explore the capability of explainable machine learning for classification of people who suffer from brain disorders. This is accomplished by the utilization of brain connection map, also referred as connectome, derived from functional magnetic resonance imaging (fMRI) data. In order to analyze features that are based on the connectome, we investigated several different feature selection procedures. These strategies included the Least Absolute Shrinkage and Selection Operator (LASSO), Relief, and Analysis of Variance (ANOVA), in addition to a logistic regression (LR) classifier. First and foremost, the purpose was to evaluate and contrast the classification accuracy of different feature selection methods in terms of distinguishing healthy controls from diseased individuals. The evaluation of the stability of the traits that were chosen was the second objective. The identification of the regions of the brain that have an effect on the classification was the third main objective. When applied to the UCLA dataset, the LASSO approach, which is our most effective strategy, produced a classification accuracy of 91.85% and a stability index of 0.74, which is greater than the results obtained by other approaches: Relief and ANOVA. These methods are effective in locating trustworthy biomarkers, which adds to the development of connectome-based classification in the context of issues that impact the brain.

Paper number 102:
Title: Gravity-Awareness: Deep Learning Models and LLM Simulation of Human Awareness in Altered Gravity
Authors: Bakytzhan Alibekov, Alina Gutoreva, Elisa Raffaella-Ferre
Abstract: Earth's gravity has fundamentally shaped human development by guiding the brain's integration of vestibular, visual, and proprioceptive inputs into an internal model of gravity: a dynamic neural representation enabling prediction and interpretation of gravitational forces. This work presents a dual computational framework to quantitatively model these adaptations. The first component is a lightweight Multi-Layer Perceptron (MLP) that predicts g-load-dependent changes in key electroencephalographic (EEG) frequency bands, representing the brain's cortical state. The second component utilizes a suite of independent Gaussian Processes (GPs) to model the body's broader physiological state, including Heart Rate Variability (HRV), Electrodermal Activity (EDA), and motor behavior. Both models were trained on data derived from a comprehensive review of parabolic flight literature, using published findings as anchor points to construct robust, continuous functions. To complement this quantitative analysis, we simulated subjective human experience under different gravitational loads, ranging from microgravity (0g) and partial gravity (Moon 0.17g, Mars 0.38g) to hypergravity associated with spacecraft launch and re-entry (1.8g), using a large language model (Claude 3.5 Sonnet). The model was prompted with physiological parameters to generate introspective narratives of alertness and self-awareness, which closely aligned with the quantitative findings from both the EEG and physiological models. This combined framework integrates quantitative physiological modeling with generative cognitive simulation, offering a novel approach to understanding and predicting human performance in altered gravity

Paper number 103:
Title: Diffusion-Based Image Editing: An Unforeseen Adversary to Robust Invisible Watermarks
Authors: Wenkai Fu, Finn Carter, Yue Wang, Emily Davis, Bo Zhang
Abstract: Robust invisible watermarking aims to embed hidden messages into images such that they survive various manipulations while remaining imperceptible. However, powerful diffusion-based image generation and editing models now enable realistic content-preserving transformations that can inadvertently remove or distort embedded watermarks. In this paper, we present a theoretical and empirical analysis demonstrating that diffusion-based image editing can effectively break state-of-the-art robust watermarks designed to withstand conventional distortions. We analyze how the iterative noising and denoising process of diffusion models degrades embedded watermark signals, and provide formal proofs that under certain conditions a diffusion model's regenerated image retains virtually no detectable watermark information. Building on this insight, we propose a diffusion-driven attack that uses generative image regeneration to erase watermarks from a given image. Furthermore, we introduce an enhanced \emph{guided diffusion} attack that explicitly targets the watermark during generation by integrating the watermark decoder into the sampling loop. We evaluate our approaches on multiple recent deep learning watermarking schemes (e.g., StegaStamp, TrustMark, and VINE) and demonstrate that diffusion-based editing can reduce watermark decoding accuracy to near-zero levels while preserving high visual fidelity of the images. Our findings reveal a fundamental vulnerability in current robust watermarking techniques against generative model-based edits, underscoring the need for new watermarking strategies in the era of generative AI.

Paper number 104:
Title: Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots
Authors: Justin Williams, Kishor Datta Gupta, Roy George, Mrinmoy Sarkar
Abstract: The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations.

Paper number 105:
Title: STAIR: Stability criterion for Time-windowed Assignment and Internal adversarial influence in Routing and decision-making
Authors: Roee M. Francos, Daniel Garces, Orhan Eren Akgün, Stephanie Gil
Abstract: A major limitation of existing routing algorithms for multi-agent systems is that they are designed without considering the potential presence of adversarial agents in the decision-making loop, which could lead to severe performance degradation in real-life applications where adversarial agents may be present. We study autonomous pickup-and-delivery routing problems in which adversarial agents launch coordinated denial-of-service attacks by spoofing their locations. This deception causes the central scheduler to assign pickup requests to adversarial agents instead of cooperative agents. Adversarial agents then choose not to service the requests with the goal of disrupting the operation of the system, leading to delays, cancellations, and potential instability in the routing policy. Policy stability in routing problems is typically defined as the cost of the policy being uniformly bounded over time, and it has been studied through two different lenses: queuing theory and reinforcement learning (RL), which are not well suited for routing with adversaries. In this paper, we propose a new stability criterion, STAIR, which is easier to analyze than queuing-theory-based stability in adversarial settings. Furthermore, STAIR does not depend on a chosen discount factor as is the case in discounted RL stability. STAIR directly links stability to desired operational metrics, like a finite number of rejected requests. This characterization is particularly useful in adversarial settings as it provides a metric for monitoring the effect of adversaries in the operation of the system. Furthermore, we demonstrate STAIR's practical relevance through simulations on real-world San Francisco mobility-on-demand data. We also identify a phenomenon of degenerate stability that arises in the adversarial routing problem, and we introduce time-window constraints in the decision-making algorithm to mitigate it.

Paper number 106:
Title: Controller-Light CI/CD with Jenkins: Remote Container Builds and Automated Artifact Delivery
Authors: Kawshik Kumar Paul, Sawmik Kumar Paul
Abstract: Traditional Jenkins installations often perform resource-intensive builds directly on the controller, which can overload system resources and decrease reliability. This paper presents a controller-light CI/CD framework in which Jenkins runs as a containerized controller with persistent volumes, delegating heavy build and packaging operations to a remote Docker host. The controller container maintains secure SSH connections to remote compute nodes and focuses solely on orchestration and reporting. Atomic deployments with time-stamped backups, containerized build environments, immutable artifact packaging, and automatic notifications are all integrated into the system. Experimental evaluation shows reduced CPU and RAM usage on the controller, faster build throughput, and lower artifact delivery latency. For small and medium-sized DevOps organizations looking for scalable automation without adding orchestration complexity, this method offers a repeatable, low-maintenance CI/CD pipeline.

Paper number 107:
Title: QiVC-Net: Quantum-Inspired Variational Convolutional Network, with Application to Biosignal Classification
Authors: Amin Golnari, Jamileh Yousefi, Reza Moheimani, Saeid Sanei
Abstract: This work introduces the quantum-inspired variational convolution (QiVC) framework, a novel learning paradigm that integrates principles of probabilistic inference, variational optimization, and quantum-inspired transformations within convolutional architectures. The central innovation of QiVC lies in its quantum-inspired rotated ensemble (QiRE) mechanism. QiRE performs differentiable low-dimensional subspace rotations of convolutional weights, analogously to quantum state evolution. This approach enables structured uncertainty modeling while preserving the intrinsic geometry of the parameter space, resulting in more expressive, stable, and uncertainty-aware representations. To demonstrate its practical potential, the concept is instantiated in a QiVC-based convolutional network (QiVC-Net) and evaluated in the context of biosignal classification, focusing on phonocardiogram (PCG) recordings, a challenging domain characterized by high noise, inter-subject variability, and often imbalanced data. The proposed QiVC-Net integrates an architecture in which the QiVC layer does not introduce additional parameters, instead performing an ensemble rotation of the convolutional weights through a structured mechanism ensuring robustness without added highly computational burden. Experiments on two benchmark datasets, PhysioNet CinC 2016 and PhysioNet CirCor DigiScope 2022, show that QiVC-Net achieves state-of-the-art performance, reaching accuracies of 97.84% and 97.89%, respectively. These findings highlight the versatility of the QiVC framework and its promise for advancing uncertainty-aware modeling in real-world biomedical signal analysis. The implementation of the QiVConv layer is openly available in GitHub.

Paper number 108:
Title: Adaptive Time Budgets for Safe and Comfortable Vehicle Control Transition in Conditionally Automated Driving
Authors: Kexin Liang, Simeon C. Calvert, J.W.C. van Lint
Abstract: Conditionally automated driving requires drivers to resume vehicle control promptly when automation reaches its operational limits. Ensuring smooth vehicle control transitions is critical for the safety and efficiency of mixed-traffic transportation systems, where complex interactions and variable traffic behaviors pose additional challenges. This study addresses this challenge by introducing an adaptive time budget framework that provides drivers with sufficient time to complete takeovers both safely and comfortably across diverse scenarios. We focus in particular on the takeover buffer, that is, the extra time available after drivers consciously resume control to complete evasive maneuvers. A driving simulator experiment is conducted to evaluate the influence of different takeover buffer lengths on safety-related indicators (minimum time-to-collision, maximum deceleration, and steering wheel angle) and subjective assessments (perceived time sufficiency, perceived risk, and performance satisfaction). Results show that (i) takeover buffers of about 5-6 seconds consistently lead to optimal safety and comfort; and (ii) drivers prefer relatively stable takeover buffers across varying traffic densities and n-back tasks. This study introduces an adaptive time budget framework that dynamically allocates transition time by incorporating a predicted takeover time and a preferred takeover buffer (piecewise function). This can serve as an important first step toward providing drivers with sufficient time to resume vehicle control across diverse scenarios, which needs to be validated in more diverse and real-world driving contexts. By aligning the provided time budget with driver needs under specific circumstances, the adaptive framework can improve reliability of control transitions, facilitate human-centered automated driving, reduce crash risk, and maintain overall traffic efficiency.

Paper number 109:
Title: Signal and Image Recovery with Scale and Signed Permutation Invariant Sparsity-Promoting Functions
Authors: Jianqing Jia, Ashley Prater-Bennette, Lixin Shen
Abstract: Sparse signal recovery has been a cornerstone of advancements in data processing and imaging. Recently, the squared ratio of $\ell_1$ to $\ell_2$ norms, $(\ell_1/\ell_2)^2$, has been introduced as a sparsity-prompting function, showing superior performance compared to traditional $\ell_1$ minimization, particularly in challenging scenarios with high coherence and dynamic range. This paper explores the integration of the proximity operator of $(\ell_1/\ell_2)^2$ and $\ell_1/\ell_2$ into efficient optimization frameworks, including the Accelerated Proximal Gradient (APG) and Alternating Direction Method of Multipliers (ADMM). We rigorously analyze the convergence properties of these algorithms and demonstrate their effectiveness in compressed sensing and image restoration applications. Numerical experiments highlight the advantages of our proposed methods in terms of recovery accuracy and computational efficiency, particularly under noise and high-coherence conditions.

Paper number 110:
Title: Catching Contamination Before Generation: Spectral Kill Switches for Agents
Authors: Valentin Noël
Abstract: Agentic language models compose multi step reasoning chains, yet intermediate steps can be corrupted by inconsistent context, retrieval errors, or adversarial inputs, which makes post hoc evaluation too late because errors propagate before detection. We introduce a diagnostic that requires no additional training and uses only the forward pass to emit a binary accept or reject signal during agent execution. The method analyzes token graphs induced by attention and computes two spectral statistics in early layers, namely the high frequency energy ratio and spectral entropy. We formalize these signals, establish invariances, and provide finite sample estimators with uncertainty quantification. Under a two regime mixture assumption with a monotone likelihood ratio property, we show that a single threshold on the high frequency energy ratio is optimal in the Bayes sense for detecting context inconsistency. Empirically, the high frequency energy ratio exhibits robust bimodality during context verification across multiple model families, which enables gating decisions with overhead below one millisecond on our hardware and configurations. We demonstrate integration into retrieval augmented agent pipelines and discuss deployment as an inline safety monitor. The approach detects contamination while the model is still processing the text, before errors commit to the reasoning chain.

Paper number 111:
Title: Enhancing Diffusion Model Guidance through Calibration and Regularization
Authors: Seyed Alireza Javid, Amirhossein Bagheri, Nuria González-Prelcic
Abstract: Classifier-guided diffusion models have emerged as a powerful approach for conditional image generation, but they suffer from overconfident predictions during early denoising steps, causing the guidance gradient to vanish. This paper introduces two complementary contributions to address this issue. First, we propose a differentiable calibration objective based on the Smooth Expected Calibration Error (Smooth ECE), which improves classifier calibration with minimal fine-tuning and yields measurable improvements in Frechet Inception Distance (FID). Second, we develop enhanced sampling guidance methods that operate on off-the-shelf classifiers without requiring retraining. These include tilted sampling with batch-level reweighting, adaptive entropy-regularized sampling to preserve diversity, and a novel f-divergence-based sampling strategy that strengthens class-consistent guidance while maintaining mode coverage. Experiments on ImageNet 128x128 demonstrate that our divergence-regularized guidance achieves an FID of 2.13 using a ResNet-101 classifier, improving upon existing classifier-guided diffusion methods while requiring no diffusion model retraining. The results show that principled calibration and divergence-aware sampling provide practical and effective improvements for classifier-guided diffusion.

Paper number 112:
Title: Who Gets Heard? Rethinking Fairness in AI for Music Systems
Authors: Atharva Mehta, Shivam Chauhan, Megha Sharma, Gus Xia, Kaustuv Kanti Ganguli, Nishanth Chandran, Zeerak Talat, Monojit Choudhury
Abstract: In recent years, the music research community has examined risks of AI models for music, with generative AI models in particular, raised concerns about copyright, deepfakes, and transparency. In our work, we raise concerns about cultural and genre biases in AI for music systems (music-AI systems) which affect stakeholders including creators, distributors, and listeners shaping representation in AI for music. These biases can misrepresent marginalized traditions, especially from the Global South, producing inauthentic outputs (e.g., distorted ragas) that reduces creators' trust on these systems. Such harms risk reinforcing biases, limiting creativity, and contributing to cultural erasure. To address this, we offer recommendations at dataset, model and interface level in music-AI systems.

Paper number 113:
Title: Multiscale aperture synthesis imager
Authors: Ruihai Wang, Qianhao Zhao, Tianbo Wang, Mitchell Modarelli, Peter Vouras, Zikun Ma, Zhixuan Hong, Kazunori Hoshino, David Brady, Guoan Zheng
Abstract: Synthetic aperture imaging has enabled breakthrough observations from radar to astronomy. However, optical implementation remains challenging due to stringent wavefield synchronization requirements among multiple receivers. Here we present the multiscale aperture synthesis imager (MASI), which utilizes parallelism to break complex optical challenges into tractable sub-problems. MASI employs a distributed array of coded sensors that operate independently yet coherently to surpass the diffraction limit of single receiver. It combines the propagated wavefields from individual sensors through a computational phase synchronization scheme, eliminating the need for overlapping measurement regions to establish phase coherence. Light diffraction in MASI naturally expands the imaging field, generating phase-contrast visualizations that are substantially larger than sensor dimensions. Without using lenses, MASI resolves sub-micron features at ultralong working distances and reconstructs 3D shapes over centimeter-scale fields. MASI transforms the intractable optical synchronization problem into a computational one, enabling practical deployment of scalable synthetic aperture systems at optical wavelengths.

Paper number 114:
Title: Deep-ultraviolet ptychographic pocket-scope (DART): mesoscale lensless molecular imaging with label-free spectroscopic contrast
Authors: Ruihai Wang, Qianhao Zhao, Julia Quinn, Liming Yang, Yuhui Zhu, Feifei Huang, Chengfei Guo, Tianbo Wang, Pengming Song, Michael Murphy, Thanh D. Nguyen, Andrew Maiden, Francisco E. Robles, Guoan Zheng
Abstract: The mesoscale characterization of biological specimens has traditionally required compromises between resolution, field-of-view, depth-of-field, and molecular specificity, with most approaches relying on external labels. Here we present the Deep-ultrAviolet ptychogRaphic pockeT-scope (DART), a handheld platform that transforms label-free molecular imaging through intrinsic deep-ultraviolet spectroscopic contrast. By leveraging biomolecules' natural absorption fingerprints and combining them with lensless ptychographic microscopy, DART resolves down to 308-nm linewidths across centimeter-scale areas while maintaining millimeter-scale depth-of-field. The system's virtual error-bin methodology effectively eliminates artifacts from limited temporal coherence and other optical imperfections, enabling high-fidelity molecular imaging without lenses. Through differential spectroscopic imaging at deep-ultraviolet wavelengths, DART quantitatively maps nucleic acid and protein distributions with femtogram sensitivity, providing an intrinsic basis for explainable virtual staining. We demonstrate DART's capabilities through molecular imaging of tissue sections, cytopathology specimens, blood cells, and neural populations, revealing detailed molecular contrast without external labels. The combination of high-resolution molecular mapping and broad mesoscale imaging in a portable platform opens new possibilities from rapid clinical diagnostics, tissue analysis, to biological characterization in space exploration.

Paper number 115:
Title: Video-rate gigapixel ptychography via space-time neural field representations
Authors: Ruihai Wang, Qianhao Zhao, Zhixuan Hong, Qiong Ma, Tianbo Wang, Lingzhi Jiang, Liming Yang, Shaowei Jiang, Feifei Huang, Thanh D. Nguyen, Leslie Shor, Daniel Gage, Mary Lipton, Christopher Anderton, Arunima Bhattacharjee, David Brady, Guoan Zheng
Abstract: Achieving gigapixel space-bandwidth products (SBP) at video rates represents a fundamental challenge in imaging science. Here we demonstrate video-rate ptychography that overcomes this barrier by exploiting spatiotemporal correlations through neural field representations. Our approach factorizes the space-time volume into low-rank spatial and temporal features, transforming SBP scaling from sequential measurements to efficient correlation extraction. The architecture employs dual networks for decoding real and imaginary field components, avoiding phase-wrapping discontinuities plagued in amplitude-phase representations. A gradient-domain loss on spatial derivatives ensures robust convergence. We demonstrate video-rate gigapixel imaging with centimeter-scale coverage while resolving 308-nm linewidths. Validations span from monitoring sample dynamics of crystals, bacteria, stem cells, microneedle to characterizing time-varying probes in extreme ultraviolet experiments, demonstrating versatility across wavelengths. By transforming temporal variations from a constraint into exploitable correlations, we establish that gigapixel video is tractable with single-sensor measurements, making ptychography a high-throughput sensing tool for monitoring mesoscale dynamics without lenses.

Paper number 116:
Title: Secret Protection in Labeled Petri Nets
Authors: Stefan Haar, Tomáš Masopust, Jakub Večeřa
Abstract: We study the secret protection problem (SPP), where the objective is to find a policy of minimal cost ensuring that every execution path from an initial state to a secret state contains a sufficient number of protected events. The problem was originally introduced and studied in the setting of finite automata. In this paper, we extend the framework to labeled Petri nets. We consider two variants of the problem: the Parikh variant, where all occurrences of protected events along an execution path contribute to the security requirement, and the indicator variant, where each protected event is counted only once per execution path. We show that both variants can be solved in exponential space for labeled Petri nets, and that their decision versions are ExpSpace-complete. As a consequence, there is no polynomial-time or polynomial-space algorithm for these problems.

Paper number 117:
Title: LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling
Authors: Hanlin Sun, Jiayang Li
Abstract: Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models. Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler. Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics. To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions. Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size. The representative-agent design improves scalability, while the separation of reasoning from updating clarifies the decision logic while stabilizing learning. In classic traffic assignment settings, we find that the proposed approach converges rapidly to the user equilibrium. In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.

Paper number 118:
Title: ELEGANCE: Efficient LLM Guidance for Audio-Visual Target Speech Extraction
Authors: Wenxuan Wu, Shuai Wang, Xixin Wu, Helen Meng, Haizhou Li
Abstract: Audio-visual target speaker extraction (AV-TSE) models primarily rely on visual cues from the target speaker. However, humans also leverage linguistic knowledge, such as syntactic constraints, next word prediction, and prior knowledge of conversation, to extract target speech. Inspired by this observation, we propose ELEGANCE, a novel framework that incorporates linguistic knowledge from large language models (LLMs) into AV-TSE models through three distinct guidance strategies: output linguistic constraints, intermediate linguistic prediction, and input linguistic prior. Comprehensive experiments with RoBERTa, Qwen3-0.6B, and Qwen3-4B on two AV-TSE backbones demon- strate the effectiveness of our approach. Significant improvements are observed in challenging scenarios, including visual cue impaired, unseen languages, target speaker switches, increased interfering speakers, and out-of-domain test set. Demo page: this https URL.

Paper number 119:
Title: Precision-Scalable Microscaling Datapaths with Optimized Reduction Tree for Efficient NPU Integration
Authors: Stef Cuyckens, Xiaoling Yi, Robin Geens, Joren Dumoulin, Martin Wiesner, Chao Fang, Marian Verhelst
Abstract: Emerging continual learning applications necessitate next-generation neural processing unit (NPU) platforms to support both training and inference operations. The promising Microscaling (MX) standard enables narrow bit-widths for inference and large dynamic ranges for training. However, existing MX multiply-accumulate (MAC) designs face a critical trade-off: integer accumulation requires expensive conversions from narrow floating-point products, while FP32 accumulation suffers from quantization losses and costly normalization. To address these limitations, we propose a hybrid precision-scalable reduction tree for MX MACs that combines the benefits of both approaches, enabling efficient mixed-precision accumulation with controlled accuracy relaxation. Moreover, we integrate an 8x8 array of these MACs into the state-of-the-art (SotA) NPU integration platform, SNAX, to provide efficient control and data transfer to our optimized precision-scalable MX datapath. We evaluate our design both on MAC and system level and compare it to the SotA. Our integrated system achieves an energy efficiency of 657, 1438-1675, and 4065 GOPS/W, respectively, for MXINT8, MXFP8/6, and MXFP4, with a throughput of 64, 256, and 512 GOPS.

Paper number 120:
Title: Scalable Verification of Neural Control Barrier Functions Using Linear Bound Propagation
Authors: Nikolaus Vertovec, Frederik Baymler Mathiesen, Thom Badings, Luca Laurenti, Alessandro Abate
Abstract: Control barrier functions (CBFs) are a popular tool for safety certification of nonlinear dynamical control systems. Recently, CBFs represented as neural networks have shown great promise due to their expressiveness and applicability to a broad class of dynamics and safety constraints. However, verifying that a trained neural network is indeed a valid CBF is a computational bottleneck that limits the size of the networks that can be used. To overcome this limitation, we present a novel framework for verifying neural CBFs based on piecewise linear upper and lower bounds on the conditions required for a neural network to be a CBF. Our approach is rooted in linear bound propagation (LBP) for neural networks, which we extend to compute bounds on the gradients of the network. Combined with McCormick relaxation, we derive linear upper and lower bounds on the CBF conditions, thereby eliminating the need for computationally expensive verification procedures. Our approach applies to arbitrary control-affine systems and a broad range of nonlinear activation functions. To reduce conservatism, we develop a parallelizable refinement strategy that adaptively refines the regions over which these bounds are computed. Our approach scales to larger neural networks than state-of-the-art verification procedures for CBFs, as demonstrated by our numerical experiments.

Paper number 121:
Title: Privacy-Preserving Federated Learning for Fair and Efficient Urban Traffic Optimization
Authors: Rathin Chandra Shit, Sharmila Subudhi
Abstract: The optimization of urban traffic is threatened by the complexity of achieving a balance between transport efficiency and the maintenance of privacy, as well as the equitable distribution of traffic based on socioeconomically diverse neighborhoods. Current centralized traffic management schemes invade user location privacy and further entrench traffic disparity by offering disadvantaged route suggestions, whereas current federated learning frameworks do not consider fairness constraints in multi-objective traffic settings. This study presents a privacy-preserving federated learning framework, termed FedFair-Traffic, that jointly and simultaneously optimizes travel efficiency, traffic fairness, and differential privacy protection. This is the first attempt to integrate three conflicting objectives to improve urban transportation systems. The proposed methodology enables collaborative learning between related vehicles with data locality by integrating Graph Neural Networks with differential privacy mechanisms ($\epsilon$-privacy guarantees) and Gini coefficient-based fair constraints using multi-objective optimization. The framework uses federated aggregation methods of gradient clipping and noise injection to provide differential privacy and optimize Pareto-efficient solutions for the efficiency-fairness tradeoff. Real-world comprehensive experiments on the METR-LA traffic dataset showed that FedFair-Traffic can reduce the average travel time by 7\% (14.2 minutes) compared with their centralized baselines, promote traffic fairness by 73\% (Gini coefficient, 0.78), and offer high privacy protection (privacy score, 0.8) with an 89\% reduction in communication overhead. These outcomes demonstrate that FedFair-Traffic is a scalable privacy-aware smart city infrastructure with possible use-cases in metropolitan traffic flow control and federated transportation networks.

Paper number 122:
Title: Public Transport Under Epidemic Conditions: Nonlinear Trade-Offs Between Risk and Accessibility
Authors: Gerhard Hiermann, Joana Ji, Ana Moreno, Rolf Moeckel, Maximilian Schiffer
Abstract: Epidemics expose critical tensions between protecting public health and maintaining essential urban mobility. Public transport systems face this dilemma most acutely: they enable access to jobs, education, and services, yet also facilitate close contact among travelers. We develop an integrated modeling framework that couples agent-based epidemic simulation (EpiSim) with an optimization-based public transport flow model under capacity constraints. Using Munich as a case study, we analyze how combinations of facility closures and transport restrictions shape epidemic outcomes and accessibility. The results reveal three key insights. First, epidemic interventions redistribute rather than simply reduce infection risks, shifting transmission to households. Second, epidemic and transport policies interact nonlinearly - moderate demand suppression can offset large capacity cuts. Third, epidemic pressures amplify temporal and spatial inequalities, disproportionately affecting peripheral and peak-hour travelers. These findings highlight that blanket restrictions are both inefficient and inequitable, calling for targeted, time- and space-differentiated measures to build epidemic-resilient and socially fair transport systems.

Paper number 123:
Title: From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies
Authors: Ralf Römer, Julian Balletshofer, Jakob Thumm, Marco Pavone, Angela P. Schoellig, Matthias Althoff
Abstract: Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: this https URL.

Paper number 124:
Title: EchoMark: Perceptual Acoustic Environment Transfer with Watermark-Embedded Room Impulse Response
Authors: Chenpei Huang, Lingfeng Yao, Kyu In Lee, Lan Emily Zhang, Xun Chen, Miao Pan
Abstract: Acoustic Environment Matching (AEM) is the task of transferring clean audio into a target acoustic environment, enabling engaging applications such as audio dubbing and auditory immersive virtual reality (VR). Recovering similar room impulse response (RIR) directly from reverberant speech offers more accessible and flexible AEM solution. However, this capability also introduces vulnerabilities of arbitrary ``relocation" if misused by malicious user, such as facilitating advanced voice spoofing attacks or undermining the authenticity of recorded evidence. To address this issue, we propose EchoMark, the first deep learning-based AEM framework that generates perceptually similar RIRs with embedded watermark. Our design tackle the challenges posed by variable RIR characteristics, such as different durations and energy decays, by operating in the latent domain. By jointly optimizing the model with a perceptual loss for RIR reconstruction and a loss for watermark detection, EchoMark achieves both high-quality environment transfer and reliable watermark recovery. Experiments on diverse datasets validate that EchoMark achieves room acoustic parameter matching performance comparable to FiNS, the state-of-the-art RIR estimator. Furthermore, a high Mean Opinion Score (MOS) of 4.22 out of 5, watermark detection accuracy exceeding 99\%, and bit error rates (BER) below 0.3\% collectively demonstrate the effectiveness of EchoMark in preserving perceptual quality while ensuring reliable watermark embedding.

Paper number 125:
Title: Learning Time-Varying Graph Signals via Koopman
Authors: Sivaram Krishnan, Jinho Choi, Jihong Park
Abstract: A wide variety of real-world data, such as sea measurements, e.g., temperatures collected by distributed sensors and multiple unmanned aerial vehicles (UAV) trajectories, can be naturally represented as graphs, often exhibiting non-Euclidean structures. These graph representations may evolve over time, forming time-varying graphs. Effectively modeling and analyzing such dynamic graph data is critical for tasks like predicting graph evolution and reconstructing missing graph data. In this paper, we propose a framework based on the Koopman autoencoder (KAE) to handle time-varying graph data. Specifically, we assume the existence of a hidden non-linear dynamical system, where the state vector corresponds to the graph embedding of the time-varying graph signals. To capture the evolving graph structures, the graph data is first converted into a vector time series through graph embedding, representing the structural information in a finite-dimensional latent space. In this latent space, the KAE is applied to learn the underlying non-linear dynamics governing the temporal evolution of graph features, enabling both prediction and reconstruction tasks.

Paper number 126:
Title: Differential Space-Time Block Coding for Phase-Unsynchronized Cell-Free MIMO Downlink
Authors: Marx M. M. Freitas, Giovanni Interdonato, Stefano Buzzi
Abstract: In the downlink of a cell-free massive multiple-input multiple-output (CF-mMIMO) system, spectral efficiency gains critically rely on joint coherent transmission, as all access points (APs) must align their transmitted signals in phase at the user equipment (UE). Achieving such phase alignment is technically challenging, as it requires tight synchronization among geographically distributed APs. In this paper, we address this issue by introducing a differential space-time block coding (DSTBC) approach that bypasses the need for AP phase synchronization. We first provide analytic bounds to the achievable spectral efficiency of CF-mMIMO with phase-unsynchronized APs. Then, we propose a DSTBC-based transmission scheme specifically tailored to CF-mMIMO, which operates without channel state information and does not require any form of phase synchronization among the APs. We derive a closed-form expression for the resulting signal-to-interference-plus-noise ratio (SINR), enabling quantitative comparisons among different DSTBC schemes. Numerical simulations confirm that phase misalignments can significantly impair system performance. In contrast, the proposed DSTBC scheme successfully mitigates these effects, achieving performance comparable to that of fully synchronized systems.

Paper number 127:
Title: On Driftless Systems with m controls and 2m or 2m-1 states that are Flat by Pure Prolongation
Authors: Jean Lévine, Jaume Franch
Abstract: It is widely recognized that no tractable necessary and sufficient conditions exist for determining whether a system is, in general, differentially flat. However, specific cases do provide such conditions. For instance, driftless systems with two inputs have known necessary and sufficient conditions. For driftless systems with three or more inputs, the available conditions are only sufficient. This paper presents new findings on determining whether a system with m inputs and $2m$ or $2m-1$ states is flat by pure prolongation, a specific subclass of differential flatness. While this condition is more restrictive than general differential flatness, the algorithm for computing flat outputs remains remarkably simple, and the verification requirements are relatively lenient. Moreover, the conditions proposed in this work broaden the class of systems recognized as differentially flat, as our sufficient condition differs from existing criteria.

Paper number 128:
Title: Efficient Approximation of Volterra Series for High-Dimensional Systems
Authors: Navin Khoshnan, Claudia K Petritsch, Bryce-Allen Bagley
Abstract: The identification of high-dimensional nonlinear dynamical systems via the Volterra series has significant potential, but has been severely hindered by the curse of dimensionality. Tensor Network (TN) methods such as the Modified Alternating Linear Scheme (MVMALS) have been a breakthrough for the field, offering a tractable approach by exploiting the low-rank structure in Volterra kernels. However, these techniques still encounter prohibitive computational and memory bottlenecks due to high-order polynomial scaling with respect to input dimension. To overcome this barrier, we introduce the Tensor Head Averaging (THA) algorithm, which significantly reduces complexity by constructing an ensemble of localized MVMALS models trained on small subsets of the input space. In this paper, we present a theoretical foundation for the THA algorithm. We establish observable, finite-sample bounds on the error between the THA ensemble and a full MVMALS model, and we derive an exact decomposition of the squared error. This decomposition is used to analyze the manner in which subset models implicitly compensate for omitted dynamics. We quantify this effect, and prove that correlation between the included and omitted dynamics creates an optimization incentive which drives THA's performance toward accuracy superior to a simple truncation of a full MVMALS model. THA thus offers a scalable and theoretically grounded approach for identifying previously intractable high-dimensional systems.

Paper number 129:
Title: Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring
Authors: Kaustubh Singh, Shivam Kumar, Shashikant Pawar, Sandeep Manjanna
Abstract: In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on

Paper number 130:
Title: MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical Decision-Making
Authors: Zhi Rui Tam, Yun-Nung Chen
Abstract: As large language models transition from text-based interfaces to audio interactions in clinical settings, they might introduce new vulnerabilities through paralinguistic cues in audio. We evaluated these models on 170 clinical cases, each synthesized into speech from 36 distinct voice profiles spanning variations in age, gender, and emotion. Our findings reveal a severe modality bias: surgical recommendations for audio inputs varied by as much as 35% compared to identical text-based inputs, with one model providing 80% fewer recommendations. Further analysis uncovered age disparities of up to 12% between young and elderly voices, which persisted in most models despite chain-of-thought prompting. While explicit reasoning successfully eliminated gender bias, the impact of emotion was not detected due to poor recognition performance. These results demonstrate that audio LLMs are susceptible to making clinical decisions based on a patient's voice characteristics rather than medical evidence, a flaw that risks perpetuating healthcare disparities. We conclude that bias-aware architectures are essential and urgently needed before the clinical deployment of these models.

Paper number 131:
Title: Wireless Sensor Networks Nodes Clustering and Optimization Based on Fuzzy C-Means and Water Strider Algorithms
Authors: Raya Majid Alsharfa, Mahmood Mohassel Feghhi, Majid Hameed Majeed
Abstract: Wireless sensor networks (WSNs) face critical challenges in energy management and network lifetime optimization due to limited battery resources and communication overhead. This study introduces a novel hybrid clustering protocol that integrates the Water Strider Algorithm (WSA) with Fuzzy C-Means (FCM) clustering to achieve superior energy efficiency and network longevity. The proposed WSA-FCM method employs WSA for global optimization of cluster- head positions and FCM for refined node membership assignment with fuzzy boundaries. Through extensive experimentation across networks of 200-800 nodes with 10 independent simulation runs, the method demonstrates significant improvements: First Node Death (FND) delayed by 16.1% ($678\pm12$ vs $584\pm18$ rounds), Last Node Death (LND) extended by 11.9% ($1,262\pm8$ vs $1,128\pm11$ rounds), and 37.4% higher residual energy retention ($5.47\pm0.09$ vs $3.98\pm0.11$ J) compared to state-of-the-art hybrid methods. Intra-cluster distances are reduced by 19.4% with statistical significance (p < 0.001). Theoretical analysis proves convergence guarantees and complexity bounds of $O(n\times c\times T)$, while empirical scalability analysis demonstrates near-linear scaling behaviour. The method outperforms recent hybrid approaches including MOALO-FCM, MSSO-MST, Fuzzy+HHO, and GWO-FCM across all performance metrics with rigorous statistical validation.

Paper number 132:
Title: ASTER: Attention-based Spiking Transformer Engine for Event-driven Reasoning
Authors: Tamoghno Das, Khanh Phan Vu, Hanning Chen, Hyunwoo Oh, Mohsen Imani
Abstract: The integration of spiking neural networks (SNNs) with transformer-based architectures has opened new opportunities for bio-inspired low-power, event-driven visual reasoning on edge devices. However, the high temporal resolution and binary nature of spike-driven computation introduce architectural mismatches with conventional digital hardware (CPU/GPU). Prior neuromorphic and Processing-in-Memory (PIM) accelerators struggle with high sparsity and complex operations prevalent in such models. To address these challenges, we propose a memory-centric hardware accelerator tailored for spiking transformers, optimized for deployment in real-time event-driven frameworks such as classification with both static and event-based input frames. Our design leverages a hybrid analog-digital PIM architecture with input sparsity optimizations, and a custom-designed dataflow to minimize memory access overhead and maximize data reuse under spatiotemporal sparsity, for compute and memory-efficient end-to-end execution of spiking transformers. We subsequently propose inference-time software optimizations for layer skipping, and timestep reduction, leveraging Bayesian Optimization with surrogate modeling to perform robust, efficient co-exploration of the joint algorithmic-microarchitectural design spaces under tight computational budgets. Evaluated on both image(ImageNet) and event-based (CIFAR-10 DVS, DVSGesture) classification, the accelerator achieves up to ~467x and ~1.86x energy reduction compared to edge GPU (Jetson Orin Nano) and previous PIM accelerators for spiking transformers, while maintaining competitive task accuracy on ImageNet dataset. This work enables a new class of intelligent ubiquitous edge AI, built using spiking transformer acceleration for low-power, real-time visual processing at the extreme edge.

Paper number 133:
Title: Vision-Based System Identification of a Quadrotor
Authors: Selim Ahmet Iz, Mustafa Unel
Abstract: This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes.

Paper number 134:
Title: Aerial Image Stitching Using IMU Data from a UAV
Authors: Selim Ahmet Iz, Mustafa Unel
Abstract: Unmanned Aerial Vehicles (UAVs) are widely used for aerial photography and remote sensing applications. One of the main challenges is to stitch together multiple images into a single high-resolution image that covers a large area. Featurebased image stitching algorithms are commonly used but can suffer from errors and ambiguities in feature detection and matching. To address this, several approaches have been proposed, including using bundle adjustment techniques or direct image alignment. In this paper, we present a novel method that uses a combination of IMU data and computer vision techniques for stitching images captured by a UAV. Our method involves several steps such as estimating the displacement and rotation of the UAV between consecutive images, correcting for perspective distortion, and computing a homography matrix. We then use a standard image stitching algorithm to align and blend the images together. Our proposed method leverages the additional information provided by the IMU data, corrects for various sources of distortion, and can be easily integrated into existing UAV workflows. Our experiments demonstrate the effectiveness and robustness of our method, outperforming some of the existing feature-based image stitching algorithms in terms of accuracy and reliability, particularly in challenging scenarios such as large displacements, rotations, and variations in camera pose.

Paper number 135:
Title: Experimental Validation of Reflective Near-Field Beamfocusing using a b-bit RIS
Authors: Emil Björnson, Murat Babek Salman
Abstract: This paper presents the first experimental validation of reflective near-field beamfocusing using a reconfigurable intelligent surface (RIS). While beamfocusing has been theoretically established as a key feature of large-aperture RISs, its practical realization has remained unexplored. We derive new analytical expressions for the array gain achieved with a $b$-bit RIS in near-field line-of-sight scenarios, characterizing both the finite depth and angular width of the focal region. The theoretical results are validated through a series of measurements in an indoor office environment at 28 GHz using a one-bit 1024-element RIS. The experiments confirm that near-field beamfocusing can be dynamically achieved and accurately predicted by the proposed analytical model, despite the presence of hardware imperfections and multipath propagation. These findings demonstrate that near-field beamfocusing is a robust and practically viable feature of RIS-assisted wireless communications.

Paper number 136:
Title: A Provably-Correct and Robust Convex Model for Smooth Separable NMF
Authors: Junjun Pan, Valentin Leplat, Michael Ng, Nicolas Gillis
Abstract: Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.

Paper number 137:
Title: On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation
Authors: Matteo Pettenó, Alessandro Ilic Mezza, Alberto Bernardini
Abstract: Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regularization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.

Paper number 138:
Title: Generating Novel and Realistic Speakers for Voice Conversion
Authors: Meiying Melissa Chen, Zhenyu Wang, Zhiyao Duan
Abstract: Voice conversion models modify timbre while preserving paralinguistic features, enabling applications like dubbing and identity protection. However, most VC systems require access to target utterances, limiting their use when target data is unavailable or when users desire conversion to entirely novel, unseen voices. To address this, we introduce a lightweight method SpeakerVAE to generate novel speakers for VC. Our approach uses a deep hierarchical variational autoencoder to model the speaker timbre space. By sampling from the trained model, we generate novel speaker representations for voice synthesis in a VC pipeline. The proposed method is a flexible plug-in module compatible with various VC models, without co-training or fine-tuning of the base VC system. We evaluated our approach with state-of-the-art VC models: FACodec and CosyVoice2. The results demonstrate that our method successfully generates novel, unseen speakers with quality comparable to that of the training speakers.

Paper number 139:
Title: Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation
Authors: Matteo Pettenó, Alessandro Ilic Mezza, Alberto Bernardini
Abstract: Recent advances in latent diffusion models have demonstrated state-of-the-art performance in high-dimensional time-series data synthesis while providing flexible control through conditioning and guidance. However, existing methodologies primarily rely on musical context or natural language as the main modality of interacting with the generative process, which may not be ideal for expert users who seek precise fader-like control over specific musical attributes. In this work, we explore the application of denoising diffusion processes as plug-and-play latent constraints for unconditional symbolic music generation models. We focus on a framework that leverages a library of small conditional diffusion models operating as implicit probabilistic priors on the latents of a frozen unconditional backbone. While previous studies have explored domain-specific use cases, this work, to the best of our knowledge, is the first to demonstrate the versatility of such an approach across a diverse array of musical attributes, such as note density, pitch range, contour, and rhythm complexity. Our experiments show that diffusion-driven constraints outperform traditional attribute regularization and other latent constraints architectures, achieving significantly stronger correlations between target and generated attributes while maintaining high perceptual quality and diversity.

Paper number 140:
Title: Generating Piano Music with Transformers: A Comparative Study of Scale, Data, and Metrics
Authors: Jonathan Lehmkuhl, Ábel Ilyés-Kun, Nico Bremes, Cemhan Kaan Özaltan, Frederik Muthers, Jiayi Yuan
Abstract: Although a variety of transformers have been proposed for symbolic music generation in recent years, there is still little comprehensive study on how specific design choices affect the quality of the generated music. In this work, we systematically compare different datasets, model architectures, model sizes, and training strategies for the task of symbolic piano music generation. To support model development and evaluation, we examine a range of quantitative metrics and analyze how well they correlate with human judgment collected through listening studies. Our best-performing model, a 950M-parameter transformer trained on 80K MIDI files from diverse genres, produces outputs that are often rated as human-composed in a Turing-style listening survey.

Paper number 141:
Title: Roundabout Constrained Convex Generators: A Unified Framework for Multiply-Connected Reachable Sets
Authors: Peng Xie, Sabin Diaconescu, Florin Stoican, Amr Alanwar
Abstract: This paper introduces Roundabout Constrained Convex Generators (RCGs), a set representation framework for modeling multiply connected regions in control and verification applications. The RCG representation extends the constrained convex generators framework by incorporating an inner exclusion zone, creating sets with topological holes that naturally arise in collision avoidance and safety-critical control problems. We present two equivalent formulations: a set difference representation that provides geometric intuition and a unified parametric representation that facilitates computational implementation. The paper establishes closure properties under fundamental operations, including linear transformations, Minkowski sums, and intersections with convex generator sets. We derive special cases, including roundabout zonotopes and roundabout ellipsotopes, which offer computational advantages for specific norm selections. The framework maintains compatibility with existing optimization solvers while enabling the representation of non-convex feasible regions that were previously challenging to model efficiently.

Paper number 142:
Title: Modeling Unsteady Aircraft Aerodynamics Using Lorenz Attractor: A Reduced-Order Approach for Wing Rock
Authors: Marcel Menner, Eugene Lavretsky
Abstract: This paper presents a novel modeling approach for unsteady aircraft airflow, leveraging the Lorenz attractor framework. The proposed model is based on the force distribution exerted by a lift-generating wing on the surrounding fluid. It distinguishes between turbulent and nominal components of the force distribution, with the nominal force distribution modeled to peak at the wing and decay linearly into the free stream. This separation allows the turbulent component to be represented by a transport equation that is influenced by flight conditions, specifically dynamic pressure and angle of attack. Consequently, the Navier-Stokes equations, along with the turbulence transport equation, can be transformed into a reduced-order model characterized by three scalar ordinary differential equations - similar to the Lorenz attractor. This resulting system effectively captures chaotic behavior, facilitating the exploration of complex dynamics without the computational demands of solving the full Navier-Stokes equations. A simulation trade study is conducted that models wing rock phenomena at high angles of attack, demonstrating the effectiveness of the proposed approach in capturing the intricate dynamics of unsteady aircraft aerodynamics.

Paper number 143:
Title: Privacy in Speech Technology
Authors: Tom Bäckström
Abstract: Speech technology for communication, accessing information, and services has rapidly improved in quality. It is convenient and appealing because speech is the primary mode of communication for humans. Such technology, however, also presents proven threats to privacy. Speech is a tool for communication and it will thus inherently contain private information. Importantly, it however also contains a wealth of side information, such as information related to health, emotions, affiliations, and relationships, all of which are private. Exposing such private information can lead to serious threats such as price gouging, harassment, extortion, and stalking. This paper is a tutorial on privacy issues related to speech technology, modeling their threats, approaches for protecting users' privacy, measuring the performance of privacy-protecting methods, perception of privacy as well as societal and legal consequences. In addition to a tutorial overview, it also presents lines for further development where improvements are most urgently needed.

Paper number 144:
Title: From Discrete to Continuous Binary Best-Response Dynamics: Discrete Fluctuations Almost Surely Vanish with Population Size
Authors: Azadeh Aghaeeyan, Pouria Ramazi
Abstract: In binary decision-making, individuals often choose either the rare or the common action. In the framework of evolutionary game theory, the best-response update rule can be used to model this dichotomy. Those who prefer the common action are called \emph{coordinators}, and those who prefer the rare one are called \emph{anticoordinators}. A finite mixed population of the two types may undergo perpetual fluctuations, the characterization of which appears to be challenging. It is particularly unknown whether the fluctuations persist as population size grows. To fill this gap, we approximate the discrete finite population dynamics of coordinators and anticoordinators with the associated mean dynamics in the form of differential inclusions. We show that the family of the state sequences of the discrete dynamics for increasing population sizes forms a generalized stochastic approximation process for the differential inclusion. On the other hand, we show that the differential inclusions always converge to an equilibrium. This implies that the reported perpetual fluctuations in the finite discrete dynamics of coordinators and anticoordinators almost surely vanish with population size. The results encourage to first analyze the often simpler {continuous-time} mean dynamics of the discrete population dynamics as the continuous-time dynamics partly reveal the asymptotic behavior of the discrete dynamics.

Paper number 145:
Title: Intent Demonstration in General-Sum Dynamic Games via Iterative Linear-Quadratic Approximations
Authors: Jingqi Li, Anand Siththaranjan, Somayeh Sojoudi, Claire Tomlin, Andrea Bajcsy
Abstract: Autonomous agents should coordinate effectively without prior knowledge of others' intents. While prior work has focused on intent inference, we address the inverse problem: how agents can strategically demonstrate their intents within general-sum dynamic games. We model this problem and propose an algorithm that balances intent demonstration with task performance. To handle nonlinear dynamic games with continuous state-action spaces, our method leverages iterative linear-quadratic game approximations and provides efficient intent-teaching guarantees: the uncertain agent's belief can be driven rapidly to the ground truth, while the demonstrating agent avoids expending effort on unnecessary belief alignment when it does not improve task performance. Theoretical analysis and hardware experiments confirm that our approach enables the demonstrating agent to reconcile task execution with belief alignment and strategically manage the information asymmetry among agents, even as its intent evolves during deployment.

Paper number 146:
Title: X-Diffusion: Generating Detailed 3D MRI Volumes From a Single Image Using Cross-Sectional Diffusion Models
Authors: Emmanuelle Bourigault, Abdullah Hamdi, Amir Jamaludin
Abstract: Magnetic Resonance Imaging (MRI) is a crucial diagnostic tool, but high-resolution scans are often slow and expensive due to extensive data acquisition requirements. Traditional MRI reconstruction methods aim to expedite this process by filling in missing frequency components in the K-space, performing 3D-to-3D reconstructions that demand full 3D scans. In contrast, we introduce X-Diffusion, a novel cross-sectional diffusion model that reconstructs detailed 3D MRI volumes from extremely sparse spatial-domain inputs, achieving 2D-to-3D reconstruction from as little as a single 2D MRI slice or few slices. A key aspect of X-Diffusion is that it models MRI data as holistic 3D volumes during the cross-sectional training and inference, unlike previous learning approaches that treat MRI scans as collections of 2D slices in standard planes (coronal, axial, sagittal). We evaluated X-Diffusion on brain tumor MRIs from the BRATS dataset and full-body MRIs from the UK Biobank dataset. Our results demonstrate that X-Diffusion not only surpasses state-of-the-art methods in quantitative accuracy (PSNR) on unseen data but also preserves critical anatomical features such as tumor profiles, spine curvature, and brain volume. Remarkably, the model generalizes beyond the training domain, successfully reconstructing knee MRIs despite being trained exclusively on brain data. Medical expert evaluations further confirm the clinical relevance and fidelity of the generated images. To our knowledge, X-Diffusion is the first method capable of producing detailed 3D MRIs from highly limited 2D input data, potentially accelerating MRI acquisition and reducing associated costs. The code is available on the project website this https URL .

Paper number 147:
Title: Evaluating BM3D and NBNet: A Comprehensive Study of Image Denoising Across Multiple Datasets
Authors: Ghazal Kaviani, Reza Marzban, Ghassan AlRegib
Abstract: This paper investigates image denoising, comparing traditional non-learning-based techniques, represented by Block-Matching 3D (BM3D), with modern learning-based methods, exemplified by NBNet. We assess these approaches across diverse datasets, including CURE-OR, CURE-TSR, SSID+, Set-12, and Chest-Xray, each presenting unique noise challenges. Our analysis employs seven Image Quality Assessment (IQA) metrics and examines the impact on object detection performance. We find that while BM3D excels in scenarios like blur challenges, NBNet is more effective in complex noise environments such as under-exposure and over-exposure. The study reveals the strengths and limitations of each method, providing insights into the effectiveness of different denoising strategies in varied real-world applications.

Paper number 148:
Title: Enhancing Multimodal Medical Image Classification using Cross-Graph Modal Contrastive Learning
Authors: Jun-En Ding, Chien-Chin Hsu, Chi-Hsiang Chu, Shuqiang Wang, Feng Liu
Abstract: The classification of medical images is a pivotal aspect of disease diagnosis, often enhanced by deep learning techniques. However, traditional approaches typically focus on unimodal medical image data, neglecting the integration of diverse non-image patient data. This paper proposes a novel Cross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal structured data from different data domains to improve medical image classification. The model effectively integrates both image and non-image data by constructing cross-modality graphs and leveraging contrastive learning to align multimodal features in a shared latent space. An inter-modality feature scaling module further optimizes the representation learning process by reducing the gap between heterogeneous modalities. The proposed approach is evaluated on two datasets: a Parkinson's disease (PD) dataset and a public melanoma dataset. Results demonstrate that CGMCL outperforms conventional unimodal methods in accuracy, interpretability, and early disease prediction. Additionally, the method shows superior performance in multi-class melanoma classification. The CGMCL framework provides valuable insights into medical image classification while offering improved disease interpretability and predictive capabilities.

Paper number 149:
Title: Parameterized TDOA: TDOA estimation for mobile target localization in a time-division broadcast positioning system
Authors: Chenxin Tu, Xiaowei Cui, Gang Liu, Sihao Zhao, Mingquan Lu
Abstract: In a time-division broadcast positioning system (TDBPS), localizing mobile targets using classical time difference of arrival (TDOA) methods poses significant challenges. Concurrent TDOA measurements are infeasible because targets receive signals from different anchors and extract their transmission times at different reception times, as well as at varying positions. Traditional TDOA estimation schemes implicitly assume that the target remains stationary during the measurement period, which is impractical for mobile targets exhibiting high dynamics. Existing methods for mobile target localization are mostly specialized and rely on motion modeling and do not rely on the concurrent TDOA measurements. This issue limits their direct use of the well-established classical TDOA-based localization methods and complicating the entire localization process. In this paper, to obtain concurrent TDOA estimates at any instant out of the sequential measurements for direct use of existing TDOA-based localization methods, we propose a novel TDOA estimation method, termed parameterized TDOA (P-TDOA). By approximating the time-varying TDOA as a polynomial function over a short period, we transform the TDOA estimation problem into a model parameter estimation problem and derive the desired TDOA estimates thereafter. Theoretical analysis shows that, under certain conditions, the proposed P-TDOA method closely approaches the Cramer-Rao Lower Bound (CRLB) for TDOA estimation in concurrent measurement scenarios, despite measurements being obtained sequentially. Extensive numerical simulations validate our theoretical analysis and demonstrate the effectiveness of the proposed method, highlighting substantial improvements over existing approaches across various scenarios.

Paper number 150:
Title: MAROON: A Dataset for the Joint Characterization of Near-Field High-Resolution Radio-Frequency and Optical Depth Imaging Techniques
Authors: Vanessa Wirth, Johanna Bräunig, Nikolai Hofmann, Martin Vossiek, Tim Weyrich, Marc Stamminger
Abstract: Utilizing the complementary strengths of wavelength-specific range or depth sensors is crucial for robust computer-assisted tasks such as autonomous driving. Despite this, there is still little research done at the intersection of optical depth sensors and radars operating close range, where the target is decimeters away from the sensors. Together with a growing interest in high-resolution imaging radars operating in the near field, the question arises how these sensors behave in comparison to their traditional optical counterparts. In this work, we take on the unique challenge of jointly characterizing depth imagers from both, the optical and radio-frequency domain using a multimodal spatial calibration. We collect data from four depth imagers, with three optical sensors of varying operation principle and an imaging radar. We provide a comprehensive evaluation of their depth measurements with respect to distinct object materials, geometries, and object-to-sensor distances. Specifically, we reveal scattering effects of partially transmissive materials and investigate the response of radio-frequency signals. All object measurements will be made public in form of a multimodal dataset, called MAROON.

Paper number 151:
Title: Spectral Efficiency of Low Earth Orbit Satellite Constellations
Authors: Cuneyd Ozturk, Dongning Guo, Randall A. Berry, Michael L.Honig
Abstract: This paper investigates the maximum achievable downlink spectral efficiency of low Earth orbit (LEO) satellite constellations. Spectral efficiency is defined here as the total network sum rate per unit bandwidth per unit area of Earth's surface. To estimate an upper bound on spectral efficiency, the problem is reduced to a single-channel network model, where all satellites and ground terminals operate over a common narrowband frequency channel. Within this model a regular configuration is proposed and evaluated, with satellites and terminals arranged in hexagonal lattices. Numerical results validate that this configuration provides a robust upper bound for spectral efficiency in more complex multi-channel LEO networks, especially when satellite-terminal associations are based on minimum distance. Further improvements are achieved by adjusting association rules to prevent neighboring satellites from simultaneously serving terminals in the same region, highlighting the critical role of interference-aware association strategies.

Paper number 152:
Title: Bidding in Ancillary Service Markets: An Analytical Approach Using Extreme Value Theory
Authors: Torine Reed Herstad, Jalal Kazempour, Lesia Mitridati, Bert Zwart
Abstract: To enable the participation of stochastic distributed energy resources in ancillary service markets, the Danish transmission system operator, Energinet, mandates that flexibility providers satisfy a minimum 90% reliability requirement for reserve bids. This paper examines the bidding strategy of an electric vehicle aggregator under this regulation and develops a chance-constrained optimization model. In contrast to conventional sample-based approaches that demand large datasets to capture uncertainty, we propose an analytical reformulation that leverages extreme value theory to characterize the tail behavior of flexibility distributions. A case study with real-world charging data from 1400 residential electric vehicles in Denmark demonstrates that the analytical solution improves out-of-sample reliability, reducing bid violation rates by up to 8% relative to a sample-based benchmark. The method is also computationally more efficient, solving optimization problems up to 4.8 times faster while requiring substantially fewer samples to ensure compliance. Moreover, the proposed approach enables the construction of feasible bids with reliability levels as high as 99.95%, which would otherwise require prohibitively large scenario sets under the sample-based method. Beyond its computational and reliability advantages, the framework also provides actionable insights into how reliability thresholds influence aggregator bidding behavior and market participation. This study establishes a regulation-compliant, tractable, and risk-aware bidding methodology for stochastic flexibility aggregators, enhancing both market efficiency and power system security.

Paper number 153:
Title: Unsupervised Multi-Parameter Inverse Solving for Reducing Ring Artifacts in 3D X-Ray CBCT
Authors: Qing Wu, Hongjiang Wei, Jingyi Yu, Yuyao Zhang
Abstract: Ring artifacts are prevalent in 3D cone-beam computed tomography (CBCT) due to non-ideal responses of X-ray detectors, substantially affecting image quality and diagnostic reliability. Existing state-of-the-art (SOTA) ring artifact reduction (RAR) methods rely on supervised learning with large-scale paired CT datasets. While effective in-domain, supervised methods tend to struggle to fully capture the physical characteristics of ring artifacts, leading to pronounced performance drops in complex real-world acquisitions. Moreover, their scalability to 3D CBCT is limited by high memory demands. In this work, we propose Riner, a new unsupervised RAR method. Based on a theoretical analysis of ring artifact formation, we reformulate RAR as a multi-parameter inverse problem, where the non-ideal responses of X-ray detectors are parameterized as solvable physical variables. Using a new differentiable forward model, Riner can jointly learn the implicit neural representation of artifact-free images and estimate the physical parameters directly from CT measurements, without external training data. Additionally, Riner is memory-friendly due to its ray-based optimization, enhancing its usability in large-scale 3D CBCT. Experiments on both simulated and real-world datasets show Riner outperforms existing SOTA supervised methods.

Paper number 154:
Title: Fixed-Time Input-to-State Stability for Singularly Perturbed Systems via Composite Lyapunov Functions
Authors: Michael Tang, Miroslav Krstic, Jorge Poveda
Abstract: We study singularly perturbed systems that exhibit input-to-state stability (ISS) with fixed-time properties in the presence of bounded disturbances. In these systems, solutions converge to the origin within a time frame independent of initial conditions when undisturbed, and to a vicinity of the origin when subjected to bounded disturbances. First, we extend the traditional composite Lyapunov method, commonly applied in singular perturbation theory to analyze asymptotic stability, to include fixed-time ISS. We demonstrate that if both the reduced system and the boundary layer system exhibit fixed-time ISS, and if certain interconnection conditions are met, the entire multi-time scale system retains this fixed-time ISS characteristic, provided the separation of time scales is sufficiently pronounced. Next, we illustrate our findings via analytical and numerical examples, including a novel application in fixed-time feedback optimization for dynamic plants with slowly varying cost functions.

Paper number 155:
Title: Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked Diffusion
Authors: Zekun Zhou, Tan Liu, Bing Yu, Yanru Gong, Liu Shi, Qiegen Liu
Abstract: Diffusion model shows remarkable potential on sparse-view computed tomography (SVCT) reconstruction. However, when a network is trained on a limited sample space, its generalization capability may be constrained, which degrades performance on unfamiliar data. For image generation tasks, this can lead to issues such as blurry details and inconsistencies between regions. To alleviate this problem, we propose a Sinogram-based Wavelet random decomposition And Random mask diffusion Model (SWARM) for SVCT reconstruction. Specifically, introducing a random mask strategy in the sinogram effectively expands the limited training sample space. This enables the model to learn a broader range of data distributions, enhancing its understanding and generalization of data uncertainty. In addition, applying a random training strategy to the high-frequency components of the sinogram wavelet enhances feature representation and improves the ability to capture details in different frequency bands, thereby improving performance and robustness. Two-stage iterative reconstruction method is adopted to ensure the global consistency of the reconstructed image while refining its details. Experimental results demonstrate that SWARM outperforms competing approaches in both quantitative and qualitative performance across various datasets.

Paper number 156:
Title: Retrieving Filter Spectra in CNN for Explainable Sleep Stage Classification
Authors: Stephan Goerttler, Yucheng Wang, Fei He, Min Wu
Abstract: Despite significant advances in deep learning-based sleep stage classification, the clinical adoption of automatic classification models remains slow. One key challenge is the lack of explainability, as many models function as black boxes with millions of parameters. In response, recent work has increasingly focussed on enhancing model explainability. This study contributes to these efforts by introducing an explainability tool for spectral processing of individual EEG channels. Specifically, this tools retrieves the filter spectrum of low-level convolutional feature extraction and compares it with the classification-relevant spectral information in the data. We apply our tool on the EEGNet and MSA-CNN models using the ISRUC-S3 and Sleep-EDF-20 datasets. The tool reveals that spectral processing plays a significant role in the lower frequency bands. In addition, comparing the correlation between filter spectrum and data-derived spectral information with univariate performance indicates that the model naturally prioritises the most informative channels in a multimodal setting. We specify how these insights can be leveraged to enhance model performance. The code for the filter spectrum retrieval and its analysis is available at this https URL.

Paper number 157:
Title: Network-Realised Model Predictive Control Part I: NRF-Enabled Closed-loop Decomposition
Authors: Andrei Sperilă, Alessio Iovine, Sorin Olaru, Patrick Panciatici
Abstract: A two-layer control architecture is proposed, which promotes scalable implementations for constraint-based decision strategies, such as model predictive controllers. The bottom layer is based upon a distributed feedback-feedforward scheme, which directs the controlled network's information flow according to a pre-specified communication infrastructure. Explicit expressions for the resulting closed-loop maps are obtained, and an offline model-matching procedure is proposed for designing the first layer. The obtained control laws are deployed via distributed state-space-based implementations, and the resulting closed-loop models enable predictive control design for the constraint management procedure described in our companion paper.

Paper number 158:
Title: Network-Realised Model Predictive Control Part II: Distributed Constraint Management
Authors: Andrei Sperilă, Alessio Iovine, Sorin Olaru, Patrick Panciatici
Abstract: A two-layer control architecture is proposed, which promotes scalable implementations for model predictive controllers. The top layer acts as both reference governor for the bottom layer, and as a feedback controller for the regulated network. By employing set-based methods, global theoretical guarantees are obtained by enforcing local constraints upon the network's variables and upon those of the first layer's implementation. The proposed technique offers recursive feasibility guarantees as one of its central features, and the expressions of the resulting predictive strategies bear a striking resemblance to classical formulations from model predictive control literature, allowing for flexible and easily customizable implementations.

Paper number 159:
Title: Adaptive Convolution for CNN-based Speech Enhancement Models
Authors: Dahan Wang, Xiaobin Rong, Shiruo Sun, Yuxiang Hu, Changbao Zhu, Jing Lu
Abstract: Deep learning-based speech enhancement methods have significantly improved speech quality and intelligibility. Convolutional neural networks (CNNs) have been proven to be essential components of many high-performance models. In this paper, we introduce adaptive convolution, an efficient and versatile convolutional module that enhances the model's capability to adaptively represent speech signals. Adaptive convolution performs frame-wise causal dynamic convolution, generating time-varying kernels for each frame by assembling multiple parallel candidate kernels. A lightweight attention mechanism is proposed for adaptive convolution, leveraging both current and historical information to assign adaptive weights to each candidate kernel. This enables the convolution operation to adapt to frame-level speech spectral features, leading to more efficient extraction and reconstruction. We integrate adaptive convolution into various CNN-based models, highlighting its generalizability. Experimental results demonstrate that adaptive convolution significantly improves the performance with negligible increases in computational complexity, especially for lightweight models. Moreover, we present an intuitive analysis revealing a strong correlation between kernel selection and signal characteristics. Furthermore, we propose the adaptive convolutional recurrent network (AdaptCRN), an ultra-lightweight model that incorporates adaptive convolution and an efficient encoder-decoder design, achieving superior performance compared to models with similar or even higher computational costs.

Paper number 160:
Title: Distributed Coordination for Heterogeneous Non-Terrestrial Networks
Authors: Jikang Deng, Hui Zhou, Mohamed-Slim Alouini
Abstract: To achieve global coverage and ubiquitous connectivity, the non-terrestrial network (NTN) has been regarded as a key enabler in the sixth generation (6G) network, which includes uncrewed aerial vehicles (UAVs), high-altitude platforms (HAPs), and satellites. Since the unique characteristics of various NTN platforms strongly affect their implementation and lead to a highly dynamic and heterogeneous NTN scenario, achieving distributed coordination remains an important research direction. However, the explicit and systematic analysis of the individual layers' challenges and corresponding distributed coordination solutions in heterogeneous NTNs has not been proposed yet. Therefore, in this paper, we summarize the unique characteristics of each NTN platform, identify communication challenges within individual layers, and propose potential delay-tolerant or delay-sensitive coordinated solutions accordingly. We further analyse the feasibility of leveraging multi-agent deep reinforcement learning (MADRL) algorithms to achieve the proposed coordinated solutions. Finally, we present a case study of the joint scheduling and trajectory optimization problem in heterogeneous NTN, where a two-timescale multi-agent deep deterministic policy gradient (TTS-MADDPG) algorithm is developed to validate the effectiveness of distributed coordination.

Paper number 161:
Title: A Unified Approach to Enforce Non-Negativity Constraint in Neural Network Approximation for Optimal Voltage Regulation
Authors: Jiaqi Wu, Jingyi Yuan, Yang Weng, Guangwen Wang
Abstract: Power system voltage regulation is crucial to maintain power quality while integrating intermittent renewable resources in distribution grids. However, the system model on the grid edge is often unknown, making it difficult to model physical equations for optimal control. Therefore, previous work proposes structured data-driven methods like input convex neural networks (ICNN) for "optimal" control without relying on a physical model. While ICNNs offer theoretical guarantees based on restrictive assumptions of non-negative neural network parameters, can one improve the approximation power with an extra step on negative duplication of inputs? We show that such added mirroring step fails to improve accuracy, as a linear combination of the original input and duplicated input is equivalent to a linear operation of ICNN's input without duplication. While this design can not improve performance, we propose a unified approach to embed the non-negativity constraint as a regularized optimization of the neural network, contrary to the existing methods, which added a loosely integrated second step for post-processing on parameter negation. Our integration directly ties back-propagation to simultaneously minimizing the approximation error while enforcing the convexity constraints. Numerical experiments validate the issues of the mirroring method and show that our integrated objective can avoid problems such as unstable training and non-convergence existing in other methods for optimal control. (preprint)

Paper number 162:
Title: System Identification Under Multi-rate Sensing Environment
Authors: Hiroshi Okajima, Risa Furukawa, Nobutomo Matsunaga
Abstract: This paper proposes a system identification algorithm for systems with multi-rate sensors in a discrete-time framework. It is challenging to obtain an accurate mathematical model when the ratios of inputs and outputs are different in the system. A cyclic reformulation-based model for multi-rate systems is formulated, and the multi-rate system can be reduced to a linear time-invariant system to derive the model under the multi-rate sensing environment. The proposed algorithm integrates a cyclic reformulation with a state coordinate transformation of the cycled system to enable precise identification of systems under the multi-rate sensing environment. The effectiveness of the proposed system identification method is demonstrated using numerical simulations.

Paper number 163:
Title: Safe On-Orbit Dislodging of Deployable Structures via Robust Adaptive MPC
Authors: Longsen Gao, Claus Danielson, Andrew Kwas, Rafael Fierro
Abstract: This paper proposes a novel robust adaptive model predictive controller for on-orbit dislodging. We study orbit dislodging where a servicing spacecraft uses a robotic arm to free a jammed and unactuated solar panel mounted on a hybrid hinge that acts as a time-varying client on a space station. Our method couples online set-membership identification with a robust adaptive MPC to enforce safety under bounded disturbances. The controller explicitly balances exploration to excite the system and shrink uncertainty and exploitation to improve control performance through a dual-mode cost. The feasibility of the developed robust adaptive MPC method is also examined through dislodging simulations and hardware experiments in freefall and terrestrial laboratory environments, respectively. In addition, the advantages of our method are shown through comparison experiments with several state-of-the-art control schemes for both accuracy of parameter estimation and control performance.

Paper number 164:
Title: Inverted Gaussian Process Optimization for Probabilistic Koopman Operator Discovery
Authors: Abhigyan Majumdar, Navid Mojahed, Shima Nazari
Abstract: Koopman Operator Theory has opened the doors to data-driven learning of globally linear representations of complex nonlinear systems. However, current methodologies for Koopman Operator discovery struggle with uncertainty quantification and the dependency on a finite dictionary of heuristically chosen observable functions. We leverage Gaussian Process Regression (GPR) to learn a probabilistic Koopman linear model from data, while removing the need for heuristic observable specification. We present inverted Gaussian Process optimization based Koopman operator learning (iGPK), an automatic differentiation-based approach to simultaneously learn the observable-operator combination. Our numerical results show that the iGPK method is able to learn complex nonlinearities from simulation data while being resilient to measurement noise in the training data and consistently encapsulating the ground truth in the predictive distribution.

Paper number 165:
Title: Bridging the Gap between Continuous and Informative Discrete Representations by Random Product Quantization
Authors: Xueqing Li, Hao Ma, Zehan Li, Rujin Chen, Boyu Zhu, Ruihao Jing, Jian Kang, Jie Li, Chi Zhang, Xiao-Lei Zhang, Xuelong Li
Abstract: Self-supervised learning (SSL) has become a core technique in speech processing, but the high dimensionality of its representations makes discretization essential for improving efficiency. However, existing discretization methods still suffer from significant information loss, resulting in a notable performance gap compared to continuous representations. To overcome these limitations, we propose two quantization-based discretization methods: Product Quantization (PQ) and Random Product Quantization (RPQ). PQ partitions the original feature space into multiple subspaces and independently quantizes each sub-vector, producing a fused set of discrete units that retain diverse information from different subspaces, thereby mitigating the loss associated with single-cluster quantization. RPQ further enhances representation diversity by randomly sampling a fixed proportion of feature dimensions multiple times to construct sub-vectors, thereby better capturing the variability in the data distribution. Theoretical analysis shows that RPQ reduces the correlation coefficient rho (where 0 <= rho <= 1) between sub-quantizers. Its quantization error is lower-bounded by the product of rho and epsilon-kms, where epsilon-kms denotes the quantization error of a single K-means quantizer. Experimental results on a combined dataset built from LibriSpeech and ML-SUPERB show that PQ and RPQ outperform standard K-means discretization, achieving relative improvements of 21.8 percent and 20.0 percent in WER on LibriSpeech, and 24.1 percent and 19.6 percent in CER on ML-SUPERB, respectively. Moreover, their performance is competitive with, and in some cases even surpasses, that of continuous SSL representations.

Paper number 166:
Title: On the Deployment of RIS-mounted UAV Networks
Authors: Anupam Mondal, Priyadarshi Mukherjee, Sasthi C. Ghosh
Abstract: Reconfigurable intelligent surfaces (RIS) enable smart wireless environments by dynamically controlling signal propagation to enhance communication and localization. Unmanned aerial vehicles (UAVs) can act as flying base stations and thus, improve system performance by avoiding signal blockages. In this paper, we propose a gradient ascent and coordinate search based method to determine the optimal location for a system that consists of a UAV and a RIS, where the UAV serves cellular users (CUs) and the RIS serves device-to-device (D2D) pairs. In particular, by optimizing the net throughput for both the D2D pairs and the CUs, the suggested method establishes the ideal location for the RIS-mounted UAV. We consider both line of sight (LoS) and non-LoS paths for the RIS and UAV to calculate the throughput while accounting for blockages in the system. The numerical results show that the proposed method performs better than the existing approaches in terms of both the net throughput and the user fairness.

Paper number 167:
Title: Data-assimilated model-informed reinforcement learning
Authors: Defne E. Ozan, Andrea Nóvoa, Georgios Rigas, Luca Magri
Abstract: The control of spatio-temporally chaos is challenging because of high dimensionality and unpredictability. Model-free reinforcement learning (RL) discovers optimal control policies by interacting with the system, typically requiring observations of the full physical state. In practice, sensors often provide only partial and noisy measurements (observations) of the system. The objective of this paper is to develop a framework that enables the control of chaotic systems with partial and noisy observability. The proposed method, data-assimilated model-informed reinforcement learning (DA-MIRL), integrates (i) low-order models to approximate high-dimensional dynamics; (ii) sequential data assimilation to correct the model prediction when observations become available; and (iii) an off-policy actor-critic RL algorithm to adaptively learn an optimal control strategy based on the corrected state estimates. We test DA-MIRL on the spatiotemporally chaotic solutions of the Kuramoto-Sivashinsky equation. We estimate the full state of the environment with (i) a physics-based model, here, a coarse-grained model; and (ii) a data-driven model, here, the control-aware echo state network, which is proposed in this paper. We show that DA-MIRL successfully estimates and suppresses the chaotic dynamics of the environment in real time from partial observations and approximate models. This work opens opportunities for the control of partially observable chaotic systems.

Paper number 168:
Title: A Fairness-Aware Strategy for B5G Physical-layer Security Leveraging Reconfigurable Intelligent Surfaces
Authors: Alex Pierron, Michel Barbeau, Luca De Cicco, Jose Rubio-Hernan, Joaquin Garcia-Alfaro
Abstract: Reconfigurable Intelligent Surfaces are composed of physical elements that can dynamically alter electromagnetic wave properties to enhance beamforming and lead to improvements in areas with low coverage properties. When combined with Reinforcement Learning techniques, they have the potential to enhance both system behavior and physical-layer security hardening. In addition to security improvements, it is crucial to consider the concept of fair communication. Reconfigurable Intelligent Surfaces must ensure that User Equipment units receive their signals with adequate strength, without other units being deprived of ser- vice due to insufficient power. In this paper, we address such a problem. We explore the fairness properties of previous work and propose a novel method that aims at obtaining both an efficient and fair duplex Reconfigurable Intelligent Surface-Reinforcement Learning system for multiple legitimate User Equipment units without reducing the level of achieved physical-layer security hardening. In terms of contributions, we uncover a fairness imbalance of a previous physical-layer security hardening solution, validate our findings and report experimental work via simulation results. We also provide an alternative reward strategy to solve the uncovered problems and release both code and datasets to foster further research in the topics of this paper.

Paper number 169:
Title: CT Radiomics-Based Explainable Machine Learning Model for Accurate Differentiation of Malignant and Benign Endometrial Tumors: A Two-Center Study
Authors: Tingrui Zhang, Honglin Wu, Zekun Jiang, Yingying Wang, Rui Ye, Huiming Ni, Chang Liu, Jin Cao, Xuan Sun, Rong Shao, Xiaorong Wei, Yingchun Sun
Abstract: Aimed to develop and validate a CT radiomics-based explainable machine learning model for precise diagnosing malignancy and benignity specifically in endometrial cancer (EC) patients. A total of 83 EC patients from two centers, including 46 with malignant and 37 with benign conditions, were included, with data split into a training set (n=59) and a testing set (n=24). The regions of interest (ROIs) were manually segmented from pre-surgical CT scans, and 1132 radiomic features were extracted from the pre-surgical CT scans using Pyradiomics. Six explainable machine learning (ML) modeling algorithms were implemented respectively, for determining the optimal radiomics pipeline. The diagnostic performance of the radiomic model was evaluated by using sensitivity, specificity, accuracy, precision, F1 score, AUROC, and AUPRC. To enhance clinical understanding and usability, we separately implemented SHAP analysis and feature mapping visualization, and evaluated the calibration curve and decision curve. By comparing six modeling strategies, the Random Forest model emerged as the optimal choice for diagnosing EC, with a training AUROC of 1.00 and a testing AUROC of 0.96. SHAP identified the most important radiomic features, revealing that all selected features were significantly associated with EC (P < 0.05). Radiomics feature maps also provide a feasible assessment tool for clinical applications. Decision Curve Analysis (DCA) indicated a higher net benefit for our model compared to the "All" and "None" strategies, suggesting its clinical utility in identifying high-risk cases and reducing unnecessary interventions. In conclusion, the CT radiomics-based explainable ML model achieved high diagnostic performance, which could be used as an intelligent auxiliary tool for the diagnosis of endometrial cancer.

Paper number 170:
Title: A Data-Driven Approach for Topology Correction in Low Voltage Distribution Networks with PVs
Authors: Dong Liu, Sander Timmerman, Yu Xiang, Ensieh Hosseini, Peter Palensky, Pedro P. Vergara
Abstract: To correct the outdated and incomplete topology of low voltage distribution networks (LVDNs) solely based on voltage magnitudes, a data driven approach is developed based on machine learning algorithms and correlation analysis. Meanwhile, to address the similarity among smart meter (SM) data induced by distributed photovoltaic (PV) systems, a time based SM data selection strategy is combined with the proposed correlation analysis. Unlike offline approaches, the proposed approach uses up to date voltage magnitudes to help distribution system operators determine switch states via supervised learning and refine user feeder connections and customer phase labels through a modified hierarchical clustering algorithm. The feasibility and robustness of the proposed approach are validated using modified real world LVDNs and multiple incomplete SM datasets collected from customers in the Netherlands. The results demonstrate that the time-based SM data selection strategy effectively mitigates its impact on phase identification, and the corrected topology not only improves network observability but also supports network operators in load balancing and PV consumption.

Paper number 171:
Title: General Signal Model and Capacity Limit for Rydberg Quantum Information System
Authors: Jieao Zhu, Linglong Dai
Abstract: Rydberg atomic receivers represent a transformative approach to achieving high-sensitivity, broadband, and miniaturized radio frequency (RF) reception. However, existing static signal models for Rydberg atomic receivers rely on the steady-state assumption of atomic quantum states, which cannot fully describe the signal reception process of dynamic signals. To fill in this gap, in this paper, we present a general model to compute the dynamic signal response of Rydberg atomic receivers in closed form. Specifically, by applying small-signal perturbation techniques to the quantum master equation, we derive closed-form Laplace domain transfer functions that characterize the receiver's dynamic responses to time-varying signal fields. To gain more insights into the quantum-based RF-photocurrent conversion process, we further introduce the concept of quantum transconductance that describes the quantum system as an equivalent classical system. By applying quantum transconductance, we quantify the influence of in-band blackbody radiation (BBR) noise on the atomic receiver sensitivity. Extensive simulations for Rydberg atomic receivers validate the proposed signal model, and demonstrate the possibility of quantum receivers to outperform classical electronic receivers through the improvement of quantum transconductance.

Paper number 172:
Title: Time-Frequency Mode Decomposition: A Morphological Segmentation Framework for Signal Analysis and Its Application
Authors: Wei Zhou, Wei-Jian Li, Desen Zhu, Hongbin Xu, Wei-Xin Ren
Abstract: While time-frequency analysis provides rich representations of multicomponent signals, current signal decomposition methods fail to fully exploit the spatial structure of time-frequency distributions, where components often manifest as morphologically distinct regions. This paper introduces time-frequency mode decomposition (TFMD), a novel framework that reframes signal decomposition as a morphological segmentation task in the time-frequency domain. TFMD constructs a unique TF mask for each component by first identifying high-energy core regions with unsupervised k-means clustering, segmenting them with connected-component labeling and a size filter, and then expanding each core using an iterative competitive dilation algorithm to form the complete TF mask, enabling precise isolation and reconstruction of individual modes. Validation on a comprehensive suite of synthetic signals demonstrates that TFMD accurately identifies the number of components and reconstructs them with high fidelity, particularly excelling in high-noise conditions. A comparative analysis confirms that TFMD offers robust and competitive performance across diverse signal types, outperforming several benchmark methods in both accuracy and computational efficiency. Its practical utility is demonstrated by successfully decomposing a non-stationary wind turbine vibration signal, where a two-stage $\mathrm{TFMD}^2$ approach effectively isolates both the fundamental rotational frequency components and their weaker harmonic components across varying operational speeds. TFMD thus provides an accurate, adaptive, and efficient morphological segmentation framework for multicomponent signal analysis with broad applicability.

Paper number 173:
Title: A multi-dynamic low-rank deep image prior (ML-DIP) for 3D real-time cardiovascular MRI
Authors: Chong Chen, Marc Vornehm, Zhenyu Bu, Preethi Chandrasekaran, Muhammad A. Sultan, Syed M. Arshad, Yingmin Liu, Yuchi Han, Rizwan Ahmad
Abstract: Purpose: To develop a reconstruction framework for 3D real-time cine cardiovascular magnetic resonance (CMR) from highly undersampled data without requiring fully sampled training datasets. Methods: We developed a multi-dynamic low-rank deep image prior (ML-DIP) framework that models spatial image content and deformation fields using separate neural networks. These networks are optimized per scan to reconstruct the dynamic image series directly from undersampled k-space data. ML-DIP was evaluated on (i) a 3D cine digital phantom with simulated premature ventricular contractions (PVCs), (ii) ten healthy subjects (including two scanned during both rest and exercise), and (iii) 12 patients with a history of PVCs. Phantom results were assessed using peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM). In vivo performance was evaluated by comparing left-ventricular function quantification (against 2D real-time cine) and image quality (against 2D real-time cine and binning-based 5D-Cine). Results: In the phantom study, ML-DIP achieved PSNR > 29 dB and SSIM > 0.90 for scan times as short as two minutes, while recovering cardiac motion, respiratory motion, and PVC events. In healthy subjects, ML-DIP yielded functional measurements comparable to 2D cine and higher image quality than 5D-Cine, including during exercise with high heart rates and bulk motion. In PVC patients, ML-DIP preserved beat-to-beat variability and reconstructed irregular beats, whereas 5D-Cine showed motion artifacts and information loss due to binning. Conclusion: ML-DIP enables high-quality 3D real-time CMR with acceleration factors exceeding 1,000 by learning low-rank spatial and motion representations from undersampled data, without relying on external fully sampled training datasets.

Paper number 174:
Title: Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network
Authors: Davide Piccinini, Diego Valsesia, Enrico Magli
Abstract: Hyperspectral imagers on satellites obtain the fine spectral signatures essential for distinguishing one material from another at the expense of limited spatial resolution. Enhancing the latter is thus a desirable preprocessing step in order to further improve the detection capabilities offered by hyperspectral images on downstream tasks. At the same time, there is a growing interest towards deploying inference methods directly onboard of satellites, which calls for lightweight image super-resolution methods that can be run on the payload in real time. In this paper, we present a novel neural network design, called Deep Pushbroom Super-Resolution (DPSR) that matches the pushbroom acquisition of hyperspectral sensors by processing an image line by line in the along-track direction with a causal memory mechanism to exploit previously acquired lines. This design greatly limits memory requirements and computational complexity, achieving onboard real-time performance, i.e., the ability to super-resolve a line in the time it takes to acquire the next one, on low-power hardware. Experiments show that the quality of the super-resolved images is competitive or even outperforms state-of-the-art methods that are significantly more complex.

Paper number 175:
Title: Hybrid Pruning: In-Situ Compression of Self-Supervised Speech Models for Speaker Verification and Anti-Spoofing
Authors: Junyi Peng, Lin Zhang, Jiangyu Han, Oldřich Plchot, Johan Rohdin, Themos Stafylakis, Shuai Wang, Jan Černocký
Abstract: Although large-scale self-supervised learning (SSL) models like WavLM have achieved state-of-the-art performance in speech processing, their significant size impedes deployment on resource-constrained devices. While structured pruning is a key technique for model compression, existing methods typically separate it from task-specific fine-tuning. This multi-stage approach struggles to create optimal architectures tailored for diverse downstream tasks. In this work, we introduce a unified framework that integrates structured pruning into the downstream fine-tuning process. Our framework unifies these steps, jointly optimizing for task performance and model sparsity in a single stage. This allows the model to learn a compressed architecture specifically for the end task, eliminating the need for complex multi-stage pipelines and knowledge distillation. Our pruned models achieve up to a 70\% parameter reduction with negligible performance degradation on large-scale datasets, achieving equal error rates of 0.7\%, 0.8\%, and 1.6\% on Vox1-O, -E, and -H, respectively. Furthermore, our approach demonstrates improved generalization in low-resource scenarios, reducing overfitting and achieving a state-of-the-art 3.7\% EER on ASVspoof5.

Paper number 176:
Title: Opinion Clustering under the Friedkin-Johnsen Model: Agreement in Disagreement
Authors: Aashi Shrinate, Twinkle Tripathy
Abstract: The convergence of opinions in the Friedkin-Johnsen (FJ) framework is well studied, but the topological conditions leading to opinion clustering remain less explored. To bridge this gap, we examine the role of topology in the emergence of opinion clusters within the network. The key contribution of the paper lies in the introduction of the notion of topologically prominent agents, referred to as Locally Topologically Persuasive (LTP) agents. Interestingly, each LTP agent is associated with a unique set of (non-influential) agents in its vicinity. Using them, we present conditions to obtain opinion clusters in the FJ framework in any arbitrarily connected digraph. A key advantage of the proposed result is that the resulting opinion clusters are independent of the edge weights and the stubbornness of the agents. Finally, we demonstrate using simulation results that, by suitably placing LTP agents, one can design networks that achieve any desired opinion clustering.

Paper number 177:
Title: Automated Detection of Circadian-Dependent Epileptic Biomarkers for Seizure Localization: A Machine Learning and Signal Processing Framework
Authors: Mehdi Zekriyapanah Gashti, Mostafa Mohammadpour, Hassan Eshkiki, Vahid Ghanbarizadeh
Abstract: Epileptic biomarkers play a crucial role in identifying the origin of seizures, an essential aspect of pre-surgical planning for epilepsy treatment. These biomarkers can vary significantly over time. By studying these temporal fluctuations, we can enhance their effectiveness in guiding surgical planning. This research focuses on examining how circadian rhythms influence epilepsy biomarkers and aims to determine the optimal times for their analysis. To investigate the relationship between epilepsy biomarkers and circadian rhythm, the sleep/wake states first need to be classified. After the biomarkers are identified, they are compared across these states. A retrospective analysis was conducted on intracranial electroencephalography data from patients with focal epilepsy. The biomarkers-spikes, spike sequences, high-frequency oscillations (HFOs), and pathological HFOs-were identified through automatic detection. The alpha/delta ratio was also calculated to distinguish between asleep and awake stages. Data from 9 patients were analyzed, and the classification of sleep and wake states was achieved with an area under the curve of 84%. All biomarker rates were higher during the sleep stage compared to the wake stage. Pathological HFOs and the sequence of spikes proved to be more precise indicators regarding distance to seizure onset than spikes or HFOs. Unlike previous studies that relied predominantly on long-term spike biomarker analysis, this study is the first to utilize a comprehensive set of biomarkers, including HFOs, spike sequences, and pathological HFOs, to enhance seizure onset zone prediction. The rates of epilepsy biomarkers during sleep vary considerably from those seen while awake, making sleep data analysis more effective in accurately predicting the seizure onset zone.

Paper number 178:
Title: Beyond Data Scarcity Optimizing R3GAN for Medical Image Generation from Small Datasets
Authors: Tsung-Wei Pan, Chang-Hong Wu, Jung-Hua Wang, Ming-Jer Chen, Yu-Chiao Yi, Tsung-Hsien Lee
Abstract: Medical image datasets frequently exhibit significant class imbalance, a challenge that is further amplified by the inherently limited sample sizes that characterize clinical imaging data. Using human embryo time-lapse imaging (TLI) as a case study, this work investigates how generative adversarial networks (GANs) can be optimized for small datasets to generate realistic and diagnostically meaningful images. Based on systematic experiments with R3GAN, we established effective training strategies and designed an optimized configuration for 256x256-resolution datasets, featuring a full burn-in phase and a low, gradually increasing gamma range (5 to 40). The generated samples were used to balance an imbalanced embryo dataset, leading to substantial improvement in classification performance. The recall and F1-score of the three-cell (t3) class increased from 0.06 to 0.69 and from 0.11 to 0.60, respectively, without compromising the performance of other classes. These results demonstrate that tailored R3GAN training strategies can effectively alleviate data scarcity and improve model robustness in small-scale medical imaging tasks.

Paper number 179:
Title: Estimation of aboveground biomass in a tropical dry forest: An intercomparison of airborne, unmanned, and space laser scanning
Authors: Nelson Mattié, Arturo Sanchez-Azofeifa, Pablo Crespo-Peremarch, Juan-Ygnacio López-Hernández
Abstract: According to the Paris Climate Change Agreement, all nations are required to submit reports on their greenhouse gas emissions and absorption every two years by 2024. Consequently, forests play a crucial role in reducing carbon emissions, which is essential for meeting these obligations. Recognizing the significance of forest conservation in the global battle against climate change, Article 5 of the Paris Agreement emphasizes the need for high-quality forest data. This study focuses on enhancing methods for mapping aboveground biomass in tropical dry forests. Tropical dry forests are considered one of the least understood tropical forest environments; therefore, there is a need for accurate approaches to estimate carbon pools. We employ a comparative analysis of AGB estimates, utilizing different discrete and full-waveform laser scanning datasets in conjunction with Ordinary Least Squares and Bayesian approaches SVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanning were used as independent variables for extracting forest metrics. Variable selection, SVM regression tuning, and cross-validation via a machine-learning approach were applied to account for overfitting and underfitting. The results indicate that six key variables primarily related to tree height: Elevminimum, ElevL3, levMADmode, Elevmode, ElevMADmedian, and Elevskewness, are important for AGB estimation using ALSD and ULSD, while Leaf Area Index, canopy coverage and height, terrain elevation, and full-waveform signal energy emerged as the most vital variables. AGB values estimated from ten permanent tropical dry forest plots in Costa Rica Guanacaste province ranged from 26.02 Mg/ha to 175.43 Mg/ha. The SVM regressions demonstrated a 17.89 error across all laser scanning systems, with SLSF W exhibiting the lowest error 17.07 in estimating total biomass per plot.

Paper number 180:
Title: Stacked Flexible Intelligent Metasurface Design for Multi-User Wireless Communications
Authors: Ahmed Magbool, Vaibhav Kumar, Marco Di Renzo, Mark F. Flanagan
Abstract: Stacked intelligent metasurfaces (SIMs) have recently emerged as an effective solution for next-generation wireless networks. A SIM comprises multiple metasurface layers that enable signal processing directly in the wave domain. Moreover, recent advances in flexible metamaterials have highlighted the potential of flexible intelligent metasurfaces (FIMs), which can be physically morphed to enhance communication performance. In this paper, we propose a stacked flexible intelligent metasurface (SFIM)-based communication system for the first time, where each metasurface layer is deformable to improve the system's performance. We first present the system model, including the transmit and receive signal models as well as the channel model, and then formulate an optimization problem to maximize the system sum rate under constraints on the transmit power budget, morphing distance, and the unit-modulus condition of the meta-atom responses. To solve this problem, we develop an alternating optimization framework based on the gradient projection method. Simulation results demonstrate that the proposed SFIM-based system achieves significant performance gains compared to its rigid SIM counterpart.

Paper number 181:
Title: An Alternative Derivation and Optimal Design Method of the Generalized Bilinear Transformation for Discretizing Analog Systems
Authors: Shen Chen, Yanlong Li, Jiamin Cui, Wei Yao, Jisong Wang, Yixin Tian, Chaohou Liu, Yang Yang, Jiaxi Ying, Zeng Liu, Jinjun Liu
Abstract: A common approach to digital system design involves transforming a continuous-time (s-domain) transfer function into the discrete-time (z-domain) using methods such as Euler or Tustin. These transformations are shown to be specific cases of the Generalized Bilinear Transformation (GBT), characterized by a design parameter, $\alpha$, whose physical interpretation and optimal selection remain inadequately explored. In this paper, we propose an alternative derivation of the GBT derived by employing a new hexagonal shape to approximate the enclosed area of the error function, and we define the parameter $\alpha$ as a shape factor. We reveal, for the first time, the physical meaning of $\alpha$ as the backward rectangular ratio of the proposed hexagonal shape. Through domain mapping, the stable range of is rigorously established to be [0.5, 1]. Depending on the operating frequency and the chosen $\alpha$, we observe two distinct distortion modes, i.e., the magnitude and phase distortion. We further develop an optimal design method for $\alpha$ by minimizing a normalized magnitude or phase error objective function. The effectiveness of the proposed method is validated through the design and testing of a low-pass filter (LPF), demonstrating strong agreement between theoretical predictions and experimental results.

Paper number 182:
Title: A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting
Authors: Guang An Ooi, Otavio Bertozzi, Mohd Asim Aftab, Charalambos Konstantinou, Shehab Ahmed
Abstract: Modern power systems with high penetration of inverter-based resources exhibit complex dynamic behaviors that challenge the scalability and generalizability of traditional stability assessment methods. This paper presents a dynamic recurrent adjacency memory network (DRAMN) that combines physics-informed analysis with deep learning for real-time power system stability forecasting. The framework employs sliding-window dynamic mode decomposition to construct time-varying, multi-layer adjacency matrices from phasor measurement unit and sensor data to capture system dynamics such as modal participation factors, coupling strengths, phase relationships, and spectral energy distributions. As opposed to processing spatial and temporal dependencies separately, DRAMN integrates graph convolution operations directly within recurrent gating mechanisms, enabling simultaneous modeling of evolving dynamics and temporal dependencies. Extensive validations on modified IEEE 9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance, achieving 99.85%, 99.90%, and 99.69% average accuracies, respectively, surpassing all tested benchmarks, including classical machine learning algorithms and recent graph-based models. The framework identifies optimal combinations of measurements that reduce feature dimensionality by 82% without performance degradation. Correlation analysis between dominant measurements for small-signal and transient stability events validates generalizability across different stability phenomena. DRAMN achieves state-of-the-art accuracy while providing enhanced interpretability for power system operators, making it suitable for real-time deployment in modern control centers.

Paper number 183:
Title: RCMCL: A Unified Contrastive Learning Framework for Robust Multi-Modal (RGB-D, Skeleton, Point Cloud) Action Understanding
Authors: Hasan Akgul, Mari Eplik, Javier Rojas, Akira Yamamoto, Rajesh Kumar, Maya Singh
Abstract: Human action recognition (HAR) with multi-modal inputs (RGB-D, skeleton, point cloud) can achieve high accuracy but typically relies on large labeled datasets and degrades sharply when sensors fail or are noisy. We present Robust Cross-Modal Contrastive Learning (RCMCL), a self-supervised framework that learns modality-invariant representations and remains reliable under modality dropout and corruption. RCMCL jointly optimizes (i) a cross-modal contrastive objective that aligns heterogeneous streams, (ii) an intra-modal self-distillation objective that improves view-invariance and reduces redundancy, and (iii) a degradation simulation objective that explicitly trains models to recover from masked or corrupted inputs. At inference, an Adaptive Modality Gating (AMG) network assigns data-driven reliability weights to each modality for robust fusion. On NTU RGB+D 120 (CS/CV) and UWA3D-II, RCMCL attains state-of-the-art accuracy in standard settings and exhibits markedly better robustness: under severe dual-modality dropout it shows only an 11.5% degradation, significantly outperforming strong supervised fusion baselines. These results indicate that self-supervised cross-modal alignment, coupled with explicit degradation modeling and adaptive fusion, is key to deployable multi-modal HAR.

Paper number 184:
Title: A CNN-LSTM Quantifier for Single Access Point CSI Indoor Localization
Authors: Minh Tu Hoang, Brosnan Yuen, Kai Ren, Xiaodai Dong, Tao Lu, Hung Le Nguyen, Robert Westendorp, Kishore Reddy
Abstract: This paper proposes a combined network structure between convolutional neural network (CNN) and long-short term memory (LSTM) quantifier for WiFi fingerprinting indoor localization. In contrast to conventional methods that utilize only spatial data with classification models, our CNN-LSTM network extracts both space and time features of the received channel state information (CSI) from a single router. Furthermore, the proposed network builds a quantification model rather than a limited classification model as in most of the literature work, which enables the estimation of testing points that are not identical to the reference points. We analyze the instability of CSI and demonstrate a mitigation solution using a comprehensive filter and normalization scheme. The localization accuracy is investigated through extensive on-site experiments with several mobile devices including mobile phone (Nexus 5) and laptop (Intel 5300 NIC) on hundreds of testing locations. Using only a single WiFi router, our structure achieves an average localization error of 2.5~m with $\mathrm{80\%}$ of the errors under 4~m, which outperforms the other reported algorithms by approximately $\mathrm{50\%}$ under the same test environment.

Paper number 185:
Title: Large Language Model Empowered Next-Generation MIMO Networks: Fundamentals, Challenges, and Visions
Authors: Zhe Wang, Jiayi Zhang, Hongyang Du, Ruichen Zhang, Dusit Niyato, Bo Ai, Khaled B. Letaief
Abstract: Next-generation Multiple-Input Multiple-Output (MIMO) is expected to be intelligent and scalable. In this paper, we study Large Language Model (LLM)-enabled next-generation MIMO networks. Firstly, we provide an overview of the development, fundamentals, and challenges of the next-generation MIMO. Then, we propose the concept of the generative AI agent, which is capable of generating tailored and specialized contents with the aid of LLM and Retrieval Augmented Generation (RAG). Next, we comprehensively discuss the features and advantages of the generative AI agent framework. More importantly, to tackle existing challenges of next-generation MIMO, we discuss generative AI agent-enabled next-generation MIMO networks from the perspective of performance analysis, signal processing, and resource allocation. Furthermore, we present two compelling case studies that demonstrate the effectiveness of leveraging the generative AI agent for performance analysis in complex configuration scenarios. These examples highlight how the integration of generative AI agents can significantly enhance the analysis and design of next-generation MIMO systems. Finally, we discuss important potential research future directions.

Paper number 186:
Title: Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment
Authors: Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso
Abstract: Speech emotion recognition (SER) systems often struggle in real-world environments, where ambient noise severely degrades their performance. This paper explores a novel approach that exploits prior knowledge of testing environments to maximize SER performance under noisy conditions. To address this task, we propose a text-guided, environment-aware training where an SER model is trained with contaminated speech samples and their paired noise description. We use a pre-trained text encoder to extract the text-based environment embedding and then fuse it to a transformer-based SER model during training and inference. We demonstrate the effectiveness of our approach through our experiment with the MSP-Podcast corpus and real-world additive noise samples collected from the Freesound and DEMAND repositories. Our experiment indicates that the text-based environment descriptions processed by a large language model (LLM) produce representations that improve the noise-robustness of the SER system. With a contrastive learning (CL)-based representation, our proposed method can be improved by jointly fine-tuning the text encoder with the emotion recognition model. Under the -5dB signal-to-noise ratio (SNR) level, fine-tuning the text encoder improves our CL-based representation method by 76.4% (arousal), 100.0% (dominance), and 27.7% (valence).

Paper number 187:
Title: Topological Antenna: A Non-Classical Beam-Steering Micro-Antenna Based on Spin Injection from a Topological Insulator
Authors: Raisa Fabiha, Patrick J. Taylor, Supriyo Bandyopadhyay
Abstract: Antennas are the quintessential means to communicate information wirelessly over long distances via electromagnetic waves. Traditional antennas have two shortcomings that have prevented miniaturization: (1) their radiation efficiencies plummet and (2) they radiate isotropically when miniaturized to small fractions of the radiated wavelength. Here, we report a new genre of non-classical antennas that overcome these limitations by employing non-traditional principles and harnessing topological insulators. An alternating charge current of frequency 1-10 GHz injected into a thin film of a three-dimensional topological insulator (3D-TI) injects a spin current of alternating spin polarization into a periodic array of cobalt nanomagnets deposited on the surface of the 3D-TI. This generates spin waves in the nanomagnets, which radiate electromagnetic waves in space, thereby implementing an antenna. The frequency of the electromagnetic wave is the same as that of the current. The antenna dimension is only 0.6-1.8% of the free space wavelength and yet it radiates with an efficiency several orders of magnitude larger than the theoretical limit for conventional antennas. Furthermore, it radiates anisotropically (despite being a "point source") and one can change the anisotropic radiation pattern by changing the direction of the injected alternating charge current, which changes the spin wave patterns within the nanomagnets because of spin-momentum locking in the 3D-TI. This enables beam steering without the use of a phased array. We have overcome several limitations of classical antennas by harnessing the quantum mechanical attributes of a quantum material, namely a 3D-TI.

Paper number 188:
Title: Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment
Authors: Junlin Guo, Siqi Lu, Can Cui, Ruining Deng, Tianyuan Yao, Zhewen Tao, Yizhe Lin, Marilyn Lionts, Quan Liu, Juming Xiong, Yu Wang, Shilin Zhao, Catie Chang, Mitchell Wilkes, Mengmeng Yin, Haichun Yang, Yuankai Huo
Abstract: Training AI foundation models has emerged as a promising large-scale learning approach for addressing real-world healthcare challenges, including digital pathology. While many of these models have been developed for tasks like disease diagnosis and tissue quantification using extensive and diverse training datasets, their readiness for deployment on some arguably simplest tasks, such as nuclei segmentation within a single organ (e.g., the kidney), remains uncertain. This paper seeks to answer this key question, "How good are we?", by thoroughly evaluating the performance of recent cell foundation models on a curated multi-center, multi-disease, and multi-species external testing dataset. Additionally, we tackle a more challenging question, "How can we improve?", by developing and assessing human-in-the-loop data enrichment strategies aimed at enhancing model performance while minimizing the reliance on pixel-level human annotation. To address the first question, we curated a multicenter, multidisease, and multispecies dataset consisting of 2,542 kidney whole slide images (WSIs). Three state-of-the-art (SOTA) cell foundation models-Cellpose, StarDist, and CellViT-were selected for evaluation. To tackle the second question, we explored data enrichment algorithms by distilling predictions from the different foundation models with a human-in-the-loop framework, aiming to further enhance foundation model performance with minimal human efforts. Our experimental results showed that all three foundation models improved over their baselines with model fine-tuning with enriched data. Interestingly, the baseline model with the highest F1 score does not yield the best segmentation outcomes after fine-tuning. This study establishes a benchmark for the development and deployment of cell vision foundation models tailored for real-world data applications.

Paper number 189:
Title: A Learning-Based Control Barrier Function for Car-Like Robots: Toward Less Conservative Collision Avoidance
Authors: Jianye Xu, Bassam Alrifaee
Abstract: We propose a learning-based Control Barrier Function (CBF) to reduce conservatism in collision avoidance for car-like robots. Traditional CBFs often use the Euclidean distance between robots' centers as a safety margin, which neglects their headings and approximates their geometries as circles. Although this simplification meets the smoothness and differentiability requirements of CBFs, it may result in overly conservative behavior in dense environments. We address this by designing a safety margin that considers both the robot's heading and actual shape, thereby enabling a more precise estimation of safe regions. Because this safety margin is non-differentiable, we approximate it with a neural network to ensure differentiability. In addition, we propose a notion of relative dynamics that makes the learning process tractable. In a case study, we establish the theoretical foundation for applying this notion to a nonlinear kinematic bicycle model. Numerical experiments in overtaking and bypassing scenarios show that our approach reduces conservatism (e.g., requiring 33.5% less lateral space for bypassing) without incurring significant extra computation time. Code: this https URL

Paper number 190:
Title: Compositional Phoneme Approximation for L1-Grounded L2 Pronunciation Training
Authors: Jisang Park, Minu Kim, DaYoung Hong, Jongha Lee
Abstract: Learners of a second language (L2) often map non-native phonemes to similar native-language (L1) phonemes, making conventional L2-focused training slow and effortful. To address this, we propose an L1-grounded pronunciation training method based on compositional phoneme approximation (CPA), a feature-based representation technique that approximates L2 sounds with sequences of L1 phonemes. Evaluations with 20 Korean non-native English speakers show that CPA-based training achieves a 76% in-box formant rate in acoustic analysis, 17.6% relative improvement in phoneme recognition accuracy, and over 80% of speech being rated as more native-like, with minimal training. Project page: this https URL.

Paper number 191:
Title: TIMESAFE: Timing Interruption Monitoring and Security Assessment for Fronthaul Environments
Authors: Joshua Groen, Simone Di Valerio, Imtiaz Karim, Davide Villa, Yiewi Zhang, Leonardo Bonati, Michele Polese, Salvatore D'Oro, Tommaso Melodia, Elisa Bertino, Francesca Cuomo, Kaushik Chowdhury
Abstract: 5G and beyond cellular systems embrace the disaggregation of Radio Access Network (RAN) components, exemplified by the evolution of the fronthaul (FH) connection between cellular baseband and radio unit equipment. Crucially, synchronization over the FH is pivotal for reliable 5G services. In recent years, there has been a push to move these links to an Ethernet-based packet network topology, leveraging existing standards and ongoing research for Time-Sensitive Networking (TSN). However, TSN standards, such as Precision Time Protocol (PTP), focus on performance with little to no concern for security. This increases the exposure of the open FH to security risks. Attacks targeting synchronization mechanisms pose significant threats, potentially disrupting 5G networks and impairing connectivity. In this paper, we demonstrate the impact of successful spoofing and replay attacks against PTP synchronization. We show how a spoofing attack is able to cause a production-ready O-RAN and 5G-compliant private cellular base station to catastrophically fail within 2 seconds of the attack, necessitating manual intervention to restore full network operations. To counter this, we design a Machine Learning (ML)-based monitoring solution capable of detecting various malicious attacks with over 97.5% accuracy.

Paper number 192:
Title: Temporal Inconsistency Guidance for Super-resolution Video Quality Assessment
Authors: Yixiao Li, Xiaoyuan Yang, Weide Liu, Xin Jin, Xu Jia, Yukun Lai, Paul L Rosin, Haotao Liu, Wei Zhou
Abstract: As super-resolution (SR) techniques introduce unique distortions that fundamentally differ from those caused by traditional degradation processes (e.g., compression), there is an increasing demand for specialized video quality assessment (VQA) methods tailored to SR-generated content. One critical factor affecting perceived quality is temporal inconsistency, which refers to irregularities between consecutive frames. However, existing VQA approaches rarely quantify this phenomenon or explicitly investigate its relationship with human perception. Moreover, SR videos exhibit amplified inconsistency levels as a result of enhancement processes. In this paper, we propose \textit{Temporal Inconsistency Guidance for Super-resolution Video Quality Assessment (TIG-SVQA)} that underscores the critical role of temporal inconsistency in guiding the quality assessment of SR videos. We first design a perception-oriented approach to quantify frame-wise temporal inconsistency. Based on this, we introduce the Inconsistency Highlighted Spatial Module, which localizes inconsistent regions at both coarse and fine scales. Inspired by the human visual system, we further develop an Inconsistency Guided Temporal Module that performs progressive temporal feature aggregation: (1) a consistency-aware fusion stage in which a visual memory capacity block adaptively determines the information load of each temporal segment based on inconsistency levels, and (2) an informative filtering stage for emphasizing quality-related features. Extensive experiments on both single-frame and multi-frame SR video scenarios demonstrate that our method significantly outperforms state-of-the-art VQA approaches. The code is publicly available at this https URL.

Paper number 193:
Title: Low-altitude UAV Friendly-Jamming for Satellite-Maritime Communications via Generative AI-enabled Deep Reinforcement Learning
Authors: Jiawei Huang, Aimin Wang, Geng Sun, Jiahui Li, Jiacheng Wang, Dusit Niyato, Victor C. M. Leung
Abstract: Low Earth orbit (LEO) satellites can be used to assist maritime wireless communications for wide-area data transmission. However, the extensive coverage of LEO satellites, combined with the openness of channels, can cause the communication process to suffer from security risks. This paper presents a LEO satellite-maritime communication system assisted by low-altitude unmanned aerial vehicle (UAV) friendly-jamming to ensure data security at the physical layer. Since such a system requires balancing the conflicting performance metrics of secrecy rate and energy consumption of the UAV to meet evolving scenario demands, we formulate a secure satellite-maritime communication multi-objective optimization problem (SSMCMOP). In order to solve the dynamic and long-term optimization problem, we reformulate it into a Markov decision process. We then propose a transformer-enhanced soft actor-critic (TransSAC) algorithm, which is a generative artificial intelligence-enabled deep reinforcement learning approach to solve the reformulated problem, thus capturing strong temporal correlations and diversely exploring weights. Simulation results demonstrate that the TransSAC algorithm outperforms comparative approaches and algorithms, maximizing the secrecy rate while effectively minimizing the energy consumption of the UAV. Moreover, the results identify more suitable constraints for the system.

Paper number 194:
Title: MACS: Multi-source Audio-to-image Generation with Contextual Significance and Semantic Alignment
Authors: Hao Zhou, Xiaobao Guo, Yuzhe Zhu, Adams Wai-Kin Kong
Abstract: Propelled by the breakthrough in deep generative models, audio-to-image generation has emerged as a pivotal cross-modal task that converts complex auditory signals into rich visual representations. However, previous works only focus on single-source audio inputs for image generation, ignoring the multi-source characteristic in natural auditory scenes, thus limiting the performance in generating comprehensive visual content. To bridge this gap, we propose a method called MACS to conduct multi-source audio-to-image generation. To our best knowledge, this is the first work that explicitly separates multi-source audio to capture the rich audio components before image generation. MACS is a two-stage method. In the first stage, multi-source audio inputs are separated by a weakly supervised method, where the audio and text labels are semantically aligned by casting into a common space using the large pre-trained CLAP model. We introduce a ranking loss to consider the contextual significance of the separated audio signals. In the second stage, effective image generation is achieved by mapping the separated audio signals to the generation condition using only a trainable adapter and a MLP layer. We preprocess the LLP dataset as the first full multi-source audio-to-image generation benchmark. The experiments are conducted on multi-source, mixed-source, and single-source audio-to-image generation tasks. The proposed MACS outperforms the current state-of-the-art methods in 17 out of the 21 evaluation indexes on all tasks and delivers superior visual quality.

Paper number 195:
Title: MultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation
Authors: Khai Le-Duc, Tuyen Tran, Bach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo, Nguyen X. Khanh, Thanh Nguyen-Tang
Abstract: Multilingual speech translation (ST) and machine translation (MT) in the medical domain enhances patient care by enabling efficient communication across language barriers, alleviating specialized workforce shortages, and facilitating improved diagnosis and treatment, particularly during pandemics. In this work, we present the first systematic study on medical ST, to our best knowledge, by releasing MultiMed-ST, a large-scale ST dataset for the medical domain, spanning all translation directions in five languages: Vietnamese, English, German, French, and Simplified/Traditional Chinese, together with the models. With 290,000 samples, this is the largest medical MT dataset and the largest many-to-many multilingual ST among all domains. Secondly, we present the most comprehensive ST analysis in the field's history, to our best knowledge, including: empirical baselines, bilingual-multilingual comparative study, end-to-end vs. cascaded comparative study, task-specific vs. multi-task sequence-to-sequence comparative study, code-switch analysis, and quantitative-qualitative error analysis. All code, data, and models are available online: this https URL

Paper number 196:
Title: Environment-Aware Indoor LoRaWAN Ranging Using Path Loss Model Inversion and Adaptive RSSI Filtering
Authors: Nahshon Mokua Obiri, Kristof Van Laerhoven
Abstract: Achieving sub-10 m indoor ranging with LoRaWAN is difficult because multipath, human blockage, and micro-climate dynamics induce non-stationary attenuation in received signal strength indicator (RSSI) measurements. We present a lightweight, interpretable pipeline that couples an environment-aware multi-wall path loss model with a forward-only, innovation-driven Kalman prefilter for RSSI. The model augments distance and wall terms with frequency, signal-to-noise ratio (SNR), and co-located environmental covariates (temperature, relative humidity, carbon dioxide, particulate matter, and barometric pressure), and is inverted deterministically for distance estimation. On a one-year single-gateway office dataset comprising over 2 million uplinks, the approach attains a mean absolute error (MAE) of 4.74 m and a root mean square error (RMSE) of 6.76 m in distance estimation, improving over a COST-231 multi-wall baseline (12.07 m MAE) and its environment-augmented variant (7.76 m MAE. Filtering reduces RSSI volatility from 10.33 to 5.43 dB and halves path loss error to 5.35 dB while raising R-squared from 0.82 to 0.89. The result is a single-anchor LoRaWAN ranging method with constant per-packet cost that is accurate, robust, and interpretable, providing a strong building block for multi-gateway localization.

Paper number 197:
Title: Properties of zero-determinant strategies in multichannel games
Authors: Masahiko Ueda
Abstract: Controlling payoffs in repeated games is one of the important topics in control theory of multi-agent systems. Recently proposed zero-determinant strategies enable players to unilaterally enforce linear relations between payoffs. Furthermore, based on the mathematics of zero-determinant strategies, regional payoff control, in which payoffs are enforced into some feasible regions, has been discovered in social dilemma situations. More recently, theory of payoff control was extended to multichannel games, where players parallelly interact with each other in multiple channels. However, the existence of payoff-controlling strategies in multichannel games seems to require the existence of payoff-controlling strategies in some channels, and properties of zero-determinant strategies specific to multichannel games are still not clear. In this paper, we elucidate properties of zero-determinant strategies in multichannel games. First, we relate the existence condition of zero-determinant strategies in multichannel games to that of zero-determinant strategies in each channel. We then show that the existence of zero-determinant strategies in multichannel games requires the existence of zero-determinant strategies in some channels. This result implies that the existence of zero-determinant strategies in multichannel games is tightly restricted by structure of games played in each channel.

Paper number 198:
Title: GRAM: Spatial general-purpose audio representation models for real-world applications
Authors: Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden
Abstract: Although audio foundations models have seen great progress on a wide variety of tasks, their application in real-world acoustic environments with reverberation and noise has been less successful. Moreover, as audio foundation models are typically trained on dry, single-channel audio clips, the inherent spatial nature of real-world sound scenes is overlooked and tasks involving sound localization ruled out. To address these limitations, we propose GRAM: a General-purpose Real-world Audio Model utilizing a multi-channel masked auto-encoder approach to efficiently learn spatial audio representations from high-quality simulated real-world scenes. To evaluate the performance of GRAM and other audio foundation models in real-world sound scenes, we release Nat-HEAR: A naturalistic version of the HEAR benchmark suite comprising a simulated real-world version, as well as two new sound localization tasks. We show that the performance of GRAM surpasses all state-of-the-art self-supervised audio foundation models and speech models on both HEAR and Nat-HEAR, while using only a fraction of the training data. GRAM also showcases state-of-the-art localization performance, surpassing even supervised sound localization approaches, and can be flexibly applied either to a two-channel, binaural sound format or a four-channel, Ambisonics format. Validating GRAM's performance on real-world sound recordings demonstrates robust transfer to real-world scenes. Taken together, GRAM presents a significant advancement towards robust, spatial audio foundation models for real-world applications.

Paper number 199:
Title: Causal Discovery in Dynamic Fading Wireless Networks
Authors: Oluwaseyi Giwa
Abstract: Dynamic causal discovery in wireless networks is essential due to evolving interference, fading, and mobility, which complicate traditional static causal models. This paper addresses causal inference challenges in dynamic fading wireless environments by proposing a sequential regression-based algorithm with a novel application of the NOTEARS acyclicity constraint, enabling efficient online updates. We derive theoretical lower and upper bounds on the detection delay required to identify structural changes, explicitly quantifying their dependence on network size, noise variance, and fading severity. Monte Carlo simulations validate these theoretical results, demonstrating linear increases in detection delay with network size, quadratic growth with noise variance, and inverse-square dependence on the magnitude of structural changes. Our findings provide rigorous theoretical insights and practical guidelines for designing robust online causal inference mechanisms to maintain network reliability under nonstationary wireless conditions.

Paper number 200:
Title: Differentially Private Distribution Release of Gaussian Mixture Models via KL-Divergence Minimization
Authors: Hang Liu, Anna Scaglione, Sean Peisert
Abstract: Gaussian Mixture Models (GMMs) are widely used statistical models for representing multi-modal data distributions, with numerous applications in data mining, pattern recognition, data simulation, and machine learning. However, recent research has shown that releasing GMM parameters poses significant privacy risks, potentially exposing sensitive information about the underlying data. In this paper, we address the challenge of releasing GMM parameters while ensuring differential privacy (DP) guarantees. Specifically, we focus on the privacy protection of mixture weights, component means, and covariance matrices. We propose to use Kullback-Leibler (KL) divergence as a utility metric to assess the accuracy of the released GMM, as it captures the joint impact of noise perturbation on all the model parameters. To achieve privacy, we introduce a DP mechanism that adds carefully calibrated random perturbations to the GMM parameters. Through theoretical analysis, we quantify the effects of privacy budget allocation and perturbation statistics on the DP guarantee, and derive a tractable expression for evaluating KL divergence. We formulate and solve an optimization problem to minimize the KL divergence between the released and original models, subject to a given $(\epsilon, \delta)$-DP constraint. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach achieves strong privacy guarantees while maintaining high utility.

Paper number 201:
Title: Flexible MIMO for Future Wireless Communications: Which Flexibilities are Possible?
Authors: Zhe Wang, Jiayi Zhang, Bokai Xu, Wenhui Yi, Emil Björnson, Bo Ai
Abstract: In conventional multiple-input multiple-output (MIMO), static array configurations struggle in dynamic environments, and further antenna scaling is bounded by cost, energy, and footprint. Emerging approaches, which can enable next-generation wireless communication networks with modest spectrum availability by leveraging flexibility and adaptability rather than sheer array growth, are therefore needed. In this paper, we present a taxonomy framework, referred to as flexible MIMO technology, that systematically categorizes a wide range of evolving MIMO technologies. The focus is on MIMO technologies with flexible physical configurations and integrated applications. We categorize twelve representative flexible MIMO technologies into three major classifications: flexible deployment characteristics-based, flexible geometry characteristics-based, and flexible real-time modifications-based. We then comprehensively overview their fundamental characteristics, potential, and challenges. In addition, we highlight three vital enablers for flexible MIMO technology, including efficient channel state information acquisition schemes, low-complexity beamforming design, and explainable artificial intelligence (AI)-enabled optimization, and discuss eight representative sub-techniques. Finally, two brief case studies -- pre-optimized irregular array for high-speed railway network and cell-free movable antenna -- are presented, showing how flexible MIMO can open new design possibilities and inspire future research directions for next-generation wireless networks.

Paper number 202:
Title: DIFFA: Large Language Diffusion Models Can Listen and Understand
Authors: Jiaming Zhou, Hongjie Chen, Shiwan Zhao, Jian Kang, Jie Li, Enzhi Wang, Yujie Guo, Haoqin Sun, Hui Wang, Aobo Kong, Yong Qin, Xuelong Li
Abstract: Recent advances in large language models (LLMs) have shown remarkable capabilities across textual and multimodal domains. In parallel, diffusion-based language models have emerged as a promising alternative to the autoregressive paradigm, offering improved controllability, bidirectional context modeling, and robust generation. However, their application to the audio modality remains underexplored. In this work, we introduce \textbf{DIFFA}, the first diffusion-based large audio-language model designed to perform spoken language understanding. DIFFA integrates a frozen diffusion language model with a lightweight dual-adapter architecture that bridges speech understanding and natural language reasoning. We employ a two-stage training pipeline: first, aligning semantic representations via an ASR objective; then, learning instruction-following abilities through synthetic audio-caption pairs automatically generated by prompting LLMs. Despite being trained on only 960 hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates competitive performance on major benchmarks, including MMSU, MMAU, and VoiceBench, outperforming several autoregressive open-source baselines. Our results reveal the potential of diffusion-based language models for efficient and scalable audio understanding, opening a new direction for speech-driven AI. Our code will be available at this https URL.

Paper number 203:
Title: How Does a Deep Neural Network Look at Lexical Stress?
Authors: Itai Allouche, Itay Asael, Rotem Rousso, Vered Dassa, Ann Bradlow, Seung-Eun Kim, Matthew Goldrick, Joseph Keshet
Abstract: Despite their success in speech processing, neural networks often operate as black boxes, prompting the question: what informs their decisions, and how can we interpret them? This work examines this issue in the context of lexical stress. A dataset of English disyllabic words was automatically constructed from read and spontaneous speech. Several Convolutional Neural Network (CNN) architectures were trained to predict stress position from a spectrographic representation of disyllabic words lacking minimal stress pairs (e.g., initial stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out test data. Layerwise Relevance Propagation (LRP), a technique for CNN interpretability analysis, revealed that predictions for held-out minimal pairs (PROtest vs. proTEST ) were most strongly influenced by information in stressed versus unstressed syllables, particularly the spectral properties of stressed vowels. However, the classifiers also attended to information throughout the word. A feature-specific relevance analysis is proposed, and its results suggest that our best-performing classifier is strongly influenced by the stressed vowel's first and second formants, with some evidence that its pitch and third formant also contribute. These results reveal deep learning's ability to acquire distributed cues to stress from naturally occurring data, extending traditional phonetic work based around highly controlled stimuli.

Paper number 204:
Title: Online Learning and Coverage of Unknown Fields Using Random-Feature Gaussian Processes
Authors: Ruijie Du, Ruoyu Lin, Yanning Shen, Magnus Egerstedt
Abstract: This paper proposes a framework for multi-robot systems to perform simultaneous learning and coverage of a domain of interest characterized by an unknown and potentially time-varying density function. To overcome the limitations of Gaussian Process (GP) regression, we employ Random Feature GP (RFGP) and its online variant (O-RFGP) which enables online and incremental inference. By integrating these with Voronoi-based coverage control and Upper Confidence Bound (UCB) sampling strategy, a team of robots can adaptively focus on important regions while refining the learned spatial field for efficient coverage. The incremental update mechanism of O-RFGP naturally supports time-varying environments, allowing efficient adaptation without retaining historical data. Furthermore, to the best of our knowledge, we provide the first theoretical analysis of online learning and coverage through a regret-based formulation, establishing asymptotic no-regret guarantees in the time-invariant setting. The effectiveness of the proposed framework is demonstrated through simulations with both time-invariant and time-varying density functions, along with a physical experiment with a time-varying density function.

Paper number 205:
Title: WavJEPA: Semantic learning unlocks robust audio foundation models for raw waveforms
Authors: Goksenin Yuksel, Pierre Guetschel, Michael Tangermann, Marcel van Gerven, Kiki van der Heijden
Abstract: Learning audio representations from raw waveforms overcomes key limitations of spectrogram-based audio representation learning, such as the long latency of spectrogram computation and the loss of phase information. Yet, while self-supervised speech representation learning from raw waveforms has been remarkably successful, these approaches have not achieved similar feats for general-purpose audio representation learning from waveforms. Here, we propose WavJEPA, a waveform-based version of the Joint-Embedding Predictive Architecture. WavJEPA leverages high-level semantic representation learning to tackle the shortcomings of representation learning at the speech unit or token level. We show that this approach substantially outperforms state-of-the-art time-domain audio foundation models across a wide variety of downstream benchmark tasks, while requiring considerably fewer computational resources. Additionally, to overcome the performance drop that time-domain models typically exhibit in noisy and reverberant real-world acoustic environments, we present WavJEPA-Nat. WavJEPA-Nat is a multi-channel extension of the WavJEPA architecture trained on simulated naturalistic scenes. We find that WavJEPA-Nat is highly robust to reverberation and noise. These results highlight the feasibility and computational efficiency of general-purpose audio representation learning from raw waveforms, showcasing the potential for low-latency, robust time-domain audio foundation models for real-world applications.

Paper number 206:
Title: Sequential Change Detection Under A Markov Setup With Unknown Pre-Change and Post-Change Distributions
Authors: Ashish Bhoopesh Gulaguli, Shashwat Singh, Rakesh Kumar Bansal
Abstract: In this work we extend the results developed in 2022 for a sequential change detection algorithm making use of Page's CUSUM statistic, the empirical distribution as an estimate of the pre-change distribution, and a universal code as a tool for estimating the post-change distribution, from the i.i.d. case to the Markov setup.

Paper number 207:
Title: Nonasymptotic Convergence Rates for Plug-and-Play Methods With MMSE Denoisers
Authors: Henry Pritchard, Rahul Parhi
Abstract: It is known that the minimum-mean-squared-error (MMSE) denoiser under Gaussian noise can be written as a proximal operator, which suffices for asymptotic convergence of plug-and-play (PnP) methods but does not reveal the structure of the induced regularizer or give convergence rates. We show that the MMSE denoiser corresponds to a regularizer that can be written explicitly as an upper Moreau envelope of the negative log-marginal density, which in turn implies that the regularizer is 1-weakly convex. Using this property, we derive (to the best of our knowledge) the first sublinear convergence guarantee for PnP proximal gradient descent with an MMSE denoiser. We validate the theory with a one-dimensional synthetic study that recovers the implicit regularizer. We also validate the theory with imaging experiments (deblurring and computed tomography), which exhibit the predicted sublinear behavior.

Paper number 208:
Title: Toward an Agricultural Operational Design Domain: A Framework
Authors: Mirco Felske, Jannik Redenius, Georg Happich, Julius Schöning
Abstract: The agricultural sector increasingly relies on autonomous systems that operate in complex and variable environments. Unlike on-road applications, agricultural automation integrates driving and working processes, each of which imposes distinct operational constraints. Handling this complexity and ensuring consistency throughout the development and validation processes requires a structured, transparent, and verified description of the environment. However, existing Operational Design Domain (ODD) concepts do not yet address the unique challenges of agricultural applications. Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework, which can be used to describe and verify the operational boundaries of autonomous agricultural systems. The Ag-ODD Framework consists of three core elements. First, the Ag-ODD description concept, which provides a structured method for unambiguously defining environmental and operational parameters using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model derived from the PEGASUS 6-Layer Model, has been extended to include a process layer to capture dynamic agricultural operations. Third, the iterative verification process verifies the Ag-ODD against its corresponding logical scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness and consistency. Together, these elements provide a consistent approach for creating unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD Framework can support the standardization and scalability of environmental descriptions for autonomous agricultural systems.
    