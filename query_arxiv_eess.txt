
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: SDF-TopoNet: A Two-Stage Framework for Tubular Structure Segmentation via SDF Pre-training and Topology-Aware Fine-Tuning
Authors: Siyi Wu, Leyi Zhao, Haitian Ma, Xinyuan Song
Abstract: Accurate segmentation of tubular and curvilinear structures, such as blood vessels, neurons, and road networks, is crucial in various applications. A key challenge is ensuring topological correctness while maintaining computational efficiency. Existing approaches often employ topological loss functions based on persistent homology, such as Betti error, to enforce structural consistency. However, these methods suffer from high computational costs and are insensitive to pixel-level accuracy, often requiring additional loss terms like Dice or MSE to compensate. To address these limitations, we propose \textbf{SDF-TopoNet}, an improved topology-aware segmentation framework that enhances both segmentation accuracy and training efficiency. Our approach introduces a novel two-stage training strategy. In the pre-training phase, we utilize the signed distance function (SDF) as an auxiliary learning target, allowing the model to encode topological information without directly relying on computationally expensive topological loss functions. In the fine-tuning phase, we incorporate a dynamic adapter alongside a refined topological loss to ensure topological correctness while mitigating overfitting and computational overhead. We evaluate our method on five benchmark datasets. Experimental results demonstrate that SDF-TopoNet outperforms existing methods in both topological accuracy and quantitative segmentation metrics, while significantly reducing training complexity.

Paper number 2:
Title: Spline refinement with differentiable rendering
Authors: Frans Zdyb, Albert Alonso, Julius B. Kirkegaard
Abstract: Detecting slender, overlapping structures remains a challenge in computational microscopy. While recent coordinate-based approaches improve detection, they often produce less accurate splines than pixel-based methods. We introduce a training-free differentiable rendering approach to spline refinement, achieving both high reliability and sub-pixel accuracy. Our method improves spline quality, enhances robustness to distribution shifts, and shrinks the gap between synthetic and real-world data. Being fully unsupervised, the method is a drop-in replacement for the popular active contour model for spline refinement. Evaluated on C. elegans nematodes, a popular model organism for drug discovery and biomedical research, we demonstrate that our approach combines the strengths of both coordinate- and pixel-based methods.

Paper number 3:
Title: Ship Detection in Remote Sensing Imagery for Arbitrarily Oriented Object Detection
Authors: Bibi Erum Ayesha, T. Satyanarayana Murthy, Palamakula Ramesh Babu, Ramu Kuchipudi
Abstract: This research paper presents an innovative ship detection system tailored for applications like maritime surveillance and ecological monitoring. The study employs YOLOv8 and repurposed U-Net, two advanced deep learning models, to significantly enhance ship detection accuracy. Evaluation metrics include Mean Average Precision (mAP), processing speed, and overall accuracy. The research utilizes the "Airbus Ship Detection" dataset, featuring diverse remote sensing images, to assess the models' versatility in detecting ships with varying orientations and environmental contexts. Conventional ship detection faces challenges with arbitrary orientations, complex backgrounds, and obscured perspectives. Our approach incorporates YOLOv8 for real-time processing and U-Net for ship instance segmentation. Evaluation focuses on mAP, processing speed, and overall accuracy. The dataset is chosen for its diverse images, making it an ideal benchmark. Results demonstrate significant progress in ship detection. YOLOv8 achieves an 88% mAP, excelling in accurate and rapid ship detection. U Net, adapted for ship instance segmentation, attains an 89% mAP, improving boundary delineation and handling occlusions. This research enhances maritime surveillance, disaster response, and ecological monitoring, exemplifying the potential of deep learning models in ship detection.

Paper number 4:
Title: Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis
Authors: Praveen Shastry, Sowmya Chowdary Muthulur, Naveen Kumarasami, Anandakumar D, Mounigasri M, Keerthana R, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam, Revathi Ezhumalai, Abitha Marimuthu
Abstract: Background This study proposes a Vision-Language Model (VLM) leveraging the SIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic tuberculosis (TB) screening. By integrating chest X-ray images with clinical data, the model addresses the challenges of manual interpretation, improving diagnostic consistency and accessibility, particularly in resource-constrained settings. Methods The VLM architecture combines a Vision Transformer (ViT) for visual encoding and a transformer-based text encoder to process clinical context, such as patient histories and treatment records. Cross-modal attention mechanisms align radiographic features with textual information, while the Gemma-3b decoder generates comprehensive diagnostic reports. The model was pre-trained on 5 million paired medical images and texts and fine-tuned using 100,000 chronic TB-specific chest X-rays. Results The model demonstrated high precision (94 percent) and recall (94 percent) for detecting key chronic TB pathologies, including fibrosis, calcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores exceeded 0.93, and Intersection over Union (IoU) values were above 0.91, validating its effectiveness in detecting and localizing TB-related abnormalities. Conclusion The VLM offers a robust and scalable solution for automated chronic TB diagnosis, integrating radiographic and clinical data to deliver actionable and context-aware insights. Future work will address subtle pathologies and dataset biases to enhance the model's generalizability, ensuring equitable performance across diverse populations and healthcare settings.

Paper number 5:
Title: Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data
Authors: Ananya Ganapthy, Praveen Shastry, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Varshinipriya M, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: This study introduces a Vision-Language Model (VLM) leveraging SIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB) screening. By integrating chest X-ray images and clinical notes, the model aims to enhance diagnostic accuracy and efficiency, particularly in resource-limited settings. Methods: The VLM combines visual data from chest X-rays with clinical context to generate detailed, context-aware diagnostic reports. The architecture employs SIGLIP for visual encoding and Gemma-3b for decoding, ensuring effective representation of acute TB-specific pathologies and clinical insights. Results: Key acute TB pathologies, including consolidation, cavities, and nodules, were detected with high precision (97percent) and recall (96percent). The model demonstrated strong spatial localization capabilities and robustness in distinguishing TB-positive cases, making it a reliable tool for acute TB diagnosis. Conclusion: The multimodal capability of the VLM reduces reliance on radiologists, providing a scalable solution for acute TB screening. Future work will focus on improving the detection of subtle pathologies and addressing dataset biases to enhance its generalizability and application in diverse global healthcare settings.

Paper number 6:
Title: AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients
Authors: Agnieszka Sroka-Oleksiak, Adam Pardyl, Dawid Rymarczyk, Aldona Olechowska-Jarząb, Katarzyna Biegun-Drożdż, Dorota Ochońska, Michał Wronka, Adriana Borowa, Tomasz Gosiewski, Miłosz Adamczyk, Henryk Telega, Bartosz Zieliński, Monika Brzychczy-Włoch
Abstract: Sepsis is a life-threatening condition which requires rapid diagnosis and treatment. Traditional microbiological methods are time-consuming and expensive. In response to these challenges, deep learning algorithms were developed to identify 14 bacteria species and 3 yeast-like fungi from microscopic images of Gram-stained smears of positive blood samples from sepsis patients. A total of 16,637 Gram-stained microscopic images were used in the study. The analysis used the Cellpose 3 model for segmentation and Attention-based Deep Multiple Instance Learning for classification. Our model achieved an accuracy of 77.15% for bacteria and 71.39% for fungi, with ROC AUC of 0.97 and 0.88, respectively. The highest values, reaching up to 96.2%, were obtained for Cutibacterium acnes, Enterococcus faecium, Stenotrophomonas maltophilia and Nakaseomyces glabratus. Classification difficulties were observed in closely related species, such as Staphylococcus hominis and Staphylococcus haemolyticus, due to morphological similarity, and within Candida albicans due to high morphotic diversity. The study confirms the potential of our model for microbial classification, but it also indicates the need for further optimisation and expansion of the training data set. In the future, this technology could support microbial diagnosis, reducing diagnostic time and improving the effectiveness of sepsis treatment due to its simplicity and accessibility. Part of the results presented in this publication was covered by a patent application at the European Patent Office EP24461637.1 "A computer implemented method for identifying a microorganism in a blood and a data processing system therefor".

Paper number 7:
Title: The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances
Authors: Gustavo Correia, Victor Alves, Paulo Novais
Abstract: Artificial Intelligence (AI) is revolutionizing emergency medicine by enhancing diagnostic processes and improving patient outcomes. This article provides a review of the current applications of AI in emergency imaging studies, focusing on the last five years of advancements. AI technologies, particularly machine learning and deep learning, are pivotal in interpreting complex imaging data, offering rapid, accurate diagnoses and potentially surpassing traditional diagnostic methods. Studies highlighted within the article demonstrate AI's capabilities in accurately detecting conditions such as fractures, pneumothorax, and pulmonary diseases from various imaging modalities including X-rays, CT scans, and MRIs. Furthermore, AI's ability to predict clinical outcomes like mechanical ventilation needs illustrates its potential in crisis resource optimization. Despite these advancements, the integration of AI into clinical practice presents challenges such as data privacy, algorithmic bias, and the need for extensive validation across diverse settings. This review underscores the transformative potential of AI in emergency settings, advocating for a future where AI and clinical expertise synergize to elevate patient care standards.

Paper number 8:
Title: Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk
Authors: Theodorus Dapamede, Aisha Urooj, Vedant Joshi, Gabrielle Gershon, Frank Li, Mohammadreza Chavoshi, Beatrice Brown-Mulry, Rohan Satya Isaac, Aawez Mansuri, Chad Robichaux, Chadi Ayoub, Reza Arsanjani, Laurence Sperling, Judy Gichoya, Marly van Assen, Charles W. ONeill, Imon Banerjee, Hari Trivedi
Abstract: Women are underdiagnosed and undertreated for cardiovascular disease. Automatic quantification of breast arterial calcification on screening mammography can identify women at risk for cardiovascular disease and enable earlier treatment and management of disease. In this retrospective study of 116,135 women from two healthcare systems, a transformer-based neural network quantified BAC severity (no BAC, mild, moderate, and severe) on screening mammograms. Outcomes included major adverse cardiovascular events (MACE) and all-cause mortality. BAC severity was independently associated with MACE after adjusting for cardiovascular risk factors, with increasing hazard ratios from mild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22) across datasets (all p<0.001). This association remained significant across all age groups, with even mild BAC indicating increased risk in women under 50. BAC remained an independent predictor when analyzed alongside ASCVD risk scores, showing significant associations with myocardial infarction, stroke, heart failure, and mortality (all p<0.005). Automated BAC quantification enables opportunistic cardiovascular risk assessment during routine mammography without additional radiation or cost. This approach provides value beyond traditional risk factors, particularly in younger women, offering potential for early CVD risk stratification in the millions of women undergoing annual mammography.

Paper number 9:
Title: Analysis of human visual field information using machine learning methods and assessment of their accuracy
Authors: A.I. Medvedeva, V.V. Bakutkin
Abstract: Subject of research: is the study of methods for analyzing perimetric images for the diagnosis and control of glaucoma diseases. Objects of research: is a dataset collected on the ophthalmological perimeter with the results of various patient pathologies, since the ophthalmological community is acutely aware of the issue of disease control and import substitution. [5]. Purpose of research: is to consider various machine learning methods that can classify glaucoma. This is possible thanks to the classifier built after labeling the dataset. It is able to determine from the image whether the visual fields depicted on it are the results of the impact of glaucoma on the eyes or other visual diseases. Earlier in the work [3], a dataset was described that was collected on the Tomey perimeter. The average age of the examined patients ranged from 30 to 85 years. Methods of research: machine learning methods for classifying image results (stochastic gradient descent, logistic regression, random forest, naive Bayes). Main results of research: the result of the study is computer modeling that can determine from the image whether the result is glaucoma or another disease (binary classification).

Paper number 10:
Title: Three-dimensional Reconstruction of the Lumbar Spine with Submillimeter Accuracy Using Biplanar X-ray Images
Authors: Wanxin Yu, Zhemin Zhu, Cong Wang, Yihang Bao, Chunjie Xia, Rongshan Cheng, Yan Yu, Tsung-Yuan Tsai
Abstract: Three-dimensional reconstruction of the spine under weight-bearing conditions from biplanar X-ray images is of great importance for the clinical assessment of spinal diseases. However, the current fully automated reconstruction methods have low accuracy and fail to meet the clinical application standards. This study developed and validated a fully automated method for high-accuracy 3D reconstruction of the lumbar spine from biplanar X-ray images. The method involves lumbar decomposition and landmark detection from the raw X-ray images, followed by a deformable model and landmark-weighted 2D-3D registration approach. The reconstruction accuracy was validated by the gold standard obtained through the registration of CT-segmented vertebral models with the biplanar X-ray images. The proposed method achieved a 3D reconstruction accuracy of 0.80 mm, representing a significant improvement over the mainstream approaches. This study will contribute to the clinical diagnosis of lumbar in weight-bearing positions.

Paper number 11:
Title: Inductive Position Sensors based on Coupling of Coils on Printed Circuit Boards for Demanding Automotive Applications
Authors: Stefan Kuntz, Gerald Gerlach, Sina Fella
Abstract: Rotor position feedback is required in many industrial and automotive applications, e.g. for field-oriented control of brushless motors. Traditionally, magnetic sensors, resolvers or optical encoders are used to measure the rotor position. However, advances in inductive sensing concepts enable a low-cost, high-precision position measurement principle which is robust against magnetic stray fields exceeding 4000 A/m. The operating principle is based on the coupling of a transmitter coil with several receiver coils in the megahertz frequency range. The coils are part of a printed circuit board (PCB) which also comprises circuitry for demodulation and signal processing. The transmitter coil induces eddy currents in an electrically conductive passive coupling element, which provides position-dependent amplitude modulation. The voltage induced in the receiver coils encodes the rotor angle information, typically in quadrature signals. The coupling element requires no rare-earth materials and can be made of stainless steel, for instance. The PCB-based design of the sensor offers considerable flexibility in optimizing its performance. By tailoring the coil geometry and arrangement, accuracy, air gap and overall sensor dimensions can be adjusted to meet a broad range of application-specific requirements. A sensor design sample exhibits a mechanical angle error less than 0.02° (0.1° electrical) in both, finite-element simulation and test bench measurement, with good agreement.

Paper number 12:
Title: Assessment of Cyberattack Detection-Isolation Algorithm for CAV Platoons Using SUMO
Authors: Sanchita Ghosh, Tanushree Roy
Abstract: A Connected Autonomous Vehicle (CAV) platoon in an evolving real-world driving environment relies strongly on accurate vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication for its safe and efficient operation. However, a cyberattack on this communication network can corrupt the appropriate control actions, tamper with system measurement, and drive the platoon to unsafe or undesired conditions. As a first step toward practicable resilience against such V2V-V2I attacks, in this paper, we implemented a unified V2V-V2I cyberattack detection scheme and a V2I isolation scheme for a CAV platoon under changing driving conditions in Simulation of Urban MObility (SUMO). The implemented algorithm utilizes vehicle-specific residual generators that are designed based on analytical disturbance-to-state stability, robustness, and sensitivity performance constraints. Our case studies include two driving scenarios where highway driving is simulated using the Next-Generation Simulation (NGSIM) data and urban driving follows the benchmark EPA Urban Dynamometer Driving Schedule (UDDS). The results validate the applicability of the algorithm to ensure CAV cybersecurity and demonstrate the promising potential for practical test-bed implementation in the future.

Paper number 13:
Title: Synthesis of omnidirectional path loss model based on directional model and multi-elliptical geometry
Authors: Jaroslaw Wojtun, Cezary Ziolkowski, Jan M. Kelner, Tomas Mikulasek, Radek Zavorka, Jiri Blumenstein, Ales Prokes, Aniruddha Chandra, Niraj Narayan, Anirban Ghosh
Abstract: Millimeter wave (mmWave) technology offers high throughput but has a limited radio range, necessitating the use of directional antennas or beamforming systems such as massive MIMO. Path loss (PL) models using narrow-beam antennas are known as directional models, while those using omnidirectional antennas are referred to as omnidirectional models. To standardize the analysis, omnidirectional PL models for mmWave ranges have been introduced, including TR 38.901 by 3GPP, which is based on measurements from directional antennas. However, synthesizing these measurements can be complex and time-consuming. This study proposes a numerical approach to derive an omnidirectional model from directional data using multi-elliptical geometry. We assessed the effectiveness of this method against existing PL models for mmWaves that are available in the literature.

Paper number 14:
Title: Controlling Peak Sharpness in Multimodal Biomolecular Systems via the Chemical Fokker-Planck Equation
Authors: Taishi Kotsuka, Enoch Yeung
Abstract: Intracellular biomolecular systems exhibit intrinsic stochasticity due to low molecular copy numbers, leading to multimodal probability distributions that play a crucial role in probabilistic differentiation and cellular decision-making. Controlling the dispersion of multimodal probability distributions in biomolecular systems is critical for regulating stochastic behavior, robustness, and adaptability. However, modifying system parameters to adjust dispersion often affects peak positions, potentially altering a desired phenotype or even fundamental behavior in a genetic pathway. In this paper, we establish a theoretical framework that enables independent control of dispersion while preserving peak positions and modality using the Chemical Fokker-Planck Equation (CFPE) and sharpness, a measure of probability concentration around individual peaks. By analyzing the steady-state solution of the CFPE, we derive explicit conditions under which peak sharpness can be tuned monotonically without changing peak positions or modality. We validate our approach through Monte Carlo simulations on a bimodal chemical system, demonstrating effective dispersion control while maintaining structural stability. This framework provides a systematic approach for designing biomolecular systems with tunable stochastic properties, contributing to advancements in synthetic biology and probabilistic cellular regulation.

Paper number 15:
Title: Risk-Aware Planning of Power Distribution Systems Using Scalable Cloud Technologies
Authors: Shiva Poudel, Poorva Sharma, Abhineet Parchure, Daniel Olsen, Sayantan Bhowmik, Tonya Martin, Dylan Locsin, Andrew P. Reiman
Abstract: The uncertainty in distribution grid planning is driven by the unpredictable spatial and temporal patterns in adopting electric vehicles (EVs) and solar photovoltaic (PV) systems. This complexity, stemming from interactions among EVs, PV systems, customer behavior, and weather conditions, calls for a scalable framework to capture a full range of possible scenarios and analyze grid responses to factor in compound uncertainty. Although this process is challenging for many utilities today, the need to model numerous grid parameters as random variables and evaluate the impact on the system from many different perspectives will become increasingly essential to facilitate more strategic and well-informed planning investments. We present a scalable, stochastic-aware distribution system planning application that addresses these uncertainties by capturing spatial and temporal variability through a Markov model and conducting Monte Carlo simulations leveraging modular cloud-based architecture. The results demonstrate that 15,000 power flow scenarios generated from the Markov model are completed on the modified IEEE 123-bus test feeder, with each simulation representing an 8,760-hour time series run, all in under an hour. The grid impact extracted from this huge volume of simulated data provides insights into the spatial and temporal effects of adopted technology, highlighting that planning solely for average conditions is inadequate, while worst-case scenario planning may lead to prohibitive expenses.

Paper number 16:
Title: MTLoc: A Confidence-Based Source-Free Domain Adaptation Approach For Indoor Localization
Authors: Negar Mehregan, Berk Bozkurt, Eric Granger, Mohammadjavad Hajikhani, Mohammadhadi Shateri
Abstract: Various deep learning models have been developed for indoor localization based on radio-frequency identification (RFID) tags. However, they often require adaptation to ensure accurate tracking in new target operational domains. To address this challenge, unsupervised domain adaptation (UDA) methods have been proposed to align pre-trained models with data from target environments. However, they rely on large annotated datasets from the initial domain (source). Source data access is limited by privacy, storage, computational, and transfer constraints. Although many source-free domain adaptation (SFDA) methods address these constraints in classification, applying them to regression models for localization remains challenging. Indeed, target datasets for indoor localization are typically small, with few features and samples, and are noisy. Adapting regression models requires high-confidence target pseudo-annotation to avoid over-training. In this paper, a specialized mean-teacher method called MTLoc is proposed for SFDA. MTLoc updates the student network using noisy data and teacher-generated pseudo-labels. The teacher network maintains stability through exponential moving averages. To further ensure robustness, the teacher's pseudo-labels are refined using k-nearest neighbor correction. MTLoc allows for self-supervised learning on target data, facilitating effective adaptation to dynamic and noisy indoor environments. Validated using real-world data from our experimental setup with INLAN Inc., our results show that MTLoc achieves high localization accuracy under challenging conditions, significantly reducing localization error compared to baselines, including the state-of-the-art adversarial UDA approach with access to source data.

Paper number 17:
Title: Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution
Authors: Akram Khatami-Rizi, Ahmad Mahmoudi-Aznaveh
Abstract: Single Image Super-Resolution (SISR) aims to reconstruct high-resolution (HR) images from low-resolution (LR) inputs. Deep learning, especially Convolutional Neural Networks (CNNs), has advanced SISR. However, increasing network depth increases parameters, and memory usage, and slows training, which is problematic for resource-limited devices. To address this, lightweight models are developed to balance accuracy and efficiency. We propose the Involution & BSConv Multi-Depth Distillation Network (IBMDN), combining Involution & BSConv Multi-Depth Distillation Block (IBMDB) and the Contrast and High-Frequency Attention Block (CHFAB). IBMDB integrates Involution and BSConv to balance computational efficiency and feature extraction. CHFAB enhances high-frequency details for better visual quality. IBMDB is compatible with other SISR architectures and reduces complexity, improving evaluation metrics like PSNR and SSIM. In transformer-based models, IBMDB reduces memory usage while improving feature extraction. In GANs, it enhances perceptual quality, balancing pixel-level accuracy with perceptual details. Our experiments show that the method achieves high accuracy with minimal computational cost. The code is available at GitHub.

Paper number 18:
Title: Defect Analysis and Built-In-Self-Test for Chiplet Interconnects in Fan-out Wafer-Level Packaging
Authors: Partho Bhoumik, Christopher Bailey, Krishnendu Chakrabarty
Abstract: Fan-out wafer-level packaging (FOWLP) addresses the demand for higher interconnect densities by offering reduced form factor, improved signal integrity, and enhanced performance. However, FOWLP faces manufacturing challenges such as coefficient of thermal expansion (CTE) mismatch, warpage, die shift, and post-molding protrusion, causing misalignment and bonding issues during redistribution layer (RDL) buildup. Moreover, the organic nature of the package exposes it to severe thermo-mechanical stresses during fabrication and operation. In order to address these challenges, we propose a comprehensive defect analysis and testing framework for FOWLP interconnects. We use Ansys Q3D to map defects to equivalent electrical circuit models and perform fault simulations to investigate the impacts of these defects on chiplet functionality. Additionally, we present a built-in self-test (BIST) architecture to detect stuck-at and bridging faults while accurately diagnosing the fault type and location. Our simulation results demonstrate the efficacy of the proposed BIST solution and provide critical insights for optimizing design decisions in packages, balancing fault detection and diagnosis with the cost of testability insertion.

Paper number 19:
Title: Towards Connected Smart Work Zones: Advancing Work Zone Management through Improved Connectivity
Authors: Mariam Nour, Mohamed H. Zaki, Mohamed Abdel-Aty
Abstract: Work zones play a key role in road and highway maintenance but can lead to significant risks to both drivers and workers. Smart Work Zones (SWZs) have emerged as a potential solution, offering decision-makers real-time insights into the status of the work zone. By utilizing work zone barrels equipped with sensors and communication nodes, SWZs facilitate collecting and transmitting critical data, including location, traffic density, flow patterns, and worker proximity alerts. In collaboration with the Florida Department of Transportation (FDOT), this study addresses work zone barrel connectivity requirements while considering a cost-effective, low-power, and low-maintenance solution. While the broader project aimed to create a complete SWZ system for the localization of work zone barrels, this paper proposes a novel relay node selection algorithm integrated with Bluetooth Low Energy (BLE) technology to enhance network performance. The proposed algorithm enhances the communication network performance by selecting specific nodes as relay points, avoiding message flooding in the network. It demonstrates an improvement in message delivery rates, achieving up to a 40% increase over existing methods while ensuring balanced load distribution among nodes. Moreover, it maintains an 80% message delivery rate while minimizing power consumption, outperforming other approaches. This improvement in communication efficiency is critical, as it ensures the accurate transmission and delivery of vital work zone data, allowing for faster and more informed decisions to enhance work zone safety and management.

Paper number 20:
Title: On a Dissimilarity Metric for Analyzing Body Synergistic Coordination in Non-Periodic Motion
Authors: Shunpei Fujii, Kanta Tachibana
Abstract: This study proposes a novel metric to quantitatively evaluate body synergistic coordination, explicitly addressing dynamic interactions between pairs of body segments in baseball pitching motions. Conventional methods typically compare motion trajectories using individual joint coordinates or velocities independently, employing techniques like Dynamic Time Warping (DTW) that inherently apply temporal alignment even when such correction may distort meaningful rhythm-based differences. In contrast, our approach models the coordination dynamics as Linear Time-Invariant (LTI) systems, leveraging convolution operations between pairs of time series data to capture the gain and phase-lag inherent in genuine coordination dynamics. Empirical validation demonstrates the robustness of the proposed metric to variations in camera angles and scaling, providing superior discriminative capability compared to DTW and deep learning-based methods.

Paper number 21:
Title: Robust Transmission of Punctured Text with Large Language Model-based Recovery
Authors: Sojeong Park, Hyeonho Noh, Hyun Jong Yang
Abstract: With the recent advancements in deep learning, semantic communication which transmits only task-oriented features, has rapidly emerged. However, since feature extraction relies on learning-based models, its performance fundamentally depends on the training dataset or tasks. For practical scenarios, it is essential to design a model that demonstrates robust performance regardless of dataset or tasks. In this correspondence, we propose a novel text transmission model that selects and transmits only a few characters and recovers the missing characters at the receiver using a large language model (LLM). Additionally, we propose a novel importance character extractor (ICE), which selects transmitted characters to enhance LLM recovery performance. Simulations demonstrate that the proposed filter selection by ICE outperforms random filter selection, which selects transmitted characters randomly. Moreover, the proposed model exhibits robust performance across different datasets and tasks and outperforms traditional bit-based communication in low signal-to-noise ratio conditions.

Paper number 22:
Title: Design for Sensing and Digitalisation (DSD): A Modern Approach to Engineering Design
Authors: Daniel N. Wilke
Abstract: This paper introduces Design for Sensing and Digitalisation (DSD), a new engineering design paradigm that integrates sensor technology for digitisation and digitalisation from the earliest stages of the design process. Unlike traditional methodologies that treat sensing as an afterthought, DSD emphasises sensor integration, signal path optimisation, and real-time data utilisation as core design principles. The paper outlines DSD's key principles, discusses its role in enabling digital twin technology, and argues for its importance in modern engineering education. By adopting DSD, engineers can create more intelligent and adaptable systems that leverage real-time data for continuous design iteration, operational optimisation and data-driven predictive maintenance.

Paper number 23:
Title: Analysis and Extension of Noisy-target Training for Unsupervised Target Signal Enhancement
Authors: Takuya Fujimura, Tomoki Toda
Abstract: Deep neural network-based target signal enhancement (TSE) is usually trained in a supervised manner using clean target signals. However, collecting clean target signals is costly and such signals are not always available. Thus, it is desirable to develop an unsupervised method that does not rely on clean target signals. Among various studies on unsupervised TSE methods, Noisy-target Training (NyTT) has been established as a fundamental method. NyTT simply replaces clean target signals with noisy ones in the typical supervised training, and it has been experimentally shown to achieve TSE. Despite its effectiveness and simplicity, its mechanism and detailed behavior are still unclear. In this paper, to advance NyTT and, thus, unsupervised methods as a whole, we analyze NyTT from various perspectives. We experimentally demonstrate the mechanism of NyTT, the desirable conditions, and the effectiveness of utilizing noisy signals in situations where a small number of clean target signals are available. Furthermore, we propose an improved version of NyTT based on its properties and explore its capabilities in the dereverberation and declipping tasks, beyond the denoising task.

Paper number 24:
Title: MetaFAP: Meta-Learning for Frequency Agnostic Prediction of Metasurface Properties
Authors: Rafid Umayer Murshed, Md Shoaib Akhter Rafi, Sakib Reza, Mohammad Saquib, Ifana Mahbub
Abstract: Metasurfaces, and in particular reconfigurable intelligent surfaces (RIS), are revolutionizing wireless communications by dynamically controlling electromagnetic waves. Recent wireless communication advancements necessitate broadband and multi-band RIS, capable of supporting dynamic spectrum access and carrier aggregation from sub-6 GHz to mmWave and THz bands. The inherent frequency dependence of meta-atom resonances degrades performance as operating conditions change, making real-time, frequency-agnostic metasurface property prediction crucial for practical deployment. Yet, accurately predicting metasurface behavior across different frequencies remains challenging. Traditional simulations struggle with complexity, while standard deep learning models often overfit or generalize poorly. To address this, we introduce MetaFAP (Meta-Learning for Frequency-Agnostic Prediction), a novel framework built on the meta-learning paradigm for predicting metasurface properties. By training on diverse frequency tasks, MetaFAP learns broadly applicable patterns. This allows it to adapt quickly to new spectral conditions with minimal data, solving key limitations of existing methods. Experimental evaluations demonstrate that MetaFAP reduces prediction errors by an order of magnitude in MSE and MAE while maintaining high Pearson correlations. Remarkably, it achieves inference in less than a millisecond, bypassing the computational bottlenecks of traditional simulations, which take minutes per unit cell and scale poorly with array size. These improvements enable real-time RIS optimization in dynamic environments and support scalable, frequency-agnostic designs. MetaFAP thus bridges the gap between intelligent electromagnetic systems and practical deployment, offering a critical tool for next-generation wireless networks.

Paper number 25:
Title: Synthesizing Grid Data with Cyber Resilience and Privacy Guarantees
Authors: Shengyang Wu, Vladimir Dvorkin
Abstract: Differential privacy (DP) provides a principled approach to synthesizing data (e.g., loads) from real-world power systems while limiting the exposure of sensitive information. However, adversaries may exploit synthetic data to calibrate cyberattacks on the source grids. To control these risks, we propose new DP algorithms for synthesizing data that provide the source grids with both cyber resilience and privacy guarantees. The algorithms incorporate both normal operation and attack optimization models to balance the fidelity of synthesized data and cyber resilience. The resulting post-processing optimization is reformulated as a robust optimization problem, which is compatible with the exponential mechanism of DP to moderate its computational burden.

Paper number 26:
Title: Degradation Alchemy: Self-Supervised Unknown-to-Known Transformation for Blind Hyperspectral Image Fusion
Authors: He Huang, Yong Chen, Yujun Guo, Wei He
Abstract: Hyperspectral image (HSI) fusion is an efficient technique that combines low-resolution HSI (LR-HSI) and high-resolution multispectral images (HR-MSI) to generate high-resolution HSI (HR-HSI). Existing supervised learning methods (SLMs) can yield promising results when test data degradation matches the training ones, but they face challenges in generalizing to unknown degradations. To unleash the potential and generalization ability of SLMs, we propose a novel self-supervised unknown-to-known degradation transformation framework (U2K) for blind HSI fusion, which adaptively transforms unknown degradation into the same type of degradation as those handled by pre-trained SLMs. Specifically, the proposed U2K framework consists of: (1) spatial and spectral Degradation Wrapping (DW) modules that map HR-HSI to unknown degraded HR-MSI and LR-HSI, and (2) Degradation Transformation (DT) modules that convert these wrapped data into predefined degradation patterns. The transformed HR-MSI and LR-HSI pairs are then processed by a pre-trained network to reconstruct the target HR-HSI. We train the U2K framework in a self-supervised manner using consistency loss and greedy alternating optimization, significantly improving the flexibility of blind HSI fusion. Extensive experiments confirm the effectiveness of our proposed U2K framework in boosting the adaptability of five existing SLMs under various degradation settings and surpassing state-of-the-art blind methods.

Paper number 27:
Title: A Cost Effective Deaf-mute Electronic Assistant System Using Myo Armband and Smartphone
Authors: Hussein Naeem Hasan
Abstract: Communication is essential feature in human communities. For some reasons, deaf-mute disabled people lose their ability to hear, speak, or both which makes them suffer to communicate and convey their ideas, especially with normal people. Sign language is the solution for communication in the deaf-mute societies, but it is difficult for the rest of people to understand. Therefore, in this work, a cost effective Deaf-Mute Electronic Assistant System (DMEAS) has been developed to help in solving the communication problem between the deaf-mute people and the normal people. The system hardware consists only of a Myo armband from \textit{Thalmic Labs} and a smartphone. The Myo armband reads the electromyographic signals of the muscles of the disabled person's forearm through non-invasive, surface mounted electrodes (sEMG) and sends the data directly to the smartphone via Bluetooth. The smartphone will recognize and interpret them to a predefined word depending on the hand gestures. The recognized gesture will be displayed on the smartphone screen as well as displaying the text of the word related to the gesture and its voice record. All the EMG signals are processed using discrete wavelet transform and classified by neural network classifier. The system was extensively tested through experiments by normal subjects to prove its functionality.

Paper number 28:
Title: FetalFlex: Anatomy-Guided Diffusion Model for Flexible Control on Fetal Ultrasound Image Synthesis
Authors: Yaofei Duan, Tao Tan, Zhiyuan Zhu, Yuhao Huang, Yuanji Zhang, Rui Gao, Patrick Cheong-Iao Pang, Xinru Gao, Guowei Tao, Xiang Cong, Zhou Li, Lianying Liang, Guangzhi He, Linliang Yin, Xuedong Deng, Xin Yang, Dong Ni
Abstract: Fetal ultrasound (US) examinations require the acquisition of multiple planes, each providing unique diagnostic information to evaluate fetal development and screening for congenital anomalies. However, obtaining a comprehensive, multi-plane annotated fetal US dataset remains challenging, particularly for rare or complex anomalies owing to their low incidence and numerous subtypes. This poses difficulties in training novice radiologists and developing robust AI models, especially for detecting abnormal fetuses. In this study, we introduce a Flexible Fetal US image generation framework (FetalFlex) to address these challenges, which leverages anatomical structures and multimodal information to enable controllable synthesis of fetal US images across diverse planes. Specifically, FetalFlex incorporates a pre-alignment module to enhance controllability and introduces a repaint strategy to ensure consistent texture and appearance. Moreover, a two-stage adaptive sampling strategy is developed to progressively refine image quality from coarse to fine levels. We believe that FetalFlex is the first method capable of generating both in-distribution normal and out-of-distribution abnormal fetal US images, without requiring any abnormal data. Experiments on multi-center datasets demonstrate that FetalFlex achieved state-of-the-art performance across multiple image quality metrics. A reader study further confirms the close alignment of the generated results with expert visual assessments. Furthermore, synthetic images by FetalFlex significantly improve the performance of six typical deep models in downstream classification and anomaly detection tasks. Lastly, FetalFlex's anatomy-level controllable generation offers a unique advantage for anomaly simulation and creating paired or counterfactual data at the pixel level. The demo is available at: this https URL.

Paper number 29:
Title: A Language Vision Model Approach for Automated Tumor Contouring in Radiation Oncology
Authors: Yi Luo, Hamed Hooshangnejad, Xue Feng, Gaofeng Huang, Xiaojian Chen, Rui Zhang, Quan Chen, Wil Ngwa, Kai Ding
Abstract: Background: Lung cancer ranks as the leading cause of cancer-related mortality worldwide. The complexity of tumor delineation, crucial for radiation therapy, requires expertise often unavailable in resource-limited settings. Artificial Intelligence(AI), particularly with advancements in deep learning (DL) and natural language processing (NLP), offers potential solutions yet is challenged by high false positive rates. Purpose: The Oncology Contouring Copilot (OCC) system is developed to leverage oncologist expertise for precise tumor contouring using textual descriptions, aiming to increase the efficiency of oncological workflows by combining the strengths of AI with human oversight. Methods: Our OCC system initially identifies nodule candidates from CT scans. Employing Language Vision Models (LVMs) like GPT-4V, OCC then effectively reduces false positives with clinical descriptive texts, merging textual and visual data to automate tumor delineation, designed to elevate the quality of oncology care by incorporating knowledge from experienced domain experts. Results: Deployments of the OCC system resulted in a significant reduction in the false discovery rate by 35.0%, a 72.4% decrease in false positives per scan, and an F1-score of 0.652 across our dataset for unbiased evaluation. Conclusions: OCC represents a significant advance in oncology care, particularly through the use of the latest LVMs to improve contouring results by (1) streamlining oncology treatment workflows by optimizing tumor delineation, reducing manual processes; (2) offering a scalable and intuitive framework to reduce false positives in radiotherapy planning using LVMs; (3) introducing novel medical language vision prompt techniques to minimize LVMs hallucinations with ablation study, and (4) conducting a comparative analysis of LVMs, highlighting their potential in addressing medical language vision challenges.

Paper number 30:
Title: Enhancing Fault Detection and Isolation in an All-Electric Auxiliary Power Unit (APU) Gas Generator by Utilizing Starter/Generator Signal
Authors: Haotian Mao, Khashayar Khorasani, Yingqing Guo
Abstract: This study proposes a novel paradigm for enhancing fault detection and isolation (FDI) of gas generators in all-electric auxiliary power unit (APU) by utilizing shaft power information from the starter/generator. First, we conduct a pioneering investigation into the challenges and opportunities for FDI brought about by APU electrification. Our analysis reveals that the electrification of APU opens up new possibilities for utilizing shaft power estimates from starter/generator to improve gas generator FDI. We then provide comprehensive theoretical and analytical evidence demonstrating why, how, and to what extent, the shaft power information from the starter/generator can fundamentally enhance the estimation accuracy of system states and health parameters of the gas generator, while also identifying the key factors influencing these improvements in FDI performance. The effectiveness of the proposed paradigm and its theoretical foundations are validated through extensive Monte Carlo simulations. Furthermore, through comprehensive comparative analysis with state-of-the-art gas generator fault diagnosis methods, our experimental results not only demonstrate the superior performance of the proposed approach but also validate that the diagnostic capabilities of existing advanced FDI techniques can be substantially enhanced by incorporating shaft power information. And the observed performance improvement patterns strongly align with our theoretical analysis, verifying both the effectiveness and guiding significance of our theoretical framework. These research findings provide a unique perspective in answering three fundamental questions: why joint fault diagnosis of the starter/generator and gas generator is essential, how it can be implemented, and what factors determine its effectiveness, thereby opening up promising new avenues for FDI technologies in all-electric APU systems.

Paper number 31:
Title: A low-PAPR Pilot Design and Optimization for OTFS Modulation
Authors: Davide Bergamasco, Federico Clazzer, Andrea Munari, Paolo Casari
Abstract: Orthogonal time frequency space (OTFS) modulation has been proposed recently as a new waveform in the context of doubly-selective multi-path channels. This article proposes a novel pilot design that improves OTFS spectral efficiency (SE) while reducing its peak-to-average power ratio (PAPR). Instead of adopting an embedded data-orthogonal pilot for channel estimation, our scheme relies on Chu sequences superimposed to data symbols. We optimize the construction by investigating the best energy split between pilot and data symbols. Two equalizers, and an iterative channel estimation and equalization procedure are considered. We present extensive numerical results of relevant performance metrics, including the normalized mean squared error of the estimator, bit error rate, PAPR and SE. Our results show that, while the embedded pilot scheme estimates the channel more accurately, our approach yields a better tradeoff by achieving much higher spectral efficiency and lower PAPR.

Paper number 32:
Title: A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection
Authors: Aamir Mehmood, Yue Hu, Saddam Hussain Khan (Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)
Abstract: Recent advancements in detecting tumors using deep learning on breast ultrasound images (BUSI) have demonstrated significant success. Deep CNNs and vision-transformers (ViTs) have demonstrated individually promising initial performance. However, challenges related to model complexity and contrast, texture, and tumor morphology variations introduce uncertainties that hinder the effectiveness of current methods. This study introduces a novel hybrid framework, CB-Res-RBCMT, combining customized residual CNNs and new ViT components for detailed BUSI cancer analysis. The proposed RBCMT uses stem convolution blocks with CNN Meet Transformer (CMT) blocks, followed by new Regional and boundary (RB) feature extraction operations for capturing contrast and morphological variations. Moreover, the CMT block incorporates global contextual interactions through multi-head attention, enhancing computational efficiency with a lightweight design. Additionally, the customized inverse residual and stem CNNs within the CMT effectively extract local texture information and handle vanishing gradients. Finally, the new channel-boosted (CB) strategy enriches the feature diversity of the limited dataset by combining the original RBCMT channels with transfer learning-based residual CNN-generated maps. These diverse channels are processed through a spatial attention block for optimal pixel selection, reducing redundancy and improving the discrimination of minor contrast and texture variations. The proposed CB-Res-RBCMT achieves an F1-score of 95.57%, accuracy of 95.63%, sensitivity of 96.42%, and precision of 94.79% on the standard harmonized stringent BUSI dataset, outperforming existing ViT and CNN methods. These results demonstrate the versatility of our integrated CNN-Transformer framework in capturing diverse features and delivering superior performance in BUSI cancer diagnosis.

Paper number 33:
Title: High-Order Control Barrier Functions: Insights and a Truncated Taylor-Based Formulation
Authors: Jianye Xu, Bassam Alrifaee
Abstract: We examine the complexity of the standard High-Order Control Barrier Function (HOCBF) approach and propose a truncated Taylor-based approach that reduces design parameters. First, we derive the explicit inequality condition for the HOCBF approach and show that the corresponding equality condition sets a lower bound on the barrier function value that regulates its decay rate. Next, we present our Truncated Taylor CBF (TTCBF), which uses a truncated Taylor series to approximate the discrete-time CBF condition. While the standard HOCBF approach requires multiple class K functions, leading to more design parameters as the constraint's relative degree increases, our TTCBF approach requires only one. We support our theoretical findings in numerical collision-avoidance experiments and show that our approach ensures safety while reducing design complexity.

Paper number 34:
Title: Enhancing Reset Control Phase with Lead Shaping Filters: Applications to Precision Motion Systems
Authors: Xinxin Zhang, S. Hassan HosseinNia
Abstract: This study presents a shaped reset feedback control strategy to enhance the performance of precision motion systems. The approach utilizes a phase-lead compensator as a shaping filter to tune the phase of reset instants, thereby shaping the nonlinearity in the first-order reset control. {The design achieves either an increased phase margin while maintaining gain properties or improved gain without sacrificing phase margin, compared to reset control without the shaping filter.} Then, frequency-domain design procedures are provided for both Clegg Integrator (CI)-based and First-Order Reset Element (FORE)-based reset control systems. Finally, the effectiveness of the proposed strategy is demonstrated through two experimental case studies on a precision motion stage. In the first case, the shaped reset control leverages phase-lead benefits to achieve zero overshoot in the transient response. In the second case, the shaped reset control strategy enhances the gain advantages of the previous reset element, resulting in improved steady-state performance, including better tracking precision and disturbance rejection, while reducing overshoot for an improved transient response.

Paper number 35:
Title: Joint Design of Radar Receive Filter and Unimodular ISAC Waveform with Sidelobe Level Control
Authors: Kecheng Zhang, Ya-Feng Liu, Zhongbin Wang, Weijie Yuan, Musa Furkan Keskin, Henk Wymeersch, Shuqiang Xia
Abstract: Integrated sensing and communication (ISAC) has been considered a key feature of next-generation wireless networks. This paper investigates the joint design of the radar receive filter and dual-functional transmit waveform for the multiple-input multiple-output (MIMO) ISAC system. While optimizing the mean square error (MSE) of the radar receive spatial response and maximizing the achievable rate at the communication receiver, besides the constraints of full-power radar receiving filter and unimodular transmit sequence, we control the maximum range sidelobe level, which is often overlooked in existing ISAC waveform design literature, for better radar imaging performance. To solve the formulated optimization problem with convex and nonconvex constraints, we propose an inexact augmented Lagrangian method (ALM) algorithm. For each subproblem in the proposed inexact ALM algorithm, we custom-design a block successive upper-bound minimization (BSUM) scheme with closed-form solutions for all blocks of variable to enhance the computational efficiency. Convergence analysis shows that the proposed algorithm is guaranteed to provide a stationary and feasible solution. Extensive simulations are performed to investigate the impact of different system parameters on communication and radar imaging performance. Comparison with the existing works shows the superiority of the proposed algorithm.

Paper number 36:
Title: Texture-Aware StarGAN for CT data harmonisation
Authors: Francesco Di Feola, Ludovica Pompilio, Cecilia Assolito, Valerio Guarrasi, Paolo Soda
Abstract: Computed Tomography (CT) plays a pivotal role in medical diagnosis; however, variability across reconstruction kernels hinders data-driven approaches, such as deep learning models, from achieving reliable and generalized performance. To this end, CT data harmonization has emerged as a promising solution to minimize such non-biological variances by standardizing data across different sources or conditions. In this context, Generative Adversarial Networks (GANs) have proved to be a powerful framework for harmonization, framing it as a style-transfer problem. However, GAN-based approaches still face limitations in capturing complex relationships within the images, which are essential for effective harmonization. In this work, we propose a novel texture-aware StarGAN for CT data harmonization, enabling one-to-many translations across different reconstruction kernels. Although the StarGAN model has been successfully applied in other domains, its potential for CT data harmonization remains unexplored. Furthermore, our approach introduces a multi-scale texture loss function that embeds texture information across different spatial and angular scales into the harmonization process, effectively addressing kernel-induced texture variations. We conducted extensive experimentation on a publicly available dataset, utilizing a total of 48667 chest CT slices from 197 patients distributed over three different reconstruction kernels, demonstrating the superiority of our method over the baseline StarGAN.

Paper number 37:
Title: Movable-Element RIS-Aided Wireless Communications: An Element-Wise Position Optimization Approach
Authors: Jingjing Zhao, Qingyi Huang, Kaiquan Cai, Quan Zhou, Xidong Mu, Yuanwei Liu
Abstract: A point-to-point movable element (ME) enabled reconfigurable intelligent surface (ME-RIS) communication system is investigated, where each element position can be flexibly adjusted to create favorable channel conditions. For maximizing the communication rate, an efficient ME position optimization approach is proposed. Specifically, by characterizing the cascaded channel power gain in an element-wise manner, the position of each ME is iteratively updated by invoking the successive convex approximation method. Numerical results unveil that 1) the proposed element-wise ME position optimization algorithm outperforms the gradient descent algorithm; and 2) the ME-RIS significantly improves the communication rate compared to the conventional RIS with fixed-position elements.

Paper number 38:
Title: Waveform and Filter Design for Integrated Sensing and Communication Against Signal-dependent Modulated Jamming
Authors: Yu Zhou, Qiao Shi, Zhengchun Zhou, Zilong Liu, Pingzhi Fan
Abstract: This paper focuses on an integrated sensing and communication (ISAC) system in the presence of signal-dependent modulated jamming (SDMJ). Our goal is to suppress jamming while carrying out simultaneous communications and sensing. We minimize the integrated sidelobe level (ISL) of the mismatch filter output for the transmitted waveform and the integrated level (IL) of the mismatch filter output for the jamming, under the constraints of the loss in-processing gain (LPG) and the peak-to-average power ratio (PAPR) of the transmitted waveform. Meanwhile, the similarity constraint is introduced for information-bearing transmit waveform. We develop a decoupled majorization minimization (DMM) algorithm to solve the proposed multi-constrained optimization problem. In contrast to the existing approaches, the proposed algorithm transforms the difficult optimization problem involving two variables into two parallel sub-problems with one variable, thus significantly speeding up the convergence rate. Furthermore, fast Fourier transform (FFT) is introduced to compute the closed-form solution of each sub-problem, giving rise to a greatly reduced computation complexity. Simulation results demonstrate the capabilities of the proposed ISAC system which strikes a proper trade-off among sensing and jamming suppression.

Paper number 39:
Title: Gridless Chirp Parameter Retrieval via Constrained Two-Dimensional Atomic Norm Minimization
Authors: Dehui Yang, Feng Xi
Abstract: This paper is concerned with the fundamental problem of estimating chirp parameters from a mixture of linear chirp signals. Unlike most previous methods, which solve the problem by discretizing the parameter space and then estimating the chirp parameters, we propose a gridless approach by reformulating the inverse problem as a constrained two-dimensional atomic norm minimization from structured measurements. This reformulation enables the direct estimation of continuous-valued parameters without discretization, thereby resolving the issue of basis mismatch. An approximate semidefinite programming (SDP) is employed to solve the proposed convex program. Additionally, a dual polynomial is constructed to certify the optimality of the atomic decomposition. Numerical simulations demonstrate that exact recovery of chirp parameters is achievable using the proposed atomic norm minimization.

Paper number 40:
Title: Context-Aware Vision Language Foundation Models for Ocular Disease Screening in Retinal Images
Authors: Lucie Berger, Mathieu Lamard, Philippe Zhang, Laurent Borderie, Alexandre Le Guilcher, Pascale Massin, Béatrice Cochener, Gwenolé Quellec, Sarah Matta
Abstract: Foundation models are large-scale versatile systems trained on vast quantities of diverse data to learn generalizable representations. Their adaptability with minimal fine-tuning makes them particularly promising for medical imaging, where data variability and domain shifts are major challenges. Currently, two types of foundation models dominate the literature: self-supervised models and more recent vision-language models. In this study, we advance the application of vision-language foundation (VLF) models for ocular disease screening using the OPHDIAT dataset, which includes nearly 700,000 fundus photographs from a French diabetic retinopathy (DR) screening network. This dataset provides extensive clinical data (patient-specific information such as diabetic health conditions, and treatments), labeled diagnostics, ophthalmologists text-based findings, and multiple retinal images for each examination. Building on the FLAIR model $\unicode{x2013}$ a VLF model for retinal pathology classification $\unicode{x2013}$ we propose novel context-aware VLF models (e.g jointly analyzing multiple images from the same visit or taking advantage of past diagnoses and contextual data) to fully leverage the richness of the OPHDIAT dataset and enhance robustness to domain shifts. Our approaches were evaluated on both in-domain (a testing subset of OPHDIAT) and out-of-domain data (public datasets) to assess their generalization performance. Our model demonstrated improved in-domain performance for DR grading, achieving an area under the curve (AUC) ranging from 0.851 to 0.9999, and generalized well to ocular disease detection on out-of-domain data (AUC: 0.631-0.913).

Paper number 41:
Title: Sig2text, a Vision-language model for Non-cooperative Radar Signal Parsing
Authors: Hancong Feng KaiLI Jiang Bin tang
Abstract: Automatic non-cooperative analysis of intercepted radar signals is essential for intelligent equipment in both military and civilian domains. Accurate modulation identification and parameter estimation enable effective signal classification, threat assessment, and the development of countermeasures. In this paper, we propose a symbolic approach for radar signal recognition and parameter estimation based on a vision-language model that combines context-free grammar with time-frequency representation of radar waveforms. The proposed model, called Sig2text, leverages the power of vision transformers for time-frequency feature extraction and transformer-based decoders for symbolic parsing of radar waveforms. By treating radar signal recognition as a parsing problem, Sig2text can effectively recognize and parse radar waveforms with different modulation types and parameters. We evaluate the performance of Sig2text on a synthetic radar signal dataset and demonstrate its effectiveness in recognizing and parsing radar waveforms with varying modulation types and parameters. The training code of the model is available at this https URL.

Paper number 42:
Title: Variational Message Passing-based Multiobject Tracking for MIMO-Radars using Raw Sensor Signals
Authors: Anders Malthe Westerkam, Jakob Möderl, Erik Leitinger, Troels Pedersen
Abstract: In this paper, we propose a direct multiobject tracking (MOT) approach for MIMO-radar signals that operates on raw sensor data via variational message passing (VMP). Unlike classical track-before-detect (TBD) methods, which often rely on simplified likelihood models and exclude nuisance parameters (e.g., object amplitudes, noise variance), our method adopts a superimposed signal model and employs a mean-field approximation to jointly estimate both object existence and object states. By considering correlations within in the radar signal due to closely spaced objects and jointly estimating nuisance parameters, the proposed method achieves robust performance for close-by objects and in low-signal-to-noise ratio (SNR) regimes. Our numerical evaluation based on MIMO-radar signals demonstrate that our VMP-based direct-MOT method outperforms a detect-then-track (DTT) pipeline comprising a super-resolution sparse Bayesian learning (SBL)-based estimation stage followed by classical MOT using global nearest neighbour data association and a Kalman filter.

Paper number 43:
Title: Joint Hybrid Precoding and Multi-IRS Optimization for mmWave MU-MISO Communication Network
Authors: Fardad Rahkheir, Soroush Akhlaghi
Abstract: This paper attempts to jointly optimize the hybrid precoding (HP) and intelligent reflecting surfaces (IRS) beamforming matrices in a multi-IRS-aided mmWave communication network, utilizing the Alamouti scheme at the base station (BS). Considering the overall signal-to-noise ratio (SNR) as the objective function, the underlying problem is cast as an optimization problem, which is shown to be non-convex in general. To tackle the problem, noting that the unknown matrices contribute multiplicatively to the objective function, they are reformulated into two new matrices with rank constraints. Then, using the so-called inner approximation (IA) technique in conjunction with majorization-minimization (MM) approaches, these new matrices are solved iteratively. From one of these matrices, the IRS beamforming matrices can be effectively extracted. Meanwhile, HP precoding matrices can be solved separately through a new optimization problem aimed at minimizing the Euclidean distance between the fully digital (FD) precoder and HP analog/digital precoders. This is achieved through the use of a modified block coordinate descent (MBCD) algorithm. Simulation results demonstrate that the proposed algorithm outperforms various benchmark schemes in terms of achieving a higher achievable rate.

Paper number 44:
Title: Satellite Selection for In-Band Coexistence of Dense LEO Networks
Authors: Eunsun Kim, Ian P. Roberts, Taekyun Lee, Jeffrey G. Andrews
Abstract: We study spectrum sharing between two dense low-earth orbit (LEO) satellite constellations, an incumbent primary system and a secondary system that must respect interference protection constraints on the primary system. In particular, we propose a secondary satellite selection framework and algorithm that maximizes capacity while guaranteeing that the time-average interference and absolute interference inflicted upon each primary ground user never exceeds specified thresholds. We solve this NP-hard constrained, combinatorial satellite selection problem through Lagrangian relaxation to decompose it into simpler problems which can then be solved through subgradient methods. A high-fidelity simulation is developed based on public FCC filings and technical specifications of the Starlink and Kuiper systems. We use this case study to illustrate the effectiveness of our approach and that explicit protection is indeed necessary for healthy coexistence. We further demonstrate that deep learning models can be used to predict the primary satellite system associations, which helps the secondary system avoid inflicting excessive interference and maximize its own capacity.

Paper number 45:
Title: A Sigma Point-based Low Complexity Algorithm for Multipath-based SLAM in MIMO Systems
Authors: Anna Masiero, Alexander Venus, Erik Leitinger
Abstract: Multipath-based simultaneous localization and mapping (MP-SLAM) is a promising approach in wireless networks to jointly obtain position information of transmitters/receivers and information of the propagation environment. MP-SLAM models specular reflections at flat surfaces as virtual anchors (VAs), which are mirror images of base stations (BSs). Particlebased methods offer high flexibility and can approximate posterior probability density functions (PDFs) with complex shapes. However, they often require a large number of particles to counteract degeneracy in high-dimensional parameter spaces, leading to high runtimes. Conversely using too few particles leads to reduced estimation accuracy. In this paper, we propose a low-complexity algorithm for MP-SLAM in MIMO systems that employs sigma point (SP) approximations via the sum-product algorithm (SPA). Specifically, we use Gaussian approximations through SP-transformations, drastically reducing computational overhead without sacrificing accuracy. Nonlinearities are handled by SP updates, and moment matching approximates the Gaussian mixtures arising from probabilistic data association (PDA). Numerical results show that our method achieves considerably shorter runtimes than particle-based schemes, with comparable or even superior performance.

Paper number 46:
Title: Automated Functional Decomposition for Hybrid Zonotope Over-approximations with Application to LSTM Networks
Authors: Jonah J. Glunt, Jacob A. Siefert, Andrew F. Thompson, Justin Ruths, Herschel C. Pangborn
Abstract: Functional decomposition is a powerful tool for systems analysis because it can reduce a function of arbitrary input dimensions to the sum and superposition of functions of a single variable, thereby mitigating (or potentially avoiding) the exponential scaling often associated with analyses over high-dimensional spaces. This paper presents automated methods for constructing functional decompositions used to form set-based over-approximations of nonlinear functions, with particular focus on the hybrid zonotope set representation. To demonstrate these methods, we construct a hybrid zonotope set that over-approximates the input-output graph of a long short-term memory neural network, and use functional decomposition to represent a discrete hybrid automaton via a hybrid zonotope.

Paper number 47:
Title: Solla: Towards a Speech-Oriented LLM That Hears Acoustic Context
Authors: Junyi Ao, Dekun Chen, Xiaohai Tian, Wenjie Feng, Jun Zhang, Lu Lu, Yuxuan Wang, Haizhou Li, Zhizheng Wu
Abstract: Large Language Models (LLMs) have recently shown remarkable ability to process not only text but also multimodal inputs such as speech and audio. However, most existing models primarily focus on analyzing input signals using text instructions, overlooking scenarios in which speech instructions and audio are mixed and serve as inputs to the model. To address these challenges, we introduce Solla, a novel framework designed to understand speech-based questions and hear the acoustic context concurrently. Solla incorporates an audio tagging module to effectively identify and represent audio events, as well as an ASR-assisted prediction method to improve comprehension of spoken content. To rigorously evaluate Solla and other publicly available models, we propose a new benchmark dataset called SA-Eval, which includes three tasks: audio event classification, audio captioning, and audio question answering. SA-Eval has diverse speech instruction with various speaking styles, encompassing two difficulty levels, easy and hard, to capture the range of real-world acoustic conditions. Experimental results show that Solla performs on par with or outperforms baseline models on both the easy and hard test sets, underscoring its effectiveness in jointly understanding speech and audio.

Paper number 48:
Title: Experimental Validation of Distributed Dispatching of Multiple Active Distribution Networks Using the ADMM
Authors: Matthieu Jacobs, Hanmin Cai, Mario Paolone
Abstract: This paper presents the experimental validation of a framework for the coordinated dispatch and control of multiple active distribution networks (ADNs) hosting distributed energy resource (DER). We show that the presented method, which builds further on work done in [1], effectively allows to control multiple ADNs in a distributed way to ensure they achieve a common objective without revealing information on their DERs capabilities or grid model. This experimental validation is carried out using demonstrators at the DESL of EPFL and the NEST site at Empa, both in Switzerland. The coordination of the systems to share the flexibility of their controllable assets is demonstrated through a set of 24h experiments. Finally, the limitations of the method are discussed and future extensions proposed.

Paper number 49:
Title: Lyapunov-Based Graph Neural Networks for Adaptive Control of Multi-Agent Systems
Authors: Brandon C. Fallin, Cristian F. Nino, Omkar Sudhir Patil, Zachary I. Bell, Warren E. Dixon
Abstract: Graph neural networks (GNNs) have a message-passing framework in which vector messages are exchanged between graph nodes and updated using feedforward layers. The inclusion of distributed message-passing in the GNN architecture makes them ideally suited for distributed control and coordination tasks. Existing results develop GNN-based controllers to address a variety of multi-agent control problems while compensating for modeling uncertainties in the systems. However, these results use GNNs that are pre-trained offline. This paper provides the first result on GNNs with stability-driven online weight updates to address the multi-agent target tracking problem. Specifically, new Lyapunov-based distributed GNN and graph attention network (GAT)-based controllers are developed to adaptively estimate unknown target dynamics and address the second-order target tracking problem. A Lyapunov-based stability analysis is provided to guarantee exponential convergence of the target state estimates and agent states to a neighborhood of the target state. Numerical simulations show a 20.8% and 48.1% position tracking error performance improvement by the GNN and GAT architectures over a baseline DNN architecture, respectively.

Paper number 50:
Title: Priority-driven Constraints Softening in Safe MPC for Perturbed Systems
Authors: Ying Shuai Quan, Mohammad Jeddi, Francesco Prignoli, Paolo Falcone
Abstract: This paper presents a safe model predictive control (SMPC) framework designed to ensure the satisfaction of hard constraints for systems perturbed by an external disturbance. Such safety guarantees are ensured, despite the disturbance, by online softening a subset of adjustable constraints defined by the designer. The selection of the constraints to be softened is made online based on a predefined priority assigned to each adjustable constraint. The design of a learning-based algorithm enables real-time computation while preserving the original safety properties. Simulations results, obtained from an automated driving application, show that the proposed approach provides guarantees of collision-avoidance hard constraints despite the unpredicted behaviors of the surrounding environment.

Paper number 51:
Title: Probabilistic Flexibility Aggregation of DERs for Ancillary Services Provision
Authors: Matthieu Jacobs, Mario Paolone
Abstract: This paper presents a grid-aware probabilistic approach to compute the aggregated flexibility at the grid connection point (GCP) of active distribution networks (ADNs) to allow the participation of DERs in ancillary services (AS) markets. Specifically an optimal power flow (OPF) method using a linear network model is used to compute the aggregated capability for the provision of multiple AS. We start from the method proposed in [1] and extend it to allow for optimizing the provision of multiple services simultaneously, ensure cost-effectiveness of the used DERs and handle uncertainties in a probabilistic way. The allocation of individual DERs power flexibilities accounts for the operational costs associated to the provision of different services and ensures cost-effectiveness while maximizing the value of the advertised aggregated flexibility, assuming known service prices. Empirical uncertainty sets are obtained to achieve a predefined coverage of the probability distribution in line with recent developments in the Nordic AS markets. Finally, a feeder-decomposition approach is proposed to ensure the methods applicability to realistic distribution networks with a large number of buses. Different case studies show the effectiveness of the method, highlight the importance of accounting for network constraints and illustrate its applicability to realistic distribution systems.

Paper number 52:
Title: Energy-efficient Merging of Connected and Automated Vehicles using Control Barrier Functions
Authors: Shreshta Rajakumar Deshpande, Mrdjan Jankovic
Abstract: Highway merges present difficulties for human drivers and automated vehicles due to incomplete situational awareness and a need for a structured (precedence, order) environment, respectively. In this paper, an unstructured merge algorithm is presented for connected and automated vehicles. There is neither precedence nor established passing order through the merge point. The algorithm relies on Control Barrier Functions for safety (collision avoidance) and for coordination that arises from exponential instability of stall-equilibria in the inter-agent space. A Monte Carlo simulation comparison to a first-in-first-out approach shows improvement in traffic flow and a significant energy efficiency benefit.

Paper number 53:
Title: FedSCA: Federated Tuning with Similarity-guided Collaborative Aggregation for Heterogeneous Medical Image Segmentation
Authors: Yumin Zhang, Yan Gao, Haoran Duan, Hanqing Guo, Tejal Shah, Rajiv Ranjan, Bo Wei
Abstract: Transformer-based foundation models (FMs) have recently demonstrated remarkable performance in medical image segmentation. However, scaling these models is challenging due to the limited size of medical image datasets within isolated hospitals, where data centralization is restricted due to privacy concerns. These constraints, combined with the data-intensive nature of FMs, hinder their broader application. Integrating federated learning (FL) with foundation models (FLFM) fine-tuning offers a potential solution to these challenges by enabling collaborative model training without data sharing, thus allowing FMs to take advantage of a diverse pool of sensitive medical image data across hospitals/clients. However, non-independent and identically distributed (non-IID) data among clients, paired with computational and communication constraints in federated environments, presents an additional challenge that limits further performance improvements and remains inadequately addressed in existing studies. In this work, we propose a novel FLFM fine-tuning framework, \underline{\textbf{Fed}}erated tuning with \underline{\textbf{S}}imilarity-guided \underline{\textbf{C}}ollaborative \underline{\textbf{A}}ggregation (FedSCA), encompassing all phases of the FL process. This includes (1) specially designed parameter-efficient fine-tuning (PEFT) for local client training to enhance computational efficiency; (2) partial low-level adapter transmission for communication efficiency; and (3) similarity-guided collaborative aggregation (SGCA) on the server side to address non-IID issues. Extensive experiments on three FL benchmarks for medical image segmentation demonstrate the effectiveness of our proposed FedSCA, establishing new SOTA performance.

Paper number 54:
Title: Advancing MG Energy Management: A Rolling Horizon Optimization Framework for Three-Phase Unbalanced Networks Integrating Convex Formulations
Authors: Pablo Cortés, Alejandra Tabares, Fredy Franco
Abstract: Real-world three-phase microgrids face two interconnected challenges: 1. time-varying uncertainty from renewable generation and demand, and 2. persistent phase imbalances caused by uneven distributed energy resources DERs, load asymmetries, and grid faults. Conventional energy management systems fail to address these challenges holistically and static optimization methods lack adaptability to real-time fluctuations, while balanced three-phase models ignore critical asymmetries that degrade voltage stability and efficiency. This work introduces a dynamic rolling horizon optimization framework specifically designed for unbalanced three-phase microgrids. Unlike traditional two-stage stochastic approaches that fix decisions for the entire horizon, the rolling horizon algorithm iteratively updates decisions in response to real-time data. By solving a sequence of shorter optimization windows, each incorporating the latest system state and forecasts, the method achieves three key advantages: Adaptive Uncertainty Handling by continuously re plans operations to mitigate forecast errors. Phase Imbalance Correction by dynamically adjusts power flows across phases to minimize voltage deviations and losses caused by asymmetries, and computational Tractability, i.e., shorter optimization windows, combined with the mathematical mhodel, enable better decision making holding accuracy. For comparison purposes, we derive three optimization models: a nonlinear nonconvex model for high-fidelity offline planning, a convex quadratic approximation for day-ahead scheduling, and a linearized model to important for theoretical reasons such as decomposition algorithms.

Paper number 55:
Title: Exploiting Prior Knowledge in Preferential Learning of Individualized Autonomous Vehicle Driving Styles
Authors: Lukas Theiner, Sebastian Hirt, Alexander Steinke, Rolf Findeisen
Abstract: Trajectory planning for automated vehicles commonly employs optimization over a moving horizon - Model Predictive Control - where the cost function critically influences the resulting driving style. However, finding a suitable cost function that results in a driving style preferred by passengers remains an ongoing challenge. We employ preferential Bayesian optimization to learn the cost function by iteratively querying a passenger's preference. Due to increasing dimensionality of the parameter space, preference learning approaches might struggle to find a suitable optimum with a limited number of experiments and expose the passenger to discomfort when exploring the parameter space. We address these challenges by incorporating prior knowledge into the preferential Bayesian optimization framework. Our method constructs a virtual decision maker from real-world human driving data to guide parameter sampling. In a simulation experiment, we achieve faster convergence of the prior-knowledge-informed learning procedure compared to existing preferential Bayesian optimization approaches and reduce the number of inadequate driving styles sampled.

Paper number 56:
Title: Federated Continual 3D Segmentation With Single-round Communication
Authors: Can Peng, Qianhui Men, Pramit Saha, Qianye Yang, Cheng Ouyang, J. Alison Noble
Abstract: Federated learning seeks to foster collaboration among distributed clients while preserving the privacy of their local data. Traditionally, federated learning methods assume a fixed setting in which client data and learning objectives remain constant. However, in real-world scenarios, new clients may join, and existing clients may expand the segmentation label set as task requirements evolve. In such a dynamic federated analysis setup, the conventional federated communication strategy of model aggregation per communication round is suboptimal. As new clients join, this strategy requires retraining, linearly increasing communication and computation overhead. It also imposes requirements for synchronized communication, which is difficult to achieve among distributed clients. In this paper, we propose a federated continual learning strategy that employs a one-time model aggregation at the server through multi-model distillation. This approach builds and updates the global model while eliminating the need for frequent server communication. When integrating new data streams or onboarding new clients, this approach efficiently reuses previous client models, avoiding the need to retrain the global model across the entire federation. By minimizing communication load and bypassing the need to put unchanged clients online, our approach relaxes synchronization requirements among clients, providing an efficient and scalable federated analysis framework suited for real-world applications. Using multi-class 3D abdominal CT segmentation as an application task, we demonstrate the effectiveness of the proposed approach.

Paper number 57:
Title: The value of hedging against energy storage uncertainties when designing energy parks
Authors: Max Langtry, Ruchi Choudhary
Abstract: Energy storage is needed to match renewable generation to industrial loads in energy parks. However, the future performance of bulk storage technologies is currently highly uncertain. Due to the urgency of decarbonization targets, energy park projects must be designed and begun now. But, as uncertainty in storage performance reduces, a different technology than identified during initial design may turn out cheaper. Enabling flexibility so that design adaptations can be made as better information becomes available would lower the cost of decarbonizing industry. But having this flexibility is itself costly. This raises the question, "Is it worth it?" This study quantifies the benefit of retaining flexibility to adapt energy park designs and optionality over storage technology choice as uncertainty reduces, to determine whether it is economically worthwhile. It applies the Value of Information analysis framework to the sizing of wind, solar, and storage in an illustrative energy park model based on a real-world proposal near Rotterdam, considering uncertainty in storage efficiency, lifetime, and capital cost. Updating asset sizings after storage uncertainty reduced is found to reduce total costs by 18% on average. Having the option to switch storage technology choice as well reduces costs by a further 13%, which is substantially greater than the cost of providing storage optionality. Using two storage technologies in the energy park reduces costs by 14%, and in this case storage optionality is not worthwhile. These results are robust to the level of uncertainty reduction in storage performance, and the risk aversion of the system designer.

Paper number 58:
Title: Fast Two-photon Microscopy by Neuroimaging with Oblong Random Acquisition (NORA)
Authors: Esther Whang, Skyler Thomas, Ji Yi, Adam S. Charles
Abstract: Advances in neural imaging have enabled neuroscience to study how the joint activity of large neural populations conspire to produce perception, behavior and cognition. Despite many advances in optical methods, there exists a fundamental tradeoff between imaging speed, field of view, and resolution that limits the scope of neural imaging, especially for the raster-scanning multi-photon imaging needed for imaging deeper into the brain. One approach to overcoming this trade-off is in computational imaging: the co-development of optics and algorithms where the optics are designed to encode the target images into fewer measurements that are faster to acquire, and the algorithms compensate by inverting the optical image coding process to recover a larger or higher resolution image. We present here one such approach for raster-scanning two-photon imaging: Neuroimaging with Oblong Random Acquisition (NORA). NORA quickly acquires each frame in a microscopic video by subsampling only a fraction of the fast scanning lines, ignoring large portions of each frame. NORA mitigates the information loss by extending the point-spread function in the slow-scan direction to integrate the fluorescence of neighboring lines into a single set of measurements. By imaging different, randomly selected, lines at each frame, NORA diversifies the information collected across frames and enables video-level reconstruction. Rather than reconstruct the video frame-by-frame using image-level recovery, NORA recovers full video sequences through a nuclear-norm minimization (i.e., matrix completion) on the pixels-by-time matrix. We simulated NORA imaging using the Neural Anatomy and Optical Microscopy (NAOMi) biophysical simulation suite. Using these simulations we demonstrate that NORA imaging can accurately recover 400 um X 400 um fields of view at subsampling rates up to 20X, despite realistic noise and motion conditions.

Paper number 59:
Title: Value-Oriented Forecast Combinations for Unit Commitment
Authors: Mehrnoush Ghazanfariharandi, Robert Mieth
Abstract: Value-oriented forecasts for two-stage power system operational problems have been demonstrated to reduce cost, but prove to be computationally challenging for large-scale systems because the underlying optimization problem must be internalized into the forecast model training. Therefore, existing approaches typically scale poorly in the usable training data or require relaxations of the underlying optimization. This paper presents a method for value-oriented forecast combinations using progressive hedging, which unlocks high-fidelity, at-scale models and large-scale datasets in training. We also derive a direct one-shot training model for reference and study how different modifications of the training model impact the solution quality. Our method reduces operation cost by 1.8% on average and trains forecast combinations for a 2736-bus test system with one year of data within 20 hours.

Paper number 60:
Title: Synthetic Data Generation of Body Motion Data by Neural Gas Network for Emotion Recognition
Authors: Seyed Muhammad Hossein Mousavi
Abstract: In the domain of emotion recognition using body motion, the primary challenge lies in the scarcity of diverse and generalizable datasets. Automatic emotion recognition uses machine learning and artificial intelligence techniques to recognize a person's emotional state from various data types, such as text, images, sound, and body motion. Body motion poses unique challenges as many factors, such as age, gender, ethnicity, personality, and illness, affect its appearance, leading to a lack of diverse and robust datasets specifically for emotion recognition. To address this, employing Synthetic Data Generation (SDG) methods, such as Generative Adversarial Networks (GANs) and Variational Auto Encoders (VAEs), offers potential solutions, though these methods are often complex. This research introduces a novel application of the Neural Gas Network (NGN) algorithm for synthesizing body motion data and optimizing diversity and generation speed. By learning skeletal structure topology, the NGN fits the neurons or gas particles on body joints. Generated gas particles, which form the skeletal structure later on, will be used to synthesize the new body posture. By attaching body postures over frames, the final synthetic body motion appears. We compared our generated dataset against others generated by GANs, VAEs, and another benchmark algorithm, using benchmark metrics such as Fréchet Inception Distance (FID), Diversity, and a few more. Furthermore, we continued evaluation using classification metrics such as accuracy, precision, recall, and a few others. Joint-related features or kinematic parameters were extracted, and the system assessed model performance against unseen data. Our findings demonstrate that the NGN algorithm produces more realistic and emotionally distinct body motion data and does so with more synthesizing speed than existing methods.

Paper number 61:
Title: Content ARCs: Decentralized Content Rights in the Age of Generative AI
Authors: Kar Balan, Andrew Gilbert, John Collomosse
Abstract: The rise of Generative AI (GenAI) has sparked significant debate over balancing the interests of creative rightsholders and AI developers. As GenAI models are trained on vast datasets that often include copyrighted material, questions around fair compensation and proper attribution have become increasingly urgent. To address these challenges, this paper proposes a framework called \emph{Content ARCs} (Authenticity, Rights, Compensation). By combining open standards for provenance and dynamic licensing with data attribution, and decentralized technologies, Content ARCs create a mechanism for managing rights and compensating creators for using their work in AI training. We characterize several nascent works in the AI data licensing space within Content ARCs and identify where challenges remain to fully implement the end-to-end framework.

Paper number 62:
Title: Interpretable Unsupervised Joint Denoising and Enhancement for Real-World low-light Scenarios
Authors: Huaqiu Li, Xiaowan Hu, Haoqian Wang
Abstract: Real-world low-light images often suffer from complex degradations such as local overexposure, low brightness, noise, and uneven illumination. Supervised methods tend to overfit to specific scenarios, while unsupervised methods, though better at generalization, struggle to model these degradations due to the lack of reference images. To address this issue, we propose an interpretable, zero-reference joint denoising and low-light enhancement framework tailored for real-world scenarios. Our method derives a training strategy based on paired sub-images with varying illumination and noise levels, grounded in physical imaging principles and retinex theory. Additionally, we leverage the Discrete Cosine Transform (DCT) to perform frequency domain decomposition in the sRGB space, and introduce an implicit-guided hybrid representation strategy that effectively separates intricate compounded degradations. In the backbone network design, we develop retinal decomposition network guided by implicit degradation representation mechanisms. Extensive experiments demonstrate the superiority of our method. Code will be available at this https URL.

Paper number 63:
Title: PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing
Authors: Yanjia Huang, Renjie Li, Zhengzhong Tu
Abstract: We present PANDORA, a novel diffusion-based policy learning framework designed specifically for dexterous robotic piano performance. Our approach employs a conditional U-Net architecture enhanced with FiLM-based global conditioning, which iteratively denoises noisy action sequences into smooth, high-dimensional trajectories. To achieve precise key execution coupled with expressive musical performance, we design a composite reward function that integrates task-specific accuracy, audio fidelity, and high-level semantic feedback from a large language model (LLM) oracle. The LLM oracle assesses musical expressiveness and stylistic nuances, enabling dynamic, hand-specific reward adjustments. Further augmented by a residual inverse-kinematics refinement policy, PANDORA achieves state-of-the-art performance in the ROBOPIANIST environment, significantly outperforming baselines in both precision and expressiveness. Ablation studies validate the critical contributions of diffusion-based denoising and LLM-driven semantic feedback in enhancing robotic musicianship. Videos available at: this https URL

Paper number 64:
Title: Sampling Decisions
Authors: Michael Chertkov, Sungsoo Ahn, Hamidreza Behjoo
Abstract: In this manuscript we introduce a novel Decision Flow (DF) framework for sampling from a target distribution while incorporating additional guidance from a prior sampler. DF can be viewed as an AI driven algorithmic reincarnation of the Markov Decision Process (MDP) approach in Stochastic Optimal Control. It extends the continuous space, continuous time path Integral Diffusion sampling technique to discrete time and space, while also generalizing the Generative Flow Network framework. In its most basic form, an explicit, Neural Network (NN) free formulation, DF leverages the linear solvability of the the underlying MDP to adjust the transition probabilities of the prior sampler. The resulting Markov Process is expressed as a convolution of the reverse time Green's function of the prior sampling with the target distribution. We illustrate the DF framework through an example of sampling from the Ising model, discuss potential NN based extensions, and outline how DF can enhance guided sampling across various applications.

Paper number 65:
Title: Link Prediction and Navigability of Multiplex Energy Networks
Authors: Muhammad Kazim, Harun Pirim, Chau Le, Trung Le, Om Prakash Yadav
Abstract: In modern energy networks, where operational efficiency and resilience are critical, this study introduces an in-depth analysis from a multiplex network perspective - defined as a network where multiple types of connections exist between the same set of nodes. Utilizing Belgium's electricity and gas networks, we construct a five-layer multiplex network to simulate random node shutdown scenarios. We tailored the Jaccard and Adamic-Adar link prediction algorithms by integrating the concept of exclusive neighbors, thereby enhancing prediction accuracy with such multi-layered information. Emphasizing navigability, i.e., the network's ability to maintain resilience and efficiency under random failures, we analyze the impact of different random walk strategies and strategic link additions at various stages - individual layers, two-layer combinations, and three-layer combinations - on the network's navigability. Directed networks show modest improvements with new links, partly due to trapping effects, where a random walker can become circumscribed within certain network loops, limiting reachability across the network. In contrast, the undirected networks demonstrate notable increases in navigability with new link additions. Spectral gap analysis in directed networks indicates that new link additions can aid and impede navigability, depending on their configuration. This study deepens our understanding of multiplex energy network navigability and highlights the importance of strategic link additions influenced by random walk strategies in these networks.

Paper number 66:
Title: Core-Periphery Principle Guided State Space Model for Functional Connectome Classification
Authors: Minheng Chen, Xiaowei Yu, Jing Zhang, Tong Chen, Chao Cao, Yan Zhuang, Yanjun Lyu, Lu Zhang, Tianming Liu, Dajiang Zhu
Abstract: Understanding the organization of human brain networks has become a central focus in neuroscience, particularly in the study of functional connectivity, which plays a crucial role in diagnosing neurological disorders. Advances in functional magnetic resonance imaging and machine learning techniques have significantly improved brain network analysis. However, traditional machine learning approaches struggle to capture the complex relationships between brain regions, while deep learning methods, particularly Transformer-based models, face computational challenges due to their quadratic complexity in long-sequence modeling. To address these limitations, we propose a Core-Periphery State-Space Model (CP-SSM), an innovative framework for functional connectome classification. Specifically, we introduce Mamba, a selective state-space model with linear complexity, to effectively capture long-range dependencies in functional brain networks. Furthermore, inspired by the core-periphery (CP) organization, a fundamental characteristic of brain networks that enhances efficient information transmission, we design CP-MoE, a CP-guided Mixture-of-Experts that improves the representation learning of brain connectivity patterns. We evaluate CP-SSM on two benchmark fMRI datasets: ABIDE and ADNI. Experimental results demonstrate that CP-SSM surpasses Transformer-based models in classification performance while significantly reducing computational complexity. These findings highlight the effectiveness and efficiency of CP-SSM in modeling brain functional connectivity, offering a promising direction for neuroimaging-based neurological disease diagnosis.

Paper number 67:
Title: Reinforcement Learning-Based Neuroadaptive Control of Robotic Manipulators under Deferred Constraints
Authors: Hamed Rahimi Nohooji, Abolfazl Zaraki, Holger Voos
Abstract: This paper presents a reinforcement learning-based neuroadaptive control framework for robotic manipulators operating under deferred constraints. The proposed approach improves traditional barrier Lyapunov functions by introducing a smooth constraint enforcement mechanism that offers two key advantages: (i) it minimizes control effort in unconstrained regions and progressively increases it near constraints, improving energy efficiency, and (ii) it enables gradual constraint activation through a prescribed-time shifting function, allowing safe operation even when initial conditions violate constraints. To address system uncertainties and improve adaptability, an actor-critic reinforcement learning framework is employed. The critic network estimates the value function, while the actor network learns an optimal control policy in real time, enabling adaptive constraint handling without requiring explicit system modeling. Lyapunov-based stability analysis guarantees the boundedness of all closed-loop signals. The effectiveness of the proposed method is validated through numerical simulations.

Paper number 68:
Title: Parking control of an active-joint center-articulated mobile robot based on feedback from beacons
Authors: Mehdi Delrobaei, Kenneth McIsaac
Abstract: This paper presents an autonomous parking control system for an active-joint center-articulated mobile robot. We begin by proposing a kinematic model of the robot, then derive a control law designed to stabilize the vehicle's configuration within a small neighborhood of the target position. The control law is developed using Lyapunov techniques and is based on the robot's equations of motion in polar coordinates. Additionally, a beacon-based guidance system provides real-time feedback on the target's position and orientation. Simulation results demonstrate the robot's capability to start from arbitrary initial positions and orientations and successfully achieve parking.

Paper number 69:
Title: Nonlinear Modeling and Observability of a Planar Multi-Link Robot with Link Thrusters
Authors: Nicholas B. Andrews, Kristi A. Morgansen
Abstract: This work is motivated by the development of cooperative teams of small, soft underwater robots designed to accomplish complex tasks through collective behavior. These robots take inspiration from biology: salps are gelatinous, jellyfish-like marine animals that utilize jet propulsion for maneuvering and can physically connect to form dynamic chains of arbitrary shape and size. The primary contributions of this research are twofold: first, we adapt a planar nonlinear multi-link snake robot model to model a planar multi-link salp-inspired system by removing joint actuators, introducing link thrusters, and allowing for non-uniform link lengths, masses, and moments of inertia. Second, we conduct a nonlinear observability analysis of the multi-link system with link thrusters, showing that the link angles, angular velocities, masses, and moments of inertia are locally observable when equipped with inertial measurement units and operating under specific thruster conditions. This research provides a theoretical foundation for modeling and estimating both the state and intrinsic parameters of a multi-link system with link thrusters, which are essential for effective controller design and performance.

Paper number 70:
Title: Pruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure
Authors: Fatemeh Dehrouyeh, Ibrahim Shaer, Soodeh Nikan, Firouz Badrkhani Ajaei, Abdallah Shami
Abstract: With the growing need for real-time processing on IoT devices, optimizing machine learning (ML) models' size, latency, and computational efficiency is essential. This paper investigates a pruning method for anomaly detection in resource-constrained environments, specifically targeting Electric Vehicle Charging Infrastructure (EVCI). Using the CICEVSE2024 dataset, we trained and optimized three models-Multi-Layer Perceptron (MLP), Long Short-Term Memory (LSTM), and XGBoost-through hyperparameter tuning with Optuna, further refining them using SHapley Additive exPlanations (SHAP)-based feature selection (FS) and unstructured pruning techniques. The optimized models achieved significant reductions in model size and inference times, with only a marginal impact on their performance. Notably, our findings indicate that, in the context of EVCI, pruning and FS can enhance computational efficiency while retaining critical anomaly detection capabilities.

Paper number 71:
Title: Project Jenkins: Turning Monkey Neural Data into Robotic Arm Movement, and Back
Authors: Andrii Zahorodnii, Dima Yanovsky
Abstract: Project Jenkins explores how neural activity in the brain can be decoded into robotic movement and, conversely, how movement patterns can be used to generate synthetic neural data. Using real neural data recorded from motor and premotor cortex areas of a macaque monkey named Jenkins, we develop models for decoding (converting brain signals into robotic arm movements) and encoding (simulating brain activity corresponding to a given movement). For the interface between the brain simulation and the physical world, we utilized Koch v1.1 leader and follower robotic arms. We developed an interactive web console that allows users to generate synthetic brain data from joystick movements in real time. Our results are a step towards brain-controlled robotics, prosthetics, and enhancing normal motor function. By accurately modeling brain activity, we take a step toward flexible brain-computer interfaces that generalize beyond predefined movements. To support the research community, we provide open source tools for both synthetic data generation and neural decoding, fostering reproducibility and accelerating progress. The project is available at this https URL

Paper number 72:
Title: Communication-Efficient Distributed On-Device LLM Inference Over Wireless Networks
Authors: Kai Zhang, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief
Abstract: Large language models (LLMs) have demonstrated remarkable success across various application domains, but their enormous sizes and computational demands pose significant challenges for deployment on resource-constrained edge devices. To address this issue, we propose a novel distributed on-device LLM inference framework that leverages tensor parallelism to partition the neural network tensors (e.g., weight matrices) of one LLM across multiple edge devices for collaborative inference. A key challenge in tensor parallelism is the frequent all-reduce operations for aggregating intermediate layer outputs across participating devices, which incurs significant communication overhead. To alleviate this bottleneck, we propose an over-the-air computation (AirComp) approach that harnesses the analog superposition property of wireless multiple-access channels to perform fast all-reduce steps. To utilize the heterogeneous computational capabilities of edge devices and mitigate communication distortions, we investigate a joint model assignment and transceiver optimization problem to minimize the average transmission error. The resulting mixed-timescale stochastic non-convex optimization problem is intractable, and we propose an efficient two-stage algorithm to solve it. Moreover, we prove that the proposed algorithm converges almost surely to a stationary point of the original problem. Comprehensive simulation results will show that the proposed framework outperforms existing benchmark schemes, achieving up to 5x inference speed acceleration and improving inference accuracy.

Paper number 73:
Title: Online Optimization with Unknown Time-varying Parameters
Authors: Shivanshu Tripathi, Abed AlRahman Al Makdah, Fabio Pasqualetti
Abstract: In this paper, we study optimization problems where the cost function contains time-varying parameters that are unmeasurable and evolve according to linear, yet unknown, dynamics. We propose a solution that leverages control theoretic tools to identify the dynamics of the parameters, predict their evolution, and ultimately compute a solution to the optimization problem. The identification of the dynamics of the time-varying parameters is done online using measurements of the gradient of the cost function. This system identification problem is not standard, since the output matrix is known and the dynamics of the parameters must be estimated in the original coordinates without similarity transformations. Interestingly, our analysis shows that, under mild conditions that we characterize, the identification of the parameters dynamics and, consequently, the computation of a time-varying solution to the optimization problem, requires only a finite number of measurements of the gradient of the cost function. We illustrate the effectiveness of our algorithm on a series of numerical examples.

Paper number 74:
Title: Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability and Weight Convergence
Authors: Yidan Wu, Yu Yu, Jianan Zhang, Li Jin
Abstract: We consider the traffic control problem of dynamic routing over parallel servers, which arises in a variety of engineering systems such as transportation and data transmission. We propose a semi-gradient, on-policy algorithm that learns an approximate optimal routing policy. The algorithm uses generic basis functions with flexible weights to approximate the value function across the unbounded state space. Consequently, the training process lacks Lipschitz continuity of the gradient, boundedness of the temporal-difference error, and a prior guarantee on ergodicity, which are the standard prerequisites in existing literature on reinforcement learning theory. To address this, we combine a Lyapunov approach and an ordinary differential equation-based method to jointly characterize the behavior of traffic state and approximation weights. Our theoretical analysis proves that the training scheme guarantees traffic state stability and ensures almost surely convergence of the weights to the approximate optimum. We also demonstrate via simulations that our algorithm attains significantly faster convergence than neural network-based methods with an insignificant approximation error.

Paper number 75:
Title: Shushing! Let's Imagine an Authentic Speech from the Silent Video
Authors: Jiaxin Ye, Hongming Shan
Abstract: Vision-guided speech generation aims to produce authentic speech from facial appearance or lip motions without relying on auditory signals, offering significant potential for applications such as dubbing in filmmaking and assisting individuals with aphonia. Despite recent progress, existing methods struggle to achieve unified cross-modal alignment across semantics, timbre, and emotional prosody from visual cues, prompting us to propose Consistent Video-to-Speech (CV2S) as an extended task to enhance cross-modal consistency. To tackle emerging challenges, we introduce ImaginTalk, a novel cross-modal diffusion framework that generates faithful speech using only visual input, operating within a discrete space. Specifically, we propose a discrete lip aligner that predicts discrete speech tokens from lip videos to capture semantic information, while an error detector identifies misaligned tokens, which are subsequently refined through masked language modeling with BERT. To further enhance the expressiveness of the generated speech, we develop a style diffusion transformer equipped with a face-style adapter that adaptively customizes identity and prosody dynamics across both the channel and temporal dimensions while ensuring synchronization with lip-aware semantic features. Extensive experiments demonstrate that ImaginTalk can generate high-fidelity speech with more accurate semantic details and greater expressiveness in timbre and emotion compared to state-of-the-art baselines. Demos are shown at our project page: this https URL.

Paper number 76:
Title: Ultrasound Image-to-Video Synthesis via Latent Dynamic Diffusion Models
Authors: Tingxiu Chen, Yilei Shi, Zixuan Zheng, Bingcong Yan, Jingliang Hu, Xiao Xiang Zhu, Lichao Mou
Abstract: Ultrasound video classification enables automated diagnosis and has emerged as an important research area. However, publicly available ultrasound video datasets remain scarce, hindering progress in developing effective video classification models. We propose addressing this shortage by synthesizing plausible ultrasound videos from readily available, abundant ultrasound images. To this end, we introduce a latent dynamic diffusion model (LDDM) to efficiently translate static images to dynamic sequences with realistic video characteristics. We demonstrate strong quantitative results and visually appealing synthesized videos on the BUSV benchmark. Notably, training video classification models on combinations of real and LDDM-synthesized videos substantially improves performance over using real data alone, indicating our method successfully emulates dynamics critical for discrimination. Our image-to-video approach provides an effective data augmentation solution to advance ultrasound video analysis. Code is available at this https URL.

Paper number 77:
Title: Disentangling Modes and Interference in the Spectrogram of Multicomponent Signals
Authors: Kévin Polisano (SVH), Sylvain Meignen (DAO), Nils Laurent (Phys-ENS), Hubert Leterme (ENSICAEN)
Abstract: In this paper, we investigate how the spectrogram of multicomponent signals can be decomposed into a mode part and an interference part. We explore two approaches: (i) a variational method inspired by texture-geometry decomposition in image processing, and (ii) a supervised learning approach using a U-Net architecture, trained on a dataset encompassing diverse interference patterns and noise conditions. Once the interference component is identified, we explain how it enables us to define a criterion to locally adapt the window length used in the definition of the spectrogram, for the sake of improving ridge detection in the presence of close modes. Numerical experiments illustrate the advantages and limitations of both approaches for spectrogram decomposition, highlighting their potential for enhancing time-frequency analysis in the presence of strong interference.

Paper number 78:
Title: Low-Complexity Patch-based No-Reference Point Cloud Quality Metric exploiting Weighted Structure and Texture Features
Authors: Michael Neri, Federica Battisti
Abstract: During the compression, transmission, and rendering of point clouds, various artifacts are introduced, affecting the quality perceived by the end user. However, evaluating the impact of these distortions on the overall quality is a challenging task. This study introduces PST-PCQA, a no-reference point cloud quality metric based on a low-complexity, learning-based framework. It evaluates point cloud quality by analyzing individual patches, integrating local and global features to predict the Mean Opinion Score. In summary, the process involves extracting features from patches, combining them, and using correlation weights to predict the overall quality. This approach allows us to assess point cloud quality without relying on a reference point cloud, making it particularly useful in scenarios where reference data is unavailable. Experimental tests on three state-of-the-art datasets show good prediction capabilities of PST-PCQA, through the analysis of different feature pooling strategies and its ability to generalize across different datasets. The ablation study confirms the benefits of evaluating quality on a patch-by-patch basis. Additionally, PST-PCQA's light-weight structure, with a small number of parameters to learn, makes it well-suited for real-time applications and devices with limited computational capacity. For reproducibility purposes, we made code, model, and pretrained weights available at this https URL.

Paper number 79:
Title: InsectSet459: an open dataset of insect sounds for bioacoustic machine learning
Authors: Marius Faiß, Burooj Ghani, Dan Stowell
Abstract: Automatic recognition of insect sound could help us understand changing biodiversity trends around the world -- but insect sounds are challenging to recognize even for deep learning. We present a new dataset comprised of 26399 audio files, from 459 species of Orthoptera and Cicadidae. It is the first large-scale dataset of insect sound that is easily applicable for developing novel deep-learning methods. Its recordings were made with a variety of audio recorders using varying sample rates to capture the extremely broad range of frequencies that insects produce. We benchmark performance with two state-of-the-art deep learning classifiers, demonstrating good performance but also significant room for improvement in acoustic insect classification. This dataset can serve as a realistic test case for implementing insect monitoring workflows, and as a challenging basis for the development of audio representation methods that can handle highly variable frequencies and/or sample rates.

Paper number 80:
Title: Proximal Gradient Dynamics and Feedback Control for Equality-Constrained Composite Optimization
Authors: Veronica Centorrino, Francesca Rossi, Francesco Bullo, Giovanni Russo
Abstract: This paper studies equality-constrained composite minimization problems. This class of problems, capturing regularization terms and convex inequality constraints, naturally arises in a wide range of engineering and machine learning applications. To tackle these minimization problems, we introduce the \emph{proportional--integral proximal gradient dynamics} (PI--PGD): a closed-loop system where the Lagrange multipliers are control inputs and states are the problem decision variables. First, we establish the equivalence between the minima of the optimization problem and the equilibria of the PI--PGD. Then, leveraging tools from contraction theory, we give a comprehensive convergence analysis for the dynamics, showing linear--exponential convergence towards the equilibrium. That is, the distance between each solution and the equilibrium is upper bounded by a function that first decreases linearly and then exponentially. Our findings are illustrated numerically on a set of representative examples, which include an application to entropic-regularized optimal transport.

Paper number 81:
Title: Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control
Authors: Stelios Zarifis, Ioannis Kordonis, Petros Maragos
Abstract: We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic framework for uncertainty-aware prediction and decision-making in partially observable stochastic systems by integrating diffusion-based time series forecasting models in Model Predictive Control algorithms. In our approach, a diffusion-based time series forecasting model is used to probabilistically estimate the evolution of the system's stochastic components. These forecasts are then incorporated into MPC algorithms to estimate future trajectories and optimize action selection under the uncertainty of the future. We evaluate the framework on the task of energy arbitrage, where a Battery Energy Storage System participates in the day-ahead electricity market of the New York state. Experimental results indicate that our model-based approach with a diffusion-based forecaster significantly outperforms both implementations with classical forecasting methods and model-free reinforcement learning baselines.

Paper number 82:
Title: A Comparative Study of Human Motion Models in Reinforcement Learning Algorithms for Social Robot Navigation
Authors: Tommaso Van Der Meer, Andrea Garulli, Antonio Giannitrapani, Renato Quartullo
Abstract: Social robot navigation is an evolving research field that aims to find efficient strategies to safely navigate dynamic environments populated by humans. A critical challenge in this domain is the accurate modeling of human motion, which directly impacts the design and evaluation of navigation algorithms. This paper presents a comparative study of two popular categories of human motion models used in social robot navigation, namely velocity-based models and force-based models. A system-theoretic representation of both model types is presented, which highlights their common feedback structure, although with different state variables. Several navigation policies based on reinforcement learning are trained and tested in various simulated environments involving pedestrian crowds modeled with these approaches. A comparative study is conducted to assess performance across multiple factors, including human motion model, navigation policy, scenario complexity and crowd density. The results highlight advantages and challenges of different approaches to modeling human behavior, as well as their role during training and testing of learning-based navigation policies. The findings offer valuable insights and guidelines for selecting appropriate human motion models when designing socially-aware robot navigation systems.

Paper number 83:
Title: A Coupled Friedkin-Johnsen Model of Popularity Dynamics in Social Media
Authors: Gaya Cocca, Paolo Frasca, Chiara Ravazzi
Abstract: Popularity dynamics in social media depend on a complex interplay of social influence between users and popularity-based recommendations that are provided by the platforms. In this work, we introduce a discrete-time dynamical system to model the evolution of popularity on social media. Our model generalizes the well-known Friedkin-Johnsen model to a set of influencers vying for popularity. We study the asymptotic behavior of this model and illustrate it with numerical examples. Our results highlight the interplay of social influence, past popularity, and content quality in determining the popularity of influencers.

Paper number 84:
Title: A Robust Routing Protocol for 5G Mesh Networks
Authors: Niclas Führling, Ivan Alexander Morales Sandoval, Giuseppe Thadeu Freitas de Abreu
Abstract: We consider a novel routing protocol suitable for ad-hoc networks with dynamically changing topologies, such as DECT 2020 NR (NR+) systems, which often lead to missing links between the nodes and thus, incomplete or inefficient routes. A key point of the proposed protocol is the combination of network discovery and matrix completion techniques, which allow the nodes to establish communication paths efficiently and reliably. Additionally, multihop localization is performed to estimate the location of the nodes without needing to broadcast each node's geographical position, thus preserving privacy during the routing process and enabling nodes in the network to independently find potentially missing paths in a decentralized manner instead of flooding the whole network. Simulation results illustrate the good performance of the proposed technique in terms of the average number of hops of the obtained routes in different scenarios, with different network densities and amounts of incompleteness.

Paper number 85:
Title: A Personalized Data-Driven Generative Model of Human Motion
Authors: Angelo Di Porzio, Marco Coraggio
Abstract: The deployment of autonomous virtual avatars (in extended reality) and robots in human group activities - such as rehabilitation therapy, sports, and manufacturing - is expected to increase as these technologies become more pervasive. Designing cognitive architectures and control strategies to drive these agents requires realistic models of human motion. However, existing models only provide simplified descriptions of human motor behavior. In this work, we propose a fully data-driven approach, based on Long Short-Term Memory neural networks, to generate original motion that captures the unique characteristics of specific individuals. We validate the architecture using real data of scalar oscillatory motion. Extensive analyses show that our model effectively replicates the velocity distribution and amplitude envelopes of the individual it was trained on, remaining different from other individuals, and outperforming state-of-the-art models in terms of similarity to human data.

Paper number 86:
Title: Sensing-Based Beamformed Resource Allocation in Standalone Millimeter-Wave Vehicular Networks
Authors: Alessandro Traspadini, Anay Ajit Deshpande, Marco Giordani, Chinmay Mahabal, Takayuki Shimizu, Michele Zorzi
Abstract: In 3GPP New Radio (NR) Vehicle-to-Everything (V2X), the new standard for next-generation vehicular networks, vehicles can autonomously select sidelink resources for data transmission, which permits network operations without cellular coverage. However, standalone resource allocation is uncoordinated, and is complicated by the high mobility of the nodes that may introduce unforeseen channel collisions (e.g., when a transmitting vehicle changes path) or free up resources (e.g., when a vehicle moves outside of the communication area). Moreover, unscheduled resource allocation is prone to the hidden node and exposed node problems, which are particularly critical considering directional transmissions. In this paper, we implement and demonstrate a new channel access scheme for NR V2X in Frequency Range 2 (FR2), i.e., at millimeter wave (mmWave) frequencies, based on directional and beamformed transmissions along with Sidelink Control Information (SCI) to select resources for transmission. We prove via simulation that this approach can reduce the probability of collision for resource allocation, compared to a baseline solution that does not configure SCI transmissions.

Paper number 87:
Title: Polynomial and Parallelizable Preconditioning for Block Tridiagonal Positive Definite Matrix
Authors: Shaohui Yang, Toshiyuki Ohtsuka, Brian Plancher, Colin N. Jones
Abstract: The efficient solution of moderately large-scale linear systems arising from the KKT conditions in optimal control problems (OCPs) is a critical challenge in robotics. With the stagnation of Moore's law, there is growing interest in leveraging GPU-accelerated iterative methods, and corresponding parallel preconditioners, to overcome these computational challenges. To improve the computational performance of such solvers, we introduce a parallel-friendly, parametrized multi-splitting polynomial preconditioner framework that leverages positive and negative factors. Our approach results in improved convergence of the linear systems solves needed in OCPs. We construct and prove the optimal parametrization of multi-splitting theoretically and demonstrate empirically a 76% reduction in condition number and 46% in iteration counts on a series of numerical benchmarks.

Paper number 88:
Title: Brunovsky Riccati Recursion for Linear Model Predictive Control
Authors: Shaohui Yang, Toshiyuki Ohtsuka, Colin N. Jones
Abstract: In almost all algorithms for Model Predictive Control (MPC), the most time-consuming step is to solve some form of Linear Quadratic (LQ) Optimal Control Problem (OCP) repeatedly. The commonly recognized best option for this is a Riccati recursion based solver, which has a time complexity of $\mathcal{O}(N(n_x^3 + n_x^2 n_u + n_x n_u^2 + n_u^3))$. In this paper, we propose a novel \textit{Brunovsky Riccati Recursion} algorithm to solve LQ OCPs for Linear Time Invariant (LTI) systems. The algorithm transforms the system into Brunovsky form, formulates a new LQ cost (and constraints, if any) in Brunovsky coordinates, performs the Riccati recursion there, and converts the solution back. Due to the sparsity (block-diagonality and zero-one pattern per block) of Brunovsky form and the data parallelism introduced in the cost, constraints, and solution transformations, the time complexity of the new method is greatly reduced to $\mathcal{O}(n_x^3 + N(n_x^2 n_u + n_x n_u^2 + n_u^3))$ if $N$ threads/cores are available for parallel computing.

Paper number 89:
Title: Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer
Authors: Abhi Kamboj, Minh N. Do
Abstract: Multimodal alignment aims to construct a joint latent vector space where two modalities representing the same concept map to the same vector. We formulate this as an inverse problem and show that under certain conditions perfect alignment can be achieved. We then address a specific application of alignment referred to as cross-modal transfer. Unsupervised cross-modal transfer aims to leverage a model trained with one modality to perform inference on another modality, without any labeled fine-tuning on the new modality. Assuming that semantic classes are represented as a mixture of Gaussians in the latent space, we show how cross-modal transfer can be performed by projecting the data points from the representation space onto different subspaces representing each modality. Our experiments on synthetic multimodal Gaussian data verify the effectiveness of our perfect alignment and cross-modal transfer method. We hope these findings inspire further exploration of the applications of perfect alignment and the use of Gaussian models for cross-modal learning.

Paper number 90:
Title: Blocked Cholesky factorization updates of the Riccati recursion using hyperbolic Householder transformations
Authors: Pieter Pas, Panagiotis Patrinos
Abstract: Newton systems in quadratic programming (QP) methods are often solved using direct Cholesky or LDL factorizations. When the linear systems in successive iterations differ by a low-rank modification (as is common in active set and augmented Lagrangian methods), updating the existing factorization can offer significant performance improvements over recomputing a full Cholesky factorization. We review the hyperbolic Householder transformation, and demonstrate its usefulness in describing low-rank Cholesky factorization updates. By applying this hyperbolic Householder-based framework to the well-known Riccati recursion for solving saddle-point problems with optimal control structure, we develop a novel algorithm for updating the factorizations used in optimization solvers for optimal control. Specifically, the proposed method can be used to efficiently solve the semismooth Newton systems that are at the core of the augmented Lagrangian-based QPALM-OCP solver. An optimized open-source implementation of the proposed factorization update routines is provided as well.

Paper number 91:
Title: Friction-Scaled Vibrotactile Feedback for Real-Time Slip Detection in Manipulation using Robotic Sixth Finger
Authors: Naqash Afzal, Basma Hasanen, Lakmal Seneviratne, Oussama Khatib, Irfan Hussain
Abstract: The integration of extra-robotic limbs/fingers to enhance and expand motor skills, particularly for grasping and manipulation, possesses significant challenges. The grasping performance of existing limbs/fingers is far inferior to that of human hands. Human hands can detect onset of slip through tactile feedback originating from tactile receptors during the grasping process, enabling precise and automatic regulation of grip force. The frictional information is perceived by humans depending upon slip happening between finger and object. Enhancing this capability in extra-robotic limbs or fingers used by humans is challenging. To address this challenge, this paper introduces novel approach to communicate frictional information to users through encoded vibrotactile cues. These cues are conveyed on onset of incipient slip thus allowing users to perceive friction and ultimately use this information to increase force to avoid dropping of object. In a 2-alternative forced-choice protocol, participants gripped and lifted a glass under three different frictional conditions, applying a normal force of 3.5 N. After reaching this force, glass was gradually released to induce slip. During this slipping phase, vibrations scaled according to static coefficient of friction were presented to users, reflecting frictional conditions. The results suggested an accuracy of 94.53 p/m 3.05 (mean p/mSD) in perceiving frictional information upon lifting objects with varying friction. The results indicate effectiveness of using vibrotactile feedback for sensory feedback, allowing users of extra-robotic limbs or fingers to perceive frictional information. This enables them to assess surface properties and adjust grip force according to frictional conditions, enhancing their ability to grasp, manipulate objects more effectively.

Paper number 92:
Title: More Information is Not Always Better: Connections between Zero-Sum Local Nash Equilibria in Feedback and Open-Loop Information Patterns
Authors: Kushagra Gupta, Ross Allen, David Fridovich-Keil, Ufuk Topcu
Abstract: Non-cooperative dynamic game theory provides a principled approach to modeling sequential decision-making among multiple noncommunicative agents. A key focus has been on finding Nash equilibria in two-agent zero-sum dynamic games under various information structures. A well-known result states that in linear-quadratic games, unique Nash equilibria under feedback and open-loop information structures yield identical trajectories. Motivated by two key perspectives -- (i) many real-world problems extend beyond linear-quadratic settings and lack unique equilibria, making only local Nash equilibria computable, and (ii) local open-loop Nash equilibria (OLNE) are easier to compute than local feedback Nash equilibria (FBNE) -- it is natural to ask whether a similar result holds for local equilibria in zero-sum games. To this end, we establish that for a broad class of zero-sum games with potentially nonconvex-nonconcave objectives and nonlinear dynamics: (i) the state/control trajectory of a local FBNE satisfies local OLNE first-order optimality conditions, and vice versa, (ii) a local FBNE trajectory satisfies local OLNE second-order necessary conditions, (iii) a local FBNE trajectory satisfying feedback sufficiency conditions also constitutes a local OLNE, and (iv) with additional hard constraints on agents' actuations, a local FBNE where strict complementarity holds also satisfies local OLNE first-order optimality conditions, and vice versa.

Paper number 93:
Title: Audio-Visual Speech Enhancement Using Self-supervised Learning to Improve Speech Intelligibility in Cochlear Implant Simulations
Authors: Richard Lee Lai, Jen-Cheng Hou, I-Chun Chern, Kuo-Hsuan Hung, Yi-Ting Chen, Mandar Gogate, Tughrul Arslan, Amir Hussain, Yu Tsao
Abstract: Individuals with hearing impairments face challenges in their ability to comprehend speech, particularly in noisy environments. The aim of this study is to explore the effectiveness of audio-visual speech enhancement (AVSE) in enhancing the intelligibility of vocoded speech in cochlear implant (CI) simulations. Notably, the study focuses on a challenged scenario where there is limited availability of training data for the AVSE task. To address this problem, we propose a novel deep neural network framework termed Self-Supervised Learning-based AVSE (SSL-AVSE). The proposed SSL-AVSE combines visual cues, such as lip and mouth movements, from the target speakers with corresponding audio signals. The contextually combined audio and visual data are then fed into a Transformer-based SSL AV-HuBERT model to extract features, which are further processed using a BLSTM-based SE model. The results demonstrate several key findings. Firstly, SSL-AVSE successfully overcomes the issue of limited data by leveraging the AV-HuBERT model. Secondly, by fine-tuning the AV-HuBERT model parameters for the target SE task, significant performance improvements are achieved. Specifically, there is a notable enhancement in PESQ (Perceptual Evaluation of Speech Quality) from 1.43 to 1.67 and in STOI (Short-Time Objective Intelligibility) from 0.70 to 0.74. Furthermore, the performance of the SSL-AVSE was evaluated using CI vocoded speech to assess the intelligibility for CI users. Comparative experimental outcomes reveal that in the presence of dynamic noises encountered during human conversations, SSL-AVSE exhibits a substantial improvement. The NCM (Normal Correlation Matrix) values indicate an increase of 26.5% to 87.2% compared to the noisy baseline.

Paper number 94:
Title: Joint Optimization of Continuous Variables and Priority Assignments for Real-Time Systems with Black-box Schedulability Constraints
Authors: Sen Wang, Dong Li, Shao-Yu Huang, Xuanliang Deng, Ashrarul H. Sifat, Changhee Jung, Ryan Williams, Haibo Zeng
Abstract: In real-time systems optimization, designers often face a challenging problem posed by the non-convex and non-continuous schedulability conditions, which may even lack an analytical form to understand their properties. To tackle this challenging problem, we treat the schedulability analysis as a black box that only returns true/false results. We propose a general and scalable framework to optimize real-time systems, named Numerical Optimizer with Real-Time Highlight (NORTH). NORTH is built upon the gradient-based active-set methods from the numerical optimization literature but with new methods to manage active constraints for the non-differentiable schedulability constraints. In addition, we also generalize NORTH to NORTH+, to collaboratively optimize certain types of discrete variables (e.g., priority assignments, categorical variables) with continuous variables based on numerical optimization algorithms. We demonstrate the algorithm performance with two example applications: energy minimization based on dynamic voltage and frequency scaling (DVFS), and optimization of control system performance. In these experiments, NORTH achieved $10^2$ to $10^5$ times speed improvements over state-of-the-art methods while maintaining similar or better solution quality. NORTH+ outperforms NORTH by 30% with similar algorithm scalability. Both NORTH and NORTH+ support black-box schedulability analysis, ensuring broad applicability.

Paper number 95:
Title: Line zonotopes: a set representation suitable for unbounded systems and its application to set-based state estimation and active fault diagnosis of descriptor systems
Authors: Brenner S. Rego, Davide M. Raimondo, Guilherme V. Raffo
Abstract: This paper proposes new methods for set-based state estimation and active fault diagnosis (AFD) of linear descriptor systems (LDS). Unlike intervals, ellipsoids, and zonotopes, constrained zonotopes (CZs) can directly incorporate linear static constraints on state variables - typical of descriptor systems - into their mathematical representation, leading to less conservative enclosures. However, for LDS that are unstable or not fully observable, a bounded representation cannot ensure a valid enclosure of the states over time. To address this limitation, we introduce line zonotopes, a new representation for unbounded sets that retains key properties of CZs, including polynomial time complexity reduction methods, while enabling the description of strips, hyperplanes, and the entire n-dimensional Euclidean space. This extension not only generalizes the use of CZs to unbounded settings but can also enhance set-based estimation and AFD in both stable and unstable scenarios. Additionally, we extend the AFD method for LDS from Rego et al. (2020) to operate over reachable tubes rather than solely on the reachable set at the final time of the considered horizon. This reduces conservatism in input separation and enables more accurate fault diagnosis based on the entire output sequence. The advantages of the proposed methods over existing CZ-based approaches are demonstrated through numerical examples.

Paper number 96:
Title: SARLink: Satellite Backscatter Connectivity using Synthetic Aperture Radar
Authors: Geneva Ecola, Bill Yen, Ana Banzer Morgado, Bodhi Priyantha, Ranveer Chandra, Zerina Kapetanovic
Abstract: SARLink is a passive satellite backscatter communication system that uses existing spaceborne synthetic aperture radar (SAR) imaging satellites to provide connectivity in remote regions. It achieves orders of magnitude more range than traditional backscatter systems, enabling communication between a passive ground node and a satellite in low earth orbit. The system is composed of a cooperative ground target, a SAR satellite, and a data processing algorithm. A mechanically modulating reflector was designed to apply amplitude modulation to ambient SAR backscatter signals by changing its radar cross section. These communication bits are extracted from the raw SAR data using an algorithm that leverages subaperture processing to detect multiple bits from a target in a single image dataset. A theoretical analysis of this communication system using on-off keying is presented, including the expected signal model, throughput, and bit error rate. The results suggest a 5.5 ft by 5.5 ft modulating corner reflector could send 60 bits every satellite pass, enough to support low bandwidth sensor data and messages. Using Sentinel-1A, a SAR satellite at an altitude of 693~km, we deployed static and modulating reflectors to evaluate the system. The results, successfully detecting the changing state of a modulating ground target, demonstrate our algorithm's effectiveness for extracting bits, paving the way for ultra-long-range, low-power satellite backscatter communication.

Paper number 97:
Title: Efficient Design and Implementation of Fast-Convolution-Based Variable-Bandwidth Filters
Authors: Oksana Moryakova, Håkan Johansson
Abstract: This paper introduces an efficient design approach for a fast-convolution-based variable-bandwidth (VBW) filter. The proposed approach is based on a hybrid of frequency sampling and optimization (HFSO), that offers significant computational complexity reduction compared to existing solutions for a given performance. The paper provides a design procedure based on minimax optimization to obtain the minimum complexity of the overall filter. A design example includes a comparison of the proposed design-based VBW filter and time-domain designed VBW filters implemented in the time domain and in the frequency domain. It is shown that not only the implementation complexity can be reduced but also the design complexity by excluding any computations when the bandwidth of the filter is adjusted. Moreover, memory requirements are also decreased compared to the existing frequency-domain implementations.

Paper number 98:
Title: Medical Image Fusion for High-Level Analysis: A Mutual Enhancement Framework for Unaligned PAT and MRI
Authors: Yutian Zhong, Jinchuan He, Zhichao Liang, Shuangyang Zhang, Qianjin Feng, Lijun Lu, Li Qi
Abstract: Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion have made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT-MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.

Paper number 99:
Title: Skin Cancer Machine Learning Model Tone Bias
Authors: James Pope, Md Hassanuzzaman, William Chapman, Huw Day, Mingmar Sherpa, Omar Emara, Nirmala Adhikari, Ayush Joshi
Abstract: Background: Many open-source skin cancer image datasets are the result of clinical trials conducted in countries with lighter skin tones. Due to this tone imbalance, machine learning models derived from these datasets can perform well at detecting skin cancer for lighter skin tones. Any tone bias in these models could introduce fairness concerns and reduce public trust in the artificial intelligence health field. Methods: We examine a subset of images from the International Skin Imaging Collaboration (ISIC) archive that provide tone information. The subset has a significant tone imbalance. These imbalances could explain a model's tone bias. To address this, we train models using the imbalanced dataset and a balanced dataset to compare against. The datasets are used to train a deep convolutional neural network model to classify the images as malignant or benign. We then evaluate the models' disparate impact, based on selection rate, relative to dark or light skin tone. Results: Using the imbalanced dataset, we found that the model is significantly better at detecting malignant images in lighter tone resulting in a disparate impact of 0.577. Using the balanced dataset, we found that the model is also significantly better at detecting malignant images in lighter versus darker tones with a disparate impact of 0.684. Using the imbalanced or balanced dataset to train the model still results in a disparate impact well below the standard threshold of 0.80 which suggests the model is biased with respect to skin tone. Conclusion: The results show that typical skin cancer machine learning models can be tone biased. These results provide evidence that diagnosis or tone imbalance is not the cause of the bias. Other techniques will be necessary to identify and address the bias in these models, an area of future investigation.

Paper number 100:
Title: Window Function-less DFT with Reduced Noise and Latency for Real-Time Music Analysis
Authors: Cai Biesinger, Hiromitsu Awano, Masanori Hashimoto
Abstract: Music analysis applications demand algorithms that can provide both high time and frequency resolution while minimizing noise in an already-noisy signal. Real-time analysis additionally demands low latency and low computational requirements. We propose a DFT-based algorithm that accomplishes all these requirements by extending a method that post-processes DFT output without the use of window functions. Our approach yields greatly reduced sidelobes and noise, and improves time resolution without sacrificing frequency resolution. We use exponentially spaced output bins which directly map to notes in music. The resulting improved performance, compared to existing FFT and DFT-based approaches, creates possibilities for improved real-time visualizations, and contributes to improved analysis quality in other applications such as automatic transcription.

Paper number 101:
Title: Path Loss Modeling for NLoS Ultraviolet Channels Incorporating Scattering and Reflection Effects
Authors: Tianfeng Wu, Fang Yang, Fei Li, Renzhi Yuan, Tian Cao, Ling Cheng, Jian Song, Julian Cheng, Zhu Han
Abstract: This paper tackles limitations in existing non-line-of-sight (NLoS) ultraviolet (UV) channel models, where conventional approaches assume obstacle-free propagation or uniform radiation intensity. In this paper, we develop a path loss model incorporating scattering and reflection, and then propose an obstacle-boundary approximation method to achieve computational tractability. Our framework systematically incorporates spatial obstacle properties, including dimensions, coordinates, contours, and orientation angles, while employing the Lambertian radiation pattern for source modeling. Additionally, the proposed path loss model is validated by comparing it with the Monte-Carlo photon-tracing model and analytical integral model via numerical results, which indicate that when obstacle reflection is prominent, an approximation treatment of obstacle boundaries has a negligible influence on the path loss estimation of NLoS UV communication channels.

Paper number 102:
Title: Clutter-Aware Target Detection for ISAC in a Millimeter-Wave Cell-Free Massive MIMO System
Authors: Steven Rivetti, Ozlem Tugfe Demir, Emil Bjornson, Mikael Skoglund
Abstract: In this paper, we investigate the performance of an integrated sensing and communication (ISAC) system within a cell-free massive multiple-input multiple-output (MIMO) system. Each access point (AP) operates in the millimeter-wave (mmWave) frequency band. The APs jointly serve the user equipments (UEs) in the downlink while simultaneously detecting a target through dedicated sensing beams, which are directed toward a reconfigurable intelligent surface (RIS). Although the AP-RIS, RIS-target, and AP-target channels have both line-of-sight (LoS) and non-line-of-sight (NLoS) parts, it is assumed only knowledge of the LoS paths is available. A key contribution of this study is the consideration of clutter, which degrades the target detection if not handled. We propose an algorithm to alternatively optimize the transmit power allocation and the RIS phase-shift matrix, maximizing the target signal-to-clutter-plus-noise ratio (SCNR) while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for the UEs. Numerical results demonstrate that exploiting clutter subspace significantly enhances detection probability, particularly at high clutter-to-noise ratios, and reveal that an increased number of transmit side clusters impair detection performance. Finally, we highlight the performance gains achieved using a dedicated sensing stream.

Paper number 103:
Title: Enhancing the automatic segmentation and analysis of 3D liver vasculature models
Authors: Yassine Machta, Omar Ali, Kevin Hakkakian, Ana Vlasceanu, Amaury Facque, Nicolas Golse, Irene Vignon-Clementel
Abstract: Surgical assessment of liver cancer patients requires identification of the vessel trees from medical images. Specifically, the venous trees - the portal (perfusing) and the hepatic (draining) trees are important for understanding the liver anatomy and disease state, and perform surgery planning. This research aims to improve the 3D segmentation, skeletonization, and subsequent analysis of vessel trees, by creating an automatic pipeline based on deep learning and image processing techniques. The first part of this work explores the impact of differentiable skeletonization methods such as ClDice and morphological skeletonization loss, on the overall liver vessel segmentation performance. To this aim, it studies how to improve vessel tree connectivity. The second part of this study converts a single class vessel segmentation into multi-class ones, separating the two venous trees. It builds on the previous two-class vessel segmentation model, which vessel tree outputs might be entangled, and on connected components and skeleton analyses of the trees. After providing sub-labeling of the specific anatomical branches of each venous tree, these algorithms also enable a morphometric analysis of the vessel trees by extracting various geometrical markers. In conclusion, we propose a method that successfully improves current skeletonization methods, for extensive vascular trees that contain vessels of different calibers. The separation algorithm creates a clean multi-class segmentation of the vessels, validated by surgeons to provide low error. A new, publicly shared high-quality liver vessel dataset of 77 cases is thus created. Finally a method to annotate vessel trees according to anatomy is provided, enabling a unique liver vessel morphometry analysis.

Paper number 104:
Title: WiFo: Wireless Foundation Model for Channel Prediction
Authors: Boxun Liu, Shijian Gao, Xuanyu Liu, Xiang Cheng, Liuqing Yang
Abstract: Channel prediction permits to acquire channel state information (CSI) without signaling overhead. However, almost all existing channel prediction methods necessitate the deployment of a dedicated model to accommodate a specific configuration. Leveraging the powerful modeling and multi-task learning capabilities of foundation models, we propose the first space-time-frequency (STF) wireless foundation model (WiFo) to address time-frequency channel prediction tasks in a one-for-all manner. Specifically, WiFo is initially pre-trained over massive and extensive diverse CSI datasets. Then, the model will be instantly used for channel prediction under various CSI configurations without any fine-tuning. We propose a masked autoencoder (MAE)-based network structure for WiFo to handle heterogeneous STF CSI data, and design several mask reconstruction tasks for self-supervised pre-training to capture the inherent 3D variations of CSI. To fully unleash its predictive power, we build a large-scale heterogeneous simulated CSI dataset consisting of 160K CSI samples for pre-training. Simulations validate its superior unified learning performance across multiple datasets and demonstrate its state-of-the-art (SOTA) zero-shot generalization performance via comparisons with other full-shot baselines.

Paper number 105:
Title: Data-Based Efficient Off-Policy Stabilizing Optimal Control Algorithms for Discrete-Time Linear Systems via Damping Coefficients
Authors: Dongdong Li, Jiuxiang Dong
Abstract: Policy iteration is one of the classical frameworks of reinforcement learning, which requires a known initial stabilizing control. However, finding the initial stabilizing control depends on the known system model. To relax this requirement and achieve model-free optimal control, in this paper, two different reinforcement learning algorithms based on policy iteration and variable damping coefficients are designed for unknown discrete-time linear systems. First, a stable artificial system is designed, and this system is gradually iterated to the original system by varying the damping coefficients. This allows the initial stabilizing control to be obtained in a finite number of iteration steps. Then, an off-policy iteration algorithm and an off-policy $\mathcal{Q}$-learning algorithm are designed to select the appropriate damping coefficients and realize data-driven. In these two algorithms, the current estimates of optimal control gain are not applied to the system to re-collect data. Moreover, they are characterized by the fast convergence of the traditional policy iteration. Finally, the proposed algorithms are validated by simulation.

Paper number 106:
Title: Blind Training for Channel-Adaptive Digital Semantic Communications
Authors: Yongjeong Oh, Joohyuk Park, Jinho Choi, Jihong Park, Yo-Seb Jeon
Abstract: Semantic encoders and decoders for digital semantic communication (SC) often struggle to adapt to variations in unpredictable channel environments and diverse system designs. To address these challenges, this paper proposes a novel framework for training semantic encoders and decoders to enable channel-adaptive digital SC. The core idea is to use binary symmetric channel (BSC) as a universal representation of generic digital communications, eliminating the need to specify channel environments or system designs. Based on this idea, our framework employs parallel BSCs to equivalently model the relationship between the encoder's output and the decoder's input. The bit-flip probabilities of these BSCs are treated as trainable parameters during end-to-end training, with varying levels of regularization applied to address diverse requirements in practical systems. The advantage of our framework is justified by developing a training-aware communication strategy for the inference stage. This strategy makes communication bit errors align with the pre-trained bit-flip probabilities by adaptively selecting power and modulation levels based on practical requirements and channel conditions. Simulation results demonstrate that the proposed framework outperforms existing training approaches in terms of both task performance and power consumption.

Paper number 107:
Title: A Systematic Method for Optimum Biomedical Wireless Power Transfer using Inductive Links in Area-Constrained Implants
Authors: Asif Iftekhar Omi, Anyu Jiang, Baibhab Chatterjee
Abstract: In the context of implantable bioelectronics, this work provides new insights into maximizing biomedical wireless power transfer (BWPT) via the systematic development of inductive links. This approach addresses the specific challenges of power transfer efficiency (PTE) optimization within the area constraints of bio-implants embedded in tissue. Key contributions include the derivation of an optimal self-inductance with S-parameter-based analyses leading to the co-design of planar spiral coils and L-section impedance matching networks. To validate the proposed design methodology, two coil prototypes -- one symmetric (type-1) and one asymmetric (type-2) -- were fabricated and tested for PTE in pork tissue. Targeting a 20 MHz design frequency, the type-1 coil demonstrated a state-of-the-art PTE of $\sim$ 4\% (channel length = 15 mm) with a return loss (RL) $>$ 20 dB on both the input and output sides, within an area constraint of $<$ 18 $ \times $ 18 mm$^{2}$. In contrast, the type-2 coil achieved a PTE of $\sim$ 2\% with an RL $>$ 15 dB, for a smaller receiving coil area of $<$ 5x5 mm$^{2}$ for the same tissue environment. To complement the coils, we demonstrate a 65 nm test chip with an integrated energy harvester, which includes \asif{a} 30-stage rectifier and low-dropout regulator (LDO), producing a stable $\sim$ 1V DC output within tissue medium, matching theoretical predictions and simulations. Furthermore, we provide a robust and comprehensive guideline for advancing efficient inductive links for various BWPT applications, with shared resources in GitHub available for utilization by the broader community.

Paper number 108:
Title: Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans
Authors: Matthias Schwab, Mathias Pamminger, Christian Kremser, Markus Haltmeier, Agnes Mayr
Abstract: Purpose: To develop and evaluate a deep learning-based method that allows to perform myocardial infarct segmentation in a fully-automated way. Materials and Methods: For this retrospective study, a cascaded framework of two and three-dimensional convolutional neural networks (CNNs), specialized on identifying ischemic myocardial scars on late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) images, was trained on an in-house training dataset consisting of 144 examinations. On a separate test dataset from the same institution, including images from 152 examinations obtained between 2021 and 2023, a quantitative comparison between artificial intelligence (AI)-based segmentations and manual segmentations was performed. Further, qualitative assessment of segmentation accuracy was evaluated for both human and AI-generated contours by two CMR experts in a blinded experiment. Results: Excellent agreement could be found between manually and automatically calculated infarct volumes ($\rho_c$ = 0.9). The qualitative evaluation showed that compared to human-based measurements, the experts rated the AI-based segmentations to better represent the actual extent of infarction significantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On the contrary, for segmentation of microvascular obstruction (MVO), manual measurements were still preferred (11.3% AI, 55.6% human, 33.1% equal). Conclusion: This fully-automated segmentation pipeline enables CMR infarct size to be calculated in a very short time and without requiring any pre-processing of the input images while matching the segmentation quality of trained human observers. In a blinded experiment, experts preferred automated infarct segmentations more often than manual segmentations, paving the way for a potential clinical application.

Paper number 109:
Title: Gaussian Random Fields as an Abstract Representation of Patient Metadata for Multimodal Medical Image Segmentation
Authors: Bill Cassidy, Christian McBride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Shaghayegh Raad, Moi Hoon Yap
Abstract: The growing rate of chronic wound occurrence, especially in patients with diabetes, has become a concerning trend in recent years. Chronic wounds are difficult and costly to treat, and have become a serious burden on health care systems worldwide. Chronic wounds can have devastating consequences for the patient, with infection often leading to reduced quality of life and increased mortality risk. Innovative deep learning methods for the detection and monitoring of such wounds have the potential to reduce the impact to both patient and clinician. We present a novel multimodal segmentation method which allows for the introduction of patient metadata into the training workflow whereby the patient data are expressed as Gaussian random fields. Our results indicate that the proposed method improved performance when utilising multiple models, each trained on different metadata categories. Using the Diabetic Foot Ulcer Challenge 2022 test set, when compared to the baseline results (intersection over union = 0.4670, Dice similarity coefficient = 0.5908) we demonstrate improvements of +0.0220 and +0.0229 for intersection over union and Dice similarity coefficient respectively. This paper presents the first study to focus on integrating patient data into a chronic wound segmentation workflow. Our results show significant performance gains when training individual models using specific metadata categories, followed by average merging of prediction masks using distance transforms. All source code for this study is available at: this https URL

Paper number 110:
Title: Input Delay Compensation for a Class of Switched Linear Systems via Averaging Exact Predictor Feedbacks
Authors: Andreas Katsanikakis, Nikolaos Bekiaris-Liberis
Abstract: The key challenges in design of predictor-based control laws for switched systems with arbitrary switching and long input delay are the potential unavailability of the future values of the switching signal (at current time) and the fact that dwell time may be arbitrary. In the present paper, we resolve these challenges developing a new predictor-based control law that is, essentially, an average of exact predictor feedbacks, each one corresponding to an exact predictor-feedback law for a system that operates only in a single mode. Because the predictor state in our control design does not correspond to an exact predictor, stability can be guaranteed under a restriction on the differences among the system's matrices and controller's gains. This is an unavoidable limitation, for a switching signal whose future values may be unavailable, when no constraint is imposed on the values of delay and dwell time (as it is the case here). We establish (uniform) stability of the closed-loop system employing a Lyapunov functional. The key step in the stability proof is constructive derivation of an estimate of the mismatch between an exact predictor feedback and the average of predictor feedbacks constructed. We illustrate the performance of the proposed predictor-based control law in simulation, including comparisons with alternative, predictor-based control laws.

Paper number 111:
Title: Data-Driven Inverse Optimal Control for Continuous-Time Nonlinear Systems
Authors: Hamed Jabbari Asl, Eiji Uchibe
Abstract: This paper introduces a novel model-free and a partially model-free algorithm for inverse optimal control (IOC), also known as inverse reinforcement learning (IRL), aimed at estimating the cost function of continuous-time nonlinear deterministic systems. Using the input-state trajectories of an expert agent, the proposed algorithms separately utilize control policy information and the Hamilton-Jacobi-Bellman equation to estimate different sets of cost function parameters. This approach allows the algorithms to achieve broader applicability while maintaining a model-free framework. Also, the model-free algorithm reduces complexity compared to existing methods, as it requires solving a forward optimal control problem only once during initialization. Furthermore, in our partially model-free algorithm, this step can be bypassed entirely for systems with known input dynamics. Simulation results demonstrate the effectiveness and efficiency of our algorithms, highlighting their potential for real-world deployment in autonomous systems and robotics.

Paper number 112:
Title: A nonlinear real time capable motion cueing algorithm based on deep reinforcement learning
Authors: Hendrik Scheidel, Camilo Gonzalez, Houshyar Asadi, Tobias Bellmann, Andreas Seefried, Shady Mohamed, Saeid Nahavandi
Abstract: In motion simulation, motion cueing algorithms are used for the trajectory planning of the motion simulator platform, where workspace limitations prevent direct reproduction of reference trajectories. Strategies such as motion washout, which return the platform to its center, are crucial in these settings. For serial robotic MSPs with highly nonlinear workspaces, it is essential to maximize the efficient utilization of the MSPs kinematic and dynamic capabilities. Traditional approaches, including classical washout filtering and linear model predictive control, fail to consider platform-specific, nonlinear properties, while nonlinear model predictive control, though comprehensive, imposes high computational demands that hinder real-time, pilot-in-the-loop application without further simplification. To overcome these limitations, we introduce a novel approach using deep reinforcement learning for motion cueing, demonstrated here for the first time in a 6-degree-of-freedom setting with full consideration of the MSPs kinematic nonlinearities. Previous work by the authors successfully demonstrated the application of DRL to a simplified 2-DOF setup, which did not consider kinematic or dynamic constraints. This approach has been extended to all 6 DOF by incorporating a complete kinematic model of the MSP into the algorithm, a crucial step for enabling its application on a real motion simulator. The training of the DRL-MCA is based on Proximal Policy Optimization in an actor-critic implementation combined with an automated hyperparameter optimization. After detailing the necessary training framework and the algorithm itself, we provide a comprehensive validation, demonstrating that the DRL MCA achieves competitive performance against established algorithms. Moreover, it generates feasible trajectories by respecting all system constraints and meets all real-time requirements with low...

Paper number 113:
Title: AI and Deep Learning for Automated Segmentation and Quantitative Measurement of Spinal Structures in MRI
Authors: Praveen Shastry, Bhawana Sonawane, Kavya Mohan, Naveen Kumarasami, Raghotham Sripadraj, Anandakumar D, Keerthana R, Mounigasri M, Kaviya SP, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: Accurate spinal structure measurement is crucial for assessing spine health and diagnosing conditions like spondylosis, disc herniation, and stenosis. Manual methods for measuring intervertebral disc height and spinal canal diameter are subjective and time-consuming. Automated solutions are needed to improve accuracy, efficiency, and reproducibility in clinical practice. Purpose: This study develops an autonomous AI system for segmenting and measuring key spinal structures in MRI scans, focusing on intervertebral disc height and spinal canal anteroposterior (AP) diameter in the cervical, lumbar, and thoracic regions. The goal is to reduce clinician workload, enhance diagnostic consistency, and improve assessments. Methods: The AI model leverages deep learning architectures, including UNet, nnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated against expert annotations. Performance was evaluated using Dice coefficients and segmentation accuracy. Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for cervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely measured spinal parameters like disc height and canal diameter, demonstrating robustness and clinical applicability. Conclusion: The AI system effectively automates MRI-based spinal measurements, improving accuracy and reducing clinician workload. Its consistent performance across spinal regions supports clinical decision-making, particularly in high-demand settings, enhancing spinal assessments and patient outcomes.

Paper number 114:
Title: DCAT: Dual Cross-Attention Fusion for Disease Classification in Radiological Images with Uncertainty Estimation
Authors: Jutika Borah, Hidam Kumarjit Singh
Abstract: Accurate and reliable image classification is crucial in radiology, where diagnostic decisions significantly impact patient outcomes. Conventional deep learning models tend to produce overconfident predictions despite underlying uncertainties, potentially leading to misdiagnoses. Attention mechanisms have emerged as powerful tools in deep learning, enabling models to focus on relevant parts of the input data. Combined with feature fusion, they can be effective in addressing uncertainty challenges. Cross-attention has become increasingly important in medical image analysis for capturing dependencies across features and modalities. This paper proposes a novel dual cross-attention fusion model for medical image analysis by addressing key challenges in feature integration and interpretability. Our approach introduces a bidirectional cross-attention mechanism with refined channel and spatial attention that dynamically fuses feature maps from EfficientNetB4 and ResNet34 leveraging multi-network contextual dependencies. The refined features through channel and spatial attention highlights discriminative patterns crucial for accurate classification. The proposed model achieved AUC of 99.75%, 100%, 99.93% and 98.69% and AUPR of 99.81%, 100%, 99.97%, and 96.36% on Covid-19, Tuberculosis, Pneumonia Chest X-ray images and Retinal OCT images respectively. The entropy values and several high uncertain samples give an interpretable visualization from the model enhancing transparency. By combining multi-scale feature extraction, bidirectional attention and uncertainty estimation, our proposed model strongly impacts medical image analysis.

Paper number 115:
Title: ISLS: IoT-Based Smart Lighting System for Improving Energy Conservation in Office Buildings
Authors: Peace Obioma, Obinna Agbodike, Jenhui Chen, Lei Wang
Abstract: With the Internet of Things (IoT) fostering seamless device-to-human and device-to-device interactions, the domain of intelligent lighting systems have evolved beyond simple occupancy and daylight sensing towards autonomous monitoring and control of power consumption and illuminance levels. To this regard, this paper proposes a new do-it-yourself (DIY) IoT-based method of smart lighting system featuring an illuminance control algorithm. The design involves the integration of occupancy and presence sensors alongside a communication module, to enable real-time wireless interaction and remote monitoring of the system parameters from any location through an end-user application. A constrained optimization problem was formulated to determine the optimal dimming vector for achieving target illuminance at minimal power consumption. The simplex algorithm was used to solve this problem, and the system's performance was validated through both MATLAB simulations and real-world prototype testing in an indoor office environment. The obtained experimental results demonstrate substantial power savings across multiple user occupancy scenarios, achieving reductions of approx. 80%, 48%, and 26% for one, two, and four user settings, respectively, in comparison to traditional basic lighting installation systems.

Paper number 116:
Title: FLP-XR: Future Location Prediction on Extreme Scale Maritime Data in Real-time
Authors: George S. Theodoropoulos, Andreas Patakis, Andreas Tritsarolis, Yannis Theodoridis
Abstract: Movements of maritime vessels are inherently complex and challenging to model due to the dynamic and often unpredictable nature of maritime operations. Even within structured maritime environments, such as shipping lanes and port approaches, where vessels adhere to navigational rules and predefined sea routes, uncovering underlying patterns is far from trivial. The necessity for accurate modeling of the mobility of maritime vessels arises from the numerous applications it serves, including risk assessment for collision avoidance, optimization of shipping routes, and efficient port management. This paper introduces FLP-XR, a model that leverages maritime mobility data to construct a robust framework that offers precise predictions while ensuring extremely fast training and inference capabilities. We demonstrate the efficiency of our approach through an extensive experimental study using three real-world AIS datasets. According to the experimental results, FLP-XR outperforms the current state-of-the-art in many cases, whereas it performs 2-3 orders of magnitude faster in terms of training and inference.

Paper number 117:
Title: From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence
Authors: Krti Tallam
Abstract: The rapid evolution of artificial intelligence (AI) has ushered in a new era of integrated systems that merge computational prowess with human decision-making. In this paper, we introduce the concept of Orchestrated Distributed Intelligence (ODI), a novel paradigm that reconceptualizes AI not as isolated autonomous agents, but as cohesive, orchestrated networks that work in tandem with human expertise. ODI leverages advanced orchestration layers, multi-loop feedback mechanisms, and a high cognitive density framework to transform static, record-keeping systems into dynamic, action-oriented environments. Through a comprehensive review of multi-agent system literature, recent technological advances, and practical insights from industry forums, we argue that the future of AI lies in integrating distributed intelligence within human-centric workflows. This approach not only enhances operational efficiency and strategic agility but also addresses challenges related to scalability, transparency, and ethical decision-making. Our work outlines key theoretical implications and presents a practical roadmap for future research and enterprise innovation, aiming to pave the way for responsible and adaptive AI systems that drive sustainable innovation in human organizations.

Paper number 118:
Title: Modeling, Analysis, and Optimization of Cascaded Power Amplifiers
Authors: Oksana Moryakova, Thomas Eriksson, Håkan Johansson
Abstract: This paper deals with modeling, analysis, and optimization of power amplifiers (PAs) placed in a cascaded structure, particularly the effect of cascaded nonlinearities is studied by showing potential ways to minimize the total nonlinearities. The nonlinear least-squares algorithm is proposed to optimize the PA parameters along with the input power level, and thereby minimize the total nonlinearities in the cascaded structure. The simulation results demonstrate that the performance of the optimized configurations for up to five PAs using the proposed framework can improve the linearity properties of the overall cascade.

Paper number 119:
Title: MoonCast: High-Quality Zero-Shot Podcast Generation
Authors: Zeqian Ju, Dongchao Yang, Jianwei Yu, Kai Shen, Yichong Leng, Zhengtao Wang, Xu Tan, Xinyu Zhou, Tao Qin, Xiangyang Li
Abstract: Recent advances in text-to-speech synthesis have achieved notable success in generating high-quality short utterances for individual speakers. However, these systems still face challenges when extending their capabilities to long, multi-speaker, and spontaneous dialogues, typical of real-world scenarios such as podcasts. These limitations arise from two primary challenges: 1) long speech: podcasts typically span several minutes, exceeding the upper limit of most existing work; 2) spontaneity: podcasts are marked by their spontaneous, oral nature, which sharply contrasts with formal, written contexts; existing works often fall short in capturing this spontaneity. In this paper, we propose MoonCast, a solution for high-quality zero-shot podcast generation, aiming to synthesize natural podcast-style speech from text-only sources (e.g., stories, technical reports, news in TXT, PDF, or Web URL formats) using the voices of unseen speakers. To generate long audio, we adopt a long-context language model-based audio modeling approach utilizing large-scale long-context speech data. To enhance spontaneity, we utilize a podcast generation module to generate scripts with spontaneous details, which have been empirically shown to be as crucial as the text-to-speech modeling itself. Experiments demonstrate that MoonCast outperforms baselines, with particularly notable improvements in spontaneity and coherence.

Paper number 120:
Title: A Deep Reinforcement Learning Based Motion Cueing Algorithm for Vehicle Driving Simulation
Authors: Hendrik Scheidel, Houshyar Asadi, Tobias Bellmann, Andreas Seefried, Shady Mohamed, Saeid Nahavandi
Abstract: Motion cueing algorithms (MCA) are used to control the movement of motion simulation platforms (MSP) to reproduce the motion perception of a real vehicle driver as accurately as possible without exceeding the limits of the workspace of the MSP. Existing approaches either produce non-optimal results due to filtering, linearization, or simplifications, or the computational time required exceeds the real-time requirements of a closed-loop application. This work presents a new solution to the motion cueing problem, where instead of a human designer specifying the principles of the MCA, an artificial intelligence (AI) learns the optimal motion by trial and error in interaction with the MSP. To achieve this, a well-established deep reinforcement learning (RL) algorithm is applied, where an agent interacts with an environment, allowing him to directly control a simulated MSP to obtain feedback on its performance. The RL algorithm used is proximal policy optimization (PPO), where the value function and the policy corresponding to the control strategy are both learned and mapped in artificial neural networks (ANN). This approach is implemented in Python and the functionality is demonstrated by the practical example of pre-recorded lateral maneuvers. The subsequent validation shows that the RL algorithm is able to learn the control strategy and improve the quality of the immersion compared to an established method. Thereby, the perceived motion signals determined by a model of the vestibular system are more accurately reproduced, and the resources of the MSP are used more economically.

Paper number 121:
Title: SNAIL Radar: A large-scale diverse benchmark for evaluating 4D-radar-based SLAM
Authors: Jianzhu Huai, Binliang Wang, Yuan Zhuang, Yiwen Chen, Qipeng Li, Yulong Han
Abstract: 4D radars are increasingly favored for odometry and mapping of autonomous systems due to their robustness in harsh weather and dynamic environments. Existing datasets, however, often cover limited areas and are typically captured using a single platform. To address this gap, we present a diverse large-scale dataset specifically designed for 4D radar-based localization and mapping. This dataset was gathered using three different platforms: a handheld device, an e-bike, and an SUV, under a variety of environmental conditions, including clear days, nighttime, and heavy rain. The data collection occurred from September 2023 to February 2024, encompassing diverse settings such as roads in a vegetated campus and tunnels on highways. Each route was traversed multiple times to facilitate place recognition evaluations. The sensor suite included a 3D lidar, 4D radars, stereo cameras, consumer-grade IMUs, and a GNSS/INS system. Sensor data packets were synchronized to GNSS time using a two-step process including a convex-hull-based smoothing and a correlation-based correction. The reference motion for the platforms was generated by registering lidar scans to a terrestrial laser scanner (TLS) point cloud map by a lidar inertial sequential localizer which supports forward and backward processing. The backward pass enables detailed quantitative and qualitative assessments of reference motion accuracy. To demonstrate the dataset's utility, we evaluated several state-of-the-art radar-based odometry and place recognition methods, indicating existing challenges in radar-based SLAM.

Paper number 122:
Title: Downlink Channel Covariance Matrix Estimation via Representation Learning with Graph Regularization
Authors: Melih Can Zerin, Elif Vural, Ali Özgür Yılmaz
Abstract: In this paper, we propose an algorithm for downlink (DL) channel covariance matrix (CCM) estimation for frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) communication systems with base station (BS) possessing a uniform linear array (ULA) antenna structure. We consider a setting where the UL CCM is mapped to DL CCM by a mapping function. We first present a theoretical error analysis of learning a nonlinear embedding by constructing a mapping function, which points to the importance of the Lipschitz regularity of the mapping function for achieving high estimation performance. Then, based on the theoretical ground, we propose a representation learning algorithm as a solution for the estimation problem, where Gaussian RBF kernel interpolators are chosen to map UL CCMs to their DL counterparts. The proposed algorithm is based on the optimization of an objective function that fits a regression model between the DL CCM and UL CCM samples in the training dataset and preserves the local geometric structure of the data in the UL CCM space, while explicitly regulating the Lipschitz continuity of the mapping function in light of our theoretical findings. The proposed algorithm surpasses benchmark methods in terms of three error metrics as shown by simulations.

Paper number 123:
Title: ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5
Authors: Jiaming Zhou, Shiyao Wang, Shiwan Zhao, Jiabei He, Haoqin Sun, Hui Wang, Cheng Liu, Aobo Kong, Yujie Guo, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin
Abstract: Automatic speech recognition (ASR) systems have advanced significantly with models like Whisper, Conformer, and self-supervised frameworks such as Wav2vec 2.0 and HuBERT. However, developing robust ASR models for young children's speech remains challenging due to differences in pronunciation, tone, and pace compared to adult speech. In this paper, we introduce a new Mandarin speech dataset focused on children aged 3 to 5, addressing the scarcity of resources in this area. The dataset comprises 41.25 hours of speech with carefully crafted manual transcriptions, collected from 397 speakers across various provinces in China, with balanced gender representation. We provide a comprehensive analysis of speaker demographics, speech duration distribution and geographic coverage. Additionally, we evaluate ASR performance on models trained from scratch, such as Conformer, as well as fine-tuned pre-trained models like HuBERT and Whisper, where fine-tuning demonstrates significant performance improvements. Furthermore, we assess speaker verification (SV) on our dataset, showing that, despite the challenges posed by the unique vocal characteristics of young children, the dataset effectively supports both ASR and SV tasks. This dataset is a valuable contribution to Mandarin child speech research. The dataset is now open-source and freely available for all academic purposes on this https URL.

Paper number 124:
Title: A Convex Relaxation Approach to Generalization Analysis for Parallel Positively Homogeneous Networks
Authors: Uday Kiran Reddy Tadipatri, Benjamin D. Haeffele, Joshua Agterberg, René Vidal
Abstract: We propose a general framework for deriving generalization bounds for parallel positively homogeneous neural networks--a class of neural networks whose input-output map decomposes as the sum of positively homogeneous maps. Examples of such networks include matrix factorization and sensing, single-layer multi-head attention mechanisms, tensor factorization, deep linear and ReLU networks, and more. Our general framework is based on linking the non-convex empirical risk minimization (ERM) problem to a closely related convex optimization problem over prediction functions, which provides a global, achievable lower-bound to the ERM problem. We exploit this convex lower-bound to perform generalization analysis in the convex space while controlling the discrepancy between the convex model and its non-convex counterpart. We apply our general framework to a wide variety of models ranging from low-rank matrix sensing, to structured matrix sensing, two-layer linear networks, two-layer ReLU networks, and single-layer multi-head attention mechanisms, achieving generalization bounds with a sample complexity that scales almost linearly with the network width.

Paper number 125:
Title: The Pitfalls of Imitation Learning when Actions are Continuous
Authors: Max Simchowitz, Daniel Pfrommer, Ali Jadbabaie
Abstract: We study the problem of imitating an expert demonstrator in a discrete-time, continuous state-and-action control system. We show that, even if the dynamics are stable (i.e. contracting exponentially quickly), and the expert is smooth and deterministic, any smooth, deterministic imitator policy necessarily suffers error on execution that is exponentially larger, as a function of problem horizon, than the error under the distribution of expert training data. Our negative result applies to both behavior cloning and offline-RL algorithms, unless they produce highly "improper" imitator policies--those which are non-smooth, non-Markovian, or which exhibit highly state-dependent stochasticity--or unless the expert trajectory distribution is sufficiently "spread." We provide experimental evidence of the benefits of these more complex policy parameterizations, explicating the benefits of today's popular policy parameterizations in robot learning (e.g. action-chunking and Diffusion Policies). We also establish a host of complementary negative and positive results for imitation in control systems.

Paper number 126:
Title: Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering
Authors: Gang Li, Jizhong Liu, Heinrich Dinkel, Yadong Niu, Junbo Zhang, Jian Luan
Abstract: Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks. However, the audio modality has largely been overlooked in these developments. Thus, we conduct a series of RL explorations in audio understanding and reasoning, specifically focusing on the audio question answering (AQA) task. We leverage the group relative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and our experiments demonstrated state-of-the-art performance on the MMAU Test-mini benchmark, achieving an accuracy rate of 64.5%. The main findings in this technical report are as follows: 1) The GRPO algorithm can be effectively applied to large audio language models (LALMs), even when the model has only 8.2B parameters; 2) With only 38k post-training samples, RL significantly outperforms supervised fine-tuning (SFT), indicating that RL-based approaches can be effective without large datasets; 3) The explicit reasoning process has not shown significant benefits for AQA tasks, and how to efficiently utilize deep thinking remains an open question for further research; 4) LALMs still lag far behind humans auditory-language reasoning, suggesting that the RL-based approaches warrant further exploration. Our project is available at this https URL and this https URL.

Paper number 127:
Title: Low-PAPR OFDM-ISAC Waveform Design Based on Frequency-Domain Phase Differences
Authors: Kaimin Li, Jiahuan Wang, Haixia Cui, Bingpeng Zhou, Pingzhi Fan
Abstract: Low peak-to-average power ratio (PAPR) orthogonal frequency division multiplexing (OFDM) waveform design is a crucial issue in integrated sensing and communications (ISAC). This paper introduces an OFDM-ISAC waveform design that utilizes the entire spectrum simultaneously for both communication and sensing by leveraging a novel degree of freedom (DoF): the frequency-domain phase difference (PD). Based on this concept, we develop a novel PD-based OFDM-ISAC waveform structure and utilize it to design a PD-based Low-PAPR OFDM-ISAC (PLPOI) waveform. The design is formulated as an optimization problem incorporating four key constraints: the time-frequency relationship equation, frequency-domain unimodular constraints, PD constraints, and time-domain low PAPR requirements. To solve this challenging non-convex problem, we develop an efficient algorithm, ADMM-PLPOI, based on the alternating direction method of multipliers (ADMM) framework. Extensive simulation results demonstrate that the proposed PLPOI waveform achieves significant improvements in both PAPR and bit error rate (BER) performance compared to conventional OFDM-ISAC waveforms.

Paper number 128:
Title: AI-driven control of bioelectric signalling for real-time topological reorganization of cells
Authors: Gonçalo Hora de Carvalho
Abstract: Understanding and manipulating bioelectric signaling could present a new wave of progress in developmental biology, regenerative medicine, and synthetic biology. Bioelectric signals, defined as voltage gradients across cell membranes caused by ionic movements, play a role in regulating crucial processes including cellular differentiation, proliferation, apoptosis, and tissue morphogenesis. Recent studies demonstrate the ability to modulate these signals to achieve controlled tissue regeneration and morphological outcomes in organisms such as planaria and frogs. However, significant knowledge gaps remain, particularly in predicting and controlling the spatial and temporal dynamics of membrane potentials (V_mem), understanding their regulatory roles in tissue and organ development, and exploring their therapeutic potential in diseases. In this work we propose an experiment using Deep Reinforcement Learning (DRL) framework together with lab automation techniques for real-time manipulation of bioelectric signals to guide tissue regeneration and morphogenesis. The proposed framework should interact continuously with biological systems, adapting strategies based on direct biological feedback. Combining DRL with real-time measurement techniques -- such as optogenetics, voltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could provide a comprehensive platform for precise bioelectric control, leading to improved understanding of bioelectric mechanisms in morphogenesis, quantitative bioelectric models, identification of minimal experimental setups, and advancements in bioelectric modulation techniques relevant to regenerative medicine and cancer therapy. Ultimately, this research aims to utilize bioelectric signaling to develop new biomedical and bioengineering applications.

Paper number 129:
Title: CTSR: Controllable Fidelity-Realness Trade-off Distillation for Real-World Image Super Resolution
Authors: Runyi Li, Bin Chen, Jian Zhang, Radu Timofte
Abstract: Real-world image super-resolution is a critical image processing task, where two key evaluation criteria are the fidelity to the original image and the visual realness of the generated results. Although existing methods based on diffusion models excel in visual realness by leveraging strong priors, they often struggle to achieve an effective balance between fidelity and realness. In our preliminary experiments, we observe that a linear combination of multiple models outperforms individual models, motivating us to harness the strengths of different models for a more effective trade-off. Based on this insight, we propose a distillation-based approach that leverages the geometric decomposition of both fidelity and realness, alongside the performance advantages of multiple teacher models, to strike a more balanced trade-off. Furthermore, we explore the controllability of this trade-off, enabling a flexible and adjustable super-resolution process, which we call CTSR (Controllable Trade-off Super-Resolution). Experiments conducted on several real-world image super-resolution benchmarks demonstrate that our method surpasses existing state-of-the-art approaches, achieving superior performance across both fidelity and realness metrics.
    