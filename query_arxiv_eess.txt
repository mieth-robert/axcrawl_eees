
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Accurate, provable, and fast nonlinear tomographic reconstruction: A variational inequality approach
Authors: Mengqi Lou, Kabir Aladin Verchand, Sara Fridovich-Keil, Ashwin Pananjady
Abstract: We consider the problem of signal reconstruction for computed tomography (CT) under a nonlinear forward model that accounts for exponential signal attenuation, a polychromatic X-ray source, general measurement noise (e.g. Poisson shot noise), and observations acquired over multiple wavelength windows. We develop a simple iterative algorithm for single-material reconstruction, which we call EXACT (EXtragradient Algorithm for Computed Tomography), based on formulating our estimate as the fixed point of a monotone variational inequality. We prove guarantees on the statistical and computational performance of EXACT under practical assumptions on the measurement process. We also consider a recently introduced variant of this model with Gaussian measurements, and present sample and iteration complexity bounds for EXACT that improve upon those of existing algorithms. We apply our EXACT algorithm to a CT phantom image recovery task and show that it often requires fewer X-ray projection exposures, lower source intensity, and less computation time to achieve similar reconstruction quality to existing methods.

Paper number 2:
Title: A Spatiotemporal Radar-Based Precipitation Model for Water Level Prediction and Flood Forecasting
Authors: Sakshi Dhankhar, Stefan Wittek, Hamidreza Eivazi, Andreas Rausch
Abstract: Study Region: Goslar and Göttingen, Lower Saxony, Germany. Study Focus: In July 2017, the cities of Goslar and Göttingen experienced severe flood events characterized by short warning time of only 20 minutes, resulting in extensive regional flooding and significant damage. This highlights the critical need for a more reliable and timely flood forecasting system. This paper presents a comprehensive study on the impact of radar-based precipitation data on forecasting river water levels in Goslar. Additionally, the study examines how precipitation influences water level forecasts in Göttingen. The analysis integrates radar-derived spatiotemporal precipitation patterns with hydrological sensor data obtained from ground stations to evaluate the effectiveness of this approach in improving flood prediction capabilities. New Hydrological Insights for the Region: A key innovation in this paper is the use of residual-based modeling to address the non-linearity between precipitation images and water levels, leading to a Spatiotemporal Radar-based Precipitation Model with residuals (STRPMr). Unlike traditional hydrological models, our approach does not rely on upstream data, making it independent of additional hydrological inputs. This independence enhances its adaptability and allows for broader applicability in other regions with RADOLAN precipitation. The deep learning architecture integrates (2+1)D convolutional neural networks for spatial and temporal feature extraction with LSTM for timeseries forecasting. The results demonstrate the potential of the STRPMr for capturing extreme events and more accurate flood forecasting.

Paper number 3:
Title: Optimizing Breast Cancer Detection in Mammograms: A Comprehensive Study of Transfer Learning, Resolution Reduction, and Multi-View Classification
Authors: Daniel G. P. Petrini, Hae Yong Kim
Abstract: This study explores open questions in the application of machine learning for breast cancer detection in mammograms. Current approaches often employ a two-stage transfer learning process: first, adapting a backbone model trained on natural images to develop a patch classifier, which is then used to create a single-view whole-image classifier. Additionally, many studies leverage both mammographic views to enhance model performance. In this work, we systematically investigate five key questions: (1) Is the intermediate patch classifier essential for optimal performance? (2) Do backbone models that excel in natural image classification consistently outperform others on mammograms? (3) When reducing mammogram resolution for GPU processing, does the learn-to-resize technique outperform conventional methods? (4) Does incorporating both mammographic views in a two-view classifier significantly improve detection accuracy? (5) How do these findings vary when analyzing low-quality versus high-quality mammograms? By addressing these questions, we developed models that outperform previous results for both single-view and two-view classifiers. Our findings provide insights into model architecture and transfer learning strategies contributing to more accurate and efficient mammogram analysis.

Paper number 4:
Title: Automated Video-EEG Analysis in Epilepsy Studies: Advances and Challenges
Authors: Valerii A. Zuev, Elena G. Salmagambetova, Stepan N. Djakov, Lev V. Utkin
Abstract: Epilepsy is typically diagnosed through electroencephalography (EEG) and long-term video-EEG (vEEG) monitoring. The manual analysis of vEEG recordings is time-consuming, necessitating automated tools for seizure detection. Recent advancements in machine learning have shown promise in real-time seizure detection and prediction using EEG and video data. However, diversity of seizure symptoms, markup ambiguities, and limited availability of multimodal datasets hinder progress. This paper reviews the latest developments in automated video-EEG analysis and discusses the integration of multimodal data. We also propose a novel pipeline for treatment effect estimation from vEEG data using concept-based learning, offering a pathway for future research in this domain.

Paper number 5:
Title: Deep-Learning-Based Classification of Digitally Modulated Signals
Authors: John A. Snoap
Abstract: This dissertation presents several novel deep-learning (DL)-based approaches for classifying digitally modulated signals, one method of which involves the use of capsule networks (CAPs) together with cyclic cumulant (CC) features of the signals. These were blindly estimated using cyclostationary signal processing (CSP) and were then input into the CAP for training and classification. The results showed that the classification of digitally modulated signals using CAPs and CCs proposed in this dissertation outperformed alternative approaches for classifying digitally modulated signals that included conventional classifiers that employed CSP-based techniques, as well as alternative DL-based classifiers that used various conventional neural networks (NNs) with in-phase/quadrature (I/Q) data used for training and classification. Another method of digital modulation classification presented in this dissertation showcases two novel DL-based classifiers that each use a CAP with custom-designed feature extraction layers. The classifiers take I/Q data as input, and the feature extraction layers are inspired by CSP techniques, which extract the CC features employed by conventional CSP-based approaches to blind modulation classification and signal identification. Specifically, the feature extraction layers implement a proxy of the mathematical functions used in the calculation of the CC features and include a squaring layer, a raise-to-the-power-of-three layer, and a fast-Fourier-transform (FFT) layer, along with additional normalization and warping layers to ensure that the relative signal powers are retained and to prevent the trainable NN layers from diverging in the training process.

Paper number 6:
Title: Control Barrier Functions for Shared Control and Vehicle Safety
Authors: James Dallas, John Talbot, Makoto Suminaka, Michael Thompson, Thomas Lew, Gabor Orosz, John Subosits
Abstract: This manuscript presents a control barrier function based approach to shared control for preventing a vehicle from entering the part of the state space where it is unrecoverable. The maximal phase recoverable ellipse is presented as a safe set in the sideslip angle--yaw rate phase plane where the vehicle's state can be maintained. An exponential control barrier function is then defined on the maximal phase recoverable ellipse to promote safety. Simulations demonstrate that this approach enables safe drifting, that is, driving at the handling limit without spinning out. Results are then validated for shared control drifting with an experimental vehicle in a closed course. The results show the ability of this shared control formulation to maintain the vehicle's state within a safe domain in a computationally efficient manner, even in extreme drifting maneuvers.

Paper number 7:
Title: Unlocking Multi-Task Electric Energy System Intelligence: Data Scaling Laws and Performance with Limited Fine-Tuning
Authors: Shaohuai Liu, Lin Dong, Chao Tian, Le Xie
Abstract: Data scaling has revolutionized research fields like natural language processing, computer vision, and robotics control, providing foundation models with remarkable multi-task and generalization capabilities. In this paper, we investigate whether similar data scaling laws exist in developing foundation models for power systems, and whether appropriate data scaling can yield multi-task, cross-timescales capabilities that can be deployed in \textit{unseen} operational scenarios. To this end, we conducted a comprehensive empirical study on data scaling by fine-tuning open-source foundation models using labeled data collected from diverse operational tasks and scenarios. We study how a foundation model's scenario generalization performance evolves with the number of training tasks, scenarios, and demonstrations. Our study involved collecting more than 450k demonstrations and implementing independent tests under a rigorous evaluation framework. Our findings reveal several key insights: First, the generalization performance of a fine-tuned foundation model follows an approximate power-law relationship with the number of demonstrations and scenarios. Second, the fine-tuned model also demonstrates impressive multi-task capabilities, where multi-task training shares similar performance improvements with single-task training as the number of demonstrations increases, without interference among tasks. Lastly, models with small parameter sizes could have strong performance as well. Model performance does not scale significantly with parameter size. These findings underscore the feasibility of developing multi-task foundation models tailored for power systems, demonstrating that while larger datasets and models generally improve performance, extreme scaling is unnecessary to achieve satisfactory outcomes.

Paper number 8:
Title: Med3DVLM: An Efficient Vision-Language Model for 3D Medical Image Analysis
Authors: Yu Xin, Gorkem Can Ates, Kuang Gong, Wei Shao
Abstract: Vision-language models (VLMs) have shown promise in 2D medical image analysis, but extending them to 3D remains challenging due to the high computational demands of volumetric data and the difficulty of aligning 3D spatial features with clinical text. We present Med3DVLM, a 3D VLM designed to address these challenges through three key innovations: (1) DCFormer, an efficient encoder that uses decomposed 3D convolutions to capture fine-grained spatial features at scale; (2) SigLIP, a contrastive learning strategy with pairwise sigmoid loss that improves image-text alignment without relying on large negative batches; and (3) a dual-stream MLP-Mixer projector that fuses low- and high-level image features with text embeddings for richer multi-modal representations. We evaluate our model on the M3D dataset, which includes radiology reports and VQA data for 120,084 3D medical images. Results show that Med3DVLM achieves superior performance across multiple benchmarks. For image-text retrieval, it reaches 61.00% R@1 on 2,000 samples, significantly outperforming the current state-of-the-art M3D model (19.10%). For report generation, it achieves a METEOR score of 36.42% (vs. 14.38%). In open-ended visual question answering (VQA), it scores 36.76% METEOR (vs. 33.58%), and in closed-ended VQA, it achieves 79.95% accuracy (vs. 75.78%). These results highlight Med3DVLM's ability to bridge the gap between 3D imaging and language, enabling scalable, multi-task reasoning across clinical applications. Our code is publicly available at this https URL.

Paper number 9:
Title: Federated Learning: A new frontier in the exploration of multi-institutional medical imaging data
Authors: Dominika Ciupek, Maciej Malawski, Tomasz Pieciak
Abstract: Artificial intelligence has transformed the perspective of medical imaging, leading to a genuine technological revolution in modern computer-assisted healthcare systems. However, ubiquitously featured deep learning (DL) systems require access to a considerable amount of data, facilitating proper knowledge extraction and generalization. Admission to such extensive resources may be hindered due to the time and effort required to convey ethical agreements, set up and carry the acquisition procedures through, and manage the datasets adequately with a particular emphasis on proper anonymization. One of the pivotal challenges in the DL field is data integration from various sources acquired using different hardware vendors, diverse acquisition protocols, experimental setups, and even inter-operator variabilities. In this paper, we review the federated learning (FL) concept that fosters the integration of large-scale heterogeneous datasets from multiple institutions in training DL models. In contrast to a centralized approach, the decentralized FL procedure promotes training DL models while preserving data privacy at each institution involved. We formulate the FL principle and comprehensively review general and dedicated medical imaging aggregation and learning algorithms, enabling the generation of a globally generalized model. We meticulously go through the challenges in constructing FL-based systems, such as data heterogeneity across the institutions, resilience to potential attacks on data privacy, and the variability in computational and communication resources among the entangled sites that might induce efficiency issues of the entire system. Finally, we explore the up-to-date open frameworks for rapid FL-based algorithm prototyping and shed light on future directions in this intensively growing field.

Paper number 10:
Title: Hybrid FSO and RF Lunar Wireless Power Transfer
Authors: Baris Donmez, Yanni Jiwan-Mercier, Sebastien Loranger, Gunes Karabulut Kurt
Abstract: This study focuses on the feasibility analyses of the hybrid FSO and RF-based WPT system used in the realistic Cislunar environment, which is established by using STK HPOP software in which many external forces are incorporated. In our proposed multi-hop scheme, a solar-powered satellite (SPS) beams the laser power to the low lunar orbit (LLO) satellite in the first hop, then the harvested power is used as a relay power for RF-based WPT to two critical lunar regions, which are lunar south pole (LSP) (0°E,90°S) and Malapert Mountain (0°E,86°S), owing to the multi-point coverage feature of RF systems. The end-to-end system is analyzed for two cases, i) the perfect alignment, and ii) the misalignment fading due to the random mechanical vibrations in the optical inter-satellite link. It is found that the harvested power is maximized when the distance between the SPS and LLO satellite is minimized and it is calculated as 331.94 kW, however, when the random misalignment fading is considered, the mean of the harvested power reduces to 309.49 kW for the same distance. In the next hop, the power harvested by the solar array on the LLO satellite is consumed entirely as the relay power. Identical parabolic antennas are considered during the RF-based WPT system between the LLO satellite and the LSP, which utilizes a full-tracking module, and between the LLO satellite and the Malapert Mountain region, which uses a half-tracking module that executes the tracking on the receiver dish only. In the perfectly aligned hybrid WPT system, 19.80 W and 573.7 mW of maximum harvested powers are yielded at the LSP and Mountain Malapert, respectively. On the other hand, when the misalignment fading in the end-to-end system is considered, the mean of the maximum harvested powers degrades to 18.41 W and 534.4 mW for the former and latter hybrid WPT links.

Paper number 11:
Title: Near-Field THz Bending Beamforming: A Convex Optimization Perspective
Authors: Aoran Liu, Weidong Mei, Peilan Wang, Dong Wang, Ya Fei Wu, Zhi Chen
Abstract: Terahertz (THz) communication systems suffer severe blockage issues, which may significantly degrade the communica tion coverage and quality. Bending beams, capable of adjusting their propagation direction to bypass obstacles, have recently emerged as a promising solution to resolve this issue by engineer ing the propagation trajectory of the beam. However, traditional bending beam generation methods rely heavily on the specific geometric properties of the propagation trajectory and can only achieve sub-optimal performance. In this paper, we propose a new and general bending beamforming method by adopting the convex optimization techniques. In particular, we formulate the bending beamforming design as a max-min optimization problem, aiming to optimize the analog or digital transmit beamforming vector to maximize the minimum received signal power among all positions along the bending beam trajectory. However, the resulting problem is non-convex and difficult to be solved optimally. To tackle this difficulty, we apply the successive convex approximation (SCA) technique to obtain a high-quality suboptimal solution. Numerical results show that our proposed bending beamforming method outperforms the traditional method and shows robustness to the obstacle in the environment.

Paper number 12:
Title: Small-Signal Stability Condition of Inverter-Integrated Power Systems: Closed-Form Expression by Stationary Power Flow Variables
Authors: Taku Nishino, Yoshiyuki Onishi, Takayuki Ishizaki
Abstract: This paper shows that a necessary and sufficient condition for the small-signal stability of an inverter-integrated power system can be expressed in terms of semidefinite matrix inequalities determined only by the synchronous reactance of the components, the susceptance matrix of the transmission network, and the stationary values of the power flow distribution. To derive the stability condition, we consider a class of grid-forming inverters corresponding to a singular perturbation of the synchronous generator. The resulting matrix inequality condition, which has twice as many dimensions as the number of buses and is independent of the dynamics of the connected components, is expressed in terms of each component compensating in a decentralized manner for the loss of frequency synchronization caused by the reactive power consumption in the transmission network. A simple numerical example using a 3-bus power system model shows that a grid-forming inverter load improves power system synchronization, while a grid-following inverter load disrupts it.

Paper number 13:
Title: Impact of the Pilot Design for OFDM Based Bi-static Integrated Sensing and Communication System
Authors: Cuneyd Ozturk, Cagri Goken
Abstract: A bistatic milimeter-wave (mmWave) ISAC system utilizing OFDM signaling is considered. For a single-target scnenario, closed-form expressions for the Cramer-Rao bounds (CRBs) of range and velocity estimation are derived for a given pilot pattern. The analysis shows that when the target's range and velocity remain within the maximum unambiguous limits, allocating pilot symbols more frequently in time improves position estimation, while increasing their density in frequency enhances velocity estimation. Numerical results further validate that the least squares (LS) channel estimation approach closely follows CRB predictions, particularly in the high-SNR regime.

Paper number 14:
Title: QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions
Authors: Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang
Abstract: This paper explores a novel perspective to speech quality assessment by leveraging natural language descriptions, offering richer, more nuanced insights than traditional numerical scoring methods. Natural language feedback provides instructive recommendations and detailed evaluations, yet existing datasets lack the comprehensive annotations needed for this approach. To bridge this gap, we introduce QualiSpeech, a comprehensive low-level speech quality assessment dataset encompassing 11 key aspects and detailed natural language comments that include reasoning and contextual insights. Additionally, we propose the QualiSpeech Benchmark to evaluate the low-level speech understanding capabilities of auditory large language models (LLMs). Experimental results demonstrate that finetuned auditory LLMs can reliably generate detailed descriptions of noise and distortion, effectively identifying their types and temporal characteristics. The results further highlight the potential for incorporating reasoning to enhance the accuracy and reliability of quality assessments. The dataset will be released at this https URL.

Paper number 15:
Title: Optimal One- and Two-Sided Multi-Level ASK for Noncoherent SIMO Systems Over Correlated Rician Fading
Authors: Badri Ramanjaneya Reddy, Soumya P. Dash, George C. Alexandropoulos
Abstract: This paper analyzes the performance of a single-input multiple-output (SIMO) wireless communication system employing one- and two-sided amplitude shift keying (ASK) modulation schemes for data transmission and operating under correlated Rician fading channels. The receiver deploys an optimal noncoherent maximum likelihood detector, which exploits statistical knowledge of the channel state information for signal decoding. An optimal receiver structure is derived, from which series-form and closed-form expressions for the union bound on the symbol error probability (SEP) are obtained for general and massive SIMO systems, respectively. Furthermore, an optimization framework to derive the optimal one- and two-sided ASK modulation schemes is proposed, which focuses on minimizing SEP performance under an average transmit energy constraint. The conducted numerical investigations for various system parameters demonstrate that the proposed noncoherent SIMO system with the designed optimal ASK modulation schemes achieves superior error performance compared to traditional equispaced ASK modulation. It is also shown that, when the proposed system employs traditional two-sided ASK modulation, superior error performance from the case of using one-sided ASK is obtained.

Paper number 16:
Title: Merits of Serving UAVs via Terrestrial Networks: A Vertical Antenna Radiation Study
Authors: Nesrine Cherif, Qurrat-Ul-Ain Nadeem
Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in a plethora of applications such as shipping, surveillance, and search-and-rescue. For UAVs to operate safely, reliable cellular connectivity is essential. Utilizing the terrestrial networks for aerial connectivity has been proposed, but the 3D radiation pattern of base station antennas significantly affects the performance of aerial links.. To address this, we evaluate the coverage probability of cellular-connected UAVs, considering vertical antenna gain, by leveraging tools from stochastic geometry. We also analyze how the UAV hovering height, tilt angle and 3D antenna beamwidth influence the reliability of the communication link. Our results show that a down-tiled antenna does not only improve the connectivity of terrestrial users but also its cellularconnected UAVs counterpart. Moreover, the coverage probability of the UAV-UE becomes saturated at large down-tilt angles at the TBSs due to the antenna sidelobe gain at the serving and interfering TBSs. We also found that the significant increase of the vertical antenna beamwidth improves the UAV user coverage probability especially at relatively low hovering altitudes thanks to the increase of the desired signal strength compared to the interference power.

Paper number 17:
Title: 3D Convolutional Neural Networks for Improved Detection of Intracranial bleeding in CT Imaging
Authors: Bargava Subramanian, Naveen Kumarasami, Praveen Shastry, Kalyan Sivasailam, Anandakumar D, Elakkiya R, Harsha KG, Rithanya V, Harini T, Afshin Hussain, Kishore Prasath Venkatesh
Abstract: Background: Intracranial bleeding (IB) is a life-threatening condition caused by traumatic brain injuries, including epidural, subdural, subarachnoid, and intraparenchymal hemorrhages. Rapid and accurate detection is crucial to prevent severe complications. Traditional imaging can be slow and prone to variability, especially in high-pressure scenarios. Artificial Intelligence (AI) provides a solution by quickly analyzing medical images, identifying subtle hemorrhages, and flagging urgent cases. By enhancing diagnostic speed and accuracy, AI improves workflows and patient care. This article explores AI's role in transforming IB detection in emergency settings. Methods: A U-shaped 3D Convolutional Neural Network (CNN) automates IB detection and classification in volumetric CT scans. Advanced preprocessing, including CLAHE and intensity normalization, enhances image quality. The architecture preserves spatial and contextual details for precise segmentation. A dataset of 2,912 annotated CT scans was used for training and evaluation. Results: The model achieved high performance across major bleed types, with precision, recall, and accuracy exceeding 90 percent in most cases 96 percent precision for epidural hemorrhages and 94 percent accuracy for subarachnoid hemorrhages. Its ability to classify and localize hemorrhages highlights its clinical reliability. Conclusion: This U-shaped 3D CNN offers a scalable solution for automating IB detection, reducing diagnostic delays, and improving emergency care outcomes. Future work will expand dataset diversity, optimize real-time processing, and integrate multimodal data for enhanced clinical applicability.

Paper number 18:
Title: AI-Driven MRI Spine Pathology Detection: A Comprehensive Deep Learning Approach for Automated Diagnosis in Diverse Clinical Settings
Authors: Bargava Subramanian, Naveen Kumarasami, Praveen Shastry, Raghotham Sripadraj, Kalyan Sivasailam, Anandakumar D, Abinaya Ramachandran, Sudhir MP, Gunakutti G, Kishore Prasath Venkatesh
Abstract: Study Design This study presents the development of an autonomous AI system for MRI spine pathology detection, trained on a dataset of 2 million MRI spine scans sourced from diverse healthcare facilities across India. The AI system integrates advanced architectures, including Vision Transformers, U-Net with cross-attention, MedSAM, and Cascade R-CNN, enabling comprehensive classification, segmentation, and detection of 43 distinct spinal pathologies. The dataset is balanced across age groups, genders, and scanner manufacturers to ensure robustness and adaptability. Subgroup analyses were conducted to validate the model's performance across different patient demographics, imaging conditions, and equipment types. Performance The AI system achieved up to 97.9 percent multi-pathology detection, demonstrating consistent performance across age, gender, and manufacturer subgroups. The normal vs. abnormal classification achieved 98.0 percent accuracy, and the system was deployed across 13 major healthcare enterprises in India, encompassing diagnostic centers, large hospitals, and government facilities. During deployment, it processed approximately 100,000 plus MRI spine scans, leading to reduced reporting times and increased diagnostic efficiency by automating the identification of common spinal conditions. Conclusion The AI system's high precision and recall validate its capability as a reliable tool for autonomous normal/abnormal classification, pathology segmentation, and detection. Its scalability and adaptability address critical diagnostic gaps, optimize radiology workflows, and improve patient care across varied healthcare environments in India.

Paper number 19:
Title: Structure Identification of NDS with Descriptor Subsystems under Asynchronous, Non-Uniform, and Slow-Rate Sampling
Authors: Yunxiang Ma, Tong Zhou
Abstract: Networked dynamic systems (NDS) exhibit collective behavior shaped by subsystem dynamics and complex interconnections, yet identifying these interconnections remains challenging due to irregularities in sampled data, including asynchronous, non-uniform, and low-rate sampling. This paper proposes a novel two-stage structure identification algorithm that leverages system zero-order moments, a concept traditionally used in model order reduction, to bridge system identification and model reduction. First, zero-order moments are estimated from steady-state time-domain outputs; second, subsystem interconnections are explicitly reconstructed from these moments. The method generalizes existing approaches by handling asynchronous, non-uniform, and slow sampling simultaneously, eliminating constraints on input signal periodicity and extending applicability to multi-input multi-output NDS with arbitrary interconnections. Unlike black-box identification techniques, our approach explicitly recovers subsystem interconnection structures. Validation on the IEEE 14-bus system demonstrates the algorithm's effectiveness in recovering subsystem interconnections from irregular sampling data.

Paper number 20:
Title: Derivation and analysis of power offset in fiber-longitudinal power profile estimation using pre-FEC hard-decision data
Authors: Du Tang, Yingjie Jiang, Ji Luo, Yu Chen, Bofang Zheng, Yaojun Qiao
Abstract: Utilizing the precise reference waveform regenerated by post-forward error correction (FEC) data, the fiber-longitudinal power profile estimation based on the minimum-mean-square-error method (MMSE-PPE) has been validated as an effective tool for absolute power monitoring. However, when post-FEC data is unavailable, it becomes necessary to rely on pre-FEC hard-decision data, which inevitably introduces hard-decision errors. These hard-decision errors will result in a power offset that undermines the accuracy of absolute power monitoring. In this paper, we present the first analytical expression for power offset in MMSE-PPE when using pre-FEC hard-decision data, achieved by introducing a virtual hard-decision nonlinear perturbation term. Based on this analytical expression, we also establish the first nonlinear relationship between the power offset and the symbol error rate (SER) of M-ary quadrature amplitude modulation (M-QAM) formats based on Gaussian assumptions. Verified in a numerical 130-GBaud single-wavelength coherent optical fiber transmission system, the correctness of the analytical expression of power offset has been confirmed with 4-QAM, 16-QAM, and 64-QAM formats under different SER situations. Furthermore, the nonlinear relationship between the power offset and SER of $M$-QAM formats has also been thoroughly validated under both linear scale (measured in mW) and logarithmic scale (measured in dB). These theoretical insights offer significant contributions to the design of potential power offset mitigation strategies in MMSE-PPE, thereby enhancing its real-time application.

Paper number 21:
Title: Modality-Independent Brain Lesion Segmentation with Privacy-aware Continual Learning
Authors: Yousef Sadegheih, Pratibha Kumari, Dorit Merhof
Abstract: Traditional brain lesion segmentation models for multi-modal MRI are typically tailored to specific pathologies, relying on datasets with predefined modalities. Adapting to new MRI modalities or pathologies often requires training separate models, which contrasts with how medical professionals incrementally expand their expertise by learning from diverse datasets over time. Inspired by this human learning process, we propose a unified segmentation model capable of sequentially learning from multiple datasets with varying modalities and pathologies. Our approach leverages a privacy-aware continual learning framework that integrates a mixture-of-experts mechanism and dual knowledge distillation to mitigate catastrophic forgetting while not compromising performance on newly encountered datasets. Extensive experiments across five diverse brain MRI datasets and four dataset sequences demonstrate the effectiveness of our framework in maintaining a single adaptable model, capable of handling varying hospital protocols, imaging modalities, and disease types. Compared to widely used privacy-aware continual learning methods such as LwF, SI, EWC, and MiB, our method achieves an average Dice score improvement of approximately 11%. Our framework represents a significant step toward more versatile and practical brain lesion segmentation models, with implementation available at \href{this https URL}{GitHub}.

Paper number 22:
Title: Euclidean Distance to Convex Polyhedra and Application to Class Representation in Spectral Images
Authors: Antoine Bottenmuller (CMM), Florent Magaud (LRCS), Arnaud Demortière (LRCS), Etienne Decencière (CMM), Petr Dokladal (CMM)
Abstract: With the aim of estimating the abundance map from observations only, linear unmixing approaches are not always suitable to spectral images, especially when the number of bands is too small or when the spectra of the observed data are too correlated. To address this issue in the general case, we present a novel approach which provides an adapted spatial density function based on any arbitrary linear classifier. A robust mathematical formulation for computing the Euclidean distance to polyhedral sets is presented, along with an efficient algorithm that provides the exact minimum-norm point in a polyhedron. An empirical evaluation on the widely-used Samson hyperspectral dataset demonstrates that the proposed method surpasses state-of-the-art approaches in reconstructing abundance maps. Furthermore, its application to spectral images of a Lithium-ion battery, incompatible with linear unmixing models, validates the method's generality and effectiveness.

Paper number 23:
Title: Phase-Center-Constrained Beamforming for Minimizing Phase-Center Displacement
Authors: Jan Steckel, Noori BniLam
Abstract: Accurate knowledge and control of the phase center in antenna arrays is essential for high-precision applications such as Global Navigation Satellite Systems (GNSS), where even small displacements can introduce significant localization errors. Traditional beamforming techniques applied to array antennas often neglect the variation of the phase center, resulting in unwanted spatial shifts, and in consequence, localization errors. In this work, we propose a novel beamforming algorithm, called Phase-Center-Constrained Beamforming (PCCB), which explicitly minimizes the displacement of the phase center (Phase Center Offset, PCO) while preserving a chosen directional gain. We formulate the problem as a constrained optimization problem and incorporate regularization terms that enforce energy compactness and beampattern fidelity. The resulting PCCB approach allows for directional gain control and interference nulling while significantly reducing PCO displacement. Experimental validation using a simulated GNSS antenna array demonstrates that our PCCB approach achieves a fivefold reduction in PCO shift compared to the PCO shifts obtained when using conventional beamforming. A stability analysis across multiple random initializations confirms the robustness of our method and highlights the benefit of repeated optimization. These results indicate that our PCCB approach can serve as a practical and effective solution for decreasing phase center variability.

Paper number 24:
Title: GNSS jammer localization and identification with airborne commercial GNSS receivers
Authors: Marco Spanghero, Filip Geib, Ronny Panier, Panos Papadimitratos
Abstract: Global Navigation Satellite Systems (GNSS) are fundamental in ubiquitously providing position and time to a wide gamut of systems. Jamming remains a realistic threat in many deployment settings, civilian and tactical. Specifically, in Unmanned Aerial Vehicles (UAVs) sustained denial raises safety critical concerns. This work presents a strategy that allows detection, localization, and classification both in the frequency and time domain of interference signals harmful to navigation. A high-performance Vertical Take Off and Landing (VTOL) UAV with a single antenna and a commercial GNSS receiver is used to geolocate and characterize RF emitters at long range, to infer the navigation impairment. Raw IQ baseband snapshots from the GNSS receiver make the application of spectral correlation methods possible without extra software-defined radio payload, paving the way to spectrum identification and monitoring in airborne platforms, aiming at RF situational awareness. Live testing at Jammertest, in Norway, with portable, commercially available GNSS multi-band jammers demonstrates the ability to detect, localize, and characterize harmful interference. Our system pinpointed the position with an error of a few meters of the transmitter and the extent of the affected area at long range, without entering the denied zone. Additionally, further spectral content extraction is used to accurately identify the jammer frequency, bandwidth, and modulation scheme based on spectral correlation techniques.

Paper number 25:
Title: Comparative analysis of clustering methods for power delay profile in MMW bands and in-vehicle scenarios
Authors: Radek Zavorka, Ales Prokes, Josef Vychodil, Tomas Mikulasek, Petr Horky, Aniruddha Chandra, Christoph Mecklenbrauker, Jan M. Kelner, Cezary Ziolkowski
Abstract: The spatial statistics of radio wave propagation in specific environments and scenarios, as well as being able to recognize important signal components, are prerequisites for dependable connectivity. There are several reasons why in-vehicle communication is unique, including safety considerations and vehicle-to-vehicle/infrastructure this http URL paper examines the characteristics of clustering power delay profiles to investigate in-vehicle communication. It has been demonstrated that the Saleh-Valenzuela channel model can also be adapted for in-vehicle communication, and that the signal is received in clusters with exponential decay. A measurement campaign was conducted, capturing the power delay profile inside the vehicle cabin, and the reweighted l1 minimization method was compared with the traditional k-means clustering techniques.

Paper number 26:
Title: Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring
Authors: Adrian Villalobos, Iban Barrutia, Rafael Pena-Alzola, Tomislav Dragicevic, Jose I. Aizpurua
Abstract: Semiconductor devices, especially MOSFETs (Metal-oxide-semiconductor field-effect transistor), are crucial in power electronics, but their reliability is affected by aging processes influenced by cycling and temperature. The primary aging mechanism in discrete semiconductors and power modules is the bond wire lift-off, caused by crack growth due to thermal fatigue. The process is empirically characterized by exponential growth and an abrupt end of life, making long-term aging forecasts challenging. This research presents a comprehensive comparative assessment of different forecasting methods for MOSFET failure forecasting applications. Classical tracking, statistical forecasting and Neural Network (NN) based forecasting models are implemented along with novel Temporal Fusion Transformers (TFTs). A comprehensive comparison is performed assessing their MOSFET ageing forecasting ability for different forecasting horizons. For short-term predictions, all algorithms result in acceptable results, with the best results produced by classical NN forecasting models at the expense of higher computations. For long-term forecasting, only the TFT is able to produce valid outcomes owing to the ability to integrate covariates from the expected future conditions. Additionally, TFT attention points identify key ageing turning points, which indicate new failure modes or accelerated ageing phases.

Paper number 27:
Title: The Crucial Role of Problem Formulation in Real-World Reinforcement Learning
Authors: Georg Schäfer, Tatjana Krau, Jakob Rehrl, Stefan Huber, Simon Hirlaender
Abstract: Reinforcement Learning (RL) offers promising solutions for control tasks in industrial cyber-physical systems (ICPSs), yet its real-world adoption remains limited. This paper demonstrates how seemingly small but well-designed modifications to the RL problem formulation can substantially improve performance, stability, and sample efficiency. We identify and investigate key elements of RL problem formulation and show that these enhance both learning speed and final policy quality. Our experiments use a one-degree-of-freedom (1-DoF) helicopter testbed, the Quanser Aero~2, which features non-linear dynamics representative of many industrial settings. In simulation, the proposed problem design principles yield more reliable and efficient training, and we further validate these results by training the agent directly on physical hardware. The encouraging real-world outcomes highlight the potential of RL for ICPS, especially when careful attention is paid to the design principles of problem formulation. Overall, our study underscores the crucial role of thoughtful problem formulation in bridging the gap between RL research and the demands of real-world industrial systems.

Paper number 28:
Title: Attention Xception UNet (AXUNet): A Novel Combination of CNN and Self-Attention for Brain Tumor Segmentation
Authors: Farzan Moodi, Fereshteh Khodadadi Shoushtari, Gelareh Valizadeh, Dornaz Mazinani, Hanieh Mobarak Salari, Hamidreza Saligheh Rad
Abstract: Accurate segmentation of glioma brain tumors is crucial for diagnosis and treatment planning. Deep learning techniques offer promising solutions, but optimal model architectures remain under investigation. We used the BraTS 2021 dataset, selecting T1 with contrast enhancement (T1CE), T2, and Fluid-Attenuated Inversion Recovery (FLAIR) sequences for model development. The proposed Attention Xception UNet (AXUNet) architecture integrates an Xception backbone with dot-product self-attention modules, inspired by state-of-the-art (SOTA) large language models such as Google Bard and OpenAI ChatGPT, within a UNet-shaped model. We compared AXUNet with SOTA models. Comparative evaluation on the test set demonstrated improved results over baseline models. Inception-UNet and Xception-UNet achieved mean Dice scores of 90.88 and 93.24, respectively. Attention ResUNet (AResUNet) attained a mean Dice score of 92.80, with the highest score of 84.92 for enhancing tumor (ET) among all models. Attention Gate UNet (AGUNet) yielded a mean Dice score of 90.38. AXUNet outperformed all models with a mean Dice score of 93.73. It demonstrated superior Dice scores across whole tumor (WT) and tumor core (TC) regions, achieving 92.59 for WT, 86.81 for TC, and 84.89 for ET. The integration of the Xception backbone and dot-product self-attention mechanisms in AXUNet showcases enhanced performance in capturing spatial and contextual information. The findings underscore the potential utility of AXUNet in facilitating precise tumor delineation.

Paper number 29:
Title: Underwater Image Enhancement by Convolutional Spiking Neural Networks
Authors: Vidya Sudevan, Fakhreddine Zayer, Rizwana Kausar, Sajid Javed, Hamad Karki, Giulia De Masi, Jorge Dias
Abstract: Underwater image enhancement (UIE) is fundamental for marine applications, including autonomous vision-based navigation. Deep learning methods using convolutional neural networks (CNN) and vision transformers advanced UIE performance. Recently, spiking neural networks (SNN) have gained attention for their lightweight design, energy efficiency, and scalability. This paper introduces UIE-SNN, the first SNN-based UIE algorithm to improve visibility of underwater images. UIE-SNN is a 19- layered convolutional spiking encoder-decoder framework with skip connections, directly trained using surrogate gradient-based backpropagation through time (BPTT) strategy. We explore and validate the influence of training datasets on energy reduction, a unique advantage of UIE-SNN architecture, in contrast to the conventional learning-based architectures, where energy consumption is model-dependent. UIE-SNN optimizes the loss function in latent space representation to reconstruct clear underwater images. Our algorithm performs on par with its non-spiking counterpart methods in terms of PSNR and structural similarity index (SSIM) at reduced timesteps ($T=5$) and energy consumption of $85\%$. The algorithm is trained on two publicly available benchmark datasets, UIEB and EUVP, and tested on unseen images from UIEB, EUVP, LSUI, U45, and our custom UIE dataset. The UIE-SNN algorithm achieves PSNR of \(17.7801~dB\) and SSIM of \(0.7454\) on UIEB, and PSNR of \(23.1725~dB\) and SSIM of \(0.7890\) on EUVP. UIE-SNN achieves this algorithmic performance with fewer operators (\(147.49\) GSOPs) and energy (\(0.1327~J\)) compared to its non-spiking counterpart (GFLOPs = \(218.88\) and Energy=\(1.0068~J\)). Compared with existing SOTA UIE methods, UIE-SNN achieves an average of \(6.5\times\) improvement in energy efficiency. The source code is available at \href{this https URL}{UIE-SNN}.

Paper number 30:
Title: Model Predictive Control for Tracking Bounded References With Arbitrary Dynamics
Authors: Shibo Han, Bonan Hou, Yuhao Zhang, Xiaotong Shi, Xingwei Zhao
Abstract: In this article, a model predictive control (MPC) method is proposed for constrained linear systems to track bounded references with arbitrary dynamics. Besides control inputs to be determined, artificial reference is introduced as additional decision variable, which serves as an intermediate target to cope with sudden changes of reference and enlarges domain of attraction. Cost function penalizes both artificial state error and reference error, while terminal constraint is imposed on artificial state error and artificial reference. We specify the requirements for terminal constraint and cost function to guarantee recursive feasibility of the proposed method and asymptotic stability of tracking error. Then, periodic and non-periodic references are considered and the method to determine required cost function and terminal constraint is proposed. Finally, the efficiency of the proposed MPC controller is demonstrated with simulation examples.

Paper number 31:
Title: Automated and Risk-Aware Engine Control Calibration Using Constrained Bayesian Optimization
Authors: Maarten Vlaswinkel, Duarte Antunes, Frank Willems
Abstract: Decarbonization of the transport sector sets increasingly strict demands to maximize thermal efficiency and minimize greenhouse gas emissions of Internal Combustion Engines. This has led to complex engines with a surge in the number of corresponding tunable parameters in actuator set points and control settings. Automated calibration is therefore essential to keep development time and costs at acceptable levels. In this work, an innovative self-learning calibration method is presented based on in-cylinder pressure curve shaping. This method combines Principal Component Decomposition with constrained Bayesian Optimization. To realize maximal thermal engine efficiency, the optimization problem aims at minimizing the difference between the actual in-cylinder pressure curve and an Idealized Thermodynamic Cycle. By continuously updating a Gaussian Process Regression model of the pressure's Principal Components weights using measurements of the actual operating conditions, the mean in-cylinder pressure curve as well as its uncertainty bounds are learned. This information drives the optimization of calibration parameters, which are automatically adapted while dealing with the risks and uncertainties associated with operational safety and combustion stability. This data-driven method does not require prior knowledge of the system. The proposed method is successfully demonstrated in simulation using a Reactivity Controlled Compression Ignition engine model. The difference between the Gross Indicated Efficiency of the optimal solution found and the true optimum is 0.017%. For this complex engine, the optimal solution was found after 64.4s, which is relatively fast compared to conventional calibration methods.

Paper number 32:
Title: Design and Evaluation of Neural Network-Based Receiver Architectures for Reliable Communication
Authors: Hüseyin Çevik, Erhan Karakoca, İbrahim Hökelek, Ali Görçin
Abstract: Neural network-based receivers leverage deep learning to optimize signal detection and decoding, significantly improving bit-error rate (BER) and block-error rate (BLER) in challenging environments. This study evaluates various architectures and compares their BER and BLER performance across different noise levels. Two novel models, the Dual Attention Transformer (DAT) and the Residual Dual Non-Local Attention Network (RDNLA), integrate self-attention and residual learning to enhance signal reconstruction. These models bypass conventional channel estimation and equalization by directly predicting log-likelihood ratios (LLRs) from received signals, with noise variance as an additional input. Simulations show that DAT and RDNLA outperform traditional and other neural receiver models under varying signal-to-noise ratios (SNR), while their computational efficiency supports their feasibility for next-generation communication systems.

Paper number 33:
Title: Problem-Structure-Informed Quantum Approximate Optimization Algorithm for Large-Scale Unit Commitment with Limited Qubits
Authors: Jingxian Zhou, Ziqing Zhu, Linghua Zhu, Siqi Bu
Abstract: As power systems expand, solving the Unit Commitment Problem (UCP) becomes increasingly challenging due to the dimensional catastrophe, and traditional methods often struggle to balance computational efficiency and solution quality. To tackle this issue, we propose a problem-structure-informed Quantum Approximate Optimization Algorithm (QAOA) framework that fully exploits the quantum advantage under extremely limited quantum resources. Specifically, we leverage the inherent topological structure of power systems to decompose large-scale UCP instances into smaller subproblems, each solvable in parallel by limited number of qubits. This decomposition not only circumvents the current hardware limitations of quantum computing but also achieves higher performance as the graph structure of the power system becomes more sparse. Consequently, our approach can be readily extended to future power systems that are larger and more complex.

Paper number 34:
Title: Exploring Robustness of Cortical Morphometry in the presence of white matter lesions, using Diffusion Models for Lesion Filling
Authors: Vinzenz Uhr, Ivan Diaz, Christian Rummel, Richard McKinley
Abstract: Cortical thickness measurements from magnetic resonance imaging, an important biomarker in many neurodegenerative and neurological disorders, are derived by many tools from an initial voxel-wise tissue segmentation. White matter (WM) hypointensities in T1-weighted imaging, such as those arising from multiple sclerosis or small vessel disease, are known to affect the output of brain segmentation methods and therefore bias cortical thickness measurements. These effects are well-documented among traditional brain segmentation tools but have not been studied extensively in tools based on deep-learning segmentations, which promise to be more robust. In this paper, we explore the potential of deep learning to enhance the accuracy and efficiency of cortical thickness measurement in the presence of WM lesions, using a high-quality lesion filling algorithm leveraging denoising diffusion networks. A pseudo-3D U-Net architecture trained on the OASIS dataset to generate synthetic healthy tissue, conditioned on binary lesion masks derived from the MSSEG dataset, allows realistic removal of white matter lesions in multiple sclerosis patients. By applying morphometry methods to patient images before and after lesion filling, we analysed robustness of global and regional cortical thickness measurements in the presence of white matter lesions. Methods based on a deep learning-based segmentation of the brain (Fastsurfer, DL+DiReCT, ANTsPyNet) exhibited greater robustness than those using classical segmentation methods (Freesurfer, ANTs).

Paper number 35:
Title: SaViD: Spectravista Aesthetic Vision Integration for Robust and Discerning 3D Object Detection in Challenging Environments
Authors: Tanmoy Dam, Sanjay Bhargav Dharavath, Sameer Alam, Nimrod Lilith, Aniruddha Maiti, Supriyo Chakraborty, Mir Feroskhan
Abstract: The fusion of LiDAR and camera sensors has demonstrated significant effectiveness in achieving accurate detection for short-range tasks in autonomous driving. However, this fusion approach could face challenges when dealing with long-range detection scenarios due to disparity between sparsity of LiDAR and high-resolution camera data. Moreover, sensor corruption introduces complexities that affect the ability to maintain robustness, despite the growing adoption of sensor fusion in this domain. We present SaViD, a novel framework comprised of a three-stage fusion alignment mechanism designed to address long-range detection challenges in the presence of natural corruption. The SaViD framework consists of three key elements: the Global Memory Attention Network (GMAN), which enhances the extraction of image features through offering a deeper understanding of global patterns; the Attentional Sparse Memory Network (ASMN), which enhances the integration of LiDAR and image features; and the KNNnectivity Graph Fusion (KGF), which enables the entire fusion of spatial information. SaViD achieves superior performance on the long-range detection Argoverse-2 (AV2) dataset with a performance improvement of 9.87% in AP value and an improvement of 2.39% in mAPH for L2 difficulties on the Waymo Open dataset (WOD). Comprehensive experiments are carried out to showcase its robustness against 14 natural sensor corruptions. SaViD exhibits a robust performance improvement of 31.43% for AV2 and 16.13% for WOD in RCE value compared to other existing fusion-based methods while considering all the corruptions for both datasets. Our code is available at \href{this https URL}

Paper number 36:
Title: Impact of Network-Controlled Repeaters in Integrated Sensing and Communication Systems
Authors: Henrik Åkesson, Diana P. M. Osorio, Erik G. Larsson
Abstract: Integrating sensing capabilities into existing massive MIMO communication networks has become crucial, stemming from a need for a more interconnected society. Improved coverage and performance can be obtained by incorporating new network components, such as reconfigurable intelligent surfaces or network-controlled repeaters (NCR). Integrating such components into modern networks brings a number of challenges. Thus, this paper contributes with the analysis of NCR impact in integrated sensing and communication networks. Particularly, the Cramér-Rao bound for a range estimator is derived where the interference from the repeater is taken into consideration. Additionally, a joint procedure for determining the repeater amplification factor, along with the precoders of the transmitting access point, is proposed.

Paper number 37:
Title: UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift
Authors: Antoine Schieb, Bilal Hadjadji, Daniel Tshokola Mweze, Natalia Fernanda Valderrama, Valentin Derangère, Laurent Arnould, Sylvain Ladoire, Alain Lalande, Louis-Oscar Morel, Nathan Vinçon
Abstract: Histopathology slide digitization introduces scanner-induced domain shift that can significantly impact computational pathology models based on deep learning methods. In the state-of-the-art, this shift is often characterized at a broad scale (slide-level or dataset-level) but not patch-level, which limits our comprehension of the impact of localized tissue characteristics on the accuracy of the deep learning models. To address this challenge, we present a domain shift analysis framework based on UWarp, a novel registration tool designed to accurately align histological slides scanned under varying conditions. UWarp employs a hierarchical registration approach, combining global affine transformations with fine-grained local corrections to achieve robust tissue patch alignment. We evaluate UWarp using two private datasets, CypathLung and BosomShieldBreast, containing whole slide images scanned by multiple devices. Our experiments demonstrate that UWarp outperforms existing open-source registration methods, achieving a median target registration error (TRE) of less than 4 pixels (<1 micrometer at 40x magnification) while significantly reducing computational time. Additionally, we apply UWarp to characterize scanner-induced local domain shift in the predictions of Breast-NEOprAIdict, a deep learning model for breast cancer pathological response prediction. We find that prediction variability is strongly correlated with tissue density on a given patch. Our findings highlight the importance of localized domain shift analysis and suggest that UWarp can serve as a valuable tool for improving model robustness and domain adaptation strategies in computational pathology.

Paper number 38:
Title: Probabilistic Forecasting for Network Resource Analysis in Integrated Terrestrial and Non-Terrestrial Networks
Authors: Cristian J. Vaca-Rubio, Vaishnavi Kasuluru, Engin Zeydan, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev
Abstract: Efficient resource management is critical for Non-Terrestrial Networks (NTNs) to provide consistent, high-quality service in remote and under-served regions. While traditional single-point prediction methods, such as Long-Short Term Memory (LSTM), have been used in terrestrial networks, they often fall short in NTNs due to the complexity of satellite dynamics, signal latency and coverage variability. Probabilistic forecasting, which quantifies the uncertainties of the predictions, is a robust alternative. In this paper, we evaluate the application of probabilistic forecasting techniques, in particular SFF, to NTN resource allocation scenarios. Our results show their effectiveness in predicting bandwidth and capacity requirements in different NTN segments of probabilistic forecasting compared to single-point prediction techniques such as LSTM. The results show the potential of black probabilistic forecasting models to provide accurate and reliable predictions and to quantify their uncertainty, making them indispensable for optimizing NTN resource allocation. At the end of the paper, we also present application scenarios and a standardization roadmap for the use of probabilistic forecasting in integrated Terrestrial Network (TN)-NTN environments.

Paper number 39:
Title: Agent-Based Analysis of the Impact of Near Real-Time Data and Smart Balancing on the Frequency Stability of Power Systems
Authors: Johannes Lips, Boyana Georgieva, Dominik Schlipf, Hendrik Lens
Abstract: Single imbalance pricing provides an incentive to balance responsible parties (BRPs) to intentionally introduce power schedule deviations in order to reduce the control area imbalance and receive a remuneration through the imbalance settlement mechanism. This is called smart balancing or passive balancing and is actively encouraged in, e.g., the Netherlands and Belgium through the publication of near real-time (NRT) data on the control area imbalance by the transmission system operator. It is known that under certain conditions, smart balancing can deteriorate the frequency stability of the power system. This paper examines how the publication of different types of NRT data affects smart balancing and the frequency stability. A Monte-Carlo simulation of a dynamic multi-agent model is performed to analyse the effects of smart balancing with different parameters for the agents and the environment, using historical time series of the power imbalance of the German control block as a basis. It is found that smart balancing can significantly reduce the amount and cost of frequency restoration reserve activation, but leads to a general increase of the frequency variability. Depending on the type of NRT data and agent parameters, the frequency stability margins are also reduced. The negative effects on the frequency stability are stronger when NRT data is published using large bins and with long delays.

Paper number 40:
Title: Benchmarking Machine Learning Methods for Distributed Acoustic Sensing
Authors: Shuaikai Shi, Qijun Zong
Abstract: Distributed acoustic sensing (DAS) technology represents an innovative fiber-optic-based sensing methodology that enables real-time acoustic signal monitoring through the detection of minute perturbations along optical fibers. This sensing approach offers compelling advantages, including extensive measurement ranges, exceptional spatial resolution, and an expansive dynamic measurement spectrum. The integration of machine learning (ML) paradigms presents transformative potential for DAS technology, encompassing critical domains such as data augmentation, sophisticated preprocessing techniques, and advanced acoustic event classification and recognition. By leveraging ML algorithms, DAS systems can transition from traditional data processing methodologies to more automated and intelligent analytical frameworks. The computational intelligence afforded by ML-enhanced DAS technologies facilitates unprecedented monitoring capabilities across diverse critical infrastructure sectors. Particularly noteworthy are the technology's applications in transportation infrastructure, energy management systems, and Natural disaster monitoring frameworks, where the precision of data acquisition and the reliability of intelligent decision-making mechanisms are paramount. This research critically examines the comparative performance characteristics of classical machine learning methodologies and state-of-the-art deep learning models in the context of DAS data recognition and interpretation, offering comprehensive insights into the evolving landscape of intelligent sensing technologies.

Paper number 41:
Title: Data-driven Distributionally Robust Control Based on Sinkhorn Ambiguity Sets
Authors: Riccardo Cescon, Andrea Martin, Giancarlo Ferrari-Trecate
Abstract: As the complexity of modern control systems increases, it becomes challenging to derive an accurate model of the uncertainty that affects their dynamics. Wasserstein Distributionally Robust Optimization (DRO) provides a powerful framework for decision-making under distributional uncertainty only using noise samples. However, while the resulting policies inherit strong probabilistic guarantees when the number of samples is sufficiently high, their performance may significantly degrade when only a few data are available. Inspired by recent results from the machine learning community, we introduce an entropic regularization to penalize deviations from a given reference distribution and study data-driven DR control over Sinkhorn ambiguity sets. We show that for finite-horizon control problems, the optimal DR linear policy can be computed via convex programming. By analyzing the relation between the ambiguity set defined in terms of Wasserstein and Sinkhorn discrepancies, we reveal that, as the regularization parameter increases, this optimal policy interpolates between the solution of the Wasserstein DR problem and that of the stochastic problem under the reference distribution. We validate our theoretical findings and the effectiveness of our approach when only scarce data are available on a numerical example.

Paper number 42:
Title: Model-free Vehicle Rollover Prevention: A Data-driven Predictive Control Approach
Authors: Mohammad R. Hajidavalloo, Kaixiang Zhang, Vaibhav Srivastava, Zhaojian Li
Abstract: Vehicle rollovers pose a significant safety risk and account for a disproportionately high number of fatalities in road accidents. This paper addresses the challenge of rollover prevention using Data-EnablEd Predictive Control (DeePC), a data-driven control strategy that directly leverages raw input-output data to maintain vehicle stability without requiring explicit system modeling. To enhance computational efficiency, we employ a reduced-dimension DeePC that utilizes singular value decomposition-based dimension reduction to significantly lower computation complexity without compromising control performance. This optimization enables real-time application in scenarios with high-dimensional data, making the approach more practical for deployment in real-world vehicles. The proposed approach is validated through high-fidelity CarSim simulations in both sedan and utility truck scenarios, demonstrating its versatility and ability to maintain vehicle stability under challenging driving conditions. Comparative results with Linear Model Predictive Control (LMPC) highlight the superior performance of DeePC in preventing rollovers while preserving maneuverability. The findings suggest that DeePC offers a robust and adaptable solution for rollover prevention, capable of handling varying road and vehicle conditions.

Paper number 43:
Title: Insights from Game Theory into the Impact of Smart Balancing on Power System Stability
Authors: Johannes Lips, Hendrik Lens
Abstract: Smart balancing, also called passive balancing, is the intentional introduction of active power schedule deviations by balance responsible parties (BRPs) to receive a remuneration through the imbalance settlement mechanism. From a system perspective, smart balancing is meant to reduce the need for, and costs of, frequency restoration reserves (FRR), but it can also cause large oscillations in the FRR and jeopardize the system stability. Using a dynamic control area model, this work defines a 2x2 game in which two BRPs can choose to perform smart balancing. We study the impact of time delay, ramp rates, and pricing mechanisms on Nash equilibria and Experience-weighted Attraction (EWA) learning. It is found that, even in an idealized setting, a significant fraction of games in a learned equilibrium results in an overreaction relative to the baseline disturbance, creating an imbalance in the opposite direction. This suggests that the system stability risks are inherent to smart balancing and not a question of implementation. Recommendations are given for implementation choices that can reduce (but not eliminate) the risk of overreactions.

Paper number 44:
Title: Convergence Theory of Flexible ALADIN for Distributed Optimization
Authors: Xu Du, Xiaohua Zhou, Shijie Zhu
Abstract: The Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) method is a cutting-edge distributed optimization algorithm known for its superior numerical performance. It relies on each agent transmitting information to a central coordinator for data exchange. However, in practical network optimization and federated learning, unreliable information transmission often leads to packet loss, posing challenges for the convergence analysis of ALADIN. To address this issue, this paper proposes Flexible ALADIN, a random polling variant of ALADIN, and presents a rigorous convergence analysis, including global convergence for convex problems and local convergence for non-convex problems.

Paper number 45:
Title: Continual Learning With Quasi-Newton Methods
Authors: Steven Vander Eeckt, Hugo Van hamme
Abstract: Catastrophic forgetting remains a major challenge when neural networks learn tasks sequentially. Elastic Weight Consolidation (EWC) attempts to address this problem by introducing a Bayesian-inspired regularization loss to preserve knowledge of previously learned tasks. However, EWC relies on a Laplace approximation where the Hessian is simplified to the diagonal of the Fisher information matrix, assuming uncorrelated model parameters. This overly simplistic assumption often leads to poor Hessian estimates, limiting its effectiveness. To overcome this limitation, we introduce Continual Learning with Sampled Quasi-Newton (CSQN), which leverages Quasi-Newton methods to compute more accurate Hessian approximations. CSQN captures parameter interactions beyond the diagonal without requiring architecture-specific modifications, making it applicable across diverse tasks and architectures. Experimental results across four benchmarks demonstrate that CSQN consistently outperforms EWC and other state-of-the-art baselines, including rehearsal-based methods. CSQN reduces EWC's forgetting by 50 percent and improves its performance by 8 percent on average. Notably, CSQN achieves superior results on three out of four benchmarks, including the most challenging scenarios, highlighting its potential as a robust solution for continual learning.

Paper number 46:
Title: Deploying an Aerial Reconfigurable Intelligent Surface for Vehicle-to-Vehicle Communications (PL: Wykorzystanie powietrznych przełączalnych inteligentnych powierzchni do komunikacji międzypojazdowej)
Authors: Salim Janji
Abstract: This paper addresses the deployment of a drone equipped with a reconfigurable intelligent surface (RIS), creating a drone relay station (DRS) to enhance the connectivity of vehicle-to-vehicle (V2V) pairs on the ground. The trajectory of the DRS is optimized to quickly reach the best location for maximizing throughput. Additionally, the presence of an interfering node is considered, and an analytical solution is derived to determine the optimal orientation of the DRS at each time step, minimizing interference to the receiver. Simulation results confirm the effectiveness of the proposed framework.

Paper number 47:
Title: DRPA-MPPI: Dynamic Repulsive Potential Augmented MPPI for Reactive Navigation in Unstructured Environments
Authors: Takahiro Fuke, Masafumi Endo, Kohei Honda, Genya Ishigami
Abstract: Reactive mobile robot navigation in unstructured environments is challenging when robots encounter unexpected obstacles that invalidate previously planned trajectories. Model predictive path integral control (MPPI) enables reactive planning, but still suffers from limited prediction horizons that lead to local minima traps near obstacles. Current solutions rely on heuristic cost design or scenario-specific pre-training, which often limits their adaptability to new environments. We introduce dynamic repulsive potential augmented MPPI (DRPA-MPPI), which dynamically detects potential entrapments on the predicted trajectories. Upon detecting local minima, DRPA-MPPI automatically switches between standard goal-oriented optimization and a modified cost function that generates repulsive forces away from local minima. Comprehensive testing in simulated obstacle-rich environments confirms DRPA-MPPI's superior navigation performance and safety compared to conventional methods with less computational burden.

Paper number 48:
Title: Spectrum from Defocus: Fast Spectral Imaging with Chromatic Focal Stack
Authors: M. Kerem Aydin, Yi-Chun Hung, Jaclyn Pytlarz, Qi Guo, Emma Alexander
Abstract: Hyperspectral cameras face harsh trade-offs between spatial, spectral, and temporal resolution in an inherently low-photon regime. Computational imaging systems break through these trade-offs with compressive sensing, but require complex optics and/or extensive compute. We present Spectrum from Defocus (SfD), a chromatic focal sweep method that recovers state-of-the-art hyperspectral images with a small system of off-the-shelf optics and < 1 second of compute. Our camera uses two lenses and a grayscale sensor to preserve nearly all incident light in a chromatically-aberrated focal stack. Our physics-based iterative algorithm efficiently demixes, deconvolves, and denoises the blurry grayscale focal stack into a sharp spectral image. The combination of photon efficiency, optical simplicity, and physical modeling makes SfD a promising solution for fast, compact, interpretable hyperspectral imaging.

Paper number 49:
Title: Mutual Information-Empowered Task-Oriented Communication: Principles, Applications and Challenges
Authors: Hongru Li, Songjie Xie, Jiawei Shao, Zixin Wang, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief
Abstract: Mutual information (MI)-based guidelines have recently proven to be effective for designing task-oriented communication systems, where the ultimate goal is to extract and transmit task-relevant information for downstream task. This paper provides a comprehensive overview of MI-empowered task-oriented communication, highlighting how MI-based methods can serve as a unifying design framework in various task-oriented communication scenarios. We begin with the roadmap of MI for designing task-oriented communication systems, and then introduce the roles and applications of MI to guide feature encoding, transmission optimization, and efficient training with two case studies. We further elaborate the limitations and challenges of MI-based methods. Finally, we identify several open issues in MI-based task-oriented communication to inspire future research.

Paper number 50:
Title: Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages
Authors: Yangyang Meng, Jinpeng Li, Guodong Lin, Yu Pu, Guanbo Wang, Hu Du, Zhiming Shao, Yukai Huang, Ke Li, Wei-Qiang Zhang
Abstract: This report introduces Dolphin, a large-scale multilingual automatic speech recognition (ASR) model that extends the Whisper architecture to support a wider range of languages. Our approach integrates in-house proprietary and open-source datasets to refine and optimize Dolphin's performance. The model is specifically designed to achieve notable recognition accuracy for 40 Eastern languages across East Asia, South Asia, Southeast Asia, and the Middle East, while also supporting 22 Chinese dialects. Experimental evaluations show that Dolphin significantly outperforms current state-of-the-art open-source models across various languages. To promote reproducibility and community-driven innovation, we are making our trained models and inference source code publicly available.

Paper number 51:
Title: Qwen2.5-Omni Technical Report
Authors: Jin Xu, Zhifang Guo, Jinzheng He, Hangrui Hu, Ting He, Shuai Bai, Keqin Chen, Jialin Wang, Yang Fan, Kai Dang, Bin Zhang, Xiong Wang, Yunfei Chu, Junyang Lin
Abstract: In this report, we present Qwen2.5-Omni, an end-to-end multimodal model designed to perceive diverse modalities, including text, images, audio, and video, while simultaneously generating text and natural speech responses in a streaming manner. To enable the streaming of multimodal information inputs, both audio and visual encoders utilize a block-wise processing approach. To synchronize the timestamps of video inputs with audio, we organize the audio and video sequentially in an interleaved manner and propose a novel position embedding approach, named TMRoPE(Time-aligned Multimodal RoPE). To concurrently generate text and speech while avoiding interference between the two modalities, we propose \textbf{Thinker-Talker} architecture. In this framework, Thinker functions as a large language model tasked with text generation, while Talker is a dual-track autoregressive model that directly utilizes the hidden representations from the Thinker to produce audio tokens as output. Both the Thinker and Talker models are designed to be trained and inferred in an end-to-end manner. For decoding audio tokens in a streaming manner, we introduce a sliding-window DiT that restricts the receptive field, aiming to reduce the initial package delay. Qwen2.5-Omni is comparable with the similarly sized Qwen2.5-VL and outperforms Qwen2-Audio. Furthermore, Qwen2.5-Omni achieves state-of-the-art performance on multimodal benchmarks like Omni-Bench. Notably, Qwen2.5-Omni's performance in end-to-end speech instruction following is comparable to its capabilities with text inputs, as evidenced by benchmarks such as MMLU and GSM8K. As for speech generation, Qwen2.5-Omni's streaming Talker outperforms most existing streaming and non-streaming alternatives in robustness and naturalness.

Paper number 52:
Title: Two-Player Dynamic Potential LQ Games with Sequentially Revealed Costs
Authors: Yitian Chen, Timothy L. Molloy, Iman Shames
Abstract: We investigate a novel finite-horizon linear-quadratic (LQ) feedback dynamic potential game with a priori unknown cost matrices played between two players. The cost matrices are revealed to the players sequentially, with the potential for future values to be previewed over a short time window. We propose an algorithm that enables the players to predict and track a feedback Nash equilibrium trajectory, and we measure the quality of their resulting decisions by introducing the concept of \emph{price of uncertainty}. We show that under the proposed algorithm, the price of uncertainty is bounded by horizon-invariant constants. The constants are the sum of three terms; the first and second terms decay exponentially as the preview window grows, and another depends on the magnitude of the differences between the cost matrices for each player. Through simulations, we illustrate that the resulting price of uncertainty initially decays at an exponential rate as the preview window lengthens, then remains constant for large time horizons.

Paper number 53:
Title: A Virtual Fencing Framework for Safe and Efficient Collaborative Robotics
Authors: Vineela Reddy Pippera Badguna, Aliasghar Arab, Durga Avinash Kodavalla
Abstract: Collaborative robots (cobots) increasingly operate alongside humans, demanding robust real-time safeguarding. Current safety standards (e.g., ISO 10218, ANSI/RIA 15.06, ISO/TS 15066) require risk assessments but offer limited guidance for real-time responses. We propose a virtual fencing approach that detects and predicts human motion, ensuring safe cobot operation. Safety and performance tradeoffs are modeled as an optimization problem and solved via sequential quadratic programming. Experimental validation shows that our method minimizes operational pauses while maintaining safety, providing a modular solution for human-robot collaboration.

Paper number 54:
Title: ESSR: An 8K@30FPS Super-Resolution Accelerator With Edge Selective Network
Authors: Chih-Chia Hsu, Tian-Sheuan Chang
Abstract: Deep learning-based super-resolution (SR) is challenging to implement in resource-constrained edge devices for resolutions beyond full HD due to its high computational complexity and memory bandwidth requirements. This paper introduces an 8K@30FPS SR accelerator with edge-selective dynamic input processing. Dynamic processing chooses the appropriate subnets for different patches based on simple input edge criteria, achieving a 50\% MAC reduction with only a 0.1dB PSNR decrease. The quality of reconstruction images is guaranteed and maximized its potential with \textit{resource adaptive model switching} even under resource constraints. In conjunction with hardware-specific refinements, the model size is reduced by 84\% to 51K, but with a decrease of less than 0.6dB PSNR. Additionally, to support dynamic processing with high utilization, this design incorporates a \textit{configurable group of layer mapping} that synergizes with the \textit{structure-friendly fusion block}, resulting in 77\% hardware utilization and up to 79\% reduction in feature SRAM access. The implementation, using the TSMC 28nm process, can achieve 8K@30FPS throughput at 800MHz with a gate count of 2749K, 0.2075W power consumption, and 4797Mpixels/J energy efficiency, exceeding previous work.

Paper number 55:
Title: Sequential Task Assignment and Resource Allocation in V2X-Enabled Mobile Edge Computing
Authors: Yufei Ye, Shijian Gao, Xinhu Zheng, Liuqing Yang
Abstract: Nowadays, the convergence of Mobile Edge Computing (MEC) and vehicular networks has emerged as a vital facilitator for the ever-increasing intelligent onboard applications. This paper introduces a multi-tier task offloading mechanism for MEC-enabled vehicular networks leveraging vehicle-to-everything (V2X) communications. The study focuses on applications with sequential subtasks and explores two tiers of collaboration. In the vehicle tier, we design a needing vehicle (NV)-helping vehicle (HV) matching scheme and inter-vehicle collaborative computation is studied, with joint optimization of task offloading decision, communication, and computation resource allocation to minimize energy consumption and meet latency requirements. In the roadside unit (RSU) tier, collaboration among RSUs is investigated to address multi-access issues of bandwidth and computation resources for multiple vehicles. A two-step method is proposed to solve the subchannel allocation problem. Detailed experiments are conducted to demonstrate the effectiveness of the proposed method and assess the impact of different parameters on system energy consumption.

Paper number 56:
Title: Turning Circle-based Control Barrier Function for Efficient Collision Avoidance of Nonholonomic Vehicles
Authors: Changyu Lee, Kiyong Park, Jinwhan Kim
Abstract: This paper presents a new control barrier function (CBF) designed to improve the efficiency of collision avoidance for nonholonomic vehicles. Traditional CBFs typically rely on the shortest Euclidean distance to obstacles, overlooking the limited heading change ability of nonholonomic vehicles. This often leads to abrupt maneuvers and excessive speed reductions, which is not desirable and reduces the efficiency of collision avoidance. Our approach addresses these limitations by incorporating the distance to the turning circle, considering the vehicle's limited maneuverability imposed by its nonholonomic constraints. The proposed CBF is integrated with model predictive control (MPC) to generate more efficient trajectories compared to existing methods that rely solely on Euclidean distance-based CBFs. The effectiveness of the proposed method is validated through numerical simulations on unicycle vehicles and experiments with underactuated surface vehicles.

Paper number 57:
Title: UnReference: analysis of the effect of spoofing on RTK reference stations for connected rovers
Authors: Marco Spanghero, Panos Papadimitratos
Abstract: Global Navigation Satellite Systems (GNSS) provide standalone precise navigation for a wide gamut of applications. Nevertheless, applications or systems such as unmanned vehicles (aerial or ground vehicles and surface vessels) generally require a much higher level of accuracy than those provided by standalone receivers. The most effective and economical way of achieving centimeter-level accuracy is to rely on corrections provided by fixed \emph{reference station} receivers to improve the satellite ranging measurements. Differential GNSS (DGNSS) and Real Time Kinematics (RTK) provide centimeter-level accuracy by distributing online correction streams to connected nearby mobile receivers typically termed \emph{rovers}. However, due to their static nature, reference stations are prime targets for GNSS attacks, both simplistic jamming and advanced spoofing, with different levels of adversarial control and complexity. Jamming the reference station would deny corrections and thus accuracy to the rovers. Spoofing the reference station would force it to distribute misleading corrections. As a result, all connected rovers using those corrections will be equally influenced by the adversary independently of their actual trajectory. We evaluate a battery of tests generated with an RF simulator to test the robustness of a common DGNSS/RTK processing library and receivers. We test both jamming and synchronized spoofing to demonstrate that adversarial action on the rover using reference spoofing is both effective and convenient from an adversarial perspective. Additionally, we discuss possible strategies based on existing countermeasures (self-validation of the PNT solution and monitoring of own clock drift) that the rover and the reference station can adopt to avoid using or distributing bogus corrections.

Paper number 58:
Title: FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System
Authors: Hao-Han Guo, Kun Xie, Yi-Chen Wu, Feng-Long Xie
Abstract: In this work, we propose a high-quality streaming foundation text-to-speech system, FireRedTTS-1S, upgraded from the streamable version of FireRedTTS. FireRedTTS-1S achieves streaming generation via two steps: text-to-semantic decoding and semantic-to-acoustic decoding. In text-to-semantic decoding, a semantic-aware speech tokenizer converts the speech signal into semantic tokens, which can be synthesized from the text via a semantic language model in an auto-regressive manner. Meanwhile, the semantic-to-acoustic decoding module simultaneously translates generated semantic tokens into the speech signal in a streaming way via a super-resolution causal audio codec and a multi-stream acoustic language model. This design enables us to produce high-quality speech audio in zero-shot settings while presenting a real-time generation process with low latency under 150ms. In experiments on zero-shot voice cloning, the objective results validate FireRedTTS-1S as a high-quality foundation model with comparable intelligibility and speaker similarity over industrial baseline systems. Furthermore, the subjective score of FireRedTTS-1S highlights its impressive synthesis performance, achieving comparable quality to the ground-truth recordings. These results validate FireRedTTS-1S as a high-quality streaming foundation TTS system.

Paper number 59:
Title: State-Aware Perturbation Optimization for Robust Deep Reinforcement Learning
Authors: Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui
Abstract: Recently, deep reinforcement learning (DRL) has emerged as a promising approach for robotic control. However, the deployment of DRL in real-world robots is hindered by its sensitivity to environmental perturbations. While existing whitebox adversarial attacks rely on local gradient information and apply uniform perturbations across all states to evaluate DRL robustness, they fail to account for temporal dynamics and state-specific vulnerabilities. To combat the above challenge, we first conduct a theoretical analysis of white-box attacks in DRL by establishing the adversarial victim-dynamics Markov decision process (AVD-MDP), to derive the necessary and sufficient conditions for a successful attack. Based on this, we propose a selective state-aware reinforcement adversarial attack method, named STAR, to optimize perturbation stealthiness and state visitation dispersion. STAR first employs a soft mask-based state-targeting mechanism to minimize redundant perturbations, enhancing stealthiness and attack effectiveness. Then, it incorporates an information-theoretic optimization objective to maximize mutual information between perturbations, environmental states, and victim actions, ensuring a dispersed state-visitation distribution that steers the victim agent into vulnerable states for maximum return reduction. Extensive experiments demonstrate that STAR outperforms state-of-the-art benchmarks.

Paper number 60:
Title: Immersive and Wearable Thermal Rendering for Augmented Reality
Authors: Alexandra Watkins, Ritam Ghosh, Evan Chow, Nilanjan Sarkar
Abstract: In augmented reality (AR), where digital content is overlaid onto the real world, realistic thermal feedback has been shown to enhance immersion. Yet current thermal feedback devices, heavily influenced by the needs of virtual reality, often hinder physical interactions and are ineffective for immersion in AR. To bridge this gap, we have identified three design considerations relevant for AR thermal feedback: indirect feedback to maintain dexterity, thermal passthrough to preserve real-world temperature perception, and spatiotemporal rendering for dynamic sensations. We then created a unique and innovative thermal feedback device that satisfies these criteria. Human subject experiments assessing perceptual sensitivity, object temperature matching, spatial pattern recognition, and moving thermal stimuli demonstrated the impact of our design, enabling realistic temperature discrimination, virtual object perception, and enhanced immersion. These findings demonstrate that carefully designed thermal feedback systems can bridge the sensory gap between physical and virtual interactions, enhancing AR realism and usability.

Paper number 61:
Title: AutoRad-Lung: A Radiomic-Guided Prompting Autoregressive Vision-Language Model for Lung Nodule Malignancy Prediction
Authors: Sadaf Khademi, Mehran Shabanpour, Reza Taleei, Anastasia Oikonomou, Arash Mohammadi
Abstract: Lung cancer remains one of the leading causes of cancer-related mortality worldwide. A crucial challenge for early diagnosis is differentiating uncertain cases with similar visual characteristics and closely annotation scores. In clinical practice, radiologists rely on quantitative, hand-crafted Radiomic features extracted from Computed Tomography (CT) images, while recent research has primarily focused on deep learning solutions. More recently, Vision-Language Models (VLMs), particularly Contrastive Language-Image Pre-Training (CLIP)-based models, have gained attention for their ability to integrate textual knowledge into lung cancer diagnosis. While CLIP-Lung models have shown promising results, we identified the following potential limitations: (a) dependence on radiologists' annotated attributes, which are inherently subjective and error-prone, (b) use of textual information only during training, limiting direct applicability at inference, and (c) Convolutional-based vision encoder with randomly initialized weights, which disregards prior knowledge. To address these limitations, we introduce AutoRad-Lung, which couples an autoregressively pre-trained VLM, with prompts generated from hand-crafted Radiomics. AutoRad-Lung uses the vision encoder of the Large-Scale Autoregressive Image Model (AIMv2), pre-trained using a multi-modal autoregressive objective. Given that lung tumors are typically small, irregularly shaped, and visually similar to healthy tissue, AutoRad-Lung offers significant advantages over its CLIP-based counterparts by capturing pixel-level differences. Additionally, we introduce conditional context optimization, which dynamically generates context-specific prompts based on input Radiomics, improving cross-modal alignment.

Paper number 62:
Title: Decoherence time maximization and partial isolation for open quantum harmonic oscillator memory networks
Authors: Igor G. Vladimirov, Ian R. Petersen, Guodong Shi
Abstract: This paper considers a network of open quantum harmonic oscillators which interact with their neighbours through direct energy and field-mediated couplings and also with external quantum fields. The position-momentum dynamic variables of the network are governed by linear quantum stochastic differential equations associated with the nodes of a graph whose edges specify the interconnection of the component oscillators. Such systems can be employed as Heisenberg picture quantum memories with an engineered ability to approximately retain initial conditions over a bounded time interval. We use the quantum memory decoherence time defined previously in terms of a fidelity threshold on a weighted mean-square deviation for a subset (or linear combinations) of network variables from their initial values. This approach is applied to maximizing a high-fidelity asymptotic approximation of the decoherence time over the direct energy coupling parameters of the network. The resulting optimality condition is a set of linear equations for blocks of a sparse matrix associated with the edges of the direct energy coupling graph of the network. We also discuss a setting where the quantum network has a subset of dynamic variables which are affected by the external fields only indirectly, through a complementary ``shielding'' system. This holds under a rank condition on the network-field coupling matrix and can be achieved through an appropriate field-mediated coupling between the component oscillators. The partially isolated subnetwork has a longer decoherence time in the high-fidelity limit, thus providing a particularly relevant candidate for a quantum memory.

Paper number 63:
Title: A Low-complexity Structured Neural Network Approach to Intelligently Realize Wideband Multi-beam Beamformers
Authors: Hansaka Aluvihare, Sivakumar Sivasankar, Xianqi Li, Arjuna Madanayake, Sirani M. Perera
Abstract: True-time-delay (TTD) beamformers can produce wideband, squint-free beams in both analog and digital signal domains, unlike frequency-dependent FFT beams. Our previous work showed that TTD beamformers can be efficiently realized using the elements of delay Vandermonde matrix (DVM), answering the longstanding beam-squint problem. Thus, building on our work on classical algorithms based on DVM, we propose neural network (NN) architecture to realize wideband multi-beam beamformers using structure-imposed weight matrices and submatrices. The structure and sparsity of the weight matrices and submatrices are shown to reduce the space and computational complexities of the NN greatly. The proposed network architecture has O(pLM logM) complexity compared to a conventional fully connected L-layers network with O(M2L) complexity, where M is the number of nodes in each layer of the network, p is the number of submatrices per layer, and M >> p. We will show numerical simulations in the 24 GHz to 32 GHz range to demonstrate the numerical feasibility of realizing wideband multi-beam beamformers using the proposed neural architecture. We also show the complexity reduction of the proposed NN and compare that with fully connected NNs, to show the efficiency of the proposed architecture without sacrificing accuracy. The accuracy of the proposed NN architecture was shown using the mean squared error, which is based on an objective function of the weight matrices and beamformed signals of antenna arrays, while also normalizing nodes. The proposed NN architecture shows a low-complexity NN realizing wideband multi-beam beamformers in real-time for low-complexity intelligent systems.

Paper number 64:
Title: MindfulLIME: A Stable Solution for Explanations of Machine Learning Models with Enhanced Localization Precision -- A Medical Image Case Study
Authors: Shakiba Rahimiaghdam, Hande Alemdar
Abstract: Ensuring transparency in machine learning decisions is critically important, especially in sensitive sectors such as healthcare, finance, and justice. Despite this, some popular explainable algorithms, such as Local Interpretable Model-agnostic Explanations (LIME), often produce unstable explanations due to the random generation of perturbed samples. Random perturbation introduces small changes or noise to modified instances of the original data, leading to inconsistent explanations. Even slight variations in the generated samples significantly affect the explanations provided by such models, undermining trust and hindering the adoption of interpretable models. To address this challenge, we propose MindfulLIME, a novel algorithm that intelligently generates purposive samples using a graph-based pruning algorithm and uncertainty sampling. MindfulLIME substantially improves the consistency of visual explanations compared to random sampling approaches. Our experimental evaluation, conducted on a widely recognized chest X-ray dataset, confirms MindfulLIME's stability with a 100% success rate in delivering reliable explanations under identical conditions. Additionally, MindfulLIME improves the localization precision of visual explanations by reducing the distance between the generated explanations and the actual local annotations compared to LIME. We also performed comprehensive experiments considering various segmentation algorithms and sample numbers, focusing on stability, quality, and efficiency. The results demonstrate the outstanding performance of MindfulLIME across different segmentation settings, generating fewer high-quality samples within a reasonable processing time. By addressing the stability limitations of LIME in image data, MindfulLIME enhances the trustworthiness and interpretability of machine learning models in specific medical imaging applications, a critical domain.

Paper number 65:
Title: Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?
Authors: Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio Bolognani
Abstract: Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability -- ranging from ordinal level comparability to full cardinal comparability -- together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.

Paper number 66:
Title: Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising
Authors: Yan-Bo Lin, Kevin Lin, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Chung-Ching Lin, Xiaofei Wang, Gedas Bertasius, Lijuan Wang
Abstract: In this paper, we introduce zero-shot audio-video editing, a novel task that requires transforming original audio-visual content to align with a specified textual prompt without additional model training. To evaluate this task, we curate a benchmark dataset, AvED-Bench, designed explicitly for zero-shot audio-video editing. AvED-Bench includes 110 videos, each with a 10-second duration, spanning 11 categories from VGGSound. It offers diverse prompts and scenarios that require precise alignment between auditory and visual elements, enabling robust evaluation. We identify limitations in existing zero-shot audio and video editing methods, particularly in synchronization and coherence between modalities, which often result in inconsistent outcomes. To address these challenges, we propose AvED, a zero-shot cross-modal delta denoising framework that leverages audio-video interactions to achieve synchronized and coherent edits. AvED demonstrates superior results on both AvED-Bench and the recent OAVE dataset to validate its generalization capabilities. Results are available at this https URL

Paper number 67:
Title: Cutting Voxel Projector a New Approach to Construct 3D Cone Beam CT Operator
Authors: Vojtěch Kulvait (1), Julian Moosmann (1), Georg Rose (2) ((1) Institute of Materials Physics, Helmholtz-Zentrum Hereon, Geesthacht, Germany (2) Institute for Medical Engineering and Research Campus STIMULATE, University of Magdeburg, Magdeburg, Germany)
Abstract: We introduce a novel class of projectors for 3D cone beam tomographic reconstruction. Analytical formulas are derived to compute the relationship between the volume of a voxel projected onto a detector pixel and its contribution to the line integral of attenuation recorded by that pixel. Based on these formulas, we construct a near-exact projector and backprojector, particularly suited for algebraic reconstruction techniques and hierarchical reconstruction approaches with nonuniform voxel grids. Unlike traditional projectors, which assume a uniform grid with fixed voxel sizes, our method enables local refinement of voxels, allowing for adaptive grid resolution and improved reconstruction quality in regions of interest. We have implemented this cutting voxel projector along with a relaxed, speed-optimized version and compared them to two established projectors: a ray-tracing projector based on Siddon's algorithm and a TT footprint projector. Our results demonstrate that the cutting voxel projector achieves higher accuracy than the TT projector, especially for large cone beam angles. Furthermore, the relaxed version of the cutting voxel projector offers a significant speed advantage, while maintaining comparable accuracy. In contrast, Siddon's algorithm, tuned to achieve the same accuracy, is considerably slower than the cutting voxel projector. All algorithms are implemented in a GPU optimized open-source framework for algebraic reconstruction. GitHub repository of the project this https URL.

Paper number 68:
Title: Validation of Neural Network Controllers for Uncertain Systems Through Keep-Close Approach: Robustness Analysis and Safety Verification
Authors: Abdelhafid Zenati, Nabil Aouf
Abstract: Among the major challenges in neural control system technology is the validation and certification of the safety and robustness of neural network (NN) controllers against various uncertainties including unmodelled dynamics, nonlinearities, and time delays. One way in providing such validation guarantees is to maintain the closed-loop system output with a NN controller when its input changes within a bounded set, close to the output of a robustly performing closed-loop reference model. This paper presents a novel approach to analysing the performance and robustness of uncertain feedback systems with NN controllers. Due to the complexity of analysing such systems, the problem is reformulated as the problem of dynamical tracking errors between the closed-loop system with a neural controller and an ideal closed-loop reference model. Then, the approximation of the controller error is characterised by adopting the differential mean value theorem (DMV) and the Integral Quadratic Constraints (IQCs) technique. Moreover, the Relative Integral Square Error (RISE) and the Supreme Square Error (SSE) bounded set are derived for the output of the error dynamical system. The analysis is then performed by integrating Lyapunov theory with the IQCs-based technique. The resulting worst-case analysis provides the user a prior knowledge about the worst case of RISE and SSE between the reference closed-loop model and the uncertain system controlled by the neural controller.

Paper number 69:
Title: Scale-Equivariant Imaging: Self-Supervised Learning for Image Super-Resolution and Deblurring
Authors: Jérémy Scanvic, Mike Davies, Patrice Abry, Julián Tachella
Abstract: Self-supervised methods have recently proved to be nearly as effective as supervised ones in various imaging inverse problems, paving the way for learning-based approaches in scientific and medical imaging applications where ground truth data is hard or expensive to obtain. These methods critically rely on invariance to translations and/or rotations of the image distribution to learn from incomplete measurement data alone. However, existing approaches fail to obtain competitive performances in the problems of image super-resolution and deblurring, which play a key role in most imaging systems. In this work, we show that invariance to roto-translations is insufficient to learn from measurements that only contain low-frequency information. Instead, we propose scale-equivariant imaging, a new self-supervised approach that leverages the fact that many image distributions are approximately scale-invariant, enabling the recovery of high-frequency information lost in the measurement process. We demonstrate throughout a series of experiments on real datasets that the proposed method outperforms other self-supervised approaches, and obtains performances on par with fully supervised learning.

Paper number 70:
Title: Learning Soft Constrained MPC Value Functions: Efficient MPC Design and Implementation providing Stability and Safety Guarantees
Authors: Nicolas Chatzikiriakos, Kim P. Wabersich, Felix Berkel, Patricia Pauli, Andrea Iannelli
Abstract: Model Predictive Control (MPC) can be applied to safety-critical control problems, providing closed-loop safety and performance guarantees. Implementation of MPC controllers requires solving an optimization problem at every sampling instant, which is challenging to execute on embedded hardware. To address this challenge, we propose a framework that combines a tightened soft constrained MPC formulation with supervised learning to approximate the MPC value function. This combination enables us to obtain a corresponding optimal control law, which can be implemented efficiently on embedded platforms. The framework ensures stability and constraint satisfaction for various nonlinear systems. While the design effort is similar to that of nominal MPC, the proposed formulation provides input-to-state stability (ISS) with respect to the approximation error of the value function. Furthermore, we prove that the value function corresponding to the soft constrained MPC problem is Lipschitz continuous for Lipschitz continuous systems, even if the optimal control law may be discontinuous. This serves two purposes: First, it allows to relate approximation errors to a sufficiently large constraint tightening to obtain constraint satisfaction guarantees. Second, it paves the way for an efficient supervised learning procedure to obtain a continuous value function approximation. We demonstrate the effectiveness of the method using a nonlinear numerical example.

Paper number 71:
Title: Exploring Adversarial Threat Models in Cyber Physical Battery Systems
Authors: Shanthan Kumar Padisala, Shashank Dhananjay Vyas, Satadru Dey
Abstract: Technological advancements like the Internet of Things (IoT) have facilitated data exchange across various platforms. This data exchange across various platforms has transformed the traditional battery system into a cyber physical system. Such connectivity makes modern cyber physical battery systems vulnerable to cyber threats where a cyber attacker can manipulate sensing and actuation signals to bring the battery system into an unsafe operating condition. Hence, it is essential to build resilience in modern cyber physical battery systems (CPBS) under cyber attacks. The first step of building such resilience is to analyze potential adversarial behavior, that is, how the adversaries can inject attacks into the battery systems. However, it has been found that in this under-explored area of battery cyber physical security, such an adversarial threat model has not been studied in a systematic manner. In this study, we address this gap and explore adversarial attack generation policies based on optimal control framework. The framework is developed by performing theoretical analysis, which is subsequently supported by evaluation with experimental data generated from a commercial battery cell.

Paper number 72:
Title: Trustworthy UAV Cooperative Localization: Information Analysis of Performance and Security
Authors: Zexin Fang, Bin Han, Hans D. Schotten
Abstract: This paper presents a trustworthy framework for achieving accurate cooperative localization in multiple unmanned aerial vehicle (UAV) systems. The The Cramer-Rao Lower Bound (CRLB) for the three-dimensional (3D) cooperative localization network is derived, with particular attention given to practical scenarios involving non-uniform spatial distribution of anchor nodes. Challenges of mobility are then addressed with Mobility Adaptive Gradient Descent (MAGD). In the context of system security, we derive the CRLB of localization under the influence of falsified information. The methods and strategies of injecting such information and their impact on system performance are studied. To assure robust performance under falsified data, we propose a mitigation solution named Time-evolving Anomaly Detection (TAD). Furthermore, we model the system performance regarding the density and magnitude of falsified information, focusing on realistic scenarios where the adversary is resource-constrained. With the vulnerability of cooperative localization understood, we apply TAD and formulate an optimization problem from the adversary's perspective. Next, we discuss the design principles of an anomaly detector, with emphasis of the trade-off of reducing such optimum and system performance. Additionally, we also deploy a reputation propagation (RP) mechanism to fully utilize the anomaly detection and further optimize the TAD. Our proposed approaches are demonstrated through numerical simulations.

Paper number 73:
Title: A PAC-Bayesian Framework for Optimal Control with Stability Guarantees
Authors: Mahrokh Ghoddousi Boroujeni, Clara Lucía Galimberti, Andreas Krause, Giancarlo Ferrari-Trecate
Abstract: Stochastic Nonlinear Optimal Control (SNOC) involves minimizing a cost function that averages out the random uncertainties affecting the dynamics of nonlinear systems. For tractability reasons, this problem is typically addressed by minimizing an empirical cost, which represents the average cost across a finite dataset of sampled disturbances. However, this approach raises the challenge of quantifying the control performance against out-of-sample uncertainties. Particularly, in scenarios where the training dataset is small, SNOC policies are prone to overfitting, resulting in significant discrepancies between the empirical cost and the true cost, i.e., the average SNOC cost incurred during control deployment. Therefore, establishing generalization bounds on the true cost is crucial for ensuring reliability in real-world applications. In this paper, we introduce a novel approach that leverages PAC-Bayes theory to provide rigorous generalization bounds for SNOC. Based on these bounds, we propose a new method for designing optimal controllers, offering a principled way to incorporate prior knowledge into the synthesis process, which aids in improving the control policy and mitigating overfitting. Furthermore, by leveraging recent parametrizations of stabilizing controllers for nonlinear systems, our framework inherently ensures closed-loop stability. The effectiveness of our proposed method in incorporating prior knowledge and combating overfitting is shown by designing neural network controllers for tasks in cooperative robotics.

Paper number 74:
Title: Analytic Models for the Capacity Distribution in MDG-impaired Optical SDM Transmission
Authors: Lucas Alves Zischler, Darli A. A. Mello
Abstract: In coupled space-division multiplexing (SDM) transmission systems, imperfections in optical amplifiers and passive devices introduce mode-dependent loss (MDL) and gain (MDG). These effects render the channel capacity stochastic and result in a decrease in average capacity. Several previous studies employ multi-section simulations to model the capacity of these systems. Additionally, relevant works derive analytically the capacity distribution for a single-mode system with polarization-dependent gain and loss (mode count D = 2). However, to the best of our knowledge, analytic expressions of the capacity distribution for systems with D > 2 have not been presented. In this paper, we provide analytic expressions for the capacity of optical systems with arbitrary mode counts. The expressions rely on Gaussian approximations for the per-mode capacity distributions and for the overall capacity distribution, as well as on fitting parameters for the capacity cross-correlation among different modes. Compared to simulations, the derived analytical expressions exhibit a suitable level of accuracy across a wide range of practical scenarios.

Paper number 75:
Title: Desynchronization Index: a New Approach for Exploring Complex Epileptogenic Networks in Stereoelectroencephalography
Authors: Federico Mason, Lorenzo Ferri, Lidia Di Vito, Lara Alvisi, Luca Zanuttini, Matteo Martinoni, Roberto Mai, Francesco Cardinale, Paolo Tinuper, Roberto Michelucci, Elena Pasini, Francesca Bisulli
Abstract: In this work, we propose a new computational framework to assist neurophysiologists in Stereoelectroencephalography (SEEG) analysis, with the final aim of improving the definition of the Epileptogenic Zone (EZ) in patients with drug-resistant epilepsy. We design a new algorithm, named Desynchronization Index (DI), that classifies as most epileptogenic those SEEG channels that show independent behavior during the seconds preceding the seizure propagation. We test the proposed DI algorithm against the Epileptogenic Index (EI) algorithm on a clinical dataset of 11 patients, considering the neurophysiological evaluation of the EZ as the clinical ground truth. Our results denote that DI overcomes EI in terms of area under the ROC curve (AUC=0.81 vs AUC=0.74) while combining the two algorithms as a unique tool leads to the best performance (AUC=0.87). The DI algorithm underscores connectivity dynamics that can hardly be identified with a pure visual analysis, increasing the accuracy of the EZ definition compared to traditional methods. This technique can lead to the definition of a new effective biomarker of the EZ, reducing the burden required by the SEEG review in the case of extensive implants and improving our understanding of the dynamics leading to the generation of seizures.

Paper number 76:
Title: Data-driven Modeling of Linearizable Power Flow for Large-scale Grid Topology Optimization
Authors: Young-ho Cho, Hao Zhu
Abstract: Effective power flow (PF) modeling critically affects the solution accuracy and computational complexity of large-scale grid optimization problems. Especially for grid optimization involving flexible topology to enhance resilience, obtaining a tractable yet accurate approximation of nonlinear AC-PF is essential. This work puts forth a data-driven approach to obtain piecewise linear (PWL) PF approximation using an innovative neural network (NN) architecture, effectively aligning with the inherent generative structure of AC-PF equations. Accordingly, our proposed generative NN (GenNN) method directly incorporates binary topology variables, efficiently enabling a mixed-integer linear program (MILP) formulation for grid optimization tasks like optimal transmission switching (OTS) and restoration ordering problems (ROP). To attain model scalability for large-scale applications, we develop an area-partitioning-based sparsification approach by using fixed-size areas to attain a linear growth rate of model parameters, as opposed to the quadratic one of existing work. Numerical tests on the IEEE 118-bus and 6716-bus synthetic Texas grid demonstrate that our sparse GenNN achieves superior accuracy and computational efficiency, substantially outperforming existing approaches in large-scale PF modeling and topology optimization.

Paper number 77:
Title: Point Data for Site-Specific Mid-band Radio Propagation Channel Statistics in the Indoor Hotspot (InH) Environment for 3GPP and Next Generation Alliance (NGA) Channel Modeling
Authors: Theodore S. Rappaport, Dipankar Shakya, Mingjun Ying
Abstract: Extensive work has been carried out in the past year by various organizations in an effort to determine standardized statistical channel impulse response (CIR) parameters for the newly-released FR3 mid-band spectrum (7.25 GHz -- 24.25 GHz). In this work, we show that the wireless community currently lacks a unified method for presenting key parameters required for transparency and utilization by several constituencies when presenting propagation data for use by standard bodies or third parties to create statistical CIR models. This paper aims to solve the existing problem by offering a standard method to provide key propagation parameters in a point-data format that supports both statistical and site-specific channel characterization. As shown here, the point-data format enables multiple contributors to create channel model standards or pool measurement data to create larger datasets for exploring ray-tracing (e.g. site-specific) channel modeling or training in AI/ML propagation work, and to ensure the most accurate model using a larger dataset that is continually expanded through measurement contributions. The point-data approach includes site-specific point-by-point propagation data while readily supporting the creation of commonly-used cumulative distribution function (CDF) plot. The indoor hotspot (InH) datasets collected in Spring 2024 at 6.75 GHz and 16.95 GHZ by NYU WIRELESS are provided for the first time in point-data form, to augment statistical models previously presented solely as CDFs, in order to demonstrate how a standardized approach to measurement data could allow others to utilize the site-specific locations and key channel parameters observed at each location, to better understand, vet, and build upon statistical or site-specific CIRs from the contributions of many different data sources.

Paper number 78:
Title: Degrees of Freedom of Holographic MIMO in Multi-user Near-field Channels
Authors: Houfeng Chen, Shaohua Yue, Marco Di Renzo, Hongliang Zhang
Abstract: Holographic multiple-input multiple-output (HMIMO) is an emerging technology for 6G communications, in which numerous antenna units are integrated in a limited space. As the HMIMO array aperture expands, the near-field region of the array is dramatically enlarged, resulting in more users being located in the near-field region. This creates new opportunities for wireless communications. In this context, the evaluation of the spatial degrees of freedom (DoF) of HMIMO multi-user systems in near-field channels is an open problem, as the analytical methods utilized for evaluating the DoF in far-field channels cannot be directly applied. In this paper, we propose a novel method to calculate the DoF of HMIMO in multi-user near-field channels. We first derive the DoF for a single user in the near field, and then extend the analysis to multi-user scenarios. In this latter scenario, we focus on the impact of spatial blocking between HMIMO users. The derived analytical framework reveals that the DoF of HMIMO in multi-user near-field channels is not in general given by the sum of the DoF of the HMIMO single-user setting because of spatial blocking. Simulation results demonstrate the effectiveness of the proposed method. In the considered case study, the number of DoF reduces by $21.2\%$ on average due to spatial blocking.

Paper number 79:
Title: Upper Mid-Band Channel Measurements and Characterization at 6.75 GHz FR1(C) and 16.95 GHz FR3 in an Indoor Factory Scenario
Authors: Mingjun Ying, Dipankar Shakya, Theodore S. Rappaport, Peijie Ma, Yanbo Wang, Idris Al-Wazani, Yanze Wu, Hitesh Poddar
Abstract: This paper presents detailed radio propagation measurements for an indoor factory (InF) environment at 6.75 GHz and 16.95 GHz using a 1 GHz bandwidth channel sounder. Conducted at the NYU MakerSpace in the NYU Tandon School of Engineering campus in Brooklyn, NY, USA, our measurement campaign characterizes the radio propagation in a representative small factory with diverse machinery and open workspaces across 12 locations, comprising 5 line-of-sight (LOS) and 7 non-line-of-sight (NLOS) scenarios. Analysis using the close-in (CI) free space path loss (FSPL) model with a 1 m reference distance reveals path loss exponents (PLE) below 2 in LOS at 6.75 GHz and 16.95 GHz, while in NLOS, PLE is similar to free-space propagation (e.g., PLE = 2). The RMS delay spread (DS) decreases at higher frequencies with a clear frequency dependence. Also, measurements show a wider RMS angular spread (AS) in NLOS compared to LOS at both frequency bands, with a decreasing trend as frequency increases. These observations in a dense-scatterer factory environment demonstrate frequency-dependent behavior that differs from existing industry-standard 3GPP models. Our findings provide crucial insights into complex propagation mechanisms in factory environments, essential for designing robust air interface and industrial wireless networks at the upper mid-band FR3 spectrum.

Paper number 80:
Title: Image Generation with Supervised Selection Based on Multimodal Features for Semantic Communications
Authors: Chengyang Liang, Dong Li
Abstract: Semantic communication (SemCom) has emerged as a promising technique for the next-generation communication systems, in which the generation at the receiver side is allowed with semantic features' recovery. However, the majority of existing research predominantly utilizes a singular type of semantic information, such as text, images, or speech, to supervise and choose the generated source signals, which may not sufficiently encapsulate the comprehensive and accurate semantic information, and thus creating a performance bottleneck. In order to bridge this gap, in this paper, we propose and investigate a SemCom framework using multimodal information to supervise the generated image. To be specific, in this framework, we first extract semantic features at both the image and text levels utilizing the Convolutional Neural Network (CNN) architecture and the Contrastive Language-Image Pre-Training (CLIP) model before transmission. Then, we employ a generative diffusion model at the receiver to generate multiple images. In order to ensure the accurate extraction and facilitate high-fidelity image reconstruction, we select the "best" image with the minimum reconstruction errors by taking both the aided image and text semantic features into account. We further extend multimodal semantic communication (MMSemCom) system to the multiuser scenario for orthogonal transmission. Experimental results demonstrate that the proposed framework can not only achieve the enhanced fidelity and robustness in image transmission compared with existing communication systems but also sustain a high performance in the low signal-to-noise ratio (SNR) conditions.

Paper number 81:
Title: Map-Based Path Loss Prediction in Multiple Cities Using Convolutional Neural Networks
Authors: Ryan G. Dempsey, Jonathan Ethier, Halim Yanikomeroglu
Abstract: Radio deployments and spectrum planning benefit from path loss predictions. Obstructions along a communications link are often considered implicitly or through derived metrics such as representative clutter height or total obstruction depth. In this paper, we propose a path-specific path loss prediction method that uses convolutional neural networks to automatically perform feature extraction from 2-D obstruction height maps. Our methods result in low prediction error in a variety of environments without requiring derived metrics.

Paper number 82:
Title: Learning-Based Model Predictive Control for Piecewise Affine Systems with Feasibility Guarantees
Authors: Samuel Mallick, Azita Dabiri, Bart De Schutter
Abstract: Online model predictive control (MPC) for piecewise affine (PWA) systems requires the online solution to an optimization problem that implicitly optimizes over the switching sequence of PWA regions, for which the computational burden can be prohibitive. Alternatively, the computation can be moved offline using explicit MPC; however, the online memory requirements and the offline computation can then become excessive. In this work we propose a solution in between online and explicit MPC, addressing the above issues by partially dividing the computation between online and offline. To solve the underlying MPC problem, a policy, learned offline, specifies the sequence of PWA regions that the dynamics must follow, thus reducing the complexity of the remaining optimization problem that solves over only the continuous states and control inputs. We provide a condition, verifiable during learning, that guarantees feasibility of the learned policy's output, such that an optimal continuous control input can always be found online. Furthermore, a method for iteratively generating training data offline allows the feasible policy to be learned efficiently, reducing the offline computational burden. A numerical experiment demonstrates the effectiveness of the method compared to both online and explicit MPC.

Paper number 83:
Title: 4DRGS: 4D Radiative Gaussian Splatting for Efficient 3D Vessel Reconstruction from Sparse-View Dynamic DSA Images
Authors: Zhentao Liu, Ruyi Zha, Huangxuan Zhao, Hongdong Li, Zhiming Cui
Abstract: Reconstructing 3D vessel structures from sparse-view dynamic digital subtraction angiography (DSA) images enables accurate medical assessment while reducing radiation exposure. Existing methods often produce suboptimal results or require excessive computation time. In this work, we propose 4D radiative Gaussian splatting (4DRGS) to achieve high-quality reconstruction efficiently. In detail, we represent the vessels with 4D radiative Gaussian kernels. Each kernel has time-invariant geometry parameters, including position, rotation, and scale, to model static vessel structures. The time-dependent central attenuation of each kernel is predicted from a compact neural network to capture the temporal varying response of contrast agent flow. We splat these Gaussian kernels to synthesize DSA images via X-ray rasterization and optimize the model with real captured ones. The final 3D vessel volume is voxelized from the well-trained kernels. Moreover, we introduce accumulated attenuation pruning and bounded scaling activation to improve reconstruction quality. Extensive experiments on real-world patient data demonstrate that 4DRGS achieves impressive results in 5 minutes training, which is 32x faster than the state-of-the-art method. This underscores the potential of 4DRGS for real-world clinics.

Paper number 84:
Title: Betting vs. Trading: Learning a Linear Decision Policy for Selling Wind Power and Hydrogen
Authors: Yannick Heiser, Farzaneh Pourahmadi, Jalal Kazempour
Abstract: We develop a bidding strategy for a hybrid power plant combining co-located wind turbines and an electrolyzer, constructing a price-quantity bidding curve for the day-ahead electricity market while optimally scheduling hydrogen production. Without risk management, single imbalance pricing leads to an all-or-nothing trading strategy, which we term 'betting'. To address this, we propose a data-driven, pragmatic approach that leverages contextual information to train linear decision policies for both power bidding and hydrogen scheduling. By introducing explicit risk constraints to limit imbalances, we move from the all-or-nothing approach to a 'trading" strategy', where the plant diversifies its power trading decisions. We evaluate the model under three scenarios: when the plant is either conditionally allowed, always allowed, or not allowed to buy power from the grid, which impacts the green certification of the hydrogen produced. Comparing our data-driven strategy with an oracle model that has perfect foresight, we show that the risk-constrained, data-driven approach delivers satisfactory performance.

Paper number 85:
Title: Improved Encoding for Overfitted Video Codecs
Authors: Thomas Leguay, Théo Ladune, Pierrick Philippe, Olivier Deforges
Abstract: Overfitted neural video codecs offer a decoding complexity orders of magnitude smaller than their autoencoder counterparts. Yet, this low complexity comes at the cost of limited compression efficiency, in part due to their difficulty capturing accurate motion information. This paper proposes to guide motion information learning with an optical flow estimator. A joint rate-distortion optimization is also introduced to improve rate distribution across the different frames. These contributions maintain a low decoding complexity of 1300 multiplications per pixel while offering compression performance close to the conventional codec HEVC and outperforming other overfitted codecs. This work is made open-source at this https URL

Paper number 86:
Title: VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention
Authors: Adnan Iltaf, Rayan Merghani Ahmed, Zhenxi Zhang, Bin Li, Shoujun Zhou
Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, especially when dealing with complex anatomical structures such as vessels. However, accurately segmenting vessels remains challenging due to their small size, intricate edge structures, and susceptibility to artifacts and imaging noise. In this work, we propose VesselSAM, an enhanced version of the Segment Anything Model (SAM), specifically tailored for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating Atrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine-grained local details and broader global context. Additionally, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and thereby enhancing computational efficiency. We evaluate VesselSAM using two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance, attaining DSC scores of 93.50\%, 93.25\%, 93.02\%, and 93.26\% across multi-center datasets. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at this https URL.

Paper number 87:
Title: Identification and Classification of Human Performance related Challenges during Remote Driving
Authors: Ole Hans, Jürgen Adamy
Abstract: Remote driving of vehicles is gaining in importance in the transportation sector, especially when Automated Driving Systems (ADSs) reach the limits of their system boundaries. This study investigates the challenges faced by human Remote Drivers (RDs) during remote driving, particularly focusing on the identification and classification of human performance-related challenges through a comprehensive analysis of real-world remote driving data Las Vegas. For this purpose, a total of 183 RD performance-related Safety Driver (SD) interventions were analyzed and classified using an introduced severity classification. As it is essential to prevent the need for SD interventions, this study identified and analyzed harsh driving events to detect an increased likelihood of interventions by the SD. In addition, the results of the subjective RD questionnaire are used to evaluate whether the objective metrics from SD interventions and harsh driving events can also be confirmed by the RDs and whether additional challenges can be uncovered. The analysis reveals learning curves, showing a significant decrease in SD interventions as RD experience increases. Early phases of remote driving experience, especially below 200 km of experience, showed the highest frequency of safety-related events, including braking late for traffic signs and responding impatiently to other traffic participants. Over time, RDs follow defined rules for improving their control, with experience leading to less harsh braking, acceleration, and steering maneuvers. The study contributes to understanding the requirements of RDS, emphasizing the importance of targeted training to address human performance limitations. It further highlights the need for system improvements to address challenges like latency and the limited haptic feedback replaced by visual feedback, which affect the RDs' perception and vehicle control.

Paper number 88:
Title: Iterative Decoder of Channel-polarized Multilevel Coding for Data Center Networks
Authors: Takeshi Kakizaki, Masanori Nakamura, Fukutaro Hamaoka, Shuto Yamamoto, Etsushi Yamazaki
Abstract: Data center networks (DCNs) require a low-cost, low-power optical transceiver to handle increased traffic from generative artificial intelligence, video streaming services, and more. Improving the required signal-to-noise ratio (RSNR) by digital signal processing such as forward error correction (FEC) mitigates the requirements for electrical and optical components. The optical transceivers in DCNs exploit a low-complexity soft-decision (SD) FEC, consisting of short block-length linear error-correcting codes and a low-complexity SD decoder (SDD), such as a Chase decoder and ordered statistical decoding. The low complexity SDD efficiently approaches a maximum likelihood decoding (MLD). However, the decoding performance of MLD is limited by its finite block length. In this paper, we describe the detail of our proposed channel-polarized multilevel coding with iterative decoding (CP-MLC-ID), which improves the decoding performance. The 19.5$\%$-OH CP-MLC-ID 128-bit extended Bose-Chaudhuri-Hocquenghem (eBCH) and KP4 codes outperform the concatenated eBCH and KP4 codes with a net coding gain of 0.25 and 0.40 dB for the same and double the number of SDDs, respectively. We also investigate the dependency of the decoding performance on the size of a bit interleaver. The performance degradation of CP-MLC-ID using an 8-bit interleaver is about 0.1 dB compared to using the large-bit interleaver. Our results indicate that even a weak connection by exclusive-OR between codewords improves the decoding performance, compared to simple concatenated codes in the DCNs.

Paper number 89:
Title: On the Reachability of 3-Dimensional Paths with a Prescribed Curvature Bound
Authors: Juho Bae, Ji Hoon Bai, Byung-Yoon Lee, Jun-Yong Lee, Chang-Hun Lee
Abstract: This paper presents the reachability analysis of curves in $\mathbb{R}^3$ with a prescribed curvature bound. Based on Pontryagin Maximum Principle, we leverage the existing knowledge on the structure of solutions to minimum-time problems, or Markov-Dubins problem, to reachability considerations. Based on this development, two types of reachability are discussed. First, we prove that any boundary point of the reachability set, with the directional component taken into account as well as geometric coordinates, can be reached via curves of H, CSC, CCC, or their respective subsegments, where H denotes a helicoidal arc, C a circular arc with maximum curvature, and S a straight segment. Second, we show that the reachability set when directional component is not considered\textemdash{}the position reachability set\textemdash{}is simply a solid of revolution of its two-dimensional counterpart, the Dubins car. These findings extend the developments presented in literature on Dubins car into spatial curves in $\mathbb{R}^3$.

Paper number 90:
Title: CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation
Authors: Weiheng Yao, Zhihan Lyu, Mufti Mahmud, Ning Zhong, Baiying Lei, Shuqiang Wang
Abstract: Multi-modal neuroimaging analysis is crucial for a comprehensive understanding of brain function and pathology, as it allows for the integration of different imaging techniques, thus overcoming the limitations of individual modalities. However, the high costs and limited availability of certain modalities pose significant challenges. To address these issues, this paper proposes the Condition-Aligned Temporal Diffusion (CATD) framework for end-to-end cross-modal synthesis of neuroimaging, enabling the generation of functional magnetic resonance imaging (fMRI)-detected Blood Oxygen Level Dependent (BOLD) signals from more accessible Electroencephalography (EEG) signals. By constructing Conditionally Aligned Block (CAB), heterogeneous neuroimages are aligned into a latent space, achieving a unified representation that provides the foundation for cross-modal transformation in neuroimaging. The combination with the constructed Dynamic Time-Frequency Segmentation (DTFS) module also enables the use of EEG signals to improve the temporal resolution of BOLD signals, thus augmenting the capture of the dynamic details of the brain. Experimental validation demonstrates that the framework improves the accuracy of brain activity state prediction by 9.13% (reaching 69.8%), enhances the diagnostic accuracy of brain disorders by 4.10% (reaching 99.55%), effectively identifies abnormal brain regions, enhancing the temporal resolution of BOLD signals. The proposed framework establishes a new paradigm for cross-modal synthesis of neuroimaging by unifying heterogeneous neuroimaging data into a latent representation space, showing promise in medical applications such as improving Parkinson's disease prediction and identifying abnormal brain regions.

Paper number 91:
Title: Fidelity-Imposed Displacement Editing for the Learn2Reg 2024 SHG-BF Challenge
Authors: Jiacheng Wang, Xiang Chen, Renjiu Hu, Rongguang Wang, Min Liu, Yaonan Wang, Jiazheng Wang, Hao Li, Hang Zhang
Abstract: Co-examination of second-harmonic generation (SHG) and bright-field (BF) microscopy enables the differentiation of tissue components and collagen fibers, aiding the analysis of human breast and pancreatic cancer tissues. However, large discrepancies between SHG and BF images pose challenges for current learning-based registration models in aligning SHG to BF. In this paper, we propose a novel multi-modal registration framework that employs fidelity-imposed displacement editing to address these challenges. The framework integrates batch-wise contrastive learning, feature-based pre-alignment, and instance-level optimization. Experimental results from the Learn2Reg COMULISglobe SHG-BF Challenge validate the effectiveness of our method, securing the 1st place on the online leaderboard.

Paper number 92:
Title: MozzaVID: Mozzarella Volumetric Image Dataset
Authors: Pawel Tomasz Pieta, Peter Winkel Rasmussen, Anders Bjorholm Dahl, Jeppe Revall Frisvad, Siavash Arjomand Bigdeli, Carsten Gundlach, Anders Nymark Christensen
Abstract: Influenced by the complexity of volumetric imaging, there is a shortage of established datasets useful for benchmarking volumetric deep-learning models. As a consequence, new and existing models are not easily comparable, limiting the development of architectures optimized specifically for volumetric data. To counteract this trend, we introduce MozzaVID - a large, clean, and versatile volumetric classification dataset. Our dataset contains X-ray computed tomography (CT) images of mozzarella microstructure and enables the classification of 25 cheese types and 149 cheese samples. We provide data in three different resolutions, resulting in three dataset instances containing from 591 to 37,824 images. While being general-purpose, the dataset also facilitates investigating mozzarella structure properties. The structure of food directly affects its functional properties and thus its consumption experience. Understanding food structure helps tune the production and mimicking it enables sustainable alternatives to animal-derived food products. The complex and disordered nature of food structures brings a unique challenge, where a choice of appropriate imaging method, scale, and sample size is not trivial. With this dataset we aim to address these complexities, contributing to more robust structural analysis models. The dataset can be downloaded from: this https URL.

Paper number 93:
Title: A Survey of Secure Semantic Communications
Authors: Rui Meng, Song Gao, Dayu Fan, Haixiao Gao, Yining Wang, Xiaodong Xu, Bizhu Wang, Suyu Lv, Zhidi Zhang, Mengying Sun, Shujun Han, Chen Dong, Xiaofeng Tao, Ping Zhang
Abstract: Semantic communication (SemCom) is regarded as a promising and revolutionary technology in 6G, aiming to transcend the constraints of ``Shannon's trap" by filtering out redundant information and extracting the core of effective data. Compared to traditional communication paradigms, SemCom offers several notable advantages, such as reducing the burden on data transmission, enhancing network management efficiency, and optimizing resource allocation. Numerous researchers have extensively explored SemCom from various perspectives, including network architecture, theoretical analysis, potential technologies, and future applications. However, as SemCom continues to evolve, a multitude of security and privacy concerns have arisen, posing threats to the confidentiality, integrity, and availability of SemCom systems. This paper presents a comprehensive survey of the technologies that can be utilized to secure SemCom. Firstly, we elaborate on the entire life cycle of SemCom, which includes the model training, model transfer, and semantic information transmission phases. Then, we identify the security and privacy issues that emerge during these three stages. Furthermore, we summarize the techniques available to mitigate these security and privacy threats, including data cleaning, robust learning, defensive strategies against backdoor attacks, adversarial training, differential privacy, cryptography, blockchain technology, model compression, and physical-layer security. Lastly, this paper outlines future research directions to guide researchers in related fields.

Paper number 94:
Title: Quantification of Tenseness in English and Japanese Tense-Lax Vowels: A Lagrangian Model with Indicator θ1 and Force of Tenseness Ftense(t)
Authors: Tatsuya Ishizaki
Abstract: The concept of vowel tenseness has traditionally been examined through the binary distinction of tense and lax vowels. However, no universally accepted quantitative definition of tenseness has been established in any language. Previous studies, including those by Jakobson, Fant, and Halle (1951) and Chomsky and Halle (1968), have explored the relationship between vowel tenseness and the vocal tract. Building on these foundations, Ishizaki (2019, 2022) proposed an indirect quantification of vowel tenseness using formant angles {\theta}1 and {\theta}F1 and their first and second derivatives, dZ1(t)/dt = lim tan {\theta}1(t) and d2Z1(t)/dt2 = d/dt lim tan {\theta}1(t). This study extends this approach by investigating the potential role of a force-related parameter in determining vowel quality. Specifically, we introduce a simplified model based on the Lagrangian equation to describe the dynamic interaction of the tongue and jaw within the oral cavity during the articulation of close vowels. This model provides a theoretical framework for estimating the forces involved in vowel production across different languages, offering new insights into the physical mechanisms underlying vowel articulation. The findings suggest that this force-based perspective warrants further exploration as a key factor in phonetic and phonological studies.

Paper number 95:
Title: Polytope Volume Monitoring Problem: Formulation and Solution via Parametric Linear Program Based Control Barrier Function
Authors: Shizhen Wu, Jinyang Dong, Xu Fang, Ning Sun, Yongchun Fang
Abstract: Motivated by the latest research on feasible space monitoring of multiple control barrier functions (CBFs) as well as polytopic collision avoidance, this paper studies the Polytope Volume Monitoring (PVM) problem, whose goal is to design a control law for inputs of nonlinear systems to prevent the volume of some state-dependent polytope from decreasing to zero. Recent studies have explored the idea of applying Chebyshev ball method in optimization theory to solve the case study of PVM; however, the underlying difficulties caused by nonsmoothness have not been addressed. This paper continues the study on this topic, where our main contribution is to establish the relationship between nonsmooth CBF and parametric optimization theory through directional derivatives for the first time, so as to solve PVM problems more conveniently. In detail, inspired by Chebyshev ball approach, a parametric linear program (PLP) based nonsmooth barrier function candidate is established for PVM, and then, sufficient conditions for it to be a nonsmooth CBF are proposed, based on which a quadratic program (QP) based safety filter with guaranteed feasibility is proposed to address PVM problems. Finally, a numerical simulation example is given to show the efficiency of the proposed safety filter.

Paper number 96:
Title: Unleashing Vecset Diffusion Model for Fast Shape Generation
Authors: Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qingxiang Lin, Jingwei Huang, Yuhong Liu, Jie Jiang, Chunchao Guo, Xiangyu Yue
Abstract: 3D shape generation has greatly flourished through the development of so-called "native" 3D diffusion, particularly through the Vecset Diffusion Model (VDM). While recent advancements have shown promising results in generating high-resolution 3D shapes, VDM still struggles with high-speed generation. Challenges exist because of difficulties not only in accelerating diffusion sampling but also VAE decoding in VDM, areas under-explored in previous works. To address these challenges, we present FlashVDM, a systematic framework for accelerating both VAE and DiT in VDM. For DiT, FlashVDM enables flexible diffusion sampling with as few as 5 inference steps and comparable quality, which is made possible by stabilizing consistency distillation with our newly introduced Progressive Flow Distillation. For VAE, we introduce a lightning vecset decoder equipped with Adaptive KV Selection, Hierarchical Volume Decoding, and Efficient Network Design. By exploiting the locality of the vecset and the sparsity of shape surface in the volume, our decoder drastically lowers FLOPs, minimizing the overall decoding overhead. We apply FlashVDM to Hunyuan3D-2 to obtain Hunyuan3D-2 Turbo. Through systematic evaluation, we show that our model significantly outperforms existing fast 3D generation methods, achieving comparable performance to the state-of-the-art while reducing inference time by over 45x for reconstruction and 32x for generation. Code and models are available at this https URL.
    