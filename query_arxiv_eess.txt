
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: The Iris File Extension
Authors: Ryan Erik Landvater, Michael David Olp, Mustafa Yousif, Ulysses Balis
Abstract: A modern digital pathology vendor-agnostic binary slide format specifically targeting the unmet need of efficient real-time transfer and display has not yet been established. Growing adoption of digital pathology only intensifies the need for an intermediary digital slide format with an emphasis on performance for use between slide servers and image management software or for inter-institutional transmission of cases. Although the DICOM standard is a well-established format widely used for long-term storage of both images and critically associated metadata, its inherent limitations on maximum image dimensions can impact retrieval speed, particularly when accessing whole slide images using a pyramidal structure of slide viewer applications. Here, we introduce the Iris file extension, a binary file container specification explicitly designed for whole slide image systems that can abstract the file structure outline into memory for immediate tile access. The Iris file extension adds modern compression support, a dynamic structure with optional file features, computationally trivial deep file validation and corruption recovery capabilities, and slide annotation support. In addition to the file specification document, we provide source code to allow for (de)serialization and validation of a binary stream against the standard and corresponding binary builds with C++, Python, and JavaScript language bindings. We further provide full encoder and decoder implementation source code, as well as binary builds (as part of the separate Iris Codec Community module) with language bindings for C++ and Python to allow for easy integration with existing WSI solutions. We provide the Iris File Extension specification openly to the community in the form of a Creative Commons Attribution-No Derivative 4.0 international license.

Paper number 2:
Title: Deep Semantic Segmentation for Multi-Source Localization Using Angle of Arrival Measurements
Authors: Mustafa Atahan Nuhoglu, Hakan Ali Cirpan
Abstract: This paper presents a solution for multi source localization using only angle of arrival measurements. The receiver platform is in motion, while the sources are assumed to be stationary. Although numerous methods exist for single source localization, many relying on pseudo-linear formulations or non convex optimization techniques, there remains a significant gap in research addressing multi source localization in dynamic environments. To bridge this gap, we propose a deep learning-based framework that leverages semantic segmentation models for multi source localization. Specifically, we employ UNet and UNetPP as backbone models, processing input images that encode the platform's positions along with the corresponding direction finding lines at each position. By analyzing the intersections of these lines, the models effectively identify and localize multiple sources. Through simulations, we evaluate both single- and multi-source localization scenarios. Our results demonstrate that while the proposed approach performs comparably to traditional methods in single source localization, it achieves accurate source localization even in challenging conditions with high noise levels and an increased number of sources.

Paper number 3:
Title: Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective
Authors: Minye Shao, Zeyu Wang, Haoran Duan, Yawen Huang, Bing Zhai, Shizheng Wang, Yang Long, Yefeng Zheng
Abstract: Precise segmentation of brain tumors, particularly contrast-enhancing regions visible in post-contrast MRI (areas highlighted by contrast agent injection), is crucial for accurate clinical diagnosis and treatment planning but remains challenging. However, current methods exhibit notable performance degradation in segmenting these enhancing brain tumor areas, largely due to insufficient consideration of MRI-specific tumor features such as complex textures and directional variations. To address this, we propose the Harmonized Frequency Fusion Network (HFF-Net), which rethinks brain tumor segmentation from a frequency-domain perspective. To comprehensively characterize tumor regions, we develop a Frequency Domain Decomposition (FDD) module that separates MRI images into low-frequency components, capturing smooth tumor contours and high-frequency components, highlighting detailed textures and directional edges. To further enhance sensitivity to tumor boundaries, we introduce an Adaptive Laplacian Convolution (ALC) module that adaptively emphasizes critical high-frequency details using dynamically updated convolution kernels. To effectively fuse tumor features across multiple scales, we design a Frequency Domain Cross-Attention (FDCA) integrating semantic, positional, and slice-specific information. We further validate and interpret frequency-domain improvements through visualization, theoretical reasoning, and experimental analyses. Extensive experiments on four public datasets demonstrate that HFF-Net achieves an average relative improvement of 4.48\% (ranging from 2.39\% to 7.72\%) in the mean Dice scores across the three major subregions, and an average relative improvement of 7.33% (ranging from 5.96% to 8.64%) in the segmentation of contrast-enhancing tumor regions, while maintaining favorable computational efficiency and clinical applicability. Code: this https URL.

Paper number 4:
Title: Quantifying Data Requirements for EEG Independent Component Analysis Using AMICA
Authors: Gwenevere Frank, Seyed Yahya Shirazi, Jason Palmer, Gert Cauwenberghs, Scott Makeig, Arnaud Delorme
Abstract: Independent Component Analysis (ICA) is an important step in EEG processing for a wide-ranging set of applications. However, ICA requires well-designed studies and data collection practices to yield optimal results. Past studies have focused on quantitative evaluation of the differences in quality produced by different ICA algorithms as well as different configurations of parameters for AMICA, a multimodal ICA algorithm that is considered the benchmark against which other algorithms are measured. Here, the effect of the data quantity versus the number of channels on decomposition quality is explored. AMICA decompositions were run on a 71 channel dataset with 13 subjects while randomly subsampling data to correspond to specific ratios of the number of frames in a dataset to the channel count. Decomposition quality was evaluated for the varying quantities of data using measures of mutual information reduction (MIR) and the near dipolarity of components. We also note that an asymptotic trend can be seen in the increase of MIR and a general increasing trend in near dipolarity with increasing data, but no definitive plateau in these metrics was observed, suggesting that the benefits of collecting additional EEG data may extend beyond common heuristic thresholds and continue to enhance decomposition quality.

Paper number 5:
Title: Formalizing Neuromorphic Control Systems: A General Proposal and A Rhythmic Case Study
Authors: Taisia Medvedeva, Alessio Franci, Fernando Castaños
Abstract: Neuromorphic control is receiving growing attention due to the multifaceted advantages it brings over more classical control approaches, including: sparse and on-demand sensing, information transmission, and actuation; energy-efficient designs and realizations in neuromorphic hardware; event-based signal processing and control signal computation. However, a general control-theoretical formalization of what "neuromorphic control systems" are and how we can rigorously analyze, design, and control them is still largely missing. In this note, we suggest a possible path toward formalizing neuromorphic control systems. We apply the proposed framework to a rhythmic control case study and rigorously show how it has the potential to make neuromorphic control systems analysis and design amenable to mature control theoretical approaches like describing function analysis and harmonic balance, fast-slow analysis, discrete and hybrid systems, and robust optimization.

Paper number 6:
Title: Model Predictive Control-Based Optimal Energy Management of Autonomous Electric Vehicles Under Cold Temperatures
Authors: Shanthan Kumar Padisala, Satadru Dey
Abstract: In autonomous electric vehicles (AEVs), battery energy must be judiciously allocated to satisfy primary propulsion demands and secondary auxiliary demands, particularly the Heating, Ventilation, and Air Conditioning (HVAC) system. This becomes especially critical when the battery is in a low state of charge under cold ambient conditions, and cabin heating and battery preconditioning (prior to actual charging) can consume a significant percentage of available energy, directly impacting the driving range. In such cases, one usually prioritizes propulsion or applies heuristic rules for thermal management, often resulting in suboptimal energy utilization. There is a pressing need for a principled approach that can dynamically allocate battery power in a way that balances thermal comfort, battery health and preconditioning, along with range preservation. This paper attempts to address this issue using real-time Model Predictive Control to optimize the power consumption between the propulsion, HVAC, and battery temperature preparation so that it can be charged immediately once the destination is reached.

Paper number 7:
Title: Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation
Authors: Emerson P. Grabke, Masoom A. Haider, Babak Taati
Abstract: Latent diffusion models (LDM) could alleviate data scarcity challenges affecting machine learning development for medical imaging. However, medical LDM training typically relies on performance- or scientific accessibility-limiting strategies including a reliance on short-prompt text encoders, the reuse of non-medical LDMs, or a requirement for fine-tuning with large data volumes. We propose a Class-Conditioned Efficient Large Language model Adapter (CCELLA) to address these limitations. CCELLA is a novel dual-head conditioning approach that simultaneously conditions the LDM U-Net with non-medical large language model-encoded text features through cross-attention and with pathology classification through the timestep embedding. We also propose a joint loss function and a data-efficient LDM training framework. In combination, these strategies enable pathology-conditioned LDM training for high-quality medical image synthesis given limited data volume and human data annotation, improving LDM performance and scientific accessibility. Our method achieves a 3D FID score of 0.025 on a size-limited prostate MRI dataset, significantly outperforming a recent foundation model with FID 0.071. When training a classifier for prostate cancer prediction, adding synthetic images generated by our method to the training dataset improves classifier accuracy from 69% to 74%. Training a classifier solely on our method's synthetic images achieved comparable performance to training on real images alone.

Paper number 8:
Title: Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization
Authors: Ana Lawry Aguila, Peirong Liu, Oula Puonti, Juan Eugenio Iglesias
Abstract: Supervised machine learning has enabled accurate pathology detection in brain MRI, but requires training data from diseased subjects that may not be readily available in some scenarios, for example, in the case of rare diseases. Reconstruction-based unsupervised anomaly detection, in particular using diffusion models, has gained popularity in the medical field as it allows for training on healthy images alone, eliminating the need for large disease-specific cohorts. These methods assume that a model trained on normal data cannot accurately represent or reconstruct anomalies. However, this assumption often fails with models failing to reconstruct healthy tissue or accurately reconstruct abnormal regions i.e., failing to remove anomalies. In this work, we introduce a novel conditional diffusion model framework for anomaly detection and healthy image reconstruction in brain MRI. Our weakly supervised approach integrates synthetically generated pseudo-pathology images into the modeling process to better guide the reconstruction of healthy images. To generate these pseudo-pathologies, we apply fluid-driven anomaly randomization to augment real pathology segmentation maps from an auxiliary dataset, ensuring that the synthetic anomalies are both realistic and anatomically coherent. We evaluate our model's ability to detect pathology, using both synthetic anomaly datasets and real pathology from the ATLAS dataset. In our extensive experiments, our model: (i) consistently outperforms variational autoencoders, and conditional and unconditional latent diffusion; and (ii) surpasses on most datasets, the performance of supervised inpainting methods with access to paired diseased/healthy images.

Paper number 9:
Title: Intelligent Travel Activity Monitoring: Generalized Distributed Acoustic Sensing Approaches
Authors: Ruikang Zhong, Chia-Yen Chiang, Mona Jaber, Rupert De Wilde, Peter Hayward
Abstract: Obtaining data on active travel activities such as walking, jogging, and cycling is important for refining sustainable transportation systems (STS). Effectively monitoring these activities not only requires sensing solutions to have a joint feature of being accurate, economical, and privacy-preserving, but also enough generalizability to adapt to different climate environments and deployment conditions. In order to provide a generalized sensing solution, a deep learning (DL)-enhanced distributed acoustic sensing (DAS) system for monitoring active travel activities is proposed. By leveraging the ambient vibrations captured by DAS, this scheme infers motion patterns without relying on image-based or wearable devices, thereby addressing privacy concerns. We conduct real-world experiments in two geographically distinct locations and collect comprehensive datasets to evaluate the performance of the proposed system. To address the generalization challenges posed by heterogeneous deployment environments, we propose two solutions according to network availability: 1) an Internet-of-Things (IoT) scheme based on federated learning (FL) is proposed, and it enables geographically different DAS nodes to be trained collaboratively to improve generalizability; 2) an off-line initialization approach enabled by meta-learning is proposed to develop high-generality initialization for DL models and to enable rapid model fine-tuning with limited data samples, facilitating generalization at newly established or isolated DAS nodes. Experimental results of the walking and cycling classification problem demonstrate the performance and generalizability of the proposed DL-enhanced DAS system, paving the way for practical, large-scale DAS monitoring of active travel.

Paper number 10:
Title: Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing
Authors: Rongfei Li, Francis Assadian
Abstract: Visual servoing technology has been well developed and applied in many automated manufacturing tasks, especially in tools' pose alignment. To access a full global view of tools, most applications adopt eye-to-hand configuration or eye-to-hand/eye-in-hand cooperation configuration in an automated manufacturing environment. Most research papers mainly put efforts into developing control and observation architectures in various scenarios, but few of them have discussed the importance of the camera's location in eye-to-hand configuration. In a manufacturing environment, the quality of camera estimations may vary significantly from one observation location to another, as the combined effects of environmental conditions result in different noise levels of a single image shot at different locations. In this paper, we propose an algorithm for the camera's moving policy so that it explores the camera workspace and searches for the optimal location where the images' noise level is minimized. Also, this algorithm ensures the camera ends up at a suboptimal (if the optimal one is unreachable) location among the locations already searched, with limited energy available for moving the camera. Unlike a simple brute force approach, the algorithm enables the camera to explore space more efficiently by adapting the search policy from learning the environment. With the aid of an image averaging technique, this algorithm, in use of a solo camera, achieves the observation accuracy in eye-to-hand configurations to a desirable extent without filtering out high-frequency information in the original image. An automated manufacturing application has been simulated and the results show the success of this algorithm's improvement of observation precision with limited energy.

Paper number 11:
Title: Ground Reaction Force Estimation via Time-aware Knowledge Distillation
Authors: Eun Som Jeon, Sinjini Mitra, Jisoo Lee, Omik M. Save, Ankita Shukla, Hyunglae Lee, Pavan Turaga
Abstract: Human gait analysis with wearable sensors has been widely used in various applications, such as daily life healthcare, rehabilitation, physical therapy, and clinical diagnostics and monitoring. In particular, ground reaction force (GRF) provides critical information about how the body interacts with the ground during locomotion. Although instrumented treadmills have been widely used as the gold standard for measuring GRF during walking, their lack of portability and high cost make them impractical for many applications. As an alternative, low-cost, portable, wearable insole sensors have been utilized to measure GRF; however, these sensors are susceptible to noise and disturbance and are less accurate than treadmill measurements. To address these challenges, we propose a Time-aware Knowledge Distillation framework for GRF estimation from insole sensor data. This framework leverages similarity and temporal features within a mini-batch during the knowledge distillation process, effectively capturing the complementary relationships between features and the sequential properties of the target and input data. The performance of the lightweight models distilled through this framework was evaluated by comparing GRF estimations from insole sensor data against measurements from an instrumented treadmill. Empirical results demonstrated that Time-aware Knowledge Distillation outperforms current baselines in GRF estimation from wearable sensor data.

Paper number 12:
Title: RT-VC: Real-Time Zero-Shot Voice Conversion with Speech Articulatory Coding
Authors: Yisi Liu, Chenyang Wang, Hanjo Kim, Raniya Khan, Gopala Anumanchipalli
Abstract: Voice conversion has emerged as a pivotal technology in numerous applications ranging from assistive communication to entertainment. In this paper, we present RT-VC, a zero-shot real-time voice conversion system that delivers ultra-low latency and high-quality performance. Our approach leverages an articulatory feature space to naturally disentangle content and speaker characteristics, facilitating more robust and interpretable voice transformations. Additionally, the integration of differentiable digital signal processing (DDSP) enables efficient vocoding directly from articulatory features, significantly reducing conversion latency. Experimental evaluations demonstrate that, while maintaining synthesis quality comparable to the current state-of-the-art (SOTA) method, RT-VC achieves a CPU latency of 61.4 ms, representing a 13.3\% reduction in latency.

Paper number 13:
Title: Learning-Based Stable Optimal Control for Infinite-Time Nonlinear Regulation Problems
Authors: Han Wang, Di Wu, Lin Cheng, Shengping Gong, Xu Huang
Abstract: Infinite-time nonlinear optimal regulation control is widely utilized in aerospace engineering as a systematic method for synthesizing stable controllers. However, conventional methods often rely on linearization hypothesis, while recent learning-based approaches rarely consider stability guarantees. This paper proposes a learning-based framework to learn a stable optimal controller for nonlinear optimal regulation problems. First, leveraging the equivalence between Pontryagin Maximum Principle (PMP) and Hamilton-Jacobi-Bellman (HJB) equation, we improve the backward generation of optimal examples (BGOE) method for infinite-time optimal regulation problems. A state-transition-matrix-guided data generation method is then proposed to efficiently generate a complete dataset that covers the desired state space. Finally, we incorporate the Lyapunov stability condition into the learning framework, ensuring the stability of the learned optimal policy by jointly learning the optimal value function and control policy. Simulations on three nonlinear optimal regulation problems show that the learned optimal policy achieves near-optimal regulation control and the code is provided at this https URL

Paper number 14:
Title: Synthesizing Min-Max Control Barrier Functions For Switched Affine Systems
Authors: Sara Kamali, Guillaume O. Berger, Sriram Sankaranarayanan
Abstract: We study the problem of synthesizing non-smooth control barrier functions (CBFs) for continuous-time switched affine systems. Switched affine systems are defined by a set of affine dynamical modes, wherein the control consists of a state-based switching signal that determines the current operating mode. The control barrier functions seek to maintain the system state inside a control invariant set that excludes a given set of unsafe states. We consider CBFs that take the form of pointwise minima and maxima over a finite set of affine functions. Our approach uses ideas from nonsmooth analysis to formulate conditions for min- and max- affine control barrier functions. We show how a feedback switching law can be extracted from a given CBF. Next, we show how to automate the process of synthesizing CBFs given a system description through a tree-search algorithm inspired by branch-and-cut methods from combinatorial optimization. Finally, we demonstrate our approach on a series of interesting examples of switched affine systems.

Paper number 15:
Title: DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction
Authors: Yuliang Zhu, Jing Cheng, Qi Xie, Zhuo-Xu Cui, Qingyong Zhu, Yuanyuan Liu, Xin Liu, Jianfeng Ren, Chengbo Wang, Dong Liang
Abstract: Dynamic Magnetic Resonance Imaging (MRI) exhibits transformation symmetries, including spatial rotation symmetry within individual frames and temporal symmetry along the time dimension. Explicit incorporation of these symmetry priors in the reconstruction model can significantly improve image quality, especially under aggressive undersampling scenarios. Recently, Equivariant convolutional neural network (ECNN) has shown great promise in exploiting spatial symmetry priors. However, existing ECNNs critically fail to model temporal symmetry, arguably the most universal and informative structural prior in dynamic MRI reconstruction. To tackle this issue, we propose a novel Deep Unrolling Network with Spatiotemporal Rotation Equivariance (DUN-SRE) for Dynamic MRI Reconstruction. The DUN-SRE establishes spatiotemporal equivariance through a (2+1)D equivariant convolutional architecture. In particular, it integrates both the data consistency and proximal mapping module into a unified deep unrolling framework. This architecture ensures rigorous propagation of spatiotemporal rotation symmetry constraints throughout the reconstruction process, enabling more physically accurate modeling of cardiac motion dynamics in cine MRI. In addition, a high-fidelity group filter parameterization mechanism is developed to maintain representation precision while enforcing symmetry constraints. Comprehensive experiments on Cardiac CINE MRI datasets demonstrate that DUN-SRE achieves state-of-the-art performance, particularly in preserving rotation-symmetric structures, offering strong generalization capability to a broad range of dynamic MRI reconstruction tasks.

Paper number 16:
Title: AC/DC: LLM-based Audio Comprehension via Dialogue Continuation
Authors: Yusuke Fujita, Tomoya Mizumoto, Atsushi Kojima, Lianbo Liu, Yui Sudo
Abstract: We propose an instruction-following audio comprehension model that leverages the dialogue continuation ability of large language models (LLMs). Instead of directly generating target captions in training data, the proposed method trains a model to produce responses as if the input caption triggered a dialogue. This dialogue continuation training mitigates the caption variation problem. Learning to continue a dialogue effectively captures the caption's meaning beyond its surface-level words. As a result, our model enables zero-shot instruction-following capability without multitask instruction tuning, even trained solely on audio captioning datasets. Experiments on AudioCaps, WavCaps, and Clotho datasets with AudioBench audio-scene question-answering tests demonstrate our model's ability to follow various unseen instructions.

Paper number 17:
Title: SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation
Authors: Cheng Wang, Siqi Chen, Donghua Mi, Yang Chen, Yudong Zhang, Yinsheng Li
Abstract: Recent advances in medical imaging have established deep learning-based segmentation as the predominant approach, though it typically requires large amounts of manually annotated data. However, obtaining annotations for intracranial hemorrhage (ICH) remains particularly challenging due to the tedious and costly labeling process. Semi-supervised learning (SSL) has emerged as a promising solution to address the scarcity of labeled data, especially in volumetric medical image segmentation. Unlike conventional SSL methods that primarily focus on high-confidence pseudo-labels or consistency regularization, we propose SWDL-Net, a novel SSL framework that exploits the complementary advantages of Laplacian pyramid and deep convolutional upsampling. The Laplacian pyramid excels at edge sharpening, while deep convolutions enhance detail precision through flexible feature mapping. Our framework achieves superior segmentation of lesion details and boundaries through a difference learning mechanism that effectively integrates these complementary approaches. Extensive experiments on a 271-case ICH dataset and public benchmarks demonstrate that SWDL-Net outperforms current state-of-the-art methods in scenarios with only 2% labeled data. Additional evaluations on the publicly available Brain Hemorrhage Segmentation Dataset (BHSD) with 5% labeled data further confirm the superiority of our approach. Code and data have been released at this https URL.

Paper number 18:
Title: Joint ASR and Speaker Role Tagging with Serialized Output Training
Authors: Anfeng Xu, Tiantian Feng, Shrikanth Narayanan
Abstract: Automatic Speech Recognition systems have made significant progress with large-scale pre-trained models. However, most current systems focus solely on transcribing the speech without identifying speaker roles, a function that is critical for conversational AI. In this work, we investigate the use of serialized output training (SOT) for joint ASR and speaker role tagging. By augmenting Whisper with role-specific tokens and fine-tuning it with SOT, we enable the model to generate role-aware transcriptions in a single decoding pass. We compare the SOT approach against a self-supervised previous baseline method on two real-world conversational datasets. Our findings show that this approach achieves more than 10% reduction in multi-talker WER, demonstrating its feasibility as a unified model for speaker-role aware speech transcription.

Paper number 19:
Title: Heterogeneous-IRS-Assisted MIMO Systems: Channel Estimation and Beamforming
Authors: Weibiao Zhao, Qiucen Wu, Yuanqi Tang, Yu Zhu
Abstract: Intelligent reflecting surface (IRS) has gained great attention for its ability to create favorable propagation environments. However, the power consumption of conventional IRSs cannot be ignored due to the large number of reflecting elements and control circuits. To balance performance and power consumption, we previously proposed a heterogeneous-IRS (HE-IRS), a green IRS structure integrating dynamically tunable elements (DTEs) and statically tunable elements (STEs). Compared to conventional IRSs with only DTEs, the unique DTE-STE integrated structure introduces new challenges in both channel estimation and beamforming. In this paper, we investigate the channel estimation and beamforming problems in HE-IRS-assisted multi-user multiple-input multiple-output systems. Unlike the overall cascaded channel estimated in conventional IRSs, we show that the HE-IRS channel to be estimated is decomposed into a DTE-based cascaded channel and an STE-based equivalent channel. Leveraging it along with the inherent sparsity of DTE- and STE-based channels and manifold optimization, we propose an efficient channel estimation scheme. To address the rank mismatch problem in the imperfect channel sparsity information, a robust rank selection rule is developed. For beamforming, we propose an offline algorithm to optimize the STE phase shifts for wide beam coverage, and an online algorithm to optimize the BS precoder and the DTE phase shifts using the estimated HE-IRS channel. Simulation results show that the HE-IRS requires less pilot overhead than conventional IRSs with the same number of elements. With the proposed channel estimation and beamforming schemes, the green HE-IRS achieves competitive sum rate performance with significantly reduced power consumption.

Paper number 20:
Title: Relaxation-Free Min-k-Partition for PCI Assignment in 5G Networks
Authors: Yeqing Qiu, Chengpiao Huang, Ye Xue, Zhipeng Jiang, Qingjiang Shi, Dong Zhang, Zhi-Quan Luo
Abstract: Physical Cell Identity (PCI) is a critical parameter in 5G networks. Efficient and accurate PCI assignment is essential for mitigating mod-3 interference, mod-30 interference, collisions, and confusions among cells, which directly affect network reliability and user experience. In this paper, we propose a novel framework for PCI assignment by decomposing the problem into Min-3-Partition, Min-10-Partition, and a graph coloring problem, leveraging the Chinese Remainder Theorem (CRT). Furthermore, we develop a relaxation-free approach to the general Min-$k$-Partition problem by reformulating it as a quadratic program with a norm-equality constraint and solving it using a penalized mirror descent (PMD) algorithm. The proposed method demonstrates superior computational efficiency and scalability, significantly reducing interference while eliminating collisions and confusions in large-scale 5G networks. Numerical evaluations on real-world datasets show that our approach reduces computational time by up to 20 times compared to state-of-the-art methods, making it highly practical for real-time PCI optimization in large-scale networks. These results highlight the potential of our method to improve network performance and reduce deployment costs in modern 5G systems.

Paper number 21:
Title: Semi-Tensor-Product Based Convolutional Neural Networks
Authors: Daizhan Cheng
Abstract: The semi-tensor product (STP) of vectors is a generalization of conventional inner product of vectors, which allows the factor vectors to of different dimensions. This paper proposes a domain-based convolutional product (CP). Combining domain-based CP with STP of vectors, a new CP is proposed. Since there is no zero or any other padding, it can avoid the junk information caused by padding. Using it, the STP-based convolutional neural network (CNN) is developed. Its application to image and third order signal identifications is considered.

Paper number 22:
Title: Predictive control of wastewater treatment plants as energy-autonomous water resource recovery facilities
Authors: Otacilio B. L. Neto, Michela Mulas, Iiro Harjunkoski, Francesco Corona
Abstract: This work proposes an automatic control solution for the operation of conventional wastewater treatment plants (WWTPs) as energy-autonomous water resource recovery facilities. We first conceptualize a classification of the quality of treated water for three resource recovery applications (environmental, industrial, and agricultural water reuse). We then present an output-feedback model predictive controller (Output MPC) that operates a plant to produce water of specific quality class, while also producing sufficient biogas to ensure nonpositive energy costs. The controller is demonstrated in the long-term operation of a full-scale WWTP subjected to typical influent loads and periodically changing quality targets. Our results provide a proof-of-concept on the energy-autonomous operation of existing wastewater treatment infrastructure with control strategies that are general enough to accommodate a wide range of resource recovery objectives.

Paper number 23:
Title: A Neural Network-aided Low Complexity Chase Decoder for URLLC
Authors: Enrico Testi, Enrico Paolini
Abstract: Ultra-reliable low-latency communications (URLLC) demand decoding algorithms that simultaneously offer high reliability and low complexity under stringent latency constraints. While iterative decoding schemes for LDPC and Polar codes offer a good compromise between performance and complexity, they fall short in approaching the theoretical performance limits in the typical URLLC short block length regime. Conversely, quasi-ML decoding schemes for algebraic codes, like Chase-II decoding, exhibit a smaller gap to optimum decoding but are computationally prohibitive for practical deployment in URLLC systems. To bridge this gap, we propose an enhanced Chase-II decoding algorithm that leverages a neural network (NN) to predict promising perturbation patterns, drastically reducing the number of required decoding trials. The proposed approach combines the reliability of quasi-ML decoding with the efficiency of NN inference, making it well-suited for time-sensitive and resource-constrained applications.

Paper number 24:
Title: Analyzing the performance of a V2X-enhanced braking system in real-world crash situations
Authors: Jan Zimmermann, Jörg Mönnich, Michael Scherl, Ignacio Llatser, Florian Wildschütte, Frank Hofmann
Abstract: By using an automated braking system, such as the Automatic Emergency Brake (AEB), crashes can be avoided in situations where the driver is unaware of an imminent collision. However, conventional AEB systems detect potential collision adversaries with onboard sensor systems, such as radars and cameras, that may fail in non-line-of-sight situations. By leveraging vehicle-to-everything (V2X) communication, information regarding an approaching vehicle can be received by the ego vehicle at an early point in time, even if the opponent vehicle is occluded by a view obstruction. In this work, we consider a 2-stage braking cascade, consisting of a partial brake, triggered based on V2X information, and a sensor-triggered AEB. We evaluate its crash avoidance performance in real-world crash situations extracted from the German In-Depth Accident Study (GIDAS) database using an accident simulation framework. The results are compared against a sensor-triggered AEB system and a purely V2X-triggered partial brake. To further analyze the results, we identify the crash cause for each situation in which the brake function under test could not prevent the crash. The simulation results show a high added benefit of the V2X-enhanced braking systems compared to the exclusive use of visual-based sensor systems for automated collision prevention.

Paper number 25:
Title: Joint System Modeling Approach for Fault Simulation of Start-er/Generator and Gas Generator in All-Electric APU
Authors: Haotian Mao, Yingqing Guo
Abstract: This paper presents a joint system modeling approach for fault simulation of all-electric auxiliary power unit (APU), integrating starter/generator turn-to-turn short circuit (TTSC) faults with gas generator gas-path this http URL address challenges in electromechanical coupling, simulation precision and computational efficiency balance, we propose a multi-rate continuous-discrete hybrid simulation architecture. This architecture treats the starter/generator as a continuous system with variable step size in Simulink, while modeling the gas generator as a discrete system with fixed step size in a dynamic-link library (DLL) environment. For the starter/generator fault modeling, a multi-loop approach is deployed to accurately simulate TTSC faults. For the gas generator, we develop an improved GasTurb-DLL modeling method (IGDM) that enhances uncertainty modeling, state-space representation, and tool chain compatibility. Finally, the proposed methodology above was implemented in a case study based on the APS5000 all-electric APU structure and parameters. Model validation was conducted by comparing simulation results--covering steady-state, transients, healthy, and fault conditions--with reference data from third-party software and literature. The close agreement confirms both the model's accuracy and the effectiveness of our modeling methodology. This work establishes a modeling foundation for investigating the opportunities and challenges in fault detection and isolation (FDI) brought by the all electrification of the APU, including joint fault estimation and diagnosis, coupled electromechanical fault characteristics.

Paper number 26:
Title: Transient performance of MPC for tracking without terminal constraints
Authors: Nadine Ehmann, Matthias Köhler, Frank Allgöwer
Abstract: Model predictive control (MPC) for tracking is a recently introduced approach, which extends standard MPC formulations by incorporating an artificial reference as an additional optimization variable, in order to track external and potentially time-varying references. In this work, we analyze the performance of such an MPC for tracking scheme without a terminal cost and terminal constraints. We derive a transient performance estimate, i.e. a bound on the closed-loop performance over an arbitrary time interval, yielding insights on how to select the scheme's parameters for performance. Furthermore, we show that in the asymptotic case, where the prediction horizon and observed time interval tend to infinity, the closed-loop solution of MPC for tracking recovers the infinite horizon optimal solution.

Paper number 27:
Title: Sum Rate Maximization for Pinching Antennas Assisted RSMA System With Multiple Waveguides
Authors: Peiyu Wang, Hong Wang, Rongfang Song
Abstract: In this letter, a pinching antennas (PAs) assisted rate splitting multiple access (RSMA) system with multiple waveguides is investigated to maximize sum rate. A two-step algorithm is proposed to determine PA activation scheme and optimize the waveguide beamforming. Specifically, a low complexity spatial correlation and distance based method is proposed for PA activation selection. After determining the PA activation status, a semi-definite programming (SDP) based successive convex approximation (SCA) is leveraged to obtain the optimal waveguide beamforming. Simulation results show that the proposed multiple waveguides based PAs assisted RSMA method achieves better performance than various benchmarking schemes.

Paper number 28:
Title: Robust Unsupervised Adaptation of a Speech Recogniser Using Entropy Minimisation and Speaker Codes
Authors: Rogier C. van Dalen, Shucong Zhang, Titouan Parcollet, Sourav Bhattacharya
Abstract: Speech recognisers usually perform optimally only in a specific environment and need to be adapted to work well in another. For adaptation to a new speaker, there is often too little data for fine-tuning to be robust, and that data is usually unlabelled. This paper proposes a combination of approaches to make adaptation to a single minute of data robust. First, instead of estimating the adaptation parameters with cross-entropy on a single error-prone hypothesis or "pseudo-label", this paper proposes a novel loss function, the conditional entropy over complete hypotheses. Using multiple hypotheses makes adaptation more robust to errors in the initial recognition. Second, a "speaker code" characterises a speaker in a vector short enough that it requires little data to estimate. On a far-field noise-augmented version of Common Voice, the proposed scheme yields a 20% relative improvement in word error rate on one minute of adaptation data, increasing on 10 minutes to 29%.

Paper number 29:
Title: Receiving RISs: Enabling Channel Estimation and Autonomous Configuration
Authors: George C. Alexandropoulos, Konstantinos D. Katsanos, Evangelos Vlachos
Abstract: This chapter focuses on a hardware architecture for semi-passive Reconfigurable Intelligent Surfaces (RISs) and investigates its consideration for boosting the performance of Multiple-Input Multiple-Output (MIMO) communication systems. The architecture incorporates a single or multiple radio-frequency chains to receive pilot signals via tunable absorption phase profiles realized by the metasurface front end, as well as a controller encompassing a baseband processing unit to carry out channel estimation, and consequently, the optimization of the RIS reflection coefficients. A novel channel estimation protocol, according to which the RIS receives non-orthogonal training pilot sequences from two multi-antenna terminals via tunable absorption phase profiles, and then, estimates the respective channels via its signal processing unit, is presented. The channel estimates are particularly used by the RIS controller to design the capacity-achieving reflection phase configuration of the metasurface front end. The proposed channel estimation algorithm, which is based on the Alternating Direction Method of Multipliers (ADMM), profits from the RIS random spatial absorption sampling to capture the entire signal space, and exploits the beamspace sparsity and low-rank properties of extremely large MIMO channels, which is particularly relevant for communication systems at the FR3 band and above. Our extensive numerical investigations showcase the superiority of the proposed channel estimation technique over benchmark schemes for various system and RIS hardware configuration parameters, as well as the effectiveness of using channel estimates at the RIS side to dynamically optimize the possibly phase-quantized reflection coefficients of its unit elements.

Paper number 30:
Title: ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation
Authors: Xi Chen, Zhiqiang Shen, Peng Cao, Jinzhu Yang, Osmar R. Zaiane
Abstract: Medical images are usually collected from multiple domains, leading to domain shifts that impair the performance of medical image segmentation models. Domain Generalization (DG) aims to address this issue by training a robust model with strong generalizability. Recently, numerous domain randomization-based DG methods have been proposed. However, these methods suffer from the following limitations: 1) constrained efficiency of domain randomization due to their exclusive dependence on image style perturbation, and 2) neglect of the adverse effects of over-augmented images on model training. To address these issues, we propose a novel domain randomization-based DG method, called content style augmentation (ConStyX), for generalizable medical image segmentation. Specifically, ConStyX 1) augments the content and style of training data, allowing the augmented training data to better cover a wider range of data domains, and 2) leverages well-augmented features while mitigating the negative effects of over-augmented features during model training. Extensive experiments across multiple domains demonstrate that our ConStyX achieves superior generalization performance. The code is available at this https URL.

Paper number 31:
Title: Disentangling Dual-Encoder Masked Autoencoder for Respiratory Sound Classification
Authors: Peidong Wei Shiyu Miao Lin Li
Abstract: Deep neural networks have been applied to audio spectrograms for respiratory sound classification, but it remains challenging to achieve satisfactory performance due to the scarcity of available data. Moreover, domain mismatch may be introduced into the trained models as a result of the respiratory sound samples being collected from various electronic stethoscopes, patient demographics, and recording environments. To tackle this issue, we proposed a modified MaskedAutoencoder(MAE) model, named Disentangling Dual-Encoder MAE (DDE-MAE) for respiratory sound classification. Two independent encoders were designed to capture disease-related and disease-irrelevant information separately, achieving feature disentanglement to reduce the domain mismatch. Our method achieves a competitive performance on the ICBHI dataset.

Paper number 32:
Title: SNR and Resource Adaptive Deep JSCC for Distributed IoT Image Classification
Authors: Ali Waqas, Sinem Coleri
Abstract: Sensor-based local inference at IoT devices faces severe computational limitations, often requiring data transmission over noisy wireless channels for server-side processing. To address this, split-network Deep Neural Network (DNN) based Joint Source-Channel Coding (JSCC) schemes are used to extract and transmit relevant features instead of raw data. However, most existing methods rely on fixed network splits and static configurations, lacking adaptability to varying computational budgets and channel conditions. In this paper, we propose a novel SNR- and computation-adaptive distributed CNN framework for wireless image classification across IoT devices and edge servers. We introduce a learning-assisted intelligent Genetic Algorithm (LAIGA) that efficiently explores the CNN hyperparameter space to optimize network configuration under given FLOPs constraints and given SNR. LAIGA intelligently discards the infeasible network configurations that exceed computational budget at IoT device. It also benefits from the Random Forests based learning assistance to avoid a thorough exploration of hyperparameter space and to induce application specific bias in candidate optimal configurations. Experimental results demonstrate that the proposed framework outperforms fixed-split architectures and existing SNR-adaptive methods, especially under low SNR and limited computational resources. We achieve a 10\% increase in classification accuracy as compared to existing JSCC based SNR-adaptive multilayer framework at an SNR as low as -10dB across a range of available computational budget (1M to 70M FLOPs) at IoT device.

Paper number 33:
Title: A Novel Signal Processing Strategy for Short-Range Laser Feedback Interferometry Sensors
Authors: Alexander Zimmer, Johannes Meyer, Enkelejda Kasneci
Abstract: The rapid evolution of wearable technologies, such as AR glasses, demands compact, energy-efficient sensors capable of high-precision measurements in dynamic environments. Traditional Frequency-Modulated Continuous Wave (FMCW) Laser Feedback Interferometry (LFI) sensors, while promising, falter in applications that feature small distances, high velocities, shallow modulation, and low-power constraints. We propose a novel sensor-processing pipeline that reliably extracts distance and velocity measurements at distances as low as 1 cm. As a core contribution, we introduce a four-ramp modulation scheme that resolves persistent ambiguities in beat frequency signs and overcomes spectral blind regions caused by hardware limitations. Based on measurements of the implemented pipeline, a noise model is defined to evaluate its performance and sensitivity to several algorithmic and working point parameters. We show that the pipeline generally achieves robust and low-noise measurements using state-of-the-art hardware.

Paper number 34:
Title: Sampling-Based Planning Under STL Specifications: A Forward Invariance Approach
Authors: Gregorio Marchesini, Siyuan Liu, Lars Lindemann, Dimos V. Dimarogonas
Abstract: We propose a variant of the Rapidly Exploring Random Tree Star (RRT$^{\star}$) algorithm to synthesize trajectories satisfying a given spatio-temporal specification expressed in a fragment of Signal Temporal Logic (STL) for linear systems. Previous approaches for planning trajectories under STL specifications using sampling-based methods leverage either mixed-integer or non-smooth optimization techniques, with poor scalability in the horizon and complexity of the task. We adopt instead a control-theoretic perspective on the problem, based on the notion of set forward invariance. Specifically, from a given STL task defined over polyhedral predicates, we develop a novel algorithmic framework by which the task is efficiently encoded into a time-varying set via linear programming, such that trajectories evolving within the set also satisfy the task. Forward invariance properties of the resulting set with respect to the system dynamics and input limitations are then proved via non-smooth analysis. We then present a modified RRT$^{\star}$ algorithm to synthesize asymptotically optimal and dynamically feasible trajectories satisfying a given STL specification, by sampling a tree of trajectories within the previously constructed time-varying set. We showcase two use cases of our approach involving an autonomous inspection of the International Space Station and room-servicing task requiring timed revisit of a charging station.

Paper number 35:
Title: FairASR: Fair Audio Contrastive Learning for Automatic Speech Recognition
Authors: Jongsuk Kim, Jaemyung Yu, Minchan Kwon, Junmo Kim
Abstract: Large-scale ASR models have achieved remarkable gains in accuracy and robustness. However, fairness issues remain largely unaddressed despite their critical importance in real-world applications. In this work, we introduce FairASR, a system that mitigates demographic bias by learning representations that are uninformative about group membership, enabling fair generalization across demographic groups. Leveraging a multi-demographic dataset, our approach employs a gradient reversal layer to suppress demographic-discriminative features while maintaining the ability to capture generalizable speech patterns through an unsupervised contrastive loss. Experimental results show that FairASR delivers competitive overall ASR performance while significantly reducing performance disparities across different demographic groups.

Paper number 36:
Title: Joint Beamforming with Extremely Large Scale RIS: A Sequential Multi-Agent A2C Approach
Authors: Zhi Chai, Jiajie Xu, Justin P Coon, Mohamed-Slim Alouini
Abstract: It is a challenging problem to jointly optimize the base station (BS) precoding matrix and the reconfigurable intelligent surface (RIS) phases simultaneously in a RIS-assisted multiple-user multiple-input-multiple-output (MU-MIMO) scenario when the size of the RIS becomes extremely large. In this paper, we propose a deep reinforcement learning algorithm called sequential multi-agent advantage actor-critic (A2C) to solve this problem. In addition, the discrete phase of RISs, imperfect channel state information (CSI), and channel correlations between users are taken into consideration. The computational complexity is also analyzed, and the performance of the proposed algorithm is compared with the zero-forcing (ZF) beamformer in terms of the sum spectral efficiency (SE). It is noted that the computational complexity of the proposed algorithm is lower than the benchmark, while the performance is better than the benchmark. Throughout simulations, it is also found that the proposed algorithm is robust to medium channel estimation error.

Paper number 37:
Title: A Robust Optimization Framework for Flexible Industrial Energy Scheduling: Application to a Cement Plant with Market Participation
Authors: Sebastián Rojas-Innocenti, Enrique Baeyens, Alejandro Martín-Crespo, Sergio Saludes-Rodil, Fernando Frechoso Escudero
Abstract: This paper presents a scenario based robust optimization framework for short term energy scheduling in electricity intensive industrial plants, explicitly addressing uncertainty in planning decisions. The model is formulated as a two-stage Mixed Integer Linear Program (MILP) and integrates a hybrid scenario generation method capable of representing uncertain inputs such as electricity prices, renewable generation, and internal demand. A convex objective function combining expected and worst case operational costs allows for tunable risk aversion, enabling planners to balance economic performance and robustness. The resulting schedule ensures feasibility across all scenarios and supports coordinated use of industrial flexibility assets, including battery energy storage and shiftable production. To isolate the effects of market volatility, the framework is applied to a real world cement manufacturing case study considering only day-ahead electricity price uncertainty, with all other inputs treated deterministically. Results show improved resilience to forecast deviations, reduced cost variability, and more consistent operations. The proposed method offers a scalable and risk-aware approach for industrial flexibility planning under uncertainty.

Paper number 38:
Title: Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches
Authors: Andrea Moglia (1), Matteo Leccardi (1), Matteo Cavicchioli (1), Alice Maccarini (2), Marco Marcon (1), Luca Mainardi (1), Pietro Cerveri (1 and 2) ((1) Politecnico di Milano, (2) Università di Pavia)
Abstract: Following the successful paradigm shift of large language models, leveraging pre-training on a massive corpus of data and fine-tuning on different downstream tasks, generalist models have made their foray into computer vision. The introduction of Segment Anything Model (SAM) set a milestone on segmentation of natural images, inspiring the design of a multitude of architectures for medical image segmentation. In this survey we offer a comprehensive and in-depth investigation on generalist models for medical image segmentation. We start with an introduction on the fundamentals concepts underpinning their development. Then, we provide a taxonomy on the different declinations of SAM in terms of zero-shot, few-shot, fine-tuning, adapters, on the recent SAM 2, on other innovative models trained on images alone, and others trained on both text and images. We thoroughly analyze their performances at the level of both primary research and best-in-literature, followed by a rigorous comparison with the state-of-the-art task-specific models. We emphasize the need to address challenges in terms of compliance with regulatory frameworks, privacy and security laws, budget, and trustworthy artificial intelligence (AI). Finally, we share our perspective on future directions concerning synthetic data, early fusion, lessons learnt from generalist models in natural language processing, agentic AI and physical AI, and clinical translation.

Paper number 39:
Title: A novel visual data-based diagnostic approach for estimation of regime transition in pool boiling
Authors: Pranay Nirapure, Ayushman Singh, Srikanth Rangarajan, Bahgat Sammakia
Abstract: This study introduces a novel metric, the Index of Visual Similarity (IVS), to qualitatively characterize boiling heat transfer regimes using only visual data. The IVS is constructed by combining morphological similarity, through SIFT-based feature matching, with physical similarity, via vapor area estimation using Mask R-CNN. High-speed images of pool boiling on two distinct surfaces, polished copper and porous copper foam, are employed to demonstrate the generalizability of the approach. IVS captures critical changes in bubble shape, size, and distribution that correspond to transitions in heat transfer mechanisms. The metric is validated against an equivalent metric, $\Phi$, derived from measured heat transfer coefficients (HTC), showing strong correlation and reliability in detecting boiling regime transitions, including the onset of nucleate boiling and proximity to critical heat flux (CHF). Given experimental limitations in precisely measuring changes in HTC, the sensitivity of IVS to surface superheat is also examined to reinforce the credibility of IVS. IVS thus emerges as a powerful, rapid, and non-intrusive tool for real-time, image-based boiling diagnostics, with promising applications in phase change heat transfer.

Paper number 40:
Title: General Reference Frame Identification and Transformation in Unbalanced Power Systems
Authors: Francisco G. Montoya, Santiago Sánchez Acevedo
Abstract: Various domains such as power system stability analysis, electric machine modeling, and control of power electronic converters have significantly benefited from the application of coordinate transformations. One of the main benefits is the dimensional reduction, which reduces the complexity of the problems. This paper introduces a novel general transformation based on a geometric framework that directly identifies the plane containing the locus for unbalanced quantities through bivector analysis using Geometric Algebra. The proposed method provides a direct transformation valid for any degree of unbalance in $n$-phase, $(n+1)$-wire sinusoidal systems. The transformation requires only two measurements (voltage or current) taken at different time instants, making it computationally efficient. Moreover, we demonstrate through pure geometric reasoning that our approach is general and encompasses other techniques, such as the classical Clarke transformation. Numerical simulations and experimental validation using a real-time digital simulator and a physical laboratory setup demonstrate the effectiveness of the proposed method. This generalization to multi-dimensional systems, combined with the reduced measurement requirements, represents a significant advancement over existing approaches that are typically restricted to three-phase applications or suffer from computational limitations.

Paper number 41:
Title: Automotive Radar Online Channel Imbalance Estimation via NLMS
Authors: Esmaeil Kavousi Ghafi, Oliver Lang, Matthias Wagner, Alexander Melzer, Mario Huemer
Abstract: Automotive radars are one of the essential enablers of advanced driver assistance systems (ADASs). Continuous monitoring of the functional safety and reliability of automotive radars is a crucial requirement to prevent accidents and increase road safety. One of the most critical aspects to monitor in this context is radar channel imbalances, as they are a key parameter regarding the reliability of the radar. These imbalances may originate from several parameter variations or hardware fatigues, e.g., a solder ball break (SBB), and may affect some radar processing steps, such as the angle of arrival estimation. In this work, a novel method for online estimation of automotive radar channel imbalances is proposed. The proposed method exploits a normalized least mean squares (NLMS) algorithm as a block in the processing chain of the radar to estimate the channel imbalances. The input of this block is the detected targets in the range-Doppler map of the radar on the road without any prior knowledge on the angular parameters of the targets. This property in combination with low computational complexity of the NLMS, makes the proposed method suitable for online channel imbalance estimation, in parallel to the normal operation of the radar. Furthermore, it features reduced dependency on specific targets of interest and faster update rates of the channel imbalance estimation compared to the majority of state-of-the-art methods. This improvement is achieved by allowing for multiple targets in the angular spectrum, whereas most other methods are restricted to only single targets in the angular spectrum. The performance of the proposed method is validated using various simulation scenarios and is supported by measurement results.

Paper number 42:
Title: Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation
Authors: Zhenhuan Zhou
Abstract: Medical image segmentation is a fundamental and key technology in computer-aided diagnosis and treatment. Previous methods can be broadly classified into three categories: convolutional neural network (CNN) based, Transformer based, and hybrid architectures that combine both. However, each of them has its own limitations, such as restricted receptive fields in CNNs or the computational overhead caused by the quadratic complexity of Transformers. Recently, the Receptance Weighted Key Value (RWKV) model has emerged as a promising alternative for various vision tasks, offering strong long-range modeling capabilities with linear computational complexity. Some studies have also adapted RWKV to medical image segmentation tasks, achieving competitive performance. However, most of these studies focus on modifications to the Vision-RWKV (VRWKV) mechanism and train models from scratch, without exploring the potential advantages of leveraging pre-trained VRWKV models for medical image segmentation tasks. In this paper, we propose Med-URWKV, a pure RWKV-based architecture built upon the U-Net framework, which incorporates ImageNet-based pretraining to further explore the potential of RWKV in medical image segmentation tasks. To the best of our knowledge, Med-URWKV is the first pure RWKV segmentation model in the medical field that can directly reuse a large-scale pre-trained VRWKV encoder. Experimental results on seven datasets demonstrate that Med-URWKV achieves comparable or even superior segmentation performance compared to other carefully optimized RWKV models trained from scratch. This validates the effectiveness of using a pretrained VRWKV encoder in enhancing model performance. The codes will be released.

Paper number 43:
Title: Data-Driven Model Reduction by Moment Matching for Linear and Nonlinear Parametric Systems
Authors: Hanqing Zhang, Junyu Mao, Mohammad Fahim Shakib, Giordano Scarciotti
Abstract: Theory and methods to obtain parametric reduced-order models by moment matching are presented. The definition of the parametric moment is introduced, and methods (model-based and data-driven) for the approximation of the parametric moment of linear and nonlinear parametric systems are proposed. These approximations are exploited to construct families of parametric reduced-order models that match the approximate parametric moment of the system to be reduced and preserve key system properties such as asymptotic stability and dissipativity. The use of the model reduction methods is illustrated by means of a parametric benchmark model for the linear case and a large-scale wind farm model for the nonlinear case. In the illustration, a comparison of the proposed approximation methods is drawn and their advantages/disadvantages are discussed.

Paper number 44:
Title: Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach
Authors: Meredith VandeHaar, M. Clinch, I. Yilmaz, M.A. Rahman, Y. Xiao, F. Dogany, H.M. Alazab, A. Nassar, Z. Akkus, B. Dangott
Abstract: Quality assurance is a critical but underexplored area in digital pathology, where even minor artifacts can have significant effects. Artifacts have been shown to negatively impact the performance of AI diagnostic models. In current practice, trained staff manually review digitized images prior to release of these slides to pathologists which are then used to render a diagnosis. Conventional image processing approaches, provide a foundation for detecting artifacts on digital pathology slides. However, current tools do not leverage deep learning, which has the potential to improve detection accuracy and scalability. Despite these advancements, methods for quality assurance in digital pathology remain limited, presenting a gap for innovation. We propose an AI algorithm designed to screen digital pathology slides by analyzing tiles and categorizing them into one of 10 predefined artifact types or as background. This algorithm identifies and localizes artifacts, creating a map that highlights regions of interest. By directing human operators to specific tiles affected by artifacts, the algorithm minimizes the time and effort required to manually review entire slides for quality issues. From internal archives and The Cancer Genome Atlas, 133 whole slide images were selected and 10 artifacts were annotated using an internally developed software ZAPP (Mayo Clinic, Jacksonville, FL). Ablation study of multiple models at different tile sizes and magnification was performed. InceptionResNet was selected. Single artifact models were trained and tested, followed by a limited multiple instance model with artifacts that performed well together (chatter, fold, and pen). From the results of this study we suggest a hybrid design for artifact screening composed of both single artifact binary models as well as multiple instance models to optimize detection of each artifact.

Paper number 45:
Title: Bias-Switchable Row-Column Array Imaging using Fast Orthogonal Row-Column Electronic Scanning (FORCES) Compared with Conventional Row-Column Array Imaging
Authors: Randy Palamar, Mohammad Rahim Sobhani, Darren Dahunsi, Negar Majidi, Afshin Kashani Ilkhechi, Joy Wang, Jeremy Brown, Roger Zemp
Abstract: Row-Column Arrays (RCAs) offer an attractive alternative to fully wired 2D-arrays for 3D-ultrasound, due to their greatly simplified wiring. However, conventional RCAs face challenges related to their long elements. These include an inability to image beyond the shadow of the aperture and an inability to focus in both transmit and receive for desired scan planes. To address these limitations, we recently developed bias-switchable RCAs, also known as Top Orthogonal to Bottom Electrode (TOBE) arrays. These arrays provide novel opportunities to read out from every element of the array and achieve high-quality images. While TOBE arrays and their associated imaging schemes have shown promise, they have not yet been directly compared experimentally to conventional RCA imaging techniques. This study aims to provide such a comparison, demonstrating superior B-scan and volumetric images from two electrostrictive relaxor TOBE arrays, using a method called Fast Orthogonal Row-Column Electronic scanning (FORCES), compared to conventional RCA imaging schemes, including Tilted Plane Wave (TPW) compounding and Virtual Line Source (VLS) imaging. The study quantifies resolution and Generalized Contrast to Noise Ratio (gCNR) in phantoms, and also demonstrates volumetric acquisitions in phantom and animal models.

Paper number 46:
Title: Leveraging Pre-Trained Models for Multimodal Class-Incremental Learning under Adaptive Fusion
Authors: Yukun Chen, Zihuan Qiu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu
Abstract: Unlike traditional Multimodal Class-Incremental Learning (MCIL) methods that focus only on vision and text, this paper explores MCIL across vision, audio and text modalities, addressing challenges in integrating complementary information and mitigating catastrophic forgetting. To tackle these issues, we propose an MCIL method based on multimodal pre-trained models. Firstly, a Multimodal Incremental Feature Extractor (MIFE) based on Mixture-of-Experts (MoE) structure is introduced to achieve effective incremental fine-tuning for AudioCLIP. Secondly, to enhance feature discriminability and generalization, we propose an Adaptive Audio-Visual Fusion Module (AAVFM) that includes a masking threshold mechanism and a dynamic feature fusion mechanism, along with a strategy to enhance text diversity. Thirdly, a novel multimodal class-incremental contrastive training loss is proposed to optimize cross-modal alignment in MCIL. Finally, two MCIL-specific evaluation metrics are introduced for comprehensive assessment. Extensive experiments on three multimodal datasets validate the effectiveness of our method.

Paper number 47:
Title: Multimodal Emotion Coupling via Speech-to-Facial and Bodily Gestures in Dyadic Interaction
Authors: Von Ralph Dane Marquez Herbuela, Yukie Nagai
Abstract: Human emotional expression emerges through coordinated vocal, facial, and gestural signals. While speech face alignment is well established, the broader dynamics linking emotionally expressive speech to regional facial and hand motion remains critical for gaining a deeper insight into how emotional and behavior cues are communicated in real interactions. Further modulating the coordination is the structure of conversational exchange like sequential turn taking, which creates stable temporal windows for multimodal synchrony, and simultaneous speech, often indicative of high arousal moments, disrupts this alignment and impacts emotional clarity. Understanding these dynamics enhances realtime emotion detection by improving the accuracy of timing and synchrony across modalities in both human interactions and AI systems. This study examines multimodal emotion coupling using region specific motion capture from dyadic interactions in the IEMOCAP corpus. Speech features included low level prosody, MFCCs, and model derived arousal, valence, and categorical emotions (Happy, Sad, Angry, Neutral), aligned with 3D facial and hand marker displacements. Expressive activeness was quantified through framewise displacement magnitudes, and speech to gesture prediction mapped speech features to facial and hand movements. Nonoverlapping speech consistently elicited greater activeness particularly in the lower face and mouth. Sadness showed increased expressivity during nonoverlap, while anger suppressed gestures during overlaps. Predictive mapping revealed highest accuracy for prosody and MFCCs in articulatory regions while arousal and valence had lower and more context sensitive correlations. Notably, hand speech synchrony was enhanced under low arousal and overlapping speech, but not for valence.

Paper number 48:
Title: Impacts between multibody systems and deformable structures
Authors: Lipinski Krzysztof
Abstract: Collisions and impacts are the principal reasons for impulsive motions, which we frequently see in dynamic responses of systems. Precise modelling of impacts is a challenging problem due to the lack of the accurate and commonly accepted constitutive law that governs their mechanics. Rigid-body approach and soft contact methods are discussed in this paper and examined in the presented numerical examples. The main focus is set to impacts in systems with multiple unilateral contacts and collisions with elastic elements of the reference. Parameters of interconnecting unilateral springs are under discussion.

Paper number 49:
Title: Description and Discussion on DCASE 2025 Challenge Task 2: First-shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring
Authors: Tomoya Nishida, Noboru Harada, Daisuke Niizumi, Davide Albertini, Roberto Sannino, Simone Pradolini, Filippo Augusti, Keisuke Imoto, Kota Dohi, Harsh Purohit, Takashi Endo, Yohei Kawaguchi
Abstract: This paper introduces the task description for the Detection and Classification of Acoustic Scenes and Events (DCASE) 2025 Challenge Task 2, titled "First-shot unsupervised anomalous sound detection (ASD) for machine condition monitoring." Building on the DCASE 2024 Challenge Task 2, this task is structured as a first-shot problem within a domain generalization framework. The primary objective of the first-shot approach is to facilitate the rapid deployment of ASD systems for new machine types without requiring machine-specific hyperparameter tunings. For DCASE 2025 Challenge Task 2, sounds from previously unseen machine types have been collected and provided as the evaluation dataset. Results and analysis of the challenge submissions will be added following the challenge's submission deadline.

Paper number 50:
Title: Data-driven balanced truncation for second-order systems with generalized proportional damping
Authors: Sean Reiter, Steffen W. R. Werner
Abstract: Structured reduced-order modeling is a central component in the computer-aided design of control systems in which cheap-to-evaluate low-dimensional models with physically meaningful internal structures are computed. In this work, we develop a new approach for the structured data-driven surrogate modeling of linear dynamical systems described by second-order time derivatives via balanced truncation model-order reduction. The proposed method is a data-driven reformulation of position-velocity balanced truncation for second-order systems and generalizes the quadrature-based balanced truncation for unstructured first-order systems to the second-order case. The computed surrogates encode a generalized proportional damping structure, and the damping coefficients are inferred solely from data by minimizing a least-squares error over the coefficients. Several numerical examples demonstrate the effectiveness of the proposed method.

Paper number 51:
Title: The 2025 PNPL Competition: Speech Detection and Phoneme Classification in the LibriBrain Dataset
Authors: Gilad Landau, Miran Özdogan, Gereon Elvers, Francesco Mantegna, Pratik Somaiya, Dulhan Jayalath, Luisa Kurth, Teyun Kwon, Brendan Shillingford, Greg Farquhar, Minqi Jiang, Karim Jerbi, Hamza Abdelhedi, Yorguin Mantilla Ramos, Caglar Gulcehre, Mark Woolrich, Natalie Voets, Oiwi Parker Jones
Abstract: The advance of speech decoding from non-invasive brain data holds the potential for profound societal impact. Among its most promising applications is the restoration of communication to paralysed individuals affected by speech deficits such as dysarthria, without the need for high-risk surgical interventions. The ultimate aim of the 2025 PNPL competition is to produce the conditions for an "ImageNet moment" or breakthrough in non-invasive neural decoding, by harnessing the collective power of the machine learning community. To facilitate this vision we present the largest within-subject MEG dataset recorded to date (LibriBrain) together with a user-friendly Python library (pnpl) for easy data access and integration with deep learning frameworks. For the competition we define two foundational tasks (i.e. Speech Detection and Phoneme Classification from brain data), complete with standardised data splits and evaluation metrics, illustrative benchmark models, online tutorial code, a community discussion board, and public leaderboard for submissions. To promote accessibility and participation the competition features a Standard track that emphasises algorithmic innovation, as well as an Extended track that is expected to reward larger-scale computing, accelerating progress toward a non-invasive brain-computer interface for speech.

Paper number 52:
Title: DeepPolar+: Breaking the BER-BLER Trade-off with Self-Attention and SMART (SNR-MAtched Redundancy Technique) decoding
Authors: Shubham Srivastava, Adrish Banerjee
Abstract: DeepPolar codes have recently emerged as a promising approach for channel coding, demonstrating superior bit error rate (BER) performance compared to conventional polar codes. Despite their excellent BER characteristics, these codes exhibit suboptimal block error rate (BLER) performance, creating a fundamental BER-BLER trade-off that severely limits their practical deployment in communication systems. This paper introduces DeepPolar+, an enhanced neural polar coding framework that systematically eliminates this BER-BLER trade-off by simultaneously improving BLER performance while maintaining the superior BER characteristics of DeepPolar codes. Our approach achieves this breakthrough through three key innovations: (1) an attention-enhanced decoder architecture that leverages multi-head self-attention mechanisms to capture complex dependencies between bit positions, (2) a structured loss function that jointly optimizes for both bit-level accuracy and block-level reliability, and (3) an adaptive SNR-Matched Redundancy Technique (SMART) for decoding DeepPolar+ code (DP+SMART decoder) that combines specialized models with CRC verification for robust performance across diverse channel conditions. For a (256,37) code configuration, DeepPolar+ demonstrates notable improvements in both BER and BLER performance compared to conventional successive cancellation decoding and DeepPolar, while achieving remarkably faster convergence through improved architecture and optimization strategies. The DeepPolar+SMART variant further amplifies these dual improvements, delivering significant gains in both error rate metrics over existing approaches. DeepPolar+ effectively bridges the gap between theoretical potential and practical implementation of neural polar codes, offering a viable path forward for next-generation error correction systems.

Paper number 53:
Title: Wasserstein Barycenter Soft Actor-Critic
Authors: Zahra Shahrooei, Ali Baheri
Abstract: Deep off-policy actor-critic algorithms have emerged as the leading framework for reinforcement learning in continuous control domains. However, most of these algorithms suffer from poor sample efficiency, especially in environments with sparse rewards. In this paper, we take a step towards addressing this issue by providing a principled directed exploration strategy. We propose Wasserstein Barycenter Soft Actor-Critic (WBSAC) algorithm, which benefits from a pessimistic actor for temporal difference learning and an optimistic actor to promote exploration. This is achieved by using the Wasserstein barycenter of the pessimistic and optimistic policies as the exploration policy and adjusting the degree of exploration throughout the learning process. We compare WBSAC with state-of-the-art off-policy actor-critic algorithms and show that WBSAC is more sample-efficient on MuJoCo continuous control tasks.

Paper number 54:
Title: FedMLAC: Mutual Learning Driven Heterogeneous Federated Audio Classification
Authors: Jun Bai, Rajib Rana, Di Wu, Youyang Qu, Xiaohui Tao, Ji Zhang
Abstract: Federated Learning (FL) provides a privacy-preserving paradigm for training audio classification (AC) models across distributed clients without sharing raw data. However, Federated Audio Classification (FedAC) faces three critical challenges that substantially hinder performance: data heterogeneity, model heterogeneity, and data poisoning. While prior works have attempted to address these issues, they are typically treated independently, lacking a unified and robust solution suited to real-world federated audio scenarios. To bridge this gap, we propose FedMLAC, a unified mutual learning framework designed to simultaneously tackle these challenges in FedAC. Specifically, FedMLAC introduces a dual-model architecture on each client, comprising a personalized local AC model and a lightweight, globally shared Plug-in model. Through bidirectional knowledge distillation, the Plug-in model enables global knowledge transfer while adapting to client-specific data distributions, thus supporting both generalization and personalization. To further enhance robustness against corrupted audio data, we develop a Layer-wise Pruning Aggregation (LPA) strategy that filters unreliable Plug-in model updates based on parameter deviations during server-side aggregation. Extensive experiments on four diverse audio classification benchmarks, spanning both speech and non-speech tasks, demonstrate that FedMLAC consistently outperforms existing state-of-the-art methods in terms of classification accuracy and robustness to noisy data.

Paper number 55:
Title: Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms
Authors: Sajjad Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni
Abstract: Simultaneous electrocardiography (ECG) and phonocardiogram (PCG) provide a comprehensive, multimodal perspective on cardiac function by capturing the heart's electrical and mechanical activities, respectively. However, the distinct and overlapping information content of these signals, as well as their potential for mutual reconstruction and biomarker extraction, remains incompletely understood, especially under varying physiological conditions and across individuals. In this study, we systematically investigate the common and exclusive characteristics of ECG and PCG using the EPHNOGRAM dataset of simultaneous ECG-PCG recordings during rest and exercise. We employ a suite of linear and nonlinear machine learning models, including non-causal LSTM networks, to reconstruct each modality from the other and analyze the influence of causality, physiological state, and cross-subject variability. Our results demonstrate that nonlinear models, particularly non-causal LSTM, provide superior reconstruction performance, with reconstructing ECG from PCG proving more tractable than the reverse. Exercise and cross-subject scenarios present significant challenges, but envelope-based modeling that utilizes instantaneous amplitude features substantially improves cross-subject generalizability for cross-modal learning. Furthermore, we demonstrate that clinically relevant ECG biomarkers, such as fiducial points and QT intervals, can be estimated from PCG in cross-subject settings. These findings advance our understanding of the relationship between electromechanical cardiac modalities, in terms of both waveform characteristics and the timing of cardiac events, with potential applications in novel multimodal cardiac monitoring technologies.

Paper number 56:
Title: Fine-Grained control over Music Generation with Activation Steering
Authors: Dipanshu Panda, Jayden Koshy Joe, Harshith M R, Swathi Narashiman, Pranay Mathur, Anish Veerakumar, Aniruddh Krishna, Keerthiharan A
Abstract: We present a method for fine-grained control over music generation through inference-time interventions on an autoregressive generative music transformer called MusicGen. Our approach enables timbre transfer, style transfer, and genre fusion by steering the residual stream using weights of linear probes trained on it, or by steering the attention layer activations in a similar manner. We observe that modelling this as a regression task provides improved performance, hypothesizing that the mean-squared-error better preserve meaningful directional information in the activation space. Combined with the global conditioning offered by text prompts in MusicGen, our method provides both global and local control over music generation. Audio samples illustrating our method are available at our demo page.

Paper number 57:
Title: Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators
Authors: Rongfei Li, Francis Assadian
Abstract: Image-based visual servoing (IBVS) methods have been well developed and used in many applications, especially in pose (position and orientation) alignment. However, most research papers focused on developing control solutions when 3D point features can be detected inside the field of view. This work proposes an innovative feedforward-feedback adaptive control algorithm structure with the Youla Parameterization method. A designed feature estimation loop ensures stable and fast motion control when point features are outside the field of view. As 3D point features move inside the field of view, the IBVS feedback loop preserves the precision of the pose at the end of the control period. Also, an adaptive controller is developed in the feedback loop to stabilize the system in the entire range of operations. The nonlinear camera and robot manipulator model is linearized and decoupled online by an adaptive algorithm. The adaptive controller is then computed based on the linearized model evaluated at current linearized point. The proposed solution is robust and easy to implement in different industrial robotic systems. Various scenarios are used in simulations to validate the effectiveness and robust performance of the proposed controller.

Paper number 58:
Title: Optimal Voltage Control Using Online Exponential Barrier Method
Authors: Peng Zhang, Baosen Zhang
Abstract: This paper address the optimal voltage control problem of distribution systems with high penetration of inverter-based renewable energy resources, under inaccurate model information. We propose the online exponential barrier method that explicitly leverages the online feedback from grids to enhance the robustness to model inaccuracy and incorporates the voltage constraints to maintain the safety requirements. We provide analytical results on the optimal barrier parameter selection and sufficient conditions for the safety guarantee of converged voltages. We also establish theoretical results on the exponential convergence rate with proper step-size. The effectiveness of the proposed framework is validated on a 56-bus radial network, where we significantly improve the robustness against model inaccuracy compared to existing methods.

Paper number 59:
Title: A Novel Feedforward Youla Parameterization Method for Avoiding Local Minima in Stereo Image Based Visual Servoing Control
Authors: Rongfei Li, Francis Assadian
Abstract: In robot navigation and manipulation, accurately determining the camera's pose relative to the environment is crucial for effective task execution. In this paper, we systematically prove that this problem corresponds to the Perspective-3-Point (P3P) formulation, where exactly three known 3D points and their corresponding 2D image projections are used to estimate the pose of a stereo camera. In image-based visual servoing (IBVS) control, the system becomes overdetermined, as the 6 degrees of freedom (DoF) of the stereo camera must align with 9 observed 2D features in the scene. When more constraints are imposed than available DoFs, global stability cannot be guaranteed, as the camera may become trapped in a local minimum far from the desired configuration during servoing. To address this issue, we propose a novel control strategy for accurately positioning a calibrated stereo camera. Our approach integrates a feedforward controller with a Youla parameterization-based feedback controller, ensuring robust servoing performance. Through simulations, we demonstrate that our method effectively avoids local minima and enables the camera to reach the desired pose accurately and efficiently.

Paper number 60:
Title: Discrete Audio Tokens: More Than a Survey!
Authors: Pooneh Mousavi, Gallil Maimon, Adel Moumen, Darius Petermann, Jiatong Shi, Haibin Wu, Haici Yang, Anastasia Kuznetsova, Artem Ploujnikov, Ricard Marxer, Bhuvana Ramabhadran, Benjamin Elizalde, Loren Lugosch, Jinyu Li, Cem Subakan, Phil Woodland, Minje Kim, Hung-yi Lee, Shinji Watanabe, Yossi Adi, Mirco Ravanelli
Abstract: Discrete audio tokens are compact representations that aim to preserve perceptual quality, phonetic content, and speaker characteristics while enabling efficient storage and inference, as well as competitive performance across diverse downstream this http URL provide a practical alternative to continuous features, enabling the integration of speech and audio into modern large language models (LLMs). As interest in token-based audio processing grows, various tokenization methods have emerged, and several surveys have reviewed the latest progress in the field. However, existing studies often focus on specific domains or tasks and lack a unified comparison across various benchmarks. This paper presents a systematic review and benchmark of discrete audio tokenizers, covering three domains: speech, music, and general audio. We propose a taxonomy of tokenization approaches based on encoder-decoder, quantization techniques, training paradigm, streamability, and application domains. We evaluate tokenizers on multiple benchmarks for reconstruction, downstream performance, and acoustic language modeling, and analyze trade-offs through controlled ablation studies. Our findings highlight key limitations, practical considerations, and open challenges, providing insight and guidance for future research in this rapidly evolving area. For more information, including our main results and tokenizer database, please refer to our website: this https URL.

Paper number 61:
Title: Learning Safe Control via On-the-Fly Bandit Exploration
Authors: Alexandre Capone, Ryan Cosner, Aaaron Ames, Sandra Hirche
Abstract: Control tasks with safety requirements under high levels of model uncertainty are increasingly common. Machine learning techniques are frequently used to address such tasks, typically by leveraging model error bounds to specify robust constraint-based safety filters. However, if the learned model uncertainty is very high, the corresponding filters are potentially invalid, meaning no control input satisfies the constraints imposed by the safety filter. While most works address this issue by assuming some form of safe backup controller, ours tackles it by collecting additional data on the fly using a Gaussian process bandit-type algorithm. We combine a control barrier function with a learned model to specify a robust certificate that ensures safety if feasible. Whenever infeasibility occurs, we leverage the control barrier function to guide exploration, ensuring the collected data contributes toward the closed-loop system safety. By combining a safety filter with exploration in this manner, our method provably achieves safety in a setting that allows for a zero-mean prior dynamics model, without requiring a backup controller. To the best of our knowledge, it is the first safe learning-based control method that achieves this.

Paper number 62:
Title: Scheduled Interleaved Speech-Text Training for Speech-to-Speech Translation with LLMs
Authors: Hayato Futami, Emiru Tsunoo, Yosuke Kashiwagi, Yuki Ito, Hassan Shahmohammadi, Siddhant Arora, Shinji Watanabe
Abstract: Speech-to-speech translation (S2ST) has been advanced with large language models (LLMs), which are fine-tuned on discrete speech units. In such approaches, modality adaptation from text to speech has been an issue. LLMs are trained on text-only data, which presents challenges to adapt them to speech modality with limited speech-to-speech data. To address the training difficulty, we propose scheduled interleaved speech--text training in this study. We use interleaved speech--text units instead of speech units during training, where aligned text tokens are interleaved at the word level. We gradually decrease the ratio of text as training progresses, to facilitate progressive modality adaptation from text to speech. We conduct experimental evaluations by fine-tuning LLaMA3.2-1B for S2ST on the CVSS dataset. We show that the proposed method consistently improves the translation performances, especially for languages with limited training data.

Paper number 63:
Title: Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video
Authors: Fei Zhao, Da Pan, Zelu Qi, Ping Shi
Abstract: In response to the rising prominence of the Metaverse, omnidirectional videos (ODVs) have garnered notable interest, gradually shifting from professional-generated content (PGC) to user-generated content (UGC). However, the study of audio-visual quality assessment (AVQA) within ODVs remains limited. To address this, we construct a dataset of UGC omnidirectional audio and video (A/V) content. The videos are captured by five individuals using two different types of omnidirectional cameras, shooting 300 videos covering 10 different scene types. A subjective AVQA experiment is conducted on the dataset to obtain the Mean Opinion Scores (MOSs) of the A/V sequences. After that, to facilitate the development of UGC-ODV AVQA fields, we construct an effective AVQA baseline model on the proposed dataset, of which the baseline model consists of video feature extraction module, audio feature extraction and audio-visual fusion module. The experimental results demonstrate that our model achieves optimal performance on the proposed dataset.

Paper number 64:
Title: RICE: Reactive Interaction Controller for Cluttered Canopy Environment
Authors: Nidhi Homey Parayil, Thierry Peynot, Chris Lehnert
Abstract: Robotic navigation in dense, cluttered environments such as agricultural canopies presents significant challenges due to physical and visual occlusion caused by leaves and branches. Traditional vision-based or model-dependent approaches often fail in these settings, where physical interaction without damaging foliage and branches is necessary to reach a target. We present a novel reactive controller that enables safe navigation for a robotic arm in a contact-rich, cluttered, deformable environment using end-effector position and real-time tactile feedback. Our proposed framework's interaction strategy is based on a trade-off between minimizing disturbance by maneuvering around obstacles and pushing through them to move towards the target. We show that over 35 trials in 3 experimental plant setups with an occluded target, the proposed controller successfully reached the target in all trials without breaking any branch and outperformed the state-of-the-art model-free controller in robustness and adaptability. This work lays the foundation for safe, adaptive interaction in cluttered, contact-rich deformable environments, enabling future agricultural tasks such as pruning and harvesting in plant canopies.

Paper number 65:
Title: Can Sound Replace Vision in LLaVA With Token Substitution?
Authors: Ali Vosoughi, Jing Bi, Pinxin Liu, Yunlong Tang, Chenliang Xu
Abstract: While multimodal systems have achieved impressive advances, they typically rely on text-aligned representations rather than directly integrating audio and visual inputs. This reliance can limit the use of acoustic information in tasks requiring nuanced audio understanding. In response, SoundCLIP explores direct audio-visual integration within multimodal large language models (MLLMs) by substituting CLIP's visual tokens with audio representations and selecting sound-relevant patch tokens in models such as LLaVA. We investigate two configurations: (1) projecting audio features into CLIP's visual manifold via a multilayer perceptron trained with InfoNCE on paired audio-video segments, and (2) preserving raw audio embeddings with minimal dimensional adjustments. Experiments with five state-of-the-art audio encoders reveal a fundamental trade-off. While audio-to-video retrieval performance increases dramatically (up to 44 percentage points in Top-1 accuracy) when audio is projected into CLIP's space, text generation quality declines. Encoders pre-trained with text supervision (CLAP, Whisper, ImageBind) maintain stronger generative capabilities than those focused primarily on audiovisual alignment (Wav2CLIP, AudioCLIP), highlighting the value of language exposure for generation tasks. We introduce WhisperCLIP, an architecture that fuses intermediate representations from Whisper, as well as AudioVisual Event Evaluation (AVE-2), a dataset of 580,147 three-second audiovisual clips with fine-grained alignment annotations. Our findings challenge the assumption that stronger cross-modal alignment necessarily benefits all multimodal tasks; instead, a Pareto frontier emerges wherein optimal performance depends on balancing retrieval accuracy with text generation quality. Codes and datasets: this https URL.

Paper number 66:
Title: PAL: Probing Audio Encoders via LLMs -- A Study of Information Transfer from Audio Encoders to LLMs
Authors: Tony Alex, Wish Suharitdamrong, Sara Atito, Armin Mustafa, Philip J. B. Jackson, Imran Razzak, Muhammad Awais
Abstract: The integration of audio perception capabilities into Large Language Models (LLMs) has enabled significant advances in Audio-LLMs. Although application-focused developments, particularly in curating training data for specific capabilities e.g., audio reasoning, have progressed rapidly, the underlying mechanisms that govern efficient transfer of rich semantic representations from audio encoders to LLMs remain under-explored. We conceptualize effective audio-LLM interaction as the LLM's ability to proficiently probe the audio encoder representations to satisfy textual queries. This paper presents a systematic investigation on how architectural design choices can affect that. Beginning with a standard Pengi/LLaVA-style audio-LLM architecture, we propose and evaluate several modifications guided by hypotheses derived from mechanistic interpretability studies and LLM operational principles. Our experiments demonstrate that: (1) delaying audio integration until the LLM's initial layers establish textual context that enhances its ability to probe the audio representations for relevant information; (2) the LLM can proficiently probe audio representations exclusively through LLM layer's attention submodule, without requiring propagation to its Feed-Forward Network (FFN) submodule; (3) an efficiently integrated ensemble of diverse audio encoders provides richer, complementary representations, thereby broadening the LLM's capacity to probe a wider spectrum of audio information. All hypotheses are evaluated using an identical three-stage training curriculum on a dataset of 5.6 million audio-text pairs, ensuring controlled comparisons. Our final architecture, which incorporates all proposed modifications, achieves relative improvements from 10\% to 60\% over the baseline, validating our approach to optimizing cross-modal information transfer in audio-LLMs. Project page: this https URL

Paper number 67:
Title: System Identification Using Kolmogorov-Arnold Networks: A Case Study on Buck Converters
Authors: Nart Gashi, Panagiotis Kakosimos, George Papafotiou
Abstract: Kolmogorov-Arnold Networks (KANs) are emerging as a powerful framework for interpretable and efficient system identification in dynamic systems. By leveraging the Kolmogorov-Arnold representation theorem, KANs enable function approximation through learnable activation functions, offering improved scalability, accuracy, and interpretability compared to traditional neural networks. This paper investigates the application of KANs to model and analyze the dynamics of a buck converter system, focusing on state-space parameter estimation along with discovering the system equations. Using simulation data, the methodology involves approximating state derivatives with KANs, constructing interpretable state-space representations, and validating these models through numerical experiments. The results demonstrate the ability of KANs to accurately identify system dynamics, verify model consistency, and detect parameter changes, providing valuable insights into their applicability for system identification in modern industrial systems.

Paper number 68:
Title: Rethinking Generative Human Video Coding with Implicit Motion Transformation
Authors: Bolin Chen, Ru-Ling Liao, Jie Chen, Yan Ye
Abstract: Beyond traditional hybrid-based video codec, generative video codec could achieve promising compression performance by evolving high-dimensional signals into compact feature representations for bitstream compactness at the encoder side and developing explicit motion fields as intermediate supervision for high-quality reconstruction at the decoder side. This paradigm has achieved significant success in face video compression. However, compared to facial videos, human body videos pose greater challenges due to their more complex and diverse motion patterns, i.e., when using explicit motion guidance for Generative Human Video Coding (GHVC), the reconstruction results could suffer severe distortions and inaccurate motion. As such, this paper highlights the limitations of explicit motion-based approaches for human body video compression and investigates the GHVC performance improvement with the aid of Implicit Motion Transformation, namely IMT. In particular, we propose to characterize complex human body signal into compact visual features and transform these features into implicit motion guidance for signal reconstruction. Experimental results demonstrate the effectiveness of the proposed IMT paradigm, which can facilitate GHVC to achieve high-efficiency compression and high-fidelity synthesis.

Paper number 69:
Title: Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance
Authors: Chun Liu, Bingqian Zhu, Tao Xu, Zheng Zheng, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang
Abstract: Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, which pose security challenges to hyperspectral image (HSI) classification technologies based on DNNs. In the domain of natural images, numerous transfer-based adversarial attack methods have been studied. However, HSIs differ from natural images due to their high-dimensional and rich spectral information. Current research on HSI adversarial examples remains limited and faces challenges in fully utilizing the structural and feature information of images. To address these issues, this paper proposes a novel method to enhance the transferability of the adversarial examples for HSI classification models. First, while keeping the image structure unchanged, the proposed method randomly divides the image into blocks in both spatial and spectral dimensions. Then, various transformations are applied on a block by block basis to increase input diversity and mitigate overfitting. Second, a feature distancing loss targeting intermediate layers is designed, which measures the distance between the amplified features of the original examples and the features of the adversarial examples as the primary loss, while the output layer prediction serves as the auxiliary loss. This guides the perturbation to disrupt the features of the true class in adversarial examples, effectively enhancing transferability. Extensive experiments demonstrate that the adversarial examples generated by the proposed method achieve effective transferability to black-box models on two public HSI datasets. Furthermore, the method maintains robust attack performance even under defense strategies.

Paper number 70:
Title: Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization
Authors: Stone Yun, Alexander Wong
Abstract: Deep neural network (DNN) quantization for fast, efficient inference has been an important tool in limiting the cost of machine learning (ML) model inference. Quantization-specific model development techniques such as regularization, quantization-aware training, and quantization-robustness penalties have served to greatly boost the accuracy and robustness of modern DNNs. However, very little exploration has been done on improving the initial conditions of DNN training for quantization. Just as random weight initialization has been shown to significantly impact test accuracy of floating point models, it would make sense that different weight initialization methods impact quantization robustness of trained models. We present an extensive study examining the effects of different weight initializations on a variety of CNN building blocks commonly used in efficient CNNs. This analysis reveals that even with varying CNN architectures, the choice of random weight initializer can significantly affect final quantization robustness. Next, we explore a new method for quantization-robust CNN initialization -- using Graph Hypernetworks (GHN) to predict parameters of quantized DNNs. Besides showing that GHN-predicted parameters are quantization-robust after regular float32 pretraining (of the GHN), we find that finetuning GHNs to predict parameters for quantized graphs (which we call GHN-QAT) can further improve quantized accuracy of CNNs. Notably, GHN-QAT shows significant accuracy improvements for even 4-bit quantization and better-than-random accuracy for 2-bits. To the best of our knowledge, this is the first in-depth study on quantization-aware DNN weight initialization. GHN-QAT offers a novel approach to quantized DNN model design. Future investigations, such as using GHN-QAT-initialized parameters for quantization-aware training, can further streamline the DNN quantization process.

Paper number 71:
Title: DanceChat: Large Language Model-Guided Music-to-Dance Generation
Authors: Qing Wang, Xiaohang Yang, Yilan Dong, Naveen Raj Govindaraj, Gregory Slabaugh, Shanxin Yuan
Abstract: Music-to-dance generation aims to synthesize human dance motion conditioned on musical input. Despite recent progress, significant challenges remain due to the semantic gap between music and dance motion, as music offers only abstract cues, such as melody, groove, and emotion, without explicitly specifying the physical movements. Moreover, a single piece of music can produce multiple plausible dance interpretations. This one-to-many mapping demands additional guidance, as music alone provides limited information for generating diverse dance movements. The challenge is further amplified by the scarcity of paired music and dance data, which restricts the modelâĂŹs ability to learn diverse dance patterns. In this paper, we introduce DanceChat, a Large Language Model (LLM)-guided music-to-dance generation approach. We use an LLM as a choreographer that provides textual motion instructions, offering explicit, high-level guidance for dance generation. This approach goes beyond implicit learning from music alone, enabling the model to generate dance that is both more diverse and better aligned with musical styles. Our approach consists of three components: (1) an LLM-based pseudo instruction generation module that produces textual dance guidance based on music style and structure, (2) a multi-modal feature extraction and fusion module that integrates music, rhythm, and textual guidance into a shared representation, and (3) a diffusion-based motion synthesis module together with a multi-modal alignment loss, which ensures that the generated dance is aligned with both musical and textual cues. Extensive experiments on AIST++ and human evaluations show that DanceChat outperforms state-of-the-art methods both qualitatively and quantitatively.

Paper number 72:
Title: Leveraging Low-rank Factorizations of Conditional Correlation Matrices in Graph Learning
Authors: Thu Ha Phi, Alexandre Hippert-Ferrer, Florent Bouchard, Arnaud Breloy
Abstract: This paper addresses the problem of learning an undirected graph from data gathered at each nodes. Within the graph signal processing framework, the topology of such graph can be linked to the support of the conditional correlation matrix of the data. The corresponding graph learning problem then scales to the squares of the number of variables (nodes), which is usually problematic at large dimension. To tackle this issue, we propose a graph learning framework that leverages a low-rank factorization of the conditional correlation matrix. In order to solve for the resulting optimization problems, we derive tools required to apply Riemannian optimization techniques for this particular structure. The proposal is then particularized to a low-rank constrained counterpart of the GLasso algorithm, i.e., the penalized maximum likelihood estimation of a Gaussian graphical model. Experiments on synthetic and real data evidence that a very efficient dimension-versus-performance trade-off can be achieved with this approach.

Paper number 73:
Title: Deployment of Containerized Simulations in an API-Driven Distributed Infrastructure
Authors: Tim Kraus, Axel Sauer, Ingo Feldner
Abstract: The increasingly dynamic market for embedded systems makes virtual prototypes an indispensable tool for hardware/software codesign. The broad acceptance of the methodology has led to a diverse range of solutions: from open-source, pure console-based simulators to highly capable commercial simulation tools. In this work we present SUNRISE, an infrastructure to provide users a unified approach to utilizing virtual prototyping solutions, facilitate access to various simulation technologies and boost cooperation by leveraging decentralized compute resources for deployment of simulation workloads and definition of open APIs.

Paper number 74:
Title: Large Language Models-Empowered Wireless Networks: Fundamentals, Architecture, and Challenges
Authors: Latif U. Khan, Maher Guizani, Sami Muhaidat, Choong Seon Hong
Abstract: The rapid advancement of wireless networks has resulted in numerous challenges stemming from their extensive demands for quality of service towards innovative quality of experience metrics (e.g., user-defined metrics in terms of sense of physical experience for haptics applications). In the meantime, large language models (LLMs) emerged as promising solutions for many difficult and complex applications/tasks. These lead to a notion of the integration of LLMs and wireless networks. However, this integration is challenging and needs careful attention in design. Therefore, in this article, we present a notion of rational wireless networks powered by \emph{telecom LLMs}, namely, \emph{LLM-native wireless systems}. We provide fundamentals, vision, and a case study of the distributed implementation of LLM-native wireless systems. In the case study, we propose a solution based on double deep Q-learning (DDQN) that outperforms existing DDQN solutions. Finally, we provide open challenges.

Paper number 75:
Title: Description and Discussion on DCASE 2025 Challenge Task 4: Spatial Semantic Segmentation of Sound Scenes
Authors: Masahiro Yasuda, Binh Thien Nguyen, Noboru Harada, Romain Serizel, Mayank Mishra, Marc Delcroix, Shoko Araki, Daiki Takeuchi, Daisuke Niizumi, Yasunori Ohishi, Tomohiro Nakatani, Takao Kawamura, Nobutaka Ono
Abstract: Spatial Semantic Segmentation of Sound Scenes (S5) aims to enhance technologies for sound event detection and separation from multi-channel input signals that mix multiple sound events with spatial information. This is a fundamental basis of immersive communication. The ultimate goal is to separate sound event signals with 6 Degrees of Freedom (6DoF) information into dry sound object signals and metadata about the object type (sound event class) and representing spatial information, including direction. However, because several existing challenge tasks already provide some of the subset functions, this task for this year focuses on detecting and separating sound events from multi-channel spatial input signals. This paper outlines the S5 task setting of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2025 Challenge Task 4 and the DCASE2025 Task 4 Dataset, newly recorded and curated for this task. We also report experimental results for an S5 system trained and evaluated on this dataset. The full version of this paper will be published after the challenge results are made public.

Paper number 76:
Title: Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL
Authors: Tom Westermann, Aljosha Köcher, Felix Gehlhoff
Abstract: AutomationML (AML) enables standardized data exchange in engineering, yet existing recommendations for proper AML modeling are typically formulated as informal and textual constraints. These constraints cannot be validated automatically within AML itself. This work-in-progress paper introduces a pipeline to formalize and verify such constraints. First, AML models are mapped to OWL ontologies via RML and SPARQL. In addition, a Large Language Model translates textual rules into SHACL constraints, which are then validated against the previously generated AML ontology. Finally, SHACL validation results are automatically interpreted in natural language. The approach is demonstrated on a sample AML recommendation. Results show that even complex modeling rules can be semi-automatically checked -- without requiring users to understand formal methods or ontology technologies.

Paper number 77:
Title: Towards Sustainable Computing: Exploring Energy Consumption Efficiency of Alternative Configurations and Workloads in an Open Source Messaging System
Authors: Maria Voreakou, George Kousiouris, Mara Nikolaidou
Abstract: Energy consumption in current large scale computing infrastructures is becoming a critical issue, especially with the growing demand for centralized systems such as cloud environments. With the advancement of microservice architectures and the Internet of Things, messaging systems have become an integral and mainstream part of modern computing infrastructures, carrying out significant workload in a majority of applications. In this paper, we describe an experimental process to explore energy-based benchmarking for RabbitMQ, one of the main open source messaging frameworks. The involved system is described, as well as required components, and setup scenarios, involving different workloads and configurations among the tests as well as messaging system use cases. Alternative architectures are investigated and compared from an energy consumption point of view, for different message rates and consumer numbers. Differences in architectural selection have been quantified and can lead to up to 31\% reduction in power consumption. The resulting dataset is made publicly available and can thus prove helpful for architectures' comparison, energy-based cost modeling, and beyond.

Paper number 78:
Title: Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection
Authors: Emílio Dolgener Cantú, Rolf Klemens Wittmann, Oliver Abdeen, Patrick Wagner, Wojciech Samek, Moritz Baier, Sebastian Lapuschkin
Abstract: Quality management in semiconductor manufacturing often relies on template matching with known golden standards. For Indium-Phosphide (InP) multi-project wafer manufacturing, low production scale and high design variability lead to such golden standards being typically unavailable. Defect detection, in turn, is manual and labor-intensive. This work addresses this challenge by proposing a methodology to generate a synthetic golden standard using Deep Neural Networks, trained to simulate photo-realistic InP wafer images from CAD data. We evaluate various training objectives and assess the quality of the simulated images on both synthetic data and InP wafer photographs. Our deep-learning-based method outperforms a baseline decision-tree-based approach, enabling the use of a 'simulated golden die' from CAD plans in any user-defined region of a wafer for more efficient defect detection. We apply our method to a template matching procedure, to demonstrate its practical utility in surface defect detection.

Paper number 79:
Title: Anomaly Detection for Sensing Security
Authors: Stefan Roth, Aydin Sezgin
Abstract: Various approaches in the field of physical layer security involve anomaly detection, such as physical layer authentication, sensing attacks, and anti-tampering solutions. Depending on the context in which these approaches are applied, anomaly detection needs to be computationally lightweight, resilient to changes in temperature and environment, and robust against phase noise. We adapt moving average filters, autoregression filters and Kalman filters to provide predictions of feature vectors that fulfill the above criteria. Different hypothesis test designs are employed that allow omnidirectional and unidirectional outlier detection. In a case study, a sensing attack is investigated that employs the described algorithms with various channel features based on commodity WiFi devices. Thereby, various combinations of algorithms and channel features show effectiveness for motion detection by an attacker. Countermeasures only utilizing transmit power randomization are shown insufficient to mitigate such attacks if the attacker has access to channel state information (CSI) measurements, suggesting that mitigation solutions might require frequency-variant randomization.

Paper number 80:
Title: BNMusic: Blending Environmental Noises into Personalized Music
Authors: Chi Zuo, Martin B. Møller, Pablo Martínez-Nuevo, Huayang Huang, Yu Wu, Ye Zhu
Abstract: While being disturbed by environmental noises, the acoustic masking technique is a conventional way to reduce the annoyance in audio engineering that seeks to cover up the noises with other dominant yet less intrusive sounds. However, misalignment between the dominant sound and the noise-such as mismatched downbeats-often requires an excessive volume increase to achieve effective masking. Motivated by recent advances in cross-modal generation, in this work, we introduce an alternative method to acoustic masking, aiming to reduce the noticeability of environmental noises by blending them into personalized music generated based on user-provided text prompts. Following the paradigm of music generation using mel-spectrogram representations, we propose a Blending Noises into Personalized Music (BNMusic) framework with two key stages. The first stage synthesizes a complete piece of music in a mel-spectrogram representation that encapsulates the musical essence of the noise. In the second stage, we adaptively amplify the generated music segment to further reduce noise perception and enhance the blending effectiveness, while preserving auditory quality. Our experiments with comprehensive evaluations on MusicBench, EPIC-SOUNDS, and ESC-50 demonstrate the effectiveness of our framework, highlighting the ability to blend environmental noise with rhythmically aligned, adaptively amplified, and enjoyable music segments, minimizing the noticeability of the noise, thereby improving overall acoustic experiences.

Paper number 81:
Title: Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing
Authors: Hang Zhang, Xiang Chen, Renjiu Hu, Rongguang Wang, Jinwei Zhang, Min Liu, Yaonan Wang, Gaolei Li, Xinxing Cheng, Jinming Duan
Abstract: Learning-based deformable image registration (DIR) accelerates alignment by amortizing traditional optimization via neural networks. Label supervision further enhances accuracy, enabling efficient and precise nonlinear alignment of unseen scans. However, images with sparse features amid large smooth regions, such as retinal vessels, introduce aperture and large-displacement challenges that unsupervised DIR methods struggle to address. This limitation occurs because neural networks predict deformation fields in a single forward pass, leaving fields unconstrained post-training and shifting the regularization burden entirely to network weights. To address these issues, we introduce SmoothProper, a plug-and-play neural module enforcing smoothness and promoting message passing within the network's forward pass. By integrating a duality-based optimization layer with tailored interaction terms, SmoothProper efficiently propagates flow signals across spatial locations, enforces smoothness, and preserves structural consistency. It is model-agnostic, seamlessly integrates into existing registration frameworks with minimal parameter overhead, and eliminates regularizer hyperparameter tuning. Preliminary results on a retinal vessel dataset exhibiting aperture and large-displacement challenges demonstrate our method reduces registration error to 1.88 pixels on 2912x2912 images, marking the first unsupervised DIR approach to effectively address both challenges. The source code will be available at this https URL.

Paper number 82:
Title: Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models
Authors: Michele Gubian, Ioana Krehan, Oli Liu, James Kirby, Sharon Goldwater
Abstract: Analyses of self-supervised speech models have begun to reveal where and how they represent different types of information. However, almost all analyses have focused on English. Here, we examine how wav2vec2 models trained on four different languages encode both language-matched and non-matched speech. We use probing classifiers and geometric analyses to examine how phones, lexical tones, and speaker information are represented. We show that for all pretraining and test languages, the subspaces encoding phones, tones, and speakers are largely orthogonal, and that layerwise patterns of probing accuracy are similar, with a relatively small advantage for matched-language phone and tone (but not speaker) probes in the later layers. Our findings suggest that the structure of representations learned by wav2vec2 is largely independent of the speech material used during pretraining.

Paper number 83:
Title: Higher-Order Uncoupled Learning Dynamics and Nash Equilibrium
Authors: Sarah A. Toonsi, Jeff S. Shamma
Abstract: We study learnability of mixed-strategy Nash Equilibrium (NE) in general finite games using higher-order replicator dynamics as well as classes of higher-order uncoupled heterogeneous dynamics. In higher-order uncoupled learning dynamics, players have no access to utilities of opponents (uncoupled) but are allowed to use auxiliary states to further process information (higher-order). We establish a link between uncoupled learning and feedback stabilization with decentralized control. Using this association, we show that for any finite game with an isolated completely mixed-strategy NE, there exist higher-order uncoupled learning dynamics that lead (locally) to that NE. We further establish the lack of universality of learning dynamics by linking learning to the control theoretic concept of simultaneous stabilization. We construct two games such that any higher-order dynamics that learn the completely mixed-strategy NE of one of these games can never learn the completely mixed-strategy NE of the other. Next, motivated by imposing natural restrictions on allowable learning dynamics, we introduce the Asymptotic Best Response (ABR) property. Dynamics with the ABR property asymptotically learn a best response in environments that are asymptotically stationary. We show that the ABR property relates to an internal stability condition on higher-order learning dynamics. We provide conditions under which NE are compatible with the ABR property. Finally, we address learnability of mixed-strategy NE in the bandit setting using a bandit version of higher-order replicator dynamics.

Paper number 84:
Title: Dynamic Beyond 5G and 6G Connectivity: Leveraging NTN and RIS Synergies for Optimized Coverage and Capacity in High-Density Environments
Authors: Valdemar Farré, Juan Estrada, David Vega, Luis F Urquiza-Aguiar, Juan A. Vásquez Peralvo, Symeon Chatzinotas
Abstract: The increasing demand for reliable, high-capacity communication during large-scale outdoor events poses significant challenges for traditional Terrestrial Networks (TNs), which often struggle to provide consistent coverage in high-density environments. This paper presents a novel 6G radio network planning framework that integrates Non-Terrestrial Networks (NTNs) with Reconfigurable Intelligent Surfaces (RISs) to deliver ubiquitous coverage and enhanced network capacity. Our framework overcomes the limitations of conventional deployable base stations by leveraging NTN architectures, including Low Earth Orbit (LEO) satellites and passive RIS platforms seamlessly integrated with Beyond 5G (B5G) TNs. By incorporating advanced B5G technologies such as Massive Multiple Input Multiple Output (mMIMO) and beamforming, and by optimizing spectrum utilization across the C, S, and Ka bands, we implement a rigorous interference management strategy based on a dynamic SINR model. Comprehensive calculations and simulations validate the proposed framework, demonstrating significant improvements in connectivity, reliability, and cost-efficiency in crowded scenarios. This integration strategy represents a promising solution for meeting the evolving demands of future 6G networks.

Paper number 85:
Title: Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence
Authors: Eduardo Baena, Paolo Testolina, Michele Polese, Sergi Aliaga, Andrew Benincasa, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia
Abstract: Lunar surface operations impose stringent requirements on wireless communication systems, including autonomy, robustness to disruption, and the ability to adapt to environmental and mission-driven context. While Space-O-RAN provides a distributed orchestration model aligned with 3GPP standards, its decision logic is limited to static policies and lacks semantic integration. We propose a novel extension incorporating a semantic agentic layer enabled by the Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication protocols, allowing context-aware decision making across real-time, near-real-time, and non-real-time control layers. Distributed cognitive agents deployed in rovers, landers, and lunar base stations implement wireless-aware coordination strategies, including delay-adaptive reasoning and bandwidth-aware semantic compression, while interacting with multiple MCP servers to reason over telemetry, locomotion planning, and mission constraints.

Paper number 86:
Title: A Stochastic Hybrid Approach to Decentralized Networked Control: Stochastic Network Delays and Poisson Pulsing Attacks
Authors: Dandan Zhang, Xin Jin, Hongye Su
Abstract: By designing the decentralized time-regularized (Zeno-free) event-triggered strategies for the state-feedback control law, this paper considers the stochastic stabilization of a class of networked control systems, where two sources of randomness exist in multiple decentralized networks that operate asynchronously and independently: the communication channels are constrained by the stochastic network delays and also by Poisson pulsing denial-of-service (Pp-DoS) attacks. The time delay in the network denotes the length from a transmission instant to the corresponding update instant, and is supposed to be a continuous random variable subject to certain continuous probability distribution; while the attacks' cardinal number is a discrete random variable supposed to be subject to Poisson distribution, so the inter-attack time, i.e., the time between two consecutive attack instants, is subject to exponential distribution. The considered system is modeled as a stochastic hybrid formalism, where the randomness enters through the jump map into the reset value (the inter-attack time directly related) of each triggered strategy. By only sampling/transmitting state measurements when needed and simultaneously by taking the specific medium access protocols into account, the designed event-triggered strategies are synthesized in a state-based and decentralized form, which are robust (tolerable well) to stochastic network delays, under different tradeoff-conditions between the minimum inter-event times, maximum allowable delays (i.e., potentially tolerable delays) and the frequencies of attacks. Using stochastic hybrid tools to combine attack-active parts with attack-over parts, the designed triggered strategies, if designed well according to the actual system needs, can tolerate (be resilient to) the Pp-DoS attacks and stochastic network delays without jeopardizing the stability and Zeno-freeness.

Paper number 87:
Title: Quasiperiodic Disturbance Observer for Wideband Harmonic Suppression
Authors: Hisayoshi Muramatsu
Abstract: Periodic disturbances composed of harmonics typically occur during periodic operations, impairing performance of mechanical and electrical systems. To improve the performance, control of periodic-disturbance suppression has been studied, such as repetitive control and periodic-disturbance observers. However, actual periodic disturbances are typically quasiperiodic owing to perturbations in each cycle, identification errors of the period, variations in the period, and/or aperiodic disturbances. For robustness against quasiperiodicity, although wideband harmonic suppression is expected, conventional methods have trade-offs among harmonic suppression bandwidth, amplification of aperiodic disturbances, and deviation of harmonic suppression frequencies. This paper proposes a quasiperiodic disturbance observer to compensate for quasiperiodic disturbances while simultaneously achieving the wideband harmonic suppression, non-amplification of aperiodic disturbances, and proper harmonic suppression frequencies. A quasiperiodic disturbance is defined as comprising harmonics and surrounding signals. On the basis of this definition, the quasiperiodic disturbance observer is designed using a periodic-pass filter of a first-order periodic/aperiodic separation filter for its Q-filter, time delay integrated with a zero-phase low-pass filter, and an inverse plant model with a first-order low-pass filter. The periodic-pass filter achieves the wideband harmonic suppression while the zero-phase and first-order low-pass filters prevent the amplification of aperiodic disturbances and deviation of harmonic suppression frequencies. For the implementation, the Q-filter is discretized by an exact mapping of the s-plane to the z-plane, and the inverse plant model is discretized by the backward Euler method.

Paper number 88:
Title: On Secret-Message Transmission by Echoing Encrypted Probes
Authors: Yingbo Hua
Abstract: A scheme for secure communications, called ``Secret-message Transmission by Echoing Encrypted Probes (STEEP)'', is revisited. STEEP is a round-trip scheme with a probing phase from one user to another and an echoing phase in the reverse direction. STEEP is shown to be broadly applicable to yield a positive secrecy rate in bits per channel use even if the receive channels at eavesdropper (Eve) are stronger than those between legitimate users in both forward and reverse directions. This paper focuses on STEEP in the following settings: using Gaussian probing signal and Gaussian linear encryption over MIMO Gaussian channel (G-STEEP); using phase-shift-keying probing signal and a nonlinear encryption over SISO channel (P-STEEP); and a variation of G-STEEP for multiple access communication (M-STEEP). In each of the settings, Eve is assumed to have any given number of antennas, and STEEP is shown to yield a positive secrecy rate subject to a sufficiently large power in the echoing phase, as long as Eve's receive channel in the probing phase is not noiseless. It is also shown that G-STEEP, subject to asymmetric large powers in forward and reverse directions, has its secrecy rate approaching the secret-key capacity based on Gaussian probing signal over MIMO Gaussian channel. STEEP does not require secure feedback channel, collaborative third party, in-band full-duplex or reciprocal channels between users, but only needs a design for echoing encrypted probes, asymmetric power allocation and/or collaborative round-trip coding.

Paper number 89:
Title: Constraint-Driven Multi-USV Coverage Path Generation for Aquatic Environmental Monitoring
Authors: Yo Toyomoto, Toshiyuki Oshima, Kosei Oishi, José M. Maestre, Takeshi Hatanaka
Abstract: In this article, we address aquatic environmental monitoring using a fleet of unmanned surface vehicles (USVs). Specifically, we develop an online path generator that provides either circular or elliptic paths based on the real-time feedback so that the USVs efficiently sample the sensor data over given aquatic environment. To this end, we begin by formulating a novel online path generation problem for a group of Dubins vehicles in the form of cost minimization based on the formulation of persistent coverage control. We then transform the cost minimization into a constraint-based specification so that a prescribed performance level is certified. An online coverage path generator is then designed based on the so-called constraint-based control in order to meet the performance certificate together with additional constraints inherent in the parameters that specify the paths. It is also shown there that the present constraint-based approach allows one to drastically reduce the computational complexity stemming from combinations of binary variables corresponding to the turning directions of the USVs. The present coverage path generator is finally demonstrated through simulations and experiments on an original testbed of multiple USVs.

Paper number 90:
Title: Towards Clinical Practice in CT-Based Pulmonary Disease Screening: An Efficient and Reliable Framework
Authors: Qian Shao, Bang Du, Kai Zhang, Yixuan Wu, Zepeng Li, Qiyuan Chen, Qianqian Tang, Jian Wu, Jintai Chen, Honghao Gao, Hongxia Xu
Abstract: Deep learning models for pulmonary disease screening from Computed Tomography (CT) scans promise to alleviate the immense workload on radiologists. Still, their high computational cost, stemming from processing entire 3D volumes, remains a major barrier to widespread clinical adoption. Current sub-sampling techniques often compromise diagnostic integrity by introducing artifacts or discarding critical information. To overcome these limitations, we propose an Efficient and Reliable Framework (ERF) that fundamentally improves the practicality of automated CT analysis. Our framework introduces two core innovations: (1) A Cluster-based Sub-Sampling (CSS) method that efficiently selects a compact yet comprehensive subset of CT slices by optimizing for both representativeness and diversity. By integrating an efficient k-Nearest Neighbor (k-NN) search with an iterative refinement process, CSS bypasses the computational bottlenecks of previous methods while preserving vital diagnostic features. (2) A lightweight Hybrid Uncertainty Quantification (HUQ) mechanism, which uniquely assesses both Aleatoric Uncertainty (AU) and Epistemic Uncertainty (EU) with minimal computational overhead. By maximizing the discrepancy between auxiliary classifiers, HUQ provides a robust reliability score, which is crucial for building trust in automated systems operating on partial data. Validated on two public datasets with 2,654 CT volumes across diagnostic tasks for 3 pulmonary diseases, our proposed ERF achieves diagnostic performance comparable to the full-volume analysis (over 90% accuracy and recall) while reducing processing time by more than 60%. This work represents a significant step towards deploying fast, accurate, and trustworthy AI-powered screening tools in time-sensitive clinical settings.

Paper number 91:
Title: Simulation-based Approach for Fast Optimal Control of a Stefan Problem with Application to Cell Therapy
Authors: Prakitr Srisuma, George Barbastathis, Richard D. Braatz
Abstract: This article describes a new, efficient way of finding control and state trajectories in optimal control problems by reformulation as a system of differential-algebraic equations (DAEs). The optimal control and state vectors can be obtained via simulation of the resulting DAE system with the selected DAE solver, eliminating the need for an optimization solver. Our simulation-based approach is demonstrated and benchmarked against various optimization-based algorithms via four case studies associated with the optimization and control of a Stefan problem for cell therapy. The simulation-based approach is faster than every optimization-based method by more than an order of magnitude while giving similar/better accuracy in all cases. The solution obtained from the simulation-based approach is guaranteed to be optimal provided that at least one constraint or algebraic equation resulting from the reformulation remains active at all times. The proposed technique offers an efficient and reliable framework for optimal control, serving as a promising alternative to the traditional techniques in applications where speed is crucial, e.g., real-time online model predictive control.

Paper number 92:
Title: Battery State of Health Estimation and Incremental Capacity Analysis under General Charging Profiles Using Neural Networks
Authors: Qinan Zhou, Gabrielle Vuylsteke, R. Dyche Anderson, Jing Sun
Abstract: Incremental capacity analysis (ICA) and differential voltage analysis (DVA) are two effective approaches for battery degradation monitoring. One limiting factor for their real-world application is that they require constant-current charging profiles. This research removes this limitation and proposes an approach that enables ICA/DVA-based degradation monitoring under general charging profiles. A novel concept of virtual incremental capacity (VIC) and virtual differential voltage (VDV) is proposed. Then, two related convolutional neural networks (CNNs), called U-Net and Conv-Net, are proposed to construct VIC/VDV curves and estimate the state of health (SOH) from general charging profiles across any state-of-charge (SOC) ranges that satisfy some constraints. Finally, for onboard implementations, two CNNs called Mobile U-Net and Mobile-Net are proposed as replacements for the U-Net and Conv-Net, respectively, to reduce the computational footprint and memory requirements. Using an extensive experimental dataset of battery modules, the proposed CNNs are demonstrated to provide accurate VIC/VDV curves and enable ICA/DVA-based battery degradation monitoring under various fast-charging protocols and different SOC ranges.

Paper number 93:
Title: WiFi-Diffusion: Achieving Fine-Grained WiFi Radio Map Estimation With Ultra-Low Sampling Rate by Diffusion Models
Authors: Zhiyuan Liu, Shuhang Zhang, Qingyu Liu, Hongliang Zhang, Lingyang Song
Abstract: Fine-grained radio map presents communication parameters of interest, e.g., received signal strength, at every point across a large geographical region. It can be leveraged to improve the efficiency of spectrum utilization for a large area, particularly critical for the unlicensed WiFi spectrum. The problem of fine-grained radio map estimation is to utilize radio samples collected by sparsely distributed sensors to infer the map. This problem is challenging due to the ultra-low sampling rate, where the number of available samples is far less than the fine-grained resolution required for radio map estimation. We propose WiFi-Diffusion -- a novel generative framework for achieving fine-grained WiFi radio map estimation using diffusion models. WiFi-Diffusion employs the creative power of generative AI to address the ultra-low sampling rate challenge and consists of three blocks: 1) a boost block, using prior information such as the layout of obstacles to optimize the diffusion model; 2) a generation block, leveraging the diffusion model to generate a candidate set of radio maps; and 3) an election block, utilizing the radio propagation model as a guide to find the best radio map from the candidate set. Extensive simulations demonstrate that 1) the fine-grained radio map generated by WiFi-Diffusion is ten times better than those produced by state-of-the-art (SOTA) when they use the same ultra-low sampling rate; and 2) WiFi-Diffusion achieves comparable fine-grained radio map quality with only one-fifth of the sampling rate required by SOTA.

Paper number 94:
Title: Long-Range Rendezvous and Docking Maneuver Control of Satellite using Cross-Feedback Sliding Mode Controller
Authors: Vedant Vivek Kini, Dantu Phani Surya, Rakesh Kumar Sahoo, Manoranjan Sinha
Abstract: Satellite rendezvous and docking (RvD) maneuvers are essential for satellite servicing and in-orbit assembly. Traditional approaches often treat translational and rotational motions independently, simplifying control design but potentially leading to inefficiencies in maneuver time and fuel consumption. To address these challenges, a novel cross-feedback sliding mode controller has been proposed, developing an interdependent regulation system for translational and rotational motion. This method decouples the relative translational and rotational motion of chaser satellite with respect to target satellite while incorporating cross-feedback mechanisms to account for their inherent coupling. By incorporating rotational state information into translational control laws and vice versa, the approach ensures coordinated adjustments, enhancing maneuver efficiency. The chaser satellite manages both translational and rotational adjustments to rendezvous and dock with the target satellite. The stability of the cross-feedback sliding mode controller is established within the Lyapunov framework, and simulation results substantiate the effectiveness of this strategy.

Paper number 95:
Title: A Quadratic Programming Approach to Flight Envelope Protection Using Control Barrier Functions
Authors: Johannes Autenrieb
Abstract: Ensuring the safe operation of aerospace systems within their prescribed flight envelope is a fundamental requirement for modern flight control systems. Flight envelope protection prevents violations of aerodynamic, structural, and performance constraints, mitigating risks such as stall, excessive loads, and loss of control. Conventional FEP approaches, such as reference clipping via saturation functions and model-based command filtering, impose constraints at the reference input level but often fail to account for closed-loop system dynamics, potentially leading to constraint violations during transients. This paper introduces a new approach to the flight envelope protection problem by employing a quadratic programming-based safety filter using control barrier functions to dynamically enforce flight envelope constraints while preserving control performance. Unlike traditional reference filtering methods, the control barrier function-based safety filter actively ensures strict forward invariance of the safe flight envelope set, integrating seamlessly with existing control architectures. The proposed framework is implemented in a nonlinear missile flight control system and evaluated in a simulated environment. The results demonstrate its ability to prevent constraint violations while minimizing conservatism, offering a robust alternative to existing flight envelope protection methodologies.

Paper number 96:
Title: Day-Ahead Bidding Strategies for Wind Farm Operators under a One-Price Balancing Scheme
Authors: Max Bruninx, Timothy Verstraeten, Jalal Kazempour, Jan Helsen
Abstract: We study day-ahead bidding strategies for wind farm operators under a one-price balancing scheme, prevalent in European electricity markets. In this setting, the profit-maximising strategy becomes an all-or-nothing strategy, aiming to take advantage of open positions in the balancing market. However, balancing prices are difficult, if not impossible, to forecast in the day-ahead stage and large open positions can affect the balancing price by changing the direction of the system imbalance. This paper addresses day-ahead bidding as a decision-making problem under uncertainty, with the objective of maximising the expected profit while reducing the imbalance risk related to the strategy. To this end, we develop a stochastic optimisation problem with explicit constraints on the positions in the balancing market, providing risk certificates, and derive an analytical solution to this problem. Moreover, we show how the price-impact of the trading strategy on the balancing market can be included in the ex-post evaluation. Using real data from the Belgian electricity market and an offshore wind farm in the North Sea, we demonstrate that the all-or-nothing strategy negatively impacts the balancing price, resulting in long-term losses for the wind farm. Our risk-constrained strategy, however, can still significantly enhance operational profit compared to traditional point-forecast bidding.

Paper number 97:
Title: Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning
Authors: Dang Thoai Phan, Tuan Anh Huynh, Van Tuan Pham, Cao Minh Tran, Van Thuan Mai, Ngoc Quy Tran
Abstract: The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.

Paper number 98:
Title: Synergising Hierarchical Data Centers and Power Networks: A Privacy-Preserving Approach
Authors: Junhong Liu, Fei Teng, Yunhe Hou
Abstract: In the era of digitization, data centers have emerged as integral contributors sustaining our interlinked world, bearing responsibility for an increasing proportion of the world's energy consumption. To facilitate the their fast rollout while progressing towards net-zero energy systems, the synergy of hierarchical data centers (cloud-fog-edge) and power networks can play a pivotal role. However, existing centralized co-dispatch manners encroach on the privacy of different agents within the integrated systems, meanwhile suffering from the combinatorial explosion. In this research, we propose a near-optimal distributed privacy-preserving approach to solve the non-convex synergy (day-ahead co-dispatch) problem. The synergy problem is formulated as a mixed integer quadratically constrained quadratic programming considering both communication and energy conservation, where Lyapunov optimization is introduced to balance operating costs and uncertain communication delays. To mitigate impacts of the highly non-convex nature, the normalized multi-parametric disaggregation technique is leveraged to reformulate the problem into a mixed integer non-linear programming. To further overcome non-smoothness of the reformulated problem, the customized $\ell_1-$surrogate Lagrangian relaxation method with convergence guarantees is proposed to solve the problem in a distributed privacy-preserving manner. The effectiveness, optimality, and scalability of the proposed methodologies for the synergy problem are validated via numerical simulations. Simulation results also indicate that computing tasks can be delayed and migrated within the hierarchical data centers, demonstrating the flexible resource allocation capabilities of the hierarchical data center architecture, further facilitating peak load balancing in the power network.

Paper number 99:
Title: Computationally Efficient Analytical Models of Frequency and Voltage in Low-Inertia Systems
Authors: Marena Trujillo, Amir Sajadi, Jonathan Shaw, Bri-Mathias Hodge
Abstract: In this paper, low-order models of the frequency and voltage response of mixed-generation, low-inertia systems are presented. These models are unique in their ability to efficiently and accurately model frequency and voltage dynamics without increasing the computational burden as the share of inverters is increased in a system. The models are validated against industry-grade electromagnetic transient simulation, compared to which the proposed models are several orders of magnitude faster. The accuracy and efficiency of the low-inertia frequency and voltage models makes them well suited for a variety of planning and operational studies, especially for multi-scenario and probabilistic studies, as well as for screening studies to establish impact zones based on the dynamic interactions between inverters and synchronous generators.

Paper number 100:
Title: EAST: Environment Aware Safe Tracking using Planning and Control Co-Design
Authors: Zhichao Li, Yinzhuang Yi, Zhuolin Niu, Nikolay Atanasov
Abstract: This paper considers the problem of autonomous mobile robot navigation in unknown environments with moving obstacles. We propose a new method to achieve environment-aware safe tracking (EAST) of robot motion plans that integrates an obstacle clearance cost for path planning, a convex reachable set for robot motion prediction, and safety constraints for dynamic obstacle avoidance. EAST adapts the motion of the robot according to the locally sensed environment geometry and dynamics, leading to fast motion in wide open areas and cautious behavior in narrow passages or near moving obstacles. Our control design uses a reference governor, a virtual dynamical system that guides the robot's motion and decouples the path tracking and safety objectives. While reference governor methods have been used for safe tracking control in static environments, our key contribution is an extension to dynamic environments using convex optimization with control barrier function (CBF) constraints. Thus, our work establishes a connection between reference governor techniques and CBF techniques for safe control in dynamic environments. We validate our approach in simulated and real-world environments, featuring complex obstacle configurations and natural dynamic obstacle motion.

Paper number 101:
Title: Glimpse: Generalized Locality for Scalable and Robust CT
Authors: AmirEhsan Khorashadizadeh, Valentin Debarnot, Tianlin Liu, Ivan Dokmanić
Abstract: Deep learning has become the state-of-the-art approach to medical tomographic imaging. A common approach is to feed the result of a simple inversion, for example the backprojection, to a multiscale convolutional neural network (CNN) which computes the final reconstruction. Despite good results on in-distribution test data, this often results in overfitting certain large-scale structures and poor generalization on out-of-distribution (OOD) samples. Moreover, the memory and computational complexity of multiscale CNNs scale unfavorably with image resolution, making them impractical for application at realistic clinical resolutions. In this paper, we introduce Glimpse, a local coordinate-based neural network for computed tomography which reconstructs a pixel value by processing only the measurements associated with the neighborhood of the pixel. Glimpse significantly outperforms successful CNNs on OOD samples, while achieving comparable or better performance on in-distribution test data and maintaining a memory footprint almost independent of image resolution; 5GB memory suffices to train on 1024x1024 images which is orders of magnitude less than CNNs. Glimpse is fully differentiable and can be used plug-and-play in arbitrary deep learning architectures, enabling feats such as correcting miscalibrated projection orientations. Our implementation and Google Colab demo can be accessed at this https URL.

Paper number 102:
Title: SLS-BRD: A system-level approach to seeking generalised feedback Nash equilibria
Authors: Otacilio B. L. Neto, Michela Mulas, Francesco Corona
Abstract: This work proposes a policy learning algorithm for seeking generalised feedback Nash equilibria (GFNE) in $N_P$-player noncooperative dynamic games. We consider linear-quadratic games with stochastic dynamics and design a best-response dynamics in which players update and broadcast a parametrisation of their state-feedback policies. Our approach leverages the System Level Synthesis (SLS) framework to formulate each player's update rule as the solution to a robust optimisation problem. Under certain conditions, rates of convergence to a feedback Nash equilibrium can be established. The algorithm is showcased in exemplary problems ranging from the decentralised control of unstable systems to competition in oligopolistic markets.

Paper number 103:
Title: Network-level ISAC: An Analytical Study of Antenna Topologies Ranging from Massive to Cell-Free MIMO
Authors: Kaitao Meng, Kawon Han, Christos Masouros, Lajos Hanzo
Abstract: A cooperative architecture is proposed for integrated sensing and communication (ISAC) networks, incorporating coordinated multi-point (CoMP) transmission along with multi-static sensing. We investigate how the allocation of antennas-to-base stations (BSs) affects cooperative sensing and cooperative communication performance. More explicitly, we balance the benefits of geographically concentrated antennas in the massive multiple input multiple output (MIMO) fashion, which enhance beamforming and coherent processing, against those of geographically distributed antennas towards cell-free transmission, which improve diversity and reduce service distances. Regarding sensing performance, we investigate three localization methods: angle-of-arrival (AOA)-based, time-of-flight (TOF)-based, and a hybrid approach combining both AOA and TOF measurements, for critically appraising their effects on ISAC network performance. Our analysis shows that in networks having N ISAC nodes following a Poisson point process, the localization accuracy of TOF-based methods follows a \ln^2 N scaling law (explicitly, the Cramer-Rao lower bound (CRLB) reduces with \ln^2 N). The AOA-based methods follow a \ln N scaling law, while the hybrid methods scale as a\ln^2 N + b\ln N, where a and b represent parameters related to TOF and AOA measurements, respectively. The difference between these scaling laws arises from the distinct ways in which measurement results are converted into the target location. Specifically, when converting AOA measurements to the target location, the localization error introduced during this conversion is inversely proportional to the distance between the BS and the target, leading to a more significant reduction in accuracy as the number of transceivers increases.

Paper number 104:
Title: A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends
Authors: Junjun Jiang, Zengyuan Zuo, Gang Wu, Kui Jiang, Xianming Liu
Abstract: Image restoration (IR) aims to recover high-quality images from inputs degraded by various factors such as noise, blur, compression, and adverse weather. Traditional IR methods typically focus on specific types of degradation, which limits their effectiveness in real-world scenarios with complex distortions. In response to this challenge, the all-in-one image restoration (AiOIR) paradigm has recently emerged, offering a unified framework that adeptly addresses multiple degradation types. These innovative models enhance convenience and versatility by adaptively learning degradation-specific features while simultaneously leveraging shared knowledge across diverse corruptions. In this survey, we present the first comprehensive overview of AiOIR, offering a taxonomy that organizes existing methods by architecture innovations, learning strategies, and key improvements. We systematically categorize prevailing approaches and critically assess the challenges these models encounter, proposing future research directions to propel this rapidly evolving field. Our survey begins with an introduction to the foundational concepts of AiOIR models, followed by a categorization of typical scenarios. We then highlight key architectural and algorithmic advances in AiOIR, aiming to inspire continued innovation. To facilitate rigorous evaluation of existing methods, we collate and summarize established datasets, evaluation metrics, and common experimental settings. Finally, we present an objective comparison of open-sourced methods, providing valuable insights for researchers and practitioners. This paper stands as the first comprehensive and insightful review of all-in-one image restoration. A related repository is available at this https URL.

Paper number 105:
Title: Data-Driven LQR with Finite-Time Experiments via Extremum-Seeking Policy Iteration
Authors: Guido Carnevale, Nicola Mimmo, Giuseppe Notarstefano
Abstract: In this paper, we address Linear Quadratic Regulator (LQR) problems through a novel iterative algorithm named EXtremum-seeking Policy iteration LQR (EXP-LQR). The peculiarity of EXP-LQR is that it only needs access to a truncated approximation of the infinite-horizon cost associated to a given policy. Hence, EXP-LQR does not need the direct knowledge of neither the system and cost matrices. In particular, at each iteration, EXP-LQR refines the maintained policy using a truncated LQR cost retrieved by performing finite-time virtual or real experiments in which a perturbed version of the current policy is employed. Such a perturbation is done according to an extremum-seeking mechanism and makes the overall algorithm a time-varying nonlinear system. By using a Lyapunov-based approach exploiting averaging theory, we show that EXP-LQR exponentially converges to an arbitrarily small neighborhood of the optimal gain matrix. We corroborate the theoretical results with numerical simulations involving the control of an induction motor.

Paper number 106:
Title: A convex variational principle for the necessary conditions of classical optimal control
Authors: Amit Acharya, Janusz Ginster
Abstract: A scheme for generating a family of convex variational principles is developed, the Euler- Lagrange equations of each member of the family formally corresponding to the necessary conditions of optimal control of a given system of ordinary differential equations (ODE) in a well-defined sense. The scheme is applied to the Quadratic-Quadratic Regulator problem for which an explicit form of the functional is derived, and existence of minimizers of the variational principle is rigorously shown. It is shown that the Linear-Quadratic Regulator problem with time-dependent forcing can be solved within the formalism without requiring any nonlinear considerations, in contrast to the use of a Riccati system in the classical methodology. Our work demonstrates a pathway for solving nonlinear control problems via convex optimization.

Paper number 107:
Title: Safety-Ensured Robotic Control Framework for Cutting Task Automation in Endoscopic Submucosal Dissection
Authors: Yitaek Kim, Iñigo Iturrate, Christoffer Sloth, Hansoul Kim
Abstract: There is growing interest in automating surgical tasks using robotic systems, such as endoscopy for treating gastrointestinal (GI) cancer. However, previous studies have primarily focused on detecting and analyzing objects or robots, with limited attention to ensuring safety, which is critical for clinical applications, where accidents can be caused by unsafe robot motions. In this study, we propose a new control framework that can formally ensure the safety of automating the cutting task in endoscopic submucosal dissection (ESD), a representative endoscopic surgical method for the treatment of early GI cancer, by using an endoscopic robot. The proposed framework utilizes Control Barrier Functions (CBFs) to accurately identify the boundaries of individual tumors, even in close proximity within the GI tract, ensuring precise treatment and removal while preserving the surrounding normal tissue. Additionally, by adopting a model-free control scheme, safety assurance is made possible even in endoscopic robotic systems where dynamic modeling is challenging. We demonstrate the proposed framework in a simulation-based experimental environment, where the tumors to be removed are close to each other, and show that the safety constraints are enforced. We show that the model-free CBF-based controlled robot eliminates one tumor completely without damaging it, while not invading another nearby tumor.

Paper number 108:
Title: Exploring Performance-Complexity Trade-Offs in Sound Event Detection Models
Authors: Tobias Morocutti, Florian Schmid, Jonathan Greif, Francesco Foscarin, Gerhard Widmer
Abstract: We target the problem of developing new low-complexity networks for the sound event detection task. Our goal is to meticulously analyze the performance-complexity trade-off, aiming to be competitive with the large state-of-the-art models, at a fraction of the computational requirements. We find that low-complexity convolutional models previously proposed for audio tagging can be effectively adapted for event detection (which requires frame-wise prediction) by adjusting convolutional strides, removing the global pooling, and, importantly, adding a sequence model before the (now frame-wise) classification heads. Systematic experiments reveal that the best choice for the sequence model type depends on which complexity metric is most important for the given application. We also investigate the impact of enhanced training strategies such as knowledge distillation. In the end, we show that combined with an optimized training strategy, we can reach event detection performance comparable to state-of-the-art transformers while requiring only around 5% of the parameters. We release all our pre-trained models and the code for reproducing this work to support future research in low-complexity sound event detection at this https URL.

Paper number 109:
Title: Content ARCs: Decentralized Content Rights in the Age of Generative AI
Authors: Kar Balan, Andrew Gilbert, John Collomosse
Abstract: The rise of Generative AI (GenAI) has sparked significant debate over balancing the interests of creative rightsholders and AI developers. As GenAI models are trained on vast datasets that often include copyrighted material, questions around fair compensation and proper attribution have become increasingly urgent. To address these challenges, this paper proposes a framework called Content ARCs (Authenticity, Rights, Compensation). By combining open standards for provenance and dynamic licensing with data attribution, and decentralized technologies, Content ARCs create a mechanism for managing rights and compensating creators for using their work in AI training. We characterize several nascent works in the AI data licensing space within Content ARCs and identify where challenges remain to fully implement the end-to-end framework.

Paper number 110:
Title: Solving Power System Problems using Adiabatic Quantum Computing
Authors: Zeynab Kaseb, Matthias Moller, Peter Palensky, Pedro P. Vergara
Abstract: This paper proposes a novel combinatorial optimization framework that reformulates existing power system problems into a format executable on quantum annealers. The proposed framework accommodates both normal and complex numbers and enables efficient handling of large-scale problems, thus ensuring broad applicability across power system problems. As a proof of concept, we demonstrate its applicability in two classical problems: (i) power system parameter identification, where we estimate the admittance matrix given voltage and current measurements, and (ii) power flow analysis, where we reformulate the nonlinear equations governing active and reactive power balance. The results show that the proposed framework effectively and efficiently solves both linear and nonlinear power system problems, and thus offers significant advantages in scenarios where traditional solvers face challenges, such as ill-conditioned systems and fault conditions.

Paper number 111:
Title: Automated Generation of Precedence Graphs in Digital Value Chains for Automotive Production
Authors: Cornelius Hake, Christian Friedrich
Abstract: This study examines the digital value chain in automotive manufacturing, focusing on the identification, software flashing, customization, and commissioning of electronic control units in vehicle networks. A novel precedence graph design is proposed to optimize this process chain using an automated scheduling algorithm, which combines structured data extraction from heterogeneous sources via natural language processing and classification techniques with mixed integer linear programming for efficient graph generation. The results show significant improvements in key metrics. The algorithm reduces the number of production stations equipped with expensive hardware and software to execute digital value chain processes, while also increasing capacity utilization through efficient scheduling and reduced idle time. Task parallelization is optimized, resulting in streamlined workflows and increased throughput. Compared to the traditional scheduling method, the automated approach has reduced preparation time by 50% and reduced scheduling activities, as it now takes two minutes to create the precedence graph. The flexibility of the algorithm's constraints allows for vehicle-specific configurations while maintaining high responsiveness, eliminating backup stations and facilitating the integration of new topologies. Automated scheduling significantly outperforms manual methods in efficiency, functionality, and adaptability.

Paper number 112:
Title: Active inference as a unified model of collision avoidance behavior in human drivers
Authors: Julian F. Schumann, Johan Engström, Leif Johnson, Matthew O'Kelly, Joao Messias, Jens Kober, Arkady Zgonnikov
Abstract: Collision avoidance -- involving a rapid threat detection and quick execution of the appropriate evasive maneuver -- is a critical aspect of driving. However, existing models of human collision avoidance behavior are fragmented, focusing on specific scenarios or only describing certain aspects of the avoidance behavior, such as response times. This paper addresses these gaps by proposing a novel computational cognitive model of human collision avoidance behavior based on active inference. Active inference provides a unified approach to modeling human behavior: the minimization of free energy. Building on prior active inference work, our model incorporates established cognitive mechanisms such as evidence accumulation to simulate human responses in two distinct collision avoidance scenarios: front-to-rear lead vehicle braking and lateral incursion by an oncoming vehicle. We demonstrate that our model explains a wide range of previous empirical findings on human collision avoidance behavior. Specifically, the model closely reproduces both aggregate results from meta-analyses previously reported in the literature and detailed, scenario-specific effects observed in a recent driving simulator study, including response timing, maneuver selection, and execution. Our results highlight the potential of active inference as a unified framework for understanding and modeling human behavior in complex real-life driving tasks.

Paper number 113:
Title: Towards a Unified Benchmark for Arabic Pronunciation Assessment: Quranic Recitation as Case Study
Authors: Yassine El Kheir, Omnia Ibrahim, Amit Meghanani, Nada Almarwani, Hawau Olamide Toyin, Sadeen Alharbi, Modar Alfadly, Lamya Alkanhal, Ibrahim Selim, Shehab Elbatal, Salima Mdhaffar, Thomas Hain, Yasser Hifny, Mostafa Shahin, Ahmed Ali
Abstract: We present a unified benchmark for mispronunciation detection in Modern Standard Arabic (MSA) using Qur'anic recitation as a case study. Our approach lays the groundwork for advancing Arabic pronunciation assessment by providing a comprehensive pipeline that spans data processing, the development of a specialized phoneme set tailored to the nuances of MSA pronunciation, and the creation of the first publicly available test set for this task, which we term as the Qur'anic Mispronunciation Benchmark (QuranMB.v1). Furthermore, we evaluate several baseline models to provide initial performance insights, thereby highlighting both the promise and the challenges inherent in assessing MSA pronunciation. By establishing this standardized framework, we aim to foster further research and development in pronunciation assessment in Arabic language technology and related applications.
    