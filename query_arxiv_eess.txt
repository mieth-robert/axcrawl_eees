
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation
Authors: Xinglong Liang, Jiaju Huang, Luyi Han, Tianyu Zhang, Xin Wang, Yuan Gao, Chunyao Lu, Lishan Cai, Tao Tan, Ritse Mann
Abstract: PET-CT lesion segmentation is challenging due to noise sensitivity, small and variable lesion morphology, and interference from physiological high-metabolic signals. Current mainstream approaches follow the practice of one network solving the segmentation of multiple cancer lesions by treating all cancers as a single task. However, this overlooks the unique characteristics of different cancer types. Considering the specificity and similarity of different cancers in terms of metastatic patterns, organ preferences, and FDG uptake intensity, we propose DpDNet, a Dual-Prompt-Driven network that incorporates specific prompts to capture cancer-specific features and common prompts to retain shared knowledge. Additionally, to mitigate information forgetting caused by the early introduction of prompts, prompt-aware heads are employed after the decoder to adaptively handle multiple segmentation tasks. Experiments on a PET-CT dataset with four cancer types show that DpDNet outperforms state-of-the-art models. Finally, based on the segmentation results, we calculated MTV, TLG, and SUVmax for breast cancer survival analysis. The results suggest that DpDNet has the potential to serve as a valuable tool for personalized risk stratification, supporting clinicians in optimizing treatment strategies and improving outcomes. Code is available at this https URL.

Paper number 2:
Title: Wrist bone segmentation in X-ray images using CT-based simulations
Authors: Youssef ElTantawy, Alexia Karantana, Xin Chen
Abstract: Plain X-ray is one of the most common image modalities for clinical diagnosis (e.g. bone fracture, pneumonia, cancer screening, etc.). X-ray image segmentation is an essential step for many computer-aided diagnostic systems, yet it remains challenging. Deep-learning-based methods have achieved superior performance in medical image segmentation tasks but often require a large amount of high-quality annotated data for model training. Providing such an annotated dataset is not only time-consuming but also requires a high level of expertise. This is particularly challenging in wrist bone segmentation in X-rays, due to the interposition of multiple small carpal bones in the image. To overcome the data annotation issue, this work utilizes a large number of simulated X-ray images generated from Computed Tomography (CT) volumes with their corresponding 10 bone labels to train a deep learning-based model for wrist bone segmentation in real X-ray images. The proposed method was evaluated using both simulated images and real images. The method achieved Dice scores ranging from 0.80 to 0.92 for the simulated dataset generated from different view angles. Qualitative analysis of the segmentation results of the real X-ray images also demonstrated the superior performance of the trained model. The trained model and X-ray simulation code are freely available for research purposes: the link will be provided upon acceptance.

Paper number 3:
Title: Three-Dimensional Millimeter-Wave Imaging Using Active Incoherent Fourier Processing and Pulse Compression
Authors: Jorge R. Colon-Berrios, Jason M. Merlo, Jeffrey A. Nanzer
Abstract: We present a novel three-dimensional (3D) imaging approach that combines two-dimensional spatial Fourier-domain imaging techniques with traditional radar pulse compression to recover both cross-range and down-range scene information. The imaging system employs four transmitters, three of which emit spatially and temporally incoherent noise signals, while the fourth transmits a known linear frequency modulated (LFM) pulsed signal. The spatial incoherence of the noise signals enables sampling of the 2D spatial Fourier spectrum of the scene from which two-dimensional cross-range (azimuth and elevation) images can be formed via interferometric processing. Simultaneously, the LFM signal enables high-resolution downrange imaging through matched filtering. The received signals consist of a superposition of the noise sources and the known pulse allowing for joint recovery of all three dimensions. We describe the system architecture and waveform design, and demonstrate the imaging technique using both simulations with a linear array and experimental data from a 38 GHz active incoherent millimeter-wave imaging system with 23-element randomized array. Results show the reconstruction of targets in three dimensions.

Paper number 4:
Title: Label-Efficient Chest X-ray Diagnosis via Partial CLIP Adaptation
Authors: Heet Nitinkumar Dalsania
Abstract: Modern deep learning implementations for medical imaging usually rely on large labeled datasets. These datasets are often difficult to obtain due to privacy concerns, high costs, and even scarcity of cases. In this paper, a label-efficient strategy is proposed for chest X-ray diagnosis that seeks to reflect real-world hospital scenarios. The experiments use the NIH Chest X-ray14 dataset and a pre-trained CLIP ViT-B/32 model. The model is adapted via partial fine-tuning of its visual encoder and then evaluated using zero-shot and few-shot learning with 1-16 labeled examples per disease class. The tests demonstrate that CLIP's pre-trained vision-language features can be effectively adapted to few-shot medical imaging tasks, achieving over 20\% improvement in mean AUC score as compared to the zero-shot baseline. The key aspect of this work is to attempt to simulate internal hospital workflows, where image archives exist but annotations are sparse. This work evaluates a practical and scalable solution for both common and rare disease diagnosis. Additionally this research is intended for academic and experimental purposes only and has not been peer reviewed yet. All code is found at this https URL.

Paper number 5:
Title: A RIS-Enabled Computational Radar Coincidence Imaging
Authors: Kavian Zirak, Mohammadreza F. Imani
Abstract: This paper introduces an innovative imaging method using reconfigurable intelligent surfaces (RISs) by combining radar coincidence imaging (RCI) and computational imaging techniques. In the proposed framework, RISs simultaneously redirect beams toward a desired region of interest (ROI). The interference of these beams forms spatially diverse speckle patterns that carry information about the entire ROI. As a result, this method can take advantage of the benefits of both random patterns and spotlight imaging. Since the speckle pattern is formed by directive beams (instead of random patterns typically used in computational imaging), this approach results in a higher signal-to-noise ratio (SNR) and reduced clutter. In contrast to raster scanning, which requires the number of measurements to be at least equal to the number of unknowns, our proposed approach follows a computational imaging framework and can obtain high-quality images even when only a few measurements are taken. Using numerical simulation, we demonstrate this method's capabilities and contrast it against other conventional techniques. The proposed imaging approach can be applied to security screening, wireless user tracking, and activity recognition.

Paper number 6:
Title: Multilayer GNN for Predictive Maintenance and Clustering in Power Grids
Authors: Muhammad Kazim, Harun Pirim, Chau Le, Trung Le, Om Prakash Yadav
Abstract: Unplanned power outages cost the US economy over $150 billion annually, partly due to predictive maintenance (PdM) models that overlook spatial, temporal, and causal dependencies in grid failures. This study introduces a multilayer Graph Neural Network (GNN) framework to enhance PdM and enable resilience-based substation clustering. Using seven years of incident data from Oklahoma Gas & Electric (292,830 records across 347 substations), the framework integrates Graph Attention Networks (spatial), Graph Convolutional Networks (temporal), and Graph Isomorphism Networks (causal), fused through attention-weighted embeddings. Our model achieves a 30-day F1-score of 0.8935 +/- 0.0258, outperforming XGBoost and Random Forest by 3.2% and 2.7%, and single-layer GNNs by 10 to 15 percent. Removing the causal layer drops performance to 0.7354 +/- 0.0418. For resilience analysis, HDBSCAN clustering on HierarchicalRiskGNN embeddings identifies eight operational risk groups. The highest-risk cluster (Cluster 5, 44 substations) shows 388.4 incidents/year and 602.6-minute recovery time, while low-risk groups report fewer than 62 incidents/year. ANOVA (p < 0.0001) confirms significant inter-cluster separation. Our clustering outperforms K-Means and Spectral Clustering with a Silhouette Score of 0.626 and Davies-Bouldin index of 0.527. This work supports proactive grid management through improved failure prediction and risk-aware substation clustering.

Paper number 7:
Title: Probability-Raising Causality for Uncertain Parametric Markov Decision Processes with PAC Guarantees
Authors: Ryohei Oura, yuji Ito
Abstract: Recent decision-making systems are increasingly complicated, making it crucial to verify and understand their behavior for a given specification. A promising approach is to comprehensively explain undesired behavior in the systems modeled by Markov decision processes (MDPs) through formal verification and causal reasoning. However, the reliable explanation using model-based probabilistic causal analysis has not been explored when the MDP's transition probabilities are uncertain. This paper proposes a method to identify potential causes of undesired behaviors in an uncertain parametric MDP (upMDP) using parameter sampling, model checking, and a set covering for the samples. A cause is defined as a subset of states based on a probability-raising principle. We show that the probability of each identified subset being a cause exceeds a specified threshold. Further, a lower bound of the probability that the undesired paths visit the subsets is maximized as much as possible while satisfying a nonredundancy condition. While computing these probabilities is complicated, this study derives probabilistically approximately correct lower bounds of both probabilities by the sampling. We demonstrate the effectiveness of the proposed method through a path-planning scenario.

Paper number 8:
Title: mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar
Authors: Anurag Pallaprolu, Winston Hurst, Yasamin Mostofi
Abstract: In this paper, we present a novel framework for extracting underlying crowd motion patterns and inferring crowd semantics using mmWave radar. First, our proposed signal processing pipeline combines optical flow estimation concepts from vision with novel statistical and morphological noise filtering to generate high-fidelity mmWave flow fields - compact 2D vector representations of crowd motion. We then introduce a novel approach that transforms these fields into directed geometric graphs, where edges capture dominant flow currents, vertices mark crowd splitting or merging, and flow distribution is quantified across edges. Finally, we show that by analyzing the local Jacobian and computing the corresponding curl and divergence, we can extract key crowd semantics for both structured and diffused crowds. We conduct 21 experiments on crowds of up to (and including) 20 people across 3 areas, using commodity mmWave radar. Our framework achieves high-fidelity graph reconstruction of the underlying flow structure, even for complex crowd patterns, demonstrating strong spatial alignment and precise quantitative characterization of flow split ratios. Finally, our curl and divergence analysis accurately infers key crowd semantics, e.g., abrupt turns, boundaries where flow directions shift, dispersions, and gatherings. Overall, these findings validate our framework, underscoring its potential for various crowd analytics applications.

Paper number 9:
Title: Computation-resource-efficient Task-oriented Communications
Authors: Jingwen Fu, Ming Xiao, Chao Ren, Mikael Skoglund
Abstract: The rapid development of deep-learning enabled task-oriented communications (TOC) significantly shifts the paradigm of wireless communications. However, the high computation demands, particularly in resource-constrained systems e.g., mobile phones and UAVs, make TOC challenging for many tasks. To address the problem, we propose a novel TOC method with two models: a static and a dynamic model. In the static model, we apply a neural network (NN) as a task-oriented encoder (TOE) when there is no computation budget constraint. The dynamic model is used when device computation resources are limited, and it uses dynamic NNs with multiple exits as the TOE. The dynamic model sorts input data by complexity with thresholds, allowing the efficient allocation of computation resources. Furthermore, we analyze the convergence of the proposed TOC methods and show that the model converges at rate $O\left(\frac{1}{\sqrt{T}}\right)$ with an epoch of length $T$. Experimental results demonstrate that the static model outperforms baseline models in terms of transmitted dimensions, floating-point operations (FLOPs), and accuracy simultaneously. The dynamic model can further improve accuracy and computational demand, providing an improved solution for resource-constrained systems.

Paper number 10:
Title: Distributed and adaptive model predictive control for vehicle platoon systems under non-ideal communication
Authors: Qiaoni Han, Chengfei Xu, Zhiqiang Zuo
Abstract: The uncertainty of wireless communication poses significant challenges to platoon control performance. Aiming at alleviating the influence of non-ideal communication on the platoon system, this paper proposes a distributed and adaptive model predictive control (MPC) method. First of all, to deal with the transmission uncertainty caused by non-ideal communication, compensated data packets are customized for each vehicle. Then, an adaptive model predictive control method is proposed to balance the system response speed and tracking accuracy. Furthermore, to reduce the computational requirements of the vehicle platoon system, a predictive time-domain update strategy suitable for non-ideal communication was introduced. Finally, the sufficient conditions for ensuring the feasibility of the MPC algorithm and the stability of the closed-loop platoon control system are theoretically analyzed. The simulation results show that the proposed method significantly reduces the computing resource requirements for solving the optimization problem while ensuring satisfactory system performance.

Paper number 11:
Title: Featureless Wireless Communications using Enhanced Autoencoder
Authors: Ruhui Zhang, Wei Lin, Binbin Chen
Abstract: Artificial intelligence (AI) techniques, particularly autoencoders (AEs), have gained significant attention in wireless communication systems. This paper investigates using an AE to generate featureless signals with a low probability of detection and interception (LPD/LPI). Firstly, we introduce a novel loss function that adds a KL divergence term to the categorical cross entropy, enhancing the noise like characteristics of AE-generated signals while preserving block error rate (BLER). Secondly, to support long source message blocks for the AE's inputs, we replace one-hot inputs of source blocks with binary inputs pre-encoded by conventional error correction coding schemes. The AE's outputs are then decoded back to the source blocks using the same scheme. This design enables the AE to learn the coding structure, yielding superior BLER performance on coded blocks and the BLER of the source blocks is further decreased by the error correction decoder. Moreover, we also validate the AE based communication system in the over-the-air communication. Experimental results demonstrate that our proposed methods improve the featureless properties of AE signals and significantly reduce the BLER of message blocks, underscoring the promise of our AE-based approach for secure and reliable wireless communication systems.

Paper number 12:
Title: Optimization of Probabilistic Constellation Shaping for Optical OFDM Systems with Clipping Distortion
Authors: Thanh V. Pham, Susumu Ishihara
Abstract: Optical orthogonal frequency-division multiplexing (OFDM) and probabilistic constellation shaping (PCS) have emerged as powerful techniques to enhance the performance of optical wireless communications (OWC) systems. While PCS improves spectral efficiency and adaptability, we show that its integration with optical OFDM can inadvertently increase the peak-to-average power ratio (PAPR) of the signal, exacerbating clipping distortion due to signal clipping. This letter investigates the impact of PCS on the PAPR of direct current-biased optical OFDM (DCO-OFDM) waveforms and proposes an optimization of PCS that maximizes channel capacity, considering clipping distortion. The optimization problem is shown to be complex and non-convex. We thus present a suboptimal yet efficient solving approach based on projected gradient descent to solve the problem. Simulation results demonstrate the superiority of the proposed approach over the conventional uniform signaling, particularly under severe clipping distortion conditions.

Paper number 13:
Title: Leveraging Power Amplifier Distortion for Physical Layer Security
Authors: Reza Ghasemi Alavicheh, Thomas Feys, MD Arifur Rahman, François Rottenberg
Abstract: This paper introduces a new approach to physical layer security (PLS) by leveraging power amplifier (PA) nonlinear distortion through distortion-aware precoding. While some conventional PLS techniques inject artificial noise orthogonal to legitimate channels, we demonstrate that inherent PA nonlinearities typically considered undesirable can be exploited to enhance security. The zero 3rd order (Z3RO) precoder applies a negative polarity to several antennas to cancel the PA distortion at the user location, resulting in distortion being transmitted in non-user locations. Redirecting the distortion to non-user locations creates interference for potential eavesdroppers, lowering their signal-to-noise-and-distortion ratio (SNDR). Numerical simulations reveal that the Z3RO precoder achieves up to a $2.5\times$ improvement in secrecy rate compared to conventional maximum ratio transmission (MRT) precoding under a $10\%$ outage probability, SNR of $32$ dB and $-5$ dB input back-off (IBO) where the PAs enter the saturation regime.

Paper number 14:
Title: Perspective Chapter: Insights from Kalman Filtering with Correlated Noises Recursive Least-Square Algorithm for State and Parameter Estimation
Authors: Abd El Mageed Hag Elamin Khalid
Abstract: This article explores the estimation of parameters and states for linear stochastic systems with deterministic control inputs. It introduces a novel Kalman filtering approach called Kalman Filtering with Correlated Noises Recursive Generalized Extended Least Squares (KF-CN-RGELS) algorithm, which leverages the cross-correlation between process noise and measurement noise in Kalman filtering cycles to jointly estimate both parameters and system states. The study also investigates the theoretical implications of the correlation coefficient on estimation accuracy through performance analysis involving various correlation coefficients between process and measurement noises. The research establishes a clear relationship: the accuracy of identified parameters and states is directly proportional to positive correlation coefficients. To validate the efficacy of this algorithm, a comprehensive comparison is conducted among different algorithms, including the standard Kalman filter algorithm and the augmented-state Kalman filter with correlated noises algorithm. Theoretical findings are not only presented but also exemplified through a numerical case study to provide valuable insights into practical implications. This work contributes to enhancing estimation accuracy in linear stochastic systems with deterministic control inputs, offering valuable insights for control system design and state-space modeling.

Paper number 15:
Title: Generic Speech Enhancement with Self-Supervised Representation Space Loss
Authors: Hiroshi Sato, Tsubasa Ochiai, Marc Delcroix, Takafumi Moriya, Takanori Ashihara, Ryo Masumura
Abstract: Single-channel speech enhancement is utilized in various tasks to mitigate the effect of interfering signals. Conventionally, to ensure the speech enhancement performs optimally, the speech enhancement has needed to be tuned for each task. Thus, generalizing speech enhancement models to unknown downstream tasks has been challenging. This study aims to construct a generic speech enhancement front-end that can improve the performance of back-ends to solve multiple downstream tasks. To this end, we propose a novel training criterion that minimizes the distance between the enhanced and the ground truth clean signal in the feature representation domain of self-supervised learning models. Since self-supervised learning feature representations effectively express high-level speech information useful for solving various downstream tasks, the proposal is expected to make speech enhancement models preserve such information. Experimental validation demonstrates that the proposal improves the performance of multiple speech tasks while maintaining the perceptual quality of the enhanced signal.

Paper number 16:
Title: RIS-assisted ISAC Systems for Industrial Revolution 6.0: Exploring the Near-field and Far-field Coexistence
Authors: Seonghoon Yoo, Jaemin Jung, Seongah Jeong, Jinkyu Kang, Markku Juntti, Joonhyuk Kang
Abstract: The Industrial Internet of Things (IIoT) has emerged as a key technology for realizing the vision of Industry 6.0, requiring the seamless integration of diverse connected devices. In particular, integrated sensing and communication (ISAC) plays a critical role in supporting real-time control and automation within IIoT systems. In this paper, we explore reconfigurable intelligent surface (RIS)-assisted ISAC systems for IIoT in the coexistence of near-field and far-field regions. The system consists of a full-duplex access point (AP), a RIS and multiple IIoT devices, where the near-field devices simultaneously perform sensing and communication, while the far-field devices rely on a RIS-assisted communication. To enhance spectral efficiency for both sensing and communication functionalities, we consider the use of both traditional sensing-only (SO) and ISAC frequency bands. Moreover, uplink non-orthogonal multiple access (NOMA) is employed to facilitate the sequential decoding of superimposed communication and sensing signals from IIoT devices. To maximize sensing accuracy in terms of Cram${\Grave{\textrm{e}}}$r-Rao bound (CRB), we formulate a joint optimization of RIS phase shift, bandwidth splitting ratio and receive beamforming vector subject to the minimum data rate requirements of IIoT devices and resource budget constraints. The algorithmic solution is developed via the successive convex approximation (SCA)-based alternating optimization (AO) method with the semi-definite relaxation (SDR) technique. Numerical results demonstrate that the proposed method significantly outperforms conventional methods relying solely on either ISAC or SO band by achieving superior performance across RIS and device configurations, while ensuring robust ISAC performance under the near-field and far-field coexistence scenarios.

Paper number 17:
Title: PhysioEdge: Multimodal Compressive Sensing Platform for Wearable Health Monitoring
Authors: Rens Baeyens, Dennis Laurijssen, Jan Steckel, Walter Daems
Abstract: The integration of compressive sensing with real-time embedded systems opens new possibilities for efficient, low-power biomedical signal acquisition. This paper presents a custom hardware platform based on the RP2350 micro-controller, tailored for synchronized multi-modal biomedical monitoring. The system is capable of capturing cardiopulmonary sounds, along with biopotential signals such as phonocardiography (PCG), electrocardiography (ECG) and electromyography (EMG), photoplethysmography (PPG), and inertial measurement unit (IMU) data for posture recognition. To ensure sample-accurate synchronization, a Sub-1GHz radio system is used across multiple nodes. Wi-Fi and Bluetooth connectivity enable centralized data aggregation. Experimental results demonstrate the achieved decrease in power consumption when using compressive sensing, efficient multi-node synchronization, and scalability for wireless biomedical monitoring applications. The compact form factor and low-cost design make it suitable for various medical applications, including remote healthcare and long-term monitoring.

Paper number 18:
Title: Consistent and Asymptotically Efficient Localization from Bearing-only Measurements
Authors: Shenghua Hu, Guangyang Zeng, Wenchao Xue, Haitao Fang, Biqiang Mu
Abstract: We study the problem of signal source localization using bearing-only measurements. Initially, we present easily verifiable geometric conditions for sensor deployment to ensure the asymptotic identifiability of the model and demonstrate the consistency and asymptotic efficiency of the maximum likelihood (ML) estimator. However, obtaining the ML estimator is challenging due to its association with a non-convex optimization problem. To address this, we propose a two-step estimator that shares the same asymptotic properties as the ML estimator while offering low computational complexity, linear in the number of measurements. The primary challenge lies in obtaining a preliminary consistent estimator in the first step. To achieve this, we construct a linear least-squares problem through algebraic operations on the measurement nonlinear model to first obtain a biased closed-form solution. We then eliminate the bias using the data to yield an asymptotically unbiased and consistent estimator. The key to this process is obtaining a consistent estimator of the variance of the sine of the noise by taking the reciprocal of the maximum eigenvalue of a specially constructed matrix from the data. In the second step, we perform a single Gauss-Newton iteration using the preliminary consistent estimator as the initial value, achieving the same asymptotic properties as the ML estimator. Finally, simulation results demonstrate the superior performance of the proposed two-step estimator for large sample sizes.

Paper number 19:
Title: Remote Renewable Energy Hubs: a Taxonomy
Authors: Victor Dachet, Antoine Dubois, Bardhyl Miftari, Raphaël Fonteneau, Damien Ernst
Abstract: Serving the energy demand with renewable energy is hindered by its limited availability near load centres (i.e. places where the energy demand is high). To address this challenge, the concept of Remote Renewable Energy Hubs (RREH) emerges as a promising solution. RREHs are energy hubs located in areas with abundant renewable energy sources, such as sun in the Sahara Desert or wind in Greenland. In these hubs, renewable energy sources are used to synthetise energy molecules. To produce specific energy molecules, a tailored hub configuration must be designed, which means choosing a set of technologies that are interacting with each other as well as defining how they are integrated in their local environment. The plurality of technologies that may be employed in RREHs results in a large diversity of hubs. In order to characterize this diversity, we propose in this paper a taxonomy for accurately defining these hubs. This taxonomy allows to better describe and compare designs of hubs as well as to identify new ones. Thus, it may guide policymakers and engineers in hub design, contributing to cost efficiency and/or improving local integration.

Paper number 20:
Title: Ammonia, Methane, Hydrogen and Methanol Produced in Remote Renewable Energy Hubs: a Comparative Quantitative Analysis
Authors: Antoine Larbanois, Victor Dachet, Antoine Dubois, Raphaël Fonteneau, Damien Ernst
Abstract: Remote renewable energy hubs (RREHs) for synthetic fuel production are engineering systems harvesting renewable energy where it is particularly abundant. They produce transportable synthetic fuels for export to distant load centers. This article aims to evaluate the production costs of different energy carriers, and includes a discussion on advantages and disadvantages in terms of technical performance. To do so, we extend the study of Berger et al., (2021) which focuses on methane (CH4) as energy carrier and introduce three new carriers: ammonia (NH3), hydrogen (H2) and methanol (CH3OH). The four different RREHs are located in the Algerian Sahara desert and must serve to the load center, Belgium, a constant electro-fuel demand of 10 TWh per year. The modelling and optimisation of these systems are performed using the modelling language GBOML (Graph-Based Optimisation Modelling Language). Our findings reveal that the three new RREHs, each with its respective carrier (ammonia, hydrogen, and methanol), are all more cost-effective than the methane-based system. Ammonia demonstrates the most favourable cost-to-energy exported ratio.

Paper number 21:
Title: Signal Prediction for Loss Mitigation in Tactile Internet: A Leader-Follower Game-Theoretic Approach
Authors: Mohammad Ali Vahedifar, Qi Zhang
Abstract: Tactile Internet (TI) requires achieving ultra-low latency and highly reliable packet delivery for haptic signals. In the presence of packet loss and delay, the signal prediction method provides a viable solution for recovering the missing signals. To this end, we introduce the Leader-Follower (LeFo) approach based on a cooperative Stackelberg game, which enables both users and robots to learn and predict actions. With accurate prediction, the teleoperation system can safely relax its strict delay requirements. Our method achieves high prediction accuracy, ranging from 80.62% to 95.03% for remote robot signals at the Human ($H$) side and from 70.44% to 89.77% for human operation signals at the remote Robot ($R$) side. We also establish an upper bound for maximum signal loss using Taylor Expansion, ensuring robustness.

Paper number 22:
Title: Computationally Efficient Information-Driven Optical Design with Interchanging Optimization
Authors: Eric Markley, Henry Pinkard, Leyla Kabuli, Nalini Singh, Laura Waller
Abstract: Recent work has demonstrated that imaging systems can be evaluated through the information content of their measurements alone, enabling application-agnostic optical design that avoids computational decoding challenges. Information-Driven Encoder Analysis Learning (IDEAL) was proposed to automate this process through gradient-based. In this work, we study IDEAL across diverse imaging systems and find that it suffers from high memory usage, long runtimes, and a potentially mismatched objective function due to end-to-end differentiability requirements. We introduce IDEAL with Interchanging Optimization (IDEAL-IO), a method that decouples density estimation from optical parameter optimization by alternating between fitting models to current measurements and updating optical parameters using fixed models for information estimation. This approach reduces runtime and memory usage by up to 6x while enabling more expressive density models that guide optimization toward superior designs. We validate our method on diffractive optics, lensless imaging, and snapshot 3D microscopy applications, establishing information-theoretic optimization as a practical, scalable strategy for real-world imaging system design.

Paper number 23:
Title: Set-Based Control Barrier Functions and Safety Filters
Authors: Kim P. Wabersich, Felix Berkel, Felix Gruber, Sven Reimann
Abstract: High performance and formal safety guarantees are common requirements for industrial control applications. Control barrier function (CBF) methods provide a systematic approach to the modularization of safety and performance. However, the design of such CBFs can be challenging, which limits their applicability to large-scale or data-driven systems. This paper introduces the concept of a set-based CBF for linear systems with convex constraints. By leveraging control invariant sets from reachability analysis and predictive control, the set-based CBF is defined implicitly through the minimal scaling of such a set to contain the current system state. This approach enables the development of implicit, data-driven, and high-dimensional CBF representations. The paper demonstrates the design of a safety filter using set-based CBFs, which is suitable for real-time implementations and learning-based approximations to reduce online computational demands. The effectiveness of the method is illustrated through comprehensive simulations on a high-dimensional mass-spring-damper system and a motion control task, and it is validated experimentally using an electric drive application with short sampling times, highlighting its practical benefits for safety-critical control.

Paper number 24:
Title: Flying Base Stations for Offshore Wind Farm Monitoring and Control: Holistic Performance Evaluation and Optimization
Authors: Xinyi Lin, Peizheng Li, Adnan Aijaz
Abstract: Ensuring reliable and low-latency communication in offshore wind farms is critical for efficient monitoring and control, yet remains challenging due to the harsh environment and lack of infrastructure. This paper investigates a flying base station (FBS) approach for wide-area monitoring and control in the UK Hornsea offshore wind farm project. By leveraging mobile, flexible FBS platforms in the remote and harsh offshore environment, the proposed system offers real-time connectivity for turbines without the need for deploying permanent infrastructure at the sea. We develop a detailed and practical end-to-end latency model accounting for five key factors: flight duration, connection establishment, turbine state information upload, computational delay, and control transmission, to provide a holistic perspective often missing in prior studies. Furthermore, we combine trajectory planning, beamforming, and resource allocation into a multi-objective optimization framework for the overall latency minimization, specifically designed for large-scale offshore wind farm deployments. Simulation results verify the effectiveness of our proposed method in minimizing latency and enhancing efficiency in FBS-assisted offshore monitoring across various power levels, while consistently outperforming baseline designs.

Paper number 25:
Title: Identifying the Smallest Adversarial Load Perturbations that Render DC-OPF Infeasible
Authors: Samuel Chevalier, William A. Wheeler
Abstract: What is the globally smallest load perturbation that renders DC-OPF infeasible? Reliably identifying such "adversarial attack" perturbations has useful applications in a variety of emerging grid-related contexts, including machine learning performance verification, cybersecurity, and operational robustness of power systems dominated by stochastic renewable energy resources. In this paper, we formulate the inherently nonconvex adversarial attack problem by applying a parameterized version of Farkas' lemma to a perturbed set of DC-OPF equations. Since the resulting formulation is very hard to globally optimize, we also propose a parameterized generation control policy which, when applied to the primal DC-OPF problem, provides solvability guarantees. Together, these nonconvex problems provide guaranteed upper and lower bounds on adversarial attack size; by combining them into a single optimization problem, we can efficiently "squeeze" these bounds towards a common global solution. We apply these methods on a range of small- to medium-sized test cases from PGLib, benchmarking our results against the best adversarial attack lower bounds provided by Gurobi 12.0's spatial Branch and Bound solver.

Paper number 26:
Title: Polyadic encryption
Authors: Steven Duplij, Qiang Guo
Abstract: A novel original procedure of encryption/decryption based on the polyadic algebraic structures and on signal processing methods is proposed. First, we use signals with integer amplitudes to send information. Then we use polyadic techniques to transfer the plaintext into series of special integers. The receiver restores the plaintext using special rules and systems of equations.

Paper number 27:
Title: Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation
Authors: Javal Vyas, Mehmet Mercangoz
Abstract: The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.

Paper number 28:
Title: CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings
Authors: Cristina Mata, Kanchana Ranasinghe, Michael S. Ryoo
Abstract: Unsupervised domain adaptation (UDA) involves learning class semantics from labeled data within a source domain that generalize to an unseen target domain. UDA methods are particularly impactful for semantic segmentation, where annotations are more difficult to collect than in image classification. Despite recent advances in large-scale vision-language representation learning, UDA methods for segmentation have not taken advantage of the domain-agnostic properties of text. To address this, we present a novel Covariance-based Pixel-Text loss, CoPT, that uses domain-agnostic text embeddings to learn domain-invariant features in an image segmentation encoder. The text embeddings are generated through our LLM Domain Template process, where an LLM is used to generate source and target domain descriptions that are fed to a frozen CLIP model and combined. In experiments on four benchmarks we show that a model trained using CoPT achieves the new state of the art performance on UDA for segmentation. The code can be found at this https URL.

Paper number 29:
Title: Interpretable EEG-to-Image Generation with Semantic Prompts
Authors: Arshak Rezvani, Ali Akbari, Kosar Sanjar Arani, Maryam Mirian, Emad Arasteh, Martin J. McKeown
Abstract: Decoding visual experience from brain signals offers exciting possibilities for neuroscience and interpretable AI. While EEG is accessible and temporally precise, its limitations in spatial detail hinder image reconstruction. Our model bypasses direct EEG-to-image generation by aligning EEG signals with multilevel semantic captions -- ranging from object-level to abstract themes -- generated by a large language model. A transformer-based EEG encoder maps brain activity to these captions through contrastive learning. During inference, caption embeddings retrieved via projection heads condition a pretrained latent diffusion model for image generation. This text-mediated framework yields state-of-the-art visual decoding on the EEGCVPR dataset, with interpretable alignment to known neurocognitive pathways. Dominant EEG-caption associations reflected the importance of different semantic levels extracted from perceived images. Saliency maps and t-SNE projections reveal semantic topography across the scalp. Our model demonstrates how structured semantic mediation enables cognitively aligned visual decoding from EEG.

Paper number 30:
Title: Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?
Authors: Robert Kuku Fotock, Agbotiname Lucky Imoize, Alessio Zappone, Marco Di Renzo, Roberto Garello
Abstract: This work addresses the problem of secrecy energy efficiency (SEE) maximization in RIS-aided wireless networks. The use of active and nearly-passive RISs are compared and their trade-off in terms of SEE is analyzed. Considering both perfect and statistical channel state information, two SEE maximization algorithms are developed to optimize the transmit powers of the mobile users, the RIS reflection coefficients, and the base station receive filters. Numerical results quantify the trade-off between active and nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values as the static power consumed by each reflecting element increases.

Paper number 31:
Title: Robust Multimodal Learning Framework For Intake Gesture Detection Using Contactless Radar and Wearable IMU Sensors
Authors: Chunzhuo Wang, Hans Hallez, Bart Vanrumste
Abstract: Automated food intake gesture detection plays a vital role in dietary monitoring, enabling objective and continuous tracking of eating behaviors to support better health outcomes. Wrist-worn inertial measurement units (IMUs) have been widely used for this task with promising results. More recently, contactless radar sensors have also shown potential. This study explores whether combining wearable and contactless sensing modalities through multimodal learning can further improve detection performance. We also address a major challenge in multimodal learning: reduced robustness when one modality is missing. To this end, we propose a robust multimodal temporal convolutional network with cross-modal attention (MM-TCN-CMA), designed to integrate IMU and radar data, enhance gesture detection, and maintain performance under missing modality conditions. A new dataset comprising 52 meal sessions (3,050 eating gestures and 797 drinking gestures) from 52 participants is developed and made publicly available. Experimental results show that the proposed framework improves the segmental F1-score by 4.3% and 5.2% over unimodal Radar and IMU models, respectively. Under missing modality scenarios, the framework still achieves gains of 1.3% and 2.4% for missing radar and missing IMU inputs. This is the first study to demonstrate a robust multimodal learning framework that effectively fuses IMU and radar data for food intake gesture detection.

Paper number 32:
Title: Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path
Authors: Jared Miller, Mattia Bianchi, Florian Dörfler
Abstract: This work analyzes convergence times and robustness bounds for asynchronous distributed shortest-path computation. We focus on the Adaptive Bellman--Ford algorithm, a self-stabilizing method in which each agent updates its shortest-path estimate based only on the estimates of its neighbors and forgetting its previous estimate. In the asynchronous framework considered in this paper, agents are allowed to idle or encounter race conditions during their execution of the Adaptive Bellman--Ford algorithm. We build on Lyapunov-based results that develop finite-time convergence and robustness bounds for the synchronous shortest-path setting, in order to produce finite-time convergence and robustness bounds for the asynchronous setting. We also explore robustness against interval-bounded noise processes and establish convergence and robustness guarantees for asynchronous most-probable-path algorithms.

Paper number 33:
Title: Audio-Visual Speech Separation via Bottleneck Iterative Network
Authors: Sidong Zhang, Shiv Shankar, Trang Nguyen, Andrea Fanelli, Madalina Fiterau
Abstract: Integration of information from non-auditory cues can significantly improve the performance of speech-separation models. Often such models use deep modality-specific networks to obtain unimodal features, and risk being too costly or lightweight but lacking capacity. In this work, we present an iterative representation refinement approach called Bottleneck Iterative Network (BIN), a technique that repeatedly progresses through a lightweight fusion block, while bottlenecking fusion representations by fusion tokens. This helps improve the capacity of the model, while avoiding major increase in model size and balancing between the model performance and training cost. We test BIN on challenging noisy audio-visual speech separation tasks, and show that our approach consistently outperforms state-of-the-art benchmark models with respect to SI-SDRi on NTCD-TIMIT and LRS3+WHAM! datasets, while simultaneously achieving a reduction of more than 50% in training and GPU inference time across nearly all settings.

Paper number 34:
Title: ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning
Authors: Yichen Lu, Wei Dai, Jiaen Liu, Ching Wing Kwok, Zongheng Wu, Xudong Xiao, Ao Sun, Sheng Fu, Jianyuan Zhan, Yian Wang, Takatomo Saito, Sicheng Lai
Abstract: LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: this https URL

Paper number 35:
Title: Classifying Emergence in Robot Swarms: An Observer-Dependent Approach
Authors: Ricardo Vega, Cameron Nowzari
Abstract: Emergence and swarms are widely discussed topics, yet no consensus exists on their formal definitions. This lack of agreement makes it difficult not only for new researchers to grasp these concepts, but also for experts who may use the same terms to mean different things. Many attempts have been made to objectively define 'swarm' or 'emergence,' with recent work highlighting the role of the external observer. Still, several researchers argue that once an observer's vantage point (e.g., scope, resolution, context) is established, the terms can be made objective or measured quantitatively. In this note, we propose a framework to discuss these ideas rigorously by separating externally observable states from latent, unobservable ones. This allows us to compare and contrast existing definitions of swarms and emergence on common ground. We argue that these concepts are ultimately subjective-shaped less by the system itself than by the perception and tacit knowledge of the observer. Specifically, we suggest that a 'swarm' is not defined by its group behavior alone, but by the process generating that behavior. Our broader goal is to support the design and deployment of robotic swarm systems, highlighting the critical distinction between multi-robot systems and true swarms.

Paper number 36:
Title: SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models
Authors: Christian Templin, Yanda Zhu, Hao Wang
Abstract: Spatial audio is an integral part of immersive entertainment, such as VR/AR, and has seen increasing popularity in cinema and music as well. The most common format of spatial audio is described as first-order Ambisonics (FOA). We seek to extend recent advancements in FOA generative AI models to enable the generation of 3D scenes with dynamic sound sources. Our proposed end-to-end model, SonicMotion, comes in two variations which vary in their user input and level of precision in sound source localization. In addition to our model, we also present a new dataset of simulated spatial audio-caption pairs. Evaluation of our models demonstrate that they are capable of matching the semantic alignment and audio quality of state of the art models while capturing the desired spatial attributes.

Paper number 37:
Title: Discrete Beamforming Optimization for RISs with a Limited Phase Range and Amplitude Attenuation
Authors: Dogan Kutay Pekcan, Hongyi Liao, Ender Ayanoglu
Abstract: This paper addresses the problem of maximizing the received power at a user equipment via reconfigurable intelligent surface (RIS) characterized by phase-dependent amplitude (PDA) and discrete phase shifts over a limited phase range. Given complex RIS coefficients, that is, discrete phase shifts and PDAs, we derive the necessary and sufficient conditions to achieve the optimal solution. To this end, we propose an optimal search algorithm that is proven to converge in linear time within at most NK steps, significantly outperforming the exhaustive search approach that would otherwise be needed for RISs with amplitude attenuation. Furthermore, we introduce a practical quantization framework for PDA-introduced RISs termed amplitude-introduced polar quantization (APQ), and extend it to a novel algorithm named extended amplitude-introduced polar quantization (EAPQ) that works with geometric projections. We derive closed-form expressions to assess how closely the performance of the proposed RIS configuration can approximate the ideal case with continuous phases and no attenuation. Our analysis reveals that increasing the number of discrete phases beyond K = 4 yields only marginal gains, regardless of attenuation levels, provided the RIS has a sufficiently wide phase range R. Furthermore, we also show and quantify that when the phase range R is limited, the performance is sensitive to attenuation for larger R, and sensitive to R when there is less attenuation. Finally, the proposed optimal algorithm provides a generic upper bound that could serve as a benchmark for discrete beamforming in RISs with amplitude constraints.

Paper number 38:
Title: Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification
Authors: Zhanhong Jiang, Dylan Shah, Hsin-Jung Yang, Soumik Sarkar
Abstract: Precise kinematic modeling is critical in calibration and controller design for soft robots, yet remains a challenging issue due to their highly nonlinear and complex behaviors. To tackle the issue, numerous data-driven machine learning approaches have been proposed for modeling nonlinear dynamics. However, these models suffer from prediction uncertainty that can negatively affect modeling accuracy, and uncertainty quantification for kinematic modeling in soft robots is underexplored. In this work, using limited simulation and real-world data, we first investigate multiple linear and nonlinear machine learning models commonly used for kinematic modeling of soft robots. The results reveal that nonlinear ensemble methods exhibit the most robust generalization performance. We then develop a conformal kinematic modeling framework for soft robots by utilizing split conformal prediction to quantify predictive position uncertainty, ensuring distribution-free prediction intervals with a theoretical guarantee.

Paper number 39:
Title: VP-SelDoA: Visual-prompted Selective DoA Estimation of Target Sound via Semantic-Spatial Matching
Authors: Yu Chen, Xinyuan Qian, Hongxu Zhu, Jiadong Wang, Kainan Chen, Haizhou Li
Abstract: Audio-visual sound source localization (AV-SSL) identifies the position of a sound source by exploiting the complementary strengths of auditory and visual signals. However, existing AV-SSL methods encounter three major challenges: 1) inability to selectively isolate the target sound source in multi-source scenarios, 2) misalignment between semantic visual features and spatial acoustic features, and 3) overreliance on paired audio-visual data. To overcome these limitations, we introduce Cross-Instance Audio-Visual Localization (CI-AVL), a novel task that leverages images from different instances of the same sound event category to localize target sound sources, thereby reducing dependence on paired data while enhancing generalization capabilities. Our proposed VP-SelDoA tackles this challenging task through a semantic-level modality fusion and employs a Frequency-Temporal ConMamba architecture to generate target-selective masks for sound isolation. We further develop a Semantic-Spatial Matching mechanism that aligns the heterogeneous semantic and spatial features via integrated cross- and self-attention mechanisms. To facilitate the CI-AVL research, we construct a large-scale dataset named VGG-SSL, comprising 13,981 spatial audio clips across 296 sound event categories. Extensive experiments show that our proposed method outperforms state-of-the-art audio-visual localization methods, achieving a mean absolute error (MAE) of 12.04 and an accuracy (ACC) of 78.23%.

Paper number 40:
Title: IML-Spikeformer: Input-aware Multi-Level Spiking Transformer for Speech Processing
Authors: Zeyang Song, Shimin Zhang, Yuhong Chou, Jibin Wu, Haizhou Li
Abstract: Spiking Neural Networks (SNNs), inspired by biological neural mechanisms, represent a promising neuromorphic computing paradigm that offers energy-efficient alternatives to traditional Artificial Neural Networks (ANNs). Despite proven effectiveness, SNN architectures have struggled to achieve competitive performance on large-scale speech processing task. Two key challenges hinder progress: (1) the high computational overhead during training caused by multi-timestep spike firing, and (2) the absence of large-scale SNN architectures tailored to speech processing tasks. To overcome the issues, we introduce Input-aware Multi-Level Spikeformer, i.e. IML-Spikeformer, a spiking Transformer architecture specifically designed for large-scale speech processing. Central to our design is the Input-aware Multi-Level Spike (IMLS) mechanism, which simulate multi-timestep spike firing within a single timestep using an adaptive, input-aware thresholding scheme. IML-Spikeformer further integrates a Reparameterized Spiking Self-Attention (RepSSA) module with a Hierarchical Decay Mask (HDM), forming the HD-RepSSA module. This module enhances the precision of attention maps and enables modeling of multi-scale temporal dependencies in speech signals. Experiments demonstrate that IML-Spikeformer achieves word error rates of 6.0\% on AiShell-1 and 3.4\% on Librispeech-960, comparable to conventional ANN transformers while reducing theoretical inference energy consumption by 4.64$\times$ and 4.32$\times$ respectively. IML-Spikeformer marks an advance of scalable SNN architectures for large-scale speech processing in both task performance and energy efficiency.

Paper number 41:
Title: Demonstration of TFTs 3D Monolithically Integrated on GaN HEMTs using Cascode Configuration with High Breakdown Voltage (>1900V)
Authors: Tian-Li Wu, Hsin-Jou Ho, Chia-Wei Liu, Yi-Chen Chen
Abstract: This study demonstrates 3D monolithic integration of amorphous indium-gallium-zinc oxide (a-IGZO) thin-film transistors (TFTs) on Gallium Nitride (GaN) high electron mobility transistors (HEMTs) in a cascode configuration, achieving high breakdown voltage capabilities exceeding 1900 V. Two device configurations, differing in a-IGZO channel thickness (30 nm / 10 nm), are fabricated and evaluated. Sample B, with a 10 nm a-IGZO channel, demonstrates superior electrical performance, including a high ON/OFF current ratio (~10^7), low subthreshold swing (SS), and a high breakdown voltage exceeding 1900 V comparable to standalone GaN power HEMTs. The results highlight the feasibility and potential of 3D integrated TFT on GaN power HEMTs, paving the way for new opportunities for the TFTs for high voltage applications.

Paper number 42:
Title: DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel Spectrogram Reconstruction
Authors: Cunhang Fan, Sheng Zhang, Jingjing Zhang, Enrui Liu, Xinhui Li, Minggang Zhao, Zhao Lv
Abstract: Decoding speech from brain signals is a challenging research problem. Although existing technologies have made progress in reconstructing the mel spectrograms of auditory stimuli at the word or letter level, there remain core challenges in the precise reconstruction of minute-level continuous imagined speech: traditional models struggle to balance the efficiency of temporal dependency modeling and information retention in long-sequence decoding. To address this issue, this paper proposes the Dynamic Multiscale Fusion Network (DMF2Mel), which consists of four core components: the Dynamic Contrastive Feature Aggregation Module (DC-FAM), the Hierarchical Attention-Guided Multi-Scale Network (HAMS-Net), the SplineMap attention mechanism, and the bidirectional state space module (convMamba). Specifically, the DC-FAM separates speech-related "foreground features" from noisy "background features" through local convolution and global attention mechanisms, effectively suppressing interference and enhancing the representation of transient signals. HAMS-Net, based on the U-Net framework,achieves cross-scale fusion of high-level semantics and low-level details. The SplineMap attention mechanism integrates the Adaptive Gated Kolmogorov-Arnold Network (AGKAN) to combine global context modeling with spline-based local fitting. The convMamba captures long-range temporal dependencies with linear complexity and enhances nonlinear dynamic modeling capabilities. Results on the SparrKULee dataset show that DMF2Mel achieves a Pearson correlation coefficient of 0.074 in mel spectrogram reconstruction for known subjects (a 48% improvement over the baseline) and 0.048 for unknown subjects (a 35% improvement over the baseline).Code is available at: this https URL.

Paper number 43:
Title: Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series
Authors: Amirhossein Sadough, Mahyar Shahsavari, Mark Wijtvliet, Marcel van Gerven
Abstract: Anomaly detection (AD) plays a vital role across a wide range of real-world domains by identifying data instances that deviate from expected patterns, potentially signaling critical events such as system failures, fraudulent activities, or rare medical conditions. The demand for real-time AD has surged with the rise of the (Industrial) Internet of Things, where massive volumes of multivariate sensor data must be processed instantaneously. Real-time AD requires methods that not only handle high-dimensional streaming data but also operate in a single-pass manner, without the burden of storing historical instances, thereby ensuring minimal memory usage and fast decision-making. We propose DAD, a novel real-time decorrelation-based anomaly detection method for multivariate time series, based on an online decorrelation learning approach. Unlike traditional proximity-based or reconstruction-based detectors that process entire data or windowed instances, DAD dynamically learns and monitors the correlation structure of data sample by sample in a single pass, enabling efficient and effective detection. To support more realistic benchmarking practices, we also introduce a practical hyperparameter tuning strategy tailored for real-time anomaly detection scenarios. Extensive experiments on widely used benchmark datasets demonstrate that DAD achieves the most consistent and superior performance across diverse anomaly types compared to state-of-the-art methods. Crucially, its robustness to increasing dimensionality makes it particularly well-suited for real-time, high-dimensional data streams. Ultimately, DAD not only strikes an optimal balance between detection efficacy and computational efficiency but also sets a new standard for real-time, memory-constrained anomaly detection.

Paper number 44:
Title: Assessing the Alignment of Audio Representations with Timbre Similarity Ratings
Authors: Haokun Tian, Stefan Lattner, Charalampos Saitis
Abstract: Psychoacoustical so-called "timbre spaces" map perceptual similarity ratings of instrument sounds onto low-dimensional embeddings via multidimensional scaling, but suffer from scalability issues and are incapable of generalization. Recent results from audio (music and speech) quality assessment as well as image similarity have shown that deep learning is able to produce embeddings that align well with human perception while being largely free from these constraints. Although the existing human-rated timbre similarity data is not large enough to train deep neural networks (2,614 pairwise ratings on 334 audio samples), it can serve as test-only data for audio models. In this paper, we introduce metrics to assess the alignment of diverse audio representations with human judgments of timbre similarity by comparing both the absolute values and the rankings of embedding distances to human similarity ratings. Our evaluation involves three signal-processing-based representations, twelve representations extracted from pre-trained models, and three representations extracted from a novel sound matching model. Among them, the style embeddings inspired by image style transfer, extracted from the CLAP model and the sound matching model, remarkably outperform the others, showing their potential in modeling timbre similarity.

Paper number 45:
Title: BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning
Authors: Ruohong Liu, Jack Umenberger, Yize Chen
Abstract: Recent years have seen significant advancements in designing reinforcement learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.

Paper number 46:
Title: Space-Filling Regularization for Robust and Interpretable Nonlinear State Space Models
Authors: Hermann Klein, Max Heinz Herkersdorf, Oliver Nelles
Abstract: The state space dynamics representation is the most general approach for nonlinear systems and often chosen for system identification. During training, the state trajectory can deform significantly leading to poor data coverage of the state space. This can cause significant issues for space-oriented training algorithms which e.g. rely on grid structures, tree partitioning, or similar. Besides hindering training, significant state trajectory deformations also deteriorate interpretability and robustness properties. This paper proposes a new type of space-filling regularization that ensures a favorable data distribution in state space via introducing a data-distribution-based penalty. This method is demonstrated in local model network architectures where good interpretability is a major concern. The proposed approach integrates ideas from modeling and design of experiments for state space structures. This is why we present two regularization techniques for the data point distributions of the state trajectories for local affine state space models. Beyond that, we demonstrate the results on a widely known system identification benchmark.

Paper number 47:
Title: SecureSpeech: Prompt-based Speaker and Content Protection
Authors: Belinda Soh Hui Hui, Xiaoxiao Miao, Xin Wang
Abstract: Given the increasing privacy concerns from identity theft and the re-identification of speakers through content in the speech field, this paper proposes a prompt-based speech generation pipeline that ensures dual anonymization of both speaker identity and spoken content. This is addressed through 1) generating a speaker identity unlinkable to the source speaker, controlled by descriptors, and 2) replacing sensitive content within the original text using a name entity recognition model and a large language model. The pipeline utilizes the anonymized speaker identity and text to generate high-fidelity, privacy-friendly speech via a text-to-speech synthesis model. Experimental results demonstrate an achievement of significant privacy protection while maintaining a decent level of content retention and audio quality. This paper also investigates the impact of varying speaker descriptions on the utility and privacy of generated speech to determine potential biases.

Paper number 48:
Title: End-to-end Acoustic-linguistic Emotion and Intent Recognition Enhanced by Semi-supervised Learning
Authors: Zhao Ren, Rathi Adarshi Rammohan, Kevin Scheck, Sheng Li, Tanja Schultz
Abstract: Emotion and intent recognition from speech is essential and has been widely investigated in human-computer interaction. The rapid development of social media platforms, chatbots, and other technologies has led to a large volume of speech data streaming from users. Nevertheless, annotating such data manually is expensive, making it challenging to train machine learning models for recognition purposes. To this end, we propose applying semi-supervised learning to incorporate a large scale of unlabelled data alongside a relatively smaller set of labelled data. We train end-to-end acoustic and linguistic models, each employing multi-task learning for emotion and intent recognition. Two semi-supervised learning approaches, including fix-match learning and full-match learning, are compared. The experimental results demonstrate that the semi-supervised learning approaches improve model performance in speech emotion and intent recognition from both acoustic and text data. The late fusion of the best models outperforms the acoustic and text baselines by joint recognition balance metrics of 12.3% and 10.4%, respectively.

Paper number 49:
Title: HaLert: A Resilient Smart City Architecture for Post-Disaster Based on Wi-Fi HaLow Mesh and SDN
Authors: Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luís Frazão, Nuno Costa, António Pereira
Abstract: Events such as catastrophes and disasters are, in most cases, unpredictable. Consequently, reusing existing infrastructures to develop alternative communication strategies after disasters is essential to minimise the impact of these events on the population's ability to communicate and promptly receive alerts from authorities. In this context, the emergence of smart cities, characterised by dense and geographically distributed IoT networks, presents significant potential for such reuse. This work proposes HaLert, a resilient architecture for smart cities based on a Wi-Fi HaLow IEEE 802.11s mesh network, whose resources can be readily reallocated to support a emergency communication system to exchange messages (including text, location, image, audio, and video) between citizens, authorities, and between both parties. To facilitate remote monitoring and configuration of the network, the architecture incorporates the SDN (Software-Defined Networking) paradigm, supported by a LoRa controlled flooding mesh network. A prototype was developed based on this architecture and tested in a real urban scenario comprising both indoor and outdoor environments. The results demonstrated that, despite the significant impact of obstacles, lack of line-of-sight, and terrain slopes on the latency (average latency between 15 and 54.8 ms) and throughput (upload bitrates between 134 and 726 Kbps and download bitrates between 117 and 682 Kbps) of the Wi-Fi HaLow network, it remained stable and resilient, successfully providing all functionalities associated with the HaLert architecture. The tests conducted on the LoRa network revealed a high average message success rate of 94.96%.

Paper number 50:
Title: Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders
Authors: Dimitrios Bralios, Jonah Casebeer, Paris Smaragdis
Abstract: Neural audio codecs and autoencoders have emerged as versatile models for audio compression, transmission, feature-extraction, and latent-space generation. However, a key limitation is that most are trained to maximize reconstruction fidelity, often neglecting the specific latent structure necessary for optimal performance in diverse downstream applications. We propose a simple, post-hoc framework to address this by modifying the bottleneck of a pre-trained autoencoder. Our method introduces a "Re-Bottleneck", an inner bottleneck trained exclusively through latent space losses to instill user-defined structure. We demonstrate the framework's effectiveness in three experiments. First, we enforce an ordering on latent channels without sacrificing reconstruction quality. Second, we align latents with semantic embeddings, analyzing the impact on downstream diffusion modeling. Third, we introduce equivariance, ensuring that a filtering operation on the input waveform directly corresponds to a specific transformation in the latent space. Ultimately, our Re-Bottleneck framework offers a flexible and efficient way to tailor representations of neural audio models, enabling them to seamlessly meet the varied demands of different applications with minimal additional training.

Paper number 51:
Title: Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition Models
Authors: Chen Feng, Yicheng Lin, Shaojie Zhuo, Chenzheng Su, Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Xiaopeng Zhang
Abstract: Recent advances in Automatic Speech Recognition (ASR) have demonstrated remarkable accuracy and robustness in diverse audio applications, such as live transcription and voice command processing. However, deploying these models on resource constrained edge devices (e.g., IoT device, wearables) still presents substantial challenges due to strict limits on memory, compute and power. Quantization, particularly Post-Training Quantization (PTQ), offers an effective way to reduce model size and inference cost without retraining. Despite its importance, the performance implications of various advanced quantization methods and bit-width configurations on ASR models remain unclear. In this work, we present a comprehensive benchmark of eight state-of-the-art (SOTA) PTQ methods applied to two leading edge-ASR model families, Whisper and Moonshine. We systematically evaluate model performances (i.e., accuracy, memory I/O and bit operations) across seven diverse datasets from the open ASR leaderboard, analyzing the impact of quantization and various configurations on both weights and activations. Built on an extension of the LLM compression toolkit, our framework integrates edge-ASR models, diverse advanced quantization algorithms, a unified calibration and evaluation data pipeline, and detailed analysis tools. Our results characterize the trade-offs between efficiency and accuracy, demonstrating that even 3-bit quantization can succeed on high capacity models when using advanced PTQ techniques. These findings provide valuable insights for optimizing ASR models on low-power, always-on edge devices.

Paper number 52:
Title: LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification
Authors: Changheon Han, Yun Seok Kang, Yuseop Sim, Martin Byung-Guk Jun, Hyung Wook Park
Abstract: Deep learning-based machine listening is broadening the scope of industrial acoustic analysis for applications like anomaly detection and predictive maintenance, thereby improving manufacturing efficiency and reliability. Nevertheless, its reliance on large, task-specific annotated datasets for every new task limits widespread implementation on shop floors. While emerging sound foundation models aim to alleviate data dependency, they are too large and computationally expensive, requiring cloud infrastructure or high-end hardware that is impractical for on-site, real-time deployment. We address this gap with LISTEN (Lightweight Industrial Sound-representable Transformer for Edge Notification), a kilobyte-sized industrial sound foundation model. Using knowledge distillation, LISTEN runs in real-time on low-cost edge devices. On benchmark downstream tasks, it performs nearly identically to its much larger parent model, even when fine-tuned with minimal datasets and training resource. Beyond the model itself, we demonstrate its real-world utility by integrating LISTEN into a complete machine monitoring framework on an edge device with an Industrial Internet of Things (IIoT) sensor and system, validating its performance and generalization capabilities on a live manufacturing shop floor.

Paper number 53:
Title: Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms
Authors: Mateusz Wasala, Mateusz Smolarczyk, Michal Danilowicz, Tomasz Kryjak
Abstract: Accurate position estimation is essential for modern navigation systems deployed in autonomous platforms, including ground vehicles, marine vessels, and aerial drones. In this context, Visual Simultaneous Localisation and Mapping (VSLAM) - which includes Visual Odometry - relies heavily on the reliable extraction of salient feature points from the visual input data. In this work, we propose an embedded implementation of an unsupervised architecture capable of detecting and describing feature points. It is based on a quantised SuperPoint convolutional neural network. Our objective is to minimise the computational demands of the model while preserving high detection quality, thus facilitating efficient deployment on platforms with limited resources, such as mobile or embedded systems. We implemented the solution on an FPGA System-on-Chip (SoC) platform, specifically the AMD/Xilinx Zynq UltraScale+, where we evaluated the performance of Deep Learning Processing Units (DPUs) and we also used the Brevitas library and the FINN framework to perform model quantisation and hardware-aware optimisation. This allowed us to process 640 x 480 pixel images at up to 54 fps on an FPGA platform, outperforming state-of-the-art solutions in the field. We conducted experiments on the TUM dataset to demonstrate and discuss the impact of different quantisation techniques on the accuracy and performance of the model in a visual odometry task.

Paper number 54:
Title: Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases
Authors: Mihails Milehins, Dan Marghitu
Abstract: In the article titled "The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies" and published in the Journal of Computational and Nonlinear Dynamics, the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted in an attempt to validate the models. In this article, these models are augmented by taking into account the effects of external forces that are modeled as time-dependent inputs that belong to a certain function space. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces.

Paper number 55:
Title: Input Conditioned Layer Dropping in Speech Foundation Models
Authors: Abdul Hannan, Daniele Falavigna, Alessio Brutti
Abstract: Curating foundation speech models for edge and IoT settings, where computational resources vary over time, requires dynamic architectures featuring adaptable reduction strategies. One emerging approach is layer dropping ($\mathcal{LD}$) which skips fraction of the layers of a backbone network during inference to reduce the computational load. This allows transforming static models into dynamic ones. However, existing approaches exhibit limitations either in the mode of selecting layers or by significantly modifying the neural architecture. To this end, we propose input-driven $\mathcal{LD}$ that employs the network's input features and a lightweight layer selecting network to determine the optimum combination of processing layers. Extensive experimentation on 4 speech and audio public benchmarks, using two different pre-trained foundation models, demonstrates the effectiveness of our approach, thoroughly outperforming random dropping and producing on-par (or better) results to early exit.

Paper number 56:
Title: Multigranular Evaluation for Brain Visual Decoding
Authors: Weihao Xia, Cengiz Oztireli
Abstract: Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods.

Paper number 57:
Title: Smart Timing Synchronization for Small Data Transmission
Authors: Gautham Prasad, Nadhem Rojbi, Flynn Dowey, Nikhileswar Kota, Lutz Lampe, Gus Vos
Abstract: Cellular Internet-of-things (C-IoT) user equipments (UEs) typically transmit periodic but small amounts of uplink data to the base station. To avoid undergoing a traditional random access procedure prior to every transmission, 5th generation (5G) and newer systems use configured grants for small data transmission (CG-SDT), which is equivalent to its long-term evolution (LTE) counterpart of preconfigured uplink resources (PURs)-based transmission. CG-SDT configures uplink resources to UEs in advance for transmission without a random access procedure. A prerequisite for CG-SDT is that the UEs must use a valid timing advance (TA). This is done by validating a previously held TA before CG-SDT. While this validation is trivial for stationary UEs, mobile UEs often encounter conditions where the previous TA is no longer valid and a new one is to be requested by falling back to legacy random access procedures. This limits the applicability of CG-SDT in mobile UEs. To this end, we propose UE-native smart timing synchronization techniques to counter this drawback and ensure a near-universal adoption of CG-SDT. We introduce new machine learning-aided solutions for validation and prediction of TA for UEs with any type of mobility. We perform comprehensive simulation evaluations across different types of communication environments to demonstrate the effectiveness of our proposed solution in predicting the TA.

Paper number 58:
Title: Conservative Bias Linear Power Flow Approximations: Application to Unit Commitment
Authors: Paprapee Buason, Sidhant Misra, Daniel K. Molzahn
Abstract: The power flow equations are central to many problems in power system planning, analysis, and control. However, their inherent non-linearity and non-convexity present substantial challenges during problem-solving processes, especially for optimization problems. Accordingly, linear approximations are commonly employed to streamline computations, although this can often entail compromises in accuracy and feasibility. This paper proposes an approach termed Conservative Bias Linear Approximations (CBLA) for addressing these limitations. By minimizing approximation errors across a specified operating range while incorporating conservativeness (over- or under-estimating quantities of interest), CBLA strikes a balance between accuracy and tractability by maintaining linear constraints. By allowing users to design loss functions tailored to the specific approximated function, the bias approximation approach significantly enhances approximation accuracy. We illustrate the effectiveness of our proposed approach through several test cases, including its application to a unit commitment problem, where CBLA consistently achieves lower operating costs and improved feasibility compared to traditional linearization methods.

Paper number 59:
Title: Finite Sample Analysis of Distribution-Free Confidence Ellipsoids for Linear Regression
Authors: Szabolcs Szentpéteri, Balázs Csanád Csáji
Abstract: The least squares (LS) estimate is the archetypical solution of linear regression problems. The asymptotic Gaussianity of the scaled LS error is often used to construct approximate confidence ellipsoids around the LS estimate, however, for finite samples these ellipsoids do not come with strict guarantees, unless some strong assumptions are made on the noise distributions. The paper studies the distribution-free Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm which can construct non-asymptotically guaranteed confidence ellipsoids under mild assumptions, such as independent and symmetric noise terms. These ellipsoids have the same center and orientation as the classical asymptotic ellipsoids, only their radii are different, which radii can be computed by convex optimization. Here, we establish high probability non-asymptotic upper bounds for the sizes of SPS outer ellipsoids for linear regression problems and show that the volumes of these ellipsoids decrease at the optimal rate. Finally, the difference between our theoretical bounds and the empirical sizes of the regions are investigated experimentally.

Paper number 60:
Title: Vibration-based damage detection of a trainer jet via multiple input tangential interpolation
Authors: Gabriele Dessena, Marco Civera, Andrés Marcos, Bernardino Chiaia, Oscar E. Bonilla-Manrique
Abstract: Control engineering is a highly developed field, which includes similarly advanced areas like system identification. In structural dynamics, system identification methods are employed for the extraction of modal parameters, such as natural frequencies and mode shapes, from any structure. In turn, these are the main building blocks of vibration-based damage detection. However, traditional comparisons of these parameters are often ambiguous in complex systems, complicating damage detection and assessment. The modified total modal assurance criterion (MTMAC), a metric well-known in the field of finite element model updating, is extended to address this challenge and is proposed as a metric for damage identification and severity assessment. To support the requirement for precise and robust modal identification of Structural Health Monitoring (SHM), the improved Loewner Framework (iLF), known for its reliability and computational performance, is pioneeringly employed within SHM. Since the MTMAC is proposed solely as a damage identification and severity assessment metric, the coordinate modal assurance criterion (COMAC), also a well-established tool, but for damage localisation using mode shapes, is used for completeness. The iLF SHM capabilities are validated through comparisons with traditional methods, including least-squares complex exponential (LSCE) and stochastic subspace identification with canonical variate analysis (SSI-CVA) on a numerical case study of a cantilever beam. Furthermore, the MTMAC is validated against the traditional vibration-based approach, which involves directly comparing natural frequencies and mode shapes. Finally, an experimental dataset from a BAE Systems Hawk T1A trainer jet ground vibration tests is used to demonstrate the iLF and MTMAC capabilities on a real-life, real-size SHM problem, showing their effectiveness in detecting and assessing damage.

Paper number 61:
Title: Impact Assessment of Cyberattacks in Inverter-Based Microgrids
Authors: Kerd Topallaj, Colin McKerrell, Suraj Ramanathan, Ioannis Zografopoulos
Abstract: In recent years, the evolution of modern power grids has been driven by the growing integration of remotely controlled grid assets. Although Distributed Energy Resources (DERs) and Inverter-Based Resources (IBRs) enhance operational efficiency, they also introduce cybersecurity risks. The remote accessibility of such critical grid components creates entry points for attacks that adversaries could exploit, posing threats to the stability of the system. To evaluate the resilience of energy systems under such threats, this study employs real-time simulation and a modified version of the IEEE 39-bus system that incorporates a Microgrid (MG) with solar-based IBR. The study assesses the impact of remote attacks impacting the MG stability under different levels of IBR penetration through hardware-in-the-loop (HIL) simulations. Namely, we analyze voltage, current, and frequency profiles before, during, and after cyberattack-induced disruptions. The results demonstrate that real-time HIL testing is a practical approach to uncover potential risks and develop robust mitigation strategies for resilient MG operations.

Paper number 62:
Title: Learning-Based Two-Way Communications: Algorithmic Framework and Comparative Analysis
Authors: David R. Nickel, Anindya Bijoy Das, David J. Love, Christopher G. Brinton
Abstract: Machine learning (ML)-based feedback channel coding has garnered significant research interest in the past few years. However, there has been limited research exploring ML approaches in the so-called "two-way" setting where two users jointly encode messages and feedback for each other over a shared channel. In this work, we present a general architecture for ML-based two-way feedback coding, and show how several popular one-way schemes can be converted to the two-way setting through our framework. We compare such schemes against their one-way counterparts, revealing error-rate benefits of ML-based two-way coding in certain signal-to-noise ratio (SNR) regimes. We then analyze the tradeoffs between error performance and computational overhead for three state-of-the-art neural network coding models instantiated in the two-way paradigm.

Paper number 63:
Title: Discrete Optimal Transport and Voice Conversion
Authors: Anton Selitskiy, Maitreya Kocharekar
Abstract: In this work, we address the voice conversion (VC) task using a vector-based interface. To align audio embeddings between speakers, we employ discrete optimal transport mapping. Our evaluation results demonstrate the high quality and effectiveness of this method. Additionally, we show that applying discrete optimal transport as a post-processing step in audio generation can lead to the incorrect classification of synthetic audio as real.

Paper number 64:
Title: Autoregressive Stochastic Clock Jitter Compensation in Analog-to-Digital Converters
Authors: Daniele Gerosa, Rui Hou, Vimar Björk, Ulf Gustavsson, Thomas Eriksson
Abstract: This paper deals with the mathematical modeling and compensation of stochastic discrete time clock jitter in Analog-to-Digital Converters (ADCs). Two novel, computationally efficient de-jittering sample pilots-based algorithms for baseband signals are proposed: one consisting in solving a sequence of weighted least-squares problems and another that fully leverages the correlated jitter structure in a Kalman filter-type routine. Alongside, a comprehensive and rigorous mathematical analysis of the linearization errors committed is presented, and the work is complemented with extensive synthetic simulations and performance benchmarking with the scope of gauging and stress-testing the techniques in different scenarios.

Paper number 65:
Title: Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation
Authors: Fangyijie Wang, Kevin Whelan, Félix Balado, Kathleen M. Curran, Guénolé Silvestre
Abstract: Medical image data is less accessible than in other domains due to privacy and regulatory constraints. In addition, labeling requires costly, time-intensive manual image annotation by clinical experts. To overcome these challenges, synthetic medical data generation offers a promising solution. Generative AI (GenAI), employing generative deep learning models, has proven effective at producing realistic synthetic images. This study proposes a novel mask-guided GenAI approach using diffusion models to generate synthetic fetal head ultrasound images paired with segmentation masks. These synthetic pairs augment real datasets for supervised fine-tuning of the Segment Anything Model (SAM). Our results show that the synthetic data captures real image features effectively, and this approach reaches state-of-the-art fetal head segmentation, especially when trained with a limited number of real image-mask pairs. In particular, the segmentation reaches Dice Scores of 94.66\% and 94.38\% using a handful of ultrasound images from the Spanish and African cohorts, respectively. Our code, models, and data are available on GitHub.

Paper number 66:
Title: Hybrid-View Attention Network for Clinically Significant Prostate Cancer Classification in Transrectal Ultrasound
Authors: Zetian Feng, Juan Fu, Xuebin Zou, Hongsheng Ye, Hong Wu, Jianhua Zhou, Yi Wang
Abstract: Prostate cancer (PCa) is a leading cause of cancer-related mortality in men, and accurate identification of clinically significant PCa (csPCa) is critical for timely intervention. Transrectal ultrasound (TRUS) is widely used for prostate biopsy; however, its low contrast and anisotropic spatial resolution pose diagnostic challenges. To address these limitations, we propose a novel hybrid-view attention (HVA) network for csPCa classification in 3D TRUS that leverages complementary information from transverse and sagittal views. Our approach integrates a CNN-transformer hybrid architecture, where convolutional layers extract fine-grained local features and transformer-based HVA models global dependencies. Specifically, the HVA comprises intra-view attention to refine features within a single view and cross-view attention to incorporate complementary information across views. Furthermore, a hybrid-view adaptive fusion module dynamically aggregates features along both channel and spatial dimensions, enhancing the overall representation. Experiments are conducted on an in-house dataset containing 590 subjects who underwent prostate biopsy. Comparative and ablation results prove the efficacy of our method. The code is available at this https URL.

Paper number 67:
Title: PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT
Authors: Yi Liu, Yiyang Wen, Zekun Zhou, Junqi Ma, Linghang Wang, Yucheng Yao, Liu Shi, Qiegen Liu
Abstract: Generative diffusion models have received increasing attention in medical imaging, particularly in limited-angle computed tomography (LACT). Standard diffusion models achieve high-quality image reconstruction but require a large number of sampling steps during inference, resulting in substantial computational overhead. Although skip-sampling strategies have been proposed to improve efficiency, they often lead to loss of fine structural details. To address this issue, we propose a prior information embedding and wavelet feature fusion fast sampling diffusion model for LACT reconstruction. The PWD enables efficient sampling while preserving reconstruction fidelity in LACT, and effectively mitigates the degradation typically introduced by skip-sampling. Specifically, during the training phase, PWD maps the distribution of LACT images to that of fully sampled target images, enabling the model to learn structural correspondences between them. During inference, the LACT image serves as an explicit prior to guide the sampling trajectory, allowing for high-quality reconstruction with significantly fewer steps. In addition, PWD performs multi-scale feature fusion in the wavelet domain, effectively enhancing the reconstruction of fine details by leveraging both low-frequency and high-frequency information. Quantitative and qualitative evaluations on clinical dental arch CBCT and periapical datasets demonstrate that PWD outperforms existing methods under the same sampling condition. Using only 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and 10% gain in SSIM.

Paper number 68:
Title: Revisiting Chien-Hrones-Reswick Method for an Analytical Solution
Authors: Senol Gulgonul
Abstract: This study presents an analytical method for tuning PI controllers in First-Order with Time Delay (FOTD) systems, leveraging the Lambert W function. The Lambert W function enables exact pole placement, yielding analytical expressions for PI gains. The proposed approach identifies a critical condition that achieves a step response without overshoot with minimum settling time, while also providing explicit tuning rules for systems where controlled overshoot is specified. The method demonstrates strong agreement with established empirical Chien-Hrones-Reswick tuning rules for both non-overshooting and overshooting cases, bridging the gap between theoretical analysis and empirical results.

Paper number 69:
Title: Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography
Authors: Peyman Sharifian, Xiaotong Hong, Alireza Karimian, Mehdi Amini, Hossein Arabi
Abstract: Breast density assessment is a crucial component of mammographic interpretation, with high breast density (BI-RADS categories C and D) representing both a significant risk factor for developing breast cancer and a technical challenge for tumor detection. This study proposes an automated deep learning system for robust binary classification of breast density (low: A/B vs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four advanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0, and DenseNet121, each enhanced with channel attention mechanisms. To address the inherent class imbalance, we developed a novel Combined Focal Label Smoothing Loss function that integrates focal loss, label smoothing, and class-balanced weighting. Our preprocessing pipeline incorporated advanced techniques, including contrast-limited adaptive histogram equalization (CLAHE) and comprehensive data augmentation. The individual models were combined through an optimized ensemble voting approach, achieving superior performance (AUC: 0.963, F1-score: 0.952) compared to any single model. This system demonstrates significant potential to standardize density assessments in clinical practice, potentially improving screening efficiency and early cancer detection rates while reducing inter-observer variability among radiologists.

Paper number 70:
Title: Collective Bayesian Decision-Making in a Swarm of Miniaturized Robots for Surface Inspection
Authors: Thiemen Siemensma, Darren Chiu, Sneha Ramshanker, Radhika Nagpal, Bahar Haghighat
Abstract: Robot swarms can effectively serve a variety of sensing and inspection applications. Certain inspection tasks require a binary classification decision. This work presents an experimental setup for a surface inspection task based on vibration sensing and studies a Bayesian two-outcome decision-making algorithm in a swarm of miniaturized wheeled robots. The robots are tasked with individually inspecting and collectively classifying a 1mx1m tiled surface consisting of vibrating and non-vibrating tiles based on the majority type of tiles. The robots sense vibrations using onboard IMUs and perform collision avoidance using a set of IR sensors. We develop a simulation and optimization framework leveraging the Webots robotic simulator and a Particle Swarm Optimization (PSO) method. We consider two existing information sharing strategies and propose a new one that allows the swarm to rapidly reach accurate classification decisions. We first find optimal parameters that allow efficient sampling in simulation and then evaluate our proposed strategy against the two existing ones using 100 randomized simulation and 10 real experiments. We find that our proposed method compels the swarm to make decisions at an accelerated rate, with an improvement of up to 20.52% in mean decision time at only 0.78% loss in accuracy.

Paper number 71:
Title: Information-driven design of imaging systems
Authors: Henry Pinkard, Leyla Kabuli, Eric Markley, Tiffany Chien, Jiantao Jiao, Laura Waller
Abstract: In modern imaging systems that computationally process raw measurements before or instead of human viewing, information content matters more than visual appearance. However, developing information estimators that can handle the complexity of real-world measurements yet remain practical enough for widespread use has proven challenging. We introduce a data-driven approach for estimating mutual information between unknown objects and their noisy measurements. Our technique fits probabilistic models to measurements and their noise processes, quantifying information content without requiring ground truth data or making assumptions about object structure. We validate our approach across diverse applications-color photography, radio astronomy, lensless imaging, and microscopy-demonstrating that information estimates reliably predict system performance. Finally, we introduce Information-Driven Encoder Analysis Learning (IDEAL), which optimizes imaging systems to maximize information capture. Our work unlocks information theory as a powerful, practical tool for analyzing and designing imaging systems across a broad range of applications. A video summarizing this work can be found at: this https URL

Paper number 72:
Title: C3T: Cross-modal Transfer Through Time for Sensor-based Human Activity Recognition
Authors: Abhi Kamboj, Anh Duy Nguyen, Minh N. Do
Abstract: In order to unlock the potential of diverse sensors, we investigate a method to transfer knowledge between time-series modalities using a multimodal \textit{temporal} representation space for Human Activity Recognition (HAR). Specifically, we explore the setting where the modality used in testing has no labeled data during training, which we refer to as Unsupervised Modality Adaptation (UMA). We categorize existing UMA approaches as Student-Teacher or Contrastive Alignment methods. These methods typically compress continuous-time data samples into single latent vectors during alignment, inhibiting their ability to transfer temporal information through real-world temporal distortions. To address this, we introduce Cross-modal Transfer Through Time (C3T), which preserves temporal information during alignment to handle dynamic sensor data better. C3T achieves this by aligning a set of temporal latent vectors across sensing modalities. Our extensive experiments on various camera+IMU datasets demonstrate that C3T outperforms existing methods in UMA by at least 8% in accuracy and shows superior robustness to temporal distortions such as time-shift, misalignment, and dilation. Our findings suggest that C3T has significant potential for developing generalizable models for time-series sensor data, opening new avenues for various multimodal applications.

Paper number 73:
Title: A Multi-Granularity Supervised Contrastive Framework for Remaining Useful Life Prediction of Aero-engines
Authors: Zixuan He, Ziqian Kong, Zhengyu Chen, Yuling Zhan, Zijun Que, Zhengguo Xu
Abstract: Accurate remaining useful life (RUL) predictions are critical to the safe operation of aero-engines. Currently, the RUL prediction task is mainly a regression paradigm with only mean square error as the loss function and lacks research on feature space structure, the latter of which has shown excellent performance in a large number of studies. This paper develops a multi-granularity supervised contrastive (MGSC) framework from plain intuition that samples with the same RUL label should be aligned in the feature space, and address the problems of too large minibatch size and unbalanced samples in the implementation. The RUL prediction with MGSC is implemented on using the proposed multi-phase training strategy. This paper also demonstrates a simple and scalable basic network structure and validates the proposed MGSC strategy on the CMPASS dataset using a convolutional long short-term memory network as a baseline, which effectively improves the accuracy of RUL prediction.

Paper number 74:
Title: Inter-linguistic Phonetic Composition (IPC): A Theoretical and Computational Approach to Enhance Second Language Pronunciation
Authors: Jisang Park, Minu Kim, DaYoung Hong, Jongha Lee
Abstract: Learners of a second language (L2) often unconsciously substitute unfamiliar L2 phonemes with similar phonemes from their native language (L1), even though native speakers of the L2 perceive these sounds as distinct and non-interchangeable. This phonemic substitution leads to deviations from the standard phonological patterns of the L2, creating challenges for learners in acquiring accurate L2 pronunciation. To address this, we propose Inter-linguistic Phonetic Composition (IPC), a novel computational method designed to minimize incorrect phonological transfer by reconstructing L2 phonemes as composite sounds derived from multiple L1 phonemes. Tests with two automatic speech recognition models demonstrated that when L2 speakers produced IPC-generated composite sounds, the recognition rate of target L2 phonemes improved by 20% compared to when their pronunciation was influenced by original phonological transfer patterns. The improvement was observed within a relatively shorter time frame, demonstrating rapid acquisition of the composite sound.

Paper number 75:
Title: Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge
Authors: Ruiyang Qin, Dancheng Liu, Gelei Xu, Zheyu Yan, Chenhui Xu, Yuting Hu, X. Sharon Hu, Jinjun Xiong, Yiyu Shi
Abstract: The combination of Large Language Models (LLM) and Automatic Speech Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can serve as a powerful personalized assistant to enable audio-based interaction for users. Compared to text-based interaction, edge ASR-LLM allows accessible and natural audio interactions. Unfortunately, existing ASR-LLM models are mainly trained in high-performance computing environments and produce substantial model weights, making them difficult to deploy on edge devices. More importantly, to better serve users' personalized needs, the ASR-LLM must be able to learn from each distinct user, given that audio input often contains highly personalized characteristics that necessitate personalized on-device training. Since individually fine-tuning the ASR or LLM often leads to suboptimal results due to modality-specific limitations, end-to-end training ensures seamless integration of audio features and language understanding (cross-modal alignment), ultimately enabling a more personalized and efficient adaptation on edge devices. However, due to the complex training requirements and substantial computational demands of existing approaches, cross-modal alignment between ASR audio and LLM can be challenging on edge devices. In this work, we propose a resource-efficient cross-modal alignment framework that bridges ASR and LLMs on edge devices to handle personalized audio input. Our framework enables efficient ASR-LLM alignment on resource-constrained devices like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while improving the alignment quality by more than 50\%. To the best of our knowledge, this is the first work to study efficient ASR-LLM alignment on resource-constrained edge devices.

Paper number 76:
Title: Semantic Edge Computing and Semantic Communications in 6G Networks: A Unifying Survey and Research Challenges
Authors: Milin Zhang, Mohammad Abdi, Venkat R. Dasari, Francesco Restuccia
Abstract: Semantic Edge Computing (SEC) and Semantic Communications (SemComs) have been proposed as viable approaches to achieve real-time edge-enabled intelligence in sixth-generation (6G) wireless networks. On one hand, SemCom leverages the strength of Deep Neural Networks (DNNs) to encode and communicate the semantic information only, while making it robust to channel distortions by compensating for wireless effects. Ultimately, this leads to an improvement in the communication efficiency. On the other hand, SEC has leveraged distributed DNNs to divide the computation of a DNN across different devices based on their computational and networking constraints. Although significant progress has been made in both fields, the literature lacks a systematic view to connect both fields. In this work, we fulfill the current gap by unifying the SEC and SemCom fields. We summarize the research problems in these two fields and provide a comprehensive review of the state of the art with a focus on their technical strengths and challenges.

Paper number 77:
Title: A Voice-based Triage for Type 2 Diabetes using a Conversational Virtual Assistant in the Home Environment
Authors: Kelvin Summoogum, Debayan Das, Sathish Kumaran, Sumit Bhagra (MD)
Abstract: Incorporating cloud technology with Internet of Medical Things for ubiquitous healthcare has seen many successful applications in the last decade with the advent of machine learning and deep learning techniques. One of these applications, namely voice-based pathology, has yet to receive notable attention from academia and industry. Applying voice analysis to early detection of fatal diseases holds much promise to improve health outcomes and quality of life of patients. In this paper, we propose a novel application of acoustic machine learning based triaging into commoditised conversational virtual assistant systems to pre-screen for onset of diabetes. Specifically, we developed a triaging system which extracts acoustic features from the voices of n=24 older adults when they converse with a virtual assistant and predict the incidence of Diabetes Mellitus (Type 2) or not. Our triaging system achieved hit-rates of 70% and 60% for male and female older adult subjects, respectively. Our proposed triaging uses 7 non-identifiable voice-based features and can operate within resource-constrained embedded systems running voice-based virtual assistants. This application demonstrates the feasibility of applying voice-based pathology analysis to improve health outcomes of older adults within the home environment by early detection of life-changing chronic conditions like diabetes.

Paper number 78:
Title: Multi-dynamic deep image prior for cardiac MRI
Authors: Marc Vornehm, Chong Chen, Muhammad Ahmad Sultan, Syed Murtaza Arshad, Yuchi Han, Florian Knoll, Rizwan Ahmad
Abstract: Cardiovascular magnetic resonance imaging is a powerful diagnostic tool for assessing cardiac structure and function. However, traditional breath-held imaging protocols pose challenges for patients with arrhythmias or limited breath-holding capacity. This work aims to overcome these limitations by developing a reconstruction framework that enables high-quality imaging in free-breathing conditions for various dynamic cardiac MRI protocols. Multi-Dynamic Deep Image Prior (M-DIP), a novel unsupervised reconstruction framework for accelerated real-time cardiac MRI, is introduced. To capture contrast or content variation, M-DIP first employs a spatial dictionary to synthesize a time-dependent intermediate image. Then, this intermediate image is further refined using time-dependent deformation fields that model cardiac and respiratory motion. Unlike prior DIP-based methods, M-DIP simultaneously captures physiological motion and frame-to-frame content variations, making it applicable to a wide range of dynamic applications. We validate M-DIP using simulated MRXCAT cine phantom data as well as free-breathing real-time cine, single-shot late gadolinium enhancement (LGE), and first-pass perfusion data from clinical patients. Comparative analyses against state-of-the-art supervised and unsupervised approaches demonstrate M-DIP's performance and versatility. M-DIP achieved better image quality metrics on phantom data, higher reader scores on in-vivo cine and LGE data, and comparable scores on in-vivo perfusion data relative to another DIP-based approach. M-DIP enables high-quality reconstructions of real-time free-breathing cardiac MRI without requiring external training data. Its ability to model physiological motion and content variations makes it a promising approach for various dynamic imaging applications.

Paper number 79:
Title: Long-Form Speech Generation with Spoken Language Models
Authors: Se Jin Park, Julian Salazar, Aren Jansen, Keisuke Kinoshita, Yong Man Ro, RJ Skerry-Ryan
Abstract: We consider the generative modeling of speech over multiple minutes, a requirement for long-form multimedia generation and audio-native voice assistants. However, textless spoken language models struggle to generate plausible speech past tens of seconds, due to high temporal resolution of speech tokens causing loss of coherence, architectural issues with long-sequence training or extrapolation, and memory costs at inference time. From these considerations we derive SpeechSSM, the first speech language model family to learn from and sample long-form spoken audio (e.g., 16 minutes of read or extemporaneous speech) in a single decoding session without text intermediates. SpeechSSMs leverage recent advances in linear-time sequence modeling to greatly surpass current Transformer spoken LMs in coherence and efficiency on multi-minute generations while still matching them at the utterance level. As we found current spoken language evaluations uninformative, especially in this new long-form setting, we also introduce: LibriSpeech-Long, a benchmark for long-form speech evaluation; new embedding-based and LLM-judged metrics; and quality measurements over length and time. Speech samples, the LibriSpeech-Long dataset, and any future code or model releases can be found at this https URL.

Paper number 80:
Title: "I am bad": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models
Authors: Isha Gupta, David Khachaturov, Robert Mullins
Abstract: The rise of multimodal large language models has introduced innovative human-machine interaction paradigms but also significant challenges in machine learning safety. Audio-Language Models (ALMs) are especially relevant due to the intuitive nature of spoken communication, yet little is known about their failure modes. This paper explores audio jailbreaks targeting ALMs, focusing on their ability to bypass alignment mechanisms. We construct adversarial perturbations that generalize across prompts, tasks, and even base audio samples, demonstrating the first universal jailbreaks in the audio modality, and show that these remain effective in simulated real-world conditions. Beyond demonstrating attack feasibility, we analyze how ALMs interpret these audio adversarial examples and reveal them to encode imperceptible first-person toxic speech - suggesting that the most effective perturbations for eliciting toxic outputs specifically embed linguistic features within the audio signal. These results have important implications for understanding the interactions between different modalities in multimodal models, and offer actionable insights for enhancing defenses against adversarial audio attacks.

Paper number 81:
Title: Token-Domain Multiple Access: Exploiting Semantic Orthogonality for Collision Mitigation
Authors: Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Deniz Gündüz
Abstract: Token communications is an emerging generative semantic communication concept that reduces transmission rates by using context and transformer-based token processing, with tokens serving as universal semantic units. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as ToDMA, where a large number of devices share a tokenizer and a modulation codebook for source and channel coding, respectively. Specifically, the source signal is tokenized into sequences, with each token modulated into a codeword. Codewords from multiple devices are transmitted simultaneously, resulting in overlap at the receiver. The receiver detects the transmitted tokens, assigns them to their respective sources, and mitigates token collisions by leveraging context and semantic orthogonality across the devices' messages. Simulations demonstrate that the proposed ToDMA framework outperforms context-unaware orthogonal and non-orthogonal communication methods in image transmission tasks, achieving lower latency and better image quality.

Paper number 82:
Title: Sensing Rate Optimization for Multi-Band Cooperative ISAC Systems
Authors: Nemanja Stefan Perović, Mark F. Flanagan, Le-Nam Tran
Abstract: Integrated sensing and communication (ISAC) has been recognized as one of the key technologies for future wireless networks, which potentially need to operate in multiple frequency bands to satisfy ever-increasing demands for both communication and sensing services. Motivated by this, we consider the sum sensing rate (SR) optimization for a cooperative ISAC system with linear precoding, where each base station (BS) works in a different frequency band. With this aim, we propose an optimization algorithm based on the semi-definite rank relaxation that introduces covariance matrices as optimization variables, and we apply the inner approximation (IA) method to deal with the nonconvexity of the resulting problem. Simulation results show that the proposed algorithm increases the SR by approximately 25 % and 40 % compared to the case of equal power distribution in a cooperative ISAC system with two and three BSs, respectively. Additionally, the algorithm converges in only a few iterations, while its most beneficial implementation scenario is in the low power regime

Paper number 83:
Title: Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint BS Activation and Beamforming Coordination
Authors: Jie Chen, Xianbin Wang
Abstract: Coordinated beamforming across distributed base stations (BSs) in cell-free wireless infrastructure can efficiently support integrated sensing and communication (ISAC) users by enhancing resource sharing and suppressing interference in the spatial domain. However, intensive coordination among distributed BSs within the ISAC-enabled network poses risks of generating substantial interference to other coexisting networks sharing the same spectrum, while also incurring elevated costs from energy consumption and signaling exchange. To address these challenges, this paper develops an interference-suppressed and cost-efficient cell-free ISAC network, which opportunistically and cooperatively orchestrates distributed radio resources to accommodate the competing demands of sensing and communication (S\&C) services. Specifically, we conceive a radiation footprint control mechanism that autonomously suppresses interference across the entire signal propagation space to safeguard other networks without exchanging channel knowledge signaling. Then, we propose joint BS activation and beamforming coordination to dynamically activate appropriate BSs and orchestrate their spatial beams for service provisioning. Building upon this framework, we formulate a cost-efficient utility maximization problem that considers individual S\&C demands and location-dependent radiation footprint constraints. Since this results in a non-convex optimization problem, we develop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm to find the optimal solution. Additionally, we apply a low-complexity iterative method to obtain near-optimal solutions. Finally, simulation results validate the effectiveness of the proposed algorithms.

Paper number 84:
Title: Analysis of the MICCAI Brain Tumor Segmentation -- Metastases (BraTS-METS) 2025 Lighthouse Challenge: Brain Metastasis Segmentation on Pre- and Post-treatment MRI
Authors: Nazanin Maleki, Raisa Amiruddin, Ahmed W. Moawad, Nikolay Yordanov, Athanasios Gkampenis, Pascal Fehringer, Fabian Umeh, Crystal Chukwurah, Fatima Memon, Bojan Petrovic, Justin Cramer, Mark Krycia, Elizabeth B. Shrickel, Ichiro Ikuta, Gerard Thompson, Lorenna Vidal, Vilma Kosovic, Adam E. Goldman-Yassen, Virginia Hill, Tiffany So, Sedra Mhana, Albara Alotaibi, Nathan Page, Prisha Bhatia, Melisa S. Guelen, Yasaman Sharifi, Marko Jakovljevic, Salma Abosabie, Sara Abosabie, Mohanad Ghonim, Mohamed Ghonim, Amirreza Manteghinejad, Anastasia Janas, Kiril Krantchev, Maruf Adewole, Jake Albrecht, Udunna Anazodo, Sanjay Aneja, Syed Muhammad Anwar, Timothy Bergquist, Veronica Chiang, Verena Chung, Gian Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Nastaran Khalili, Keyvan Farahani, Juan Eugenio Iglesias, Zhifan Jiang, Elaine Johanson, Anahita Fathi Kazerooni, Florian Kofler, Dominic LaBella, Koen Van Leemput, Hongwei Bran Li, Marius George Linguraru, Xinyang Liu, Zeke Meier, Bjoern H Menze, Harrison Moy, Klara Osenberg, Marie Piraud, Zachary Reitman, Russell Takeshi Shinohara, Chunhao Wang, Benedikt Wiestler, Walter Wiggins, Umber Shafique, Klara Willms, Arman Avesta, Khaled Bousabarah, Satrajit Chakrabarty, Nicolo Gennaro, Wolfgang Holler, Manpreet Kaur, Pamela LaMontagne, MingDe Lin, Jan Lost, Daniel S. Marcus, Ryan Maresca, Sarah Merkaj, Gabriel Cassinelli Pedersen, Marc von Reppert, Aristeidis Sotiras, Oleg Teytelboym, Niklas Tillmans, Malte Westerhoff, Ayda Youssef, Devon Godfrey, Scott Floyd, Andreas Rauschecker, Javier Villanueva-Meyer, Irada Pflüger, Jaeyoung Cho, Martin Bendszus, Gianluca Brugnara, Gloria J. Guzman Perez-Carillo, Derek R. Johnson, Anthony Kam
Abstract: Despite continuous advancements in cancer treatment, brain metastatic disease remains a significant complication of primary cancer and is associated with an unfavorable prognosis. One approach for improving diagnosis, management, and outcomes is to implement algorithms based on artificial intelligence for the automated segmentation of both pre- and post-treatment MRI brain images. Such algorithms rely on volumetric criteria for lesion identification and treatment response assessment, which are still not available in clinical practice. Therefore, it is critical to establish tools for rapid volumetric segmentations methods that can be translated to clinical practice and that are trained on high quality annotated data. The BraTS-METS 2025 Lighthouse Challenge aims to address this critical need by establishing inter-rater and intra-rater variability in dataset annotation by generating high quality annotated datasets from four individual instances of segmentation by neuroradiologists while being recorded on video (two instances doing "from scratch" and two instances after AI pre-segmentation). This high-quality annotated dataset will be used for testing phase in 2025 Lighthouse challenge and will be publicly released at the completion of the challenge. The 2025 Lighthouse challenge will also release the 2023 and 2024 segmented datasets that were annotated using an established pipeline of pre-segmentation, student annotation, two neuroradiologists checking, and one neuroradiologist finalizing the process. It builds upon its previous edition by including post-treatment cases in the dataset. Using these high-quality annotated datasets, the 2025 Lighthouse challenge plans to test benchmark algorithms for automated segmentation of pre-and post-treatment brain metastases (BM), trained on diverse and multi-institutional datasets of MRI images obtained from patients with brain metastases.

Paper number 85:
Title: Beyond-Diagonal Dynamic Metasurface Antenna
Authors: Hugo Prod'homme, Philipp del Hougne
Abstract: Dynamic metasurface antennas (DMAs) are an emerging technology for next-generation wireless base stations, distinguished by hybrid analog/digital beamforming capabilities with low hardware complexity. However, the intrinsic coupling between meta-atoms is fixed by static waveguide or cavity structures in existing DMAs, which fundamentally constrains the achievable performance. Here, we introduce reconfigurable intrinsic coupling mechanisms between meta-atoms, yielding finer control over the DMA's analog signal processing capabilities. This novel hardware is coined "beyond-diagonal DMA" (BD-DMA), in line with established BD-RIS terminology. Considering realistic hardware constraints, we derive a physics-consistent system model revealing (correlated) "beyond-diagonal" programmability. We also present an equivalent formulation with (uncorrelated) "diagonal" programmability. Based on the latter, we propose a general and efficient mutual-coupling-aware optimization algorithm. Physics-consistent simulations validate the performance enhancement enabled by reconfigurable intrinsic coupling mechanisms in BD-DMAs. The BD-DMA benefits grow with the mutual coupling strength.

Paper number 86:
Title: HLSTester: Efficient Testing of Behavioral Discrepancies with LLMs for High-Level Synthesis
Authors: Kangwei Xu, Bing Li, Grace Li Zhang, Ulf Schlichtmann
Abstract: In high-level synthesis (HLS), C/C++ programs with synthesis directives are used to generate circuits for FPGA implementations. However, hardware-specific and platform-dependent characteristics in these implementations can introduce behavioral discrepancies between the original C/C++ programs and the circuits after high-level synthesis. Existing methods for testing behavioral discrepancies in HLS are still immature, and the testing workflow requires significant human efforts. To address this challenge, we propose HLSTester, a large language model (LLM) aided testing framework that efficiently detects behavioral discrepancies in HLS. To mitigate hallucinations in LLMs and enhance prompt quality, the testbenches for original C/C++ programs are leveraged to guide LLMs in generating HLS-compatible testbenches, effectively eliminating certain traditional C/C++ constructs that are incompatible with HLS tools. Key variables are pinpointed through a backward slicing technique in both C/C++ and HLS programs to monitor their runtime spectra, enabling an in-depth analysis of the discrepancy symptoms. To reduce test time, a testing input generation mechanism is introduced to integrate dynamic mutation with insights from an LLM-based progressive reasoning chain. In addition, repetitive hardware testing is skipped by a redundancy-aware filtering technique for the generated test inputs. Experimental results demonstrate that the proposed LLM-aided testing framework significantly accelerates the testing workflow while achieving higher testbench simulation pass rates compared with the traditional method and the direct use of LLMs on the same HLS programs.

Paper number 87:
Title: What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training
Authors: Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum
Abstract: How language-specific are speech representations learned by self-supervised models? Existing work has shown that a range of linguistic features can be successfully decoded from end-to-end models trained only on speech recordings. However, it's less clear to what extent pre-training on specific languages improves language-specific linguistic information. Here we test the encoding of Dutch phonetic and lexical information in internal representations of self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the representation of Dutch linguistic features as compared to pre-training on similar amounts of English or larger amounts of multilingual data. This language-specific advantage is well-detected by trained clustering or classification probes, and partially observable using zero-shot metrics. Furthermore, the language-specific benefit on linguistic feature encoding aligns with downstream performance on Automatic Speech Recognition.

Paper number 88:
Title: Benchmarking Time-localized Explanations for Audio Classification Models
Authors: Cecilia Bolaños, Leonardo Pepino, Martin Meza, Luciana Ferrer
Abstract: Most modern approaches for audio processing are opaque, in the sense that they do not provide an explanation for their decisions. For this reason, various methods have been proposed to explain the outputs generated by these models. Good explanations can result in interesting insights about the data or the model, as well as increase trust in the system. Unfortunately, evaluating the quality of explanations is far from trivial since, for most tasks, there is no clear ground truth explanation to use as reference. In this work, we propose a benchmark for time-localized explanations for audio classification models that uses time annotations of target events as a proxy for ground truth explanations. We use this benchmark to systematically optimize and compare various approaches for model-agnostic post-hoc explanation, obtaining, in some cases, close to perfect explanations. Finally, we illustrate the utility of the explanations for uncovering spurious correlations.

Paper number 89:
Title: Estimation of superconducting cavity bandwidth and detuning using a Luenberger observer
Authors: Bozo Richter, Andrea Bellandi, Julien Branlard, Leon Speidel, Annika Eichler
Abstract: Enabled by progress in superconducting technology, several continuous wave linear accelerators are foreseen in the next decade. For these machines, it is of crucial importance to track the main cavity parameters, such as the resonator bandwidth and detuning. The bandwidth yields information on the superconducting state of the cavity. The detuning should be minimized to limit the required power to operate the cavity. The estimation of these parameters is commonly implemented in the digital electronics of the Low-Level RF control system to minimize the computation delay. In this proceeding, we present a way to compute the bandwidth and detuning using a Luenberger observer. In contrast to previous methods, a state observer yields estimations at the native control system sample rate without explicitly filtering the input signals. Additionally, the error convergence properties of the estimations can be controlled intuitively by adjusting gain parameters. Implementation considerations and test results on the derived observer are presented in the manuscript.

Paper number 90:
Title: Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention
Authors: HyeYoung Lee, Muhammad Nadeem
Abstract: Speech Emotion Recognition (SER) traditionally relies on auditory data analysis for emotion classification. Several studies have adopted different methods for SER. However, existing SER methods often struggle to capture subtle emotional variations and generalize across diverse datasets. In this article, we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to bridge the gap between computational emotion processing and human auditory perception. To further improve robustness and feature diversity, we propose a novel 1D-CNN-based SER framework that integrates data augmentation techniques. MFCC features extracted from the augmented data are processed using a 1D Convolutional Neural Network (CNN) architecture enhanced with channel and spatial attention mechanisms. These attention modules allow the model to highlight key emotional patterns, enhancing its ability to capture subtle variations in speech signals. The proposed method delivers cutting-edge performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS, 89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO. Experimental results show new benchmarks in SER, demonstrating the effectiveness of our approach in recognizing emotional expressions with high precision. Our evaluation demonstrates that the integration of advanced Deep Learning (DL) methods substantially enhances generalization across diverse datasets, underscoring their potential to advance SER for real-world deployment in assistive technologies and human-computer interaction.

Paper number 91:
Title: Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting
Authors: Fei Teng, Kai Luo, Sheng Wu, Siyu Li, Pujun Guo, Jiale Wei, Kunyu Peng, Jiaming Zhang, Kailun Yang
Abstract: Panoramic perception holds significant potential for autonomous driving, enabling vehicles to acquire a comprehensive 360° surround view in a single shot. However, autonomous driving is a data-driven task. Complete panoramic data acquisition requires complex sampling systems and annotation pipelines, which are time-consuming and labor-intensive. Although existing street view generation models have demonstrated strong data regeneration capabilities, they can only learn from the fixed data distribution of existing datasets and cannot achieve high-quality, controllable panoramic generation. In this paper, we propose the first panoramic generation method Percep360 for autonomous driving. Percep360 enables coherent generation of panoramic data with control signals based on the stitched panoramic data. Percep360 focuses on two key aspects: coherence and controllability. Specifically, to overcome the inherent information loss caused by the pinhole sampling process, we propose the Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama generation as a spatially continuous diffusion process, bridging the gaps between different data distributions. Additionally, to achieve the controllable generation of panoramic images, we propose a Probabilistic Prompting Method (PPM). PPM dynamically selects the most relevant control cues, enabling controllable panoramic image generation. We evaluate the effectiveness of the generated images from three perspectives: image quality assessment (i.e., no-reference and with reference), controllability, and their utility in real-world Bird's Eye View (BEV) segmentation. Notably, the generated data consistently outperforms the original stitched images in no-reference quality metrics and enhances downstream perception models. The source code will be publicly available at this https URL.
    