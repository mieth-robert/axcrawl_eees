
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis
Authors: Xu Chen, Yuan Huang, Benn Jessney, Jason Sangha, Sophie Gu, Carola-Bibiane Schönlieb, Martin Bennett, Michael Roberts
Abstract: Artificial intelligence (AI) methodologies hold great promise for the rapid and accurate diagnosis of coronary artery disease (CAD) from intravascular optical coherent tomography (IVOCT) images. Numerous papers have been published describing AI-based models for different diagnostic tasks, yet it remains unclear which models have potential clinical utility and have been properly validated. This systematic review considered published literature between January 2015 and February 2023 describing AI-based diagnosis of CAD using IVOCT. Our search identified 5,576 studies, with 513 included after initial screening and 35 studies included in the final systematic review after quality screening. Our findings indicate that most of the identified models are not currently suitable for clinical use, primarily due to methodological flaws and underlying biases. To address these issues, we provide recommendations to improve model quality and research practices to enhance the development of clinically useful AI products.

Paper number 2:
Title: Rethinking the Upsampling Layer in Hyperspectral Image Super Resolution
Authors: Haohan Shi, Fei Zhou, Xin Sun, Jungong Han
Abstract: Deep learning has achieved significant success in single hyperspectral image super-resolution (SHSR); however, the high spectral dimensionality leads to a heavy computational burden, thus making it difficult to deploy in real-time scenarios. To address this issue, this paper proposes a novel lightweight SHSR network, i.e., LKCA-Net, that incorporates channel attention to calibrate multi-scale channel features of hyperspectral images. Furthermore, we demonstrate, for the first time, that the low-rank property of the learnable upsampling layer is a key bottleneck in lightweight SHSR methods. To address this, we employ the low-rank approximation strategy to optimize the parameter redundancy of the learnable upsampling layer. Additionally, we introduce a knowledge distillation-based feature alignment technique to ensure the low-rank approximated network retains the same feature representation capacity as the original. We conducted extensive experiments on the Chikusei, Houston 2018, and Pavia Center datasets compared to some SOTAs. The results demonstrate that our method is competitive in performance while achieving speedups of several dozen to even hundreds of times compared to other well-performing SHSR methods.

Paper number 3:
Title: Frequency Diverse Array OFDM System for Joint Communication and Sensing
Authors: Marcin Wachowiak, André Bourdoux, Sofie Pollin
Abstract: The frequency-diverse array (FDA) offers a time-varying beamforming capability without the use of phase shifters. The autoscanning property is achieved by applying a frequency offset between the antennas. This paper analyzes the performance of an FDA joint communication and sensing system with the orthogonal frequency-division multiplexing (OFDM) modulation. The performance of the system is evaluated against the scanning frequency, number of antennas and number of subcarriers. The utilized metrics; integrated sidelobe level (ISL) and error vector magnitude (EVM) allow for straightforward comparison with a standard single-input single-output (SISO) OFDM system.

Paper number 4:
Title: Beamforming with Oversampled Time-Modulated Arrays
Authors: Marcin Wachowiak, André Bourdoux, Sofie Pollin
Abstract: The time-modulated array (TMA) is a simple array architecture in which each antenna is connected via a multi-throw switch. The switch acts as a modulator switching state faster than the symbol rate. The phase shifting and beamforming is achieved by a cyclic shift of the periodical modulating signal across antennas. In this paper, the TMA mode of operation is proposed to improve the resolution of a conventional phase shifter. The TMAs are analyzed under constrained switching frequency being a small multiple of the symbol rate. The presented generic signal model gives insight into the magnitude, phase and spacing of the harmonic components generated by the quantized modulating sequence. It is shown that the effective phase-shifting resolution can be improved multiplicatively by the oversampling factor ($O$) at the cost of introducing harmonics. Finally, the array tapering with an oversampled modulating signal is proposed. The oversampling provides $O+1$ uniformly distributed tapering amplitudes.

Paper number 5:
Title: Optimizing Bidding Curves for Renewable Energy in Two-Settlement Electricity Markets
Authors: Dongwei Zhao, Stefanos Delikaraogloub, Vladimir Dvorkin Alberto J. Lamadrid L., Audun Botterud
Abstract: Coordination of day-ahead and real-time electricity markets is imperative for cost-effective electricity supply and also to provide efficient incentives for the energy transition. Although stochastic market designs feature the least-cost coordination, they are incompatible with current deterministic markets. This paper proposes a new approach for compatible coordination in two-settlement markets based on benchmark bidding curves for variable renewable energy. These curves are optimized based on a bilevel optimization problem, anticipating per-scenario responses of deterministic market-clearing problems and ultimately minimizing the expected cost across day-ahead and real-time markets. Although the general bilevel model is challenging to solve, we theoretically prove that a single-segment bidding curve with a zero bidding price is sufficient to achieve system optimality if the marginal cost of variable renewable energy is zero, thus addressing the computational challenge. In practice, variable renewable energy producers can be allowed to bid multi-segment curves with non-zero prices. We test the bilevel framework for both single- and multiple-segment bidding curves under the assumption of fixed bidding prices. We leverage duality theory and McCormick envelopes to derive the linear programming approximation of the bilevel problem, which scales to practical systems such as a 1576-bus NYISO system. We benchmark the proposed coordination and find absolute dominance over the baseline solution, which assumes that renewables agnostically bid their expected forecasts. We also demonstrate that our proposed scheme provides a good approximation of the least-cost, yet unattainable in practice, stochastic market outcome.

Paper number 6:
Title: Distillation-Driven Diffusion Model for Multi-Scale MRI Super-Resolution: Make 1.5T MRI Great Again
Authors: Zhe Wang, Yuhua Ru, Fabian Bauer, Aladine Chetouani, Fang Chen, Liping Zhang, Didier Hans, Rachid Jennane, Mohamed Jarraya, Yung Hsin Chen
Abstract: Magnetic Resonance Imaging (MRI) offers critical insights into microstructural details, however, the spatial resolution of standard 1.5T imaging systems is often limited. In contrast, 7T MRI provides significantly enhanced spatial resolution, enabling finer visualization of anatomical structures. Though this, the high cost and limited availability of 7T MRI hinder its widespread use in clinical settings. To address this challenge, a novel Super-Resolution (SR) model is proposed to generate 7T-like MRI from standard 1.5T MRI scans. Our approach leverages a diffusion-based architecture, incorporating gradient nonlinearity correction and bias field correction data from 7T imaging as guidance. Moreover, to improve deployability, a progressive distillation strategy is introduced. Specifically, the student model refines the 7T SR task with steps, leveraging feature maps from the inference phase of the teacher model as guidance, aiming to allow the student model to achieve progressively 7T SR performance with a smaller, deployable model size. Experimental results demonstrate that our baseline teacher model achieves state-of-the-art SR performance. The student model, while lightweight, sacrifices minimal performance. Furthermore, the student model is capable of accepting MRI inputs at varying resolutions without the need for retraining, significantly further enhancing deployment flexibility. The clinical relevance of our proposed method is validated using clinical data from Massachusetts General Hospital. Our code is available at this https URL.

Paper number 7:
Title: SDM Optical Systems with MMSE Equalizers: Information Rates and Performance Monitoring
Authors: Lucas Alves Zischler, Darli A. A. Mello
Abstract: The information rate of coupled space-division multiplexing (SDM) transmission systems is impaired by the stochastic effects of mode-dependent gain (MDG) and mode-dependent loss (MDL), turning it into a random variable and reducing its average value. In systems operating with minimum mean squared error (MMSE) equalizers and no channel-state information (CSI), co-channel interference further reduces the instantaneous and average information rates. Analytical solutions for the average information rate in MDG- and MDL-impaired systems under strong coupling have been presented in early studies assuming ideal maximum-likelihood (ML) equalization. However, to the best of our knowledge, a solution encompassing co-channel interference under MMSE equalization has not been presented yet. In this work, we derive statistical models for the MMSE equalizer coefficients and develop analytical solutions for the post-filtering information rate. We also use these statistical models and analytical solutions to carry out MDG and signal-to-noise ratio (SNR) monitoring in coupled SDM systems. The derived analytical solutions and monitoring techniques are validated by Monte-Carlo simulations, exhibiting a suitable accuracy within practical operational values.

Paper number 8:
Title: One Stack, Diverse Vehicles: Checking Safe Portability of Automated Driving Software
Authors: Vladislav Nenchev
Abstract: Integrating an automated driving software stack into vehicles with variable configuration is challenging, especially due to different hardware characteristics. Further, to provide software updates to a vehicle fleet in the field, the functional safety of every affected configuration has to be ensured. These additional demands for dependability and the increasing hardware diversity in automated driving make rigorous automatic analysis essential. This paper addresses this challenge by using formal portability checking of adaptive cruise controller code for different vehicle configurations. Given a formal specification of the safe behavior, models of target configurations are derived, which capture relevant effects of sensors, actuators and computing platforms. A corresponding safe set is obtained and used to check if the desired behavior is achievable on all targets. In a case study, portability checking of a traditional and a neural network controller are performed automatically within minutes for each vehicle hardware configuration. The check provides feedback for necessary adaptations of the controllers, thus, allowing rapid integration and testing of software or parameter changes.

Paper number 9:
Title: PSO-Net: Development of an automated psoriasis assessment system using attention-based interpretable deep neural networks
Authors: Sharif A. Kamran, Molly V. Lucas, Brendon Lutnick, Chaitanya Parmar, Basudha Pal, Asha Patel Shah, David Apfel, Steven Fakharzadeh, Lloyd Miller, Stephen Yip, Kristopher Standish, Gabriela Oana Cula
Abstract: Psoriasis is a chronic skin condition that requires long-term treatment and monitoring. Although, the Psoriasis Area and Severity Index (PASI) is utilized as a standard measurement to assess psoriasis severity in clinical trials, it has many drawbacks such as (1) patient burden for in-person clinic visits for assessment of psoriasis, (2) time required for investigator scoring and (3) variability of inter- and intra-rater scoring. To address these drawbacks, we propose a novel and interpretable deep learning architecture called PSO-Net, which maps digital images from different anatomical regions to derive attention-based scores. Regional scores are further combined to estimate an absolute PASI score. Moreover, we devise a novel regression activation map for interpretability through ranking attention scores. Using this approach, we achieved inter-class correlation scores of 82.2% [95% CI: 77- 87%] and 87.8% [95% CI: 84-91%] with two different clinician raters, respectively.

Paper number 10:
Title: A General-Purpose Neuromorphic Sensor based on Spiketrum Algorithm: Hardware Details and Real-life Applications
Authors: MHD Anas Alsakkal, Runze Wang, Jayawan Wijekoon, Piotr Dudek
Abstract: Spiking Neural Networks (SNNs) offer a biologically inspired computational paradigm, enabling energy-efficient data processing through spike-based information transmission. Despite notable advancements in hardware for SNNs, spike encoding has largely remained software-dependent, limiting efficiency. This paper addresses the need for adaptable and resource-efficient spike encoding hardware by presenting an area-optimized hardware implementation of the Spiketrum algorithm, which encodes time-varying analogue signals into spatiotemporal spike patterns. Unlike earlier performance-optimized designs, which prioritize speed, our approach focuses on reducing hardware footprint, achieving a 52% reduction in Block RAMs (BRAMs), 31% fewer Digital Signal Processing (DSP) slices, and a 6% decrease in Look-Up Tables (LUTs). The proposed implementation has been verified on an FPGA and successfully integrated into an IC using TSMC180 technology. Experimental results demonstrate the system's effectiveness in real-world applications, including sound and ECG classification. This work highlights the trade-offs between performance and resource efficiency, offering a flexible, scalable solution for neuromorphic systems in power-sensitive applications like cochlear implants and neural devices.

Paper number 11:
Title: An Adversarial Approach to Register Extreme Resolution Tissue Cleared 3D Brain Images
Authors: Abdullah Naziba, Clinton Fookes, Dimitri Perrin
Abstract: We developed a generative patch based 3D image registration model that can register very high resolution images obtained from a biochemical process name tissue clearing. Tissue clearing process removes lipids and fats from the tissue and make the tissue transparent. When cleared tissues are imaged with Light-sheet fluorescent microscopy, the resulting images give a clear window to the cellular activities and dynamics inside the this http URL the images obtained are very rich with cellular information and hence their resolution is extremely high (eg .2560x2160x676). Analyzing images with such high resolution is a difficult task for any image analysis this http URL registration is a common step in image analysis pipeline when comparison between images are required. Traditional image registration methods fail to register images with such extant. In this paper we addressed this very high resolution image registration issue by proposing a patch-based generative network named InvGAN. Our proposed network can register very high resolution tissue cleared images. The tissue cleared dataset used in this paper are obtained from a tissue clearing protocol named CUBIC. We compared our method both with traditional and deep-learning based registration this http URL different versions of CUBIC dataset are used, representing two different resolutions 25% and 100% respectively. Experiments on two different resolutions clearly show the impact of resolution on the registration quality. At 25% resolution, our method achieves comparable registration accuracy with very short time (7 minutes approximately). At 100% resolution, most of the traditional registration methods fail except Elastix registration this http URL takes 28 hours to register where proposed InvGAN takes only 10 minutes.

Paper number 12:
Title: Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential
Authors: Chenyu Gao, Kaiwen Xu, Michael E. Kim, Lianrui Zuo, Zhiyuan Li, Derek B. Archer, Timothy J. Hohman, Ann Zenobia Moore, Luigi Ferrucci, Lori L. Beason-Held, Susan M. Resnick, Christos Davatzikos, Jerry L. Prince, Bennett A. Landman
Abstract: Defacing is often applied to head magnetic resonance image (MRI) datasets prior to public release to address privacy concerns. The alteration of facial and nearby voxels has provoked discussions about the true capability of these techniques to ensure privacy as well as their impact on downstream tasks. With advancements in deep generative models, the extent to which defacing can protect privacy is uncertain. Additionally, while the altered voxels are known to contain valuable anatomical information, their potential to support research beyond the anatomical regions directly affected by defacing remains uncertain. To evaluate these considerations, we develop a refacing pipeline that recovers faces in defaced head MRIs using cascaded diffusion probabilistic models (DPMs). The DPMs are trained on images from 180 subjects and tested on images from 484 unseen subjects, 469 of whom are from a different dataset. To assess whether the altered voxels in defacing contain universally useful information, we also predict computed tomography (CT)-derived skeletal muscle radiodensity from facial voxels in both defaced and original MRIs. The results show that DPMs can generate high-fidelity faces that resemble the original faces from defaced images, with surface distances to the original faces significantly smaller than those of a population average face (p < 0.05). This performance also generalizes well to previously unseen datasets. For skeletal muscle radiodensity predictions, using defaced images results in significantly weaker Spearman's rank correlation coefficients compared to using original images (p < 10-4). For shin muscle, the correlation is statistically significant (p < 0.05) when using original images but not statistically significant (p > 0.05) when any defacing method is applied, suggesting that defacing might not only fail to protect privacy but also eliminate valuable information.

Paper number 13:
Title: Tracking Error Based Fault Tolerant Scheme for Marine Vehicles with Thruster Redundancy
Authors: Ji-Hong Li, Hyungjoo Kang, Min-Gyu Kim, Mun-Jik Lee, Han-Sol Jin, Gun Rae Cho
Abstract: This paper proposes an active model-based fault and failure tolerant control scheme for a class of marine vehicles with thruster redundancy. Unlike widely used state and parameter estimation methods, where the estimation errors are utilized to generate residual, in this paper we directly apply the trajectory tracking error terms to construct residual and detect thruster fault and failure in the steady state of the tracking system. As for identification or diagnosis, this paper proposes a novel scheme through a detailed examination of the tracking error trends and the combinations of thruster configurations. Since this fault detection and identification operates within the same closed-loop of the tracking control system, control reconfiguration can be easily achieved by adjusting the weight parameter of the isolated thruster to minimize tracking errors or residual. Numerical studies with the real world vehicle model is also carried out to verify the effectiveness of the proposed method.

Paper number 14:
Title: Non-Asymptotic Analysis of Subspace Identification for Stochastic Systems Using Multiple Trajectories
Authors: Shuai Sun, Yilin Mo
Abstract: This paper is concerned with the analysis of identification errors for $n$-dimensional discrete-time Linear Time-Invariant (LTI) systems with $m$ outputs and no external inputs, using Subspace Identification Methods (SIM) with finite sample data. We provide non-asymptotic high-probability upper bounds for matrices $A,C$, the Kalman filter gain $K$, and the closed loop matrix $A-KC $, based on multiple sample trajectories, and further give the first non-asymptotic high-probability upper bounds for the system poles, which cover both (marginally) stable systems and unstable systems. We show that, with high probability, the non-asymptotic estimation errors of these matrices decay at a rate of at least $ \mathcal{O}(\sqrt{1/N}) $, while the estimation error of the system poles decays at a rate of at least $ \mathcal{O}(N^{\frac{1}{2n}}) $, where $ N $ represents the number of sample trajectories. Furthermore, we prove that SIMs become ill-conditioned when the ratio $n/m$ is large, regardless of the system parameters. Numerical experiments are conducted to validate the non-asymptotic results and the ill-conditionedness of SIM.

Paper number 15:
Title: Scalable Distributed Reproduction Numbers of Network Epidemics with Differential Privacy
Authors: Bo Chen, Baike She, Calvin Hawkins, Philip E. Paré, Matthew T. Hale
Abstract: Reproduction numbers are widely used for the estimation and prediction of epidemic spreading processes over networks. However, conventional reproduction numbers of an overall network do not indicate where an epidemic is spreading. Therefore, we propose a novel notion of local distributed reproduction numbers to capture the spreading behaviors of each node in a network. We first show how to compute them and then use them to derive new conditions under which an outbreak can occur. These conditions are then used to derive new conditions for the existence, uniqueness, and stability of equilibrium states of the underlying epidemic model. Building upon these local distributed reproduction numbers, we define cluster distributed reproduction numbers to model the spread between clusters composed of nodes. Furthermore, we demonstrate that the local distributed reproduction numbers can be aggregated into cluster distributed reproduction numbers at different scales. However, both local and cluster distributed reproduction numbers can reveal the frequency of interactions between nodes in a network, which raises privacy concerns. Thus, we next develop a privacy framework that implements a differential privacy mechanism to provably protect the frequency of interactions between nodes when computing distributed reproduction numbers. Numerical experiments show that, even under differential privacy, the distributed reproduction numbers provide accurate estimates of the epidemic spread while also providing more insights than conventional reproduction numbers.

Paper number 16:
Title: Integrated Sensing and Communication System Based on Radio Frequency Resonance Beam
Authors: Yixuan Guo, Shuaifan Xia, Mingliang Xiong, Qingwen Liu, Shengli Zhou, Wen Fang, Qingwei Jiang, Gang Yan, Jiangchuan Mu
Abstract: To address the challenge of complex beam control in traditional multiple-input multiple-output (MIMO) systems, research has proposed establishing adaptive beam alignment by utilizing retro-directive antenna (RDA) arrays to create echo resonance between the base station (BS) and user equipment (UE), thereby reducing system computational load. However, in conventional resonant beam systems (RBS), the use of the same frequency for uplink and downlink inevitably leads to echo interference issues. Therefore, this paper proposes an innovative design for an resonance beam-based integrated sensing and communication (RB-ISAC) system to achieve efficient passive sensing and bidirectional communication. In this system, the UE does not actively transmit signals but instead relies on a passive phase conjugation and frequency conversion structure to separate the uplink and downlink carrier frequencies. Additionally, through effective compensation for signal propagation loss, resonance is achieved after multiple iterations, at which point the beam's field distribution becomes a low-diffraction-loss, high-focusing pattern, automatically aligning the transmitter with the receiver. This enables high-precision passive positioning while facilitating uplink and downlink communication. Simulation results demonstrate that the proposed system can achieve resonance after multiple iterations, and can support uplink and downlink communication within a range of 5 meters while achieving passive direction of arrival (DOA) estimation with an error of less than 2 degrees.

Paper number 17:
Title: Fully Distributed and Quantized Algorithm for MPC-based Autonomous Vehicle Platooning Optimization
Authors: Mohammadreza Doostmohammadian, Alireza Aghasi, Hamid R. Rabiee
Abstract: Intelligent transportation systems have recently emerged to address the growing interest for safer, more efficient, and sustainable transportation solutions. In this direction, this paper presents distributed algorithms for control and optimization over vehicular networks. First, we formulate the autonomous vehicle platooning framework based on model-predictive-control (MPC) strategies and present its objective optimization as a cooperative quadratic cost function. Then, we propose a distributed algorithm to locally optimize this objective at every vehicle subject to data quantization over the communication network of vehicles. In contrast to most existing literature that assumes ideal communication channels, log-scale data quantization over the network is addressed in this work, which is more realistic and practical. In particular, we show by simulation that the proposed log-quantized algorithm reaches optimal convergence with less residual and optimality gap. This outperforms the existing literature considering uniform quantization which leads to a large optimality gap and residual.

Paper number 18:
Title: Distributed Observer Design for Tracking Platoon of Connected and Autonomous Vehicles
Authors: Mohammadreza Doostmohammadian, Hamid R. Rabiee
Abstract: Intelligent transportation systems (ITS) aim to advance innovative strategies relating to different modes of transport, traffic management, and autonomous vehicles. This paper studies the platoon of connected and autonomous vehicles (CAV) and proposes a distributed observer to track the state of the CAV dynamics. First, we model the CAV dynamics via an LTI interconnected system. Then, a consensus-based strategy is proposed to infer the state of the CAV dynamics based on local information exchange over the communication network of vehicles. A linear-matrix-inequality (LMI) technique is adopted for the block-diagonal observer gain design such that this gain is associated in a distributed way and locally to every vehicle. The distributed observer error dynamics is then shown to follow the structure of the Kronecker matrix product of the system dynamics and the adjacency matrix of the CAV network. The notions of survivable network design and redundant observer scheme are further discussed in the paper to address resilience to link and node failure. Finally, we verify our theoretical contributions via numerical simulations.

Paper number 19:
Title: RIS Meets O-RAN: A Practical Demonstration of Multi-user RIS Optimization through RIC
Authors: Ali Fuat Sahin, Onur Salan, Ibrahim Hokelek, Ali Gorcin
Abstract: Open Radio Access Network (O-RAN) along with artificial intelligence, machine learning, cloud and edge networking, and virtualization are important enablers for designing flexible and software-driven programmable wireless networks. In addition, Reconfigurable Intelligent Surfaces (RIS) represent an innovative technology to direct incoming radio signals toward desired locations by software-controlled passive reflecting antenna elements. Despite their distinctive potential, there has been limited exploration of integrating RIS with the O-RAN framework, an area that holds promise for enhancing next-generation wireless systems. This paper addresses this gap by designing and developing the RIS optimization xApps within an O-RAN-based real-time 5G environment. We perform extensive measurement experiments using an end-to-end 5G testbed including the RIS prototype in a multi-user scenario. The results demonstrate that the RIS can be utilized either to boost the performance of the selected user or to provide the fairness among the users or to balance the tradeoff between the performance and fairness.

Paper number 20:
Title: Full-scale Representation Guided Network for Retinal Vessel Segmentation
Authors: Sunyong Seo, Huisu Yoon, Semin Kim, Jongha Lee
Abstract: The U-Net architecture and its variants have remained state-of-the-art (SOTA) for retinal vessel segmentation over the past decade. In this study, we introduce a Full Scale Guided Network (FSG-Net), where the feature representation network with modernized convolution blocks extracts full-scale information and the guided convolution block refines that information. Attention-guided filter is introduced to the guided convolution block under the interpretation that the filter behaves like the unsharp mask filter. Passing full-scale information to the attention block allows for the generation of improved attention maps, which are then passed to the attention-guided filter, resulting in performance enhancement of the segmentation network. The structure preceding the guided convolution block can be replaced by any U-Net variant, which enhances the scalability of the proposed approach. For a fair comparison, we re-implemented recent studies available in public repositories to evaluate their scalability and reproducibility. Our experiments also show that the proposed network demonstrates competitive results compared to current SOTA models on various public datasets. Ablation studies demonstrate that the proposed model is competitive with much smaller parameter sizes. Lastly, by applying the proposed model to facial wrinkle segmentation, we confirmed the potential for scalability to similar tasks in other domains. Our code is available on this https URL.

Paper number 21:
Title: Uplink Rate Splitting Multiple Access with Imperfect Channel State Information and Interference Cancellation
Authors: Farjam Karim, Nurul Huda Mahmood, Arthur S. de Sena, Deepak Kumar, Bruno Clerckx, Matti Latva-aho
Abstract: This article investigates the performance of uplink rate splitting multiple access (RSMA) in a two-user scenario, addressing an under-explored domain compared to its downlink counterpart. With the increasing demand for uplink communication in applications like the Internet-of-Things, it is essential to account for practical imperfections, such as inaccuracies in channel state information at the receiver (CSIR) and limitations in successive interference cancellation (SIC), to provide realistic assessments of system performance. Specifically, we derive closed-form expressions for the outage probability, throughput, and asymptotic outage behavior of uplink users, considering imperfect CSIR and SIC. We validate the accuracy of these derived expressions using Monte Carlo simulations. Our findings reveal that at low transmit power levels, imperfect CSIR significantly affects system performance more severely than SIC imperfections. However, as the transmit power increases, the impact of imperfect CSIR diminishes, while the influence of SIC imperfections becomes more pronounced. Moreover, we highlight the impact of the rate allocation factor on user performance. Finally, our comparison with non-orthogonal multiple access (NOMA) highlights the outage performance trade-offs between RSMA and NOMA. RSMA proves to be more effective in managing imperfect CSIR and enhances performance through strategic message splitting, resulting in more robust communication.

Paper number 22:
Title: The Role of Graph-based MIL and Interventional Training in the Generalization of WSI Classifiers
Authors: Rita Pereira, M. Rita Verdelho, Catarina Barata, Carlos Santiago
Abstract: Whole Slide Imaging (WSI), which involves high-resolution digital scans of pathology slides, has become the gold standard for cancer diagnosis, but its gigapixel resolution and the scarcity of annotated datasets present challenges for deep learning models. Multiple Instance Learning (MIL), a widely-used weakly supervised approach, bypasses the need for patch-level annotations. However, conventional MIL methods overlook the spatial relationships between patches, which are crucial for tasks such as cancer grading and diagnosis. To address this, graph-based approaches have gained prominence by incorporating spatial information through node connections. Despite their potential, both MIL and graph-based models are vulnerable to learning spurious associations, like color variations in WSIs, affecting their robustness. In this dissertation, we conduct an extensive comparison of multiple graph construction techniques, MIL models, graph-MIL approaches, and interventional training, introducing a new framework, Graph-based Multiple Instance Learning with Interventional Training (GMIL-IT), for WSI classification. We evaluate their impact on model generalization through domain shift analysis and demonstrate that graph-based models alone achieve the generalization initially anticipated from interventional training. Our code is available here: this http URL

Paper number 23:
Title: Controllable Neural Architectures for Multi-Task Control
Authors: Umberto Casti, Giacomo Baggio, Sandro Zampieri, Fabio Pasqualetti
Abstract: This paper studies a multi-task control problem where multiple linear systems are to be regulated by a single non-linear controller. In particular, motivated by recent advances in multi-task learning and the design of brain-inspired architectures, we consider a neural controller with (smooth) ReLU activation function. The parameters of the controller are a connectivity matrix and a bias vector: although both parameters can be designed, the connectivity matrix is constant while the bias vector can be varied and is used to adapt the controller across different control tasks. The bias vector determines the equilibrium of the neural controller and, consequently, of its linearized dynamics. Our multi-task control strategy consists of designing the connectivity matrix and a set of bias vectors in a way that the linearized dynamics of the neural controller for the different bias vectors provide a good approximation of a set of desired controllers. We show that, by properly choosing the bias vector, the linearized dynamics of the neural controller can replicate the dynamics of any single, linear controller. Further, we design gradient-based algorithms to train the parameters of the neural controller, and we provide upper and lower bounds for the performance of our neural controller. Finally, we validate our results using different numerical examples.

Paper number 24:
Title: An Integrated Sensing and Communications System Based on Affine Frequency Division Multiplexing
Authors: Yuanhan Ni, Peng Yuan, Qin Huang, Fan Liu, Zulin Wang
Abstract: This paper proposes an integrated sensing and communications (ISAC) system based on affine frequency division multiplexing (AFDM) waveform. To this end, a metric set is designed according to not only the maximum tolerable delay/Doppler, but also the weighted spectral efficiency as well as the outage/error probability of sensing and communications. This enables the analytical investigation of the performance trade-offs of AFDM-ISAC system using the derived analytical relation among metrics and AFDM waveform parameters. Moreover, by revealing that delay and the integral/fractional parts of normalized Doppler can be decoupled in the affine Fourier transform-Doppler domain, an efficient estimation method is proposed for our AFDM-ISAC system, whose unambiguous Doppler can break through the limitation of subcarrier spacing. Theoretical analyses and numerical results verify that our proposed AFDM-ISAC system may significantly enlarge unambiguous delay/Doppler while possessing good spectral efficiency and peak-to-sidelobe level ratio in high-mobility scenarios.

Paper number 25:
Title: Beamforming Design for Secure RIS-Enabled ISAC: Passive RIS vs. Active RIS
Authors: Vaibhav Kumar, Marwa Chafii
Abstract: The forthcoming sixth-generation (6G) communications standard is anticipated to provide integrated sensing and communication (ISAC) as a fundamental service. These ISAC systems present unique security challenges because of the exposure of information-bearing signals to sensing targets, enabling them to potentially eavesdrop on sensitive communication information with the assistance of sophisticated receivers. Recently, reconfigurable intelligent surfaces (RISs) have shown promising results in enhancing the physical layer security of various wireless communication systems, including ISAC. However, the performance of conventional passive RIS (pRIS)-enabled systems are often limited due to multiplicative fading, which can be alleviated using active RIS (aIRS). In this paper, we consider the problem of beampattern gain maximization in a secure pRIS/aRIS-enabled ISAC system, subject to signal-to-interference-plus-noise ratio constraints at communication receivers, and information leakage constraints at an eavesdropping target. For the challenging non-convex problem of joint beamforming design at the base station and the pRIS/aRIS, we propose a novel successive convex approximation (SCA)-based method. Unlike the conventional alternating optimization (AO)-based methods, in the proposed SCA-based approach, all of the optimization variables are updated simultaneously in each iteration. The proposed method shows significant performance superiority for pRIS-aided ISAC system compared to a benchmark scheme using penalty-based AO method. Moreover, our simulation results also confirm that aRIS-aided system has a notably higher beampattern gain at the target compared to that offered by the pRIS-aided system for the same power budget. We also present a detailed complexity analysis and proof of convergence for the proposed SCA-based method.

Paper number 26:
Title: Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence
Authors: Aurora Rofena, Claudia Lucia Piccolo, Bruno Beomonte Zobel, Paolo Soda, Valerio Guarrasi
Abstract: Full-Field Digital Mammography (FFDM) is the primary imaging modality for routine breast cancer screening; however, its effectiveness is limited in patients with dense breast tissue or fibrocystic conditions. Contrast-Enhanced Spectral Mammography (CESM), a second-level imaging technique, offers enhanced accuracy in tumor detection. Nonetheless, its application is restricted due to higher radiation exposure, the use of contrast agents, and limited accessibility. As a result, CESM is typically reserved for select cases, leaving many patients to rely solely on FFDM despite the superior diagnostic performance of CESM. While biopsy remains the gold standard for definitive diagnosis, it is an invasive procedure that can cause discomfort for patients. We introduce a multimodal, multi-view deep learning approach for virtual biopsy, integrating FFDM and CESM modalities in craniocaudal and mediolateral oblique views to classify lesions as malignant or benign. To address the challenge of missing CESM data, we leverage generative artificial intelligence to impute CESM images from FFDM scans. Experimental results demonstrate that incorporating the CESM modality is crucial to enhance the performance of virtual biopsy. When real CESM data is missing, synthetic CESM images proved effective, outperforming the use of FFDM alone, particularly in multimodal configurations that combine FFDM and CESM modalities. The proposed approach has the potential to improve diagnostic workflows, providing clinicians with augmented intelligence tools to improve diagnostic accuracy and patient care. Additionally, as a contribution to the research community, we publicly release the dataset used in our experiments, facilitating further advancements in this field.

Paper number 27:
Title: Learning Sheaf Laplacian Optimizing Restriction Maps
Authors: Leonardo Di Nino, Sergio Barbarossa, Paolo Di Lorenzo
Abstract: The aim of this paper is to propose a novel framework to infer the sheaf Laplacian, including the topology of a graph and the restriction maps, from a set of data observed over the nodes of a graph. The proposed method is based on sheaf theory, which represents an important generalization of graph signal processing. The learning problem aims to find the sheaf Laplacian that minimizes the total variation of the observed data, where the variation over each edge is also locally minimized by optimizing the associated restriction maps. Compared to alternative methods based on semidefinite programming, our solution is significantly more numerically efficient, as all its fundamental steps are resolved in closed form. The method is numerically tested on data consisting of vectors defined over subspaces of varying dimensions at each node. We demonstrate how the resulting graph is influenced by two key factors: the cross-correlation and the dimensionality difference of the data residing on the graph's nodes.

Paper number 28:
Title: A parallelizable variant of HCA*
Authors: Sreenivasan Ganti, Visnu Srinivasan, Pallavi Ramicetty, Shravan Mohan, Milind Savagaonkar, Shubhashis Sengupta
Abstract: This paper presents a parallelizable variant of the well-known Hierarchical Cooperative A* algorithm (HCA*) for the multi-agent path finding (MAPF) problem. In this variant, all agents initially find their shortest paths disregarding the presence of others. This is done using A*. Then an intersection graph (IG) is constructed; each agent is a node and two nodes have an edge between them if the paths of corresponding agents collide. Thereafter, an independent set is extracted with the aid of an approximation algorithm for the maximum independent set problem. The paths for the agents belonging to independent set are fixed. The rest of agents now again find their shortest paths, this time ensuring no collision with the prior agents. Space-time A*, which is a crucial component of HCA*, is used here. These iterations continue until no agents are left. Since the tasks of finding shortest paths for the agents in any iteration are independent of each other, the proposed algorithm can be parallelized to a large extent. In addition to this, the task of determining the IG can also be done in parallel by dividing the map into sections and with each agent focusing on a particular section. The parallelism does come at a cost of communication between the agents and the server. This is accounted for in the simulations. As an added advantage, the user need not make a choice for the priority order. It is observed, empirically, that the proposed algorithm outperforms HCA* in terms of the computation time and the cost value in many cases. Simulations are provided for corroboration.

Paper number 29:
Title: Language Bias in Self-Supervised Learning For Automatic Speech Recognition
Authors: Edward Storey, Naomi Harte, Peter Bell
Abstract: Self-supervised learning (SSL) is used in deep learning to train on large datasets without the need for expensive labelling of the data. Recently, large Automatic Speech Recognition (ASR) models such as XLS-R have utilised SSL to train on over one hundred different languages simultaneously. However, deeper investigation shows that the bulk of the training data for XLS-R comes from a small number of languages. Biases learned through SSL have been shown to exist in multiple domains, but language bias in multilingual SSL ASR has not been thoroughly examined. In this paper, we utilise the Lottery Ticket Hypothesis (LTH) to identify language-specific subnetworks within XLS-R and test the performance of these subnetworks on a variety of different languages. We are able to show that when fine-tuning, XLS-R bypasses traditional linguistic knowledge and builds only on weights learned from the languages with the largest data contribution to the pretraining data.

Paper number 30:
Title: Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates
Authors: Misha P.T Kaandorp, Damola Agbelese, Hosna Asma-ull, Hyun-Gi Kim, Kelly Payette, Patrice Grehten, Gennari Antonio Giulio, Levente István Lánczi, Andras Jakab
Abstract: Developing new methods for the automated analysis of clinical fetal and neonatal MRI data is limited by the scarcity of annotated pathological datasets and privacy concerns that often restrict data sharing, hindering the effectiveness of deep learning models. We address this in two ways. First, we introduce Fetal&Neonatal-DDPM, a novel diffusion model framework designed to generate high-quality synthetic pathological fetal and neonatal MRIs from semantic label images. Second, we enhance training data by modifying healthy label images through morphological alterations to simulate conditions such as ventriculomegaly, cerebellar and pontocerebellar hypoplasia, and microcephaly. By leveraging Fetal&Neonatal-DDPM, we synthesize realistic pathological MRIs from these modified pathological label images. Radiologists rated the synthetic MRIs as significantly (p < 0.05) superior in quality and diagnostic value compared to real MRIs, demonstrating features such as blood vessels and choroid plexus, and improved alignment with label annotations. Synthetic pathological data enhanced state-of-the-art nnUNet segmentation performance, particularly for severe ventriculomegaly cases, with the greatest improvements achieved in ventricle segmentation (Dice scores: 0.9253 vs. 0.7317). This study underscores the potential of generative AI as transformative tool for data augmentation, offering improved segmentation performance in pathological cases. This development represents a significant step towards improving analysis and segmentation accuracy in prenatal imaging, and also offers new ways for data anonymization through the generation of pathologic image data.

Paper number 31:
Title: Towards Adaptive Self-Improvement for Smarter Energy Systems
Authors: Alexander Sommer, Peter Bazan, Jonathan Fellerer, Behnam Babaeian, Reinhard German
Abstract: This paper introduces a hierarchical framework for decision-making and optimization, leveraging Large Language Models (LLMs) for adaptive code generation. Instead of direct decision-making, LLMs generate and refine executable control policies through a meta-policy that guides task generation and a base policy for operational actions. Applied to a simplified microgrid scenario, the approach achieves up to 15 percent cost savings by iteratively improving battery control strategies. The proposed methodology lays a foundation for integrating LLM-based tools into planning and control tasks, offering adaptable and scalable solutions for complex systems while addressing challenges of uncertainty and reproducibility.

Paper number 32:
Title: Using gradient of Lagrangian function to compute efficient channels for the ideal observer
Authors: Weimin Zhou
Abstract: It is widely accepted that the Bayesian ideal observer (IO) should be used to guide the objective assessment and optimization of medical imaging systems. The IO employs complete task-specific information to compute test statistics for making inference decisions and performs optimally in signal detection tasks. However, the IO test statistic typically depends non-linearly on the image data and cannot be analytically determined. The ideal linear observer, known as the Hotelling observer (HO), can sometimes be used as a surrogate for the IO. However, when image data are high dimensional, HO computation can be difficult. Efficient channels that can extract task-relevant features have been investigated to reduce the dimensionality of image data to approximate IO and HO performance. This work proposes a novel method for generating efficient channels by use of the gradient of a Lagrangian-based loss function that was designed to learn the HO. The generated channels are referred to as the Lagrangian-gradient (L-grad) channels. Numerical studies are conducted that consider binary signal detection tasks involving various backgrounds and signals. It is demonstrated that channelized HO (CHO) using L-grad channels can produce significantly better signal detection performance compared to the CHO using PLS channels. Moreover, it is shown that the proposed L-grad method can achieve significantly lower computation time compared to the PLS method.

Paper number 33:
Title: 3D Reconstruction of Shoes for Augmented Reality
Authors: Pratik Shrestha, Sujan Kapali, Swikar Gautam, Vishal Pokharel, Santosh Giri
Abstract: This paper introduces a mobile-based solution that enhances online shoe shopping through 3D modeling and Augmented Reality (AR), leveraging the efficiency of 3D Gaussian Splatting. Addressing the limitations of static 2D images, the framework generates realistic 3D shoe models from 2D images, achieving an average Peak Signal-to-Noise Ratio (PSNR) of 0.32, and enables immersive AR interactions via smartphones. A custom shoe segmentation dataset of 3120 images was created, with the best-performing segmentation model achieving an Intersection over Union (IoU) score of 0.95. This paper demonstrates the potential of 3D modeling and AR to revolutionize online shopping by offering realistic virtual interactions, with applicability across broader fashion categories.

Paper number 34:
Title: Machine Learning Strategies for Parkinson Tremor Classification Using Wearable Sensor Data
Authors: Jesus Paucar-Escalante, Matheus Alves da Silva, Bruno De Lima Sanches, Aurea Soriano-Vargas, Laura Silveira Moriyama, Esther Luna Colombini
Abstract: Parkinson's disease (PD) is a neurological disorder requiring early and accurate diagnosis for effective management. Machine learning (ML) has emerged as a powerful tool to enhance PD classification and diagnostic accuracy, particularly by leveraging wearable sensor data. This survey comprehensively reviews current ML methodologies used in classifying Parkinsonian tremors, evaluating various tremor data acquisition methodologies, signal preprocessing techniques, and feature selection methods across time and frequency domains, highlighting practical approaches for tremor classification. The survey explores ML models utilized in existing studies, ranging from traditional methods such as Support Vector Machines (SVM) and Random Forests to advanced deep learning architectures like Convolutional Neural Networks (CNN) and Long Short-Term Memory networks (LSTM). We assess the efficacy of these models in classifying tremor patterns associated with PD, considering their strengths and limitations. Furthermore, we discuss challenges and discrepancies in current research and broader challenges in applying ML to PD diagnosis using wearable sensor data. We also outline future research directions to advance ML applications in PD diagnostics, providing insights for researchers and practitioners.

Paper number 35:
Title: Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release
Authors: Andrew M Birnbaum, Adam Buchwald, Peter Turkeltaub, Adam Jacks, Yu Huang, Abhisheck Datta, Lucas C Parra, Lukas A Hirsch
Abstract: The goal of this work was to develop a deep network for whole-head segmentation, including clinical MRIs with abnormal anatomy, and compile the first public benchmark dataset for this purpose. We collected 91 MRIs with volumetric segmentation labels for a diverse set of human subjects (4 normal, 32 traumatic brain injuries, and 57 strokes). These clinical cases are characterized by extended cerebrospinal fluid (CSF) in regions normally containing the brain. Training labels were generated by manually correcting initial automated segmentations for skin/scalp, skull, CSF, gray matter, white matter, air cavity, and extracephalic air. We developed a MultiAxial network consisting of three 2D U-Net models that operate independently in sagittal, axial, and coronal planes and are then combined to produce a single 3D segmentation. The MultiAxial network achieved test-set Dice scores of 0.88 (median plus-minus 0.04). For brain tissue, it significantly outperforms existing brain segmentation methods (MultiAxial: 0.898 plus-minus 0.041, SynthSeg: 0.758 plus-minus 0.054, BrainChop: 0.757 plus-minus 0.125). The MultiAxial network gains in robustness by avoiding the need for coregistration with an atlas. It performed well in regions with abnormal anatomy and on images that have been de-identified. It enables more robust current flow modeling when incorporated into ROAST, a widely-used modeling toolbox for transcranial electric stimulation. We are releasing a state-of-the-art model for whole-head MRI segmentation, along with a dataset of 61 clinical MRIs and training labels, including non-brain structures. Together, the model and data may serve as a benchmark for future efforts.

Paper number 36:
Title: Distributed Offloading in Multi-Access Edge Computing Systems: A Mean-Field Perspective
Authors: Shubham Aggarwal, Muhammad Aneeq uz Zaman, Melih Bastopcu, Sennur Ulukus, Tamer Başar
Abstract: Multi-access edge computing (MEC) technology is a promising solution to assist power-constrained IoT devices by providing additional computing resources for time-sensitive tasks. In this paper, we consider the problem of optimal task offloading in MEC systems with due consideration of the timeliness and scalability issues under two scenarios of equitable and priority access to the edge server (ES). In the first scenario, we consider a MEC system consisting of $N$ devices assisted by one ES, where the devices can split task execution between a local processor and the ES, with equitable access to the ES. In the second scenario, we consider a MEC system consisting of one primary user, $N$ secondary users and one ES. The primary user has priority access to the ES while the secondary users have equitable access to the ES amongst themselves. In both scenarios, due to the power consumption associated with utilizing the local resource and task offloading, the devices must optimize their actions. Additionally, since the ES is a shared resource, other users' offloading activity serves to increase latency incurred by each user. We thus model both scenarios using a non-cooperative game framework. However, the presence of a large number of users makes it nearly impossible to compute the equilibrium offloading policies for each user, which would require a significant information exchange overhead between users. Thus, to alleviate such scalability issues, we invoke the paradigm of mean-field games to compute approximate Nash equilibrium policies for each user using their local information, and further study the trade-offs between increasing information freshness and reducing power consumption for each user. Using numerical evaluations, we show that our approach can recover the offloading trends displayed under centralized solutions, and provide additional insights into the results obtained.

Paper number 37:
Title: Exploring Audio Editing Features as User-Centric Privacy Defenses Against Emotion Inference Attacks
Authors: Mohd. Farhan Israk Soumik, W.K.M. Mithsara, Abdur R. Shahid, Ahmed Imteaj
Abstract: The rapid proliferation of speech-enabled technologies, including virtual assistants, video conferencing platforms, and wearable devices, has raised significant privacy concerns, particularly regarding the inference of sensitive emotional information from audio data. Existing privacy-preserving methods often compromise usability and security, limiting their adoption in practical scenarios. This paper introduces a novel, user-centric approach that leverages familiar audio editing techniques, specifically pitch and tempo manipulation, to protect emotional privacy without sacrificing usability. By analyzing popular audio editing applications on Android and iOS platforms, we identified these features as both widely available and usable. We rigorously evaluated their effectiveness against a threat model, considering adversarial attacks from diverse sources, including Deep Neural Networks (DNNs), Large Language Models (LLMs), and and reversibility testing. Our experiments, conducted on three distinct datasets, demonstrate that pitch and tempo manipulation effectively obfuscates emotional data. Additionally, we explore the design principles for lightweight, on-device implementation to ensure broad applicability across various devices and platforms.

Paper number 38:
Title: STaleX: A Spatiotemporal-Aware Adaptive Auto-scaling Framework for Microservices
Authors: Majid Dashtbani, Ladan Tahvildari
Abstract: While cloud environments and auto-scaling solutions have been widely applied to traditional monolithic applications, they face significant limitations when it comes to microservices-based architectures. Microservices introduce additional challenges due to their dynamic and spatiotemporal characteristics, which require more efficient and specialized auto-scaling strategies. Centralized auto-scaling for the entire microservice application is insufficient, as each service within a chain has distinct specifications and performance requirements. Therefore, each service requires its own dedicated auto-scaler to address its unique scaling needs effectively, while also considering the dependencies with other services in the chain and the overall application. This paper presents a combination of control theory, machine learning, and heuristics to address these challenges. We propose an adaptive auto-scaling framework, STaleX, for microservices that integrates spatiotemporal features, enabling real-time resource adjustments to minimize SLO violations. STaleX employs a set of weighted Proportional-Integral-Derivative (PID) controllers for each service, where weights are dynamically adjusted based on a supervisory unit that integrates spatiotemporal features. This supervisory unit continuously monitors and adjusts both the weights and the resources allocated to each service. Our framework accounts for spatial features, including service specifications and dependencies among services, as well as temporal variations in workload, ensuring that resource allocation is continuously optimized. Through experiments on a microservice-based demo application deployed on a Kubernetes cluster, we demonstrate the effectiveness of our framework in improving performance and reducing costs compared to traditional scaling methods like Kubernetes Horizontal Pod Autoscaler (HPA) with a 26.9% reduction in resource usage.

Paper number 39:
Title: A New Statistical Approach to the Performance Analysis of Vision-based Localization
Authors: Haozhou Hu, Harpreet S. Dhillon, R. Michael Buehrer
Abstract: Many modern wireless devices with accurate positioning needs also have access to vision sensors, such as a camera, radar, and Light Detection and Ranging (LiDAR). In scenarios where wireless-based positioning is either inaccurate or unavailable, using information from vision sensors becomes highly desirable for determining the precise location of the wireless device. Specifically, vision data can be used to estimate distances between the target (where the sensors are mounted) and nearby landmarks. However, a significant challenge in positioning using these measurements is the inability to uniquely identify which specific landmark is visible in the data. For instance, when the target is located close to a lamppost, it becomes challenging to precisely identify the specific lamppost (among several in the region) that is near the target. This work proposes a new framework for target localization using range measurements to multiple proximate landmarks. The geometric constraints introduced by these measurements are utilized to narrow down candidate landmark combinations corresponding to the range measurements and, consequently, the target's location on a map. By modeling landmarks as a marked Poisson point process (PPP), we show that three noise-free range measurements are sufficient to uniquely determine the correct combination of landmarks in a two-dimensional plane. For noisy measurements, we provide a mathematical characterization of the probability of correctly identifying the observed landmark combination based on a novel joint distribution of key random variables. Our results demonstrate that the landmark combination can be identified using ranges, even when individual landmarks are visually indistinguishable.

Paper number 40:
Title: Multispectral 3D mapping on a Roman sculpture to study ancient polychromy
Authors: Francesca Uccheddu (1), Umair Shafqat Malik (2), Emanuela Massa (3), Anna Pelagotti (4), Maria Emilia Masci (5), Gabriele Guidi (2) ((1) University of Padova, Padua, Italy, (2) Indiana University, Bloomington, IN, USA, (3) Art-Test, Florence, Italy, (4) Istituto Nazionale di Ottica (INO), Florence, Italy, (5) Opificio delle Pietre Dure, Florence, Italy)
Abstract: Research into the polychromy of Greek and Roman sculptures has surged to explore the hypothesis that ancient sculptures were originally not pristine white but adorned with colors. Multispectral and multimodal imaging techniques have been crucial in studying painted surfaces, revealing polychromies even in traces. In fact, imaging techniques, such as reflectance and fluorescence, can identify different materials and map inhomogeneities, guiding further investigations such as Raman, XRays Fluorescence, and Fourier Transform InfraRed Spectroscopy (FTIR) to investigate residual colors. However, this approach may underestimate the original polychromies' extent over the complex articulation of a sculptured surface. This study proposes a methodology to analyze the original appearance of ancient sculptures using reality-based 3D models with textures not limited to those visible to the naked eye. We employ Visible Reflected Imaging (VIS) and Ultraviolet-induced Fluorescence Imaging (UVF). From the UVF and VIS datasets, the underlying 3D model is built by means of photogrammetry. Through raw data processing, images taken with different illuminating sources are successfully aligned and processed, creating a single 3D model with multiple textures mapped onto the same bi-dimensional space. The pixel-to-pixel correspondence of different textures allows for the implementation of a classification algorithm that can directly map its outcome onto the 3D model surface. This enables conservators to deepen their understanding of artifact preservation, observe mate-rial distribution in detail, and correlate this with 3D geometrical data. In this study, we experiment with this approach on an ancient Roman sculpture of Artemis, conserved at the Archeological and Art Museum of Maremma (MAAM) in Grosseto, Italy.

Paper number 41:
Title: Learning Hamiltonian Dynamics with Bayesian Data Assimilation
Authors: Taehyeun Kim, Tae-Geun Kim, Anouck Girard, Ilya Kolmanovsky
Abstract: In this paper, we develop a neural network-based approach for time-series prediction in unknown Hamiltonian dynamical systems. Our approach leverages a surrogate model and learns the system dynamics using generalized coordinates (positions) and their conjugate momenta while preserving a constant Hamiltonian. To further enhance long-term prediction accuracy, we introduce an Autoregressive Hamiltonian Neural Network, which incorporates autoregressive prediction errors into the training objective. Additionally, we employ Bayesian data assimilation to refine predictions in real-time using online measurement data. Numerical experiments on a spring-mass system and highly elliptic orbits under gravitational perturbations demonstrate the effectiveness of the proposed method, highlighting its potential for accurate and robust long-term predictions.

Paper number 42:
Title: Integrated Communication and Binary State Detection Under Unequal Error Constraints
Authors: Daewon Seo, Sung Hoon Lim
Abstract: This work considers a problem of integrated sensing and communication (ISAC) in which the goal of sensing is to detect a binary state. Unlike most approaches that minimize the total detection error probability, in our work, we disaggregate the error probability into false alarm and missed detection probabilities and investigate their information-theoretic three-way tradeoff including communication data rate. We consider a broadcast channel that consists of a transmitter, a communication receiver, and a detector where the receiver's and the detector's channels are affected by an unknown binary state. We consider and present results on two different state-dependent models. In the first setting, the state is fixed throughout the entire transmission, for which we fully characterize the optimal three-way tradeoff between the coding rate for communication and the two possibly nonidentical error exponents for sensing in the asymptotic regime. The achievability and converse proofs rely on the analysis of the cumulant-generating function of the log-likelihood ratio. In the second setting, the state changes every symbol in an independently and identically distributed (i.i.d.) manner, for which we characterize the optimal tradeoff region based on the analysis of the receiver operating characteristic (ROC) curves.

Paper number 43:
Title: Deepfake Detection of Singing Voices With Whisper Encodings
Authors: Falguni Sharma, Priyanka Gupta
Abstract: The deepfake generation of singing vocals is a concerning issue for artists in the music industry. In this work, we propose a singing voice deepfake detection (SVDD) system, which uses noise-variant encodings of open-AI's Whisper model. As counter-intuitive as it may sound, even though the Whisper model is known to be noise-robust, the encodings are rich in non-speech information, and are noise-variant. This leads us to evaluate Whisper encodings as feature representations for the SVDD task. Therefore, in this work, the SVDD task is performed on vocals and mixtures, and the performance is evaluated in \%EER over varying Whisper model sizes and two classifiers- CNN and ResNet34, under different testing conditions.

Paper number 44:
Title: DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition
Authors: Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee
Abstract: Dysarthric speech recognition often suffers from performance degradation due to the intrinsic diversity of dysarthric severity and extrinsic disparity from normal speech. To bridge these gaps, we propose a Dynamic Phoneme-level Contrastive Learning (DyPCL) method, which leads to obtaining invariant representations across diverse speakers. We decompose the speech utterance into phoneme segments for phoneme-level contrastive learning, leveraging dynamic connectionist temporal classification alignment. Unlike prior studies focusing on utterance-level embeddings, our granular learning allows discrimination of subtle parts of speech. In addition, we introduce dynamic curriculum learning, which progressively transitions from easy negative samples to difficult-to-distinguishable negative samples based on phonetic similarity of phoneme. Our approach to training by difficulty levels alleviates the inherent variability of speakers, better identifying challenging speeches. Evaluated on the UASpeech dataset, DyPCL outperforms baseline models, achieving an average 22.10\% relative reduction in word error rate (WER) across the overall dysarthria group.

Paper number 45:
Title: Ambient Denoising Diffusion Generative Adversarial Networks for Establishing Stochastic Object Models from Noisy Image Data
Authors: Xichen Xu, Wentao Chen, Weimin Zhou
Abstract: It is widely accepted that medical imaging systems should be objectively assessed via task-based image quality (IQ) measures that ideally account for all sources of randomness in the measured image data, including the variation in the ensemble of objects to be imaged. Stochastic object models (SOMs) that can randomly draw samples from the object distribution can be employed to characterize object variability. To establish realistic SOMs for task-based IQ analysis, it is desirable to employ experimental image data. However, experimental image data acquired from medical imaging systems are subject to measurement noise. Previous work investigated the ability of deep generative models (DGMs) that employ an augmented generative adversarial network (GAN), AmbientGAN, for establishing SOMs from noisy measured image data. Recently, denoising diffusion models (DDMs) have emerged as a leading DGM for image synthesis and can produce superior image quality than GANs. However, original DDMs possess a slow image-generation process because of the Gaussian assumption in the denoising steps. More recently, denoising diffusion GAN (DDGAN) was proposed to permit fast image generation while maintain high generated image quality that is comparable to the original DDMs. In this work, we propose an augmented DDGAN architecture, Ambient DDGAN (ADDGAN), for learning SOMs from noisy image data. Numerical studies that consider clinical computed tomography (CT) images and digital breast tomosynthesis (DBT) images are conducted. The ability of the proposed ADDGAN to learn realistic SOMs from noisy image data is demonstrated. It has been shown that the ADDGAN significantly outperforms the advanced AmbientGAN models for synthesizing high resolution medical images with complex textures.

Paper number 46:
Title: Reliability Modeling for Beyond-5G Mission Critical Networks Using Effective Capacity
Authors: Anudeep Karnam, Jobish John, Kishor C. Joshi, George Exarchakos, Sonia Heemstra de Groot, Ignas Niemegeers
Abstract: Accurate reliability modeling for ultra-reliable low latency communication (URLLC) and hyper-reliable low latency communication (HRLLC) networks is challenging due to the complex interactions between network layers required to meet stringent requirements. In this paper, we propose such a model. We consider the acknowledged mode of the radio link control (RLC) layer, utilizing separate buffers for transmissions and retransmissions, along with the behavior of physical channels. Our approach leverages the effective capacity (EC) framework, which quantifies the maximum constant arrival rate a time-varying wireless channel can support while meeting statistical quality of service (QoS) constraints. We derive a reliability model that incorporates delay violations, various latency components, and multiple transmission attempts. Our method identifies optimal operating conditions that satisfy URLLC/HRLLC constraints while maintaining near-optimal EC, ensuring the system can handle peak traffic with a guaranteed QoS. Our model reveals critical trade-offs between EC and reliability across various use cases, providing guidance for URLLC/HRLLC network design for service providers and system designers.

Paper number 47:
Title: RGB-Event ISP: The Dataset and Benchmark
Authors: Yunfan Lu, Yanlin Qian, Ziyang Rao, Junren Xiao, Liming Chen, Hui Xiong
Abstract: Event-guided imaging has received significant attention due to its potential to revolutionize instant imaging systems. However, the prior methods primarily focus on enhancing RGB images in a post-processing manner, neglecting the challenges of image signal processor (ISP) dealing with event sensor and the benefits events provide for reforming the ISP process. To achieve this, we conduct the first research on event-guided ISP. First, we present a new event-RAW paired dataset, collected with a novel but still confidential sensor that records pixel-level aligned events and RAW images. This dataset includes 3373 RAW images with 2248 x 3264 resolution and their corresponding events, spanning 24 scenes with 3 exposure modes and 3 lenses. Second, we propose a conventional ISP pipeline to generate good RGB frames as reference. This conventional ISP pipleline performs basic ISP operations, this http URL, white balancing, denoising and color space transforming, with a ColorChecker as reference. Third, we classify the existing learnable ISP methods into 3 classes, and select multiple methods to train and evaluate on our new dataset. Lastly, since there is no prior work for reference, we propose a simple event-guided ISP method and test it on our dataset. We further put forward key technical challenges and future directions in RGB-Event ISP. In summary, to the best of our knowledge, this is the very first research focusing on event-guided ISP, and we hope it will inspire the community. The code and dataset are available at: this https URL.

Paper number 48:
Title: APEX: Automated Parameter Exploration for Low-Power Wireless Protocols
Authors: Mohamed Hassaan M. Hydher, Markus Schuss, Olga Saukh, Kay Römer, Carlo Alberto Boano
Abstract: Careful parametrization of networking protocols is crucial to maximize the performance of low-power wireless systems and ensure that stringent application requirements can be met. This is a non-trivial task involving thorough characterization on testbeds and requiring expert knowledge. Unfortunately, the community still lacks a tool to facilitate parameter exploration while minimizing the necessary experimentation time on testbeds. Such a tool would be invaluable, as exhaustive parameter searches can be time-prohibitive or unfeasible given the limited availability of testbeds, whereas non-exhaustive unguided searches rarely deliver satisfactory results. In this paper, we present APEX, a framework enabling an automated and informed parameter exploration for low-power wireless protocols and allowing to converge to an optimal parameter set within a limited number of testbed trials. We design APEX using Gaussian processes to effectively handle noisy experimental data and estimate the optimality of a certain parameter combination. After developing a prototype of APEX, we demonstrate its effectiveness by parametrizing two IEEE 802.15.4 protocols for a wide range of application requirements. Our results show that APEX can return the best parameter set with up to 10.6x, 4.5x and 3.25x less testbed trials than traditional solutions based on exhaustive search, greedy approaches, and reinforcement learning, respectively.

Paper number 49:
Title: Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge
Authors: Amogh Joshi, Sourav Sanyal, Kaushik Roy
Abstract: The integration of human-intuitive interactions into autonomous systems has been limited. Traditional Natural Language Processing (NLP) systems struggle with context and intent understanding, severely restricting human-robot interaction. Recent advancements in Large Language Models (LLMs) have transformed this dynamic, allowing for intuitive and high-level communication through speech and text, and bridging the gap between human commands and robotic actions. Additionally, autonomous navigation has emerged as a central focus in robotics research, with artificial intelligence (AI) increasingly being leveraged to enhance these systems. However, existing AI-based navigation algorithms face significant challenges in latency-critical tasks where rapid decision-making is critical. Traditional frame-based vision systems, while effective for high-level decision-making, suffer from high energy consumption and latency, limiting their applicability in real-time scenarios. Neuromorphic vision systems, combining event-based cameras and spiking neural networks (SNNs), offer a promising alternative by enabling energy-efficient, low-latency navigation. Despite their potential, real-world implementations of these systems, particularly on physical platforms such as drones, remain scarce. In this work, we present Neuro-LIFT, a real-time neuromorphic navigation framework implemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural language processing, Neuro-LIFT translates human speech into high-level planning commands which are then autonomously executed using event-based neuromorphic vision and physics-driven planning. Our framework demonstrates its capabilities in navigating in a dynamic environment, avoiding obstacles, and adapting to human instructions in real-time.

Paper number 50:
Title: Ultra-fast Real-time Target Recognition Using a Shift, Scale, and Rotation Invariant Hybrid Opto-electronic Joint Transform Correlator
Authors: Xi Shen, Julian Gamboa, Tabassom Hamidfar, Shamima A. Mitu, Selim M. Shahriar
Abstract: Hybrid Opto-electronic correlators (HOC) overcome many limitations of all-optical correlators (AOC) while maintaining high-speed operation. However, neither the OEC nor the AOC in their conventional configurations can detect targets that have been rotated or scaled relative to a reference. This can be addressed by using a polar Mellin transform (PMT) pre-processing step to convert input images into signatures that contain most of the relevant information, albeit represented in a shift, scale, and rotation invariant (SSRI) manner. The PMT requires the use of optics to perform the Fourier transform and electronics for a log-polar remapping step. Recently, we demonstrated a pipelined architecture that can perform the PMT at a speed of 720 frames per second (fps), enabling the construction of an efficient opto-electronic PMT pre-processor. Here, we present an experimental demonstration of a complete HOC that implements this technique to achieve real-time and ultra-fast SSRI target recognition for space situational awareness. For this demonstration, we make use of a modified version of the HOC that makes use of Joint Transform Correlation , thus rendering the system simpler and more compact.

Paper number 51:
Title: SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions
Authors: Dominik Wagner, Alexander Churchill, Siddarth Sigtia, Erik Marchi
Abstract: In this work, we present and evaluate SELMA, a Speech-Enabled Language Model for virtual Assistant interactions that integrates audio and text as inputs to a Large Language Model (LLM). SELMA is designed to handle three primary and two auxiliary tasks related to interactions with virtual assistants simultaneously within a single end-to-end model. We employ low-rank adaptation modules for parameter-efficient training of both the audio encoder and the LLM. Additionally, we implement a feature pooling strategy enabling the system to recognize global patterns and improve accuracy on tasks less reliant on individual sequence elements. Experimental results on Voice Trigger (VT) detection, Device-Directed Speech Detection (DDSD), and Automatic Speech Recognition (ASR), demonstrate that our approach both simplifies the typical input processing pipeline of virtual assistants significantly and also improves performance compared to dedicated models for each individual task. SELMA yields relative Equal-Error Rate improvements of 64% on the VT detection task, and 22% on DDSD, while also achieving word error rates close to the baseline.

Paper number 52:
Title: Multi-Frame Blind Manifold Deconvolution for Rotating Synthetic Aperture Imaging
Authors: Dao Lin, Jian Zhang, Martin Benning
Abstract: Rotating synthetic aperture (RSA) imaging system captures images of the target scene at different rotation angles by rotating a rectangular aperture. Deblurring acquired RSA images plays a critical role in reconstructing a latent sharp image underlying the scene. In the past decade, the emergence of blind convolution technology has revolutionised this field by its ability to model complex features from acquired images. Most of the existing methods attempt to solve the above ill-posed inverse problem through maximising a posterior. Despite this progress, researchers have paid limited attention to exploring low-dimensional manifold structures of the latent image within a high-dimensional ambient-space. Here, we propose a novel method to process RSA images using manifold fitting and penalisation in the content of multi-frame blind convolution. We develop fast algorithms for implementing the proposed procedure. Simulation studies demonstrate that manifold-based deconvolution can outperform conventional deconvolution algorithms in the sense that it can generate a sharper estimate of the latent image in terms of estimating pixel intensities and preserving structural details.

Paper number 53:
Title: From a Frequency-Domain Willems' Lemma to Data-Driven Predictive Control
Authors: T.J. Meijer, K.J.A. Scheres, S.A.N. Nouwens, V.S. Dolk, W.P.M.H. Heemels
Abstract: Willems' fundamental lemma has recently received an impressive amount of attention from the (data-driven) control community. In this paper, we formulate a version of this celebrated result based on frequency-domain data. In doing so, we bridge the gap between recent developments in data-driven analysis and control, and the readily-available techniques and extensive expertise for non-parametric frequency-domain identification in academia and industry. In addition, we generalize our results to allow multiple frequency-domain data sets to be carefully combined to form a sufficiently rich data set. Building on these results, we propose a data-driven predictive control scheme based on measured frequency-domain data of the plant. This novel scheme provides a frequency-domain counterpart of the well-known data-enabled predictive control scheme DeePC based on time-domain data. We prove that, under appropriate conditions, the new frequency-domain data-driven predictive control (FreePC) scheme is equivalent to the corresponding DeePC scheme, and we demonstrate the benefits of FreePC and the use of frequency-domain data in a numerical case study. These benefits include the ability to collect data in closed loop with a pre-stabilizing controller, dealing with noisy data, without increasing computational complexity, and intuitively visualizing the uncertainty in the frequency-domain data. In addition, we further showcase the potential of our frequency-domain Willems' fundamental lemma in applications to data-driven simulation, and the linear-quadratic regulator (LQR) problem. Finally, we show that our results can be used to evaluate the transfer function of the system at a desired frequency based on a finite amount of frequency-domain data.

Paper number 54:
Title: Application of Spherical Convolutional Neural Networks to Image Reconstruction and Denoising in Nuclear Medicine
Authors: Amirreza Hashemi, Yuemeng Feng, Arman Rahmim, Hamid Sabet
Abstract: This work investigates use of equivariant neural networks as efficient and high-performance frameworks for image reconstruction and denoising in nuclear medicine. Our work aims to tackle limitations of conventional Convolutional Neural Networks (CNNs), which require significant training. We investigated equivariant networks, aiming to reduce CNN's dependency on specific training sets. Specifically, we implemented and evaluated equivariant spherical CNNs (SCNNs) for 2- and 3-dimensional medical imaging problems. Our results demonstrate superior quality and computational efficiency of SCNNs in both image reconstruction and denoising benchmark problems. Furthermore, we propose a novel approach to employ SCNNs as a complement to conventional image reconstruction tools, enhancing the outcomes while reducing reliance on the training set. Across all cases, we observed significant decrease in computational cost by leveraging the inherent inclusion of equivariant representatives while achieving the same or higher quality of image processing using SCNNs compared to CNNs. Additionally, we explore the potential of SCNNs for broader tomography applications, particularly those requiring rotationally variant representation.

Paper number 55:
Title: Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach
Authors: Gergely Szabó, Paolo Bonaiuti, Andrea Ciliberto, András Horváth
Abstract: The accurate tracking of live cells using video microscopy recordings remains a challenging task for popular state-of-the-art image processing based object tracking methods. In recent years, several existing and new applications have attempted to integrate deep-learning based frameworks for this task, but most of them still heavily rely on consecutive frame based tracking embedded in their architecture or other premises that hinder generalized learning. To address this issue, we aimed to develop a new deep-learning based tracking method that relies solely on the assumption that cells can be tracked based on their spatio-temporal neighborhood, without restricting it to consecutive frames. The proposed method has the additional benefit that the motion patterns of the cells can be learned completely by the predictor without any prior assumptions, and it has the potential to handle a large number of video frames with heavy artifacts. The efficacy of the proposed method is demonstrated through biologically motivated validation strategies and compared against multiple state-of-the-art cell tracking methods.

Paper number 56:
Title: Quantized distributed Nash equilibrium seeking under DoS attacks
Authors: Shuai Feng, Maojiao Ye, Lihua Xie, Shengyuan Xu
Abstract: This paper studies distributed Nash equilibrium (NE) seeking under Denial-of-Service (DoS) attacks and quantization. The players can only exchange information with their own direct neighbors. The transmitted information is subject to quantization and packet losses induced by malicious DoS attacks. We propose a quantized distributed NE seeking strategy based on the approach of dynamic quantized consensus. To solve the quantizer saturation problem caused by DoS attacks, the quantization mechanism is equipped to have zooming-in and holding capabilities, in which the holding capability is consistent with the results in quantized consensus under DoS. A sufficient condition on the number of quantizer levels is provided, under which the quantizers are free from saturation under DoS attacks. The proposed distributed quantized NE seeking strategy is shown to have the so-called maximum resilience to DoS attacks. Namely, if the bound characterizing the maximum resilience is violated, an attacker can deny all the transmissions and hence distributed NE seeking is impossible.

Paper number 57:
Title: Role of Reconfigurable Intelligent Surfaces in 6G Radio Localization: Recent Developments, Opportunities, Challenges, and Applications
Authors: Anum Umer, Ivo Müürsepp, Muhammad Mahtab Alam, Henk Wymeersch
Abstract: Reconfigurable intelligent surfaces (RISs) are seen as a key enabler low-cost and energy-efficient technology for 6G radio communication and localization. In this paper, we aim to provide a comprehensive overview of the current research progress on the RIS technology in radio localization for 6G. Particularly, we discuss the RIS-assisted radio localization taxonomy and review the studies of RIS-assisted radio localization for different network scenarios, bands of transmission, deployment environments, as well as near-field operations. Based on this review, we highlight the future research directions, associated technical challenges, real-world applications, and limitations of RIS-assisted radio localization.

Paper number 58:
Title: Robust Control Barrier Functions using Uncertainty Estimation with Application to Mobile Robots
Authors: Ersin Das, Joel W. Burdick
Abstract: This paper proposes a safety-critical control design approach for nonlinear control affine systems in the presence of matched and unmatched uncertainties. Our constructive framework couples control barrier function (CBF) theory with a new uncertainty estimator to ensure robust safety. We use the estimated uncertainty, along with a derived upper bound on the estimation error, for synthesizing CBFs and safety-critical controllers via a quadratic program-based feedback control law that rigorously ensures robust safety while improving disturbance rejection performance. We extend the method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which may cause relative degree differences with respect to control input and disturbances. We assume the relative degree difference is at most one, resulting in a second-order cone constraint. We demonstrate the proposed robust HOCBF method through a simulation of an uncertain elastic actuator control problem and experimentally validate the efficacy of our robust CBF framework on a tracked robot with slope-induced matched and unmatched perturbations.

Paper number 59:
Title: Idempotence and Perceptual Image Compression
Authors: Tongda Xu, Ziran Zhu, Dailan He, Yanghao Li, Lina Guo, Yuanyuan Wang, Zhe Wang, Hongwei Qin, Yan Wang, Jingjing Liu, Ya-Qin Zhang
Abstract: Idempotence is the stability of image codec to re-compression. At the first glance, it is unrelated to perceptual image compression. However, we find that theoretically: 1) Conditional generative model-based perceptual codec satisfies idempotence; 2) Unconditional generative model with idempotence constraint is equivalent to conditional generative codec. Based on this newfound equivalence, we propose a new paradigm of perceptual image codec by inverting unconditional generative model with idempotence constraints. Our codec is theoretically equivalent to conditional generative codec, and it does not require training new models. Instead, it only requires a pre-trained mean-square-error codec and unconditional generative model. Empirically, we show that our proposed approach outperforms state-of-the-art methods such as HiFiC and ILLM, in terms of Fréchet Inception Distance (FID). The source code is provided in this https URL.

Paper number 60:
Title: Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies
Authors: Salma M. Elsherif, Mohamad H. Kazma, Ahmad F. Taha
Abstract: The operation of water distribution networks is a complex procedure aimed at efficiently delivering consumers with adequate water quantity (WQ) while ensuring its safe quality. An added challenge is the dependency of the WQ dynamics on the system's hydraulics, which influences the performance of the WQ controller. Prior research has addressed either solving the optimum operational hydraulic setting problem or regulating the WQ dynamics as separate problems. Additionally, there have been efforts to couple these two problems and solve one compact problem resulting in trade-offs between the contradictory objectives. In contrast, this paper takes a novel approach by examining the WQ dependency on the hydraulics from a control-theoretic standpoint. More specifically, we explore the influence of accountability for WQ controllability improvement when addressing the pump scheduling problem. We examine its effects on the cumulative cost of the interconnected systems as well as the subsequent performance of the WQ controller. To achieve this, we develop a framework that incorporates different controllability metrics within the operational hydraulic optimization problem; its aim is attaining an adequate level of WQ control across the system. We assess the aforementioned aspects' performance on various scaled networks with a wide range of numerical scenarios.

Paper number 61:
Title: Leveraging power of deep learning for fast and efficient elite pixel selection in time series SAR interferometry
Authors: Ashutosh Tiwari, Nitheshnirmal Sadhashivam, Leonard O. Ohenhen, Jonathan Lucy, Manoochehr Shirzaei
Abstract: This study proposes a new convolutional long short-term memory (ConvLSTM) based architecture for selection of elite pixels (i.e., less noisy) in time series interferometric synthetic aperture radar (TS-InSAR). The model utilizes the spatial and temporal relation among neighboring pixels to identify both persistent and distributed scatterers. We trained the model on ~20,000 training images (interferograms), each of size 100 by 100 pixels, extracted from InSAR time series interferograms containing both artificial features (buildings and infrastructure) and objects of natural environment (vegetation, forests, barren or agricultural land, water bodies). Based on such categorization, we developed two models, tailormade to detect elite pixels in urban and coastal sites. Training labels were generated from elite pixel selection outputs generated from the wavelet-based InSAR (WabInSAR) software. We used 4 urban and 7 coastal sites for training and validation respectively, and the predicted elite pixel selection maps reveal that the proposed models efficiently learn from WabInSAR-generated labels, reaching a test accuracy of 94%. The models accurately discard pixels affected by geometric and temporal decorrelation while selecting pixels corresponding to urban objects and those with stable phase history unaffected by temporal and geometric decorrelation. The density of pixels in urban areas is comparable to and higher for coastal areas than WabInSAR outputs. With significantly reduced time computation (order of minutes) and improved density of elite pixels, the proposed models can efficiently process long InSAR time series stacks and generate deformation maps quickly, making the time series InSAR technique more suitable for varied (non-urban and urban) terrains and unaddressed land deformation applications.

Paper number 62:
Title: Probabilistic reachable sets of stochastic nonlinear systems with contextual uncertainties
Authors: Xun Shen, Ye Wang, Kazumune Hashimoto, Yuhu Wu, Sebastien Gros
Abstract: Validating and controlling safety-critical systems in uncertain environments necessitates probabilistic reachable sets of future state evolutions. The existing methods of computing probabilistic reachable sets normally assume that stochastic uncertainties are independent of system states, inputs, and other environment variables. However, this assumption falls short in many real-world applications, where the probability distribution governing uncertainties depends on these variables, referred to as contextual uncertainties. This paper addresses the challenge of computing probabilistic reachable sets of stochastic nonlinear states with contextual uncertainties by seeking minimum-volume polynomial sublevel sets with contextual chance constraints. The formulated problem cannot be solved by the existing sample-based approximation method since the existing methods do not consider conditional probability densities. To address this, we propose a consistent sample approximation of the original problem by leveraging conditional density estimation and resampling. The obtained approximate problem is a tractable optimization problem. Additionally, we prove the proposed sample-based approximation's almost uniform convergence, showing that it gives the optimal solution almost consistently with the original ones. Through a numerical example, we evaluate the effectiveness of the proposed method against existing approaches, highlighting its capability to significantly reduce the bias inherent in sample-based approximation without considering a conditional probability density.

Paper number 63:
Title: A novel perspective on denoising using quantum localization with application to medical imaging
Authors: Amirreza Hashemi, Sayantan Dutta, Bertrand Georgeot, Denis Kouame, Hamid Sabet
Abstract: Background noise in many fields such as medical imaging poses significant challenges for accurate diagnosis, prompting the development of denoising algorithms. Traditional methodologies, however, often struggle to address the complexities of noisy environments in high dimensional imaging systems. This paper introduces a novel quantum-inspired approach for image denoising, drawing upon principles of quantum and condensed matter physics. Our approach views medical images as amorphous structures akin to those found in condensed matter physics and we propose an algorithm that incorporates the concept of mode resolved localization directly into the denoising process. Notably, unlike previous studies that considered localization as a hindrance, our approach considers quantum localization as a fundamental component of image reconstruction which is used to differentiate between noisy and non-noisy modes based on diffusivity and localization measurements. This perspective eliminates the need for hyperparameter tuning, making the proposed method a standalone algorithm which can be implemented with minimal manual intervention and can perform automatic filtering of noise regardless of noise level. Through numerical validation, we showcase the effectiveness of our approach in addressing noise-related challenges in imaging and especially medical imaging, underscoring its relevance for possible quantum computing applications.

Paper number 64:
Title: Novel Synchronization Scheme for Cooperative ISAC Systems
Authors: Qihao Peng, Hong Ren, Zhendong Peng, Cunhua Pan, Maged Elkashlan, Dongming Wang, Jiangzhou Wang, Xiaohu You
Abstract: Carrier frequency and timing synchronization play the fundamental roles in cooperative integrating communication and sensing (ISAC). To mitigate the effects of synchronization error, this paper develops a novel synchronization scheme in cell-free massive multiple-input multiple-output (mMIMO) systems. First, we characterize the impacts of pilot contamination on synchronization performance, i.e., Cramer-Rao bound (CRB). Furthermore, a maximum likelihood algorithm is presented to estimate the CFO and TO among the pairing APs. Then, to minimize the sum of CRBs, we devise a synchronization strategy based on a pilot-sharing scheme by jointly optimizing the cluster classification, synchronization overhead, and pilot-sharing scheme, while simultaneously considering the overhead and each AP's synchronization requirements. To solve this NP-hard problem, we simplify it into two sub-problems, namely cluster classification problem and the pilot sharing problem. To strike a balance between synchronization performance and overhead, we first classify the clusters by using the K-means algorithm, and propose a criteria to find a good set of master APs. Then, the pilot-sharing scheme is obtained by using the swap-matching operations. Simulation results validate the accuracy of our derivations and demonstrate the effectiveness of the proposed scheme over the benchmark schemes.

Paper number 65:
Title: Resilience of the Electric Grid through Trustable IoT-Coordinated Assets (Extended version)
Authors: Vineet J. Nair, Venkatesh Venkataramanan, Priyank Srivastava, Partha S. Sarker, Anurag Srivastava, Laurentiu D. Marinovici, Jun Zha, Christopher Irwin, Prateek Mittal, John Williams, Jayant Kumar, H. Vincent Poor, Anuradha M. Annaswamy
Abstract: The electricity grid has evolved from a physical system to a cyber-physical system with digital devices that perform measurement, control, communication, computation, and actuation. The increased penetration of distributed energy resources (DERs) including renewable generation, flexible loads, and storage provides extraordinary opportunities for improvements in efficiency and sustainability. However, they can introduce new vulnerabilities in the form of cyberattacks, which can cause significant challenges in ensuring grid resilience. We propose a framework in this paper for achieving grid resilience through suitably coordinated assets including a network of Internet of Things (IoT) devices. A local electricity market is proposed to identify trustable assets and carry out this coordination. Situational Awareness (SA) of locally available DERs with the ability to inject power or reduce consumption is enabled by the market, together with a monitoring procedure for their trustability and commitment. With this SA, we show that a variety of cyberattacks can be mitigated using local trustable resources without stressing the bulk grid. Multiple demonstrations are carried out using a high-fidelity co-simulation platform, real-time hardware-in-the-loop validation, and a utility-friendly simulator.

Paper number 66:
Title: Joint Beamforming Design and Bit Allocation in Massive MIMO with Resolution-Adaptive ADCs
Authors: Mengyuan Ma, Nhan Thanh Nguyen, Italo Atzeni, Markku Juntti
Abstract: Low-resolution analog-to-digital converters (ADCs) have emerged as a promising technology for reducing power consumption and complexity in massive multiple-input multiple-output (MIMO) systems while maintaining satisfactory spectral and energy efficiencies (SE/EE). In this work, we first identify the essential properties of optimal quantization and leverage them to derive a closed-form approximation of the covariance matrix of the quantization distortion. The theoretical finding facilitates the system SE analysis in the presence of low-resolution ADCs. We then focus on the joint optimization of the transmit-receive beamforming and bit allocation to maximize the SE under constraints on the transmit power and the total number of active ADC bits. To solve the resulting mixed-integer problem, we first develop an efficient beamforming design for fixed ADC resolutions. Then, we propose a low-complexity heuristic algorithm to iteratively optimize the ADC resolutions and beamforming matrices. Numerical results for a $64 \times 64$ MIMO system demonstrate that the proposed design offers $6\%$ improvement in both SE and EE with $40\%$ fewer active ADC bits compared with the uniform bit allocation. Furthermore, we numerically show that receiving more data streams with low-resolution ADCs can achieve higher SE and EE compared to receiving fewer data streams with high-resolution ADCs.

Paper number 67:
Title: EEG-Language Modeling for Pathology Detection
Authors: Sam Gijsen, Kerstin Ritter
Abstract: Multimodal language modeling has enabled breakthroughs for representation learning, yet remains unexplored in the realm of functional brain data for pathology detection. This paper pioneers EEG-language models (ELMs) trained on clinical reports and 15000 EEGs. We propose to combine multimodal alignment in this novel domain with timeseries cropping and text segmentation, enabling an extension based on multiple instance learning to alleviate misalignment between irrelevant EEG or text segments. Our multimodal models significantly improve pathology detection compared to EEG-only models across four evaluations and for the first time enable zero-shot classification as well as retrieval of both neural signals and reports. In sum, these results highlight the potential of ELMs, representing significant progress for clinical applications.

Paper number 68:
Title: Fundamental Trade-offs in Quantized Hybrid Radar Fusion: A CRB-Rate Perspective
Authors: Akhileswar Chowdary, Ahmad Bazzi, Roberto Bomfin, Marwa Chafii
Abstract: While recent advancements have highlighted the role of low-resolution analog-to-digital converters (ADCs) in integrated sensing and communication (ISAC) systems, the specific impact of ADC resolution on hybrid radar fusion (HRF), where we fuse monostatic and bistatic sensing systems remains relatively unexplored. The uplink (UL) paths in HRF, comprising both direct and reflected signals within the same frequency band, pose unique challenges, particularly given that the reflected signal is often significantly weaker than the direct path, making HRF systems susceptible to ADC resolution. To investigate the influence of quantization and ADC resolution on HRF, we employ the quantized Cramér-Rao bound (CRB) as a metric for sensing accuracy. This work derives the quantized CRB specifically for HRF systems and the quantized communication rate. We extend our analysis to obtain lower bounds on the Fisher Information Matrix (FIM) and UL communication rate, which we use to characterize quantized HRF systems. Using these derived bounds, we analyze the quantized HRF system through the lens of CRB-rate boundaries. We obtain the CRB-rate boundary through two optimization problems, where each solution point represents a trade-off boundary between the sensing accuracy and the communication rate. Extensive simulations illustrate the influence of ADC resolution, dynamic range (DR), and various system parameters on the CRB-rate boundary of HRF systems. These results offer critical insights into the design of efficient and high-performance HRF systems.

Paper number 69:
Title: Unmanned F/A-18 Aircraft Landing Control on Aircraft Carrier in Adverse Conditions
Authors: Mikhail Kistyarev, Xinhua Wang
Abstract: Carrier landing of aircrafts is a challenge for control due to the existence of nonlinear wind disturbances and the requirements of changing reference trajectories. In this paper, a robust landing control system is presented for carrier landing of unmanned F/A-18 aircraft. In the control system, an augmented observer is applied to estimate the combined disturbances in the pitch dynamics of F/A-18 aircraft during carrier landing. Therefore, the control performance is improved through the control compensations from these estimations. Additionally, the controllers are designed to regulate the velocity, rate of descent and vertical position. A full model, including the nonlinear flight dynamics, controller, carrier deck motion, wind and measurement noise, is constructed numerically and implemented in software. Combining the observer with a proportional-derivative (PD) control, the proposed pitch control shows the better transient characteristics and stronger robustness than a proportional-integral-derivative (PID) controller. The simulations verify that the designed control system can make the aircraft quickly track a time-varying reference despite the existence of nonlinear disturbances and noise.

Paper number 70:
Title: Task-based Regularization in Penalized Least-Squares for Binary Signal Detection Tasks in Medical Image Denoising
Authors: Wentao Chen, Tianming Xu, Weimin Zhou
Abstract: Image denoising algorithms have been extensively investigated for medical imaging. To perform image denoising, penalized least-squares (PLS) problems can be designed and solved, in which the penalty term encodes prior knowledge of the object being imaged. Sparsity-promoting penalties, such as total variation (TV), have been a popular choice for regularizing image denoising problems. However, such hand-crafted penalties may not be able to preserve task-relevant information in measured image data and can lead to oversmoothed image appearances and patchy artifacts that degrade signal detectability. Supervised learning methods that employ convolutional neural networks (CNNs) have emerged as a popular approach to denoising medical images. However, studies have shown that CNNs trained with loss functions based on traditional image quality measures can lead to a loss of task-relevant information in images. Some previous works have investigated task-based loss functions that employ model observers for training the CNN denoising models. However, such training processes typically require a large number of noisy and ground-truth (noise-free or low-noise) image data pairs. In this work, we propose a task-based regularization strategy for use with PLS in medical image denoising. The proposed task-based regularization is associated with the likelihood of linear test statistics of noisy images for Gaussian noise models. The proposed method does not require ground-truth image data and solves an individual optimization problem for denoising each image. Computer-simulation studies are conducted that consider a multivariate-normally distributed (MVN) lumpy background and a binary texture background. It is demonstrated that the proposed regularization strategy can effectively improve signal detectability in denoised images.

Paper number 71:
Title: Distributed Joint User Activity Detection, Channel Estimation, and Data Detection via Expectation Propagation in Cell-Free Massive MIMO
Authors: Christian Forsch, Alexander Karataev, Laura Cottatellucci
Abstract: We consider the uplink of a grant-free cell-free massive multiple-input multiple-output (GF-CF-MaMIMO) system. We propose an algorithm for distributed joint activity detection, channel estimation, and data detection (JACD) based on expectation propagation (EP) called JACD-EP. We develop the algorithm by factorizing the a posteriori probability (APP) of activities, channels, and transmitted data, then, mapping functions and variables onto a factor graph, and finally, performing a message passing on the resulting factor graph. If users with the same pilot sequence are sufficiently distant from each other, the JACD-EP algorithm is able to mitigate the effects of pilot contamination which naturally occurs in grant-free systems due to the large number of potential users and limited signaling resources. Furthermore, it outperforms state-of-the-art algorithms for JACD in GF-CF-MaMIMO systems.

Paper number 72:
Title: Rate-Adaptive Quantization: A Multi-Rate Codebook Adaptation for Vector Quantization-based Generative Models
Authors: Jiwan Seo, Joonhyuk Kang
Abstract: Learning discrete representations with vector quantization (VQ) has emerged as a powerful approach in various generative models. However, most VQ-based models rely on a single, fixed-rate codebook, requiring extensive retraining for new bitrates or efficiency requirements. We introduce Rate-Adaptive Quantization (RAQ), a multi-rate codebook adaptation framework for VQ-based generative models. RAQ applies a data-driven approach to generate variable-rate codebooks from a single baseline VQ model, enabling flexible tradeoffs between compression and reconstruction fidelity. Additionally, we provide a simple clustering-based procedure for pre-trained VQ models, offering an alternative when retraining is infeasible. Our experiments show that RAQ performs effectively across multiple rates, often outperforming conventional fixed-rate VQ baselines. By enabling a single system to seamlessly handle diverse bitrate requirements, RAQ extends the adaptability of VQ-based generative models and broadens their applicability to data compression, reconstruction, and generation tasks.

Paper number 73:
Title: A Multi-Modal Explainability Approach for Human-Aware Robots in Multi-Party Conversation
Authors: Iveta Bečková, Štefan Pócoš, Giulia Belgiovine, Marco Matarese, Omar Eldardeer, Alessandra Sciutti, Carlo Mazzola
Abstract: The addressee estimation (understanding to whom somebody is talking) is a fundamental task for human activity recognition in multi-party conversation scenarios. Specifically, in the field of human-robot interaction, it becomes even more crucial to enable social robots to participate in such interactive contexts. However, it is usually implemented as a binary classification task, restricting the robot's capability to estimate whether it was addressed \review{or not, which} limits its interactive skills. For a social robot to gain the trust of humans, it is also important to manifest a certain level of transparency and explainability. Explainable artificial intelligence thus plays a significant role in the current machine learning applications and models, to provide explanations for their decisions besides excellent performance. In our work, we a) present an addressee estimation model with improved performance in comparison with the previous state-of-the-art; b) further modify this model to include inherently explainable attention-based segments; c) implement the explainable addressee estimation as part of a modular cognitive architecture for multi-party conversation in an iCub robot; d) validate the real-time performance of the explainable model in multi-party human-robot interaction; e) propose several ways to incorporate explainability and transparency in the aforementioned architecture; and f) perform an online user study to analyze the effect of various explanations on how human participants perceive the robot.

Paper number 74:
Title: Communication- and Computation-Efficient Distributed Submodular Optimization in Robot Mesh Networks
Authors: Zirui Xu, Sandilya Sai Garimella, Vasileios Tzoumas
Abstract: We provide a communication- and computation-efficient method for distributed submodular optimization in robot mesh networks. Submodularity is a property of diminishing returns that arises in active information gathering such as mapping, surveillance, and target tracking. Our method, Resource-Aware distributed Greedy (RAG), introduces a new distributed optimization paradigm that enables scalable and near-optimal action coordination. To this end, RAG requires each robot to make decisions based only on information received from and about their neighbors. In contrast, the current paradigms allow the relay of information about all robots across the network. As a result, RAG's decision-time scales linearly with the network size, while state-of-the-art near-optimal submodular optimization algorithms scale cubically. We also characterize how the designed mesh-network topology affects RAG's approximation performance. Our analysis implies that sparser networks favor scalability without proportionally compromising approximation performance: while RAG's decision time scales linearly with network size, the gain in approximation performance scales sublinearly. We demonstrate RAG's performance in simulated scenarios of area detection with up to 45 robots, simulating realistic robot-to-robot (r2r) communication speeds such as the 0.25 Mbps speed of the Digi XBee 3 Zigbee 3.0. In the simulations, RAG enables real-time planning, up to three orders of magnitude faster than competitive near-optimal algorithms, while also achieving superior mean coverage performance. To enable the simulations, we extend the high-fidelity and photo-realistic simulator AirSim by integrating a scalable collaborative autonomy pipeline to tens of robots and simulating r2r communication delays. Our code is available at this https URL.

Paper number 75:
Title: EnergyDiff: Universal Time-Series Energy Data Generation using Diffusion Models
Authors: Nan Lin, Peter Palensky, Pedro P. Vergara
Abstract: High-resolution time series data are crucial for the operation and planning of energy systems such as electrical power systems and heating systems. Such data often cannot be shared due to privacy concerns, necessitating the use of synthetic data. However, high-resolution time series data is difficult to model due to its inherent high dimensionality and complex temporal dependencies. Leveraging the recent development of generative AI, especially diffusion models, we propose EnergyDiff, a universal data generation framework for energy time series data. EnergyDiff builds on state-of-the-art denoising diffusion probabilistic models, utilizing a proposed denoising network dedicated to high-resolution time series data and introducing a novel Marginal Calibration technique. Our extensive experimental results demonstrate that EnergyDiff achieves significant improvement in capturing the temporal dependencies and marginal distributions compared to baselines, particularly at the 1-minute resolution. Additionally, EnergyDiff consistently generates highquality time series data across diverse energy domains, time resolutions, and at both customer and transformer levels with reduced computational need.

Paper number 76:
Title: Multi-Sensor Deep Learning for Glacier Mapping
Authors: Codruţ-Andrei Diaconu, Konrad Heidler, Jonathan L. Bamber, Harry Zekollari
Abstract: The more than 200,000 glaciers outside the ice sheets play a crucial role in our society by influencing sea-level rise, water resource management, natural hazards, biodiversity, and tourism. However, only a fraction of these glaciers benefit from consistent and detailed in-situ observations that allow for assessing their status and changes over time. This limitation can, in part, be overcome by relying on satellite-based Earth Observation techniques. Satellite-based glacier mapping applications have historically mainly relied on manual and semi-automatic detection methods, while recently, a fast and notable transition to deep learning techniques has started. This chapter reviews how combining multi-sensor remote sensing data and deep learning allows us to better delineate (i.e. map) glaciers and detect their temporal changes. We explain how relying on deep learning multi-sensor frameworks to map glaciers benefits from the extensive availability of regional and global glacier inventories. We also analyse the rationale behind glacier mapping, the benefits of deep learning methodologies, and the inherent challenges in integrating multi-sensor earth observation data with deep learning algorithms. While our review aims to provide a broad overview of glacier mapping efforts, we highlight a few setups where deep learning multi-sensor remote sensing applications have a considerable potential added value. This includes applications for debris-covered and rock glaciers that are visually difficult to distinguish from surroundings and for calving glaciers that are in contact with the ocean. These specific cases are illustrated through a series of visual imageries, highlighting some significant advantages and challenges when detecting glacier changes, including dealing with seasonal snow cover, changing debris coverage, and distinguishing glacier fronts from the surrounding sea ice.

Paper number 77:
Title: Energetic Resilience of Linear Driftless Systems
Authors: Ram Padmanabhan, Melkior Ornik
Abstract: When a malfunction causes a control system to lose authority over a subset of its actuators, achieving a task may require spending additional energy in order to compensate for the effect of uncontrolled inputs. To understand this increase in energy, we introduce energetic resilience metrics that quantify the maximal additional energy required to achieve finite-time regulation in linear driftless systems that lose authority over some of their actuators. We first derive optimal control signals and minimum energies to achieve this task in both the nominal and malfunctioning systems. We then obtain a bound on the worst-case energy used by the malfunctioning system, and its exact expression in the special case of loss of authority over one actuator. Further considering this special case, we derive bounds on additive and multiplicative metrics for energetic resilience. A simulation example on a model of an underwater robot demonstrates that these bounds are useful in quantifying the increased energy used by a system suffering a partial loss of control authority.

Paper number 78:
Title: The Smart Buildings Control Suite: A Diverse Open Source Benchmark to Evaluate and Scale HVAC Control Policies for Sustainability
Authors: Judah Goldfeder, Victoria Dean, Zixin Jiang, Xuezheng Wang, Bing dong, Hod Lipson, John Sipple
Abstract: Commercial buildings account for 17% of U.S. carbon emissions, with roughly half of that from Heating, Ventilation, and Air Conditioning (HVAC). HVAC devices form a complex thermodynamic system, and while Model Predictive Control and Reinforcement Learning have been used to optimize control policies, scaling to thousands of buildings remains a significant unsolved challenge. Most current algorithms are over-optimized for specific buildings and rely on proprietary data or hard-to-configure simulations. We present the Smart Buildings Control Suite, the first open source interactive HVAC control benchmark with a focus on solutions that scale. It consists of 3 components: real-world telemetric data extracted from 11 buildings over 6 years, a lightweight data-driven simulator for each building, and a modular Physically Informed Neural Network (PINN) building model as a simulator alternative. The buildings span a variety of climates, management systems, and sizes, and both the simulator and PINN easily scale to new buildings, ensuring solutions using this benchmark are robust to these factors and only reliant on fully scalable building models. This represents a major step towards scaling HVAC optimization from the lab to buildings everywhere. To facilitate use, our benchmark is compatible with the Gym standard, and our data is part of TensorFlow Datasets.

Paper number 79:
Title: A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks
Authors: Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal
Abstract: The development of Internet of Things (IoT) technologies has led to the widespread adoption of monitoring networks for a wide variety of applications, such as smart cities, environmental monitoring, and precision agriculture. A major research focus in recent years has been the development of graph-based techniques to improve the quality of data from sensor networks, a key aspect for the use of sensed data in decision-making processes, digital twins, and other applications. Emphasis has been placed on the development of machine learning and signal processing techniques over graphs, taking advantage of the benefits provided by the use of structured data through a graph topology. Many technologies such as the graph signal processing (GSP) or the successful graph neural networks (GNNs) have been used for data quality enhancement tasks. In this survey, we focus on graph-based models for data quality control in monitoring sensor networks. Furthermore, we delve into the technical details that are commonly leveraged for providing powerful graph-based solutions for data quality tasks in sensor networks, including missing value imputation, outlier detection, or virtual sensing. To conclude, we have identified future trends and challenges such as graph-based models for digital twins or model transferability and generalization.

Paper number 80:
Title: Layer-Adaptive State Pruning for Deep State Space Models
Authors: Minseon Gwak, Seongrok Moon, Joohwan Ko, PooGyeon Park
Abstract: Due to the lack of state dimension optimization methods, deep state space models (SSMs) have sacrificed model capacity, training search space, or stability to alleviate computational costs caused by high state dimensions. In this work, we provide a structured pruning method for SSMs, Layer-Adaptive STate pruning (LAST), which reduces the state dimension of each layer in minimizing model-level output energy loss by extending modal truncation for a single system. LAST scores are evaluated using the $\mathcal{H}_{\infty}$ norms of subsystems and layer-wise energy normalization. The scores serve as global pruning criteria, enabling cross-layer comparison of states and layer-adaptive pruning. Across various sequence benchmarks, LAST optimizes previous SSMs, revealing the redundancy and compressibility of their state spaces. Notably, we demonstrate that, on average, pruning 33% of states still maintains performance with 0.52% accuracy loss in multi-input multi-output SSMs without retraining. Code is available at this https URL.

Paper number 81:
Title: Wearable Accelerometer Foundation Models for Health via Knowledge Distillation
Authors: Salar Abbaspourazad, Anshuman Mishra, Joseph Futoma, Andrew C. Miller, Ian Shapiro
Abstract: Modern wearable devices can conveniently record various biosignals in the many different environments of daily living, enabling a rich view of individual health. However, not all biosignals are the same: high-fidelity biosignals, such as photoplethysmogram (PPG), contain more physiological information, but require optical sensors with a high power footprint. Alternatively, a lower-fidelity biosignal such as accelerometry has a significantly smaller power footprint and is available in almost any wearable device. While accelerometry is widely used for activity recognition and fitness, it is less explored for health biomarkers and diagnosis. Here, we show that an accelerometry foundation model can predict a wide variety of health targets. To achieve improved performance, we distill representational knowledge from PPG encoders to accelerometery encoders using 20 million minutes of unlabeled data, collected from ~172K participants in the Apple Heart and Movement Study under informed consent. We observe strong cross-modal alignment on unseen data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from accelerometry embeddings. We show that distilled accelerometry encoders have significantly more informative representations compared to self-supervised or supervised encoders trained directly on accelerometry data, observed by at least 23%-49% improved performance for predicting heart rate and heart rate variability. We also show that distilled accelerometry encoders are readily predictive of a wide array of downstream health targets, i.e., they are generalist foundation models. We believe accelerometry foundation models for health may unlock new opportunities for developing digital biomarkers from any wearable device.

Paper number 82:
Title: DarkIR: Robust Low-Light Image Restoration
Authors: Daniel Feijoo, Juan C. Benito, Alvaro Garcia, Marcos V. Conde
Abstract: Photography during night or in dark conditions typically suffers from noise, low light and blurring issues due to the dim environment and the common use of long exposure. Although Deblurring and Low-light Image Enhancement (LLIE) are related under these conditions, most approaches in image restoration solve these tasks separately. In this paper, we present an efficient and robust neural network for multi-task low-light image restoration. Instead of following the current tendency of Transformer-based models, we propose new attention mechanisms to enhance the receptive field of efficient CNNs. Our method reduces the computational costs in terms of parameters and MAC operations compared to previous methods. Our model, DarkIR, achieves new state-of-the-art results on the popular LOLBlur, LOLv2 and Real-LOLBlur datasets, being able to generalize on real-world night and dark images. Code and models at this https URL

Paper number 83:
Title: Multiple testing in multi-stream sequential change detection
Authors: Sanjit Dandapanthula, Aaditya Ramdas
Abstract: Multi-stream sequential change detection involves simultaneously monitoring many streams of data and trying to detect when their distributions change, if at all. Here, we theoretically study multiple testing issues that arise from detecting changes in many streams. We point out that any algorithm with finite average run length (ARL) must have a trivial worst-case false detection rate (FDR), family-wise error rate (FWER), per-family error rate (PFER), and global error rate (GER); thus, any attempt to control these Type I error metrics is fundamentally in conflict with the desire for a finite ARL (which is typically necessary in order to have a small detection delay). One of our contributions is to define a new class of metrics which can be controlled, called error over patience (EOP). We propose algorithms that combine the recent e-detector framework (which generalizes the Shiryaev-Roberts and CUSUM methods) with the recent e-Benjamini-Hochberg procedure and e-Bonferroni procedures. We prove that these algorithms control the EOP at any desired level under very general dependence structures on the data within and across the streams. In fact, we prove a more general error control that holds uniformly over all stopping times and provides a smooth trade-off between the conflicting metrics. Additionally, if finiteness of the ARL is forfeited, we show that our algorithms control the worst-case Type I error.

Paper number 84:
Title: UAV-Assisted MEC Architecture for Collaborative Task Offloading in Urban IoT Environment
Authors: Subhrajit Barick, Chetna Singhal
Abstract: Mobile edge computing (MEC) is a promising technology to meet the increasing demands and computing limitations of complex Internet of Things (IoT) devices. However, implementing MEC in urban environments can be challenging due to factors like high device density, complex infrastructure, and limited network coverage. Network congestion and connectivity issues can adversely affect user satisfaction. Hence, in this article, we use unmanned aerial vehicle (UAV)-assisted collaborative MEC architecture to facilitate task offloading of IoT devices in urban environments. We utilize the combined capabilities of UAVs and ground edge servers (ESs) to maximize user satisfaction and thereby also maximize the service provider's (SP) profit. We design IoT task-offloading as joint IoT-UAV-ES association and UAV-network topology optimization problem. Due to NP-hard nature, we break the problem into two subproblems: offload strategy optimization and UAV topology optimization. We develop a Three-sided Matching with Size and Cyclic preference (TMSC) based task offloading algorithm to find stable association between IoTs, UAVs, and ESs to achieve system objective. We also propose a K-means based iterative algorithm to decide the minimum number of UAVs and their positions to provide offloading services to maximum IoTs in the system. Finally, we demonstrate the efficacy of the proposed task offloading scheme over benchmark schemes through simulation-based evaluation. The proposed scheme outperforms by 19%, 12%, and 25% on average in terms of percentage of served IoTs, average user satisfaction, and SP profit, respectively, with 25% lesser UAVs, making it an effective solution to support IoT task requirements in urban environments using UAV-assisted MEC architecture.

Paper number 85:
Title: Multimodal Magic Elevating Depression Detection with a Fusion of Text and Audio Intelligence
Authors: Lindy Gan, Yifan Huang, Xiaoyang Gao, Jiaming Tan, Fujun Zhao, Tao Yang
Abstract: This study proposes an innovative multimodal fusion model based on a teacher-student architecture to enhance the accuracy of depression classification. Our designed model addresses the limitations of traditional methods in feature fusion and modality weight allocation by introducing multi-head attention mechanisms and weighted multimodal transfer learning. Leveraging the DAIC-WOZ dataset, the student fusion model, guided by textual and auditory teacher models, achieves significant improvements in classification accuracy. Ablation experiments demonstrate that the proposed model attains an F1 score of 99. 1% on the test set, significantly outperforming unimodal and conventional approaches. Our method effectively captures the complementarity between textual and audio features while dynamically adjusting the contributions of the teacher models to enhance generalization capabilities. The experimental results highlight the robustness and adaptability of the proposed framework in handling complex multimodal data. This research provides a novel technical framework for multimodal large model learning in depression analysis, offering new insights into addressing the limitations of existing methods in modality fusion and feature extraction.
    