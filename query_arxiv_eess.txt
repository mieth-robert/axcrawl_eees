
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet
Authors: Honggang Jia, Nan Cheng, Xiucheng Wang, Conghao Zhou, Ruijin Sun, Xuemin (Sherman)Shen
Abstract: Radio map (RM) has recently attracted much attention since it can provide real-time and accurate spatial channel information for 6G services and applications. However, current deep learning-based methods for RM construction exhibit well known accuracy-efficiency trade-off. In this paper, we introduce RadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the trade-off. Generally, accurate RM construction requires modeling long-range spatial dependencies, reflecting the global nature of wave propagation physics. RadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures these global dependencies with linear complexity, while a parallel convolutional branch extracts local features. This hybrid design generates feature representations that capture both global context and local detail. Experiments show that RadioMamba achieves higher accuracy than existing methods, including diffusion models, while operating nearly 20 times faster and using only 2.9\% of the model parameters. By improving both accuracy and efficiency, RadioMamba presents a viable approach for real-time intelligent optimization in next generation wireless systems.

Paper number 2:
Title: Bayesian-Driven Graph Reasoning for Active Radio Map Construction
Authors: Wenlihan Lu, Shijian Gao, Miaowen Wen, Yuxuan Liang, Chan-Byoung Chae, H. Vincent Poor
Abstract: With the emergence of the low-altitude economy, radio maps have become essential for ensuring reliable wireless connectivity to aerial platforms. Autonomous aerial agents are commonly deployed for data collection using waypoint-based navigation; however, their limited battery capacity significantly constrains coverage and efficiency. To address this, we propose an uncertainty-aware radio map (URAM) reconstruction framework that explicitly leverages graph-based reasoning tailored for waypoint navigation. Our approach integrates two key deep learning components: (1) a Bayesian neural network that estimates spatial uncertainty in real time, and (2) an attention-based reinforcement learning policy that performs global reasoning over a probabilistic roadmap, using uncertainty estimates to plan informative and energy-efficient trajectories. This graph-based reasoning enables intelligent, non-myopic trajectory planning, guiding agents toward the most informative regions while satisfying safety constraints. Experimental results show that URAM improves reconstruction accuracy by up to 34% over existing baselines.

Paper number 3:
Title: Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation
Authors: Xuanru Zhou, Cheng Li, Shuqiang Wang, Ye Li, Tao Tan, Hairong Zheng, Shanshan Wang
Abstract: Generative artificial intelligence (AI) is rapidly transforming medical imaging by enabling capabilities such as data synthesis, image enhancement, modality translation, and spatiotemporal modeling. This review presents a comprehensive and forward-looking synthesis of recent advances in generative modeling including generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and emerging multimodal foundation architectures and evaluates their expanding roles across the clinical imaging continuum. We systematically examine how generative AI contributes to key stages of the imaging workflow, from acquisition and reconstruction to cross-modality synthesis, diagnostic support, and treatment planning. Emphasis is placed on both retrospective and prospective clinical scenarios, where generative models help address longstanding challenges such as data scarcity, standardization, and integration across modalities. To promote rigorous benchmarking and translational readiness, we propose a three-tiered evaluation framework encompassing pixel-level fidelity, feature-level realism, and task-level clinical relevance. We also identify critical obstacles to real-world deployment, including generalization under domain shift, hallucination risk, data privacy concerns, and regulatory hurdles. Finally, we explore the convergence of generative AI with large-scale foundation models, highlighting how this synergy may enable the next generation of scalable, reliable, and clinically integrated imaging systems. By charting technical progress and translational pathways, this review aims to guide future research and foster interdisciplinary collaboration at the intersection of AI, medicine, and biomedical engineering.

Paper number 4:
Title: HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction
Authors: Hongli Chen, Pengcheng Fang, Yuxia Chen, Yingxuan Ren, Jing Hao, Fangfang Tang, Xiaohao Cai, Shanshan Shan, Feng Liu
Abstract: Reconstructing high-fidelity MR images from undersampled k-space data remains a challenging problem in MRI. While Mamba variants for vision tasks offer promising long-range modeling capabilities with linear-time complexity, their direct application to MRI reconstruction inherits two key limitations: (1) insensitivity to high-frequency anatomical details; and (2) reliance on redundant multi-directional scanning. To address these limitations, we introduce High-Fidelity Mamba (HiFi-Mamba), a novel dual-stream Mamba-based architecture comprising stacked W-Laplacian (WL) and HiFi-Mamba blocks. Specifically, the WL block performs fidelity-preserving spectral decoupling, producing complementary low- and high-frequency streams. This separation enables the HiFi-Mamba block to focus on low-frequency structures, enhancing global feature modeling. Concurrently, the HiFi-Mamba block selectively integrates high-frequency features through adaptive state-space modulation, preserving comprehensive spectral details. To eliminate the scanning redundancy, the HiFi-Mamba block adopts a streamlined unidirectional traversal strategy that preserves long-range modeling capability with improved computational efficiency. Extensive experiments on standard MRI reconstruction benchmarks demonstrate that HiFi-Mamba consistently outperforms state-of-the-art CNN-based, Transformer-based, and other Mamba-based models in reconstruction accuracy while maintaining a compact and efficient model design.

Paper number 5:
Title: MedPatch: Confidence-Guided Multi-Stage Fusion for Multimodal Clinical Data
Authors: Baraa Al Jorf, Farah Shamout
Abstract: Clinical decision-making relies on the integration of information across various data modalities, such as clinical time-series, medical images and textual reports. Compared to other domains, real-world medical data is heterogeneous in nature, limited in size, and sparse due to missing modalities. This significantly limits model performance in clinical prediction tasks. Inspired by clinical workflows, we introduce MedPatch, a multi-stage multimodal fusion architecture, which seamlessly integrates multiple modalities via confidence-guided patching. MedPatch comprises three main components: (i) a multi-stage fusion strategy that leverages joint and late fusion simultaneously, (ii) a missingness-aware module that handles sparse samples with missing modalities, (iii) a joint fusion module that clusters latent token patches based on calibrated unimodal token-level confidence. We evaluated MedPatch using real-world data consisting of clinical time-series data, chest X-ray images, radiology reports, and discharge notes extracted from the MIMIC-IV, MIMIC-CXR, and MIMIC-Notes datasets on two benchmark tasks, namely in-hospital mortality prediction and clinical condition classification. Compared to existing baselines, MedPatch achieves state-of-the-art performance. Our work highlights the effectiveness of confidence-guided multi-stage fusion in addressing the heterogeneity of multimodal data, and establishes new state-of-the-art benchmark results for clinical prediction tasks.

Paper number 6:
Title: Hybrid(Transformer+CNN)-based Polyp Segmentation
Authors: Madan Baduwal
Abstract: Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the problem is extremely challenging due to high variation in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined boundaries (fluid, folds) of the polyps, rendering accurate segmentation a challenging and problematic task. To address these critical challenges in polyp segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted to enhance robustness against evolving polyp characteristics. Our hybrid architecture demonstrates superior performance over existing solutions, particularly in addressing two critical challenges: (1) accurate segmentation of polyps with ill-defined margins through boundary-aware attention mechanisms, and (2) robust feature extraction in the presence of common endoscopic artifacts, including specular highlights, motion blur, and fluid occlusions. Quantitative evaluations reveal significant improvements in segmentation accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%, i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp segmentation methods.

Paper number 7:
Title: impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction
Authors: Maria Boyko, Aleksandra Beliaeva, Dmitriy Kornilov, Alexander Bernstein, Maxim Sharaev
Abstract: The use of diverse modalities, such as omics, medical images, and clinical data can not only improve the performance of prognostic models but also deepen an understanding of disease mechanisms and facilitate the development of novel treatment approaches. However, medical data are complex, often incomplete, and contains missing modalities, making effective handling its crucial for training multimodal models. We introduce impuTMAE, a novel transformer-based end-to-end approach with an efficient multimodal pre-training strategy. It learns inter- and intra-modal interactions while simultaneously imputing missing modalities by reconstructing masked patches. Our model is pre-trained on heterogeneous, incomplete data and fine-tuned for glioma survival prediction using TCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm, RNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data during pre-training and enabling efficient resource utilization, impuTMAE surpasses prior multimodal approaches, achieving state-of-the-art performance in glioma patient survival prediction. Our code is available at this https URL

Paper number 8:
Title: FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation
Authors: Asim Ukaye, Numan Saeed, Karthik Nandakumar
Abstract: Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: this https URL

Paper number 9:
Title: Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction
Authors: Jinho Kim, Marcel Dominik Nickel, Florian Knoll
Abstract: Purpose: To investigate the feasibility of applying zero-shot self-supervised learning reconstruction to reduce breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Methods: Breath-hold MRCP was acquired from 11 healthy volunteers on a 3T scanner using an incoherent k-space sampling pattern leading to a breath-hold duration of 14s. We evaluated zero-shot reconstruction of breath-hold MRCP against parallel imaging of respiratory-triggered MRCP acquired in 338s on average and compressed sensing reconstruction of breath-hold MRCP. To address the long computation times of zero-shot trainings, we used a training approach that leverages a pretrained network to reduce backpropagation depth during training. Results: Zero-shot learning reconstruction significantly improved visual image quality compared to compressed sensing reconstruction, particularly in terms of signal-to-noise ratio and ductal delineation, and reached a level of quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Shallow training provided nearly equivalent reconstruction performance with a training time of 11 minutes in comparison to 271 minutes for a conventional zero-shot training. Conclusion: Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and shallow training offers a practical solution for translation to time-constrained clinical workflows.

Paper number 10:
Title: From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations
Authors: Yoni Schirris, Eric Marcus, Jonas Teuwen, Hugo Horlings, Efstratios Gavves
Abstract: Explaining deep learning models is essential for clinical integration of medical image analysis systems. A good explanation highlights if a model depends on spurious features that undermines generalization and harms a subset of patients or, conversely, may present novel biological insights. Although techniques like GradCAM can identify influential features, they are measurement tools that do not themselves form an explanation. We propose a human-machine-VLM interaction system tailored to explaining classifiers in computational pathology, including multi-instance learning for whole-slide images. Our proof of concept comprises (1) an AI-integrated slide viewer to run sliding-window experiments to test claims of an explanation, and (2) quantification of an explanation's predictiveness using general-purpose vision-language models. The results demonstrate that this allows us to qualitatively test claims of explanations and can quantifiably distinguish competing explanations. This offers a practical path from explainable AI to explained AI in digital pathology and beyond. Code and prompts are available at this https URL.

Paper number 11:
Title: AMRG: Extend Vision Language Models for Automatic Mammography Report Generation
Authors: Nak-Jun Sung, Donghyun Lee, Bo Hwa Choi, Chae Jung Park
Abstract: Mammography report generation is a critical yet underexplored task in medical AI, characterized by challenges such as multiview image reasoning, high-resolution visual cues, and unstructured radiologic language. In this work, we introduce AMRG (Automatic Mammography Report Generation), the first end-to-end framework for generating narrative mammography reports using large vision-language models (VLMs). Building upon MedGemma-4B-it-a domain-specialized, instruction-tuned VLM-we employ a parameter-efficient fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling lightweight adaptation with minimal computational overhead. We train and evaluate AMRG on DMID, a publicly available dataset of paired high-resolution mammograms and diagnostic reports. This work establishes the first reproducible benchmark for mammography report generation, addressing a longstanding gap in multimodal clinical AI. We systematically explore LoRA hyperparameter configurations and conduct comparative experiments across multiple VLM backbones, including both domain-specific and general-purpose models under a unified tuning protocol. Our framework demonstrates strong performance across both language generation and clinical metrics, achieving a ROUGE-L score of 0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582. Qualitative analysis further highlights improved diagnostic consistency and reduced hallucinations. AMRG offers a scalable and adaptable foundation for radiology report generation and paves the way for future research in multimodal medical AI.

Paper number 12:
Title: Objective Soups: Multilingual Multi-Task Modeling for Speech Processing
Authors: A F M Saif, Lisha Chen, Xiaodong Cui, Songtao Lu, Brian Kingsbury, Tianyi Chen
Abstract: Training a single model for multilingual, multi-task speech processing (MSP) is severely hampered by conflicting objectives between tasks like speech recognition and translation. While multi-objective optimization (MOO) aims to align gradient updates, its effectiveness diminishes as the number of tasks grows, making it difficult to find a common descent direction. This raises a fundamental question: should highly conflicting objectives be optimized jointly or separated into a hierarchical structure? To address this question, this paper investigates three multi-objective MSP formulations, which we refer to as \textbf{objective soup recipes}. These formulations apply multi-objective optimization at different optimization levels to mitigate potential conflicts among all objectives. To ensure efficiency, we introduce a lightweight layer-selection mechanism that computes the conflict-avoiding gradient using only the most problematic layers, minimizing computational and memory overhead. Extensive experiments on CoVoST v2, LibriSpeech, and AISHELL-1 reveal that a bi-level recipe separating recognition and translation tasks consistently outperforms standard flat optimization. Our work demonstrates that hierarchical MOO is a more effective and scalable approach for building state-of-the-art MSP models. Our code has been released at this https URL.

Paper number 13:
Title: A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis
Authors: Reihaneh Hassanzadeh, Anees Abrol, Hamid Reza Hassanzadeh, Vince D. Calhoun
Abstract: Multimodal data analysis can lead to more accurate diagnoses of brain disorders due to the complementary information that each modality adds. However, a major challenge of using multimodal datasets in the neuroimaging field is incomplete data, where some of the modalities are missing for certain subjects. Hence, effective strategies are needed for completing the data. Traditional methods, such as subsampling or zero-filling, may reduce the accuracy of predictions or introduce unintended biases. In contrast, advanced methods such as generative models have emerged as promising solutions without these limitations. In this study, we proposed a generative adversarial network method designed to reconstruct missing modalities from existing ones while preserving the disease patterns. We used T1-weighted structural magnetic resonance imaging and functional network connectivity as two modalities. Our findings showed a 9% improvement in the classification accuracy for Alzheimer's disease versus cognitive normal groups when using our generative imputation method compared to the traditional approaches.

Paper number 14:
Title: Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative
Authors: Xi Xuan, Zimo Zhu, Wenxin Zhang, Yi-Cheng Lin, Tomi Kinnunen
Abstract: Advances in speech synthesis intensify security threats, motivating real-time deepfake detection research. We investigate whether bidirectional Mamba can serve as a competitive alternative to Self-Attention in detecting synthetic speech. Our solution, Fake-Mamba, integrates an XLSR front-end with bidirectional Mamba to capture both local and global artifacts. Our core innovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and PN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can effectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof 21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and 5.85% EER, respectively, representing substantial relative gains over SOTA models XLSR-Conformer and XLSR-Mamba. The framework maintains real-time inference across utterance lengths, demonstrating strong generalization and practical viability. The code is available at this https URL.

Paper number 15:
Title: Dynamic Survival Prediction using Longitudinal Images based on Transformer
Authors: Bingfan Liu, Haolun Shi, Jiguo Cao
Abstract: Survival analysis utilizing multiple longitudinal medical images plays a pivotal role in the early detection and prognosis of diseases by providing insight beyond single-image evaluations. However, current methodologies often inadequately utilize censored data, overlook correlations among longitudinal images measured over multiple time points, and lack interpretability. We introduce SurLonFormer, a novel Transformer-based neural network that integrates longitudinal medical imaging with structured data for survival prediction. Our architecture comprises three key components: a Vision Encoder for extracting spatial features, a Sequence Encoder for aggregating temporal information, and a Survival Encoder based on the Cox proportional hazards model. This framework effectively incorporates censored data, addresses scalability issues, and enhances interpretability through occlusion sensitivity analysis and dynamic survival prediction. Extensive simulations and a real-world application in Alzheimer's disease analysis demonstrate that SurLonFormer achieves superior predictive performance and successfully identifies disease-related imaging biomarkers.

Paper number 16:
Title: Generative AI-Enabled Robust 6G Uplink: Principles, Challenges, and Directions
Authors: Chunmei Xu, Yi Ma, Rahim Tafazolli, Peiying Zhu
Abstract: Next-generation wireless networks (6G) face a critical uplink bottleneck due to stringent device-side resource constraints and challenging channel conditions. This article introduces GenCom, a novel system-level paradigm for robust 6G uplink that leverages Generative AI and exploits the inherent resource imbalance between transmitters and receivers. In GenCom, resource-rich receivers deploy powerful offline-trained GenAI models to reconstruct high semantic-fidelity content from degraded signals, while resource-constrained transmitters are simplified in both source and channel coding design. We present the core mechanisms and key design principles behind GenCom, which shifts from conventional approaches toward simple semantic-preserving compression, weak error-distribution codes, and semantic-aware retransmissions. Through a case study, GenCom is shown to deliver robust performance across a wide range of low and uncertain SNR/SINR conditions where conventional systems fail. Finally, we outline critical challenges and research directions toward making GenCom a practical enabler of future human-centric, intelligent, and sustainable wireless networks.

Paper number 17:
Title: Satellites are closer than you think: A near field MIMO approach for Ground stations
Authors: Rohith Reddy Vennam, Luke Wilson, Ish Kumar Jain, Dinesh Bharadia
Abstract: The rapid growth of low Earth orbit (LEO) satellite constellations has revolutionized broadband access, earth observation, and direct-to-device connectivity. However, the expansion of ground station infrastructure has not kept pace, creating a critical bottleneck in satellite-to-ground backhaul capacity. Traditional parabolic dish antennas, though effective for geostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO networks due to mechanical steering delays and their inability to track multiple satellites simultaneously. Phased array antennas offer electronically steerable beams and multisatellite support, but their integration into ground stations is limited by the high cost, hardware issues, and complexity of achieving sufficient antenna gain. We introduce ArrayLink, a distributed phased array architecture that coherently combines multiple small commercially available panels to achieve high-gain beamforming and unlock line-of-sight MIMO spatial multiplexing with minimal additional capital expenditure. By spacing 16 (32x32) panels across a kilometer-scale aperture, ArrayLink enters the radiative near-field, focusing energy in both angle and range while supporting up to four simultaneous spatial streams on a single feeder link. Through rigorous theoretical analysis, detailed 2D beam pattern simulations and real-world hardware experiments, we show that ArrayLink (i) achieves dish-class gain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel streams at ranges of hundreds of kilometers (falling to two beyond 2000 km), and (iii) exhibits tight agreement across theory, simulation, and experiment with minimal variance. These findings open a practical and scalable path to boosting LEO backhaul capacity.

Paper number 18:
Title: ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs
Authors: Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan
Abstract: Prosody conveys rich emotional and semantic information of the speech signal as well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and unmasked textual content. Trained on the GigaSpeech dataset, we compare our method with state-of-the-art style encoders. For F0 and energy predictions, we show consistent improvements for our model at different levels of granularity. We also integrate these predicted prosodic features into a TTS system and conduct perceptual tests, which show higher prosody preference compared to the baselines, demonstrating the model's potential in tasks where prosody modeling is important.

Paper number 19:
Title: Design and Simulation of 6T SRAM Array
Authors: Justin London
Abstract: Conventional 6T SRAM is used in microprocessors in the cache memory design. The basic 6T SRAM cell and a 6 bit memory array layout are designed in LEdit. The design and analysis of key SRAM components, sense amplifiers, decoders, write drivers and precharge circuits are also provided. The pulse voltage waveforms generated for read and write operations as well as Q and Qbar nodes are simulated in LTSpice. Parasitic capacitances are extracted and their impact on the waveforms analyzed. Static noise margin, propagation delays, and power dissipation are calculated. Comparison of SRAM read and write operational performance using CMOS transistors is made with edge-triggered D flip flops. If certain size area and ratio constraints are satisfied, the 6T cell with CMOS transistors will possess stability, speed, and power efficiency. Both theoretical and simulated results are given.

Paper number 20:
Title: Control Systems Analysis of a 3-Axis Photovoltatic Solar Tracker for Water Pumping
Authors: Justin London
Abstract: We propose 3-axis solar tracker water pumping system. The solar tracker can rotate and tilt using stepper/DC motors and can rise and lower on a tripod using a linear actuator. The charge generated from solar energy absorbed by photovoltaic (PV) cells in the solar panel is stored in a 12V battery that in turn powers two water diaphragm pumps using a solar charge controller. The PV uses four light photocell resistors/sensors to measure light intensity. A solar tracking algorithm determines the optimal angle for PV positioning. Using an ultrasonic sensor to measure the water level in a reservoir water tank, water is pumped from one water tank to the reservoir. Based on soil moisture sensor levels, a second water pump supplies water from the reservoir to the plant. The system is analyzed from a control systems perspective. The transfer functions, root loci, and Bode plots are generated and simulated and experimental results are provided as well as stability and steady-state error analysis.

Paper number 21:
Title: Imperfect Competition in Markets for Short-Circuit Current Services
Authors: Peng Wang, Luis Badesa
Abstract: An important limitation of Inverter-Based Resources (IBR) is their reduced contribution to Short-Circuit Current (SCC), as compared to that of Synchronous Generators (SGs). With increasing penetration of IBR in most power systems, the reducing SCC poses challenges to a secure system operation, as line protections may not trip when required. In order to address this issue, the SCC ancillary service could be procured via an economic mechanism, aiming at securing adequate SCC on all buses. However, the suitability of markets for SCC services is not well understood, given that these could be prone to market-power issues: since the SCC contributions from various SGs to a certain bus are determined by the electrical topology of the grid, this is a highly local service. It is necessary to understand if SGs at advantageous electrical locations could exert market power and, if so, how it could be mitigated. In order to fill this gap, this paper adopts an SCC-constrained bilevel model to investigate strategic behaviors of SGs. To address the non-convexity due to unit commitment variables, the model is restructured through a primal-dual formulation. Based on a modified IEEE 30-bus system, cases with strategic SGs placed at different buses are analyzed. These studies demonstrate that agents exerting market power could achieve up to triple revenues from SCC provision, highlighting the need to carefully design these markets.

Paper number 22:
Title: From Micro to Macro Flow Modeling: Characterizing Heterogeneity of Mixed-Autonomy Traffic
Authors: Chenguang Zhao, Huan Yu
Abstract: Most autonomous-vehicles (AVs) driving strategies are designed and analyzed at the vehicle level, yet their aggregate impact on macroscopic traffic flow is still not understood, particularly the flow heterogeneity that emerges when AVs interact with human-driven vehicles (HVs). Existing validation techniques for macroscopic flow models rely on high-resolution spatiotemporal data spanning entire road segments which are rarely available for mixed-autonomy traffic. AVs record detailed Lagrangian trajectories of the ego vehicle and surrounding traffic through onboard sensors. Leveraging these Lagrangian observations to validate mixed-autonomy flow models therefore remains an open research challenge. This paper closes the gap between microscopic Lagrangian data and macroscopic Euclidean traffic models by introducing a continuous traffic-heterogeneity attribute. We represent traffic flow with two coupled conservation laws with one for vehicle number and one for the traffic attribute. Reconstruction methods are designed to derive the traffic attribute from Lagrangian vehicle trajectories. When abundant trajectory data are available, we characterize traffic heterogeneity by extracting drivers' desired speed and local behavioral uncertainty from trajectories. In data-scarce mixed traffic, we design an end-to-end mapping that infers the traffic heterogeneity solely from trajectories in the current spatiotemporal region. Experiments across multiple traffic datasets show that the proposed model effectively captures traffic heterogeneity by clustering the fundamental diagram scatter into attribute-based groups. The calibration errors of traffic flow dynamics are also reduce by 20% relative to the Aw-Rascle-Zhang model benchmark. Detailed analyses further show that the model generalizes well, maintaining nearly the same accuracy when evaluated under a variety of previously unseen traffic conditions.

Paper number 23:
Title: From Formal Methods to Data-Driven Safety Certificates of Unknown Large-Scale Networks
Authors: Omid Akbarzadeh, Behrad Samari, Amy Nejati, Abolfazl Lavaei
Abstract: In this work, we propose a data-driven scheme within a compositional framework with noisy data to design robust safety controllers in a fully decentralized fashion for large-scale interconnected networks with unknown mathematical dynamics. Despite the network's high dimensionality and the inherent complexity of its unknown model, which make it intractable, our approach effectively addresses these challenges by (i) treating the network as a composition of smaller subsystems, and (ii) collecting noisy data from each subsystem's trajectory to design a control sub-barrier certificate (CSBC) and its corresponding local controller. To achieve this, our proposed scheme only requires a noise-corrupted single input-state trajectory from each unknown subsystem up to a specified time horizon, satisfying a certain rank condition. Subsequently, under a small-gain compositional reasoning, we compose those CSBC, derived from noisy data, and formulate a control barrier certificate (CBC) for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We offer a data-dependent sum-of-squares (SOS) optimization program for computing CSBC alongside local controllers of subsystems. We illustrate that while the computational complexity of designing a CBC and its safety controller grows polynomially with network dimension using SOS optimization, our compositional data-driven approach significantly reduces it to a linear scale concerning the number of subsystems. We demonstrate the capability of our data-driven approach on multiple physical networks involving unknown models and a range of interconnection topologies.

Paper number 24:
Title: Shepherd Grid Strategy: Towards Reliable SWARM Interception
Authors: Boris Kriuk, Fedor Kriuk
Abstract: Modern unmanned aerial vehicle threats require sophisticated interception strategies that can overcome advanced evasion capabilities and operate effectively in contested environments. Traditional single-interceptor and uncoordinated multi-interceptor approaches suffer from fundamental limitations including inadequate coverage, predictable pursuit patterns, and vulnerability to intelligent evasion maneuvers. This paper introduces the Shepherd Grid Strategy, a new multi-phase coordination framework that employs pack-based behavioral coordination to achieve deterministic target interception through systematic containment and coordinated strike execution. The strategy implements a four-phase operational model consisting of chase, follow, formation, and engagement phases, with dynamic role assignment and adaptive formation geometry that maintains persistent target pressure while preparing optimal strike opportunities. Our approach incorporates three key innovations: adaptive phase transition mechanisms that optimize pursuit behavior based on proximity and mission objectives, dynamic role assignment systems that designate specialized interceptor functions including formation maintenance and strike execution, and predictive formation geometry algorithms that create mobile containment grids adapting to target movement patterns. The simulation experiments demonstrate significant performance improvements over traditional methods, achieving near-perfect interception success rates (over 95%) compared to traditional approaches (65%) and reducing median time-to-intercept.

Paper number 25:
Title: Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms
Authors: Lutfi Samara, Simon Haussmann, Erind Tufa, Antonio Alberto D'Amico, Tommaso Zugno, Ingmar Kallfass, Thomas Kürner
Abstract: With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the Terahertz (THz) spectrum offers a promising solution to satisfy such forecasts. However, occupying the THz spectrum comes with its own challenges, an important one being impairments caused by broadband RF components in THz transceivers. Nonlinearities in power amplifiers (PAs) complicate meeting link budget requirements, with amplitude and phase distortions degrading the system's performance, especially when adopting waveforms with high peak-to-average power ratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In this paper, we present characterization results of a 300 GHz PA using small-signal and large-signal continuous-wave measurements. Models capturing Amplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation (AMPM) behavior across 270-330 GHz are developed and verified with wideband measurements, confirming the compression behavior, while nonetheless showing inaccuracies for low input powers due to unaccounted frequency dependencies. Based on the derived models, a predistortion algorithm is designed and analyzed, revealing significant error performance degradation when switching between single- and multi-carrier waveforms. We finally show that an appropriate selection of pre-distorter parameters can significantly improve the performance.

Paper number 26:
Title: Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm
Authors: Dumitra Iancu, Liang Liu, Ove Edfors, Erik Leitinger, Xuhong Li
Abstract: Distributed MIMO and integrated sensing and communication are expected to be key technologies in future wireless systems, enabling reliable, low-latency communication and accurate localization. Dedicated localization solutions must support distributed architecture, provide scalability across different system configurations and meet strict latency requirements. We present a scalable message-passing localization method and architecture co-designed for a panel-based distributed MIMO system and network topology, in which interconnected units operate without centralized processing. This method jointly detects line-of-sight paths to distributed units from multipath measurements in dynamic scenarios, localizes the agent, and achieves very low latency. Additionally, we introduce a cycle-accurate system latency model based on implemented FPGA operations, and show important insights into processing latency and hardware utilization and system-level trade-offs. We compare our method to a multipath-based localization method and show that it can achieve similar localization performance, with wide enough distribution of array elements, while offering lower latency and computational complexity.

Paper number 27:
Title: Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes
Authors: Zhiyuan Ren, Yutao Liu, Wenchi Cheng, Kun Yang
Abstract: This paper proposes a saturation throughput delta-based methodology to precisely measure operator costs in high-speed data planes without intrusive instrumentation. The approach captures non-linear scaling, revealing that compute-intensive operators like CRC exhibit super-linear behavior, while most others are sub-linear. We introduce the Operator Performance Quadrant (OPQ) framework to classify operators by base and scaling costs, exposing a cross-architecture Quadrant Shift between Arm and x86. This method provides accurate, architecture-aware bottleneck diagnosis and a realistic basis for performance modeling and optimization.

Paper number 28:
Title: Metering traffic flows for perimeter control through auction-based signalling using connected vehicles
Authors: Alexander Roocroft, Marco Rinaldi
Abstract: Urban traffic congestion remains a critical challenge in modern cities, with traffic signal control systems often struggling to manage congestion during peak travel times. Perimeter control of a Protected Network (PN) has emerged as a potential solution to reducing gridlock in urban networks. This paper proposes a novel auction-based mechanism for green time allocation at signalized intersections, for effective perimeter control application. Utilising a Sealed Bid, Second Price auction framework, our approach combines real-time traffic monitoring with market-inspired mechanisms to regulate vehicle inflows into PN areas. Unlike existing methods that focus primarily on gated links, our system allocates budgets to individual traffic movements, providing greater flexibility in managing multi-directional flows. We evaluate the proposed mechanism using a test case intersection with a single controlled inflow, comparing it against a volume-based fixed-time approach. The results demonstrate that our auction-based method controls flows into the PN with improved accuracy, outperforming the volume-based approach in terms of inflow regulation, queue management and delays. The framework can be applied in real time to any generic intersection, offering a scalable solution for urban traffic management. This work bridges the gap between perimeter control and market-based intersection auctions, providing a pathway for further research on adaptive traffic management systems.

Paper number 29:
Title: A Divide-and-Conquer Tiling Method for the Design of Large Aperiodic Phased Arrays
Authors: Nicola Anselmi, Paolo Rocca, Giovanni Toso, Andrea Massa
Abstract: Due to the growing request from modern wireless applications of cost-affordable and high-gain scanning antenna solutions, the design of large phased arrays (PAs) with radiating elements organized into modular clusters with sub-array-only amplitude and phase control is a key topic. In this paper, an innovative irregular tiling method is proposed where, according to a divide-and-conquer strategy, the antenna aperture is subdivided into sub-areas that are locally domino-tiled by jointly fulfilling the full-coverage condition on the remaining untiled part of the PA support. Selected representative results, including comparisons with competitive state-of-the-art synthesis methods, are reported to prove the effectiveness and the computational efficiency of the proposed tiling approach. Use-cases of current relevance for low Earth orbit (LEO) satellite communications are discussed, as well, to provide the antenna designers useful practical guidelines for handling large PAs.

Paper number 30:
Title: $\text{M}^3\text{PDB}$: A Multimodal, Multi-Label, Multilingual Prompt Database for Speech Generation
Authors: Boyu Zhu, Cheng Gong, Muyang Wu, Ruihao Jing, Fan Liu, Xiaolei Zhang, Chi Zhang, Xuelong Li
Abstract: Recent advancements in zero-shot speech generation have enabled models to synthesize speech that mimics speaker identity and speaking style from speech prompts. However, these models' effectiveness is significantly limited in real-world scenarios where high-quality speech prompts are absent, incomplete, or out of domain. This issue arises primarily from a significant quality mismatch between the speech data utilized for model training and the input prompt speech during inference. To address this, we introduce $\text{M}^3\text{PDB}$, the first large-scale, multi-modal, multi-label, and multilingual prompt database designed for robust prompt selection in speech generation. Our dataset construction leverages a novel multi-modal, multi-agent annotation framework, enabling precise and hierarchical labeling across diverse modalities. Furthermore, we propose a lightweight yet effective prompt selection strategy tailored for real-time, resource-constrained inference settings. Experimental results demonstrate that our proposed database and selection strategy effectively support various challenging speech generation scenarios. We hope our work can inspire the community to shift focus from improving performance on standard benchmarks to addressing more realistic and diverse application scenarios in speech generation. Code and dataset are available at: this https URL.

Paper number 31:
Title: 3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator
Authors: Thomas Fehrenbach, Luis Omar Ortiz Abrego, Cornelius Hellge, Thomas Schierl, Jörg Ott
Abstract: Vehicle-to-everything (V2X) communication is a key technology for enabling intelligent transportation systems (ITS) that can improve road safety, traffic efficiency, and environmental sustainability. Among the various V2X applications, platooning is one of the most promising ones, as it allows a group of vehicles to travel closely together at high speeds, reducing fuel consumption and emissions. However, it poses significant challenges for wireless communication, such as high reliability and low latency. In this paper, we evaluate the benefits of group scheduling, also referred to as Mode 2d, which is based on a distributed and scheduled resource allocation scheme that allows the group of cars to select resources from a configured pool without network assistance. We evaluated the scheme through simulations, and the results show that this approach can meet the reliability, low latency, and data rate requirements for platooning.

Paper number 32:
Title: CKFNet: Neural Network Aided Cubature Kalman filtering
Authors: Jinhui Hu, Haiquan Zhao, Yi Peng
Abstract: The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear estimation, often suffers performance degradation due to model-environment mismatches in practice. To address this limitation, we propose CKFNet-a hybrid architecture that synergistically integrates recurrent neural networks (RNN) with the CKF framework while preserving its cubature principles. Unlike conventional model-driven approaches, CKFNet embeds RNN modules in the prediction phase to dynamically adapt to unmodeled uncertainties, effectively reducing cumulative error propagation through temporal noise correlation learning. Crucially, the architecture maintains CKF's analytical interpretability via constrained optimization of cubature point distributions. Numerical simulation experiments have confirmed that our proposed CKFNet exhibits superior accuracy and robustness compared to conventional model-based methods and existing KalmanNet algorithms.

Paper number 33:
Title: Besondere Anforderungen des automatisierten Fahrens an den Entwurf
Authors: Robert Graubohm, Markus Maurer
Abstract: The development of automated vehicles and automated driving functions is an exceptionally complex task that requires the integration of numerous, sometimes conflicting interests and various constraints already in the early stages of system design. This chapter explains important challenges in concept specifications for automated driving and presents a systematic process model that contributes to overcoming the special requirements in this field. In addition, it describes the successful implementation of a structured concept specification for an automated vehicle guidance system. -- Die Entwicklung automatisierter Fahrzeuge und Fahrfunktionen stellt eine ausgesprochen komplexe Aufgabe dar, die bereits im Zuge des Systementwurfs die Einbeziehung einer Vielzahl teilweise konfliktärer Interessen und diverser Randbedingungen erfordert. Dieses Kapitel erläutert wichtige Herausforderungen bei Konzeptspezifikationen im Themenfeld des automatisierten Fahrens und stellt ein systematisches Prozessmodell vor, das einen Beitrag zur Erfüllung der besonderen Anforderungen des automatisierten Fahrens an den Entwurf leistet. Darüber hinaus wird die erfolgreiche Durchführung einer strukturierten Konzeptspezifikation für ein automatisiertes Fahrzeugführungssystem beschrieben.

Paper number 34:
Title: Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning
Authors: Sungyoung Ha, Ikbeom Lee, Seunghyeon Jeon, Yo-Seb Jeon
Abstract: Channel denoising is a practical and effective technique for mitigating channel estimation errors in multiple-input multiple-output orthogonal frequency-division multiplexing (MIMO-OFDM) systems. However, adapting denoising techniques to varying channel conditions typically requires prior knowledge or incurs significant training overhead. To address these challenges, we propose a standard-compatible strategy for generating online training data that enables online adaptive channel denoising. The key idea is to leverage high-quality channel estimates obtained via data-aided channel estimation as practical substitutes for unavailable ground-truth channels. Our data-aided method exploits adjacent detected data symbols within a specific time-frequency neighborhood as virtual reference signals, and we analytically derive the optimal size of this neighborhood to minimize the mean squared error of the resulting estimates. By leveraging the proposed strategy, we devise two channel denoising approaches, one based on transfer learning, which fine-tunes a pre-trained denoising neural network, and the other based on meta learning, which rapidly adapts to new channel environments with minimal updates. Simulation results demonstrate that the proposed methods effectively adapt to dynamic channel conditions and significantly reduce channel estimation errors compared to conventional techniques.

Paper number 35:
Title: Integrated Learning and Optimization to Control Load Demand and Wind Generation for Minimizing Ramping Cost in Real-Time Electricity Market
Authors: Imran Pervez, Omar Knio
Abstract: We developed a new integrated learning and optimization (ILO) methodology to predict context-aware unknown parameters in economic dispatch (ED), a crucial problem in power systems solved to generate optimal power dispatching decisions to serve consumer load. The ED formulation in the current study consists of load and renewable generation as unknown parameters in its constraints predicted using contextual information (e.g., prior load, temperature). The ILO framework train a neural network (NN) to estimate ED parameters by minimizing an application-specific regret function which is a difference between ground truth and NN-driven decisions favouring better ED decisions. We thoroughly analyze the feasible region of ED formulation to understand the impact of load and renewable learning together on the ED decisions. Corresponding to that we developed a new regret function to capture real-time electricity market operations where differences in predicted and true loads are corrected by ramping generators in real-time but at a higher cost than the market price. The proposed regret function when minimized using ILO framework train the NN to guide the load and renewable predictions to generate ED decisions favouring minimum generator ramping costs. This is unlike conventional sequential learning and optimization (SLO) framework which train NN to accurately estimate load and renewable instead of better ED decisions. The combined training of load and renewable using ILO is a new concept and lead to significantly improved ramping costs when compared with SLO based training of load and renewable and SLO trained load with 100% accurate renewable proving its decision-focused capability.

Paper number 36:
Title: Improving the Speaker Anonymization Evaluation's Robustness to Target Speakers with Adversarial Learning
Authors: Carlos Franzreb, Arnab Das, Tim Polzehl, Sebastian Möller
Abstract: The current privacy evaluation for speaker anonymization often overestimates privacy when a same-gender target selection algorithm (TSA) is used, although this TSA leaks the speaker's gender and should hence be more vulnerable. We hypothesize that this occurs because the evaluation does not account for the fact that anonymized speech contains information from both the source and target speakers. To address this, we propose to add a target classifier that measures the influence of target speaker information in the evaluation, which can also be removed with adversarial learning. Experiments demonstrate that this approach is effective for multiple anonymizers, particularly when using a same-gender TSA, leading to a more reliable assessment.

Paper number 37:
Title: Location Privacy-Enabled Beamforming in ISAC Scenarios
Authors: Umair Ali Khan, Lester Ho, Holger Claussen, Chinmoy Kundu
Abstract: Integrated sensing and communication (ISAC) technology enables simultaneous environmental perception and data transmission in wireless networks; however, it also exposes user location to receivers. In this paper, we introduce a novel beamforming framework guided by the proposed privacy metric direction of arrival obfuscation ratio (DAOR) to protect transmitter location privacy in ISAC scenarios. Unlike previous approaches, we do not suppress the line-of-sight (LOS) component while reshaping the angular power distribution so that a false direction appears dominant at the receiver. We derive closed-form bounds on the feasible DAOR via generalized eigenvalue analysis and formulate an achievable rate-maximization problem under the DAOR constraint. The resulting problem is non-convex, which is efficiently solved using semidefinite relaxation, eigenmode selection, and optimal power allocation. A suboptimal design strategy is also proposed with reduced complexity. Numerical results demonstrate that the proposed DAOR-based beamformer achieves a trade-off between location privacy and communication rate without nullifying the LOS path. Results also show that a suboptimal design achieves a near-optimal communication rate with nearly an 85% reduction in computation time at a signal-to-noise ratio (SNR) of 10 dB.

Paper number 38:
Title: Collision-Free Bearing-Driven Formation Tracking for Euler-Lagrange Systems
Authors: Haoshu Cheng, Martin Guay, Shimin Wang, Yunhong Che
Abstract: In this paper, we investigate the problem of tracking formations driven by bearings for heterogeneous Euler-Lagrange systems with parametric uncertainty in the presence of multiple moving leaders. To estimate the leaders' velocities and accelerations, we first design a distributed observer for the leader system, utilizing a bearing-based localization condition in place of the conventional connectivity assumption. This observer, coupled with an adaptive mechanism, enables the synthesis of a novel distributed control law that guides the formation towards the target formation, without requiring prior knowledge of the system parameters. Furthermore, we establish a sufficient condition, dependent on the initial formation configuration, that ensures collision avoidance throughout the formation evolution. The effectiveness of the proposed approach is demonstrated through a numerical example.

Paper number 39:
Title: T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis
Authors: Xiaojiao Xiao, Jianfeng Zhao, Qinmin Vivian Hu, Guanghui Wang
Abstract: Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of liver cancer, significantly improving the classification of the lesion and patient outcomes. However, traditional MRI faces challenges including risks from contrast agent (CA) administration, time-consuming manual assessment, and limited annotated datasets. To address these limitations, we propose a Time-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for synthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from non-contrast MRI (NCMRI). T-CACE introduces three core innovations: a conditional token encoding (CTE) mechanism that unifies anatomical priors and temporal phase information into latent representations; and a dynamic time-aware attention mask (DTAM) that adaptively modulates inter-phase information flow using a Gaussian-decayed attention mechanism, ensuring smooth and physiologically plausible transitions across phases. Furthermore, a constraint for temporal classification consistency (TCC) aligns the lesion classification output with the evolution of the physiological signal, further enhancing diagnostic reliability. Extensive experiments on two independent liver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods in image synthesis, segmentation, and lesion classification. This framework offers a clinically relevant and efficient alternative to traditional contrast-enhanced imaging, improving safety, diagnostic efficiency, and reliability for the assessment of liver lesion. The implementation of T-CACE is publicly available at: this https URL.

Paper number 40:
Title: Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging
Authors: Vaibhav Choudhary, Akshay Agarwal, Vivek K Goyal
Abstract: Secondary electron (SE) imaging techniques, such as scanning electron microscopy and helium ion microscopy (HIM), use electrons emitted by a sample in response to a focused beam of charged particles incident at a grid of raster scan positions. Spot size -- the diameter of the incident beam's spatial profile -- is one of the limiting factors for resolution, along with various sources of noise in the SE signal. The effect of the beam spatial profile is commonly understood as convolutional. We show that under a simple and plausible physical abstraction for the beam, though convolution describes the mean of the SE counts, the full distribution of SE counts is a mixture. We demonstrate that this more detailed modeling can enable resolution improvements over conventional estimators through a stylized application in semiconductor inspection of localizing the edge in a two-valued sample. We derive Fisher information about edge location in conventional and time-resolved measurements (TRM) and also derive the maximum likelihood estimate (MLE) from the latter. Empirically, the MLE computed from TRM is approximately efficient except at very low beam diameter, so Fisher information comparisons are predictive of performance and can be used to optimize the beam diameter relative to the raster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold reduction in root mean-squared error (RMSE) of edge localization as compared to conventional interpolation-based estimation. Applied to three real HIM datasets, the average RMSE reduction factor is 5.4.

Paper number 41:
Title: Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications
Authors: Devansh R. Agrawal, Dimitra Panagou
Abstract: This letter presents an approach to guarantee online safety of a cyber-physical system under multiple state and input constraints. Our proposed framework, called gatekeeper, recursively guarantees the existence of an infinite-horizon trajectory that satisfies all constraints and system dynamics. Such trajectory is constructed using a backup controller, which we define formally in this paper. gatekeeper relies on a small number of verifiable assumptions, and is computationally efficient since it requires optimization over a single scalar variable. We make two primary contributions in this letter. (A) First, we develop the theory of gatekeeper: we derive a sub-optimality bound relative to a full nonlinear trajectory optimization problem, and show how this can be used in runtime to validate performance. This also informs the design of the backup controllers and sets. (B) Second, we demonstrate in detail an application of gatekeeper for multi-agent formation flight, where each Dubins agent must avoid multiple obstacles and weapons engagement zones, both of which are nonlinear, nonconvex constraints.

Paper number 42:
Title: Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach
Authors: Jinghong Tan, Zhian Liu, Kun Guo, Mingxiong Zhao
Abstract: Federated learning (FL) provides a decentralized framework that enables universal model training through collaborative efforts on mobile nodes, such as smart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a mobile client, contributing to the process without uploading local data. This method leverages non-independent and identically distributed (non-IID) training data from different vehicles, influenced by various driving patterns and environmental conditions, which can significantly impact model convergence and accuracy. Although client selection can be a feasible solution for non-IID issues, it faces challenges related to selection metrics. Traditional metrics evaluate client data quality independently per round and require client selection after all clients complete local training, leading to resource wastage from unused training results. In the IoV context, where vehicles have limited connectivity and computational resources, information asymmetry in client selection risks clients submitting false information, potentially making the selection ineffective. To tackle these challenges, we propose a novel Long-term Client-Selection Federated Learning based on Truthful Auction (LCSFLA). This scheme maximizes social welfare with consideration of long-term data quality using a new assessment mechanism and energy costs, and the advised auction mechanism with a deposit requirement incentivizes client participation and ensures information truthfulness. We theoretically prove the incentive compatibility and individual rationality of the advised incentive mechanism. Experimental results on various datasets, including those from IoV scenarios, demonstrate its effectiveness in mitigating performance degradation caused by non-IID data.

Paper number 43:
Title: Real-time deep learning phase imaging flow cytometer reveals blood cell aggregate biomarkers for haematology diagnostics
Authors: Kerem Delikoyun, Qianyu Chen, Liu Wei, Si Ko Myo, Johannes Krell, Martin Schlegel, Win Sen Kuan, John Tshon Yit Soong, Gerhard Schneider, Clarissa Prazeres da Costa, Percy A. Knolle, Laurent Renia, Matthew Edward Cove, Hwee Kuan Lee, Klaus Diepold, Oliver Hayden
Abstract: While analysing rare blood cell aggregates remains challenging in automated haematology, they could markedly advance label-free functional diagnostics. Conventional flow cytometers efficiently perform cell counting with leukocyte differentials but fail to identify aggregates with flagged results, requiring manual reviews. Quantitative phase imaging flow cytometry captures detailed aggregate morphologies, but clinical use is hampered by massive data storage and offline processing. Incorporating hidden biomarkers into routine haematology panels would significantly improve diagnostics without flagged results. We present RT-HAD, an end-to-end deep learning-based image and data processing framework for off-axis digital holographic microscopy (DHM), which combines physics-consistent holographic reconstruction and detection, representing each blood cell in a graph to recognize aggregates. RT-HAD processes >30 GB of image data on-the-fly with turnaround time of <1.5 min and error rate of 8.9% in platelet aggregate detection, which matches acceptable laboratory error rates of haematology biomarkers and solves the big data challenge for point-of-care diagnostics.

Paper number 44:
Title: Offline Auto Labeling: BAAS
Authors: Stefan Haag, Bharanidhar Duraisamy, Felix Govaers, Wolfgang Koch, Martin Fritzsche, Juergen Dickmann
Abstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and fusion-based label annotation framework for radar detections in autonomous driving. Our framework utilizes Bayesian-based tracking, smoothing and eventually fusion methods to provide veritable and precise object trajectories along with shape estimation to provide annotation labels on the detection level under various supervision levels. Simultaneously, the framework provides evaluation of tracking performance and label annotation. If manually labeled data is available, each processing module can be analyzed independently or combined with other modules to enable closed-loop continuous improvements. The framework performance is evaluated in a challenging urban real-world scenario in terms of tracking performance and the label annotation errors. We demonstrate the functionality of the proposed approach for varying dynamic objects and class types

Paper number 45:
Title: HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control
Authors: Michael Fennel, Markus Walker, Dominik Pikos, Uwe D. Hanebeck
Abstract: Research in virtual reality and haptic technologies has consistently aimed to enhance immersion. While advanced head-mounted displays are now commercially available, kinesthetic haptic interfaces still face challenges such as limited workspaces, insufficient degrees of freedom, and kinematics not matching the human arm. In this paper, we present HapticGiant, a novel large-scale kinesthetic haptic interface designed to match the properties of the human arm as closely as possible and to facilitate natural user locomotion while providing full haptic feedback. The interface incorporates a novel admittance-type force control scheme, leveraging hierarchical optimization to render both arbitrary serial kinematic chains and Cartesian admittances. Notably, the proposed control scheme natively accounts for system limitations, including joint and Cartesian constraints, as well as singularities. Experimental results demonstrate the effectiveness of HapticGiant and its control scheme, paving the way for highly immersive virtual reality applications.

Paper number 46:
Title: BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots
Authors: Alejandro Posadas-Nava, Alejandro Carrasco, Richard Linares
Abstract: \textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality (VR) teleoperation system for robots, designed to unify real-time control, data recording, and policy learning across heterogeneous robotic platforms. BEAVR enables real-time, dexterous teleoperation using commodity VR hardware, supports modular integration with robots ranging from 7-DoF manipulators to full-body humanoids, and records synchronized multi-modal demonstrations directly in the LeRobot dataset schema. Our system features a zero-copy streaming architecture achieving $\leq$35\,ms latency, an asynchronous ``think--act'' control loop for scalable inference, and a flexible network API optimized for real-time, multi-robot operation. We benchmark BEAVR across diverse manipulation tasks and demonstrate its compatibility with leading visuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is publicly available, and datasets are released on Hugging Face\footnote{Code, datasets, and VR app available at this https URL.

Paper number 47:
Title: Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling
Authors: Michel Rottleuthner, Thomas C. Schmidt, Matthias Wählisch
Abstract: Minimizing energy consumption of low-power wireless nodes is a persistent challenge from the constrained Internet of Things (IoT). In this paper, we start from the observation that constrained IoT devices have largely different hardware (im-)balances than full-scale machines. We find that the performance gap between MCU and network throughput on constrained devices enables minimal energy delay product (EDP) for IoT networking at largely reduced clock frequencies. We analyze the potentials by integrating dynamic voltage and frequency scaling (DVFS) into the RIOT IoT operating system and show that the DVFS reconfiguration overhead stays below the energy saved for a single, downscaled MAC operation. Backed by these findings, we systematically investigate how DVFS further improves energy-efficiency for common networking tasks -- in addition to duty-cycling. We measure IoT communication scenarios between real-world systems and analyze two MAC operating modes -- CSMA/CA and time slotting -- in combination with different CoAP transactions, payload sizes, as well as DTLS transport encryption. Our experiments reveal energy savings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP communication. These results shall encourage research and system design work to integrate DVFS in future IoT devices for performing tasks at their optimal frequencies and thereby significantly extending battery lifetimes.

Paper number 48:
Title: Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions
Authors: Sergey Petrov, Samson Lasaulce, Merouane Debbah
Abstract: Precoding matrix construction is a key element of the wireless signal processing using the multiple-input and multiple-output model. It is established that the problem of global throughput optimization under per-antenna power constraints belongs, in general, to the class of monotonic optimization problems, and is unsolvable in real-time. The most widely used real-time baseline is the suboptimal solution of Zero-Forcing, which achieves a cubic complexity by discarding the background noise coefficients. This baseline, however, is not readily adapted to per-antenna power constraints, and performs poorly if background noise coefficients are not negligible. In this paper, we are going to present a computational algorithm which constructs a precoder that is SINR multiobjective Pareto-optimal under per-antenna power constraints - with a complexity that differs from that of Zero-Forcing only by a constant factor. The algorithm has a set of input parameters, changing which skews the importance of particular user throughputs: these parameters make up an efficient parameterization of the entire Pareto boundary.

Paper number 49:
Title: ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding
Authors: Andreas Zunker, Marvin Rübenacke, Stephan ten Brink
Abstract: Motivated by the need for channel codes with low-complexity soft-decision decoding algorithms, we consider the recursive Plotkin concatenation of optimal low-rate and high-rate codes based on simplex codes and their duals. These component codes come with low-complexity maximum likelihood (ML) decoding which, in turn, enables efficient successive cancellation (SC)-based decoding. As a result, the proposed optimally recursively concatenated simplex (ORCAS) codes achieve a performance that is at least as good as that of polar codes. For practical parameters, the proposed construction significantly outperforms polar codes in terms of block error rate by up to 0.5 dB while maintaining similar decoding complexity. Furthermore, the codes offer greater flexibility in codeword length than conventional polar codes.

Paper number 50:
Title: UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech
Authors: Shuhei Kato
Abstract: We propose UtterTune, a lightweight adaptation method that fine-tunes a multilingual text-to-speech (TTS) system based on a large language model (LLM) architecture, designed to enhance the controllability of pronunciation in a target language while preserving performance in others. While LLM architectures have enabled TTS models to achieve remarkable naturalness, accurately modeling grapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially when the model omits an explicit G2P module and directly processes minimally encoded text (e.g., byte-pair encoding). UtterTune leverages low-rank adaptation to enable the control of segmental pronunciation and pitch accent at the phoneme level for Japanese speech, the target language in this paper, while maintaining naturalness and speaker similarity in a zero-shot setting. Objective and subjective evaluations confirm its effectiveness.

Paper number 51:
Title: Bayesian autoregression to optimize temporal Matérn kernel Gaussian process hyperparameters
Authors: Wouter M. Kouw
Abstract: Gaussian processes are important models in the field of probabilistic numerics. We present a procedure for optimizing Matérn kernel temporal Gaussian processes with respect to the kernel covariance function's hyperparameters. It is based on casting the optimization problem as a recursive Bayesian estimation procedure for the parameters of an autoregressive model. We demonstrate that the proposed procedure outperforms maximizing the marginal likelihood as well as Hamiltonian Monte Carlo sampling, both in terms of runtime and ultimate root mean square error in Gaussian process regression.

Paper number 52:
Title: A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion
Authors: Xiaowei Tan, Weizhong Jiang, Bi Zhang, Wanxin Chen, Yiwen Zhao, Ning Li, Lianqing Liu, Xingang Zhao
Abstract: Exoskeletons have been shown to effectively assist humans during steady locomotion. However, their effects on non-steady locomotion, characterized by nonlinear phase progression within a gait cycle, remain insufficiently explored, particularly across diverse activities. This work presents a shank angle-based control system that enables the exoskeleton to maintain real-time coordination with human gait, even under phase perturbations, while dynamically shaping assistance profiles to match the biological ankle moment patterns across walking, running, stair negotiation tasks. The control system consists of an assistance profile online generation method and a model-based feedforward control method. The assistance profile is formulated as a dual-Gaussian model with the shank angle as the independent variable. Leveraging only IMU measurements, the model parameters are updated online each stride to adapt to inter- and intra-individual biomechanical variability. The profile tracking control employs a human-exoskeleton kinematics and stiffness model as a feedforward component, reducing reliance on historical control data due to the lack of clear and consistent periodicity in non-steady locomotion. Three experiments were conducted using a lightweight soft exoskeleton with multiple subjects. The results validated the effectiveness of each individual method, demonstrated the robustness of the control system against gait perturbations across various activities, and revealed positive biomechanical and physiological responses of human users to the exoskeleton's mechanical assistance.

Paper number 53:
Title: SINDyG: Sparse Identification of Nonlinear Dynamical Systems from Graph-Structured Data, with Applications to Stuart-Landau Oscillator Networks
Authors: Mohammad Amin Basiri, Sina Khanmohammadi
Abstract: The combination of machine learning (ML) and sparsity-promoting techniques is enabling direct extraction of governing equations from data, revolutionizing computational modeling in diverse fields of science and engineering. The discovered dynamical models could be used to address challenges in climate science, neuroscience, ecology, finance, epidemiology, and beyond. However, most existing sparse identification methods for discovering dynamical systems treat the whole system as one without considering the interactions between subsystems. As a result, such models are not able to capture small changes in the emergent system behavior. To address this issue, we developed a new method called Sparse Identification of Nonlinear Dynamical Systems from Graph-structured data (SINDyG), which incorporates the network structure into sparse regression to identify model parameters that explain the underlying network dynamics. We tested our proposed method using several case studies of neuronal dynamics, where we modeled the macroscopic oscillation of a population of neurons using the extended Stuart-Landau (SL) equation and utilize the SINDyG method to identify the underlying nonlinear dynamics. Our extensive computational experiments validate the improved accuracy and simplicity of discovered network dynamics when compared to the original SINDy approach. The proposed graph-informed penalty can be easily integrated with other symbolic regression algorithms, enhancing model interpretability and performance by incorporating network structure into the regression process.

Paper number 54:
Title: Spectrum Efficiency and Processing Latency Trade-offs in Panel-Based LIS
Authors: Lina Tinnerberg, Dumitra Iancu, Ove Edfors, Liang Liu, Juan Vidal Alegría
Abstract: The next generation wireless systems will face stringent new requirements, including ultra-low latency, high data rates and enhanced reliability. Large Intelligent Surfaces, is one proposed solution that has the potential to solve these high demands. The real-life deployment of such systems involves different design considerations with non-trivial trade-offs. This paper investigates the trade-off between spectral efficiency and processing latency, considering different antenna distribution schemes and detection algorithms. A latency model for the physical layer processing has been developed, using real FPGA and application-specific instruction processor (ASIP) hardware implementation results. Simulation results using an indoor environment show that distributing antennas throughout the scenario improves overall reliability, while the impact from this on latency is limited both when using zero-forcing (ZF) and Minimum Mean Square Error (MMSE) detection. Changing the detection algorithm to maximum-ratio combining (MRC) from ZF or MMSE, however, reduces the latency significantly, even if a larger number of antennas are needed to achieve a similar spectrum efficiency.

Paper number 55:
Title: Scaling Achievable Rates in SIM-aided MIMO Systems with Metasurface Layers: A Hybrid Optimization Framework
Authors: Eduard E. Bahingayi, Nemanja Stefan Perović, Le-Nam Tran
Abstract: We investigate the achievable rate (AR) of a stacked intelligent metasurface (SIM)-aided holographic multiple-input multiple-output (HMIMO) system by jointly optimizing the SIM phase shifts and power allocation. Contrary to earlier studies suggesting that the AR decreases when the number of metasurface layers increases past a certain point for \emph{a fixed SIM thickness}, our findings demonstrate consistent increase. To achieve this, we introduce two problem formulations: one based on directly maximizing the AR (RMax) and the other focused on minimizing inter-stream interference (IMin). To solve the RMax problem, we apply Riemannian manifold optimization (RMO) and weighted minimum mean square error (WMMSE) methods to optimize the SIM phase shifts and power allocation alternately. For the IMin problem, we derive an efficient algorithm that iteratively updates each meta-atom's phase shift using a closed-form expression while keeping others fixed. Our key contribution is integrating these two approaches, where the IMin solution initializes the SIM phase shifts in the first algorithm. This hybrid strategy enhances AR performance across varying numbers of metasurface layers. Simulation results demonstrate that the proposed algorithms outperform existing benchmarks. Most importantly, we show that increasing the number of metasurface layers while keeping the SIM thickness fixed leads to significant AR improvements.

Paper number 56:
Title: Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis
Authors: Yifan Jiang, Yannick Lemaréchal, Sophie Plante, Josée Bafaro, Jessica Abi-Rjeile, Philippe Joubert, Philippe Després, Venkata Manem
Abstract: With the rapid development of artificial intelligence (AI), AI-assisted medical imaging analysis demonstrates remarkable performance in early lung cancer screening. However, the costly annotation process and privacy concerns limit the construction of large-scale medical datasets, hampering the further application of AI in healthcare. To address the data scarcity in lung cancer screening, we propose Lung-DDPM, a thoracic CT image synthesis approach that effectively generates high-fidelity 3D synthetic CT images, which prove helpful in downstream lung nodule segmentation tasks. Our method is based on semantic layout-guided denoising diffusion probabilistic models (DDPM), enabling anatomically reasonable, seamless, and consistent sample generation even from incomplete semantic layouts. Our results suggest that the proposed method outperforms other state-of-the-art (SOTA) generative models in image quality evaluation and downstream lung nodule segmentation tasks. Specifically, Lung-DDPM achieved superior performance on our large validation cohort, with a Fréchet inception distance (FID) of 0.0047, maximum mean discrepancy (MMD) of 0.0070, and mean squared error (MSE) of 0.0024. These results were 7.4$\times$, 3.1$\times$, and 29.5$\times$ better than the second-best competitors, respectively. Furthermore, the lung nodule segmentation model, trained on a dataset combining real and Lung-DDPM-generated synthetic samples, attained a Dice Coefficient (Dice) of 0.3914 and sensitivity of 0.4393. This represents 8.8% and 18.6% improvements in Dice and sensitivity compared to the model trained solely on real samples. The experimental results highlight Lung-DDPM's potential for a broader range of medical imaging applications, such as general tumor segmentation, cancer survival estimation, and risk prediction. The code and pretrained models are available at this https URL.

Paper number 57:
Title: Stability Analysis and Intervention Strategies on a Coupled SIS Epidemic Model with Polar Opinion Dynamics
Authors: Qiulin Xu, Tatsuya Masada, Hideaki Ishii
Abstract: This paper investigates the spread of infectious diseases within a networked community by integrating epidemic transmission and public opinion dynamics. We propose a novel discrete-time networked SIS (Susceptible-Infectious-Susceptible) epidemic model coupled with opinion dynamics that includes stubborn agents with biased views. The model captures the interplay between perceived and actual epidemic severity, offering insights into epidemic dynamics in socially interconnected environments. We introduce the SIS-opinion reproduction number to assess epidemic severity and analyze conditions for disease eradication and the global stability of endemic equilibria. Additionally, we explore opinion-based intervention strategies, providing a framework for policymakers to design effective prevention measures. Numerical examples are provided to illustrate our theoretical findings and the model's practical implications.

Paper number 58:
Title: Routing Guidance for Emerging Transportation Systems with Improved Dynamic Trip Equity
Authors: Ting Bai, Anni Li, Gehui Xu, Christos G. Cassandras, Andreas A. Malikopoulos
Abstract: This paper presents a dynamic routing guidance system that optimizes route recommendations for individual vehicles in an emerging transportation system while enhancing travelers' trip equity. We develop a framework to quantify trip quality and equity in dynamic travel environments, providing new insights into how routing guidance influences equity in road transportation. Our approach enables real-time routing by incorporating both monitored and anticipated traffic congestion. We provide conditions that ensure perfect trip equity for all travelers in a free-flow network. Simulation studies on 1,000 vehicles traversing an urban road network in Boston demonstrate that our method improves trip equity by approximately 11.4\% compared to the shortest-route strategy. In addition, the results reveal that our approach redistributes travel costs across vehicle types through route optimization, contributing to a more equitable transportation system.

Paper number 59:
Title: Directional excitability in Hilbert spaces
Authors: Gustave Bainier, Alessio Franci
Abstract: We introduce a generalized excitable system in which spikes can happen in a continuum of directions, therefore drastically enriching the expressivity and control capability of the spiking dynamics. In this generalized excitable system, spiking trajectories happen in a Hilbert space with an excitable resting state at the origin and spike responses that can be triggered in any direction as a function of the system's state and inputs. State-dependence of the spiking direction provide the system with a vanishing spiking memory trace, which enables robust tracking and integration of inputs in the spiking direction history. The model exhibits generalized forms of both Hodgkin's Type I and Type II excitability, capturing their usual bifurcation behaviors in an abstract setting. When used as the controller of a two-dimensional navigation task, this model facilitates both the sparseness of the actuation and its sensitivity to environmental inputs. These results highlight the potential of the proposed generalized excitable model for excitable control in high- and infinite-dimensional spaces.

Paper number 60:
Title: EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting
Authors: Guanrou Yang, Chen Yang, Qian Chen, Ziyang Ma, Wenxi Chen, Wen Wang, Tianrui Wang, Yifan Yang, Zhikang Niu, Wenrui Liu, Fan Yu, Zhihao Du, Zhifu Gao, ShiLiang Zhang, Xie Chen
Abstract: Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Dataset, code, checkpoints, and demo samples are available at this https URL.

Paper number 61:
Title: Dynamic load balancing for cloud systems under heterogeneous setup delays
Authors: Fernando Paganini, Diego Goldsztajn
Abstract: We consider a distributed cloud service deployed at a set of distinct server pools. Arriving jobs are classified into heterogeneous types, in accordance with their setup times which are differentiated at each of the pools. A dispatcher for each job type controls the balance of load between pools, based on decentralized feedback. The system of rates and queues is modeled by a fluid differential equation system, and analyzed via convex optimization. A first, myopic policy is proposed, based on task delay-to-service. Under a simplified dynamic fluid queue model, we prove global convergence to an equilibrium point which minimizes the mean setup time; however queueing delays are incurred with this method. A second proposal is then developed based on proximal optimization, which explicitly models the setup queue and is proved to reach an optimal equilibrium, devoid of queueing delay. Results are demonstrated through a simulation example.

Paper number 62:
Title: ReverbFX: A Dataset of Room Impulse Responses Derived from Reverb Effect Plugins for Singing Voice Dereverberation
Authors: Julius Richter, Till Svajda, Timo Gerkmann
Abstract: We present ReverbFX, a new room impulse response (RIR) dataset designed for singing voice dereverberation research. Unlike existing datasets based on real recorded RIRs, ReverbFX features a diverse collection of RIRs captured from various reverb audio effect plugins commonly used in music production. We conduct comprehensive experiments using the proposed dataset to benchmark the challenge of dereverberation of singing voice recordings affected by artificial reverbs. We train two state-of-the-art generative models using ReverbFX and demonstrate that models trained with plugin-derived RIRs outperform those trained on realistic RIRs in artificial reverb scenarios.

Paper number 63:
Title: FlexCTC: GPU-powered CTC Beam Decoding With Advanced Contextual Abilities
Authors: Lilit Grigoryan, Vladimir Bataev, Nikolay Karpov, Andrei Andrusenko, Vitaly Lavrukhin, Boris Ginsburg
Abstract: While beam search improves speech recognition quality over greedy decoding, standard implementations are slow, often sequential, and CPU-bound. To fully leverage modern hardware capabilities, we present a novel open-source FlexCTC toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal Classification (CTC) models. Developed entirely in Python and PyTorch, it offers a fast, user-friendly, and extensible alternative to traditional C++, CUDA, or WFST-based decoders. The toolkit features a high-performance, fully batched GPU implementation with eliminated CPU-GPU synchronization and minimized kernel launch overhead via CUDA Graphs. It also supports advanced contextualization techniques, including GPU-powered N-gram language model fusion and phrase-level boosting. These features enable accurate and efficient decoding, making them suitable for both research and production use.

Paper number 64:
Title: MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer
Authors: Tao Tang, Chengxu Yang
Abstract: The core role of medical images in disease diagnosis makes their quality directly affect the accuracy of clinical judgment. However, due to factors such as low-dose scanning, equipment limitations and imaging artifacts, medical images are often accompanied by non-uniform noise interference, which seriously affects structure recognition and lesion detection. This paper proposes a medical image adaptive denoising model (MI-ND) that integrates multi-scale convolutional and Transformer architecture, introduces a noise level estimator (NLE) and a noise adaptive attention module (NAAB), and realizes channel-spatial attention regulation and cross-modal feature fusion driven by noise perception. Systematic testing is carried out on multimodal public datasets. Experiments show that this method significantly outperforms the comparative methods in image quality indicators such as PSNR, SSIM, and LPIPS, and improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing strong prac-tical value and promotional potential. The model has outstanding benefits in structural recovery, diagnostic sensitivity, and cross-modal robustness, and provides an effective solution for medical image enhancement and AI-assisted diagnosis and treatment.

Paper number 65:
Title: A Mini-Batch Quasi-Newton Proximal Method for Constrained Total-Variation Nonlinear Image Reconstruction
Authors: Tao Hong, Thanh-an Pham, Irad Yavneh, Michael Unser
Abstract: Over the years, computational imaging with accurate nonlinear physical models has garnered considerable interest due to its ability to achieve high-quality reconstructions. However, using such nonlinear models for reconstruction is computationally demanding. A popular choice for solving the corresponding inverse problems is the accelerated stochastic proximal method (ASPM), with the caveat that each iteration is still expensive. To overcome this issue, we propose a mini-batch quasi-Newton proximal method (BQNPM) tailored to image reconstruction problems with constrained total variation regularization. Compared to ASPM, BQNPM requires fewer iterations to converge. Moreover, we propose an efficient approach to compute a weighted proximal mapping at a cost similar to that of the proximal mapping in ASPM. We also analyze the convergence of BQNPM in the nonconvex setting. We assess the performance of BQNPM on three-dimensional inverse-scattering problems with linear and nonlinear physical models. Our results on simulated and real data demonstrate the effectiveness and efficiency of BQNPM, while also validating our theoretical analysis.

Paper number 66:
Title: TinyMPC: Model-Predictive Control on Resource-Constrained Microcontrollers
Authors: Anoushka Alavilli, Khai Nguyen, Sam Schoedel, Brian Plancher, Zachary Manchester
Abstract: Model-predictive control (MPC) is a powerful tool for controlling highly dynamic robotic systems subject to complex constraints. However, MPC is computationally demanding, and is often impractical to implement on small, resource-constrained robotic platforms. We present TinyMPC, a high-speed MPC solver with a low memory footprint targeting the microcontrollers common on small robots. Our approach is based on the alternating direction method of multipliers (ADMM) and leverages the structure of the MPC problem for efficiency. We demonstrate TinyMPC's effectiveness by benchmarking against the state-of-the-art solver OSQP, achieving nearly an order of magnitude speed increase, as well as through hardware experiments on a 27 gram quadrotor, demonstrating high-speed trajectory tracking and dynamic obstacle avoidance. TinyMPC is publicly available at this https URL.

Paper number 67:
Title: The Holonomy of Optimal Mass Transport: The Gaussian-Linear Case
Authors: Mahmoud Abdelgalil, Tryphon T. Georgiou
Abstract: The theory of Monge-Kantorovich Optimal Mass Transport (OMT) has in recent years spurred a fast developing phase of research in stochastic control, control of ensemble systems, thermodynamics, data science, and several other fields in engineering and science. We herein introduce a new type of transportation problems. The salient feature of these problems is that particles/agents in the ensemble are labeled and their relative position along their journey is of interest. Of particular importance in our program are control laws that steer ensembles along cycles ensuring that individual particles return to their original position. This feature is in contrast with the classical theory of optimal transport where the primary object of study is the path of probability densities, without any concern about particle labels. In the theory that we present, we focus on the case Gaussian distributions and linear dynamics, and explore a hitherto unstudied sub-Riemannian structure of Monge-Kantorovich transport where the relative position of particles along their journey is modeled by the holonomy of the transportation schedule. From this vantage point, we discuss several other problems of independent interest.

Paper number 68:
Title: Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination
Authors: Viswa Narayanan Sankaranarayanan, Achilleas Santi Seisa, Akshit Saradagi, Sumeet Satpute, George Nikolakopoulos
Abstract: In this article, we propose a control architecture for the safe, coordinated operation of a multi-agent system with aerial (UAVs) and ground (UGVs) robots in a confined task space. We consider the case where the aerial and ground operations are coupled, enabled by the capability of the aerial robots to land on moving ground robots. The proposed method uses time-varying Control Barrier Functions (CBFs) to impose safety constraints associated with (i) collision avoidance between agents, (ii) landing of UAVs on mobile UGVs, and (iii) task space restriction. Further, this article addresses the challenge induced by the rapid increase in the number of CBF constraints with the increasing number of agents through a hybrid centralized-distributed coordination approach that determines the set of CBF constraints that is relevant for every aerial and ground agent at any given time. A centralized node (Watcher), hosted by an edge computing cluster, activates the relevant constraints, thus reducing the network complexity and the need for high onboard processing on the robots. The CBF constraints are enforced in a distributed manner by individual robots that run a nominal controller and safety filter locally to overcome latency and other network nonidealities.

Paper number 69:
Title: Revisiting Your Memory: Reconstruction of Affect-Contextualized Memory via EEG-guided Audiovisual Generation
Authors: Joonwoo Kwon, Heehwan Wang, Jinwoo Lee, Sooyoung Kim, Shinjae Yoo, Yuewei Lin, Jiook Cha
Abstract: In this paper, we introduce RevisitAffectiveMemory, a novel task designed to reconstruct autobiographical memories through audio-visual generation guided by affect extracted from electroencephalogram (EEG) signals. To support this pioneering task, we present the EEG-AffectiveMemory dataset, which encompasses textual descriptions, visuals, music, and EEG recordings collected during memory recall from nine participants. Furthermore, we propose RYM (Revisit Your Memory), a three-stage framework for generating synchronized audio-visual contents while maintaining dynamic personal memory affect trajectories. Experimental results demonstrate our method successfully decodes individual affect dynamics trajectories from neural signals during memory recall (F1=0.9). Also, our approach faithfully reconstructs affect-contextualized audio-visual memory across all subjects, both qualitatively and quantitatively, with participants reporting strong affective concordance between their recalled memories and the generated content. Especially, contents generated from subject-reported affect dynamics showed higher correlation with participants' reported affect dynamics trajectories (r=0.265, p<.05) and received stronger user preference (preference=56%) compared to those generated from randomly reordered affect dynamics. Our approaches advance affect decoding research and its practical applications in personalized media creation via neural-based affect comprehension. Codes and the dataset are available at this https URL.

Paper number 70:
Title: Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance
Authors: Abdelrahman A. Ali, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda
Abstract: Mental health disorders are increasingly prevalent worldwide, creating an urgent need for innovative tools to support early diagnosis and intervention. This study explores the potential of Large Language Models (LLMs) in multimodal mental health diagnostics, specifically for detecting depression and Post Traumatic Stress Disorder through text and audio modalities. Using the E-DAIC dataset, we compare text and audio modalities to investigate whether LLMs can perform equally well or better with audio inputs. We further examine the integration of both modalities to determine if this can enhance diagnostic accuracy, which generally results in improved performance metrics. Our analysis specifically utilizes custom-formulated metrics; Modal Superiority Score and Disagreement Resolvement Score to evaluate how combined modalities influence model performance. The Gemini 1.5 Pro model achieves the highest scores in binary depression classification when using the combined modality, with an F1 score of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full dataset. These results represent an increase of 3.1% over its performance with the text modality and 2.7% over the audio modality, highlighting the effectiveness of integrating modalities to enhance diagnostic accuracy. Notably, all results are obtained in zero-shot inferring, highlighting the robustness of the models without requiring task-specific fine-tuning. To explore the impact of different configurations on model performance, we conduct binary, severity, and multiclass tasks using both zero-shot and few-shot prompts, examining the effects of prompt variations on performance. The results reveal that models such as Gemini 1.5 Pro in text and audio modalities, and GPT-4o mini in the text modality, often surpass other models in balanced accuracy and F1 scores across multiple tasks.

Paper number 71:
Title: A2SB: Audio-to-Audio Schrodinger Bridges
Authors: Zhifeng Kong, Kevin J Shih, Weili Nie, Arash Vahdat, Sang-gil Lee, Joao Felipe Santos, Ante Jukic, Rafael Valle, Bryan Catanzaro
Abstract: Real-world audio is often degraded by numerous factors. This work presents an audio restoration model tailored for high-res music at 44.1kHz. Our model, Audio-to-Audio Schrödinger Bridges (A2SB), is capable of both bandwidth extension (predicting high-frequency components) and inpainting (re-generating missing segments). Critically, A2SB is end-to-end requiring no vocoder to predict waveform outputs, able to restore hour-long audio inputs, and trained on permissively licensed music data. A2SB is capable of achieving state-of-the-art band-width extension and inpainting quality on several out-of-distribution music test sets.

Paper number 72:
Title: Navigating Robot Swarm Through a Virtual Tube with Flow-Adaptive Distribution Control
Authors: Yongwei Zhang, Shuli Lv, Kairong Liu, Quanyi Liang, Quan Quan, Zhikun She
Abstract: With the rapid development of robot swarm technology and its diverse applications, navigating robot swarms through complex environments has emerged as a critical research direction. To ensure safe navigation and avoid potential collisions with obstacles, the concept of virtual tubes has been introduced to define safe and navigable regions. However, current control methods in virtual tubes face the congestion issues, particularly in narrow ones with low throughput. To address these challenges, we first propose a novel control method that combines a modified artificial potential field (APF) for swarm navigation and density feedback control for distribution regulation. Then we generate a global velocity field that not only ensures collision-free navigation but also achieves locally input-to-state stability (LISS) for density tracking. Finally, numerical simulations and realistic applications validate the effectiveness and advantages of the proposed method in navigating robot swarms through narrow virtual tubes.

Paper number 73:
Title: On learning racing policies with reinforcement learning
Authors: Grzegorz Czechmanowski, Jan Węgrzynowski, Piotr Kicki, Krzysztof Walas
Abstract: Fully autonomous vehicles promise enhanced safety and efficiency. However, ensuring reliable operation in challenging corner cases requires control algorithms capable of performing at the vehicle limits. We address this requirement by considering the task of autonomous racing and propose solving it by learning a racing policy using Reinforcement Learning (RL). Our approach leverages domain randomization, actuator dynamics modeling, and policy architecture design to enable reliable and safe zero-shot deployment on a real platform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a state-of-the-art Model Predictive Control (MPC), but, to the best of our knowledge, also represents the first instance of an RL policy outperforming expert human drivers in RC racing. This work identifies the key factors driving this performance improvement, providing critical insights for the design of robust RL-based control strategies for autonomous vehicles.

Paper number 74:
Title: Non-native Children's Automatic Speech Assessment Challenge (NOCASA)
Authors: Yaroslav Getman, Tamás Grósz, Mikko Kurimo, Giampiero Salvi
Abstract: This paper presents the "Non-native Children's Automatic Speech Assessment" (NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA challenges participants to develop new systems that can assess single-word pronunciations of young second language (L2) learners as part of a gamified pronunciation training app. To achieve this, several issues must be addressed, most notably the limited nature of available training data and the highly unbalanced distribution among the pronunciation level categories. To expedite the development, we provide a pseudo-anonymized training data (TeflonNorL2), containing 10,334 recordings from 44 speakers attempting to pronounce 205 distinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that should be given in the game). In addition to the data, two already trained systems are released as official baselines: an SVM classifier trained on the ComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter achieves the best performance on the challenge test set, with an unweighted average recall (UAR) of 36.37%.

Paper number 75:
Title: MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism
Authors: Yanyi Qu, Haoyang Ma, Wenhui Xiong
Abstract: Human pose estimation based on Channel State Information (CSI) has emerged as a promising approach for non-intrusive and precise human activity monitoring, yet faces challenges including accurate multi-person pose recognition and effective CSI feature learning. This paper presents MultiFormer, a wireless sensing system that accurately estimates human pose through CSI. The proposed system adopts a Transformer based time-frequency dual-token feature extractor with multi-head self-attention. This feature extractor is able to model inter-subcarrier correlations and temporal dependencies of the CSI. The extracted CSI features and the pose probability heatmaps are then fused by Multi-Stage Feature Fusion Network (MSFN) to enforce the anatomical constraints. Extensive experiments conducted on on the public MM-Fi dataset and our self-collected dataset show that the MultiFormer achieves higher accuracy over state-of-the-art approaches, especially for high-mobility keypoints (wrists, elbows) that are particularly difficult for previous methods to accurately estimate.

Paper number 76:
Title: RoHOI: Robustness Benchmark for Human-Object Interaction Detection
Authors: Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Danda Pani Paudel, Luc Van Gool, Rainer Stiefelhagen
Abstract: Human-Object Interaction (HOI) detection is crucial for robot-human assistance, enabling context-aware support. However, models trained on clean datasets degrade in real-world conditions due to unforeseen corruptions, leading to inaccurate prediction. To address this, we introduce the first robustness benchmark for HOI detection, evaluating model resilience under diverse challenges. Despite advances, current models struggle with environmental variability, occlusions, and noise. Our benchmark, RoHOI, includes 20 corruption types based on the HICO-DET and V-COCO datasets and a new robustness-focused metric. We systematically analyze existing models in the HOI field, revealing significant performance drops under corruptions. To improve robustness, we propose a Semantic-Aware Masking-based Progressive Learning (SAMPL) strategy to guide the model to be optimized based on holistic and partial cues, thus dynamically adjusting the model's optimization to enhance robust feature learning. Extensive experiments show that our approach outperforms state-of-the-art methods, setting a new standard for robust HOI detection. Benchmarks, datasets, and code will be made publicly available at this https URL.

Paper number 77:
Title: Inversion of Arctic dual-channel sound speed profile based on random airgun signal
Authors: Jinbao Weng (1,2), Yubo Qi (3), Yanming Yang (1,2), Hongtao Wen (1,2), Hongtao Zhou (1,2), Benqing Chen (1,2), Dewei Xu (1,2), Ruichao Xue (1,2), Caigao Zeng (1,2) ((1) Laboratory of Ocean acoustics and Remote Sensing, Third Institute of Oceanography, Ministry of Natural Resources, Xiamen, Fujian, China (2) Fujian Provincial Key Laboratory of Marine Physical and Geological Processes, Xiamen, Fujian, China (3) State key laboratory of acoustics, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China)
Abstract: For the unique dual-channel sound speed profiles of the Canadian Basin and the Chukchi Plateau in the Arctic, based on the propagation characteristics of refracted normal modes under dual-channel sound speed profiles, an inversion method using refracted normal modes for dual-channel sound speed profiles is proposed. This method proposes a dual-parameter representation method for dual-channel sound speed profiles, tailored to the characteristics of dual-channel sound speed profiles. A dispersion structure extraction method is proposed for the dispersion structure characteristics of refracted normal modes under dual-channel sound speed profiles. Combining the parameter representation method of sound speed profiles and the dispersion structure extraction method, an inversion method for dual-channel sound speed profiles is proposed. For the common horizontal variation of sound speed profiles in long-distance acoustic propagation, a method for inverting horizontally varying dual-channel sound speed profiles is proposed. Finally, this article verifies the effectiveness of the dual-channel sound speed profile inversion method using the Arctic low-frequency long-range acoustic propagation experiment. Compared with previous sound speed profile inversion methods, the method proposed in this article has the advantages of fewer inversion parameters and faster inversion speed. It can be implemented using only a single hydrophone passively receiving random air gun signals, and it also solves the inversion problem of horizontal variation of sound speed profiles. It has significant advantages such as low cost, easy deployment, and fast computation speed.

Paper number 78:
Title: Acoustic source depth estimation method based on a single hydrophone in Arctic underwater
Authors: Jinbao Weng (1,2), Yubo Qi (3), Yanming Yang (1,2), Hongtao Wen (1,2), Hongtao Zhou (1,2), Benqing Chen (1,2), Dewei Xu (1,2), Ruichao Xue (1,2), Caigao Zeng (1,2) ((1) Laboratory of Ocean acoustics and Remote Sensing, Third Institute of Oceanography, Ministry of Natural Resources, Xiamen, Fujian, China (2) Fujian Provincial Key Laboratory of Marine Physical and Geological Processes, Xiamen, Fujian, China (3) State key laboratory of acoustics, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China)
Abstract: Based on the normal mode and ray theory, this article discusses the characteristics of surface sound source and reception at the surface layer, and explores depth estimation methods based on normal modes and rays, and proposes a depth estimation method based on the upper limit of modal frequency. Data verification is conducted to discuss the applicability and limitations of different methods. For the surface refracted normal mode waveguide, modes can be separated through warping transformation. Based on the characteristics of normal mode amplitude variation with frequency and number, the sound source depth can be estimated by matching amplitude information. Based on the spatial variation characteristics of eigenfunctions with frequency, a sound source depth estimation method matching the cutoff frequency of normal modes is proposed. For the deep Arctic sea, the sound ray arrival structure at the receiving end is obtained through the analysis of deep inversion sound ray trajectories, and the sound source depth can be estimated by matching the time difference of ray arrivals. Experimental data is used to verify the sound field patterns and the effectiveness of the sound source depth estimation method.

Paper number 79:
Title: CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data
Authors: Chongke Bi, Xin Gao, Jiangkang Deng, Guan Li, Jun Han
Abstract: Large-scale scientific simulations require significant resources to generate high-resolution time-varying data (TVD). While super-resolution is an efficient post-processing strategy to reduce costs, existing methods rely on a large amount of HR training data, limiting their applicability to diverse simulation scenarios. To address this constraint, we proposed CD-TVD, a novel framework that combines contrastive learning and an improved diffusion-based super-resolution model to achieve accurate 3D super-resolution from limited time-step high-resolution data. During pre-training on historical simulation data, the contrastive encoder and diffusion superresolution modules learn degradation patterns and detailed features of high-resolution and low-resolution samples. In the training phase, the improved diffusion model with a local attention mechanism is fine-tuned using only one newly generated high-resolution timestep, leveraging the degradation knowledge learned by the encoder. This design minimizes the reliance on large-scale high-resolution datasets while maintaining the capability to recover fine-grained details. Experimental results on fluid and atmospheric simulation datasets confirm that CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a significant advancement in data augmentation for large-scale scientific simulations. The code is available at this https URL.

Paper number 80:
Title: Performance Benchmarking of Machine Learning Models for Terahertz Metamaterial Absorber Prediction
Authors: Nafisa Anjum, Robiul Hasan
Abstract: This study presents a polarization-insensitive ultra-broadband terahertz metamaterial absorber based on vanadium dioxide (VO2) and evaluates machine learning methods for predicting its absorption performance. The structure consists of a VO2 metasurface, a MF2 dielectric spacer, and a gold ground plane. It achieves more than 90% absorption between 5.72 and 11.11 THz, covering a 5.38 THz bandwidth with an average absorptance of 98.15%. A dataset of 9,018 samples was generated from full-wave simulations by varying patch width, dielectric thickness, and frequency. Six regression models were trained: Linear Regression, Support Vector Regression, Decision Tree, Random Forest, XGBoost, and Bagging. Performance was measured using adjusted R2, MAE, MSE, and RMSE. Ensemble models achieved the best results, with Bagging reaching an adjusted R2 of 0.9985 and RMSE of 0.0146. The workflow offers a faster alternative to exhaustive simulations and can be applied to other metamaterial designs, enabling efficient evaluation and optimization.

Paper number 81:
Title: DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models
Authors: Yuanyuan Wang, Dongchao Yang, Yiwen Shao, Hangting Chen, Jiankun Zhao, Zhiyong Wu, Helen Meng, Xixin Wu
Abstract: Extending pre-trained Large Language Models (LLMs)'s speech understanding or generation abilities by introducing various effective speech tokens has attracted great attention in the speech community. However, building a unified speech understanding and generation model still faces the following challenges: (1) Due to the huge modality gap between speech tokens and text tokens, extending text LLMs to unified speech LLMs relies on large-scale paired data for fine-tuning, and (2) Generation and understanding tasks prefer information at different levels, e.g., generation benefits from detailed acoustic features, while understanding favors high-level semantics. This divergence leads to difficult performance optimization in one unified model. To solve these challenges, in this paper, we present two key insights in speech tokenization and speech language modeling. Specifically, we first propose an Understanding-driven Speech Tokenizer (USTokenizer), which extracts high-level semantic information essential for accomplishing understanding tasks using text LLMs. In this way, USToken enjoys better modality commonality with text, which reduces the difficulty of modality alignment in adapting text LLMs to speech LLMs. Secondly, we present DualSpeechLM, a dual-token modeling framework that concurrently models USToken as input and acoustic token as output within a unified, end-to-end framework, seamlessly integrating speech understanding and generation capabilities. Furthermore, we propose a novel semantic supervision loss and a Chain-of-Condition (CoC) strategy to stabilize model training and enhance speech generation performance. Experimental results demonstrate that our proposed approach effectively fosters a complementary relationship between understanding and generation tasks, highlighting the promising strategy of mutually enhancing both tasks in one unified model.
    