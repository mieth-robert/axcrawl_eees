
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: RTFusion: A depth estimation network based on multimodal fusion in challenging scenarios
Authors: Zelin Meng, Takanori Fukao
Abstract: Depth estimation in complex real-world scenarios is a challenging task, especially when relying solely on a single modality such as visible light or thermal infrared (THR) imagery. This paper proposes a novel multimodal depth estimation model, RTFusion, which enhances depth estimation accuracy and robustness by integrating the complementary strengths of RGB and THR data. The RGB modality provides rich texture and color information, while the THR modality captures thermal patterns, ensuring stability under adverse lighting conditions such as extreme illumination. The model incorporates a unique fusion mechanism, EGFusion, consisting of the Mutual Complementary Attention (MCA) module for cross-modal feature alignment and the Edge Saliency Enhancement Module (ESEM) to improve edge detail preservation. Comprehensive experiments on the MS2 and ViViD++ datasets demonstrate that the proposed model consistently produces high-quality depth maps across various challenging environments, including nighttime, rainy, and high-glare conditions. The experimental results highlight the potential of the proposed method in applications requiring reliable depth estimation, such as autonomous driving, robotics, and augmented reality.

Paper number 2:
Title: Rethinking Few-Shot Medical Image Segmentation by SAM2: A Training-Free Framework with Augmentative Prompting and Dynamic Matching
Authors: Haiyue Zu, Jun Ge, Heting Xiao, Jile Xie, Zhangzhe Zhou, Yifan Meng, Jiayi Ni, Junjie Niu, Linlin Zhang, Li Ni, Huilin Yang
Abstract: The reliance on large labeled datasets presents a significant challenge in medical image segmentation. Few-shot learning offers a potential solution, but existing methods often still require substantial training data. This paper proposes a novel approach that leverages the Segment Anything Model 2 (SAM2), a vision foundation model with strong video segmentation capabilities. We conceptualize 3D medical image volumes as video sequences, departing from the traditional slice-by-slice paradigm. Our core innovation is a support-query matching strategy: we perform extensive data augmentation on a single labeled support image and, for each frame in the query volume, algorithmically select the most analogous augmented support image. This selected image, along with its corresponding mask, is used as a mask prompt, driving SAM2's video segmentation. This approach entirely avoids model retraining or parameter updates. We demonstrate state-of-the-art performance on benchmark few-shot medical image segmentation datasets, achieving significant improvements in accuracy and annotation efficiency. This plug-and-play method offers a powerful and generalizable solution for 3D medical image segmentation.

Paper number 3:
Title: PGAD: Prototype-Guided Adaptive Distillation for Multi-Modal Learning in AD Diagnosis
Authors: Yanfei Li, Teng Yin, Wenyi Shang, Jingyu Liu, Xi Wang, Kaiyang Zhao
Abstract: Missing modalities pose a major issue in Alzheimer's Disease (AD) diagnosis, as many subjects lack full imaging data due to cost and clinical constraints. While multi-modal learning leverages complementary information, most existing methods train only on complete data, ignoring the large proportion of incomplete samples in real-world datasets like ADNI. This reduces the effective training set and limits the full use of valuable medical data. While some methods incorporate incomplete samples, they fail to effectively address inter-modal feature alignment and knowledge transfer challenges under high missing rates. To address this, we propose a Prototype-Guided Adaptive Distillation (PGAD) framework that directly incorporates incomplete multi-modal data into training. PGAD enhances missing modality representations through prototype matching and balances learning with a dynamic sampling strategy. We validate PGAD on the ADNI dataset with varying missing rates (20%, 50%, and 70%) and demonstrate that it significantly outperforms state-of-the-art approaches. Ablation studies confirm the effectiveness of prototype matching and adaptive sampling, highlighting the potential of our framework for robust and scalable AD diagnosis in real-world clinical settings.

Paper number 4:
Title: Dissipativity-Based Distributed Control and Communication Topology Co-Design for Voltage Regulation and Current Sharing in DC Microgrids
Authors: Mohammad Javad Najafirad, Shirantha Welikala
Abstract: This paper presents a novel dissipativity-based distributed droop-free control approach for voltage regulation and current sharing in DC microgrids (MGs) comprised of an interconnected set of distributed generators (DGs), loads, and power lines. First, we describe the closed-loop DC MG as a networked system where the DGs and lines (i.e., subsystems) are interconnected via a static interconnection matrix. This interconnection matrix demonstrates how the inputs, outputs, and disturbances of DGs and lines are connected in a DC MG. Each DG has a local controller and a distributed global controller. To design the controller, we use the dissipativity properties of the subsystems and formulate a linear matrix inequality (LMI) problem. To support the feasibility of this problem, we identify a set of necessary local and global conditions that we then enforce in a specifically developed LMI-based controller design process. In contrast to existing DC MG control solutions, our approach proposes a unified framework for co-designing the distributed controller and communication topology. As the co-design process is LMI-based, it can be efficiently implemented and evaluated. The effectiveness of the proposed solution can be verified by simulating an islanded DC MG in a MATLAB/Simulink environment under different scenarios, such as load changes and topological constraint changes, and then comparing the performance with a recent droop control algorithm.

Paper number 5:
Title: Joint Delay-Doppler Estimation using OFDMA Payloads for Integrated Sensing and Communications
Authors: Marc Miranda, Sebastian Semper, Christian Schneider, Reiner Thomä, Giovanni Del Galdo
Abstract: The use of future communication systems for sensing offers the potential for a number of new applications. In this paper, we show that leveraging user data payloads in multi-node Orthogonal Frequency Division Multiple Access (OFDMA) networks for estimating target delay and Doppler-shift parameters can yield a significant advantage in SNR and addressable bandwidth. However, gaps in the frequency-time resources, reference signal boosting and amplitude modulation schemes introduce challenges for estimation at the sensing receiver. In this work, we propose a joint delay and Doppler-shift model-based estimator designed to address these challenges. Furthermore, we demonstrate that incorporating knowledge of the device model into the estimation procedure helps mitigate the effects of the non-ideal radar ambiguity function caused by amplitude-modulated user payloads and sparse reference signals. Simulation results demonstrate that the estimator achieves the theoretical lower bound on estimation variance.

Paper number 6:
Title: Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model
Authors: Siyeop Yoon, Yujin Oh, Matthew Tivnan, Sifan Song, Pengfei Jin, Sekeun KimHyun Jin Cho, Dufan Wu, Raul Uppot, Quanzheng Li
Abstract: This study presents a 3D flow-matching model designed to predict the progression of the frozen region (iceball) during kidney cryoablation. Precise intraoperative guidance is critical in cryoablation to ensure complete tumor eradication while preserving adjacent healthy tissue. However, conventional methods, typically based on physics driven or diffusion based simulations, are computationally demanding and often struggle to represent complex anatomical structures accurately. To address these limitations, our approach leverages intraoperative CT imaging to inform the model. The proposed 3D flow matching model is trained to learn a continuous deformation field that maps early-stage CT scans to future predictions. This transformation not only estimates the volumetric expansion of the iceball but also generates corresponding segmentation masks, effectively capturing spatial and morphological changes over time. Quantitative analysis highlights the model robustness, demonstrating strong agreement between predictions and ground-truth segmentations. The model achieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient of 0.75. By integrating real time CT imaging with advanced deep learning techniques, this approach has the potential to enhance intraoperative guidance in kidney cryoablation, improving procedural outcomes and advancing the field of minimally invasive surgery.

Paper number 7:
Title: From Voice to Safety: Language AI Powered Pilot-ATC Communication Understanding for Airport Surface Movement Collision Risk Assessment
Authors: Yutian Pang, Andrew Paul Kendall, Alex Porcayo, Mariah Barsotti, Anahita Jain, John-Paul Clarke
Abstract: This work integrates language AI-based voice communication understanding with collision risk assessment. The proposed framework consists of two major parts, (a) Automatic Speech Recognition (ASR); (b) surface collision risk modeling. ASR module generates information tables by processing voice communication transcripts, which serve as references for producing potential taxi plans and calculating the surface movement collision risk. For ASR, we collect and annotate our own Named Entity Recognition (NER) dataset based on open-sourced video recordings and safety investigation reports. Additionally, we refer to FAA Order JO 7110.65W and FAA Order JO 7340.2N to get the list of heuristic rules and phase contractions of communication between the pilot and the Air Traffic Controller (ATCo) used in daily aviation operations. Then, we propose the novel ATC Rule-Enhanced NER method, which integrates the heuristic rules into the model training and inference stages, resulting into hybrid rule-based NER model. We show the effectiveness of this hybrid approach by comparing different setups with different token-level embedding models. For the risk modeling, we adopt the node-link airport layout graph from NASA FACET and model the aircraft taxi speed at each link as a log-normal distribution and derive the total taxi time distribution. Then, we propose a spatiotemporal formulation of the risk probability of two aircraft moving across potential collision nodes during ground movement. We show the effectiveness of our approach by simulating two case studies, (a) the Henada airport runway collision accident happened in January 2024; (b) the KATL taxiway collision happened in September 2024. We show that, by understanding the pilot-ATC communication transcripts and analyzing surface movement patterns, the proposed model improves airport safety by providing risk assessment in time.

Paper number 8:
Title: Musical Source Separation of Brazilian Percussion
Authors: Richa Namballa, Giovana Morais, Magdalena Fuentes
Abstract: Musical source separation (MSS) has recently seen a big breakthrough in separating instruments from a mixture in the context of Western music, but research on non-Western instruments is still limited due to a lack of data. In this demo, we use an existing dataset of Brazilian sama percussion to create artificial mixtures for training a U-Net model to separate the surdo drum, a traditional instrument in samba. Despite limited training data, the model effectively isolates the surdo, given the drum's repetitive patterns and its characteristic low-pitched timbre. These results suggest that MSS systems can be successfully harnessed to work in more culturally-inclusive scenarios without the need of collecting extensive amounts of data.

Paper number 9:
Title: Lessons learned from field demonstrations of model predictive control and reinforcement learning for residential and commercial HVAC: A review
Authors: Arash J. Khabbazi, Elias N. Pergantis, Levi D. Reyes Premer, Panagiotis Papageorgiou, Alex H. Lee, James E. Braun, Gregor P. Henze, Kevin J. Kircher
Abstract: A large body of simulation research suggests that model predictive control (MPC) and reinforcement learning (RL) for heating, ventilation, and air-conditioning (HVAC) in residential and commercial buildings could reduce energy costs, pollutant emissions, and strain on power grids. Despite this potential, neither MPC nor RL has seen widespread industry adoption. Field demonstrations could accelerate MPC and RL adoption by providing real-world data that support the business case for deployment. This paper reviews 24 field demonstrations of MPC and RL in residential buildings and 80 in commercial buildings. After presenting demographic information -- such as experiment scopes, locations, and durations -- this paper analyzes experiment protocols and their influence on performance estimates. We find that 71% of the reviewed field demonstrations use experiment protocols that may lead to unreliable performance estimates. Over the remaining 29% that we view as reliable, the weighted-average cost savings, weighted by experiment duration, are 16% in residential buildings and 13% in commercial buildings. While these savings are potentially attractive, making the business case for MPC and RL also requires characterizing the costs of deployment, operation, and maintenance. Only 13 of the 104 reviewed papers report these costs or discuss related challenges. Based on these observations, we recommend directions for future field research, including: Improving experiment protocols; reporting deployment, operation, and maintenance costs; designing algorithms and instrumentation to reduce these costs; controlling HVAC equipment alongside other distributed energy resources; and pursuing emerging objectives such as peak shaving, arbitraging wholesale energy prices, and providing power grid reliability services.

Paper number 10:
Title: ISC-POMDPs: Partially Observed Markov Decision Processes with Initial-State Dependent Costs
Authors: Timothy L. Molloy
Abstract: We introduce a class of partially observed Markov decision processes (POMDPs) with costs that can depend on both the value and (future) uncertainty associated with the initial state. These Initial-State Cost POMDPs (ISC-POMDPs) enable the specification of objectives relative to a priori unknown initial states, which is useful in applications such as robot navigation, controlled sensing, and active perception, that can involve controlling systems to revisit, remain near, or actively infer their initial states. By developing a recursive Bayesian fixed-point smoother to estimate the initial state that resembles the standard recursive Bayesian filter, we show that ISC-POMDPs can be treated as POMDPs with (potentially) belief-dependent costs. We demonstrate the utility of ISC-POMDPs, including their ability to select controls that resolve (future) uncertainty about (past) initial states, in simulation.

Paper number 11:
Title: Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes
Authors: Yanxi Chen, Mohammad Farazi, Zhangsihao Yang, Yonghui Fan, Nicholas Ashton, Eric M Reiman, Yi Su, Yalin Wang
Abstract: Alzheimer's disease (AD) is a major neurodegenerative condition that affects millions around the world. As one of the main biomarkers in the AD diagnosis procedure, brain amyloid positivity is typically identified by positron emission tomography (PET), which is costly and invasive. Brain structural magnetic resonance imaging (sMRI) may provide a safer and more convenient solution for the AD diagnosis. Recent advances in geometric deep learning have facilitated sMRI analysis and early diagnosis of AD. However, determining AD pathology, such as brain amyloid deposition, in preclinical stage remains challenging, as less significant morphological changes can be observed. As a result, few AD classification models are generalizable to the brain amyloid positivity classification task. Blood-based biomarkers (BBBMs), on the other hand, have recently achieved remarkable success in predicting brain amyloid positivity and identifying individuals with high risk of being brain amyloid positive. However, individuals in medium risk group still require gold standard tests such as Amyloid PET for further evaluation. Inspired by the recent success of transformer architectures, we propose a geometric deep learning model based on transformer that is both scalable and robust to variations in input volumetric mesh size. Our work introduced a novel tokenization scheme for tetrahedral meshes, incorporating anatomical landmarks generated by a pre-trained Gaussian process model. Our model achieved superior classification performance in AD classification task. In addition, we showed that the model was also generalizable to the brain amyloid positivity prediction with individuals in the medium risk class, where BM alone cannot achieve a clear classification. Our work may enrich geometric deep learning research and improve AD diagnosis accuracy without using expensive and invasive PET scans.

Paper number 12:
Title: Accelerated Patient-specific Non-Cartesian MRI Reconstruction using Implicit Neural Representations
Authors: Di Xu, Hengjie Liu, Xin Miao, Daniel O'Connor, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Dan Ruan, Yang Yang, Ke Sheng
Abstract: The scanning time for a fully sampled MRI can be undesirably lengthy. Compressed sensing has been developed to minimize image artifacts in accelerated scans, but the required iterative reconstruction is computationally complex and difficult to generalize on new cases. Image-domain-based deep learning methods (e.g., convolutional neural networks) emerged as a faster alternative but face challenges in modeling continuous k-space, a problem amplified with non-Cartesian sampling commonly used in accelerated acquisition. In comparison, implicit neural representations can model continuous signals in the frequency domain and thus are compatible with arbitrary k-space sampling patterns. The current study develops a novel generative-adversarially trained implicit neural representations (k-GINR) for de novo undersampled non-Cartesian k-space reconstruction. k-GINR consists of two stages: 1) supervised training on an existing patient cohort; 2) self-supervised patient-specific optimization. In stage 1, the network is trained with the generative-adversarial network on diverse patients of the same anatomical region supervised by fully sampled acquisition. In stage 2, undersampled k-space data of individual patients is used to tailor the prior-embedded network for patient-specific optimization. The UCSF StarVIBE T1-weighted liver dataset was evaluated on the proposed framework. k-GINR is compared with an image-domain deep learning method, Deep Cascade CNN, and a compressed sensing method. k-GINR consistently outperformed the baselines with a larger performance advantage observed at very high accelerations (e.g., 20 times). k-GINR offers great value for direct non-Cartesian k-space reconstruction for new incoming patients across a wide range of accelerations liver anatomy.

Paper number 13:
Title: Lightweight Hypercomplex MRI Reconstruction: A Generalized Kronecker-Parameterized Approach
Authors: Haosen Zhang, Jiahao Huang, Yinzhe Wu, Congren Dai, Fanwen Wang, Zhenxuan Zhang, Guang Yang
Abstract: Magnetic Resonance Imaging (MRI) is crucial for clinical diagnostics but is hindered by prolonged scan times. Current deep learning models enhance MRI reconstruction but are often memory-intensive and unsuitable for resource-limited systems. This paper introduces a lightweight MRI reconstruction model leveraging Kronecker-Parameterized Hypercomplex Neural Networks to achieve high performance with reduced parameters. By integrating Kronecker-based modules, including Kronecker MLP, Kronecker Window Attention, and Kronecker Convolution, the proposed model efficiently extracts spatial features while preserving representational power. We introduce Kronecker U-Net and Kronecker SwinMR, which maintain high reconstruction quality with approximately 50% fewer parameters compared to existing models. Experimental evaluation on the FastMRI dataset demonstrates competitive PSNR, SSIM, and LPIPS metrics, even at high acceleration factors (8x and 16x), with no significant performance drop. Additionally, Kronecker variants exhibit superior generalization and reduced overfitting on limited datasets, facilitating efficient MRI reconstruction on hardware-constrained systems. This approach sets a new benchmark for parameter-efficient medical imaging models.

Paper number 14:
Title: Optimal and Robust Multivariable Reaching Time Sliding Mode Control Design
Authors: J. C. Geromel, L. Hsu, E. V. L. Nunes
Abstract: This paper addresses two minimum reaching time control problems within the context of finite stable systems. The well-known Variable Structure Control (VSC) and Unity Vector Control (UVC) strategies are analyzed, with the primary objective of designing optimal and robust state feedback gains that ensure minimum finite time convergence to the origin. This is achieved in the presence of convex bounded parameter uncertainty and norm-bounded exogenous disturbances. In both cases, the optimality conditions are expressed through Linear Matrix Inequalities (LMIs), which are solved efficiently within the framework of multivariable systems using existing numerical tools. The theoretical results are demonstrated with two practically motivated examples.

Paper number 15:
Title: A Hybrid Model/Data-Driven Solution to Channel, Position and Orientation Tracking in mmWave Vehicular Systems
Authors: Yun Chen, Nuria González-Prelcic, Takayuki Shimizu, Chinmay Mahabal
Abstract: Channel tracking in millimeter wave (mmWave) vehicular systems is crucial for maintaining robust vehicle-to-infrastructure (V2I) communication links, which can be leveraged to achieve high accuracy vehicle position and orientation tracking as a byproduct of communication. While prior work tends to simplify the system model by omitting critical system factors such as clock offsets, filtering effects, antenna array orientation offsets, and channel estimation errors, we address the challenges of a practical mmWave multiple-input multiple-output (MIMO) communication system between a single base station (BS) and a vehicle while tracking the vehicle's position and orientation (PO) considering realistic driving behaviors. We first develop a channel tracking algorithm based on multidimensional orthogonal matching pursuit (MOMP) with factoring (F-MOMP) to reduce computational complexity and enable high-resolution channel estimates during the tracking stage, suitable for PO estimation. Then, we develop a network called VO-ChAT (Vehicle Orientation-Channel Attention for orientation Tracking), which processes the channel estimate sequence for orientation prediction. Afterward, a weighted least squares (WLS) problem that exploits the channel geometry is formulated to create an initial estimate of the vehicle's 2D position. A second network named VP-ChAT (Vehicle Position-Channel Attention for position Tracking) refines the geometric position estimate. VP-ChAT is a Transformer inspired network processing the historical channel and position estimates to provide the correction for the initial geometric position estimate. The proposed solution is evaluated using raytracing generated channels in an urban canyon environment. For 80% of the cases it achieves a 2D position tracking accuracy of 26 cm while orientation errors are kept below 0.5 degree.

Paper number 16:
Title: We Care Each Pixel: Calibrating on Medical Segmentation Model
Authors: Wenhao Liang, Wei Zhang, Yue Lin, Miao Xu, Olaf Maennel, Weitong Chen
Abstract: Medical image segmentation is fundamental for computer-aided diagnostics, providing accurate delineation of anatomical structures and pathological regions. While common metrics such as Accuracy, DSC, IoU, and HD primarily quantify spatial agreement between predictions and ground-truth labels, they do not assess the calibration quality of segmentation models, which is crucial for clinical reliability. To address this limitation, we propose pixel-wise Expected Calibration Error (pECE), a novel metric that explicitly measures miscalibration at the pixel level, thereby ensuring both spatial precision and confidence reliability. We further introduce a morphological adaptation strategy that applies morphological operations to ground-truth masks before computing calibration losses, particularly benefiting margin-based losses such as Margin SVLS and NACL. Additionally, we present the Signed Distance Calibration Loss (SDC), which aligns boundary geometry with calibration objectives by penalizing discrepancies between predicted and ground-truth signed distance functions (SDFs). Extensive experiments demonstrate that our method not only enhances segmentation performance but also improves calibration quality, yielding more trustworthy confidence estimates. Code is available at: this https URL.

Paper number 17:
Title: Sparse identification of nonlinear dynamics with high accuracy and reliability under noisy conditions for applications to industrial systems
Authors: Shuichi Yahagi, Ansei Yonezawa, Hiroki Seto, Heisei Yonezawa, Itsuro Kajiwara
Abstract: This paper proposes a sparse identification of nonlinear dynamics (SINDy) with control and exogenous inputs for highly accurate and reliable prediction and applies the proposed method to the diesel engine airpath systems which are known as a nonlinear complicated industrial system. Although SINDy is known as a powerful approach for the identification of nonlinear systems, some problems remain: there are few examples of application to industrial systems and multi-step predictions are not guaranteed due to noisy data and an increase of basis functions due to the extension of the coordinate such as time-delay embedding. To address the problems, we propose an improved SINDy based on ensemble learning, elite gathering, and classification techniques while keeping convex calculation. In the proposed method, library bagging is performed, and elites with an R-squared greater than 90% are gathered. Then, clustering is performed on the surviving elites because physically motivated basis functions are not always available and the elite models obtained do not always show the same trends. After the classification, discrete model candidates are obtained by taking the mean of each classified elite. Finally, the best model is selected. The simulation results show that the proposed method realizes multi-step prediction for the airpath system which is known as a complicated industrial system under noisy conditions.

Paper number 18:
Title: Cross-Layer-Optimized Link Selection for Hologram Video Streaming over Millimeter Wave Networks
Authors: Yiming Jiang, Yanwei Liu, Jinxia Liu, Antonios Argyriou, Yifei Chen, Wen Zhang
Abstract: Holographic-type communication brings an immersive tele-holography experience by delivering holographic contents to users. As the direct representation of holographic contents, hologram videos are naturally three-dimensional representation, which consist of a huge volume of data. Advanced multi-connectivity (MC) millimeter-wave (mmWave) networks are now available to transmit hologram videos by providing the necessary bandwidth. However, the existing link selection schemes in MC-based mmWave networks neglect the source content characteristics of hologram videos and the coordination among the parameters of different protocol layers in each link, leading to sub-optimal streaming performance. To address this issue, we propose a cross-layer-optimized link selection scheme for hologram video streaming over mmWave networks. This scheme optimizes link selection by jointly adjusting the video coding bitrate, the modulation and channel coding schemes (MCS), and link power allocation to minimize the end-to-end hologram distortion while guaranteeing the synchronization and quality balance between real and imaginary components of the hologram. Results show that the proposed scheme can effectively improve the hologram video streaming performance in terms of PSNR by 1.2dB to 6.4dB against the non-cross-layer scheme.

Paper number 19:
Title: Intelligent Reflecting Surface-Aided Electromagnetic Stealth over Extended Regions
Authors: Qingjie Wu, Beixiong Zheng, Guangchi Zhang, Derrick Wing Kwan Ng, A. Lee Swindlehurst
Abstract: Compared to traditional electromagnetic stealth (ES) materials, which are effective only within specific frequencies and orientations, intelligent reflecting surface (IRS) technology introduces a novel paradigm for achieving dynamic and adaptive ES by adapting its reflection pattern in real time to neutralize radar probing signals echoed back from the target. In this letter, we study an IRS-aided ES system mounted on an aerial target to evade radar detection admist uncertain/moving radar positions over an extended area. Specifically, we aim to optimize the IRS's passive reflection to minimize the maximum received signal-to-noise ratio (SNR) of the target echo signal in the area. A semi-closed-form solution is derived by first discretizing the continuous spatial frequency deviation to approximate the semi-infinite reflection gain constraint and then leveraging the Lagrange dual method. Simulation results are provided to validate that the proposed IRS-aided ES strategy can consistently reduce the reflection gains for radars located across a large region.

Paper number 20:
Title: Gaussian Random Fields as an Abstract Representation of Patient Metadata for Multimodal Medical Image Segmentation
Authors: Bill Cassidy, Christian McBride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Shaghayegh Raad, Moi Hoon Yap
Abstract: The growing rate of chronic wound occurrence, especially in patients with diabetes, has become a concerning trend in recent years. Chronic wounds are difficult and costly to treat, and have become a serious burden on health care systems worldwide. Chronic wounds can have devastating consequences for the patient, with infection often leading to reduced quality of life and increased mortality risk. Innovative deep learning methods for the detection and monitoring of such wounds have the potential to reduce the impact to both patient and clinician. We present a novel multimodal segmentation method which allows for the introduction of patient metadata into the training workflow whereby the patient data are expressed as Gaussian random fields. Our results indicate that the proposed method improved performance when utilising multiple models, each trained on different metadata categories. Using the Diabetic Foot Ulcer Challenge 2022 test set, when compared to the baseline results (intersection over union = 0.4670, Dice similarity coefficient = 0.5908) we demonstrate improvements of +0.0220 and +0.0229 for intersection over union and Dice similarity coefficient respectively. This paper presents the first study to focus on integrating patient data into a chronic wound segmentation workflow. Our results show significant performance gains when training individual models using specific metadata categories, followed by average merging of prediction masks using distance transforms. All source code for this study is available at: this https URL

Paper number 21:
Title: On reconstructing high derivatives of noisy time-series with confidence intervals
Authors: Mazen Alamir
Abstract: Reconstructing high derivatives of noisy measurements is an important step in many control, identification and diagnosis problems. In this paper, a heuristic is proposed to address this challenging issue. The framework is based on a dictionary of identified models indexed by the bandwidth, the noise level and the required degrees of derivation. Each model in the dictionary is identified via cross-validation using tailored learning data. It is also shown that the proposed approach provides heuristically defined confidence intervals on the resulting estimation. The performance of the framework is compared to the state-of-the-art available algorithms showing noticeably higher accuracy. Although the results are shown for up to the 4-th derivative, higher derivation orders can be used with comparable results.

Paper number 22:
Title: Integrated Sensing, Communication, and Computation Over-the-Air in OFDM Systems
Authors: Biao Dong, Bin Cao, Qinyu Zhang
Abstract: This work is concerned with integrated sensing, communication, and computation (ISCC) in uplink orthogonal frequency division multiplexing (OFDM) systems, wherein multiple devices perform target sensing and over-the-air computation (AirComp) simultaneously. We aim to minimize the computational mean squared error (MSE) by jointly optimizing the transmitting vector and the aggregation vector. To tackle the non-convexity of this problem, we develop a two-phase iterative algorithm. Simulations demonstrate the effectiveness of the proposed algorithm.

Paper number 23:
Title: L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation
Authors: Johanna P. Müller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi, Bernhard Kainz
Abstract: Accurate analysis of prenatal ultrasound (US) is essential for early detection of developmental anomalies. However, operator dependency and technical limitations (e.g. intrinsic artefacts and effects, setting errors) can complicate image interpretation and the assessment of diagnostic uncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with Integrated FoundatiON models), a framework that integrates uncertainty quantification through unsupervised, normative learning and large-scale foundation models for robust segmentation of fetal structures in normal and pathological scans. We propose to utilise the aleatoric logit distributions of Stochastic Segmentation Networks and Laplace approximations with fast Hessian estimations to estimate epistemic uncertainty only from the segmentation head. This enables us to achieve reliable abnormality quantification for instant diagnostic feedback. Combined with an integrated Dropout component, L-FUSION enables reliable differentiation of lesions from normal fetal anatomy with enhanced uncertainty maps and segmentation counterfactuals in US imaging. It improves epistemic and aleatoric uncertainty interpretation and removes the need for manual disease-labelling. Evaluations across multiple datasets show that L-FUSION achieves superior segmentation accuracy and consistent uncertainty quantification, supporting on-site decision-making and offering a scalable solution for advancing fetal ultrasound analysis in clinical settings.

Paper number 24:
Title: Evaluation of 3D Terrestrial and Aerial Spectrum Sharing with Massive MIMO Systems
Authors: Achiel Colpaert, Zhuangzhuang Cui, Sofie Pollin
Abstract: Connecting aerial and terrestrial users with a single base station (BS) is increasingly challenging due to the rising number of aerial users like unmanned aerial vehicles (UAVs). Traditional BSs, designed with down-tilted beams, focus mainly on ground users, but massive MIMO (mMIMO) systems can significantly enhance coverage in low-altitude airspace. This paper analyzes how a mMIMO BS serves both aerial and terrestrial users in a 3D spectrum-sharing scheme. Using Semi-orthogonal User Selection (SUS) and random scheduling, we assess the spectral efficiency and performance limits of these systems. Results reveal that mMIMO effectively supports more terrestrial users, influenced by channel characteristics and user scheduling strategies, providing key insights for future 3D aerial-terrestrial networks.

Paper number 25:
Title: Identification of Minimally Restrictive Assembly Sequences using Supervisory Control Theory
Authors: Martina Vinetti, Martin Fabian
Abstract: Modern assembly processes require flexibility and adaptability to handle increasing product variety and customization. Traditional assembly planning methods often prioritize finding an optimal assembly sequence, overlooking the requirements of contemporary manufacturing. This work uses Supervisory Control Theory to systematically generate all feasible assembly sequences while ensuring compliance with precedence and process constraints. By synthesizing a controllable, non-blocking, and minimally restrictive supervisor, the proposed method guarantees that only valid sequences are allowed, balancing flexibility and constraint enforcement. The obtained sequences can serve as a basis for further optimization or exception management, improving responsiveness to disruptions.

Paper number 26:
Title: Performance Analysis of Spatial and Temporal Learning Networks in the Presence of DVL Noise
Authors: Rajini Makam, Nadav Cohen, Sumukh Shadakshari, Srinivasa Puranika Bhatta, Itzik Klein, Suresh Sundaram
Abstract: Navigation is a critical aspect of autonomous underwater vehicles (AUVs) operating in complex underwater environments. Since global navigation satellite system (GNSS) signals are unavailable underwater, navigation relies on inertial sensing, which tends to accumulate errors over time. To mitigate this, the Doppler velocity log (DVL) plays a crucial role in determining navigation accuracy. In this paper, we compare two neural network models: an adapted version of BeamsNet, based on a one-dimensional convolutional neural network, and a Spectrally Normalized Memory Neural Network (SNMNN). The former focuses on extracting spatial features, while the latter leverages memory and temporal features to provide more accurate velocity estimates while handling biased and noisy DVL data. The proposed approaches were trained and tested on real AUV data collected in the Mediterranean Sea. Both models are evaluated in terms of accuracy and estimation certainty and are benchmarked against the least squares (LS) method, the current model-based approach. The results show that the neural network models achieve over a 50% improvement in RMSE for the estimation of the AUV velocity, with a smaller standard deviation.

Paper number 27:
Title: Environment-Aware Scheduling of URLLC and Sensing Services for Smart Industries
Authors: Navid Keshtiarast, Pradyumna Kumar Bishoyi, Marina Petrova
Abstract: In this paper, we address the problem of scheduling sensing and communication functionality in an integrated sensing and communication (ISAC) enabled base station (BS) operating in an indoor factory (InF) environment. The BS is performing the task of detecting an AGV while managing downlink transmission of ultra-reliable low-latency communication (URLLC) data in a time-sharing manner. Scheduling fixed time slots for both sensing and communication is inefficient for the InF environment, as the instantaneous environmental changes necessitate a higher frequency of sensing operations to accurately detect the AGV. To address this issue, we propose an environment-aware scheduling scheme, in which we first formulate an optimization problem to maximize the probability of detection of AGV while considering the survival time constraint of URLLC data. Subsequently, utilizing the Nash bargaining theory, we propose an adaptive time-sharing scheme that assigns sensing duration in accordance with the environmental clutter density and distributes time to URLLC depending on the incoming traffic rate. Using our own Python-based discrete-event link-level simulator, we demonstrate the effectiveness of our proposed scheme over the baseline scheme in terms of probability of detection and downlink latency.

Paper number 28:
Title: Pretext Task Adversarial Learning for Unpaired Low-field to Ultra High-field MRI Synthesis
Authors: Zhenxuan Zhang, Peiyuan Jing, Coraline Beitone, Jiahao Huang, Zhifan Gao, Guang Yang, Pete Lally
Abstract: Given the scarcity and cost of high-field MRI, the synthesis of high-field MRI from low-field MRI holds significant potential when there is limited data for training downstream tasks (e.g. segmentation). Low-field MRI often suffers from a reduced signal-to-noise ratio (SNR) and spatial resolution compared to high-field MRI. However, synthesizing high-field MRI data presents challenges. These involve aligning image features across domains while preserving anatomical accuracy and enhancing fine details. To address these challenges, we propose a Pretext Task Adversarial (PTA) learning framework for high-field MRI synthesis from low-field MRI data. The framework comprises three processes: (1) The slice-wise gap perception (SGP) network aligns the slice inconsistencies of low-field and high-field datasets based on contrastive learning. (2) The local structure correction (LSC) network extracts local structures by restoring the locally rotated and masked images. (3) The pretext task-guided adversarial training process introduces additional supervision and incorporates a discriminator to improve image realism. Extensive experiments on low-field to ultra high-field task demonstrate the effectiveness of our method, achieving state-of-the-art performance (16.892 in FID, 1.933 in IS, and 0.324 in MS-SSIM). This enables the generation of high-quality high-field-like MRI data from low-field MRI data to augment training datasets for downstream tasks. The code is available at: this https URL.

Paper number 29:
Title: Community Energy Management System for Fast Frequency Response: A Hierarchical Control Approach
Authors: Joonsung Jung, Hyunjoong Kim, Hyunghwan Shin, Jip Kim
Abstract: The increase in renewable energy sources (RES) has reduced power system inertia, making frequency stabilization more challenging and highlighting the need for fast frequency response (FFR) resources. While building energy management systems (BEMS) equipped with distributed energy resources (DERs) can provide FFR, individual BEMS alone cannot fully meet demand. To address this, we propose a community energy management system (CEMS) operational model that minimizes energy costs and generates additional revenue, which is provided FFR through coordinated DERs and building loads under photovoltaic (PV) generation uncertainty. The model incorporates a hierarchical control framework with three levels: Level 1 allocates maximum FFR capacity, Level 2 employs scenario-based stochastic model predictive control (SMPC) to adjust DER operations and ensure FFR provision despite PV uncertainties, and Level 3 performs rapid load adjustments in response to frequency fluctuations detected by a frequency meter. Simulation results on a campus building cluster demonstrate the effectiveness of the proposed model, achieving a 10\% reduction in energy costs and a 24\% increase in FFR capacity, all while maintaining occupant comfort and enhancing frequency stabilization.

Paper number 30:
Title: A Risk-aware Bi-level Bidding Strategy for Virtual Power Plant with Power-to-Hydrogen System
Authors: Jaehyun Yoo, Jip Kim
Abstract: This paper presents a risk-aware bi-level bidding strategy for Virtual Power Plant (VPP) that integrates Power-to-Hydrogen (P2H) system, addressing the challenges posed by renewable energy variability and market volatility. By incorporating Conditional Value at Risk (CVaR) within the bi-level optimization framework, the proposed strategy enables VPPs to mitigate financial risks associated with uncertain market conditions. The upper-level problem seeks to maximize revenue through optimal bidding, while the lower-level problem ensures market-clearing compliance. The integration of the P2H system allows surplus renewable energy to be stored as hydrogen, which is utilized as an energy carrier, thereby increasing market profitability and enhancing resilience against financial risks. The effectiveness of the proposed strategy is validated through a modified IEEE 14 bus system, demonstrating that the inclusion of the P2H system and CVaR-based risk aversion enhances both revenue and financial hedging capability under volatile market this http URL paper underscores the strategic role of hydrogen storage in VPP operations, contributing to supporting improved profitability and the efficacy of a risk-aware bidding strategy.

Paper number 31:
Title: Fluid Antenna System Empowering 5G NR
Authors: Hanjiang Hong, Kai-Kit Wong, Haoyang Li, Hao Xu, Han Xiao, Hyundong Shin, Kin-Fai Tong, Yangyang Zhang
Abstract: Fluid antenna system (FAS) is an emerging technology that uses the new form of shape- and position-reconfigurable antennas to empower the physical layer for wireless communications. Prior studies on FAS were however limited to narrowband channels. Motivated by this, this paper addresses the integration of FAS in the fifth generation (5G) orthogonal frequency division multiplexing (OFDM) framework to address the challenges posed by wideband communications. We propose the framework of the wideband FAS OFDM system that includes a novel port selection matrix. Then we derive the achievable rate expression and design the adaptive modulation and coding (AMC) scheme based on the rate. Extensive link-level simulation results demonstrate striking improvements of FAS in the wideband channels, underscoring the potential of FAS in future wireless communications.

Paper number 32:
Title: Data-Driven Decision Making for Enhancing Small-Signal Stability in Hybrid AC/DC Grids Through Converter Control Role Assignment
Authors: Francesca Rossi, Sergi Costa Dilme, Josep Arevalo-Soler, Eduardo Prieto-Araujo, Oriol Gomis-Bellmunt
Abstract: Hybrid AC/DC transmission grids incorporate Modular Multilevel Converters functioning as Interconnecting Power Converters (IPCs). The control role assigned to each converter significantly influences grid dynamics. Traditionally, these converters operate with static control roles, but recent studies have proposed scheduling their roles based on day-ahead forecasts to enhance stability performance. However, in systems with high renewable energy penetration, forecast deviations can render scheduled control assignments suboptimal or even lead to instability. To address this challenge, this work proposes an online scheduling recalculation algorithm that dynamically adapts IPC control roles during system operation. The approach leverages a data-driven multi-criteria decision-making framework, integrating surrogate models of conventional small-signal stability analysis tools to enable a fast computation of system stability and stability performance indicators.

Paper number 33:
Title: Quantitative Decentralized Stability Certificates for Grid-Forming Converter Control
Authors: Verena Häberle, Xiuqiang He, Linbin Huang, Florian Dörfler, Steven Low
Abstract: We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.

Paper number 34:
Title: Energy-Free Sensing and Context Recognition Using Photovoltaic Cells
Authors: Kaede Shintani, Hamada Rizk, Hirozumi Yamaguchi
Abstract: The field of energy-free sensing and context recognition has recently gained significant attention as it allows operating systems without external power sources. Photovoltaic cells can convert light energy into electrical energy to power sensing devices, but their power may not be sufficient to ensure energy-free sensing due to the varying power needs of sensors and high computational demands. In this paper, we propose the use of photovoltaic cells as a standalone sensor for the recognition of different contexts, including user identification, step counting, and location tracking. The system utilizes the photocurrent readings generated by the photovoltaic cells to capture the unique mobility patterns of different users. By analyzing these patterns, the system can accurately identify the user, count the number of steps taken, and track the user's location. We propose a computationally efficient DTW to match the variable length sequences of photocurrent readings to a database of known patterns and identify the closest subject and location matches. The system was rigorously evaluated in a realistic environment, and the results indicate that it can accurately estimate step count, identify subjects, and localize them with an accuracy of 88%, 90%, and 43cm, respectively. This is achieved while the proposed system is non-intrusive and can operate without external power sources, making it a promising technology for energy-free sensing and context recognition.

Paper number 35:
Title: A Hybrid Approach for Extending Automotive Radar Operation to NLOS Urban Scenarios
Authors: Aviran Gal, Igal Bilik
Abstract: Automotive radar is a key component of sensing suites in autonomous driving (AD) and advanced driver-assist systems (ADAS). However, limited line-of-sight (LOS) significantly reduces radar efficiency in dense urban environments. Therefore, automotive radars need to extend their capabilities beyond LOS by localizing occluding and reflective surfaces and non-line-of-sight (NLOS) targets. This work addresses the NLOS target localization challenge by revisiting the NLOS radar signal propagation model and introducing a hybrid localization approach. The proposed approach first detects and localizes reflective surfaces, then identifies the LOS/NLOS propagation conditions, and finally localizes the target without prior scene knowledge, without using Doppler information, and without any auxiliary sensors. The proposed hybrid approach addresses the computational complexity challenge by integrating a physical radar electromagnetic wave propagation model with a deep neural network (DNN) to estimate occluding surface parameters. The efficiency of the proposed approach to localize the NLOS targets and to identify the NLOS/LOS propagation conditions is evaluated via simulations in a broad range of realistic automotive scenarios. Extending automotive radar sensing beyond LOS is expected to enhance the safety and reliability of autonomous and ADAS-equipped vehicles.

Paper number 36:
Title: Hiding in Plain Sight: RIS-Aided Target Obfuscation in ISAC
Authors: Ahmed Magbool, Vaibhav Kumar, Marco Di Renzo, Mark F. Flanagan
Abstract: Integrated sensing and communication (ISAC) has been identified as a promising technology for the sixth generation (6G) of communication networks. Target privacy in ISAC is essential to ensure that only legitimate sensors can detect the target while keeping it hidden from malicious ones. In this paper, we consider a downlink reconfigurable intelligent surface (RIS)-assisted ISAC system capable of protecting a sensing region against an adversarial detector. The RIS consists of both reflecting and sensing elements, adaptively changing the element assignment based on system needs. To achieve this, we minimize the maximum sensing signal-to-interference-plus-noise-ratio (SINR) at the adversarial detector within sample points in the sensing region, by optimizing the transmit beamformer at the base station, the RIS phase shift matrix, the received beamformer at the RIS, and the division between reflecting and absorptive elements at the RIS, where the latter function as sensing elements. At the same time, the system is designed to maintain a minimum sensing SINR at each monitored location, as well as minimum communication SINR for each user. To solve this challenging optimization problem, we develop an alternating optimization approach combined with a successive convex approximation based method tailored for each subproblem. Our results show that the proposed approach achieves a 25 dB reduction in the maximum sensing SINR at the adversarial detector compared to scenarios without sensing area protection. Also, the optimal RIS element assignment can further improve sensing protection by 3 dB over RISs with fixed element configuration.

Paper number 37:
Title: Game Theory in Formula 1: Multi-agent Physical and Strategical Interactions
Authors: Giona Fienia, Marc-Philippe Neumann, Francesca Furia, Alessandro Caucino, Alberto Cerofolini, Vittorio Ravaglioli, Christopher H. Onder
Abstract: This paper presents an optimization framework for Formula 1 racing that integrates multi-agent interactions, aerodynamic wake effects, trajectory optimization, and energy management. By employing game-theoretic methods, we formulate the minimum lap time problem as either a Nash or a Stackelberg game. Exploiting their structural similarities, we compare symmetric and hierarchical strategies to analyze competitive racing dynamics and strategic dominance. Additionally, we introduce an algorithm to refine local Stackelberg solutions. Our findings underscore the importance of jointly optimizing physical interactions, energy management, and trajectory, highlighting their strong interdependence. We examine the impact of slipstreaming on trajectory selection in corners, straights, and high-speed sections, while also identifying optimal overtaking locations based on energy allocation strategies. By incorporating a physically accurate interaction model and accounting for the optimal responses of competing agents, our approach reveals characteristic strategic behaviors observed in real-world racing. The proposed methodology contributes towards realistic Formula 1 race strategy optimizations, with potential applications in motorsport engineering and autonomous racing.

Paper number 38:
Title: Generating Building-Level Heat Demand Time Series by Combining Occupancy Simulations and Thermal Modeling
Authors: Simon Malacek, José Portela, Yannick Marcus Werner, Sonja Wogrin
Abstract: Despite various efforts, decarbonizing the heating sector remains a significant challenge. To tackle it by smart planning, the availability of highly resolved heating demand data is key. Several existing models provide heating demand only for specific applications. Typically, they either offer time series for a larger area or annual demand data on a building level, but not both simultaneously. Additionally, the diversity in heating demand across different buildings is often not considered. To address these limitations, this paper presents a novel method for generating temporally resolved heat demand time series at the building level using publicly available data. The approach integrates a thermal building model with stochastic occupancy simulations that account for variability in user behavior. As a result, the tool serves as a cost-effective resource for cross-sectoral energy system planning and policy development, particularly with a focus on the heating sector. The obtained data can be used to assess the impact of renovation and retrofitting strategies, or to analyze district heating expansion. To illustrate the potential applications of this approach, we conducted a case study in Puertollano (Spain), where we prepared a dataset of heating demand with hourly resolution for each of 9,298 residential buildings. This data was then used to compare two different pathways for the thermal renovation of these buildings. By relying on publicly available data, this method can be adapted and applied to various European regions, offering broad usability in energy system optimization and analysis of decarbonization strategies.

Paper number 39:
Title: Deep Frequency Attention Networks for Single Snapshot Sparse Array Interpolation
Authors: Ruxin Zheng, Shunqiao Sun, Hongshan Liu
Abstract: Sparse arrays have been widely exploited in radar systems because of their advantages in achieving large array aperture at low hardware cost, while significantly reducing mutual coupling. However, sparse arrays suffer from high sidelobes which may lead to false detections. Missing elements in sparse arrays can be interpolated using the sparse array measurements. In snapshot-limited scenarios, such as automotive radar, it is challenging to utilize difference coarrays which require a large number of snapshots to construct a covariance matrix for interpolation. For single snapshot sparse array interpolation, traditional model-based methods, while effective, require expert knowledge for hyperparameter tuning, lack task-specific adaptability, and incur high computational costs. In this paper, we propose a novel deep learning-based single snapshot sparse array interpolation network that addresses these challenges by leveraging a frequency-domain attention mechanism. The proposed approach transforms the sparse signal into the frequency domain, where the attention mechanism focuses on key spectral regions, enabling improved interpolation of missing elements even in low signal-to-noise ratio (SNR) conditions. By minimizing computational costs and enhancing interpolation accuracy, the proposed method demonstrates superior performance compared to traditional approaches, making it well-suited for automotive radar applications.

Paper number 40:
Title: Noise-Robust Radio Frequency Fingerprint Identification Using Denoise Diffusion Model
Authors: Guolin Yin, Junqing Zhang, Yuan Ding, Simon Cotton
Abstract: Securing Internet of Things (IoT) devices presents increasing challenges due to their limited computational and energy resources. Radio Frequency Fingerprint Identification (RFFI) emerges as a promising authentication technique to identify wireless devices through hardware impairments. RFFI performance under low signal-to-noise ratio (SNR) scenarios is significantly degraded because the minute hardware features can be easily swamped in noise. In this paper, we leveraged the diffusion model to effectively restore the RFF under low SNR scenarios. Specifically, we trained a powerful noise predictor and tailored a noise removal algorithm to effectively reduce the noise level in the received signal and restore the device fingerprints. We used Wi-Fi as a case study and created a testbed involving 6 commercial off-the-shelf Wi-Fi dongles and a USRP N210 software-defined radio (SDR) platform. We conducted experimental evaluations on various SNR scenarios. The experimental results show that the proposed algorithm can improve the classification accuracy by up to 34.9%.

Paper number 41:
Title: Revisiting Beamforming Design for Stable Millimeter-Wave Communications Under Blockages
Authors: Kanta Terui, Kabuto Arai, Koji Ishibashi
Abstract: This study examines analog beamforming designs utilizing multi-panel arrays for millimeter-wave (mmWave) communication systems under stochastic path blockages where each panel is an integrated circuit that includes power amplifiers, a limited number of antenna elements, and the corresponding phase shifters. In existing commercial mmWave systems, analog beams are typically designed by leveraging all panels cooperatively to align with the line-of-sight (LoS) path, thereby maximizing array gain. Although this beam design is effective in static channels, it is highly susceptible to frequent link disconnections caused by sudden path blockages. To address this challenge, the present study revisits the design of analog beamforming and proposes a multi-beam approach using multi-panel arrays to enhance robustness to path blockages. To evaluate the performance of the multi-beam with multimodal directivity, a theoretical analysis of the outage probability of the spectral efficiency (SE) is conducted. To design the optimal multi-beam based on the derived outage probability, we formulate a panel allocation problem to determine the assignment of panels to specific paths, including both LoS and non-line-of-sight (NLoS) paths. Numerical simulations confirm that the optimal beam, at high target SE, comprises a single sharp beam aligned to the LoS path to maximize array gain, whereas the optimal beam at low target SE is a multi-beam aligned to both the LoS and NLoS paths to acquire spatial diversity. These results demonstrate that the proposed multi-beam design, which utilizes multiple paths, effectively enhances the stability of mmWave communications while ensuring a minimum required performance level.

Paper number 42:
Title: State-of-the-Art Stroke Lesion Segmentation at 1/1000th of Parameters
Authors: Alex Fedorov, Yutong Bu, Xiao Hu, Chris Rorden, Sergey Plis
Abstract: Efficient and accurate whole-brain lesion segmentation remains a challenge in medical image analysis. In this work, we revisit MeshNet, a parameter-efficient segmentation model, and introduce a novel multi-scale dilation pattern with an encoder-decoder structure. This innovation enables capturing broad contextual information and fine-grained details without traditional downsampling, upsampling, or skip-connections. Unlike previous approaches processing subvolumes or slices, we operate directly on whole-brain $256^3$ MRI volumes. Evaluations on the Aphasia Recovery Cohort (ARC) dataset demonstrate that MeshNet achieves superior or comparable DICE scores to state-of-the-art architectures such as MedNeXt and U-MAMBA at 1/1000th of parameters. Our results validate MeshNet's strong balance of efficiency and performance, making it particularly suitable for resource-limited environments such as web-based applications and opening new possibilities for the widespread deployment of advanced medical image analysis tools.

Paper number 43:
Title: Towards Effective and Efficient Context-aware Nucleus Detection in Histopathology Whole Slide Images
Authors: Zhongyi Shui, Ruizhe Guo, Honglin Li, Yuxuan Sun, Yunlong Zhang, Chenglu Zhu, Jiatong Cai, Pingyi Chen, Yanzhou Su, Lin Yang
Abstract: Nucleus detection in histopathology whole slide images (WSIs) is crucial for a broad spectrum of clinical applications. Current approaches for nucleus detection in gigapixel WSIs utilize a sliding window methodology, which overlooks boarder contextual information (eg, tissue structure) and easily leads to inaccurate predictions. To address this problem, recent studies additionally crops a large Filed-of-View (FoV) region around each sliding window to extract contextual features. However, such methods substantially increases the inference latency. In this paper, we propose an effective and efficient context-aware nucleus detection algorithm. Specifically, instead of leveraging large FoV regions, we aggregate contextual clues from off-the-shelf features of historically visited sliding windows. This design greatly reduces computational overhead. Moreover, compared to large FoV regions at a low magnification, the sliding window patches have higher magnification and provide finer-grained tissue details, thereby enhancing the detection accuracy. To further improve the efficiency, we propose a grid pooling technique to compress dense feature maps of each patch into a few contextual tokens. Finally, we craft OCELOT-seg, the first benchmark dedicated to context-aware nucleus instance segmentation. Code, dataset, and model checkpoints will be available at this https URL.

Paper number 44:
Title: Task-oriented Uncertainty Collaborative Learning for Label-Efficient Brain Tumor Segmentation
Authors: Zhenxuan Zhang, Hongjie Wu, Jiahao Huang, Baihong Xie, Zhifan Gao, Junxian Du, Pete Lally, Guang Yang
Abstract: Multi-contrast magnetic resonance imaging (MRI) plays a vital role in brain tumor segmentation and diagnosis by leveraging complementary information from different contrasts. Each contrast highlights specific tumor characteristics, enabling a comprehensive understanding of tumor morphology, edema, and pathological heterogeneity. However, existing methods still face the challenges of multi-level specificity perception across different contrasts, especially with limited annotations. These challenges include data heterogeneity, granularity differences, and interference from redundant information. To address these limitations, we propose a Task-oriented Uncertainty Collaborative Learning (TUCL) framework for multi-contrast MRI segmentation. TUCL introduces a task-oriented prompt attention (TPA) module with intra-prompt and cross-prompt attention mechanisms to dynamically model feature interactions across contrasts and tasks. Additionally, a cyclic process is designed to map the predictions back to the prompt to ensure that the prompts are effectively utilized. In the decoding stage, the TUCL framework proposes a dual-path uncertainty refinement (DUR) strategy which ensures robust segmentation by refining predictions iteratively. Extensive experimental results on limited labeled data demonstrate that TUCL significantly improves segmentation accuracy (88.2\% in Dice and 10.853 mm in HD95). It shows that TUCL has the potential to extract multi-contrast information and reduce the reliance on extensive annotations. The code is available at: this https URL.

Paper number 45:
Title: Electricity Demand Forecasting in Future Grid States: A Digital Twin-Based Simulation Study
Authors: Daniel R. Bayer, Felix Haag, Marco Pruckner, Konstantin Hopf
Abstract: Short-term forecasting of residential electricity demand is an important task for utilities. Yet, many small and medium-sized utilities still use simple forecasting approaches such as Synthesized Load Profiles, which treat residential households similarly and neither account for renewable energy installations nor novel large consumers (e.g., heat pumps, electric vehicles). The effectiveness of such "one-fits-all" approaches in future grid states--where decentral generation and sector coupling increases--are questionable. Our study challenges these forecasting practices and investigates whether Machine Learning (ML) approaches are suited to predict electricity demand in today's and in future grid states. We use real smart meter data from 3,511 households in Germany over 34 months. We extrapolate this data with future grid states (i.e., increased decentral generation and storage) based on a digital twin of a local energy system. Our results show that Long Short-Term Memory (LSTM) approaches outperform SLPs as well as simple benchmark estimators with up to 68.5% lower Root Mean Squared Error for a day-ahead forecast, especially in future grid states. Nevertheless, all prediction approaches perform worse in future grid states. Our findings therefore reinforce the need (a) for utilities and grid operators to employ ML approaches instead of traditional demand prediction methods in future grid states and (b) to prepare current ML methods for future grid states.

Paper number 46:
Title: Safety Verification of Stochastic Systems under Signal Temporal Logic Specifications
Authors: Liqian Ma, Zishun Liu, Hongzhe Yu, Yongxin Chen
Abstract: We study the verification problem of stochastic systems under signal temporal logic (STL) specifications. We propose a novel approach that enables the verification of the probabilistic satisfaction of STL specifications for nonlinear systems subject to both bounded deterministic disturbances and stochastic disturbances. Our method, referred to as the STL erosion strategy, reduces the probabilistic verification problem into a deterministic verification problem with a tighter STL specification. The degree of tightening is determined by leveraging recent results on bounding the deviation between the stochastic trajectory and the deterministic trajectory. Our approach can be seamlessly integrated with any existing deterministic STL verification algorithm. Numerical experiments are conducted to showcase the efficacy of our method.

Paper number 47:
Title: Direct Speech to Speech Translation: A Review
Authors: Mohammad Sarim, Saim Shakeel, Laeeba Javed, Jamaluddin, Mohammad Nadeem
Abstract: Speech to speech translation (S2ST) is a transformative technology that bridges global communication gaps, enabling real time multilingual interactions in diplomacy, tourism, and international trade. Our review examines the evolution of S2ST, comparing traditional cascade models which rely on automatic speech recognition (ASR), machine translation (MT), and text to speech (TTS) components with newer end to end and direct speech translation (DST) models that bypass intermediate text representations. While cascade models offer modularity and optimized components, they suffer from error propagation, increased latency, and loss of prosody. In contrast, direct S2ST models retain speaker identity, reduce latency, and improve translation naturalness by preserving vocal characteristics and prosody. However, they remain limited by data sparsity, high computational costs, and generalization challenges for low-resource languages. The current work critically evaluates these approaches, their tradeoffs, and future directions for improving real time multilingual communication.

Paper number 48:
Title: ZAugNet for Z-Slice Augmentation in Bio-Imaging
Authors: Alessandro Pasqui, Sajjad Mahdavi, Benoit Vianay, Alexandra Colin, Alex McDougall, Rémi Dumollard, Yekaterina A. Miroshnikova, Elsa Labrune, Hervé Turlier
Abstract: Three-dimensional biological microscopy has significantly advanced our understanding of complex biological structures. However, limitations due to microscopy techniques, sample properties or phototoxicity often result in poor z-resolution, hindering accurate cellular measurements. Here, we introduce ZAugNet, a fast, accurate, and self-supervised deep learning method for enhancing z-resolution in biological images. By performing nonlinear interpolation between consecutive slices, ZAugNet effectively doubles resolution with each iteration. Compared on several microscopy modalities and biological objects, it outperforms competing methods on most metrics. Our method leverages a generative adversarial network (GAN) architecture combined with knowledge distillation to maximize prediction speed without compromising accuracy. We also developed ZAugNet+, an extended version enabling continuous interpolation at arbitrary distances, making it particularly useful for datasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide high-performance, scalable z-slice augmentation solutions for large-scale 3D imaging. They are available as open-source frameworks in PyTorch, with an intuitive Colab notebook interface for easy access by the scientific community.

Paper number 49:
Title: End-to-End Human Pose Reconstruction from Wearable Sensors for 6G Extended Reality Systems
Authors: Nguyen Quang Hieu, Dinh Thai Hoang, Diep N. Nguyen, Mohammad Abu Alsheikh, Carlos C. N. Kuhn, Yibeltal F. Alem, Ibrahim Radwan
Abstract: Full 3D human pose reconstruction is a critical enabler for extended reality (XR) applications in future sixth generation (6G) networks, supporting immersive interactions in gaming, virtual meetings, and remote collaboration. However, achieving accurate pose reconstruction over wireless networks remains challenging due to channel impairments, bit errors, and quantization effects. Existing approaches often assume error-free transmission in indoor settings, limiting their applicability to real-world scenarios. To address these challenges, we propose a novel deep learning-based framework for human pose reconstruction over orthogonal frequency-division multiplexing (OFDM) systems. The framework introduces a two-stage deep learning receiver: the first stage jointly estimates the wireless channel and decodes OFDM symbols, and the second stage maps the received sensor signals to full 3D body poses. Simulation results demonstrate that the proposed neural receiver reduces bit error rate (BER), thus gaining a 5 dB gap at $10^{-4}$ BER, compared to the baseline method that employs separate signal detection steps, i.e., least squares channel estimation and linear minimum mean square error equalization. Additionally, our empirical findings show that 8-bit quantization is sufficient for accurate pose reconstruction, achieving a mean squared error of $5\times10^{-4}$ for reconstructed sensor signals, and reducing joint angular error by 37\% for the reconstructed human poses compared to the baseline.

Paper number 50:
Title: Toward Lightweight and Fast Decoders for Diffusion Models in Image and Video Generation
Authors: Alexey Buzovkin, Evgeny Shilov
Abstract: We investigate methods to reduce inference time and memory footprint in stable diffusion models by introducing lightweight decoders for both image and video synthesis. Traditional latent diffusion pipelines rely on large Variational Autoencoder decoders that can slow down generation and consume considerable GPU memory. We propose custom-trained decoders using lightweight Vision Transformer and Taming Transformer architectures. Experiments show up to 15% overall speed-ups for image generation on COCO2017 and up to 20 times faster decoding in the sub-module, with additional gains on UCF-101 for video tasks. Memory requirements are moderately reduced, and while there is a small drop in perceptual quality compared to the default decoder, the improvements in speed and scalability are crucial for large-scale inference scenarios such as generating 100K images. Our work is further contextualized by advances in efficient video generation, including dual masking strategies, illustrating a broader effort to improve the scalability and efficiency of generative models.

Paper number 51:
Title: Extended Version: Non-Preemptive Scheduling of Flexible Loads in Smart Grids via Convex Optimization
Authors: Mehdi Davoudi, Mingyu Chen, Junjie Qin
Abstract: This paper studies the scheduling of a large population of non-preemptive flexible electric loads, each of which has a flexible starting time but once started will follow a fixed load shape until completion. We first formulate the scheduling problem as a mixed-integer convex program (MICP), then propose an efficient polynomial time relaxation-adjustment-rounding algorithm for solving the problem. The key novelty of the proposed method lies in its adjustment step, which uses a graph-based algorithm to navigate within the set of optimal points of the convex relaxation while reducing the number of fractional entries in the solution. We establish mathematically that our algorithm yields solutions that are near optimal for a finite number of loads and with its sub-optimality independent of the number of loads. Consequently, the proposed method is asymptotically optimal in a per-load cost sense when the number of loads increases. Despite the gap between the MICP and its convex relaxation, we establish that the solution of the proposed algorithm can be decentralized by marginal prices of the convex relaxation. We also develop and analyze variants of the proposed algorithm for settings with uncertainty and with time-varying realistic load shapes. Finally, we numerically evaluate the proposed algorithm in a case study for the non-preemptive scheduling of electric vehicles charging loads.

Paper number 52:
Title: Neural Configuration-Space Barriers for Manipulation Planning and Control
Authors: Kehan Long, Ki Myung Brian Lee, Nikola Raicevic, Niyas Attasseri, Melvin Leok, Nikolay Atanasov
Abstract: Planning and control for high-dimensional robot manipulators in cluttered, dynamic environments require both computational efficiency and robust safety guarantees. Inspired by recent advances in learning configuration-space distance functions (CDFs) as robot body representations, we propose a unified framework for motion planning and control that formulates safety constraints as CDF barriers. A CDF barrier approximates the local free configuration space, substantially reducing the number of collision-checking operations during motion planning. However, learning a CDF barrier with a neural network and relying on online sensor observations introduce uncertainties that must be considered during control synthesis. To address this, we develop a distributionally robust CDF barrier formulation for control that explicitly accounts for modeling errors and sensor noise without assuming a known underlying distribution. Simulations and hardware experiments on a 6-DoF xArm manipulator show that our neural CDF barrier formulation enables efficient planning and robust real-time safe control in cluttered and dynamic environments, relying only on onboard point-cloud observations.

Paper number 53:
Title: Eliminating Phase Misalignments in Cell-Free Massive MIMO via Differential Transmission
Authors: Marx M.M. Freitas, Stefano Buzzi, Giovanni Interdonato
Abstract: This paper proposes two approaches for overcoming access points' phase misalignment effects in the downlink of cell-free massive MIMO (CF-mMIMO) systems. The first approach is based on the differential space-time block coding technique, while the second one is based on the use of differential modulation schemes. Both approaches are shown to perform exceptionally well and to restore system performance in CF-mMIMO systems where phase alignment at the access points for downlink joint coherent transmission cannot be achieved.

Paper number 54:
Title: Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator
Authors: R. Spencer Hallyburton, Miroslav Pajic
Abstract: Lacking security awareness, sensor fusion in systems with multi-agent networks such as smart cities is vulnerable to attacks. To guard against recent threats, we design security-aware sensor fusion that is based on the estimates of distributions over trust. Trust estimation can be cast as a hidden Markov model, and we solve it by mapping sensor data to trust pseudomeasurements (PSMs) that recursively update trust posteriors in a Bayesian context. Trust then feeds sensor fusion to facilitate trust-weighted updates to situational awareness. Essential to security-awareness are a novel field of view estimator, logic to map sensor data into PSMs, and the derivation of efficient Bayesian updates. We evaluate security-aware fusion under attacks on agents using case studies and Monte Carlo simulation in the physics-based Unreal Engine simulator, CARLA. A mix of novel and classical security-relevant metrics show that our security-aware fusion enables building trustworthy situational awareness even in hostile conditions.

Paper number 55:
Title: S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following with Paralinguistic Information
Authors: Feng Jiang, Zhiyu Lin, Fan Bu, Yuhao Du, Benyou Wang, Haizhou Li
Abstract: The rapid development of large language models (LLMs) has brought significant attention to speech models, particularly recent progress in speech2speech protocols supporting speech input and output. However, the existing benchmarks adopt automatic text-based evaluators for evaluating the instruction following ability of these models lack consideration for paralinguistic information in both speech understanding and generation. To address these issues, we introduce S2S-Arena, a novel arena-style S2S benchmark that evaluates instruction-following capabilities with paralinguistic information in both speech-in and speech-out across real-world tasks. We design 154 samples that fused TTS and live recordings in four domains with 21 tasks and manually evaluate existing popular speech models in an arena-style manner. The experimental results show that: (1) in addition to the superior performance of GPT-4o, the speech model of cascaded ASR, LLM, and TTS outperforms the jointly trained model after text-speech alignment in speech2speech protocols; (2) considering paralinguistic information, the knowledgeability of the speech model mainly depends on the LLM backbone, and the multilingual support of that is limited by the speech module; (3) excellent speech models can already understand the paralinguistic information in speech input, but generating appropriate audio with paralinguistic information is still a challenge.

Paper number 56:
Title: UniArray: Unified Spectral-Spatial Modeling for Array-Geometry-Agnostic Speech Separation
Authors: Weiguang Chen, Junjie Zhang, Jielong Yang, Eng Siong Chng, Xionghu Zhong
Abstract: Array-geometry-agnostic speech separation (AGA-SS) aims to develop an effective separation method regardless of the microphone array geometry. Conventional methods rely on permutation-free operations, such as summation or attention mechanisms, to capture spatial information. However, these approaches often incur high computational costs or disrupt the effective use of spatial information during intra- and inter-channel interactions, leading to suboptimal performance. To address these issues, we propose UniArray, a novel approach that abandons the conventional interleaving manner. UniArray consists of three key components: a virtual microphone estimation (VME) module, a feature extraction and fusion module, and a hierarchical dual-path separator. The VME ensures robust performance across arrays with varying channel numbers. The feature extraction and fusion module leverages a spectral feature extraction module and a spatial dictionary learning (SDL) module to extract and fuse frequency-bin-level features, allowing the separator to focus on using the fused features. The hierarchical dual-path separator models feature dependencies along the time and frequency axes while maintaining computational efficiency. Experimental results show that UniArray outperforms state-of-the-art methods in SI-SDRi, WB-PESQ, NB-PESQ, and STOI across both seen and unseen array geometries.

Paper number 57:
Title: DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility
Authors: Yifan Liu, Yu Fang, Zhouhan Lin
Abstract: Video-to-speech (V2S) synthesis, the task of generating speech directly from silent video input, is inherently more challenging than other speech synthesis tasks due to the need to accurately reconstruct both speech content and speaker characteristics from visual cues alone. Recently, audio-visual pre-training has eliminated the need for additional acoustic hints in V2S, which previous methods often relied on to ensure training convergence. However, even with pre-training, existing methods continue to face challenges in achieving a balance between acoustic intelligibility and the preservation of speaker-specific characteristics. We analyzed this limitation and were motivated to introduce DiVISe (Direct Visual-Input Speech Synthesis), an end-to-end V2S model that predicts Mel-spectrograms directly from video frames alone. Despite not taking any acoustic hints, DiVISe effectively preserves speaker characteristics in the generated audio, and achieves superior performance on both objective and subjective metrics across the LRS2 and LRS3 datasets. Our results demonstrate that DiVISe not only outperforms existing V2S models in acoustic intelligibility but also scales more effectively with increased data and model parameters. Code and weights can be found at this https URL.

Paper number 58:
Title: Attenuation artifact detection and severity classification in intracoronary OCT using mixed image representations
Authors: Pierandrea Cancian, Simone Saitta, Xiaojin Gu, Rudolf L.M. van Herten, Thijs J. Luttikholt, Jos Thannhauser, Rick H.J.A. Volleberg, Ruben G.A. van der Waerden, Joske L. van der Zande, Clarisa I. Sánchez, Bram van Ginneken, Niels van Royen, Ivana Išgum
Abstract: In intracoronary optical coherence tomography (OCT), blood residues and gas bubbles cause attenuation artifacts that can obscure critical vessel structures. The presence and severity of these artifacts may warrant re-acquisition, prolonging procedure time and increasing use of contrast agent. Accurate detection of these artifacts can guide targeted re-acquisition, reducing the amount of repeated scans needed to achieve diagnostically viable images. However, the highly heterogeneous appearance of these artifacts poses a challenge for the automated detection of the affected image regions. To enable automatic detection of the attenuation artifacts caused by blood residues and gas bubbles based on their severity, we propose a convolutional neural network that performs classification of the attenuation lines (A-lines) into three classes: no artifact, mild artifact and severe artifact. Our model extracts and merges features from OCT images in both Cartesian and polar coordinates, where each column of the image represents an A-line. Our method detects the presence of attenuation artifacts in OCT frames reaching F-scores of 0.77 and 0.94 for mild and severe artifacts, respectively. The inference time over a full OCT scan is approximately 6 seconds. Our experiments show that analysis of images represented in both Cartesian and polar coordinate systems outperforms the analysis in polar coordinates only, suggesting that these representations contain complementary features. This work lays the foundation for automated artifact assessment and image acquisition guidance in intracoronary OCT imaging.

Paper number 59:
Title: Wi-Fi 6 Cross-Technology Interference Detection and Mitigation by OFDMA: an Experimental Study
Authors: Thijs Havinga, Xianjun Jiao, Wei Liu, Baiheng Chen, Adnan Shahid, Ingrid Moerman
Abstract: Cross-Technology Interference (CTI) poses challenges for the performance and robustness of wireless networks. There are opportunities for better cooperation if the spectral occupation and technology of the interference can be detected. Namely, this information can help the Orthogonal Frequency Division Multiple Access (OFDMA) scheduler in IEEE 802.11ax (Wi-Fi 6) to efficiently allocate resources to multiple users inthe frequency domain. This work shows that a single Channel State Information (CSI) snapshot, which is used for packet demodulation in the receiver, is enough to detect and classify the type of CTI on low-cost Wi-Fi 6 hardware. We show the classification accuracy of a small Convolutional Neural Network (CNN) for different Signal-to-Noise Ratio (SNR) and Signal-to-Interference Ratio (SIR) with simulated data, as well as using a wired and over-the-air test with a professional wireless connectivity tester, while running the inference on the low-cost device. Furthermore, we use openwifi, a full-stack Wi-Fi transceiver running on software-defined radio (SDR) available in the w-iLab.t testbed, as Access Point (AP) to implement a CTI-aware multi-user OFDMA scheduler when the clients send CTI detection feedback to the AP. We show experimentally that it can fully mitigate the 35% throughput loss caused by CTI when the AP applies the appropriate scheduling.

Paper number 60:
Title: RiLoCo: An ISAC-oriented AI Solution to Build RIS-empowered Networks
Authors: Guillermo Encinas-Lago, Vincenzo Sciancalepore, Henk Wymeersch, Marco Di Renzo, Xavier Costa-Perez
Abstract: The advance towards 6G networks comes with the promise of unprecedented performance in sensing and communication capabilities. The feat of achieving those, while satisfying the ever-growing demands placed on wireless networks, promises revolutionary advancements in sensing and communication technologies. As 6G aims to cater to the growing demands of wireless network users, the implementation of intelligent and efficient solutions becomes essential. In particular, reconfigurable intelligent surfaces (RISs), also known as Smart Surfaces, are envisioned as a transformative technology for future 6G networks. The performance of RISs when used to augment existing devices is nevertheless largely affected by their precise location. Suboptimal deployments are also costly to correct, negating their low-cost benefits. This paper investigates the topic of optimal RISs diffusion, taking into account the improvement they provide both for the sensing and communication capabilities of the infrastructure while working with other antennas and sensors. We develop a combined metric that takes into account the properties and location of the individual devices to compute the performance of the entire infrastructure. We then use it as a foundation to build a reinforcement learning architecture that solves the RIS deployment problem. Since our metric measures the surface where given localization thresholds are achieved and the communication coverage of the area of interest, the novel framework we provide is able to seamlessly balance sensing and communication, showing its performance gain against reference solutions, where it achieves simultaneously almost the reference performance for communication and the reference performance for localization.

Paper number 61:
Title: Adaptive Neural Unscented Kalman Filter
Authors: Amit Levy, Itzik Klein
Abstract: The unscented Kalman filter is an algorithm capable of handling nonlinear scenarios. Uncertainty in process noise covariance may decrease the filter estimation performance or even lead to its divergence. Therefore, it is important to adjust the process noise covariance matrix in real time. In this paper, we developed an adaptive neural unscented Kalman filter to cope with time-varying uncertainties during platform operation. To this end, we devised ProcessNet, a simple yet efficient end-to-end regression network to adaptively estimate the process noise covariance matrix. We focused on the nonlinear inertial sensor and Doppler velocity log fusion problem in the case of autonomous underwater vehicle navigation. Using a real-world recorded dataset from an autonomous underwater vehicle, we demonstrated our filter performance and showed its advantages over other adaptive and non-adaptive nonlinear filters.

Paper number 62:
Title: Design, Dynamic Modeling and Control of a 2-DOF Robotic Wrist Actuated by Twisted and Coiled Actuators
Authors: Yunsong Zhang, Xinyu Zhou, Feitian Zhang
Abstract: Robotic wrists play a pivotal role in the functionality of industrial manipulators and humanoid robots, facilitating manipulation and grasping tasks. In recent years, there has been a growing interest in integrating artificial muscle-driven actuators for robotic wrists, driven by advancements in technology offering high energy density, lightweight construction, and compact designs. However, in the study of robotic wrists driven by artificial muscles, dynamic model-based controllers are often overlooked, despite their critical importance for motion analysis and dynamic control of robots. This paper presents a novel design of a two-degree-of-freedom (2-DOF) robotic wrist driven by twisted and coiled actuators (TCA) utilizing a parallel mechanism with a 3RRRR configuration. The proposed robotic wrist is expected to feature lightweight structures and superior motion performance while mitigating friction issues. The Lagrangian dynamic model of the wrist is established, along with a nonlinear model predictive controller (NMPC) designed for trajectory tracking tasks. A prototype of the robotic wrist is developed, and extensive experiments are conducted to validate its superior motion performance and the proposed dynamic model. Subsequently, extensive comparative experiments between NMPC and PID controller were conducted under various operating conditions. The experimental results demonstrate the effectiveness and robustness of the dynamic model-based controller in the motion control of TCA-driven robotic wrists.

Paper number 63:
Title: Kinodynamic Model Predictive Control for Energy Efficient Locomotion of Legged Robots with Parallel Elasticity
Authors: Yulun Zhuang, Yichen Wang, Yanran Ding
Abstract: In this paper, we introduce a kinodynamic model predictive control (MPC) framework that exploits unidirectional parallel springs (UPS) to improve the energy efficiency of dynamic legged robots. The proposed method employs a hierarchical control structure, where the solution of MPC with simplified dynamic models is used to warm-start the kinodynamic MPC, which accounts for nonlinear centroidal dynamics and kinematic constraints. The proposed approach enables energy efficient dynamic hopping on legged robots by using UPS to reduce peak motor torques and energy consumption during stance phases. Simulation results demonstrated a 38.8% reduction in the cost of transport (CoT) for a monoped robot equipped with UPS during high-speed hopping. Additionally, preliminary hardware experiments show a 14.8% reduction in energy consumption. Video: this https URL

Paper number 64:
Title: Uncertainty Propagation and Bayesian Fusion on Unimodular Lie Groups from a Parametric Perspective
Authors: Jikai Ye, Gregory S. Chirikjian
Abstract: We address the problem of uncertainty propagation and Bayesian fusion on unimodular Lie groups. Starting from a stochastic differential equation (SDE) defined on Lie groups via Mckean-Gangolli injection, we first convert it to a parametric SDE in exponential coordinates. The coefficient transform method for the conversion is stated for both Ito's and Stratonovich's interpretation of the SDE. Then we derive a mean and covariance fitting formula for probability distributions on Lie groups defined by a concentrated distribution on the exponential coordinate. It is used to derive the mean and covariance propagation equations for the SDE defined by injection, which coincides with the result derived from a Fokker-Planck equation in previous work. We also propose a simple modification to the update step of Kalman filters using the fitting formula, which improves the fusion accuracy with moderate computation time.

Paper number 65:
Title: A Survey on Detection, Classification, and Tracking of UAVs using Radar and Communications Systems
Authors: Wahab Khawaja, Martins Ezuma, Vasilii Semkin, Fatih Erden, Ozgur Ozdemir, Ismail Guvenc
Abstract: The use of unmanned aerial vehicles (UAVs) for a variety of commercial, civilian, and defense applications has increased many folds in recent years. While UAVs are expected to transform future air operations, there are instances where they can be used for malicious purposes. In this context, the detection, classification, and tracking (DCT) of UAVs (DCT-U) for safety and surveillance of national air space is a challenging task when compared to DCT of manned aerial vehicles. In this survey, we discuss the threats and challenges from malicious UAVs and we subsequently study three radio frequency (RF)-based systems for DCT-U. These RF-based systems include radars, communication systems, and RF analyzers. Radar systems are further divided into conventional and modern radar systems, while communication systems can be used for joint communications and sensing (JC&S) in active mode and act as a source of illumination to passive radars for DCT-U. The limitations of the three RF-based systems are also provided. The survey briefly discusses non-RF systems for DCT-U and their limitations. Future directions based on the lessons learned are provided at the end of the survey.

Paper number 66:
Title: Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion
Authors: Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha
Abstract: This paper addresses the pursuit-evasion problem involving three agents -- a purser, an evader, and a defender. We develop cooperative guidance laws for the evader-defender team that guarantee that the defender intercepts the pursuer before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, we propose a geometric solution to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another alluring feature of the proposed strategy is that the evader-defender team does not require the knowledge of the pursuer's strategy and that the pursuer's interception is guaranteed from arbitrary initial engagement geometries. We further show that the necessary error variables for the evader-defender team vanish within a time that can be exactly prescribed prior to the three-body engagement. Finally, we demonstrate the efficacy of the proposed cooperative defense strategy via simulation in diverse engagement scenarios.

Paper number 67:
Title: Improved Generalizability of CNN Based Lane Detection in Challenging Weather Using Adaptive Preprocessing Parameter Tuning
Authors: I-Chen Sang, William R. Norris
Abstract: Ensuring the robustness of lane detection systems is essential for the reliability of autonomous vehicles, particularly in the face of diverse weather conditions. While numerous algorithms have been proposed, addressing challenges posed by varying weather remains an ongoing issue. Geometric-based lane detection methods, rooted in the inherent properties of road geometry, provide enhanced generalizability. However, these methods often require manual parameter tuning to accommodate it fluctuating illumination and weather conditions. Conversely, learning-based approaches, trained on pre-labeled datasets, excel in localizing intricate and curved lane configurations but grapple with the absence of diverse weather datasets. This paper introduces a promising hybrid approach that merges the strengths of both methodologies. A novel adaptive preprocessing method is proposed in this work. Utilizing a fuzzy inference system (FIS), the algorithm dynamically adjusts parameters in geometric-based image processing functions and enhances adaptability to diverse weather conditions. Notably, this preprocessing algorithm is designed to seamlessly integrate with all learning-based lane detection models. When implemented in conjunction with CNN-based models, the hybrid approach demonstrates commendable generalizability across weather conditions and adaptability to complex lane configurations. Rigorous testing on datasets featuring challenging weather conditions showcases the proposed method's significant improvements over existing models, underscoring its efficacy in addressing the persistent challenges associated with lane detection in adverse weather scenarios.

Paper number 68:
Title: Analysis of the BraTS 2023 Intracranial Meningioma Segmentation Challenge
Authors: Dominic LaBella, Ujjwal Baid, Omaditya Khanna, Shan McBurney-Lin, Ryan McLean, Pierre Nedelec, Arif Rashid, Nourel Hoda Tahon, Talissa Altes, Radhika Bhalerao, Yaseen Dhemesh, Devon Godfrey, Fathi Hilal, Scott Floyd, Anastasia Janas, Anahita Fathi Kazerooni, John Kirkpatrick, Collin Kent, Florian Kofler, Kevin Leu, Nazanin Maleki, Bjoern Menze, Maxence Pajot, Zachary J. Reitman, Jeffrey D. Rudie, Rachit Saluja, Yury Velichko, Chunhao Wang, Pranav Warman, Maruf Adewole, Jake Albrecht, Udunna Anazodo, Syed Muhammad Anwar, Timothy Bergquist, Sully Francis Chen, Verena Chung, Rong Chai, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Nastaran Khalili, Juan Eugenio Iglesias, Zhifan Jiang, Elaine Johanson, Koen Van Leemput, Hongwei Bran Li, Marius George Linguraru, Xinyang Liu, Aria Mahtabfar, Zeke Meier, Ahmed W. Moawad, John Mongan, Marie Piraud, Russell Takeshi Shinohara, Walter F. Wiggins, Aly H. Abayazeed, Rachel Akinola, András Jakab, Michel Bilello, Maria Correia de Verdier, Priscila Crivellaro, Christos Davatzikos, Keyvan Farahani, John Freymann, Christopher Hess, Raymond Huang, Philipp Lohmann, Mana Moassefi, Matthew W. Pease, Phillipp Vollmuth, Nico Sollmann, David Diffley, Khanak K. Nandolia, Daniel I. Warren, Ali Hussain, Pascal Fehringer, Yulia Bronstein, Lisa Deptula, Evan G. Stein, Mahsa Taherzadeh, Eduardo Portela de Oliveira, Aoife Haughey, Marinos Kontzialis, Luca Saba, Benjamin Turner, Melanie M. T. Brüßeler, Shehbaz Ansari, Athanasios Gkampenis, David Maximilian Weiss, Aya Mansour, Islam H. Shawali, Nikolay Yordanov, Joel M. Stein, Roula Hourani, Mohammed Yahya Moshebah, Ahmed Magdy Abouelatta, Tanvir Rizvi, Klara Willms, Dann C. Martin
Abstract: We describe the design and results from the BraTS 2023 Intracranial Meningioma Segmentation Challenge. The BraTS Meningioma Challenge differed from prior BraTS Glioma challenges in that it focused on meningiomas, which are typically benign extra-axial tumors with diverse radiologic and anatomical presentation and a propensity for multiplicity. Nine participating teams each developed deep-learning automated segmentation models using image data from the largest multi-institutional systematically expert annotated multilabel multi-sequence meningioma MRI dataset to date, which included 1000 training set cases, 141 validation set cases, and 283 hidden test set cases. Each case included T2, FLAIR, T1, and T1Gd brain MRI sequences with associated tumor compartment labels delineating enhancing tumor, non-enhancing tumor, and surrounding non-enhancing FLAIR hyperintensity. Participant automated segmentation models were evaluated and ranked based on a scoring system evaluating lesion-wise metrics including dice similarity coefficient (DSC) and 95% Hausdorff Distance. The top ranked team had a lesion-wise median dice similarity coefficient (DSC) of 0.976, 0.976, and 0.964 for enhancing tumor, tumor core, and whole tumor, respectively and a corresponding average DSC of 0.899, 0.904, and 0.871, respectively. These results serve as state-of-the-art benchmarks for future pre-operative meningioma automated segmentation algorithms. Additionally, we found that 1286 of 1424 cases (90.3%) had at least 1 compartment voxel abutting the edge of the skull-stripped image edge, which requires further investigation into optimal pre-processing face anonymization steps.

Paper number 69:
Title: MBSS-T1: Model-Based Subject-Specific Self-Supervised Motion Correction for Robust Cardiac T1 Mapping
Authors: Eyal Hanania, Adi Zehavi-Lenz, Ilya Volovik, Daphna Link-Sourani, Israel Cohen, Moti Freiman
Abstract: Cardiac T1 mapping is a valuable quantitative MRI technique for diagnosing diffuse myocardial diseases. Traditional methods, relying on breath-hold sequences and cardiac triggering based on an ECG signal, face challenges with patient compliance, limiting their effectiveness. Image registration can enable motion-robust cardiac T1 mapping, but inherent intensity differences between time points pose a challenge. We present MBSS-T1, a subject-specific self-supervised model for motion correction in cardiac T1 mapping. Physical constraints, implemented through a loss function comparing synthesized and motion-corrected images, enforce signal decay behavior, while anatomical constraints, applied via a Dice loss, ensure realistic deformations. The unique combination of these constraints results in motion-robust cardiac T1 mapping along the longitudinal relaxation axis. In a 5-fold experiment on a public dataset of 210 patients (STONE sequence) and an internal dataset of 19 patients (MOLLI sequence), MBSS-T1 outperformed baseline deep-learning registration methods. It achieved superior model fitting quality ($R^2$: 0.975 vs. 0.941, 0.946 for STONE; 0.987 vs. 0.982, 0.965 for MOLLI free-breathing; 0.994 vs. 0.993, 0.991 for MOLLI breath-hold), anatomical alignment (Dice: 0.89 vs. 0.84, 0.88 for STONE; 0.963 vs. 0.919, 0.851 for MOLLI free-breathing; 0.954 vs. 0.924, 0.871 for MOLLI breath-hold), and visual quality (4.33 vs. 3.38, 3.66 for STONE; 4.1 vs. 3.5, 3.28 for MOLLI free-breathing; 3.79 vs. 3.15, 2.84 for MOLLI breath-hold). MBSS-T1 enables motion-robust T1 mapping for broader patient populations, overcoming challenges such as suboptimal compliance, and facilitates free-breathing cardiac T1 mapping without requiring large annotated datasets. Our code is available at this https URL.

Paper number 70:
Title: Risk-Aware Autonomous Driving with Linear Temporal Logic Specifications
Authors: Shuhao Qi, Zengjie Zhang, Zhiyong Sun, Sofie Haesaert
Abstract: Humans naturally balance the risks of different concerns while driving, including traffic rule violations, minor accidents, and fatalities. However, achieving the same behavior in autonomous systems remains an open problem. This paper extends a risk metric that has been verified in human-like driving studies to encompass more complex driving scenarios specified by linear temporal logic (LTL) that go beyond just collision risks. This extension incorporates the timing and severity of events into LTL specifications, thereby reflecting a human-like risk awareness. Without sacrificing expressivity for traffic rules, we adopt LTL specifications composed of safety and co-safety formulas, allowing the control synthesis problem to be reformulated as a reachability problem. By leveraging occupation measures, we formulate a linear programming (LP) problem for this LTL-based risk metric. Consequently, the synthesized policy balances different types of risks, including not only collision risks but also traffic rule violations. The effectiveness of the proposed approach is validated by three typical traffic scenarios in the Carla simulator.

Paper number 71:
Title: Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions
Authors: Sacha Huriot, Hussein Sibai
Abstract: We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.

Paper number 72:
Title: Neighboring Slice Noise2Noise: Self-Supervised Medical Image Denoising from Single Noisy Image Volume
Authors: Langrui Zhou, Ziteng Zhou, Xinyu Huang, Huiru Wang, Xiangyu Zhang, Guang Li
Abstract: In the last few years, with the rapid development of deep learning technologies, supervised methods based on convolutional neural networks have greatly enhanced the performance of medical image denoising. However, these methods require large quantities of noisy-clean image pairs for training, which greatly limits their practicality. Although some researchers have attempted to train denoising networks using only single noisy images, existing self-supervised methods, including blind-spot-based and data-splitting-based methods, heavily rely on the assumption that noise is pixel-wise independent. However, this assumption often does not hold in real-world medical images. Therefore, in the field of medical imaging, there remains a lack of simple and practical denoising methods that can achieve high-quality denoising performance using only single noisy images. In this paper, we propose a novel self-supervised medical image denoising method, Neighboring Slice Noise2Noise (NS-N2N). The proposed method utilizes neighboring slices within a single noisy image volume to construct weighted training data, and then trains the denoising network using a self-supervised scheme with regional consistency loss and inter-slice continuity loss. NS-N2N only requires a single noisy image volume obtained from one medical imaging procedure to achieve high-quality denoising of the image volume itself. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art self-supervised denoising methods in both denoising performance and processing efficiency. Furthermore, since NS-N2N operates solely in the image domain, it is free from device-specific issues such as reconstruction geometry, making it easier to apply in various clinical practices.

Paper number 73:
Title: Scalable control synthesis for stochastic systems via structural IMDP abstractions
Authors: Frederik Baymler Mathiesen, Sofie Haesaert, Luca Laurenti
Abstract: This paper introduces a novel abstraction-based framework for controller synthesis of nonlinear discrete-time stochastic systems. The focus is on probabilistic reach-avoid specifications. The framework is based on abstracting a stochastic system into a new class of robust Markov models, called orthogonally decoupled Interval Markov Decision Processes (odIMDPs). Specifically, an odIMDPs is a class of robust Markov processes, where the transition probabilities between each pair of states are uncertain and have the product form. We show that such a specific form in the transition probabilities allows one to build compositional abstractions of stochastic systems that, for each state, are only required to store the marginal probability bounds of the original system. This leads to improved memory complexity for our approach compared to commonly employed abstraction-based approaches. Furthermore, we show that an optimal control strategy for a odIMDPs can be computed by solving a set of linear problems. When the resulting strategy is mapped back to the original system, it is guaranteed to lead to reduced conservatism compared to existing approaches. To test our theoretical framework, we perform an extensive empirical comparison of our methods against Interval Markov Decision Process- and Markov Decision Process-based approaches on various benchmarks including 7D systems. Our empirical analysis shows that our approach substantially outperforms state-of-the-art approaches in terms of both memory requirements and the conservatism of the results.

Paper number 74:
Title: How Should One Fit Channel Measurements to Fading Distributions for Performance Analysis?
Authors: Santiago Fernández, José David Vega-Sánchez, Juan E. Galeote-Cazorla, F. Javier López-Martínez
Abstract: Accurate channel modeling plays a pivotal role in optimizing communication systems, and fitting field measurements to stochastic models is crucial for capturing the key propagation features and to map these to achievable system performances. In this work, we shed light onto what's the most appropriate alternative for channel fitting, when the ultimate goal is performance analysis. Results show that likelihood-based and average-error metrics should be used with caution, since they can largely fail to predict outage probability measures. We show that supremum-error fitting metrics with tail awareness are more robust to estimate both ergodic and outage performance measures, even when they yield a larger average-error fitting.

Paper number 75:
Title: A CAV-based perimeter-free regional traffic control strategy utilizing existing parking infrastructure
Authors: Hao Liu, Vikash V. Gayah
Abstract: This paper proposes a novel perimeter-free regional traffic management strategy for traffic networks under a connected and autonomous vehicle (CAV) environment. The proposed strategy requires CAVs, especially those with long remaining travel distances, to temporarily wait at nearby parking facilities when the network is congested. After a designated holding time, these CAVs are allowed to re-enter the network. Doing so helps reduce congestion and improve overall operational efficiency. Unlike traditional perimeter control approaches that restrict inflows to congested regions, the proposed holding strategy leverages existing parking infrastructure to temporarily hold vehicles in a way that partially avoids local queue accumulation issues. The proposed method can be easily integrated with existing signal control methods and retains the maximum stability property of the original traffic signal control methods. Simulation results show that the proposed strategy not only reduces travel time for vehicles that are not held, but can also reduce travel times for some of the held vehicles as well, which serves as another key merit of the proposed approach. Compared to the two benchmark perimeter control algorithms, the proposed strategy is more robust against demand patterns and generates stronger improvements in the operational efficiency. Importantly, since the proposed strategy requires existing parking infrastructure, its performance has been demonstrated under various configurations of parking locations and capacities. Particularly, it is demonstrated that the utilization of the parking facility consistently improves overall traffic efficiency, regardless of the facility's size. Lastly, the proposed strategy is shown to be beneficial in a partial CAV environment where only a subset of vehicles are available for holding.

Paper number 76:
Title: Performance-Barrier Event-Triggered PDE Control of Traffic Flow
Authors: Peihan Zhang, Bhathiya Rathnayake, Mamadou Diagne, Miroslav Krstic
Abstract: For stabilizing stop-and-go oscillations in traffic flow by actuating a variable speed limit (VSL) at a downstream boundary of a freeway segment, we introduce event-triggered PDE backstepping designs employing the recent concept of performance-barrier event-triggered control (P-ETC). Our design is for linearized hyperbolic Aw-Rascle-Zhang (ARZ) PDEs governing traffic velocity and density. Compared to continuous feedback, ETC provides a piecewise-constant VSL commands-more likely to be obeyed by human drivers. Unlike the existing regular ETC (R-ETC), which enforces conservatively a strict decrease of a Lyapunov function, our performance-barrier (P-ETC) approach permits an increase, as long as the Lyapunov function remains below a performance barrier, resulting in fewer control updates than R-ETC. To relieve VSL from continuously monitoring the triggering function, we also develop periodic event-triggered (PETC) and self-triggered (STC) versions of both R-ETC and P-ETC. These are referred to as R/P-PETC and R/P-STC, respectively, and we show that they both guarantee Zeno-free behavior and exponential convergence in the spatial $L^2$ norm. With comparative simulations, we illustrate the benefits of the performance-barrier designs through traffic metrics (driver comfort, safety, travel time, fuel consumption). The proposed algorithms reduce discomfort nearly in half relative to driver behavior without VSL, while tripling the driver safety, measured by the average dwell time, relative to the R-ETC frequent-switching VSL schedule.

Paper number 77:
Title: The Expected Peak-to-Average Power Ratio of White Gaussian Noise in Sampled I/Q Data
Authors: Adam Wunderlich, Aric Sanders
Abstract: One of the fundamental endeavors in radio frequency (RF) metrology is to measure the power of signals, where a common aim is to estimate the peak-to-average power ratio (PAPR), which quantifies the ratio of the maximum (peak) to the mean value. For a finite number of discrete-time samples of baseband in-phase and quadrature (I/Q) white Gaussian noise (WGN) that are independent and identically distributed with zero mean, we derive a closed-form, exact formula for mean PAPR that is well-approximated by the natural logarithm of the number of samples plus Euler's constant. Additionally, we give related theoretical results for the mean crest factor (CF). After comparing our main result to previously published approximate formulas, we examine how violations of the WGN assumptions in sampled I/Q data result in deviations from the expected value of PAPR. Finally, utilizing a measured RF I/Q acquisition, we illustrate how our formula for mean PAPR can be applied to spectral analysis with spectrograms to verify when measured RF emissions are WGN in a given frequency band.

Paper number 78:
Title: Compression and Distillation of Data Quadruplets in Non-intrusive Reduced-order Modeling
Authors: Umair Zulfiqar
Abstract: This paper introduces a quadrature-free, data-driven approach to balanced truncation for both continuous-time and discrete-time systems. The method non-intrusively constructs reduced-order models using available transfer function samples from the right half of the $s$-plane. It is highlighted that the proposed data-driven balanced truncation and existing quadrature-based balanced truncation algorithms share a common feature: both compress their respective data quadruplets to derive reduced-order models. Additionally, it is demonstrated that by using different compression strategies, these quadruplets can be utilized to develop three data-driven formulations of the IRKA. These formulations non-intrusively generate near-optimal reduced models using transfer function samples from the $j\omega$-axis or the right half of the $s$-plane, or impulse response samples. Notably, these IRKA formulations eliminate the necessity of computing new transfer function samples as IRKA iteratively updates the sampling points. The results are also extended to discrete-time systems. The efficacy of the proposed algorithms is validated through numerical examples, which show that the proposed data-driven approaches perform comparably to their intrusive counterparts.

Paper number 79:
Title: Memory-dependent abstractions of stochastic systems through the lens of transfer operators
Authors: Adrien Banse, Giannis Delimpaltadakis, Luca Laurenti, Manuel Mazo Jr., Raphaël M. Jungers
Abstract: With the increasing ubiquity of safety-critical autonomous systems operating in uncertain environments, there is a need for mathematical methods for formal verification of stochastic models. Towards formally verifying properties of stochastic systems, methods based on discrete, finite Markov approximations -- abstractions -- thereof have surged in recent years. These are found in contexts where: either a) one only has partial, discrete observations of the underlying continuous stochastic process, or b) the original system is too complex to analyze, so one partitions the continuous state-space of the original system to construct a handleable, finite-state model thereof. In both cases, the abstraction is an approximation of the discrete stochastic process that arises precisely from the discretization of the underlying continuous process. The fact that the abstraction is Markov and the discrete process is not (even though the original one is) leads to approximation errors. Towards accounting for non-Markovianity, we introduce memory-dependent abstractions for stochastic systems, capturing dynamics with memory effects. Our contribution is twofold. First, we provide a formalism for memory-dependent abstractions based on transfer operators. Second, we quantify the approximation error by upper bounding the total variation distance between the true continuous state distribution and its discrete approximation.

Paper number 80:
Title: OTFS-ISAC System with Sub-Nyquist ADC Sampling Rate
Authors: Henglin Pu, Xuefeng Wang, Ajay Kumar, Lu Su, Husheng Li
Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal technology for next-generation wireless communication and radar systems, enabling high-resolution sensing and high-throughput communication with shared spectrum and hardware. However, achieving a fine radar resolution often requires high-rate analog-to-digital converters (ADCs) and substantial storage, making it both expensive and impractical for many commercial applications. To address these challenges, this paper proposes an orthogonal time frequency space (OTFS)-based ISAC architecture that operates at reduced ADC sampling rates, yet preserves accurate radar estimation and supports simultaneous communication. The proposed architecture introduces pilot symbols directly in the delay-Doppler (DD) domain to leverage the transformation mapping between the DD and time-frequency (TF) domains to keep selected subcarriers active while others are inactive, allowing the radar receiver to exploit under-sampling aliasing and recover the original DD signal at much lower sampling rates. To further enhance the radar accuracy, we develop an iterative interference estimation and cancellation algorithm that mitigates data symbol interference. We propose a code-based spreading technique that distributes data across the DD domain to preserve the maximum unambiguous radar sensing range. For communication, we implement a complete transceiver pipeline optimized for reduced sampling rate system, including synchronization, channel estimation, and iterative data detection. Experimental results from a software-defined radio (SDR)-based testbed confirm that our method substantially lowers the required sampling rate without sacrificing radar sensing performance and ensures reliable communication.

Paper number 81:
Title: RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head Clustering
Authors: Wei Yang, Yiran Zhu, Jiayu Shen, Yuhan Tang, Chengchang Pan, Hui He, Yan Su, Honggang Qi
Abstract: Diabetic Macular Edema (DME), a prevalent complication among diabetic patients, constitutes a major cause of visual impairment and blindness. Although deep learning has achieved remarkable progress in medical image analysis, traditional DME diagnosis still relies on extensive annotated data and subjective ophthalmologist assessments, limiting practical applications. To address this, we present RURANET++, an unsupervised learning-based automated DME diagnostic system. This framework incorporates an optimized U-Net architecture with embedded Spatial and Channel Squeeze & Excitation (SCSE) attention mechanisms to enhance lesion feature extraction. During feature processing, a pre-trained GoogLeNet model extracts deep features from retinal images, followed by PCA-based dimensionality reduction to 50 dimensions for computational efficiency. Notably, we introduce a novel clustering algorithm employing multi-projection heads to explicitly control cluster diversity while dynamically adjusting similarity thresholds, thereby optimizing intra-class consistency and inter-class discrimination. Experimental results demonstrate superior performance across multiple metrics, achieving maximum accuracy (0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), with exceptional clustering quality. This work provides an efficient unsupervised solution for DME diagnosis with significant clinical implications.

Paper number 82:
Title: Generating Novel Brain Morphology by Deforming Learned Templates
Authors: Alan Q. Wang, Fangrui Huang, Bailey Trang, Wei Peng, Mohammad Abbasi, Kilian Pohl, Mert Sabuncu, Ehsan Adeli
Abstract: Designing generative models for 3D structural brain MRI that synthesize morphologically-plausible and attribute-specific (e.g., age, sex, disease state) samples is an active area of research. Existing approaches based on frameworks like GANs or diffusion models synthesize the image directly, which may limit their ability to capture intricate morphological details. In this work, we propose a 3D brain MRI generation method based on state-of-the-art latent diffusion models (LDMs), called MorphLDM, that generates novel images by applying synthesized deformation fields to a learned template. Instead of using a reconstruction-based autoencoder (as in a typical LDM), our encoder outputs a latent embedding derived from both an image and a learned template that is itself the output of a template decoder; this latent is passed to a deformation field decoder, whose output is applied to the learned template. A registration loss is minimized between the original image and the deformed template with respect to the encoder and both decoders. Empirically, our approach outperforms generative baselines on metrics spanning image diversity, adherence with respect to input conditions, and voxel-based morphometry. Our code is available at this https URL.

Paper number 83:
Title: GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain tumour Segmentation on mp-MRI
Authors: Cecilia Diana-Albelda, Roberto Alcover-Couso, Álvaro García-Martín, Jesus Bescos, Marcos Escudero-Viñolo
Abstract: Gliomas are brain tumours that stand out for their highly lethal and aggressive nature, which demands a precise approach in their diagnosis. Medical image segmentation plays a crucial role in the evaluation and follow-up of these tumours, allowing specialists to analyse their morphology. However, existing methods for automatic glioma segmentation often lack generalization capability across other brain tumour domains, require extensive computational resources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used to delineate them. In this work, we introduce GBT-SAM, a novel Generalizable Brain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to brain tumour segmentation tasks. Our method employs a two-step training protocol: first, fine-tuning the patch embedding layer to process the entire mp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks and a Depth-Condition block into the Vision Transformer (ViT) to capture inter-slice correlations. GBT-SAM achieves state-of-the-art performance on the Adult Glioma dataset (Dice Score of $93.54$) while demonstrating robust generalization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma datasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus offering an efficient solution for brain tumour segmentation. \\ Our code and models are available at this https URL .

Paper number 84:
Title: Rate-Splitting Multiple Access: Finite Constellations, Receiver Design, and SIC-free Implementation
Authors: Sibo Zhang, Bruno Clerckx, David Vargas, Oliver Haffenden, Andrew Murphy
Abstract: Rate-Splitting Multiple Access (RSMA) has emerged as a novel multiple access technique that enlarges the achievable rate region of Multiple-Input Multiple-Output (MIMO) broadcast channels with linear precoding. In this work, we jointly address three practical but fundamental questions: (1) How to exploit the benefit of RSMA under finite constellations? (2) What are the potential and promising ways to implement RSMA receivers? (3) Can RSMA still retain its superiority in the absence of successive interference cancellers (SIC)? To address these concerns, we first propose low-complexity precoder designs taking finite constellations into account and show that the potential of RSMA is better achieved with such designs than those assuming Gaussian signalling. We then consider some practical receiver designs that can be applied to RSMA. We notice that these receiver designs follow one of two principles: (1) SIC: cancelling upper layer signals before decoding the lower layer and (2) non-SIC: treating upper layer signals as noise when decoding the lower layer. In light of this, we propose to alter the precoder design according to the receiver category. Through link-level simulations, the effectiveness of the proposed precoder and receiver designs are verified. More importantly, we show that it is possible to preserve the superiority of RSMA over Spatial Domain Multiple Access (SDMA), including SDMA with advanced receivers, even without SIC at the receivers. Those results therefore open the door to competitive implementable RSMA strategies for 6G and beyond communications.

Paper number 85:
Title: Exploring Robustness of Image Recognition Models on Hardware Accelerators
Authors: Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan
Abstract: As the usage of Artificial Intelligence (AI) on resource-intensive and safety-critical tasks increases, a variety of Machine Learning (ML) compilers have been developed, enabling compatibility of Deep Neural Networks (DNNs) with a variety of hardware acceleration devices. However, given that DNNs are widely utilized for challenging and demanding tasks, the behavior of these compilers must be verified. To this direction, we propose MutateNN, a tool that utilizes elements of both differential and mutation testing in order to examine the robustness of image recognition models when deployed on hardware accelerators with different capabilities, in the presence of faults in their target device code - introduced either by developers, or problems in their compilation process. We focus on the image recognition domain by applying mutation testing to 7 well-established DNN models, introducing 21 mutations of 6 different categories. We deployed our mutants on 4 different hardware acceleration devices of varying capabilities and observed that DNN models presented discrepancies of up to 90.3% in mutants related to conditional operators across devices. We also observed that mutations related to layer modification, arithmetic types and input affected severely the overall model performance (up to 99.8%) or led to model crashes, in a consistent manner across devices.

Paper number 86:
Title: Flag Sequence Set Design for Low-Complexity Delay-Doppler Estimation
Authors: Lingsheng Meng, Yong Liang Guan, Yao Ge, Zilong Liu
Abstract: This paper studies Flag sequences for low-complexity delay-Doppler estimation by exploiting their distinctive peak-curtain ambiguity functions (AFs). Unlike the existing Flag sequence designs that are limited to prime lengths and periodic auto-AFs, we aim to design Flag sequence sets of arbitrary lengths with low (nontrivial) periodic/aperiodic auto- and cross-AFs. Since every Flag sequence consists of a Curtain sequence and a Peak sequence, we first investigate the algebraic design of Curtain sequence sets of arbitrary lengths. Our proposed design gives rise to novel Curtain sequence sets with ideal curtain auto-AFs and zero/near-zero cross-AFs within the delay-Doppler zone of operation. Leveraging these Curtain sequence sets, two optimization problems are formulated to minimize the weighted integrated masked sidelobe level (WImSL) of the Flag sequence set. Accelerated parallel partially majorization-minimization algorithms are proposed to jointly optimize the transmit Flag sequences and symmetric/asymmetric reference sequences stored in the receiver. Simulations demonstrate that our proposed Flag sequences lead to improved WImSL and peak-to-max-masked-sidelobe ratio compared with the existing Flag sequences. Additionally, our Flag sequences under the Flag method exhibit Mean Squared Errors that approach the Cramér-Rao lower bound and the sampling bound at high signal-to-noise power ratios.

Paper number 87:
Title: Channel Orthogonalization with Reconfigurable Surfaces: General Models, Theoretical Limits, and Effective Configuration
Authors: Juan Vidal Alegría, Johan Thunberg, Ove Edfors
Abstract: We envision a future in which multi-antenna technology effectively exploits the spatial domain as a set of non-interfering orthogonal resources, allowing for flexible resource allocation and efficient modulation/demodulation. We may refer to this paradigm as orthogonal space-division multiplexing (OSDM). On the other hand, reconfigurable intelligent surface (RIS) has emerged as a promising technology which allows shaping the propagation environment for improved performance. This paper studies the ability of three extended types of reconfigurable surface (RS), including the recently proposed beyond diagonal RIS (BD-RIS), to achieve perfectly orthogonal channels in a general multi-user multiple-input multiple-output (MU-MIMO) scenario. We consider practical implementations for the three types of RS consisting of passive components, and obtain the corresponding restrictions on their reconfigurability. We then use these restrictions to derive closed-form conditions and explicit expressions for achieving arbitrary (orthogonal) channels. We also study the problem of exploiting the degrees of freedom (DoFs) from the channel orthogonality constraint to maximize the channel gain while maintaining the passive RS constraints, and we propose some initial methods with satisfying performance. Finally, we provide some channel estimation and RS configuration techniques within this framework, where the computations are assumed to be performed at the BS, and we derive some limits on the amount of overhead required to achieve channel orthogonalization with RSs. The numerical results confirm the theoretical findings, showing that channel orthogonality with passive RSs can be effectively achieved in practical environments as long as the direct channel is not significant with respect to the RS cascaded channel. We thus take some important steps towards realizing OSDM.

Paper number 88:
Title: Real-Time Convolutional Neural Network-Based Star Detection and Centroiding Method for CubeSat Star Tracker
Authors: Hongrui Zhao, Michael F. Lembeck, Adrian Zhuang, Riya Shah, Jesse Wei
Abstract: Star trackers are one of the most accurate celestial sensors used for absolute attitude determination. The devices detect stars in captured images and accurately compute their projected centroids on an imaging focal plane with subpixel precision. Traditional algorithms for star detection and centroiding often rely on threshold adjustments for star pixel detection and pixel brightness weighting for centroid computation. However, challenges like high sensor noise and stray light can compromise algorithm performance. This article introduces a Convolutional Neural Network (CNN)-based approach for star detection and centroiding, tailored to address the issues posed by noisy star tracker images in the presence of stray light and other artifacts. Trained using simulated star images overlayed with real sensor noise and stray light, the CNN produces both a binary segmentation map distinguishing star pixels from the background and a distance map indicating each pixel's proximity to the nearest star centroid. Leveraging this distance information alongside pixel coordinates transforms centroid calculations into a set of trilateration problems solvable via the least squares method. Our method employs efficient UNet variants for the underlying CNN architectures, and the variants' performances are evaluated. Comprehensive testing has been undertaken with synthetic image evaluations, hardware-in-the-loop assessments, and night sky tests. The tests consistently demonstrated that our method outperforms several existing algorithms in centroiding accuracy and exhibits superior resilience to high sensor noise and stray light interference. An additional benefit of our algorithms is that they can be executed in real-time on low-power edge AI processors.

Paper number 89:
Title: Surgical-LVLM: Learning to Adapt Large Vision-Language Model for Grounded Visual Question Answering in Robotic Surgery
Authors: Guankun Wang, Long Bai, Wan Jun Nah, Jie Wang, Zhaoxi Zhang, Zhen Chen, Jinlin Wu, Mobarakol Islam, Hongbin Liu, Hongliang Ren
Abstract: Recent advancements in Surgical Visual Question Answering (Surgical-VQA) and related region grounding have shown great promise for robotic and medical applications, addressing the critical need for automated methods in personalized surgical mentorship. However, existing models primarily provide simple structured answers and struggle with complex scenarios due to their limited capability in recognizing long-range dependencies and aligning multimodal information. In this paper, we introduce Surgical-LVLM, a novel personalized large vision-language model tailored for complex surgical scenarios. Leveraging the pre-trained large vision-language model and specialized Visual Perception LoRA (VP-LoRA) blocks, our model excels in understanding complex visual-language tasks within surgical contexts. In addressing the visual grounding task, we propose the Token-Interaction (TIT) module, which strengthens the interaction between the grounding module and the language responses of the Large Visual Language Model (LVLM) after projecting them into the latent space. We demonstrate the effectiveness of Surgical-LVLM on several benchmarks, including EndoVis-17-VQLA, EndoVis-18-VQLA, and a newly introduced EndoVis Conversations dataset, which sets new performance standards. Our work contributes to advancing the field of automated surgical mentorship by providing a context-aware solution.

Paper number 90:
Title: Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio Sensors
Authors: Manuele Rusci, Francesco Paci, Marco Fariselli, Eric Flamand, Tinne Tuytelaars
Abstract: This paper proposes a self-learning method to incrementally train (fine-tune) a personalized Keyword Spotting (KWS) model after the deployment on ultra-low power smart audio sensors. We address the fundamental problem of the absence of labeled training data by assigning pseudo-labels to the new recorded audio frames based on a similarity score with respect to few user recordings. By experimenting with multiple KWS models with a number of parameters up to 0.5M on two public datasets, we show an accuracy improvement of up to +19.2% and +16.0% vs. the initial models pretrained on a large set of generic keywords. The labeling task is demonstrated on a sensor system composed of a low-power microphone and an energy-efficient Microcontroller (MCU). By efficiently exploiting the heterogeneous processing engines of the MCU, the always-on labeling task runs in real-time with an average power cost of up to 8.2 mW. On the same platform, we estimate an energy cost for on-device training 10x lower than the labeling energy if sampling a new utterance every 6.1 s or 18.8 s with a DS-CNN-S or a DS-CNN-M model. Our empirical result paves the way to self-adaptive personalized KWS sensors at the extreme edge.

Paper number 91:
Title: Large Language Models are Strong Audio-Visual Speech Recognition Learners
Authors: Umberto Cappellazzo, Minsu Kim, Honglie Chen, Pingchuan Ma, Stavros Petridis, Daniele Falavigna, Alessio Brutti, Maja Pantic
Abstract: Multimodal large language models (MLLMs) have recently become a focal point of research due to their formidable multimodal understanding capabilities. For example, in the audio and speech domains, an LLM can be equipped with (automatic) speech recognition (ASR) abilities by just concatenating the audio tokens, computed with an audio encoder, and the text tokens to achieve state-of-the-art results. On the contrary, tasks like visual and audio-visual speech recognition (VSR/AVSR), which also exploit noise-invariant lip movement information, have received little or no attention. To bridge this gap, we propose Llama-AVSR, a new MLLM with strong audio-visual speech recognition capabilities. It leverages pre-trained audio and video encoders to produce modality-specific tokens which, together with the text tokens, are processed by a pre-trained LLM (e.g., Llama3.1-8B) to yield the resulting response in an auto-regressive fashion. Llama-AVSR requires a small number of trainable parameters as only modality-specific projectors and LoRA modules are trained whereas the multi-modal encoders and LLM are kept frozen. We evaluate our proposed approach on LRS3, the largest public AVSR benchmark, and we achieve new state-of-the-art results for the tasks of ASR and AVSR with a WER of 0.79% and 0.77%, respectively. To bolster our results, we investigate the key factors that underpin the effectiveness of Llama-AVSR: the choice of the pre-trained encoders and LLM, the efficient integration of LoRA modules, and the optimal performance-efficiency trade-off obtained via modality-aware compression rates.

Paper number 92:
Title: ConSinger: Efficient High-Fidelity Singing Voice Generation with Minimal Steps
Authors: Yulin Song, Guorui Sang, Jing Yu, Chuangbai Xiao
Abstract: Singing voice synthesis (SVS) system is expected to generate high-fidelity singing voice from given music scores (lyrics, duration and pitch). Recently, diffusion models have performed well in this field. However, sacrificing inference speed to exchange with high-quality sample generation limits its application scenarios. In order to obtain high quality synthetic singing voice more efficiently, we propose a singing voice synthesis method based on the consistency model, ConSinger, to achieve high-fidelity singing voice synthesis with minimal steps. The model is trained by applying consistency constraint and the generation quality is greatly improved at the expense of a small amount of inference speed. Our experiments show that ConSinger is highly competitive with the baseline model in terms of generation speed and quality. Audio samples are available at this https URL.

Paper number 93:
Title: Transformer-Based Fault-Tolerant Control for Fixed-Wing UAVs Using Knowledge Distillation and In-Context Adaptation
Authors: Francisco Giral, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche
Abstract: This study presents a transformer-based approach for fault-tolerant control in fixed-wing Unmanned Aerial Vehicles (UAVs), designed to adapt in real time to dynamic changes caused by structural damage or actuator failures. Unlike traditional Flight Control Systems (FCSs) that rely on classical control theory and struggle under severe alterations in dynamics, our method directly maps outer-loop reference values -- altitude, heading, and airspeed -- into control commands using the in-context learning and attention mechanisms of transformers, thus bypassing inner-loop controllers and fault-detection layers. Employing a teacher-student knowledge distillation framework, the proposed approach trains a student agent with partial observations by transferring knowledge from a privileged expert agent with full observability, enabling robust performance across diverse failure scenarios. Experimental results demonstrate that our transformer-based controller outperforms industry-standard FCS and state-of-the-art reinforcement learning (RL) methods, maintaining high tracking accuracy and stability in nominal conditions and extreme failure cases, highlighting its potential for enhancing UAV operational safety and reliability.

Paper number 94:
Title: Personalized Hierarchical Split Federated Learning in Wireless Networks
Authors: Md-Ferdous Pervej, Andreas F. Molisch
Abstract: Extreme resource constraints make large-scale machine learning (ML) with distributed clients challenging in wireless networks. On the one hand, large-scale ML requires massive information exchange between clients and server(s). On the other hand, these clients have limited battery and computation powers that are often dedicated to operational computations. Split federated learning (SFL) is emerging as a potential solution to mitigate these challenges, by splitting the ML model into client-side and server-side model blocks, where only the client-side block is trained on the client device. However, practical applications require personalized models that are suitable for the client's personal task. Motivated by this, we propose a personalized hierarchical split federated learning (PHSFL) algorithm that is specially designed to achieve better personalization performance. More specially, owing to the fact that regardless of the severity of the statistical data distributions across the clients, many of the features have similar attributes, we only train the body part of the federated learning (FL) model while keeping the (randomly initialized) classifier frozen during the training phase. We first perform extensive theoretical analysis to understand the impact of model splitting and hierarchical model aggregations on the global model. Once the global model is trained, we fine-tune each client classifier to obtain the personalized models. Our empirical findings suggest that while the globally trained model with the untrained classifier performs quite similarly to other existing solutions, the fine-tuned models show significantly improved personalized performance.

Paper number 95:
Title: Completion as Enhancement: A Degradation-Aware Selective Image Guided Network for Depth Completion
Authors: Zhiqiang Yan, Zhengxue Wang, Kun Wang, Jun Li, Jian Yang
Abstract: In this paper, we introduce the Selective Image Guided Network (SigNet), a novel degradation-aware framework that transforms depth completion into depth enhancement for the first time. Moving beyond direct completion using convolutional neural networks (CNNs), SigNet initially densifies sparse depth data through non-CNN densification tools to obtain coarse yet dense depth. This approach eliminates the mismatch and ambiguity caused by direct convolution over irregularly sampled sparse data. Subsequently, SigNet redefines completion as enhancement, establishing a self-supervised degradation bridge between the coarse depth and the targeted dense depth for effective RGB-D fusion. To achieve this, SigNet leverages the implicit degradation to adaptively select high-frequency components (e.g., edges) of RGB data to compensate for the coarse depth. This degradation is further integrated into a multi-modal conditional Mamba, dynamically generating the state parameters to enable efficient global high-frequency information interaction. We conduct extensive experiments on the NYUv2, DIML, SUN RGBD, and TOFDC datasets, demonstrating the state-of-the-art (SOTA) performance of SigNet.

Paper number 96:
Title: Large Language Model Enabled Multi-Task Physical Layer Network
Authors: Tianyue Zheng, Linglong Dai
Abstract: The advance of Artificial Intelligence (AI) is continuously reshaping the future 6G wireless communications. Particularly, the development of Large Language Models (LLMs) offers a promising approach to effectively improve the performance and generalization of AI in different physical-layer (PHY) tasks. However, most existing works finetune dedicated LLM networks for a single wireless communication task separately. Thus performing diverse PHY tasks requires extremely high training resources, memory usage, and deployment costs. To solve the problem, we propose a LLM-enabled multi-task PHY network to unify multiple tasks with a single LLM, by exploiting the excellent semantic understanding and generation capabilities of LLMs. Specifically, we first propose a multi-task LLM framework, which finetunes LLM to perform multi-user precoding, signal detection and channel prediction simultaneously. Besides, multi-task instruction module, input encoders, as well as output decoders, are elaborately designed to distinguish different tasks. The proposed design allows different wireless data types to be well aligned with the LLM input format. Moreover, low-rank adaptation (LoRA) is utilized for LLM fine-tuning. To reduce the memory requirement during LLM fine-tuning, a LoRA fine-tuning-aware quantization method is introduced. Extensive numerical simulations are also displayed to verify the effectiveness of the proposed method.

Paper number 97:
Title: Wasserstein Adaptive Value Estimation for Actor-Critic Reinforcement Learning
Authors: Ali Baheri, Zahra Shahrooei, Chirayu Salgarkar
Abstract: We present Wasserstein Adaptive Value Estimation for Actor-Critic (WAVE), an approach to enhance stability in deep reinforcement learning through adaptive Wasserstein regularization. Our method addresses the inherent instability of actor-critic algorithms by incorporating an adaptively weighted Wasserstein regularization term into the critic's loss function. We prove that WAVE achieves $\mathcal{O}\left(\frac{1}{k}\right)$ convergence rate for the critic's mean squared error and provide theoretical guarantees for stability through Wasserstein-based regularization. Using the Sinkhorn approximation for computational efficiency, our approach automatically adjusts the regularization based on the agent's performance. Theoretical analysis and experimental results demonstrate that WAVE achieves superior performance compared to standard actor-critic methods.

Paper number 98:
Title: Multi-Modal Variable-Rate CSI Reconstruction for FDD Massive MIMO Systems
Authors: Yunseo Nam, Jiwook Choi
Abstract: In frequency division duplex (FDD) systems, acquiring channel state information (CSI) at the base station (BS) traditionally relies on limited feedback from mobile terminals (MTs). However, the accuracy of channel reconstruction from feedback CSI is inherently constrained by the rate-distortion trade-off. To overcome this limitation, we propose a multi-modal channel reconstruction framework that leverages auxiliary data, such as RGB images or uplink CSI, collected at the BS. By integrating contextual information from these modalities, the framework mitigates CSI distortions caused by noise, compression, and quantization. At its core, the framework utilizes an autoencoder network capable of generating variable-length CSI, tailored for rate-adaptive multi-modal channel reconstruction. By augmenting the foundational autoencoder network using a transfer learning-based multi-modal fusion strategy, we enable accurate channel reconstruction in both single-modal and multi-modal scenarios. To train and evaluate the network under diverse and realistic wireless conditions, we construct a synthetic dataset that pairs wireless channel data with sensor data through 3D modeling and ray tracing. Simulation results demonstrate that the proposed framework achieves near-optimal beamforming gains in 5G New Radio (5G NR)-compliant scenarios, highlighting the potential of sensor data integration to improve CSI reconstruction accuracy.

Paper number 99:
Title: DLF: Extreme Image Compression with Dual-generative Latent Fusion
Authors: Naifu Xue, Zhaoyang Jia, Jiahao Li, Bin Li, Yuan Zhang, Yan Lu
Abstract: Recent studies in extreme image compression have achieved remarkable performance by compressing the tokens from generative tokenizers. However, these methods often prioritize clustering common semantics within the dataset, while overlooking the diverse details of individual objects. Consequently, this results in suboptimal reconstruction fidelity, especially at low bitrates. To address this issue, we introduce a Dual-generative Latent Fusion (DLF) paradigm. DLF decomposes the latent into semantic and detail elements, compressing them through two distinct branches. The semantic branch clusters high-level information into compact tokens, while the detail branch encodes perceptually critical details to enhance the overall fidelity. Additionally, we propose a cross-branch interactive design to reduce redundancy between the two branches, thereby minimizing the overall bit cost. Experimental results demonstrate the impressive reconstruction quality of DLF even below 0.01 bits per pixel (bpp). On the CLIC2020 test set, our method achieves bitrate savings of up to 27.93% on LPIPS and 53.55% on DISTS compared to MS-ILLM. Furthermore, DLF surpasses recent diffusion-based codecs in visual fidelity while maintaining a comparable level of generative realism. Code will be available later.

Paper number 100:
Title: AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and Adaptive Residual Learning
Authors: Yuheng Xu, Shijie Yang, Xin Liu, Jie Liu, Jie Tang, Gangshan Wu
Abstract: In recent years, the increasing popularity of Hi-DPI screens has driven a rising demand for high-resolution images. However, the limited computational power of edge devices poses a challenge in deploying complex super-resolution neural networks, highlighting the need for efficient methods. While prior works have made significant progress, they have not fully exploited pixel-level information. Moreover, their reliance on fixed sampling patterns limits both accuracy and the ability to capture fine details in low-resolution images. To address these challenges, we introduce two plug-and-play modules designed to capture and leverage pixel information effectively in Look-Up Table (LUT) based super-resolution networks. Our method introduces Automatic Sampling (AutoSample), a flexible LUT sampling approach where sampling weights are automatically learned during training to adapt to pixel variations and expand the receptive field without added inference cost. We also incorporate Adaptive Residual Learning (AdaRL) to enhance inter-layer connections, enabling detailed information flow and improving the network's ability to reconstruct fine details. Our method achieves significant performance improvements on both MuLUT and SPF-LUT while maintaining similar storage sizes. Specifically, for MuLUT, we achieve a PSNR improvement of approximately +0.20 dB improvement on average across five datasets. For SPF-LUT, with more than a 50% reduction in storage space and about a 2/3 reduction in inference time, our method still maintains performance comparable to the original. The code is available at this https URL.

Paper number 101:
Title: Nexus-O: An Omni-Perceptive And -Interactive Model for Language, Audio, And Vision
Authors: Che Liu, Yingji Zhang, Dong Zhang, Weijie Zhang, Chenggong Gong, Haohan Li, Yu Lu, Shilin Zhou, Yue Lu, Ziliang Gan, Ziao Wang, Junwei Liao, Haipang Wu, Ji Liu, André Freitas, Qifan Wang, Zenglin Xu, Rongjuncheng Zhang, Yong Dai
Abstract: Human beings perceive the real world through a spectrum of sensory modalities, encompassing auditory, visual, and linguistic faculties. The journey towards achieving Artificial General Intelligence (AGI) necessitates the development of models that can emulate these multifaceted perceptual capabilities and comprehensively understand these diversified data. To this end, we introduce \textbf{Nexus-O}, an industry-level \textbf{omni-perceptive and -interactive} model capable of efficiently processing Audio, Image, Video, and Text data in any combination and output audio/text in an end-to-end way. We systematically investigate Nexus-O by addressing three key research questions: First, how can models be efficiently designed and trained to achieve tri-modal alignment, understanding and reasoning capabilities across multiple modalities? Second, what approaches can be implemented to evaluate tri-modal model robustness, ensuring reliable performance and applicability in real-world scenarios? Third, what strategies can be employed to curate and obtain high-quality, real-life scenario speech datasets? For the first question, we design and pre-train Nexus-O based on the vision-language model, rather than the language model. By pre-training the model over high-quality synthetic audio data, our model is capable of tri-modal perception and interaction. For the second question, we introduce a new audio testbed, Nexus-O-audio, comprising diverse Automatic Speech Recognition (ASR) samples, spanning various real-world scenarios, such as corporate meetings and live stream. For the third question, we design the speech data synthesis pipeline to obtain high-quality speech training datasets, covering various real-world scenarios. Comprehensive experimentation and an in-depth analysis of tri-modal alignment over latent space demonstrate the advantages of our model on downstream tasks.
    