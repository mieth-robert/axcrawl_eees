
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle
Authors: Amirhesam Aghanouri, Mohamed Sabry, Joshua Cherian Varughese, Cristina Olaverri-Monreal
Abstract: This paper presents an experimental investigation and performance evaluation of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride battery combined with a renewable Proton Exchange Membrane Fuel Cell system. The study evaluates the performance of the system under various load-carrying scenarios and varying environmental conditions, simulating real-world operating conditions including throttle operation. In order to build a predictive model, gather operational insights, and detect anomalies, data-driven analyses using signal processing and modern machine learning techniques were employed. Specifically, machine learning techniques were used to distinguish throttle levels with high precision based on the operational data. Anomaly and change point detection methods enhanced voltage stability, resulting in fewer critical faults in the hybrid system compared to battery-only operation. Temporal Convolutional Networks were effectively employed to predict voltage behavior, demonstrating potential for use in planning the locations of fueling or charging stations. Moreover, integration with a solar-powered electrolyzer confirmed the system's potential for off-grid, renewable hydrogen use. The results indicate that integrating a Proton Exchange Membrane Fuel Cell with Nickel-Metal Hydride batteries significantly improves electrical performance and reliability for small electric vehicles, and these findings can be a potential baseline for scaling up to larger vehicles.

Paper number 2:
Title: In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning
Authors: Massimo Capurso, Luciano Afferrante
Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH) requirements demand high-precision finishing operations such as power honing. Conventional quality control strategies rely on post-process inspections and Statistical Process Control (SPC), which fail to capture transient machining anomalies and cannot ensure real-time defect detection. This study proposes a novel, data-driven framework for in-process monitoring of gear power honing using vibration signal analysis and machine learning. Our proposed methodology involves continuous data acquisition via accelerometers, followed by time-frequency signal analysis. We investigate and compare the efficacy of three subspace learning methods for features extraction: (1) Principal Component Analysis (PCA) for dimensionality reduction; (2) a two-stage framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with Regularization (R-UMLDA), adapted for tensor data, which enforces feature decorrelation and includes regularization for small sample sizes. These extracted features are then fed into a Support Vector Machine (SVM) classifier to predict four distinct gear quality categories, established through rigorous geometrical inspections and test bench results of assembled gearboxes. The models are trained and validated on an experimental dataset collected in an industrial context during gear power-honing operations, with gears classified into four different quality categories. The proposed framework achieves high classification accuracy (up to 100%) in an industrial setting. The approach offers interpretable spectral features that correlate with process dynamics, enabling practical integration into real-time monitoring and predictive maintenance systems.

Paper number 3:
Title: Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification
Authors: Camilo Quiceno Quintero, Sandip Varkey George
Abstract: The complex dynamics of the heart are reflected in its electrical activity, captured through electrocardiograms (ECGs). In this study we use nonlinear time series analysis to understand how ECG complexity varies with cardiac pathology. Using the large PTB-XL dataset, we extracted nonlinear measures from lead II ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations and mutual information. Significant differences between diseased and healthy individuals were found in almost all measures between healthy and diseased classes, and between 5 diagnostic superclasses ($p<.001$). Moreover, incorporating these complexity quantifiers into machine learning models substantially improved classification accuracy measured using area under the ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90 (including cross-time series metrics).

Paper number 4:
Title: Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach
Authors: Zhixing Wang, Renzhi Yuan, Haifeng Yao, Chuang Yang, Mugen Peng
Abstract: Channel modeling for satellite-to-underwater laser communication (StULC) links remains challenging due to long distances and the diversity of the channel constituents. The StULC channel is typically segmented into three isolated channels: the atmospheric channel, the air-water interface channel, and the underwater channel. Previous studies involving StULC channel modeling either focused on separated channels or neglected the combined effects of particles and turbulence on laser propagation. In this paper, we established a comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach, taking into account the effects of both particles and turbulence. We first obtained the intensity distribution of the transmitted laser beam after passing through the turbulent atmosphere based on the extended Huygens-Fresnel principle. Then we derived a closed-form probability density function of the photon propagating direction after passing through the air-water interface, which greatly simplified the modeling of StULC links. At last, we employed a Monte Carlo method to model the underwater links and obtained the power distribution at the receiving plane. Based on the proposed StULC channel model, we analyzed the bit error rate and the outage probability under different environmental conditions. Numerical results demonstrated that, the influence of underwater particle concentration on the communication performance is much pronounced than those of both the atmospheric turbulence and the underwater turbulence. Notably, increasing the wind speed at the air-water interface does not significantly worsen the communication performance of the StULC links.

Paper number 5:
Title: LLM Assisted Alpha Fairness for 6 GHz WiFi and NR_U Coexistence: An Agentic Orchestrator for Throughput, Energy, and SLA
Authors: Qun Wang, Yingzhou Lu, Guiran Liu, Binrong Zhu, Yang Liu
Abstract: Unlicensed 6GHz is becoming a primary workhorse for high-capacity access, with Wi-Fi and 5G NR-U competing for the same channels under listen-before-talk (LBT) rules. Operating in this regime requires decisions that jointly trade throughput, energy, and service-level objectives while remaining safe and auditable. We present an agentic controller that separates {policy} from {execution}. At the start of each scheduling epoch the agent summarizes telemetry (per-channel busy and baseline LBT failure; per-user CQI, backlog, latency, battery, priority, and power mode) and invokes a large language model (LLM) to propose a small set of interpretable knobs: a fairness index \alpha, per-channel duty-cycle caps for Wi-Fi/NR-U, and class weights. A deterministic optimizer then enforces feasibility and computes an \alpha-fair allocation that internalizes LBT losses and energy cost; malformed or unsafe policies are clamped and fall back to a rule baseline. In a 6GHz simulator with two 160MHz channels and mixed Wi-Fi/NR-U users, LLM-assisted policies consistently improve energy efficiency while keeping throughput competitive with a strong rule baseline. One LLM lowers total energy by 35.3% at modest throughput loss, and another attains the best overall trade-off, finishing with higher total bits (+3.5%) and higher bits/J (+12.2%) than the baseline. We release code, per-epoch logs, and plotting utilities to reproduce all figures and numbers, illustrating how transparent, policy-level LLM guidance can safely improve wireless coexistence.

Paper number 6:
Title: Towards the True Switching-ON of Transistors
Authors: Wucheng Ying, Jinwei Qi, Hui Zhao, Ameer Janabi, Hui Li, Biao Zhao, Teng Long
Abstract: Transistors are core component across all domains of electrical and electronic engineering (EEE), such as data centers, electrified transportation, robotics, renewables and grid applications, etc. Transistors' switching behavior governs energy loss, carbon emissions, cooling demand, water use, lifetime, material use and cost etc. throughout EEE. Despite near a century since the transistor's invention, the understanding of transistor switching remains fragmented: switching is treated as a black box relying on observed waveforms, cannot be explained using physical laws alone, and is not integrated into circuit theory. This forms one of the most critical barriers to recognizing the true physical boundaries, prohibiting more sustainable solutions. For example, the conventional Eon prediction model, derived from the conventional switching analysis, exhibits significant prediction errors (ranging from 34.41% to 80.05%). Here we present a unified first-principles paradigm to explain the switching phenomena. Using this paradigm, we revealed the physical origins and mechanisms of switching-ON phenomena across scenarios, and derived the proposed Eon prediction model, with error ranging from 0.88% to 11.60%, achieving a 17-fold average improvement. These results demonstrate the unprecedented power of the proposed paradigm: textbook-level foundations are established, transforming the fundamental understanding of transistor switching from empirical to first-principles analysis, and simultaneously stimulating follow-up research and applications for sustainable development across disciplines.

Paper number 7:
Title: Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing
Authors: Xin Li, Jingzhi Hu, Yinghui He, Hongbo Wang, Jin Gan, Jun Luo
Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience and has emerged as a thriving research field, yet the coarse spatial resolution inherent to Wi-Fi significantly hinders its ability to distinguish multiple subjects. By exploiting the near-field domination effect, establishing a dedicated sensing link for each subject through their personal Wi-Fi device offers a promising solution for multi-person HAR under native traffic. However, due to the subject-specific characteristics and irregular patterns of near-field signals, HAR neural network models require fine-tuning (FT) for cross-domain adaptation, which becomes particularly challenging with certain categories unavailable. In this paper, we propose WiAnchor, a novel training framework for efficient cross-domain adaptation in the presence of incomplete activity categories. This framework processes Wi-Fi signals embedded with irregular time information in three steps: during pre-training, we enlarge inter-class feature margins to enhance the separability of activities; in the FT stage, we innovate an anchor matching mechanism for cross-domain adaptation, filtering subject-specific interference informed by incomplete activity categories, rather than attempting to extract complete features from them; finally, the recognition of input samples is further improved based on their feature-level similarity with anchors. We construct a comprehensive dataset to thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with absent activity categories.

Paper number 8:
Title: Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach
Authors: Salar Nouri
Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D) direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a single snapshot of data. Conventional gridless methods often fail in this scenario due to prohibitive computational costs or a lack of robustness. We propose a novel framework that overcomes these limitations by jointly estimating a manifold transformation matrix and the source azimuth-elevation pairs within a single, unified optimization problem. This problem is solved efficiently using an inexact Augmented Lagrangian Method (iALM), which completely circumvents the need for semidefinite programming. By unifying the objectives of data fidelity and transformation robustness, our approach is uniquely suited for the demanding single-snapshot case. Simulation results confirm that the proposed iALM framework provides robust and high-resolution, gridless 2D-DOA estimates, establishing its efficacy for challenging array signal processing applications.

Paper number 9:
Title: CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms
Authors: Long Lin, Pablo Peiro-Corbacho, Pablo Ávila, Alejandro Carta-Bergaz, Ángel Arenal, Gonzalo R. Ríos-Muñoz, Carlos Sevilla-Salcedo
Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights into cardiac electrophysiology but are often contaminated by noise and remain high-dimensional, limiting real-time analysis. We introduce CLARAE (CLArity-preserving Reconstruction AutoEncoder), a one-dimensional encoder--decoder designed for atrial EGMs, which achieves both high-fidelity reconstruction and a compact 64-dimensional latent representation. CLARAE is designed to preserve waveform morphology, mitigate reconstruction artifacts, and produce interpretable embeddings through three principles: downsampling with pooling, a hybrid interpolation--convolution upsampling path, and a bounded latent space. We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29 patients across three rhythm types (AF, SR300, SR600). Performance was benchmarked against six state-of-the-art autoencoders using reconstruction metrics, rhythm classification, and robustness across signal-to-noise ratios from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved F1-scores above 0.97 for all rhythm types, and its latent space showed clear clustering by rhythm. In denoising tasks, it consistently ranked among the top performers for both unipolar and bipolar signals. In order to promote reproducibility and enhance accessibility, we offer an interactive web-based application. This platform enables users to explore pre-trained CLARAE models, visualize the reconstructions, and compute metrics in real time. Overall, CLARAE combines robust denoising with compact, discriminative representations, offering a practical foundation for clinical workflows such as rhythm discrimination, signal quality assessment, and real-time mapping.

Paper number 10:
Title: Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming
Authors: Saeed Mohammadzadeh, Rodrigo C.de Lamare, Yuriy Zakharov
Abstract: This work proposes an efficient, robust adaptive beamforming technique to deal with steering vector (SV) estimation mismatches and data covariance matrix reconstruction problems. In particular, the direction-of-arrival(DoA) of interfering sources is estimated with available snapshots in which the angular sectors of the interfering signals are computed adaptively. Then, we utilize the well-known general linear combination algorithm to reconstruct the interference-plus-noise covariance (IPNC) matrix using preprocessing-based spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be replaced by the sample covariance matrix (SCM) in the shrinkage method. A power spectrum sampling strategy is then devised based on a preprocessing matrix computed with the estimated angular sectors' information. Moreover, the covariance matrix for the signal is formed for the angular sector of the signal-of-interest (SOI), which allows for calculating an SV for the SOI using the power method. An analysis of the array beampattern in the proposed PPBSS technique is carried out, and a study of the computational cost of competing approaches is conducted. Simulation results show the proposed method's effectiveness compared to existing approaches.

Paper number 11:
Title: Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin
Authors: Shumaila Javaid, Nasir Saeed
Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as key enablers of 6G, providing global connectivity for applications such as autonomous transportation, Industrial IoT, and disaster response. Their large-scale deployment, however, risks unsustainable energy use and carbon emissions. This work advances prior energy-aware studies by proposing a carbon-aware orchestration framework for ISATNs that leverages Digital Twin (DT) technology. The framework adopts grams of CO$_2$-equivalent per bit (gCO$_2$/bit) as a primary sustainability metric and implements a multi timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting with real-time adaptive optimization. ISATN-specific control knobs, including carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement, are exploited to reduce emissions. Simulation results with real carbon intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration, while improving renewable utilization and resilience under adverse events.

Paper number 12:
Title: Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks
Authors: Henrique de Lima Alexandre, Clodoaldo Aparecido de Moraes Lima
Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for capturing brain activity, and is particularly relevant for applications in Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data remains a major challenge due to sensor costs, acquisition time, and inter-subject variability. To address these limitations, this study proposes a methodology for generating synthetic EEG signals associated with motor imagery brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves preprocessing real EEG data, training a diffusion model to reconstruct EEG channels from noise, and evaluating the quality of the generated signals through both signal-level and task-level metrics. For validation, we employed classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks (CNN), and U-Net to compare the performance of synthetic data against real data in classification tasks. The generated data achieved classification accuracies above 95%, with low mean squared error and high correlation with real signals. Our results demonstrate that synthetic EEG signals produced by diffusion models can effectively complement datasets, improving classification performance in EEG-based BCIs and addressing data scarcity.

Paper number 13:
Title: Two Phases Leakage Detection Strategy Supported by DMAs
Authors: G. Messa, G. Acconciaioco, S. Ripani, L. Bozzelli, A. Simone, O. Giustolisi
Abstract: The present work proposes a novel two phases model-based strategy for leakage detection. The two phases are: the identification of the district metering area (DMA) and the pipe pre-localization into the identified DMA. The strategy is based on detecting and pre-localizing the punctual leakage as anomaly with respect to the normal working conditions. A further novelty is the fact that the pre-localization phase returns the sequence of pipes to inspect, which makes the strategy attractive for water utilities, whose aim is to identify the anomaly at DMA level and, successively, to localize it with the minimum inspection cost. Furthermore, a random database is useful to test the performance of the strategy with respect to the configuration of DMAs and the pressure metering system. Consequently, a novel strategy to design the location of pressure meters is also proposed. It is demonstrated that the entire strategy limits false positives during the DMA identification phase by using the recently proposed index named Asset Management Support Indicator (AMSI). AMSI is invariant with respect to the deterioration, i.e., it is sensitive to its increase causing punctual leakage. The strategy is studied and discussed using two real Apulian WDNs managed by Acquedotto Pugliese.

Paper number 14:
Title: Introducing Coherent-Control Koopman to Reservoir Scale Porous Media Flow Studies
Authors: Dimitrios Voulanas, Eduardo Gildin
Abstract: Accurate and robust surrogate modeling is essential for the real time control and optimization of large-scale subsurface systems, such as geological CO2 storage and waterflood management. This study investigates the limits of classical Dynamic Mode Decomposition with control (DMDc) in replicating pressure and water saturation dynamics under challenging prediction scenarios. We benchmark CCKM against DMDc and a Hybrid B-only surrogate that reuses DMDcs bottom B (same step feed through), showing that only CCKM remains stable and accurate under regime shifts. Two representative cases are considered: (i) an out of distribution shut in and restart case, and (ii) an in distribution bottom hole pressure (BHP) drawdown. Results show that only CCKM consistently maintains stability and accuracy across both scenarios, achieving sub bar mean absolute error and sub percent Frobenius norm percent change error even under regime shifts, while DMDc exhibit large unphysical errors during control transients. The findings demonstrate that strict control coherence is critical for reliable surrogate modeling, particularly in settings with abrupt changes in control strategy. The proposed framework is broadly applicable to real time reservoir optimization and can be integrated seamlessly into existing optimization and monitoring workflows, enabling fast and trustworthy decision support in the presence of both expected and unexpected actuation regimes.

Paper number 15:
Title: Mixed Monotonicity Reachability Analysis of Neural ODE: A Trade-Off Between Tightness and Efficiency
Authors: Abdelrahman Sayed Sayed, Pierre-Jean Meyer, Mohamed Ghazel
Abstract: Neural ordinary differential equations (neural ODE) are powerful continuous-time machine learning models for depicting the behavior of complex dynamical systems, but their verification remains challenging due to limited reachability analysis tools adapted to them. We propose a novel interval-based reachability method that leverages continuous-time mixed monotonicity techniques for dynamical systems to compute an over-approximation for the neural ODE reachable sets. By exploiting the geometric structure of full initial sets and their boundaries via the homeomorphism property, our approach ensures efficient bound propagation. By embedding neural ODE dynamics into a mixed monotone system, our interval-based reachability approach, implemented in TIRA with single-step, incremental, and boundary-based approaches, provides sound and computationally efficient over-approximations compared with CORA's zonotopes and NNV2.0 star set representations, while trading tightness for efficiency. This trade-off makes our method particularly suited for high-dimensional, real-time, and safety-critical applications. Applying mixed monotonicity to neural ODE reachability analysis paves the way for lightweight formal analysis by leveraging the symmetric structure of monotone embeddings and the geometric simplicity of interval boxes, opening new avenues for scalable verification aligned with the symmetry and geometry of neural representations. This novel approach is illustrated on two numerical examples of a spiral system and a fixed-point attractor system modeled as a neural ODE.

Paper number 16:
Title: DMTrack: Deformable State-Space Modeling for UAV Multi-Object Tracking with Kalman Fusion and Uncertainty-Aware Association
Authors: Zenghuang Fu, Xiaofeng Han, Mingda Jia, Jin ming Yang, Qi Zeng, Muyang Zahng, Changwei Wang, Weiliang Meng, Xiaopeng Zhang
Abstract: Multi-object tracking (MOT) from unmanned aerial vehicles (UAVs) presents unique challenges due to unpredictable object motion, frequent occlusions, and limited appearance cues inherent to aerial viewpoints. These issues are further exacerbated by abrupt UAV movements, leading to unreliable trajectory estimation and identity switches. Conventional motion models, such as Kalman filters or static sequence encoders, often fall short in capturing both linear and non-linear dynamics under such conditions. To tackle these limitations, we propose DMTrack, a deformable motion tracking framework tailored for UAV-based MOT. Our DMTrack introduces three key components: DeformMamba, a deformable state-space predictor that dynamically aggregates historical motion states for adaptive trajectory modeling; MotionGate, a lightweight gating module that fuses Kalman and Mamba predictions based on motion context and uncertainty; and an uncertainty-aware association strategy that enhances identity preservation by aligning motion trends with prediction confidence. Extensive experiments on the VisDrone-MOT and UAVDT benchmarks demonstrate that our DMTrack achieves state-of-the-art performance in identity consistency and tracking accuracy, particularly under high-speed and non-linear motion. Importantly, our method operates without appearance models and maintains competitive efficiency, highlighting its practicality for robust UAV-based tracking.

Paper number 17:
Title: Quantum-Driven State-Reduction for Reliable UAV Trajectory Optimization in Low-Altitude Networks
Authors: Zeeshan Kaleem, Muhammad Afaq, Chau Yuen, Octavia A. Dobre, John M. Cioffi
Abstract: This letter introduces a Graph-Condensed Quantum-Inspired Placement (GC-QAP) framework for reliability-driven trajectory optimization in Uncrewed Aerial Vehicle (UAV) assisted low-altitude wireless networks. The dense waypoint graph is condensed using probabilistic quantum-annealing to preserve interference-aware centroids while reducing the control state space and maintaining link-quality. The resulting problem is formulated as a priority-aware Markov decision process and solved using epsilon-greedy off-policy Q-learning, considering UAV kinematic and flight corridor constraints. Unlike complex continuous-action reinforcement learning approaches, GC-QAP achieves stable convergence and low outage with substantially and lower computational cost compared to baseline schemes.

Paper number 18:
Title: Epistemology-Inspired Bayesian Games for Distributed IoT Uplink Power Control
Authors: Nirmal D. Wickramasinghe, John Dooley, Dirk Pesch, Indrakshi Dey
Abstract: Massive number of simultaneous Internet of Things (IoT) uplinks strain gateways with interference and energy limits, yet devices often lack neighbors' Channel State Information (CSI) and cannot sustain centralized Mobile Edge Computing (MEC) or heavy Machine Learning (ML) coordination. Classical Bayesian solvers help with uncertainty but become intractable as users and strategies grow, making lightweight, distributed control essential. In this paper, we introduce the first-ever, novel epistemic Bayesian game for uplink power control under incomplete CSI that operates while suppressing interference among multiple uplink channels from distributed IoT devices firing at the same time. Nodes run inter-/intra-epistemic belief updates over opponents' strategies, replacing exhaustive expected-utility tables with conditional belief hierarchies. Using an exponential-Gamma SINR model and higher-order utility moments (variance, skewness, kurtosis), the scheme remains computationally lean with a single-round upper bound of $O\!\left(N^{2} S^{2N}\right)$. Precise power control and stronger coverage amid realistic interference: with channel magnitude equal to $1$ and a signal-to-interference-plus-noise ratio (SINR) threshold of $-18$ dB, coverage reaches approximately $60\%$ at approximately $55\%$ of the maximum transmit power; mid-rate devices with a threshold of $-27$ dB achieve full coverage with less than $0.1\%$ of the maximum transmit this http URL $80\%$ interference, a fourth-moment policy cuts average power from approximately $52\%$ to approximately $20\%$ of the maximum transmit power with comparable outage, outperforming expectation-only baselines. These results highlight a principled, computationally lean path to optimal power allocation and higher network coverage under real-world uncertainty within dense, distributed IoT networks.

Paper number 19:
Title: DRL-Based Resource Allocation for Energy-Efficient IRS-Assisted UAV Spectrum Sharing Systems
Authors: Yiheng Wang
Abstract: Intelligent reflecting surface (IRS) assisted unmanned aerial vehicle (UAV) systems provide a new paradigm for reconfigurable and flexible wireless communications. To enable more energy efficient and spectrum efficient IRS assisted UAV wireless communications, this paper introduces a novel IRS-assisted UAV enabled spectrum sharing system with orthogonal frequency division multiplexing (OFDM). The goal is to maximize the energy efficiency (EE) of the secondary network by jointly optimizing the beamforming, subcarrier allocation, IRS phase shifts, and the UAV trajectory subject to practical transmit power and passive reflection constraints as well as UAV physical limitations. A physically grounded propulsion-energy model is adopted, with its tight upper bound used to form a tractable EE lower bound for the spectrum sharing system. To handle highly non convex, time coupled optimization problems with a mixed continuous and discrete policy space, we develop a deep reinforcement learning (DRL) approach based on the actor critic framework. Extended experiments show the significant EE improvement of the proposed DRL-based approach compared to several benchmark schemes, thus demonstrating the effectiveness and robustness of the proposed approach with mobility.

Paper number 20:
Title: Conformal Lesion Segmentation for 3D Medical Images
Authors: Binyu Tan, Zhiyuan Wang, Jinhao Duan, Kaidi Xu, Heng Tao Shen, Xiaoshuang Shi, Fumin Shen
Abstract: Medical image segmentation serves as a critical component of precision medicine, enabling accurate localization and delineation of pathological regions, such as lesions. However, existing models empirically apply fixed thresholds (e.g., 0.5) to differentiate lesions from the background, offering no statistical guarantees on key metrics such as the false negative rate (FNR). This lack of principled risk control undermines their reliable deployment in high-stakes clinical applications, especially in challenging scenarios like 3D lesion segmentation (3D-LS). To address this issue, we propose a risk-constrained framework, termed Conformal Lesion Segmentation (CLS), that calibrates data-driven thresholds via conformalization to ensure the test-time FNR remains below a target tolerance $\varepsilon$ under desired risk levels. CLS begins by holding out a calibration set to analyze the threshold setting for each sample under the FNR tolerance, drawing on the idea of conformal prediction. We define an FNR-specific loss function and identify the critical threshold at which each calibration data point just satisfies the target tolerance. Given a user-specified risk level $\alpha$, we then determine the approximate $1-\alpha$ quantile of all the critical thresholds in the calibration set as the test-time confidence threshold. By conformalizing such critical thresholds, CLS generalizes the statistical regularities observed in the calibration set to new test data, providing rigorous FNR constraint while yielding more precise and reliable segmentations. We validate the statistical soundness and predictive performance of CLS on six 3D-LS datasets across five backbone models, and conclude with actionable insights for deploying risk-aware segmentation in clinical practice.

Paper number 21:
Title: An Exact Quantile-Energy Equality for Terminal Halfspaces in Linear-Gaussian Control with a Discrete-Time Companion, KL/Schrodinger Links, and High-Precision Validation
Authors: Sandro Andric
Abstract: We prove an exact equality between the minimal quadratic control energy and the squared normal-quantile gap for terminal halfspaces in linear-Gaussian systems with additive control and quadratic effort $E(u)=\tfrac12\!\int u^\top M u\,dt$ where $M=B^\top\Sigma^{-1}B$. For terminal halfspace events, the minimal energy equals the squared normal-quantile gap divided by twice a controllability-to-noise ratio $R_T^2(w)=(w^\topW_c^M w)/(w^\top V_T w)$ and is attained by a matched-filter control. We provide an exact zero-order-hold discrete-time companion via block exponentials, relate the result to minimum-energy control, Gaussian isoperimetry, risk-sensitive/KL control, and Schrodinger bridges, and validate to high precision with Monte Carlo. We state assumptions, singular-$M$ handling, and edge cases. The statement is a compact synthesis and design-ready translator, not a universal principle. Novelty: while the ingredients (Gramians, Cauchy-Schwarz, Gaussian isoperimetry) are classical, to our knowledge the explicit quantile-energy equality with a constructive matched-filter achiever for terminal halfspaces, and its discrete-time companion, are not recorded together in the cited literature.

Paper number 22:
Title: Majority Vote Compressed Sensing
Authors: Henrik Hellström, Jiwon Jeong, Ayfer Özgür, Viktoria Fodor, Carlo Fischione
Abstract: We consider the problem of non-coherent over-the-air computation (AirComp), where $n$ devices carry high-dimensional data vectors $\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$ whose sum has to be computed at a receiver. Previous results on non-coherent AirComp require more than $d$ channel uses to compute functions of $\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent signal aggregation. However, if the data vectors are sparse, sparsity can be exploited to offer significantly cheaper communication. In this paper, we propose to use random transforms to transmit lower-dimensional projections $\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are communicated to the receiver using a majority vote (MV)-AirComp scheme, which estimates the bit-vector corresponding to the signs of the aggregated projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from $\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error $\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we specify algorithms that leverage MVCS for histogram estimation and distributed machine learning. Finally, we provide numerical evaluations that reveal the advantage of MVCS compared to the state-of-the-art.

Paper number 23:
Title: Hearing Health in Home Healthcare: Leveraging LLMs for Illness Scoring and ALMs for Vocal Biomarker Extraction
Authors: Yu-Wen Chen, William Ho, Sasha M. Vergez, Grace Flaherty, Pallavi Gupta, Zhihong Zhang, Maryam Zolnoori, Margaret V. McDonald, Maxim Topaz, Zoran Kostic, Julia Hirschberg
Abstract: The growing demand for home healthcare calls for tools that can support care delivery. In this study, we explore automatic health assessment from voice using real-world home care visit data, leveraging the diverse patient information it contains. First, we utilize Large Language Models (LLMs) to integrate Subjective, Objective, Assessment, and Plan (SOAP) notes derived from unstructured audio transcripts and structured vital signs into a holistic illness score that reflects a patient's overall health. This compact representation facilitates cross-visit health status comparisons and downstream analysis. Next, we design a multi-stage preprocessing pipeline to extract short speech segments from target speakers in home care recordings for acoustic analysis. We then employ an Audio Language Model (ALM) to produce plain-language descriptions of vocal biomarkers and examine their association with individuals' health status. Our experimental results benchmark both commercial and open-source LLMs in estimating illness scores, demonstrating their alignment with actual clinical outcomes, and revealing that SOAP notes are substantially more informative than vital signs. Building on the illness scores, we provide the first evidence that ALMs can identify health-related acoustic patterns from home care recordings and present them in a human-readable form. Together, these findings highlight the potential of LLMs and ALMs to harness heterogeneous in-home visit data for better patient monitoring and care.

Paper number 24:
Title: Joint Estimation of Piano Dynamics and Metrical Structure with a Multi-task Multi-Scale Network
Authors: Zhanhong He, Hanyu Meng, David Huang, Roberto Togneri
Abstract: Estimating piano dynamic from audio recordings is a fundamental challenge in computational music analysis. In this paper, we propose an efficient multi-task network that jointly predicts dynamic levels, change points, beats, and downbeats from a shared latent representation. These four targets form the metrical structure of dynamics in the music score. Inspired by recent vocal dynamic research, we use a multi-scale network as the backbone, which takes Bark-scale specific loudness as the input feature. Compared to log-Mel as input, this reduces model size from 14.7 M to 0.5 M, enabling long sequential input. We use a 60-second audio length in audio segmentation, which doubled the length of beat tracking commonly used. Evaluated on the public MazurkaBL dataset, our model achieves state-of-the-art results across all tasks. This work sets a new benchmark for piano dynamic estimation and delivers a powerful and compact tool, paving the way for large-scale, resource-efficient analysis of musical expression.

Paper number 25:
Title: Adaptive Per-Channel Energy Normalization Front-end for Robust Audio Signal Processing
Authors: Hanyu Meng, Vidhyasaharan Sethu, Eliathamby Ambikairajah, Qiquan Zhang, Haizhou Li
Abstract: In audio signal processing, learnable front-ends have shown strong performance across diverse tasks by optimizing task-specific representation. However, their parameters remain fixed once trained, lacking flexibility during inference and limiting robustness under dynamic complex acoustic environments. In this paper, we introduce a novel adaptive paradigm for audio front-ends that replaces static parameterization with a closed-loop neural controller. Specifically, we simplify the learnable front-end LEAF architecture and integrate a neural controller for adaptive representation via dynamically tuning Per-Channel Energy Normalization. The neural controller leverages both the current and the buffered past subband energies to enable input-dependent adaptation during inference. Experimental results on multiple audio classification tasks demonstrate that the proposed adaptive front-end consistently outperforms prior fixed and learnable front-ends under both clean and complex acoustic conditions. These results highlight neural adaptability as a promising direction for the next generation of audio front-ends.

Paper number 26:
Title: Urban Air Mobility: A Review of Recent Advances in Communication, Management, and Sustainability
Authors: Zhitong He, Zijing Wang, Lingxi Li
Abstract: Urban Air Mobility (UAM) offers a transformative approach to addressing urban congestion, improving accessibility, and advancing environmental sustainability. Rapid progress has emerged in three tightly linked domains since 2020: (1) Communication, where dynamic spectrum allocation and low-altitude channel characterization support reliable air-ground data exchange; (2) UAM management, with novel air-traffic control concepts for dense, largely autonomous urban airspace; and (3) Sustainability, driven by energy-efficient propulsion, integrated charging infrastructure, and holistic environmental assessment. This paper reviews and synthesizes the latest research across these areas, compares the state-of-the-art solutions, and outlines the technological and infrastructural milestones that are critical to realizing a scalable, sustainable UAM ecosystem.

Paper number 27:
Title: Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure
Authors: Mohammadreza Doostmohammadian, Sergio Pequito
Abstract: Distributed resource allocation (DRA) is fundamental to modern networked systems, spanning applications from economic dispatch in smart grids to CPU scheduling in data centers. Conventional DRA approaches require reliable communication, yet real-world networks frequently suffer from link failures, packet drops, and communication delays due to environmental conditions, network congestion, and security threats. We introduce a novel resilient DRA algorithm that addresses these critical challenges, and our main contributions are as follows: (1) guaranteed constraint feasibility at all times, ensuring resource-demand balance even during algorithm termination or network disruption; (2) robust convergence despite sector-bound nonlinearities at nodes/links, accommodating practical constraints like quantization and saturation; and (3) optimal performance under merely uniformly-connected networks, eliminating the need for continuous connectivity. Unlike existing approaches that require persistent network connectivity and provide only asymptotic feasibility, our graph-theoretic solution leverages network percolation theory to maintain performance during intermittent disconnections. This makes it particularly valuable for mobile multi-agent systems where nodes frequently move out of communication range. Theoretical analysis and simulations demonstrate that our algorithm converges to optimal solutions despite heterogeneous time delays and substantial link failures, significantly advancing the reliability of distributed resource allocation in practical network environments.

Paper number 28:
Title: MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments
Authors: Wangye Jiang (1), Haoming Yang (2), Xinyu Lu (1), Mingyuan Wang (1), Huimei Sun (1), Jingya Zhang (1) ((1) Suzhou University of Technology, (2) Jinling Institute of Technology)
Abstract: As wireless communication systems evolve, automatic modulation recognition (AMR) plays a key role in improving spectrum efficiency, especially in cognitive radio systems. Traditional AMR methods face challenges in complex, noisy environments, particularly in low signal-to-noise ratio (SNR) conditions. This paper introduces MCANet (Multimodal Collaborative Attention Network), a multimodal deep learning framework designed to address these challenges. MCANet employs refined feature extraction and global modeling to support its fusion this http URL results across multiple benchmark datasets show that MCANet outperforms mainstream AMR models, offering better robustness in low-SNR conditions.

Paper number 29:
Title: MVDR Beamforming for Cyclostationary Processes
Authors: Giovanni Bologni, Martin Bo Møller, Richard Heusdens, Richard C. Hendriks
Abstract: Conventional acoustic beamformers assume that noise is stationary within short time frames. This assumption prevents them from exploiting correlations between frequencies in almost-periodic noise sources such as musical instruments, fans, and engines. These signals exhibit periodically varying statistics and are better modeled as cyclostationary processes. This paper introduces the cyclic MVDR (cMVDR) beamformer, an extension of the conventional MVDR that leverages both spatial and spectral correlations to improve noise reduction, particularly in low-SNR scenarios. The method builds on frequency-shifted (FRESH) filtering, where shifted versions of the input are combined to attenuate or amplify components that are coherent across frequency. To address inharmonicity, where harmonic partials deviate from exact integer multiples of the fundamental frequency, we propose a data-driven strategy that estimates resonant frequencies via periodogram analysis and computes the frequency shifts from their spacing. Analytical and experimental results demonstrate that performance improves with increasing spectral correlation. On real recordings, the cMVDR achieves up to 5 dB gain in scale-invariant signal-to-distortion ratio (SI-SDR) over the MVDR and remains effective even with a single microphone. Code is available at this https URL.

Paper number 30:
Title: Sliding-Mode Control Strategies for PMSM speed control: A Comprehensive Review, Taxonomy and Research Gaps
Authors: Abdullah Ajasa, Mubarak Badamasi Aremu, Ali Nasir
Abstract: Permanent Magnet Synchronous Motors (PMSMs) are widely employed in high-performance drive systems due to their high efficiency, power density, and precise dynamic behavior. However, nonlinearities, load disturbances, and parameter uncertainties present persistent challenges to control. Sliding-Mode Control (SMC) remains one of the most reliable strategies for high-performance PMSM drives. Yet, the rapid proliferation of adaptive, fractional-order, and intelligent variants has fragmented recent literature. This paper presents a comprehensive review and taxonomy of SMC-based PMSM speed-control methods published between 2020 and 2025. More than 200 studies are systematically analyzed and classified according to control order, surface design, disturbance-observer integration, optimization approach, and intelligent augmentation. Trends in publication activity, dominant hybrid structures, and application domains are quantitatively summarized. The review reveals a clear evolution from conventional discontinuous SMC toward adaptive, higher-order, and data-driven frameworks that mitigate chattering while preserving robustness. Persistent research gaps are identified in hardware validation, energy-efficiency assessment, and real-time tuning strategies. The taxonomy and critical synthesis provided herein establish a coherent reference for researchers and form the conceptual foundation for the companion paper (Part II), which delivers a unified benchmark and comparative simulation study of representative SMC designs.

Paper number 31:
Title: AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression
Authors: Yizhen Jia, Siyao Xiao, Wenkai Jia, Hui Chen, Wen-Qin Wang
Abstract: The increasing of digital radio frequency memory based electronic countermeasures poses a significant threat to the survivability and effectiveness of radar systems. These jammers can generate a multitude of deceptive false targets, overwhelming the radar's processing capabilities and masking targets. Consequently, the ability to robustly discriminate between true targets and complex jamming signals, especially in low signal-to-noise ratio (SNR) environments, is of importance. This paper introduces the attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a deep learning framework designed for simultaneous radar target recognition and jamming suppression. The core of AWSPNet is the encoder that leverages the dual-tree complex wavelet transform to extract features that are inherently robust to noise and signal translations. These features are further refined by an attention mechanism and a pre-trained backbone network. To address the challenge of limited labeled data and enhance generalization, we employ a supervised contrastive learning strategy during the training phase. The classification is performed by a prototypical network, which is particularly effective in few-shot learning scenarios, enabling rapid adaptation to new signal types. We demonstrate the efficacy of our approach through extensive experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB SNR. Furthermore, we provide a physical interpretation of the network's inner workings through t-SNE visualizations, which analyze the feature separability at different stages of the model. Finally, by integrating AWSPNet with a time-domain sliding window approach, we present a complete algorithm capable of not only identifying but also effectively suppressing various types of jamming, thereby validating its potential for practical application in complex electromagnetic environments.

Paper number 32:
Title: ProLAP: Probabilistic Language-Audio Pre-Training
Authors: Toranosuke Manabe, Yuchi Ishikawa, Hokuto Munakata, Tatsuya Komatsu
Abstract: Language-audio joint representation learning frameworks typically depend on deterministic embeddings, assuming a one-to-one correspondence between audio and text. In real-world settings, however, the language-audio relationship is inherently many-to-many: one audio segment can be described by multiple captions and vice versa. To address this, we propose Probabilistic Language-Audio Pre-training (ProLAP), which models multiplicity as the spread of probability distributions in a joint language-audio embedding space. To train the intra-modal hierarchical relationship effectively, we also introduce two objectives: (i) hierarchical inclusion loss to promote semantic hierarchical understanding of inputs and (ii) mask repulsive loss to improve the efficiency of learning when optimizing the hierarchical inclusion loss. With this training strategy, our model can learn the hierarchical structure inherent in the data even from small datasets, in contrast to prior probabilistic approaches that rely on large-scale datasets. In our experiments, ProLAP outperforms existing deterministic approaches on audio-text retrieval tasks. Moreover, through experiments on the audio traversal task introduced in this paper, we demonstrate that ProLAP captures the plausible semantic hierarchy.

Paper number 33:
Title: Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection
Authors: Tung-Anh Nguyen, Van-Phuc Bui, Shashi Raj Pandey, Kim Hue Ta, Nguyen H. Tran, Petar Popovski
Abstract: This paper introduces FedSVD, a novel unsupervised federated learning framework for real-time anomaly detection in IoT networks. By leveraging Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds, FedSVD enables accurate detection of both known and unknown intrusions without relying on labeled data or centralized data sharing. Tailored for deployment on low-power devices like the NVIDIA Jetson AGX Orin, the proposed method significantly reduces communication overhead and computational cost. Experimental results show that FedSVD achieves performance comparable to deep learning baselines while reducing inference latency by over 10x, making it suitable for latency-sensitive IoT applications.

Paper number 34:
Title: Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels
Authors: Zian Meng, Qiang Li, Wenqian Tang, Mingdie Yan, Xiaohu Ge
Abstract: Deep learning-based semantic communication has largely relied on analog or semi-digital transmission, which limits compatibility with modern digital communication infrastructures. Recent studies have employed vector quantization (VQ) to enable discrete semantic transmission, yet existing methods neglect channel state information during codebook optimization, leading to suboptimal robustness. To bridge this gap, we propose a channel-aware vector quantization (CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed VQJSCC, established on a discrete memoryless channel. In this framework, semantic features are discretized and directly mapped to modulation constellation symbols, while CAVQ integrates channel transition probabilities into the quantization process, aligning easily confused symbols with semantically similar codewords. A multi-codebook alignment mechanism is further introduced to handle mismatches between codebook order and modulation order by decomposing the transmission stream into multiple independently optimized subchannels. Experimental results demonstrate that VQJSCC effectively mitigates the digital cliff effect, achieves superior reconstruction quality across various modulation schemes, and outperforms state-of-the-art digital semantic communication baselines in both robustness and efficiency.

Paper number 35:
Title: Quantifying Security for Networked Control Systems: A Review
Authors: Sribalaji C. Anand, Anh Tung Nguyen, André M.H. Teixeira, Henrik Sandberg, Karl H. Johansson
Abstract: Networked Control Systems (NCSs) are integral in critical infrastructures such as power grids, transportation networks, and production systems. Ensuring the resilient operation of these large-scale NCSs against cyber-attacks is crucial for societal well-being. Over the past two decades, extensive research has been focused on developing metrics to quantify the vulnerabilities of NCSs against attacks. Once the vulnerabilities are quantified, mitigation strategies can be employed to enhance system resilience. This article provides a comprehensive overview of methods developed for assessing NCS vulnerabilities and the corresponding mitigation strategies. Furthermore, we emphasize the importance of probabilistic risk metrics to model vulnerabilities under adversaries with imperfect process knowledge. The article concludes by outlining promising directions for future research.

Paper number 36:
Title: Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems
Authors: Anwar Ahmed Khan, Shama Siddiqui, Indrakshi Dey
Abstract: Managing delay is one of the core requirements of industrial automation applications due to the high risk associated for equipment and human lives. Using efficient Media Access Control (MAC) schemes guarantees the timely transmission of critical data, particularly in the industrial environments where heterogeneous data is inherently expected. This paper compares the performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority Scheduling based MAC (FPS-MAC), both of which have been designed to optimize the performance of heterogenous wireless networks. Contiki has been used as a simulation platform and a single hop star topology has been assumed to resemble the industrial environment. It has been shown that FROG-MAC has the potential to outperform FPS-MAC in terms of energy efficiency and delay both, due to its inherent feature of interrupting ongoing lower priority transmission on the channel.

Paper number 37:
Title: A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks
Authors: Shama Siddiqui, Anwar Ahmed Khan, Indrakshi Dey
Abstract: Simulation studies are conducted at different levels of details for assessing the performance of Media Access Control (MAC) protocols in Wireless Sensor Networks (WSN). In the present-day scenario where hundreds of MAC protocols have been proposed, it is important to assess the quality of performance evaluation being conducted for each of the proposed protocols. It therefore becomes crucial to compare the results of high-level theoretical simulations with the detailed implementation results before any network protocol could be deployed for a real-world scenario. In this work, we present a comparison of high-level theoretical and detailed implementation results for Adaptive and Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial theoretical simulations and TinyOS has been used to develop the detailed implementation of protocol for Mica2 platform. Performance evaluation of ADP-MAC using the two levels of simulation has been conducted based on energy and delay. In the high-level implementation, energy consumption was found to be decreasing whereas delay was found to be increasing for increasing channel polling intervals. On the other hand, when detailed implementation was developed, it was observed that both energy consumption and delay revealed an increasing trend with the increasing polling intervals. Therefore, it has been shown that the trends for high- and low-level simulations for ADP-MAC are significantly different, due to the lack of realistic assumptions in the higher-level study.

Paper number 38:
Title: mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates
Authors: Yhonatan Kvich, Rotem Arie, Hana Hasan, Shaik Basheeruddin Shah, Yonina C. Eldar
Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range by folding the input into a bounded interval prior to sampling, thus eliminating the risk of signal clipping and preserving information without requiring highresolution ADCs. While this enables low-cost hardware, the nonlinear distortion introduced by folding presents recovery challenges, particularly under noise and quantization. We propose a model-based deep unfolding network tailored to this setting, combining the interpretability of classical compress sensing (CS) solvers with the flexibility of learning. A key innovation is a soft-quantization module that encodes the modulo prior by guiding the solution toward discrete multiples of the folding range in a differentiable and learnable way. Our method, modulo soft-quantized unfolded iterative decoder (mSQUID), achieves superior reconstruction performance at low sampling rates under additive Gaussian noise. We further demonstrate its utility in a challenging case where signals with vastly different amplitudes and disjoint frequency bands are acquired simultaneously and quantized. In this scenario, classical sampling often struggles due to weak signal distortion or strong signal clipping, while our approach is able to recover the input signals. Our method also offers significantly reduced runtimes, making it suitable for real-time, resource-limited systems.

Paper number 39:
Title: $\ell_1$-Based Adaptive Identification under Quantized Observations with Applications
Authors: Xin Zheng, Yifei Jin, Yujing Liu, Lei Guo
Abstract: Quantized observations are ubiquitous in a wide range of applications across engineering and the social sciences, and algorithms based on the $\ell_1$-norm are well recognized for their robustness to outliers compared with their $\ell_2$-based counterparts. Nevertheless, adaptive identification methods that integrate quantized observations with $\ell_1$-optimization remain largely underexplored. Motivated by this gap, we develop a novel $\ell_1$-based adaptive identification algorithm specifically designed for quantized observations. Without relying on the traditional persistent excitation condition, we establish global convergence of the parameter estimates to their true values and show that the average regret asymptotically vanishes as the data size increases. Finally, we apply our new identification algorithm to a judicial sentencing problem using real-world data, which demonstrates its superior performance and practical significance.

Paper number 40:
Title: Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks
Authors: Kasun R. Wijewardhana, Animesh Yadav, Ming Zeng, Mohamed Elsayed, Octavia A. Dobre, Zhiguo Ding
Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a promising solution to mitigate severe propagation losses in millimeter-wave and terahertz bands by intelligently and flexibly establishing line-of-sight links. However, their reliance on wire-based feeding confines deployment to areas near the base station (BS), limiting installation flexibility and making them cost-ineffective for serving distant users or regions. To overcome this challenge, this article proposes wireless-fed pinchingantenna systems (Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer a practical and cost-efficient means to extend coverage beyond the BS vicinity. Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS. Numerical results further show that Wi-PASS deliver higher data rates than conventional fixed-antenna systems, confirming the superior feasibility and performance of Wi-PASS. Key future research directions are also discussed to advance Wi-PASS deployment.

Paper number 41:
Title: Diffusion Buffer for Online Generative Speech Enhancement
Authors: Bunlong Lay, Rostislav Makarov, Simon Welker, Maris Hillemann, Timo Gerkmann
Abstract: Online Speech Enhancement was mainly reserved for predictive models. A key advantage of these models is that for an incoming signal frame from a stream of data, the model is called only once for enhancement. In contrast, generative Speech Enhancement models often require multiple calls, resulting in a computational complexity that is too high for many online speech enhancement applications. This work presents the Diffusion Buffer, a generative diffusion-based Speech Enhancement model which only requires one neural network call per incoming signal frame from a stream of data and performs enhancement in an online fashion on a consumer-grade GPU. The key idea of the Diffusion Buffer is to align physical time with Diffusion time-steps. The approach progressively denoises frames through physical time, where past frames have more noise removed. Consequently, an enhanced frame is output to the listener with a delay defined by the Diffusion Buffer, and the output frame has a corresponding look-ahead. In this work, we extend upon our previous work by carefully designing a 2D convolutional UNet architecture that specifically aligns with the Diffusion Buffer's look-ahead. We observe that the proposed UNet improves performance, particularly when the algorithmic latency is low. Moreover, we show that using a Data Prediction loss instead of Denoising Score Matching loss enables flexible control over the trade-off between algorithmic latency and quality during inference. The extended Diffusion Buffer equipped with a novel NN and loss function drastically reduces the algorithmic latency from 320 - 960 ms to 32 - 176 ms with an even increased performance. While it has been shown before that offline generative diffusion models outperform predictive approaches in unseen noisy speech data, we confirm that the online Diffusion Buffer also outperforms its predictive counterpart on unseen noisy speech data.

Paper number 42:
Title: Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux
Authors: Mouna Gharbi, Silvia Villa, Emilie Chouzenoux, Jean-Christophe Pesquet, Laurent Duval
Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an active field of study. Traditional iterative optimization methods are now complemented by deep learning techniques. The development of unfolded methods benefits from both families. We carry out a comparative study of three architectures on parameterized chromatographic signal databases, highlighting the performance of these approaches, especially when employing metrics adapted to physico-chemical peak signal characterization.

Paper number 43:
Title: SO(3)-invariant PCA with application to molecular data
Authors: Michael Fraiman, Paulina Hoyos, Tamir Bendory, Joe Kileel, Oscar Mickelin, Nir Sharon, Amit Singer
Abstract: Principal component analysis (PCA) is a fundamental technique for dimensionality reduction and denoising; however, its application to three-dimensional data with arbitrary orientations -- common in structural biology -- presents significant challenges. A naive approach requires augmenting the dataset with many rotated copies of each sample, incurring prohibitive computational costs. In this paper, we extend PCA to 3D volumetric datasets with unknown orientations by developing an efficient and principled framework for SO(3)-invariant PCA that implicitly accounts for all rotations without explicit data augmentation. By exploiting underlying algebraic structure, we demonstrate that the computation involves only the square root of the total number of covariance entries, resulting in a substantial reduction in complexity. We validate the method on real-world molecular datasets, demonstrating its effectiveness and opening up new possibilities for large-scale, high-dimensional reconstruction problems.

Paper number 44:
Title: Robust interpretation of electrochemical impedance spectra using numerical complex analysis
Authors: Jithin D. George, Willa Brenneis, Vinod K. Sangwan, Dilara Meli, Heather Kurtz, Jeffrey Richards, Lincoln J. Lauhon, Jonathan Rivnay, Mark C. Hersam, Jeffrey Lopez, Maria K. Y. Chan, Valerie Taylor
Abstract: Electrochemical Impedance Spectroscopy (EIS) is a non-invasive technique widely used for understanding charge transfer and charge transport processes in electrochemical systems and devices. Standard approaches for the interpretation of EIS data involve starting with a hypothetical circuit model for the physical processes in the device based on experience/intuition, and then fitting the EIS data to this circuit model. This work explores a mathematical approach for extracting key characteristic features from EIS data by relying on fundamental principles of complex analysis. These characteristic features can ascertain the presence of inductors and constant phase elements (non-ideal capacitors) in circuit models and enable us to answer questions about the identifiability and uniqueness of equivalent circuit models. In certain scenarios such as models with only resistors and capacitors, we are able to enumerate all possible families of circuit models. Finally, we apply the mathematical framework presented here to real-world electrochemical systems and highlight results using impedance measurements from a lithium-ion battery coin cell.

Paper number 45:
Title: Transformer Redesign for Late Fusion of Audio-Text Features on Ultra-Low-Power Edge Hardware
Authors: Stavros Mitsis, Ermos Hadjikyriakos, Humaid Ibrahim, Savvas Neofytou, Shashwat Raman, James Myles, Eiman Kanjo
Abstract: Deploying emotion recognition systems in real-world environments where devices must be small, low-power, and private remains a significant challenge. This is especially relevant for applications such as tension monitoring, conflict de-escalation, and responsive wearables, where cloud-based solutions are impractical. Multimodal emotion recognition has advanced through deep learning, but most systems remain unsuitable for deployment on ultra-constrained edge devices. Prior work typically relies on powerful hardware, lacks real-time performance, or uses unimodal input. This paper addresses that gap by presenting a hardware-aware emotion recognition system that combines acoustic and linguistic features using a late-fusion architecture optimised for Edge TPU. The design integrates a quantised transformer-based acoustic model with frozen keyword embeddings from a DSResNet-SE network, enabling real-time inference within a 1.8MB memory budget and 21-23ms latency. The pipeline ensures spectrogram alignment between training and deployment using MicroFrontend and MLTK. Evaluation on re-recorded, segmented IEMOCAP samples captured through the Coral Dev Board Micro microphone shows a 6.3% macro F1 improvement over unimodal baselines. This work demonstrates that accurate, real-time multimodal emotion inference is achievable on microcontroller-class edge platforms through task-specific fusion and hardware-guided model design.

Paper number 46:
Title: TriggerNet: A Novel Explainable AI Framework for Red Palm Mite Detection and Multi-Model Comparison and Heuristic-Guided Annotation
Authors: Harshini Suresha, Kavitha SH
Abstract: The red palm mite infestation has become a serious concern, particularly in regions with extensive palm cultivation, leading to reduced productivity and economic losses. Accurate and early identification of mite-infested plants is critical for effective management. The current study focuses on evaluating and comparing the ML model for classifying the affected plants and detecting the infestation. TriggerNet is a novel interpretable AI framework that integrates Grad-CAM, RISE, FullGrad, and TCAV to generate novel visual explanations for deep learning models in plant classification and disease detection. This study applies TriggerNet to address red palm mite (Raoiella indica) infestation, a major threat to palm cultivation and agricultural productivity. A diverse set of RGB images across 11 plant species, Arecanut, Date Palm, Bird of Paradise, Coconut Palm, Ginger, Citrus Tree, Palm Oil, Orchid, Banana Palm, Avocado Tree, and Cast Iron Plant was utilized for training and evaluation. Advanced deep learning models like CNN, EfficientNet, MobileNet, ViT, ResNet50, and InceptionV3, alongside machine learning classifiers such as Random Forest, SVM, and KNN, were employed for plant classification. For disease classification, all plants were categorized into four classes: Healthy, Yellow Spots, Reddish Bronzing, and Silk Webbing. Snorkel was used to efficiently label these disease classes by leveraging heuristic rules and patterns, reducing manual annotation time and improving dataset reliability.

Paper number 47:
Title: Prompt-to-Primal Teaching
Authors: Euzeli dos Santos
Abstract: This paper introduces Prompt-to-Primal (P2P) Teaching, an AI-integrated instructional approach that links prompt-driven exploration with first-principles reasoning, guided and moderated by the instructor within the classroom setting. In P2P teaching, student-generated AI prompts serve as entry points for inquiry and initial discussions in class, while the instructor guides learners to validate, challenge, and reconstruct AI responses through fundamental physical and mathematical laws. The approach encourages self-reflective development, critical evaluation of AI outputs, and conceptual foundational knowledge of the core engineering principles. A large language model (LLM) can be a highly effective tool for those who already possess foundational knowledge of a subject; however, it may also mislead students who lack sufficient background in the subject matter. Results from two student cohorts across different semesters suggest the pedagogical effectiveness of the P2P teaching framework in enhancing both AI literacy and engineering reasoning.

Paper number 48:
Title: Provably Optimal Reinforcement Learning under Safety Filtering
Authors: Donggeon David Oh, Duy P. Nguyen, Haimin Hu, Jaime F. Fisac
Abstract: Recent advances in reinforcement learning (RL) enable its use on increasingly complex tasks, but the lack of formal safety guarantees still limits its application in safety-critical settings. A common practical approach is to augment the RL policy with a safety filter that overrides unsafe actions to prevent failures during both training and deployment. However, safety filtering is often perceived as sacrificing performance and hindering the learning process. We show that this perceived safety-performance tradeoff is not inherent and prove, for the first time, that enforcing safety with a sufficiently permissive safety filter does not degrade asymptotic performance. We formalize RL safety with a safety-critical Markov decision process (SC-MDP), which requires categorical, rather than high-probability, avoidance of catastrophic failure states. Additionally, we define an associated filtered MDP in which all actions result in safe effects, thanks to a safety filter that is considered to be a part of the environment. Our main theorem establishes that (i) learning in the filtered MDP is safe categorically, (ii) standard RL convergence carries over to the filtered MDP, and (iii) any policy that is optimal in the filtered MDP-when executed through the same filter-achieves the same asymptotic return as the best safe policy in the SC-MDP, yielding a complete separation between safety enforcement and performance optimization. We validate the theory on Safety Gymnasium with representative tasks and constraints, observing zero violations during training and final performance matching or exceeding unfiltered baselines. Together, these results shed light on a long-standing question in safety-filtered learning and provide a simple, principled recipe for safe RL: train and deploy RL policies with the most permissive safety filter that is available.

Paper number 49:
Title: ANGEL: A Novel Gripper for Versatile and Light-touch Fruit Harvesting
Authors: Dharmik Patel, Antonio Rafael Vazquez Pantoja, Jiuzhou Lei, Kiju Lee, Xiao Liang, Minghui Zheng
Abstract: Fruit harvesting remains predominantly a labor-intensive process, motivating the development of research for robotic grippers. Conventional rigid or vacuum-driven grippers require complex mechanical design or high energy consumption. Current enveloping-based fruit harvesting grippers lack adaptability to fruits of different sizes. This paper introduces a drawstring-inspired, cable-driven soft gripper for versatile and gentle fruit harvesting. The design employs 3D-printed Thermoplastic Polyurethane (TPU) pockets with integrated steel wires that constrict around the fruit when actuated, distributing pressure uniformly to minimize bruising and allow versatility to fruits of varying sizes. The lightweight structure, which requires few components, reduces mechanical complexity and cost compared to other grippers. Actuation is achieved through servo-driven cable control, while motor feedback provides autonomous grip adjustment with tunable grip strength. Experimental validation shows that, for tomatoes within the gripper's effective size range, harvesting was achieved with a 0% immediate damage rate and a bruising rate of less than 9% after five days, reinforcing the gripper's suitability for fruit harvesting.

Paper number 50:
Title: Harmonic Cancellation in Multi-Electrolyzer P2H Plants via Phasor-Modulated Production Scheduling
Authors: Yangjun Zeng (1), Yiwei Qiu (1), Li Jiang (1), Jie Zhu (1), Yi Zhou (1), Jiarong Li (2), Shi Chen (1), Buxiang Zhou (1) ((1) College of Electrical Engineering, Sichuan University, (2) Harvard John A. Paulson School of Engineering and Applied Sciences)
Abstract: Thyristor rectifiers (TRs) are cost-effective power supplies for hydrogen electrolyzers (ELZs) but introduce harmonic distortion that may violate grid codes. This letter proposes a self-governing harmonic mitigation strategy through coordinated operation of multiple ELZs in large power-to-hydrogen (P2H) plants. First, the harmonic model of TR-powered ELZs is derived, revealing a natural harmonic cancellation mechanism among them. Based on this, a system-level operation scheme based on phasor modulation is developed and integrated into plant scheduling. Case studies demonstrate that the proposed method reduces harmonic currents by 21.2%-39.7% and ensures grid-code compliance, with only a 0.25% loss in hydrogen output, while increasing total revenue by over 21\% compared to production-oriented strategies.

Paper number 51:
Title: Brute-force search and Warshall algorithms for matrix-weighted graphs
Authors: Minh Hoang Trinh, Hyo-Sung Ahn
Abstract: Although research on the control of networked systems has grown considerably, graph-theoretic and algorithmic studies on matrix-weighted graphs remain limited. To bridge this gap in the literature, this work introduces two algorithms-the brute-force search and the Warshall algorithm-for determining connectedness and clustering in undirected matrix-weighted graphs. The proposed algorithms, which are derived from a sufficient condition for connectedness, emphasize a key distinction between matrix-weighted and scalar-weighted graphs. While the existence of a path between two vertices guarantees connectedness in scalar-weighted graphs, connectedness in matrix-weighted graphs is a collective contribution of all paths joining the two vertices. Proofs of correctness and numerical examples are provided to illustrate and demonstrate the effectiveness of the algorithms.

Paper number 52:
Title: Explicit Reformulation of Discrete Distributionally Robust Optimization Problems
Authors: Yuma Shida, Yuji Ito
Abstract: Distributionally robust optimization (DRO) is an effective framework for controlling real-world systems with various uncertainties, typically modeled using distributional uncertainty balls. However, DRO problems often involve infinitely many inequality constraints, rendering exact solutions computationally expensive. In this study, we propose a discrete DRO (DDRO) method that significantly simplifies the problem by reducing it to a single trivial constraint. Specifically, the proposed method utilizes two types of distributional uncertainty balls to reformulate the DDRO problem into a single-layer smooth convex program, significantly improving tractability. Furthermore, we provide practical guidance for selecting the appropriate ball sizes. The original DDRO problem is further reformulated into two optimization problems: one minimizing the mean and standard deviation, and the other minimizing the conditional value at risk (CVaR). These formulations account for the choice of ball sizes, thereby enhancing the practical applicability of the method. The proposed method was applied to a distributionally robust patrol-agent design problem, identifying a Pareto front in which the mean and standard deviation of the mean hitting time varied by up to 3% and 14%, respectively, while achieving a CVaR reduction of up to 13%.

Paper number 53:
Title: ParaStyleTTS: Toward Efficient and Robust Paralinguistic Style Control for Expressive Text-to-Speech Generation
Authors: Haowei Lou, Hye-Young Paik, Wen Hu, Lina Yao
Abstract: Controlling speaking style in text-to-speech (TTS) systems has become a growing focus in both academia and industry. While many existing approaches rely on reference audio to guide style generation, such methods are often impractical due to privacy concerns and limited accessibility. More recently, large language models (LLMs) have been used to control speaking style through natural language prompts; however, their high computational cost, lack of interpretability, and sensitivity to prompt phrasing limit their applicability in real-time and resource-constrained environments. In this work, we propose ParaStyleTTS, a lightweight and interpretable TTS framework that enables expressive style control from text prompts alone. ParaStyleTTS features a novel two-level style adaptation architecture that separates prosodic and paralinguistic speech style modeling. It allows fine-grained and robust control over factors such as emotion, gender, and age. Unlike LLM-based methods, ParaStyleTTS maintains consistent style realization across varied prompt formulations and is well-suited for real-world applications, including on-device and low-resource deployment. Experimental results show that ParaStyleTTS generates high-quality speech with performance comparable to state-of-the-art LLM-based systems while being 30x faster, using 8x fewer parameters, and requiring 2.5x less CUDA memory. Moreover, ParaStyleTTS exhibits superior robustness and controllability over paralinguistic speaking styles, providing a practical and efficient solution for style-controllable text-to-speech generation. Demo can be found at this https URL. Code can be found at this https URL.

Paper number 54:
Title: Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback
Authors: Muhammad Hanif, Reiji Terunuma, Takumi Sumino, Kelvin Cheng, Takeshi Hatanaka
Abstract: This article addresses collaborative 3D map reconstruction using multiple drones. Achieving high-quality reconstruction requires capturing images of keypoints within the target scene from diverse viewing angles, and coverage control offers an effective framework to meet this requirement. Meanwhile, recent advances in real-time 3D reconstruction algorithms make it possible to render an evolving map during flight, enabling immediate feedback to guide drone motion. Building on this, we present Coverage-Recon, a novel coordinated image sampling algorithm that integrates online map feedback to improve reconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of drones is governed by a Quadratic Programming (QP)-based angle-aware coverage controller, which ensures multi-viewpoint image capture while enforcing safety constraints. The captured images are processed in real time by the NeuralRecon algorithm to generate an evolving 3D mesh. Mesh changes across the scene are interpreted as indicators of reconstruction uncertainty and serve as feedback to update the importance index of the coverage control as the map evolves. The effectiveness of Coverage-Recon is validated through simulation and experiments, demonstrating both qualitatively and quantitatively that incorporating online map feedback yields more complete and accurate 3D reconstructions than conventional methods. Project page: this https URL

Paper number 55:
Title: MMRHP: A Miniature Mixed-Reality HIL Platform for Auditable Closed-Loop Evaluation
Authors: Mingxin Li, Haibo Hu, Jinghuai Deng, Yuchen Xi, Xinhong Chen, Jianping Wang
Abstract: Validation of autonomous driving systems requires a trade-off between test fidelity, cost, and scalability. While miniaturized hardware-in-the-loop (HIL) platforms have emerged as a promising solution, a systematic framework supporting rigorous quantitative analysis is generally lacking, limiting their value as scientific evaluation tools. To address this challenge, we propose MMRHP, a miniature mixed-reality HIL platform that elevates miniaturized testing from functional demonstration to rigorous, reproducible quantitative analysis. The core contributions are threefold. First, we propose a systematic three-phase testing process oriented toward the Safety of the Intended Functionality(SOTIF)standard, providing actionable guidance for identifying the performance limits and triggering conditions of otherwise correctly functioning systems. Second, we design and implement a HIL platform centered around a unified spatiotemporal measurement core to support this process, ensuring consistent and traceable quantification of physical motion and system timing. Finally, we demonstrate the effectiveness of this solution through comprehensive experiments. The platform itself was first validated, achieving a spatial accuracy of 10.27 mm RMSE and a stable closed-loop latency baseline of approximately 45 ms. Subsequently, an in-depth Autoware case study leveraged this validated platform to quantify its performance baseline and identify a critical performance cliff at an injected latency of 40 ms. This work shows that a structured process, combined with a platform offering a unified spatio-temporal benchmark, enables reproducible, interpretable, and quantitative closed-loop evaluation of autonomous driving systems.

Paper number 56:
Title: Quantification of dual-state 5-ALA-induced PpIX fluorescence: Methodology and validation in tissue-mimicking phantoms
Authors: Silvère Ségaud, Charlie Budd, Matthew Elliot, Graeme Stasiuk, Jonathan Shapey, Yijing Xie, Tom Vercauteren
Abstract: Quantification of protoporphyrin IX (PpIX) fluorescence in human brain tumours has the potential to significantly improve patient outcomes in neuro-oncology, but represents a formidable imaging challenge. Protoporphyrin is a biological molecule which interacts with the tissue micro-environment to form two photochemical states in glioma. Each exhibits markedly different quantum efficiencies, with distinct but overlapping emission spectra that also overlap with tissue autofluorescence. Fluorescence emission is known to be distorted by the intrinsic optical properties of tissue, coupled with marked intra-tumoural heterogeneity as a hallmark of glioma tumours. Existing quantitative fluorescence systems are developed and validated using simplified phantoms that do not simultaneously mimic the complex interactions between fluorophores and tissue optical properties or micro-environment. Consequently, existing systems risk introducing systematic errors into PpIX quantification when used in tissue. In this work, we introduce a novel pipeline for quantification of PpIX in glioma, which robustly differentiates both emission states from background autofluorescence without reliance on a priori spectral information, and accounts for variations in their quantum efficiency. Unmixed PpIX emission forms are then corrected for wavelength-dependent optical distortions and weighted for accurate quantification. Significantly, this pipeline is developed and validated using novel tissue-mimicking phantoms replicating the optical properties of glioma tissues and photochemical variability of PpIX fluorescence in glioma. Our workflow achieves strong correlation with ground-truth PpIX concentrations (R2 = 0.918+-0.002), demonstrating its potential for robust, quantitative PpIX fluorescence imaging in clinical settings.

Paper number 57:
Title: MPC-based motion planning for non-holonomic systems in non-convex domains
Authors: Matthias Lorenzen, Teodoro Alamo, Martina Mammarella, Fabrizio Dabbene
Abstract: Motivated by the application of using model predictive control (MPC) for motion planning of autonomous mobile robots, a form of output tracking MPC for non- holonomic systems and with non-convex constraints is studied. Although the advantages of using MPC for motion planning have been demonstrated in several papers, in most of the available fundamental literature on output tracking MPC it is assumed, often implicitly, that the model is holonomic and generally the state or output constraints must be convex. Thus, in application-oriented publications, empirical results dominate and the topic of proving completeness, in particular under which assumptions the target is always reached, has received comparatively little attention. To address this gap, we present a novel MPC formulation that guarantees convergence to the desired target under realistic assumptions, which can be verified in relevant real-world scenarios.

Paper number 58:
Title: DeLoad: Demand-Driven Short-Video Preloading with Scalable Watch-Time Estimation
Authors: Tong Liu, Zhiwei Fan, Guanyan Peng, Haodan Zhang, Yucheng Zhang, Zhen Wang, Pengjin Xie, Liang Liu
Abstract: Short video streaming has become a dominant paradigm in digital media, characterized by rapid swiping interactions and diverse media content. A key technical challenge is designing an effective preloading strategy that dynamically selects and prioritizes download tasks from an evolving playlist, balancing Quality of Experience (QoE) and bandwidth efficiency under practical commercial constraints. However, real world analysis reveals critical limitations of existing approaches: (1) insufficient adaptation of download task sizes to dynamic conditions, and (2) watch time prediction models that are difficult to deploy reliably at scale. In this paper, we propose DeLoad, a novel preloading framework that addresses these issues by introducing dynamic task sizing and a practical, multi dimensional watch time estimation method. Additionally, a Deep Reinforcement Learning (DRL) enhanced agent is trained to optimize the download range decisions adaptively. Extensive evaluations conducted on an offline testing platform, leveraging massive real world network data, demonstrate that DeLoad achieves significant improvements in QoE metrics (34.4% to 87.4% gain). Furthermore, after deployment on a large scale commercial short video platform, DeLoad has increased overall user watch time by 0.09% while simultaneously reducing rebuffering events and 3.76% bandwidth consumption.

Paper number 59:
Title: Designing trajectories in the Earth-Moon system: a Levenberg-Marquardt approach
Authors: António Nunes, Sérgio Brás, Pedro Batista, João Xavier
Abstract: Trajectory design in cislunar space under a High-Fidelity Ephemeris Model (HFEM) is pursued through a nonlinear optimization perspective anchored on the transition of solutions from lower fidelity models, namely the Circular Restricted Three-Body Problem (CR3BP). The optimization problem is posed in the likeness of a multiple-shooting approach, aiming for segment-to-segment continuity while tracking proximity to the original CR3BP structures. The analysis of various formulations leads to the selection of an unconstrained least-squares problem for further investigation. The nonlinear optimization problem is convexified and the use of the Levenberg-Marquardt algorithm, as an alternative to the minimum-norm update equation found in most literature, is investigated for its control over the update step and inherent robustness. Additional techniques such as adaptive weighting are employed to further consolidate the behavior of the proposed algorithm in challenging scenarios. Numerical trials evaluate the adequacy of the methodology presented and compare it to the minimum-norm baseline over various application cases, including the generation of quasi-periodic trajectories and orbital transfers between them. The proposed approach is found to outperform the baseline in applications where the initial guess is poor and the ease of including proximity constraints provides benefits in control over the shape of the converged solution.

Paper number 60:
Title: A Stage-Wise Learning Strategy with Fixed Anchors for Robust Speaker Verification
Authors: Bin Gu, Lipeng Dai, Huipeng Du, Haitao Zhao, Jibo Wei
Abstract: Learning robust speaker representations under noisy conditions presents significant challenges, which requires careful handling of both discriminative and noise-invariant properties. In this work, we proposed an anchor-based stage-wise learning strategy for robust speaker representation learning. Specifically, our approach begins by training a base model to establish discriminative speaker boundaries, and then extract anchor embeddings from this model as stable references. Finally, a copy of the base model is fine-tuned on noisy inputs, regularized by enforcing proximity to their corresponding fixed anchor embeddings to preserve speaker identity under distortion. Experimental results suggest that this strategy offers advantages over conventional joint optimization, particularly in maintaining discrimination while improving noise robustness. The proposed method demonstrates consistent improvements across various noise conditions, potentially due to its ability to handle boundary stabilization and variation suppression separately.

Paper number 61:
Title: Noise-Conditioned Mixture-of-Experts Framework for Robust Speaker Verification
Authors: Bin Gu, Lipeng Dai, Huipeng Du, Haitao Zhao, Jibo Wei
Abstract: Robust speaker verification under noisy conditions remains an open challenge. Conventional deep learning methods learn a robust unified speaker representation space against diverse background noise and achieve significant improvement. In contrast, this paper presents a noise-conditioned mixture-ofexperts framework that decomposes the feature space into specialized noise-aware subspaces for speaker verification. Specifically, we propose a noise-conditioned expert routing mechanism, a universal model based expert specialization strategy, and an SNR-decaying curriculum learning protocol, collectively improving model robustness and generalization under diverse noise conditions. The proposed method can automatically route inputs to expert networks based on noise information derived from the inputs, where each expert targets distinct noise characteristics while preserving speaker identity information. Comprehensive experiments demonstrate consistent superiority over baselines, confirming that explicit noise-dependent feature modeling significantly enhances robustness without sacrificing verification accuracy.

Paper number 62:
Title: PIRA: Pan-CDN Intra-video Resource Adaptation for Short Video Streaming
Authors: Chunyu Qiao, Tong Liu, Yucheng Zhang, Zhiwei Fan, Pengjin Xie, Zhen Wang, Liang Liu
Abstract: In large scale short video platforms, CDN resource selection plays a critical role in maintaining Quality of Experience (QoE) while controlling escalating traffic costs. To better understand this phenomenon, we conduct in the wild network measurements during video playback in a production short video system. The results reveal that CDNs delivering higher average QoE often come at greater financial cost, yet their connection quality fluctuates even within a single video underscoring a fundamental and dynamic trade off between QoE and cost. However, the problem of sustaining high QoE under cost constraints remains insufficiently investigated in the context of CDN selection for short video streaming. To address this, we propose PIRA, a dynamic resource selection algorithm that optimizes QoE and cost in real time during video playback. PIRA formally integrating QoE and cost by a mathematical model, and introduce a intra video control theoretic CDN resource selection approach which can balance QoE and cost under network dynamics. To reduce the computation overheads, PIRA employs state space pruning and adaptive parameter adjustment to efficiently solve the high dimensional optimization problem. In large scale production experiments involving 450,000 users over two weeks, PIRA outperforms the production baseline, achieving a 2.1% reduction in start up delay, 15.2% shorter rebuffering time, and 10% lower average unit traffic cost, demonstrating its effectiveness in balancing user experience and financial cost at scale.

Paper number 63:
Title: A Note on Optimal Distributed State Estimation for Linear Time-Varying Systems
Authors: Irene Perez-Salesa, Rodrigo Aldana-Lopez, Carlos Sagues
Abstract: In this technical note, we prove that the ODEFTC algorithm constitutes the first optimal distributed state estimator for continuous-time linear time-varying systems subject to stochastic disturbances. Particularly, we formally show that it is able to asymptotically recover the performance, in terms of error covariance of the estimates at each node, of the centralized Kalman-Bucy filter, which is known to be the optimal filter for the considered class of systems. Moreover, we provide a simple sufficient value for the consensus gain to guarantee the stability of the distributed estimator.

Paper number 64:
Title: Bayesian Low-Rank Factorization for Robust Model Adaptation
Authors: Enes Yavuz Ugan, Ngoc-Quan Pham, Alexander Waibel
Abstract: Large speech foundation models achieve strong performance across many domains, but they often require adaptation to handle local needs such as code-switching, where speakers mix languages within the same utterance. Direct fine-tuning of these models risks overfitting to the target domain and overwriting the broad capabilities of the base model. To address this challenge, we explore Bayesian factorized adapters for speech foundation models, which place priors near zero to achieve sparser adaptation matrices and thereby retain general performance while adapting to specific domains. We apply our approach to the Whisper model and evaluate on different multilingual code-switching scenarios. Our results show only minimal adaptation loss while significantly reducing catastrophic forgetting of the base model. Compared to LoRA, our method achieves a backward gain of 54% with only a 4% drop on the new domain. These findings highlight the effectiveness of Bayesian adaptation for fine-tuning speech foundation models without sacrificing generalization.

Paper number 65:
Title: Adapting Language Balance in Code-Switching Speech
Authors: Enes Yavuz Ugan, Ngoc-Quan Pham, Alexander Waibel
Abstract: Despite achieving impressive results on standard benchmarks, large foundational models still struggle against code-switching test cases. When data scarcity cannot be used as the usual justification for poor performance, the reason may lie in the infrequent occurrence of code-switched moments, where the embedding of the second language appears subtly. Instead of expecting the models to learn this infrequency on their own, it might be beneficial to provide the training process with labels. Evaluating model performance on code-switching data requires careful localization of code-switching points where recognition errors are most consequential, so that the analysis emphasizes mistakes occurring at those moments. Building on this observation, we leverage the difference between the embedded and the main language to highlight those code-switching points and thereby emphasize learning at those locations. This simple yet effective differentiable surrogate mitigates context bias during generation -- the central challenge in code-switching -- thereby improving the model's robustness. Our experiments with Arabic and Chinese-English showed that the models are able to predict the switching places more correctly, reflected by the reduced substitution error.

Paper number 66:
Title: MADR: MPC-guided Adversarial DeepReach
Authors: Ryan Teoh, Sander Tonkens, William Sharpless, Aijia Yang, Zeyuan Feng, Somil Bansal, Sylvia Herbert
Abstract: Hamilton-Jacobi (HJ) Reachability offers a framework for generating safe value functions and policies in the face of adversarial disturbance, but is limited by the curse of dimensionality. Physics-informed deep learning is able to overcome this infeasibility, but itself suffers from slow and inaccurate convergence, primarily due to weak PDE gradients and the complexity of self-supervised learning. A few works, recently, have demonstrated that enriching the self-supervision process with regular supervision (based on the nature of the optimal control problem), greatly accelerates convergence and solution quality, however, these have been limited to single player problems and simple games. In this work, we introduce MADR: MPC-guided Adversarial DeepReach, a general framework to robustly approximate the two-player, zero-sum differential game value function. In doing so, MADR yields the corresponding optimal strategies for both players in zero-sum games as well as safe policies for worst-case robustness. We test MADR on a multitude of high-dimensional simulated and real robotic agents with varying dynamics and games, finding that our approach significantly out-performs state-of-the-art baselines in simulation and produces impressive results in hardware.

Paper number 67:
Title: Lyapunov-Aware Quantum-Inspired Reinforcement Learning for Continuous-Time Vehicle Control: A Feasibility Study
Authors: Nutkritta Kraipatthanapong, Natthaphat Thathong, Pannita Suksawas, Thanunnut Klunklin, Kritin Vongthonglua, Krit Attahakul, Aueaphum Aueawatthanaphisut
Abstract: This paper presents a novel Lyapunov-Based Quantum Reinforcement Learning (LQRL) framework that integrates quantum policy optimization with Lyapunov stability analysis for continuous-time vehicle control. The proposed approach combines the representational power of variational quantum circuits (VQCs) with a stability-aware policy gradient mechanism to ensure asymptotic convergence and safe decision-making under dynamic environments. The vehicle longitudinal control problem was formulated as a continuous-state reinforcement learning task, where the quantum policy network generates control actions subject to Lyapunov stability constraints. Simulation experiments were conducted in a closed-loop adaptive cruise control scenario using a quantum-inspired policy trained under stability feedback. The results demonstrate that the LQRL framework successfully embeds Lyapunov stability verification into quantum policy learning, enabling interpretable and stability-aware control performance. Although transient overshoot and Lyapunov divergence were observed under aggressive acceleration, the system maintained bounded state evolution, validating the feasibility of integrating safety guarantees within quantum reinforcement learning architectures. The proposed framework provides a foundational step toward provably safe quantum control in autonomous systems and hybrid quantum-classical optimization domains.

Paper number 68:
Title: Finite-time Safety and Reach-avoid Verification of Stochastic Discrete-time Systems
Authors: Bai Xue
Abstract: This paper studies finite-time safety and reach-avoid verification for stochastic discrete-time dynamical systems. The aim is to ascertain lower and upper bounds of the probability that, within a predefined finite-time horizon, a system starting from an initial state in a safe set will either exit the safe set (safety verification) or reach a target set while remaining within the safe set until the first encounter with the target (reach-avoid verification). We introduce novel barrier-like sufficient conditions for characterizing these bounds, which either complement existing ones or fill gaps. Finally, we demonstrate the efficacy of these conditions on two examples.

Paper number 69:
Title: Experimental Assessment of Human Blockage at sub-THz and mmWave Frequency Bands
Authors: Juan E. Galeote-Cazorla, Alejandro Ramírez-Arroyo, José-María Molina-García-Pardo, María-Teresa Martínez-Inglés, Juan F. Valenzuela Valdés
Abstract: The fifth generation (5G) of mobile communications relies on extremely high data transmissions using a large variety of frequency bands, such as FR1 (sub-6 GHz) and FR2 (mmWave). Future mobile communications envisage using electromagnetic spectrum beyond FR2, i.e. above 100 GHz, known as sub-THz band. These new frequencies open up challenging scenarios where communications shall rely on a major contribution such as the line-of-sight (LoS) component. To the best of the authors' knowledge, for the first time in literature this work studies the human blockage effects over an extremely wide frequency band from 75 GHz to 215 GHz given: (i) the distance between the blocker and the antennas and (ii) the body orientation. Furthermore, the obtained results are modeled with the classical path loss models and compared to 3GPP alternatives. The average losses increase from 42 dB to 56 dB when frequency rises from 75 GHz to 215 GHz. In terms of distance, a 18 dB increment in the received power is found when the Tx--Rx separation is increased from 1 m to 2.5 m. Finally, the blocker orientation induces variations of up to 4.6 dB.

Paper number 70:
Title: RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation
Authors: Juntao Jiang, Jiangning Zhang, Weixuan Liu, Muxuan Gao, Xiaobin Hu, Zhucun Xue, Yong Liu, Shuicheng Yan
Abstract: In recent years, significant advancements have been made in deep learning for medical image segmentation, particularly with convolutional neural networks (CNNs) and transformer models. However, CNNs face limitations in capturing long-range dependencies, while transformers suffer from high computational complexity. To address this, we propose RWKV-UNet, a novel model that integrates the RWKV (Receptance Weighted Key Value) structure into the U-Net architecture. This integration enhances the model's ability to capture long-range dependencies and to improve contextual understanding, which is crucial for accurate medical image segmentation. We build a strong encoder with developed Global-Local Spatial Perception (GLSP) blocks combining CNNs and RWKVs. We also propose a Cross-Channel Mix (CCM) module to improve skip connections with multi-scale feature fusion, achieving global channel information integration. Experiments on 11 benchmark datasets show that the RWKV-UNet achieves state-of-the-art performance on various types of medical image segmentation tasks. Additionally, smaller variants, RWKV-UNet-S and RWKV-UNet-T, balance accuracy and computational efficiency, making them suitable for broader clinical applications.

Paper number 71:
Title: Low-cost Embedded Breathing Rate Determination Using 802.15.4z IR-UWB Hardware for Remote Healthcare
Authors: Anton Lambrecht, Stijn Luchie, Jaron Fontaine, Ben Van Herbruggen, Adnan Shahid, Eli De Poorter
Abstract: Respiratory diseases account for a significant portion of global mortality. Affordable and early detection is an effective way of addressing these ailments. To this end, a low-cost commercial off-the-shelf (COTS), IEEE 802.15.4z standard compliant impulse-radio ultra-wideband (IR-UWB) radar system is used to estimate human respiration rates. We propose a convolutional neural network (CNN) specifically adapted to predict breathing rates from ultra-wideband (UWB) channel impulse response (CIR) data, and compare its performance with both other rule-based algorithms and model-based solutions. The study uses a diverse dataset, incorporating various real-life environments to evaluate system robustness. To facilitate future research, this dataset will be released as open source. Results show that the CNN achieves a mean absolute error (MAE) of 1.73 breaths per minute (BPM) in unseen situations, significantly outperforming rule-based methods (3.40 BPM). By incorporating calibration data from other individuals in the unseen situations, the error is further reduced to 0.84 BPM. In addition, this work evaluates the feasibility of running the pipeline on a low-cost embedded device. Applying 8-bit quantization to both the weights and input/ouput tensors, reduces memory requirements by 67% and inference time by 64% with only a 3% increase in MAE. As a result, we show it is feasible to deploy the algorithm on an nRF52840 system-on-chip (SoC) requiring only 46 KB of memory and operating with an inference time of only 192 ms. Once deployed, an analytical energy model estimates that the system, while continuously monitoring the room, can operate for up to 268 days without recharging when powered by a 20 000 mAh battery pack. For breathing monitoring in bed, the sampling rate can be lowered, extending battery life to 313 days, making the solution highly efficient for real-world, low-cost deployments.

Paper number 72:
Title: Semi-Blind Strategies for MMSE Channel Estimation Utilizing Generative Priors
Authors: Franz Weißer, Nurettin Turan, Dominik Semmler, Fares Ben Jazia, Wolfgang Utschick
Abstract: This paper investigates semi-blind channel estimation for massive multiple-input multiple-output (MIMO) systems. To this end, we first estimate a subspace based on all received symbols (pilot and payload) to provide additional information for subsequent channel estimation. This additional information enhances minimum mean square error (MMSE) channel estimation. Two variants of the linear MMSE (LMMSE) estimator are formulated, where the first one solves the estimation within the subspace, and the second one uses a subspace projection as a preprocessing step. Theoretical derivations show the latter method's superior estimation performance in terms of mean square error for uncorrelated Rayleigh fading. Further, we provide asymptotic insights on how the proposed MMSE-based channel estimation strategy outperforms the unbiased Cramer-Rao bound. Subsequently, we introduce parameterizations of these semi-blind LMMSE estimators based on two different conditional Gaussian latent models, i.e., the Gaussian mixture model and the variational autoencoder. Both models learn the propagation environment's underlying channel distribution based on training data and serve as generative priors for our semi-blind channel estimation. Extensive simulations for real-world measurement data and spatial channel models show the proposed methods' superior performance compared to state-of-the-art semi-blind channel estimators in terms of MSE.

Paper number 73:
Title: Unifying Direct and Indirect Learning for Safe Control of Linear Systems
Authors: Amir Modares, Niyousha Ghiasi, Bahare Kiumarsi, Hamidreza Modares
Abstract: This paper develops learning-enabled safe controllers for linear systems subject to system uncertainties and bounded disturbances. Given the disturbance zonotope, the databased closed-loop dynamics (CLDs) are first characterized using a matrix zonotope (MZ), and refined through several steps to yield a constrained matrix zonotope (CMZ). This refinement is achieved by introducing conformal equality constraints that eliminate incompatible disturbance realizations. More precisely, prior knowledge and observed data are used separately to construct CMZ representations of disturbance sequences that conform to both data and prior knowledge, and are intersected by the initial MZ of the disturbance sequence, producing a refined CMZ. This approach reduces conservatism. To further reduce the conservativeness, we unify open-loop learning with closed-loop learning by presenting a novel set-membership identification method that models open-loop dynamics as a CMZ. The prior knowledge serves as an initial feasible open-loop model set (FOLMS) of this CMZ, which is refined into a posterior set whenever new informative online data becomes available. This posterior FOLMS then adaptively replaces the prior knowledge set employed in the disturbance elimination of the closed-loop learning process. The resulting refined parameterized set of CLD is subsequently leveraged to directly and adaptively learn a controller that robustly enforces safety. Toward this goal, we formulate a linear programming problem that guarantees {\lambda}contractiveness of a polyhedral safe set. A simulation example is provided to validate the effectiveness of the proposed approach and support the theoretical results.

Paper number 74:
Title: A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography
Authors: Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Fan Zhang, Weidong Cai, Lauren J. O'Donnell
Abstract: Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) features to predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model to predict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis.

Paper number 75:
Title: Regression is all you need for medical image translation
Authors: Sebastian Rassmann, David Kügler, Christian Ewert, Martin Reuter
Abstract: While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have achieved impressive results in natural image synthesis, their core strengths - creativity and realism - can be detrimental in medical applications, where accuracy and fidelity are paramount. These models instead risk introducing hallucinations and replication of unwanted acquisition noise. Here, we propose YODA (You Only Denoise once - or Average), a 2.5D diffusion-based framework for medical image translation (MIT). Consistent with DM theory, we find that conventional diffusion sampling stochastically replicates noise. To mitigate this, we draw and average multiple samples, akin to physical signal averaging. As this effectively approximates the DM's expected value, we term this Expectation-Approximation (ExpA) sampling. We additionally propose regression sampling YODA, which retains the initial DM prediction and omits iterative refinement to produce noise-free images in a single step. Across five diverse multi-modal datasets - including multi-contrast brain MRI and pelvic MRI-CT - we demonstrate that regression sampling is not only substantially more efficient but also matches or exceeds image quality of full diffusion sampling even with ExpA. Our results reveal that iterative refinement solely enhances perceptual realism without benefiting information translation, which we confirm in relevant downstream tasks. YODA outperforms eight state-of-the-art DMs and GANs and challenges the presumed superiority of DMs and GANs over computationally cheap regression models for high-quality MIT. Furthermore, we show that YODA-translated images are interchangeable with, or even superior to, physical acquisitions for several medical applications.

Paper number 76:
Title: Robust Activity Detection for Massive Random Access
Authors: Xinjue Wang, Esa Ollila, Sergiy A. Vorobyov
Abstract: Massive machine-type communications (mMTC) are fundamental to the Internet of Things (IoT) framework in future wireless networks, involving the connection of a vast number of devices with sporadic transmission patterns. Traditional device activity detection (AD) methods are typically developed for Gaussian noise, but their performance may deteriorate when these conditions are not met, particularly in the presence of heavy-tailed impulsive noise. In this paper, we propose robust statistical techniques for AD that do not rely on the Gaussian assumption and replace the Gaussian loss function with robust loss functions that can effectively mitigate the impact of heavy-tailed noise and outliers. First, we prove that the coordinate-wise (conditional) objective function is geodesically convex and derive a fixed-point (FP) algorithm for minimizing it, along with convergence guarantees. Building on the FP algorithm, we propose two robust algorithms for solving the full (unconditional) objective function: a coordinate-wise optimization algorithm (RCWO) and a greedy covariance learning-based matching pursuit algorithm (RCL-MP). Numerical experiments demonstrate that the proposed methods significantly outperform existing algorithms in scenarios with non-Gaussian noise, achieving higher detection accuracy and robustness.

Paper number 77:
Title: Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone
Authors: Cen Liu, Xiangyun Zhou, Nan Yang, Salman Durrani, A. Lee Swindlehurst
Abstract: This work studies near-field secure communications through transmit beamfocusing. We examine the benefit of having a protected eavesdropper-free zone around the legitimate receiver, and we determine the worst-case secrecy performance against a potential eavesdropper located anywhere outside the protected zone. A max-min optimization problem is formulated for the beamfocusing design with and without artificial noise transmission. Despite the NP-hardness of the problem, we develop a synchronous gradient descent-ascent framework that approximates the global maximin solution. A low-complexity solution is also derived that delivers excellent performance over a wide range of operating conditions. We further extend this study to a scenario where it is not possible to physically enforce a protected zone. To this end, we consider secure communications through the creation of a virtual protected zone using a full-duplex legitimate receiver. Numerical results demonstrate that exploiting either the physical or virtual receiver-centered protected zone with appropriately designed beamfocusing is an effective strategy for achieving secure near-field communications.

Paper number 78:
Title: Model-based Implicit Neural Representation for sub-wavelength Radio Localization
Authors: Baptiste Chatelier (IETR, INSA Rennes, MERCE-France), Vincent Corlay (MERCE-France), Musa Furkan Keskin, Matthieu Crussière (INSA Rennes, IETR), Henk Wymeersch, Luc Le Magoarou (INSA Rennes, IETR)
Abstract: The increasing deployment of large antenna arrays at base stations has significantly improved the spatial resolution and localization accuracy of radio-localization methods. However, traditional signal processing techniques struggle in complex radio environments, particularly in scenarios dominated by non line of sight (NLoS) propagation paths, resulting in degraded localization accuracy. Recent developments in machine learning have facilitated the development of machine learning-assisted localization techniques, enhancing localization accuracy in complex radio environments. However, these methods often involve substantial computational complexity during both the training and inference phases. This work extends the well-established fingerprinting-based localization framework by simultaneously reducing its memory requirements and improving its accuracy. Specifically, a model-based neural network is used to learn the location-to-channel mapping, and then serves as a generative neural channel model. This generative model augments the fingerprinting comparison dictionary while reducing the memory requirements. The proposed method outperforms fingerprinting baselines by achieving sub-wavelength localization accuracy, even in complex static NLoS environments. Remarkably, it offers an improvement by several orders of magnitude in localization accuracy, while simultaneously reducing memory requirements by an order of magnitude compared to classical fingerprinting methods.

Paper number 79:
Title: Lightweight and Robust Multi-Channel End-to-End Speech Recognition with Spherical Harmonic Transform
Authors: Xiangzhu Kong, Huang Hao, Zhijian Ou
Abstract: This paper presents SHTNet, a lightweight spherical harmonic transform (SHT) based framework, which is designed to address cross-array generalization challenges in multi-channel automatic speech recognition (ASR) through three key innovations. First, SHT based spatial sound field decomposition converts microphone signals into geometry-invariant spherical harmonic coefficients, isolating signal processing from array geometry. Second, the Spatio-Spectral Attention Fusion Network (SSAFN) combines coordinate-aware spatial modeling, refined self-attention channel combinator, and spectral noise suppression without conventional beamforming. Third, Rand-SHT training enhances robustness through random channel selection and array geometry reconstruction. The system achieves 39.26\% average CER across heterogeneous arrays (e.g., circular, square, and binaural) on datasets including Aishell-4, Alimeeting, and XMOS, with 97.1\% fewer computations than conventional neural beamformers.

Paper number 80:
Title: Post-training for Deepfake Speech Detection
Authors: Wanying Ge, Xin Wang, Xuechen Liu, Junichi Yamagishi
Abstract: We introduce a post-training approach that adapts self-supervised learning (SSL) models for deepfake speech detection by bridging the gap between general pre-training and domain-specific fine-tuning. We present AntiDeepfake models, a series of post-trained models developed using a large-scale multilingual speech dataset containing over 56,000 hours of genuine speech and 18,000 hours of speech with various artifacts in over one hundred languages. Experimental results show that the post-trained models already exhibit strong robustness and generalization to unseen deepfake speech. When they are further fine-tuned on the Deepfake-Eval-2024 dataset, these models consistently surpass existing state-of-the-art detectors that do not leverage post-training. Model checkpoints and source code are available online.

Paper number 81:
Title: SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction
Authors: Kaveh Moradkhani, R Jarrett Rushmore, Sylvain Bouix
Abstract: Accurate cortical surface reconstruction from magnetic resonance imaging (MRI) data is crucial for reliable neuroanatomical analyses. Current methods have to contend with complex cortical geometries, strict topological requirements, and often produce surfaces with overlaps, self-intersections, and topological defects. To overcome these shortcomings, we introduce SimCortex, a deep learning framework that simultaneously reconstructs all brain surfaces (left/right white-matter and pial) from T1-weighted(T1w) MRI volumes while preserving topological properties. Our method first segments the T1w image into a nine-class tissue label map. From these segmentations, we generate subject-specific, collision-free initial surface meshes. These surfaces serve as precise initializations for subsequent multiscale diffeomorphic deformations. Employing stationary velocity fields (SVFs) integrated via scaling-and-squaring, our approach ensures smooth, topology-preserving transformations with significantly reduced surface collisions and self-intersections. Evaluations on standard datasets demonstrate that SimCortex dramatically reduces surface overlaps and self-intersections, surpassing current methods while maintaining state-of-the-art geometric accuracy.

Paper number 82:
Title: Adapting Medical Vision Foundation Models for Volumetric Medical Image Segmentation via Active Learning and Selective Semi-supervised Fine-tuning
Authors: Jin Yang, Daniel S. Marcus, Aristeidis Sotiras
Abstract: Medical Vision Foundation Models (Med-VFMs) have superior capabilities of interpreting medical images due to the knowledge learned from self-supervised pre-training with extensive unannotated images. To improve their performance on adaptive downstream evaluations, especially segmentation, a few samples from target domains are selected randomly for fine-tuning them. However, there lacks works to explore the way of adapting Med-VFMs to achieve the optimal performance on target domains efficiently. Thus, it is highly demanded to design an efficient way of fine-tuning Med-VFMs by selecting informative samples to maximize their adaptation performance on target domains. To achieve this, we propose an Active Source-Free Domain Adaptation (ASFDA) method to efficiently adapt Med-VFMs to target domains for volumetric medical image segmentation. This ASFDA employs a novel Active Learning (AL) method to select the most informative samples from target domains for fine-tuning Med-VFMs without the access to source pre-training samples, thus maximizing their performance with the minimal selection budget. In this AL method, we design an Active Test Time Sample Query strategy to select samples from the target domains via two query metrics, including Diversified Knowledge Divergence (DKD) and Anatomical Segmentation Difficulty (ASD). DKD is designed to measure the source-target knowledge gap and intra-domain diversity. It utilizes the knowledge of pre-training to guide the querying of source-dissimilar and semantic-diverse samples from the target domains. ASD is designed to evaluate the difficulty in segmentation of anatomical structures by measuring predictive entropy from foreground regions adaptively. Additionally, our ASFDA method employs a Selective Semi-supervised Fine-tuning to improve the performance and efficiency of fine-tuning by identifying samples with high reliability from unqueried ones.

Paper number 83:
Title: Accurate Small-Signal Modeling of Digitally Controlled Buck Converters with ADC-PWM Synchronization
Authors: Hang Zhou, Yuxin Yang, Branislav Hredzak, John Edward Fletcher
Abstract: Digital control has become increasingly widespread in modern power electronic converters. When acquiring feedback signals such as the inductor current, synchronizing the analog-to-digital converter (ADC) with the digital pulse-width modulator (DPWM) is commonly employed to accurately track their steady-state average. However, the small-signal implications of such synchronization have not been investigated. This paper presents an exact small-signal model for digitally controlled buck converters operating in forced continuous-conduction mode (FCCM) under constant-frequency current-mode control, explicitly accounting for DPWM-ADC synchronization. Using a sampled-data framework, the proposed model captures all sideband effects introduced by the sampling process, yielding precise predictions of both analog and digital loop gains, even at frequencies beyond the switching and sampling frequencies. Both asymmetrical and symmetrical carrier modulations are considered. Furthermore, the digital loop gain is derived in closed form using the modified z-transform, enabling low-complexity compensator design and stability assessment. Within this framework, the analog loop gain can be directly obtained from the digital loop gain, thereby eliminating the need for computationally intensive infinite series evaluations. The validity of the proposed model is confirmed through both simulation and experimental results.

Paper number 84:
Title: Curriculum Learning with Synthetic Data for Enhanced Pulmonary Nodule Detection in Chest Radiographs
Authors: Pranav Sambhu, Om Guin, Madhav Sambhu, Jinho Cha
Abstract: This study evaluates whether integrating curriculum learning with diffusion-based synthetic augmentation can enhance the detection of difficult pulmonary nodules in chest radiographs, particularly those with low size, brightness, and contrast, which often challenge conventional AI models due to data imbalance and limited annotation. A Faster R-CNN with a Feature Pyramid Network (FPN) backbone was trained on a hybrid dataset comprising expert-labeled NODE21 (1,213 patients; 52.4 percent male; mean age 63.2 +/- 11.5 years), VinDr-CXR, CheXpert, and 11,206 DDPM-generated synthetic images. Difficulty scores based on size, brightness, and contrast guided curriculum learning. Performance was compared to a non-curriculum baseline using mean average precision (mAP), Dice score, and area under the curve (AUC). Statistical tests included bootstrapped confidence intervals, DeLong tests, and paired t-tests. The curriculum model achieved a mean AUC of 0.95 versus 0.89 for the baseline (p < 0.001), with improvements in sensitivity (70 percent vs. 48 percent) and accuracy (82 percent vs. 70 percent). Stratified analysis demonstrated consistent gains across all difficulty bins (Easy to Very Hard). Grad-CAM visualizations confirmed more anatomically focused attention under curriculum learning. These results suggest that curriculum-guided synthetic augmentation enhances model robustness and generalization for pulmonary nodule detection.

Paper number 85:
Title: Modeling the Impact of Communication and Human Uncertainties on Runway Capacity in Terminal Airspace
Authors: Yutian Pang, Andrew Kendall, John-Paul Clarke
Abstract: We investigate the potential impact of communication and human performance uncertainties on runway operations. Specifically, we consider these impacts within the context of an arrival scenario with two converging flows: a straight-in approach stream and a downwind stream merging into it. Both arrival stream are modeled using a modified Possion distribution that incorporate the separation minima as well as the runway occupancy time. Various system level uncertainties are addressed in this process, including communication link- and human-related uncertainties. In this research, we first build a Monte Carlo-based discrete-time simulation, where aircraft arrivals are generated by modified Poisson processes subject to minimum separation constraints, simulating various traffic operations. The merging logic incorporates standard bank angle continuous turn-to-final, pilot response delays, and dynamic gap availability in real time. Then, we investigate an automated final approach vectoring model (i.e., Auto-ATC), in which inverse optimal control is used to learn decision advisories from human expert records. By augmenting trajectories and incorporating the aforementioned uncertainties into the planning scenario, we create a setup analogous to the discrete event simulation. For both studies, runway capacity is measured by runway throughput, the fraction of downwind arrivals that merge immediately without holding, and the average delay (i.e., holding time/distance) experienced on the downwind leg. This research provides a method for runway capacity estimation in merging scenarios, and demonstrates that aeronautical communication link uncertainties significantly affect runway capacity in current voice-based operations, whereas the impact can be mitigated in autonomous operational settings.

Paper number 86:
Title: Wireless Channel Modeling for Machine Learning - A Critical View on Standardized Channel Models
Authors: Benedikt Böck, Amar Kasibovic, Wolfgang Utschick
Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models are frequently used to evaluate machine learning (ML)-based physical-layer methods. However, in this work, we argue that a link-level perspective incorporates limiting assumptions, causing unwanted distributional shifts or necessitating impractical online training. An additional drawback is that this perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based models, trained on link-level channel data, do not outperform classical approaches for a variety of physical-layer applications. Particularly, we demonstrate the optimality of simple linear methods for channel compression, estimation, and modeling, revealing the unsuitability of link-level channel models for evaluating ML models. On the upside, adopting a scenario-level perspective offers a solution to this problem and unlocks the relative gains enabled by ML.

Paper number 87:
Title: Incomplete Multi-view Clustering via Hierarchical Semantic Alignment and Cooperative Completion
Authors: Xiaojian Ding, Lin Zhao, Xian Li, Xiaoying Zhu
Abstract: Incomplete multi-view data, where certain views are entirely missing for some samples, poses significant challenges for traditional multi-view clustering methods. Existing deep incomplete multi-view clustering approaches often rely on static fusion strategies or two-stage pipelines, leading to suboptimal fusion results and error propagation issues. To address these limitations, this paper proposes a novel incomplete multi-view clustering framework based on Hierarchical Semantic Alignment and Cooperative Completion (HSACC). HSACC achieves robust cross-view fusion through a dual-level semantic space design. In the low-level semantic space, consistency alignment is ensured by maximizing mutual information across views. In the high-level semantic space, adaptive view weights are dynamically assigned based on the distributional affinity between individual views and an initial fused representation, followed by weighted fusion to generate a unified global representation. Additionally, HSACC implicitly recovers missing views by projecting aligned latent representations into high-dimensional semantic spaces and jointly optimizes reconstruction and clustering objectives, enabling cooperative learning of completion and clustering. Experimental results demonstrate that HSACC significantly outperforms state-of-the-art methods on five benchmark datasets. Ablation studies validate the effectiveness of the hierarchical alignment and dynamic weighting mechanisms, while parameter analysis confirms the model's robustness to hyperparameter variations.

Paper number 88:
Title: Through-the-Earth Magnetic Induction Communication and Networking: A Comprehensive Survey
Authors: Honglei Ma, Erwu Liu, Wei Ni, Zhijun Fang, Rui Wang, Yongbin Gao, Dusit Niyato, Ekram Hossain
Abstract: Magnetic induction (MI) communication (MIC) has emerged as a promising candidate for underground communication networks due to its excellent penetration capabilities. Integration with Space-Air-Ground-Underground (SAGUI) networks in next-generation mobile communication systems requires a well-defined network architecture. A recent discovery in MIC research, MI fast fading, remains in its early stages and presents unique challenges. This paper provides a comprehensive survey on through-the-earth (TTE) MIC, covering MI applications, channel modeling, point-to-point MIC design, relay techniques, network frameworks, and emerging technologies. We compare various MIC applications to highlight TTE-specific challenges and review the principles of channel modeling, addressing both MI slow fading and MI fast fading, along with its potential impact on existing MIC theories. We conduct a fine-grained decomposition of MI channel power gain into four distinct physical parameters, and propose a novel geometric model to analyze MI fast fading. We also summarize MI relay techniques, examine crosstalk effects in relay and high-density networks, and explore key research tasks within the OSI framework for a holistic MI network protocol in SAGUI. To bridge the gaps identified, we propose a MIC framework that supports TCP/IP and Linux, enabling full implementation of existing and emerging MIC solutions. This framework empowers researchers to leverage Linux resources and deep learning platforms for accelerated development of MIC in SAGUI networks. Remaining research challenges, open issues, and promising novel techniques are further identified to advance MIC research.

Paper number 89:
Title: Computer Navigated Spinal Surgery Using Magnetic Resonance Imaging and Augmented Reality
Authors: Songyuan Lu, Jingwen Hui, Jake Weeks, David B. Berry, Fanny Chapelin, Frank Talke
Abstract: Current spinal pain management procedures, such as radiofrequency ablation (RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle placement which exposes patients and physicians to ionizing radiation. In this paper, we investigate a radiation-free surgical navigation system for spinal pain management procedures that combines magnetic resonance imaging (MRI) with fiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans of a lumbar spinal phantom were obtained and assembled as a surface mesh. Laplacian smoothing algorithms were then applied to smoothen the surface and improve the model fidelity. A commercially available stereo camera (ZED2) was used to track single or dual fiducial ArUco markers on the patient to determine the patient's real-time pose. Custom AR software was applied to overlay the MRI image onto the patient, allowing the physician to see not only the outer surface of the patient but also the complete anatomy of the patient below the surface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that dual-ArUco marker tracking increased the accuracy of needle insertions and reduced the average needle misplacement distance compared to single-ArUco marker procedures. The average needle misplacement is comparable to the average deviation of 2 mm for conventional epidural techniques using fluoroscopy. Our radiation-free system demonstrates promise to serve as an alternative to fluoroscopy by improving image-guided spinal navigation.

Paper number 90:
Title: One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares
Authors: Youngjae Min, Namhoon Cho, Navid Azizan
Abstract: While large machine learning models have shown remarkable performance in various domains, their training typically requires iterating for many passes over the training data. However, due to computational and memory constraints and potential privacy concerns, storing and accessing all the data is impractical in many real-world scenarios where the data arrives in a stream. In this paper, we investigate the problem of one-pass learning, in which a model is trained on sequentially arriving data without retraining on previous datapoints. Motivated by the demonstrated effectiveness of overparameterized models and the phenomenon of benign overfitting, we propose Orthogonal Recursive Fitting (ORFit), an algorithm for one-pass learning which seeks to perfectly fit each new datapoint while minimally altering the predictions on previous datapoints. ORFit updates the parameters in a direction orthogonal to past gradients, similar to orthogonal gradient descent (OGD) in continual learning. We show that, interestingly, ORFit's update leads to an operation similar to the recursive least-squares (RLS) algorithm in adaptive filtering but with significantly improved memory and computational efficiency, i.e., linear, instead of quadratic, in the number of parameters. To further reduce memory usage, we leverage the structure of the streaming data via an incremental principal component analysis (IPCA). We show that using the principal components is minimax optimal, i.e., it minimizes the worst-case forgetting of previous predictions for unknown future updates. Further, we prove that, for overparameterized linear models, the parameter vector obtained by ORFit matches what the standard multi-pass stochastic gradient descent (SGD) would converge to. Finally, we extend our results to the nonlinear setting for highly overparameterized models, relevant for deep learning.

Paper number 91:
Title: A Flow-Based Model for Conditional and Probabilistic Electricity Consumption Profile Generation and Prediction
Authors: Weijie Xia, Chenguang Wang, Peter Palensky, Pedro P. Vergara
Abstract: Residential Load Profile (RLP) generation and prediction are critical for the operation and planning of distribution networks, especially as diverse low-carbon technologies (e.g., photovoltaic and electric vehicles) are increasingly adopted. This paper introduces a novel flow-based generative model, termed Full Convolutional Profile Flow (FCPFlow), which is uniquely designed for both conditional and unconditional RLP generation, and for probabilistic load forecasting. By introducing two new layers--the invertible linear layer and the invertible normalization layer--the proposed FCPFlow architecture shows three main advantages compared to traditional statistical and contemporary deep generative models: 1) it is well-suited for RLP generation under continuous conditions, such as varying weather and annual electricity consumption, 2) it demonstrates superior scalability in different datasets compared to traditional statistical models, and 3) it also demonstrates better modeling capabilities in capturing the complex correlation of RLPs compared with deep generative models.

Paper number 92:
Title: Optimal state estimation: Turnpike analysis and performance results
Authors: Julian D. Schiller, Lars Grüne, Matthias A. Müller
Abstract: In this paper, we introduce turnpike arguments in the context of optimal state estimation. In particular, we show that the optimal solution of the state estimation problem involving all available past data serves as turnpike for the solutions of truncated problems involving only a subset of the data. We mathematically formalize this phenomenon and derive a sufficient condition that relies on a decaying sensitivity property of the underlying nonlinear program. As second contribution, we show how a specific turnpike property can be used to establish performance guarantees when approximating the optimal solution of the full problem by a sequence of truncated problems, and we show that the resulting performance (both averaged and non-averaged) is approximately optimal with error terms that can be made arbitrarily small by an appropriate choice of the horizon length. In addition, we discuss interesting implications of these results for the practically relevant case of moving horizon estimation and illustrate our results with a numerical example.

Paper number 93:
Title: 3D Audio-Visual Segmentation
Authors: Artem Sokolov, Swapnil Bhosale, Xiatian Zhu
Abstract: Recognizing the sounding objects in scenes is a longstanding objective in embodied AI, with diverse applications in robotics and AR/VR/MR. To that end, Audio-Visual Segmentation (AVS), taking as condition an audio signal to identify the masks of the target sounding objects in an input image with synchronous camera and microphone sensors, has been recently advanced. However, this paradigm is still insufficient for real-world operation, as the mapping from 2D images to 3D scenes is missing. To address this fundamental limitation, we introduce a novel research problem, 3D Audio-Visual Segmentation, extending the existing AVS to the 3D output space. This problem poses more challenges due to variations in camera extrinsics, audio scattering, occlusions, and diverse acoustics across sounding object categories. To facilitate this research, we create the very first simulation based benchmark, 3DAVS-S34-O7, providing photorealistic 3D scene environments with grounded spatial audio under single-instance and multi-instance settings, across 34 scenes and 7 object categories. This is made possible by re-purposing the Habitat simulator to generate comprehensive annotations of sounding object locations and corresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet, characterized by integrating the ready-to-use knowledge from pretrained 2D audio-visual foundation models synergistically with 3D visual scene representation through spatial audio-aware mask alignment and refinement. Extensive experiments demonstrate that EchoSegnet can effectively segment sounding objects in 3D space on our new benchmark, representing a significant advancement in the field of embodied AI. Project page: this https URL

Paper number 94:
Title: Byzantine-Eavesdropper Alliance: How to Achieve Symmetric Privacy in Quantum $X$-Secure $B$-Byzantine $E$-Eavesdropped $U$-Unresponsive $T$-Colluding PIR?
Authors: Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus
Abstract: We consider the quantum \emph{symmetric} private information retrieval (QSPIR) problem in a system with $N$ databases and $K$ messages, with $U$ unresponsive servers, $T$-colluding servers, and $X$-security parameter, under several fundamental threat models. In the first model, there are $\mathcal{E}_1$ eavesdropped links in the uplink direction (the direction from the user to the $N$ servers), $\mathcal{E}_2$ eavesdropped links in the downlink direction (the direction from the servers to the user), where $|\mathcal{E}_1|, |\mathcal{E}_2| \leq E$; we coin this eavesdropper setting as \emph{dynamic} eavesdroppers. We show that super-dense coding gain can be achieved for some regimes. In the second model, we consider the case with Byzantine servers, i.e., servers that can coordinate to devise a plan to harm the privacy and security of the system together with static eavesdroppers, by listening to the same links in both uplink and downlink directions. It is important to note the considerable difference between the two threat models, since the eavesdroppers can take huge advantage of the presence of the Byzantine servers. Unlike the previous works in SPIR with Byzantine servers, that assume that the Byzantine servers can send only random symbols independent of the stored messages, we follow the definition of Byzantine servers in \cite{byzantine_tpir}, where the Byzantine servers can send symbols that can be functions of the storage, queries, as well as the random symbols in a way that can produce worse harm to the system. In the third and the most novel threat model, we consider the presence of Byzantine servers and dynamic eavesdroppers together. We show that having dynamic eavesdroppers along with Byzantine servers in the same system model creates more threats to the system than having static eavesdroppers with Byzantine servers.

Paper number 95:
Title: Implicit Neural Compression of Point Clouds
Authors: Hongning Ruan, Yulin Shao, Qianqian Yang, Liang Zhao, Zhaoyang Zhang, Dusit Niyato
Abstract: Point clouds have gained prominence across numerous applications due to their ability to accurately represent 3D objects and scenes. However, efficiently compressing unstructured, high-precision point cloud data remains a significant challenge. In this paper, we propose NeRC$^3$, a novel point cloud compression framework that leverages implicit neural representations (INRs) to encode both geometry and attributes of dense point clouds. Our approach employs two coordinate-based neural networks: one maps spatial coordinates to voxel occupancy, while the other maps occupied voxels to their attributes, thereby implicitly representing the geometry and attributes of a voxelized point cloud. The encoder quantizes and compresses network parameters alongside auxiliary information required for reconstruction, while the decoder reconstructs the original point cloud by inputting voxel coordinates into the neural networks. Furthermore, we extend our method to dynamic point cloud compression through techniques that reduce temporal redundancy, including a 4D spatio-temporal representation termed 4D-NeRC$^3$. Experimental results validate the effectiveness of our approach: For static point clouds, NeRC$^3$ outperforms octree-based G-PCC standard and existing INR-based methods. For dynamic point clouds, 4D-NeRC$^3$ achieves superior geometry compression performance compared to the latest G-PCC and V-PCC standards, while matching state-of-the-art learning-based methods. It also demonstrates competitive performance in joint geometry and attribute compression.

Paper number 96:
Title: Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning
Authors: Ali Forootani, Raffaele Iervolino
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for decentralized machine learning, enabling collaborative model training across diverse clients without sharing raw data. However, traditional FL approaches often face limitations in scalability and efficiency due to their reliance on synchronous client updates, which can result in significant delays and increased communication overhead, particularly in heterogeneous and dynamic environments. To address these challenges in this paper, we propose an Asynchronous Federated Learning (AFL) algorithm, which allows clients to update the global model independently and asynchronously. Our key contributions include a comprehensive convergence analysis of AFL in the presence of client delays and model staleness. By leveraging martingale difference sequence theory and variance bounds, we ensure robust convergence despite asynchronous updates. Assuming strongly convex local objective functions, we establish bounds on gradient variance under random client sampling and derive a recursion formula quantifying the impact of client delays on convergence. Furthermore, we demonstrate the practical applicability of the AFL algorithm by training decentralized linear regression and Support Vector Machine (SVM) based classifiers and compare its results with synchronous FL algorithm to effectively handling non-IID data distributed among clients. The proposed AFL algorithm addresses key limitations of traditional FL methods, such as inefficiency due to global synchronization and susceptibility to client drift. It enhances scalability, robustness, and efficiency in real-world settings with heterogeneous client populations and dynamic network conditions. Our results underscore the potential of AFL to drive advancements indistributed learning systems, particularly for large-scale, privacy-preserving applications in resource-constrained environments.

Paper number 97:
Title: Dynamic object goal pushing with mobile manipulators through model-free constrained reinforcement learning
Authors: Ioannis Dadiotis, Mayank Mittal, Nikos Tsagarakis, Marco Hutter
Abstract: Non-prehensile pushing to move and reorient objects to a goal is a versatile loco-manipulation skill. In the real world, the object's physical properties and friction with the floor contain significant uncertainties, which makes the task challenging for a mobile manipulator. In this paper, we develop a learning-based controller for a mobile manipulator to move an unknown object to a desired position and yaw orientation through a sequence of pushing actions. The proposed controller for the robotic arm and the mobile base motion is trained using a constrained Reinforcement Learning (RL) formulation. We demonstrate its capability in experiments with a quadrupedal robot equipped with an arm. The learned policy achieves a success rate of 91.35% in simulation and at least 80% on hardware in challenging scenarios. Through our extensive hardware experiments, we show that the approach demonstrates high robustness against unknown objects of different masses, materials, sizes, and shapes. It reactively discovers the pushing location and direction, thus achieving contact-rich behavior while observing only the pose of the object. Additionally, we demonstrate the adaptive behavior of the learned policy towards preventing the object from toppling.

Paper number 98:
Title: PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning
Authors: Ori Peleg, Natalie Lang, Dan Ben Ami, Stefano Rini, Nir Shlezinger, Kobi Cohen
Abstract: Federated learning (FL) enables multiple edge devices to collaboratively train a machine learning model without the need to share potentially private data. Federated learning proceeds through iterative exchanges of model updates, which pose two key challenges: First, the accumulation of privacy leakage over time, and second, communication latency. These two limitations are typically addressed separately: The former via perturbed updates to enhance privacy and the latter using user selection to mitigate latency - both at the expense of accuracy. In this work, we propose a method that jointly addresses the accumulation of privacy leakage and communication latency via active user selection, aiming to improve the trade-off among privacy, latency, and model performance. To achieve this, we construct a reward function that accounts for these three objectives. Building on this reward, we propose a multi-armed bandit (MAB)-based algorithm, termed Privacy-aware Active User SElection (PAUSE) which dynamically selects a subset of users each round while ensuring bounded overall privacy leakage. We establish a theoretical analysis, systematically showing that the reward growth rate of PAUSE follows that of the best-known rate in MAB literature. To address the complexity overhead of active user selection, we propose a simulated annealing-based relaxation of PAUSE and analyze its ability to approximate the reward-maximizing policy under reduced complexity. We numerically validate the privacy leakage, associated improved latency, and accuracy gains of our methods for the federated training in various scenarios.

Paper number 99:
Title: Rethink Repeatable Measures of Robot Performance with Statistical Query
Authors: Bowen Weng, Linda Capito, Guillermo A. Castillo, Dylan Khor
Abstract: For a general standardized testing algorithm designed to evaluate a specific aspect of a robot's performance, several key expectations are commonly imposed. Beyond accuracy (i.e., closeness to a typically unknown ground-truth reference) and efficiency (i.e., feasibility within acceptable testing costs and equipment constraints), one particularly important attribute is repeatability. Repeatability refers to the ability to consistently obtain the same testing outcome when similar testing algorithms are executed on the same subject robot by different stakeholders, across different times or locations. However, achieving repeatable testing has become increasingly challenging as the components involved grow more complex, intelligent, diverse, and, most importantly, stochastic. While related efforts have addressed repeatability at ethical, hardware, and procedural levels, this study focuses specifically on repeatable testing at the algorithmic level. Specifically, we target the well-adopted class of testing algorithms in standardized evaluation: statistical query (SQ) algorithms (i.e., algorithms that estimate the expected value of a bounded function over a distribution using sampled data). We propose a lightweight, parameterized, and adaptive modification applicable to any SQ routine, whether based on Monte Carlo sampling, importance sampling, or adaptive importance sampling, that makes it provably repeatable, with guaranteed bounds on both accuracy and efficiency. We demonstrate the effectiveness of the proposed approach across three representative scenarios: (i) established and widely adopted standardized testing of manipulators, (ii) emerging intelligent testing algorithms for operational risk assessment in automated vehicles, and (iii) developing use cases involving command tracking performance evaluation of humanoid robots in locomotion tasks.

Paper number 100:
Title: GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction
Authors: Eya Cherif (1, 2 and 3), Arthur Ouaknine (3 and 4), Luke A. Brown (5), Phuong D. Dao (6, 7 and 8), Kyle R. Kovach (9), Bing Lu (10), Daniel Mederer (1), Hannes Feilhauer (1, 2, 12 and 13), Teja Kattenborn (11 and 12), David Rolnick (3 and 4) ((1) Institute for Earth System Science and Remote Sensing, Leipzig University, Germany, (2) Center for Scalable Data Analytics and Artificial Intelligence (<a href="http://ScaDS.AI" rel="external noopener nofollow" class="link-external link-http">this http URL</a>), Leipzig University, Germany, (3) Mila Quebec AI Institute, Canada, (4) McGill University, Canada, (5) School of Science, Engineering and Environment, University of Salford, UK, (6) Department of Agricultural Biology, Colorado State University, USA, (7) Graduate Degree Program in Ecology, Colorado State University, USA, (8) School of Global Environmental Sustainability, Colorado State University, USA, (9) Department of Forest and Wildlife Ecology, University of Wisconsin, USA, (10) Department of Geography, Simon Fraser University, Canada, (11) Chair of Sensor-based Geoinformatics (geosense), University of Freiburg, Germany, (12) German Centre for Integrative Biodiversity Research (iDiv), Halle-Jena-Leipzig, Germany, (13) Helmholtz-Centre for Environmental Research (UFZ), Leipzig, Germany)
Abstract: Plant traits such as leaf carbon content and leaf mass are essential variables in the study of biodiversity and climate change. However, conventional field sampling cannot feasibly cover trait variation at ecologically meaningful spatial scales. Machine learning represents a valuable solution for plant trait prediction across ecosystems, leveraging hyperspectral data from remote sensing. Nevertheless, trait prediction from hyperspectral data is challenged by label scarcity and substantial domain shifts (\eg across sensors, ecological distributions), requiring robust cross-domain methods. Here, we present GreenHyperSpectra, a pretraining dataset encompassing real-world cross-sensor and cross-ecosystem samples designed to benchmark trait prediction with semi- and self-supervised methods. We adopt an evaluation framework encompassing in-distribution and out-of-distribution scenarios. We successfully leverage GreenHyperSpectra to pretrain label-efficient multi-output regression models that outperform the state-of-the-art supervised baseline. Our empirical analyses demonstrate substantial improvements in learning spectral representations for trait prediction, establishing a comprehensive methodological framework to catalyze research at the intersection of representation learning and plant functional traits assessment. All code and data are available at: this https URL.

Paper number 101:
Title: PowerChain: A Verifiable Agentic AI System for Automating Distribution Grid Analyses
Authors: Emmanuel O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey
Abstract: Rapid electrification and decarbonization are increasing the complexity of distribution grid (DG) operation and planning, necessitating advanced computational analyses to ensure reliability and resilience. These analyses depend on disparate workflows comprising complex models, function calls, and data pipelines that require substantial expert knowledge and remain difficult to automate. Workforce and budget constraints further limit utilities' ability to apply such analyses at scale. To address this gap, we build an agentic system PowerChain, which is capable of autonomously performing complex grid analyses. Existing agentic AI systems are typically developed in a bottom-up manner with customized context for predefined analysis tasks; therefore, they do not generalize to tasks that the agent has never seen. In comparison, to generalize to unseen DG analysis tasks, PowerChain dynamically generates structured context by leveraging supervisory signals from self-contained power systems tools (e.g., GridLAB-D) and an optimized set of expert-annotated and verified reasoning trajectories. For complex DG tasks defined in natural language, empirical results on real utility data demonstrate that PowerChain achieves up to a 144/% improvement in performance over baselines.

Paper number 102:
Title: Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles
Authors: Àlmos Veres-Vitàlyos, Genis Castillo Gomez-Raya, Filip Lemic, Daniel Johannes Bugelnig, Bernhard Rinner, Sergi Abadal, Xavier Costa-Pérez
Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for navigating indoor and hard-to-reach areas, yet their significant constraints in payload and autonomy have largely prevented their use for complex tasks like high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we introduce a novel system architecture that enables fully autonomous, high-fidelity 3D scanning of static objects using UAVs weighing under 100 grams. Our core innovation lies in a dual-reconstruction pipeline that creates a real-time feedback loop between data capture and flight control. A near-real-time (near-RT) process uses Structure from Motion (SfM) to generate an instantaneous pointcloud of the object. The system analyzes the model quality on the fly and dynamically adapts the UAV's trajectory to intelligently capture new images of poorly covered areas. This ensures comprehensive data acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR) approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB) location data to achieve superior accuracy. We implemented and validated this architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both single- and multi-UAV configurations, conclusively show that dynamic trajectory adaptation consistently improves reconstruction quality over static flight paths. This work demonstrates a scalable and autonomous solution that unlocks the potential of miniaturized UAVs for fine-grained 3D reconstruction in constrained environments, a capability previously limited to much larger platforms.

Paper number 103:
Title: Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks
Authors: Jianzhu Yao, Hongxu Su, Taobo Liao, Zerui Cheng, Huan Zhang, Xuechao Wang, Pramod Viswanath
Abstract: Neural networks increasingly run on hardware outside the user's control (cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about what actually ran or whether returned outputs faithfully reflect the intended inputs. Users lack recourse against service downgrades (model swaps, quantization, graph rewrites, or discrepancies like altered ad embeddings). Verifying outputs is hard because floating-point(FP) execution on heterogeneous accelerators is inherently nondeterministic. Existing approaches are either impractical for real FP neural networks or reintroduce vendor trust. We present NAO: a Nondeterministic tolerance Aware Optimistic verification protocol that accepts outputs within principled operator-level acceptance regions rather than requiring bitwise equality. NAO combines two error models: (i) sound per-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile profiles calibrated across hardware. Discrepancies trigger a Merkle-anchored, threshold-guided dispute game that recursively partitions the computation graph until one operator remains, where adjudication reduces to a lightweight theoretical-bound check or a small honest-majority vote against empirical thresholds. Unchallenged results finalize after a challenge window, without requiring trusted hardware or deterministic kernels. We implement NAO as a PyTorch-compatible runtime and a contract layer currently deployed on Ethereum Holesky testnet. The runtime instruments graphs, computes per-operator bounds, and runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on Qwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100, RTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than theoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO reconciles scalability with verifiability for real-world heterogeneous ML compute.
    