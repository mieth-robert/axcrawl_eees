
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: AdaptSR: Low-Rank Adaptation for Efficient and Scalable Real-World Super-Resolution
Authors: Cansu Korkmaz, Nancy Mehta, Radu Timofte
Abstract: Recovering high-frequency details and textures from low-resolution images remains a fundamental challenge in super-resolution (SR), especially when real-world degradations are complex and unknown. While GAN-based methods enhance realism, they suffer from training instability and introduce unnatural artifacts. Diffusion models, though promising, demand excessive computational resources, often requiring multiple GPU days, even for single-step variants. Rather than naively fine-tuning entire models or adopting unstable generative approaches, we introduce AdaptSR, a low-rank adaptation (LoRA) framework that efficiently repurposes bicubic-trained SR models for real-world tasks. AdaptSR leverages architecture-specific insights and selective layer updates to optimize real SR adaptation. By updating only lightweight LoRA layers while keeping the pretrained backbone intact, it captures domain-specific adjustments without adding inference cost, as the adapted layers merge seamlessly post-training. This efficient adaptation not only reduces memory and compute requirements but also makes real-world SR feasible on lightweight hardware. Our experiments demonstrate that AdaptSR outperforms GAN and diffusion-based SR methods by up to 4 dB in PSNR and 2% in perceptual scores on real SR benchmarks. More impressively, it matches or exceeds full model fine-tuning while training 92% fewer parameters, enabling rapid adaptation to real SR tasks within minutes.

Paper number 2:
Title: Short-Term Load Forecasting for AI-Data Center
Authors: Mariam Mughees, Yuzhuo Li, Yize Chen, Yunwei Ryan Li
Abstract: Recent research shows large-scale AI-centric data centers could experience rapid fluctuations in power demand due to varying computation loads, such as sudden spikes from inference or interruption of training large language models (LLMs). As a consequence, such huge and fluctuating power demand pose significant challenges to both data center and power utility operation. Accurate short-term power forecasting allows data centers and utilities to dynamically allocate resources and power large computing clusters as required. However, due to the complex data center power usage patterns and the black-box nature of the underlying AI algorithms running in data centers, explicit modeling of AI-data center is quite challenging. Alternatively, to deal with this emerging load forecasting problem, we propose a data-driven workflow to model and predict the short-term electricity load in an AI-data center, and such workflow is compatible with learning-based algorithms such as LSTM, GRU, 1D-CNN. We validate our framework, which achieves decent accuracy on data center GPU short-term power consumption. This provides opportunity for improved power management and sustainable data center operations.

Paper number 3:
Title: Real-Time Line Parameter Estimation Method for Multi-Phase Unbalanced Distribution Networks
Authors: Sakirat Wolly, Xiaozhe Wang
Abstract: An accurate distribution network model is crucial for monitoring, state estimation and energy management. However, existing data-driven methods often struggle with scalability or impose a heavy computational burden on large distribution networks. In this paper, leveraging natural load dynamics, we propose a two-stage line estimation method for multiphase unbalanced distribution networks. Simulation results using real-life load and PV data show that the proposed method reduces computational time by one to two orders of magnitude compared to existing methods.

Paper number 4:
Title: Modifying Range-Doppler geometry frameworks to process Spotlight SAR imagery in Polar Format
Authors: Piyush S. Agram
Abstract: We present a simple method to enable processing of Spotlight Synthetic Aperture Radar (SAR) imagery distributed in Polar Format (PFA) using standard Range-Doppler (RDA) geometry algorithms. Our approach is applicable to PFA SAR images characterized by a constant value of the Center of Aperture (COA) time. We present simplified expressions for forward (image-to-ground) and inverse (ground-to-image) geometry mapping using Sensor Independent Complex Data (SICD) conventions. We discuss simple changes needed to current open source SAR software that implement Range-Doppler algorithms, to enable support within them for Spotlight data distributed in SICD format. We include a proof-of-concept script that utilizes the Python packages sarpy and isce3 to demonstrate the correctness of the proposed approach.

Paper number 5:
Title: Co-Optimizing Distributed Energy Resources under Demand Charges and Bi-Directional Power Flow
Authors: Ruixiao Yang, Gulai Shen, Ahmed S. Alahmed, Chuchu Fan
Abstract: We address the co-optimization of behind-the-meter (BTM) distributed energy resources (DER), including flexible demands, renewable distributed generation (DG), and battery energy storage systems (BESS) under net energy metering (NEM) frameworks with demand charges. We formulate the problem as a stochastic dynamic program that accounts for renewable generation uncertainty and operational surplus maximization. Our theoretical analysis reveals that the optimal policy follows a threshold structure. Finally, we show that even a simple algorithm leveraging this threshold structure performs well in simulation, emphasizing its importance in developing near-optimal algorithms. These findings provide crucial insights for implementing prosumer energy management systems under complex tariff structures.

Paper number 6:
Title: Adaptive Control with Rate-Limited Integral Action for Systems with Matched, Time-Varying Uncertainties
Authors: Ying-Chun Chen, Craig Woolsey
Abstract: This paper considers the problem of controlling a piecewise continuously differentiable system subject to time-varying uncertainties. The uncertainties are decomposed into a time-invariant, linearly-parameterized portion and a time-varying unstructured portion. The former is addressed using conventional model reference adaptive control. The latter is handled using disturbance observer-based control. The objective is to ensure good performance through observer-based disturbance rejection when possible, while preserving the robustness guarantees of adaptive control. A key feature of the observer-based disturbance compensation is a magnitude and rate limit on the integral action that prevents fast fluctuations in the control command due to the observer dynamics.

Paper number 7:
Title: Decentralized Integration of Grid Edge Resources into Wholesale Electricity Markets via Mean-field Games
Authors: Chen Feng, Andrew L. Liu
Abstract: Grid edge resources refer to distributed energy resources (DERs) located on the consumer side of the electrical grid, controlled by consumers rather than utility companies. Integrating DERs with real-time electricity pricing can better align distributed supply with system demand, improving grid efficiency and reliability. However, DER owners, known as prosumers, often lack the expertise and resources to directly participate in wholesale energy markets, limiting their ability to fully realize the economic potential of their assets. Meanwhile, as DER adoption grows, the number of prosumers participating in the energy system is expected to increase significantly, creating additional challenges in coordination and market participation. To address these challenges, we propose a mean-field game framework that enables prosumers to autonomously learn optimal decision policies based on dynamic market prices and their variable solar generation. Our framework is designed to accommodate heterogeneous agents and demonstrates the existence of a mean-field equilibrium (MFE) in a wholesale energy market with many prosumers. Additionally, we introduce an algorithm that automates prosumers' resource control, facilitating real-time decision-making for energy storage management. Numerical experiments suggest that our approach converges towards an MFE and effectively reduces peak loads and price volatility, especially during periods of external demand or supply shocks. This study highlights the potential of a fully decentralized approach to integrating DERs into wholesale markets while improving market efficiency.

Paper number 8:
Title: A Survey of Challenges and Sensing Technologies in Autonomous Retail Systems
Authors: Shimmy Rukundo, David Wang, Front Wongnonthawitthaya, Youssouf Sidib√©, Minsik Kim, Emily Su, Jiale Zhang
Abstract: Autonomous stores leverage advanced sensing technologies to enable cashier-less shopping, real-time inventory tracking, and seamless customer interactions. However, these systems face significant challenges, including occlusion in vision-based tracking, scalability of sensor deployment, theft prevention, and real-time data processing. To address these issues, researchers have explored multi-modal sensing approaches, integrating computer vision, RFID, weight sensing, vibration-based detection, and LiDAR to enhance accuracy and efficiency. This survey provides a comprehensive review of sensing technologies used in autonomous retail environments, highlighting their strengths, limitations, and integration strategies. We categorize existing solutions across inventory tracking, environmental monitoring, people-tracking, and theft detection, discussing key challenges and emerging trends. Finally, we outline future directions for scalable, cost-efficient, and privacy-conscious autonomous store systems.

Paper number 9:
Title: Joint Semantic Transmission and Resource Allocation for Intelligent Computation Task Offloading in MEC Systems
Authors: Yuanpeng Zheng, Tiankui Zhang, Xidong Mu, Yuanwei Liu, Rong Huang
Abstract: Mobile edge computing (MEC) enables the provision of high-reliability and low-latency applications by offering computation and storage resources in close proximity to end-users. Different from traditional computation task offloading in MEC systems, the large data volume and complex task computation of artificial intelligence involved intelligent computation task offloading have increased greatly. To address this challenge, we propose a MEC system for multiple base stations and multiple terminals, which exploits semantic transmission and early exit of inference. Based on this, we investigate a joint semantic transmission and resource allocation problem for maximizing system reward combined with analysis of semantic transmission and intelligent computation process. To solve the formulated problem, we decompose it into communication resource allocation subproblem, semantic transmission subproblem, and computation capacity allocation subproblem. Then, we use 3D matching and convex optimization method to solve subproblems based on the block coordinate descent (BCD) framework. The optimized feasible solutions are derived from an efficient BCD based joint semantic transmission and resource allocation algorithm in MEC systems. Our simulation demonstrates that: 1) The proposed algorithm significantly improves the delay performance for MEC systems compared with benchmarks; 2) The design of transmission mode and early exit of inference greatly increases system reward during offloading; and 3) Our proposed system achieves efficient utilization of resources from the perspective of system reward in the intelligent scenario.

Paper number 10:
Title: Integrated Energy Management for Operational Cost Optimization in Community Microgrids
Authors: Moslem Uddin, Huadong Mo, Daoyi Dong
Abstract: This study presents an integrated energy management strategy for cost optimization in multi-energy community microgrids (MGs). The proposed approach combines storage-based peak shaving, economic dispatch of diesel generators, and efficient utilization of renewable energy sources to enhance energy management in community MGs. The efficacy of the energy management system (EMS) was validated through a simulation case study for a rural Australian community. The results demonstrate that the proposed EMS effectively reduces the peak energy demand by up to 43%, lowers operational costs by 84.63% (from $189,939/year to $29,188/year), and achieves a renewable energy utilization of 92.3%, up from 47.8% in the base system. Furthermore, the levelized cost of energy was reduced by 14.21% to $0.163/kWh. The strategy ensures an uninterrupted power supply during grid outages by utilizing DGs and battery energy storage systems. The environmental benefits included a 196.4% reduction in CO2 emissions and 100% reductions in CO, unburned hydrocarbons, and particulate matter. These findings validate the feasibility of the proposed EMS in achieving cost-effective, reliable, and sustainable energy management in community MGs. These findings contribute to the field by introducing a novel approach and demonstrating the practical feasibility of multi-energy MGs.

Paper number 11:
Title: A Three-Dimensional Pursuit-Evasion Game Based on Fuzzy Actor-Critic Learning Algorithm
Authors: Penglin Hu
Abstract: Most of the existing research on pursuit-evasion game (PEG) is conducted in a two-dimensional (2D) environment. In this paper, we investigate the PEG in a 3D space. We extend the Apollonius circle (AC) to the 3D space and introduce its detailed analytical form. To enhance the capture efficiency, we derive the optimal motion space for both the pursuer and the evader. To address the issue arising from a discrete state space, we design a fuzzy actor-critic learning (FACL) algorithm to obtain the agents' strategies. To improve learning performance, we devise a reward function for the agents, which enables obstacle avoidance functionality. The effectiveness of the proposed algorithm is validated through simulation experiments.

Paper number 12:
Title: Deep Perceptual Enhancement for Medical Image Analysis
Authors: S M A Sharif, Rizwan Ali Naqvi, Mithun Biswas, Woong-Kee Loh
Abstract: Due to numerous hardware shortcomings, medical image acquisition devices are susceptible to producing low-quality (i.e., low contrast, inappropriate brightness, noisy, etc.) images. Regrettably, perceptually degraded images directly impact the diagnosis process and make the decision-making manoeuvre of medical practitioners notably complicated. This study proposes to enhance such low-quality images by incorporating end-to-end learning strategies for accelerating medical image analysis tasks. To the best concern, this is the first work in medical imaging which comprehensively tackles perceptual enhancement, including contrast correction, luminance correction, denoising, etc., with a fully convolutional deep network. The proposed network leverages residual blocks and a residual gating mechanism for diminishing visual artefacts and is guided by a multi-term objective function to perceive the perceptually plausible enhanced images. The practicability of the deep medical image enhancement method has been extensively investigated with sophisticated experiments. The experimental outcomes illustrate that the proposed method could outperform the existing enhancement methods for different medical image modalities by 5.00 to 7.00 dB in peak signal-to-noise ratio (PSNR) metrics and 4.00 to 6.00 in DeltaE metrics. Additionally, the proposed method can drastically improve the medical image analysis tasks' performance and reveal the potentiality of such an enhancement method in real-world applications. Code Available: this https URL

Paper number 13:
Title: Data-Driven Dynamic Controller Synthesis for Discrete-Time General Nonlinear Systems
Authors: Behrad Samari, Abolfazl Lavaei
Abstract: Synthesizing safety controllers for general nonlinear systems is a highly challenging task, particularly when the system models are unknown, and input constraints are present. While some recent efforts have explored data-driven safety controller design for nonlinear systems, these approaches are primarily limited to specific classes of nonlinear dynamics (e.g., polynomials) and are not applicable to general nonlinear systems. This paper develops a direct data-driven approach for discrete-time general nonlinear systems, facilitating the simultaneous learning of control barrier certificates (CBCs) and dynamic controllers to ensure safety properties under input constraints. Specifically, by leveraging the adding-one-integrator approach, we incorporate the controller's dynamics into the system dynamics to synthesize a virtual static-feedback controller for the augmented system, resulting in a dynamic safety controller for the actual dynamics. We collect input-state data from the augmented system during a finite-time experiment, referred to as a single trajectory. Using this data, we learn augmented CBCs and the corresponding virtual safety controllers, ensuring the safety of the actual system and adherence to input constraints over a finite time horizon. We demonstrate that our proposed conditions boil down to some data-dependent linear matrix inequalities (LMIs), which are easy to satisfy. We showcase the effectiveness of our data-driven approach through two case studies: one exhibiting significant nonlinearity and the other featuring high dimensionality.

Paper number 14:
Title: How Does CP Length Affect the Sensing Range for OFDM-ISAC?
Authors: Xiaoli Xu, Zhiwen Zhou, Yong Zeng
Abstract: Orthogonal frequency division multiplexing (OFDM), which has been the dominating waveform for contemporary wireless communications, is also regarded as a competitive candidate for future integrated sensing and communication (ISAC) systems. Existing works on OFDM-ISAC usually assume that the maximum sensing range should be limited by the cyclic prefix (CP) length since inter-symbol interference (ISI) and inter-carrier interference (ICI) should be avoided. However, in this paper, we provide rigorous analysis to reveal that the random data embedded in OFDM-ISAC signal can actually act as a free ``mask" for ISI, which makes ISI/ICI random and hence greatly attenuated after radar signal processing. The derived signal-to-interference-plus-noise ratio (SINR) in the range profile demonstrates that the maximum sensing range of OFDM-ISAC can greatly exceed the ISI-free distance that is limited by the CP length, which is validated by simulation results. To further mitigate power degradation for long-range targets, a novel sliding window sensing method is proposed, which iteratively detects and cancels short-range targets before shifting the detection window. The shifted detection window can effectively compensate the power degradation due to insufficient CP length for long-range targets. Such results provide valuable guidance for the CP length design in OFDM-ISAC systems.

Paper number 15:
Title: From Data to Global Asymptotic Stability of Unknown Large-Scale Networks with Provable Guarantees
Authors: Mahdieh Zaker, Amy Nejati, Abolfazl Lavaei
Abstract: We offer a compositional data-driven scheme for synthesizing controllers that ensure global asymptotic stability (GAS) across large-scale interconnected networks, characterized by unknown mathematical models. In light of each network's configuration composed of numerous subsystems with smaller dimensions, our proposed framework gathers data from each subsystem's trajectory, enabling the design of local controllers that ensure input-to-state stability (ISS) properties over subsystems, signified by ISS Lyapunov functions. To accomplish this, we require only a single input-state trajectory from each unknown subsystem up to a specified time horizon, fulfilling certain rank conditions. Subsequently, under small-gain compositional reasoning, we leverage ISS Lyapunov functions derived from data to offer a control Lyapunov function (CLF) for the interconnected network, ensuring GAS certificate over the network. We demonstrate that while the computational complexity for designing a CLF increases polynomially with the network dimension using sum-of-squares (SOS) optimization, our compositional data-driven approach significantly mitigates it to \emph{linear} with respect to the number of subsystems. We showcase the efficacy of our data-driven approach over a set of benchmarks, involving physical networks with diverse interconnection topologies.

Paper number 16:
Title: Electrifying Heavy-Duty Trucks: Battery-Swapping vs Fast Charging
Authors: Ruiting Wang, Antoine Martinez, Zaid Allybokus, Wente Zeng, Nicolas Obrecht, Scott Moura
Abstract: The advantages and disadvantages of Battery Swapping Stations (BSS) for heavy-duty trucks are poorly understood, relative to Fast Charging Stations (FCS) systems. This study evaluates these two charging mechanisms for electric heavy-duty trucks, aiming to compare the systems' efficiency and identify the optimal design for each option. A model was developed to address the planning and operation of BSS in a charging network, considering in-station batteries as assets for various services. We assess performance metrics including transportation efficiency and battery utilization efficiency. Our evaluation reveals that BSS significantly increased transportation efficiency by reducing vehicle downtime compared to fast charging, but may require more batteries. BSS with medium-sized batteries offers improved transportation efficiency in terms of time and labor. FCS-reliant trucks require larger batteries to compensate for extended charging times. To understand the trade-off between these two metrics, a cost-benefit analysis was performed under different scenarios involving potential shifts in battery prices and labor costs. Additionally, BSS shows potential for significant $\text{CO}_2$ emission reductions and increased profitability through energy arbitrage and grid ancillary services. These findings emphasize the importance of integrating BSS into future electric truck charging networks and adopting carbon-aware operational frameworks.

Paper number 17:
Title: TRUST: Stability and Safety Controller Synthesis for Unknown Dynamical Models Using a Single Trajectory
Authors: Jamie Gardner, Ben Wooding, Amy Nejati, Abolfazl Lavaei
Abstract: TRUST is an open-source software tool developed for data-driven controller synthesis of dynamical systems with unknown mathematical models, ensuring either stability or safety properties. By collecting only a single input-state trajectory from the unknown system and satisfying a rank condition that ensures the system is persistently excited according to the Willems et al.'s fundamental lemma, TRUST aims to design either control Lyapunov functions (CLF) or control barrier certificates (CBC), along with their corresponding stability or safety controllers. The tool implements sum-of-squares (SOS) optimization programs solely based on data to enforce stability or safety properties across four system classes: (i) continuous-time nonlinear polynomial systems, (ii) continuous-time linear systems, (iii) discrete-time nonlinear polynomial systems, and (iv) discrete-time linear systems. TRUST is a Python-based web application featuring an intuitive, reactive graphic user interface (GUI) built with web technologies. It can be accessed at this https URL or installed locally, and supports both manual data entry and data file uploads. Leveraging the power of the Python backend and a JavaScript frontend, TRUST is designed to be highly user-friendly and accessible across desktop, laptop, tablet, and mobile devices. We apply TRUST to a set of physical benchmarks with unknown dynamics, ensuring either stability or safety properties across the four supported classes of models.

Paper number 18:
Title: Intelligent Joint Security and Delay Determinacy Performance Guarantee Strategy in RIS-Assisted IIoT Communication Systems
Authors: Rui Meng, Zhuo Meng, Jiaqi Lu, Xiaodong Xu, Jingxuan Zhang, Xiqi Cheng, Chen Dong
Abstract: With the advancement of the Industrial Internet of Things (IIoT), IIoT services now exhibit diverse Quality of Service (QoS) requirements in terms of delay, determinacy, and security, which pose significant challenges for alignment with existing network resources. Reconfigurable Intelligent Surface (RIS), a key enabling technology for IIoT, not only optimizes signal propagation and enhances network performance but also ensures secure communication and deterministic delays to mitigate threats such as data leakage and eavesdropping. In this paper, we conduct a deterministic delay analysis under a specified decoding error rate for RIS-assisted IIoT communication systems using Stochastic Network Calculus (SNC). We propose an on-demand joint strategy to maximize delay determinacy while guaranteeing secure transmission performance. This is achieved by jointly optimizing the transmit power, channel blocklength (CBL) at the user end, and the phase shift matrix at the RIS. Furthermore, we introduce a State Interdependence-Driven Parameterized Deep Q-Network (SID-PDQN) algorithm to intelligently enforce on-demand performance guarantees. Simulation results demonstrate that the proposed SID-PDQN algorithm significantly enhances network performance compared to baseline methods such as DQN, Dueling-DQN, and DDPG.

Paper number 19:
Title: Enhancing Vehicle Platooning Safety via Control Node Placement and Sizing under State and Input Bounds
Authors: Yifei She, Shen Wang, Ahmad Taha, Xiaofeng Tao
Abstract: Vehicle platooning with Cooperative Adaptive Cruise Control improves traffic efficiency, reduces energy consumption, and enhances safety but remains vulnerable to cyber-attacks that disrupt communication and cause unsafe actions. To address these risks, this paper investigates control node placement and input bound optimization to balance safety and defense efficiency under various conditions. We propose a two-stage actuator placement and actuator saturation approach, which focuses on identifying key actuators that maximize the system's controllability while operating under state and input constraints. By strategically placing and limiting the input bounds of critical actuators, we ensure that vehicles maintain safe distances even under attack. Simulation results show that our method effectively mitigates the impact of attacks while preserving defense efficiency, offering a robust solution to vehicle platooning safety challenges.

Paper number 20:
Title: Revolution of Wireless Signal Recognition for 6G: Recent Advances, Challenges and Future Directions
Authors: Hao Zhang, Fuhui Zhou, Hongyang Du, Qihui Wu, Chau Yuen
Abstract: Wireless signal recognition (WSR) is a crucial technique for intelligent communications and spectrum sharing in the next six-generation (6G) wireless communication networks. It can be utilized to enhance network performance and efficiency, improve quality of service (QoS), and improve network security and reliability. Additionally, WSR can be applied for military applications such as signal interception, signal race, and signal abduction. In the past decades, great efforts have been made for the research of WSR. Earlier works mainly focus on model-based methods, including likelihood-based (LB) and feature-based (FB) methods, which have taken the leading position for many years. With the emergence of artificial intelligence (AI), intelligent methods including machine learning-based (ML-based) and deep learning-based (DL-based) methods have been developed to extract the features of the received signals and perform the classification. In this work, we provide a comprehensive review of WSR from the view of applications, main tasks, recent advances, datasets and evaluation metrics, challenges, and future directions. Specifically, intelligent WSR methods are introduced from the perspective of model, data, learning and implementation. Moreover, we analyze the challenges for WSR from the view of complex, dynamic, and open 6G wireless environments and discuss the future directions for WSR. This survey is expected to provide a comprehensive overview of the state-of-the-art WSR techniques and inspire new research directions for WSR in 6G networks.

Paper number 21:
Title: Denoising via Repainting: an image denoising method using layer wise medical image repainting
Authors: Arghya Pal, Sailaja Rajanala, CheeMing Ting, Raphael Phan
Abstract: Medical image denoising is essential for improving the reliability of clinical diagnosis and guiding subsequent image-based tasks. In this paper, we propose a multi-scale approach that integrates anisotropic Gaussian filtering with progressive Bezier-path redrawing. Our method constructs a scale-space pyramid to mitigate noise while preserving critical structural details. Starting at the coarsest scale, we segment partially denoised images into coherent components and redraw each using a parametric Bezier path with representative color. Through iterative refinements at finer scales, small and intricate structures are accurately reconstructed, while large homogeneous regions remain robustly smoothed. We employ both mean square error and self-intersection constraints to maintain shape coherence during path optimization. Empirical results on multiple MRI datasets demonstrate consistent improvements in PSNR and SSIM over competing methods. This coarse-to-fine framework offers a robust, data-efficient solution for cross-domain denoising, reinforcing its potential clinical utility and versatility. Future work extends this technique to three-dimensional data.

Paper number 22:
Title: Control Barrier Functions for Prescribed-time Reach-Avoid-Stay Tasks using Spatiotemporal Tubes
Authors: Ratnangshu Das, Pranav Bakshi, Pushpak Jagtap
Abstract: Prescribed-time reach-avoid-stay (PT-RAS) specifications are crucial in applications requiring precise timing, state constraints, and safety guarantees. While control carrier functions (CBFs) have emerged as a promising approach, providing formal guarantees of safety, constructing CBFs that satisfy PT-RAS specifications remains challenging. In this paper, we present a novel approach using a spatiotemporal tubes (STTs) framework to construct CBFs for PT-RAS tasks. The STT framework allows for the systematic design of CBFs that dynamically manage both spatial and temporal constraints, ensuring the system remains within a safe operational envelope while achieving the desired temporal objectives. The proposed method is validated with two case studies: temporal motion planning of an omnidirectional robot and temporal waypoint navigation of a drone with obstacles, using higher-order CBFs.

Paper number 23:
Title: Forecast-Driven Scenario Generation for Building Energy Management Using Stochastic Optimization
Authors: Hossein Nourollahi Hokmabad, Tala Hemmati Shahsavar, Pedro P. Vergara, Oleksandr Husev, Juri Belikov
Abstract: Buildings are essential components of power grids, and their energy performance directly affects overall power system operation. This paper presents a novel stochastic optimization framework for building energy management systems, aiming to enhance buildings' energy performance and facilitate their effective integration into emerging intelligent power grids. In this method, solar power generation and building electricity demand forecasts are combined with historical data, leveraging statistical characteristics to generate probability matrices and corresponding scenarios with associated probabilities. These scenarios are then used to solve the stochastic optimization problem, optimizing building energy flow while accounting for existing uncertainties. The results demonstrate that the proposed methodology effectively manages inherent uncertainties while maintaining performance and outperforming rule-based and custom build reinforcement learning based solutions.

Paper number 24:
Title: Quantization Design for Deep Learning-Based CSI Feedback
Authors: Manru Yin, Shengqian Han, Chenyang Yang
Abstract: Deep learning-based autoencoders have been employed to compress and reconstruct channel state information (CSI) in frequency-division duplex systems. Practical implementations require judicious quantization of encoder outputs for digital transmission. In this paper, we propose a novel quantization module with bit allocation among encoder outputs and develop a method for joint training the module and the autoencoder. To enhance learning performance, we design a loss function that adaptively weights the quantization loss and the logarithm of reconstruction loss. Simulation results show the performance gain of the proposed method over existing baselines.

Paper number 25:
Title: Coordinated Path Following of UAVs using Event-Triggered Communication over Networks with Digraph Topologies
Authors: Hyungsoo Kang, Isaac Kaminer, Venanzio Cichella, Naira Hovakimyan
Abstract: This article presents a novel time-coordination algorithm based on event-triggered communication to ensure multiple UAVs progress along their desired paths in coordination with one another. In the proposed algorithm, a UAV transmits its progression information to its neighbor UAVs only when a decentralized trigger condition is satisfied. Consequently, it significantly reduces the volume of inter-vehicle communications required to achieve the goal compared with the existing algorithms based on continuous communication. With such intermittent communications, it is shown that a decentralized coordination controller guarantees exponential convergence of the coordination error to a neighborhood of zero. Furthermore, a lower bound on the difference between two consecutive event-triggered times is provided showing that the Zeno behavior is excluded with the proposed algorithm. Lastly, simulation results validate the efficacy of the proposed algorithm.

Paper number 26:
Title: THz Beam Squint Mitigation via 3D Rotatable Antennas
Authors: Yike Xie, Weidong Mei, Dong Wang, Boyu Ning, Zhi Chen, Jun Fang, Wei Guo
Abstract: Analog beamforming holds great potential for future terahertz (THz) communications due to its ability to generate high-gain directional beams with low-cost phase this http URL, conventional analog beamforming may suffer substantial performance degradation in wideband systems due to the beam-squint effects. Instead of relying on high-cost true time delayers, we propose in this paper an efficient three-dimensional (3D) rotatable antenna technology to mitigate the beam-squint effects, motivated by the fact that beam squint disappears along the boresight direction. In particular, we focus on a wideband wide-beam coverage problem in this paper, aiming to maximize the minimum beamforming gain within a given angle and frequency range by jointly optimizing the analog beamforming vector and the 3D rotation angles of the antenna array. However, this problem is non-convex and difficult to be optimally solved due to the coupling of the spatial and frequency domains and that of the antenna weights and rotation. To tackle this issue, we first reformulate the problem into an equivalent form by merging the spatial and frequency domains into a single composite domain. Next, we combine alternating optimization (AO) and successive convex approximation (SCA) algorithms to optimize the analog beamforming and rotation angles within this composite domain. Simulation results demonstrate that the proposed scheme can significantly outperform conventional schemes without antenna rotation, thus offering a cost-effective solution for wideband transmission over THz bands.

Paper number 27:
Title: Ultra-low Power AMOLED Displays for Smart Wearable Applications: Theory and Practice
Authors: Bojia Lyu
Abstract: With the continuous advancement and maturity of AMOLED (Active-Matrix Organic Light Emitting Diode) technology, smart wearable products such as watches and bracelets are increasingly incorporating related technologies as display screen implementation solutions. Using standby time is the most critical product performance measurement indicator at the moment, according to the power supply system design of smart wearable products and customer usage habits. AMOLED displays, as one of the major power-consuming components in smart wearable products, are also subject to extremely stringent power consumption requirements. This paper divides an AMOLED display into five parts: the power chip, the driver chip, the array substrate, the light-emitting structure, and the light-transmitting structure. In this paper, we propose targeted power-saving solutions for each component based on their respective operating principles, subject areas, and the most recent advances in related fields, and we provide the best overall solution by combining the interactions between each component and even the entire system. The relevant solutions have been validated in practice, and there is clear verification data to demonstrate their feasibility.

Paper number 28:
Title: Reconfigurable Intelligent Sensing Surface enables Wireless Powered Communication Networks: Interference Suppression and Massive Wireless Energy Transfer
Authors: Cheng Luo, Jie Hu, Luping Xiang, Kun Yang
Abstract: Recently, a novel structures of reconfigurable intelligent surface (RIS) integrating both passive and active elements, termed reconfigurable intelligent sensing surface (RISS), efficiently addresses challenges in RIS channel estimation and mitigates issues related to multiplicative path loss by processing the signal at the RISS. In this paper, we propose a sensing-assisted wirelessly powered communication network (WPCN) that utilizes RISS's sensing capabilities to maximize the channel capacity in uplink wireless information transfer (WIT) and assist in massive wireless energy transmission (WET) for downlink. For the WIT in the uplink, the sensing information is utilized to design an interference suppression passive reflection phase shift for the RISS, and take the imperfect sensing results and sharp null into consideration, we also propose a robust scheme. For the WET in the downlink, the massive WET scheme is adopted and benefits from a period of sensing results. The massive WET scheme including beam selection and rotation order optimization to enhance the lower bound of energy harvest for massive users and optimize waiting costs. Numerical results demonstrate the optimal interference suppression threshold for uplink WIT and underscore the achieved fairness in downlink WET. Collectively, by utilizing sensing information, the uplink channel capacity is improved by 20\%, and the worst energy performance and waiting costs for massive WET are effectively optimized, with improvements ranging from 19\% to 59\% and 27\% to 29\%, respectively.

Paper number 29:
Title: Low-Complexity Beamforming Design for Null Space-based Simultaneous Wireless Information and Power Transfer Systems
Authors: Cheng Luo, Jie Hu, Luping Xiang, Kun Yang
Abstract: Simultaneous wireless information and power transfer (SWIPT) is a promising technology for the upcoming sixth-generation (6G) communication networks, enabling internet of things (IoT) devices and sensors to extend their operational lifetimes. In this paper, we propose a SWIPT scheme by projecting the interference signals from both intra-wireless information transfer (WIT) and inter-wireless energy transfer (WET) into the null space, simplifying the system into a point-to-point WIT and WET problem. Upon further analysis, we confirm that dedicated energy beamforming is unnecessary. In addition, we develop a low-complexity algorithm to solve the problem efficiently, further reducing computational overhead. Numerical results validate our analysis, showing that the computational complexity is reduced by 97.5\% and 99.96\% for the cases of $K^I = K^E = 2$, $M = 4$ and $K^I = K^E = 16$, $M = 64$, respectively.

Paper number 30:
Title: Construction and Control of Validated Highly Configurable Multi-Physics Building Models for Multi-Energy System Analysis in a Co-Simulation Setup
Authors: Haozhen Cheng, Jan Stock, Andr√© Xhonneux, H√ºseyin K. √áakmak, Veit Hagenmeyer
Abstract: Improving energy efficiency by monitoring system behavior and predicting future energy scenarios in light of increased penetration of renewable energy sources are becoming increasingly important, especially for energy systems that distribute and provide heat. On this background, digital twins of cities become paramount in advancing urban energy system planning and infrastructure management. The use of recorded energy data from sensors in district digital twins in collaborative co-simulation platforms is a promising way to analyze detailed system behavior and estimate future scenarios. However, the development and coupling of multi-physics energy system models need to be validated before they can be used for further in-depth analyses. In the present paper, a new multi-physics/-modal and highly configurable building model is presented. Its accuracy and reliability are validated by comparison with data from the TABULA project, ensuring its relevance and applicability to real-world scenarios. The modularity and flexibility with regard to the system configurability of the developed building model is evaluated on various real building types. In addition, the applicability of the building model in a multi-energy system is highlighted by implementing the model in a collaborative co-simulation setup and by coupling it to a district heating grid model in yearly co-simulations. The simulation results for the proposed multi-physical/-modal building modeling concept show a very high level of agreement compared to published reference building data and can therefore be used individually as flexible and modular building models including both thermal and electrical systems for future sector-coupled energy system analyses in view of sustainability.

Paper number 31:
Title: Bedrock Models in Communication and Sensing: Advancing Generalization, Transferability, and Performance
Authors: Cheng Luo, Luping Xiang, Jie Hu, Kun Yang
Abstract: Deep learning (DL) has emerged as a powerful tool for addressing the intricate challenges inherent in communication and sensing systems, significantly enhancing the intelligence of future sixth-generation (6G) networks. A substantial body of research has highlighted the promise of DL-based techniques in these domains. However, in addition to improving accuracy, new challenges must be addressed regarding the generalization and transferability of DL-based systems. To tackle these issues, this paper introduces a series of mathematically grounded and modularized models, referred to as bedrock models, specifically designed for integration into both communication and sensing systems. Due to their modular architecture, these models can be seamlessly incorporated into existing communication and sensing frameworks. For communication systems, the proposed models demonstrate substantial performance improvements while also exhibit strong transferability, enabling direct parameter sharing across different tasks, which greatly facilitates practical deployment. In sensing applications, the integration of the bedrock models into existing systems results in superior performance, reducing delay and Doppler estimation errors by an order of magnitude compared to traditional methods. Additionally, a pre-equalization strategy based on the bedrock models is proposed for the transmitter. By leveraging sensing information, the transmitted communication signal is dynamically adjusted without altering the communication model pre-trained in AWGN channels. This adaptation enables the system to effectively cope with doubly dispersive channels, restoring the received signal to an AWGN-like condition and achieving near-optimal performance. Simulation results substantiate the effectiveness and transferability of the proposed bedrock models, underscoring their potential to advance both communication and sensing systems.

Paper number 32:
Title: New Co-Simulation Variants for Emissions and Cost Reduction of Sustainable District Heating Planning
Authors: Haozhen Cheng, Verena Buccoliero, Alexander Kocher, Veit Hagenmeyer, H√ºseyin K. √áakmak
Abstract: Classical heating of residential areas is very energy-intensive, so alternatives are needed, including renewable energies and advanced heating technologies. Thus, the present paper introduces a new methodology for comprehensive variant analysis for future district heating planning, aiming at optimizing emissions and costs. For this, an extensive Modelica-based modeling study comprising models of heating center, heat grid pipelines and heating interface units to buildings are coupled in co-simulations. These enable a comparative analysis of the economic feasibility and sustainability for various technologies and energy carriers to be carried out. The new modular and highly parameterizable building model serves for validation of the introduced heat grid model. The results show that bio-methane as an energy source reduces carbon equivalent emissions by nearly 70% compared to conventional natural gas heating, and the use of hydrogen as an energy source reduces carbon equivalent emissions by 77% when equipped with a heat pump. In addition, the use of ground source heat pumps has a high economic viability when economic benefits are taken into account. The study findings highlight the importance of strategic planning and flexible design in the early stages of district development in order to achieve improved energy efficiency and a reduced carbon footprint.

Paper number 33:
Title: Generation and Balancing Capacity in Future Electric Power Systems -- Scenario Analysis Using Bayesian Networks
Authors: Seppo Borenius, Pekka Kekolahti, Petri M√§h√∂nen, Matti Lehtonen
Abstract: This paper examines the evolution of the Finnish electric energy system up to 2035, focusing on the likelihood of different development paths. The primary contribution of this paper is the development of an extensive Bayesian Network, designed to model and analyse the evolution of power generation capacity mix, assess the likelihood of different grid management scenarios, and understand the causal relationships underlying these scenarios. A target optimisation was carried out using the constructed Bayesian Network to explore possibilities to minimise grid management complexity. The results of the optimisation reveal that the authorities and stakeholders should prioritise increasing demand response, gas power, and battery storage capacities. These mature technologies are well-suited to guarantee energy adequacy during peak consumption periods, which in Finland typically occur during consecutive cold, dark and windless winter weeks. Although this study focuses on the evolution of the Finnish power grid, the constructed Bayesian Network approach is broadly applicable and can be utilised to explore causal relationships in other countries by employing the designed questionnaire and engaging a panel of experts specific to the country's energy infrastructure.

Paper number 34:
Title: Reduced-latency DL-based Fractional Channel Estimation in OTFS Receivers
Authors: Mauro Marchese, Henk Wymeersch, Paolo Spallaccini, Stefano Chinnici, Pietro Savazzi
Abstract: In this work, we propose a deep learning (DL)-based approach that integrates a state-of-the-art algorithm with a time-frequency (TF) learning framework to minimize overall latency. Meeting the stringent latency requirements of 6G orthogonal time-frequency space (OTFS) systems necessitates low-latency designs. The performance of the proposed approach is evaluated under challenging conditions: low delay and Doppler resolutions caused by limited time and frequency resources, and significant interpath interference (IPI) due to poor separability of propagation paths in the delay-Doppler (DD) domain. Simulation results demonstrate that the proposed method achieves high estimation accuracy while reducing latency by approximately 55\% during the maximization process. However, a performance trade-off is observed, with a maximum loss of 3 dB at high pilot SNR values.

Paper number 35:
Title: MT-NAM: An Efficient and Adaptive Model for Epileptic Seizure Detection
Authors: Arshia Afzal, Volkan Cevher, Mahsa Shoaran
Abstract: Enhancing the accuracy and efficiency of machine learning algorithms employed in neural interface systems is crucial for advancing next-generation intelligent therapeutic devices. However, current systems often utilize basic machine learning models that do not fully exploit the natural structure of brain signals. Additionally, existing learning models used for neural signal processing often demonstrate low speed and efficiency during inference. To address these challenges, this study introduces Micro Tree-based NAM (MT-NAM), a distilled model based on the recently proposed Neural Additive Models (NAM). The MT-NAM achieves a remarkable 100$\times$ improvement in inference speed compared to standard NAM, without compromising accuracy. We evaluate our approach on the CHB-MIT scalp EEG dataset, which includes recordings from 24 patients with varying numbers of sessions and seizures. NAM achieves an 85.3\% window-based sensitivity and 95\% specificity. Interestingly, our proposed MT-NAM shows only a 2\% reduction in sensitivity compared to the original NAM. To regain this sensitivity, we utilize a test-time template adjuster (T3A) as an update mechanism, enabling our model to achieve higher sensitivity during test time by accommodating transient shifts in neural signals. With this online update approach, MT-NAM achieves the same sensitivity as the standard NAM while achieving approximately 50$\times$ acceleration in inference speed.

Paper number 36:
Title: Geometric Nonlinear Filtering with Almost Global Convergence for Attitude and Bias Estimation on the Special Orthogonal Group
Authors: Farooq Aslam, Muhammad Farooq Haydar, Suhail Akhtar
Abstract: This paper proposes a novel geometric nonlinear filter for attitude and bias estimation on the Special Orthogonal Group $SO(3)$ using matrix measurements. The structure of the proposed filter is similar to that of the continuous-time deterministic multiplicative extended Kalman filter (MEKF). The main difference with the MEKF is the inclusion of curvature correction terms in both the filter gain and gain update equations. These terms ensure that the proposed filter, named the Generalized $SO(3)$-MEKF, renders the desired equilibrium of the estimation error system to be almost globally uniformly asymptotically stable (AGUAS). More precisely, the attitude and bias estimation errors converge uniformly asymptotically to zero for almost all initial conditions except those where the initial angular estimation error equals $\pi$ radians. Moreover, in the case of small estimation errors, the proposed generalized $SO(3)$-MEKF simplifies to the standard $SO(3)$-MEKF with matrix measurements. Simulation results indicate that the proposed filter has similar performance compared to the latter. Thus, the main advantage of the proposed filter over the MEKF is the guarantee of (almost) global uniform asymptotic stability.

Paper number 37:
Title: Spatiotemporal Tubes based Controller Synthesis against Omega-Regular Specifications for Unknown Systems
Authors: Ratnangshu Das, Aiman Aatif Bayezeed, Pushpak Jagtap
Abstract: This paper provides a discretization-free solution to the synthesis of approx-imation-free closed-form controllers for unknown nonlinear systems to enforce complex properties expressed by $\omega$-regular languages, as recognized by Non-deterministic B√ºchi Automata (NBA). In order to solve this problem, we first decompose NBA into a sequence of reach-avoid problems, which are solved using the Spatiotemporal Tubes (STT) approach. Controllers for each reach-avoid task are then integrated into a hybrid policy that ensures the fulfillment of the desired $\omega$-regular properties. We validate our method through omnidirectional robot navigation and manipulator control case studies.

Paper number 38:
Title: On Digital Optimization of Analog Self-Interference Cancellation for Full-Duplex Wireless Systems
Authors: Niklas Knaepper, Gerald Enzner, Aleksej Chinaev
Abstract: Wireless systems with inband full-duplex transceiver typically require multiple lines of defense against the effect of harsh self-interference, specifically, to avoid saturation of the analog-to-digital converter (ADC) in the receiver. We may unite the typical tandem operation of successive analog and digital self-interference cancellation (SIC) stages by means of digitally-assisted analog SIC. In this case, the ADC in the receive path requires considerable attention due its possibly overloaded operation outside the intended range. Using neural-network-based architectures of the transmitter nonlinearity, we therefore describe and compare four system options for SIC model optimization with different treatment of the receiver ADC in the learning process. We find that omitting the ADC in the backwards path via a so-called straight-through estimation approximation barely impedes model learning, thus providing an efficient alternative to the classical approach of automatic gain control.

Paper number 39:
Title: 3D Medical Imaging Segmentation on Non-Contrast CT
Authors: Canxuan Gang, Yuhan Peng
Abstract: This technical report analyzes non-contrast CT image segmentation in computer vision. It revisits a proposed method, examines the background of non-contrast CT imaging, and highlights the significance of segmentation. The study reviews representative methods, including convolutional-based and CNN-Transformer hybrid approaches, discussing their contributions, advantages, and limitations. The nnUNet stands out as the state-of-the-art method across various segmentation tasks. The report explores the relationship between the proposed method and existing approaches, emphasizing the role of global context modeling in semantic labeling and mask generation. Future directions include addressing the long-tail problem, utilizing pre-trained models for medical imaging, and exploring self-supervised or contrastive pre-training techniques. This report offers insights into non-contrast CT image segmentation and potential advancements in the field.

Paper number 40:
Title: Survey on Beyond Diagonal RIS Enabled 6G Wireless Networks: Fundamentals, Recent Advances, and Challenges
Authors: Wali Ullah Khan, Manzoor Ahmed, Chandan Kumar Sheemar, Marco Di Renzo, Eva Lagunas, Asad Mahmood, Syed Tariq Shah, Octavia A. Dobre, Jorge Querol, Symeon Chatzinotas
Abstract: Beyond Diagonal Reconfigurable Intelligent Surfaces (BD-RIS) represent a groundbreaking innovation in sixth-generation (6G) wireless networks, enabling unprecedented control over wireless propagation environments compared to conventional diagonal RIS (D-RIS). This survey provides a comprehensive analysis of BD-RIS, detailing its architectures, operational principles, and mathematical modeling while highlighting its performance benefits. BD-RIS classifications, including single-connected, fully-connected, and group-connected architectures, and their reflective, transmissive, hybrid, and multi-sector operating modes are examined. Recent advances in BD-RIS-enabled 6G networks are reviewed, focusing on critical areas such as channel estimation, sum-rate and spectral efficiency optimization, energy efficiency enhancement, and security. The survey identifies fundamental challenges in BD-RIS research, including hardware design limitations, adaptive channel estimation, and the impact of non-ideal hardware effects. Future research directions for BD-RIS are proposed, emphasizing the integration of artificial intelligence and machine learning (AI/ML), joint optimization of communication and sensing, and enhanced physical layer security (PLS). This study concludes by underscoring BD-RIS's transformative potential to redefine 6G wireless networks, offering valuable insights and lessons for future research and development.

Paper number 41:
Title: Input Delay Compensation for a Class of Switched Linear Systems via Averaging Exact Predictor Feedbacks
Authors: Andreas Katsanikakis, Nikolaos Bekiaris-Liberis
Abstract: The key challenges in design of predictor-based control laws for switched systems with arbitrary switching and long input delay are the potential unavailability of the future values of the switching signal (at current time) and the fact that dwell time may be arbitrary. In the present paper, we resolve these challenges developing a new predictor-based control law that is, essentially, an average of exact predictor feedbacks, each one corresponding to an exact predictor-feedback law for a system that operates only in a single mode. Because the predictor state in our control design does not correspond to an exact predictor, stability can be guaranteed under a restriction on the differences among the system's matrices and controller's gains. This is an unavoidable limitation, for a switching signal whose future values may be unavailable, when no constraint is imposed on the values of delay and dwell time (as it is the case here). We establish (uniform) stability of the closed-loop system employing a Lyapunov functional. The key step in the stability proof is constructive derivation of an estimate of the mismatch between an exact predictor feedback and the average of predictor feedbacks constructed. We illustrate the performance of the proposed predictor-based control law in simulation, including comparisons with alternative, predictor-based control laws.

Paper number 42:
Title: Posterior-Mean Denoising Diffusion Model for Realistic PET Image Reconstruction
Authors: Yiran Sun, Osama Mawlawi
Abstract: Positron Emission Tomography (PET) is a functional imaging modality that enables the visualization of biochemical and physiological processes across various tissues. Recently, deep learning (DL)-based methods have demonstrated significant progress in directly mapping sinograms to PET images. However, regression-based DL models often yield overly smoothed reconstructions lacking of details (i.e., low distortion, low perceptual quality), whereas GAN-based and likelihood-based posterior sampling models tend to introduce undesirable artifacts in predictions (i.e., high distortion, high perceptual quality), limiting their clinical applicability. To achieve a robust perception-distortion tradeoff, we propose Posterior-Mean Denoising Diffusion Model (PMDM-PET), a novel approach that builds upon a recently established mathematical theory to explore the closed-form expression of perception-distortion function in diffusion model space for PET image reconstruction from sinograms. Specifically, PMDM-PET first obtained posterior-mean PET predictions under minimum mean square error (MSE), then optimally transports the distribution of them to the ground-truth PET images distribution. Experimental results demonstrate that PMDM-PET not only generates realistic PET images with possible minimum distortion and optimal perceptual quality but also outperforms five recent state-of-the-art (SOTA) DL baselines in both qualitative visual inspection and quantitative pixel-wise metrics PSNR (dB)/SSIM/NRMSE.

Paper number 43:
Title: Additive Frequency Diverse Active Incoherent Millimeter-Wave Imaging
Authors: Jorge R. Colon-Berrios, Jeffrey A. Nanzer
Abstract: We present an approach for improving spatial frequency sampling in active incoherent millimeter-wave (AIM) imaging systems using frequency diversity. AIM imaging relies on active transmission of spatio-temporally incoherent signals to illuminate a scene, from which interferometric Fourier-domain imaging can be implemented using a sparse receiving antenna array. One of the benefits of Fourier domain imaging is the sparsity of the receiving array, which can form images with equivalent resolution to traditional filled beamsteering arrays, but with a small fraction of the elements. The hardware reduction afforded by the sparse array often leads to an undersampled Fourier space, where even though image formation is possible, the image reconstruction may be degraded when viewing complex objects. To address this challenge without requiring additional receiver channels, we explore the use of frequency diversity in the illuminating and receiving systems. Fourier domain spatial frequency samples are determined by the electrical spacing and rotation of the receiving elements, thus by changing the frequency the sampled spatial frequencies also change. We implement an additive technique where the spatial frequency samples are summed prior to Fourier transform image formation. Importantly, because the system is active, a consistent signal-to-noise ratio is maintained across all frequencies, which may not be possible in traditional passive Fourier-domain imagers.

Paper number 44:
Title: Integrated Sensing, Communication, and Powering (ISCAP) for IoT: A Joint Beamforming Design
Authors: Maryam Asadi Ahmadabadi, S. Mohammad Razavizadeh, Vahid Jamali
Abstract: This paper studies Integrated Sensing, Communication, and Powering (ISCAP) as a novel framework designed to enhance Internet of Things (IoT) applications within sixth-generation wireless networks. In these applications, in addition to IoT devices requiring an energy supply and receiving information or control data to perform their tasks, the base station serving them must sense the devices and their environment to localize them, thereby improving data transmission and enabling simultaneous power delivery. In our multi-node ISCAP IoT system, we optimize base station beamforming alongside the receiver's power-splitting factor to maximize energy harvesting while adhering to strict communication and sensing constraints. To effectively tackle this non-convex optimization problem, we decompose it into three manageable subproblems and employ several techniques such as semidefinite relaxation and Rayleigh quotient methods to find an efficient solution. Simulation results demonstrate the effectiveness of the proposed design, highlighting performance trade-offs among sensing accuracy, communication reliability, and power transfer efficiency.

Paper number 45:
Title: Weakly Supervised Convolutional Dictionary Learning with Shared and Discriminative Components for Classification
Authors: Hao Chen, Yusen Wu, Dayuan Tan
Abstract: In today's data-driven landscape spanning finance, government, and healthcare sectors, the exponential growth of information necessitates robust solutions for secure storage, efficient dissemination, and fine-grained access control. Convolutional dictionary learning emerges as a powerful approach for extracting meaningful representations from complex data. This paper presents a novel weakly supervised convolutional dictionary learning framework that incorporates both shared and discriminative components for classification tasks. Our approach leverages limited label information to learn dictionaries that capture common patterns across classes while simultaneously highlighting class-specific features. By decomposing the learned representations into shared and discriminative parts, we enhance both feature interpretability and classification performance. Extensive experiments across multiple datasets demonstrate that our method outperforms state-of-the-art approaches, particularly in scenarios with limited labeled data. The proposed framework offers a promising solution for applications requiring both effective feature extraction and accurate classification in weakly supervised settings.

Paper number 46:
Title: Vision Transformer for Intracranial Hemorrhage Classification in CT Scans Using an Entropy-Aware Fuzzy Integral Strategy for Adaptive Scan-Level Decision Fusion
Authors: Mehdi Hosseini Chagahi, Niloufar Delfan, Behzad Moshiri, Md. Jalil Piran, Jaber Hatam Parikhan
Abstract: Intracranial hemorrhage (ICH) is a critical medical emergency caused by the rupture of cerebral blood vessels, leading to internal bleeding within the skull. Accurate and timely classification of hemorrhage subtypes is essential for effective clinical decision-making. To address this challenge, we propose an advanced pyramid vision transformer (PVT)-based model, leveraging its hierarchical attention mechanisms to capture both local and global spatial dependencies in brain CT scans. Instead of processing all extracted features indiscriminately, A SHAP-based feature selection method is employed to identify the most discriminative components, which are then used as a latent feature space to train a boosting neural network, reducing computational complexity. We introduce an entropy-aware aggregation strategy along with a fuzzy integral operator to fuse information across multiple CT slices, ensuring a more comprehensive and reliable scan-level diagnosis by accounting for inter-slice dependencies. Experimental results show that our PVT-based framework significantly outperforms state-of-the-art deep learning architectures in terms of classification accuracy, precision, and robustness. By combining SHAP-driven feature selection, transformer-based modeling, and an entropy-aware fuzzy integral operator for decision fusion, our method offers a scalable and computationally efficient AI-driven solution for automated ICH subtype classification.

Paper number 47:
Title: YuE: Scaling Open Foundation Models for Long-Form Music Generation
Authors: Ruibin Yuan, Hanfeng Lin, Shuyue Guo, Ge Zhang, Jiahao Pan, Yongyi Zang, Haohe Liu, Yiming Liang, Wenye Ma, Xingjian Du, Xinrun Du, Zhen Ye, Tianyu Zheng, Yinghao Ma, Minghao Liu, Zeyue Tian, Ziya Zhou, Liumeng Xue, Xingwei Qu, Yizhi Li, Shangda Wu, Tianhao Shen, Ziyang Ma, Jun Zhan, Chunhui Wang, Yatian Wang, Xiaowei Chi, Xinyue Zhang, Zhenzhu Yang, Xiangzhou Wang, Shansong Liu, Lingrui Mei, Peng Li, Junjie Wang, Jianwei Yu, Guojian Pang, Xu Li, Zihao Wang, Xiaohuan Zhou, Lijun Yu, Emmanouil Benetos, Yong Chen, Chenghua Lin, Xie Chen, Gus Xia, Zhaoxiang Zhang, Chao Zhang, Wenhu Chen, Xinyu Zhou, Xipeng Qiu, Roger Dannenberg, Jiaheng Liu, Jian Yang, Wenhao Huang, Wei Xue, Xu Tan, Yike Guo
Abstract: We tackle the task of long-form music generation--particularly the challenging \textbf{lyrics-to-song} problem--by introducing YuE, a family of open foundation models based on the LLaMA2 architecture. Specifically, YuE scales to trillions of tokens and generates up to five minutes of music while maintaining lyrical alignment, coherent musical structure, and engaging vocal melodies with appropriate accompaniment. It achieves this through (1) track-decoupled next-token prediction to overcome dense mixture signals, (2) structural progressive conditioning for long-context lyrical alignment, and (3) a multitask, multiphase pre-training recipe to converge and generalize. In addition, we redesign the in-context learning technique for music generation, enabling versatile style transfer (e.g., converting Japanese city pop into an English rap while preserving the original accompaniment) and bidirectional generation. Through extensive evaluation, we demonstrate that YuE matches or even surpasses some of the proprietary systems in musicality and vocal agility. In addition, fine-tuning YuE enables additional controls and enhanced support for tail languages. Furthermore, beyond generation, we show that YuE's learned representations can perform well on music understanding tasks, where the results of YuE match or exceed state-of-the-art methods on the MARBLE benchmark. Keywords: lyrics2song, song generation, long-form, foundation model, music generation

Paper number 48:
Title: A Quantum Neural Network Transfer-Learning Model for Forecasting Problems with Continuous and Discrete Variables
Authors: Ismael Abdulrahman
Abstract: This study introduces a continuous-variable quantum neural network (CV-QNN) model designed as a transfer-learning approach for forecasting problems. The proposed quantum technique features a simple structure with only eight trainable parameters, a single quantum layer with two wires to create entanglement, and ten quantum gates, hence the name QNNet10, effectively mimicking the functionality of classical neural networks. A notable aspect is that the quantum network achieves high accuracy with random initialization after a single iteration. This pretrained model is innovative as it requires no training or parameter tuning when applied to new datasets, allowing for parameter freezing while enabling the addition of a final layer for fine-tuning. Additionally, an equivalent discrete-variable quantum neural network (DV-QNN) is presented, structured similarly to the CV model. However, analysis shows that the two-wire DV model does not significantly enhance performance. As a result, a four-wire DV model is proposed, achieving comparable results but requiring a larger and more complex structure with additional gates. The pretrained model is applied to five forecasting problems of varying sizes, demonstrating its effectiveness.

Paper number 49:
Title: Data Foundations for Large Scale Multimodal Clinical Foundation Models
Authors: Wei Dai, Peilin Chen, Malinda Lu, Daniel Li, Haowen Wei, Hejie Cui, Paul Pu Liang
Abstract: Recent advances in clinical AI have enabled remarkable progress across many clinical domains. However, existing benchmarks and models are primarily limited to a small set of modalities and tasks, which hinders the development of large-scale multimodal methods that can make holistic assessments of patient health and well-being. To bridge this gap, we introduce Clinical Large-Scale Integrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark unifying diverse clinical data across imaging, language, temporal, and graph modalities. CLIMB comprises 4.51 million patient samples totaling 19.01 terabytes distributed across 2D imaging, 3D video, time series, graphs, and multimodal data. Through extensive empirical evaluation, we demonstrate that multitask pretraining significantly improves performance on understudied domains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis over single-task learning. Pretraining on CLIMB also effectively improves models' generalization capability to new tasks, and strong unimodal encoder performance translates well to multimodal performance when paired with task-appropriate fusion strategies. Our findings provide a foundation for new architecture designs and pretraining strategies to advance clinical AI research. Code is released at this https URL.

Paper number 50:
Title: Retrieval Augmented Generation with Multi-Modal LLM Framework for Wireless Environments
Authors: Muhammad Ahmed Mohsin, Ahsan Bilal, Sagnik Bhattacharya, John M. Cioffi
Abstract: Future wireless networks aim to deliver high data rates and lower power consumption while ensuring seamless connectivity, necessitating robust optimization. Large language models (LLMs) have been deployed for generalized optimization scenarios. To take advantage of generative AI (GAI) models, we propose retrieval augmented generation (RAG) for multi-sensor wireless environment perception. Utilizing domain-specific prompt engineering, we apply RAG to efficiently harness multimodal data inputs from sensors in a wireless environment. Key pre-processing pipelines including image-to-text conversion, object detection, and distance calculations for multimodal RAG input from multi-sensor data are proposed to obtain a unified vector database crucial for optimizing LLMs in global wireless tasks. Our evaluation, conducted with OpenAI's GPT and Google's Gemini models, demonstrates an 8%, 8%, 10%, 7%, and 12% improvement in relevancy, faithfulness, completeness, similarity, and accuracy, respectively, compared to conventional LLM-based designs. Furthermore, our RAG-based LLM framework with vectorized databases is computationally efficient, providing real-time convergence under latency constraints.

Paper number 51:
Title: Theoretical Analysis of Multi-coding with Non-orthogonal Signaling
Authors: Brian Nelson, Behrouz Farhang-Boroujeny
Abstract: Even though orthogonal multi-code signaling and its derivative, simplex signaling, are well known and widely used in different communication systems, certain applications may choose to adopt non-orthogonal signaling to benefit from other advantages that such signaling methods can offer. Motivated by a class of multi-carrier spread spectrum systems, this paper presents a thorough symbol error rate analysis of the broad class of multi-code signaling methods when they make use of codes which are not necessarily orthogonal. Our analysis is also extended to the case where the code set includes the negative of each code vector, i.e., an extension to biorthogonal signaling. Moreover, it is shown that the symbol error rate results derived in this paper reduce to those available in the literature when the multi-codes are orthogonal or satisfy the correlation property of simplex multi-codes.

Paper number 52:
Title: A Landmark-Aided Navigation Approach Using Side-Scan Sonar
Authors: Ellen Davenport, Khoa Nguyen, Junsu Jang, Clair Ma, Sean Fish, Luc Lenain, Florian Meyer
Abstract: Cost-effective localization methods for Autonomous Underwater Vehicle (AUV) navigation are key for ocean monitoring and data collection at high resolution in time and space. Algorithmic solutions suitable for real-time processing that handle nonlinear measurement models and different forms of measurement uncertainty will accelerate the development of field-ready technology. This paper details a Bayesian estimation method for landmark-aided navigation using a Side-scan Sonar (SSS) sensor. The method bounds navigation filter error in the GPS-denied undersea environment and captures the highly nonlinear nature of slant range measurements while remaining computationally tractable. Combining a novel measurement model with the chosen statistical framework facilitates the efficient use of SSS data and, in the future, could be used in real time. The proposed filter has two primary steps: a prediction step using an unscented transform and an update step utilizing particles. The update step performs probabilistic association of sonar detections with known landmarks. We evaluate algorithm performance and tractability using synthetic data and real data collected field experiments. Field experiments were performed using two different marine robotic platforms with two different SSS and at two different sites. Finally, we discuss the computational requirements of the proposed method and how it extends to real-time applications.

Paper number 53:
Title: Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for Remote Sensing
Authors: Xing Zi, Kairui Jin, Xian Tao, Jun Li, Ali Braytee, Rajiv Ratn Shah, Mukesh Prasad
Abstract: Pixel-level segmentation is essential in remote sensing, where foundational vision models like CLIP and Segment Anything Model(SAM) have demonstrated significant capabilities in zero-shot segmentation tasks. Despite their advances, challenges specific to remote sensing remain substantial. Firstly, The SAM without clear prompt constraints, often generates redundant masks, and making post-processing more complex. Secondly, the CLIP model, mainly designed for global feature alignment in foundational models, often overlooks local objects crucial to remote sensing. This oversight leads to inaccurate recognition or misplaced focus in multi-target remote sensing imagery. Thirdly, both models have not been pre-trained on multi-scale aerial views, increasing the likelihood of detection failures. To tackle these challenges, we introduce the innovative VTPSeg pipeline, utilizing the strengths of Grounding DINO, CLIP, and SAM for enhanced open-vocabulary image segmentation. The Grounding DINO+(GD+) module generates initial candidate bounding boxes, while the CLIP Filter++(CLIP++) module uses a combination of visual and textual prompts to refine and filter out irrelevant object bounding boxes, ensuring that only pertinent objects are considered. Subsequently, these refined bounding boxes serve as specific prompts for the FastSAM model, which executes precise segmentation. Our VTPSeg is validated by experimental and ablation study results on five popular remote sensing image segmentation datasets.

Paper number 54:
Title: Counterfactual Explanations for Model Ensembles Using Entropic Risk Measures
Authors: Erfaun Noorani, Pasan Dissanayake, Faisal Hamman, Sanghamitra Dutta
Abstract: Counterfactual explanations indicate the smallest change in input that can translate to a different outcome for a machine learning model. Counterfactuals have generated immense interest in high-stakes applications such as finance, education, hiring, etc. In several use-cases, the decision-making process often relies on an ensemble of models rather than just one. Despite significant research on counterfactuals for one model, the problem of generating a single counterfactual explanation for an ensemble of models has received limited interest. Each individual model might lead to a different counterfactual, whereas trying to find a counterfactual accepted by all models might significantly increase cost (effort). We propose a novel strategy to find the counterfactual for an ensemble of models using the perspective of entropic risk measure. Entropic risk is a convex risk measure that satisfies several desirable properties. We incorporate our proposed risk measure into a novel constrained optimization to generate counterfactuals for ensembles that stay valid for several models. The main significance of our measure is that it provides a knob that allows for the generation of counterfactuals that stay valid under an adjustable fraction of the models. We also show that a limiting case of our entropic-risk-based strategy yields a counterfactual valid for all models in the ensemble (worst-case min-max approach). We study the trade-off between the cost (effort) for the counterfactual and its validity for an ensemble by varying degrees of risk aversion, as determined by our risk parameter knob. We validate our performance on real-world datasets.

Paper number 55:
Title: Accelerating Development in UAV Network Digital Twins with a Flexible Simulation Framework
Authors: Md Sharif Hossen, Anil Gurses, Mihail Sichitiu, Ismail Guvenc
Abstract: Unmanned aerial vehicles (UAVs) enhance coverage and provide flexible deployment in 5G and next-generation wireless networks. The performance of such wireless networks can be improved by developing new navigation and wireless adaptation approaches in digital twins (DTs). However, challenges such as complex propagation conditions and hardware complexities in real-world scenarios introduce a realism gap with the DTs. Moreover, while using real-time full-stack protocols in DTs enables subsequent deployment and testing in a real-world environment, development in DTs requires high computational complexity and involves a long development time. In this paper, to accelerate the development cycle, we develop a measurement-calibrated Matlab-based simulation framework to replicate performance in a full-stack UAV wireless network DT. In particular, we use the DT from the NSF AERPAW platform and compare its reports with those generated by our developed simulation framework in wireless networks with similar settings. In both environments, we observe comparable results in terms of RSRP measurement, hence motivating iterative use of the developed simulation environment with the DT.

Paper number 56:
Title: BUFFER-X: Towards Zero-Shot Point Cloud Registration in Diverse Scenes
Authors: Minkyun Seo, Hyungtae Lim, Kanghee Lee, Luca Carlone, Jaesik Park
Abstract: Recent advances in deep learning-based point cloud registration have improved generalization, yet most methods still require retraining or manual parameter tuning for each new environment. In this paper, we identify three key factors limiting generalization: (a) reliance on environment-specific voxel size and search radius, (b) poor out-of-domain robustness of learning-based keypoint detectors, and (c) raw coordinate usage, which exacerbates scale discrepancies. To address these issues, we present a zero-shot registration pipeline called BUFFER-X by (a) adaptively determining voxel size/search radii, (b) using farthest point sampling to bypass learned detectors, and (c) leveraging patch-wise scale normalization for consistent coordinate bounds. In particular, we present a multi-scale patch-based descriptor generation and a hierarchical inlier search across scales to improve robustness in diverse scenes. We also propose a novel generalizability benchmark using 11 datasets that cover various indoor/outdoor scenarios and sensor modalities, demonstrating that BUFFER-X achieves substantial generalization without prior information or manual parameter tuning for the test datasets. Our code is available at this https URL.

Paper number 57:
Title: Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal Manipulation using Tight Convex Relaxations
Authors: Yuki Shirai, Arvind Raghunathan, Devesh K. Jha
Abstract: Designing trajectories for manipulation through contact is challenging as it requires reasoning of object \& robot trajectories as well as complex contact sequences simultaneously. In this paper, we present a novel framework for simultaneously designing trajectories of robots, objects, and contacts efficiently for contact-rich manipulation. We propose a hierarchical optimization framework where Mixed-Integer Linear Program (MILP) selects optimal contacts between robot \& object using approximate dynamical constraints, and then a NonLinear Program (NLP) optimizes trajectory of the robot(s) and object considering full nonlinear constraints. We present a convex relaxation of bilinear constraints using binary encoding technique such that MILP can provide tighter solutions with better computational complexity. The proposed framework is evaluated on various manipulation tasks where it can reason about complex multi-contact interactions while providing computational advantages. We also demonstrate our framework in hardware experiments using a bimanual robot system.

Paper number 58:
Title: Boundary Regression for Leitmotif Detection in Music Audio
Authors: Sihun Lee, Dasaem Jeong
Abstract: Leitmotifs are musical phrases that are reprised in various forms throughout a piece. Due to diverse variations and instrumentation, detecting the occurrence of leitmotifs from audio recordings is a highly challenging task. Leitmotif detection may be handled as a subcategory of audio event detection, where leitmotif activity is predicted at the frame level. However, as leitmotifs embody distinct, coherent musical structures, a more holistic approach akin to bounding box regression in visual object detection can be helpful. This method captures the entirety of a motif rather than fragmenting it into individual frames, thereby preserving its musical integrity and producing more useful predictions. We present our experimental results on tackling leitmotif detection as a boundary regression task.

Paper number 59:
Title: GPT-PPG: A GPT-based Foundation Model for Photoplethysmography Signals
Authors: Zhaoliang Chen, Cheng Ding, Saurabh Kataria, Runze Yan, Minxiao Wang, Randall Lee, Xiao Hu
Abstract: This study introduces a novel application of a Generative Pre-trained Transformer (GPT) model tailored for photoplethysmography (PPG) signals, serving as a foundation model for various downstream tasks. Adapting the standard GPT architecture to suit the continuous characteristics of PPG signals, our approach demonstrates promising results. Our models are pre-trained on our extensive dataset that contains more than 200 million 30s PPG samples. We explored different supervised fine-tuning techniques to adapt our model to downstream tasks, resulting in performance comparable to or surpassing current state-of-the-art (SOTA) methods in tasks like atrial fibrillation detection. A standout feature of our GPT model is its inherent capability to perform generative tasks such as signal denoising effectively, without the need for further fine-tuning. This success is attributed to the generative nature of the GPT framework.

Paper number 60:
Title: Elastic Motion Policy: An Adaptive Dynamical System for Robust and Efficient One-Shot Imitation Learning
Authors: Tianyu Li, Sunan Sun, Shubhodeep Shiv Aditya, Nadia Figueroa
Abstract: Behavior cloning (BC) has become a staple imitation learning paradigm in robotics due to its ease of teaching robots complex skills directly from expert demonstrations. However, BC suffers from an inherent generalization issue. To solve this, the status quo solution is to gather more data. Yet, regardless of how much training data is available, out-of-distribution performance is still sub-par, lacks any formal guarantee of convergence and success, and is incapable of allowing and recovering from physical interactions with humans. These are critical flaws when robots are deployed in ever-changing human-centric environments. Thus, we propose Elastic Motion Policy (EMP), a one-shot imitation learning framework that allows robots to adjust their behavior based on the scene change while respecting the task specification. Trained from a single demonstration, EMP follows the dynamical systems paradigm where motion planning and control are governed by first-order differential equations with convergence guarantees. We leverage Laplacian editing in full end-effector space, $\mathbb{R}^3\times SO(3)$, and online convex learning of Lyapunov functions, to adapt EMP online to new contexts, avoiding the need to collect new demonstrations. We extensively validate our framework in real robot experiments, demonstrating its robust and efficient performance in dynamic environments, with obstacle avoidance and multi-step task capabilities. Project Website: this https URL

Paper number 61:
Title: FilmComposer: LLM-Driven Music Production for Silent Film Clips
Authors: Zhifeng Xie, Qile He, Youjia Zhu, Qiwei He, Mengtian Li
Abstract: In this work, we implement music production for silent film clips using LLM-driven method. Given the strong professional demands of film music production, we propose the FilmComposer, simulating the actual workflows of professional musicians. FilmComposer is the first to combine large generative models with a multi-agent approach, leveraging the advantages of both waveform music and symbolic music generation. Additionally, FilmComposer is the first to focus on the three core elements of music production for film-audio quality, musicality, and musical development-and introduces various controls, such as rhythm, semantics, and visuals, to enhance these key aspects. Specifically, FilmComposer consists of the visual processing module, rhythm-controllable MusicGen, and multi-agent assessment, arrangement and mix. In addition, our framework can seamlessly integrate into the actual music production pipeline and allows user intervention in every step, providing strong interactivity and a high degree of creative freedom. Furthermore, we propose MusicPro-7k which includes 7,418 film clips, music, description, rhythm spots and main melody, considering the lack of a professional and high-quality film music dataset. Finally, both the standard metrics and the new specialized metrics we propose demonstrate that the music generated by our model achieves state-of-the-art performance in terms of quality, consistency with video, diversity, musicality, and musical development. Project page: this https URL

Paper number 62:
Title: Observer-Based Output-Feedback Backstepping Stabilization of Continua of Hyperbolic PDEs and Application to Large-Scale $n+m$ Coupled Hyperbolic PDEs
Authors: Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis
Abstract: We develop a non-collocated, observer-based output-feedback law for a class of continua of linear hyperbolic PDE systems, which are viewed as the continuum version of $n+m$, general heterodirectional hyperbolic systems as $n\to\infty$. The design relies on the introduction of a novel, continuum PDE backstepping transformation, which enables the construction of a Lyapunov functional for the estimation error system. Stability under the observer-based output-feedback law is established by using the Lyapunov functional construction for the estimation error system and proving well-posedness of the complete closed-loop system, which allows utilization of the separation principle. Motivated by the fact that the continuum-based designs may provide computationally tractable control laws for large-scale, $n+m$ systems, we then utilize the control/observer kernels and the observer constructed for the continuum system to introduce an output-feedback control design for the original $n+m$ system. We establish exponential stability of the resulting closed-loop system, which consists of a mixed $n+m$-continuum PDE system (comprising the plant-observer dynamics), introducing a virtual continuum system with resets, which enables utilization of the continuum approximation property of the solutions of the $n+m$ system by its continuum counterpart (for large $n$). We illustrate the potential computational complexity/flexibility benefits of our approach via a numerical example of stabilization of a large-scale $n+m$ system, for which we employ the continuum observer-based controller, while the continuum-based stabilizing control/observer kernels can be computed in closed form.

Paper number 63:
Title: Safety-Ensured Control Framework for Robotic Endoscopic Task Automation
Authors: Yitaek Kim, I√±igo Iturrate, Christoffer Sloth, Hansoul Kim
Abstract: There is growing interest in automating surgical tasks using robotic systems, such as endoscopy for treating gastrointestinal (GI) cancer. However, previous studies have primarily focused on detecting and analyzing objects or robots, with limited attention to ensuring safety, which is critical for clinical applications, where accidents can be caused by unsafe robot motions. In this study, we propose a new control framework that can formally ensure the safety of automating certain processes involved in endoscopic submucosal dissection (ESD), a representative endoscopic surgical method for the treatment of early GI cancer, by using an endoscopic robot. The proposed framework utilizes Control Barrier Functions (CBFs) to accurately identify the boundaries of individual tumors, even in close proximity within the GI tract, ensuring precise treatment and removal while preserving the surrounding normal tissue. Additionally, by adopting a model-free control scheme, safety assurance is made possible even in endoscopic robotic systems where dynamic modeling is challenging. We demonstrate the proposed framework in cases where the tumors to be removed are close to each other, showing that the safety constraints are enforced. We show that the model-free CBF-based controlled robot eliminates one tumor completely without damaging it, while not invading another nearby tumor.

Paper number 64:
Title: Online Conformal Compression for Zero-Delay Communication with Distortion Guarantees
Authors: Unnikrishnan Kunnath Ganesan, Giuseppe Durisi, Matteo Zecchin, Petar Popovski, Osvaldo Simeone
Abstract: We investigate a lossy source compression problem in which both the encoder and decoder are equipped with a pre-trained sequence predictor. We propose an online lossy compression scheme that, under a 0-1 loss distortion function, ensures a deterministic, per-sequence upper bound on the distortion (outage) level for any time instant. The outage guarantees apply irrespective of any assumption on the distribution of the sequences to be encoded or on the quality of the predictor at the encoder and decoder. The proposed method, referred to as online conformal compression (OCC), is built upon online conformal prediction--a novel method for constructing confidence intervals for arbitrary predictors. Numerical results show that OCC achieves a compression rate comparable to that of an idealized scheme in which the encoder, with hindsight, selects the optimal subset of symbols to describe to the decoder, while satisfying the overall outage constraint.

Paper number 65:
Title: Controlling Latent Diffusion Using Latent CLIP
Authors: Jason Becker, Chris Wendler, Peter Baylies, Robert West, Christian Wressnegger
Abstract: Instead of performing text-conditioned denoising in the image domain, latent diffusion models (LDMs) operate in latent space of a variational autoencoder (VAE), enabling more efficient processing at reduced computational costs. However, while the diffusion process has moved to the latent space, the contrastive language-image pre-training (CLIP) models, as used in many image processing tasks, still operate in pixel space. Doing so requires costly VAE-decoding of latent images before they can be processed. In this paper, we introduce Latent-CLIP, a CLIP model that operates directly in the latent space. We train Latent-CLIP on 2.7B pairs of latent images and descriptive texts, and show that it matches zero-shot classification performance of similarly sized CLIP models on both the ImageNet benchmark and a LDM-generated version of it, demonstrating its effectiveness in assessing both real and generated content. Furthermore, we construct Latent-CLIP rewards for reward-based noise optimization (ReNO) and show that they match the performance of their CLIP counterparts on GenEval and T2I-CompBench while cutting the cost of the total pipeline by 21%. Finally, we use Latent-CLIP to guide generation away from harmful content, achieving strong performance on the inappropriate image prompts (I2P) benchmark and a custom evaluation, without ever requiring the costly step of decoding intermediate images.

Paper number 66:
Title: Efficient Resource Allocation in 5G Massive MIMO-NOMA Networks: Comparative Analysis of SINR-Aware Power Allocation and Spatial Correlation-Based Clustering
Authors: Samar Chebbi, Oussama Habachi, Jean-Pierre Cances, Vahid Meghdadi Essaid Sabir
Abstract: With the evolution of 5G networks, optimizing resource allocation has become crucial to meeting the increasing demand for massive connectivity and high throughput. Combining Non-Orthogonal Multiple Access (NOMA) and massive Multi-Input Multi-Output (MIMO) enhances spectral efficiency, power efficiency, and device connectivity. However, deploying MIMO-NOMA in dense networks poses challenges in managing interference and optimizing power allocation while ensuring that the Signal-to-Interference-plus-Noise Ratio (SINR) meets required thresholds. Unlike previous studies that analyze user clustering and power allocation techniques under simplified assumptions, this work provides a comparative evaluation of multiple clustering and allocation strategies under identical spatially correlated network conditions. We focus on maximizing the number of served users under a given Quality of Service (QoS) constraint rather than the conventional sum-rate maximization approach. Additionally, we consider spatial correlation in user grouping, a factor often overlooked despite its importance in mitigating intra-cluster interference. We evaluate clustering algorithms, including user pairing, random clustering, Correlation Iterative Clustering Algorithm (CIA), K-means++-based User Clustering (KUC), and Grey Wolf Optimizer-based clustering (GWO), in a downlink spatially correlated MIMO-NOMA environment. Numerical results demonstrate that the GWO-based clustering algorithm achieves superior energy efficiency while maintaining scalability, whereas CIA effectively maximizes the number of served users. These findings provide valuable insights for designing MIMO-NOMA systems that optimize resource allocation in next-generation wireless networks.

Paper number 67:
Title: ESPnet-SDS: Unified Toolkit and Demo for Spoken Dialogue Systems
Authors: Siddhant Arora, Yifan Peng, Jiatong Shi, Jinchuan Tian, William Chen, Shikhar Bharadwaj, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Shuichiro Shimizu, Vaibhav Srivastav, Shinji Watanabe
Abstract: Advancements in audio foundation models (FMs) have fueled interest in end-to-end (E2E) spoken dialogue systems, but different web interfaces for each system makes it challenging to compare and contrast them effectively. Motivated by this, we introduce an open-source, user-friendly toolkit designed to build unified web interfaces for various cascaded and E2E spoken dialogue systems. Our demo further provides users with the option to get on-the-fly automated evaluation metrics such as (1) latency, (2) ability to understand user input, (3) coherence, diversity, and relevance of system response, and (4) intelligibility and audio quality of system output. Using the evaluation metrics, we compare various cascaded and E2E spoken dialogue systems with a human-human conversation dataset as a proxy. Our analysis demonstrates that the toolkit allows researchers to effortlessly compare and contrast different technologies, providing valuable insights such as current E2E systems having poorer audio quality and less diverse responses. An example demo produced using our toolkit is publicly available here: this https URL.

Paper number 68:
Title: Mellow: a small audio language model for reasoning
Authors: Soham Deshmukh, Satvik Dixit, Rita Singh, Bhiksha Raj
Abstract: Multimodal Audio-Language Models (ALMs) can understand and reason over both audio and text. Typically, reasoning performance correlates with model size, with the best results achieved by models exceeding 8 billion parameters. However, no prior work has explored enabling small audio-language models to perform reasoning tasks, despite the potential applications for edge devices. To address this gap, we introduce Mellow, a small Audio-Language Model specifically designed for reasoning. Mellow achieves state-of-the-art performance among existing small audio-language models and surpasses several larger models in reasoning capabilities. For instance, Mellow scores 52.11 on MMAU, comparable to SoTA Qwen2 Audio (which scores 52.5) while using 50 times fewer parameters and being trained on 60 times less data (audio hrs). To train Mellow, we introduce ReasonAQA, a dataset designed to enhance audio-grounded reasoning in models. It consists of a mixture of existing datasets (30% of the data) and synthetically generated data (70%). The synthetic dataset is derived from audio captioning datasets, where Large Language Models (LLMs) generate detailed and multiple-choice questions focusing on audio events, objects, acoustic scenes, signal properties, semantics, and listener emotions. To evaluate Mellow's reasoning ability, we benchmark it on a diverse set of tasks, assessing on both in-distribution and out-of-distribution data, including audio understanding, deductive reasoning, and comparative reasoning. Finally, we conduct extensive ablation studies to explore the impact of projection layer choices, synthetic data generation methods, and language model pretraining on reasoning performance. Our training dataset, findings, and baseline pave the way for developing small ALMs capable of reasoning.

Paper number 69:
Title: An Analysis of Safety Guarantees in Multi-Task Bayesian Optimization
Authors: Jannis O. Luebsen, Annika Eichler
Abstract: In many practical scenarios of black box optimization, the objective function is subject to constraints that must be satisfied to avoid undesirable outcomes. Such constraints are typically unknown and must be learned during optimization. Safe Bayesian optimization aims to find the global optimum while ensuring that the constraints are satisfied with high probability. However, it is often sample-inefficient due to the small initial feasible set, which requires expansion by evaluating the objective or constraint functions, limiting its applicability to low-dimensional or inexpensive problems. To enhance sample efficiency, additional information from cheap simulations can be leveraged, albeit at the cost of safeness guarantees. This paper introduces a novel safe multi-task Bayesian optimization algorithm that integrates multiple tasks while maintaining high-probability safety. We derive robust uniform error bounds for the multi-task case and demonstrate the effectiveness of the approach on benchmark functions and a control problem. Our results show a significant improvement in sample efficiency, making the proposed method well-suited for expensive-to-evaluate functions.

Paper number 70:
Title: Task-Oriented Co-Design of Communication, Computing, and Control for Edge-Enabled Industrial Cyber-Physical Systems
Authors: Yufeng Diao, Yichi Zhang, Daniele De Martini, Philip Guodong Zhao, Emma Liying Li
Abstract: This paper proposes a task-oriented co-design framework that integrates communication, computing, and control to address the key challenges of bandwidth limitations, noise interference, and latency in mission-critical industrial Cyber-Physical Systems (CPS). To improve communication efficiency and robustness, we design a task-oriented Joint Source-Channel Coding (JSCC) using Information Bottleneck (IB) to enhance data transmission efficiency by prioritizing task-specific information. To mitigate the perceived End-to-End (E2E) delays, we develop a Delay-Aware Trajectory-Guided Control Prediction (DTCP) strategy that integrates trajectory planning with control prediction, predicting commands based on E2E delay. Moreover, the DTCP is co-designed with task-oriented JSCC, focusing on transmitting task-specific information for timely and reliable autonomous driving. Experimental results in the CARLA simulator demonstrate that, under an E2E delay of 1 second (20 time slots), the proposed framework achieves a driving score of 48.12, which is 31.59 points higher than using Better Portable Graphics (BPG) while reducing bandwidth usage by 99.19%.

Paper number 71:
Title: Convex Hull Prediction Methods for Bitrate Ladder Construction: Design, Evaluation, and Comparison
Authors: Ahmed Telili, Wassim Hamidouche, Hadi Amirpour, Sid Ahmed Fezza, Luce Morin, Christian Timmerer
Abstract: HTTP adaptive streaming (HAS) has emerged as a prevalent approach for over-the-top (OTT) video streaming services due to its ability to deliver a seamless user experience. A fundamental component of HAS is the bitrate ladder, which comprises a set of encoding parameters (e.g., bitrate-resolution pairs) used to encode the source video into multiple representations. This adaptive bitrate ladder enables the client's video player to dynamically adjust the quality of the video stream in real-time based on fluctuations in network conditions, ensuring uninterrupted playback by selecting the most suitable representation for the available bandwidth. The most straightforward approach involves using a fixed bitrate ladder for all videos, consisting of pre-determined bitrate-resolution pairs known as one-size-fits-all. Conversely, the most reliable technique relies on intensively encoding all resolutions over a wide range of bitrates to build the convex hull, thereby optimizing the bitrate ladder by selecting the representations from the convex hull for each specific video. Several techniques have been proposed to predict content-based ladders without performing a costly, exhaustive search encoding. This paper provides a comprehensive review of various convex hull prediction methods, including both conventional and learning-based approaches. Furthermore, we conduct a benchmark study of several handcrafted- and DL-based approaches for predicting content-optimized convex hulls across multiple codec settings. The considered methods are evaluated on our proposed large-scale dataset, which includes 300 UHD video shots encoded with software and hardware encoders using three state-of-the-art video standards, including AVC/H.264, HEVC/H.265, and VVC/H.266, at various bitrate points. Our analysis provides valuable insights and establishes baseline performance for future research in this field.

Paper number 72:
Title: Transformers are Provably Optimal In-context Estimators for Wireless Communications
Authors: Vishnu Teja Kunde, Vicram Rajagopalan, Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Srinivas Shakkottai, Dileep Kalathil, Jean-Francois Chamberland
Abstract: Pre-trained transformers exhibit the capability of adapting to new tasks through in-context learning (ICL), where they efficiently utilize a limited set of prompts without explicit model optimization. The canonical communication problem of estimating transmitted symbols from received observations can be modeled as an in-context learning problem: received observations are a noisy function of transmitted symbols, and this function can be represented by an unknown parameter whose statistics depend on an unknown latent context. This problem, which we term in-context estimation (ICE), has significantly greater complexity than the extensively studied linear regression problem. The optimal solution to the ICE problem is a non-linear function of the underlying context. In this paper, we prove that, for a subclass of such problems, a single-layer softmax attention transformer (SAT) computes the optimal solution of the above estimation problem in the limit of large prompt length. We also prove that the optimal configuration of such a transformer is indeed the minimizer of the corresponding training loss. Further, we empirically demonstrate the proficiency of multi-layer transformers in efficiently solving broader in-context estimation problems. Through extensive simulations, we show that solving ICE problems using transformers significantly outperforms standard approaches. Moreover, just with a few context examples, it achieves the same performance as an estimator with perfect knowledge of the latent context. The code is available \href{this https URL}{here}.

Paper number 73:
Title: From Classification to Optimization: Slicing and Resource Management with TRACTOR
Authors: Joshua Groen, Zixian Yang, Divyadharshini Muruganandham, Mauro Belgiovine, Lei Ying, Kaushik Chowdhury
Abstract: 5G and beyond networks promise advancements in bandwidth, latency, and connectivity. The Open Radio Access Network (O-RAN) framework enhances flexibility through network slicing and closed-loop RAN control. Central to this evolution is integrating machine learning (ML) for dynamic network control. This paper presents a framework to optimize O-RAN operation. First, we build and share a robust O-RAN dataset from real-world traffic captured across diverse locations and mobility scenarios, replicated within a full-stack srsRAN-based O-RAN system using the Colosseum RF emulator. This dataset supports ML training and deployment. We then introduce a traffic classification approach leveraging various ML models, demonstrating rapid training, testing, and refinement to improve accuracy. With up to 99% offline accuracy and 92% online accuracy for specific slices, our framework adapts efficiently to different models and network conditions. Finally, we present a physical resource block (PRB) assignment optimization strategy using reinforcement learning to refine resource allocation. Our learned policy achieves a mean performance score (0.631), surpassing a manually configured expert policy (0.609) and a random baseline (0.588), demonstrating improved PRB utilization. More importantly, our approach exhibits lower variability, with the Coefficient of Variation (CV) reduced by up to an order of magnitude in three out of four cases, ensuring more consistent performance. Our contributions, including open-source tools and datasets, accelerate O-RAN and ML-driven network control research.

Paper number 74:
Title: Beyond Subspace Isolation: Many-to-Many Transformer for Light Field Image Super-resolution
Authors: Zeke Zexi Hu, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen
Abstract: The effective extraction of spatial-angular features plays a crucial role in light field image super-resolution (LFSR) tasks, and the introduction of convolution and Transformers leads to significant improvement in this area. Nevertheless, due to the large 4D data volume of light field images, many existing methods opted to decompose the data into a number of lower-dimensional subspaces and perform Transformers in each sub-space individually. As a side effect, these methods inadvertently restrict the self-attention mechanisms to a One-to-One scheme accessing only a limited subset of LF data, explicitly preventing comprehensive optimization on all spatial and angular cues. In this paper, we identify this limitation as subspace isolation and introduce a novel Many-to-Many Transformer (M2MT) to address it. M2MT aggregates angular information in the spatial subspace before performing the self-attention mechanism. It enables complete access to all information across all sub-aperture images (SAIs) in a light field image. Consequently, M2MT is enabled to comprehensively capture long-range correlation dependencies. With M2MT as the pivotal component, we develop a simple yet effective M2MT network for LFSR. Our experimental results demonstrate that M2MT achieves state-of-the-art performance across various public datasets. We further conduct in-depth analysis using local attribution maps (LAM) to obtain visual interpretability, and the results validate that M2MT is empowered with a truly non-local context in both spatial and angular subspaces to mitigate subspace isolation and acquire effective spatial-angular representation.

Paper number 75:
Title: MAD Speech: Measures of Acoustic Diversity of Speech
Authors: Matthieu Futeral, Andrea Agostinelli, Marco Tagliasacchi, Neil Zeghidour, Eugene Kharitonov
Abstract: Generative spoken language models produce speech in a wide range of voices, prosody, and recording conditions, seemingly approaching the diversity of natural speech. However, the extent to which generated speech is acoustically diverse remains unclear due to a lack of appropriate metrics. We address this gap by developing lightweight metrics of acoustic diversity, which we collectively refer to as MAD Speech. We focus on measuring five facets of acoustic diversity: voice, gender, emotion, accent, and background noise. We construct the metrics as a composition of specialized, per-facet embedding models and an aggregation function that measures diversity within the embedding space. Next, we build a series of datasets with a priori known diversity preferences for each facet. Using these datasets, we demonstrate that our proposed metrics achieve a stronger agreement with the ground-truth diversity than baselines. Finally, we showcase the applicability of our proposed metrics across several real-life evaluation scenarios. MAD Speech is made publicly accessible.

Paper number 76:
Title: Experiences with Sub-Arctic Sensor Network Deployment
Authors: Priyesh Pappinisseri Puluckul, Maarten Weyn
Abstract: This paper discusses the experiences gained from designing, deploying, and maintaining low-power Wireless Sensor Networks (WSN) in three geothermally active remote locations in Iceland. The network was deployed for environmental monitoring and real-time data collection to assist in investigating the impact of global warming on the (sub)Arctic climate and the resulting carbon release from the region. Functional networks with more than 50 sensor nodes from three sites with extreme weather conditions and hard-to-access terrain have been collecting data since 2021. The networks employ primary cell-powered wireless sensor nodes equipped with DASH7 Alliance Protocol (D7A) for low-power data transmission and solar-powered D7A-cellular gateways for the backend connection. The WSNs have so far achieved over three years of uptime with minimal maintenance required throughout this period. We present a detailed discussion of different network components, their architecture, and the networks' overall performance and reliability.

Paper number 77:
Title: Physics-informed Score-based Diffusion Model for Limited-angle Reconstruction of Cardiac Computed Tomography
Authors: Shuo Han, Yongshun Xu, Dayang Wang, Bahareh Morovati, Li Zhou, Jonathan S. Maltz, Ge Wang, Hengyong Yu
Abstract: Cardiac computed tomography (CT) has emerged as a major imaging modality for the diagnosis and monitoring of cardiovascular diseases. High temporal resolution is essential to ensure diagnostic accuracy. Limited-angle data acquisition can reduce scan time and improve temporal resolution, but typically leads to severe image degradation and motivates for improved reconstruction techniques. In this paper, we propose a novel physics-informed score-based diffusion model (PSDM) for limited-angle reconstruction of cardiac CT. At the sampling time, we combine a data prior from a diffusion model and a model prior obtained via an iterative algorithm and Fourier fusion to further enhance the image quality. Specifically, our approach integrates the primal-dual hybrid gradient (PDHG) algorithm with score-based diffusion models, thereby enabling us to reconstruct high-quality cardiac CT images from limited-angle data. The numerical simulations and real data experiments confirm the effectiveness of our proposed approach.

Paper number 78:
Title: Advancing Ubiquitous Wireless Connectivity through Channel Twinning
Authors: Yashuai Cao, Linglong Dai, Jingbo Tan, Jintao Wang, Tianyue Zheng, Wei Ni, Ekram Hossain, Dusit Niyato
Abstract: As an emerging trend in channel acquisition (CA), the concept of channel twinning (CT) has been proposed as a powerful enabler of ubiquitous connectivity in next-generation (xG) wireless systems. By fusing multimodal sensor data, CT advocates a high-fidelity and low-overhead CA paradigm, which is promising to provide accurate channel prediction in cross-domain and high-mobility scenarios of ubiquitous xG networks. However, existing literature lacks a universal CT architecture to address the challenges of heterogeneous scenarios, data, and resources in xG networks, which hinders the widespread deployment and applications of CT. This article discusses a new modularized CT architecture to bridge scene recognition, cooperative sensing, and decentralized training, comprising versatile model configuration, multimodal cooperative sensing, and lightweight twin modeling modules. Additionally, this article presents a detailed concept, technical features, and case studies of CT, outlines mainstream trends of realization methods, followed by potential applications of CT-empowered ubiquitous connectivity, and issues requiring future investigations.

Paper number 79:
Title: Dequantization of a signal from two parallel quantized observations
Authors: Vojtƒõch Kovanda, Pavel Rajmic
Abstract: We propose a technique of signal acquisition using a combination of two devices with different sampling rates and quantization accuracies. Subsequent processing involving sparsity regularization enables us to reconstruct the signal at such a sampling frequency and with such a bit depth that was not possible using the two devices independently. Objective and subjective tests show the superiority of the proposed method in comparison with alternatives.

Paper number 80:
Title: Co-learning Single-Step Diffusion Upsampler and Downsampler with Two Discriminators and Distillation
Authors: Sohwi Kim, Tae-Kyun Kim
Abstract: Super-resolution (SR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts, often relying on effective downsampling to generate diverse and realistic training pairs. In this work, we propose a co-learning framework that jointly optimizes a single-step diffusion-based upsampler and a learnable downsampler, enhanced by two discriminators and a cyclic distillation strategy. Our learnable downsampler is designed to better capture realistic degradation patterns while preserving structural details in the LR domain, which is crucial for enhancing SR performance. By leveraging a diffusion-based approach, our model generates diverse LR-HR pairs during training, enabling robust learning across varying degradations. We demonstrate the effectiveness of our method on both general real-world and domain-specific face SR tasks, achieving state-of-the-art performance in both fidelity and perceptual quality. Our approach not only improves efficiency with a single inference step but also ensures high-quality image reconstruction, bridging the gap between synthetic and real-world SR scenarios.

Paper number 81:
Title: AtlasSeg: Atlas Prior Guided Dual-U-Net for Cortical Segmentation in Fetal Brain MRI
Authors: Haoan Xu, Tianshu Zheng, Xinyi Xu, Yao Shen, Jiwei Sun, Cong Sun, Guangbin Wang, Zhaopeng Cui, Dan Wu
Abstract: Accurate automatic tissue segmentation in fetal brain MRI is a crucial step in clinical diagnosis but remains challenging, particularly due to the dynamically changing anatomy and tissue contrast during fetal development. Existing segmentation networks can only implicitly learn age-related features, leading to a decline in accuracy at extreme early or late gestational ages (GAs). To improve segmentation performance throughout gestation, we introduce AtlasSeg, a dual-U-shape convolution network that explicitly integrates GA-specific information as guidance. By providing a publicly available fetal brain atlas with segmentation labels corresponding to relevant GAs, AtlasSeg effectively extracts age-specific patterns in the atlas branch and generates precise tissue segmentation in the segmentation branch. Multi-scale spatial attention feature fusions are constructed during both encoding and decoding stages to enhance feature flow and facilitate better information interactions between two branches. We compared AtlasSeg with six well-established networks in a seven-tissue segmentation task, achieving the highest average Dice similarity coefficient of 0.91. The improvement was particularly evident in extreme early or late GA cases, where training data was scare. Furthermore, AtlasSeg exhibited minimal performance degradation on low-quality images with contrast changes and noise, attributed to its anatomical shape priors. Overall, AtlasSeg demonstrated enhanced segmentation accuracy, better consistency across fetal ages, and robustness to perturbations, making it a powerful tool for reliable fetal brain MRI tissue segmentation, particularly suited for diagnostic assessments during early gestation.

Paper number 82:
Title: Cell as Point: One-Stage Framework for Efficient Cell Tracking
Authors: Yaxuan Song, Jianan Fan, Heng Huang, Mei Chen, Weidong Cai
Abstract: Conventional multi-stage cell tracking approaches rely heavily on detection or segmentation in each frame as a prerequisite, requiring substantial resources for high-quality segmentation masks and increasing the overall prediction time. To address these limitations, we propose CAP, a novel end-to-end one-stage framework that reimagines cell tracking by treating Cell as Point. Unlike traditional methods, CAP eliminates the need for explicit detection or segmentation, instead jointly tracking cells for sequences in one stage by leveraging the inherent correlations among their trajectories. This simplification reduces both labeling requirements and pipeline complexity. However, directly processing the entire sequence in one stage poses challenges related to data imbalance in capturing cell division events and long sequence inference. To solve these challenges, CAP introduces two key innovations: (1) adaptive event-guided (AEG) sampling, which prioritizes cell division events to mitigate the occurrence imbalance of cell events, and (2) the rolling-as-window (RAW) inference strategy, which ensures continuous and stable tracking of newly emerging cells over extended sequences. By removing the dependency on segmentation-based preprocessing while addressing the challenges of imbalanced occurrence of cell events and long-sequence tracking, CAP demonstrates promising cell tracking performance and is 10 to 55 times more efficient than existing methods. The code and model checkpoints will be available soon.

Paper number 83:
Title: MambaIRv2: Attentive State Space Restoration
Authors: Hang Guo, Yong Guo, Yaohua Zha, Yulun Zhang, Wenbo Li, Tao Dai, Shu-Tao Xia, Yawei Li
Abstract: The Mamba-based image restoration backbones have recently demonstrated significant potential in balancing global reception and computational efficiency. However, the inherent causal modeling limitation of Mamba, where each token depends solely on its predecessors in the scanned sequence, restricts the full utilization of pixels across the image and thus presents new challenges in image restoration. In this work, we propose MambaIRv2, which equips Mamba with the non-causal modeling ability similar to ViTs to reach the attentive state space restoration model. Specifically, the proposed attentive state-space equation allows to attend beyond the scanned sequence and facilitate image unfolding with just one single scan. Moreover, we further introduce a semantic-guided neighboring mechanism to encourage interaction between distant but similar pixels. Extensive experiments show our MambaIRv2 outperforms SRFormer by even 0.35dB PSNR for lightweight SR even with 9.3\% less parameters and suppresses HAT on classic SR by up to 0.29dB. Code is available at this https URL.

Paper number 84:
Title: PromptHSI: Universal Hyperspectral Image Restoration with Vision-Language Modulated Frequency Adaptation
Authors: Chia-Ming Lee, Ching-Heng Cheng, Yu-Fan Lin, Yi-Ching Cheng, Wo-Ting Liao, Fu-En Yang, Yu-Chiang Frank Wang, Chih-Chung Hsu
Abstract: Recent advances in All-in-One (AiO) RGB image restoration have demonstrated the effectiveness of prompt learning in handling multiple degradations within a single model. However, extending these approaches to hyperspectral image (HSI) restoration is challenging due to the domain gap between RGB and HSI features, information loss in visual prompts under severe composite degradations, and difficulties in capturing HSI-specific degradation patterns via text prompts. In this paper, we propose PromptHSI, the first universal AiO HSI restoration framework that addresses these challenges. By incorporating frequency-aware feature modulation, which utilizes frequency analysis to narrow down the restoration search space and employing vision-language model (VLM)-guided prompt learning, our approach decomposes text prompts into intensity and bias controllers that effectively guide the restoration process while mitigating domain discrepancies. Extensive experiments demonstrate that our unified architecture excels at both fine-grained recovery and global information restoration across diverse degradation scenarios, highlighting its significant potential for practical remote sensing applications. The source code is available at this https URL.

Paper number 85:
Title: Assessing Electricity Network Capacity Requirements for Industrial Decarbonisation in Great Britain
Authors: Ahmed Gailani, Peter Taylor
Abstract: Decarbonising the industrial sector is vital to reach net zero targets. The deployment of industrial decarbonisation technologies is expected to increase industrial electricity demand in many countries and this may require upgrades to the existing electricity network or new network investment. While the infrastructure requirements to support the introduction of new fuels and technologies in industry, such as hydrogen and carbon capture, utilisation and storage are often discussed, the need for investment to increase the capacity of the electricity network to meet increasing industrial electricity demands is often overlooked in the literature. This paper addresses this gap by quantifying the requirements for additional electricity network capacity to support the decarbonisation of industrial sectors across Great Britain (GB). The Net Zero Industrial Pathways model is used to predict the future electricity demand from industrial sites to 2050 which is then compared spatially to the available headroom across the distribution network in GB. The results show that network headroom is sufficient to meet extra capacity demands from industrial sites over the period to 2030 in nearly all GB regions and network scenarios. However, as electricity demand rises due to increased electrification across all sectors and industrial decarbonisation accelerates towards 2050, the network will need significant new capacity (71 GW + by 2050) particularly in the central, south, and north-west regions of England, and Wales. Without solving these network constraints, around 65% of industrial sites that are large point sources of emissions would be constrained in terms of electric capacity by 2040. These sites are responsible for 69% of industrial point source emissions.

Paper number 86:
Title: Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework
Authors: Edgar Beck, Hsuan-Yu Lin, Patrick R√ºckert, Yongping Bao, Bettina von Helversen, Sebastian Fehrler, Kirsten Tracht, Armin Dekorsy
Abstract: As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided to the HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support HDM both in theory and in simulations. In this sense, our study reveals the fundamental design trade-off between maximizing the relevant semantic information and matching the cognitive capabilities of the HDM model. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.

Paper number 87:
Title: Self Pre-training with Adaptive Mask Autoencoders for Variable-Contrast 3D Medical Imaging
Authors: Badhan Kumar Das, Gengyan Zhao, Han Liu, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier
Abstract: The Masked Autoencoder (MAE) has recently demonstrated effectiveness in pre-training Vision Transformers (ViT) for analyzing natural images. By reconstructing complete images from partially masked inputs, the ViT encoder gathers contextual information to predict the missing regions. This capability to aggregate context is especially important in medical imaging, where anatomical structures are functionally and mechanically linked to surrounding regions. However, current methods do not consider variations in the number of input images, which is typically the case in real-world Magnetic Resonance (MR) studies. To address this limitation, we propose a 3D Adaptive Masked Autoencoders (AMAE) architecture that accommodates a variable number of 3D input contrasts per subject. A magnetic resonance imaging (MRI) dataset of 45,364 subjects was used for pretraining and a subset of 1648 training, 193 validation and 215 test subjects were used for finetuning. The performance demonstrates that self pre-training of this adaptive masked autoencoders can enhance the infarct segmentation performance by 2.8%-3.7% for ViT-based segmentation models.

Paper number 88:
Title: Lipschitz Safe Bayesian Optimization for Automotive Control
Authors: Johanna Menn, Pietro Pelizzari, Michael Fleps-Dezasse, Sebastian Trimpe
Abstract: Controller tuning is a labor-intensive process that requires human intervention and expert knowledge. Bayesian optimization has been applied successfully in different fields to automate this process. However, when tuning on hardware, such as in automotive applications, strict safety requirements often arise. To obtain safety guarantees, many existing safe Bayesian optimization methods rely on assumptions that are hard to verify in practice. This leads to the use of unjustified heuristics in many applications, which invalidates the theoretical safety guarantees. Furthermore, applications often require multiple safety constraints to be satisfied simultaneously. Building on recently proposed Lipschitz-only safe Bayesian optimization, we develop an algorithm that relies on readily interpretable assumptions and satisfies multiple safety constraints at the same time. We apply this algorithm to the problem of automatically tuning a trajectory-tracking controller of a self-driving car. Results both from simulations and an actual test vehicle underline the algorithm's ability to learn tracking controllers without leaving the track or violating any other safety constraints.

Paper number 89:
Title: Benchmarking Self-Supervised Methods for Accelerated MRI Reconstruction
Authors: Andrew Wang, Mike Davies
Abstract: Reconstructing MRI from highly undersampled measurements is crucial for accelerating medical imaging, but is challenging due to the ill-posedness of the inverse problem. While supervised deep learning approaches have shown remarkable success, they rely on fully-sampled ground truth data, which is often impractical or impossible to obtain. Recently, numerous self-supervised methods have emerged that do not require ground truth, however, the lack of systematic comparison and standard experimental setups have hindered research. We present the first comprehensive review of loss functions from all feedforward self-supervised methods and the first benchmark on accelerated MRI reconstruction without ground truth, showing that there is a wide range in performance across methods. In addition, we propose Multi-Operator Equivariant Imaging (MO-EI), a novel framework that builds on the imaging model considered in existing methods to outperform all state-of-the-art and approaches supervised performance. Finally, to facilitate reproducible benchmarking, we provide implementations of all methods in the DeepInverse library (this https URL) and easy-to-use demo code at this https URL.

Paper number 90:
Title: Transfer Learning Assisted Fast Design Migration Over Technology Nodes: A Study on Transformer Matching Network
Authors: Chenhao Chu, Yuhao Mao, Hua Wang
Abstract: In this study, we introduce an innovative methodology for the design of mm-Wave passive networks that leverages knowledge transfer from a pre-trained synthesis neural network (NN) model in one technology node and achieves swift and reliable design adaptation across different integrated circuit (IC) technologies, operating frequencies, and metal options. We prove this concept through simulation-based demonstrations focusing on the training and comparison of the coefficient of determination (R2) of synthesis NNs for 1:1 on-chip transformers in GlobalFoundries(GF) 22nm FDX+ (target domain), with and without transfer learning from a model trained in GF 45nm SOI (source domain). In the experiments, we explore varying target data densities of 0.5%, 1%, 5%, and 100% with a complete dataset of 0.33 million in GF 22FDX+, and for comparative analysis, apply source data densities of 25%, 50%, 75%, and 100% with a complete dataset of 2.5 million in GF 45SOI. With the source data only at 30GHz, the experiments span target data from two metal options in GF 22FDX+ at frequencies of 30 and 39 GHz. The results prove that the transfer learning with the source domain knowledge (GF 45SOI) can both accelerate the training process in the target domain (GF 22FDX+) and improve the R2 values compared to models without knowledge transfer. Furthermore, it is observed that a model trained with just 5% of target data and augmented by transfer learning achieves R2 values superior to a model trained with 20% of the data without transfer, validating the advantage seen from 1% to 5% data density. This demonstrates a notable reduction of 4X in the necessary dataset size highlighting the efficacy of utilizing transfer learning to mm-Wave passive network design. The PyTorch learning and testing code is publicly available at this https URL.

Paper number 91:
Title: Online Learning of Nonlinear Parametric Models under Non-smooth Regularization using EKF and ADMM
Authors: Lapo Frascati, Alberto Bemporad
Abstract: This paper proposes a novel combination of extended Kalman filtering (EKF) with the alternating direction method of multipliers (ADMM) for learning parametric nonlinear models online under non-smooth regularization terms, including l1 and l0 penalties and bound constraints on model parameters. For the case of linear time-varying models and non-smoothconvex regularization terms, we provide a sublinear regret bound that ensures the proper behavior of the online learning strategy. The approach is computationally efficient for a wide range of regularization terms, which makes it appealing for its use in embedded control applications for online model adaptation. We show the performance of the proposed method in three simulation examples, highlighting its effectiveness compared to other batch and online algorithms.

Paper number 92:
Title: Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model
Authors: Siyeop Yoon, Yujin Oh, Matthew Tivnan, Sifan Song, Pengfei Jin, Sekeun Kim, Hyun Jin Cho, Dufan Wu, Raul Uppot, Quanzheng Li
Abstract: This study presents a 3D flow-matching model designed to predict the progression of the frozen region (iceball) during kidney cryoablation. Precise intraoperative guidance is critical in cryoablation to ensure complete tumor eradication while preserving adjacent healthy tissue. However, conventional methods, typically based on physics driven or diffusion based simulations, are computationally demanding and often struggle to represent complex anatomical structures accurately. To address these limitations, our approach leverages intraoperative CT imaging to inform the model. The proposed 3D flow matching model is trained to learn a continuous deformation field that maps early-stage CT scans to future predictions. This transformation not only estimates the volumetric expansion of the iceball but also generates corresponding segmentation masks, effectively capturing spatial and morphological changes over time. Quantitative analysis highlights the model robustness, demonstrating strong agreement between predictions and ground-truth segmentations. The model achieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient of 0.75. By integrating real time CT imaging with advanced deep learning techniques, this approach has the potential to enhance intraoperative guidance in kidney cryoablation, improving procedural outcomes and advancing the field of minimally invasive surgery.

Paper number 93:
Title: Lessons learned from field demonstrations of model predictive control and reinforcement learning for residential and commercial HVAC: A review
Authors: Arash J. Khabbazi, Elias N. Pergantis, Levi D. Reyes Premer, Panagiotis Papageorgiou, Alex H. Lee, James E. Braun, Gregor P. Henze, Kevin J. Kircher
Abstract: A large body of simulation research suggests that model predictive control (MPC) and reinforcement learning (RL) for heating, ventilation, and air-conditioning (HVAC) in residential and commercial buildings could reduce energy costs, pollutant emissions, and strain on power grids. Despite this potential, neither MPC nor RL has seen widespread industry adoption. Field demonstrations could accelerate MPC and RL adoption by providing real-world data that support the business case for deployment. This paper reviews 24 field demonstrations of MPC and RL in residential buildings and 80 in commercial buildings. After presenting demographic information -- such as experiment scopes, locations, and durations -- this paper analyzes experiment protocols and their influence on performance estimates. We find that 71% of the reviewed field demonstrations use experiment protocols that may lead to unreliable performance estimates. Over the remaining 29% that we view as reliable, the weighted-average cost savings, weighted by experiment duration, are 16% in residential buildings and 13% in commercial buildings. While these savings are potentially attractive, making the business case for MPC and RL also requires characterizing the costs of deployment, operation, and maintenance. Only 13 of the 104 reviewed papers report these costs or discuss related challenges. Based on these observations, we recommend directions for future field research, including: Improving experiment protocols; reporting deployment, operation, and maintenance costs; designing algorithms and instrumentation to reduce these costs; controlling HVAC equipment alongside other distributed energy resources; and pursuing emerging objectives such as peak shaving, arbitraging wholesale energy prices, and providing power grid reliability services.

Paper number 94:
Title: Physics-Informed Generative Approaches for Wireless Channel Modeling
Authors: Satyavrat Wagle, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, David J. Love, Christopher G. Brinton
Abstract: In recent years, machine learning (ML) methods have become increasingly popular in wireless communication systems for several applications. A critical bottleneck for designing ML systems for wireless communications is the availability of realistic wireless channel datasets, which are extremely resource intensive to produce. To this end, the generation of realistic wireless channels plays a key role in the subsequent design of effective ML algorithms for wireless communication systems. Generative models have been proposed to synthesize channel matrices, but outputs produced by such methods may not correspond to geometrically viable channels and do not provide any insight into the scenario of interest. In this work, we aim to address both these issues by integrating a parametric, physics-based geometric channel (PBGC) modeling framework with generative methods. To address limitations with gradient flow through the PBGC model, a linearized reformulation is presented, which ensures smooth gradient flow during generative model training, while also capturing insights about the underlying physical environment. We evaluate our model against prior baselines by comparing the generated samples in terms of the 2-Wasserstein distance and through the utility of generated data when used for downstream compression tasks.

Paper number 95:
Title: Stochastic Tube-based Model Predictive Control for Cyber-Physical Systems under False Data Injection Attacks with Bounded Probability
Authors: Yuzhou Xiao, Senchun Chai, Li Dai, Yuanqing Xia, Runqi Chai
Abstract: This paper addresses the challenge of amplitude-unbounded false data injection (FDI) attacks targeting the sensor-to-controller (S-C) channel in cyber-physical systems (CPSs). We introduce a resilient tube-based model predictive control (MPC) scheme. This scheme incorporates a threshold-based attack detector and a control sequence buffer to enhance system security. We mathematically model the common FDI attacks and derive the maximum duration of such attacks based on the hypothesis testing principle. Following this, the minimum feasible sequence length of the control sequence buffer is obtained. The system is proven to remain input-to-state stable (ISS) under bounded external disturbances and amplitude-unbounded FDI attacks. Moreover, the feasible region under this scenario is provided in this paper. Finally, the proposed algorithm is validated by numerical simulations and shows superior control performance compared to the existing methods.

Paper number 96:
Title: Categorical semantics of compositional reinforcement learning
Authors: Georgios Bakirtzis, Michail Savvas, Ufuk Topcu
Abstract: Compositional knowledge representations in reinforcement learning (RL) facilitate modular, interpretable, and safe task specifications. However, generating compositional models requires the characterization of minimal assumptions for the robustness of the compositionality feature, especially in the case of functional decompositions. Using a categorical point of view, we develop a knowledge representation framework for a compositional theory of RL. Our approach relies on the theoretical study of the category $\mathsf{MDP}$, whose objects are Markov decision processes (MDPs) acting as models of tasks. The categorical semantics models the compositionality of tasks through the application of pushout operations akin to combining puzzle pieces. As a practical application of these pushout operations, we introduce zig-zag diagrams that rely on the compositional guarantees engendered by the category $\mathsf{MDP}$. We further prove that properties of the category $\mathsf{MDP}$ unify concepts, such as enforcing safety requirements and exploiting symmetries, generalizing previous abstraction theories for RL.

Paper number 97:
Title: Learning Hypergraphs From Signals With Dual Smoothness Prior
Authors: Bohan Tang, Siheng Chen, Xiaowen Dong
Abstract: Hypergraph structure learning, which aims to learn the hypergraph structures from the observed signals to capture the intrinsic high-order relationships among the entities, becomes crucial when a hypergraph topology is not readily available in the datasets. There are two challenges that lie at the heart of this problem: 1) how to handle the huge search space of potential hyperedges, and 2) how to define meaningful criteria to measure the relationship between the signals observed on nodes and the hypergraph structure. In this paper, for the first challenge, we adopt the assumption that the ideal hypergraph structure can be derived from a learnable graph structure that captures the pairwise relations within signals. Further, we propose a hypergraph structure learning framework HGSL with a novel dual smoothness prior that reveals a mapping between the observed node signals and the hypergraph structure, whereby each hyperedge corresponds to a subgraph with both node signal smoothness and edge signal smoothness in the learnable graph structure. Finally, we conduct extensive experiments to evaluate HGSL on both synthetic and real world datasets. Experiments show that HGSL can efficiently infer meaningful hypergraph topologies from observed signals.

Paper number 98:
Title: Hypergraph Structure Inference From Data Under Smoothness Prior
Authors: Bohan Tang, Siheng Chen, Xiaowen Dong
Abstract: Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing them. We use this prior to derive the relation between the hypergraph structure and the node features via probabilistic modelling. This allows us to develop an unsupervised inference method to estimate the probability for each potential hyperedge via solving an optimisation problem that has an analytical solution. Experiments on both synthetic and real-world data demonstrate that our method can learn meaningful hypergraph structures from data more efficiently than existing hypergraph structure inference methods.

Paper number 99:
Title: Hypergraph-MLP: Learning on Hypergraphs without Message Passing
Authors: Bohan Tang, Siheng Chen, Xiaowen Dong
Abstract: Hypergraphs are vital in modelling data with higher-order relations containing more than two entities, gaining prominence in machine learning and signal processing. Many hypergraph neural networks leverage message passing over hypergraph structures to enhance node representation learning, yielding impressive performances in tasks like hypergraph node classification. However, these message-passing-based models face several challenges, including oversmoothing as well as high latency and sensitivity to structural perturbations at inference time. To tackle those challenges, we propose an alternative approach where we integrate the information about hypergraph structures into training supervision without explicit message passing, thus also removing the reliance on it at inference. Specifically, we introduce Hypergraph-MLP, a novel learning framework for hypergraph-structured data, where the learning model is a straightforward multilayer perceptron (MLP) supervised by a loss function based on a notion of signal smoothness on hypergraphs. Experiments on hypergraph node classification tasks demonstrate that Hypergraph-MLP achieves competitive performance compared to existing baselines, and is considerably faster and more robust against structural perturbations at inference.

Paper number 100:
Title: SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems
Authors: Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen
Abstract: Surrogate models are used to predict the behavior of complex energy systems that are too expensive to simulate with traditional numerical methods. Our work introduces the use of language descriptions, which we call ``system captions'' or SysCaps, to interface with such surrogates. We argue that interacting with surrogates through text, particularly natural language, makes these models more accessible for both experts and non-experts. We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata. Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities, such as handling semantically related descriptions of the same test system. Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.

Paper number 101:
Title: HDRT: A Large-Scale Dataset for Infrared-Guided HDR Imaging
Authors: Jingchao Peng, Thomas Bashford-Rogers, Francesco Banterle, Haitao Zhao, Kurt Debattista
Abstract: Capturing images with enough details to solve imaging tasks is a long-standing challenge in imaging, particularly due to the limitations of standard dynamic range (SDR) images which often lose details in underexposed or overexposed regions. Traditional high dynamic range (HDR) methods, like multi-exposure fusion or inverse tone mapping, struggle with ghosting and incomplete data reconstruction. Infrared (IR) imaging offers a unique advantage by being less affected by lighting conditions, providing consistent detail capture regardless of visible light intensity. In this paper, we introduce the HDRT dataset, the first comprehensive dataset that consists of HDR and thermal IR images. The HDRT dataset comprises 50,000 images captured across three seasons over six months in eight cities, providing a diverse range of lighting conditions and environmental contexts. Leveraging this dataset, we propose HDRTNet, a novel deep neural method that fuses IR and SDR content to generate HDR images. Extensive experiments validate HDRTNet against the state-of-the-art, showing substantial quantitative and qualitative quality improvements. The HDRT dataset not only advances IR-guided HDR imaging but also offers significant potential for broader research in HDR imaging, multi-modal fusion, domain transfer, and beyond. The dataset is available at this https URL.

Paper number 102:
Title: Video-to-Audio Generation with Hidden Alignment
Authors: Manjie Xu, Chenxing Li, Xinyi Tu, Yong Ren, Rilin Chen, Yu Gu, Wei Liang, Dong Yu
Abstract: Generating semantically and temporally aligned audio content in accordance with video input has become a focal point for researchers, particularly following the remarkable breakthrough in text-to-video generation. In this work, we aim to offer insights into the video-to-audio generation paradigm, focusing on three crucial aspects: vision encoders, auxiliary embeddings, and data augmentation techniques. Beginning with a foundational model built on a simple yet surprisingly effective intuition, we explore various vision encoders and auxiliary embeddings through ablation studies. Employing a comprehensive evaluation pipeline that emphasizes generation quality and video-audio synchronization alignment, we demonstrate that our model exhibits state-of-the-art video-to-audio generation capabilities. Furthermore, we provide critical insights into the impact of different data augmentation methods on enhancing the generation framework's overall capacity. We showcase possibilities to advance the challenge of generating synchronized audio from semantic and temporal perspectives. We hope these insights will serve as a stepping stone toward developing more realistic and accurate audio-visual generation models.

Paper number 103:
Title: Multilinear Extensions in Submodular Optimization for Optimal Sensor Scheduling in Nonlinear Networks
Authors: Mohamad H. Kazma, Ahmad F. Taha
Abstract: Optimal sensing nodes selection (SNS) in dynamic systems is a combinatorial optimization problem that has been thoroughly studied in the recent literature. This problem can be formulated within the context of set optimization. For high-dimensional nonlinear systems, the problem is extremely difficult to solve. It scales poorly too. Current literature poses combinatorial submodular set optimization problems via maximizing observability performance metrics subject to matroid constraints. Such an approach is typically solved using greedy algorithms that require lower computational effort yet often yield sub-optimal solutions. In this paper, we address the SNS problem for nonlinear dynamical networks using a variational form of the system dynamics, that basically perturb the system physics. As a result, we show that the observability performance metrics under such system representation are indeed submodular. The optimal problem is then solved using the multilinear continuous extension. This extension offers a computationally scalable and approximate continuous relaxation with a performance guarantee. The effectiveness of the extended submodular program is studied and compared to greedy algorithms. We demonstrate the proposed set optimization formulation for SNS on nonlinear natural gas combustion networks.

Paper number 104:
Title: Surgical SAM 2: Real-time Segment Anything in Surgical Video by Efficient Frame Pruning
Authors: Haofeng Liu, Erli Zhang, Junde Wu, Mingxuan Hong, Yueming Jin
Abstract: Surgical video segmentation is a critical task in computer-assisted surgery and is vital for enhancing surgical quality and patient outcomes. Recently, the Segment Anything Model 2 (SAM2) framework has shown superior advancements in image and video segmentation. However, SAM2 struggles with efficiency due to the high computational demands of processing high-resolution images and complex and long-range temporal dynamics in surgical videos. To address these challenges, we introduce Surgical SAM 2 (SurgSAM2), an advanced model to utilize SAM2 with an Efficient Frame Pruning (EFP) mechanism, to facilitate real-time surgical video segmentation. The EFP mechanism dynamically manages the memory bank by selectively retaining only the most informative frames, reducing memory usage and computational cost while maintaining high segmentation accuracy. Our extensive experiments demonstrate that SurgSAM2 significantly improves both efficiency and segmentation accuracy compared to the vanilla SAM2. Remarkably, SurgSAM2 achieves a 3$\times$ FPS compared with SAM2, while also delivering state-of-the-art performance after fine-tuning with lower-resolution data. These advancements establish SurgSAM2 as a leading model for surgical video analysis, making real-time surgical video segmentation in resource-constrained environments a reality. Our source code is available at this https URL.

Paper number 105:
Title: MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization
Authors: Bogdan Vlahov, Jason Gibson, Manan Gandhi, Evangelos A. Theodorou
Abstract: This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: this https URL .

Paper number 106:
Title: ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone Navigation via Scene-Aware Control Barrier Functions
Authors: Sourav Sanyal, Kaushik Roy
Abstract: In the rapidly evolving field of vision-language navigation (VLN), ensuring safety for physical agents remains an open challenge. For a human-in-the-loop language-operated drone to navigate safely, it must understand natural language commands, perceive the environment, and simultaneously avoid hazards in real time. Control Barrier Functions (CBFs) are formal methods that enforce safe operating conditions. Model Predictive Control (MPC) is an optimization framework that plans a sequence of future actions over a prediction horizon, ensuring smooth trajectory tracking while obeying constraints. In this work, we consider a VLN-operated drone platform and enhance its safety by formulating a novel scene-aware CBF that leverages ego-centric observations from a camera which has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less baseline system uses a Vision-Language Encoder with cross-modal attention to convert commands into an ordered sequence of landmarks. An object detection model identifies and verifies these landmarks in the captured images to generate a planned path. To further enhance safety, an Adaptive Safety Margin Algorithm (ASMA) is proposed. ASMA tracks moving objects and performs scene-aware CBF evaluation on-the-fly, which serves as an additional constraint within the MPC framework. By continuously identifying potentially risky observations, the system performs prediction in real time about unsafe conditions and proactively adjusts its control actions to maintain safe navigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in the Gazebo environment using the Robot Operating System (ROS), ASMA achieves 64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in trajectory lengths compared to the baseline CBF-less VLN.

Paper number 107:
Title: A Parallel-in-Time Newton's Method for Nonlinear Model Predictive Control
Authors: Casian Iacob, Hany Abdulsamad, Simo S√§rkk√§
Abstract: Model predictive control (MPC) is a powerful framework for optimal control of dynamical systems. However, MPC solvers suffer from a high computational burden that restricts their application to systems with low sampling frequency. This issue is further amplified in nonlinear and constrained systems that require nesting MPC solvers within iterative procedures. In this paper, we address these issues by developing parallel-in-time algorithms for constrained nonlinear optimization problems that take advantage of massively parallel hardware to achieve logarithmic computational time scaling over the planning horizon. We develop time-parallel second-order solvers based on interior point methods and the alternating direction method of multipliers, leveraging fast convergence and lower computational cost per iteration. The parallelization is based on a reformulation of the subproblems in terms of associative operations that can be parallelized using the associative scan algorithm. We validate our approach on numerical examples of nonlinear and constrained dynamical systems.

Paper number 108:
Title: Online Control-Informed Learning
Authors: Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou
Abstract: This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.

Paper number 109:
Title: Sensor-fusion based Prognostics Framework for Complex Engineering Systems Exhibiting Multiple Failure Modes
Authors: Benjamin Peters, Ayush Mohanty, Xiaolei Fang, Stephen K. Robinson, Nagi Gebraeel
Abstract: Complex engineering systems are often subject to multiple failure modes. Developing a remaining useful life (RUL) prediction model that does not consider the failure mode causing degradation is likely to result in inaccurate predictions. However, distinguishing between causes of failure without manually inspecting the system is nontrivial. This challenge is increased when the causes of historically observed failures are unknown. Sensors, which are useful for monitoring the state-of-health of systems, can also be used for distinguishing between multiple failure modes as the presence of multiple failure modes results in discriminatory behavior of the sensor signals. When systems are equipped with multiple sensors, some sensors may exhibit behavior correlated with degradation, while other sensors do not. Furthermore, which sensors exhibit this behavior may differ for each failure mode. In this paper, we present a simultaneous clustering and sensor selection approach for unlabeled training datasets of systems exhibiting multiple failure modes. The cluster assignments and the selected sensors are then utilized in real-time to first diagnose the active failure mode and then to predict the system RUL. We validate the methodology using a simulated dataset of systems exhibiting two failure modes and on NASA turbofan degradation dataset.

Paper number 110:
Title: AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal Audio-Video Generation
Authors: Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Ivan Skorokhodov, Alper Canberk, Kwot Sin Lee, Vicente Ordonez, Sergey Tulyakov
Abstract: We propose AV-Link, a unified framework for Video-to-Audio (A2V) and Audio-to-Video (A2V) generation that leverages the activations of frozen video and audio diffusion models for temporally-aligned cross-modal conditioning. The key to our framework is a Fusion Block that facilitates bidirectional information exchange between video and audio diffusion models through temporally-aligned self attention operations. Unlike prior work that uses dedicated models for A2V and V2A tasks and relies on pretrained feature extractors, AV-Link achieves both tasks in a single self-contained framework, directly leveraging features obtained by the complementary modality (i.e. video features to generate audio, or audio features to generate video). Extensive automatic and subjective evaluations demonstrate that our method achieves a substantial improvement in audio-video synchronization, outperforming more expensive baselines such as the MovieGen video-to-audio model.

Paper number 111:
Title: TinySense: A Lighter Weight and More Power-efficient Avionics System for Flying Insect-scale Robots
Authors: Zhitao Yu, Joshua Tran, Claire Li, Aaron Weber, Yash P.Talwekar, Sawyer Fuller
Abstract: In this paper, we introduce advances in the sensor suite of an autonomous flying insect robot (FIR) weighing less than a gram. FIRs, because of their small weight and size, offer unparalleled advantages in terms of material cost and scalability. However, their size introduces considerable control challenges, notably high-speed dynamics, restricted power, and limited payload capacity. While there have been advancements in developing lightweight sensors, often drawing inspiration from biological systems, no sub-gram aircraft has been able to attain sustained hover without relying on feedback from external sensing such as a motion capture system. The lightest vehicle capable of sustained hovering -- the first level of ``sensor autonomy'' -- is the much larger 28 g Crazyflie. Previous work reported a reduction in size of that vehicle's avionics suite to 187 mg and 21 mW. Here, we report a further reduction in mass and power to only 78.4 mg and 15 mW. We replaced the laser rangefinder with a lighter and more efficient pressure sensor, and built a smaller optic flow sensor around a global-shutter imaging chip. A Kalman Filter (KF) fuses these measurements to estimate the state variables that are needed to control hover: pitch angle, translational velocity, and altitude. Our system achieved performance comparable to that of the Crazyflie's estimator while in flight, with root mean squared errors of 1.573 deg, 0.186 m/s, and 0.136 m, respectively, relative to motion capture.

Paper number 112:
Title: Intra-day Solar and Power Forecast for Optimization of Intraday Market Participation
Authors: Nelson Salazar-Pena, Adolfo Palma-Vergara, Mateo Montes-Vera, Maria Alejandra Vargas-Torres, Rodrigo Hernandez-Vanegas, Maria Amador, Boris Rojas, Adriana Salinas, Andres Velasco, Alejandra Tabares, Andres Gonzalez-Mancera
Abstract: The prediction of solar irradiance enhances reliability in photovoltaic (PV) solar plant generation and grid integration. In Colombia, PV plants face penalties if energy production deviates beyond governmental thresholds from intraday market offers. This research employs Long Short-Term Memory (LSTM) and Bidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV plant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour horizon and 10-minute resolution. While Bi-LSTM showed superior performance, the LSTM model achieved comparable results with significantly reduced training time (6 hours versus 18 hours), making it computationally advantageous. The LSTM predictions were averaged to create an hourly resolution model, evaluated using Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square Error, and Mean Absolute Percentage Error metrics. Comparison with the Global Forecast System (GFS) revealed similar performance, with both models effectively capturing daily solar irradiance patterns. The forecast model integrates with an Object-Oriented power production model, enabling accurate energy offers in the intraday market while minimizing penalty costs.

Paper number 113:
Title: Fast Inexact Bilevel Optimization for Analytical Deep Image Priors
Authors: Mohammad Sadegh Salehi, Tatiana A. Bubba, Yury Korolev
Abstract: The analytical deep image prior (ADP) introduced by Dittmer et al. (2020) establishes a link between deep image priors and classical regularization theory via bilevel optimization. While this is an elegant construction, it involves expensive computations if the lower-level problem is to be solved accurately. To overcome this issue, we propose to use adaptive inexact bilevel optimization to solve ADP problems. We discuss an extension of a recent inexact bilevel method called the method of adaptive inexact descent of Salehi et al.(2024) to an infinite-dimensional setting required by the ADP framework. In our numerical experiments we demonstrate that the computational speed-up achieved by adaptive inexact bilevel optimization allows one to use ADP on larger-scale problems than in the previous literature, e.g. in deblurring of 2D color images.

Paper number 114:
Title: Flexible Intelligent Metasurfaces for Enhancing MIMO Communications
Authors: Jiancheng An, Zhu Han, Dusit Niyato, M√©rouane Debbah, Chau Yuen, Lajos Hanzo
Abstract: Flexible intelligent metasurfaces (FIMs) show great potential for improving the wireless network capacity in an energy-efficient manner. An FIM is a soft array consisting of several low-cost radiating elements. Each element can independently emit electromagnetic signals, while flexibly adjusting its position even perpendicularly to the overall surface to `morph' its 3D shape. More explicitly, compared to a conventional rigid antenna array, an FIM is capable of finding an optimal 3D surface shape that provides improved signal quality. In this paper, we study point-to-point multiple-input multiple-output (MIMO) communications between a pair of FIMs. In order to characterize the capacity limits of FIM-aided MIMO transmissions over frequency-flat fading channels, we formulate a transmit optimization problem for maximizing the MIMO channel capacity by jointly optimizing the 3D surface shapes of the transmitting and receiving FIMs as well as the MIMO transmit covariance matrix, subject to the total transmit power constraint and to the maximum perpendicular morphing range of the FIM. To solve this problem, we develop an efficient block coordinate descent (BCD) algorithm. The BCD algorithm iteratively updates the 3D surface shapes of the FIMs and the transmit covariance matrix, while keeping the other fixed, to find a locally optimal solution. Numerical results verify that FIMs can achieve higher MIMO capacity than that of the conventional rigid arrays. In particular, the MIMO channel capacity can be doubled by the proposed BCD algorithm under some setups.

Paper number 115:
Title: CBW: Towards Dataset Ownership Verification for Speaker Verification via Clustering-based Backdoor Watermarking
Authors: Yiming Li, Kaiying Yan, Shuo Shao, Tongqing Zhai, Shu-Tao Xia, Zhan Qin, Dacheng Tao
Abstract: With the increasing adoption of deep learning in speaker verification, large-scale speech datasets have become valuable intellectual property. To audit and prevent the unauthorized usage of these valuable released datasets, especially in commercial or open-source scenarios, we propose a novel dataset ownership verification method. Our approach introduces a clustering-based backdoor watermark (CBW), enabling dataset owners to determine whether a suspicious third-party model has been trained on a protected dataset under a black-box setting. The CBW method consists of two key stages: dataset watermarking and ownership verification. During watermarking, we implant multiple trigger patterns in the dataset to make similar samples (measured by their feature similarities) close to the same trigger while dissimilar samples are near different triggers. This ensures that any model trained on the watermarked dataset exhibits specific misclassification behaviors when exposed to trigger-embedded inputs. To verify dataset ownership, we design a hypothesis-test-based framework that statistically evaluates whether a suspicious model exhibits the expected backdoor behavior. We conduct extensive experiments on benchmark datasets, verifying the effectiveness and robustness of our method against potential adaptive attacks. The code for reproducing main experiments is available at this https URL

Paper number 116:
Title: End-to-End Action Segmentation Transformer
Authors: Tieqiao Wang, Sinisa Todorovic
Abstract: Existing approaches to action segmentation use pre-computed frame features extracted by methods which have been trained on tasks that are different from action segmentation. Also, recent approaches typically use deep framewise representations that lack explicit modeling of action segments. To address these shortcomings, we introduce the first end-to-end solution to action segmentation -- End-to-End Action Segmentation Transformer (EAST). Our key contributions include: (1) a simple and efficient adapter design for effective backbone fine-tuning; (2) a segmentation-by-detection framework for leveraging action proposals initially predicted over a coarsely downsampled video toward labeling of all frames; and (3) a new action-proposal based data augmentation for robust training. EAST achieves state-of-the-art performance on standard benchmarks, including GTEA, 50Salads, Breakfast, and Assembly-101. The model and corresponding code will be released.
    