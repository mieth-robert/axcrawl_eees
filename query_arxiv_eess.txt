
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: A Wearable Strain-Sensor-Based Shoulder Patch for Fatigue Detection in Bicep Curls
Authors: Ming Xuan Chua, Shuhua Peng, Thanh Nho Do, Chun Hui Wang, Liao Wu
Abstract: A common challenge in home-based rehabilitation is muscle compensation induced by pain or fatigue, where patients with weakened primary muscles recruit secondary muscle groups to assist their movement, causing issues such as delayed rehabilitation progress or risk of further injury. In a home-based setting, the subtle compensatory actions may not be perceived since physiotherapists cannot directly observe patients. To address this problem, this study develops a novel wearable strain-sensor-based shoulder patch to detect fatigue-induced muscle compensation during bicep curl exercises. Built on an observation that the amplitude of a strain sensor's resistance is correlated to the motion of a joint that the sensor is attached to, we develop an algorithm that can robustly detect the state when significant changes appear in the shoulder joint motion, which indicates fatigue-induced muscle compensation in bicep curls. The developed shoulder patch is tested on 13 subjects who perform bicep curl exercises with a 5 kg dumbell until reaching fatigue. During the experiment, the performance of the shoulder patch is also benchmarked with optical tracking sensors and surface electromyography (sEMG) sensors. Results reveal that the proposed wearable sensor and detection methods effectively monitor fatigue-induced muscle compensation during bicep curl exercises in both Real-Time and Post Hoc modes. This development marks a significant step toward enhancing the effectiveness of home-based rehabilitation by providing physiotherapists with a tool to monitor and adjust treatment plans remotely.

Paper number 2:
Title: A causal learning approach to in-orbit inertial parameter estimation for multi-payload deployers
Authors: Konstantinos Platanitis, Miguel Arana-Catania, Saurabh Upadhyay, Leonard Felicetti
Abstract: This paper discusses an approach to inertial parameter estimation for the case of cargo carrying spacecraft that is based on causal learning, i.e. learning from the responses of the spacecraft, under actuation. Different spacecraft configurations (inertial parameter sets) are simulated under different actuation profiles, in order to produce an optimised time-series clustering classifier that can be used to distinguish between them. The actuation is comprised of finite sequences of constant inputs that are applied in order, based on typical actuators available. By learning from the system's responses across multiple input sequences, and then applying measures of time-series similarity and F1-score, an optimal actuation sequence can be chosen either for one specific system configuration or for the overall set of possible configurations. This allows for both estimation of the inertial parameter set without any prior knowledge of state, as well as validation of transitions between different configurations after a deployment event. The optimisation of the actuation sequence is handled by a reinforcement learning model that uses the proximal policy optimisation (PPO) algorithm, by repeatedly trying different sequences and evaluating the impact on classifier performance according to a multi-objective metric.

Paper number 3:
Title: Temporal Brightness Management for Immersive Content
Authors: Luca Surace, Jorge Condor, Piotr Didyk
Abstract: Modern virtual reality headsets demand significant computational resources to render high-resolution content in real-time. Therefore, prioritizing power efficiency becomes crucial, particularly for portable versions reliant on batteries. A significant portion of the energy consumed by these systems is attributed to their displays. Dimming the screen can save a considerable amount of energy; however, it may also result in a loss of visible details and contrast in the displayed content. While contrast may be partially restored by applying post-processing contrast enhancement steps, our work is orthogonal to these approaches, and focuses on optimal temporal modulation of screen brightness. We propose a technique that modulates brightness over time while minimizing the potential loss of visible details and avoiding noticeable temporal instability. Given a predetermined power budget and a video sequence, we achieve this by measuring contrast loss through band decomposition of the luminance image and optimizing the brightness level of each frame offline to ensure uniform temporal contrast loss. We evaluate our method through a series of subjective experiments and an ablation study, on a variety of content. We showcase its power-saving capabilities in practice using a built-in hardware proxy. Finally, we present an online version of our approach which further emphasizes the potential for low level vision models to be leveraged in power saving settings to preserve content quality.

Paper number 4:
Title: What is a Relevant Signal-to-Noise Ratio for Numerical Differentiation?
Authors: Shashank Verma, Mohammad Almuhaihi, Dennis S. Bernstein
Abstract: In applications that involve sensor data, a useful measure of signal-to-noise ratio (SNR) is the ratio of the root-mean-squared (RMS) signal to the RMS sensor noise. The present paper shows that, for numerical differentiation, the traditional SNR is ineffective. In particular, it is shown that, for a harmonic signal with harmonic sensor noise, a natural and relevant SNR is given by the ratio of the RMS of the derivative of the signal to the RMS of the derivative of the sensor noise. For a harmonic signal with white sensor noise, an effective SNR is derived. Implications of these observations for signal processing are discussed.

Paper number 5:
Title: AI-driven Wireless Positioning: Fundamentals, Standards, State-of-the-art, and Challenges
Authors: Guangjin Pan, Yuan Gao, Yilin Gao, Zhiyong Zhong, Xiaoyu Yang, Xinyu Guo, Shugong Xu
Abstract: Wireless positioning technologies hold significant value for applications in autonomous driving, extended reality (XR), unmanned aerial vehicles (UAVs), and more. With the advancement of artificial intelligence (AI), leveraging AI to enhance positioning accuracy and robustness has emerged as a field full of potential. Driven by the requirements and functionalities defined in the 3rd Generation Partnership Project (3GPP) standards, AI/machine learning (ML)-based positioning is becoming a key technology to overcome the limitations of traditional methods. This paper begins with an introduction to the fundamentals of AI and wireless positioning, covering AI models, algorithms, positioning applications, emerging wireless technologies, and the basics of positioning techniques. Subsequently, focusing on standardization progress, we provide a comprehensive review of the evolution of 3GPP positioning standards, with an emphasis on the integration of AI/ML technologies in recent and upcoming releases. Based on the AI/ML-assisted positioning and direct AI/ML positioning schemes outlined in the standards, we conduct an in-depth investigation of related research. we focus on state-of-the-art (SOTA) research in AI-based line-of-sight (LOS)/non-line-of-sight (NLOS) detection, time of arrival (TOA)/time difference of arrival (TDOA) estimation, and angle estimation techniques. For Direct AI/ML Positioning, we explore SOTA advancements in fingerprint-based positioning, knowledge-assisted AI positioning, and channel charting-based positioning. Furthermore, we introduce publicly available datasets for wireless positioning and conclude by summarizing the challenges and opportunities of AI-driven wireless positioning.

Paper number 6:
Title: Automatic Link Selection in Multi-Channel Multiple Access with Link Failures
Authors: Mevan Wijewardena, Michael J. Neely
Abstract: This paper focuses on the problem of automatic link selection in multi-channel multiple access control using bandit feedback. In particular, a controller assigns multiple users to multiple channels in a time slotted system, where in each time slot at most one user can be assigned to a given channel and at most one channel can be assigned to a given user. Given that user $i$ is assigned to channel $j$, the transmission fails with a fixed probability $f_{i,j}$. The failure probabilities are not known to the controller. The assignments are made dynamically using success/failure feedback. The goal is to maximize the time average utility, where we consider an arbitrary (possibly nonsmooth) concave and entrywise nondecreasing utility function. The problem of merely maximizing the total throughput has a solution of always assigning the same user-channel pairs and can be unfair to certain users, particularly when the number of channels is less than the number of users. Instead, our scheme allows various types of fairness, such as proportional fairness, maximizing the minimum, or combinations of these by defining the appropriate utility function. We propose two algorithms for this task. The first algorithm is adaptive and gets within $\mathcal{O}(\log(T)/T^{1/3})$ of optimality over any interval of $T$ consecutive slots over which the success probabilities do not change. The second algorithm has faster $\mathcal{O}(\sqrt{\log(T)/T})$ performance over the first $T$ slots, but does not adapt well if probabilities change.

Paper number 7:
Title: Graph Neural Network Based Beamforming and RIS Reflection Design in A Multi-RIS Assisted Wireless Network
Authors: Byungju Lim, Mai Vu
Abstract: We propose a graph neural network (GNN) architecture to optimize base station (BS) beamforming and reconfigurable intelligent surface (RIS) phase shifts in a multi-RIS assisted wireless network. We create a bipartite graph model to represent a network with multi-RIS, then construct the GNN architecture by exploiting channel information as node and edge features. We employ a message passing mechanism to enable information exchange between RIS nodes and user nodes and facilitate the inference of interference. Each node also maintains a representation vector which can be mapped to the BS beamforming or RIS phase shifts output. Message generation and update of the representation vector at each node are performed using two unsupervised neural networks, which are trained off-line and then used on all nodes of the same type. Simulation results demonstrate that the proposed GNN architecture provides strong scalability with network size, generalizes to different settings, and significantly outperforms conventional algorithms.

Paper number 8:
Title: Fast Inventory for 3GPP Ambient IoT Considering Device Unavailability due to Energy Harvesting
Authors: Zhikun Wu, Kazuk Takeda, Piyush Gupta, Ruiming Zheng, Luanxia Yang, Chengjin Zhang, Zhifei Fan, Hao Xu, Kiran Mukkavilli, Tingfang Ji
Abstract: With the growing demand for massive internet of things (IoT), new IoT technology, namely ambient IoT (A-IoT), has been studied in the 3rd Generation Partnership Project (3GPP). A-IoT devices are batteryless and consume ultra-low power, relying on energy harvesting and energy storage to capture a small amount of energy for communication. A promising usecase of A-IoT is inventory, where a reader communicates with hundreds of A-IoT devices to identify them. However, energy harvesting required before communication can significantly delay or even fail inventory completion. In this work, solutions including duty cycled monitoring (DCM), device grouping and low-power receiving chain are proposed. Evaluation results show that the time required for a reader to complete an inventory procedure for hundreds of A-IoT devices can be reduced by 50% to 83% with the proposed methods.

Paper number 9:
Title: Signal Whisperers: Enhancing Wireless Reception Using DRL-Guided Reflector Arrays
Authors: Hieu Le, Oguz Bedir, Mostafa Ibrahim, Jian Tao, Sabit Ekin
Abstract: This paper presents a novel approach for enhancing wireless signal reception through self-adjustable metallic surfaces, termed reflectors, which are guided by deep reinforcement learning (DRL). The designed reflector system aims to improve signal quality for multiple users in scenarios where a direct line-of-sight (LOS) from the access point (AP) and reflector to users is not guaranteed. Utilizing DRL techniques, the reflector autonomously modifies its configuration to optimize beam allocation from the AP to user equipment (UE), thereby maximizing path gain. Simulation results indicate substantial improvements in the average path gain for all UEs compared to baseline configurations, highlighting the potential of DRL-driven reflectors in creating adaptive communication environments.

Paper number 10:
Title: Exploring the Limitations of Structured Orthogonal Dictionary Learning
Authors: Anirudh Dash, Aditya Siripuram
Abstract: This work is motivated by recent applications of structured dictionary learning, in particular when the dictionary is assumed to be the product of a few Householder atoms. We investigate the following two problems: 1) How do we approximate an orthogonal matrix $\mathbf{V}$ with a product of a specified number of Householder matrices, and 2) How many samples are required to learn a structured (Householder) dictionary from data? For 1) we discuss an algorithm that decomposes $\mathbf{V}$ as a product of a specified number of Householder matrices. We see that the algorithm outputs the decomposition when it exists, and give bounds on the approximation error of the algorithm when such a decomposition does not exist. For 2) given data $\mathbf{Y}=\mathbf{HX}$, we show that when assuming a binary coefficient matrix $\mathbf{X}$, the structured (Householder) dictionary learning problem can be solved with just $2$ samples (columns) in $\mathbf{Y}$.

Paper number 11:
Title: Path Evolution Model for Endogenous Channel Digital Twin towards 6G Wireless Networks
Authors: Haoyu Wang, Zhi Sun, Shuangfeng Han, Xiaoyun Wang, Shidong Zhou, Zhaocheng Wang
Abstract: Massive Multiple Input Multiple Output (MIMO) is critical for boosting 6G wireless network capacity. Nevertheless, high dimensional Channel State Information (CSI) acquisition becomes the bottleneck of 6G massive MIMO system. Recently, Channel Digital Twin (CDT), which replicates physical entities in wireless channels, has been proposed, providing site-specific prior knowledge for CSI acquisition. However, external devices (e.g., cameras and GPS devices) cannot always be integrated into existing communication systems, nor are they universally available across all scenarios. Moreover, the trained CDT model cannot be directly applied in new environments, which lacks environmental generalizability. To this end, Path Evolution Model (PEM) is proposed as an alternative CDT to reflect physical path evolutions from consecutive channel measurements. Compared to existing CDTs, PEM demonstrates virtues of full endogeneity, self-sustainability and environmental generalizability. Firstly, PEM only requires existing channel measurements, which is free of other hardware devices and can be readily deployed. Secondly, self-sustaining maintenance of PEM can be achieved in dynamic channel by progressive updates. Thirdly, environmental generalizability can greatly reduce deployment costs in dynamic environments. To facilitate the implementation of PEM, an intelligent and light-weighted operation framework is firstly designed. Then, the environmental generalizability of PEM is rigorously analyzed. Next, efficient learning approaches are proposed to reduce the amount of training data practically. Extensive simulation results reveal that PEM can simultaneously achieve high-precision and low-overhead CSI acquisition, which can serve as a fundamental CDT for 6G wireless networks.

Paper number 12:
Title: Crystal Oscillators in OSNMA-Enabled Receivers: An Implementation View for Automotive Applications
Authors: Francesco Ardizzon, Nicola Laurenti, Carlo Sarto, Giovanni Gamba, Cillian O'Driscoll, Ignacio Fernandez-Hernandez
Abstract: To ensure the authenticity of navigation data, Galileo Open Service navigation message authentication (OSNMA) requires loose synchronization between the receiver clock and the system time. This means that during the period between clock calibrations, the receiver clock error needs to be smaller than a pre-defined threshold, currently up to 165s for OSNMA. On the other hand, relying on the PVT solution to steer the receiver clock or correct its bias may not be possible since this would depend on the very same signals we intend to authenticate. This work aims to investigate the causes of the frequency accuracy loss leading to clock errors and to build a model that, from the datasheet of a real-time clock (RTC) device, allows to bound the error clock during a certain period. The model's main contributors are temperature changes, long-term aging, and offset at calibration, but it includes other factors. We then apply the model to several RTCs from different manufacturers and bound the maximum error for certain periods, with a focus on the two-year between-calibration period expected for the smart tachograph, an automotive application that will integrate OSNMA.

Paper number 13:
Title: MAP-based Problem-Agnostic diffusion model for Inverse Problems
Authors: Pingping Tao, Haixia Liu, Jing Su, Xiaochen Yang, Hongchen Tan
Abstract: Diffusion models have indeed shown great promise in solving inverse problems in image processing. In this paper, we propose a novel, problem-agnostic diffusion model called the maximum a posteriori (MAP)-based guided term estimation method for inverse problems. We divide the conditional score function into two terms according to Bayes' rule: the unconditional score function and the guided term. We design the MAP-based guided term estimation method, while the unconditional score function is approximated by an existing score network. To estimate the guided term, we base on the assumption that the space of clean natural images is inherently smooth, and introduce a MAP estimate of the $t$-th latent variable. We then substitute this estimation into the expression of the inverse problem and obtain the approximation of the guided term. We evaluate our method extensively on super-resolution, inpainting, and denoising tasks, and demonstrate comparable performance to DDRM, DMPS, DPS and $\Pi$GDM.

Paper number 14:
Title: Target Localization with a Coprime Multistatic MIMO Radar via Coupled Canonical Polyadic Decomposition Based on Joint EVD
Authors: Guo-Zhao Liao, Xiao-Feng Gong, Wei Liu, Hing Cheung So
Abstract: This paper addresses target localization using a multistatic multiple-input multiple-output (MIMO) radar system with coprime L-shaped receive arrays (CLsA). A target localization method is proposed by modeling the observed signals as tensors that admit a coupled canonical polyadic decomposition (C-CPD) model without matched filtering. It consists of a novel joint eigenvalue decomposition (J-EVD) based (semi-)algebraic algorithm, and a post-processing approach to determine the target locations by fusing the direction-of-arrival estimates extracted from J-EVD-based CCPD results. Particularly, by leveraging the rotational invariance of Vandermonde structure in CLsA, we convert the CCPD problem into a J-EVD problem, significantly reducing its computational complexity. Experimental results show that our method outperforms existing tensor-based ones.

Paper number 15:
Title: A Block Term Decomposition Model Based Algorithm for Tensor Completion of Multidimensional Harmonic Signals
Authors: Lei Wang, Xiao-Feng Gong, Xi-Yuan Liu, Wei Feng, Qiu-Hua Lin
Abstract: We consider tensor data completion of an incomplete observation of multidimensional harmonic (MH) signals. Unlike existing tensor-based techniques for MH retrieval (MHR), which mostly adopt the canonical polyadic decomposition (CPD) to model the simple "one-to-one" correspondence among harmonics across difference modes, we herein use the more flexible block term decomposition (BTD) model that can be used to describe the complex mutual correspondences among several groups of harmonics across different modes. An optimization principle that aims to fit the BTD model in the least squares sense, subject to rank minimization of hankelized MH components, is set up for the tensor completion task, and an algorithm based on alternating direction method of multipliers is proposed, of which the effectiveness and applicability are validated through both numerical simulations and an application in Sub-6GHz channel state information (CSI) completion.

Paper number 16:
Title: On Spectral Approach to the Synthesis of Shaping Filters
Authors: Konstantin A. Rybakov
Abstract: This paper describes various approaches to modeling a random process with a given rational power spectral density. The main attention is paid to the spectral form of mathematical description, which allows one to obtain a relation for the shaping filter using a transfer function without any additional calculations. The paper provides all necessary relations for the implementation of the shaping filter based on the spectral form of mathematical description.

Paper number 17:
Title: Three-Dimensional Sparse Random Mode Decomposition for Mode Disentangling with Crossover Instantaneous Frequencies
Authors: Chen Luo, Tao Chen, Lei Xie, Hongye Su
Abstract: Sparse random mode decomposition (SRMD) is a novel algorithm that constructs a random time-frequency feature space to sparsely approximate spectrograms, effectively separating modes. However, it fails to distinguish adjacent or overlapped frequency components, especially, those with crossover instantaneous frequencies. To address this limitation, an enhanced version, termed three-dimensional SRMD (3D-SRMD), is proposed in this letter. In 3D-SRMD, the random features are lifted from a two-dimensional space to a three-dimensional (3D) space by introducing one extra chirp rate axis. This enhancement effectively disentangles the frequency components overlapped in the low dimension. Additionally, a novel random feature generation strategy is designed to improve the separation accuracy of 3D-SRMD by combining the 3D ridge detection method. Finally, numerical experiments on both simulated and real-world signals demonstrate the effectiveness of our method.

Paper number 18:
Title: Performance evaluation of non-uniform sensor spacing in a linear array configuration for MUSIC algorithm
Authors: Pradeep Dheerendra, Sumit Saraogi, Palanisamy P., Kalyanasundaram N
Abstract: In this paper, the performance of non-uniform spacing of sensors is evaluated for the MUSIC algorithm which estimates the direction of arrival (DOA) of a narrowband plane wave impinging on an array of sensors. Unlike uniform sensor spacing arrangement, where sensors are equidistant (equal to half the wavelength), we consider non-uniform spacing for the arrangement of sensors, where the distance between consecutive sensors increases progressively. We observe that the non-uniform sensor spacing configuration (with lesser number of sensors) can provide similar or better accuracy in DOA estimation compared to uniform sensor spacing configuration despite more number of sensors at identical array length.

Paper number 19:
Title: Flexible Cylindrical Arrays with Movable Antennas for MISO System: Beamforming and Position Optimization
Authors: Jiahe Guo, Songjie Yang, Xiangyu Dong, Jiapan Yang, Junfeng Deng, Zhongpei Zhang, Chau Yuen
Abstract: As wireless communication advances toward the 6G era, the demand for ultra-reliable, high-speed, and ubiquitous connectivity is driving the exploration of new degrees-of-freedom (DoFs) in communication systems. Among the key enabling technologies, Movable Antennas (MAs) integrated into Flexible Cylindrical Arrays (FCLA) have shown great potential in optimizing wireless communication by providing spatial flexibility. This paper proposes an innovative optimization framework that leverages the dynamic mobility of FCLAs to improve communication rates and overall system performance. By employing Fractional Programming (FP) for alternating optimization of beamforming and antenna positions, the system enhances throughput and resource utilization. Additionally, a novel Constrained Grid Search-Based Adaptive Moment Estimation Algorithm (CGS-Adam) is introduced to optimize antenna positions while adhering to antenna spacing constraints. Extensive simulations validate that the proposed system, utilizing movable antennas, significantly outperforms traditional fixed antenna optimization, achieving up to a 31\% performance gain in general scenarios. The integration of FCLAs in wireless networks represents a promising solution for future 6G systems, offering improved coverage, energy efficiency, and flexibility.

Paper number 20:
Title: A parametric non-negative coupled canonical polyadic decomposition algorithm for hyperspectral super-resolution
Authors: Xi-Yuan Liu, Xiao-Feng Gong, Lei Wang, Wei Feng, Qiu-Hua Lin
Abstract: Recently, coupled tensor decomposition has been widely used in data fusion of a hyperspectral image (HSI) and a multispectral image (MSI) for hyperspectral super-resolution (HSR). However, exsiting works often ignore the inherent non-negative (NN) property of the image data, or impose the NN constraint via hard-thresholding which may interfere with the optimization procedure and cause the method to be sub-optimal. As such, we propose a novel NN coupled canonical polyadic decomposition (NN-C-CPD) algorithm, which makes use of the parametric method and nonlinear least squares (NLS) framework to impose the NN constraint into the C-CPD computation. More exactly, the NN constraint is converted into the squared relationship between the NN entries of the factor matrices and a set of latent parameters. Based on the chain rule for deriving the derivatives, the key entities such as gradient and Jacobian with regards to the latent parameters can be derived, thus the NN constraint is naturally integrated without interfering with the optimization procedure. Experimental results are provided to demonstrate the performance of the proposed NN-C-CPD algorithm in HSR applications.

Paper number 21:
Title: End-to-end localized deep learning for Cryo-ET
Authors: Vinith Kishore, Valentin Debarnot, Ricardo D. Righetto, AmirEhsan Khorashadizadeh, Ivan Dokmanić
Abstract: Cryo-electron tomography (cryo-ET) enables 3D visualization of cellular environments. Accurate reconstruction of high-resolution volumes is complicated by the very low signal-to-noise ratio and a restricted range of sample tilts, creating a missing wedge of Fourier information. Recent self-supervised deep learning approaches, which post-process initial reconstructions done by filtered backprojection (FBP), have significantly improved reconstruction quality, but they are computationally expensive, demand large memory, and require retraining for each new dataset. End-to-end supervised learning is an appealing alternative but is impeded by the lack of ground truth and the large memory demands of high-resolution volumetric data. Training on synthetic data often leads to overfitting and poor generalization to real data, and, to date, no general end-to-end deep learning reconstructors exist for cryo-ET. In this work, we introduce CryoLithe, a local, memory-efficient reconstruction network that directly estimates the volume from an aligned tilt-series, overcoming the suboptimal FBP. We demonstrate that leveraging transform-domain locality makes our network robust to distribution shifts, enabling effective supervised training and giving excellent results on real data -- without retraining or fine-tuning.

Paper number 22:
Title: Deep Multimodal Learning for Real-Time DDoS Attacks Detection in Internet of Vehicles
Authors: Mohamed Ababsa, Soheyb Ribouh, Abdelhamid Malki, Lyes Khoukhi
Abstract: The progress and integration of intelligent transport systems (ITS) have therefore been central to creating safer and more efficient transport networks. The Internet of Vehicles (IoV) has the potential to improve road safety and provide comfort to travelers. However, this technology is exposed to a variety of security vulnerabilities that malicious actors could exploit. One of the most serious threats to IoV is the Distributed Denial of Service (DDoS) attack, which could be used to disrupt traffic flow, disable communication between vehicles, or even cause accidents. In this paper, we propose a novel Deep Multimodal Learning (DML) approach for detecting DDoS attacks in IoV, addressing a critical aspect of cybersecurity in intelligent transport systems. Our proposed DML model integrates Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), enhanced by Attention and Gating mechanisms, and Multi-Layer Perceptron (MLP) with a multimodal intermediate fusion architecture. This innovative method effectively identifies and mitigates DDoS attacks in real-time by utilizing the Framework for Misbehavior Detection (F2MD) to generate a synthetic dataset, thereby overcoming the limitations of the existing Vehicular Reference Misbehavior (VeReMi) extension dataset. The proposed approach is evaluated in real-time across different simulated real-world scenario with 10\%, $30\%$, and $50\%$ attacker densities. The proposed DML model achieves an average accuracy of 96.63\%, outperforming the classical Machine Learning (ML) approaches and state-of-the-art methods which demonstrate significant efficacy and reliability in protecting vehicular networks from malicious cyber-attacks.

Paper number 23:
Title: Fusion of Millimeter-wave Radar and Pulse Oximeter Data for Low-burden Diagnosis of Obstructive Sleep Apnea-Hypopnea Syndrome
Authors: Wei Wang, Zhaoxi Chen, Wenyu Zhang, Zetao Wang, Xiang Zhao, Chenyang Li, Jian Guan, Shankai Yin, Gang Li
Abstract: Objective: The aim of the study is to develop a novel method for improved diagnosis of obstructive sleep apnea-hypopnea syndrome (OSAHS) in clinical or home settings, with the focus on achieving diagnostic performance comparable to the gold-standard polysomnography (PSG) with significantly reduced monitoring burden. Methods: We propose a method using millimeter-wave radar and pulse oximeter for OSAHS diagnosis (ROSA). It contains a sleep apnea-hypopnea events (SAE) detection network, which directly predicts the temporal localization of SAE, and a sleep staging network, which predicts the sleep stages throughout the night, based on radar signals. It also fuses oxygen saturation (SpO2) information from the pulse oximeter to adjust the score of SAE detected by radar. Results: Experimental results on a real-world dataset (>800 hours of overnight recordings, 100 subjects) demonstrated high agreement (ICC=0.9870) on apnea-hypopnea index (AHI) between ROSA and PSG. ROSA also exhibited excellent diagnostic performance, exceeding 90% in accuracy across AHI diagnostic thresholds of 5, 15 and 30 events/h. Conclusion: ROSA improves diagnostic accuracy by fusing millimeter-wave radar and pulse oximeter data. It provides a reliable and low-burden solution for OSAHS diagnosis. Significance: ROSA addresses the limitations of high complexity and monitoring burden associated with traditional PSG. The high accuracy and low burden of ROSA show its potential to improve the accessibility of OSAHS diagnosis among population.

Paper number 24:
Title: Investigating the Feasibility of Patch-based Inference for Generalized Diffusion Priors in Inverse Problems for Medical Images
Authors: Saikat Roy, Mahmoud Mostapha, Radu Miron, Matt Holbrook, Mariappan Nadar
Abstract: Plug-and-play approaches to solving inverse problems such as restoration and super-resolution have recently benefited from Diffusion-based generative priors for natural as well as medical images. However, solutions often use the standard albeit computationally intensive route of training and inferring with the whole image on the diffusion prior. While patch-based approaches to evaluating diffusion priors in plug-and-play methods have received some interest, they remain an open area of study. In this work, we explore the feasibility of the usage of patches for training and inference of a diffusion prior on MRI images. We explore the minor adaptation necessary for artifact avoidance, the performance and the efficiency of memory usage of patch-based methods as well as the adaptability of whole image training to patch-based evaluation - evaluating across multiple plug-and-play methods, tasks and datasets.

Paper number 25:
Title: Kalman filter/deep-learning hybrid automatic boundary tracking of optical coherence tomography data for deep anterior lamellar keratoplasty (DALK)
Authors: Hongrui Yi, Jingjun Yu, Yaning Wang, Justin Opfermann, Bill G. Gensheimer, Axel Kriger, Jin U. Kang
Abstract: Deep anterior lamellar keratoplasty (DALK) is a highly challenging partial thickness cornea transplant surgery that replaces the anterior cornea above Descemet's membrane (DM) with a donor cornea. In our previous work, we proposed the design of an optical coherence tomography (OCT) sensor integrated needle to acquire real-time M-mode images to provide depth feedback during OCT-guided needle insertion during Big Bubble DALK procedures. Machine learning and deep learning techniques were applied to M-mode images to automatically identify the DM in OCT M-scan data. However, such segmentation methods often produce inconsistent or jagged segmentation of the DM which reduces the model accuracy. Here we present a Kalman filter based OCT M-scan boundary tracking algorithm in addition to AI-based precise needle guidance to improve automatic DM segmentation for OCT-guided DALK procedures. By using the Kalman filter, the proposed method generates a smoother layer segmentation result from OCT M-mode images for more accurate tracking of the DM layer and epithelium. Initial ex vivo testing demonstrates that the proposed approach significantly increases the segmentation accuracy compared to conventional methods without the Kalman filter. Our proposed model can provide more consistent and precise depth sensing results, which has great potential to improve surgical safety and ultimately contributes to better patient outcomes.

Paper number 26:
Title: Scaling laws for decoding images from brain activity
Authors: Hubert Banville, Yohann Benchetrit, Stéphane d'Ascoli, Jérémy Rapin amd Jean-Rémi King
Abstract: Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings.

Paper number 27:
Title: Assessing the Impact of Sampling Irregularity in Time Series Data: Human Activity Recognition As A Case Study
Authors: Mengxi Liu, Daniel Geißler, Sizhen Bian, Bo Zhou, Paul Lukowicz
Abstract: Human activity recognition (HAR) ideally relies on data from wearable or environment-instrumented sensors sampled at regular intervals, enabling standard neural network models optimized for consistent time-series data as input. However, real-world sensor data often exhibits irregular sampling due to, for example, hardware constraints, power-saving measures, or communication delays, posing challenges for deployed static HAR models. This study assesses the impact of sampling irregularities on HAR by simulating irregular data through two methods: introducing slight inconsistencies in sampling intervals (timestamp variations) to mimic sensor jitter, and randomly removing data points (random dropout) to simulate missing values due to packet loss or sensor failure. We evaluate both discrete-time neural networks and continuous-time neural networks, which are designed to handle continuous-time data, on three public datasets. We demonstrate that timestamp variations do not significantly affect the performance of discrete-time neural networks, and the continuous-time neural network is also ineffective in addressing the challenges posed by irregular sampling, possibly due to limitations in modeling complex temporal patterns with missing data. Our findings underscore the necessity for new models or approaches that can robustly handle sampling irregularity in time-series data, like the reading in human activity recognition, paving the way for future research in this domain.

Paper number 28:
Title: DER Hosting capacity for distribution networks: definitions, attributes, use-cases and challenges
Authors: Md Umar Hashmi
Abstract: The rapid adoption of distributed energy resources (DERs) has outpaced grid modernization, leading to capacity limitations that challenge their further integration. Hosting Capacity Assessment (HCA) is a critical tool for evaluating how much DER capacity a grid can handle without breaching operational limits. HCA serves multiple goals: enabling higher DER penetration, accelerating grid connection times, guiding infrastructure upgrades or flexible resource deployment, ensuring equitable policies, and improving grid flexibility while minimizing curtailment. HCA lacks a universal definition, varying by modelling approaches, uncertainty considerations, and objectives. This paper addresses five key questions to standardize and enhance HCA practices. First, it classifies HCA objectives associated with different stakeholders such as system operators, consumers, market operators and consumers. Second, it examines model attributes, including modelling sophistication, data requirements, and uncertainty handling, thus balancing complexity with computational efficiency. Third, it explores HCA applications, such as planning grid investments or operational decisions, and summarizes use cases associated with HCA. Fourth, it emphasizes the need for periodic updates to reflect dynamic grid conditions, evolving technologies, and new DER installations. Finally, it identifies challenges, such as ensuring data quality, managing computational demands, and aligning short-term and long-term goals. By addressing these aspects, this paper provides a structured approach to perform and apply HCA, offering insights for engineers, planners, and policymakers to manage DER integration effectively.

Paper number 29:
Title: Learning-Enhanced Safeguard Control for High-Relative-Degree Systems: Robust Optimization under Disturbances and Faults
Authors: Xinyang Wang, Hongwei Zhang, Shimin Wang, Wei Xiao, Martin Guay
Abstract: Merely pursuing performance may adversely affect the safety, while a conservative policy for safe exploration will degrade the performance. How to balance the safety and performance in learning-based control problems is an interesting yet challenging issue. This paper aims to enhance system performance with safety guarantee in solving the reinforcement learning (RL)-based optimal control problems of nonlinear systems subject to high-relative-degree state constraints and unknown time-varying disturbance/actuator faults. First, to combine control barrier functions (CBFs) with RL, a new type of CBFs, termed high-order reciprocal control barrier function (HO-RCBF) is proposed to deal with high-relative-degree constraints during the learning process. Then, the concept of gradient similarity is proposed to quantify the relationship between the gradient of safety and the gradient of performance. Finally, gradient manipulation and adaptive mechanisms are introduced in the safe RL framework to enhance the performance with a safety guarantee. Two simulation examples illustrate that the proposed safe RL framework can address high-relative-degree constraint, enhance safety robustness and improve system performance.

Paper number 30:
Title: Modern Base Station Architecture: Enabling Passive Beamforming with Beyond Diagonal RISs
Authors: Mahmoud Raeisi, Hui Chen, Henk Wymeersch, Ertugrul Basar
Abstract: Beamforming plays a crucial role in millimeter wave (mmWave) communication systems to mitigate the severe attenuation inherent to this spectrum. However, the use of large active antenna arrays in conventional architectures often results in high implementation costs and excessive power consumption, limiting their practicality. As an alternative, deploying large arrays at transceivers using passive devices, such as reconfigurable intelligent surfaces (RISs), offers a more cost-effective and energy-efficient solution. In this paper, we investigate a promising base station (BS) architecture that integrates a beyond diagonal RIS (BD-RIS) within the BS to enable passive beamforming. By utilizing Takagi's decomposition and leveraging the effective beamforming vector, the RIS profile can be designed to enable passive beamforming directed toward the target. Through the beamforming analysis, we reveal that BD-RIS provides robust beamforming performance across various system configurations, whereas the traditional diagonal RIS (D-RIS) exhibits instability with increasing RIS size and decreasing BS-RIS separation-two critical factors in optimizing RIS-assisted systems. Comprehensive computer simulation results across various aspects validate the superiority of the proposed BS-integrated BD-RIS over conventional D-RIS architectures, showcasing performance comparable to active analog beamforming antenna arrays.

Paper number 31:
Title: Movable Antenna-Aided Cooperative ISAC Network with Time Synchronization error and Imperfect CSI
Authors: Yue Xiu, Yang Zhao, Ran Yang, Dusit Niyato, Jing Jin, Qixing Wang, Guangyi Liu, Ning Wei
Abstract: Cooperative-integrated sensing and communication (C-ISAC) networks have emerged as promising solutions for communication and target sensing. However, imperfect channel state information (CSI) estimation and time synchronization (TS) errors degrade performance, affecting communication and sensing accuracy. This paper addresses these challenges {by employing} {movable antennas} (MAs) to enhance C-ISAC robustness. We analyze the impact of CSI errors on achievable rates and introduce a hybrid Cramer-Rao lower bound (HCRLB) to evaluate the effect of TS errors on target localization accuracy. Based on these models, we derive the worst-case achievable rate and sensing precision under such errors. We optimize cooperative beamforming, {base station (BS)} selection factor and MA position to minimize power consumption while ensuring accuracy. {We then propose a} constrained deep reinforcement learning (C-DRL) approach to solve this non-convex optimization problem, using a modified deep deterministic policy gradient (DDPG) algorithm with a Wolpertinger architecture for efficient training under complex constraints. {Simulation results show that the proposed method significantly improves system robustness against CSI and TS errors, where robustness mean reliable data transmission under poor channel conditions.} These findings demonstrate the potential of MA technology to reduce power consumption in imperfect CSI and TS environments.

Paper number 32:
Title: Rate-Splitting Sparse Code Multiple Access
Authors: Minerva Priyadarsini, Kuntal Deka, Zilong Liu, Sujit Kumar Sahoo, Sanjeev Sharma
Abstract: This paper presents a novel rate-splitting sparse code multiple access (RS-SCMA) framework, where common messages are transmitted using quadrature phase-shift keying (QPSK) modulation, while private messages are sent using SCMA encoding. A key feature of RS-SCMA is its ability to achieve a tunable overloading factor by adjusting the splitting factor. This flexibility enables an optimal trade-off, ensuring the system maintains superior performance across varying levels of overloading factor. We present a detailed transceiver design and analyze the influence of rate-splitting on the overloading factor. Extensive simulation results, both with and without low-density parity-check (LDPC) codes, highlight RS-SCMA's potential as a strong candidate for next-generation multiple access technologies.

Paper number 33:
Title: Semantic Communication with Entropy-and-Channel-Adaptive Rate Control
Authors: Weixuan Chen, Yuhao Chen, Qianqian Yang, Chongwen Huang, Qian Wang, Zehui Xiong, Zhaoyang Zhang
Abstract: Traditional wireless image transmission methods struggle to balance rate efficiency and reconstruction quality under varying channel conditions. To address these challenges, we propose a novel semantic communication (SemCom) system that integrates entropy-aware and channel-adaptive mechanisms for wireless image transmission over multi-user multiple-input multiple-output (MU-MIMO) fading channels. Unlike existing approaches, our system dynamically adjusts transmission rates based on the entropy of feature maps, channel state information (CSI), and signal-to-noise ratio (SNR), ensuring optimal resource utilization and robust performance. The system employs feature map pruning, channel attention, spatial attention, and multihead self-attention (MHSA) mechanisms to prioritize critical semantic features and effectively reconstruct images. Experimental results demonstrate that the proposed system outperforms state-of-the-art benchmarks, including BPG+LDPC+4QAM and Deep JSCC, in terms of rate-distortion performance, flexibility, and robustness, particularly under challenging conditions such as low SNR, imperfect CSI, and inter-user interference. This work establishes a strong foundation for adaptive-rate SemCom systems and highlights their potential for real-time, bandwidthintensive applications.

Paper number 34:
Title: Stroke Lesion Segmentation using Multi-Stage Cross-Scale Attention
Authors: Liang Shang, William A. Sethares, Anusha Adluru, Andrew L. Alexander, Vivek Prabhakaran, Veena A. Nair, Nagesh Adluru
Abstract: Precise characterization of stroke lesions from MRI data has immense value in prognosticating clinical and cognitive outcomes following a stroke. Manual stroke lesion segmentation is time-consuming and requires the expertise of neurologists and neuroradiologists. Often, lesions are grossly characterized for their location and overall extent using bounding boxes without specific delineation of their boundaries. While such characterization provides some clinical value, to develop a precise mechanistic understanding of the impact of lesions on post-stroke vascular contributions to cognitive impairments and dementia (VCID), the stroke lesions need to be fully segmented with accurate boundaries. This work introduces the Multi-Stage Cross-Scale Attention (MSCSA) mechanism, applied to the U-Net family, to improve the mapping between brain structural features and lesions of varying sizes. Using the Anatomical Tracings of Lesions After Stroke (ATLAS) v2.0 dataset, MSCSA outperforms all baseline methods in both Dice and F1 scores on a subset focusing on small lesions, while maintaining competitive performance across the entire dataset. Notably, the ensemble strategy incorporating MSCSA achieves the highest scores for Dice and F1 on both the full dataset and the small lesion subset. These results demonstrate the effectiveness of MSCSA in segmenting small lesions and highlight its robustness across different training schemes for large stroke lesions. Our code is available at: this https URL.

Paper number 35:
Title: Enhanced Generalized OFDM with Index Modulation
Authors: A.Atef Ibrahim, Amr A.Nagy, Ashraf Mahran, Amr Abdelaziz
Abstract: In recent years, many attempts have been made to enhance Orthogonal Frequency Multiplexing with Index Modulation (OFDM-IM) in terms of spectral efficiency and error performance. Two challenges typically erupt when using OFDM-IM. First, the degradation in spectral efficiency due to the subcarrier's deactivation, especially when using higher order modulation (M-ary) where every inactive subcarrier will cost $Log_2(M)$ bits loss. Second, using a fixed number of active subcarriers within a sub-block forces the error to be localized within the sub-block. Yet, it loses the advantage of exploiting all possible pattern combinations degrading the overall spectral efficiency. In this paper, we introduce a solution to tackle those problems. The Enhanced Generalized Index Modulation (EGIM) is a simple systematic way to generate and detect the OFDM-IM frame. Unlike the classical OFDM-IM generation by splitting the frame into sub-frames which increases the complexity of the OFDM-IM transmitter and reflects on the receiver Maximum likelihood detector, EGIM Makes full use of all possible combinations of active subcarriers within the frame by using variable active subcarriers (k) depending on the incoming data. The EGIM is still susceptible to error propagation if the OFF symbol is wrongly mapped to one of the ON symbols or vice versa. For that reason, we offer an OFDM-IM autoencoder to overcome this problem. The encoder generates the (ON/OFF) symbols systematically to achieve the advantage of sending all possible frame indices patterns depending on the input bit stream offering an average of 3dB gain in terms of power efficiency. The proposed encoder performance was compared to the standard encoder with the same effective coding rate using soft and hard decision Viterbi decoding utilizing the power gain achieved.

Paper number 36:
Title: FlatTrack: Eye-tracking with ultra-thin lensless cameras
Authors: Purvam Jain, Althaf M. Nazar, Salman S. Khan, Kaushik Mitra, Praneeth Chakravarthula
Abstract: Existing eye trackers use cameras based on thick compound optical elements, necessitating the cameras to be placed at focusing distance from the eyes. This results in the overall bulk of wearable eye trackers, especially for augmented and virtual reality (AR/VR) headsets. We overcome this limitation by building a compact flat eye gaze tracker using mask-based lensless cameras. These cameras, in combination with co-designed lightweight deep neural network algorithm, can be placed in extreme close proximity to the eye, within the eyeglasses frame, resulting in ultra-flat and lightweight eye gaze tracker system. We collect a large dataset of near-eye lensless camera measurements along with their calibrated gaze directions for training the gaze tracking network. Through real and simulation experiments, we show that the proposed gaze tracking system performs on par with conventional lens-based trackers while maintaining a significantly flatter and more compact form-factor. Moreover, our gaze regressor boasts real-time (>125 fps) performance for gaze tracking.

Paper number 37:
Title: End-to-End Target Speaker Speech Recognition Using Context-Aware Attention Mechanisms for Challenging Enrollment Scenario
Authors: Mohsen Ghane, Mohammad Sadegh Safari
Abstract: This paper presents a novel streaming end-to-end target-speaker speech recognition that addresses two critical limitations in systems: the handling of noisy enrollment utterances and specific enrollment phrase requirements. This paper proposes a robust Target-Speaker Recurrent Neural Network Transducer (TS-RNNT) with dual attention mechanisms for contextual biasing and overlapping enrollment processing. The model incorporates a text decoder and attention mechanism specifically designed to extract relevant speaker characteristics from noisy, overlapping enrollment audio. Experimental results on a synthesized dataset demonstrate the model's resilience, maintaining a Word Error Rate (WER) of 16.44% even with overlapping enrollment at 5dB Signal-to-Interference Ratio (SIR), compared to conventional approaches that degrade to WERs above 75% under similar conditions. This significant performance improvement, coupled with the model's semi-text-dependent enrollment capabilities, represents a substantial advancement toward more practical and versatile voice-controlled devices.

Paper number 38:
Title: Dynamic Regressor Extension and Mixing-based Re-design of Adaptive Observer for Affine Systems
Authors: Mehdi Tavan
Abstract: The dynamic regressor extension and mixing procedure is employed to redesign a conventional adaptive observer algorithm for affine systems. A reduced-order observer is designed without the construction of the state transition matrix. The dynamics of the regressor are redesigned to incorporate feedback from its extension, transforming the regressor dynamics into a perturbed damped nonlinear oscillator form. This introduces some flexibility in reducing the degradation of parameter convergence due to the lack of the transition matrix and in enhancing the excitation property of the extension matrix.

Paper number 39:
Title: Differentiable Low-computation Global Correlation Loss for Monotonicity Evaluation in Quality Assessment
Authors: Yipeng Liu, Qi Yang, Yiling Xu
Abstract: In this paper, we propose a global monotonicity consistency training strategy for quality assessment, which includes a differentiable, low-computation monotonicity evaluation loss function and a global perception training mechanism. Specifically, unlike conventional ranking loss and linear programming approaches that indirectly implement the Spearman rank-order correlation coefficient (SROCC) function, our method directly converts SROCC into a loss function by making the sorting operation within SROCC differentiable and functional. Furthermore, to mitigate the discrepancies between batch optimization during network training and global evaluation of SROCC, we introduce a memory bank mechanism. This mechanism stores gradient-free predicted results from previous batches and uses them in the current batch's training to prevent abrupt gradient changes. We evaluate the performance of the proposed method on both images and point clouds quality assessment tasks, demonstrating performance gains in both cases.

Paper number 40:
Title: Variational Bayesian Adaptive Learning of Deep Latent Variables for Acoustic Knowledge Transfer
Authors: Hu Hu, Sabato Marco Siniscalchi, Chao-Han Huck Yang, Chin-Hui Lee
Abstract: In this work, we propose a novel variational Bayesian adaptive learning approach for cross-domain knowledge transfer to address acoustic mismatches between training and testing conditions, such as recording devices and environmental noise. Different from the traditional Bayesian approaches that impose uncertainties on model parameters risking the curse of dimensionality due to the huge number of parameters, we focus on estimating a manageable number of latent variables in deep neural models. Knowledge learned from a source domain is thus encoded in prior distributions of deep latent variables and optimally combined, in a Bayesian sense, with a small set of adaptation data from a target domain to approximate the corresponding posterior distributions. Two different strategies are proposed and investigated to estimate the posterior distributions: Gaussian mean-field variational inference, and empirical Bayes. These strategies address the presence or absence of parallel data in the source and target domains. Furthermore, structural relationship modeling is investigated to enhance the approximation. We evaluated our proposed approaches on two acoustic adaptation tasks: 1) device adaptation for acoustic scene classification, and 2) noise adaptation for spoken command recognition. Experimental results show that the proposed variational Bayesian adaptive learning approach can obtain good improvements on target domain data, and consistently outperforms state-of-the-art knowledge transfer methods.

Paper number 41:
Title: Comparative clinical evaluation of "memory-efficient" synthetic 3d generative adversarial networks (gan) head-to-head to state of art: results on computed tomography of the chest
Authors: Mahshid shiri, Chandra Bortolotto, Alessandro Bruno, Alessio Consonni, Daniela Maria Grasso, Leonardo Brizzi, Daniele Loiacono, Lorenzo Preda
Abstract: Introduction: Generative Adversarial Networks (GANs) are increasingly used to generate synthetic medical images, addressing the critical shortage of annotated data for training Artificial Intelligence (AI) systems. This study introduces a novel memory-efficient GAN architecture, incorporating Conditional Random Fields (CRFs) to generate high-resolution 3D medical images and evaluates its performance against the state-of-the-art hierarchical (HA)-GAN model. Materials and Methods: The CRF-GAN was trained using the open-source lung CT LUNA16 dataset. The architecture was compared to HA-GAN through a quantitative evaluation, using Frechet Inception Distance (FID) and Maximum Mean Discrepancy (MMD) metrics, and a qualitative evaluation, through a two-alternative forced choice (2AFC) test completed by a pool of 12 resident radiologists, in order to assess the realism of the generated images. Results: CRF-GAN outperformed HA-GAN with lower FID (0.047 vs. 0.061) and MMD (0.084 vs. 0.086) scores, indicating better image fidelity. The 2AFC test showed a significant preference for images generated by CRF-Gan over those generated by HA-GAN with a p-value of 1.93e-05. Additionally, CRF-GAN demonstrated 9.34% lower memory usage at 256 resolution and achieved up to 14.6% faster training speeds, offering substantial computational savings. Discussion: CRF-GAN model successfully generates high-resolution 3D medical images with non-inferior quality to conventional models, while being more memory-efficient and faster. Computational power and time saved can be used to improve the spatial resolution and anatomical accuracy of generated images, which is still a critical factor limiting their direct clinical applicability.

Paper number 42:
Title: Vehicular Multi-Tier Distributed Computing with Hybrid THz-RF Transmission in Satellite-Terrestrial Integrated Networks
Authors: Ni Zhang, Kunlun Wang, Wen Chen, Jing Xu, Yonghui Li, Arumugam Nallanathan
Abstract: In this paper, we propose a Satellite-Terrestrial Integrated Network (STIN) assisted vehicular multi-tier distributed computing (VMDC) system leveraging hybrid terahertz (THz) and radio frequency (RF) communication technologies. Task offloading for satellite edge computing is enabled by THz communication using the orthogonal frequency division multiple access (OFDMA) technique. For terrestrial edge computing, we employ non-orthogonal multiple access (NOMA) and vehicle clustering to realize task offloading. We formulate a non-convex optimization problem aimed at maximizing computation efficiency by jointly optimizing bandwidth allocation, task allocation, subchannel-vehicle matching and power allocation. To address this non-convex optimization problem, we decompose the original problem into four sub-problems and solve them using an alternating iterative optimization approach. For the subproblem of task allocation, we solve it by linear programming. To solve the subproblem of sub-channel allocation, we exploit many-to-one matching theory to obtain the result. The subproblem of bandwidth allocation of OFDMA and the subproblem of power allocation of NOMA are solved by quadratic transformation method. Finally, the simulation results show that our proposed scheme significantly enhances the computation efficiency of the STIN-based VMDC system compared with the benchmark schemes.

Paper number 43:
Title: Tumor Detection, Segmentation and Classification Challenge on Automated 3D Breast Ultrasound: The TDSC-ABUS Challenge
Authors: Gongning Luo, Mingwang Xu, Hongyu Chen, Xinjie Liang, Xing Tao, Dong Ni, Hyunsu Jeong, Chulhong Kim, Raphael Stock, Michael Baumgartner, Yannick Kirchhoff, Maximilian Rokuss, Klaus Maier-Hein, Zhikai Yang, Tianyu Fan, Nicolas Boutry, Dmitry Tereshchenko, Arthur Moine, Maximilien Charmetant, Jan Sauer, Hao Du, Xiang-Hui Bai, Vipul Pai Raikar, Ricardo Montoya-del-Angel, Robert Marti, Miguel Luna, Dongmin Lee, Abdul Qayyum, Moona Mazher, Qihui Guo, Changyan Wang, Navchetan Awasthi, Qiaochu Zhao, Wei Wang, Kuanquan Wang, Qiucheng Wang, Suyu Dong
Abstract: Breast cancer is one of the most common causes of death among women worldwide. Early detection helps in reducing the number of deaths. Automated 3D Breast Ultrasound (ABUS) is a newer approach for breast screening, which has many advantages over handheld mammography such as safety, speed, and higher detection rate of breast cancer. Tumor detection, segmentation, and classification are key components in the analysis of medical images, especially challenging in the context of 3D ABUS due to the significant variability in tumor size and shape, unclear tumor boundaries, and a low signal-to-noise ratio. The lack of publicly accessible, well-labeled ABUS datasets further hinders the advancement of systems for breast tumor analysis. Addressing this gap, we have organized the inaugural Tumor Detection, Segmentation, and Classification Challenge on Automated 3D Breast Ultrasound 2023 (TDSC-ABUS2023). This initiative aims to spearhead research in this field and create a definitive benchmark for tasks associated with 3D ABUS image analysis. In this paper, we summarize the top-performing algorithms from the challenge and provide critical analysis for ABUS image examination. We offer the TDSC-ABUS challenge as an open-access platform at this https URL to benchmark and inspire future developments in algorithmic research.

Paper number 44:
Title: Radiologist-in-the-Loop Self-Training for Generalizable CT Metal Artifact Reduction
Authors: Chenglong Ma, Zilong Li, Yuanlin Li, Jing Han, Junping Zhang, Yi Zhang, Jiannan Liu, Hongming Shan
Abstract: Metal artifacts in computed tomography (CT) images can significantly degrade image quality and impede accurate diagnosis. Supervised metal artifact reduction (MAR) methods, trained using simulated datasets, often struggle to perform well on real clinical CT images due to a substantial domain gap. Although state-of-the-art semi-supervised methods use pseudo ground-truths generated by a prior network to mitigate this issue, their reliance on a fixed prior limits both the quality and quantity of these pseudo ground-truths, introducing confirmation bias and reducing clinical applicability. To address these limitations, we propose a novel Radiologist-In-the-loop SElf-training framework for MAR, termed RISE-MAR, which can integrate radiologists' feedback into the semi-supervised learning process, progressively improving the quality and quantity of pseudo ground-truths for enhanced generalization on real clinical CT images. For quality assurance, we introduce a clinical quality assessor model that emulates radiologist evaluations, effectively selecting high-quality pseudo ground-truths for semi-supervised training. For quantity assurance, our self-training framework iteratively generates additional high-quality pseudo ground-truths, expanding the clinical dataset and further improving model generalization. Extensive experimental results on multiple clinical datasets demonstrate the superior generalization performance of our RISE-MAR over state-of-the-art methods, advancing the development of MAR models for practical application. Code is available at this https URL.

Paper number 45:
Title: Nuisance-free Automatic Ground Collision Avoidance System Design: Merging Exponential-CBF and Adaptive Sliding Manifolds
Authors: Ege C. Altunkaya, Ibrahim Ozkol
Abstract: The significance of the automatic ground collision avoidance system (Auto-GCAS) has been proven by considering the fatal crashes that have occurred over decades. Even though extensive efforts have been put forth to address the ground collision avoidance in the literature, the notion of being nuisance-free has not been sufficiently addressed. At this point, in this study, the Auto-GCAS design is formulated by merging exponential control barrier functions with sliding manifolds to manipulate the barrier function dynamics. The adaptive properties of the sliding manifolds are tailored to the key and governing flight parameters, ensuring that the nuisance-free requirement is satisfied. Furthermore, to ensure all safety requirements are met, a flight envelope protection algorithm is designed using control barrier functions to assess the commands generated by the Auto-GCAS. Eventually, the performance of the proposed methodology is demonstrated, focusing on authority-sharing, collision avoidance capability, and nuisance-free operation through various scenarios and Monte Carlo simulations.

Paper number 46:
Title: SeqSeg: Learning Local Segments for Automatic Vascular Model Construction
Authors: Numi Sveinsson Cepero, Shawn C. Shadden
Abstract: Computational modeling of cardiovascular function has become a critical part of diagnosing, treating and understanding cardiovascular disease. Most strategies involve constructing anatomically accurate computer models of cardiovascular structures, which is a multistep, time-consuming process. To improve the model generation process, we herein present SeqSeg (sequential segmentation): a novel deep learning based automatic tracing and segmentation algorithm for constructing image-based vascular models. SeqSeg leverages local U-Net-based inference to sequentially segment vascular structures from medical image volumes. We tested SeqSeg on CT and MR images of aortic and aortofemoral models and compared the predictions to those of benchmark 2D and 3D global nnU-Net models, which have previously shown excellent accuracy for medical image segmentation. We demonstrate that SeqSeg is able to segment more complete vasculature and is able to generalize to vascular structures not annotated in the training data.

Paper number 47:
Title: Leveraging Video Vision Transformer for Alzheimer's Disease Diagnosis from 3D Brain MRI
Authors: Taymaz Akan, Sait Alp, Md. Shenuarin Bhuiyan, Elizabeth A. Disbrow, Steven A. Conrad, John A. Vanchiere, Christopher G. Kevil, Mohammad A. N. Bhuiyan
Abstract: Alzheimer's disease (AD) is a neurodegenerative disorder affecting millions worldwide, necessitating early and accurate diagnosis for optimal patient management. In recent years, advancements in deep learning have shown remarkable potential in medical image analysis. Methods In this study, we present "ViTranZheimer," an AD diagnosis approach which leverages video vision transformers to analyze 3D brain MRI data. By treating the 3D MRI volumes as videos, we exploit the temporal dependencies between slices to capture intricate structural relationships. The video vision transformer's self-attention mechanisms enable the model to learn long-range dependencies and identify subtle patterns that may indicate AD progression. Our proposed deep learning framework seeks to enhance the accuracy and sensitivity of AD diagnosis, empowering clinicians with a tool for early detection and intervention. We validate the performance of the video vision transformer using the ADNI dataset and conduct comparative analyses with other relevant models. Results The proposed ViTranZheimer model is compared with two hybrid models, CNN-BiLSTM and ViT-BiLSTM. CNN-BiLSTM is the combination of a convolutional neural network (CNN) and a bidirectional long-short-term memory network (BiLSTM), while ViT-BiLSTM is the combination of a vision transformer (ViT) with BiLSTM. The accuracy levels achieved in the ViTranZheimer, CNN-BiLSTM, and ViT-BiLSTM models are 98.6%, 96.479%, and 97.465%, respectively. ViTranZheimer demonstrated the highest accuracy at 98.6%, outperforming other models in this evaluation metric, indicating its superior performance in this specific evaluation metric. Conclusion This research advances the understanding of applying deep learning techniques in neuroimaging and Alzheimer's disease research, paving the way for earlier and less invasive clinical diagnosis.

Paper number 48:
Title: Geometric Deep Learning for Automated Landmarking of Maxillary Arches on 3D Oral Scans from Newborns with Cleft Lip and Palate
Authors: Artur Agaronyan, HyeRan Choo, Marius Linguraru, Syed Muhammad Anwar
Abstract: Rapid advances in 3D model scanning have enabled the mass digitization of dental clay models. However, most clinicians and researchers continue to use manual morphometric analysis methods on these models such as landmarking. This is a significant step in treatment planning for craniomaxillofacial conditions. We aimed to develop and test a geometric deep learning model that would accurately and reliably label landmarks on a complicated and specialized patient population -- infants, as accurately as a human specialist without a large amount of training data. Our developed pipeline demonstrated an accuracy of 94.44% with an absolute mean error of 1.676 +/- 0.959 mm on a set of 100 models acquired from newborn babies with cleft lip and palate. Our proposed pipeline has the potential to serve as a fast, accurate, and reliable quantifier of maxillary arch morphometric features, as well as an integral step towards a future fully automated dental treatment pipeline.

Paper number 49:
Title: Intuition and importance of feedback control through laboratory experiences
Authors: Aldo Jonathan Munoz-Vazquez
Abstract: This work aims to raise awareness among engineering students from different disciplines on the importance of feedback control. The proposal consists in comparing the performance of different control strategies in a laboratory session, considering Matlab/Simulink simulations of the non-linear pendulum model. First, students attempt to make the pendulum stop at unstable equilibrium by controlling the torque input with a joystick connected to the computer via an Arduino board. Different friction scenarios are considered for students to explore the dissipation in the system response. Then, as a second task, the Arduino is used to introduce the position reference, while students implement different control strategies, such as Bang-Bang, PID (proportional-integral-derivative) and FPID (fractional PID) controllers, analyzing the system response by inspecting the signals in a scope and in a 3D animated model. The dynamic model results as an application of the laws of rotational motion, and the control methods are explained from an intuitive point of view, focusing on the meaning and motivation of the control actions, with the intention to develop intuition about PID and FPID control methods.

Paper number 50:
Title: Z-Stack Scanning can Improve AI Detection of Mitosis: A Case Study of Meningiomas
Authors: Hongyan Gu, Ellie Onstott, Wenzhong Yan, Tengyou Xu, Ruolin Wang, Zida Wu, Xiang 'Anthony' Chen, Mohammad Haeri
Abstract: Z-stack scanning is an emerging whole slide imaging technology that captures multiple focal planes alongside the z-axis of a glass slide. Because z-stacking can offer enhanced depth information compared to the single-layer whole slide imaging, this technology can be particularly useful in analyzing small-scaled histopathological patterns. However, its actual clinical impact remains debated with mixed results. To clarify this, we investigate the effect of z-stack scanning on artificial intelligence (AI) mitosis detection of meningiomas. With the same set of 22 Hematoxylin and Eosin meningioma glass slides scanned by three different digital pathology scanners, we tested the performance of three AI pipelines on both single-layer and z-stacked whole slide images (WSIs). Results showed that in all scanner-AI combinations, z-stacked WSIs significantly increased AI's sensitivity (+17.14%) on the mitosis detection with only a marginal impact on precision. Our findings provide quantitative evidence that highlights z-stack scanning as a promising technique for AI mitosis detection, paving the way for more reliable AI-assisted pathology workflows, which can ultimately benefit patient management.

Paper number 51:
Title: Noise disturbance and lack of privacy: Modeling acoustic dissatisfaction in open-plan offices
Authors: Manuj Yadav, Jungsoo Kim, Valtteri Hongisto, Densil Cabrera, Richard de Dear
Abstract: Open-plan offices are well-known to be adversely affected by acoustic issues. This study aims to model acoustic dissatisfaction using measurements of room acoustics, sound environment during occupancy, and occupant surveys (n = 349) in 28 offices representing a diverse range of workplace parameters. As latent factors, the contribution of $\textit{lack of privacy}$ (LackPriv) was 25% higher than $\textit{noise disturbance}$ (NseDstrb) in predicting $\textit{acoustic dissatisfaction}$ (AcDsat). Room acoustic metrics based on sound pressure level (SPL) decay of speech ($L_{\text{p,A,s,4m}}$ and $r_{\text{C}}$) were better in predicting these factors than distraction distance ($r_{\text{D}}$) based on speech transmission index. This contradicts previous findings, and the trends for SPL-based metrics in predicting AcDsat and LackPriv go against expectations based on ISO 3382-3. For sound during occupation, $L_{\text{A,90}}$ and psychoacoustic loudness ($N_{\text{90}}$) predicted AcDsat, and a SPL fluctuation metric ($M_{\text{A,eq}}$) predicted LackPriv. However, these metrics were weaker predictors than ISO 3382-3 metrics. Medium-sized offices exhibited higher dissatisfaction than larger ($\geq$50 occupants) offices. Dissatisfaction varied substantially across parameters including ceiling heights, number of workstations, and years of work, but not between offices with fixed seating compared to more flexible and activity-based working configurations. Overall, these findings highlight the complexities in characterizing occupants' perceptions using instrumental acoustic measurements.

Paper number 52:
Title: Introducing RIFT: A Hierarchical Entropic Filtering Scheme for Ideal Time-Frequency Reconstruction
Authors: James M. Cozens, Simon J. Godsill
Abstract: In this paper, we introduce the Reconstructive Ideal Fractional Transform (RIFT), an entropy-based probabilistic filtering algorithm formulated to reconstruct the Ideal Time-Frequency Representation (ITFR). RIFT surpasses the limitations imposed by the Gabor uncertainty principle for linear transforms, achieving the bilinear transform accuracy present in the Wigner-Ville Distribution (WVD) while effectively suppressing cross-terms. The algorithm utilises a hierarchical fractional wavelet-based scheme to account for localised time-frequency trajectory curvature. This scheme is optimised through an entropic-based filtering method that probabilistically extracts auto-terms while retaining the resolution of the WVD. This is achieved by employing a spatially varying, positively constrained deconvolution algorithm (Lucy-Richardson) with regularisation for adequate noise suppression. Additionally, the optimisation yields an Instantaneous Phase Direction field, which allows the localised curvature in speech or music extracts to be visualised and utilised within a Kalman tracking scheme, enabling the extraction of signal component trajectories. Evaluation demonstrates the algorithm's ability to eradicate cross-terms effectively and achieve superior time-frequency precision. This advance holds significant potential for a wide range of applications requiring high-resolution cross-term-free time-frequency analysis.

Paper number 53:
Title: FuzzyLight: A Robust Two-Stage Fuzzy Approach for Traffic Signal Control Works in Real Cities
Authors: Mingyuan Li, Jiahao Wang, Bo Du, Jun Shen, Qiang Wu
Abstract: Effective traffic signal control (TSC) is crucial in mitigating urban congestion and reducing emissions. Recently, reinforcement learning (RL) has been the research trend for TSC. However, existing RL algorithms face several real-world challenges that hinder their practical deployment in TSC: (1) Sensor accuracy deteriorates with increased sensor detection range, and data transmission is prone to noise, potentially resulting in unsafe TSC decisions. (2) During the training of online RL, interactions with the environment could be unstable, potentially leading to inappropriate traffic signal phase (TSP) selection and traffic congestion. (3) Most current TSC algorithms focus only on TSP decisions, overlooking the critical aspect of phase duration, affecting safety and efficiency. To overcome these challenges, we propose a robust two-stage fuzzy approach called FuzzyLight, which integrates compressed sensing and RL for TSC deployment. FuzzyLight offers several key contributions: (1) It employs fuzzy logic and compressed sensing to address sensor noise and enhances the efficiency of TSP decisions. (2) It maintains stable performance during training and combines fuzzy logic with RL to generate precise phases. (3) It works in real cities across 22 intersections and demonstrates superior performance in both real-world and simulated environments. Experimental results indicate that FuzzyLight enhances traffic efficiency by 48% compared to expert-designed timings in the real world. Furthermore, it achieves state-of-the-art (SOTA) performance in simulated environments using six real-world datasets with transmission noise. The code and deployment video are available at the URL1

Paper number 54:
Title: Pfungst and Clever Hans: Identifying the unintended cues in a widely used Alzheimer's disease MRI dataset using explainable deep learning
Authors: Christian Tinauer, Maximilian Sackl, Rudolf Stollberger, Stefan Ropele, Christian Langkammer
Abstract: Backgrounds. Deep neural networks have demonstrated high accuracy in classifying Alzheimer's disease (AD). This study aims to enlighten the underlying black-box nature and reveal individual contributions of T1-weighted (T1w) gray-white matter texture, volumetric information and preprocessing on classification performance. Methods. We utilized T1w MRI data from the Alzheimer's Disease Neuroimaging Initiative to distinguish matched AD patients (990 MRIs) from healthy controls (990 MRIs). Preprocessing included skull stripping and binarization at varying thresholds to systematically eliminate texture information. A deep neural network was trained on these configurations, and the model performance was compared using McNemar tests with discrete Bonferroni-Holm correction. Layer-wise Relevance Propagation (LRP) and structural similarity metrics between heatmaps were applied to analyze learned features. Results. Classification performance metrics (accuracy, sensitivity, and specificity) were comparable across all configurations, indicating a negligible influence of T1w gray- and white signal texture. Models trained on binarized images demonstrated similar feature performance and relevance distributions, with volumetric features such as atrophy and skull-stripping features emerging as primary contributors. Conclusions. We revealed a previously undiscovered Clever Hans effect in a widely used AD MRI dataset. Deep neural networks classification predominantly rely on volumetric features, while eliminating gray-white matter T1w texture did not decrease the performance. This study clearly demonstrates an overestimation of the importance of gray-white matter contrasts, at least for widely used structural T1w images, and highlights potential misinterpretation of performance metrics.

Paper number 55:
Title: Mode Switching-Induced Instability of Multi-source Feed DC Microgrid
Authors: Shanshan Jiang, Zelin Sun, Jiankun Zhang, Hua Geng
Abstract: In DC microgrids (DCMGs), DC-bus signaling based control strategy is extensively used for power management, where mode switching plays a crucial role in achieving multi-source coordination. However, few studies have noticed the impact of mode switching and switching strategies on system voltage stability. To fill this gap, this paper aims to provide a general analysis framework for mode switching-induced instability in multi-source DCMGs. First, manifold theory is employed to analyze the stability of the DCMG switched system. Subsequently, the instability mechanism and its physical interpretation are explored. The positive feedback activated by the decreasing DC bus voltage during the switching process leads to instability. Switching strategy may inadvertently contribute to this instability. To improve stability, a novel control method based on mode scheduling is proposed, by adjusting switching strategy and thereby correcting the system trajectory. Finally, both real-time simulations and experimental tests on a DCMG system verify the correctness and effectiveness of theoretical analysis results.

Paper number 56:
Title: Gaussian Process-Based Prediction and Control of Hammerstein-Wiener Systems
Authors: Mingzhou Yin, Matthias A. Müller
Abstract: This work investigates data-driven prediction and control of Hammerstein-Wiener systems using physics-informed Gaussian process models. Data-driven prediction algorithms have been developed for structured nonlinear systems based on Willems' fundamental lemma. However, existing frameworks cannot treat output nonlinearities and require a dictionary of basis functions for Hammerstein systems. In this work, an implicit predictor structure is considered, leveraging the multi-step-ahead ARX structure for the linear part of the model. This implicit function is learned by Gaussian process regression with kernel functions designed from Gaussian process priors for the nonlinearities. The linear model parameters are estimated as hyperparameters by assuming a stable spline hyperprior. The implicit Gaussian process model provides explicit output prediction by optimizing selected optimality criteria. The model is also applied to receding horizon control with the expected control cost and chance constraint satisfaction guarantee. Numerical results demonstrate that the proposed prediction and control algorithms are superior to black-box Gaussian process models.

Paper number 57:
Title: One-Bit Sigma-Delta DFRC Waveform Design: Using Quantization Noise for Radar Probing
Authors: Wai-Yiu Keung, Hei Victor Cheng, Wing-Kin Ma
Abstract: Dual-functional radar-communication (DFRC) signal design has received much attention lately. We consider the scenario of one-bit massive multi-input multi-output (MIMO) wherein one-bit DACs are employed for the sake of saving hardware costs. Specifically, a spatial Sigma-Delta $(\Sigma\Delta)$ modulation scheme is proposed for one-bit MIMO-DFRC waveform design. Unlike the existing approaches which require large-scale binary optimization, the proposed scheme performs $\Sigma\Delta$ modulation on a continuous-valued DFRC signal. The subsequent waveform design is formulated as a constrained least square problem, which can be efficiently solved. Moreover, we leverage quantization noise for radar probing purposes, rather than treating it as unwanted noise. Numerical results demonstrate that the proposed scheme performs well in both radar probing and downlink precoding.

Paper number 58:
Title: MPC4RL -- A Software Package for Reinforcement Learning based on Model Predictive Control
Authors: Dirk Reinhardt, Katrin Baumgärnter, Jonathan Frey, Moritz Diehl, Sebastien Gros
Abstract: In this paper, we present an early software integrating Reinforcement Learning (RL) with Model Predictive Control (MPC). Our aim is to make recent theoretical contributions from the literature more accessible to both the RL and MPC communities. We combine standard software tools developed by the RL community, such as Gymnasium, stable-baselines3, or CleanRL with the acados toolbox, a widely-used software package for efficient MPC algorithms. Our core contribution is MPC4RL, an open-source Python package that supports learning-enhanced MPC schemes for existing acados implementations. The package is designed to be modular, extensible, and user-friendly, facilitating the tuning of MPC algorithms for a broad range of control problems. It is available on GitHub.

Paper number 59:
Title: Asynchronous distributed collision avoidance with intention consensus for inland autonomous ships
Authors: Hoang Anh Tran, Nikolai Lauvås, Tor Arne Johansen, Rudy R. Negenborn
Abstract: This paper focuses on the problem of collaborative collision avoidance for autonomous inland ships. Two solutions are provided to solve the problem in a distributed manner. We first present a distributed model predictive control (MPC) algorithm that allows ships to directly negotiate their intention to avoid collision in a synchronous communication framework. Moreover, we introduce a new approach to shape the ship's behavior to follow the waterway traffic regulations. The conditional convergence toward a stationary solution of this algorithm is guaranteed by the theory of the Alternating Direction Method of Multipliers (ADMM). To overcome the problem of asynchronous communication between ships, we adopt a new asynchronous nonlinear ADMM and present an asynchronous distributed MPC algorithm based on it. Several simulations and field experiments show that the proposed algorithms can prevent ship collisions even in complex scenarios.

Paper number 60:
Title: Stabilization of an unstable reaction-diffusion PDE with input delay despite state and input quantization
Authors: Florent Koudohode, Nikolaos Bekiaris-Liberis
Abstract: We solve the global asymptotic stability problem of an unstable reaction-diffusion Partial Differential Equation (PDE) subject to input delay and state quantization developing a switched predictor-feedback law. To deal with the input delay, we reformulate the problem as an actuated transport PDE coupled with the original reaction-diffusion PDE. Then, we design a quantized predictor-based feedback mechanism that employs a dynamic switching strategy to adjust the quantization range and error over time. The stability of the closed-loop system is proven properly combining backstepping with a small-gain approach and input-to-state stability techniques, for deriving estimates on solutions, despite the quantization effect and the system's instability. We also extend this result to the input quantization case.

Paper number 61:
Title: Superimposed Pilot-Based OTFS -- Will it Work?
Authors: Yuta Kanazawa, Hiroki Iimori, Chandan Pradhan, Szabolcs Malomsoky, Naoki Ishikawa
Abstract: Orthogonal time frequency space (OTFS) modulation is a promising solution to handle doubly-selective fading, but its channel estimation is a nontrivial task in terms of maximizing spectral efficiency. Conventional pilot assignment approaches face challenges: the standard embedded pilot-based scheme suffers from low transmission rates, and the single superimposed pilot (SP)-based scheme experiences inevitable data-pilot interference, leading to coarse channel estimation. To cope with this issue, focusing on the SP-based OTFS system in channel coded scenarios, we propose a novel pilot assignment scheme and an iterative algorithm. The proposed scheme allocates multiple SPs per frame to estimate channel coefficients accurately. Furthermore, the proposed algorithm performs refined interference cancellation, utilizing a replica of data symbols generated from soft-decision outputs provided by a decoder. Assuming fair and unified conditions, we evaluate each pilot assignment scheme in terms of reliability, channel estimation accuracy, effective throughput, and computational complexity. Our numerical simulations demonstrate that the multiple SP-based scheme, which balances the transmission rate and the interference cancellation performance, has the best throughput at the expense of slightly increased complexity. In addition, we confirm that the multiple SP-based scheme achieves further improved throughput due to the proposed interference cancellation algorithm.

Paper number 62:
Title: Compensation based Dictionary Transfer for Similar Multispectral Image Spectral Super-resolution
Authors: Xiaolin Han, Huan Zhang, Lijuan Niu, Weidong Sun
Abstract: Utilizing a spectral dictionary learned from a couple of similar-scene multi- and hyperspectral image, it is possible to reconstruct a desired hyperspectral image only with one single multispectral image. However, the differences between the similar scene and the desired hyperspectral image make it difficult to directly apply the spectral dictionary from the training domain to the task domain. To this end, a compensation matrix based dictionary transfer method for the similar-scene multispectral image spectral super-resolution is proposed in this paper, trying to reconstruct a more accurate high spatial resolution hyperspectral image. Specifically, a spectral dictionary transfer scheme is established by using a compensation matrix with similarity constraint, to transfer the spectral dictionary learned in the training domain to the spectral super-resolution domain. Subsequently, the sparse coefficient matrix is optimized under sparse and low-rank constraints. Experimental results on two AVIRIS datasets from different scenes indicate that, the proposed method outperforms other related SOTA methods.

Paper number 63:
Title: Impact of Lead Time on Aggregate EV Flexibility for Congestion Management Services
Authors: Nanda Kishor Panda, Peter Palensky, Simon H. Tindemans
Abstract: Increased electrification of energy end-usage can lead to network congestion during periods of high consumption. Flexibility of loads, such as aggregate smart charging of Electric Vehicles (EVs), is increasingly leveraged to manage grid congestion through various market-based mechanisms. Under such an arrangement, this paper quantifies the effect of lead time on the aggregate flexibility of EV fleets. Simulations using real-world charging transactions spanning over different categories of charging stations are performed for two flexibility products (redispatch and capacity limitations) when offered along with different business-as-usual (BAU) schedules. Results show that the variation of tradable flexibility depends mainly on the BAU schedules, the duration of the requested flexibility, and its start time. Further, the implication of these flexibility products on the average energy costs and emissions is also studied for different cases. Simulations show that bidirectional (V2G) charging outperforms unidirectional smart charging in all cases.

Paper number 64:
Title: EDSep: An Effective Diffusion-Based Method for Speech Source Separation
Authors: Jinwei Dong, Xinsheng Wang, Qirong Mao
Abstract: Generative models have attracted considerable attention for speech separation tasks, and among these, diffusion-based methods are being explored. Despite the notable success of diffusion techniques in generation tasks, their adaptation to speech separation has encountered challenges, notably slow convergence and suboptimal separation outcomes. To address these issues and enhance the efficacy of diffusion-based speech separation, we introduce EDSep, a novel single-channel method grounded in score matching via stochastic differential equation (SDE). This method enhances generative modeling for speech source separation by optimizing training and sampling efficiency. Specifically, a novel denoiser function is proposed to approximate data distributions, which obtains ideal denoiser outputs. Additionally, a stochastic sampler is carefully designed to resolve the reverse SDE during the sampling process, gradually separating speech from mixtures. Extensive experiments on databases such as WSJ0-2mix, LRS2-2mix, and VoxCeleb2-2mix demonstrate our proposed method's superior performance over existing diffusion and discriminative models, validating its efficacy.

Paper number 65:
Title: Real-Time Brain Tumor Detection in Intraoperative Ultrasound Using YOLO11: From Model Training to Deployment in the Operating Room
Authors: Santiago Cepeda, Olga Esteban-Sinovas, Roberto Romero, Vikas Singh, Prakash Shetty, Aliasgar Moiyadi, Ilyess Zemmoura, Giuseppe Roberto Giammalva, Massimiliano Del Bene, Arianna Barbotti, Francesco DiMeco, Timothy R. West, Brian V. Nahed, Ignacio Arrese, Roberto Hornero, Rosario Sarabia
Abstract: Intraoperative ultrasound (ioUS) is a valuable tool in brain tumor surgery due to its versatility, affordability, and seamless integration into the surgical workflow. However, its adoption remains limited, primarily because of the challenges associated with image interpretation and the steep learning curve required for effective use. This study aimed to enhance the interpretability of ioUS images by developing a real-time brain tumor detection system deployable in the operating room. We collected 2D ioUS images from the Brain Tumor Intraoperative Database (BraTioUS) and the public ReMIND dataset, annotated with expert-refined tumor labels. Using the YOLO11 architecture and its variants, we trained object detection models to identify brain tumors. The dataset included 1,732 images from 192 patients, divided into training, validation, and test sets. Data augmentation expanded the training set to 11,570 images. In the test dataset, YOLO11s achieved the best balance of precision and computational efficiency, with a mAP@50 of 0.95, mAP@50-95 of 0.65, and a processing speed of 34.16 frames per second. The proposed solution was prospectively validated in a cohort of 15 consecutively operated patients diagnosed with brain tumors. Neurosurgeons confirmed its seamless integration into the surgical workflow, with real-time predictions accurately delineating tumor regions. These findings highlight the potential of real-time object detection algorithms to enhance ioUS-guided brain tumor surgery, addressing key challenges in interpretation and providing a foundation for future development of computer vision-based tools for neuro-oncological surgery.

Paper number 66:
Title: Spatial-Angular Representation Learning for High-Fidelity Continuous Super-Resolution in Diffusion MRI
Authors: Ruoyou Wu, Jian Cheng, Cheng Li, Juan Zou, Wenxin Fan, Hua Guo, Yong Liang, Shanshan Wang
Abstract: Diffusion magnetic resonance imaging (dMRI) often suffers from low spatial and angular resolution due to inherent limitations in imaging hardware and system noise, adversely affecting the accurate estimation of microstructural parameters with fine anatomical details. Deep learning-based super-resolution techniques have shown promise in enhancing dMRI resolution without increasing acquisition time. However, most existing methods are confined to either spatial or angular super-resolution, limiting their effectiveness in capturing detailed microstructural features. Furthermore, traditional pixel-wise loss functions struggle to recover intricate image details essential for high-resolution reconstruction. To address these challenges, we propose SARL-dMRI, a novel Spatial-Angular Representation Learning framework for high-fidelity, continuous super-resolution in dMRI. SARL-dMRI explores implicit neural representations and spherical harmonics to model continuous spatial and angular representations, simultaneously enhancing both spatial and angular resolution while improving microstructural parameter estimation accuracy. To further preserve image fidelity, a data-fidelity module and wavelet-based frequency loss are introduced, ensuring the super-resolved images remain consistent with the original input and retain fine details. Extensive experiments demonstrate that, compared to five other state-of-the-art methods, our method significantly enhances dMRI data resolution, improves the accuracy of microstructural parameter estimation, and provides better generalization capabilities. It maintains stable performance even under a 45$\times$ downsampling factor.

Paper number 67:
Title: BMAR: Barometric and Motion-based Alignment and Refinement for Offline Signal Synchronization across Devices
Authors: Manuel Meier, Christian Holz
Abstract: A requirement of cross-modal signal processing is accurate signal alignment. Though simple on a single device, accurate signal synchronization becomes challenging as soon as multiple devices are involved, such as during activity monitoring, health tracking, or motion capture - particularly outside controlled scenarios where data collection must be standalone, low-power, and support long runtimes. In this paper, we present BMAR, a novel synchronization method that operates purely based on recorded signals and is thus suitable for offline processing. BMAR needs no wireless communication between devices during runtime and does not require any specific user input, action, or behavior. BMAR operates on the data from devices worn by the same person that record barometric pressure and acceleration - inexpensive, low-power, and thus commonly included sensors in today's wearable devices. In its first stage, BMAR verifies that two recordings were acquired simultaneously and pre-aligns all data traces. In a second stage, BMAR refines the alignment using acceleration measurements while accounting for clock skew between devices. In our evaluation, three to five body-worn devices recorded signals from the wearer for up to ten hours during a series of activities. BMAR synchronized all signal recordings with a median error of 33.4 ms and reliably rejected non-overlapping signal traces. The worst-case activity was sleeping, where BMAR's second stage could not exploit motion for refinement and, thus, aligned traces with a median error of 3.06 s.

Paper number 68:
Title: TransPathNet: A Novel Two-Stage Framework for Indoor Radio Map Prediction
Authors: Xin Li, Ran Liu, Saihua Xu, Sirajudeen Gulam Razul, Chau Yuen
Abstract: Accurate indoor pathloss prediction is crucial for optimizing wireless communication in indoor settings, where diverse materials and complex electromagnetic interactions pose significant modeling challenges. This paper introduces TransPathNet, a novel two-stage deep learning framework that leverages transformer-based feature extraction and multiscale convolutional attention decoding to generate high-precision indoor radio pathloss maps. TransPathNet demonstrates state-of-the-art performance in the ICASSP 2025 Indoor Pathloss Radio Map Prediction Challenge, achieving an overall Root Mean Squared Error (RMSE) of 10.397 dB on the challenge full test set and 9.73 dB on the challenge Kaggle test set, showing excellent generalization capabilities across different indoor geometries, frequencies, and antenna patterns. Our project page, including the associated code, is available at this https URL.

Paper number 69:
Title: Graphene-Assisted Chemical Stabilization of Liquid Metal Nano Droplets for Liquid Metal Based Energy Storage
Authors: Afsaneh L. Sanati, Timur Nikitin, Rui Fausto, Carmel Majidi, Mahmoud Tavakoli
Abstract: Energy storage devices with liquid_metal electrodes have attracted interest in recent years due to their potential for mechanical resilience, self_healing, dendrite_free operation, and fast reaction kinetics. Gallium alloys like Eutectic Gallium Indium (EGaIn) are appealing due to their low melting point and high theoretical specific capacity. However, EGaIn electrodes are unstable in highly alkaline electrolytes due to Gallium oxide dissolution. In this letter, this bottleneck is addressed by introducing chemically stable films in which nanoscale droplets of EGaIn are coated with trace amounts of graphene oxide (GO). It is demonstrated that a GO to EGaIn weight ratio as low as 0.01 provides enough protection for a thin film formed by GO EGaIn nanocomposite against significantly acidic or alkaline environments (pH 1-14). It is shown that GO coating significantly enhances the surface stability in such environments, thus improving the energy storage capacity by over 10x. Microstructural analysis confirms GO EGaIn composite stability and enhanced electrochemical performance. Utilizing this, a thin film supercapacitor is fabricated. Results indicate that when coating the EGaIn with GO to EGaIn ratio of 0.001 the areal capacitance improves by 10 times, reaching 20.02 mF cm_2. This breakthrough paves the way for advanced liquid metal-based thin film electrodes, promising significant improvements in energy storage applications.

Paper number 70:
Title: A Dynamic Similarity Index for Assessing Voltage Source Behaviour in Power Systems
Authors: Onur Alican, Dionysios Moutevelis, Josep Arevalo-Soler, Carlos Collados-Rodriguez, Jaume Amoros-Torrent, Oriol Gomis-Bellmunt, Marc Cheah-Mane, Eduardo Prieto-Araujo
Abstract: Due to the fundamental transition to a power electronic dominated power system, the increasing diversity of dynamic elements underscores the need to assess their similarity to mature electrical engineering models. This article addresses the concept of the Dynamic Similarity Index (DSI) for its use in, power electronics-dominated networks. The DSI is a multipurpose tool developed to be used by different stakeholders (e.g., converter manufacturers and system operators). Such an index is calculated per frequency, which serves to anticipate potential differences in particular frequency ranges of interest between the model under study and the reference model. Within the scope of this study, the dynamic similarity of inverter-based generators to an ideal voltage source behind an impedance is assessed, due to the relevance of this fundamental circuit in the representation of generation units in power system studies. The article presents two potential applications based on this mathematical framework. First, for manufacturers to evaluate control performance compared to a reference model and second, it enables operators to diagnose buses with voltage vulnerability based on a user-defined reference Short-Circuit Ratio (SCR) value. The DSI results for these two case studies are validated using Matlab Simulink simulations.

Paper number 71:
Title: Separate This, and All of these Things Around It: Music Source Separation via Hyperellipsoidal Queries
Authors: Karn N. Watcharasupat, Alexander Lerch
Abstract: Music source separation is an audio-to-audio retrieval task of extracting one or more constituent components, or composites thereof, from a musical audio mixture. Each of these constituent components is often referred to as a "stem" in literature. Historically, music source separation has been dominated by a stem-based paradigm, leading to most state-of-the-art systems being either a collection of single-stem extraction models, or a tightly coupled system with a fixed, difficult-to-modify, set of supported stems. Combined with the limited data availability, advances in music source separation have thus been mostly limited to the "VDBO" set of stems: \textit{vocals}, \textit{drum}, \textit{bass}, and the catch-all \textit{others}. Recent work in music source separation has begun to challenge the fixed-stem paradigm, moving towards models able to extract any musical sound as long as this target type of sound could be specified to the model as an additional query input. We generalize this idea to a \textit{query-by-region} source separation system, specifying the target based on the query regardless of how many sound sources or which sound classes are contained within it. To do so, we propose the use of hyperellipsoidal regions as queries to allow for an intuitive yet easily parametrizable approach to specifying both the target (location) as well as its spread. Evaluation of the proposed system on the MoisesDB dataset demonstrated state-of-the-art performance of the proposed system both in terms of signal-to-noise ratios and retrieval metrics.

Paper number 72:
Title: Enhancing and Exploring Mild Cognitive Impairment Detection with W2V-BERT-2.0
Authors: Yueguan Wang, Tatsunari Matsushima, Soichiro Matsushima, Toshimitsu Sakai
Abstract: This study explores a multi-lingual audio self-supervised learning model for detecting mild cognitive impairment (MCI) using the TAUKADIAL cross-lingual dataset. While speech transcription-based detection with BERT models is effective, limitations exist due to a lack of transcriptions and temporal information. To address these issues, the study utilizes features directly from speech utterances with W2V-BERT-2.0. We propose a visualization method to detect essential layers of the model for MCI classification and design a specific inference logic considering the characteristics of MCI. The experiment shows competitive results, and the proposed inference logic significantly contributes to the improvements from the baseline. We also conduct detailed analysis which reveals the challenges related to speaker bias in the features and the sensitivity of MCI classification accuracy to the data split, providing valuable insights for future research.

Paper number 73:
Title: Convolutions with Radio-Frequency Spin-Diodes
Authors: Erwann Plouet, Hanuman Singh, Pankaj Sethi, Frank A. Mizrahi, Dedalo Sanz-Hernandez, Julie Grollier
Abstract: The classification of radio-frequency (RF) signals is crucial for applications in robotics, traffic control, and medical devices. Spintronic devices, which respond to RF signals via ferromagnetic resonance, offer a promising solution. Recent studies have shown that a neural network of nanoscale magnetic tunnel junctions can classify RF signals without digitization. However, the complexity of these junctions poses challenges for rapid scaling. In this work, we demonstrate that simple spintronic devices, known as metallic spin-diodes, can effectively perform RF classification. These devices consist of NiFe/Pt bilayers and can implement weighted sums of RF inputs. We experimentally show that chains of four spin-diodes can execute 2x2 pixel filters, achieving high-quality convolutions on the Fashion-MNIST dataset. Integrating the hardware spin-diodes in a software network, we achieve a top-1 accuracy of 88 \% on the first 100 images, compared to 88.4 \% for full software with noise, and 90 \% without noise.

Paper number 74:
Title: Lightweight Weighted Average Ensemble Model for Pneumonia Detection in Chest X-Ray Images
Authors: Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham
Abstract: Pneumonia is a leading cause of illness and death in children, underscoring the need for early and accurate detection. In this study, we propose a novel lightweight ensemble model for detecting pneumonia in children using chest X-ray images. This ensemble model integrates two pre-trained convolutional neural networks (CNNs), MobileNetV2 and NASNetMobile, selected for their balance of computational efficiency and accuracy. These models were fine-tuned on a pediatric chest X-ray dataset and combined to enhance classification performance. Our proposed ensemble model achieved a classification accuracy of 98.63%, significantly outperforming individual models such as MobileNetV2 (97.10%) and NASNetMobile(96.25%) in terms of accuracy, precision, recall, and F1 score. Moreover, the ensemble model outperformed state-of-the-art architectures, including ResNet50, InceptionV3, and DenseNet201, while maintaining computational efficiency. The proposed lightweight ensemble model presents a highly effective and resource-efficient solution for pneumonia detection, making it particularly suitable for deployment in resource-constrained settings.

Paper number 75:
Title: Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models
Authors: Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang, Tong Chen, Chao Cao, Yan Zhuang, Minheng Chen, Tianming Liu, Dajiang Zhu
Abstract: Understanding brain disorders is crucial for accurate clinical diagnosis and treatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a promising approach to interpreting medical images with the support of text descriptions. However, previous research has primarily focused on 2D medical images, leaving richer spatial information of 3D images under-explored, and single-modality-based methods are limited by overlooking the critical clinical information contained in other modalities. To address this issue, this paper proposes Brain-Adapter, a novel approach that incorporates an extra bottleneck layer to learn new knowledge and instill it into the original pre-trained knowledge. The major idea is to incorporate a lightweight bottleneck layer to train fewer parameters while capturing essential information and utilize a Contrastive Language-Image Pre-training (CLIP) strategy to align multimodal data within a unified representation space. Extensive experiments demonstrated the effectiveness of our approach in integrating multimodal data to significantly improve the diagnosis accuracy without high computational costs, highlighting the potential to enhance real-world diagnostic workflows.

Paper number 76:
Title: Graph Neural Network Based Hybrid Beamforming Design in Wideband Terahertz MIMO-OFDM Systems
Authors: Beier Li, Mai Vu
Abstract: 6G wireless technology is projected to adopt higher and wider frequency bands, enabled by highly directional beamforming. However, the vast bandwidths available also make the impact of beam squint in massive multiple input and multiple output (MIMO) systems non-negligible. Traditional approaches such as adding a true-time-delay line (TTD) on each antenna are costly due to the massive antenna arrays required. This paper puts forth a signal processing alternative, specifically adapted to the multicarrier structure of OFDM systems, through an innovative application of Graph Neural Networks (GNNs) to optimize hybrid beamforming. By integrating two types of graph nodes to represent the analog and the digital beamforming matrices efficiently, our approach not only reduces the computational and memory burdens but also achieves high spectral efficiency performance, approaching that of all digital beamforming. The GNN runtime and memory requirement are at a fraction of the processing time and resource consumption of traditional signal processing methods, hence enabling real-time adaptation of hybrid beamforming. Furthermore, the proposed GNN exhibits strong resiliency to beam squinting, achieving almost constant spectral efficiency even as the system bandwidth increases at higher carrier frequencies.

Paper number 77:
Title: Hybrid Cooperative Co-Evolution Algorithm for Deadlock-prone Distributed Assembly Flowshop Scheduling with Limited buffers Using Petri nets
Authors: Siyi Wang, Yanxiang Feng, Xiaoling Li, Guanghui Zhang, Yikang Yang
Abstract: The distributed assembly flowshop scheduling problem (DAFSP) can be applied to immense manufacturing environments. In DAFSP, jobs are first processed in distributed flowshops, and then assembled into final products by an assembly machine, which usually has limited buffers in practical application. This limited capacity can lead to deadlocks, halting job completion and blocking the entire manufacturing process. However, existing scheduling methods fail to address these deadlocks in DAFSP effectively. As such, we develop a hybrid cooperative co-evolution (HCCE) algorithm for solving the deadlock-prone DAFSP by minimizing the makespan. For the first time, we use Petri nets to analyze the deadlocks in DAFSP and propose a Petri net-based deadlock amending method (IDAM), which is further integrated into HCCE to ensure the feasibility (i.e., deadlock-freeness) of solutions. Importantly, HCCE contains an elite archive (EAR) and two subpopulations. It uses the problem-specific operators for heuristic initialization and global-search. To enhance the quality and diversity of solutions, an information transfer mechanism (ITM) is developed among subpopulation and EAR, and four local-search operators are performed sequentially on each individual in EAR. Finally, comprehensive experiments demonstrate the effectiveness and superiority of the proposed HCCE algorithm.

Paper number 78:
Title: Methods to Increase the Amount of Data for Speech Recognition for Low Resource Languages
Authors: Alexan Ayrapetyan, Sofia Kostandian, Ara Yeroyan, Mher Yerznkanyan, Nikolay Karpov, Nune Tadevosyan, Vitaly Lavrukhin, Boris Ginsburg
Abstract: This study explores methods to increase data volume for low-resource languages using techniques such as crowdsourcing, pseudo-labeling, advanced data preprocessing and various permissive data sources such as audiobooks, Common Voice, YouTube. While these methods are well-explored for highresource languages, their application for low-resource languages remains underexplored. Using Armenian and Georgian as case studies, we demonstrate how linguistic and resource-specific characteristics influence the success of these methods. This work provides practical guidance for researchers to choose cost-effective and quality-driven dataset extension strategies for low-resource languages. The key takeaway from various data extension approaches is that paid crowd-sourcing offers the best balance between cost and quality, outperforming volunteer crowd-sourcing, open-source audiobooks, and unlabeled data usage. Ablation study shows that models trained on the expanded datasets outperform existing baselines and achieve 5.73% for Gergian and 9.9% for Armenian ASR word error rate using a relatively small FastConformer architecture. We open-sourced both the Armenian and Georgian models to allow further research and practical applications.

Paper number 79:
Title: Towards Dynamic Neural Communication and Speech Neuroprosthesis Based on Viseme Decoding
Authors: Ji-Ha Park, Seo-Hyun Lee, Soowon Kim, Seong-Whan Lee
Abstract: Decoding text, speech, or images from human neural signals holds promising potential both as neuroprosthesis for patients and as innovative communication tools for general users. Although neural signals contain various information on speech intentions, movements, and phonetic details, generating informative outputs from them remains challenging, with mostly focusing on decoding short intentions or producing fragmented outputs. In this study, we developed a diffusion model-based framework to decode visual speech intentions from speech-related non-invasive brain signals, to facilitate face-to-face neural communication. We designed an experiment to consolidate various phonemes to train visemes of each phoneme, aiming to learn the representation of corresponding lip formations from neural signals. By decoding visemes from both isolated trials and continuous sentences, we successfully reconstructed coherent lip movements, effectively bridging the gap between brain signals and dynamic visual interfaces. The results highlight the potential of viseme decoding and talking face reconstruction from human neural signals, marking a significant step toward dynamic neural communication systems and speech neuroprosthesis for patients.

Paper number 80:
Title: A Deep-Unfolding-Optimized Coordinate-Descent Data-Detector ASIC for mmWave Massive MIMO
Authors: Zixiao Li, Seyed Hadi Mirfarshbafan, Oscar Castañeda, Christoph Studer
Abstract: We present a 22 nm FD-SOI (fully depleted silicon-on-insulator) application-specific integrated circuit (ASIC) implementation of a novel soft-output Gram-domain block coordinate descent (GBCD) data detector for massive multi-user (MU) multiple-input multiple-output (MIMO) systems. The ASIC simultaneously addresses the high throughput requirements for millimeter wave (mmWave) communication, stringent area and power budget per subcarrier in an orthogonal frequency-division multiplexing (OFDM) system, and error-rate performance challenges posed by realistic mmWave channels. The proposed GBCD algorithm utilizes a posterior mean estimate (PME) denoiser and is optimized using deep unfolding, which results in superior error-rate performance even in scenarios with highly correlated channels or where the number of user equipment (UE) data streams is comparable to the number of basestation (BS) antennas. The fabricated GBCD ASIC supports up to 16 UEs transmitting QPSK to 256-QAM symbols to a 128-antenna BS, and achieves a peak throughput of 7.1 Gbps at 367 mW. The core area is only 0.97 mm$^2$ thanks to a reconfigurable array of processing elements that enables extensive resource sharing. Measurement results demonstrate that the proposed GBCD data-detector ASIC achieves best-in-class throughput and area efficiency.

Paper number 81:
Title: Robust Cross-Etiology and Speaker-Independent Dysarthric Speech Recognition
Authors: Satwinder Singh, Qianli Wang, Zihan Zhong, Clarion Mendes, Mark Hasegawa-Johnson, Waleed Abdulla, Seyed Reza Shahamiri
Abstract: In this paper, we present a speaker-independent dysarthric speech recognition system, with a focus on evaluating the recently released Speech Accessibility Project (SAP-1005) dataset, which includes speech data from individuals with Parkinson's disease (PD). Despite the growing body of research in dysarthric speech recognition, many existing systems are speaker-dependent and adaptive, limiting their generalizability across different speakers and etiologies. Our primary objective is to develop a robust speaker-independent model capable of accurately recognizing dysarthric speech, irrespective of the speaker. Additionally, as a secondary objective, we aim to test the cross-etiology performance of our model by evaluating it on the TORGO dataset, which contains speech samples from individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS). By leveraging the Whisper model, our speaker-independent system achieved a CER of 6.99% and a WER of 10.71% on the SAP-1005 dataset. Further, in cross-etiology settings, we achieved a CER of 25.08% and a WER of 39.56% on the TORGO dataset. These results highlight the potential of our approach to generalize across unseen speakers and different etiologies of dysarthria.

Paper number 82:
Title: Stealthy Voice Eavesdropping with Acoustic Metamaterials: Unraveling a New Privacy Threat
Authors: Zhiyuan Ning, Zhanyong Tang, Juan He, Weizhi Meng, Yuntian Chen
Abstract: We present SuperEar, a novel privacy threat based on acoustic metamaterials. Unlike previous research, SuperEar can surreptitiously track and eavesdrop on the phone calls of a moving outdoor target from a safe distance. To design this attack, SuperEar overcomes the challenges faced by traditional acoustic metamaterials, including low low-frequency gain and audio distortion during reconstruction. It successfully magnifies the speech signal by approximately 20 times, allowing the sound to be captured from the earpiece of the target phone. In addition, SuperEar optimizes the trade-off between the number and size of acoustic metamaterials, improving the portability and concealability of the interceptor while ensuring effective interception performance. This makes it highly suitable for outdoor tracking and eavesdropping scenarios. Through extensive experimentation, we have evaluated SuperEar and our results show that it can achieve an eavesdropping accuracy of over 80% within a range of 4.5 meters in the aforementioned scenario, thus validating its great potential in real-world applications.

Paper number 83:
Title: Deep Reinforcement Learning for Energy Efficiency Maximization in RSMA-IRS-Assisted ISAC System
Authors: Zhangfeng Ma, Ruichen Zhang, Bo Ai, Zhuxian Lian, Linzhou Zeng, Dusit Niyato
Abstract: This paper proposes a three-dimensional (3D) geometry-based channel model to accurately represent intelligent reflecting surfaces (IRS)-enhanced integrated sensing and communication (ISAC) networks using rate-splitting multiple access (RSMA) in practical urban environments. Based on this model, we formulate an energy efficiency (EE) maximization problem that incorporates transceiver beamforming constraints, IRS phase adjustments, and quality-of-service (QoS) requirements to optimize communication and sensing functions. To solve this problem, we use the proximal policy optimization (PPO) algorithm within a deep reinforcement learning (DRL) framework. Our numerical results confirm the effectiveness of the proposed method in improving EE and satisfying QoS requirements. Additionally, we observe that system EE drops at higher frequencies, especially under double-Rayleigh fading.

Paper number 84:
Title: Efficient Video Neural Network Processing Based on Motion Estimation
Authors: Haichao Wang, Jiangtao Wen, Yuxing Han
Abstract: Video neural network (VNN) processing using the conventional pipeline first converts Bayer video information into human understandable RGB videos using image signal processing (ISP) on a pixel by pixel basis. Then, VNN processing is performed on a frame by frame basis. Both ISP and VNN are computationally expensive with high power consumption and latency. In this paper, we propose an efficient VNN processing framework. Instead of using ISP, computer vision tasks are directly accomplished using Bayer pattern information. To accelerate VNN processing, motion estimation is introduced to find temporal redundancies in input video data so as to avoid repeated and unnecessary computations. Experiments show greater than 67\% computation reduction, while maintaining computer vision task accuracy for typical computer vision tasks and data sets.

Paper number 85:
Title: UAV-Assisted MEC Architecture for Collaborative Task Offloading in Urban IoT Environment
Authors: Subhrajit Barick, Chetna Singhal
Abstract: Mobile edge computing (MEC) is a promising technology to meet the increasing demands and computing limitations of complex Internet of Things (IoT) devices. However, implementing MEC in urban environments can be challenging due to factors like high device density, complex infrastructure, and limited network coverage. Network congestion and connectivity issues can adversely affect user satisfaction. Hence, in this article, we use unmanned aerial vehicle (UAV)-assisted collaborative MEC architecture to facilitate task offloading of IoT devices in urban environments. We utilize the combined capabilities of UAVs and ground edge servers (ESs) to maximize user satisfaction and thereby also maximize the service provider's (SP) profit. We design IoT task-offloading as joint IoT-UAV-ES association and UAV-network topology optimization problem. Due to NP-hard nature, we break the problem into two subproblems: offload strategy optimization and UAV topology optimization. We develop a Three-sided Matching with Size and Cyclic preference (TMSC) based task offloading algorithm to find stable association between IoTs, UAVs, and ESs to achieve system objective. We also propose a K-means based iterative algorithm to decide the minimum number of UAVs and their positions to provide offloading services to maximum IoTs in the system. Finally, we demonstrate the efficacy of the proposed task offloading scheme over benchmark schemes through simulation-based evaluation. The proposed scheme outperforms by 19%, 12%, and 25% on average in terms of percentage of served IoTs, average user satisfaction, and SP profit, respectively, with 25% lesser UAVs, making it an effective solution to support IoT task requirements in urban environments using UAV-assisted MEC architecture.

Paper number 86:
Title: DeepDIVE: Optimizing Input-Constrained Distributions for Composite DNA Storage via Multinomial Channel
Authors: Adir Kobovich, Eitan Yaakobi, Nir Weinberger
Abstract: We address the challenge of optimizing the capacity-achieving input distribution for a multinomial channel under the constraint of limited input support size, which is a crucial aspect in the design of DNA storage systems. We propose an algorithm that further elaborates the Multidimensional Dynamic Assignment Blahut-Arimoto (M-DAB) algorithm. Our proposed algorithm integrates variational autoencoder for determining the optimal locations of input distribution, into the alternating optimization of the input distribution locations and weights.

Paper number 87:
Title: Audio-Language Models for Audio-Centric Tasks: A survey
Authors: Yi Su, Jisheng Bai, Qisheng Xu, Kele Xu, Yong Dou
Abstract: Audio-Language Models (ALMs), which are trained on audio-text data, focus on the processing, understanding, and reasoning of sounds. Unlike traditional supervised learning approaches learning from predefined labels, ALMs utilize natural language as a supervision signal, which is more suitable for describing complex real-world audio recordings. ALMs demonstrate strong zero-shot capabilities and can be flexibly adapted to diverse downstream tasks. These strengths not only enhance the accuracy and generalization of audio processing tasks but also promote the development of models that more closely resemble human auditory perception and comprehension. Recent advances in ALMs have positioned them at the forefront of computer audition research, inspiring a surge of efforts to advance ALM technologies. Despite rapid progress in the field of ALMs, there is still a notable lack of systematic surveys that comprehensively organize and analyze developments. In this paper, we present a comprehensive review of ALMs with a focus on general audio tasks, aiming to fill this gap by providing a structured and holistic overview of ALMs. Specifically, we cover: (1) the background of computer audition and audio-language models; (2) the foundational aspects of ALMs, including prevalent network architectures, training objectives, and evaluation methods; (3) foundational pre-training and audio-language pre-training approaches; (4) task-specific fine-tuning, multi-task tuning and agent systems for downstream applications; (5) datasets and benchmarks; and (6) current challenges and future directions. Our review provides a clear technical roadmap for researchers to understand the development and future trends of existing technologies, offering valuable references for implementation in real-world scenarios.

Paper number 88:
Title: Extracting Forward Invariant Sets from Neural Network-Based Control Barrier Functions
Authors: Goli Vaisi, James Ferlez, Yasser Shoukry
Abstract: Training Neural Networks (NNs) to serve as Barrier Functions (BFs) is a popular way to improve the safety of autonomous dynamical systems. Despite significant practical success, these methods are not generally guaranteed to produce true BFs in a provable sense, which undermines their intended use as safety certificates. In this paper, we consider the problem of formally certifying a learned NN as a BF with respect to state avoidance for an autonomous system: viz. computing a region of the state space on which the candidate NN is provably a BF. In particular, we propose a sound algorithm that efficiently produces such a certificate set for a shallow NN. Our algorithm combines two novel approaches: it first uses NN reachability tools to identify a subset of states for which the output of the NN does not increase along system trajectories; then, it uses a novel enumeration algorithm for hyperplane arrangements to find the intersection of the NN's zero-sub-level set with the first set of states. In this way, our algorithm soundly finds a subset of states on which the NN is certified as a BF. We further demonstrate the effectiveness of our algorithm at certifying for real-world NNs as BFs in two case studies. We complemented these with scalability experiments that demonstrate the efficiency of our algorithm.

Paper number 89:
Title: Engineering-Oriented Design of Drift-Resilient MTJ Random Number Generator via Hybrid Control Strategies
Authors: Ran Zhang, Caihua Wan, Yingqian Xu, Xiaohan Li, Raik Hoffmann, Meike Hindenberg, Shiqiang Liu, Dehao Kong, Shilong Xiong, Shikun He, Alptekin Vardar, Qiang Dai, Junlu Gong, Yihui Sun, Zejie Zheng, Thomas Kämpfe, Guoqiang Yu, Xiufeng Han
Abstract: In the quest for secure and reliable random number generation, Magnetic Tunnel Junctions (MTJs) have emerged as a promising technology due to their unique ability to exploit the stochastic nature of magnetization switching. This paper presents an engineering-oriented design of a drift-resilient MTJ-based True Random Number Generator (TRNG) utilizing a hybrid control strategy. We address the critical issue of switching probability drift, which can compromise the randomness and bias the output of MTJ-based TRNGs. Our approach combines a self-stabilization strategy, which dynamically adjusts the driving voltage based on real-time feedback, with pulse width modulation to enhance control over the switching probability. Through comprehensive experimental and simulation results, we demonstrate significant improvements in the stability, uniformity, and quality of the random numbers generated. The proposed system offers flexibility and adaptability for diverse applications, making it a reliable solution for high-quality randomness in cryptography, secure communications, and beyond.

Paper number 90:
Title: Hybrid Near/Far-Field Frequency-Dependent Beamforming via Joint Phase-Time Arrays
Authors: Yeyue Cai, Meixia Tao, Jianhua Mo, Shu Sun
Abstract: Joint phase-time arrays (JPTA) emerge as a cost-effective and energy-efficient architecture for frequency-dependent beamforming in wideband communications by utilizing both true-time delay units and phase shifters. This paper exploits the potential of JPTA to simultaneously serve multiple users in both near- and far-field regions with a single radio frequency chain. The goal is to jointly optimize JPTA-based beamforming and subband allocation to maximize overall system performance. To this end, we formulate a system utility maximization problem, including sum-rate maximization and proportional fairness as special cases. We develop a 3-step alternating optimization (AO) algorithm and an efficient deep learning (DL) method for this problem. The DL approach includes a 2-layer convolutional neural network, a 3-layer graph attention network (GAT), and a normalization module for resource and beamforming optimization. The GAT efficiently captures the interactions between resource allocation and analog beamformers. Simulation results confirm that JPTA outperforms conventional phased arrays (PA) in enhancing user rate and strikes a good balance between PA and fully-digital approach in energy efficiency. Employing a logarithmic utility function for user rates ensures greater fairness than maximizing sum-rates. Furthermore, the DL network achieves comparable performance to the AO approach, while having orders of magnitude lower computational complexity.

Paper number 91:
Title: Predictive Lagrangian Optimization for Constrained Reinforcement Learning
Authors: Tianqi Zhang, Puzhen Yuan, Guojian Zhan, Ziyu Lin, Yao Lyu, Zhenzhi Qin, Jingliang Duan, Liping Zhang, Shengbo Eben Li
Abstract: Constrained optimization is popularly seen in reinforcement learning for addressing complex control tasks. From the perspective of dynamic system, iteratively solving a constrained optimization problem can be framed as the temporal evolution of a feedback control system. Classical constrained optimization methods, such as penalty and Lagrangian approaches, inherently use proportional and integral feedback controllers. In this paper, we propose a more generic equivalence framework to build the connection between constrained optimization and feedback control system, for the purpose of developing more effective constrained RL algorithms. Firstly, we define that each step of the system evolution determines the Lagrange multiplier by solving a multiplier feedback optimal control problem (MFOCP). In this problem, the control input is multiplier, the state is policy parameters, the dynamics is described by policy gradient descent, and the objective is to minimize constraint violations. Then, we introduce a multiplier guided policy learning (MGPL) module to perform policy parameters updating. And we prove that the resulting optimal policy, achieved through alternating MFOCP and MGPL, aligns with the solution of the primal constrained RL problem, thereby establishing our equivalence framework. Furthermore, we point out that the existing PID Lagrangian is merely one special case within our framework that utilizes a PID controller. We also accommodate the integration of other various feedback controllers, thereby facilitating the development of new algorithms. As a representative, we employ model predictive control (MPC) as the feedback controller and consequently propose a new algorithm called predictive Lagrangian optimization (PLO). Numerical experiments demonstrate its superiority over the PID Lagrangian method, achieving a larger feasible region up to 7.2% and a comparable average reward.

Paper number 92:
Title: Detecting Unauthorized Drones with Cell-Free Integrated Sensing and Communication
Authors: Xinyue Li, Zinat Behdad, Ozan Alp Topal, Ozlem Tugfe Demir, Cicek Cavdar
Abstract: Integrated sensing and communication (ISAC) boosts network efficiency by using existing resources for diverse sensing applications. In this work, we propose a cell-free massive MIMO (multiple-input multiple-output)-ISAC framework to detect unauthorized drones while simultaneously ensuring communication requirements. We develop a detector to identify passive aerial targets by analyzing signals from distributed access points (APs). In addition to the precision of the sensing, timeliness of the sensing information is also crucial due to the risk of drones leaving the area before the sensing procedure is finished. We introduce the age of sensing (AoS) and sensing coverage as our sensing performance metrics and propose a joint sensing blocklength and power optimization algorithm to minimize AoS and maximize sensing coverage while meeting communication requirements. Moreover, we propose an adaptive weight selection algorithm based on concave-convex procedure to balance the inherent trade-off between AoS and sensing coverage. Our numerical results show that increasing the communication requirements would significantly reduce both the sensing coverage and the timeliness of the sensing. Furthermore, the proposed adaptive weight selection algorithm can provide high sensing coverage and reduce the AoS by 45% compared to the fixed weights, demonstrating efficient utilization of both power and sensing blocklength.

Paper number 93:
Title: Efficient Point Clouds Upsampling via Flow Matching
Authors: Zhi-Song Liu, Chenhang He, Lei Li
Abstract: Diffusion models are a powerful framework for tackling ill-posed problems, with recent advancements extending their use to point cloud upsampling. Despite their potential, existing diffusion models struggle with inefficiencies as they map Gaussian noise to real point clouds, overlooking the geometric information inherent in sparse point clouds. To address these inefficiencies, we propose PUFM, a flow matching approach to directly map sparse point clouds to their high-fidelity dense counterparts. Our method first employs midpoint interpolation to sparse point clouds, resolving the density mismatch between sparse and dense point clouds. Since point clouds are unordered representations, we introduce a pre-alignment method based on Earth Mover's Distance (EMD) optimization to ensure coherent interpolation between sparse and dense point clouds, which enables a more stable learning path in flow matching. Experiments on synthetic datasets demonstrate that our method delivers superior upsampling quality but with fewer sampling steps. Further experiments on ScanNet and KITTI also show that our approach generalizes well on RGB-D point clouds and LiDAR point clouds, making it more practical for real-world applications.

Paper number 94:
Title: The ICME 2025 Audio Encoder Capability Challenge
Authors: Junbo Zhang, Heinrich Dinkel, Qiong Song, Helen Wang, Yadong Niu, Si Cheng, Xiaofeng Xin, Ke Li, Wenwu Wang, Yujun Wang, Jian Luan
Abstract: This challenge aims to evaluate the capabilities of audio encoders, especially in the context of multi-task learning and real-world applications. Participants are invited to submit pre-trained audio encoders that map raw waveforms to continuous embeddings. These encoders will be tested across diverse tasks including speech, environmental sounds, and music, with a focus on real-world usability. The challenge features two tracks: Track A for parameterized evaluation, and Track B for parameter-free evaluation. This challenge provides a platform for evaluating and advancing the state-of-the-art in audio encoder design.

Paper number 95:
Title: Music Generation using Human-In-The-Loop Reinforcement Learning
Authors: Aju Ani Justus
Abstract: This paper presents an approach that combines Human-In-The-Loop Reinforcement Learning (HITL RL) with principles derived from music theory to facilitate real-time generation of musical compositions. HITL RL, previously employed in diverse applications such as modelling humanoid robot mechanics and enhancing language models, harnesses human feedback to refine the training process. In this study, we develop a HILT RL framework that can leverage the constraints and principles in music theory. In particular, we propose an episodic tabular Q-learning algorithm with an epsilon-greedy exploration policy. The system generates musical tracks (compositions), continuously enhancing its quality through iterative human-in-the-loop feedback. The reward function for this process is the subjective musical taste of the user.

Paper number 96:
Title: The Multicultural Medical Assistant: Can LLMs Improve Medical ASR Errors Across Borders?
Authors: Ayo Adedeji, Mardhiyah Sanni, Emmanuel Ayodele, Sarita Joshi, Tobi Olatunji
Abstract: The global adoption of Large Language Models (LLMs) in healthcare shows promise to enhance clinical workflows and improve patient outcomes. However, Automatic Speech Recognition (ASR) errors in critical medical terms remain a significant challenge. These errors can compromise patient care and safety if not detected. This study investigates the prevalence and impact of ASR errors in medical transcription in Nigeria, the United Kingdom, and the United States. By evaluating raw and LLM-corrected transcriptions of accented English in these regions, we assess the potential and limitations of LLMs to address challenges related to accents and medical terminology in ASR. Our findings highlight significant disparities in ASR accuracy across regions and identify specific conditions under which LLM corrections are most effective.

Paper number 97:
Title: Heterogeneous Population Encoding for Multi-joint Regression using sEMG Signals
Authors: Farah Baracat, Luca Manneschi, Elisa Donati
Abstract: Regression-based decoding of continuous movements is essential for human-machine interfaces (HMIs), such as prosthetic control. This study explores a feature-based approach to encoding Surface Electromyography (sEMG) signals, focusing on the role of variability in neural-inspired population encoding. By employing heterogeneous populations of Leaky Integrate-and- Fire (LIF) neurons with varying sizes and diverse parameter distributions, we investigate how population size and variability in encoding parameters, such as membrane time constants and thresholds, influence decoding performance. Using a simple linear readout, we demonstrate that variability improves robustness and generalizability compared to single-neuron encoders. These findings emphasize the importance of optimizing variability and population size for efficient and scalable regression tasks in spiking neural networks (SNNs), paving the way for robust, low-power HMI implementations.

Paper number 98:
Title: Baichuan-Omni-1.5 Technical Report
Authors: Yadong Li, Jun Liu, Tao Zhang, Tao Zhang, Song Chen, Tianpeng Li, Zehuan Li, Lijun Liu, Lingfeng Ming, Guosheng Dong, Da Pan, Chong Li, Yuanbo Fang, Dongdong Kuang, Mingrui Wang, Chenglin Zhu, Youwei Zhang, Hongyu Guo, Fengyu Zhang, Yuran Wang, Bowen Ding, Wei Song, Xu Li, Yuqi Huo, Zheng Liang, Shusen Zhang, Xin Wu, Shuai Zhao, Linchu Xiong, Yozhen Wu, Jiahui Ye, Wenhao Lu, Bowen Li, Yan Zhang, Yaqi Zhou, Xin Chen, Lei Su, Hongda Zhang, Fuzhong Chen, Xuezhen Dong, Na Nie, Zhiying Wu, Bin Xiao, Ting Li, Shunya Dang, Ping Zhang, Yijia Sun, Jincheng Wu, Jinjie Yang, Xionghai Lin, Zhi Ma, Kegeng Wu, Jia li, Aiyuan Yang, Hui Liu, Jianqiang Zhang, Xiaoxi Chen, Guangwei Ai, Wentao Zhang, Yicong Chen, Xiaoqin Huang, Kun Li, Wenjing Luo, Yifei Duan, Lingling Zhu, Ran Xiao, Zhe Su, Jiani Pu, Dian Wang, Xu Jia, Tianyu Zhang, Mengyu Ai, Mang Wang, Yujing Qiao, Lei Zhang, Yanjun Shen, Fan Yang, Miao Zhen, Yijie Zhou, Mingyang Chen, Fei Li, Chenzheng Zhu, Keer Lu, Yaqi Zhao, Hao Liang, Youquan Li, Yanzhao Qin, Linzhuang Sun, Jianhua Xu, Haoze Sun, Mingan Lin, Zenan Zhou, Weipeng Chen
Abstract: We introduce Baichuan-Omni-1.5, an omni-modal model that not only has omni-modal understanding capabilities but also provides end-to-end audio generation capabilities. To achieve fluent and high-quality interaction across modalities without compromising the capabilities of any modality, we prioritized optimizing three key aspects. First, we establish a comprehensive data cleaning and synthesis pipeline for multimodal data, obtaining about 500B high-quality data (text, audio, and vision). Second, an audio-tokenizer (Baichuan-Audio-Tokenizer) has been designed to capture both semantic and acoustic information from audio, enabling seamless integration and enhanced compatibility with MLLM. Lastly, we designed a multi-stage training strategy that progressively integrates multimodal alignment and multitask fine-tuning, ensuring effective synergy across all modalities. Baichuan-Omni-1.5 leads contemporary models (including GPT4o-mini and MiniCPM-o 2.6) in terms of comprehensive omni-modal capabilities. Notably, it achieves results comparable to leading models such as Qwen2-VL-72B across various multimodal medical benchmarks.

Paper number 99:
Title: DDUNet: Dual Dynamic U-Net for Highly-Efficient Cloud Segmentation
Authors: Yijie Li, Hewei Wang, Jinfeng Xu, Puzhen Wu, Yunzhong Xiao, Shaofan Wang, Soumyabrata Dev
Abstract: Cloud segmentation amounts to separating cloud pixels from non-cloud pixels in an image. Current deep learning methods for cloud segmentation suffer from three issues. (a) Constrain on their receptive field due to the fixed size of the convolution kernel. (b) Lack of robustness towards different scenarios. (c) Requirement of a large number of parameters and limitations for real-time implementation. To address these issues, we propose a Dual Dynamic U-Net (DDUNet) for supervised cloud segmentation. The DDUNet adheres to a U-Net architecture and integrates two crucial modules: the dynamic multi-scale convolution (DMSC), improving merging features under different reception fields, and the dynamic weights and bias generator (DWBG) in classification layers to enhance generalization ability. More importantly, owing to the use of depth-wise convolution, the DDUNet is a lightweight network that can achieve 95.3% accuracy on the SWINySEG dataset with only 0.33M parameters, and achieve superior performance over three different configurations of the SWINySEg dataset in both accuracy and efficiency.

Paper number 100:
Title: Foundations of a Knee Joint Digital Twin from qMRI Biomarkers for Osteoarthritis and Knee Replacement
Authors: Gabrielle Hoyer, Kenneth T Gao, Felix G Gassert, Johanna Luitjens, Fei Jiang, Sharmila Majumdar, Valentina Pedoia
Abstract: This study forms the basis of a digital twin system of the knee joint, using advanced quantitative MRI (qMRI) and machine learning to advance precision health in osteoarthritis (OA) management and knee replacement (KR) prediction. We combined deep learning-based segmentation of knee joint structures with dimensionality reduction to create an embedded feature space of imaging biomarkers. Through cross-sectional cohort analysis and statistical modeling, we identified specific biomarkers, including variations in cartilage thickness and medial meniscus shape, that are significantly associated with OA incidence and KR outcomes. Integrating these findings into a comprehensive framework represents a considerable step toward personalized knee-joint digital twins, which could enhance therapeutic strategies and inform clinical decision-making in rheumatological care. This versatile and reliable infrastructure has the potential to be extended to broader clinical applications in precision health.

Paper number 101:
Title: AnyEnhance: A Unified Generative Model with Prompt-Guidance and Self-Critic for Voice Enhancement
Authors: Junan Zhang, Jing Yang, Zihao Fang, Yuancheng Wang, Zehua Zhang, Zhuo Wang, Fan Fan, Zhizheng Wu
Abstract: We introduce AnyEnhance, a unified generative model for voice enhancement that processes both speech and singing voices. Based on a masked generative model, AnyEnhance is capable of handling both speech and singing voices, supporting a wide range of enhancement tasks including denoising, dereverberation, declipping, super-resolution, and target speaker extraction, all simultaneously and without fine-tuning. AnyEnhance introduces a prompt-guidance mechanism for in-context learning, which allows the model to natively accept a reference speaker's timbre. In this way, it could boost enhancement performance when a reference audio is available and enable the target speaker extraction task without altering the underlying architecture. Moreover, we also introduce a self-critic mechanism into the generative process for masked generative models, yielding higher-quality outputs through iterative self-assessment and refinement. Extensive experiments on various enhancement tasks demonstrate AnyEnhance outperforms existing methods in terms of both objective metrics and subjective listening tests. Demo audios are publicly available at this https URL.

Paper number 102:
Title: FAVbot: An Autonomous Target Tracking Micro-Robot with Frequency Actuation Control
Authors: Zhijian Hao, Ashwin Lele, Yan Fang, Arijit Raychowdhury, Azadeh Ansari
Abstract: Robotic autonomy at centimeter scale requires compact and miniaturization-friendly actuation integrated with sensing and neural network processing assembly within a tiny form factor. Applications of such systems have witnessed significant advancements in recent years in fields such as healthcare, manufacturing, and post-disaster rescue. The system design at this scale puts stringent constraints on power consumption for both the sensory front-end and actuation back-end and the weight of the electronic assembly for robust operation. In this paper, we introduce FAVbot, the first autonomous mobile micro-robotic system integrated with a novel actuation mechanism and convolutional neural network (CNN) based computer vision - all integrated within a compact 3-cm form factor. The novel actuation mechanism utilizes mechanical resonance phenomenon to achieve frequency-controlled steering with a single piezoelectric actuator. Experimental results demonstrate the effectiveness of FAVbot's frequency-controlled actuation, which offers a diverse selection of resonance modes with different motion characteristics. The actuation system is complemented with the vision front-end where a camera along with a microcontroller supports object detection for closed-loop control and autonomous target tracking. This enables adaptive navigation in dynamic environments. This work contributes to the evolving landscape of neural network-enabled micro-robotic systems showing the smallest autonomous robot built using controllable multi-directional single-actuator mechanism.

Paper number 103:
Title: Overview of the Amphion Toolkit (v0.2)
Authors: Jiaqi Li, Xueyao Zhang, Yuancheng Wang, Haorui He, Chaoren Wang, Li Wang, Huan Liao, Junyi Ao, Zeyu Xie, Yiqiao Huang, Junan Zhang, Zhizheng Wu
Abstract: Amphion is an open-source toolkit for Audio, Music, and Speech Generation, designed to lower the entry barrier for junior researchers and engineers in these fields. It provides a versatile framework that supports a variety of generation tasks and models. In this report, we introduce Amphion v0.2, the second major release developed in 2024. This release features a 100K-hour open-source multilingual dataset, a robust data preparation pipeline, and novel models for tasks such as text-to-speech, audio coding, and voice conversion. Furthermore, the report includes multiple tutorials that guide users through the functionalities and usage of the newly released models.

Paper number 104:
Title: Low-altitude Friendly-Jamming for Satellite-Maritime Communications via Generative AI-enabled Deep Reinforcement Learning
Authors: Jiawei Huang, Aimin Wang, Geng Sun, Jiahui Li, Jiacheng Wang, Dusit Niyato, Victor C. M. Leung
Abstract: Low Earth Orbit (LEO) satellites can be used to assist maritime wireless communications for data transmission across wide-ranging areas. However, extensive coverage of LEO satellites, combined with openness of channels, can cause the communication process to suffer from security risks. This paper presents a low-altitude friendly-jamming LEO satellite-maritime communication system enabled by a unmanned aerial vehicle (UAV) to ensure data security at the physical layer. Since such a system requires trade-off policies that balance the secrecy rate and energy consumption of the UAV to meet evolving scenario demands, we formulate a secure satellite-maritime communication multi-objective optimization problem (SSMCMOP). In order to solve the dynamic and long-term optimization problem, we reformulate it into a Markov decision process. We then propose a transformer-enhanced soft actor critic (TransSAC) algorithm, which is a generative artificial intelligence-enable deep reinforcement learning approach to solve the reformulated problem, so that capturing global dependencies and diversely exploring weights. Simulation results demonstrate that the TransSAC outperforms various baselines, and achieves an optimal secrecy rate while effectively minimizing the energy consumption of the UAV. Moreover, the results find more suitable constraint values for the system.

Paper number 105:
Title: AI in Oncology: Transforming Cancer Detection through Machine Learning and Deep Learning Applications
Authors: Muhammad Aftab, Faisal Mehmood, Chengjuan Zhang, Alishba Nadeem, Zigang Dong, Yanan Jiang, Kangdongs Liu
Abstract: Artificial intelligence (AI) has potential to revolutionize the field of oncology by enhancing the precision of cancer diagnosis, optimizing treatment strategies, and personalizing therapies for a variety of cancers. This review examines the limitations of conventional diagnostic techniques and explores the transformative role of AI in diagnosing and treating cancers such as lung, breast, colorectal, liver, stomach, esophageal, cervical, thyroid, prostate, and skin cancers. The primary objective of this paper is to highlight the significant advancements that AI algorithms have brought to oncology within the medical industry. By enabling early cancer detection, improving diagnostic accuracy, and facilitating targeted treatment delivery, AI contributes to substantial improvements in patient outcomes. The integration of AI in medical imaging, genomic analysis, and pathology enhances diagnostic precision and introduces a novel, less invasive approach to cancer screening. This not only boosts the effectiveness of medical facilities but also reduces operational costs. The study delves into the application of AI in radiomics for detailed cancer characterization, predictive analytics for identifying associated risks, and the development of algorithm-driven robots for immediate diagnosis. Furthermore, it investigates the impact of AI on addressing healthcare challenges, particularly in underserved and remote regions. The overarching goal of this platform is to support the development of expert recommendations and to provide universal, efficient diagnostic procedures. By reviewing existing research and clinical studies, this paper underscores the pivotal role of AI in improving the overall cancer care system. It emphasizes how AI-enabled systems can enhance clinical decision-making and expand treatment options, thereby underscoring the importance of AI in advancing precision oncology

Paper number 106:
Title: One Model to Forecast Them All and in Entity Distributions Bind Them
Authors: Kutay Bölat, Simon Tindemans
Abstract: Probabilistic forecasting in power systems often involves multi-entity datasets like households, feeders, and wind turbines, where generating reliable entity-specific forecasts presents significant challenges. Traditional approaches require training individual models for each entity, making them inefficient and hard to scale. This study addresses this problem using GUIDE-VAE, a conditional variational autoencoder that allows entity-specific probabilistic forecasting using a single model. GUIDE-VAE provides flexible outputs, ranging from interpretable point estimates to full probability distributions, thanks to its advanced covariance composition structure. These distributions capture uncertainty and temporal dependencies, offering richer insights than traditional methods. To evaluate our GUIDE-VAE-based forecaster, we use household electricity consumption data as a case study due to its multi-entity and highly stochastic nature. Experimental results demonstrate that GUIDE-VAE outperforms conventional quantile regression techniques across key metrics while ensuring scalability and versatility. These features make GUIDE-VAE a powerful and generalizable tool for probabilistic forecasting tasks, with potential applications beyond household electricity consumption.

Paper number 107:
Title: Intelligent Surface Assisted Radar Stealth Against Unauthorized ISAC
Authors: Fan Xu, Wenhai Lai, Kaiming Shen
Abstract: The integration of radar sensors and communication networks as envisioned for the 6G wireless networks poses significant security risks, e.g., the user position information can be released to an unauthorized dual-functional base station (DFBS). To address this issue, we propose an intelligent surface (IS)-assisted radar stealth technology that prevents adversarial sensing. Specifically, we modify the wireless channels by tuning the phase shifts of IS in order to protect the target user from unauthorized sensing without jeopardizing the wireless communication link. In principle, we wish to maximize the distortion between the estimated angle-of-arrival (AoA) by the DFBS and the ground truth given the minimum signal-to-noise-radio (SNR) constraint for communication. Toward this end, we propose characterizing the problem as a game played by the DFBS and the IS, in which the DFBS aims to maximize a particular utility while the IS aims to minimize the utility. Although the problem is nonconvex, this paper shows that it can be optimally solved in closed form from a geometric perspective. According to the simulations, the proposed closed-form algorithm outperforms the baseline methods significantly in combating unauthorized sensing while limiting the impacts on wireless communications.

Paper number 108:
Title: Stepback: Enhanced Disentanglement for Voice Conversion via Multi-Task Learning
Authors: Qian Yang, Calbert Graham
Abstract: Voice conversion (VC) modifies voice characteristics while preserving linguistic content. This paper presents the Stepback network, a novel model for converting speaker identity using non-parallel data. Unlike traditional VC methods that rely on parallel data, our approach leverages deep learning techniques to enhance disentanglement completion and linguistic content preservation. The Stepback network incorporates a dual flow of different domain data inputs and uses constraints with self-destructive amendments to optimize the content encoder. Extensive experiments show that our model significantly improves VC performance, reducing training costs while achieving high-quality voice conversion. The Stepback network's design offers a promising solution for advanced voice conversion tasks.

Paper number 109:
Title: Marker Track: Accurate Fiducial Marker Tracking for Evaluation of Residual Motions During Breath-Hold Radiotherapy
Authors: Aimee Guo, Weihua Mao
Abstract: Fiducial marker positions in projection image of cone-beam computed tomography (CBCT) scans have been studied to evaluate daily residual motion during breath-hold radiation therapy. Fiducial marker migration posed challenges in accurately locating markers, prompting the development of a novel algorithm that reconstructs volumetric probability maps of marker locations from filtered gradient maps of projections. This guides the development of a Python-based algorithm to detect fiducial markers in projection images using Meta AI's Segment Anything Model 2 (SAM 2). Retrospective data from a pancreatic cancer patient with two fiducial markers were analyzed. The three-dimensional (3D) marker positions from simulation computed tomography (CT) were compared to those reconstructed from CBCT images, revealing a decrease in relative distances between markers over time. Fiducial markers were successfully detected in 2777 out of 2786 projection frames. The average standard deviation of superior-inferior (SI) marker positions was 0.56 mm per breath-hold, with differences in average SI positions between two breath-holds in the same scan reaching up to 5.2 mm, and a gap of up to 7.3 mm between the end of the first and beginning of the second breath-hold. 3D marker positions were calculated using projection positions and confirmed marker migration. This method effectively calculates marker probability volume and enables accurate fiducial marker tracking during treatment without requiring any specialized equipment, additional radiation doses, or manual initialization and labeling. It has significant potential for automatically assessing daily residual motion to adjust planning margins, functioning as an adaptive radiation therapy tool.

Paper number 110:
Title: Multi-compartment diffusion-relaxation MR signal representation in the spherical 3D-SHORE basis
Authors: Fabian Bogusz, Tomasz Pieciak
Abstract: Modelling the diffusion-relaxation magnetic resonance (MR) signal obtained from multi-parametric sequences has recently gained immense interest in the community due to new techniques significantly reducing data acquisition time. A preferred approach for examining the diffusion-relaxation MR data is to follow the continuum modelling principle that employs kernels to represent the tissue features, such as the relaxations or diffusion properties. However, constructing reasonable dictionaries with predefined signal components depends on the sampling density of model parameter space, thus leading to a geometrical increase in the number of atoms per extra tissue parameter considered in the model. That makes estimating the contributions from each atom in the signal challenging, especially considering diffusion features beyond the mono-exponential decay. This paper presents a new Multi-Compartment diffusion-relaxation MR signal representation based on the Simple Harmonic Oscillator-based Reconstruction and Estimation (MC-SHORE) representation, compatible with scattered acquisitions. The proposed technique imposes sparsity constraint on the solution via the $\ell_1$ norm and enables the estimation of the microstructural measures, such as the return-to-the-origin probability, and the orientation distribution function, depending on the compartments considered in a single voxel. The procedure has been verified with in silico and in vivo data and enabled the approximation of the diffusion-relaxation MR signal more accurately than single-compartment non-Gaussian representations and multi-compartment mono-exponential decay techniques, maintaining a low number of atoms in the dictionary. Ultimately, the MC-SHORE procedure allows for separating intra-/extra-axonal and free water contributions from the signal, thus reducing the partial volume effect observable in the boundaries of the tissues.

Paper number 111:
Title: Vision-Aided Channel Prediction Based on Image Segmentation at Street Intersection Scenarios
Authors: Xuejian Zhang, Ruisi He, Mi Yang, Ziyi Qi, Zhengyu Zhang, Bo Ai, Zhangdui Zhong
Abstract: Intelligent vehicular communication with vehicle road collaboration capability is a key technology enabled by 6G, and the integration of various visual sensors on vehicles and infrastructures plays a crucial role. Moreover, accurate channel prediction is foundational to realizing intelligent vehicular communication. Traditional methods are still limited by the inability to balance accuracy and operability based on substantial spectrum resource consumption and highly refined description of environment. Therefore, leveraging out-of-band information introduced by visual sensors provides a new solution and is increasingly applied across various communication tasks. In this paper, we propose a computer vision (CV)-based prediction model for vehicular communications, realizing accurate channel characterization prediction including path loss, Rice K-factor and delay spread based on image segmentation. First, we conduct extensive vehicle-to-infrastructure measurement campaigns, collecting channel and visual data from various street intersection scenarios. The image-channel dataset is generated after a series of data post-processing steps. Image data consists of individual segmentation of target user using YOLOv8 network. Subsequently, established dataset is used to train and test prediction network ResNet-32, where segmented images serve as input of network, and various channel characteristics are treated as labels or target outputs of network. Finally, self-validation and cross-validation experiments are performed. The results indicate that models trained with segmented images achieve high prediction accuracy and remarkable generalization performance across different streets and target users. The model proposed in this paper offers novel solutions for achieving intelligent channel prediction in vehicular communications.

Paper number 112:
Title: Integrating Personalized Federated Learning with Control Systems for Enhanced Performance
Authors: Alice Smith, Bob Johnson, Michael Geller
Abstract: In the expanding field of machine learning, federated learning has emerged as a pivotal methodology for distributed data environments, ensuring privacy while leveraging decentralized data sources. However, the heterogeneity of client data and the need for tailored models necessitate the integration of personalization techniques to enhance learning efficacy and model performance. This paper introduces a novel framework that amalgamates personalized federated learning with robust control systems, aimed at optimizing both the learning process and the control of data flow across diverse networked environments. Our approach harnesses personalized algorithms that adapt to the unique characteristics of each client's data, thereby improving the relevance and accuracy of the model for individual nodes without compromising the overall system performance. To manage and control the learning process across the network, we employ a sophisticated control system that dynamically adjusts the parameters based on real-time feedback and system states, ensuring stability and efficiency. Through rigorous experimentation, we demonstrate that our integrated system not only outperforms standard federated learning models in terms of accuracy and learning speed but also maintains system integrity and robustness in face of varying network conditions and data distributions. The experimental results, obtained from a multi-client simulated environment with non-IID data distributions, underscore the benefits of integrating control systems into personalized federated learning frameworks, particularly in scenarios demanding high reliability and precision.

Paper number 113:
Title: Selective Experience Sharing in Reinforcement Learning Enhances Interference Management
Authors: Madan Dahal, Mojtaba Vaezi
Abstract: We propose a novel multi-agent reinforcement learning (RL) approach for inter-cell interference mitigation, in which agents selectively share their experiences with other agents. Each base station is equipped with an agent, which receives signal-to-interference-plus-noise ratio from its own associated users. This information is used to evaluate and selectively share experiences with neighboring agents. The idea is that even a few pertinent experiences from other agents can lead to effective learning. This approach enables fully decentralized training and execution, minimizes information sharing between agents and significantly reduces communication overhead, which is typically the burden of interference management. The proposed method outperforms state-of-the-art multi-agent RL techniques where training is done in a decentralized manner. Furthermore, with a 75% reduction in experience sharing, the proposed algorithm achieves 98% of the spectral efficiency obtained by algorithms sharing all experiences.

Paper number 114:
Title: Potential Applications of Artificial Intelligence for Cross-language Intelligibility Assessment of Dysarthric Speech
Authors: Eunjung Yeo, Julie Liss, Visar Berisha, David Mortensen
Abstract: Purpose: This commentary introduces how artificial intelligence (AI) can be leveraged to advance cross-language intelligibility assessment of dysarthric speech. Method: We propose a dual-component framework consisting of a universal module that generates language-independent speech representations and a language-specific intelligibility model that incorporates linguistic nuances. Additionally, we identify key barriers to cross-language intelligibility assessment, including data scarcity, annotation complexity, and limited linguistic insights, and present AI-driven solutions to overcome these challenges. Conclusion: Advances in AI offer transformative opportunities to enhance cross-language intelligibility assessment for dysarthric speech by balancing scalability across languages and adaptability by languages.

Paper number 115:
Title: Movable Antennas Meet Intelligent Reflecting Surface: Friends or Foes?
Authors: Xin Wei, Weidong Mei, Qingqing Wu, Qiaoran Jia, Boyu Ning, Zhi Chen, Jun Fang
Abstract: Movable antenna (MA) and intelligent reflecting surface (IRS) are considered promising technologies for the next-generation wireless communication systems due to their shared channel reconfiguration capabilities. This, however, raises a fundamental question: Does the performance gain of MAs over conventional fixed-position antennas (FPAs) still exist in the presence of the IRS? To answer this question, we investigate in this paper an IRS-assisted multi-user multiple-input single-output (MISO) MA system, where a multi-MA base station (BS) transmits to multiple single-FPA users. We formulate a sum-rate maximization problem by jointly optimizing the active/passive beamforming of the BS/IRS and the MA positions within a one-dimensional transmit region, which is challenging to be optimally solved. To drive essential insights, we first study a simplified case with a single user. Then, we analyze the performance gain of MAs over FPAs in the light-of-sight (LoS) BS-IRS channel and derive the conditions under which this gain becomes more or less significant. In addition, we propose an alternating optimization (AO) algorithm to solve the signal-to-noise ratio (SNR) maximization problem in the single-user case by combining the block coordinate descent (BCD) method and the graph-based method. For the general multi-user case, our performance analysis unveils that the performance gain of MAs over FPAs diminishes with typical transmit precoding strategies at the BS under certain conditions. We also propose a high-quality suboptimal solution to the sum-rate maximization problem by applying the AO algorithm that combines the weighted minimum mean square error (WMMSE) algorithm, manifold optimization method and discrete sampling method. Numerical results validate our theoretical analyses and demonstrate that the performance gain of MAs over FPAs may be reduced if the IRS passive beamforming is optimized.

Paper number 116:
Title: Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for Speech Generation
Authors: Haorui He, Zengqiang Shang, Chaoren Wang, Xuyuan Li, Yicheng Gu, Hua Hua, Liwei Liu, Chen Yang, Jiaqi Li, Peiyang Shi, Yuancheng Wang, Kai Chen, Pengyuan Zhang, Zhizheng Wu
Abstract: Recent advancements in speech generation have been driven by the large-scale training datasets. However, current models fall short of capturing the spontaneity and variability inherent in real-world human speech, due to their reliance on audiobook datasets limited to formal read-aloud speech styles. To bridge this gap, we introduce Emilia-Pipe, an open-source preprocessing pipeline to extract high-quality training data from valuable yet underexplored in-the-wild data that capture spontaneous human speech in real-world contexts. By leveraging Emilia-Pipe, we construct Emilia, the first multilingual speech generation dataset derived from in-the-wild speech data. This dataset comprises over 101k hours of speech across six languages: English, Chinese, German, French, Japanese, and Korean. Besides, we expand Emilia to Emilia-Large, a dataset exceeding 216k hours, making it the largest open-source speech generation dataset available. Extensive experiments demonstrate that Emilia significantly outperforms traditional audiobook datasets in generating spontaneous and human-like speech, showcasing superior performance in capturing diverse speaker timbre and speaking styles of real-world human speech. Furthermore, this work underscores the importance of scaling dataset size to advance speech generation research and validates the effectiveness of Emilia for both multilingual and crosslingual speech generation.

Paper number 117:
Title: The Sample Complexity of Online Reinforcement Learning: A Multi-model Perspective
Authors: Michael Muehlebach, Zhiyu He, Michael I. Jordan
Abstract: We study the sample complexity of online reinforcement learning for nonlinear dynamical systems with continuous state and action spaces. Our analysis accommodates a large class of dynamical systems ranging from a finite set of nonlinear candidate models to models with bounded and Lipschitz continuous dynamics, to systems that are parametrized by a compact and real-valued set of parameters. In the most general setting, our algorithm achieves a policy regret of $\mathcal{O}(N \epsilon^2 + \mathrm{ln}(m(\epsilon))/\epsilon^2)$, where $N$ is the time horizon, $\epsilon$ is a user-specified discretization width, and $m(\epsilon)$ measures the complexity of the function class under consideration via its packing number. In the special case where the dynamics are parametrized by a compact and real-valued set of parameters (such as neural networks, transformers, etc.), we prove a policy regret of $\mathcal{O}(\sqrt{N p})$, where $p$ denotes the number of parameters, recovering earlier sample-complexity results that were derived for linear time-invariant dynamical systems. While this article focuses on characterizing sample complexity, the proposed algorithms are likely to be useful in practice, due to their simplicity, the ability to incorporate prior knowledge, and their benign transient behavior.

Paper number 118:
Title: Modeling and stability analysis of live systems with time-varying dimension
Authors: Andrii Mironchenko
Abstract: A major limitation of the classical control theory is the assumption that the state space and its dimension do not change with time. This prevents analyzing and even formalizing the stability and control problems for open multi-agent systems whose agents may enter or leave the network, industrial processes where the sensors or actuators may be exchanged frequently, smart grids, etc. In this work, we propose a framework of live systems that covers a rather general class of systems with a time-varying state space. We argue that input-to-state stability is a proper stability notion for this class of systems, and many of the classic tools and results, such as Lyapunov methods and superposition theorems, can be extended to this setting.

Paper number 119:
Title: Brain-Inspired Decentralized Satellite Learning in Space Computing Power Networks
Authors: Peng Yang, Ting Wang, Haibin Cai, Yuanming Shi, Chunxiao Jiang, Linling Kuang
Abstract: Satellite networks are able to collect massive space information with advanced remote sensing technologies, which is essential for real-time applications such as natural disaster monitoring. However, traditional centralized processing by the ground server incurs a severe timeliness issue caused by the transmission bottleneck of raw data. To this end, Space Computing Power Networks (Space-CPN) emerges as a promising architecture to coordinate the computing capability of satellites and enable on board data processing. Nevertheless, due to the natural limitations of solar panels, satellite power system is difficult to meet the energy requirements for ever-increasing intelligent computation tasks of artificial neural networks. To tackle this issue, we propose to employ spiking neural networks (SNNs), which is supported by the neuromorphic computing architecture, for on-board data processing. The extreme sparsity in its computation enables a high energy efficiency. Furthermore, to achieve effective training of these on-board models, we put forward a decentralized neuromorphic learning framework, where a communication-efficient inter-plane model aggregation method is developed with the inspiration from RelaySum. We provide a theoretical analysis to characterize the convergence behavior of the proposed algorithm, which reveals a network diameter related convergence speed. We then formulate a minimum diameter spanning tree problem on the inter-plane connectivity topology and solve it to further improve the learning performance. Extensive experiments are conducted to evaluate the superiority of the proposed method over benchmarks.

Paper number 120:
Title: Combating Interference for Over-the-Air Federated Learning: A Statistical Approach via RIS
Authors: Wei Shi, Jiacheng Yao, Wei Xu, Jindan Xu, Xiaohu You, Yonina C. Eldar, Chunming Zhao
Abstract: Over-the-air computation (AirComp) integrates analog communication with task-oriented computation, serving as a key enabling technique for communication-efficient federated learning (FL) over wireless networks. However, owing to its analog characteristics, AirComp-enabled FL (AirFL) is vulnerable to both unintentional and intentional interference. In this paper, we aim to attain robustness in AirComp aggregation against interference via reconfigurable intelligent surface (RIS) technology to artificially reconstruct wireless environments. Concretely, we establish performance objectives tailored for interference suppression in wireless FL systems, aiming to achieve unbiased gradient estimation and reduce its mean square error (MSE). Oriented at these objectives, we introduce the concept of phase-manipulated favorable propagation and channel hardening for AirFL, which relies on the adjustment of RIS phase shifts to realize statistical interference elimination and reduce the error variance of gradient estimation. Building upon this concept, we propose two robust aggregation schemes of power control and RIS phase shifts design, both ensuring unbiased gradient estimation in the presence of interference. Theoretical analysis of the MSE and FL convergence affirms the anti-interference capability of the proposed schemes. It is observed that computation and interference errors diminish by an order of $\mathcal{O}\left(\frac{1}{N}\right)$ where $N$ is the number of RIS elements, and the ideal convergence rate without interference can be asymptotically achieved by increasing $N$. Numerical results confirm the analytical results and validate the superior performance of the proposed schemes over existing baselines.

Paper number 121:
Title: AI Agents for Computer Use: A Review of Instruction-based Computer Control, GUI Automation, and Operator Assistants
Authors: Pascal J. Sager, Benjamin Meyer, Peng Yan, Rebekka von Wartburg-Kottler, Layan Etaiwi, Aref Enayati, Gabriel Nobel, Ahmed Abdulkadir, Benjamin F. Grewe, Thilo Stadelmann
Abstract: Instruction-based computer control agents (CCAs) execute complex action sequences on personal computers or mobile devices to fulfill tasks using the same graphical user interfaces as a human user would, provided instructions in natural language. This review offers a comprehensive overview of the emerging field of instruction-based computer control, examining available agents -- their taxonomy, development, and respective resources -- and emphasizing the shift from manually designed, specialized agents to leveraging foundation models such as large language models (LLMs) and vision-language models (VLMs). We formalize the problem and establish a taxonomy of the field to analyze agents from three perspectives: (a) the environment perspective, analyzing computer environments; (b) the interaction perspective, describing observations spaces (e.g., screenshots, HTML) and action spaces (e.g., mouse and keyboard actions, executable code); and (c) the agent perspective, focusing on the core principle of how an agent acts and learns to act. Our framework encompasses both specialized and foundation agents, facilitating their comparative analysis and revealing how prior solutions in specialized agents, such as an environment learning step, can guide the development of more capable foundation agents. Additionally, we review current CCA datasets and CCA evaluation methods and outline the challenges to deploying such agents in a productive setting. In total, we review and classify 86 CCAs and 33 related datasets. By highlighting trends, limitations, and future research directions, this work presents a comprehensive foundation to obtain a broad understanding of the field and push its future development.

Paper number 122:
Title: UDBE: Unsupervised Diffusion-based Brightness Enhancement in Underwater Images
Authors: Tatiana Taís Schein, Gustavo Pereira de Almeira, Stephanie Loi Brião, Rodrigo Andrade de Bem, Felipe Gomes de Oliveira, Paulo L. J. Drews-Jr
Abstract: Activities in underwater environments are paramount in several scenarios, which drives the continuous development of underwater image enhancement techniques. A major challenge in this domain is the depth at which images are captured, with increasing depth resulting in a darker environment. Most existing methods for underwater image enhancement focus on noise removal and color adjustment, with few works dedicated to brightness enhancement. This work introduces a novel unsupervised learning approach to underwater image enhancement using a diffusion model. Our method, called UDBE, is based on conditional diffusion to maintain the brightness details of the unpaired input images. The input image is combined with a color map and a Signal-Noise Relation map (SNR) to ensure stable training and prevent color distortion in the output images. The results demonstrate that our approach achieves an impressive accuracy rate in the datasets UIEB, SUIM and RUIE, well-established underwater image benchmarks. Additionally, the experiments validate the robustness of our approach, regarding the image quality metrics PSNR, SSIM, UIQM, and UISM, indicating the good performance of the brightness enhancement process. The source code is available here: this https URL.

Paper number 123:
Title: Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models
Authors: Huayu Li, Xiwen Chen, Ci Zhang, Stuart F. Quan, William D.S. Killgore, Shu-Fen Wung, Chen X. Chen, Geng Yuan, Jin Lu, Ao Li
Abstract: Large language models (LLMs) exhibit remarkable capabilities in visual inspection of medical time-series data, achieving proficiency comparable to human clinicians. However, their broad scope limits domain-specific precision, and proprietary weights hinder fine-tuning for specialized datasets. In contrast, small specialized models (SSMs) excel in targeted tasks but lack the contextual reasoning required for complex clinical decision-making. To address these challenges, we propose ConMIL (Conformalized Multiple Instance Learning), a decision-support SSM that integrates seamlessly with LLMs. By using Multiple Instance Learning (MIL) to identify clinically significant signal segments and conformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs' interpretative capabilities for medical time-series analysis. Experimental results demonstrate that ConMIL significantly improves the performance of state-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically, \ConMIL{}-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision for confident samples in arrhythmia detection and sleep staging, compared to standalone LLM accuracy of 46.13% and 13.16%. These findings highlight the potential of ConMIL to bridge task-specific precision and broader contextual reasoning, enabling more reliable and interpretable AI-driven clinical decision support.

Paper number 124:
Title: Active Hypothesis Testing for Quantum Detection of Phase-Shift Keying Coherent States
Authors: Yun-Feng Lo, Matthieu R. Bloch
Abstract: This paper explores the quantum detection of Phase-Shift Keying (PSK)-coded coherent states through the lens of active hypothesis testing, focusing on a Dolinar-like receiver with constraints on displacement amplitude and energy. With coherent state slicing, we formulate the problem as a controlled sensing task in which observation kernels have parameters shrinking with sample size. The constrained open-loop error exponent and a corresponding upper bound on the Bayesian error probability are proven. Surprisingly, the exponent-optimal open-loop policy for binary PSK with high dark counts is not simply time-sharing. This work serves as a first step towards obtaining analytical insights through the active hypothesis testing framework for designing resource-constrained quantum communication receivers.

Paper number 125:
Title: SP-IMPact: A Framework for Static Partitioning Interference Mitigation and Performance Analysis
Authors: Diogo Costa, Gonçalo Moreira, Afonso Oliveira, José Martins, Sandro Pinto
Abstract: Modern embedded systems are evolving toward complex, heterogeneous architectures to accommodate increasingly demanding applications. Driven by SWAP-C constraints, this shift has led to consolidating multiple systems onto single hardware platforms. Static Partitioning Hypervisors offer a promising solution to partition hardware resources and provide spatial isolation between critical workloads. However, shared resources like the Last-Level Cache and system bus can introduce temporal interference between virtual machines (VMs), negatively impacting performance and predictability. Over the past decade, academia and industry have developed interference mitigation techniques, such as cache partitioning and memory bandwidth reservation. However, configuring these techniques is complex and time-consuming. Cache partitioning requires balancing cache sections across VMs, while memory bandwidth reservation needs tuning bandwidth budgets and periods. Testing all configurations is impractical and often leads to suboptimal results. Moreover, understanding how these techniques interact is limited, as their combined use can produce compounded or conflicting effects on performance. Static analysis tools estimating worst-case execution times offer guidance for configuring mitigation techniques but often fail to capture the complexity of modern multi-core systems. They typically focus on limited shared resources while neglecting others, such as IOMMUs and interrupt controllers. To address these challenges, we present SP-IMPact, an open-source framework for analyzing and guiding interference mitigation configurations. SP-IMPact supports (i) cache coloring and (ii) memory bandwidth reservation, while evaluating their interactions and cumulative impact. By providing insights on real hardware, SP-IMPact helps optimize configurations for mixed-criticality systems, ensuring performance and predictability.

Paper number 126:
Title: Entanglement-Assisted Coding for Arbitrary Linear Computations Over a Quantum MAC
Authors: Lei Hu, Mohamed Nomeir, Alptug Aytekin, Yu Shi, Sennur Ulukus, Saikat Guha
Abstract: We study a linear computation problem over a quantum multiple access channel (LC-QMAC), where $S$ servers share an entangled state and separately store classical data streams $W_1,\cdots, W_S$ over a finite field $\mathbb{F}_d$. A user aims to compute $K$ linear combinations of these data streams, represented as $Y = \mathbf{V}_1 W_1 + \mathbf{V}_2 W_2 + \cdots + \mathbf{V}_S W_S \in \mathbb{F}_d^{K \times 1}$. To this end, each server encodes its classical information into its local quantum subsystem and transmits it to the user, who retrieves the desired computations via quantum measurements. In this work, we propose an achievable scheme for LC-QMAC based on the stabilizer formalism and the ideas from entanglement-assisted quantum error-correcting codes (EAQECC). Specifically, given any linear computation matrix, we construct a self-orthogonal matrix that can be implemented using the stabilizer formalism. Also, we apply precoding matrices to minimize the number of auxiliary qudits required. Our scheme achieves more computations per qudit, i.e., a higher computation rate, compared to the best-known methods in the literature, and attains the capacity in certain cases.

Paper number 127:
Title: LUCY: Linguistic Understanding and Control Yielding Early Stage of Her
Authors: Heting Gao, Hang Shao, Xiong Wang, Chaofan Qiu, Yunhang Shen, Siqi Cai, Yuchen Shi, Zihan Xu, Zuwei Long, Yike Zhang, Shaoqi Dong, Chaoyou Fu, Ke Li, Long Ma, Xing Sun
Abstract: The film Her features Samantha, a sophisticated AI audio agent who is capable of understanding both linguistic and paralinguistic information in human speech and delivering real-time responses that are natural, informative and sensitive to emotional subtleties. Moving one step toward more sophisticated audio agent from recent advancement in end-to-end (E2E) speech systems, we propose LUCY, a E2E speech model that (1) senses and responds to user's emotion, (2) deliver responses in a succinct and natural style, and (3) use external tool to answer real-time inquiries. Experiment results show that LUCY is better at emotion control than peer models, generating emotional responses based on linguistic emotional instructions and responding to paralinguistic emotional cues. Lucy is also able to generate responses in a more natural style, as judged by external language models, without sacrificing much performance on general question answering. Finally, LUCY can leverage function calls to answer questions that are out of its knowledge scope.

Paper number 128:
Title: The Third Evolution Equation for Optimal Control Computation
Authors: Sheng Zhang, Fei Liao, Kai-Feng He
Abstract: The Variation Evolving Method (VEM) that originates from the continuous-time dynamics stability theory seeks the optimal solutions with variation evolution principle. After establishing the first and the second evolution equations within its frame, the third evolution equation is developed. This equation only solves the control variables along the variation time to get the optimal solution, and its definite conditions may be arbitrary since the equation can eliminate possible infeasibilities. With this equation, the dimension of the resulting Initial-value Problem (IVP), transformed via the semi-discrete method, is greatly reduced. Therefore it might relieve the computation burden in seeking solutions. Illustrative examples are solved and it is shown that the proposed equation may produce more precise numerical solutions than the second evolution equation, and its computation time may be shorter for the dense discretization.

Paper number 129:
Title: A Framework for Quasi Time-Optimal Nonlinear Model Predictive Control with Soft Constraints
Authors: Joe Ismail, Steven Liu
Abstract: In many mechatronic applications, controller input costs are negligible and time optimality is of great importance to maximize the productivity by executing fast positioning maneuvers. As a result, the obtained control input has mostly a bang-bang nature, which excite undesired mechanical vibrations, especially in systems with flexible structures. This paper tackles the time-optimal control problem and proposes a novel approach, which explicitly addresses the vibrational behavior in the context of the receding horizon technique. Such technique is a key feature, especially for systems with a time-varying vibrational behavior. In the context of model predictive control (MPC), vibrational behavior is predicted and coped in a soft-constrained formulation, which penalize any violation of undesired vibrations. This formulation enlarges the feasibility on a wide operating range in comparison with a hard-constrained formulation. The closed-loop performance of this approach is demonstrated on a numerical example of stacker crane with high degree of flexibility.

Paper number 130:
Title: R2C-GAN: Restore-to-Classify Generative Adversarial Networks for Blind X-Ray Restoration and COVID-19 Classification
Authors: Mete Ahishali, Aysen Degerli, Serkan Kiranyaz, Tahir Hamid, Rashid Mazhar, Moncef Gabbouj
Abstract: Restoration of poor quality images with a blended set of artifacts plays a vital role for a reliable diagnosis. Existing studies have focused on specific restoration problems such as image deblurring, denoising, and exposure correction where there is usually a strong assumption on the artifact type and severity. As a pioneer study in blind X-ray restoration, we propose a joint model for generic image restoration and classification: Restore-to-Classify Generative Adversarial Networks (R2C-GANs). Such a jointly optimized model keeps any disease intact after the restoration. Therefore, this will naturally lead to a higher diagnosis performance thanks to the improved X-ray image quality. To accomplish this crucial objective, we define the restoration task as an Image-to-Image translation problem from poor quality having noisy, blurry, or over/under-exposed images to high quality image domain. The proposed R2C-GAN model is able to learn forward and inverse transforms between the two domains using unpaired training samples. Simultaneously, the joint classification preserves the disease label during restoration. Moreover, the R2C-GANs are equipped with operational layers/neurons reducing the network depth and further boosting both restoration and classification performances. The proposed joint model is extensively evaluated over the QaTa-COV19 dataset for Coronavirus Disease 2019 (COVID-19) classification. The proposed restoration approach achieves over 90% F1-Score which is significantly higher than the performance of any deep model. Moreover, in the qualitative analysis, the restoration performance of R2C-GANs is approved by a group of medical doctors. We share the software implementation at this https URL.

Paper number 131:
Title: Fatigue monitoring and maneuver identification for vehicle fleets using a virtual sensing approach
Authors: Leonhard Heindel, Peter Hantschke, Markus Kästner
Abstract: Extensive monitoring comes at a prohibitive cost, limiting Predictive Maintenance strategies for vehicle fleets. This paper presents a measurement-based virtual sensing technique where local strain gauges are only required for few reference vehicles, while the remaining fleet relies exclusively on accelerometers. The scattering transform is used to perform feature extraction, while principal component analysis provides a reduced, low dimensional data representation. This enables direct fatigue damage regression, parameterized from unlabeled usage data. Identification measurements allow for a physical interpretation of the reduced representation. The approach is demonstrated using experimental data from a sensor equipped eBike, which is made publicly available.

Paper number 132:
Title: Once-Training-All-Fine: No-Reference Point Cloud Quality Assessment via Domain-relevance Degradation Description
Authors: Yipeng Liu, Qi Yang, Yujie Zhang, Yiling Xu, Le Yang, Xiaozhong Xu, Shan Liu
Abstract: The visual quality of point clouds plays a crucial role in the development and broadcasting of immersive media. Therefore, investigating point cloud quality assessment (PCQA) is instrumental in facilitating immersive media applications, including virtual reality and augmented reality applications. Considering reference point clouds are not available in many cases, no-reference (NR) metrics have become a research hotspot. Existing NR methods suffer from difficult training. To address this shortcoming, we propose a novel NR-PCQA method, Point Cloud Quality Assessment via Domain-relevance Degradation Description (D$^3$-PCQA). First, we demonstrate our model's interpretability by deriving the function of each module using a kernelized ridge regression model. Specifically, quality assessment can be characterized as a leap from the scattered perceptual domain (reflecting subjective perception) to the ordered quality domain (reflecting mean opinion score). Second, to reduce the significant domain discrepancy, we establish an intermediate domain, the description domain, based on insights from the human visual system (HVS), by considering the domain relevance among samples located in the perception domain and learning a structured latent space. The anchor features derived from the learned latent space are generated as cross-domain auxiliary information to promote domain transformation. Furthermore, the newly established description domain decomposes the NR-PCQA problem into two relevant stages. These stages include a classification stage that gives the degradation descriptions to point clouds and a regression stage to determine the confidence degrees of descriptions, providing a semantic explanation for the predicted quality scores. Experimental results demonstrate that D$^3$-PCQA exhibits robust performance and outstanding generalization on several publicly available datasets.

Paper number 133:
Title: Causality-based Cost Allocation for Peer-to-Peer Energy Trading in Distribution System
Authors: Hyun Joong Kim, Yong Hyun Song, Jip Kim
Abstract: While peer-to-peer energy trading has the potential to harness the capabilities of small-scale energy resources, a peer-matching process often overlooks power grid conditions, yielding increased losses, line congestion, and voltage problems. This imposes a great challenge on the distribution system operator (DSO), which can eventually limit peer-to-peer energy trading. To align the peer-matching process with the physical grid conditions, this paper proposes a cost causality-based network cost allocation method and the grid-aware peer-matching process. Building on the cost causality principle, the proposed model utilizes the network cost (loss, congestion, and voltage) as a signal to encourage peers to adjust their preferences ensuring that matches are more in line with grid conditions, leading to enhanced social welfare. Additionally, this paper presents mathematical proof showing the superiority of the causality-based cost allocation over existing methods.

Paper number 134:
Title: Scanning diffraction imaging without stable illumination and scan position information
Authors: Tao Liu, Bingyang Wang, JiangTao Zhao, Maik Kahnt, Fucai Zhang
Abstract: Ptychography has become prominent at synchrotron facilities worldwide for characterizing biological and material specimens' topological structures and properties at the nanometer or atomic scale, due to its lens - less, highly quantitative phase imaging. Its high - resolution imaging depends on accurate lateral scan position info, a large overlap ratio, and a stable probe function. But as research moves to atomic scales, meeting these requirements gets harder, often needing high - precision motion control and manual pre - calibration. This paper presents a new imaging framework. By adding a wavefront modulator and a new phase retrieval workflow, it removes the strict requirements of traditional ptychography. Significantly, our method doesn't need pre - calibration of the wavefront modulator. Optical validation showed the deviation between the recovered position and a top - tier motion stage was less than 10 nm. Sub - pixel position accuracy was achievable even with a 13% overlap ratio. In an X - ray experiment with a spatially unstable probe violating the ptychographic model and an 18% overlap ratio, our method simultaneously and quantitatively retrieved beam spatial deviation, scan position, probe function, and sample transmission function. Notably, it measured probe spatial deviations of 500nm along the X - axis and 50nm along the Y - axis, which is not feasible by previous methods. With these experimentally proven advantages, we anticipate our method to be a powerful imaging tool with auto - quantitative calibration of various parameters. It will simplify scanning diffraction microscopy implementation and expand its application scope, especially in nanometer and atomic scale imaging.

Paper number 135:
Title: Learning Exactly Linearizable Deep Dynamics Models
Authors: Ryuta Moriyasu, Masayuki Kusunoki, Kenji Kashima
Abstract: Research on control using models based on machine-learning methods has now shifted to the practical engineering stage. Achieving high performance and theoretically guaranteeing the safety of the system is critical for such applications. In this paper, we propose a learning method for exactly linearizable dynamical models that can easily apply various control theories to ensure stability, reliability, etc., and to provide a high degree of freedom of expression. As an example, we present a design that combines simple linear control and control barrier functions. The proposed model is employed for the real-time control of an automotive engine, and the results demonstrate good predictive performance and stable control under constraints.

Paper number 136:
Title: Antifragile Perimeter Control: Anticipating and Gaining from Disruptions with Reinforcement Learning
Authors: Linghang Sun, Michail A. Makridis, Alexander Genser, Cristian Axenie, Margherita Grossi, Anastasios Kouvelas
Abstract: The optimal operation of transportation networks is often susceptible to unexpected disruptions, such as traffic incidents and social events. Many established control strategies rely on mathematical models that struggle to cope with real-world uncertainties, leading to a significant decline in effectiveness when faced with substantial disruptions. While previous research works have dedicated efforts to improving the robustness or resilience of transportation systems against disruptions, this paper applies the cutting-edge concept of antifragility to better design a traffic control strategy for urban road networks. Antifragility sets itself apart from robustness and resilience as it represents a system's ability to not only withstand stressors, shocks, and volatility but also thrive and enhance performance in the presence of such adversarial events. Hence, modern transportation systems call for solutions that are antifragile. In this work, we propose a model-free deep Reinforcement Learning (RL) scheme to control a two-region urban traffic perimeter network. The system exploits the learning capability of RL under disruptions to achieve antifragility. By monitoring the change rate and curvature of the traffic state with the RL framework, the proposed algorithm anticipates imminent disruptions. An additional term is also integrated into the RL algorithm as redundancy to improve the performance under disruption scenarios. When compared to a state-of-the-art model predictive control approach and a state-of-the-art RL algorithm, our proposed method demonstrates two antifragility-related properties: (a) gradual performance improvement under disruptions of constant magnitude; and (b) increasingly superior performance under growing disruptions.

Paper number 137:
Title: Grid Monitoring with Synchro-Waveform and AI Foundation Model Technologies
Authors: Lang Tong, Xinyi Wang, Qing Zhao
Abstract: Purpose:This article advocates for the development of a next-generation grid monitoring and control system designed for future grids dominated by inverter-based resources. Leveraging recent progress in generative artificial intelligence (AI), machine learning, and networking technology, we develop a physics-based AI foundation model with high-resolution synchro-waveform measurement technology to enhance grid resilience and reduce economic losses from outages. Methods and Results:The proposed framework adopts the AI Foundation Model paradigm, where a generative and pre-trained (GPT) foundation model extracts physical features from power system measurements, enabling adaptation to a wide range of grid operation tasks. Replacing the large language models used in popular AI foundation models, this approach is based on the Wiener-Kallianpur-Rosenblatt innovation model for power system time series, trained to capture the physical laws of power flows and sinusoidal characteristics of grid measurements. The pre-trained foundation model causally extracts sufficient statistics from grid measurement time series for various downstream applications, including anomaly detection, over-current protection, probabilistic forecasting, and data compression for streaming synchro-waveform data. Numerical simulations using field-collected data demonstrate significantly improved fault detection accuracy and detection speed. Conclusion:The future grid will be rich in inverter-based resources, making it highly dynamic, stochastic, and low inertia. This work underscores the limitations of existing Supervisory-Control-and-Data-Acquisition and Phasor-Measurement-Unit monitoring systems and advocates for AI-enabled monitoring and control with high-resolution synchro-waveform technology to provide accurate situational awareness, rapid response to faults, and robust network protection.

Paper number 138:
Title: Discrete-Time Modeling and Handover Analysis of Intelligent Reflecting Surface-Assisted Networks
Authors: Haoyan Wei, Hongtao Zhang
Abstract: Owning to the reflection gain and double path loss featured by intelligent reflecting surface (IRS) channels, handover (HO) locations become irregular and the signal strength fluctuates sharply with variations in IRS connections during HO, the risk of HO failures (HOFs) is exacerbated and thus HO parameters require reconfiguration. However, existing HO models only assume monotonic negative exponential path loss and cannot obtain sound HO parameters. This paper proposes a discrete-time model to explicitly track the HO process with variations in IRS connections, where IRS connections and HO process are discretized as finite states by measurement intervals, and transitions between states are modeled as stochastic processes. Specifically, to capture signal fluctuations during HO, IRS connection state-dependent distributions of the user-IRS distance are modified by the correlation between measurement intervals. In addition, states of the HO process are formed with Time-to-Trigger and HO margin whose transition probabilities are integrated concerning all IRS connection states. Trigger location distributions and probabilities of HO, HOF, and ping-pong (PP) are obtained by tracing user HO states. Results show IRSs mitigate PPs by 48% but exacerbate HOFs by 90% under regular parameters. Optimal parameters are mined ensuring probabilities of HOF and PP are both less than 0.1%.

Paper number 139:
Title: Analysis of Intelligent Reflecting Surface-Enhanced Mobility Through a Line-of-Sight State Transition Model
Authors: Haoyan Wei, Hongtao Zhang
Abstract: Rapid signal fluctuations due to blockage effects cause excessive handovers (HOs) and degrade mobility performance. By reconfiguring line-of-sight (LoS) Links through passive reflections, intelligent reflective surface (IRS) has the potential to address this issue. Due to the lack of introducing blocking effects, existing HO analyses cannot capture excessive HOs or exploit enhancements via IRSs. This paper proposes an LoS state transition model enabling analysis of mobility enhancement achieved by IRS-reconfigured LoS links, where LoS link blocking and reconfiguration utilizing IRS during user movement are explicitly modeled as stochastic processes. Specifically, the condition for blocking LoS links is characterized as a set of possible blockage locations, the distribution of available IRSs is thinned by the criteria for reconfiguring LoS links. In addition, BSs potentially handed over are categorized by probabilities of LoS states to enable HO decision analysis. By projecting distinct gains of LoS states onto a uniform equivalent distance criterion, mobility enhanced by IRS is quantified through the compact expression of HO probability. Results show the probability of dropping into non-LoS due to movement decreases by 70% when deploying IRSs with the density of 93/km$^2$, and HOs decrease by 57% under the optimal IRS distributed deployment parameter.

Paper number 140:
Title: A Modified da Vinci Surgical Instrument for OCE based Elasticity Estimation with Deep Learning
Authors: Maximilian Neidhardt, Robin Mieling, Sarah Latus, Martin Fischer, Tobias Maurer, Alexander Schlaefer
Abstract: Robot-assisted surgery has advantages compared to conventional laparoscopic procedures, e.g., precise movement of the surgical instruments, improved dexterity, and high-resolution visualization of the surgical field. However, mechanical tissue properties may provide additional information, e.g., on the location of lesions or vessels. While elastographic imaging has been proposed, it is not readily available as an online modality during robot-assisted surgery. We propose modifying a da~Vinci surgical instrument to realize optical coherence elastography (OCE) for quantitative elasticity estimation. The modified da~Vinci instrument is equipped with piezoelectric elements for shear wave excitation and we employ fast optical coherence tomography (OCT) imaging to track propagating wave fields, which are directly related to biomechanical tissue properties. All high-voltage components are mounted at the proximal end outside the patient. We demonstrate that external excitation at the instrument shaft can effectively stimulate shear waves, even when considering damping. Comparing conventional and deep learning-based signal processing, resulting in mean absolute errors of 19.27 kPa and 6.29 kPa, respectively. These results illustrate that precise quantitative elasticity estimates can be obtained. We also demonstrate quantitative elasticity estimation on ex-vivo tissue samples of heart, liver and stomach, and show that the measurements can be used to distinguish soft and stiff tissue types.

Paper number 141:
Title: Near-Field Communications with Block-Dominant Compressed Sensing: Fundamentals, Approaches, and Future Directions
Authors: Liyang Lu, Ke Ma, Yue Wang, Zhaocheng Wang
Abstract: In the context of extremely large-scale antenna arrays deployed in sixth-generation (6G) mobile networks, near-field (NF) communications have gained considerable attention. Unlike the planar waves formulated in the far-field, electromagnetic radiation propagates as spherical waves in the NF. This alteration affects the NF channel characteristics, particularly resulting in weak sparsity in angular-domain NF channels, which poses tricky challenges to the application of compressed sensing (CS). Motivated by these facts, the block-dominant compressed sensing (BD-CS) techniques are proposed to assist NF communications. This article starts with the introduction on why block sparsity exists in the distance-limited NF region. Then, block-dominant side-information (BD-SI) is exploited to facilitate the actual NF communication implementation. While BD-CS shows promise in providing exceptional channel estimation accuracy and high spectral efficiency, several key challenges, opportunities, and practical implementation issues in NF communications need careful consideration.

Paper number 142:
Title: Jammer-Resilient Time Synchronization in the MIMO Uplink
Authors: Gian Marti, Flurin Arquint, Christoph Studer
Abstract: Spatial filtering based on multiple-input multiple-output (MIMO) processing is a promising approach to jammer mitigation. Effective MIMO data detectors that mitigate smart jammers have recently been proposed, but they all assume perfect time synchronization between transmitter(s) and receiver. However, to the best of our knowledge, there are no methods for resilient time synchronization in the presence of smart jammers. To remedy this situation, we propose JASS, the first method that enables reliable time synchronization for the single-user MIMO uplink while mitigating smart jamming attacks. JASS detects a randomized synchronization sequence based on a novel optimization problem that fits a spatial filter to the time-windowed receive signal in order to mitigate the jammer. We underscore the efficacy of the proposed optimization problem by proving that it ensures successful time synchronization under certain intuitive conditions. We then derive an efficient algorithm for approximately solving our optimization problem. Finally, we use simulations to demonstrate the effectiveness of JASS against a wide range of different jammer types.

Paper number 143:
Title: Sustainable and Precision Agriculture with the Internet of Everything (IoE)
Authors: Adil Z. Babar, Ozgur B. Akan
Abstract: Agriculture faces critical challenges from population growth, resource scarcity, and climate change, driving a shift toward advanced, technology-integrated farming. Mechanization has transformed agriculture, enhancing sustainability and crop productivity. Now, technologies like artificial intelligence (AI), robotics, biotechnology, blockchain, and the Internet of Things (IoT) are advancing precision agriculture. The concept of the Internet of Everything (IoE) has gained traction due to its holistic approach to integrating various IoT specializations, called IoXs with X referring to a specific domain. This paper explores the transformative role of IoE in agriculture, expanding beyond traditional IoT applications to integrate niche subdomains like molecular communication (MC), the Internet of Nano Things (IoNT), the Internet of Bio-Nano Things (IoBNT), designer phages, and the Internet of Fungus (IoF). Our study provides a detailed review of how these IoE subdomains, in conjunction with 6G, blockchain, and machine learning (ML), can enhance precision farming in areas like crop monitoring, resource management, and disease control. Unlike prior IoT centric reviews, this work uniquely focuses on IoEs potential to advance agriculture at molecular and biological scales, achieving more precise resource utilization and resilience. Key contributions include an exploration of these technologies applicability, associated challenges, and recommendations for future research directions within precision agriculture.

Paper number 144:
Title: Learning to Slice Wi-Fi Networks: A State-Augmented Primal-Dual Approach
Authors: Yiğit Berkay Uslu, Roya Doostnejad, Alejandro Ribeiro, Navid NaderiAlizadeh
Abstract: Network slicing is a key feature in 5G/NG cellular networks that creates customized slices for different service types with various quality-of-service (QoS) requirements, which can achieve service differentiation and guarantee service-level agreement (SLA) for each service type. In Wi-Fi networks, there is limited prior work on slicing, and a potential solution is based on a multi-tenant architecture on a single access point (AP) that dedicates different channels to different slices. In this paper, we define a flexible, constrained learning framework to enable slicing in Wi-Fi networks subject to QoS requirements. We specifically propose an unsupervised learning-based network slicing method that leverages a state-augmented primal-dual algorithm, where a neural network policy is trained offline to optimize a Lagrangian function and the dual variable dynamics are updated online in the execution phase. We show that state augmentation is crucial for generating slicing decisions that meet the ergodic QoS requirements.

Paper number 145:
Title: A Deep Joint Source-Channel Coding Scheme for Hybrid Mobile Multi-hop Networks
Authors: Chenghong Bian, Yulin Shao, Deniz Gündüz
Abstract: Efficient data transmission across mobile multi-hop networks that connect edge devices to core servers presents significant challenges, particularly due to the variability in link qualities between wireless and wired segments. This variability necessitates a robust transmission scheme that transcends the limitations of existing deep joint source-channel coding (DeepJSCC) strategies, which often struggle at the intersection of analog and digital methods. Addressing this need, this paper introduces a novel hybrid DeepJSCC framework, h-DJSCC, tailored for effective image transmission from edge devices through a network architecture that includes initial wireless transmission followed by multiple wired hops. Our approach harnesses the strengths of DeepJSCC for the initial, variable-quality wireless link to avoid the cliff effect inherent in purely digital schemes. For the subsequent wired hops, which feature more stable and high-capacity connections, we implement digital compression and forwarding techniques to prevent noise accumulation. This dual-mode strategy is adaptable even in scenarios with limited knowledge of the image distribution, enhancing the framework's robustness and utility. Extensive numerical simulations demonstrate that our hybrid solution outperforms traditional fully digital approaches by effectively managing transitions between different network segments and optimizing for variable signal-to-noise ratios (SNRs). We also introduce a fully adaptive h-DJSCC architecture {with both SNR-adaptive (SA) and rate-adaptive (RA) modules} capable of adjusting to different network conditions and achieving diverse rate-distortion objectives, thereby reducing the memory requirements on network nodes.

Paper number 146:
Title: Learning Point Spread Function Invertibility Assessment for Image Deconvolution
Authors: Romario Gualdrón-Hurtado, Roman Jacome, Sergio Urrea, Henry Arguello, Luis Gonzalez
Abstract: Deep-learning (DL)-based image deconvolution (ID) has exhibited remarkable recovery performance, surpassing traditional linear methods. However, unlike traditional ID approaches that rely on analytical properties of the point spread function (PSF) to achieve high recovery performance - such as specific spectrum properties or small conditional numbers in the convolution matrix - DL techniques lack quantifiable metrics for evaluating PSF suitability for DL-assisted recovery. Aiming to enhance deconvolution quality, we propose a metric that employs a non-linear approach to learn the invertibility of an arbitrary PSF using a neural network by mapping it to a unit impulse. A lower discrepancy between the mapped PSF and a unit impulse indicates a higher likelihood of successful inversion by a DL network. Our findings reveal that this metric correlates with high recovery performance in DL and traditional methods, thereby serving as an effective regularizer in deconvolution tasks. This approach reduces the computational complexity over conventional condition number assessments and is a differentiable process. These useful properties allow its application in designing diffractive optical elements through end-to-end (E2E) optimization, achieving invertible PSFs, and outperforming the E2E baseline framework.

Paper number 147:
Title: DiffCom: Channel Received Signal is a Natural Condition to Guide Diffusion Posterior Sampling
Authors: Sixian Wang, Jincheng Dai, Kailin Tan, Xiaoqi Qin, Kai Niu, Ping Zhang
Abstract: End-to-end visual communication systems typically optimize a trade-off between channel bandwidth costs and signal-level distortion metrics. However, under challenging physical conditions, this traditional coding and transmission paradigm often results in unrealistic reconstructions with perceptible blurring and aliasing artifacts, despite the inclusion of perceptual or adversarial losses for optimizing. This issue primarily stems from the receiver's limited knowledge about the underlying data manifold and the use of deterministic decoding mechanisms. To address these limitations, this paper introduces DiffCom, a novel end-to-end generative communication paradigm that utilizes off-the-shelf generative priors and probabilistic diffusion models for decoding, thereby improving perceptual quality without heavily relying on bandwidth costs and received signal quality. Unlike traditional systems that rely on deterministic decoders optimized solely for distortion metrics, our DiffCom leverages raw channel-received signal as a fine-grained condition to guide stochastic posterior sampling. Our approach ensures that reconstructions remain on the manifold of real data with a novel confirming constraint, enhancing the robustness and reliability of the generated outcomes. Furthermore, DiffCom incorporates a blind posterior sampling technique to address scenarios with unknown forward transmission characteristics. Extensive experimental validations demonstrate that DiffCom not only produces realistic reconstructions with details faithful to the original data but also achieves superior robustness against diverse wireless transmission degradations. Collectively, these advancements establish DiffCom as a new benchmark in designing generative communication systems that offer enhanced robustness and generalization superiorities.

Paper number 148:
Title: High Performance 5G FR-2 Millimeter-Wave Antenna Array for Point-to-Point and Point-to-Multipoint Operation: Design and OTA Measurements Using a Compact Antenna Test Range
Authors: Abdul Jabbar, Jalil Ur-Rehman Kazim, Mahmoud A. Shawky, Muhammad Ali Imran, Qammer Abbasi, Muhammad Usman, Masood Ur-Rehman
Abstract: This paper presents the design and comprehensive measurements of a high-performance 8-element linear array and a compact high-gain 32-element planar antenna array covering the n257 (26.5--29.5 GHz) FR-2 millimeter-wave (mmWave) band. First, an 8-element series-fed linear array is designed with a fan-shaped pattern for 5G point-to-multipoint connectivity. Then a 4-way corporate-series feed network is designed for a high-gain 32-element compact and directive array for point-to-point mmWave connectivity. Comprehensive over-the-air (OTA) measurements are conducted using a state-of-the-art compact antenna test range (CATR) system, enabling precise characterization of radiation patterns across a 180^\circ span in the azimuth and elevation planes. The planar array achieves a peak measured gain of 18.45 dBi at 28.5 GHz, with half-power beamwidths ranging from 11^\circ--13^\circ (wide axis) and 23^\circ--27^\circ (narrow axis) across the band of interest. The sidelobe levels are below -10 dB in the desired band of interest. The measured results match well with the simulation results. The designed antenna array is applicable to various emerging 5G and beyond mmWave applications such as high data rate mmWave wireless backhaul, mmWave near-field focusing, high-resolution indoor radar systems, 28 GHz Local Multipoint Distribution Service (LMDS), as well as the characterization of mmWave path loss and channel sounding in diverse indoor environments.

Paper number 149:
Title: Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach
Authors: Alireza Saber, Pouria Parhami, Alimohammad Siahkarzadeh, Mansoor Fateh, Amirreza Fateh
Abstract: Pneumonia, a prevalent respiratory infection, remains a leading cause of morbidity and mortality worldwide, particularly among vulnerable populations. Chest X-rays serve as a primary tool for pneumonia detection; however, variations in imaging conditions and subtle visual indicators complicate consistent interpretation. Automated tools can enhance traditional methods by improving diagnostic reliability and supporting clinical decision-making. In this study, we propose a novel multi-scale transformer approach for pneumonia detection that integrates lung segmentation and classification into a unified framework. Our method introduces a lightweight transformer-enhanced TransUNet for precise lung segmentation, achieving a Dice score of 95.68% on the "Chest X-ray Masks and Labels" dataset with fewer parameters than traditional transformers. For classification, we employ pre-trained ResNet models (ResNet-50 and ResNet-101) to extract multi-scale feature maps, which are then processed through a modified transformer module to enhance pneumonia detection. This integration of multi-scale feature extraction and lightweight transformer modules ensures robust performance, making our method suitable for resource-constrained clinical environments. Our approach achieves 93.75% accuracy on the "Kermany" dataset and 96.04% accuracy on the "Cohen" dataset, outperforming existing methods while maintaining computational efficiency. This work demonstrates the potential of multi-scale transformer architectures to improve pneumonia diagnosis, offering a scalable and accurate solution to global healthcare challenges."this https URL

Paper number 150:
Title: Beyond the Neural Fog: Interpretable Learning for AC Optimal Power Flow
Authors: Salvador Pineda, Juan Pérez-Ruiz, Juan Miguel Morales
Abstract: The AC optimal power flow (AC-OPF) problem is essential for power system operations, but its non-convex nature makes it challenging to solve. A widely used simplification is the linearized DC optimal power flow (DC-OPF) problem, which can be solved to global optimality, but whose optimal solution is always infeasible in the original AC-OPF problem. Recently, neural networks (NN) have been introduced for solving the AC-OPF problem at significantly faster computation times. However, these methods necessitate extensive datasets, are difficult to train, and are often viewed as black boxes, leading to resistance from operators who prefer more transparent and interpretable solutions. In this paper, we introduce a novel learning-based approach that merges simplicity and interpretability, providing a bridge between traditional approximation methods and black-box learning techniques. Our approach not only provides transparency for operators but also achieves competitive accuracy. Numerical results across various power networks demonstrate that our method provides accuracy comparable to, and often surpassing, that of neural networks, particularly when training datasets are limited.

Paper number 151:
Title: Fast Burst-Sparsity Learning Approach for Massive MIMO-OTFS Channel Estimation
Authors: Ming Ma, Jisheng Dai, Xue-Qin Jiang
Abstract: Accurate channel estimation in orthogonal time frequency space (OTFS) systems with massive multiple-input multiple-output (MIMO) configurations is challenging due to high-dimensional sparse representation (SR). Existing methods often face performance degradation and/or high computational complexity. To address these issues and exploit intricate channel sparsity structure, this letter first leverages a novel hybrid burst-sparsity prior to capture the burst/common sparse structure in the angle/delay domain, and then utilizes an independent variational Bayesian inference (VBI) factorization technique to efficiently solve the high-dimensional SR problem. Additionally, an angle/Doppler refinement approach is incorporated into the proposed method to automatically mitigate off-grid mismatches.

Paper number 152:
Title: MSFMamba: Multi-Scale Feature Fusion State Space Model for Multi-Source Remote Sensing Image Classification
Authors: Feng Gao, Xuepeng Jin, Xiaowei Zhou, Junyu Dong, Qian Du
Abstract: In the field of multi-source remote sensing image classification, remarkable progress has been made by using Convolutional Neural Network (CNN) and Transformer. Recently, Mamba-based methods built upon the State Space Model (SSM) have shown great potential for long-range dependency modeling with linear complexity, but they have rarely been explored for multi-source remote sensing image classification tasks. To address this issue, we propose the Multi-Scale Feature Fusion Mamba (MSFMamba) network, a novel framework designed for the joint classification of hyperspectral image (HSI) and Light Detection and Ranging (LiDAR)/Synthetic Aperture Radar (SAR) data. The MSFMamba network is composed of three key components: the Multi-Scale Spatial Mamba (MSpa-Mamba) block, the Spectral Mamba (Spe-Mamba) block, and the Fusion Mamba (Fus-Mamba) block. The MSpa-Mamba block employs a multi-scale strategy to reduce computational cost and alleviate feature redundancy in multiple scanning routes, ensuring efficient spatial feature modeling. The Spe-Mamba block focuses on spectral feature extraction, addressing the unique challenges of HSI data representation. Finally, the Fus-Mamba block bridges the heterogeneous gap between HSI and LiDAR/SAR data by extending the original Mamba architecture to accommodate dual inputs, enhancing cross-modal feature interactions and enabling seamless data fusion. Together, these components enable MSFMamba to effectively tackle the challenges of multi-source data classification, delivering improved performance with optimized computational efficiency. Comprehensive experiments on four real-world multi-source remote sensing datasets demonstrate the superiority of MSFMamba outperforms several state-of-the-art methods. The source codes of MSFMamba are publicly available at this https URL.

Paper number 153:
Title: Practical Challenges for Reliable RIS Deployment in Heterogeneous Multi-Operator Multi-Band Networks
Authors: Mehdi Monemi, Mehdi Rasti, Arthur S. de Sena, Mohammad Amir Fallah, Matti Latva-Aho, Marco Di Renzo
Abstract: Reconfigurable intelligent surfaces (RISs) have been introduced as arrays of nearly passive elements with software-tunable electromagnetic properties to dynamically manipulate the reflection/transmission of radio signals. Research works in this area are focused on two applications, namely {\it user-assist} RIS aiming at tuning the RIS to enhance the quality-of-service (QoS) of target users, and the {\it malicious} RIS aiming for an attacker to degrade the QoS at victim receivers through generating {\it intended} destructive interference. While both user-assist and malicious RIS applications have been explored extensively, the impact of RIS deployments on imposing {\it unintended} interference on various wireless user-equipments (EUs) remains underexplored. This paper investigates the challenges of integrating RISs into multi-carrier, multi-user, and multi-operator networks. We discuss how RIS deployments intended to benefit specific users can negatively impact other users served at various carrier frequencies through different network operators. While not an ideal solution, we discuss how ultra-narrowband metasurfaces can be incorporated into the manufacturing of RISs to mitigate some challenges of RIS deployment in wireless networks. We also present a simulation scenario to illuminate some practical challenges associated with the deployment of RISs in shared public environments.

Paper number 154:
Title: SINDyG: Sparse Identification of Nonlinear Dynamical Systems from Graph-Structured Data
Authors: Mohammad Amin Basiri, Sina Khanmohammadi
Abstract: The combination of machine learning (ML) and sparsity-promoting techniques is enabling direct extraction of governing equations from data, revolutionizing computational modeling in diverse fields of science and engineering. The discovered dynamical models could be used to address challenges in climate science, neuroscience, ecology, finance, epidemiology, and beyond. However, most existing sparse identification methods for discovering dynamical systems treat the whole system as one without considering the interactions between subsystems. As a result, such models are not able to capture small changes in the emergent system behavior. To address this issue, we developed a new method called Sparse Identification of Nonlinear Dynamical Systems from Graph-structured data (SINDyG), which incorporates the network structure into sparse regression to identify model parameters that explain the underlying network dynamics. We showcase the application of our proposed method using several case studies of neuronal dynamics, where we model the macroscopic oscillation of a population of neurons using the extended Stuart-Landau (SL) equation and utilize the SINDyG method to identify the underlying nonlinear dynamics. Our extensive computational experiments validate the improved accuracy and simplicity of discovered network dynamics when compared to the original SINDy approach.

Paper number 155:
Title: Transfer Learning and Double U-Net Empowered Wave Propagation Model in Complex Indoor Environment
Authors: Ziheng Fu, Swagato Mukherjee, Michael T. Lanagan, Prasenjit Mitra, Tarun Chawla, Ram M. Narayanan
Abstract: A Machine Learning (ML) network based on transfer learning and transformer networks is applied to wave propagation models for complex indoor settings. This network is designed to predict signal propagation in environments with a variety of objects, effectively simulating the diverse range of furniture typically found in indoor spaces. We propose Attention U-Net with Efficient Networks as the backbone, to process images encoded with the essential information of the indoor environment. The indoor environment is defined by its fundamental structure, such as the arrangement of walls, windows, and doorways, alongside varying configurations of furniture placement. An innovative algorithm is introduced to generate a 3D environment from a 2D floorplan, which is crucial for efficient collection of data for training. The model is evaluated by comparing the predicted signal coverage map with ray tracing (RT) simulations. The prediction results show a root mean square error of less than 6 dB across all tested scenarios, with significant improvements observed when using a Double U-Net structure compared to a single U-Net model.

Paper number 156:
Title: DeSTA2: Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data
Authors: Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee
Abstract: Recent end-to-end speech language models (SLMs) have expanded upon the capabilities of large language models (LLMs) by incorporating pre-trained speech models. However, these SLMs often undergo extensive speech instruction-tuning to bridge the gap between speech and text modalities. This requires significant annotation efforts and risks catastrophic forgetting of the original language capabilities. In this work, we present a simple yet effective automatic process for creating speech-text pair data that carefully injects speech paralinguistic understanding abilities into SLMs while preserving the inherent language capabilities of the text-based LLM. Our model demonstrates general capabilities for speech-related tasks without the need for speech instruction-tuning data, achieving impressive performance on Dynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits the ability to follow complex instructions derived from LLMs, such as specific output formatting and chain-of-thought reasoning. Our approach not only enhances the versatility and effectiveness of SLMs but also reduces reliance on extensive annotated datasets, paving the way for more efficient and capable speech understanding systems.

Paper number 157:
Title: RDEIC: Accelerating Diffusion-Based Extreme Image Compression with Relay Residual Diffusion
Authors: Zhiyuan Li, Yanhui Zhou, Hao Wei, Chenyang Ge, Ajmal Mian
Abstract: Diffusion-based extreme image compression methods have achieved impressive performance at extremely low bitrates. However, constrained by the iterative denoising process that starts from pure noise, these methods are limited in both fidelity and efficiency. To address these two issues, we present Relay Residual Diffusion Extreme Image Compression (RDEIC), which leverages compressed feature initialization and residual diffusion. Specifically, we first use the compressed latent features of the image with added noise, instead of pure noise, as the starting point to eliminate the unnecessary initial stages of the denoising process. Second, we directly derive a novel residual diffusion equation from Stable Diffusion's original diffusion equation that reconstructs the raw image by iteratively removing the added noise and the residual between the compressed and target latent features. In this way, we effectively combine the efficiency of residual diffusion with the powerful generative capability of Stable Diffusion. Third, we propose a fixed-step fine-tuning strategy to eliminate the discrepancy between the training and inference phases, thereby further improving the reconstruction quality. Extensive experiments demonstrate that the proposed RDEIC achieves state-of-the-art visual quality and outperforms existing diffusion-based extreme image compression methods in both fidelity and efficiency. The source code will be provided in this https URL.

Paper number 158:
Title: Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection
Authors: Christoforos Galazis, Huiyi Wu, Igor Goryanin
Abstract: Improving breast cancer detection and monitoring techniques is a critical objective in healthcare, driving the need for innovative imaging technologies and diagnostic approaches. This study introduces a novel multi-tiered self-contrastive model tailored for microwave radiometry (MWR) in breast cancer detection. Our approach incorporates three distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR (G-MWR), designed to analyze varying sub-regional comparisons within the breasts. These models are integrated through the Joint-MWR (J-MWR) network, which leverages self-contrastive results at each analytical level to improve diagnostic accuracy. Utilizing a dataset of 4,932 female patients, our research demonstrates the efficacy of our proposed models. Notably, the J-MWR model achieves a Matthew's correlation coefficient of 0.74 $\pm$ 0.018, surpassing existing MWR neural networks and contrastive methods. These findings highlight the potential of self-contrastive learning techniques in improving the diagnostic accuracy and generalizability for MWR-based breast cancer detection. This advancement holds considerable promise for future investigations into enabling point-of-care testing. The source code is available at: this https URL.

Paper number 159:
Title: LISAC: Learned Coded Waveform Design for ISAC with OFDM
Authors: Chenghong Bian, Yumeng Zhang, Deniz Gunduz
Abstract: We propose a novel deep learning based method to design a coded waveform for integrated sensing and communication (ISAC) system based on orthogonal frequency-division multiplexing (OFDM). Our ultimate goal is to design a coded waveform, which is capable of providing satisfactory sensing performance of the target while maintaining high communication quality measured in terms of the bit error rate (BER). The proposed LISAC provides an improved waveform design with the assistance of deep neural networks for the encoding and decoding of the information bits. In particular, the transmitter, parameterized by a recurrent neural network (RNN), encodes the input bit sequence into the transmitted waveform for both sensing and communications. The receiver employs a RNN-based decoder to decode the information bits while the transmitter senses the target via maximum likelihood detection. We optimize the system considering both the communication and sensing performance. Simulation results show that the proposed LISAC waveform achieves a better trade-off curve compared to existing alternatives.

Paper number 160:
Title: Towards Kriging-informed Conditional Diffusion for Regional Sea-Level Data Downscaling
Authors: Subhankar Ghosh, Arun Sharma, Jayant Gupta, Aneesh Subramanian, Shashi Shekhar
Abstract: Given coarser-resolution projections from global climate models or satellite data, the downscaling problem aims to estimate finer-resolution regional climate data, capturing fine-scale spatial patterns and variability. Downscaling is any method to derive high-resolution data from low-resolution variables, often to provide more detailed and local predictions and analyses. This problem is societally crucial for effective adaptation, mitigation, and resilience against significant risks from climate change. The challenge arises from spatial heterogeneity and the need to recover finer-scale features while ensuring model generalization. Most downscaling methods \cite{Li2020} fail to capture the spatial dependencies at finer scales and underperform on real-world climate datasets, such as sea-level rise. We propose a novel Kriging-informed Conditional Diffusion Probabilistic Model (Ki-CDPM) to capture spatial variability while preserving fine-scale features. Experimental results on climate data show that our proposed method is more accurate than state-of-the-art downscaling techniques.

Paper number 161:
Title: SpineFM: Leveraging Foundation Models for Automatic Spine X-ray Segmentation
Authors: Samuel J. Simons, Bartłomiej W. Papież
Abstract: This paper introduces SpineFM, a novel pipeline that achieves state-of-the-art performance in the automatic segmentation and identification of vertebral bodies in cervical and lumbar spine radiographs. SpineFM leverages the regular geometry of the spine, employing a novel inductive process to sequentially infer the location of each vertebra along the spinal column. Vertebrae are segmented using Medical-SAM-Adaptor, a robust foundation model that diverges from commonly used CNN-based models. We achieved outstanding results on two publicly available spine X-Ray datasets, with successful identification of 97.8\% and 99.6\% of annotated vertebrae, respectively. Of which, our segmentation reached an average Dice of 0.942 and 0.921, surpassing previous state-of-the-art methods.

Paper number 162:
Title: Multi-modal deformable image registration using untrained neural networks
Authors: Quang Luong Nhat Nguyen, Ruiming Cao, Laura Waller
Abstract: Image registration techniques usually assume that the images to be registered are of a certain type (e.g. single- vs. multi-modal, 2D vs. 3D, rigid vs. deformable) and there lacks a general method that can work for data under all conditions. We propose a registration method that utilizes neural networks for image representation. Our method uses untrained networks with limited representation capacity as an implicit prior to guide for a good registration. Unlike previous approaches that are specialized for specific data types, our method handles both rigid and non-rigid, as well as single- and multi-modal registration, without requiring changes to the model or objective function. We have performed a comprehensive evaluation study using a variety of datasets and demonstrated promising performance.

Paper number 163:
Title: Enhancing Brain Age Estimation with a Multimodal 3D CNN Approach Combining Structural MRI and AI-Synthesized Cerebral Blood Volume Data
Authors: Jordan Jomsky, Zongyu Li, Yiren Zhang, Tal Nuriel, Jia Guo
Abstract: The increasing global aging population necessitates improved methods to assess brain aging and its related neurodegenerative changes. Brain Age Gap Estimation (BrainAGE) offers a neuroimaging biomarker for understanding these changes by predicting brain age from MRI scans. Current approaches primarily use T1-weighted magnetic resonance imaging (T1w MRI) data, capturing only structural brain information. To address this limitation, AI-generated Cerebral Blood Volume (AICBV) data, synthesized from non-contrast MRI scans, offers functional insights by revealing subtle blood-tissue contrasts otherwise undetectable in standard imaging. We integrated AICBV with T1w MRI to predict brain age, combining both structural and functional metrics. We developed a deep learning model using a VGG-based architecture for both modalities and combined their predictions using linear regression. Our model achieved a mean absolute error (MAE) of 3.95 years and an $R^2$ of 0.943 on the test set ($n = 288$), outperforming existing models trained on similar data. We have further created gradient-based class activation maps (Grad-CAM) to visualize the regions of the brain that most influenced the model's predictions, providing interpretable insights into the structural and functional contributors to brain aging.

Paper number 164:
Title: Disturbance Observer-Parameterized Control Barrier Function with Adaptive Safety Bounds
Authors: Ziqi Yang, Lihua Xie
Abstract: This letter presents a nonlinear disturbance observer-parameterized control barrier function (DOp-CBF) designed for a robust safety control system under external disturbances. This framework emphasizes that the safety bounds are relevant to the disturbances, acknowledging the critical impact of disturbances on system safety. This work incorporates a disturbance observer (DO) as an adaptive mechanism of the safety bounds design. Instead of considering the worst-case scenario, the safety bounds are dynamically adjusted using DO. The forward invariance of the proposed method regardless of the observer error is ensured, and the corresponding optimal control formulation is presented. The performance of the proposed method is demonstrated through simulations of a cruise control problem under varying road grades. The influence of road grade on the safe distance between vehicles is analyzed and managed using a DO. The results demonstrate the advantages of this approach in maintaining safety and improving system performance under disturbances.

Paper number 165:
Title: Future Pathways for EVTOLs: A Design Optimization Perspective
Authors: Johannes Janning, Sophie F. Armanini, Urban Fasel
Abstract: The rapid development of advanced urban air mobility, particularly electric vertical take-off and landing (eVTOL) aircraft, requires interdisciplinary approaches involving the future urban air mobility ecosystem. Operational cost efficiency, regulatory aspects, sustainability, and environmental compatibility must be incorporated directly into the preliminary design of aircraft and across operational and regulatory strategies. In this work, we present a novel multidisciplinary design optimization framework for the preliminary design of eVTOL aircraft. The framework optimizes conventional design elements of eVTOL aircraft over a generic mission and integrates a comprehensive operational cost model to directly capture economic incentives of the designed system through profit modeling for operators. We compare the optimized eVTOL system with various competing road, rail, and air transportation modes in terms of sustainability, cost, and travel time. We investigate four objective-specific eVTOL optimization designs in a broad scenario space, mapping regulatory, technical, and operational constraints to generate a representation of potential urban air mobility ecosystem conditions. The analysis of an optimized profit-maximizing eVTOL, cost-minimizing eVTOL, sustainability-maximizing eVTOL, and a combined figure of merit maximizing eVTOL design highlights significant trade-offs in the area of profitability, operational flexibility, and sustainability strategies. This underlines the importance of incorporating multiple operationally tangential disciplines into the design process.

Paper number 166:
Title: Online Fault Tolerance Strategy for Abrupt Reachability Constraint Changes
Authors: Henghua Shen, Qixin Wang
Abstract: When a system's constraints change abruptly, the system's reachability safety does no longer sustain. Thus, the system can reach a forbidden/dangerous value. Conventional remedy practically involves online controller redesign (OCR) to re-establish the reachability's compliance with the new constraints, which, however, is usually too slow. There is a need for an online strategy capable of managing runtime changes in reachability constraints. However, to the best of the authors' knowledge, this topic has not been addressed in the existing literature. In this paper, we propose a fast fault tolerance strategy to recover the system's reachability safety in runtime. Instead of redesigning the system's controller, we propose to change the system's reference state to modify the system's reachability to comply with the new constraints. We frame the reference state search as an optimization problem and employ the Karush-Kuhn-Tucker (KKT) method as well as the Interior Point Method (IPM) based Newton's method (as a fallback for the KKT method) for fast solution derivation. The optimization also allows more future fault tolerance. Numerical simulations demonstrate that our method outperforms the conventional OCR method in terms of computational efficiency and success rate. Specifically, the results show that the proposed method finds a solution $10^{2}$ (with the IPM based Newton's method) $\sim 10^{4}$ (with the KKT method) times faster than the OCR method. Additionally, the improvement rate of the success rate of our method over the OCR method is $40.81\%$ without considering the deadline of run time. The success rate remains at $49.44\%$ for the proposed method, while it becomes $0\%$ for the OCR method when a deadline of $1.5 \; seconds$ is imposed.

Paper number 167:
Title: Linear Model of Aggregated Homogeneous Energy Storage Elements with Realizable Dispatch Guarantees
Authors: Mazen Elsaadany, Mads R. Almassalkhi, Simon H. Tindemans
Abstract: To optimize battery dispatch, a model is required that can predict the state of charge (SOC) trajectory and ensure dispatch is admissible (i.e., does not lead to unexpected SOC saturation). However, battery dispatch optimization is inherently challenging since batteries cannot simultaneously charge and discharge, which begets a non-convex complementarity constraint. In this paper, we consider a composition of energy storage elements that can charge or discharge independently and provide a sufficient linear energy storage model of the composite battery. This permits convex optimization of the composite battery SOC trajectory while ensuring admissibility of the resulting (aggregated) power schedule and disaggregation to the individual energy storage elements.

Paper number 168:
Title: BOOST: Microgrid Sizing using Ordinal Optimization
Authors: Mohamad Fares El Hajj Chehade, Sami Karaki
Abstract: The transition to sustainable energy systems has highlighted the critical need for efficient sizing of renewable energy resources in microgrids. In particular, designing photovoltaic (PV) and battery systems to meet residential loads is challenging due to trade-offs between cost, reliability, and environmental impact. While previous studies have employed dynamic programming and heuristic techniques for microgrid sizing, these approaches often fail to balance computational efficiency and accuracy. In this work, we propose BOOST, or Battery-solar Ordinal Optimization Sizing Technique, a novel framework for optimizing the sizing of PV and battery components in microgrids. Ordinal optimization enables computationally efficient evaluations of potential designs while preserving accuracy through robust ranking of solutions. To determine the optimal operation of the system at any given time, we introduce a mixed-integer linear programming (MILP) approach, which achieves lower costs than the commonly used dynamic programming methods. Our numerical experiments demonstrate that the proposed framework identifies optimal designs that achieve a levelized cost of energy (LCOE) as low as 8.84 cents/kWh, underscoring its potential for cost-effective microgrid design. The implications of our work are significant: BOOST provides a scalable and accurate methodology for integrating renewable energy into residential microgrids, addressing economic and environmental goals simultaneously.

Paper number 169:
Title: Diffusion based Text-to-Music Generation with Global and Local Text based Conditioning
Authors: Jisi Zhang, Pablo Peso Parada, Md Asif Jalal, Karthikeyan Saravanan
Abstract: Diffusion based Text-To-Music (TTM) models generate music corresponding to text descriptions. Typically UNet based diffusion models condition on text embeddings generated from a pre-trained large language model or from a cross-modality audio-language representation model. This work proposes a diffusion based TTM, in which the UNet is conditioned on both (i) a uni-modal language model (e.g., T5) via cross-attention and (ii) a cross-modal audio-language representation model (e.g., CLAP) via Feature-wise Linear Modulation (FiLM). The diffusion model is trained to exploit both a local text representation from the T5 and a global representation from the CLAP. Furthermore, we propose modifications that extract both global and local representations from the T5 through pooling mechanisms that we call mean pooling and self-attention pooling. This approach mitigates the need for an additional encoder (e.g., CLAP) to extract a global representation, thereby reducing the number of model parameters. Our results show that incorporating the CLAP global embeddings to the T5 local embeddings enhances text adherence (KL=1.47) compared to a baseline model solely relying on the T5 local embeddings (KL=1.54). Alternatively, extracting global text embeddings directly from the T5 local embeddings through the proposed mean pooling approach yields superior generation quality (FAD=1.89) while exhibiting marginally inferior text adherence (KL=1.51) against the model conditioned on both CLAP and T5 text embeddings (FAD=1.94 and KL=1.47). Our proposed solution is not only efficient but also compact in terms of the number of parameters required.

Paper number 170:
Title: Gland Segmentation Using SAM With Cancer Grade as a Prompt
Authors: Yijie Zhu, Shan E Ahmed Raza
Abstract: Cancer grade is a critical clinical criterion that can be used to determine the degree of cancer malignancy. Revealing the condition of the glands, a precise gland segmentation can assist in a more effective cancer grade classification. In machine learning, binary classification information about glands (i.e., benign and malignant) can be utilized as a prompt for gland segmentation and cancer grade classification. By incorporating prior knowledge of the benign or malignant classification of the gland, the model can anticipate the likely appearance of the target, leading to better segmentation performance. We utilize Segment Anything Model to solve the segmentation task, by taking advantage of its prompt function and applying appropriate modifications to the model structure and training strategies. We improve the results from fine-tuned Segment Anything Model and produce SOTA results using this approach.

Paper number 171:
Title: Tube-based Robust Model Predictive Control for a Distributed Parameter System Modeled as a Polytopic LPV (extended version)
Authors: Joe Ismail, Steven Liu
Abstract: Distributed parameter systems (DPS) are formulated as partial differential equations (PDE). Especially, under time-varying boundary conditions, PDE introduce force coupling. In the case of the flexible stacker crane (STC), nonlinear coupling is introduced. Accordingly, online trajectory planning and tracking can be addressed using a nonlinear model predictive control (NMPC). However, due to the high computational demands of a NMPC, this paper discusses a possibility of embedding nonlinearities inside a linear parameter varying (LPV) system and thus make a use of a numerically low-demanding linear MPC. The resulting mismatches are treated as parametric and additive uncertainties in the context of robust tube-based MPC (TMPC). For the proposed approach, most of the computations are carried out offline. Only a simple convex quadratic program (QP) is conducted online. Additionally a soft-constrained extension was briefly proposed. Simulation results are used to illustrate the good performance, closed-loop stability and recursive feasibility of the proposed approach despite uncertainties.

Paper number 172:
Title: Distributed Model Predictive Covariance Steering
Authors: Augustinos D. Saravanos, Isin M. Balci, Efstathios Bakolas, Evangelos A. Theodorou
Abstract: This paper proposes Distributed Model Predictive Covariance Steering (DiMPCS) for multi-agent control under stochastic uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single framework that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-agent system to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers. This method is then extended to a receding horizon form, which yields the proposed DiMPCS algorithm. Simulation experiments on a variety of multi-robot tasks with up to hundreds of robots demonstrate the effectiveness of DiMPCS. The superior scalability and performance of the proposed method is also highlighted through a comparison against related stochastic MPC approaches. Finally, hardware results on a multi-robot platform also verify the applicability of DiMPCS on real systems. A video with all results is available in this https URL.

Paper number 173:
Title: Almost Surely $\sqrt{T}$ Regret for Adaptive LQR
Authors: Yiwen Lu, Yilin Mo
Abstract: The Linear-Quadratic Regulation (LQR) problem with unknown system parameters has been widely studied, but it has remained unclear whether $\tilde{ \mathcal{O}}(\sqrt{T})$ regret, which is the best known dependence on time, can be achieved almost surely. In this paper, we propose an adaptive LQR controller with almost surely $\tilde{ \mathcal{O}}(\sqrt{T})$ regret upper bound. The controller features a circuit-breaking mechanism, which circumvents potential safety breach and guarantees the convergence of the system parameter estimate, but is shown to be triggered only finitely often and hence has negligible effect on the asymptotic performance of the controller. The proposed controller is also validated via simulation on Tennessee Eastman Process~(TEP), a commonly used industrial process example.

Paper number 174:
Title: Differential Privacy with Higher Utility by Exploiting Coordinate-wise Disparity: Laplace Mechanism Can Beat Gaussian in High Dimensions
Authors: Gokularam Muthukrishnan, Sheetal Kalyani
Abstract: Conventionally, in a differentially private additive noise mechanism, independent and identically distributed (i.i.d.) noise samples are added to each coordinate of the response. In this work, we formally present the addition of noise that is independent but not identically distributed (i.n.i.d.) across the coordinates to achieve tighter privacy-accuracy trade-off by exploiting coordinate-wise disparity in privacy leakage. In particular, we study the i.n.i.d. Gaussian and Laplace mechanisms and obtain the conditions under which these mechanisms guarantee privacy. The optimal choice of parameters that ensure these conditions are derived considering (weighted) mean squared and $\ell_{p}^{p}$-errors as measures of accuracy. Theoretical analyses and numerical simulations demonstrate that the i.n.i.d. mechanisms achieve higher utility for the given privacy requirements compared to their i.i.d. counterparts. One of the interesting observations is that the Laplace mechanism outperforms Gaussian even in high dimensions, as opposed to the popular belief, if the irregularity in coordinate-wise sensitivities is exploited. We also demonstrate how the i.n.i.d. noise can improve the performance in private (a) coordinate descent, (b) principal component analysis, and (c) deep learning with group clipping.

Paper number 175:
Title: Continuous-Time Zeroth-Order Dynamics with Projection Maps: Model-Free Feedback Optimization with Safety Guarantees
Authors: Xin Chen, Jorge I. Poveda, Na Li
Abstract: This paper introduces a class of model-free feedback methods for solving generic constrained optimization problems where the specific mathematical forms of the objective and constraint functions are not available. The proposed methods, termed Projected Zeroth-Order (P-ZO) dynamics, incorporate projection maps into a class of continuous-time model-free dynamics that make use of periodic dithering for the purpose of gradient learning. In particular, the proposed P-ZO algorithms can be interpreted as new extremum-seeking algorithms that autonomously drive an unknown system toward a neighborhood of the set of solutions of an optimization problem using only output feedback, while systematically guaranteeing that the input trajectories remain in a feasible set for all times. In this way, the P-ZO algorithms can properly handle hard and asymptotical constraints in model-free optimization problems without using penalty terms or barrier functions. Moreover, the proposed dynamics have suitable robustness properties with respect to small bounded additive disturbances on the states and dynamics, a property that is fundamental for practical real-world implementations. Additional tracking results for time-varying and switching cost functions are also derived under stronger convexity and smoothness assumptions and using tools from hybrid dynamical systems. Numerical examples are presented throughout the paper to illustrate the above results.

Paper number 176:
Title: Model-Predictive Control with NUP Priors
Authors: Raphael Keusch, Hans-Andrea Loeliger
Abstract: Normals with unknown variance (NUV) and, more generally, normals with unknown parameters (NUP) can represent many useful priors including L_p norms and other sparsifying priors, and they blend well with linear-Gaussian models and Gaussian message passing algorithms. In this paper, we elaborate on recently proposed NUP representations of half-space constraints, box constraints, and finite-level constraints. We then demonstrate the use of such NUP representations for exemplary applications in model predictive control with a variety of constraints on the input, the output, or the internal state of the controlled system. In such applications, the computations boil down to iterations of Kalman-type forward-backward recursions, with a complexity (per iteration) that is linear in the planning horizon. In consequence, this approach can handle long planning horizons, which distinguishes it from the prior art. For nonconvex constraints, this approach has no claim to optimality, but it is empirically very effective.

Paper number 177:
Title: Federated Learning over Hierarchical Wireless Networks: Training Latency Minimization via Submodel Partitioning
Authors: Wenzhi Fang, Dong-Jun Han, Christopher G. Brinton
Abstract: Hierarchical federated learning (HFL) has demonstrated promising scalability advantages over the traditional "star-topology" architecture-based federated learning (FL). However, HFL still imposes significant computation, communication, and storage burdens on the edge, especially when training a large-scale model over resource-constrained wireless devices. In this paper, we propose hierarchical independent submodel training (HIST), a new FL methodology that aims to address these issues in hierarchical cloud-edge-client networks. The key idea behind HIST is to divide the global model into disjoint partitions (or submodels) per round so that each group of clients (i.e., cells) is responsible for training only one partition of the model. We characterize the convergence behavior of HIST under mild assumptions, showing the impacts of several key attributes (e.g., submodel sizes, number of cells, edge and global aggregation frequencies) on the rate and stationarity gap. Building upon the theoretical results, we propose a submodel partitioning strategy to minimize the training latency depending on network resource availability and a target learning performance guarantee. We then demonstrate how HIST can be augmented with over-the-air computation (AirComp) to further enhance the efficiency of the model aggregation over the edge cells. Through numerical evaluations, we verify that HIST is able to save training time and communication costs by wide margins while achieving comparable accuracy as conventional HFL. Moreover, our experiments demonstrate that AirComp-assisted HIST provides further improvements in training latency.

Paper number 178:
Title: A Superposition Code-Based Semantic Communication Approach with Quantifiable and Controllable Security
Authors: Weixuan Chen, Shuo Shao, Qianqian Yang, Zhaoyang Zhang, Ping Zhang
Abstract: This paper addresses the challenge of achieving security in semantic communication (SemCom) over a wiretap channel, where a legitimate receiver coexists with an eavesdropper experiencing a poorer channel condition. Despite previous efforts to secure SemCom against eavesdroppers, guarantee of approximately zero information leakage remains an open issue. In this work, we propose a secure digital semantic communication (SemCom) approach based on superposition codes, aiming to provide quantifiable and controllable security for digital SemCom systems. The proposed method employs a double-layered constellation map, where semantic information is associated with satellite constellation points and cloud center constellation points are randomly selected. By carefully allocating power between these two layers of constellation, we ensure that the symbol error probability (SEP) of the eavesdropper decoding satellite constellation points is nearly equivalent to random guessing, while maintaining a low SEP for the legitimate receiver to successfully decode the semantic information. Simulation results demonstrate that the Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) of the eavesdropper' s reconstructed data, under the proposed method, can range from decoding Gaussian-distributed random noise to approaching the variance of the data. This validates the effectiveness of our method in nearly achieving the experimental upper bound of security for digital SemCom systems when both eavesdroppers and legitimate users utilize identical decoding schemes. Furthermore, the proposed method consistently outperforms benchmark techniques, showcasing superior data security and robustness against eavesdropping.

Paper number 179:
Title: Gradient Networks
Authors: Shreyas Chaudhari, Srinivasa Pranav, José M. F. Moura
Abstract: Directly parameterizing and learning gradients of functions has widespread significance, with specific applications in inverse problems, generative modeling, and optimal transport. This paper introduces gradient networks (GradNets): novel neural network architectures that parameterize gradients of various function classes. GradNets exhibit specialized architectural constraints that ensure correspondence to gradient functions. We provide a comprehensive GradNet design framework that includes methods for transforming GradNets into monotone gradient networks (mGradNets), which are guaranteed to represent gradients of convex functions. Our results establish that our proposed GradNet (and mGradNet) universally approximate the gradients of (convex) functions. Furthermore, these networks can be customized to correspond to specific spaces of potential functions, including transformed sums of (convex) ridge functions. Our analysis leads to two distinct GradNet architectures, GradNet-C and GradNet-M, and we describe the corresponding monotone versions, mGradNet-C and mGradNet-M. Our empirical results demonstrate that these architectures provide efficient parameterizations and outperform existing methods by up to 15 dB in gradient field tasks and by up to 11 dB in Hamiltonian dynamics learning tasks.

Paper number 180:
Title: Sensor-Based Distributionally Robust Control for Safe Robot Navigation in Dynamic Environments
Authors: Kehan Long, Yinzhuang Yi, Zhirui Dai, Sylvia Herbert, Jorge Cortés, Nikolay Atanasov
Abstract: We introduce a novel method for mobile robot navigation in dynamic, unknown environments, leveraging onboard sensing and distributionally robust optimization to impose probabilistic safety constraints. Our method introduces a distributionally robust control barrier function (DR-CBF) that directly integrates noisy sensor measurements and state estimates to define safety constraints. This approach is applicable to a wide range of control-affine dynamics, generalizable to robots with complex geometries, and capable of operating at real-time control frequencies. Coupled with a control Lyapunov function (CLF) for path following, the proposed CLF-DR-CBF control synthesis method achieves safe, robust, and efficient navigation in challenging environments. We demonstrate the effectiveness and robustness of our approach for safe autonomous navigation under uncertainty in simulations and real-world experiments with differential-drive robots.

Paper number 181:
Title: A Novel Finite Fractional Fourier Transform and its Quantum Circuit Implementation on Qudits
Authors: Emmanuel Floratos, Archimedes Pavlidis
Abstract: We present a new number theoretic definition of discrete fractional Fourier transform (DFrFT) . In this approach the DFrFT is defined as the $N \times N$ dimensional unitary representation of the generator of the arithmetic rotational group $SO_{2}[\mathbb{Z}_N]$, which is the finite set of $\bmod N$ integer, $2\times 2$ matrices acting on the points of the discrete toroidal phase space lattice $\mathbb{Z}_N \times \mathbb{Z}_N$, preserving the euclidean distance $\bmod N$. We construct explicitly, using techniques of the Finite Quantum Mechanics (FQM), the $p^n$ dimensional unitary matrix representation of the group $SO_{2}[\mathbb{Z}_{p^n}]$ and especially we work out in detail the one which corresponds to the generator. This is our definition of the arithmetic fractional Fourier transform (AFrFT). Following this definition, we proceed to the construction of efficient quantum circuits for the AFrFT, on sets of $n$ $p$-dimensional qudits with $p$ a prime integer, by introducing novel quantum subcircuits for diagonal operators with quadratic phases as well as new quantum subcircuits for multipliers by a constant. The quantum subcircuits that we introduce provide a set capable to construct quantum circuits for any element of a more general group, the group of Linear Canonical Transformations (LCT), $SL_{2}[\mathbb{Z}_N]$ of the toroidal phase space lattice. As a byproduct, extensions of the diagonal and multiplier quantum circuits for both the qudit and qubit case are given, which are useful alone in various applications. Also, we analyze the depth, width and gate complexity of the efficient AFrFT quantum circuit and we estimate its gate complexity which is of the order $O(n^2)$, its depth which is of the order $O(n)$ with depth $n$, while at the same time it has a structure permitting local interactions between the qudits.

Paper number 182:
Title: People are poorly equipped to detect AI-powered voice clones
Authors: Sarah Barrington, Emily A. Cooper, Hany Farid
Abstract: As generative artificial intelligence (AI) continues its ballistic trajectory, everything from text to audio, image, and video generation continues to improve at mimicking human-generated content. Through a series of perceptual studies, we report on the realism of AI-generated voices in terms of identity matching and naturalness. We find human participants cannot consistently identify recordings of AI-generated voices. Specifically, participants perceived the identity of an AI-voice to be the same as its real counterpart approximately 80% of the time, and correctly identified a voice as AI generated only about 60% of the time.

Paper number 183:
Title: Enhancing Glucose Level Prediction of ICU Patients through Hierarchical Modeling of Irregular Time-Series
Authors: Hadi Mehdizavareh, Arijit Khan, Simon Lebech Cichosz
Abstract: Accurately predicting blood glucose (BG) levels of ICU patients is critical, as both hypoglycemia (BG < 70 mg/dL) and hyperglycemia (BG > 180 mg/dL) are associated with increased morbidity and mortality. This study presents a proof-of-concept machine learning framework, the Multi-source Irregular Time-Series Transformer (MITST), designed to predict blood glucose (BG) levels in ICU patients. Unlike existing approaches that rely on manual feature engineering or are limited to a small number of Electronic Health Record (EHR) data sources, MITST demonstrates the feasibility of integrating diverse clinical data (e.g., lab results, medications, vital signs) and handling irregular time-series data without predefined aggregation. MITST employs a hierarchical architecture of Transformers, comprising feature-level, timestamp-level, and source-level components, to capture fine-grained temporal dynamics and enable learning-based data integration. This eliminates the need for traditional aggregation and manual feature engineering. In a large-scale evaluation using the eICU database (200,859 ICU stays across 208 hospitals), MITST achieves an average improvement of 1.7% (p < 0.001) in AUROC and 1.8% (p < 0.001) in AUPRC over a state-of-the-art baseline. For hypoglycemia, MITST achieves an AUROC of 0.915 and an AUPRC of 0.247, both significantly outperforming the baseline. The flexible architecture of MITST allows seamless integration of new data sources without retraining the entire model, enhancing its adaptability for clinical decision support. While this study focuses on predicting BG levels, MITST can easily be extended to other critical event prediction tasks in ICU settings, offering a robust solution for analyzing complex, multi-source, irregular time-series data.

Paper number 184:
Title: Prion-ViT: Prions-Inspired Vision Transformers for Temperature prediction with Specklegrams
Authors: Abhishek Sebastian, Pragna R, Sonaa Rajagopal, Muralikrishnan Mani
Abstract: Fiber Specklegram Sensors (FSS) are vital for environmental monitoring due to their high temperature sensitivity, but their complex data poses challenges for predictive models. This study introduces Prion-ViT, a prion-inspired Vision Transformer model, inspired by biological prion memory mechanisms, to improve long-term dependency modeling and temperature prediction accuracy using FSS data. Prion-ViT leverages a persistent memory state to retain and propagate key features across layers, reducing mean absolute error (MAE) to 0.71$^\circ$C and outperforming models like ResNet, Inception Net V2, and Standard Vision Transformers. This paper also discusses Explainable AI (XAI) techniques, providing a perspective on specklegrams through attention and saliency maps, which highlight key regions contributing to predictions

Paper number 185:
Title: Quality Time: Carbon-Aware Quality Adaptation for Energy-Intensive Services
Authors: Philipp Wiesner, Dennis Grinwald, Philipp Weiß, Patrick Wilhelm, Ramin Khalili, Odej Kao
Abstract: The energy demand of modern cloud services, particularly those related to generative AI, is increasing at an unprecedented pace. While hyperscalers collectively fail to meet their self-imposed emission reduction targets, they face increasing pressure from environmental sustainability reporting across many jurisdictions. To date, carbon-aware computing strategies have primarily focused on batch process scheduling or geo-distributed load balancing. However, such approaches are not applicable to services that require constant availability at specific locations due to latency, privacy, data, or infrastructure constraints. In this paper, we explore how the carbon footprint of energy-intensive services can be reduced by adjusting the fraction of requests served by different service quality tiers. We show that adapting this quality of responses with respect to grid carbon intensity can lead to additional carbon savings beyond resource and energy efficiency. Building on this, we introduce a forecast-based multi-horizon optimization that reaches close-to-optimal carbon savings and is able to automatically adapt service quality for best-effort users to stay within an annual carbon budget. Our approach can reduce the emissions of large-scale LLM services, which we estimate at multiple 10,000 tons of CO2 annually, by up to 10%.

Paper number 186:
Title: Cooperative Cruising: Reinforcement Learning-Based Time-Headway Control for Increased Traffic Efficiency
Authors: Yaron Veksler, Sharon Hornstein, Han Wang, Maria Laura Delle Monache, Daniel Urieli
Abstract: The proliferation of connected automated vehicles represents an unprecedented opportunity for improving driving efficiency and alleviating traffic congestion. However, existing research fails to address realistic multi-lane highway scenarios without assuming connectivity, perception, and control capabilities that are typically unavailable in current vehicles. This paper proposes a novel AI system that is the first to improve highway traffic efficiency compared with human-like traffic in realistic, simulated multi-lane scenarios, while relying on existing connectivity, perception, and control capabilities. At the core of our approach is a reinforcement learning based controller that dynamically communicates time-headways to automated vehicles near bottlenecks based on real-time traffic conditions. These desired time-headways are then used by adaptive cruise control (ACC) systems to adjust their following distance. By (i) integrating existing traffic estimation technology and low-bandwidth vehicle-to-infrastructure connectivity, (ii) leveraging safety-certified ACC systems, and (iii) targeting localized bottleneck challenges that can be addressed independently in different locations, we propose a potentially practical, safe, and scalable system that can positively impact numerous road users.

Paper number 187:
Title: Joint Task Offloading and Routing in Wireless Multi-hop Networks Using Biased Backpressure Algorithm
Authors: Zhongyuan Zhao, Jake Perazzone, Gunjan Verma, Kevin Chan, Ananthram Swami, Santiago Segarra
Abstract: A significant challenge for computation offloading in wireless multi-hop networks is the complex interaction among traffic flows in the presence of interference. Existing approaches often ignore these key effects and/or rely on outdated queueing and channel state information. To fill these gaps, we reformulate joint offloading and routing as a routing problem on an extended graph with physical and virtual links. We adopt the state-of-the-art shortest path-biased Backpressure routing algorithm, which allows the destination and the route of a job to be dynamically adjusted at every time step based on network-wide long-term information and real-time states of local neighborhoods. In large networks, our approach achieves smaller makespan than existing approaches, such as separated Backpressure offloading and joint offloading and routing based on linear programming.

Paper number 188:
Title: Sample-Based Piecewise Linear Power Flow Approximations Using Second-Order Sensitivities
Authors: Paprapee Buason, Sidhant Misra, Daniel K. Molzahn
Abstract: The inherent nonlinearity of the power flow equations poses significant challenges in accurately modeling power systems, particularly when employing linearized approximations. Although power flow linearizations provide computational efficiency, they can fail to fully capture nonlinear behavior across diverse operating conditions. To improve approximation accuracy, we propose conservative piecewise linear approximations (CPLA) of the power flow equations, which are designed to consistently over- or under-estimate the quantity of interest, ensuring conservative behavior in optimization. The flexibility provided by piecewise linear functions can yield improved accuracy relative to standard linear approximations. However, applying CPLA across all dimensions of the power flow equations could introduce significant computational complexity, especially for large-scale optimization problems. In this paper, we propose a strategy that selectively targets dimensions exhibiting significant nonlinearities. Using a second-order sensitivity analysis, we identify the directions where the power flow equations exhibit the most significant curvature and tailor the CPLAs to improve accuracy in these specific directions. This approach reduces the computational burden while maintaining high accuracy, making it particularly well-suited for mixed-integer programming problems involving the power flow equations.

Paper number 189:
Title: What Does an Audio Deepfake Detector Focus on? A Study in the Time Domain
Authors: Petr Grinberg, Ankur Kumar, Surya Koppisetti, Gaurav Bharaj
Abstract: Adding explanations to audio deepfake detection (ADD) models will boost their real-world application by providing insight on the decision making process. In this paper, we propose a relevancy-based explainable AI (XAI) method to analyze the predictions of transformer-based ADD models. We compare against standard Grad-CAM and SHAP-based methods, using quantitative faithfulness metrics as well as a partial spoof test, to comprehensively analyze the relative importance of different temporal regions in an audio. We consider large datasets, unlike previous works where only limited utterances are studied, and find that the XAI methods differ in their explanations. The proposed relevancy-based XAI method performs the best overall on a variety of metrics. Further investigation on the relative importance of speech/non-speech, phonetic content, and voice onsets/offsets suggest that the XAI results obtained from analyzing limited utterances don't necessarily hold when evaluated on large datasets.
    