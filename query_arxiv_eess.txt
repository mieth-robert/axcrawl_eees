
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Magnification-Aware Distillation (MAD): A Self-Supervised Framework for Unified Representation Learning in Gigapixel Whole-Slide Images
Authors: Mahmut S. Gokmen, Mitchell A. Klusty, Peter T. Nelson, Allison M. Neltner, Sen-Ching Samson Cheung, Thomas M. Pearce, David A Gutman, Brittany N. Dugger, Devavrat S. Bisht, Margaret E. Flanagan, V. K. Cody Bumgardner
Abstract: Whole-slide images (WSIs) contain tissue information distributed across multiple magnification levels, yet most self-supervised methods treat these scales as independent views. This separation prevents models from learning representations that remain stable when resolution changes, a key requirement for practical neuropathology workflows. This study introduces Magnification-Aware Distillation (MAD), a self-supervised strategy that links low-magnification context with spatially aligned high-magnification detail, enabling the model to learn how coarse tissue structure relates to fine cellular patterns. The resulting foundation model, MAD-NP, is trained entirely through this cross-scale correspondence without annotations. A linear classifier trained only on 10x embeddings maintains 96.7% of its performance when applied to unseen 40x tiles, demonstrating strong resolution-invariant representation learning. Segmentation outputs remain consistent across magnifications, preserving anatomical boundaries and minimizing noise. These results highlight the feasibility of scalable, magnification-robust WSI analysis using a unified embedding space

Paper number 2:
Title: Artificial Intelligence for the Assessment of Peritoneal Carcinosis during Diagnostic Laparoscopy for Advanced Ovarian Cancer
Authors: Riccardo Oliva, Farahdiba Zarin, Alice Zampolini Faustini, Armine Vardazaryan, Andrea Rosati, Vinkle Srivastav, Nunzia Del Villano, Jacques Marescaux, Giovanni Scambia, Pietro Mascagni, Nicolas Padoy, Anna Fagotti
Abstract: Advanced Ovarian Cancer (AOC) is often diagnosed at an advanced stage with peritoneal carcinosis (PC). Fagotti score (FS) assessment at diagnostic laparoscopy (DL) guides treatment planning by estimating surgical resectability, but its subjective and operator-dependent nature limits reproducibility and widespread use. Videos of patients undergoing DL with concomitant FS assessments at a referral center were retrospectively collected and divided into a development dataset, for data annotation, AI training and evaluation, and an independent test dataset, for internal validation. In the development dataset, FS-relevant frames were manually annotated for anatomical structures and PC. Deep learning models were trained to automatically identify FS-relevant frames, segment structures and PC, and predict video-level FS and indication to surgery (ItS). AI performance was evaluated using Dice score for segmentation, F1-scores for anatomical stations (AS) and ItS prediction, and root mean square error (RMSE) for final FS estimation. In the development dataset, the segmentation model trained on 7,311 frames, achieved Dice scores of 70$\pm$3% for anatomical structures and 56$\pm$3% for PC. Video-level AS classification achieved F1-scores of 74$\pm$3% and 73$\pm$4%, FS prediction showed normalized RMSE values of 1.39$\pm$0.18 and 1.15$\pm$0.08, and ItS reached F1-scores of 80$\pm$8% and 80$\pm$2% in the development (n=101) and independent test datasets (n=50), respectively. This is the first AI model to predict the feasibility of cytoreductive surgery providing automated FS estimation from DL videos. Its reproducible and reliable performance across datasets suggests that AI can support surgeons through standardized intraoperative tumor burden assessment and clinical decision-making in AOC.

Paper number 3:
Title: Compensation of Coarse Quantization Effects on Channel Estimation and BER in Massive MIMO
Authors: Reza Mohammadkhani, Azad Azizzadeh, Seyed Vahab Al-Din Makki, John Thompson, Maziar Nekovee
Abstract: Low-resolution quantization is essential to reduce implementation cost and power consumption in massive multiple-input multiple-output (MIMO) systems for 5G and 6G. While most existing studies assume perfect channel state information (CSI), we model the impact of coarse quantization noise on both channel estimation and data transmission, yielding a more realistic assessment of system performance under imperfect CSI conditions in the uplink. We develop a tight approximation for the bit-error ratio (BER) of uncoded M-QAM with zero-forcing detection, based on the linear minimum mean-square error (LMMSE) channel estimate. These analytical results enable compensation strategies that jointly optimize quantization resolution, transmit power, and pilot length across different numbers of users and base station antennas. We further demonstrate the applicability of the proposed framework through several design scenarios that highlight its effectiveness in optimizing system parameters and improving energy efficiency under quantization constraints. For example, in a 16-QAM system, extending the pilot sequence by 2.5 times and lowering transmit power by 0.5 dB enables a 3-bit quantized system to match the BER of the full-resolution case. The proposed framework offers a fast and accurate alternative to Monte Carlo simulations, enabling practical system optimization under realistic quantization constraints.

Paper number 4:
Title: Assessing the Frequency Response Potential of Heavy-Duty Electric Vehicles with Vehicle-to-Grid Integration in the California Power System
Authors: Xiaojie Tao, Yaoyu Fan, Zhaoyi Ye, Rajit Gadh
Abstract: The integration of heavy-duty electric vehicles (EVs) with Vehicle-to-Grid (V2G) capability can enhance primary frequency response and improve stability in power systems with high renewable penetration. This study evaluates the technical potential of heavy-duty EV fleets to support the California power grid under three practical charging strategies: immediate charging, delayed charging, and constant-minimum-power charging. We develop a simulation framework that couples aggregated frequency dynamics with battery and charger constraints, state-of-charge management, and fleet-availability profiles. Performance is assessed using standard frequency security metrics, including nadir, rate-of-change-of-frequency, overshoot, and settling time, across credible contingency scenarios and renewable generation conditions. Results indicate that both non-V2G modes and V2G-enabled operation can contribute meaningful primary response, with V2G providing the strongest and fastest support while respecting mobility and network limits. Sensitivity analyses show that the relative benefits depend on charging strategy, control parameters, and renewable output, highlighting design trade-offs between response magnitude, duration, and battery usage. Overall, heavy-duty EV fleets-when coordinated by appropriate charging and V2G controls-offer a viable resource for strengthening primary frequency control on the California grid and mitigating stability challenges associated with increasing renewable penetration.

Paper number 5:
Title: Deep learning water-unsuppressed MRSI at ultra-high field for simultaneous quantitative metabolic, susceptibility and myelin water imaging
Authors: Paul J. Weiser, Jiye Kim, Jongho Lee, Amirmohammad Shamaei, Gulnur Ungan, Malte Hoffmann, Antoine Klauser, Berkin Bilgic, Ovidiu C. Andronesi
Abstract: Purpose: Magnetic Resonance Spectroscopic Imaging (MRSI) maps endogenous brain metabolism while suppressing the overwhelming water signal. Water-unsuppressed MRSI (wu-MRSI) allows simultaneous imaging of water and metabolites, but large water sidebands cause challenges for metabolic fitting. We developed an end-to-end deep-learning pipeline to overcome these challenges at ultra-high field. Methods:Fast high-resolution wu-MRSI was acquired at 7T with non-cartesian ECCENTRIC sampling and ultra-short echo time. A water and lipid removal network (WALINET+) was developed to remove lipids, water signal, and sidebands. MRSI reconstruction was performed by DeepER and a physics-informed network for metabolite fitting. Water signal was used for absolute metabolite quantification, quantitative susceptibility mapping (QSM), and myelin water fraction imaging (MWF). Results: WALINET+ provided the lowest NRMSE (< 2%) in simulations and in vivo the smallest bias (< 20%) and limits-of-agreement (+-63%) between wu-MRSI and ws-MRSI scans. Several metabolites such as creatine and glutamate showed higher SNR in wu-MRSI. QSM and MWF obtained from wu-MRSI and GRE showed good agreement with 0 ppm/5.5% bias and +-0.05 ppm/ +- 12.75% limits-of-agreement. Conclusion: High-quality metabolic, QSM, and MWF mapping of the human brain can be obtained simultaneously by ECCENTRIC wu-MRSI at 7T with 2 mm isotropic resolution in 12 min. WALINET+ robustly removes water sidebands while preserving metabolite signal, eliminating the need for water suppression and separate water acquisitions.

Paper number 6:
Title: Optimizing Sensor Node Localization for Achieving Sustainable Smart Agriculture System Connectivity
Authors: Mohamed Naeem
Abstract: The innovative agriculture system is revolutionizing how we farm, making it one of the most critical innovations of our time! Yet it faces significant connectivity challenges, particularly with the sensors that power this technology. An efficient sensor deployment solution is still required to maximize the network's detection capabilities and efficiency while minimizing resource consumption and operational costs. This paper introduces an innovative sensor allocation optimization method that employs a Gradient-Based Iteration with Lagrange. The proposed method enhances coverage by utilizing a hybrid approach while minimizing the number of sensor nodes required under grid-based allocation. The proposed sensor distribution outperformed the classic deterministic deployment across coverage, number of sensors, cost, and power consumption. Furthermore, scalability is enhanced by extending sensing coverage to the remaining area via Bluetooth, which has a shorter communication range. Moreover, the proposed algorithm achieved 98.5% wireless sensor coverage, compared with 95% for the particle swarm distribution.

Paper number 7:
Title: A Gaussian Parameterization for Direct Atomic Structure Identification in Electron Tomography
Authors: Nalini M. Singh, Tiffany Chien, Arthur R.C. McCray, Colin Ophus, Laura Waller
Abstract: Atomic electron tomography (AET) enables the determination of 3D atomic structures by acquiring a sequence of 2D tomographic projection measurements of a particle and then computationally solving for its underlying 3D representation. Classical tomography algorithms solve for an intermediate volumetric representation that is post-processed into the atomic structure of interest. In this paper, we reformulate the tomographic inverse problem to solve directly for the locations and properties of individual atoms. We parameterize an atomic structure as a collection of Gaussians, whose positions and properties are learnable. This representation imparts a strong physical prior on the learned structure, which we show yields improved robustness to real-world imaging artifacts. Simulated experiments and a proof-of-concept result on experimentally-acquired data confirm our method's potential for practical applications in materials characterization and analysis with Transmission Electron Microscopy (TEM). Our code is available at this https URL.

Paper number 8:
Title: Janus Metasurface Breaking Polarization Symmetry: Surface-Modulated Electromagnetic Wave Radiation with Coexistent Linear and Circular Polarization
Authors: Aparna Parameswaran, Hoyoung Kim, Sangkil Kim
Abstract: In this work, a Janus metasurface based tensor impedance holographic antenna (JHA) is proposed that simultaneously radiates linearly polarized (LP) and circularly polarized (CP) beams from a single aperture excited by a single feed. The proposed design introduces modified tensor impedance equations to significantly reduce cross-polarization at higher radiation angles. It demonstrates broadband operation bandwidth of 0.5 GHz while maintaining high circular polarization purity. The design methodology is verified using aperture field integration theory, ensuring that the impedance distribution produces the desired far-field radiation patterns. Prototypes of three variations of the holographic antenna are fabricated, validating its performance. The radiation characteristics of the proposed antenna make it an attractive choice for advanced broadband communication applications.

Paper number 9:
Title: Meta-learners for few-shot weakly-supervised optic disc and cup segmentation on fundus images
Authors: Pandega Abyan Zumarsyah, Igi Ardiyanto, Hanung Adi Nugroho
Abstract: This study develops meta-learners for few-shot weakly-supervised segmentation (FWS) to address the challenge of optic disc (OD) and optic cup (OC) segmentation for glaucoma diagnosis with limited labeled fundus images. We significantly improve existing meta-learners by introducing Omni meta-training which balances data usage and diversifies the number of shots. We also develop their efficient versions that reduce computational costs. In addition, we develop sparsification techniques that generate more customizable and representative scribbles and other sparse labels. After evaluating multiple datasets, we find that Omni and efficient versions outperform the original versions, with the best meta-learner being Efficient Omni ProtoSeg (EO-ProtoSeg). It achieves intersection over union (IoU) scores of 88.15% for OD and 71.17% for OC on the REFUGE dataset using just one sparsely labeled image, outperforming few-shot and semi-supervised methods which require more labeled images. Its best performance reaches 86.80% for OD and 71.78%for OC on DRISHTIGS, 88.21% for OD and 73.70% for OC on REFUGE, 80.39% for OD and 52.65% for OC on REFUGE. EO-ProtoSeg is comparable to unsupervised domain adaptation methods yet much lighter with less than two million parameters and does not require any retraining.

Paper number 10:
Title: Deep Reinforcement Learning for Joint Time and Power Management in SWIPT-EH CIoT
Authors: Nadia Abdolkhani, Nada Abdel Khalek, Walaa Hamouda, Iyad Dayoub
Abstract: This letter presents a novel deep reinforcement learning (DRL) approach for joint time allocation and power control in a cognitive Internet of Things (CIoT) system with simultaneous wireless information and power transfer (SWIPT). The CIoT transmitter autonomously manages energy harvesting (EH) and transmissions using a learnable time switching factor while optimizing power to enhance throughput and lifetime. The joint optimization is modeled as a Markov decision process under small-scale fading, realistic EH, and interference constraints. We develop a double deep Q-network (DDQN) enhanced with an upper confidence bound. Simulations benchmark our approach, showing superior performance over existing DRL methods.

Paper number 11:
Title: CF-Net: A Cross-Feature Reconstruction Network for High-Accuracy 1-Bit Target Classification
Authors: Jundong Qi, Weize Sun, Shaowu Chen, Lei Huang, Qiuchen Liu
Abstract: Target classification is a fundamental task in radar systems, and its performance critically depends on the quantization precision of the signal. While high-precision quantization (e.g. 16-bit) is well established, 1-bit quantization offers distinct advantages by enabling direct sampling at high frequencies and eliminating complex intermediate stages. However, its extreme quantization leads to significant information loss. Although higher sampling rates can compensate for this loss, such oversampling is impractical at the high frequencies targeted for direct sampling. To achieve high-accuracy classification directly from 1-bit radar data under the same sampling rate, this paper proposes a novel two-stage deep learning framework, CF-Net. First, we introduce a self-supervised pre-training strategy based on a dual-branch U-Net architecture. This network learns to restore high-fidelity 16-bit images from their 1-bit counterparts via a cross-feature reconstruction task, forcing the 1-bit encoder to learn robust features despite extreme quantization. Subsequently, this pre-trained encoder is repurposed and fine-tuned for the downstream multi-class target classification task. Experiments on two radar target datasets demonstrate that CF-Net can effectively extract discriminative features from 1-bit imagery, achieving comparable and even superior accuracy to some 16-bit methods without oversampling.

Paper number 12:
Title: Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network
Authors: Zhuoran Li, Zhen Gao, Xinhua Liu, Zheng Wang, Xiaotian Zhou, Lei Liu, Yongpeng Wu, Wei Feng, Yongming Huang
Abstract: The advent of sixth-generation (6G) places intelligence at the core of wireless architecture, fusing perception, communication, and computation into a single closed-loop. This paper argues that large artificial intelligence models (LAMs) can endow base stations with perception, reasoning, and acting capabilities, thus transforming them into intelligent base station agents (IBSAs). We first review the historical evolution of BSs from single-functional analog infrastructure to distributed, software-defined, and finally LAM-empowered IBSA, highlighting the accompanying changes in architecture, hardware platforms, and deployment. We then present an IBSA architecture that couples a perception-cognition-execution pipeline with cloud-edge-end collaboration and parameter-efficient adaptation. Subsequently,we study two representative scenarios: (i) cooperative vehicle-road perception for autonomous driving, and (ii) ubiquitous base station support for low-altitude uncrewed aerial vehicle safety monitoring and response against unauthorized drones. On this basis, we analyze key enabling technologies spanning LAM design and training, efficient edge-cloud inference, multi-modal perception and actuation, as well as trustworthy security and governance. We further propose a holistic evaluation framework and benchmark considerations that jointly cover communication performance, perception accuracy, decision-making reliability, safety, and energy efficiency. Finally, we distill open challenges on benchmarks, continual adaptation, trustworthy decision-making, and standardization. Together, this work positions LAM-enabled IBSAs as a practical path toward integrated perception, communication, and computation native, safety-critical 6G systems.

Paper number 13:
Title: QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management
Authors: Jiayang Wan, Ke He, Yafei Wang, Fan Liu, Wenjin Wang, Shi Jin
Abstract: Due to the significant variations in unmanned aerial vehicle (UAV) altitude and horizontal mobility, it becomes difficult for any single network to ensure continuous and reliable threedimensional coverage. Towards that end, the space-air-ground integrated network (SAGIN) has emerged as an essential architecture for enabling ubiquitous UAV connectivity. To address the pronounced disparities in coverage and signal characteristics across heterogeneous networks, this paper formulates UAV mobility management in SAGIN as a constrained multi-objective joint optimization problem. The formulation couples discrete link selection with continuous trajectory optimization. Building on this, we propose a two-level multi-agent hierarchical deep reinforcement learning (HDRL) framework that decomposes the problem into two alternately solvable subproblems. To map complex link selection decisions into a compact discrete action space, we conceive a double deep Q-network (DDQN) algorithm in the top-level, which achieves stable and high-quality policy learning through double Q-value estimation. To handle the continuous trajectory action space while satisfying quality of service (QoS) constraints, we integrate the maximum-entropy mechanism of the soft actor-critic (SAC) and employ a Lagrangian-based constrained SAC (CSAC) algorithm in the lower-level that dynamically adjusts the Lagrange multipliers to balance constraint satisfaction and policy optimization. Moreover, the proposed algorithm can be extended to multi-UAV scenarios under the centralized training and decentralized execution (CTDE) paradigm, which enables more generalizable policies. Simulation results demonstrate that the proposed scheme substantially outperforms existing benchmarks in throughput, link switching frequency and QoS satisfaction.

Paper number 14:
Title: Intertemporal Hedging Demand under Epstein-Zin Preferences in a Multi-Asset Long-Run Risk Model: Evidence from Projected Pontryagin-Guided Deep Policy Optimization
Authors: Wonchan Cho
Abstract: I study intertemporal hedging demand in a continuous-time multi-asset long-run risk (LRR) model under Epstein--Zin (EZ) recursive preferences. The investor trades a risk-free asset and several risky assets whose drifts and volatilities depend on an Ornstein--Uhlenbeck type LRR factor. Preferences are described by EZ utility with risk aversion $R$, elasticity of intertemporal substitution $\psi$, and discount rate $\delta$, so that the standard time-additive CRRA case appears as a limiting benchmark. To handle the high-dimensional consumption--investment problem, I use a projected Pontryagin-guided deep policy optimization (P-PGDPO) scheme adapted to EZ preferences. The method starts from the continuous-time Hamiltonian implied by the Pontryagin maximum principle, represents the value and costate processes with neural networks, and updates the policy along the Hamiltonian gradient. Portfolio constraints and a lower bound on wealth are enforced by explicit projection operators rather than by adding ad hoc penalties. Three main findings emerge from numerical experiments in a five-asset LRR economy: \textbf{(1)} the P-PGDPO algorithm achieves stable convergence across multiple random seeds, validating its reliability for solving high-dimensional EZ problems; \textbf{(2)} wealth floors materially reduce hedging demand by limiting the investor's ability to exploit intertemporal risk-return tradeoffs; and \textbf{(3)} the learned hedging portfolios concentrate exposure in assets with high correlation to the LRR factor, confirming that EZ agents actively hedge long-run uncertainty rather than merely following myopic rules. Because EZ preferences nest time-additive CRRA in the limit $\psi \to 1/R$, I use CRRA as an explicit diagnostic benchmark and, when needed, a warm start to stabilize training in high dimensions.

Paper number 15:
Title: Remote Magnetic Levitation Using Reduced Attitude Control and Parametric Field Models
Authors: Neelaksh Singh, Jasan Zughaibi, Denis von Arx, Bradley J. Nelson, Michael Muehlebach
Abstract: Electromagnetic navigation systems (eMNS) are increasingly used in minimally invasive procedures such as endovascular interventions and targeted drug delivery due to their ability to generate fast and precise magnetic fields. In this paper, we utilize the OctoMag eMNS to achieve remote levitation and control of a rigid body across large air gaps which showcases the dynamic capabilities of clinical eMNS. A compact parametric analytical model maps coil currents to the forces and torques acting on the levitating object, eliminating the need for computationally expensive simulations or lookup tables and leading to a levitator agnostic modeling approach. Translational motion is stabilized using linear quadratic regulators. A nonlinear time-invariant controller is used to regulate the reduced attitude accounting for the inherent uncontrollability of rotations about the dipole axis and stabilizing the full five degrees of freedom controllable pose subspace. We analyze key design limitations and evaluate the approach through trajectory tracking experiments. This work demonstrates the dynamic capabilities and potential of feedback control in electromagnetic navigation, which is likely to open up new medical applications.

Paper number 16:
Title: On the Use of Self-Supervised Representation Learning for Speaker Diarization and Separation
Authors: Séverin Baroudi, Hervé Bredin, Joseph Razik, Ricard Marxer
Abstract: Self-supervised speech models such as wav2vec2.0 and WavLM have been shown to significantly improve the performance of many downstream speech tasks, especially in low-resource settings, over the past few years. Despite this, evaluations on tasks such as Speaker Diarization and Speech Separation remain limited. This paper investigates the quality of recent self-supervised speech representations on these two speaker identity-related tasks, highlighting gaps in the current literature that stem from limitations in the existing benchmarks, particularly the lack of diversity in evaluation datasets and variety in downstream systems associated to both diarization and separation.

Paper number 17:
Title: Consensus-based formation of a swarm of quadrotors interacting over ring digraphs
Authors: Sahaya Aarti Dennisselvan, Shashi Ranjan Kumar, Dwaipayan Mukherjee
Abstract: This work proposes a cooperative strategy for a group of quadrotors interacting over ring digraphs with macro-vertices of size two. Consensus for a group of general double integrators has been initially investigated, and it has been proved that through a suitable choice of a single controller parameter, consensus and stability of the resulting networked dynamical system can be ensured. This further opens up the possibility of achieving a desired formation and to move a swarm of quadrotors, interacting over ring digraphs, at a desired flight velocity, using a single controller gain. An analysis of achievable velocities is performed. Examples have been provided to offer deeper insights into the obtained analytical results. Simulation studies clearly demonstrate that a desired formation is achieved, starting from arbitrary initial positions, while also ensuring convergence to a final desired flight velocity.

Paper number 18:
Title: Enhancing Alzheimer's Detection through Late Fusion of Multi-Modal EEG Features
Authors: Nguyen Thanh Vinh, Manoj Vishwanath, Thinh Nguyen-Quang, Nguyen Viet Ha, Bui Thanh Tung, Huy-Dung Han, Nguyen Quang Linh, Nguyen Hai Linh, Hung Cao
Abstract: Alzheimer s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline, where early detection is essential for timely intervention and improved patient outcomes. Traditional diagnostic methods are time-consuming and require expert interpretation, thus, automated approaches are highly desirable. This study presents a novel deep learning framework for AD diagnosis using Electroencephalograph (EEG) signals, integrating multiple feature extraction techniques including alpha-wave analysis, Discrete Wavelet Transform (DWT), and Markov Transition Fields (MTF). A late-fusion strategy is employed to combine predictions from separate neural networks trained on these diverse representations, capturing both temporal and frequency-domain patterns in the EEG data. The proposed model attains a classification accuracy of 87.23%, with a precision of 87.95%, a recall of 86.91%, and an F1 score of 87.42% when evaluated on a publicly available dataset, demonstrating its potential for reliable, scalable, and early AD screening. Rigorous preprocessing and targeted frequency band selection, particularly in the alpha range due to its cognitive relevance, further enhance performance. This work highlights the promise of deep learning in supporting physicians with efficient and accessible tools for early AD diagnosis.

Paper number 19:
Title: Audio-Visual Cross-Modal Compression for Generative Face Video Coding
Authors: Youmin Xu, Mengxi Guo, Shijie Zhao, Weiqi Li, Junlin Li, Li Zhang, Jian Zhang
Abstract: Generative face video coding (GFVC) is vital for modern applications like video conferencing, yet existing methods primarily focus on video motion while neglecting the significant bitrate contribution of audio. Despite the well-established correlation between audio and lip movements, this cross-modal coherence has not been systematically exploited for compression. To address this, we propose an Audio-Visual Cross-Modal Compression (AVCC) framework that jointly compresses audio and video streams. Our framework extracts motion information from video and tokenizes audio features, then aligns them through a unified audio-video diffusion process. This allows synchronized reconstruction of both modalities from a shared representation. In extremely low-rate scenarios, AVCC can even reconstruct one modality from the other. Experiments show that AVCC significantly outperforms the Versatile Video Coding (VVC) standard and state-of-the-art GFVC schemes in rate-distortion performance, paving the way for more efficient multimodal communication systems.

Paper number 20:
Title: Dataset and UAV Propagation Channel Modeling for LoRa in the 860 MHz ISM Band
Authors: Joachim Tapparel, Andreas Burg
Abstract: LoRa is one of the most widely used low-power wide-area network technology for the Internet of Things. To achieve long-range communication with low power consumption at a low cost, LoRa uses a chirp spread spectrum modulation and transmits in the sub-GHz unlicensed industrial, scientific, and medical (ISM) frequency bands. Due to the rapid densification of IoT networks, it is crucial to obtain tailored channel models to evaluate the performance of LoRa networks. While channel models for cellular technologies have been investigated extensively, specific characteristics of LoRa transmissions operating at long range with a rather small (~ 250kHz) bandwidth require dedicated measurement campaigns and modeling efforts. In this work, we leverage an SDR-based testbed to gather and publish a dataset of LoRa frames transmitted in a campus environment. The dataset includes IQ samples of the received frames at multiple locations and allows for the evaluation of channel variations with high time resolution. Using the gathered data, we derive empirical propagation channel models for LoRa that include receiver correlation over distance for three scenarios: unmanned aerial vehicle (UAV) line-of-sight (LoS), UAV non-LoS, and pedestrian non-LoS. Furthermore, the dataset is annotated with synchronization information, enabling the evaluation of receiver algorithms using experimental data.

Paper number 21:
Title: Generative Preprocessing for Image Compression with Pre-trained Diffusion Models
Authors: Mengxi Guo, Shijie Zhao, Junlin Li, Li Zhang
Abstract: Preprocessing is a well-established technique for optimizing compression, yet existing methods are predominantly Rate-Distortion (R-D) optimized and constrained by pixel-level fidelity. This work pioneers a shift towards Rate-Perception (R-P) optimization by, for the first time, adapting a large-scale pre-trained diffusion model for compression preprocessing. We propose a two-stage framework: first, we distill the multi-step Stable Diffusion 2.1 into a compact, one-step image-to-image model using Consistent Score Identity Distillation (CiD). Second, we perform a parameter-efficient fine-tuning of the distilled model's attention modules, guided by a Rate-Perception loss and a differentiable codec surrogate. Our method seamlessly integrates with standard codecs without any modification and leverages the model's powerful generative priors to enhance texture and mitigate artifacts. Experiments show substantial R-P gains, achieving up to a 30.13% BD-rate reduction in DISTS on the Kodak dataset and delivering superior subjective visual quality.

Paper number 22:
Title: Learning-Based Phase Shift Optimization of Liquid Crystal RIS in Dynamic mmWave Networks
Authors: Le Hao (1), Robin Neuder (2), Mohamadreza Delbari (3), Alejandro Jiménez-Sáez (2), Vahid Jamali (3), Arash Asadi (4), Andrea Ortiz (1) ((1) Institute of Telecommunications, Technische Universität Wien (TU Wien), 1040 Vienna, Austria, (2) Institute of Microwave Engineering and Photonics, Technische Universität Darmstadt, 64283 Darmstadt, Germany, (3) Resilient Communication Systems Laboratory, Technische Universität Darmstadt, 64283 Darmstadt, Germany, (4) Embedded Systems Group, Delft University of Technology, 2628 CD Delft, Netherlands)
Abstract: To enhance coverage and signal quality in millimeter-wave (mmWave) frequencies, reconfigurable intelligent surfaces (RISs) have emerged as a game-changing solution to manipulate the wireless environment. Traditional semiconductor-based RISs face scalability issues due to high power consumption. Meanwhile, liquid crystal-based RISs (LC-RISs) offer energy-efficient and cost-effective operation even for large arrays. However, this promise has a caveat. LC-RISs suffer from long reconfiguration times, on the order of tens of milliseconds, which limits their applicability in dynamic scenarios. To date, prior works have focused on hardware design aspects or static scenarios to address this limitation, but little attention has been paid to optimization solutions for dynamic settings. Our paper fills this gap by proposing a reinforcement learning-based optimization framework to dynamically control the phase shifts of LC-RISs and maximize the data rate of a moving user. Specifically, we propose a Deep Deterministic Policy Gradient (DDPG) algorithm that adapts the LC-RIS phase shifts without requiring perfect channel state information and balances the tradeoff between signal-to-noise ratio (SNR) and configuration time. We validate our approach through high-fidelity ray tracing simulations, leveraging measurement data from an LC-RIS prototype. Our results demonstrate the potential of our solution to bring adaptive control to dynamic LC-RIS-assisted mmWave systems.

Paper number 23:
Title: Moment-Matching Array Processing Technique for diffuse source estimation
Authors: Colin Cros, Laurent Ferro-Famil (CESBIO)
Abstract: Direction of Arrival (DOA) estimation is a fundamental problem in signal processing. Diffuse sources, whose power density cannot be represented with a single angular coordinate, are usually characterized based on prior assumptions, which associate the source angular density with a specific set of functions. However, these assumptions can lead to significant estimation biases when they are incorrect. This paper introduces the Moment-Matching Estimation Technique (MoMET), a low-complexity method for estimating the mean DOA, spread, and power of a narrow diffuse source without requiring prior knowledge on the source distribution. The unknown source density is characterized by its mean DOA and its first central moments, which are estimated through covariance matching techniques which fit the empirical covariance of the measurements to that modeled from the moments. The MoMET parameterization is robust to incorrect model assumptions, and numerically efficient. The asymptotic bias and covariance of the new estimator are derived and its performance is demonstrated through simulations.

Paper number 24:
Title: On the Asymptotic Performance of Diagonally Loaded Detectors for Large Arrays: To Achieve CFAR and Optimality
Authors: Jie Zhou, Junhao Xie
Abstract: This paper addresses two critical limitations in diagonally loaded (DL) adaptive matched filter (AMF) detector: (1) the lack of CFAR property with respect to arbitrary covariance matrices, and (2) the absence of selection criteria for optimal loading factor from the perspective of maximizing the detection probability (Pd). We provide solutions to both challenges through a comprehensive analysis for the asymptotic performance of DL-AMF under large dimensional regime (LDR) where the dimension N and sample size K tend to infinity whereas their ratio N/K converges to a constant c\in(0,1). The analytical results show that any DL detectors constructed by normalizing the random variable |a|2=|sH(R+{\lambda}IN)-1y0|2 with a deterministic quantity or a random variable that converges almost surely to a deterministic value will exhibit equivalent performance under LDR. Following this idea, we derive two CFAR DL detectors: CFAR DL semi-clairvoyant matched filter (CFAR-DL-SCMF) detector and CFAR DL adaptive matched filter (CFAR-DL-AMF) detector, by normalizing |a|2 with an appropriate deterministic quantity and its consistent estimate, respectively. The theoretical analysis and simulations show that both CFAR-DL-SCMF and CFAR-DL-AMF achieve CFAR with respect to covariance matrix, target steering vector and loading factor. Furthermore, we derive the asymptotically optimal loading factor \lambda_opt by maximizing the explicit expression of asymptotic Pd. For practical implementation, we provide a consistent estimator for \lambda_opt under LDR. Based on \lambda_opt and its consistent estimate, we establish the optimal CFAR-DL-SCMF (opt-CFAR-DL-SCMF) and the optimal CFAR-DL-AMF (opt-CFAR-DL-AMF). Numerical examples demonstrate that the proposed opt-CFAR-DL-SCMF and opt-CFAR-DL-AMF consistently outperform EL-AMF and persymmetric AMF in both full-rank and low-rank clutter plus noise environments.

Paper number 25:
Title: Deep Learning-Driven Quantitative Spectroscopic Photoacoustic Imaging for Segmentation and Oxygen Saturation Estimation
Authors: Ruibo Shang, Sidhartha Jandhyala, Yujia Wu, Kevin Hoffer-Hawlik, Austin Van Namen, Matthew O'Donnell, Geoffrey P. Luke
Abstract: Spectroscopic photoacoustic (sPA) imaging can potentially estimate blood oxygenation saturation (sO2) in vivo noninvasively. However, quantitatively accurate results require accurate optical fluence estimates. Robust modeling in heterogeneous tissue, where light with different wavelengths can experience significantly different absorption and scattering, is difficult. In this work, we developed a deep neural network (Hybrid-Net) for sPA imaging to simultaneously estimate sO2 in blood vessels and segment those vessels from surrounding background tissue. sO2 error was minimized only in blood vessels segmented in Hybrid-Net, resulting in more accurate predictions. Hybrid-Net was first trained on simulated sPA data (at 700 nm and 850 nm) representing initial pressure distributions from three-dimensional Monte Carlo simulations of light transport in breast tissue. Then, for experimental verification, the network was retrained on experimental sPA data (at 700 nm and 850 nm) acquired from simple tissue mimicking phantoms with an embedded blood pool. Quantitative measures were used to evaluate Hybrid-Net performance with an averaged segmentation accuracy of >= 0.978 in simulations with varying noise levels (0dB-35dB) and 0.998 in the experiment, and an averaged sO2 mean squared error of <= 0.048 in simulations with varying noise levels (0dB-35dB) and 0.003 in the experiment. Overall, these results show that Hybrid-Net can provide accurate blood oxygenation without estimating the optical fluence, and this study could lead to improvements in in-vivo sO2 estimation.

Paper number 26:
Title: Semi-Blind Joint Channel and Symbol Estimation for Beyond Diagonal Reconfigurable Surfaces
Authors: Gilderlan Tavares de Araújo, André L. F. de Almeida Buno Sokal, Gabor Fodor, Paulo R. B. Gomes
Abstract: The beyond-diagonal reconfigurable intelligent surface (BD-RIS) is a recent architecture in which scattering elements are interconnected to enhance the degrees of freedom for wave control, yielding performance gains over traditional single-connected RISs. For BD-RIS, channel estimation - well-studied for conventional RIS - becomes more challenging due to the complex connections and a larger number of coefficients. Prior works rely on pilot-assisted estimation followed by data decoding. This paper introduces a semi-blind tensor-based approach for joint channel and symbol estimation that eliminates the need for training sequences by leveraging data symbols directly. A practical scenario with time-varying user terminal-RIS channels under mobility is considered. By reformulating the received signal from a tensor decomposition perspective, we develop two semi-blind receivers: a two-stage method transforming the fourth-order PARATUCK model into a third-order PARAFAC model, and a single-stage iterative process based on fourth-order TUCKER decomposition. Identifiability conditions for reliable joint recovery are derived, and numerical results demonstrate the performance advantages and trade-offs of the proposed schemes over existing solutions.

Paper number 27:
Title: Ising Machines for Model Predictive Path Integral-Based Optimal Control
Authors: Lorin Werthen-Brabants, Pieter Simoens
Abstract: We present a sampling-based Model Predictive Control (MPC) method that implements Model Predictive Path Integral (MPPI) as an \emph{Ising machine}, suitable for novel forms of probabilistic computing. By expressing the control problem as a Quadratic Unconstrained Binary Optimization (QUBO) problem, we map MPC onto an energy landscape suitable for Gibbs sampling from an Ising model. This formulation enables efficient exploration of (near-)optimal control trajectories. We demonstrate that the approach achieves accurate trajectory tracking compared to a reference MPPI implementation, highlighting the potential of Ising-based MPPI for real-time control in robotics and autonomous systems.

Paper number 28:
Title: Nine Years of Pediatric Iris Recognition: Evidence for Biometric Permanence
Authors: Naveenkumar G Venkataswamy, Masudul H Imtiaz, Stephanie Schuckers
Abstract: Biometric permanence in pediatric populations remains poorly understood despite widespread deployment of iris recognition for children in national identity programs such as India's Aadhaar and trusted traveler programs like Canada's NEXUS. This study presents a comprehensive longitudinal evaluation of pediatric iris recognition, analyzing 276 subjects enrolled between ages 4-12 and followed up to nine years through adolescence. Using 18,318 near-infrared iris images acquired semi-annually, we evaluated commercial (VeriEye) and open-source (OpenIris) systems through linear mixed-effects models that disentangle enrollment age, developmental maturation, and elapsed time while controlling for image quality and physiological factors. False non-match rates remained below 0.5% across the nine-year period for both matchers using pediatric-calibrated thresholds, approaching adult-level performance. However, we reveal significant algorithm-dependent temporal behaviors: VeriEye's apparent decline reflects developmental confounding across enrollment cohorts rather than genuine template aging, while OpenIris exhibits modest but genuine temporal aging (0.5 standard deviations over eight years). Image quality and pupil dilation constancy dominated longitudinal performance, with dilation effects reaching 3.0-3.5 standard deviations, substantially exceeding temporal factors. Failures concentrated in 9.4% of subjects with persistent acquisition challenges rather than accumulating with elapsed time, confirming acquisition conditions as the primary limitation. These findings justify extending conservative re-enrollment policies, potentially to 10-12 year validity periods for high-quality enrollments at ages 7+, and demonstrate iris recognition remains viable throughout childhood and adolescence with proper imaging control.

Paper number 29:
Title: Optimum Discrete Beamforming via Minkowski Sum of Polygons
Authors: Heedong Do, Angel Lozano
Abstract: This letter casts the problem of optimum discrete beamforming as the computation of the Minkowski sum of convex polygons, which is itself a convex polygon. The number of vertices of the latter is at most the sum of the number of vertices of the original polygons, enabling its efficient computation. This original and intuitive formulation confirms that the optimum beamforming solution can be found efficiently.

Paper number 30:
Title: An Open-Source Framework for Quality-Assured Smartphone-Based Visible Light Iris Recognition
Authors: Naveenkumar G. Venkataswamy, Yu Liu, Soumyabrata Dey, Stephanie Schuckers, Masudul H. Imtiaz
Abstract: Smartphone-based iris recognition in the visible spectrum (VIS) offers a low-cost and accessible biometric alternative but remains a challenge due to lighting variability, pigmentation effects, and the limited adoption of standardized capture protocols. In this work, we present CUVIRIS, a dataset of 752 ISO/IEC 29794-6 compliant iris images from 47 subjects, collected with a custom Android application that enforces real-time framing, sharpness assessment, and quality feedback. We further introduce LightIrisNet, a MobileNetV3-based multi-task segmentation model optimized for on-device deployment. In addition, we adapt IrisFormer, a transformer-based matcher, to the VIS domain. We evaluate OSIRIS and IrisFormer under a standardized protocol and benchmark against published CNN baselines reported in prior work. On CUVIRIS, the open-source OSIRIS system achieves a TAR of 97.9% at FAR = 0.01 (EER = 0.76%), while IrisFormer, trained only on the UBIRIS.v2 dataset, achieves an EER of 0.057\%. To support reproducibility, we release the Android application, LightIrisNet, trained IrisFormer weights, and a subset of the CUVIRIS dataset. These results show that, with standardized acquisition and VIS-adapted lightweight models, accurate iris recognition on commodity smartphones is feasible under controlled conditions, bringing this modality closer to practical deployment.

Paper number 31:
Title: Deep Reinforcement Learning for EH-Enabled Cognitive-IoT Under Jamming Attacks
Authors: Nadia Abdolkhani, Nada Abdel Khalek, Walaa Hamouda
Abstract: In the evolving landscape of the Internet of Things (IoT), integrating cognitive radio (CR) has become a practical solution to address the challenge of spectrum scarcity, leading to the development of cognitive IoT (CIoT). However, the vulnerability of radio communications makes radio jamming attacks a key concern in CIoT networks. In this paper, we introduce a novel deep reinforcement learning (DRL) approach designed to optimize throughput and extend network lifetime of an energy-constrained CIoT system under jamming attacks. This DRL framework equips a CIoT device with the autonomy to manage energy harvesting (EH) and data transmission, while also regulating its transmit power to respect spectrum-sharing constraints. We formulate the optimization problem under various constraints, and we model the CIoT device's interactions within the channel as a model-free Markov decision process (MDP). The MDP serves as a foundation to develop a double deep Q-network (DDQN), designed to help the CIoT agent learn the optimal communication policy to navigate challenges such as dynamic channel occupancy, jamming attacks, and channel fading while achieving its goal. Additionally, we introduce a variant of the upper confidence bound (UCB) algorithm, named UCB-IA, which enhances the CIoT network's ability to efficiently navigate jamming attacks within the channel. The proposed DRL algorithm does not rely on prior knowledge and uses locally observable information such as channel occupancy, jamming activity, channel gain, and energy arrival to make decisions. Extensive simulations prove that our proposed DRL algorithm that utilizes the UCB-IA strategy surpasses existing benchmarks, allowing for a more adaptive, energy-efficient, and secure spectrum sharing in CIoT networks.

Paper number 32:
Title: Scheduling the Charge of Temporally Flexible Electric Vehicles: a Market-based Approach
Authors: Sabri El Amrani, Thibaut Horel, Saurabh Vaishampayan, Maryam Kamgarpour, Munther A. Dahleh
Abstract: The increasing electrification of human activities and the rapid integration of variable renewable energy sources strain the power grid. A solution to address the need for more grid storage is to use the battery of electric vehicles as a back-up capacity. However, drivers tend to disconnect their electric vehicle when its battery is needed the most. We propose a charge scheduler that incentivizes drivers to delay their disconnection to improve vehicle-to-grid services. We also leverage drivers' temporal flexibility to alleviate congestion in oversubscribed charging stations. We formulate the computation of an optimal flexible schedule as a mixed-integer quadratic problem. We tractably approximate its solution using the Alternating Direction Method of Multipliers. Considering the possibility that strategic drivers misreport their charging preferences to the station coordinator, we then propose a Vickrey-Clarke-Groves mechanism that incentivizes truthful reporting. We conclude with a simulated case study using real-world data to quantitatively assess the added value of drivers' temporal flexibility for enhancing vehicle-to-grid services and reducing station congestion.

Paper number 33:
Title: Operator-Theoretic Joint Estimation of Aging-Aware State of Charge and Control-Informed State of Health
Authors: Rahmat K. Adesunkanmi, Adel Alaeddini, Mahesh Krishnamurthy
Abstract: Accurate estimation of a battery's state of charge and state of health is essential for safe and reliable battery management. Existing approaches often decouple these two states, lack stability guarantees, and exhibit limited generalization across operating conditions. This study introduces a unified operator-theoretic framework for aging-aware state of charge and control-informed state of health estimation. The architecture couples a Koopman-based latent dynamics model, which enables linear forecasting of nonlinear discharge-capacity evolution under varying operational conditions, with a neural operator that maps measurable intra-cycle signals to state of charge. The predicted discharge capacity is incorporated as a static correction within the neural operator pathway, yielding an age-aware state of charge estimate. Stability is ensured through spectral-radius clipping of the Koopman operator. The overall framework is trained end-to-end and evaluated on real-world lithium-ion battery datasets, demonstrating real-time capability while maintaining stable dynamics. To handle condition shifts and unseen regimes, the method integrates both zero-shot and few-shot out-of-distribution adaptation using only a limited number of cycles. Results show accurate and stable capacity forecasts, competitive state of charge trajectories on held-out cycles, and a direct, model-consistent mechanism for tracking capacity fade as a surrogate for state of health across diverse operating conditions.

Paper number 34:
Title: Enhancing industrial microalgae production through Economic Model Predictive Control
Authors: Pablo Otálora, Sigurd Skogestad, José Luis Guzmán, Manuel Berenguel
Abstract: The industrial production of microalgae is an important and sustainable process, but its actual competitiveness is closely related to its optimization. The biological nature of the process hinders this task, mainly due to the high nonlinearity of the process along with its changing nature, features that make its modeling, control and optimization remarkably challenging. This paper presents an economic optimization framework aiming to enhance the operation of such systems. An Economic Model Predictive Controller is proposed, centralizing the decision making and achieving the theoretical optimal operation. Different scenarios with changing climate conditions are presented, and a comparison with the typical, non-optimized industrial process operation is established. The obtained results achieve economic optimization and dynamic stability of the process, while providing some insight into the priorities during process operation at industrial level, and justifying the use of optimal controllers over traditional operation.

Paper number 35:
Title: Service-Oriented Fast Frequency Response from Flexible Loads and Energy Storage in Low-Inertia Power Systems
Authors: Xiaojie Tao, Rajit Gadh
Abstract: The increasing penetration of inverter-based renewable generation has significantly reduced system inertia, making modern power grids more vulnerable to rapid frequency deviations following disturbances. While a wide range of flexible resources-including electric vehicles (EVs), data centers, and battery energy storage systems (BESS)-have demonstrated the physical capability to provide fast frequency response (FFR), existing studies primarily focus on individual resource performance or controller-level designs. A systematic framework that translates heterogeneous FFR capabilities into deployable, system-level frequency services remains largely unexplored. This paper proposes a service-oriented coordination framework for fast frequency response from flexible loads and energy storage, bridging the gap between physical capability assessment and grid-operational utilization. The framework decomposes frequency support into multiple time-critical service layers based on response speed, power capacity, and energy sustainability, and dynamically allocates FFR responsibilities among heterogeneous resources accordingly. By explicitly accounting for response latency, saturation limits, and energy constraints, the proposed approach enables coordinated dispatch that prioritizes ultra-fast resources for initial frequency arrest while leveraging slower but energy-rich resources to sustain recovery.

Paper number 36:
Title: Radiomics and Clinical Features in Predictive Modelling of Brain Metastases Recurrence
Authors: Ines Faria, Matheus Silva, Crystian Saraiva, Jose Soares, Victor Alves
Abstract: Brain metastases affect approximately between 20% and 40% of cancer patients and are commonly treated with radiotherapy or radiosurgery. Early prediction of recurrence following treatment could enable timely clinical intervention and improve patient outcomes. This study proposes an artificial intelligence based approach for predicting brain metastasis recurrence using multimodal imaging and clinical data. A retrospective cohort of 97 patients was collected, including Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) acquired before treatment and at first follow-up, together with relevant clinical variables. Image preprocessing included CT windowing and artifact reduction, MRI enhancement, and multimodal CT MRI registration. After applying inclusion criteria, 53 patients were retained for analysis. Radiomics features were extracted from the imaging data, and delta radiomics was employed to characterize temporal changes between pre-treatment and follow-up scans. Multiple machine learning classifiers were trained and evaluated, including an analysis of discrepancies between treatment planning target volumes and delivered isodose volumes. Despite limitations related to sample size and class imbalance, the results demonstrate the feasibility of radiomics based models, namely ensemble models, for recurrence prediction and suggest a potential association between radiation dose discrepancies and recurrence risk. This work supports further investigation of AI-driven tools to assist clinical decision-making in brain metastasis management.

Paper number 37:
Title: INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT
Authors: Idan Tankel, Nir Mazor, Rafi Brada, Christina LeBedis, Guy ben-Yosef
Abstract: Incidental findings in CT scans, though often benign, can have significant clinical implications and should be reported following established guidelines. Traditional manual inspection by radiologists is time-consuming and variable. This paper proposes a novel framework that leverages large language models (LLMs) and foundational vision-language models (VLMs) in a plan-and-execute agentic approach to improve the efficiency and precision of incidental findings detection, classification, and reporting for abdominal CT scans. Given medical guidelines for abdominal organs, the process of managing incidental findings is automated through a planner-executor framework. The planner, based on LLM, generates Python scripts using predefined base functions, while the executor runs these scripts to perform the necessary checks and detections, via VLMs, segmentation models, and image processing subroutines. We demonstrate the effectiveness of our approach through experiments on a CT abdominal benchmark for three organs, in a fully automatic end-to-end manner. Our results show that the proposed framework outperforms existing pure VLM-based approaches in terms of accuracy and efficiency.

Paper number 38:
Title: HERBench: A Benchmark for Multi-Evidence Integration in Video Question Answering
Authors: Dan Ben-Ami, Gabriele Serussi, Kobi Cohen, Chaim Baskin
Abstract: Video Large Language Models (Video-LLMs) are rapidly improving, yet current Video Question Answering (VideoQA) benchmarks often allow questions to be answered from a single salient cue, under-testing reasoning that must aggregate multiple, temporally separated visual evidence. We present HERBench, a VideoQA benchmark purpose-built to assess multi-evidence integration across time. Each question requires aggregating at least three non-overlapping evidential cues across distinct video segments, so neither language priors nor a single snapshot can suffice. HERBench comprises 26K five-way multiple-choice questions organized into twelve compositional tasks that probe identity binding, cross-entity relations, temporal ordering, co-occurrence verification, and counting. To make evidential demand measurable, we introduce the Minimum Required Frame-Set (MRFS), the smallest number of frames a model must fuse to answer correctly, and show that HERBench imposes substantially higher demand than prior datasets (mean MRFS 5.5 vs. 2.6-4.2). Evaluating 13 state-of-the-art Video-LLMs on HERBench reveals pervasive failures: accuracies of 31-42% are only slightly above the 20% random-guess baseline. We disentangle this failure into two critical bottlenecks: (1) a retrieval deficit, where frame selectors overlook key evidence, and (2) a fusion deficit, where models fail to integrate information even when all necessary evidence is provided. By making cross-time evidence both unavoidable and quantifiable, HERBench establishes a principled target for advancing robust, compositional video understanding.

Paper number 39:
Title: Restless Multi-Process Multi-Armed Bandits with Applications to Self-Driving Microscopies
Authors: Jaume Anguera Peris, Songtao Cheng, Hanzhao Zhang, Wei Ouyang, Joakim Jaldén
Abstract: High-content screening microscopy generates large amounts of live-cell imaging data, yet its potential remains constrained by the inability to determine when and where to image most effectively. Optimally balancing acquisition time, computational capacity, and photobleaching budgets across thousands of dynamically evolving regions of interest remains an open challenge, further complicated by limited field-of-view adjustments and sensor sensitivity. Existing approaches either rely on static sampling or heuristics that neglect the dynamic evolution of biological processes, leading to inefficiencies and missed events. Here, we introduce the restless multi-process multi-armed bandit (RMPMAB), a new decision-theoretic framework in which each experimental region is modeled not as a single process but as an ensemble of Markov chains, thereby capturing the inherent heterogeneity of biological systems such as asynchronous cell cycles and heterogeneous drug responses. Building upon this foundation, we derive closed-form expressions for transient and asymptotic behaviors of aggregated processes, and design scalable Whittle index policies with sub-linear complexity in the number of imaging regions. Through both simulations and a real biological live-cell imaging dataset, we show that our approach achieves substantial improvements in throughput under resource constraints. Notably, our algorithm outperforms Thomson Sampling, Bayesian UCB, epsilon-Greedy, and Round Robin by reducing cumulative regret by more than 37% in simulations and capturing 93% more biologically relevant events in live imaging experiments, underscoring its potential for transformative smart microscopy. Beyond improving experimental efficiency, the RMPMAB framework unifies stochastic decision theory with optimal autonomous microscopy control, offering a principled approach to accelerate discovery across multidisciplinary sciences.

Paper number 40:
Title: Vector Flow Imaging in Layered Models With a High Speed of Sound Contrast Using Pulse-Echo Ultrasound and Photoacoustics
Authors: Caitlin Smith, Guillaume Renaud, Kasper van Wijk, Jami Shepherd
Abstract: In this study, we develop vector flow imaging techniques for multi-layered models with a high wavespeed contrast using photoacoustic and ultrasonic imaging. We use refraction-corrected delay-and-sum image reconstruction (RC-DAS), which enforces Snell's law to accurately calculate time delays within each layer. We compare RC-DAS against conventional delay-and-sum for vector flow imaging in benchtop phantoms made of transparent polymethyl methacrylate (PMMA) in a water bath. We study the flow beneath a PMMA layer using two phantoms, where the PMMA layer has different shapes and thicknesses. We image a slow-moving suspension of carbon microspheres (~4 mm/s) using interleaved photoacoustic and multi-angle plane wave ultrasound acquisitions measured with a 7.6 MHz linear ultrasound array. Photoacoustic waves are generated by a 1064 nm wavelength nanosecond-pulsed laser at 50 Hz, and multi-angle plane wave ultrasound data are acquired at 100 Hz for eleven steering angles between $\pm$10$^\circ$. RC-DAS improves the flow speed accuracy, reducing the mean absolute error by 0.41-0.63 mm/s compared to the expected flow profile. The error in direction estimates improves when we use RC-DAS, with the interdecile range reducing by up to 17$^\circ$. This work emphasises the importance of refraction correction for accurate flow measurements in layered media with photoacoustics and ultrasonic imaging. While both imaging modalities can quantify flow in these multi-layered models, the modality best suited for a specific application will depend on the imaging target and flow dynamics. These techniques show promise for biomedical applications such as intraosseous and transcranial blood flow quantification, and in nondestructive testing to monitor fluid motion.

Paper number 41:
Title: Adaptive Multimodal Person Recognition: A Robust Framework for Handling Missing Modalities
Authors: Aref Farhadipour, Teodora Vukovic, Volker Dellwo, Petr Motlicek, Srikanth Madikeri
Abstract: Person recognition systems often rely on audio, visual, or behavioral cues, but real-world conditions frequently result in missing or degraded modalities. To address this challenge, we propose a Trimodal person identification framework that integrates voice, face, and gesture modalities, while remaining robust to modality loss. Our approach leverages multi-task learning to process each modality independently, followed by a cross-attention and gated fusion mechanisms to facilitate interaction across modalities. Moreover, a confidence-weighted fusion strategy dynamically adapts to missing and low-quality data, ensuring optimal classification even in Unimodal or Bimodal scenarios. We evaluate our method on CANDOR, a newly introduced interview-based multimodal dataset, which we benchmark for the first time. Our results demonstrate that the proposed Trimodal system achieves 99.18% Top-1 accuracy on person identification tasks, outperforming conventional Unimodal and late-fusion approaches. In addition, we evaluate our model on the VoxCeleb1 dataset as a benchmark and reach 99.92% accuracy in Bimodal mode. Moreover, we show that our system maintains high accuracy even when one or two modalities are unavailable, making it a robust solution for real-world person recognition applications. The code and data for this work are publicly available.

Paper number 42:
Title: EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks
Authors: Zijiang Yan, Yixiang Huang, Jianhua Pei, Hina Tabassum, Luca Chiaraviglio
Abstract: The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wideband aggregate EMF data, frequency-selective multivariate forecasting is needed to capture the inter-operator and inter-frequency variations essential for proactive network planning. To this end, this paper introduces EMFusion, a conditional multivariate diffusion-based probabilistic forecasting framework that integrates diverse contextual factors (e.g., time of day, season, and holidays) while providing explicit uncertainty estimates. The proposed architecture features a residual U-Net backbone enhanced by a cross-attention mechanism that dynamically integrates external conditions to guide the generation process. Furthermore, EMFusion integrates an imputation-based sampling strategy that treats forecasting as a structural inpainting task, ensuring temporal coherence even with irregular measurements. Unlike standard point forecasters, EMFusion generates calibrated probabilistic prediction intervals directly from the learned conditional distribution, providing explicit uncertainty quantification essential for trustworthy decision-making. Numerical experiments conducted on frequency-selective EMF datasets demonstrate that EMFusion with the contextual information of working hours outperforms the baseline models with or without conditions. The EMFusion outperforms the best baseline by 23.85% in continuous ranked probability score (CRPS), 13.93% in normalized root mean square error, and reduces prediction CRPS error by 22.47%.

Paper number 43:
Title: Historical Information Accelerates Decentralized Optimization: A Proximal Bundle Method
Authors: Zhao Zhu, Yu-Ping Tian, Xuyang Wu
Abstract: Historical information, such as past function values or gradients, has significant potential to enhance decentralized optimization methods for two key reasons: first, it provides richer information about the objective function, which also explains its established success in centralized optimization; second, unlike the second-order derivative or its alternatives, historical information has already been computed or communicated and requires no additional cost to acquire. Despite this potential, it remains underexploited. In this work, we employ a proximal bundle framework to incorporate the function values and gradients at historical iterates and adapt the framework to the proximal decentralized gradient descent method, resulting in a Decentralized Proximal Bundle Method (DPBM). To broaden its applicability, we further extend DPBM to the asynchronous and stochastic setting. We theoretically analysed the convergence of the proposed methods. Notably, both the asynchronous DPBM and its stochastic variant can converge with fixed step-sizes that are independent of delays, which is superior to the delay-dependent step-sizes required by most existing asynchronous optimization methods, as it is easier to determine and often leads to faster convergence. Numerical experiments on classification problems demonstrate that by using historical information, our methods yield faster convergence and stronger robustness in the step-sizes.

Paper number 44:
Title: O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization
Authors: Elio Gruttadauria (IP Paris, LTCI, IDS, S2A), Mathieu Fontaine (LTCI, IP Paris), Jonathan Le Roux, Slim Essid (IDS, S2A, LTCI)
Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

Paper number 45:
Title: A Blind Source Separation Framework to Monitor Sectoral Power Demand from Grid-Scale Load Measurements
Authors: Guillaume Koechlin, Filippo Bovera, Elena Degli Innocenti, Barbara Santini, Alessandro Venturi, Simona Vazio, Piercesare Secchi
Abstract: As we are moving towards decentralized power systems dominated by intermittent electricity generation from renewable energy sources, demand-side flexibility is becoming a critical issue. In this context, it is essential to understand the composition of electricity demand at various scales of the power grid. At the regional or national scale, there is however little visibility on the relative contributions of different consumer categories, due to the complexity and costs of collecting end-users consumption data. To address this issue, we propose a blind source separation framework based on a constrained variant of non-negative matrix factorization to monitor the consumption of residential, services and industrial sectors at high frequency from aggregate high-voltage grid load measurements. Applying the method to Italy's national load curve between 2021 and 2023, we reconstruct accurate hourly consumption profiles for each sector. Results reveal that both households and services daily consumption behaviors are driven by two distinct regimes related to the season and day type whereas industrial demand follows a single, stable daily profile. Besides, the monthly consumption estimates of each sector derived from the disaggregated load are found to closely align with sample-based indices and be more precise than forecasting approaches based on these indices for real-time monitoring.

Paper number 46:
Title: Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery
Authors: Hiroyoshi Nagahama, Katsufumi Inoue, Masayoshi Todorokihara, Michifumi Yoshioka
Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

Paper number 47:
Title: Remotely Detectable Robot Policy Watermarking
Authors: Michael Amir, Manon Flageat, Amanda Prorok
Abstract: The success of machine learning for real-world robotic systems has created a new form of intellectual property: the trained policy. This raises a critical need for novel methods that verify ownership and detect unauthorized, possibly unsafe misuse. While watermarking is established in other domains, physical policies present a unique challenge: remote detection. Existing methods assume access to the robot's internal state, but auditors are often limited to external observations (e.g., video footage). This ``Physical Observation Gap'' means the watermark must be detected from signals that are noisy, asynchronous, and filtered by unknown system dynamics. We formalize this challenge using the concept of a \textit{glimpse sequence}, and introduce Colored Noise Coherency (CoNoCo), the first watermarking strategy designed for remote detection. CoNoCo embeds a spectral signal into the robot's motions by leveraging the policy's inherent stochasticity. To show it does not degrade performance, we prove CoNoCo preserves the marginal action distribution. Our experiments demonstrate strong, robust detection across various remote modalities, including motion capture and side-way/top-down video footage, in both simulated and real-world robot experiments. This work provides a necessary step toward protecting intellectual property in robotics, offering the first method for validating the provenance of physical policies non-invasively, using purely remote observations.

Paper number 48:
Title: Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection
Authors: Julian Oelhaf, Mehran Pashaei, Georg Kordowich, Christian Bergler, Andreas Maier, Johann Jäger, Siming Bayer
Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection. High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

Paper number 49:
Title: Three-Dimensional Radio Localization: A Channel Charting-Based Approach
Authors: Phillip Stephan, Florian Euchner, Stephan ten Brink
Abstract: Channel charting creates a low-dimensional representation of the radio environment in a self-supervised manner using manifold learning. Preserving relative spatial distances in the latent space, channel charting is well suited to support user localization. While prior work on channel charting has mainly focused on two-dimensional scenarios, real-world environments are inherently three-dimensional. In this work, we investigate two distinct three-dimensional indoor localization scenarios using simulated, but realistic ray tracing-based datasets: a factory hall with a three-dimensional spatial distribution of datapoints, and a multistory building where each floor exhibits a two-dimensional datapoint distribution. For the first scenario, we apply the concept of augmented channel charting, which combines classical localization and channel charting, to a three-dimensional setting. For the second scenario, we introduce multistory channel charting, a two-stage approach consisting of floor classification via clustering followed by the training of a dedicated expert neural network for channel charting on each individual floor, thereby enhancing the channel charting performance. In addition, we propose a novel feature engineering method designed to extract sparse features from the beamspace channel state information that are suitable for localization.

Paper number 50:
Title: Lithium-ion battery degradation: Introducing the concept of reservoirs to design for lifetime
Authors: Mohammed Asheruddin Nazeeruddin, Ruihe Li, Simon E. J. OKane, Monica Marinescu, Gregory J. Offer
Abstract: Designing lithium-ion batteries for long service life remains a challenge, as most cells are optimized for beginning-of-life metrics such as energy density, often overlooking how design and operating conditions shape degradation. This work introduces a degradation-aware design framework built around finite, interacting reservoirs (lithium, porosity, and electrolyte) that are depleted over time by coupled degradation processes. We extend a physics-based Doyle-Fuller-Newman model to include validated mechanisms such as SEI growth, lithium plating, cracking, and solvent dry-out, and simulate how small design changes impact lifetime. Across more than 1,000 cycles, we find that increasing electrolyte volume by just 1% or porosity by 5% can extend service life by over 30% without significantly affecting cell energy density. However, lithium excess, while boosting initial capacity, can accelerate failure if not supported by sufficient structural or ionic buffers. Importantly, we show that interaction between reservoirs is crucial to optimal design: multi-reservoir tuning yields either synergistic benefits or compound failures, depending on operating conditions. We also quantify how C-rate and operating temperature influence degradation pathways, emphasizing the need for co-optimized design and usage profiles. By reframing degradation as a problem of managing finite internal reservoirs, this work offers a predictive and mechanistic foundation for designing lithium-ion batteries that balance energy, durability, and application-specific needs.

Paper number 51:
Title: A Container-based Approach For Proactive Asset Administration Shell Digital Twins
Authors: Carsten Ellwein, Jingxi Zhang, Andreas Wortmann, Antony Ayman Alfy Meckhael
Abstract: In manufacturing, digital twins, realized as Asset Administration Shells (AAS), have emerged as a prevalent practice. These digital replicas, often utilized as structured repositories of asset-related data, facilitate interoperability across diverse systems. However, extant approaches treat the AAS as a static information model, lacking support for dynamic service integration and system adaptation. The existing body of literature has not yet thoroughly explored the potential for integrating executable behavior, particularly in the form of containerized services, into or from the AAS. This integration could serve to enable proactive functionality. In this paper, we propose a submodel-based architecture that introduces a structured service notion to the AAS, enabling services to dynamically interact with and adapt AAS instances at runtime. This concept is implemented through the extension of a submodel with behavioral definitions, resulting in a modular event-driven architecture capable of deploying containerized services based on embedded trigger conditions. The approach is illustrated through a case study on a 3-axis milling machine. Our contribution enables the AAS to serve not only as a passive digital representation but also as an active interface for executing added-value services.%, thereby laying the foundation for future AI-driven adaptation and system-level intelligence in digital twin environments.

Paper number 52:
Title: QuantGraph: A Receding-Horizon Quantum Graph Solver
Authors: Pranav Vaidhyanathan, Aristotelis Papatheodorou, David R. M. Arvidsson-Shukur, Mark T. Mitchison, Natalia Ares, Ioannis Havoutis
Abstract: Dynamic programming is a cornerstone of graph-based optimization. While effective, it scales unfavorably with problem size. In this work, we present QuantGraph, a two-stage quantum-enhanced framework that casts local and global graph-optimization problems as quantum searches over discrete trajectory spaces. The solver is designed to operate efficiently by first finding a sequence of locally optimal transitions in the graph (local stage), without considering full trajectories. The accumulated cost of these transitions acts as a threshold that prunes the search space (up to 60% reduction for certain examples). The subsequent global stage, based on this threshold, refines the solution. Both stages utilize variants of the Grover-adaptive-search algorithm. To achieve scalability and robustness, we draw on principles from control theory and embed QuantGraph's global stage within a receding-horizon model-predictive-control scheme. This classical layer stabilizes and guides the quantum search, improving precision and reducing computational burden. In practice, the resulting closed-loop system exhibits robust behavior and lower overall complexity. Notably, for a fixed query budget, QuantGraph attains a 2x increase in control-discretization precision while still benefiting from Grover-search's inherent quadratic speedup compared to classical methods.

Paper number 53:
Title: The LUMirage: An independent evaluation of zero-shot performance in the LUMIR challenge
Authors: Rohit Jena, Pratik Chaudhari, James C. Gee
Abstract: The LUMIR challenge represents an important benchmark for evaluating deformable image registration methods on large-scale neuroimaging data. While the challenge demonstrates that modern deep learning methods achieve competitive accuracy on T1-weighted MRI, it also claims exceptional zero-shot generalization to unseen contrasts and resolutions, assertions that contradict established understanding of domain shift in deep learning. In this paper, we perform an independent re-evaluation of these zero-shot claims using rigorous evaluation protocols while addressing potential sources of instrumentation bias. Our findings reveal a more nuanced picture: (1) deep learning methods perform comparably to iterative optimization on in-distribution T1w images and even on human-adjacent species (macaque), demonstrating improved task understanding; (2) however, performance degrades significantly on out-of-distribution contrasts (T2, T2*, FLAIR), with Cohen's d scores ranging from 0.7-1.5, indicating substantial practical impact on downstream clinical workflows; (3) deep learning methods face scalability limitations on high-resolution data, failing to run on 0.6 mm isotropic images, while iterative methods benefit from increased resolution; and (4) deep methods exhibit high sensitivity to preprocessing choices. These results align with the well-established literature on domain shift and suggest that claims of universal zero-shot superiority require careful scrutiny. We advocate for evaluation protocols that reflect practical clinical and research workflows rather than conditions that may inadvertently favor particular method classes.

Paper number 54:
Title: A Conditioned UNet for Music Source Separation
Authors: Ken O'Hanlon, Basil Woods, Lin Wang, Mark Sandler
Abstract: In this paper we propose a conditioned UNet for Music Source Separation (MSS). MSS is generally performed by multi-output neural networks, typically UNets, with each output representing a particular stem from a predefined instrument vocabulary. In contrast, conditioned MSS networks accept an audio query related to a stem of interest alongside the signal from which that stem is to be extracted. Thus, a strict vocabulary is not required and this enables more realistic tasks in MSS. The potential of conditioned approaches for such tasks has been somewhat hidden due to a lack of suitable data, an issue recently addressed with the MoisesDb dataset. A recent method, Banquet, employs this dataset with promising results seen on larger vocabularies. Banquet uses Bandsplit RNN rather than a UNet and the authors state that UNets should not be suitable for conditioned MSS. We counter this argument and propose QSCNet, a novel conditioned UNet for MSS that integrates network conditioning elements in the Sparse Compressed Network for MSS. We find QSCNet to outperform Banquet by over 1dB SNR on a couple of MSS tasks, while using less than half the number of parameters.

Paper number 55:
Title: Reducing Pilots in Channel Estimation With Predictive Foundation Models
Authors: Xingyu Zhou, Le Liang, Hao Ye, Jing Zhang, Chao-Kai Wen, Shi Jin
Abstract: Accurate channel state information (CSI) acquisition is essential for modern wireless systems, which becomes increasingly difficult under large antenna arrays, strict pilot overhead constraints, and diverse deployment environments. Existing artificial intelligence-based solutions often lack robustness and fail to generalize across scenarios. To address this limitation, this paper introduces a predictive-foundation-model-based channel estimation framework that enables accurate, low-overhead, and generalizable CSI acquisition. The proposed framework employs a predictive foundation model trained on large-scale cross-domain CSI data to extract universal channel representations and provide predictive priors with strong cross-scenario transferability. A pilot processing network based on a vision transformer architecture is further designed to capture spatial, temporal, and frequency correlations from pilot observations. An efficient fusion mechanism integrates predictive priors with real-time measurements, enabling reliable CSI reconstruction even under sparse or noisy conditions. Extensive evaluations across diverse configurations demonstrate that the proposed estimator significantly outperforms both classical and data-driven baselines in accuracy, robustness, and generalization capability.

Paper number 56:
Title: Exact Learning of Linear Model Predictive Control Laws using Oblique Decision Trees with Linear Predictions
Authors: Jiayang Ren, Qiangqiang Mao, Tianwei Zhao, Yankai Cao
Abstract: Model Predictive Control (MPC) is a powerful strategy for constrained multivariable systems but faces computational challenges in real-time deployment due to its online optimization requirements. While explicit MPC and neural network approximations mitigate this burden, they suffer from scalability issues or lack interpretability, limiting their applicability in safety-critical systems. This work introduces a data-driven framework that directly learns the Linear MPC control law from sampled state-action pairs using Oblique Decision Trees with Linear Predictions (ODT-LP), achieving both computational efficiency and interpretability. By leveraging the piecewise affine structure of Linear MPC, we prove that the Linear MPC control law can be replicated by finite-depth ODT-LP models. We develop a gradient-based training algorithm using smooth approximations of tree routing functions to learn this structure from grid-sampled Linear MPC solutions, enabling end-to-end optimization. Input-to-state stability is established under bounded approximation errors, with explicit error decomposition into learning inaccuracies and sampling errors to inform model design. Numerical experiments demonstrate that ODT-LP controllers match MPC's closed-loop performance while reducing online evaluation time by orders of magnitude compared to MPC, explicit MPC, neural network, and random forest counterparts. The transparent tree structure enables formal verification of control logic, bridging the gap between computational efficiency and certifiable reliability for safety-critical systems.

Paper number 57:
Title: Persistent feature reconstruction of resident space objects (RSOs) within inverse synthetic aperture radar (ISAR) images
Authors: Morgan Coe, Gruffudd Jones, Leah-Nani Alconcel, Marina Gashinova
Abstract: With the rapidly growing population of resident space objects (RSOs) in the near-Earth space environment, detailed information about their condition and capabilities is needed to provide Space Domain Awareness (SDA). Space-based sensing will enable inspection of RSOs at shorter ranges, independent of atmospheric effects, and from all aspects. The use of a sub-THz inverse synthetic aperture radar (ISAR) imaging and sensing system for SDA has been proposed in previous work, demonstrating the achievement of sub-cm image resolution at ranges of up to 100 km. This work focuses on recognition of external structures by use of sequential feature detection and tracking throughout the aligned ISAR images of the satellites. The Hough transform is employed to detect linear features, which are tracked throughout the sequence. ISAR imagery is generated via a metaheuristic simulator capable of modelling encounters for a variety of deployment scenarios. Initial frame-to-frame alignment is achieved through a series of affine transformations to facilitate later association between image features. A gradient-by-ratio method is used for edge detection within individual ISAR images, and edge magnitude and direction are subsequently used to inform a double-weighted Hough transform to detect features with high accuracy. Feature evolution during sequences of frames is analysed. It is shown that the use of feature tracking within sequences with the proposed approach will increase confidence in feature detection and classification, and an example use-case of robust detection of shadowing as a feature is presented.

Paper number 58:
Title: Multi-Modal Semantic Communication
Authors: Matin Mortaheb, Erciyes Karakaya, Sennur Ulukus
Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

Paper number 59:
Title: Online convex optimization for robust control of constrained dynamical systems
Authors: Marko Nonhoff, Emiliano Dall'Anese, Matthias A. Müller
Abstract: This article investigates the problem of controlling linear time-invariant systems subject to time-varying and a priori unknown cost functions, state and input constraints, and exogenous disturbances. We combine the online convex optimization framework with tools from robust model predictive control to propose an algorithm that is able to guarantee robust constraint satisfaction. The performance of the closed loop emerging from application of our framework is studied in terms of its dynamic regret, which is proven to be bounded linearly by the variation of the cost functions and the magnitude of the disturbances. We corroborate our theoretical findings and illustrate implementational aspects of the proposed algorithm by a numerical case study on a tracking control problem of an autonomous vehicle.

Paper number 60:
Title: Exploring the Influence of Residential Electric Vehicle Charging on Distribution System Hosting Capacity -- A Case-Study in Arizona
Authors: Mohammad Golgol, Anamitra Pal, Vijay Vittal, Christine Fini, Ernest Palomino, Kyle Girardi
Abstract: The installation of high-capacity fast chargers for electric vehicles (EVs) is posing a significant risk to the distribution grid as the increased demand from widespread residential EV charging could exceed the technical limits of the distribution system. Addressing this issue is critical, given that current infrastructure upgrades to enhance EV hosting capacity are both costly and time-consuming. Moreover, the inherent uncertainties associated with EV charging parameters make it challenging for power utilities to accurately assess the impact of EVs added to specific locations. To address these knowledge gaps, this study (a) introduces an algorithm to coordinate residential EV charging, and (b) proposes a comprehensive framework that evaluates all transformers within a feeder. The proposed method is applied to a real-world feeder, which includes 120 transformers of varying capacities. The results demonstrate that this approach effectively manages a substantial number of EVs without overloading any of the transformers, while also pinpointing locations that must be prioritized for future upgrades. This framework can serve as a valuable reference for utilities when conducting distribution system evaluations for supporting the growing EV penetration.

Paper number 61:
Title: From Pretraining to Privacy: Federated Ultrasound Foundation Model with Self-Supervised Learning
Authors: Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Zhen Li
Abstract: Ultrasound imaging is widely used in clinical diagnosis due to its non-invasive nature and real-time capabilities. However, traditional ultrasound diagnostics relies heavily on physician expertise and is often hampered by suboptimal image quality, leading to potential diagnostic errors. While artificial intelligence (AI) offers a promising solution to enhance clinical diagnosis by detecting abnormalities across various imaging modalities, existing AI methods for ultrasound face two major challenges. First, they typically require vast amounts of labeled medical data, raising serious concerns regarding patient privacy. Second, most models are designed for specific tasks, which restricts their broader clinical utility. To overcome these challenges, we present UltraFedFM, an innovative privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively pre-trained using federated learning across 16 distributed medical institutions in 9 countries, leveraging a dataset of over 1 million ultrasound images covering 19 organs and 10 ultrasound modalities. This extensive and diverse data, combined with a secure training framework, enables UltraFedFM to exhibit strong generalization and diagnostic capabilities. It achieves an average area under the receiver operating characteristic curve (AUROC) of 0.927 for disease diagnosis and a dice similarity coefficient (DSC) of 0.878 for lesion segmentation. Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level ultrasonographers (4-8 years of experience) and matches the performance of expert-level sonographers (10+ years of experience) in the joint diagnosis of 8 common systemic diseases.c These findings indicate that UltraFedFM can significantly enhance clinical diagnostics while safeguarding patient privacy, marking a significant advancement in AI-driven ultrasound imaging for future clinical applications.

Paper number 62:
Title: Detection of Performance Interference Among Network Slices in 5G/6G Systems
Authors: Van Sy Mai, Richard La, Tao Zhang, Bin Hu
Abstract: Recent studies showed that network slices (NSs), which are logical networks supported by shared physical networks, can experience service interference due to sharing of physical and virtual resources. Thus, from the perspective of providing end-to-end (E2E) service quality assurance in 5G/6G systems, it is crucial to discover possible service interference among existing NSs in a timely manner and isolate the potential issues before they can lead to violations of service quality agreements. We study the problem of (a) detecting service interference among NSs in 5G/6G systems and (b) identifying misbehaving NSs and other affected NSs, only using E2E key performance indicator measurements, and propose new algorithms. Our numerical studies demonstrate that, even when the service interference among NSs is weak to moderate, provided that a reasonable number of measurements are available, the proposed algorithms can correctly identify most of shared resources that can lead to service interference among the NSs that utilize the shared resources and misbehaving NSs that can cause potentially adverse service interference and affected NSs.

Paper number 63:
Title: Differentially Private Gradient-Tracking-Based Distributed Stochastic Optimization over Directed Graphs
Authors: Jialong Chen, Jimin Wang, Ji-Feng Zhang
Abstract: This paper proposes a differentially private gradient-tracking-based distributed stochastic optimization algorithm over directed graphs. In particular, privacy noises are incorporated into each agent's state and tracking variable to mitigate information leakage, after which the perturbed states and tracking variables are transmitted to neighbors. We design two novel schemes for the step-sizes and the sampling number within the algorithm. The sampling parameter-controlled subsampling method employed by both schemes enhances the differential privacy level, and ensures a finite cumulative privacy budget even over infinite iterations. The algorithm achieves both almost sure and mean square convergence for nonconvex objectives. Furthermore, when nonconvex objectives satisfy the Polyak-Lojasiewicz (PL) condition, Scheme (S1) achieves a polynomial mean square convergence rate, and Scheme (S2) achieves an exponential mean square convergence rate. The trade-off between privacy and convergence is presented. The effectiveness of the algorithm and its superior performance compared to existing works are illustrated through numerical examples of distributed training on the benchmark datasets "MNIST" and "CIFAR-10".

Paper number 64:
Title: MedicoSAM: Robust Improvement of SAM for Medical Imaging
Authors: Anwai Archit, Luca Freckmann, Constantin Pape
Abstract: Medical image segmentation is an important analysis task in clinical practice and research. Deep learning has massively advanced the field, but current approaches are mostly based on models trained for a specific task. Training such models or adapting them to a new condition is costly due to the need for (manually) labeled data. The emergence of vision foundation models, especially Segment Anything, offers a path to universal segmentation for medical images, overcoming these issues. Here, we study how to improve Segment Anything for medical images by comparing different finetuning strategies on a large and diverse dataset. We evaluate the finetuned models on a wide range of interactive and (automatic) semantic segmentation tasks. We find that the performance can be clearly improved for interactive segmentation. However, semantic segmentation does not benefit from pretraining on medical images. Our best model, MedicoSAM, is publicly available at this https URL. We show that it is compatible with existing tools for data annotation and believe that it will be of great practical value.

Paper number 65:
Title: MTLoc: A Confidence-Based Source-Free Domain Adaptation Approach For Indoor Localization
Authors: Negar Mehregan, Berk Bozkurt, Eric Granger, Mohammadjavad Hajikhani, Mohammadhadi Shateri
Abstract: Various deep learning models have been developed for indoor localization based on radio-frequency identification (RFID) tags. However, they often require adaptation to ensure accurate tracking in new target operational domains. To address this challenge, unsupervised domain adaptation (UDA) methods have been proposed to align pre-trained models with data from target environments. However, they rely on large annotated datasets from the initial domain (source). Source data access is limited by privacy, storage, computational, and transfer constraints. Although many source-free domain adaptation (SFDA) methods address these constraints in classification, applying them to regression models for localization remains challenging. Indeed, target datasets for indoor localization are typically small, with few features and samples, and are noisy. Adapting regression models requires high-confidence target pseudo-annotation to avoid over-training. In this paper, a specialized mean-teacher method called MTLoc is proposed for SFDA. MTLoc updates the student network using noisy data and teacher-generated pseudo-labels. The teacher network maintains stability through exponential moving averages. To further ensure robustness, the teacher's pseudo-labels are refined using k-nearest neighbor correction. MTLoc allows for self-supervised learning on target data, facilitating effective adaptation to dynamic and noisy indoor environments. Validated using real-world data from our experimental setup with INLAN Inc., our results show that MTLoc achieves high localization accuracy under challenging conditions, significantly reducing localization error compared to baselines, including the state-of-the-art adversarial UDA approach with access to source data.

Paper number 66:
Title: Observation Compression in Rate-Limited Closed-Loop Distributed ISAC Systems: From Signal Reconstruction to Control
Authors: Guangjin Pan, Zhixing Li, Ayça Özçelikkale, Christian Häger, Musa Furkan Keskin, Henk Wymeersch
Abstract: In closed-loop distributed multi-sensor integrated sensing and communication (ISAC) systems, performance often hinges on transmitting high-dimensional sensor observations over rate-limited networks. In this paper, we first present a general framework for rate-limited closed-loop distributed ISAC systems, and then propose an autoencoder-based observation compression method to overcome the constraints imposed by limited transmission capacity. Building on this framework, we conduct a case study using a closed-loop linear quadratic regulator (LQR) system to analyze how the interplay among observation, compression, and state dimensions affects reconstruction accuracy, state estimation error, and control performance. In multi-sensor scenarios, our results further show that optimal resource allocation initially prioritizes low-noise sensors until the compression becomes lossless, after which resources are reallocated to high-noise sensors.

Paper number 67:
Title: Improving Action Smoothness for a Cascaded Online Learning Flight Control System
Authors: Yifei Li, Erik-jan van Kampen
Abstract: This paper aims to improve the action smoothness of a cascaded online learning flight control system. Although the cascaded structure is widely used in flight control design, its stability can be compromised by oscillatory control actions, which poses challenges for practical engineering applications. To address this issue, we introduce an online temporal smoothness technique and a low-pass filter to reduce the amplitude and frequency of the control actions. Fast Fourier Transform (FFT) is used to analyze policy performance in the frequency domain. Simulation results demonstrate the improvements achieved by the two proposed techniques.

Paper number 68:
Title: OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion
Authors: Yizhuo Wu, Ang Li, Chang Gao
Abstract: Neural network (NN)-based Digital Predistortion (DPD) has demonstrated superior performance in improving signal quality in wideband radio frequency (RF) power amplifiers (PAs) employing complex modulation. However, NN DPDs usually rely on a large number of parameters for effective linearization and can significantly contribute to the energy consumption of the digital back-end in RF systems. This paper presents OpenDPDv2, an open-source, end-to-end framework that unifies PA modeling, NN-DPD learning, and deployment-oriented model optimization to reduce inference energy while preserving linearization performance. OpenDPDv2 introduces TRes-DeltaGRU, a delta-RNN DPD architecture with a lightweight temporal residual path that improves robustness under aggressive temporal sparsity, and it supports joint optimization of temporal sparsity and fixed-point quantization. On a 3.5 GHz GaN Doherty PA driven by a TM3.1a 200 MHz 256-QAM OFDM signal, the FP32 TRes-DeltaGRU model achieves ACPR of -59.9 dBc and EVM of -42.1 dB. By combining quantization with dynamic temporal sparsity, the model reduces inference energy by 4.5x while maintaining -51.8 dBc ACPR and -35.2 dB EVM at 56% temporal sparsity. Code, datasets, and documentation are publicly available at this https URL.

Paper number 69:
Title: Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering
Authors: Daniele Pugliese, Giovanni Iacovelli, Alessio Fascista, Domenico Striccoli, Oleksandr Romanov, Luigi Alfredo Grieco, Gennaro Boggia
Abstract: The integration of Optical Intelligent Reflective Surfaces (OIRSs) into Visible Light Communication (VLC) systems is gaining momentum as a valid alternative to RF technologies, harnessing the existing lighting infrastructures and the vast unlicensed optical spectrum to enable higher spectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and enhanced positioning capabilities. This paper investigates the problem of localizing a low-cost Photo Detector (PD) in a VLC-based indoor environment consisting of only a single Light Emitting Diode (LED) as an active anchor, and multiple spatially distributed single-element OIRSs. We formulate the problem within an indirect, computationally efficient localization framework: first, the optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight (NLoS) distances are derived, using a suitable OIRS activation strategy to prevent interferences. To overcome the grid-based optimization required by the ML NLoS estimator, we devise a novel algorithm based on an unstructured noise variance transformation, which admits a closed-form solution. The set of estimated LoS/NLoS distances are then used within a low-complexity localization algorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose weights are set according to the inverse of the Cramér-Rao Lower Bound (CRLB), with an adaptive beam steering strategy that allows the OIRSs network to dynamically align with the PD, without any prior knowledge of its position. Accordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD position estimation. Simulation results demonstrate the effectiveness of our approach in terms of localization accuracy, robustness against OIRSs misalignment conditions, and low number of iterations required to attain the theoretical bounds.

Paper number 70:
Title: Modeling and Analysis of Land-to-Ship Maritime Wireless Channels at 5.8 GHz
Authors: Shu Sun, Yulu Guo, Meixia Tao, Wei Feng, Jun Chen, Ruifeng Gao, Ye Li, Jue Wang, Theodore S. Rappaport
Abstract: Maritime channel modeling is crucial for designing robust nearshore communication systems, yet reliable models that account for the dynamic marine environment with varying sea waves, wind conditions, and vessel motions remain scarce. This article investigates land-to-ship maritime wireless channel characteristics at 5.8 GHz based upon an extensive measurement campaign, with concurrent hydrological and meteorological information collection. First, a novel large-scale path loss model with physical foundation and high accuracy is proposed for dynamic marine environments. Then, we introduce the concept of sea-wave-induced fixed-point (SWIFT) fading, a peculiar phenomenon in maritime scenarios that captures the impact of sea surface fluctuations on received power. An enhanced two-ray model incorporating vessel rotational motion is propounded to simulate the SWIFT fading, showing good alignment with measured data, particularly for modest antenna movements. Next, the small-scale fading is studied by leveraging a variety of models including the two-wave with diffuse power (TWDP) and asymmetric Laplace distributions, with the latter performing well in most cases, while TWDP better captures bimodal fading in rough seas. Furthermore, maritime channel sparsity is examined via the Gini index and Rician $K$ factor, and temporal dispersion is characterized. The resulting channel models and parameter characteristics offer valuable insights for maritime wireless system design and deployment.

Paper number 71:
Title: Missing Money and Market-Based Adequacy in Deeply Decarbonized Power Systems with Long-Duration Energy Storage
Authors: Adam Suski, Elina Spyrou, Richard Green
Abstract: The ability of deeply decarbonised power systems to ensure adequacy may increasingly depend on long-duration energy storage (LDES). A central challenge is whether capacity markets (CMs), originally designed around thermal generation, can provide efficient investment signals when storage becomes a central participant. While recent studies have advanced methods for accrediting variable renewables and short-duration storage, the effectiveness of these methods in CMs with substantial LDES penetration remains largely unexplored. To address this gap, we extend a two-stage stochastic equilibrium investment model by endogenising continuous, duration-based capacity accreditation for storage and apply it to a Great Britain-based case using 40 years of weather-driven demand and renewable profiles under varying emission limits. Results show that well-calibrated CMs can sustain near-efficient investment and mitigate revenue volatility, but their effectiveness diminishes in deeply decarbonized systems, underscoring both their potential and the regulatory challenges of supporting large-scale LDES.

Paper number 72:
Title: EDMD-Based Robust Observer Synthesis for Nonlinear Systems
Authors: Xiuzhen Ye, Wentao Tang
Abstract: This paper presents a data-driven Koopman operator-based approach for designing robust state observers for nonlinear systems. Based on a finite-dimensional surrogate of the Koopman generator, identified via an extended dynamic mode decomposition (EDMD) procedure, a tractable formulation of the observer design problem is enabled on the data-driven model with conic uncertainties. The resulting problem is cast as a semidefinite program (SDP) with linear matrix inequalities (LMIs), guaranteeing exponential convergence of the observer with a predetermined rate in a probabilistic sense. The approach bridges the gap between statistical error tolerance and observer convergence certification, and enables an explicit use of linear systems theory for nonlinear observation in a data-driven framework. Numerical studies demonstrate the effectiveness and flexibility of the proposed method.

Paper number 73:
Title: Performance Bounds of Near-Field Velocity Estimation with Modular Linear Array
Authors: Khalid A. Alshumayri, Mudassir Masood, Ali. A. Nasir (Electrical Engineering Department and Interdisciplinary Research Center for Communication Systems and Sensing (IRC-CSS), King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia)
Abstract: Velocity estimation is a cornerstone of the recently introduced near-field predictive beamforming. This paper derives the Cramer-Rao bounds (CRBs) for joint radial and transverse velocity estimation within a predictive beamforming framework employing a modular linear array (MLA). We obtain closed-form expressions that characterize the interplay between array geometry and estimation accuracy, showing that increasing the inter-module separation enlarges the effective aperture and reduces the transverse-velocity CRB, while the radial-velocity CRB remains largely insensitive to this separation. Furthermore, we show that an MLA can achieve the same accuracy as a collocated ULA with fewer antennas and quantify the relation between inter-module spacing and antenna savings. The derived expressions are validated through simulations by comparing them with the mean-squared error (MSE) of the maximum likelihood estimator (MLE) reported in the literature.

Paper number 74:
Title: Pipeline Stage Resolved Timing Characterization of FPGA and ASIC Implementations of a RISC V Processor
Authors: Mostafa Darvishi
Abstract: This paper presents a pipeline stage resolved timing characterization of a 32-bit RISC V processor implemented on a 20 nm FPGA and a 7 nm FinFET ASIC platform. A unified analysis framework is introduced that decomposes timing paths into logic, routing, and clocking components and maps them to well-defined pipeline stage transitions. This approach enables systematic comparison of timing behavior across heterogeneous implementation technologies at a microarchitectural level. Using static timing analysis and statistical characterization, the study shows that although both implementations exhibit dominant critical paths in the EX to MEM pipeline transition, their underlying timing mechanisms differ fundamentally. FPGA timing is dominated by routing parasitics and placement dependent variability, resulting in wide slack distributions and sensitivity to routing topology. In contrast, ASIC timing is governed primarily by combinational logic depth and predictable parametric variation across process, voltage, and temperature corners, yielding narrow and stable timing distributions. The results provide quantitative insight into the structural origins of timing divergence between programmable and custom fabrics and demonstrate the effectiveness of pipeline stage resolved analysis for identifying platform specific bottlenecks. Based on these findings, the paper derives design implications for achieving predictable timing closure in processor architectures targeting both FPGA and ASIC implementations.

Paper number 75:
Title: Simultaneous and Proportional Finger Motion Decoding Using Spatial Features from High-Density Surface Electromyography
Authors: Ricardo Gonçalves Molinari, Leonardo Abdala Elias
Abstract: Restoring natural and intuitive hand function requires simultaneous and proportional control (SPC) of multiple degrees of freedom (DoFs). This study systematically evaluated the multichannel linear descriptors-based block field method (MLD-BFM) for continuous decoding of five finger-joint DoFs by leveraging the rich spatial information of high-density surface electromyography (HD sEMG). Twenty-one healthy participants performed dynamic sinusoidal finger movements while HD sEMG signals were recorded from the extensor digitorum communis (EDC) and flexor digitorum superficialis (FDS) muscles. MLD-BFM extracted region-specific spatial features, including effective field strength ($\Sigma$), field-strength variation rate ($\Phi$), and spatial complexity ($\Omega$). Model performance was optimized (block size: $2 \times 2$; window: 0.15 s) and compared with conventional time-domain features and dimensionality reduction approaches when applied to multi-output regression models. MLD-BFM consistently achieved the highest $\mathrm{R}^2_{\mathrm{vw}}$ values across all models. The multilayer perceptron (MLP) combined with MLD-BFM yielded the best performance ($\mathrm{R}^2_{\mathrm{vw}} = 86.68\% \pm 0.33$). Time-domain features also showed strong predictive capability and were statistically comparable to MLD-BFM in some models, whereas dimensionality reduction techniques exhibited lower accuracy. Decoding accuracy was higher for the middle and ring fingers than for the thumb. Overall, MLD-BFM improved continuous finger movement decoding accuracy, underscoring the importance of taking advantage of the spatial richness of HD sEMG. These findings suggest that spatially structured features enhance SPC and provide practical guidance for designing robust, real-time, and responsive myoelectric interfaces.

Paper number 76:
Title: A Fair, Flexible, Zero-Waste Digital Electricity Market: A First-Principles Approach Combining Automatic Market Making, Holarchic Architectures and Shapley Theory
Authors: Shaun Sweeney, Robert Shorten, Mark O'Malley
Abstract: This thesis presents a fundamental rethink of electricity market design at the wholesale and balancing layers. Rather than treating markets as static spot clearing mechanisms, it reframes them as a continuously online, event driven dynamical control system: a two sided marketplace operating directly on grid physics. Existing energy only, capacity augmented, and zonal market designs are shown to admit no shock robust Nash equilibrium under realistic uncertainty, instead relying on price caps, uplift, and regulatory intervention to preserve solvency and security. In response, the thesis develops a holarchic Automatic Market Maker (AMM) in which prices are bounded, exogenous control signals derived from physical tightness rather than emergent equilibrium outcomes. The AMM generalises nodal and zonal pricing through nested scarcity layers, from node to cluster to zone to region to system, such that participant facing prices inherit from the tightest binding constraint. Nodal and zonal pricing therefore emerge as special cases of a unified scarcity propagation rule. Beyond pricing, the AMM functions as a scarcity aware control system and a digitally enforceable rulebook for fair access and proportional allocation under shortage. Fuel costs are recovered through pay as bid energy dispatch consistent with merit order, while non fuel operating and capital costs are allocated according to adequacy, flexibility, and locational contribution. Large scale simulations demonstrate bounded input bounded output stability, controllable procurement costs, zero structural waste, and improved distributional outcomes. The architecture is climate aligned and policy configurable, but requires a managed transition and new operational tools for system operators and market participants.

Paper number 77:
Title: Single-channel speech enhancement by using psychoacoustical model inspired fusion framework
Authors: Suman Samui
Abstract: When the parameters of Bayesian Short-time Spectral Amplitude (STSA) estimator for speech enhancement are selected based on the characteristics of the human auditory system, the gain function of the estimator becomes more flexible. Although this type of estimator in acoustic domain is quite effective in reducing the back-ground noise at high frequencies, it produces more speech distortions, which make the high-frequency contents of the speech such as friciatives less perceptible in heavy noise conditions, resulting in intelligibility reduction. On the other hand, the speech enhancement scheme, which exploits the psychoacoustic evidence of frequency selectivity in the modulation domain, is found to be able to increase the intelligibility of noisy speech by a substantial amount, but also suffers from the temporal slurring problem due to its essential design constraint. In order to achieve the joint improvements in both the perceived speech quality and intelligibility, we proposed and investigated a fusion framework by combining the merits of acoustic and modulation domain approaches while avoiding their respective weaknesses. Objective measure evaluation shows that the proposed speech enhancement fusion framework can provide consistent improvements in the perceived speech quality and intelligibility across different SNR levels in various noise conditions, while compared to the other baseline techniques.

Paper number 78:
Title: Steering Language Model to Stable Speech Emotion Recognition via Contextual Perception and Chain of Thought
Authors: Zhixian Zhao, Xinfa Zhu, Xinsheng Wang, Shuiyuan Wang, Xuelong Geng, Wenjie Tian, Lei Xie
Abstract: Large-scale audio language models (ALMs), such as Qwen2-Audio, are capable of comprehending diverse audio signal, performing audio analysis and generating textual responses. However, in speech emotion recognition (SER), ALMs often suffer from hallucinations, resulting in misclassifications or irrelevant outputs. To address these challenges, we propose C$^2$SER, a novel ALM designed to enhance the stability and accuracy of SER through Contextual perception and Chain of Thought (CoT). C$^2$SER integrates the Whisper encoder for semantic perception and Emotion2Vec-S for acoustic perception, where Emotion2Vec-S extends Emotion2Vec with semi-supervised learning to enhance emotional discrimination. Additionally, C$^2$SER employs a CoT approach, processing SER in a step-by-step manner while leveraging speech content and speaking styles to improve recognition. To further enhance stability, C$^2$SER introduces self-distillation from explicit CoT to implicit CoT, mitigating error accumulation and boosting recognition accuracy. Extensive experiments show that C$^2$SER outperforms existing popular ALMs, such as Qwen2-Audio and SECap, delivering more stable and precise emotion recognition. We release the training code, checkpoints, and test sets to facilitate further research.

Paper number 79:
Title: Safety with Agency: Human-Centered Safety Filter with Application to AI-Assisted Motorsports
Authors: Donggeon David Oh, Justin Lidard, Haimin Hu, Himani Sinhmar, Elle Lazarski, Deepak Gopinath, Emily S. Sumner, Jonathan A. DeCastro, Guy Rosman, Naomi Ehrich Leonard, Jaime Fernández Fisac
Abstract: We propose a human-centered safety filter (HCSF) for shared autonomy that significantly enhances system safety without compromising human agency. Our HCSF is built on a neural safety value function, which we first learn scalably through black-box interactions and then use at deployment to enforce a novel state-action control barrier function (Q-CBF) safety constraint. Since this Q-CBF safety filter does not require any knowledge of the system dynamics for both synthesis and runtime safety monitoring and intervention, our method applies readily to complex, black-box shared autonomy systems. Notably, our HCSF's CBF-based interventions modify the human's actions minimally and smoothly, avoiding the abrupt, last-moment corrections delivered by many conventional safety filters. We validate our approach in a comprehensive in-person user study using Assetto Corsa-a high-fidelity car racing simulator with black-box dynamics-to assess robustness in "driving on the edge" scenarios. We compare both trajectory data and drivers' perceptions of our HCSF assistance against unassisted driving and a conventional safety filter. Experimental results show that 1) compared to having no assistance, our HCSF improves both safety and user satisfaction without compromising human agency or comfort, and 2) relative to a conventional safety filter, our proposed HCSF boosts human agency, comfort, and satisfaction while maintaining robustness.

Paper number 80:
Title: Large Language Model-Based Intelligent Antenna Design System
Authors: Tao Wu, Kexue Fu, Qiang Hua, Xinxin Liu, Bo Liu
Abstract: Antenna simulation typically involves modeling and optimization, which are time-consuming and labor-intensive, slowing down antenna analysis and design. This paper presents a prototype of a large language model (LLM)-based antenna design system (LADS) to assist in antenna simulation. LADS generates antenna models with textual descriptions and images extracted from academic papers, patents, and technical reports (either one or multiple), and it interacts with engineers to iteratively refine the designs. After that, LADS configures and runs an optimizer to meet the design specifications. The effectiveness of LADS is demonstrated by a monopole slotted antenna generated from images and descriptions from the literature. To improve gain stability across the 3.1-10.6 GHz ultra-wide band, LADS modifies the cross-slot into an H-slot and changes substrate material, followed by parameter optimization. As a result, the gain variation is reduced while maintaining the same gain level. The LLM-enabled antenna modeling (LEAM) is available at: this https URL.

Paper number 81:
Title: Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach
Authors: Jingwang Li, Vincent Lau
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms to solve this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, under additional assumptions, we establish linear convergence rates and derive significantly lower communication and computational complexity bounds than those of existing algorithms. Several numerical experiments validate our theoretical analysis and demonstrate the practical superiority of the proposed algorithms.

Paper number 82:
Title: Sparse Autoencoders Make Audio Foundation Models more Explainable
Authors: Théo Mariotte, Martin Lebourdais, Antonio Almudévar, Marie Tahon, Alfonso Ortega, Nicolas Dugué
Abstract: Audio pretrained models are widely employed to solve various tasks in speech processing, sound event detection, or music information retrieval. However, the representations learned by these models are unclear, and their analysis mainly restricts to linear probing of the hidden representations. In this work, we explore the use of Sparse Autoencoders (SAEs) to analyze the hidden representations of pretrained models, focusing on a case study in singing technique classification. We first demonstrate that SAEs retain both information about the original representations and class labels, enabling their internal structure to provide insights into self-supervised learning systems. Furthermore, we show that SAEs enhance the disentanglement of vocal attributes, establishing them as an effective tool for identifying the underlying factors encoded in the representations.

Paper number 83:
Title: Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation
Authors: Shimaa Elbana, Ahmad Kamal, Shahd Ahmed Ali, Ahmad Al-Kabbany
Abstract: The increasing size and complexity of medical imaging datasets, particularly in 3D formats, present significant barriers to collaborative research and transferability. This study investigates whether the ZFP compression technique can mitigate these challenges without compromising the performance of automated cerebrovascular segmentation, a critical first step in intracranial aneurysm detection. We apply ZFP in both its error tolerance and fixed-rate modes to a large scale, and one of the most recent, datasets in the literature, 3D medical dataset containing ground-truth vascular segmentations. The segmentation quality on the compressed volumes is rigorously compared to the uncompressed baseline (Dice approximately equals 0.8774). Our findings reveal that ZFP can achieve substantial data reduction--up to a 22.89:1 ratio in error tolerance mode--while maintaining a high degree of fidelity, with the mean Dice coefficient remaining high at 0.87656. These results demonstrate that ZFP is a viable and powerful tool for enabling more efficient and accessible research on large-scale medical datasets, fostering broader collaboration across the community.

Paper number 84:
Title: Few-Shot Multimodal Medical Imaging: A Theoretical Framework
Authors: Md Talha Mohsin, Ismail Abdulrashid
Abstract: Medical imaging often operates under limited labeled data, especially in rare disease and low resource clinical environments. Existing multimodal and meta learning approaches improve performance in these settings but lack a theoretical explanation of why or when they succeed. This paper presents a unified theoretical framework for few shot multimodal medical imaging that jointly characterizes sample complexity, uncertainty quantification, and interpretability. Using PAC learning, VC theory, and PAC Bayesian analysis, we derive bounds that describe the minimum number of labeled samples required for reliable performance and show how complementary modalities reduce effective capacity through an information gain term. We further introduce a formal metric for explanation stability, proving that explanation variance decreases at an inverse n rate. A sequential Bayesian interpretation of Chain of Thought reasoning is also developed to show stepwise posterior contraction. To illustrate these ideas, we implement a controlled multimodal dataset and evaluate an additive CNN MLP fusion model under few shot regimes, confirming predicted multimodal gains, modality interference at larger sample sizes, and shrinking predictive uncertainty. Together, the framework provides a principled foundation for designing data efficient, uncertainty aware, and interpretable diagnostic models in low resource settings.

Paper number 85:
Title: AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Soccer Substitutions
Authors: Pedro Passos
Abstract: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.

Paper number 86:
Title: Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges
Authors: Yuxing Wang, Zhiyu Chen, Tiantian Zhang, Qiyue Yin, Yongzhe Chang, Zhiheng Li, Liang Wang, Xueqian Wang
Abstract: Brain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at this https URL.
    