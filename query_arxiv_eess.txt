
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks
Authors: Danny Scott, William LaForest, Hritom Das, Ioannis Polykretis, Catherine D. Schuman, Charles Rizzo, James Plank, Sai Swaminathan
Abstract: The deployment of dense, low-cost sensors is critical for realizing ubiquitous smart environments. However, existing sensing solutions struggle with the energy, scalability, and reliability trade-offs imposed by battery maintenance, wireless transmission overhead, and data processing complexity. In this work, we present Vibe2Spike, a novel battery-free, wireless sensing framework that enables vibration-based activity recognition using visible light communication (VLC) and spiking neural networks (SNNs). Our system uses ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and an LED, which harvest vibration energy and emit sparse visible light spikes without requiring batteries or RF radios. These optical spikes are captured by event cameras and classified using optimized SNN models evolved via the EONS framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\% average classification fitness while analyzing the latency-accuracy trade-offs of different temporal binning strategies. Vibe2Spike demonstrates a scalable, and energy-efficient approach for enabling intelligent environments in a batteryless manner.

Paper number 2:
Title: Data-driven RF Tomography via Cross-modal Sensing and Continual Learning
Authors: Yang Zhao, Tao Wang, Said Elhadi
Abstract: Data-driven radio frequency (RF) tomography has demonstrated significant potential for underground target detection, due to the penetrative nature of RF signals through soil. However, it is still challenging to achieve accurate and robust performance in dynamic environments. In this work, we propose a data-driven radio frequency tomography (DRIFT) framework with the following key components to reconstruct cross section images of underground root tubers, even with significant changes in RF signals. First, we design a cross-modal sensing system with RF and visual sensors, and propose to train an RF tomography deep neural network (DNN) model following the cross-modal learning approach. Then we propose to apply continual learning to automatically update the DNN model, once environment changes are detected in a dynamic environment. Experimental results show that our approach achieves an average equivalent diameter error of 2.29 cm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and dataset are publicly available on this https URL.

Paper number 3:
Title: Inductive transfer learning from regression to classification in ECG analysis
Authors: Ridma Jayasundara, Ishan Fernando, Adeepa Fernando, Roshan Ragel, Vajira Thambawita, Isuru Nawinne
Abstract: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, accounting for over 30% of global deaths according to the World Health Organization (WHO). Importantly, one-third of these deaths are preventable with timely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive method for recording the electrical activity of the heart, is crucial for diagnosing CVDs. However, privacy concerns surrounding the use of patient ECG data in research have spurred interest in synthetic data, which preserves the statistical properties of real data without compromising patient confidentiality. This study explores the potential of synthetic ECG data for training deep learning models from regression to classification tasks and evaluates the feasibility of transfer learning to enhance classification performance on real ECG data. We experimented with popular deep learning models to predict four key cardiac parameters, namely, Heart Rate (HR), PR interval, QT interval, and QRS complex-using separate regression models. Subsequently, we leveraged these regression models for transfer learning to perform 5-class ECG signal classification. Our experiments systematically investigate whether transfer learning from regression to classification is viable, enabling better utilization of diverse open-access and synthetic ECG datasets. Our findings demonstrate that transfer learning from regression to classification improves classification performance, highlighting its potential to maximize the utility of available data and advance deep learning applications in this domain.

Paper number 4:
Title: Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding
Authors: Yuanhao Li, Badong Chen, Wenjun Bai, Yasuharu Koike, Okito Yamashita
Abstract: Objective: Sparse Bayesian learning provides an effective scheme to solve the high-dimensional problem in brain signal decoding. However, traditional assumptions regarding data distributions such as Gaussian and binomial are potentially inadequate to characterize the noisy signals of brain activity. Hence, this study aims to propose a robust sparse Bayesian learning framework to address noisy highdimensional brain activity decoding. Methods: Motivated by the commendable robustness of the minimum error entropy (MEE) criterion for handling complex data distributions, we proposed an MEE-based likelihood function to facilitate the accurate inference of sparse Bayesian learning in analyzing noisy brain datasets. Results: Our proposed approach was evaluated using two high-dimensional brain decoding tasks in regression and classification contexts, respectively. The experimental results showed that, our approach can realize superior decoding metrics and physiological patterns than the conventional and state-of-the-art methods. Conclusion: Utilizing the proposed MEE-based likelihood model, sparse Bayesian learning is empowered to simultaneously address the challenges of noise and high dimensionality in the brain decoding task. Significance: This work provides a powerful tool to realize robust brain decoding, advancing biomedical engineering applications such as brain-computer interface.

Paper number 5:
Title: CECGSR: Circular ECG Super-Resolution
Authors: Honggui Li, Zhengyang Zhang, Dingtai Li, Sinan Chen, Nahid Md Lokman Hossain, Xinfeng Xu, Yuting Feng, Hantao Lu, Yinlu Qin, Ruobing Wang, Maria Trocan, Dimitri Galayko, Amara Amara, Mohamad Sawan
Abstract: The electrocardiogram (ECG) plays a crucial role in the diagnosis and treatment of various cardiac diseases. ECG signals suffer from low-resolution (LR) due to the use of convenient acquisition devices, as well as internal and external noises and artifacts. Classical ECG super-resolution (ECGSR) methods adopt an open-loop architecture that converts LR ECG signals to super-resolution (SR) ones. According to the theory of automatic control, a closed-loop framework exhibits superior dynamic and static performance compared with its open-loop counterpart. This paper proposes a closed-loop approach, termed circular ECGSR (CECGSR), which models the degradation process from SR ECG signals to LR ones. The negative feedback mechanism of the closed-loop system is based on the differences between the LR ECG signals. A mathematical loop equation is constructed to characterize the closed-loop infrastructure. The Taylor series expansion is employed to demonstrate the near-zero steady-state error of the proposed method. A Plug-and-Play strategy is considered to establish the SR unit of the proposed architecture, leveraging any existing advanced open-loop ECGSR methods. Simulation experiments on both noiseless and noisy subsets of the PTB-XL datasets demonstrate that the proposed CECGSR outperforms state-of-the-art open-loop ECGSR algorithms in the reconstruction performance of ECG signals.

Paper number 6:
Title: Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation
Authors: Guangli Li, Canbiao Wu, Zhen Liang
Abstract: Affective computing is a rapidly developing interdisciplinary research direction in the field of brain-computer interface. In recent years, the introduction of deep learning technology has greatly promoted the development of the field of emotion recognition. However, due to physiological differences between subjects, as well as the variations in experimental environments and equipment, cross-corpus emotion recognition faces serious challenges, especially for samples near the decision boundary. To solve the above problems, we propose an optimization method based on domain adversarial transfer learning to fine-grained alignment of affective features, named Maximum classifier discrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a dual adversarial classifier (Ada classifier and RMS classifier), and apply a three-stage adversarial training to maximize classification discrepancy and minimize feature distribution to align controversy samples near the decision boundary. In the process of domain adversarial training, the two classifiers also maintain an adversarial relationship, ultimately enabling precise cross-corpus feature alignment. In addition, the introduction of pairwise learning transforms the classification problem of samples into a similarity problem between samples, alleviating the influence of label noise. We conducted systematic experimental evaluation of the model using publicly available SEED, SEED-IV and SEED-V databases. The results show that the McdPL model is superior to other baseline models in the cross-corpus emotion recognition task, and the average accuracy improvements of 4.76\% and 3.97\%, respectively. Our work provides a promising solution for emotion recognition cross-corpus. The source code is available at this https URL.

Paper number 7:
Title: Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study
Authors: Zahra Mohammadi, Parnian Fazel, Siamak Mohammadi
Abstract: Sleep stage classification is crucial for diagnosing and managing disorders such as sleep apnea and insomnia. Conventional clinical methods like polysomnography are costly and impractical for long-term home use. We present an energy-efficient pipeline that detects four sleep stages (wake, REM, light, and deep) from a single-lead ECG. Two windowing strategies are introduced: (1) a 5-minute window with 30-second steps for machine-learning models that use handcrafted features, and (2) a 30-second window with 10-second steps for deep-learning models, enabling near-real-time 10-second resolution. Lightweight networks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score but still draw significant energy. We therefore design SleepLiteCNN, a custom model that achieves 89 percent accuracy and 89 percent F1-score while lowering energy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit quantization preserves accuracy and further reduces power, and FPGA deployment confirms low resource usage. The proposed system offers a practical solution for continuous, wearable ECG-based sleep monitoring.

Paper number 8:
Title: Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion
Authors: Timothy Oladunni, Ehimen Aneni
Abstract: The limitations of unimodal deep learning models, particularly their tendency to overfit and limited generalizability, have renewed interest in multimodal fusion strategies. Multimodal deep neural networks (MDNN) have the capability of integrating diverse data domains and offer a promising solution for robust and accurate predictions. However, the optimal fusion strategy, intermediate fusion (feature-level) versus late fusion (decision-level) remains insufficiently examined, especially in high-stakes clinical contexts such as ECG-based cardiovascular disease (CVD) classification. This study investigates the comparative effectiveness of intermediate and late fusion strategies using ECG signals across three domains: time, frequency, and time-frequency. A series of experiments were conducted to identify the highest-performing fusion architecture. Results demonstrate that intermediate fusion consistently outperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's d > 0.8 relative to standalone models and d = 0.40 compared to late fusion. Interpretability analyses using saliency maps reveal that both models align with the discretized ECG signals. Statistical dependency between the discretized ECG signals and corresponding saliency maps for each class was confirmed using Mutual Information (MI). The proposed ECG domain-based multimodal model offers superior predictive capability and enhanced explainability, crucial attributes in medical AI applications, surpassing state-of-the-art models.

Paper number 9:
Title: Neural Gaussian Radio Fields for Channel Estimation
Authors: Muhammad Umer, Muhammad Ahmed Mohsin, Ahsan Bilal, John M. Cioffi
Abstract: Accurate channel state information (CSI) remains the most critical bottleneck in modern wireless networks, with pilot overhead consuming up to 11-21% of transmission bandwidth, increasing latency by 20-40% in massive MIMO systems, and reducing potential spectral efficiency by over 53%. Traditional estimation techniques fundamentally fail under mobility, with feedback delays as small as 4 ms causing 50% throughput degradation at even modest speeds (30 km/h). We present neural Gaussian radio fields (nGRF), a novel framework that leverages explicit 3D Gaussian primitives to synthesize complex channel matrices accurately and efficiently. Unlike NeRF-based approaches that rely on slow implicit representations or existing Gaussian splatting methods that use non-physical 2D projections, nGRF performs direct 3D electromagnetic field aggregation, with each Gaussian acting as a localized radio modulator. nGRF demonstrates superior performance across diverse environments: in indoor scenarios, it achieves a 10.9$\times$ higher prediction SNR than state of the art methods while reducing inference latency from 242 ms to just 1.1 ms (a 220$\times$ speedup). For large-scale outdoor environments, where existing approaches fail to function, nGRF achieves an SNR of 26.2 dB. Moreover, nGRF requires only 0.011 measurements per cubic foot compared to 0.2-178.1 for existing methods, thereby reducing data collection burden by 18$\times$. Training time is similarly reduced from hours to minutes (a 180$\times$ reduction), enabling rapid adaptation to dynamic environments. The code and datasets are available at: this https URL

Paper number 10:
Title: Direction of Arrival Estimation: A Tutorial Survey of Classical and Modern Methods
Authors: Amgad A. Salama
Abstract: Direction of arrival (DOA) estimation is a fundamental problem in array signal processing with applications spanning radar, sonar, wireless communications, and acoustic signal processing. This tutorial survey provides a comprehensive introduction to classical and modern DOA estimation methods, specifically designed for students and researchers new to the field. We focus on narrowband signal processing using uniform linear arrays, presenting step-by-step mathematical derivations with geometric intuition. The survey covers classical beamforming methods, subspace-based techniques (MUSIC, ESPRIT), maximum likelihood approaches, and sparse signal processing methods. Each method is accompanied by Python implementations available in an open-source repository, enabling reproducible research and hands-on learning. Through systematic performance comparisons across various scenarios, we provide practical guidelines for method selection and parameter tuning. This work aims to bridge the gap between theoretical foundations and practical implementation, making DOA estimation accessible to beginners while serving as a comprehensive reference for the field. See this https URL for detail implementation of the methods.

Paper number 11:
Title: Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study
Authors: Md Basit Azam, Sarangthem Ibotombi Singh
Abstract: Non-invasive glucose monitoring remains a critical challenge in the management of diabetes. HRV during sleep shows promise for glucose prediction however, age-related autonomic changes significantly confound traditional HRV analyses. We analyzed 43 subjects with multi-modal data including sleep-stage specific ECG, HRV features, and clinical measurements. A novel age-normalization technique was applied to the HRV features by, dividing the raw values by age-scaled factors. BayesianRidge regression with 5-fold cross-validation was employed for log-glucose prediction. Age-normalized HRV features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction, representing a 25.6% improvement over non-normalized features (R2 = 0.132). The top predictive features were hrv rem mean rr age normalized (r = 0.443, p = 0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed age-normalization as the critical component, with sleep-stage specific features providing additional predictive value. Age-normalized HRV features significantly enhance glucose prediction accuracy compared with traditional approaches. This sleep-aware methodology addresses fundamental limitations in autonomic function assessment and suggests a preliminary feasibility for non-invasive glucose monitoring applications. However, these results require validation in larger cohorts before clinical consideration.

Paper number 12:
Title: A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG
Authors: BG Tong
Abstract: Objective: This study proposes and preliminarily validates a novel "Functional-Energetic Topology Model" to uncover neurodynamic mechanisms of Non-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode brain network patterns from single-channel EEG in real-world this http URL: EEG data were collected over ~1 month from three adolescents with NSSI using a smartphone app and a portable Fp1 EEG headband during impulsive and non-impulsive states. A theory-driven GNN with seven functional nodes was built. Performance was evaluated via intra-subject (80/20 split) and leave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for this http URL: The model achieved high intra-subject accuracy (>85%) and significantly above-chance cross-subject performance (approximately73.7%). Explainability analysis revealed a key finding: during NSSI states, a critical feedback loop regulating somatic sensation exhibits dysfunction and directional reversal. Specifically, the brain loses its ability to self-correct via negative bodily feedback, and the regulatory mechanism enters an "ineffective idling" this http URL: This work demonstrates the feasibility of applying theory-guided GNNs to sparse, single-channel EEG for decoding complex mental states. The identified "feedback loop reversal" offers a novel, dynamic, and computable model of NSSI mechanisms, paving the way for objective biomarkers and next-generation Digital Therapeutics (DTx).

Paper number 13:
Title: Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling
Authors: Farnaz Kaboudvand, Maham Khalid, Nydia Assaf, Vardaan Sahgal, Jon P. Ruffley, Brian J. McDermott
Abstract: Corrosion poses a significant challenge to the performance of aluminum alloys, particularly in marine environments. This study investigates the application of machine learning (ML) algorithms to predict and optimize corrosion resistance, utilizing a comprehensive open-source dataset compiled from various sources. The dataset encompasses corrosion rate data and environmental conditions, preprocessed to standardize units and formats. We explored two different approaches, a direct approach, where the material's composition and environmental conditions were used as inputs to predict corrosion rates; and an inverse approach, where corrosion rate served as the input to identify suitable material compositions as output. We employed and compared three distinct ML methodologies for forward predictions: Random Forest regression, optimized via grid search; a feed-forward neural network, utilizing ReLU activation and Adam optimization; and Gaussian Process Regression (GPR), implemented with GPyTorch and employing various kernel functions. The Random Forest and neural network models provided predictive capabilities based on elemental compositions and environmental conditions. Notably, Gaussian Process Regression demonstrated superior performance, particularly with hybrid kernel functions. Log-transformed GPR further refined predictions. This study highlights the efficacy of ML, particularly GPR, in predicting corrosion rates and material properties.

Paper number 14:
Title: The Lost-K and Shorter-J Phenomenon in Non-Standard Ballistocardiography Data
Authors: Shuai Jiao, Jian Fang, Tianshu Zhou, Jinsong Li, Yanhong Liu, Ye Liu, Ming Ju
Abstract: Non-standard ballistocardiogram(BCG) data generally do not have prominent J peaks. This paper introduces two phenomena that reduce the prominence of Jpeaks: the shorter-J phenomenon and the lost-K phenomenon, both of which are commonly observed in non-standard BCG signals . This paper also proposes three signal transformation methods that effectively improve the lost-K and shorter-J phenomena. The methods were evaluated on a time-aligned ECG-BCG dataset with 40 subjects. The results show that based on the transformed signal, simple J-peak-based methods using only the detection of local maxima or minima show better performance in locating J-peaks and extracting BCG cycles, especially for non-standard BCG data.

Paper number 15:
Title: Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey
Authors: Jingpu Yang, Mingxuan Cui, Hang Zhang, Fengxian Ji, Zhengzhao Lai, Yufeng Wang
Abstract: Unmanned Aerial Vehicle communications are encountering increasingly severe multi-source interference challenges in dynamic adversarial environments, which impose higher demands on their reliability and resilience. To address these challenges, agent-based autonomous anti-jamming techniques have emerged as a crucial research direction. This paper presents a comprehensive survey that first formalizes the concept of intelligent anti-jamming agents for UAV communications and establishes a closed-loop decision-making framework centered on the "Perception-Decision-Action" (P-D-A) paradigm. Within this framework, we systematically review key technologies at each stage, with particular emphasis on employing game theory to model UAV-jammer interactions and integrating reinforcement learning-based intelligent algorithms to derive adaptive anti-jamming strategies. Furthermore, we discuss potential limitations of current approaches, identify critical engineering challenges, and outline promising future research directions, aiming to provide valuable references for developing more intelligent and robust anti-jamming communication systems for UAVs.

Paper number 16:
Title: Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception
Authors: Mathis Rezzouk, Fabrice Gagnon, Alyson Champagne, Mathieu Roy, Philippe Albouy, Michel-Pierre Coll, Cem Subakan
Abstract: EEG-based analysis of pain perception, enhanced by machine learning, reveals how the brain encodes pain by identifying neural patterns evoked by noxious stimulation. However, a major challenge that remains is the generalization of machine learning models across individuals, given the high cross-participant variability inherent to EEG signals and the limited focus on direct pain perception identification in current research. In this study, we systematically evaluate the performance of cross-participant generalization of a wide range of models, including traditional classifiers and deep neural classifiers for identifying the sensory modality of thermal pain and aversive auditory stimulation from EEG recordings. Using a novel dataset of EEG recordings from 108 participants, we benchmark model performance under both within- and cross-participant evaluation settings. Our findings show that traditional models suffered the largest drop from within- to cross-participant performance, while deep learning models proved more resilient, underscoring their potential for subject-invariant EEG decoding. Even though performance variability remained high, the strong results of the graph-based model highlight its potential to capture subject-invariant structure in EEG signals. On the other hand, we also share the preprocessed dataset used in this study, providing a standardized benchmark for evaluating future algorithms under the same generalization constraints.

Paper number 17:
Title: Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning
Authors: Eduardo Di Santi (1), Ruixiang Ci (2), Clément Lefebvre (1), Nenad Mijatovic (1), Michele Pugnaloni (1), Jonathan Brown (1), Victor Martín (1), Kenza Saiah (1) ((1) Digital and Integrated Systems, Alstom (2) Innovation and Smart Mobility, Alstom)
Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches train routes by diverting tracks through a switchblade. As with any critical safety equipment, a failure will halt operations leading to service disruptions; therefore, pre-emptive maintenance may avoid unnecessary interruptions by detecting anomalies before they become failures. Previous work relies on several inputs and crafting custom features by segmenting the signal. This not only adds additional requirements for data collection and processing, but it is also specific to the PM technology, the installed locations and operational conditions limiting scalability. Based on the available maintenance records, the main failure causes for PM are obstacles, friction, power source issues and misalignment. Those failures affect the energy consumption pattern of PMs, altering the usual (or healthy) shape of the power signal during the PM movement. In contrast to the current state-of-the-art, our method requires only one input. We apply a deep learning model to the power signal pattern to classify if the PM is nominal or associated with any failure type, achieving >99.99\% precision, <0.01\% false positives and negligible false negatives. Our methodology is generic and technology-agnostic, proven to be scalable on several electromechanical PM types deployed in both real-world and test bench environments. Finally, by using conformal prediction the maintainer gets a clear indication of the certainty of the system outputs, adding a confidence layer to operations and making the method compliant with the ISO-17359 standard.

Paper number 18:
Title: Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data
Authors: Francisco López, Eduardo Di Santi, Clément Lefebvre, Nenad Mijatovic, Michele Pugnaloni, Victor Martín, Kenza Saiah
Abstract: Track Circuits (TC) are the main signalling devices used to detect the presence of a train on a rail track. It has been used since the 19th century and nowadays there are many types depending on the technology. As a general classification, Track Circuits can be divided into 2 main groups, DC (Direct Current) and AC (Alternating Current) circuits. This work is focused on a particular AC track circuit, called "Smart Train Detection System" (STDS), designed with both high and low-frequency bands. This approach uses STDS current data applied to an SVM (support vector machine) classifier as a type of failure identifier. The main purpose of this work consists on determine automatically which is the component of the track that is failing to improve the maintenance action. Model was trained to classify 15 different failures that belong to 3 more general categories. The method was tested with field data from 10 different track circuits and validated by the STDS track circuit expert and maintainers. All use cases were correctly classified by the method.

Paper number 19:
Title: Operational machine learning for park-scale irrigation to support urban cooling
Authors: Mesut Koçyiğit, Bahman Javadi, Russell Thomson, Sebastian Pfautsch, Oliver Obst
Abstract: Urban parks can mitigate local heat, yet irrigation control is usually tuned for water savings rather than cooling. We report on SIMPaCT (Smart Irrigation Management for Parks and Cool Towns), a park-scale deployment that links per-zone soil-moisture forecasts to overnight irrigation set-points in support of urban cooling. SIMPaCT ingests data from 202 soil-moisture sensors, 50 temperature-relative humidity (TRH) nodes, and 13 weather stations, and trains a per-sensor k-nearest neighbours (kNN) predictor on short rolling windows (200-900h). A rule-first anomaly pipeline screens missing and stuck-at signals, with model-based checks (Isolation Forest and ARIMA). When a device fails, a mutual-information neighbourhood selects the most informative neighbour and a small multilayer perceptron supplies a "virtual sensor" until restoration. Across sensors the mean absolute error was 0.78%, comparable to more complex baselines; the upper-quartile error (P75) was lower for kNN than SARIMA (0.71% vs 0.93%). SIMPaCT runs daily and writes proposed set-points to the existing controller for operator review. This short communication reports an operational recipe for robust, cooling-oriented irrigation at city-park scale.

Paper number 20:
Title: Scaling Wideband Massive MIMO Radar via Beamspace Dimension Reduction
Authors: Oveys Delafrooz Noroozi, Jiyoon Han, Wei Tang, Zhengya Zhang, Upamanyu Madhow
Abstract: We present an architecture for scaling digital beamforming for wideband massive MIMO radar. Conventional spatial processing becomes computationally prohibitive as array size grows; for example, the computational complexity of MVDR beamforming scales as O(N^3) for an N-element array. In this paper, we show that energy concentration in beamspace provides the basis for drastic complexity reduction, with array scaling governed by the O(NlogN) complexity of the spatial FFT used for beamspace transformation. Specifically, we propose an architecture for windowed beamspace MVDR beamforming, parallelized across targets and subbands, and evaluate its efficacy for beamforming and interference suppression for government-supplied wideband radar data from the DARPA SOAP (Scalable On-Array Processing) program. We demonstrate that our approach achieves detection performance comparable to full-dimensional benchmarks while significantly reducing computational and training overhead, and provide insight into tradeoffs between beamspace window size and FFT resolution in balancing complexity, detection accuracy, and interference suppression.

Paper number 21:
Title: Digital Post-Distortion Architectures for Nonlinear Power Amplifiers: Volterra and Kernel Methods
Authors: Daniel Schäufele, Jochen Fink, Renato L. G. Cavalcante, Sławomir Stańczak
Abstract: In modern 5G user equipments (UEs), the power amplifier (PA) contributes significantly to power consumption during uplink transmissions, especially in cell-edge scenarios. While reducing power backoff can enhance PA efficiency, it introduces nonlinear distortions that degrade signal quality. Existing solutions, such as digital pre-distortion, require complex feedback mechanisms for optimal performance, leading to increased UE complexity and power consumption. Instead, in this study we explore digital post-distortion (DPoD) techniques, which compensate for these distortions at the base station, leveraging its superior computational resources. In this study, we conduct an comprehensive study concerning the challenges and advantages associated with applying DPoD in time-domain, frequency-domain, and DFT-s-domain. Our findings suggest that implementing DPoD in the time-domain, complemented by frequency-domain channel equalization, strikes a good balance between low computational complexity and efficient nonlinearity compensation. In addition, we demonstrate that memory has to be taken into account regardless of the memory of the PA. Subsequently, we show how to pose the complex-valued problem of nonlinearity compensation in a real Hilbert space, emphasizing the potential performance enhancements as a result. We then discuss the traditional Volterra series and show an equivalent kernel method that can reduce algorithmic complexity. Simulations validate the results of our analysis and show that our proposed algorithm can significantly improve performance compared to state-of-the-art algorithms.

Paper number 22:
Title: Matrix Control Barrier Functions
Authors: Pio Ong, Yicheng Xu, Ryan M. Bena, Faryar Jabbari, Aaron D. Ames
Abstract: This paper generalizes the control barrier function framework by replacing scalar-valued functions with matrix-valued ones. Specifically, we develop barrier conditions for safe sets defined by matrix inequalities -- both semidefinite and indefinite. Matrix inequalities can be used to describe a richer class of safe sets, including nonsmooth ones. The safety filters constructed from our proposed matrix control barrier functions via semidefinite programming (CBF-SDP) are shown to be continuous. Our matrix formulation naturally provides a continuous safety filter for Boolean-based control barrier functions, notably for disjunctions (OR), without relaxing the safe set. We illustrate the effectiveness of the proposed framework with applications in drone network connectivity maintenance and nonsmooth obstacle avoidance, both in simulations and hardware experiments.

Paper number 23:
Title: Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface
Authors: Xinyun Zou, Jorge Gamez, Meghna Menon, Phillip Ring, Chadwick Boulay, Likhith Chitneni, Jackson Brennecke, Shana R. Melby, Gracy Kureel, Kelsie Pejsa, Emily R. Rosario, Ausaf A. Bari, Aniruddh Ravindran, Tyson Aflalo, Spencer S. Kellis, Dimitar Filev, Florian Solzbacher, Richard A. Andersen
Abstract: Brain-computer interfaces (BCIs) read neural signals directly from the brain to infer motor planning and execution. However, the implementation of this technology has been largely limited to laboratory settings, with few real-world applications. We developed a bimanual BCI system to drive a vehicle in both simulated and real-world environments. We demonstrate that an individual with tetraplegia, implanted with intracortical BCI electrodes in the posterior parietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts at least as fast and precisely as motor intact participants, and drives a simulated vehicle as proficiently as the same control group. This BCI participant, living in California, could also remotely drive a Ford Mustang Mach-E vehicle in Michigan. Our first teledriving task relied on cursor control for speed and steering in a closed urban test facility. However, the final BCI system added click control for full-stop braking and thus enabled bimanual cursor-and-click control for both simulated driving through a virtual town with traffic and teledriving through an obstacle course without traffic in the real world. We also demonstrate the safety and feasibility of BCI-controlled driving. This first-of-its-kind implantable BCI application not only highlights the versatility and innovative potentials of BCIs but also illuminates the promising future for the development of life-changing solutions to restore independence to those who suffer catastrophic neurological injury.

Paper number 24:
Title: FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with advanced prosodic modeling based on Mixture of Experts
Authors: Qingliang Meng, Luogeng Xiong, Wei Liang, Limei Yu, Huizhi Liang, Tian Li
Abstract: Achieving natural and human-like speech synthesis with low inference costs remains a major challenge in speech synthesis research. This study focuses on human prosodic patterns and synthesized spectrum harmony, addressing the challenges of prosody modeling and artifact issues in non-autoregressive models. To enhance prosody modeling and synthesis quality, we introduce a new Duration Predictor based on the Mixture of Experts alongside a new Vocoder with two advanced multi-scale discriminators. We integrated the these new modules into the VITS system, forming our FNH-TTS system. Our experiments on LJSpeech, VCTK, and LibriTTS demonstrate the system's superiority in synthesis quality, phoneme duration prediction, Vocoder results, and synthesis speed. Our prosody visualization results show that FNH-TTS produces duration predictions that more closely align with natural human beings than other systems.

Paper number 25:
Title: Autonomous Driving with RSMA-Enabled Finite Blocklength Transmissions: Ergodic Performance Analysis and Optimization
Authors: Yi Wang, Yingyang Chen, Li Wang, Donghong Cai, Xiaofan Li, Pingzhi Fan
Abstract: Rate-splitting multiple access (RSMA) is a key technology for next-generation multiple access systems due to its robustness against imperfect channel state information (CSI). This makes RSMA particularly suitable for high-mobility autonomous driving, where ultra-reliable and low-latency communication (URLLC) is essential. To address the stringent requirements, this study enables RSMA finite blocklength (FBL) transmissions and explicitly evaluates the ergodic performance. We derive the closed-form lower bound for the ergodic sum-rate of RSMA, considering vital factors such as the vehicle velocities, vehicle positions, power allocation of each stream, blocklengths, and block error rates (BLERs). To further enhance the ergodic sum-rate while complying with quality of service (QoS) rate constraints, we jointly optimize the global power coefficient, private power distribution, and common rate splitting. Guided by gradient descent, we first adjust the global power coefficient based on its sum-rate solution. This parameter regulates the power state of the common stream, allowing for dynamic activation or deactivation: if active, we optimize the private power distribution and adjust the common rate splitting to meet minimum transmission constraints; if inactive, we use the sequential quadratic programming for private power distribution optimization. Simulation results confirm that our RSMA scheme significantly improves the ergodic performance, reduces blocklength and BLER, surpassing the RSMA counterpart with average private power and space division multiple access (SDMA). Furthermore, our approach is validated to guarantee the rates for users with the poorest channel conditions, thereby enhancing fairness across the network.

Paper number 26:
Title: MASSLOC: A Massive Sound Source Localization System based on Direction-of-Arrival Estimation
Authors: Georg K.J. Fischer, Thomas Schaechtle, Moritz Schabinger, Alexander Richter, Ivo Häring, Fabian Höflinger, Stefan J. Rupitsch
Abstract: Acoustic indoor localization offers the potential for highly accurate position estimation while generally exhibiting low hardware requirements compared to Radio Frequency (RF)-based solutions. Furthermore, angular-based localization significantly reduces installation effort by minimizing the number of required fixed anchor nodes. In this contribution, we propose the so-called MASSLOC system, which leverages sparse two-dimensional array geometries to localize and identify a large number of concurrently active sources. Additionally, the use of complementary Zadoff-Chu sequences is introduced to enable efficient, beamforming-based source identification. These sequences provide a trade-off between favorable correlation properties and accurate, unsynchronized direction-of-arrival estimation by exhibiting a spectrally balanced waveform. The system is evaluated in both a controlled anechoic chamber and a highly reverberant lobby environment with a reverberation time of 1.6 s. In a laboratory setting, successful direction-of-arrival estimation and identification of up to 14 simultaneously emitting sources are demonstrated. Adopting a Perspective-n-Point (PnP) calibration approach, the system achieves a median three-dimensional localization error of 55.7 mm and a median angular error of 0.84 deg with dynamic source movement of up to 1.9 mps in the challenging reverberant environment. The multi-source capability is also demonstrated and evaluated in that environment with a total of three tags. These results indicate the scalability and robustness of the MASSLOC system, even under challenging acoustic conditions.

Paper number 27:
Title: Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games
Authors: Mingjia He, Andrea Censi, Emilio Frazzoli, Gioele Zardini
Abstract: Network-based systems are inherently interconnected, with the design and performance of subnetworks being interdependent. However, the decisions of self-interested operators may lead to suboptimal outcomes for users and the overall system. This paper explores cooperative mechanisms that can simultaneously benefit both operators and users. We address this challenge using a game-theoretical framework that integrates both non-cooperative and cooperative game theory. In the non-cooperative stage, we propose a network design game in which subnetwork decision-makers strategically design local infrastructures. In the cooperative stage, co-investment with payoff-sharing mechanism is developed to enlarge collective benefits and fairly distribute them. To demonstrate the effectiveness of our framework, we conduct case studies on the Sioux Falls network and real-world public transport networks in Zurich and Winterthur, Switzerland. Our evaluation considers impacts on environmental sustainability, social welfare, and economic efficiency. The proposed framework provides a foundation for improving interdependent networked systems by enabling strategic cooperation among self-interested operators.

Paper number 28:
Title: A Generalized Multidimensional Chinese Remainder Theorem (MD-CRT) for Multiple Integer Vectors
Authors: Guangpu Guo, Xiang-Gen Xia
Abstract: Chinese remainder theorem (CRT) is widely applied in cryptography, coding theory, and signal processing. It has been extended to the multidimensional CRT (MD-CRT), which reconstructs an integer vector from its vector remainders modulo multiple integer matrices. This paper investigates a generalized MD-CRT for multiple integer vectors, where the goal is to determine multiple integer vectors from multiple vector residue sets modulo multiple integer this http URL to the existing generalized CRT for multiple scalar integers, the challenge is that the moduli in MD-CRT are matrices that do not commute and the corresponding uniquely determinable range is multidimensional and the inclusion relationship is much more complicated. In this paper,we address two fundamental questions regarding the generalized MD-CRT. The first question concerns the uniquely determinable range of multiple integer vectors when no prior information about them is available. The second question is about the conditions under which the maximal possible dynamic range can be this http URL answer these two questions, we first derive a uniquely determinable range without prior information and accordingly propose an algorithm to achieve it. A special case involving only two integer vectors is investigated for the second question, leading to a new condition for achieving the maximal possible dynamic range. Interestingly, this newly obtained condition, when the dimension is reduced to $1$, is even better than the existing ones for the conventional generalized CRT for scalar this http URL results may have applications for frequency detection in multidimensional signal processing.

Paper number 29:
Title: RFSS: A Comprehensive Multi-Standard RF Signal Source Separation Dataset with Advanced Channel Modeling
Authors: Hao Chen, Rui Jin, Dayuan Tan
Abstract: The rapid evolution of wireless communication systems has created complex electromagnetic environments where multiple cellular standards (2G/3G/4G/5G) coexist, necessitating advanced signal source separation techniques. We present RFSS (RF Signal Source Separation), a comprehensive open-source dataset containing 52,847 realistic multi-standard RF signal samples with complete 3GPP standards compliance. Our framework generates authentic baseband signals for GSM, UMTS, LTE, and 5G NR with advanced channel modeling including multipath fading, MIMO processing up to 8 by 8 antennas, and realistic interference scenarios. Experimental validation demonstrates superior performance of CNN-LSTM architectures achieving 26.7 dB SINR improvement in source separation tasks, significantly outperforming traditional ICA (15.2 dB) and NMF (18.3 dB) approaches. The RFSS dataset enables reproducible research in RF source separation, cognitive radio, and machine learning applications while maintaining complete open-source accessibility

Paper number 30:
Title: Effect of Phase Shift Errors on the Security of UAV-assisted STAR-RIS IoT Networks
Authors: Mustafa Gusaibat, Mohammed Hnaish, Abdelhamid Salem, Khaled Rabie, Zubair Md Fadlullah, Wali Ullah Khan, Mohamad A. Alawad, Yazeed Alkhrijah
Abstract: Unmanned aerial vehicles (UAV)-mounted simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) systems can provide full-dimensional coverage and flexible deployment opportunities in future 6G-enabled IoT networks. However, practical imperfections such as jittering and airflow of UAV could affect the phase shift of STAR-RIS, and consequently degrade network security. In this respect, this paper investigates the impact of phase shift errors on the secrecy performance of UAV-mounted STAR-RIS-assisted IoT systems. More specifically, we consider a UAV-mounted STAR-RIS-assisted non-orthogonal multiple access (NOMA) system where IoT devices are grouped into two groups: one group on each side of the STAR-RIS. The nodes in each group are considered as potential Malicious nodes for the ones on the other side. By modeling phase estimation errors using a von Mises distribution, analytical closed-form expressions for the ergodic secrecy rates under imperfect phase adjustment are derived. An optimization problem to maximize the weighted sum secrecy rate (WSSR) by optimizing the UAV placement is formulated and is then solved using a linear grid-based algorithm. Monte Carlo simulations are provided to validate the analytical derivations. The impact of phase estimation errors on system's secrecy performance is analyzed, providing critical insights for the practical realisation of STAR-RIS deployments for secure UAV-enabled IoT networks.

Paper number 31:
Title: Design of MIMO Lur'e oscillators via dominant system theory with application in multi-agent rhythm synchronization
Authors: Yu Kawano, Fulvio Forni
Abstract: This paper presents a new design framework for dynamic output-feedback controllers for Lur'e oscillation in a multiple-input multiple-output setting. We first revisit and extend dominant system theory to state-dependent rates, with the goal of deriving conditions based on linear matrix inequalities. Then, we introduce a separation principle for Lur'e oscillator design, which allows for the independent design of a state-feedback oscillator and an observer. Our proposed control synthesis is demonstrated through the rhythm synchronization in multi-agent systems, illustrating how networks of stable, heterogeneous linear agents can be driven into phase-locked rhythmic behavior.

Paper number 32:
Title: Euclidean Approach to Green-Wave Theory Applied to Traffic Signal Networks
Authors: Melvin H. Friedman, Brian L. Mark, Nathan H. Gartner
Abstract: Travel on long arterials with signalized intersections can be inefficient if not coordinated properly. As the number of signals increases, coordination becomes more challenging and traditional progression schemes tend to break down. Long progressions save travel time and fuel, reduce pollution and traffic accidents by providing a smoother flow of traffic. This paper introduces a green-wave theory that can be applied to a network of intersecting arterial roads. It enables uninterrupted flow on arbitrary long signalized arterials using a Road-to-Traveler-Feedback Device. The approach is modelled after Euclid. We define concepts such as RGW-roads (roads where vehicles traveling at the recommended speed make all traffic signals), green-arrows (representing vehicle platoons), real nodes (representing signalized intersections where RGW-roads intersect) and virtual nodes, green-wave speed, blocks, etc. - the analogue of Euclid's postulates. We then use geometric reasoning to deduce results: green-arrow lengths have a maximum value, are restricted to discrete lengths, and green-arrow laws of motion imply that select existing arterial roads can be converted to RGW-roads. The signal timings and offsets that are produced have been shown to be effective using a simulation model developed previously called RGW-SIM.

Paper number 33:
Title: A layered smart sensing platform for physiologically informed human-exoskeleton interaction
Authors: Chenyu Tang, Yu Zhu, Josée Mallah, Wentian Yi, Luyao Jin, Zibo Zhang, Shengbo Wang, Muzi Xu, Ming Shen, Calvin Kalun Or, Shuo Gao, Shaoping Bai, Luigi G. Occhipinti
Abstract: Wearable exoskeletons offer transformative potential to assist mobility across diverse user groups with reduced muscle strength or other forms of impaired mobility. Yet, their deployment beyond laboratory settings remains constrained by sensing systems able to fully capture users' physiological and biomechanical states in real time. We introduce a soft, lightweight smart leg sleeve with anatomically inspired layered multimodal sensing, integrating textile-based surface electromyography (sEMG) electrodes, ultrasensitive textile strain sensors, and inertial measurement units (IMUs). Each sensing modality targets a distinct physiological layer: IMUs track joint kinematics at the skeletal level, sEMG monitors muscle activation at the muscular level, and strain sensors detect skin deformation at the cutaneous level. Together, these sensors provide real-time perception to support three core objectives: controlling personalized assistance, optimizing user effort, and safeguarding against injury risks. The system is skin-conformal, mechanically compliant, and seamlessly integrated with a custom exoskeleton (<20 g total sensor and electronics weight). We demonstrate: (1) accurate ankle joint moment estimation (RMSE = 0.13 Nm/kg), (2) real-time classification of metabolic trends (accuracy = 97.1%), and (3) injury risk detection within 100 ms (recall = 0.96), all validated on unseen users using a leave-one-subject-out protocol. This work demonstrates a lightweight, multimodal sensing architecture for next-generation human-exoskeleton interaction in controlled and semi-structured walking scenarios, with potential for scaling to broader exoskeleton applications towards intelligent, responsive, and personalized wearable robotics.

Paper number 34:
Title: Monotone Neural Control Barrier Certificates
Authors: Alireza Nadali, Ashutosh Trivedi, Majid Zamani, Saber Jafarpour
Abstract: This work presents a neurosymbolic framework for synthesizing and verifying safety controllers in high-dimensional monotone dynamical systems using only linear sample complexity, without requiring explicit models or conservative Lipschitz bounds. The approach combines the expressiveness of neural networks with the rigor of symbolic reasoning via barrier certificates, functional analogs of inductive invariants that formally guarantee safety. Prior data-driven methods often treat dynamics as black-box models, relying on dense state-space discretization or Lipschitz overapproximations, leading to exponential sample complexity. In contrast, monotonicity -- a pervasive structural property in many real-world systems -- provides a symbolic scaffold that simplifies both learning and verification. Exploiting order preservation reduces verification to localized boundary checks, transforming a high-dimensional problem into a tractable, low-dimensional one. Barrier certificates are synthesized using monotone neural networks -- architectures with embedded monotonicity constraints -- trained via gradient-based optimization guided by barrier conditions. This enables scalable, formally sound verification directly from simulation data, bridging black-box learning and formal guarantees within a unified neurosymbolic framework. Empirical results on three large-scale benchmarks -- a 1,000-dimensional freeway traffic model, a 50-dimensional urban traffic network, and a 13,000-dimensional power grid -- demonstrate the scalability and effectiveness of the approach in real-world, safety-critical systems.

Paper number 35:
Title: Understanding the Fundamental Trade-Off Between Age of Information and Throughput in Unreliable Wireless Networks
Authors: Lin Wang, I-Hong Hou
Abstract: This paper characterizes the fundamental trade-off between throughput and Age of Information (AoI) in wireless networks where multiple devices transmit status updates to a central base station over unreliable channels. To address the complexity introduced by stochastic transmission successes, we propose the throughput-AoI capacity region, which defines all feasible throughput-AoI pairs achievable under any scheduling policy. Using a second-order approximation that incorporates both mean and temporal variance, we derive an outer bound and a tight inner bound for the throughput-AoI capacity region. Furthermore, we propose a simple and low complexity scheduling policy and prove that it achieves every interior point within the tight inner bound. This establishes a systematic and theoretically grounded framework for the joint optimization of throughput and information freshness in practical wireless communication scenarios. To validate our theoretical framework and demonstrate the utility of the throughput-AoI capacity region, extensive simulations are implemented. Simulation results demonstrate that our proposed policy significantly outperforms conventional methods across various practical network optimization scenarios. The findings highlight our approach's effectiveness in optimizing both throughput and AoI, underscoring its applicability and robustness in practical wireless networks.

Paper number 36:
Title: DermINO: Hybrid Pretraining for a Versatile Dermatology Foundation Model
Authors: Jingkai Xu, De Cheng, Xiangqian Zhao, Jungang Yang, Zilong Wang, Xinyang Jiang, Xufang Luo, Lili Chen, Xiaoli Ning, Chengxu Li, Xinzhu Zhou, Xuejiao Song, Ang Li, Qingyue Xia, Zhou Zhuang, Hongfei Ouyang, Ke Xue, Yujun Sheng, Rusong Meng, Feng Xu, Xi Yang, Weimin Ma, Yusheng Lee, Dongsheng Li, Xinbo Gao, Jianming Liang, Lili Qiu, Nannan Wang, Xianbo Zuo, Cui Yong
Abstract: Skin diseases impose a substantial burden on global healthcare systems, driven by their high prevalence (affecting up to 70% of the population), complex diagnostic processes, and a critical shortage of dermatologists in resource-limited areas. While artificial intelligence(AI) tools have demonstrated promise in dermatological image analysis, current models face limitations-they often rely on large, manually labeled datasets and are built for narrow, specific tasks, making them less effective in real-world settings. To tackle these limitations, we present DermNIO, a versatile foundation model for dermatology. Trained on a curated dataset of 432,776 images from three sources (public repositories, web-sourced images, and proprietary collections), DermNIO incorporates a novel hybrid pretraining framework that augments the self-supervised learning paradigm through semi-supervised learning and knowledge-guided prototype initialization. This integrated method not only deepens the understanding of complex dermatological conditions, but also substantially enhances the generalization capability across various clinical tasks. Evaluated across 20 datasets, DermNIO consistently outperforms state-of-the-art models across a wide range of tasks. It excels in high-level clinical applications including malignancy classification, disease severity grading, multi-category diagnosis, and dermatological image caption, while also achieving state-of-the-art performance in low-level tasks such as skin lesion segmentation. Furthermore, DermNIO demonstrates strong robustness in privacy-preserving federated learning scenarios and across diverse skin types and sexes. In a blinded reader study with 23 dermatologists, DermNIO achieved 95.79% diagnostic accuracy (versus clinicians' 73.66%), and AI assistance improved clinician performance by 17.21%.

Paper number 37:
Title: ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search
Authors: Mauro Belgiovine, Suyash Pradhan, Johannes Lange, Michael Löhning, Kaushik Chowdhury
Abstract: Industry adoption of Artificial Intelligence (AI)-native wireless receivers, or even modular, Machine Learning (ML)-aided wireless signal processing blocks, has been slow. The main concern is the lack of explainability of these trained ML models and the significant risks posed to network functionalities in case of failures, especially since (i) testing on every exhaustive case is infeasible and (ii) the data used for model training may not be available. This paper proposes ATLAS, an AI-guided approach that generates a battery of tests for pre-trained AI-native receiver models and benchmarks the performance against a classical receiver architecture. Using gradient-based optimization, it avoids spanning the exhaustive set of all environment and channel conditions; instead, it generates the next test in an online manner to further probe specific configurations that offer the highest risk of failure. We implement and validate our approach by adopting the well-known DeepRx AI-native receiver model as well as a classical receiver using differentiable tensors in NVIDIA's Sionna environment. ATLAS uncovers specific combinations of mobility, channel delay spread, and noise, where fully and partially trained variants of AI-native DeepRx perform suboptimally compared to the classical receivers. Our proposed method reduces the number of tests required per failure found by 19% compared to grid search for a 3-parameters input optimization problem, demonstrating greater efficiency. In contrast, the computational cost of the grid-based approach scales exponentially with the number of variables, making it increasingly impractical for high-dimensional problems.

Paper number 38:
Title: Weighted Covariance Intersection for Range-based Distributed Cooperative Localization of Multi-Agent Systems
Authors: Chenxin Tu, Xiaowei Cui, Gang Liu, Mingquan Lu
Abstract: Precise localization of multi-agent systems (MAS) in harsh environments is a critical challenge for swarm applications, and cooperative localization is considered a key solution to this issue. Among all solutions, distributed cooperative localization (DCL) has garnered widespread attention due to its robustness and scalability. The main challenge of DCL lies in how to fuse relative measurements between agents under unknown correlations. To address this, covariance intersection (CI) was introduced to DCL. However, the classical CI optimization criteria suffer from issues such as scale imbalance and correlation mismatch during the fusion process. These deficiencies are not as pronounced in 2D scenarios, where the state space is relatively simple and the observability of each state component is well. However, in 3D scenarios, where the state space is more complex and there are significant disparities in the scale and observability of state components, performance degradation becomes severe. This necessitates the design of specialized mechanisms to improve the data fusion process. In this paper, we identify three main drawbacks of the classical CI optimization criteria in recursive filtering and introduce a weighting mechanism, namely weighted covariance intersection (WCI), to improve its performance. We then introduce WCI into range-based distributed cooperative localization in 3D scenarios, developing a concurrent fusion strategy for multiple distance measurements and designing a weighting matrix based on the error propagation rule of the inertial navigation system (INS). Simulation results demonstrate that the proposed WCI significantly enhances cooperative localization performance compared to classical CI, while the distributed approach outperforms the centralized approach in terms of robustness, scalability, and is more suitable for large-scale swarms.

Paper number 39:
Title: Towards Generalizable Human Activity Recognition: A Survey
Authors: Yize Cai, Baoshen Guo, Flora Salim, Zhiqing Hong
Abstract: As a critical component of Wearable AI, IMU-based Human Activity Recognition (HAR) has attracted increasing attention from both academia and industry in recent years. Although HAR performance has improved considerably in specific scenarios, its generalization capability remains a key barrier to widespread real-world adoption. For example, domain shifts caused by variations in users, sensor positions, or environments can significantly decrease the performance in practice. As a result, in this survey, we explore the rapidly evolving field of IMU-based generalizable HAR, reviewing 229 research papers alongside 25 publicly available datasets to provide a broad and insightful overview. We first present the background and overall framework of IMU-based HAR tasks, as well as the generalization-oriented training settings. Then, we categorize representative methodologies from two perspectives: (i) model-centric approaches, including pre-training method, end-to-end method, and large language model (LLM)-based learning method; and (ii) data-centric approaches, including multi-modal learning and data augmentation techniques. In addition, we summarize widely used datasets in this field, as well as relevant tools and benchmarks. Building on these methodological advances, the broad applicability of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent challenges (e.g., data scarcity, efficient training, and reliable evaluation) and also outline future directions for HAR, including the adoption of foundation and large language models, physics-informed and context-aware reasoning, generative modeling, and resource-efficient training and inference. The complete list of this survey is available at this https URL, which will be updated continuously.

Paper number 40:
Title: A Novel Symbol Level Precoding based AFDM Transmission Framework: Offloading Equalization Burden to Transmitter Side
Authors: Shuntian Tang, Zesong Fei, Xinyi Wang, Dongkai Zhou, Zhiqiang Wei, Christos Masouros
Abstract: Affine Frequency Division Multiplexing (AFDM) has attracted considerable attention for its robustness to Doppler effects. However, its high receiver-side computational complexity remains a major barrier to practical deployment. To address this, we propose a novel symbol-level precoding (SLP)-based AFDM transmission framework, which shifts the signal processing burden in downlink communications from user side to the base station (BS), enabling direct symbol detection without requiring channel estimation or equalization at the receiver. Specifically, in the uplink phase, we propose a Sparse Bayesian Learning (SBL) based channel estimation algorithm by exploiting the inherent sparsity of affine frequency (AF) domain channels. In particular, the sparse prior is modeled via a hierarchical Laplace distribution, and parameters are iteratively updated using the Expectation-Maximization (EM) algorithm. We also derive the Bayesian Cramer-Rao Bound (BCRB) to characterize the theoretical performance limit. In the downlink phase, the BS employs the SLP technology to design the transmitted waveform based on the estimated uplink channel state information (CSI) and channel reciprocity. The resulting optimization problem is formulated as a second-order cone programming (SOCP) problem, and its dual problem is investigated by Lagrangian function and Karush-Kuhn-Tucker conditions. Simulation results demonstrate that the proposed SBL estimator outperforms traditional orthogonal matching pursuit (OMP) in accuracy and robustness to off-grid effects, while the SLP-based waveform design scheme achieves performance comparable to conventional AFDM receivers while significantly reducing the computational complexity at receiver, validating the practicality of our approach.

Paper number 41:
Title: Adaptive Control with Set-Point Tracking and Linear-like Closed-loop Behavior
Authors: Mohamad T. Shahab
Abstract: In this paper, we consider the problem of set-point tracking for a discrete-time plant with unknown plant parameters belonging to a convex and compact uncertainty set. We carry out parameter estimation for an associated auxiliary plant, and a pole-placement-based control law is employed. We prove that this adaptive controller provides desirable linear-like closed-loop behavior which guarantees a bound consisting of: exponential decay with respect to the initial condition, a linear-like convolution bound with respect to the exogenous inputs, and a constant scaled by the square root of the constant in the denominator of the parameter estimator update law. This implies that the system has a bounded gain. Moreover, asymptotic tracking is also proven when the disturbance is constant.

Paper number 42:
Title: Design and Analysis of Curved Electrode Configurations for Enhanced Sensitivity in 1-Axis MEMS Accelerometers
Authors: Adhinarayan Naembin Ashok, Adarsh Ganesan
Abstract: This paper presents a comprehensive analytical and simulation-based study of curved electrode geometries for enhancing the sensitivity of MEMS capacitive accelerometers. Expressions for the capacitance between a planar movable electrode and six distinct fixed electrode profiles (biconvex, biconcave, concavo-convex, convexo-concave, plano-convex, and plano-concave) are derived, enabling direct calculation of differential gain and sensitivity as functions of electrode curvature and gap displacement. These analytical models are then rigorously validated using finite element simulations performed using COMSOL Multiphysics under identical bias and boundary conditions. The simulation results demonstrate agreement with the analytical results with a deviation of less than 7% in all configurations. The results also reveal that biconvex curved electrodes yield the greatest sensitivity improvement over the planar electrodes, with sensitivity monotonically increasing with arc length, while concave and plano-concave designs exhibit reduced performance. The concavo-convex and convexo-concave configurations furthermore introduce polarity inversion in the output voltage, offering additional design flexibility. Importantly, these sensitivity enhancements are achieved without any change in the overall volumetric dimensions of the device or the proofmass dimensions of the module for achieving higher-resolution inertial sensing.

Paper number 43:
Title: Polarization Reconfigurable Transmit-Receive Beam Alignment with Interpretable Transformer
Authors: Seungcheol Oh, Han Han, Joongheon Kim, Sean Kwon
Abstract: Recent advancement in next generation reconfigurable antenna and fluid antenna technology has influenced the wireless system with polarization reconfigurable (PR) channels to attract significant attention for promoting beneficial channel condition. We exploit the benefit of PR antennas by integrating such technology into massive multiple-input-multiple-output (MIMO) system. In particular, we aim to jointly design the polarization and beamforming vectors on both transceivers for simultaneous channel reconfiguration and beam alignment, which remarkably enhance the beamforming gain. However, joint optimization over polarization and beamforming vectors without channel state information (CSI) is a challenging task, since depolarization increases the channel dimension; whereas massive MIMO systems typically have low-dimensional pilot measurement from limited radio frequency (RF) chain. This leads to pilot overhead because the transceivers can only observe low-dimensional measurement of the high-dimension channel. This paper pursues the reduction of the pilot overhead in such systems by proposing to employ \emph{interpretable transformer}-based deep learning framework on both transceivers to actively design the polarization and beamforming vectors for pilot stage and transmission stage based on the sequence of accumulated received pilots. Numerical experiments demonstrate the significant performance gain of our proposed framework over the existing non-adaptive and active data-driven methods. Furthermore, we exploit the interpretability of our proposed framework to analyze the learning capabilities of the model.

Paper number 44:
Title: Jamming Identification with Differential Transformer for Low-Altitude Wireless Networks
Authors: Pengyu Wang, Zhaocheng Wang, Tianqi Mao, Weijie Yuan, Haijun Zhang, George K. Karagiannidis
Abstract: Wireless jamming identification, which detects and classifies electromagnetic jamming from non-cooperative devices, is crucial for emerging low-altitude wireless networks consisting of many drone terminals that are highly susceptible to electromagnetic jamming. However, jamming identification schemes adopting deep learning (DL) are vulnerable to attacks involving carefully crafted adversarial samples, resulting in inevitable robustness degradation. To address this issue, we propose a differential transformer framework for wireless jamming identification. Firstly, we introduce a differential transformer network in order to distinguish jamming signals, which overcomes the attention noise when compared with its traditional counterpart by performing self-attention operations in a differential manner. Secondly, we propose a randomized masking training strategy to improve network robustness, which leverages the patch partitioning mechanism inherent to transformer architectures in order to create parallel feature extraction branches. Each branch operates on a distinct, randomly masked subset of patches, which fundamentally constrains the propagation of adversarial perturbations across the network. Additionally, the ensemble effect generated by fusing predictions from these diverse branches demonstrates superior resilience against adversarial attacks. Finally, we introduce a novel consistent training framework that significantly enhances adversarial robustness through dualbranch regularization. Simulation results demonstrate that our proposed methodology is superior to existing methods in boosting robustness to adversarial samples.

Paper number 45:
Title: Efficient and accurate solution of wind-integrated optimal power flow based on enhanced second-order cone relaxation with rolling cutting plane technique
Authors: Zhaojun Ruan, Botao Gao, Libao Shi
Abstract: The integration of large-scale renewable energy sources, such as wind power, poses significant challenges for the optimal operation of power systems owing to their inherent uncertainties. This paper proposes a solution framework for wind-integrated optimal power flow (OPF) that leverages an enhanced second-order cone relaxation (SOCR), supported by a rolling cutting plane technique. Initially, the wind generation cost, arising from discrepancies between scheduled and actual wind power outputs, is meticulously modeled using a Gaussian mixture model based on historical wind power data. This modelled wind generation cost is subsequently incorporated into the objective function of the conventional OPF problem. To achieve the efficient and accurate solution for the wind-integrated OPF, effectively managing the constraints associated with AC power flow equations is essential. In this regard, a SOCR, combined with a second-order Taylor series expansion, is employed to facilitate the convex approximation of the AC power flow equations. Additionally, a warm-start strategy, grounded in a proposed rolling cutting plane technique, is devised to reduce relaxation errors and enhance computational efficiency. Finally, the effectiveness and efficiency of the proposed solution framework are demonstrated across various case studies. Specifically, the influence of wind power cost is also examined, further highlighting the practical implications of the proposed solution framework.

Paper number 46:
Title: Coherent Compensation-Based Sensing for Long-Range Targets in Integrated Sensing and Communication System
Authors: Lin Wang, Zhiqing Wei, Xu Chen, Zhiyong Feng
Abstract: Integrated sensing and communication (ISAC) is a promising candidate technology for 6G due to its improvement in spectral efficiency and energy efficiency. Orthogonal frequency division multiplexing (OFDM) signal is a mainstream candidate ISAC waveform. However, there are inter-symbol interference (ISI) and inter-carrier interference (ICI) when the round-trip delay exceeds the cyclic prefix (CP) duration for OFDM signals, which limits the maximum sensing range of ISAC system. When detecting a long-range target, the wide beam inevitably covers the close-range target, of which the echo's power is much larger than that of the long-range target. In order to tackle the above problem, a multiple signal classification (MUSIC) and least squares (LS)-based spatial signal separation method is proposed to separate the echo signals reflected from different targets. Moreover, a coherent compensation-based sensing signal processing method at the receiver is proposed to enhance the signal to interference plus noise power ratio (SINR) of the OFDM block for generating the range-Doppler map (RDM) with higher SINR. Simulation results reveal that the proposed method greatly enhances the SINR of RDM by 10 dB for a target at 500 m compared with two-dimensional fast Fourier transform (2D-FFT) method. Besides, the detection probability is also significantly improved compared to the benchmarking method.

Paper number 47:
Title: On the Extension of Differential Beamforming Theory to Arbitrary Planar Arrays of First-Order Elements
Authors: Federico Miotello, Davide Albertini, Alberto Bernardini
Abstract: Small-size acoustic arrays exploit spatial diversity to achieve capabilities beyond those of single-element devices, with applications ranging from teleconferencing to immersive multimedia. A key requirement for broadband array processing is a frequency-invariant spatial response, which ensures consistent directivity across wide bandwidths and prevents spectral coloration. Differential beamforming offers an inherently frequency-invariant solution by leveraging pressure differences between closely spaced elements of small-size arrays. Traditional approaches, however, assume the array elements to be omnidirectional, whereas real transducers exhibit frequency-dependent directivity that can degrade performance if not properly modeled. To address this limitation, we propose a generalized modal matching framework for frequency-invariant differential beamforming, applicable to unconstrained planar arrays of first-order directional elements. By representing the desired beampattern as a truncated circular harmonic expansion and fitting it to the actual element responses, our method accommodates arbitrary planar geometries and element orientations. This approach enables the synthesis of beampatterns of any order and steering direction without imposing rigid layout requirements. Simulations confirm that accounting for sensor directivity at the design stage yields accurate and robust performance across varying frequencies, geometries, and noise conditions.

Paper number 48:
Title: Data-driven quantification and visualization of resilience metrics of power distribution system
Authors: Dingwei Wang, Salish Maharjan, Junyuan Zheng, Liming Liu, Zhaoyu Wang
Abstract: This paper presents a data-driven approach for quantifying the resilience of distribution power grids to extreme weather events using two key metrics: (a) the number of outages and (b) restoration time. The method leverages historical outage records maintained by power utilities and weather measurements collected by the National Oceanic and Atmospheric Administration (NOAA) to evaluate resilience across a utility's service territory. The proposed framework consists of three stages. First, outage events are systematically extracted from the outage records by temporally and spatially aggregating coincident component outages. In the second stage, weather zones across the service territory are delineated using a Voronoi polygon approach, based on the locations of NOAA weather sensors. Finally, data-driven models for outage fragility and restoration time are developed for each weather zone. These models enable the quantification and visualization of resilience metrics under varying intensities of extreme weather events. The proposed method is demonstrated using real-world data from a US distribution utility, located in Indianapolis, focused on wind- and precipitation-related events. The dataset spans two decades and includes over 160,000 outage records.

Paper number 49:
Title: A One-Class Explainable AI Framework for Identification of Non-Stationary Concurrent False Data Injections in Nuclear Reactor Signals
Authors: Zachery Dahm, Vasileios Theos, Konstantinos Vasili, William Richards, Konstantinos Gkouliaras, Stylianos Chatzidakis
Abstract: The transition of next generation advanced nuclear reactor systems from analog to fully digital instrumentation and control will necessitate robust mechanisms to safeguard against potential data integrity threats. One challenge is the real-time characterization of false data injections, which can mask sensor signals and potentially disrupt reactor control systems. While significant progress has been made in anomaly detection within reactor systems, potential false data injections have been shown to bypass conventional linear time-invariant state estimators and failure detectors based on statistical thresholds. The dynamic, nonlinear, multi-variate nature of sensor signals, combined with inherent noise and limited availability of real-world training data, makes the characterization of such threats and more importantly their differentiation from anticipated process anomalies particularly challenging. In this paper, we present an eXplainable AI (XAI) framework for identifying non-stationary concurrent replay attacks in nuclear reactor signals with minimal training data. The proposed framework leverages progress on recurrent neural networks and residual analysis coupled with a modified SHAP algorithm and rule-based correlations. The recurrent neural networks are trained only on normal operational data while for residual analysis we introduce an adaptive windowing technique to improve detection accuracy. We successfully benchmarked this framework on a real-world dataset from Purdue's nuclear reactor (PUR-1). We were able to detect false data injections with accuracy higher than 0.93 and less than 0.01 false positives, differentiate from expected process anomalies, and to identify the origin of the falsified signals.

Paper number 50:
Title: Sspherical sailing omnidirectional rover (SSailOR): wind tunnel experimental setup and results
Authors: Aditya Varanwal, Parin Shah, George Carrion, Ashley Ortenburg, Diego Ramirez-Gomez, Chris Vermillion, Andre P. Mazzoleni
Abstract: This paper presents the design, instrumentation, and experimental procedures used to test the Spherical Sailing Omnidirectional Rover (SSailOR) in a controlled wind tunnel environment. The SSailOR is a wind-powered autonomous rover. This concept is motivated by the growing need for persistent and sustainable robotic systems in applications such as planetary exploration, Arctic observation, and military surveillance. SSailOR uses wind propulsion via onboard sails to enable long-duration mobility with minimal energy consumption. The spherical design simplifies mechanical complexity while enabling omnidirectional movement. Experimental tests were conducted to validate dynamic models and assess the aerodynamic performance of the rover under various configurations and environmental conditions. As a result, this design requires a co-design approach. Details of the mechanical structure, sensor integration, electronics, data acquisition system, and test parameters are presented in this paper. In addition, key observations are made that are relevant to the design optimization for further development of the rover.

Paper number 51:
Title: FractMorph: A Fractional Fourier-Based Multi-Domain Transformer for Deformable Image Registration
Authors: Shayan Kebriti, Shahabedin Nabavi, Ali Gooya
Abstract: Deformable image registration (DIR) is a crucial and challenging technique for aligning anatomical structures in medical images and is widely applied in diverse clinical applications. However, existing approaches often struggle to capture fine-grained local deformations and large-scale global deformations simultaneously within a unified framework. We present FractMorph, a novel 3D dual-parallel transformer-based architecture that enhances cross-image feature matching through multi-domain fractional Fourier transform (FrFT) branches. Each Fractional Cross-Attention (FCA) block applies parallel FrFTs at fractional angles of 0°, 45°, 90°, along with a log-magnitude branch, to effectively extract local, semi-global, and global features at the same time. These features are fused via cross-attention between the fixed and moving image streams. A lightweight U-Net style network then predicts a dense deformation field from the transformer-enriched features. On the ACDC cardiac MRI dataset, FractMorph achieves state-of-the-art performance with an overall Dice Similarity Coefficient (DSC) of 86.45%, an average per-structure DSC of 75.15%, and a 95th-percentile Hausdorff distance (HD95) of 1.54 mm on our data split. We also introduce FractMorph-Light, a lightweight variant of our model with only 29.6M parameters, which maintains the superior accuracy of the main model while using approximately half the memory. Our results demonstrate that multi-domain spectral-spatial attention in transformers can robustly and efficiently model complex non-rigid deformations in medical images using a single end-to-end network, without the need for scenario-specific tuning or hierarchical multi-scale networks. The source code of our implementation is available at this https URL.

Paper number 52:
Title: Segmenting Thalamic Nuclei: T1 Maps Provide a Reliable and Efficient Solution
Authors: Anqi Feng, Zhangxing Bian, Samuel W. Remedios, Savannah P. Hays, Blake E. Dewey, Jiachen Zhuo, Dan Benjamini, Jerry L. Prince
Abstract: Accurate thalamic nuclei segmentation is crucial for understanding neurological diseases, brain functions, and guiding clinical interventions. However, the optimal inputs for segmentation remain unclear. This study systematically evaluates multiple MRI contrasts, including MPRAGE and FGATIR sequences, quantitative PD and T1 maps, and multiple T1-weighted images at different inversion times (multi-TI), to determine the most effective inputs. For multi-TI images, we employ a gradient-based saliency analysis with Monte Carlo dropout and propose an Overall Importance Score to select the images contributing most to segmentation. A 3D U-Net is trained on each of these configurations. Results show that T1 maps alone achieve strong quantitative performance and superior qualitative outcomes, while PD maps offer no added value. These findings underscore the value of T1 maps as a reliable and efficient input among the evaluated options, providing valuable guidance for optimizing imaging protocols when thalamic structures are of clinical or research interest.

Paper number 53:
Title: Techno-Economic Planning of Spatially-Resolved Battery Storage Systems in Renewable-Dominant Grids Under Weather Variability
Authors: Seyed Ehsan Ahmadi, Elnaz Kabir, Mohammad Fattahi, Mousa Marzband, Dongjun Li
Abstract: The ongoing energy transition is significantly increasing the share of renewable energy sources (RES) in power systems; however, their intermittency and variability pose substantial challenges, including load shedding and system congestion. This study examines the role of the battery storage system (BSS) in mitigating these challenges by balancing power supply and demand. We optimize the location, size, and type of batteries using a two-stage stochastic program, with the second stage involving hourly operational decisions over an entire year. Unlike previous research, we incorporate the comprehensive technical and economic characteristics of battery technologies. The New York State (NYS) power system, currently undergoing a significant shift towards increased RES generation, serves as our case study. Using available load and weather data from 1980-2019, we account for the uncertainty of both load and RES generation through a sample average approximation approach. Our findings indicate that BSS can reduce renewable curtailment by 34% and load shedding by 21%, contributing to a more resilient power system in achieving NYS 2030 energy targets. Furthermore, the cost of employing BSS for the reduction of load shedding and RES curtailment does not increase linearly with additional capacity, revealing a complex relationship between costs and renewable penetration. This study provides valuable insights for the strategic BSS deployment to achieve a cost-effective and reliable power system in the energy transition as well as the feasibility of the NYS 2030 energy targets.

Paper number 54:
Title: Anatomic Feature Fusion Model for Diagnosing Calcified Pulmonary Nodules on Chest X-Ray
Authors: Hyeonjin Choi, Yang-gon Kim, Dong-yeon Yoo, Ju-sung Sun, Jung-won Lee
Abstract: Accurate and timely identification of pulmonary nodules on chest X-rays can differentiate between life-saving early treatment and avoidable invasive procedures. Calcification is a definitive indicator of benign nodules and is the primary foundation for diagnosis. In actual practice, diagnosing pulmonary nodule calcification on chest X-rays predominantly depends on the physician's visual assessment, resulting in significant diversity in interpretation. Furthermore, overlapping anatomical elements, such as ribs and spine, complicate the precise identification of calcification patterns. This study presents a calcification classification model that attains strong diagnostic performance by utilizing fused features derived from raw images and their structure-suppressed variants to reduce structural interference. We used 2,517 lesion-free images and 656 nodule images (151 calcified nodules and 550 non-calcified nodules), all obtained from Ajou University Hospital. The suggested model attained an accuracy of 86.52% and an AUC of 0.8889 in calcification diagnosis, surpassing the model trained on raw images by 3.54% and 0.0385, respectively.

Paper number 55:
Title: Feedback Linearization for Replicator Dynamics: A Control Framework for Evolutionary Game Convergence
Authors: Adil Faisal
Abstract: This paper demonstrates the first application of feedback linearization to replicator dynamics, driving the evolution of non-convergent evolutionary games to systems with guaranteed global asymptotic stability.

Paper number 56:
Title: Towards SISO Bistatic Sensing for ISAC
Authors: Zhongqin Wang, J. Andrew Zhang, Kai Wu, Min Xu, Y. Jay Guo
Abstract: Integrated Sensing and Communication (ISAC) is a key enabler for next-generation wireless systems. However, real-world deployment is often limited to low-cost, single-antenna transceivers. In such bistatic Single-Input Single-Output (SISO) setup, clock asynchrony introduces random phase offsets in Channel State Information (CSI), which cannot be mitigated using conventional multi-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic SISO sensing framework that enables accurate delay and Doppler estimation from distorted CSI by effectively suppressing Doppler mirroring ambiguity. It operates with only a single antenna at both the transmitter and receiver, making it suitable for low-complexity deployments. We propose a self-referencing cross-correlation (SRCC) method for SISO random phase removal and employ delay-domain beamforming to resolve Doppler ambiguity. The resulting unambiguous delay-Doppler-time features enable robust sensing with compact neural networks. Extensive experiments show that WiDFS 3.0 achieves accurate parameter estimation, with performance comparable to or even surpassing that of prior multi-antenna methods, especially in delay estimation. Validated under single- and multi-target scenarios, the extracted ambiguity-resolved features show strong sensing accuracy and generalization. For example, when deployed on the embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0 consistently outperforms conventional features such as CSI amplitude, mirrored Doppler, and multi-receiver aggregated Doppler.

Paper number 57:
Title: DCT-MARL: A Dynamic Communication Topology-Based MARL Algorithm for Connected Vehicle Platoon Control
Authors: Yaqi Xu, Yan Shi, Jin Tian, Fanzeng Xia, Shanzhi Chen, Yuming Ge
Abstract: With the rapid advancement of vehicular communication and autonomous driving technologies, connected vehicle platoon has emerged as a promising approach to improve traffic efficiency and driving safety. Reliable Vehicle-to-Vehicle (V2V) communication is critical to achieving efficient cooperative control. However, in real-world traffic environments, V2V links may suffer from time-varying delay and packet loss, leading to degraded control performance and even safety risks. To mitigate the adverse effects of non-ideal communication, this paper proposes a Dynamic Communication Topology based Multi-Agent Reinforcement Learning (DCT-MARL) algorithm for robust cooperative platoon control. Specifically, the state space is augmented with historical control action and delay to enhance robustness against communication delay. To mitigate the impact of packet loss, a multi-key gated communication mechanism is introduced, which dynamically adjusts the communication topology based on the correlation between agents and their current communication this http URL results demonstrate that the proposed DCT-MARL significantly outperforms state-of-the-art methods in terms of string stability and driving comfort, validating its superior robustness and effectiveness.

Paper number 58:
Title: Factorized Disentangled Representation Learning for Interpretable Radio Frequency Fingerprin
Authors: Yezhuo Zhang, Zinan Zhou, Guangyu Li, Xuanpeng Li
Abstract: In response to the rapid growth of Internet of Things (IoT) devices and rising security risks, Radio Frequency Fingerprint (RFF) has become key for device identification and authentication. However, various changing factors - beyond the RFF itself - can be entangled from signal transmission to reception, reducing the effectiveness of RFF Identification (RFFI). Existing RFFI methods mainly rely on domain adaptation techniques, which often lack explicit factor representations, resulting in less robustness and limited controllability for downstream tasks. To tackle this problem, we propose a novel Disentangled Representation Learning (DRL) framework that learns explicit and independent representations of multiple factors, including the RFF. Our framework introduces modules for disentanglement, guided by the principles of explicitness, modularity, and compactness. We design two dedicated modules for factor classification and signal reconstruction, each with tailored loss functions that encourage effective disentanglement and enhance support for downstream tasks. Thus, the framework can extract a set of interpretable vectors that explicitly represent corresponding factors. We evaluate our approach on two public benchmark datasets and a self-collected dataset. Our method achieves impressive performance on multiple DRL metrics. We also analyze the effectiveness of our method on downstream RFFI task and conditional signal generation task. All modules of the framework contribute to improved classification accuracy, and enable precise control over conditional generated signals. These results highlight the potential of our DRL framework for interpretable and explicit RFFs.

Paper number 59:
Title: Cryfish: On deep audio analysis with Large Language Models
Authors: Anton Mitrofanov, Sergei Novoselov, Tatiana Prisyach, Vladislav Marchevskiy, Arseniy Karelin, Nikita Khmelev, Dmitry Dutov, Stepan Malykh, Igor Agafonov, Aleksandr Nikitin, Oleg Petrov
Abstract: The recent revolutionary progress in text-based large language models (LLMs) has contributed to the growth of interest in extending capabilities of such models to multimodal perception and understanding tasks. Hearing is an essential capability that is highly desired to be integrated into LLMs. However, effective integrating listening capabilities into LLMs is a significant challenge lying in generalizing complex auditory tasks across speech and sounds. To address these issues, we introduce Cryfish, our version of auditory-capable LLM. The model integrates WavLM audio-encoder features into Qwen2 model using a transformer-based connector. Cryfish is adapted to various auditory tasks through a specialized training strategy. We evaluate the model on the new Dynamic SUPERB Phase-2 comprehensive multitask benchmark specifically designed for auditory-capable models. The paper presents an in-depth analysis and detailed comparison of Cryfish with the publicly available models.

Paper number 60:
Title: Multi-Domain Supervised Contrastive Learning for UAV Radio-Frequency Open-Set Recognition
Authors: Ning Gao, Tianrui Zeng, Bowen Chen, Donghong Cai, Shi Jin, Michail Matthaiou
Abstract: 5G-Advanced (5G-A) has enabled the vibrant development of low altitude integrated sensing and communication (LA-ISAC) networks. As a core component of these networks, unmanned aerial vehicles (UAVs) have witnessed rapid growth in recent years. However, due to the lag in traditional industry regulatory norms, unauthorized flight incidents occur frequently, posing a severe security threat to LA-ISAC networks. To surveil the non-cooperative UAVs, in this paper, we propose a multi-domain supervised contrastive learning (MD-SupContrast) framework for UAV radio frequency (RF) open-set recognition. Specifically, first, the texture features and the time-frequency position features from the ResNet and the TransformerEncoder are fused, and then the supervised contrastive learning is applied to optimize the feature representation of the closed-set samples. Next, to surveil the invasive UAVs that appear in real life, we propose an improved generative OpenMax (IG-OpenMax) algorithm and construct an open-set recognition model, namely Open-RFNet. According to the unknown samples, we first freeze the feature extraction layers and then only retrain the classification layer, which achieves excellent recognition performance both in closed-set and open-set recognitions. We analyze the computational complexity of the proposed model. Experiments are conducted with a large-scale UAV open dataset. The results show that the proposed Open-RFNet outperforms the existing benchmark methods in terms of recognition accuracy between the known and the unknown UAVs, as it achieves 95.12% in closed-set and 96.08% in open-set under 25 UAV types, respectively.

Paper number 61:
Title: Stability Analysis of the Newton-Raphson Controller for a Class of Differentially Flat Systems
Authors: Kaicheng Niu, Yorai Wardi, Chaouki T. Abdallah
Abstract: The Newton-Raphson Controller, established on the output prediction and the Newton-Raphson algorithm, is shown to be effective in a variety of control applications. Although the stability condition of the controller for linear systems has already been established, such condition for nonlinear systems remains unexplored. In this paper, we study the stability of the Newton-Raphson controller for a class of differentially flat nonlinear systems in the context of output regulation and tracking control. For output regulation, we prove that the controlled system is stable within a neighborhood of the origin if the corresponding flat system and output predictor satisfy a verifiable stability criterion. A semi-quantitative analysis is conducted to determine the measure of the domain of attraction. For tracking control, we prove that the controller is capable of driving the outputs to the external reference signals using a specific selection of controller parameters. Simulation results show that the controller achieves regulation and tracking respectively on the inverted pendulum and the kinematic bicycle, suggesting a potential in future control applications.

Paper number 62:
Title: Deadline-Aware Bandwidth Allocation for Semantic Generative Communication with Diffusion Models
Authors: Jinhyuk Choi, Jihong Park, Seungeun Oh, Seong-Lyun Kim
Abstract: The importance of Radio Access Network (RAN) in support Artificial Intelligence (AI) application services has grown significantly, underscoring the need for an integrated approach that considers not only network efficiency but also AI performance. In this paper we focus on a semantic generative communication (SGC) framework for image inpainting application. Specifically, the transmitter sends semantic information, i.e., semantic masks and textual descriptions, while the receiver utilizes a conditional diffusion model on a base image, using them as conditioning data to produce the intended image. In this framework, we propose a bandwidth allocation scheme designed to maximize bandwidth efficiency while ensuring generation performance. This approach is based on our finding of a Semantic Deadline--the minimum time that conditioning data is required to be injected to meet a given performance threshold--within the multi-modal SGC framework. Given this observation, the proposed scheme allocates limited bandwidth so that each semantic information can be transmitted within the corresponding semantic deadline. Experimental results corroborate that the proposed bandwidth allocation scheme achieves higher generation performance in terms of PSNR for a given bandwidth compared to traditional schemes that do not account for semantic deadlines.

Paper number 63:
Title: On the Gaussian Limit of the Output of IIR Filters
Authors: Yashaswini Murthy, Bassam Bamieh, R. Srikant
Abstract: We study the asymptotic distribution of the output of a stable Linear Time-Invariant (LTI) system driven by a non-Gaussian stochastic input. Motivated by longstanding heuristics in the stochastic describing function method, we rigorously characterize when the output process becomes approximately Gaussian, even when the input is not. Using the Wasserstein-1 distance as a quantitative measure of non-Gaussianity, we derive upper bounds on the distance between the appropriately scaled output and a standard normal distribution. These bounds are obtained via Stein's method and depend explicitly on the system's impulse response and the dependence structure of the input process. We show that when the dominant pole of the system approaches the edge of stability and the input satisfies one of the following conditions: (i) independence, (ii) positive correlation with a real and positive dominant pole, or (iii) sufficient correlation decay, the output converges to a standard normal distribution at rate $O(1/\sqrt{t})$. We also present counterexamples where convergence fails, thereby motivating the stated assumptions. Our results provide a rigorous foundation for the widespread observation that outputs of low-pass LTI systems tend to be approximately Gaussian.

Paper number 64:
Title: LLM-RIMSA: Large Language Models driven Reconfigurable Intelligent Metasurface Antenna Systems
Authors: Yunsong Huang, Hui-Ming Wang, Qingli Yan, Zhaowei Wang
Abstract: The evolution of 6G networks demands ultra-massive connectivity and intelligent radio environments, yet existing reconfigurable intelligent surface (RIS) technologies face critical limitations in hardware efficiency, dynamic control, and scalability. This paper introduces LLM-RIMSA, a transformative framework that integrates large language models (LLMs) with a novel reconfigurable intelligent metasurface antenna (RIMSA) architecture to address these challenges. Unlike conventional RIS designs, RIMSA employs parallel coaxial feeding and 2D metasurface integration, enabling each individual metamaterial element to independently adjust both its amplitude and phase. While traditional optimization and deep learning (DL) methods struggle with high-dimensional state spaces and prohibitive training costs for RIMSA control, LLM-RIMSA leverages pre-trained LLMs cross-modal reasoning and few-shot learning capabilities to dynamically optimize RIMSA configurations. Simulations demonstrate that LLM-RIMSA achieves state-of-the-art performance, outperforming conventional DL-based methods in sum rate while reducing training overhead. The proposed framework pave the way for LLM-driven intelligent radio environments.

Paper number 65:
Title: A Hierarchical Surrogate Model for Efficient Multi-Task Parameter Learning in Closed-Loop Contro
Authors: Sebastian Hirt, Lukas Theiner, Maik Pfefferkorn, Rolf Findeisen
Abstract: Many control problems require repeated tuning and adaptation of controllers across distinct closed-loop tasks, where data efficiency and adaptability are critical. We propose a hierarchical Bayesian optimization (BO) framework that is tailored to efficient controller parameter learning in sequential decision-making and control scenarios for distinct tasks. Instead of treating the closed-loop cost as a black-box, our method exploits structural knowledge of the underlying problem, consisting of a dynamical system, a control law, and an associated closed-loop cost function. We construct a hierarchical surrogate model using Gaussian processes that capture the closed-loop state evolution under different parameterizations, while the task-specific weighting and accumulation into the closed-loop cost are computed exactly via known closed-form expressions. This allows knowledge transfer and enhanced data efficiency between different closed-loop tasks. The proposed framework retains sublinear regret guarantees on par with standard black-box BO, while enabling multi-task or transfer learning. Simulation experiments with model predictive control demonstrate substantial benefits in both sample efficiency and adaptability when compared to purely black-box BO approaches.

Paper number 66:
Title: Range-Angle Likelihood Maps for Indoor Positioning Using Deep Neural Networks
Authors: Muhammad Ammad, Paul Schwarzbach, Michael Schultz, Oliver Michler
Abstract: Accurate and high precision of the indoor positioning is as important as ensuring reliable navigation in outdoor environments. Using the state-of-the-art deep learning models provides better reliability and accuracy to navigate and monitor the accurate positions in the aircraft cabin environment. We utilize the simulated aircraft cabin environment measurements and propose a residual neural network (ResNet) model to predict the accurate positions inside the cabin. The measurements include the ranges and angles between a tag and the anchors points which are then mapped onto a grid as range and angle residuals. These residual maps are then transformed into the likelihood grid maps where each cell of the grid shows the likelihood of being a true location. These grid maps along with the true positions are then passed as inputs to train the ResNet model. Since any deep learning model involve numerous parameter settings, hyperparameter optimization is performed to get the optimal parameters for training the model effectively with the highest accuracy. Once we get the best hyperparameters settings of the model, it is then trained to predict the positions which provides a centimeter-level accuracy of the localization.

Paper number 67:
Title: PFD or PDF: Rethinking the Probability of Failure in Mitigation Safety Functions
Authors: Hamid Jahanian
Abstract: SIL (Safety Integrity Level) allocation plays a crucial role in defining the design requirements for Safety Functions (SFs) within high-risk industries. SIL is typically determined based on the estimated Probability of Failure on Demand (PFD), which must remain within permissible limits to manage risk effectively. Extensive research has been conducted on determining target PFD and SIL, with a stronger emphasis on preventive SFs than on mitigation SFs. In this paper, we address a rather conceptual issue: we argue that PFD is not an appropriate reliability measure for mitigation SFs to begin with, and we propose an alternative approach that leverages the Probability Density Function (PDF) and the expected degree of failure as key metrics. The principles underlying this approach are explained and supported by detailed mathematical formulations. Furthermore, the practical application of this new methodology is illustrated through case studies.

Paper number 68:
Title: A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN
Authors: Mahdi Abdollahpour, Marco Bertuletti, Yichao Zhang, Yawei Li, Luca Benini, Alessandro Vanelli-Coralli
Abstract: Artificial intelligence approaches for base-band processing for radio receivers have demonstrated significant performance gains. Most of the proposed methods are characterized by high compute and memory requirements, hindering their deployment at the edge of the Radio Access Networks (RAN) and limiting their scalability to large bandwidths and many antenna 6G systems. In this paper, we propose a low-complexity, model-driven neural network-based receiver, designed for multi-user multiple-input multiple-output (MU-MIMO) systems and suitable for implementation at the RAN edge. The proposed solution is compliant with the 5G New Radio (5G NR), and supports different modulation schemes, bandwidths, number of users, and number of base-station antennas with a single trained model without the need for further training. Numerical simulations of the Physical Uplink Shared Channel (PUSCH) processing show that the proposed solution outperforms the state-of-the-art methods in terms of achievable Transport Block Error Rate (TBLER), while reducing the Floating Point Operations (FLOPs) by 66$\times$, and the learnable parameters by 396$\times$.

Paper number 69:
Title: Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization
Authors: Robin Trombetta, Carole Lartizien
Abstract: Unsupervised anomaly detection aims to detect defective parts of a sample by having access, during training, to a set of normal, i.e. defect-free, data. It has many applications in fields, such as industrial inspection or medical imaging, where acquiring labels is costly or when we want to avoid introducing biases in the type of anomalies that can be spotted. In this work, we propose a novel UAD method based on prototype learning and introduce a metric to compare a structured set of embeddings that balances a feature-based cost and a spatial-based cost. We leverage this metric to learn local and global prototypes with optimal transport from latent representations extracted with a pre-trained image encoder. We demonstrate that our approach can enforce a structural constraint when learning the prototypes, allowing to capture the underlying organization of the normal samples, thus improving the detection of incoherencies in images. Our model achieves performance that is on par with strong baselines on two reference benchmarks for anomaly detection on industrial images. The code is available at this https URL.

Paper number 70:
Title: Grid Edge Intelligence-Assisted Model Predictive Framework for Black Start of Distribution Systems with Inverter-Based Resources
Authors: Junyuan Zheng, Salish Maharjan, Zhaoyu Wang
Abstract: The growing proliferation of distributed energy resources (DERs) is significantly enhancing the resilience and reliability of distribution systems. However, a substantial portion of behind-the-meter (BTM) DERs is often overlooked during black start (BS) and restoration processes. Existing BS strategies that utilize grid-forming (GFM) battery energy storage systems (BESS) frequently ignore critical frequency security and synchronization constraints. To address these limitations, this paper proposes a predictive framework for bottom-up BS that leverages the flexibility of BTM DERs through Grid Edge Intelligence (GEI). A predictive model is developed for GEI to estimate multi-period flexibility ranges and track dispatch signals from the utility. A frequency-constrained BS strategy is then introduced, explicitly incorporating constraints on frequency nadir, rate-of-change-of-frequency (RoCoF), and quasi-steady-state (QSS) frequency. The framework also includes synchronizing switches to enable faster and more secure load restoration. Notably, it requires GEI devices to communicate only their flexibility ranges and the utility to send dispatch signals without exchanging detailed asset information. The proposed framework is validated using a modified IEEE 123-bus test system, and the impact of GEI is demonstrated by comparing results across various GEI penetration scenarios.

Paper number 71:
Title: Interference-Asymmetric UAV Remote Control Links: Measurements and Performance Evaluation
Authors: Donggu Lee, Sung Joon Maeng, Ozgur Ozdemir, Mani Bharathi Pandian, Ismail Guvenc
Abstract: Reliable and secure connectivity is crucial for remote control (RC) and uncrewed aerial vehicles (UAVs) links. A major problem for UAV RC links is that interference sources within the coverage may degrade the link quality. Such interference problems are a higher concern for the UAV than the RC unit on the ground due to the UAV being in line of sight (LoS) with a larger number of interference sources. As a result, lost hybrid automatic repeat request (HARQ) indicators (ACK/NACK) feedback in the uplink (UL, RC to UAV) may degrade the downlink (DL, UAV to RC) throughput. To get physical evidence for our interference asymmetry argument, we first conducted a measurement campaign using a helikite platform at the Main Campus area of NC State University during the 2024 Packapalooza festival. Subsequently, we evaluated the throughput impact of the loss of HARQ indicator feedback caused by UL asymmetry using MATLAB long-term-evolution (LTE) and fifth-generation (5G) toolboxes. Our numerical results confirm that UL interference asymmetry substantially degrades the throughput performance due to the loss of HARQ indicator feedback.

Paper number 72:
Title: A Novel CNN Based Standalone Detector for Faster-than-Nyquist Signaling
Authors: Osman Tokluoglu, Enver Cavus, Ebrahim Bedeer, Halim Yanikomeroglu
Abstract: This paper presents a novel convolutional neural network (CNN)-based detector for faster-than-Nyquist (FTN) signaling, introducing structured fixed kernel layers with domain-informed masking to effectively mitigate intersymbol interference (ISI). Unlike standard CNN architectures that rely on moving kernels, the proposed approach employs fixed convolutional kernels at predefined positions to explicitly learn ISI patterns at varying distances from the central symbol. To enhance feature extraction, a hierarchical filter allocation strategy is employed, assigning more filters to earlier layers for stronger ISI components and fewer to later layers for weaker components. This structured design improves feature representation, eliminates redundant computations, and enhances detection accuracy while maintaining computational efficiency. Simulation results demonstrate that the proposed detector achieves near-optimal bit error rate (BER) performance, comparable to the BCJR algorithm for the compression factor $\tau \geq 0.7$, while offering up to $46\%$ and $84\%$ computational cost reduction over M-BCJR for BPSK and QPSK, respectively. Additional evaluations confirm the method's adaptability to high-order modulations (up to 64-QAM), resilience in quasi-static multipath Rayleigh fading channels, and effectiveness under LDPC-coded FTN transmission, highlighting its robustness and practicality.

Paper number 73:
Title: Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with Transformer-Based Models
Authors: Branislav Gerazov, Marcello Politi, Sébastien Bratières
Abstract: We explore the performance of several state-of-the-art automatic speech recognition (ASR) models on a large-scale Arabic speech dataset, the SADA (Saudi Audio Dataset for Arabic), which contains 668 hours of high-quality audio from Saudi television shows. The dataset includes multiple dialects and environments, specifically a noisy subset that makes it particularly challenging for ASR. We evaluate the performance of the models on the SADA test set, and we explore the impact of fine-tuning, language models, as well as noise and denoising on their performance. We find that the best performing model is the MMS 1B model finetuned on SADA with a 4-gram language model that achieves a WER of 40.9\% and a CER of 17.6\% on the SADA test clean set.

Paper number 74:
Title: Revisiting Functional Derivatives in Multi-object Tracking
Authors: Jan Krejčí, Ondřej Straka, Petr Girg, Jiří Benedikt
Abstract: Probability generating functionals (PGFLs) are efficient and powerful tools for tracking independent objects in clutter. It was shown that PGFLs could be used for the elegant derivation of practical multi-object tracking algorithms, e.g., the probability hypothesis density (PHD) filter. However, derivations using PGFLs use the so-called functional derivatives whose definitions usually appear too complicated or heuristic, involving Dirac delta ``functions''. This paper begins by comparing different definitions of functional derivatives and exploring their relationships and implications for practical applications. It then proposes a rigorous definition of the functional derivative, utilizing straightforward yet precise mathematics for clarity. Key properties of the functional derivative are revealed and discussed.

Paper number 75:
Title: Wavefield Correlation Imaging in Arbitrary Media with Inherent Aberration Correction
Authors: Scott Schoen Jr, Brian Lause, Marko Jakovljevic, Rimon Tadross, Mike Washburn, Anthony E. Samir
Abstract: Ultrasound (US) imaging is an indispensable tool for diagnostic imaging, particularly given its cost, safety, and portability profiles compared to other modalities. However, US is challenged in subjects with morphological heterogeneity (e.g., those with overweight or obesity), largely because conventional imaging algorithms do not account for such variation in the beamforming process. Specific knowledge of the these spatial variations enables supplemental corrections of these algorithms, but with added computational complexity. Wavefield correlation imaging (WCI) enables efficient image formation in the spatial frequency domain that, in its canonical formulation, assumes a uniform medium. In this work, we present an extension of WCI to arbitrary known speed-of-sound distributions directly in the image formation process, and demonstrate its feasibility in silico, in vitro, and in vivo. We report resolution improvements of over 30% and contrast improvements of order 10% over conventional WCI imaging. Together our results suggest heterogeneous WCI (HWCI) may have high translational potential to improve the objective quality, and thus clinical utility, of ultrasound images.

Paper number 76:
Title: Low-complexity Leakage Minimization Beamforming for Large-scale Multi-user Cell-Free Massive MIMO
Authors: Iván Alexander Morales Sandoval, Getuar Rexhepi, Kengo Ando, Giuseppe Thadeu Freitas de Abreu
Abstract: We propose a low-complexity beamforming (BF) design for information leakage minimization in multi-user (MU) cell-free massive multiple-input multiple-output (CF-mMIMO) systems. Our approach leverages fractional programming (FP) to reformulate the secrecy rate maximization problem into a tractable difference-of-convex form. To efficiently solve the resulting non-convex problem, we employ the Concave-Convex Procedure (CCP), enabling fast convergence to a local optimum. Simulation results demonstrate that the proposed scheme achieves secrecy rates comparable to state-of-the-art (SotA) methods, while significantly reducing computational complexity and improving convergence speed.

Paper number 77:
Title: BeamSeek: Deep Learning-based DOA Estimation for Low-Complexity mmWave Phased Arrays
Authors: Arav Sharma, Lei Chi, Ari Gebhardt, Alon S. Levin, Timothy R. Hoerning, Sam Keene
Abstract: A novel approach combining agile beam switching with deep learning to enhance the speed and accuracy of Direction of Arrival (DOA) estimation for millimeter-wave (mmWave) phased array systems with low-complexity hardware implementations is proposed and evaluated. Traditional DOA methods requiring direct access to individual antenna elements are impractical for analog or hybrid beamforming systems prevalent in modern mmWave implementations. Recent agile beam switching techniques have demonstrated rapid DOA estimation, but their accuracy and robustness can be further improved via deep learning. BeamSeek addresses these limitations by employing a Multi-Layer Perceptron (MLP) and specialized data augmentation that emulates real-world propagation conditions. The proposed approach was experimentally validated at 60 GHz using the NSF PAWR COSMOS testbed, demonstrating significant improvements over a correlation-based method across various Signal-to-Noise Ratio (SNR) levels. Results show that BeamSeek achieves up to an 8 degree reduction in average estimation error compared to this baseline, with particular advantages in noisy channels. This makes it especially suitable for practical mmWave deployments in environments characterized by multipath interference and hardware constraints.

Paper number 78:
Title: From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion
Authors: Emmanuel Oladokun, Yuxuan Ou, Anna Novikova, Daria Kulikova, Sarina Thomas, Jurica Šprem, Vicente Grau
Abstract: Deep diffusion models excel at realistic image synthesis but demand large training sets-an obstacle in data-scarce domains like transesophageal echocardiography (TEE). While synthetic augmentation has boosted performance in transthoracic echo (TTE), TEE remains critically underrepresented, limiting the reach of deep learning in this high-impact modality. We address this gap by adapting a TTE-trained, mask-conditioned diffusion backbone to TEE with only a limited number of new cases and adapters as small as $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$, a lightweight remapping layer that aligns novel mask formats with the pretrained model's conditioning channels. This design lets users adapt models to new datasets with a different set of anatomical structures to the base model's original set. Through a targeted adaptation strategy, we find that adapting only MLP layers suffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real TEE frames with our synthetic echoes improves the dice score on a multiclass segmentation task, particularly boosting performance on underrepresented right-heart structures. Our results demonstrate that (1) semantically controlled TEE images can be generated with low overhead, (2) MaskR$^2$ effectively transforms unseen mask formats into compatible formats without damaging downstream task performance, and (3) our method generates images that are effective for improving performance on a downstream task of multiclass segmentation.

Paper number 79:
Title: Exploiting Convexity of Neural Networks in Dynamic Operating Envelope Optimization for Distributed Energy Resources
Authors: Hongyi Li, Liming Liu, Yunyi Li, Zhaoyu Wang
Abstract: The increasing penetration of distributed energy resources (DERs) brings opportunities and challenges to the operation of distribution systems. To ensure network integrity, dynamic operating envelopes (DOEs) are issued by utilities to DERs as their time-varying export/import power limits. Due to the non-convex nature of power flow equations, the optimization of DOEs faces a dilemma of solution accuracy and computation efficiency. To bridge this gap, in this paper, we facilitate DOE optimization by exploiting the convexity of input convex neural networks (ICNNs). A DOE optimization model is first presented, comprehensively considering multiple operational constraints. We propose a constraint embedding method that allows us to replace the non-convex power flow constraints with trained ICNN models and convexify the problem. To further speed up DOE optimization, we propose a linear relaxation of the ICNN-based DOE optimization problem, for which the tightness is theoretically proven. The effectiveness of the proposed method is validated with numerical case studies. Results show that the proposed ICNN-based method outperforms other benchmark methods in optimizing DOEs in terms of both solution quality and solution time.

Paper number 80:
Title: Prediction of Spotify Chart Success Using Audio and Streaming Features
Authors: Ian Jacob Cabansag, Paul Ntegeka
Abstract: Spotify's streaming charts offer a real-time lens into music popularity, driving discovery, playlists, and even revenue potential. Understanding what influences a song's rise in ranks on these charts-especially early on-can guide marketing efforts, investment decisions, and even artistic direction. In this project, we developed a classification pipeline to predict a song's chart success based on its musical characteristics and early engagement data. Using all 2024 U.S. Top 200 Spotify Daily Charts and the Spotify Web API, we built a dataset containing both metadata and audio features for 14,639 unique songs. The project was structured in two phases. First, we benchmarked four models: Logistic Regression, K Nearest Neighbors, Random Forest, and XGBoost-using a standard train-test split. In the second phase, we incorporated cross-validation, hyperparameter tuning, and detailed class-level evaluation to ensure robustness. Tree-based models consistently outperformed the rest, with Random Forest and XGBoost achieving macro F1-scores near 0.95 and accuracy around 97%. Even when stream count and rank history were excluded, models trained solely on audio attributes retained predictive power. These findings validate the potential of audio-based modeling in A&R scouting, playlist optimization, and hit forecasting-long before a track reaches critical mass.

Paper number 81:
Title: Stretchable and self-adhesive triboelectric sensor for real-time musculoskeletal monitoring and personalized recovery
Authors: Cai Lin, Yunyi Ding, Kai Lin, Ru Wang, Yichen Luo, Xiaofen Wu
Abstract: Recent advances in medical diagnostics have highlighted the importance of wearable technologies for continuous and real-time physiological monitoring. In this study, we introduce a flexible, self-powered triboelectric nanogenerator (MB-TENG) engineered from commercially available medical elastic bandages for biomechanical sensing during rehabilitation and gait analysis. Leveraging the porous and skin-friendly properties of the bandage combined with a PTFE film, the MB-TENG delivers robust electrical performance, achieving a peak open-circuit voltage (VOC) of 122~V, a short-circuit current (ISC) of 25~$\mu$A, and a transferred charge (QSC) of 110~nC, while maintaining long-term stability across 40{,}000 mechanical cycles. Its inherent self-adhesive property allows for multi-layer assembly without extra bonding agents, and mechanical stretching enhances output, enabling dual configurability. A stacked design further improves the power capacity, supporting applications in wearable medical electronics. The MB-TENG device seamlessly conforms to joint surfaces and foot regions, providing accurate detection of motion states and abnormal gait patterns. These features underscore the MB-TENG's potential as a low-cost, scalable platform for personalized rehabilitation, injury monitoring, and early musculoskeletal diagnosis.

Paper number 82:
Title: Music and Artificial Intelligence: Artistic Trends
Authors: Jordi Pons, Zack Zukowski, Julian D. Parker, CJ Carr, Josiah Taylor, Zach Evans
Abstract: We study how musicians use artificial intelligence (AI) across formats like singles, albums, performances, installations, voices, ballets, operas, or soundtracks. We collect 337 music artworks and categorize them based on AI usage: AI composition, co-composition, sound design, lyrics generation, and translation. We find that AI is employed as a co-creative tool, as an artistic medium, and in live performances and installations. Innovative uses of AI include exploring uncanny aesthetics, multilingual and multigenre song releases, and new formats such as online installations. This research provides a comprehensive overview of current AI music practices, offering insights into emerging artistic trends and the challenges faced by AI musicians.

Paper number 83:
Title: Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)
Authors: Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez
Abstract: Remote user verification in Internet-based applications is becoming increasingly important nowadays. A popular scenario for it consists of submitting a picture of the user's Identity Document (ID) to a service platform, authenticating its veracity, and then granting access to the requested digital service. An ID is well-suited to verify the identity of an individual, since it is government issued, unique, and nontransferable. However, with recent advances in Artificial Intelligence (AI), attackers can surpass security measures in IDs and create very realistic physical and synthetic fake IDs. Researchers are now trying to develop methods to detect an ever-growing number of these AI-based fakes that are almost indistinguishable from authentic (bona fide) IDs. In this counterattack effort, researchers are faced with an important challenge: the difficulty in using real data to train fake ID detectors. This real data scarcity for research and development is originated by the sensitive nature of these documents, which are usually kept private by the ID owners (the users) and the ID Holders (e.g., government, police, bank, etc.). The main contributions of our study are: 1) We propose and discuss a patch-based methodology to preserve privacy in fake ID detection research. 2) We provide a new public database, FakeIDet2-db, comprising over 900K real/fake ID patches extracted from 2,000 ID images, acquired using different smartphone sensors, illumination and height conditions, etc. In addition, three physical attacks are considered: print, screen, and composite. 3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We release a standard reproducible benchmark that considers physical and synthetic attacks from popular databases in the literature.

Paper number 84:
Title: Bayesian Learning for Pilot Decontamination in Cell-Free Massive MIMO
Authors: Christian Forsch, Zilu Zhao, Dirk Slock, Laura Cottatellucci
Abstract: Pilot contamination (PC) arises when the pilot sequences assigned to user equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In this work, we propose a novel expectation propagation (EP)-based joint channel estimation and data detection (JCD) algorithm specifically designed to mitigate the effects of PC in the uplink of cell-free massive multiple-input multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is distributed, scalable, demonstrates strong robustness to PC, and outperforms state-of-the-art Bayesian learning algorithms. Through a comprehensive performance evaluation, we assess the performance of Bayesian learning algorithms for different pilot sequences and observe that the use of non-orthogonal pilots can lead to better performance compared to shared orthogonal sequences. Motivated by this analysis, we introduce a new metric to quantify PC at the UE level. We show that the performance of the considered algorithms degrades monotonically with respect to this metric, providing a valuable theoretical and practical tool for understanding and managing PC via iterative JCD algorithms.

Paper number 85:
Title: Securing Sideways: Thwarting Lateral Movement by Implementing Active Directory Tiering
Authors: Tyler Schroder, Sohee Kim Park
Abstract: The advancement of computing equipment and the advances in services over the Internet has allowed corporations, higher education, and many other organizations to pursue the shared computing network environment. A requirement for shared computing environments is a centralized identity system to authenticate and authorize user access. An organization's digital identity plane is a prime target for cyber threat actors. When compromised, identities can be exploited to steal credentials, create unauthorized accounts, and manipulate permissions-enabling attackers to gain control of the network and undermine its confidentiality, availability, and integrity. Cybercrime losses reached a record of 16.6 B in the United States in 2024. For organizations using Microsoft software, Active Directory is the on-premises identity system of choice. In this article, we examine the challenge of security compromises in Active Directory (AD) environments and present effective strategies to prevent credential theft and limit lateral movement by threat actors. Our proposed approaches aim to confine the movement of compromised credentials, preventing significant privilege escalation and theft. We argue that through our illustration of real-world scenarios, tiering can halt lateral movement and advanced cyber-attacks, thus reducing ransom escalation. Our work bridges a gap in existing literature by combining technical guidelines with theoretical arguments in support of tiering, positioning it as a vital component of modern cybersecurity strategy even though it cannot function in isolation. As the hardware advances and the cloud sourced services along with AI is advancing with unprecedented speed, we think it is important for security experts and the business to work together and start designing and developing software and frameworks to classify devices automatically and accurately within the tiered structure.

Paper number 86:
Title: Recent Advances in Transformer and Large Language Models for UAV Applications
Authors: Hamza Kheddar, Yassine Habchi, Mohamed Chahine Ghanem, Mustapha Hemis, Dusit Niyato
Abstract: The rapid advancement of Transformer-based models has reshaped the landscape of uncrewed aerial vehicle (UAV) systems by enhancing perception, decision-making, and autonomy. This review paper systematically categorizes and evaluates recent developments in Transformer architectures applied to UAVs, including attention mechanisms, CNN-Transformer hybrids, reinforcement learning Transformers, and large language models (LLMs). Unlike previous surveys, this work presents a unified taxonomy of Transformer-based UAV models, highlights emerging applications such as precision agriculture and autonomous navigation, and provides comparative analyses through structured tables and performance benchmarks. The paper also reviews key datasets, simulators, and evaluation metrics used in the field. Furthermore, it identifies existing gaps in the literature, outlines critical challenges in computational efficiency and real-time deployment, and offers future research directions. This comprehensive synthesis aims to guide researchers and practitioners in understanding and advancing Transformer-driven UAV technologies.

Paper number 87:
Title: Optimality of Linear Policies in Distributionally Robust Linear Quadratic Control
Authors: Bahar Taşkesen, Dan A. Iancu, Çağıl Koçyiğit, Daniel Kuhn
Abstract: We study a generalization of the classical discrete-time, Linear-Quadratic-Gaussian (LQG) control problem where the noise distributions affecting the states and observations are unknown and chosen adversarially from divergence-based ambiguity sets centered around a known nominal distribution. For a finite horizon model with Gaussian nominal noise and a structural assumption on the divergence that is satisfied by many examples -- including 2-Wasserstein distance, Kullback-Leibler divergence, moment-based divergences, entropy-regularized optimal transport, or Fisher (score-matching) divergence -- we prove that a control policy that is affine in the observations is optimal and the adversary's corresponding worst-case optimal distribution is Gaussian. When the nominal means are zero (as in the classical LQG model), we show that the adversary should optimally set the distribution's mean to zero and the optimal control policy becomes linear. Moreover, the adversary should optimally ``inflate" the noise by choosing covariance matrices that dominate the nominal covariance in Loewner order. Exploiting these structural properties, we develop a Frank-Wolfe algorithm whose inner step solves standard LQG subproblems via Kalman filtering and dynamic programming and show that the implementation consistently outperforms semidefinite-programming reformulations of the problem. All structural and algorithmic results extend to an infinite-horizon, average-cost formulation, yielding stationary linear policies and a time-invariant Gaussian distribution for the adversary. Lastly, we show that when the divergence is 2-Wasserstein, the entire framework remains valid when the nominal distributions are elliptical rather than Gaussian.

Paper number 88:
Title: EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models
Authors: Wenhui Zhu, Xiwen Chen, Zhipeng Wang, Shao Tang, Sayan Ghosh, Xuanzhao Dong, Rajat Koner, Yalin Wang
Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in images or videos based on natural language instructions. While recent multimodal large language models (MLLMs) have achieved strong performance on IVS, their inference cost remains a major bottleneck, particularly in video. We empirically analyze visual token sampling in MLLMs and observe a strong correlation between subset token coverage and segmentation performance. This motivates our design of a simple and effective token pruning method that selects a compact yet spatially representative subset of tokens to accelerate inference. In this paper, we introduce a novel visual token pruning method for IVS, called EVTP-IV, which builds upon the k-center by integrating spatial information to ensure better coverage. We further provide an information-theoretic analysis to support our design. Experiments on standard IVS benchmarks show that our method achieves up to 5X speed-up on video tasks and 3.5X on image tasks, while maintaining comparable accuracy using only 20% of the tokens. Our method also consistently outperforms state-of-the-art pruning baselines under varying pruning ratios.

Paper number 89:
Title: Large Kernel Modulation Network for Efficient Image Super-Resolution
Authors: Quanwei Hu, Yinggan Tang, Xuguang Zhang
Abstract: Image super-resolution (SR) in resource-constrained scenarios demands lightweight models balancing performance and latency. Convolutional neural networks (CNNs) offer low latency but lack non-local feature capture, while Transformers excel at non-local modeling yet suffer slow inference. To address this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes channel shuffle to boost inter-channel interaction, incorporates channel attention to focus on key information, and applies large kernel strip convolutions on partial channels for non-local feature extraction with reduced complexity. The CGFN dynamically adjusts discrepancies between input, local, and non-local features via a learnable scaling factor, then employs a cross-gate strategy to modulate and fuse these features, enhancing their complementarity. Extensive experiments demonstrate that our method outperforms existing state-of-the-art (SOTA) lightweight SR models while balancing quality and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8 times faster. Codes are in the supplementary materials. The code is available at this https URL.

Paper number 90:
Title: Virtual Trading in Multi-Settlement Electricity Markets
Authors: Agostino Capponi, Garud Iyengar, Bo Yang, Daniel Bienstock
Abstract: In the Day-Ahead (DA) market, suppliers sell and load-serving entities (LSEs) purchase energy commitments, with both sides adjusting for imbalances between contracted and actual deliveries in the Real-Time (RT) market. We develop a supply function equilibrium model to study how virtual trading-speculating on DA-RT price spreads without physical delivery-affects market efficiency. Without virtual trading, LSEs underbid relative to actual demand in the DA market, pushing DA prices below expected RT prices. Virtual trading narrows, and in the limit of large number traders can eliminates, this price gap. However, it does not induce quantity alignment: DA-cleared demand remains below true expected demand, as price alignment makes the LSE indifferent between markets and prompts it to reduce DA bids to avoid over-purchasing. Renewable energy suppliers cannot offset these strategic distortions. We provide empirical support to our main model implications using data from the California and New York Independent System Operators.

Paper number 91:
Title: Active Fault Identification and Robust Control for Unknown Bounded Faults via Volume-Based Costs
Authors: Annalena Daniels, Johannes Teutsch, Fabian Kleindienst, Marion Leibold, Dirk Wollherr
Abstract: This paper proposes a novel framework for active fault diagnosis and parameter estimation in linear systems operating in closed-loop, subject to unknown but bounded faults. The approach integrates set-membership identification with a cost function designed to accelerate fault identification. Informative excitation is achieved by minimizing the size of the parameter uncertainty set, which is approximated using ellipsoidal outer bounds. Combining this formulation with a scheduling parameter enables a transition back to nominal control as confidence in the model estimates increases. Unlike many existing methods, the proposed approach does not rely on predefined fault models. Instead, it only requires known bounds on parameter deviations and additive disturbances. Robust constraint satisfaction is guaranteed through a tube-based model predictive control scheme. Simulation results demonstrate that the method achieves faster fault detection and identification compared to passive strategies and adaptive ones based on persistent excitation constraints.

Paper number 92:
Title: Means of Random Variables in Lie Groups
Authors: Shiraz Khan, Jikai Ye, Gregory S. Chirikjian
Abstract: The concepts of mean (i.e., average) and covariance of a random variable are fundamental in statistics, and are used to solve real-world problems such as those that arise in robotics, computer vision, and medical imaging. On matrix Lie groups, multiple competing definitions of the mean arise, including the Euclidean, projected, distance-based (i.e., Fréchet and Karcher), group-theoretic, and parametric means. This article provides a comprehensive review of these definitions, investigates their relationships to each other, and determines the conditions under which the group-theoretic means minimize a least-squares type cost function. We also highlight the dependence of these definitions on the choice of inner product on the Lie algebra. The goal of this article is to guide practitioners in selecting an appropriate notion of the mean in applications involving matrix Lie groups.

Paper number 93:
Title: Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing
Authors: Gokul Puthumanaillam, Aditya Penumarti, Manav Vora, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla, Jane Shin, Melkior Ornik
Abstract: Robots equipped with rich sensor suites can localize reliably in partially-observable environments, but powering every sensor continuously is wasteful and often infeasible. Belief-space planners address this by propagating pose-belief covariance through analytic models and switching sensors heuristically--a brittle, runtime-expensive approach. Data-driven approaches--including diffusion models--learn multi-modal trajectories from demonstrations, but presuppose an accurate, always-on state estimate. We address the largely open problem: for a given task in a mapped environment, which \textit{minimal sensor subset} must be active at each location to maintain state uncertainty \textit{just low enough} to complete the task? Our key insight is that when a diffusion planner is explicitly conditioned on a pose-belief raster and a sensor mask, the spread of its denoising trajectories yields a calibrated, differentiable proxy for the expected localisation error. Building on this insight, we present Belief-Conditioned One-Step Diffusion (B-COD), the first planner that, in a 10 ms forward pass, returns a short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for localisation error--eliminating external covariance rollouts. We show that this single proxy suffices for a soft-actor-critic to choose sensors online, optimising energy while bounding pose-covariance growth. We deploy B-COD in real-time marine trials on an unmanned surface vehicle and show that it reduces sensing energy consumption while matching the goal-reach performance of an always-on baseline.

Paper number 94:
Title: Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection
Authors: Bing Han, Anbai Jiang, Xinhu Zheng, Wei-Qiang Zhang, Jia Liu, Pingyi Fan, Yanmin Qian
Abstract: Machine anomalous sound detection (ASD) is a valuable technique across various applications. However, its generalization performance is often limited due to challenges in data collection and the complexity of acoustic environments. Inspired by the success of large pre-trained models in numerous fields, this paper introduces a robust ASD model that leverages self-supervised pre-trained models trained on large-scale speech and audio datasets. Although there are inconsistencies between the pre-training datasets and the ASD task, our findings indicate that pre-training still provides substantial benefits for ASD. To mitigate overfitting and retain learned knowledge when fine-tuning with limited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an alternative to full fine-tuning. Additionally, we propose a Machine-aware Group Adapter module, which enables the model to capture differences between various machines within a unified framework, thereby enhancing the generalization performance of ASD systems. To address the challenge of missing attribute labels, we design a novel objective function that dynamically clusters unattributed data using vector quantization and optimizes through a dual-level contrastive learning loss. The proposed methods are evaluated on all benchmark datasets, including the DCASE 2020-2024 five ASD challenges, and the experimental results show significant improvements of our new approach and demonstrate the effectiveness of our proposed strategies.

Paper number 95:
Title: Communication-Efficient Distributed Asynchronous ADMM
Authors: Sagar Shrestha
Abstract: In distributed optimization and federated learning, asynchronous alternating direction method of multipliers (ADMM) serves as an attractive option for large-scale optimization, data privacy, straggler nodes and variety of objective functions. However, communication costs can become a major bottleneck when the nodes have limited communication budgets or when the data to be communicated is prohibitively large. In this work, we propose introducing coarse quantization to the data to be exchanged in aynchronous ADMM so as to reduce communication overhead for large-scale federated learning and distributed optimization applications. We experimentally verify the convergence of the proposed method for several distributed learning tasks, including neural networks.

Paper number 96:
Title: What do Speech Foundation Models Learn? Analysis and Applications
Authors: Ankita Pasad
Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose representations for a wide range of speech-processing tasks. The last five years have seen an influx of increasingly successful self-supervised and supervised pre-trained models with impressive performance on various downstream tasks. Although the zoo of SFMs continues to grow, our understanding of the knowledge they acquire lags behind. This thesis presents a lightweight analysis framework using statistical tools and training-free tasks to investigate the acoustic and linguistic knowledge encoded in SFM layers. We conduct a comparative study across multiple SFMs and statistical tools. Our study also shows that the analytical insights have concrete implications for downstream task performance. The effectiveness of an SFM is ultimately determined by its performance on speech applications. Yet it remains unclear whether the benefits extend to spoken language understanding (SLU) tasks that require a deeper understanding than widely studied ones, such as speech recognition. The limited exploration of SLU is primarily due to a lack of relevant datasets. To alleviate that, this thesis contributes tasks, specifically spoken named entity recognition (NER) and named entity localization (NEL), to the Spoken Language Understanding Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded (speech recognition followed by a text model) approaches. Further, we evaluate E2E SLU models across SFMs and adaptation strategies to assess the impact on task performance. Collectively, this thesis tackles previously unanswered questions about SFMs, providing tools and datasets to further our understanding and to enable the community to make informed design choices for future model development and adoption.

Paper number 97:
Title: HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization
Authors: Hyebin Ahn, Kangwook Jang, Hoirin Kim
Abstract: Noise robustness in speech foundation models (SFMs) has been a critical challenge, as most models are primarily trained on clean data and experience performance degradation when the models are exposed to noisy speech. To address this issue, we propose HuBERT-VIC, a noise-robust SFM with variance, in-variance, and covariance regularization (VICReg) objectives. These objectives adjust the statistics of noisy speech representations, enabling the model to capture diverse acoustic characteristics and improving the generalization ability across different types of noise. When applied to HuBERT, our model shows relative performance improvements of 23.3% on LibriSpeech test-clean and 13.2% on test-other, compared to the baseline model pre-trained on noisy speech.

Paper number 98:
Title: CarelessWhisper: Turning Whisper into a Causal Streaming Model
Authors: Tomer Krichli, Bhiksha Raj, Joseph Keshet
Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA) performance in offline transcription. However, these models are not designed for streaming (online or real-time) transcription, due to limitations in their architecture and training methodology. We propose a method to turn the transformer encoder-decoder model into a low-latency streaming model that is careless about future context. We present an analysis explaining why it is not straightforward to convert an encoder-decoder transformer to a low-latency streaming model. Our proposed method modifies the existing (non-causal) encoder to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated inference mechanism that utilizes the fine-tune causal encoder and decoder to yield greedy and beam-search decoding, and is shown to be locally optimal. Experiments on low-latency chunk sizes (less than 300 msec) show that our fine-tuned model outperforms existing non-fine-tuned streaming approaches in most cases, while using a lower complexity. Additionally, we observe that our training process yields better alignment, enabling a simple method for extracting word-level timestamps. We release our training and inference code, along with the fine-tuned models, to support further research and development in streaming ASR.

Paper number 99:
Title: Semi-Infinite Programming for Collision-Avoidance in Optimal and Model Predictive Control
Authors: Yunfan Gao, Florian Messerer, Niels van Duijkeren, Rashmi Dabir, Moritz Diehl
Abstract: This paper presents a novel approach for collision avoidance in optimal and model predictive control, in which the environment is represented by a large number of points and the robot as a union of padded polygons. The conditions that none of the points shall collide with the robot can be written in terms of an infinite number of constraints per obstacle point. We show that the resulting semi-infinite programming (SIP) optimal control problem (OCP) can be efficiently tackled through a combination of two methods: local reduction and an external active-set method. Specifically, this involves iteratively identifying the closest point obstacles, determining the lower-level distance minimizer among all feasible robot shape parameters, and solving the upper-level finitely-constrained subproblems. In addition, this paper addresses robust collision avoidance in the presence of ellipsoidal state uncertainties. Enforcing constraint satisfaction over all possible uncertainty realizations extends the dimension of constraint infiniteness. The infinitely many constraints arising from translational uncertainty are handled by local reduction together with the robot shape parameterization, while rotational uncertainty is addressed via a backoff reformulation. A controller implemented based on the proposed method is demonstrated on a real-world robot running at 20Hz, enabling fast and collision-free navigation in tight spaces. An application to 3D collision avoidance is also demonstrated in simulation.

Paper number 100:
Title: PUB: A Plasma-Propelled Ultra-Quiet Blimp with Two-DOF Vector Thrusting
Authors: Zihan Wang
Abstract: This study presents the design and control of a Plasma-propelled Ultra-silence Blimp (PUB), a novel aerial robot employing plasma vector propulsion for ultra-quiet flight without mechanical propellers. The system utilizes a helium-lift platform for extended endurance and a four-layer ring asymmetric capacitor to generate ionic wind thrust. The modular propulsion units allow flexible configuration to meet mission-specific requirements, while a two-degree-of-freedom (DOF) head enables thrust vector control. A closed-loop slip control scheme is implemented for stable maneuvering. Flight experiments demonstrate full-envelope capability, including take-off, climb, hover, descent, and smooth landing, confirming the feasibility of plasma vector propulsion, the effectiveness of DOF vector control, and the stability of the control system. Owing to its low acoustic signature, structural simplicity, and high maneuverability, PUB is well suited for noise-sensitive, enclosed, and near-space applications.

Paper number 101:
Title: Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework
Authors: Lida Shahbandari, Hossein Mohseni
Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index (BIS), keeping it within the ideal range of forty to sixty. The FOFPID controller combines fuzzy logic for adapting to changes and fractional order dynamics for fine tuning. This allows it to adjust its control gains to handle a person's unique physiology. The WOA helps fine tune the controller's parameters, including the fractional orders and the fuzzy membership functions, which boosts its performance. Tested on models of eight different patient profiles, the FOFPID controller performed better than a standard Fractional Order PID (FOPID) controller. It achieved faster settling times, at two and a half minutes versus three point two minutes, and had a lower steady state error, at zero point five versus one point two. These outcomes show the FOFPID's excellent strength and accuracy. It offers a scalable, artificial intelligence driven solution for automated anesthesia delivery that could enhance clinical practice and improve patient results.

Paper number 102:
Title: Graphon Mean-Field Logit Dynamic: Derivation, Computation, and Applications
Authors: H. Yoshioka
Abstract: We present a graphon mean-field logit dynamic, a stationary mean-field game based on logit interactions. This dynamic emerges from a stochastic control problem involving a continuum of nonexchangeable and interacting agents and reduces to solving a continuum of Hamilton-Jacobi-Bellman (HJB) equations connected through a graphon that models the connections among agents. Using a fixed-point argument, we prove that this HJB system admits a unique solution in the space of bounded functions when the discount rate is high (i.e., agents are myopic). Under certain assumptions, we also establish regularity properties of the system, such as equi-continuity. We propose a finite difference scheme for computing the HJB system and prove the uniqueness and existence of its numerical solutions. The mean-field logit dynamic is applied to a case study on inland fisheries resource management in the upper Tedori River of Japan. A series of computational cases are then conducted to investigate the dependence of the dynamic on both the discount rate and graphon.

Paper number 103:
Title: BUILDA: A Thermal Building Data Generation Framework for Transfer Learning
Authors: Thomas Krug, Fabian Raisch, Dominik Aimer, Markus Wirnsberger, Ferdinand Sigg, Benjamin Schäfer, Benjamin Tischler
Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal dynamics. Therefore, many new TL research areas emerge in the field, such as selecting the right source model for TL. However, these research directions require massive amounts of thermal building data which is lacking presently. Neither public datasets nor existing data generators meet the needs of TL research in terms of data quality and quantity. Moreover, existing data generation approaches typically require expert knowledge in building simulation. We present BuilDa, a thermal building data generation framework for producing synthetic data of adequate quality and quantity for TL research. The framework does not require profound building simulation knowledge to generate large volumes of data. BuilDa uses a single-zone Modelica model that is exported as a Functional Mock-up Unit (FMU) and simulated in Python. We demonstrate BuilDa by generating data and utilizing it for pretraining and fine-tuning TL models.

Paper number 104:
Title: MCTR: Midpoint Corrected Triangulation for Autonomous Racing via Digital Twin Simulation in CARLA
Authors: Junhao Ye, Cheng Hu, Yiqin Wang, Weizhan Huang, Nicolas Baumann, Jie He, Meixun Qu, Lei Xie, Hongye Su
Abstract: In autonomous racing, reactive controllers eliminate the computational burden of the full See-Think-Act autonomy stack by directly mapping sensor inputs to control actions. This bypasses the need for explicit localization and trajectory planning. A widely adopted baseline in this category is the Follow-The-Gap method, which performs trajectory planning using LiDAR data. Building on FTG, the Delaunay Triangulation-based Racing algorithm introduces further enhancements. However, DTR's use of circumcircles for trajectory generation often results in insufficiently smooth paths, ultimately degrading performance. Additionally, the commonly used F1TENTH-simulator for autonomous racing competitions lacks support for 3D LiDAR perception, limiting its effectiveness in realistic testing. To address these challenges, this work proposes the MCTR algorithm. MCTR improves trajectory smoothness through the use of Curvature Corrected Moving Average and implements a digital twin system within the CARLA simulator to validate the algorithm's robustness under 3D LiDAR perception. The proposed algorithm has been thoroughly validated through both simulation and real-world vehicle experiments.

Paper number 105:
Title: On the Importance of Behavioral Nuances: Amplifying Non-Obvious Motor Noise Under True Empirical Considerations May Lead to Briefer Assays and Faster Classification Processes
Authors: Theodoros Bermperidis, Joe Vero, Elizabeth B Torres
Abstract: There is a tradeoff between attaining statistical power with large, difficult to gather data sets, and producing highly scalable assays that register brief data samples. Often, as grand-averaging techniques a priori assume normally-distributed parameters and linear, stationary processes in biorhythmic, time series data, important information is lost, averaged out as gross data. We developed an affective computing platform that enables taking brief data samples while maintaining personalized statistical power. This is achieved by combining a new data type derived from the micropeaks present in time series data registered from brief (5-second-long) face videos with recent advances in AI-driven face-grid estimation methods. By adopting geometric and nonlinear dynamical systems approaches to analyze the kinematics, especially the speed data, the new methods capture all facial micropeaks. These include as well the nuances of different affective micro expressions. We offer new ways to differentiate dynamical and geometric patterns present in autistic individuals from those found more commonly in neurotypical development.

Paper number 106:
Title: [Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise
Authors: Imran Khan
Abstract: The notion of homeostasis typically conceptualises biological and artificial systems as maintaining stability by resisting deviations caused by environmental and social perturbations. In contrast, (social) allostasis proposes that these systems can proactively leverage these very perturbations to reconfigure their regulatory parameters in anticipation of environmental demands, aligning with von Foerster's ``order through noise'' principle. This paper formulates a computational model of allostatic and social allostatic regulation that employs biophysiologically inspired signal transducers, analogous to hormones like cortisol and oxytocin, to encode information from both the environment and social interactions, which mediate this dynamic reconfiguration. The models are tested in a small society of ``animats'' across several dynamic environments, using an agent-based model. The results show that allostatic and social allostatic regulation enable agents to leverage environmental and social ``noise'' for adaptive reconfiguration, leading to improved viability compared to purely reactive homeostatic agents. This work offers a novel computational perspective on the principles of social allostasis and their potential for designing more robust, bio-inspired, adaptive systems

Paper number 107:
Title: Sufficient A Priori Conditions for the Linear Relaxation of the Energy Storage Scheduling Problem
Authors: Eléa Prat, Richard Martin Lusby, Pierre Pinson
Abstract: When modeling energy storage systems, an essential question is how to account for the physical infeasibility of simultaneous charge and discharge. The use of complementarity constraints or of binary variables is common, but these formulations do not scale well. Alternatively, assumptions such as perfect efficiencies or positive prices are often used to justify the choice of a linear model. In this paper, we establish new a priori conditions that guarantee the existence of an optimal solution without simultaneous charge and discharge when solving the linear relaxation of the storage scheduling problem. They are based on the characteristics of the storage system, in particular, the duration of charge. They can be valid for negative prices and with inefficiencies, thereby enlarging the set of conditions for which the complementarity constraints can be relaxed. We prove mathematically the validity of these conditions and illustrate them with practical examples. We also introduce a refined mixed-integer linear equivalent, in which the number of binary variables can be drastically reduced.

Paper number 108:
Title: XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads
Authors: Tejas Chaudhari, Akarsh J., Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma
Abstract: This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural Processing Engine, designed for extended reality (XR) perception workloads like visual inertial odometry (VIO), object classification, and eye gaze extraction. XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1) formats, with layer adaptive hybrid-algorithmic implementation supporting ultra-low bit precision to significantly reduce memory bandwidth requirements, and accompanied by quantization-aware training for minimal accuracy loss. The proposed Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted by selective power gating to reduce energy consumption, providing 2.85x improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of 1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm, reducing 42% area, 38% power compared to the best of state-of-the-art MAC approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x better energy efficiency compared to SoTA accelerators on VCU129. The proposed co-processor provides 23% better energy efficiency and 4% better compute density for VIO workloads. XR-NPE establishes itself as a scalable, precision-adaptive compute engine for future resource-constrained XR devices. The complete set for codes for results reproducibility are released publicly, enabling designers and researchers to readily adopt and build upon them. this https URL.

Paper number 109:
Title: Hybrid Deep Reconstruction for Vignetting-Free Upconversion Imaging through Scattering in ENZ Materials
Authors: Hao Zhang, Yang Xu, Wenwen Zhang, Saumya Choudhary, M. Zahirul Alam, Long D. Nguyen, Matthew Klein, Shivashankar Vangala, J. Keith Miller, Eric G. Johnson, Joshua R. Hendrickson, Robert W. Boyd, Sergio Carbajo
Abstract: Optical imaging through turbid or heterogeneous environments (collectively referred to as complex media) is fundamentally challenged by scattering, which scrambles structured spatial and phase information. To address this, we propose a hybrid-supervised deep learning framework to reconstruct high-fidelity images from nonlinear scattering measurements acquired with a time-gated epsilon-near-zero (ENZ) imaging system. The system leverages four-wave mixing (FWM) in subwavelength indium tin oxide (ITO) films to temporally isolate ballistic photons, thus rejecting multiply scattered light and enhancing contrast. To recover structured features from these signals, we introduce DeepTimeGate, a U-Net-based supervised model that performs initial reconstruction, followed by a Deep Image Prior (DIP) refinement stage using self-supervised learning. Our approach demonstrates strong performance across different imaging scenarios, including binary resolution patterns and complex vortex-phase masks, under varied scattering conditions. Compared to raw scattering inputs, it boosts average PSNR by 124%, SSIM by 231%, and achieves a 10 times improvement in intersection-over-union (IoU). Beyond enhancing fidelity, our method removes the vignetting effect and expands the effective field-of-view compared to the ENZ-based optical time gate output. These results suggest broad applicability in biomedical imaging, in-solution diagnostics, and other scenarios where conventional optical imaging fails due to scattering.

Paper number 110:
Title: Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors
Authors: Yuying Zhang, Joni Pajarinen
Abstract: Mobile manipulation in dynamic environments is challenging due to movable obstacles blocking the robot's path. Traditional methods, which treat navigation and manipulation as separate tasks, often fail in such 'manipulate-to-navigate' scenarios, as obstacles must be removed before navigation. In these cases, active interaction with the environment is required to clear obstacles while ensuring sufficient space for movement. To address the manipulate-to-navigate problem, we propose a reinforcement learning-based approach for learning manipulation actions that facilitate subsequent navigation. Our method combines manipulability priors to focus the robot on high manipulability body positions with affordance maps for selecting high-quality manipulation actions. By focusing on feasible and meaningful actions, our approach reduces unnecessary exploration and allows the robot to learn manipulation strategies more effectively. We present two new manipulate-to-navigate simulation tasks called Reach and Door with the Boston Dynamics Spot robot. The first task tests whether the robot can select a good hand position in the target area such that the robot base can move effectively forward while keeping the end effector position fixed. The second task requires the robot to move a door aside in order to clear the navigation path. Both of these tasks need first manipulation and then navigating the base forward. Results show that our method allows a robot to effectively interact with and traverse dynamic environments. Finally, we transfer the learned policy to a real Boston Dynamics Spot robot, which successfully performs the Reach task.

Paper number 111:
Title: Interpretable and Robust AI in EEG Systems: A Survey
Authors: Xinliang Zhou, Chenyu Liu, Jinan Zhou, Zhongruo Wang, Liming Zhai, Ziyu Jia, Cuntai Guan, Yang Liu
Abstract: The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it into three types: backpropagation, perturbation, and inherently interpretable methods. Then we classify the robustness mechanisms into four classes: noise and artifacts, human variability, data acquisition instability, and adversarial attacks. Finally, we identify several critical and unresolved challenges for interpretable and robust AI in EEG systems and further discuss their future directions.

Paper number 112:
Title: Self-Tuning PID Control via a Hybrid Actor-Critic-Based Neural Structure for Quadcopter Control
Authors: Iman Sharifi, Aria Alasty
Abstract: Proportional-Integrator-Derivative (PID) controller is used in a wide range of industrial and experimental processes. There are a couple of offline methods for tuning PID gains. However, due to the uncertainty of model parameters and external disturbances, real systems such as Quadrotors need more robust and reliable PID controllers. In this research, a self-tuning PID controller using a Reinforcement-Learning-based Neural Network for attitude and altitude control of a Quadrotor has been investigated. An Incremental PID, which contains static and dynamic gains, has been considered and only the variable gains have been tuned. To tune dynamic gains, a model-free actor-critic-based hybrid neural structure was used that was able to properly tune PID gains, and also has done the best as an identifier. In both tunning and identification tasks, a Neural Network with two hidden layers and sigmoid activation functions has been learned using Adaptive Momentum (ADAM) optimizer and Back-Propagation (BP) algorithm. This method is online, able to tackle disturbance, and fast in training. In addition to robustness to mass uncertainty and wind gust disturbance, results showed that the proposed method had a better performance when compared to a PID controller with constant gains.

Paper number 113:
Title: Learning Zero-Sum Linear Quadratic Games with Improved Sample Complexity and Last-Iterate Convergence
Authors: Jiduan Wu, Anas Barakat, Ilyas Fatkhullin, Niao He
Abstract: Zero-sum Linear Quadratic (LQ) games are fundamental in optimal control and can be used (i)~as a dynamic game formulation for risk-sensitive or robust control and (ii)~as a benchmark setting for multi-agent reinforcement learning with two competing agents in continuous state-control spaces. In contrast to the well-studied single-agent linear quadratic regulator problem, zero-sum LQ games entail solving a challenging nonconvex-nonconcave min-max problem with an objective function that lacks coercivity. Recently, Zhang et al. showed that an~$\epsilon$-Nash equilibrium (NE) of finite horizon zero-sum LQ games can be learned via nested model-free Natural Policy Gradient (NPG) algorithms with poly$(1/\epsilon)$ sample complexity. In this work, we propose a simpler nested Zeroth-Order (ZO) algorithm improving sample complexity by several orders of magnitude and guaranteeing convergence of the last iterate. Our main results are two-fold: (i) in the deterministic setting, we establish the first global last-iterate linear convergence result for the nested algorithm that seeks NE of zero-sum LQ games; (ii) in the model-free setting, we establish a~$\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity using a single-point ZO estimator. For our last-iterate convergence results, our analysis leverages the Implicit Regularization (IR) property and a new gradient domination condition for the primal function. Our key improvements in the sample complexity rely on a more sample-efficient nested algorithm design and a finer control of the ZO natural gradient estimation error utilizing the structure endowed by the finite-horizon setting.

Paper number 114:
Title: Massive MIMO-ISAC System With 1-Bit ADCs/DACs
Authors: Bowen Wang, Hongyu Li, Bin Liao, Ziyang Cheng
Abstract: This paper investigates a hardware-efficient massive multiple-input multiple-output integrated sensing and communication (MIMO-ISAC) system with 1-bit analog-to-digital converters (ADCs)/digital-to-analog converters (DACs). The proposed system, referred to as 1BitISAC, employs 1-bit DACs at the ISAC transmitter and 1-bit ADCs at the sensing receiver, achieving significant reductions in power consumption and hardware costs. For such kind of systems, two 1BitISAC joint transceiver designs, i.e., i) quality of service constrained 1BitISAC design and ii) quality of detection constrained design, are considered and the corresponding problems are formulated. In order to address these problems, we thoroughly analyze the radar detection performance after 1-bit ADCs quantization and the communication bit error rate. This analysis yields new design insights and leads to unique radar and communication metrics, which enables us to simplify the original problems and employ majorization-minimization and integer linear programming methods to solve the problems. Numerical results are provided to validate the performance analysis of the proposed 1BitISAC and to compare with other ISAC configurations. The superiority of the proposed 1BitISAC system in terms of balancing ISAC performance and energy efficiency is also demonstrated.

Paper number 115:
Title: Online Identification of Time-Varying Systems Using Excitation Sets and Change Point Detection
Authors: Chi Ho Leung, Ashish R. Hota, Philip E. Paré
Abstract: In this work, we first show that the problem of parameter identification is often ill-conditioned and lacks the persistence of excitation required for the convergence of online learning schemes. To tackle these challenges, we introduce the notion of optimal and greedy excitation sets which contain data points with sufficient richness to aid in the identification task. We then present the greedy excitation set-based recursive least squares algorithm to alleviate the problem of the lack of persistent excitation, and prove that the iterates generated by the proposed algorithm minimize an auxiliary weighted least squares cost function. When data points are generated from time-varying parameters, online estimators tend to underfit the true parameter trajectory, and their predictability deteriorates. To tackle this problem, we propose a memory resetting scheme leveraging change point detection techniques. Finally, we illustrate the performance of the proposed algorithms via several numerical case studies to learn the (time-varying) parameters of networked epidemic dynamics, and compare it with results obtained using conventional approaches.

Paper number 116:
Title: Formal Verification and Control with Conformal Prediction
Authors: Lars Lindemann, Yiqi Zhao, Xinyi Yu, George J. Pappas, Jyotirmoy V. Deshmukh
Abstract: We present recent advances in formal verification and control for autonomous systems with practical safety guarantees enabled by conformal prediction (CP), a statistical tool for uncertainty quantification. This survey is particularly motivated by learning-enabled autonomous systems (LEASs), where the complexity of learning-enabled components (LECs) poses a major bottleneck for applying traditional model-based verification and control techniques. To address this challenge, we advocate for CP as a lightweight alternative and demonstrate its use in formal verification, systems and control, and robotics. CP is appealing due to its simplicity (easy to understand, implement, and adapt), generality (requires no assumptions on learned models and underlying data distributions), and efficiency (real-time capable and accurate). This survey provides an accessible introduction to CP for non-experts interested in applying CP to autonomy problems. We particularly show how CP can be used for formal verification of LECs and the design of safe control as well as offline and online verification algorithms for LEASs. We present these techniques within a unifying framework that addresses the complexity of LEASs. Our exposition spans simple specifications, such as robot navigation tasks, to complex mission requirements expressed in temporal logic. Throughout the survey, we contrast CP with other statistical techniques, including scenario optimization and PAC-Bayes theory, highlighting advantages and limitations for verification and control. Finally, we outline open problems and promising directions for future research.

Paper number 117:
Title: Open-/Closed-loop Active Learning for Data-driven Predictive Control
Authors: Shilun Feng, Dawei Shi, Yang Shi, Kaikai Zheng
Abstract: An important question in data-driven control is how to obtain an informative dataset. In this work, we consider the problem of effective data acquisition of an unknown linear system with bounded disturbance for both open-loop and closed-loop stages. The learning objective is to minimize the volume of the set of admissible systems. First, a performance measure based on historical data and the input sequence is introduced to characterize the upper bound of the volume of the set of admissible systems. On the basis of this performance measure, an open-loop active learning strategy is proposed to minimize the volume by actively designing inputs during the open-loop stage. For the closed-loop stage, a closed-loop active learning strategy is designed to select and learn from informative closed-loop data. The efficiency of the proposed closed-loop active learning strategy is proved by showing that the unselected data cannot benefit the learning performance. Furthermore, an adaptive predictive controller is designed in accordance with the proposed data acquisition approach. The recursive feasibility and the stability of the controller are proved by analyzing the effect of the closed-loop active learning strategy. Finally, numerical examples and comparisons illustrate the effectiveness of the proposed data acquisition strategy.

Paper number 118:
Title: A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems
Authors: Gregorio Marchesini, Siyuan Liu, Lars Lindemann, Dimos V. Dimarogonas
Abstract: We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each other's states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasks' satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition.

Paper number 119:
Title: Transforming Blood Cell Detection and Classification with Advanced Deep Learning Models: A Comparative Study
Authors: Shilpa Choudhary, Sandeep Kumar, Pammi Sri Siddhaarth, Guntu Charitasri
Abstract: Efficient detection and classification of blood cells are vital for accurate diagnosis and effective treatment of blood disorders. This study utilizes a YOLOv10 model trained on Roboflow data with images resized to 640x640 pixels across varying epochs. The results show that increased training epochs significantly enhance accuracy, precision, and recall, particularly in real-time blood cell detection & classification. The YOLOv10 model outperforms MobileNetV2, ShuffleNetV2, and DarkNet in real-time performance, though MobileNetV2 and ShuffleNetV2 are more computationally efficient, and DarkNet excels in feature extraction for blood cell classification. This research highlights the potential of integrating deep learning models like YOLOv10, MobileNetV2, ShuffleNetV2, and DarkNet into clinical workflows, promising improvements in diagnostic accuracy and efficiency. Additionally, a new, well-annotated blood cell dataset was created and will be open-sourced to support further advancements in automatic blood cell detection and classification. The findings demonstrate the transformative impact of these models in revolutionizing medical diagnostics and enhancing blood disorder management

Paper number 120:
Title: Joint Power and Spectrum Orchestration for D2D Semantic Communication Underlying Energy-Efficient Cellular Networks
Authors: Le Xia, Yao Sun, Haijian Sun, Rose Qingyang Hu, Dusit Niyato, Muhammad Ali Imran
Abstract: Semantic communication (SemCom) has been recently deemed a promising next-generation wireless technique to enable efficient spectrum savings and information exchanges, thus naturally introducing a novel and practical network paradigm where cellular and device-to-device (D2D) SemCom approaches coexist. Nevertheless, the involved wireless resource management becomes complicated and challenging due to the unique semantic performance measurements and energy-consuming semantic coding mechanism. To this end, this paper jointly investigates power control and spectrum reuse problems for energy-efficient D2D SemCom cellular networks. Concretely, we first model the user preference-aware semantic triplet transmission and leverage a novel metric of semantic value to identify the semantic information importance conveyed in SemCom. Then, we define the additional power consumption from semantic encoding in conjunction with basic power amplifier dissipation to derive the overall system energy efficiency (semantic-value/Joule). Next, we formulate an energy efficiency maximization problem for joint power and spectrum allocation subject to several SemCom-related and practical constraints. Afterward, we propose an optimal resource management solution by employing the fractional-to-subtractive problem transformation and decomposition while developing a three-stage method with theoretical analysis of its optimality guarantee and computational complexity. Numerical results demonstrate the adequate performance superiority of our proposed solution compared with different benchmarks.

Paper number 121:
Title: Efficient Sampling Allocation Strategies for General Graph-Filter-Based Signal Recovery
Authors: Lital Dabush, Tirza Routtenberg
Abstract: Sensor placement plays a crucial role in graph signal recovery in underdetermined systems. In this paper, we present the graph-filtered regularized maximum likelihood (GFR-ML) estimator of graph signals, which integrates general graph filtering with regularization to enhance signal recovery performance under a limited number of sensors. Then, we investigate task-based sampling allocation aimed at minimizing the mean squared error (MSE) of the GFR-ML estimator by wisely choosing sensor placement. Since this MSE depends on the unknown graph signals to be estimated, we propose four cost functions for the optimization of the sampling allocation: the biased Cram$\acute{\text{e}}$r-Rao bound (bCRB), the worst-case MSE (WC-MSE), the Bayesian MSE (BMSE), and the worst-case BMSE (WC-BMSE), where the last two assume a Gaussian prior. We investigate the properties of these cost functions and develop two algorithms for their practical implementation: 1) the straightforward greedy algorithm; and 2) the alternating projection gradient descent (PGD) algorithm that reduces the computational complexity. Simulation results on synthetic and real-world datasets of the IEEE 118-bus power system and the Minnesota road network demonstrate that, in the tested scenarios, the proposed sampling allocation methods reduce the MSE by up to $50\%$ compared to the common sampling methods A-design, E-design, and LR-design. Thus, the proposed methods improve the estimation performance and reduce the required number of measurements in graph signal processing (GSP)-based signal recovery in the case of underdetermined systems.

Paper number 122:
Title: Optical Wireless Ether: Enabling Controlled Dynamic Signal Propagation in OWC Systems
Authors: Hongwei Cui, Soung Chang Liew
Abstract: Optical wireless communication (OWC) leverages the terahertz-scale optical spectrum to enable ultra-fast data transfer, offering a compelling alternative to often-congested radio frequency systems. However, the highly directional nature of optical signals and their susceptibility to obstruction inherently limit coverage and reliability, particularly in dynamic indoor environments. To overcome these limitations, we propose optical wireless ether (OWE), a novel framework that transforms indoor spaces into a dynamically controllable optical propagation medium. OWE employs a distributed network of ether amplifiers (EAs), which act as optical amplifiers with programmable gain values to extend coverage through diffuse reflections while compensating for signal attenuation. A key challenge in OWE is preventing amplifier saturation from feedback loops. We rigorously derive stability constraints to guarantee system robustness. Beyond coverage extension, OWE dynamically adjusts EA gains in response to user locations and channel conditions, enhancing signal-to-noise ratio, balancing resource allocation, and suppressing interference. As the first framework to harness diffuse reflection for controllable optical propagation, we validate OWE's effectiveness through analytical modeling, simulations, and prototyping. Our work lays the foundation for robust, high-speed indoor OWC networks.

Paper number 123:
Title: Tracking Control of Euler-Lagrangian Systems with Prescribed State, Input, and Temporal Constraints
Authors: Chidre Shravista Kashyap, Pushpak Jagtap, Jishnu Keshavan
Abstract: The synthesis of a smooth tracking control for Euler-Lagrangian (EL) systems under stringent state, input, and temporal (SIT) constraints is challenging. In contrast to existing methods that utilize prior knowledge of EL model parameters and uncertainty bounds, this study proposes an approximation-free adaptive barrier function-based control policy to ensure local prescribed time convergence of tracking error under state and input constraints. The proposed approach uses smooth time-based generator functions embedded in the filtered tracking error, which is combined with a saturation function that limits control action and confines states within the prescribed limits by enforcing the time-varying bounds on the filtered tracking error. Importantly, corresponding feasibility conditions are derived pertaining to the minimum control authority, the maximum disturbance rejection capability of the control policy, and the viable set of initial conditions, illuminating the narrow operating domain of EL systems arising from the interplay of SIT constraints. Finally, the efficacy of the proposed approach is demonstrated using experimental and comparison studies.

Paper number 124:
Title: Alzheimer's Disease Classification Using Retinal OCT: TransnetOCT and Swin Transformer Models
Authors: Siva Manohar Reddy Kesu, Neelam Sinha, Hariharan Ramasangu, Thomas Gregor Issac
Abstract: Retinal optical coherence tomography (OCT) images are the biomarkers for neurodegenerative diseases, which are rising in prevalence. Early detection of Alzheimer's disease using retinal OCT is a primary challenging task. This work utilizes advanced deep learning techniques to classify retinal OCT images of subjects with Alzheimer's disease (AD) and healthy controls (CO). The goal is to enhance diagnostic capabilities through efficient image analysis. In the proposed model, Raw OCT images have been preprocessed with ImageJ and given to various deep-learning models to evaluate the accuracy. The best classification architecture is TransNetOCT, which has an average accuracy of 98.18% for input OCT images and 98.91% for segmented OCT images for five-fold cross-validation compared to other models, and the Swin Transformer model has achieved an accuracy of 93.54%. The evaluation accuracy metric demonstrated TransNetOCT and Swin transformer models capability to classify AD and CO subjects reliably, contributing to the potential for improved diagnostic processes in clinical settings.

Paper number 125:
Title: TEANet: A Transpose-Enhanced Autoencoder Network for Wearable Stress Monitoring
Authors: Md Santo Ali, Sapnil Sarker Bipro, Mohammod Abdul Motin, Sumaiya Kabir, Manish Sharma, M. E. H. Chowdhury
Abstract: Mental stress poses a significant public health concern due to its detrimental effects on physical and mental well-being, necessitating the development of continuous stress monitoring tools for wearable devices. Blood volume pulse (BVP) sensors, readily available in many smartwatches, offer a convenient and cost-effective solution for stress monitoring. This study presents a deep learning approach, a Transpose-Enhanced Autoencoder Network (TEANet), for stress detection using BVP signals on resource-constrained devices. The proposed TEANet model was trained and validated utilizing a self-developed RUET SPML dataset, and the publicly available wearable stress and affect detection (WESAD) dataset. It achieves the highest accuracy of 92.94% and 96.94%, F1 scores of 95.16% and 95.95%, and kappa of 0.8181 and 0.9350 for RUET SPML, and WESAD datasets, respectively. The proposed TEANet effectively detects mental stress through BVP signals with high accuracy, making it a promising tool for continuous stress monitoring. Furthermore, deploying the proposed model on the Raspberry Pi 3B+ enhances its potential for reliable real-time stress monitoring using resource-constrained devices.

Paper number 126:
Title: Predicting speech intelligibility in older adults for speech enhancement using the Gammachirp Envelope Similarity Index, GESI
Authors: Ayako Yamamoto, Fuki Miyazaki, Toshio Irino
Abstract: We propose an objective intelligibility measure (OIM), called the Gammachirp Envelope Similarity Index (GESI), that can predict speech intelligibility (SI) in older adults. GESI is a bottom-up model based on psychoacoustic knowledge from the peripheral to the central auditory system. It computes the single SI metric using the gammachirp filterbank (GCFB), the modulation filterbank, and the extended cosine similarity measure. It takes into account not only the hearing level represented in the audiogram, but also the temporal processing characteristics captured by the temporal modulation transfer function (TMTF). To evaluate performance, SI experiments were conducted with older adults of various hearing levels using speech-in-noise with ideal speech enhancement on familiarity-controlled Japanese words. The prediction performance was compared with HASPIw2, which was developed for keyword SI prediction. The results showed that GESI predicted the subjective SI scores more accurately than HASPIw2. GESI was also found to be at least as effective as, if not more effective than, HASPIv2 in predicting English sentence-level SI. The effect of introducing TMTF into the GESI algorithm was insignificant, suggesting that TMTF measurements and models are not yet mature. Therefore, it may be necessary to perform TMTF measurements with bandpass noise and to improve the incorporation of temporal characteristics into the model.

Paper number 127:
Title: Lightweight Prompt Biasing for Contextualized End-to-End ASR Systems
Authors: Bo Ren, Yu Shi, Jinyu Li
Abstract: End-to-End Automatic Speech Recognition (ASR) has advanced significantly yet still struggles with rare and domain-specific entities. This paper introduces a simple yet efficient prompt-based biasing technique for contextualized ASR, enhancing recognition accuracy by leverage a unified multitask learning framework. The approach comprises two key components: a prompt biasing model which is trained to determine when to focus on entities in prompt, and a entity filtering mechanism which efficiently filters out irrelevant entities. Our method significantly enhances ASR accuracy on entities, achieving a relative 30.7% and 18.0% reduction in Entity Word Error Rate compared to the baseline model with shallow fusion on in-house domain dataset with small and large entity lists, respectively. The primary advantage of this method lies in its efficiency and simplicity without any structure change, making it lightweight and highly efficient.

Paper number 128:
Title: Multi-agent Auditory Scene Analysis
Authors: Caleb Rascon, Luis Gato-Diaz, Eduardo García-Alarcón
Abstract: Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.

Paper number 129:
Title: Controllable joint noise reduction and hearing loss compensation using a differentiable auditory model
Authors: Philippe Gonzalez, Torsten Dau, Tobias May
Abstract: Deep learning-based hearing loss compensation (HLC) seeks to enhance speech intelligibility and quality for hearing impaired listeners using neural networks. One major challenge of HLC is the lack of a ground-truth target. Recent works have used neural networks to emulate non-differentiable auditory peripheral models in closed-loop frameworks, but this approach lacks flexibility. Alternatively, differentiable auditory models allow direct optimization, yet previous studies focused on individual listener profiles, or joint noise reduction (NR) and HLC without balancing each task. This work formulates NR and HLC as a multi-task learning problem, training a system to simultaneously predict denoised and compensated signals from noisy speech and audiograms using a differentiable auditory model. Results show the system achieves similar objective metric performance to systems trained for each task separately, while being able to adjust the balance between NR and HLC during inference.

Paper number 130:
Title: Estimating Reliability of Electric Vehicle Charging Ecosystem using the Principle of Maximum Entropy
Authors: Himanshu Tripathi, Subash Neupane, Shahram Rahimi, Noorbakhsh Amiri Golilarz, Sudip Mittal, Mohammad Sepehrifar
Abstract: This paper addresses the critical challenge of estimating the reliability of an Electric Vehicle (EV) charging systems when facing risks such as overheating, unpredictable, weather, and cyberattacks. Traditional methods for predicting failures often rely on past data or limiting assumptions, making them ineffective for new or less common threats that results in failure. To solve this issue, we utilize the Principle of Maximum Entropy (PME), a statistical tool that estimates risks even with limited information. PME works by balancing known constraints to create an unbiased predictions without guessing missing details. Using the EV charging ecosystem as a case study, we show how PME models stress factors responsible for failure. Our findings reveal a critical insight: even minor, localized stress events can trigger disproportionately large drops in overall system reliability, similar to a domino effect. The our PME model demonstrates how high-impact components, such as the power grid, are more likely to fail as stress accumulates, creating network-wide tipping points. Beyond EVs, this approach applies to any complex system with incomplete data, such as smart grids, healthcare devices, or logistics networks. By mathematically establishing an inverse relationship between uncertainty (entropy) and reliability, our work quantifies how greater system unpredictability directly degrades robustness. This offers a universal tool to improve decision-making under unpredictable conditions. This work bridges advanced mathematics with real-world engineering, providing actionable insights for policymakers and industries to build safer, more efficient systems in our increasingly connected world.

Paper number 131:
Title: LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation
Authors: Cristian Minoccheri, Matthew Hodgman, Haoyuan Ma, Rameez Merchant, Emily Wittrup, Craig Williamson, Kayvan Najarian
Abstract: Aneurysmal subarachnoid hemorrhage (SAH) is a life-threatening neurological emergency with mortality rates exceeding 30%. Transfer learning from related hematoma types represents a potentially valuable but underexplored approach. Although Unet architectures remain the gold standard for medical image segmentation due to their effectiveness on limited datasets, Low-Rank Adaptation (LoRA) methods for parameter-efficient transfer learning have been rarely applied to convolutional neural networks in medical imaging contexts. We implemented a Unet architecture pre-trained on computed tomography scans from 124 traumatic brain injury patients across multiple institutions, then fine-tuned on 30 aneurysmal SAH patients from the University of Michigan Health System using 3-fold cross-validation. We developed a novel CP-LoRA method based on tensor CP-decomposition and introduced DoRA variants (DoRA-C, convDoRA, CP-DoRA) that decompose weight matrices into magnitude and directional components. We compared these approaches against existing LoRA methods (LoRA-C, convLoRA) and standard fine-tuning strategies across different modules on a multi-view Unet model. LoRA-based methods consistently outperformed standard Unet fine-tuning. Performance varied by hemorrhage volume, with all methods showing improved accuracy for larger volumes. CP-LoRA achieved comparable performance to existing methods while using significantly fewer parameters. Over-parameterization with higher ranks consistently yielded better performance than strictly low-rank adaptations. This study demonstrates that transfer learning between hematoma types is feasible and that LoRA-based methods significantly outperform conventional Unet fine-tuning for aneurysmal SAH segmentation.

Paper number 132:
Title: Fast Algorithm for Moving Sound Source
Authors: Dong Yang
Abstract: Modern neural network-based speech processing systems usually need to have reverberation resistance, so the training of such systems requires a large amount of reverberation data. In the process of system training, it is now more inclined to use sampling static systems to simulate dynamic systems, or to supplement data through actually recorded data. However, this cannot fundamentally solve the problem of simulating motion data that conforms to physical laws. Aiming at the core issue of insufficient training data for speech enhancement models in moving scenarios, this paper proposes Yang's motion spatio-temporal sampling reconstruction theory to realize efficient simulation of motion continuous time-varying reverberation. This theory breaks through the limitations of the traditional static Image-Source Method (ISM) in time-varying systems. By decomposing the impulse response of the moving image source into two parts: linear time-invariant modulation and discrete time-varying fractional delay, a moving sound field model conforming to physical laws is established. Based on the band-limited characteristics of motion displacement, a hierarchical sampling strategy is proposed: high sampling rate is used for low-order images to retain details, and low sampling rate is used for high-order images to reduce computational complexity. A fast synthesis architecture is designed to realize real-time simulation. Experiments show that compared with the open-source models, the proposed theory can more accurately restore the amplitude and phase changes in moving scenarios, solving the industry problem of motion sound source data simulation, and providing high-quality dynamic training data for speech enhancement models.

Paper number 133:
Title: When Deep Learning Fails: Limitations of Recurrent Models on Stroke-Based Handwriting for Alzheimer's Disease Detection
Authors: Emanuele Nardone, Tiziana D'Alessandro, Francesco Fontanella, Claudio De Stefano
Abstract: Alzheimer's disease detection requires expensive neuroimaging or invasive procedures, limiting accessibility. This study explores whether deep learning can enable non-invasive Alzheimer's disease detection through handwriting analysis. Using a dataset of 34 distinct handwriting tasks collected from healthy controls and Alzheimer's disease patients, we evaluate and compare three recurrent neural architectures (LSTM, GRU, RNN) against traditional machine learning models. A crucial distinction of our approach is that the recurrent models process pre-extracted features from discrete strokes, not raw temporal signals. This violates the assumption of a continuous temporal flow that recurrent networks are designed to capture. Results reveal that they exhibit poor specificity and high variance. Traditional ensemble methods significantly outperform all deep architectures, achieving higher accuracy with balanced metrics. This demonstrates that recurrent architectures, designed for continuous temporal sequences, fail when applied to feature vectors extracted from ambiguously segmented strokes. Despite their complexity, deep learning models cannot overcome the fundamental disconnect between their architectural assumptions and the discrete, feature-based nature of stroke-level handwriting data. Although performance is limited, the study highlights several critical issues in data representation and model compatibility, pointing to valuable directions for future research.

Paper number 134:
Title: Pinching-Antenna Systems (PASS): A Tutorial
Authors: Yuanwei Liu, Hao Jiang, Xiaoxia Xu, Zhaolin Wang, Jia Guo, Chongjun Ouyang, Xidong Mu, Zhiguo Ding, Arumugam Nallanathan, George K. Karagiannidis, Robert Schober
Abstract: Pinching antenna systems (PASS) present a breakthrough among the flexible-antenna technologies, and distinguish themselves by facilitating large-scale antenna reconfiguration, line-of-sight creation, scalable implementation, and near-field benefits, thus bringing wireless communications from the last mile to the last meter. A comprehensive tutorial is presented in this paper. First, the fundamentals of PASS are discussed, including PASS signal models, hardware models, power radiation models, and pinching antenna activation methods. Building upon this, the information-theoretic capacity limits achieved by PASS are characterized, and several typical performance metrics of PASS-based communications are analyzed to demonstrate its superiority over conventional antenna technologies. Next, the pinching beamforming design is investigated. The corresponding power scaling law is first characterized. For the joint transmit and pinching design in the general multiple-waveguide case, 1) a pair of transmission strategies is proposed for PASS-based single-user communications to validate the superiority of PASS, namely sub-connected and fully connected structures; and 2) three practical protocols are proposed for facilitating PASS-based multi-user communications, namely waveguide switching, waveguide division, and waveguide multiplexing. A possible implementation of PASS in wideband communications is further highlighted. Moreover, the channel state information acquisition in PASS is elaborated with a pair of promising solutions. To overcome the high complexity and suboptimality inherent in conventional convex-optimization-based approaches, machine-learning-based methods for operating PASS are also explored, focusing on selected deep neural network architectures and training algorithms. Finally, several promising applications of PASS in next-generation wireless networks are highlighted.

Paper number 135:
Title: Is Smaller Always Faster? Tradeoffs in Compressing Self-Supervised Speech Transformers
Authors: Tzu-Quan Lin, Tsung-Huan Yang, Chun-Yao Chang, Kuang-Ming Chen, Tzu-hsun Feng, Hung-yi Lee, Hao Tang
Abstract: Transformer-based self-supervised models have achieved remarkable success in speech processing, but their large size and high inference cost present significant challenges for real-world deployment. While numerous compression techniques have been proposed, inconsistent evaluation metrics make it difficult to compare their practical effectiveness. In this work, we conduct a comprehensive study of four common compression methods, including weight pruning, head pruning, low-rank approximation, and knowledge distillation on self-supervised speech Transformers. We evaluate each method under three key metrics: parameter count, multiply-accumulate operations, and real-time factor. Results show that each method offers distinct advantages. In addition, we contextualize recent compression techniques, comparing DistilHuBERT, FitHuBERT, LightHuBERT, ARMHuBERT, and STaRHuBERT under the same framework, offering practical guidance on compression for deployment.

Paper number 136:
Title: Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach
Authors: Iman Sharifi, Mustafa Yildirim, Saber Fallah
Abstract: The dynamic nature of driving environments and the presence of diverse road users pose significant challenges for decision-making in autonomous driving. Deep reinforcement learning (DRL) has emerged as a popular approach to tackle this problem. However, the application of existing DRL solutions is mainly confined to simulated environments due to safety concerns, impeding their deployment in real-world. To overcome this limitation, this paper introduces a novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logic (DRLSL) that combines the strengths of DRL (learning from experience) and symbolic first-order logic (knowledge-driven reasoning) to enable safe learning in real-time interactions of autonomous driving within real environments. This innovative approach provides a means to learn autonomous driving policies by actively engaging with the physical environment while ensuring safety. We have implemented the DRLSL framework in a highway driving scenario using the HighD dataset and demonstrated that our method successfully avoids unsafe actions during both the training and testing phases. Furthermore, our results indicate that DRLSL achieves faster convergence during training and exhibits better generalizability to new highway driving scenarios compared to traditional DRL methods.

Paper number 137:
Title: A transversality theorem for semi-algebraic sets with application to signal recovery from the second moment and cryo-EM
Authors: Tamir Bendory, Nadav Dym, Dan Edidin, Arun Suresh
Abstract: Semi-algebraic priors are ubiquitous in signal processing and machine learning. Prevalent examples include a) linear models where the signal lies in a low-dimensional subspace; b) sparse models where the signal can be represented by only a few coefficients under a suitable basis; and c) a large family of neural network generative models. In this paper, we prove a transversality theorem for semi-algebraic sets in orthogonal or unitary representations of groups: with a suitable dimension bound, a generic translate of any semi-algebraic set is transverse to the orbits of the group action. This, in turn, implies that if a signal lies in a low-dimensional semi-algebraic set, then it can be recovered uniquely from measurements that separate orbits. As an application, we consider the implications of the transversality theorem to the problem of recovering signals that are translated by random group actions from their second moment. As a special case, we discuss cryo-EM: a leading technology to constitute the spatial structure of biological molecules, which serves as our prime motivation. In particular, we derive explicit bounds for recovering a molecular structure from the second moment under a semi-algebraic prior and deduce information-theoretic implications. We also obtain information-theoretic bounds for three additional applications: factoring Gram matrices, multi-reference alignment, and phase retrieval. Finally, we deduce bounds for designing permutation invariant separators in machine learning.

Paper number 138:
Title: S2Cap: A Benchmark and a Baseline for Singing Style Captioning
Authors: Hyunjong Ok, Jaeho Lee
Abstract: Singing voices contain much richer information than common voices, including varied vocal and acoustic properties. However, current open-source audio-text datasets for singing voices capture only a narrow range of attributes and lack acoustic features, leading to limited utility towards downstream tasks, such as style captioning. To fill this gap, we formally define the singing style captioning task and present S2Cap, a dataset of singing voices with detailed descriptions covering diverse vocal, acoustic, and demographic characteristics. Using this dataset, we develop an efficient and straightforward baseline algorithm for singing style captioning. The dataset is available at this https URL.

Paper number 139:
Title: Communicate Less, Synthesize the Rest: Latency-aware Intent-based Generative Semantic Multicasting with Diffusion Models
Authors: Xinkai Liu, Mahdi Boloursaz Mashhadi, Li Qiao, Yi Ma, Rahim Tafazolli, Mehdi Bennis
Abstract: Generative diffusion models (GDMs) have recently shown great success in synthesizing multimedia signals with high perceptual quality, enabling highly efficient semantic communications in future wireless networks. In this paper, we develop an intent-aware generative semantic multicasting framework utilizing pre-trained diffusion models. In the proposed framework, the transmitter decomposes the source signal into multiple semantic classes based on the multi-user intent, i.e. each user is assumed to be interested in details of only a subset of the semantic classes. To better utilize the wireless resources, the transmitter sends to each user only its intended classes, and multicasts a highly compressed semantic map to all users over shared wireless resources that allows them to locally synthesize the other classes, namely non-intended classes, utilizing pre-trained diffusion models. The signal retrieved at each user is thereby partially reconstructed and partially synthesized utilizing the received semantic map. We design a communication/computation-aware scheme for per-class adaptation of the communication parameters, such as the transmission power and compression rate, to minimize the total latency of retrieving signals at multiple receivers, tailored to the prevailing channel conditions as well as the users' reconstruction/synthesis distortion/perception requirements. The simulation results demonstrate significantly reduced per-user latency compared with non-generative and intent-unaware multicasting benchmarks while maintaining high perceptual quality of the signals retrieved at the users.

Paper number 140:
Title: Diagnostic performance of deep learning for predicting glioma isocitrate dehydrogenase and 1p/19q co-deletion in MRI: a systematic review and meta-analysis
Authors: Somayeh Farahani, Marjaneh Hejazi, Mehnaz Tabassum, Antonio Di Ieva, Neda Mahdavifar, Sidong Liu
Abstract: Objectives We aimed to evaluate the diagnostic performance of deep learning (DL)-based radiomics models for the noninvasive prediction of isocitrate dehydrogenase (IDH) mutation and 1p/19q co-deletion status in glioma patients using MRI sequences, and to identify methodological factors influencing accuracy and generalizability. Materials and methods Following PRISMA guidelines, we systematically searched major databases (PubMed, Scopus, Embase, Web of Science, and Google Scholar) up to March 2025, screening studies that utilized DL to predict IDH and 1p/19q co-deletion status from MRI data. We assessed study quality and risk of bias using the Radiomics Quality Score and the QUADAS-2 tool. Our meta-analysis employed a bivariate model to compute pooled sensitivity and specificity, and meta-regression to assess interstudy heterogeneity. Results Among the 1517 unique publications, 104 were included in the qualitative synthesis, and 72 underwent meta-analysis. Pooled estimates for IDH prediction in test cohorts yielded a sensitivity of 0.80 and specificity of 0.85. For 1p/19q co-deletion, sensitivity was 0.75 and specificity was 0.82. Meta-regression identified the tumor segmentation method and the extent of DL integration into the radiomics pipeline as significant contributors to interstudy variability. Conclusion Although DL models demonstrate strong potential for noninvasive molecular classification of gliomas, clinical translation requires several critical steps: harmonization of multi-center MRI data using techniques such as histogram matching and DL-based style transfer; adoption of standardized and automated segmentation protocols; extensive multi-center external validation; and prospective clinical validation.

Paper number 141:
Title: On-device Anomaly Detection in Conveyor Belt Operations
Authors: Luciano S. Martinez-Rau, Yuxuan Zhang, Bengt Oelmann, Sebastian Bader
Abstract: Conveyor belts are crucial in mining operations by enabling the continuous and efficient movement of bulk materials over long distances, which directly impacts productivity. While detecting anomalies in specific conveyor belt components has been widely studied, identifying the root causes of these failures, such as changing production conditions and operator errors, remains critical. Continuous monitoring of mining conveyor belt work cycles is still at an early stage and requires robust solutions. Recently, an anomaly detection method for duty cycle operations of a mining conveyor belt has been proposed. Based on its limited performance and unevaluated long-term proper operation, this study proposes two novel methods for classifying normal and abnormal duty cycles. The proposed approaches are pattern recognition systems that make use of threshold-based duty-cycle detection mechanisms, manually extracted features, pattern-matching, and supervised tiny machine learning models. The explored low-computational models include decision tree, random forest, extra trees, extreme gradient boosting, Gaussian naive Bayes, and multi-layer perceptron. A comprehensive evaluation of the former and proposed approaches is carried out on two datasets. Both proposed methods outperform the former method in anomaly detection, with the best-performing approach being dataset-dependent. The heuristic rule-based approach achieves the highest F1-score in the same dataset used for algorithm training, with 97.3% for normal cycles and 80.2% for abnormal cycles. The ML-based approach performs better on a dataset including the effects of machine aging, with an F1-score scoring 91.3% for normal cycles and 67.9% for abnormal cycles. Implemented on two low-power microcontrollers, the methods demonstrate efficient, real-time operation with energy consumption of 13.3 and 20.6 \textmu J during inference. These results ...

Paper number 142:
Title: STRAP: Robot Sub-Trajectory Retrieval for Augmented Policy Learning
Authors: Marius Memmel, Jacob Berg, Bingqing Chen, Abhishek Gupta, Jonathan Francis
Abstract: Robot learning is witnessing a significant increase in the size, diversity, and complexity of pre-collected datasets, mirroring trends in domains such as natural language processing and computer vision. Many robot learning methods treat such datasets as multi-task expert data and learn a multi-task, generalist policy by training broadly across them. Notably, while these generalist policies can improve the average performance across many tasks, the performance of generalist policies on any one task is often suboptimal due to negative transfer between partitions of the data, compared to task-specific specialist policies. In this work, we argue for the paradigm of training policies during deployment given the scenarios they encounter: rather than deploying pre-trained policies to unseen problems in a zero-shot manner, we non-parametrically retrieve and train models directly on relevant data at test time. Furthermore, we show that many robotics tasks share considerable amounts of low-level behaviors and that retrieval at the "sub"-trajectory granularity enables significantly improved data utilization, generalization, and robustness in adapting policies to novel problems. In contrast, existing full-trajectory retrieval methods tend to underutilize the data and miss out on shared cross-task content. This work proposes STRAP, a technique for leveraging pre-trained vision foundation models and dynamic time warping to retrieve sub-sequences of trajectories from large training corpora in a robust fashion. STRAP outperforms both prior retrieval algorithms and multi-task learning methods in simulated and real experiments, showing the ability to scale to much larger offline datasets in the real world as well as the ability to learn robust control policies with just a handful of real-world demonstrations.

Paper number 143:
Title: Stability and performance guarantees for misspecified multivariate score-driven filters
Authors: Simon Donker van Heel, Rutger-Jan Lange, Bram van Os, Dick van Dijk
Abstract: Can stochastic gradient methods track a moving target? We address the problem of tracking multivariate time-varying parameters under noisy observations and potential model misspecification. Specifically, we examine implicit and explicit score-driven (ISD and ESD) filters, which update parameter predictions using the gradient of the logarithmic postulated observation density (commonly referred to as the score). For both filter types, we derive novel sufficient conditions that ensure the exponential stability of the filtered parameter path and the existence of a finite mean squared error (MSE) bound relative to the pseudo-true parameter path. Our (non-)asymptotic MSE bounds rely on mild moment conditions on the data-generating process, while our stability results are agnostic about the true process. For the ISD filter, concavity of the postulated log density combined with simple parameter restrictions is sufficient to guarantee stability. In contrast, the ESD filter additionally requires the score to be Lipschitz continuous and the learning rate to be sufficiently small. We validate our theoretical findings through simulation studies, showing that ISD filters outperform ESD filters in terms of accuracy and stability.

Paper number 144:
Title: Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities
Authors: Guan-Ting Lin, Jiachen Lian, Tingle Li, Qirui Wang, Gopala Anumanchipalli, Alexander H. Liu, Hung-yi Lee
Abstract: Spoken dialogue modeling poses challenges beyond text-based language modeling, requiring real-time interaction, turn-taking, and backchanneling. While most Spoken Dialogue Models (SDMs) operate in half-duplex mode-processing one turn at a time - emerging full-duplex SDMs can listen and speak simultaneously, enabling more natural conversations. However, current evaluations remain limited, focusing mainly on turn-based metrics or coarse corpus-level analyses. To address this, we introduce Full-Duplex-Bench, a benchmark that systematically evaluates key interactive behaviors: pause handling, backchanneling, turn-taking, and interruption management. Our framework uses automatic metrics for consistent, reproducible assessment and provides a fair, fast evaluation setup. By releasing our benchmark and code, we aim to advance spoken dialogue modeling and foster the development of more natural and engaging SDMs.

Paper number 145:
Title: Self-sustained oscillations in discrete-time relay feedback systems
Authors: Kang Tong, Christian Grussler, Michelle S. Chong
Abstract: We study the problem of determining self-sustained oscillations in discrete-time linear time-invariant relay feedback systems. Concretely, we are interested in predicting when such a system admits unimodal oscillations, i.e., when the output has a single-peaked period. Under the assumption that the linear system is stable and has an impulse response that is strictly monotonically decreasing on its infinite support, we take a novel approach in using the framework of total positivity to address our main question. It is shown that unimodal self-oscillations can only exist if the number of positive and negative elements in a period coincides. Based on this result, we derive conditions for the existence of such oscillations, determine bounds on their periods, and address the question of uniqueness.

Paper number 146:
Title: DiffVox: A Differentiable Model for Capturing and Analysing Vocal Effects Distributions
Authors: Chin-Yun Yu, Marco A. Martínez-Ramírez, Junghyun Koo, Ben Hayes, Wei-Hsiang Liao, György Fazekas, Yuki Mitsufuji
Abstract: This study introduces a novel and interpretable model, DiffVox, for matching vocal effects in music production. DiffVox, short for ``Differentiable Vocal Fx", integrates parametric equalisation, dynamic range control, delay, and reverb with efficient differentiable implementations to enable gradient-based optimisation for parameter estimation. Vocal presets are retrieved from two datasets, comprising 70 tracks from MedleyDB and 365 tracks from a private collection. Analysis of parameter correlations reveals strong relationships between effects and parameters, such as the high-pass and low-shelf filters often working together to shape the low end, and the delay time correlating with the intensity of the delayed signals. Principal component analysis reveals connections to McAdams' timbre dimensions, where the most crucial component modulates the perceived spaciousness while the secondary components influence spectral brightness. Statistical testing confirms the non-Gaussian nature of the parameter distribution, highlighting the complexity of the vocal effects space. These initial findings on the parameter distributions set the foundation for future research in vocal effects modelling and automatic mixing. Our source code and datasets are accessible at this https URL.

Paper number 147:
Title: HuB: Learning Extreme Humanoid Balance
Authors: Tong Zhang, Boyuan Zheng, Ruiqian Nai, Yingdong Hu, Yen-Jen Wang, Geng Chen, Fanqi Lin, Jiongye Li, Chuye Hong, Koushil Sreenath, Yang Gao
Abstract: The human body demonstrates exceptional motor capabilities-such as standing steadily on one foot or performing a high kick with the leg raised over 1.5 meters-both requiring precise balance control. While recent research on humanoid control has leveraged reinforcement learning to track human motions for skill acquisition, applying this paradigm to balance-intensive tasks remains challenging. In this work, we identify three key obstacles: instability from reference motion errors, learning difficulties due to morphological mismatch, and the sim-to-real gap caused by sensor noise and unmodeled dynamics. To address these challenges, we propose HuB (Humanoid Balance), a unified framework that integrates reference motion refinement, balance-aware policy learning, and sim-to-real robustness training, with each component targeting a specific challenge. We validate our approach on the Unitree G1 humanoid robot across challenging quasi-static balance tasks, including extreme single-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy remains stable even under strong physical disturbances-such as a forceful soccer strike-while baseline methods consistently fail to complete these tasks. Project website: this https URL

Paper number 148:
Title: Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning
Authors: Luciano Sebastian Martinez-Rau, Quynh Nguyen Phuong Vu, Yuxuan Zhang, Bengt Oelmann, Sebastian Bader
Abstract: Keyword spotting (KWS) is a key component of smart devices, enabling efficient and intuitive audio interaction. However, standard KWS systems deployed on embedded devices often suffer performance degradation under real-world operating conditions. Resilient KWS systems address this issue by enabling dynamic adaptation, with applications such as adding or replacing keywords, adjusting to specific users, and improving noise robustness. However, deploying resilient, standalone KWS systems with low latency on resource-constrained devices remains challenging due to limited memory and computational resources. This study proposes a low computational approach for continuous noise adaptation of pretrained neural networks used for KWS classification, requiring only 1-shot learning and one epoch. The proposed method was assessed using two pretrained models and three real-world noise sources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted models consistently outperformed the pretrained models across all scenarios, especially at SNR $\leq$ 18 dB, achieving accuracy improvements of 4.9% to 46.0%. These results highlight the efficacy of the proposed methodology while being lightweight enough for deployment on resource-constrained devices.

Paper number 149:
Title: Comparative Evaluation of Acoustic Feature Extraction Tools for Clinical Speech Analysis
Authors: Anna Seo Gyeong Choi, Alexander Richardson, Ryan Partlan, Sunny Tang, Sunghye Cho
Abstract: This study compares three acoustic feature extraction toolkits (OpenSMILE, Praat, and Librosa) applied to clinical speech data from individuals with schizophrenia spectrum disorders (SSD) and healthy controls (HC). By standardizing extraction parameters across the toolkits, we analyzed speech samples from 77 SSD and 87 HC participants and found significant toolkit-dependent variations. While F0 percentiles showed high cross-toolkit correlation (r=0.962 to 0.999), measures like F0 standard deviation and formant values often had poor, even negative, agreement. Additionally, correlation patterns differed between SSD and HC groups. Classification analysis identified F0 mean, HNR, and MFCC1 (AUC greater than 0.70) as promising discriminators. These findings underscore reproducibility concerns and advocate for standardized protocols, multi-toolkit cross-validation, and transparent reporting.

Paper number 150:
Title: Hyperspectral Image Generation with Unmixing Guided Diffusion Model
Authors: Shiyu Shen, Bin Pan, Ziye Zhang, Zhenwei Shi
Abstract: Recently, hyperspectral image generation has received increasing attention, but existing generative models rely on conditional generation schemes, which limits the diversity of generated images. Diffusion models are popular for their ability to generate high-quality samples, but adapting these models from RGB to hyperspectral data presents the challenge of high dimensionality and physical constraints. To address these challenges, we propose a novel diffusion model guided by hyperspectral unmixing. Our model comprises two key modules: an unmixing autoencoder module and an abundance diffusion module. The unmixing autoencoder module leverages unmixing guidance to shift the generative task from the image space to the low-dimensional abundance space, significantly reducing computational complexity while preserving high fidelity. The abundance diffusion module generates samples that satisfy the constraints of non-negativity and unity, ensuring the physical consistency of the reconstructed HSIs. Additionally, we introduce two evaluation metrics tailored to hyperspectral data. Empirical results, evaluated using both traditional metrics and our proposed metrics, indicate that our model is capable of generating high-quality and diverse hyperspectral images, offering an advancement in hyperspectral data generation.

Paper number 151:
Title: Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control
Authors: Ruitao Chen, Mozhang Guo, Jinge Li
Abstract: Automated driving (AD) has substantially improved vehicle safety and driving comfort, but their impact on passenger well-being, particularly infant sleep, is not sufficiently studied. Sudden acceleration, abrupt braking, and sharp maneuvers can disrupt infant sleep, compromising both passenger comfort and parental convenience. To solve this problem, this paper explores the integration of reinforcement learning (RL) within AD to personalize driving behavior and optimally balance occupant comfort and travel efficiency. In particular, we propose an intelligent cruise control framework that adapts to varying driving conditions to enhance infant sleep quality by effectively synergizing wearable sensing and vehicle data. Long short-term memory (LSTM) and transformer-based neural networks are integrated with RL to model the relationship between driving behavior and infant sleep quality under diverse traffic and road conditions. Based on the sleep quality indicators from the wearable sensors, driving action data from vehicle controllers, and map data from map applications, the model dynamically computes the optimal driving aggressiveness level, which is subsequently translated into specific AD control strategies, e.g., the magnitude and frequency of acceleration, lane change, and overtaking. Simulation experiments conducted in the CARLA environment indicate that the proposed solution significantly improves infant sleep quality compared to baseline methods, while preserving desirable travel efficiency.

Paper number 152:
Title: Towards Generalized Source Tracing for Codec-Based Deepfake Speech
Authors: Xuanjun Chen, I-Ming Lin, Lin Zhang, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang
Abstract: Recent attempts at source tracing for codec-based deepfake speech (CodecFake), generated by neural audio codec-based speech generation (CoSG) models, have exhibited suboptimal performance. However, how to train source tracing models using simulated CoSG data while maintaining strong performance on real CoSG-generated audio remains an open challenge. In this paper, we show that models trained solely on codec-resynthesized data tend to overfit to non-speech regions and struggle to generalize to unseen content. To mitigate these challenges, we introduce the Semantic-Acoustic Source Tracing Network (SASTNet), which jointly leverages Whisper for semantic feature encoding and Wav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet achieves state-of-the-art performance on the CoSG test set of the CodecFake+ dataset, demonstrating its effectiveness for reliable source tracing.

Paper number 153:
Title: USAD: Universal Speech and Audio Representation via Distillation
Authors: Heng-Jui Chang, Saurabhchand Bhati, James Glass, Alexander H. Liu
Abstract: Self-supervised learning (SSL) has revolutionized audio representations, yet models often remain domain-specific, focusing on either speech or non-speech tasks. In this work, we present Universal Speech and Audio Distillation (USAD), a unified approach to audio representation learning that integrates diverse audio types - speech, sound, and music - into a single model. USAD employs efficient layer-to-layer distillation from domain-specific SSL models to train a student on a comprehensive audio dataset. USAD offers competitive performance across various benchmarks and datasets, including frame and instance-level speech processing tasks, audio tagging, and sound classification, achieving near state-of-the-art results with a single encoder on SUPERB and HEAR benchmarks.

Paper number 154:
Title: Radif Corpus: A Symbolic Dataset for Non-Metric Iranian Classical Music
Authors: Maziar Kanani, Sean O Leary, James McDermott
Abstract: Non-metric music forms the core of the repertoire in Iranian classical music. Dastgahi music serves as the underlying theoretical system for both Iranian art music and certain folk traditions. At the heart of Iranian classical music lies the radif, a foundational repertoire that organizes melodic material central to performance and pedagogy. In this study, we introduce a digital corpus representing the complete non-metrical radif repertoire, covering all 13 existing components of this repertoire. We provide MIDI files (about 281 minutes in total) and data spreadsheets describing notes, note durations, intervals, and hierarchical structures for 228 pieces of music. We faithfully represent the tonality including quarter-tones, and the non-metric aspect. Furthermore, we provide supporting basic statistics, and measures of complexity and similarity over the corpus. Our corpus provides a platform for computational studies of Iranian classical music. Researchers might employ it in studying melodic patterns, investigating improvisational styles, or for other tasks in music information retrieval, music theory, and computational (ethno)musicology.

Paper number 155:
Title: SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization
Authors: Beilong Tang, Xiaoxiao Miao, Xin Wang, Ming Li
Abstract: Voice anonymization protects speaker privacy by concealing identity while preserving linguistic and paralinguistic content. Self-supervised learning (SSL) representations encode linguistic features but preserve speaker traits. We propose a novel speaker-embedding-free framework called SEF-MK. Instead of using a single k-means model trained on the entire dataset, SEF-MK anonymizes SSL representations for each utterance by randomly selecting one of multiple k-means models, each trained on a different subset of speakers. We explore this approach from both attacker and user perspectives. Extensive experiments show that, compared to a single k-means model, SEF-MK with multiple k-means models better preserves linguistic and emotional content from the user's viewpoint. However, from the attacker's perspective, utilizing multiple k-means models boosts the effectiveness of privacy attacks. These insights can aid users in designing voice anonymization systems to mitigate attacker threats.

Paper number 156:
Title: Two-Instrument Screening under Soft Budget Constraints
Authors: Xinli Guo
Abstract: We study soft budget constraints in multi-tier public finance when an upper-tier government uses two instruments: an ex-ante grant schedule and an ex-post rescue. Under convex rescue costs and standard primitives, the three-stage leader-follower problem collapses to one dimensional screening with a single allocation index: the cap on realized rescue. A hazard-based characterization delivers a unified rule that nests (i) no rescue, (ii) a threshold-cap with commitment, and (iii) a threshold--linear--cap without commitment. The knife-edge for eliminating bailouts compares the marginal cost at the origin to the supremum of a virtual weight, and the comparative statics show how greater curvature tightens caps while discretion shifts transfers toward front loading by lowering the effective grant weight. The framework provides a portable benchmark for mechanism design and yields testable implications for policy and empirical work on intergovernmental finance.
    