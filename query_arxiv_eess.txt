
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Polynomial Order Selection for Savitzky-Golay Smoothers via N-fold Cross-Validation (extended version)
Authors: Cagatay Candan
Abstract: Savitzky-Golay (SG) smoothers are noise suppressing filters operating on the principle of projecting noisy input onto the subspace of polynomials. A poorly selected polynomial order results in over- or under-smoothing which shows as either bias or excessive noise at the output. In this study, we apply the N-fold cross-validation technique (also known as leave-one-out cross-validation) for model order selection and show that the inherent analytical structure of the SG filtering problem, mainly its minimum norm formulation, enables an efficient and effective order selection solution. More specifically, a novel connection between the total prediction error and SG-projection spaces is developed to reduce the implementation complexity of cross-validation method. The suggested solution compares favorably with the state-of-the-art Bayesian Information Criterion (BIC) rule in non-asymptotic signal-to-noise ratio (SNR) and sample size regimes. MATLAB codes reproducing the numerical results are provided.

Paper number 2:
Title: RIS-Aided Localization and Sensing
Authors: Dimitris Kompostiotis, Dimitris Vordonis, Konstantinos D. Katsanos, Florin-Catalin Grec, Vassilis Paliouras, George C. Alexandropoulos
Abstract: High-precision localization and environmental sensing are essential for a new wave of applications, ranging from industrial automation and autonomous systems to augmented reality and remote healthcare. Conventional wireless methods, however, often face limitations in accuracy, reliability, and coverage, especially in complex non-line-of-sight (NLoS) environments. Reconfigurable Intelligent Surfaces (RISs) have emerged as a key enabling technology, offering dynamic control over the radio propagation environment to overcome these challenges. This chapter provides a comprehensive overview of RIS-aided localization and sensing, bridging fundamental theory with practical implementation. The core principles of the RIS technology are first described detailing how programmable metasurfaces can intelligently combat blockages, enhance signal diversity, and create virtual line-of-sight (LoS) links. The chapter then reviews a range of application scenarios where RISs can offer significant improvements. A significant portion of the chapter is dedicated to algorithmic methodologies, covering beam sweeping protocols, codebook-based techniques, and advanced optimization and machine learning strategies for both localization and sensing. To validate the theoretical concepts in real-world conditions, recent experimental results using an RIS prototype are detailed, showcasing the technology's efficacy and illustrating key performance trade-offs.

Paper number 3:
Title: Comparative Evaluation of Generative AI Models for Chest Radiograph Report Generation in the Emergency Department
Authors: Woo Hyeon Lim, Ji Young Lee, Jong Hyuk Lee, Saehoon Kim, Hyungjin Kim
Abstract: Purpose: To benchmark open-source or commercial medical image-specific VLMs against real-world radiologist-written reports. Methods: This retrospective study included adult patients who presented to the emergency department between January 2022 and April 2025 and underwent same-day CXR and CT for febrile or respiratory symptoms. Reports from five VLMs (AIRead, Lingshu, MAIRA-2, MedGemma, and MedVersa) and radiologist-written reports were randomly presented and blindly evaluated by three thoracic radiologists using four criteria: RADPEER, clinical acceptability, hallucination, and language clarity. Comparative performance was assessed using generalized linear mixed models, with radiologist-written reports treated as the reference. Finding-level analyses were also performed with CT as the reference. Results: A total of 478 patients (median age, 67 years [interquartile range, 50-78]; 282 men [59.0%]) were included. AIRead demonstrated the lowest RADPEER 3b rate (5.3% [76/1434] vs. radiologists 13.9% [200/1434]; P<.001), whereas other VLMs showed higher disagreement rates (16.8-43.0%; P<.05). Clinical acceptability was the highest with AIRead (84.5% [1212/1434] vs. radiologists 74.3% [1065/1434]; P<.001), while other VLMs performed worse (41.1-71.4%; P<.05). Hallucinations were rare with AIRead, comparable to radiologists (0.3% [4/1425]) vs. 0.1% [1/1425]; P=.21), but frequent with other models (5.4-17.4%; P<.05). Language clarity was higher with AIRead (82.9% [1189/1434]), Lingshu (88.0% [1262/1434]), and MedVersa (88.4% [1268/1434]) compared with radiologists (78.1% [1120/1434]; P<.05). Sensitivity varied substantially across VLMs for the common findings: AIRead, 15.5-86.7%; Lingshu, 2.4-86.7%; MAIRA-2, 6.0-72.0%; MedGemma, 4.8-76.7%; and MedVersa, 20.2-69.3%. Conclusion: Medical VLMs for CXR report generation exhibited variable performance in report quality and diagnostic measures.

Paper number 4:
Title: Dependent Reachable Sets for the Constant Bearing Pursuit Strategy
Authors: Venkata Ramana Makkapati, Tulasi Ram Vechalapu, Vinodhini Comandur, Seth Hutchinson
Abstract: This paper introduces a novel reachability problem for the scenario where one agent follows another agent using the constant bearing pursuit strategy, and analyzes the geometry of the reachable set of the follower. Key theoretical results are derived, providing bounds for the associated dependent reachable set. Simulation results are presented to empirically establish the shape of the dependent reachable set. In the process, an original optimization problem for the constant bearing strategy is formulated and analyzed.

Paper number 5:
Title: Datamodel-Based Data Selection for Nonlinear Data-Enabled Predictive Control
Authors: Jiachen Li, Shihao Li, Dongmei Chen
Abstract: Data-Enabled Predictive Control (DeePC) has emerged as a powerful framework for controlling unknown systems directly from input-output data. For nonlinear systems, recent work has proposed selecting relevant subsets of data columns based on geometric proximity to the current operating point. However, such proximity-based selection ignores the control objective: different reference trajectories may benefit from different data even at the same operating point. In this paper, we propose a datamodel-based approach that learns a context-dependent influence function mapping the current initial trajectory and reference trajectory to column importance scores. Adapting the linear datamodel framework from machine learning, we model closed-loop cost as a linear function of column inclusion indicators, with coefficients that depend on the control context. Training on closed-loop simulations, our method captures which data columns actually improve tracking performance for specific control tasks. Experimental results demonstrate that task-aware selection substantially outperforms geometry-based heuristics, particularly when using small data subsets.

Paper number 6:
Title: FAS-RSMA: Can Fluid Antennas Elevate RSMA Performance?
Authors: Jinyuan Liu, Yong Liang Guan, Tuo Wu, Kai-Kit Wong, Bruno Clerckx
Abstract: As 6G networks demand massive connectivity and stronger interference control, rate-splitting multiple access (RSMA) is attractive because it superposes a common stream and user-private streams and remains effective under imperfect CSIT and heterogeneous traffic. In practical multiuser deployments, two considerations arise: the common stream decoding constraint imposed by the weakest user, and residual inter-user interference can remain non-negligible, particularly in single-input single-output (SISO) broadcast settings and under an imperfect CSIT scenario. Motivated by prior advances of RSMA research, we investigate a complementary mechanism-fluid antenna systems (FAS), with dynamic port reconfiguration supplies adaptive spatial selectivity without altering the RSMA signaling structure. Can FAS help alleviate these considerations and enhance RSMA performance? We develop a tractable correlation-aware analytical framework based on block-correlation models, including constant block correlation (CBC) and variable block correlation (VBC), to capture realistic spatial dependence among ports. Closed-form expressions are derived for outage probability (OP) and average capacity (AC), revealing how port reconfiguration strengthens the weakest effective channel and improves SINR through higher channel gains and lower relative noise impact. Monte Carlo simulations verify the analysis and show that VBC matches simulations more tightly than CBC across all port configurations. Finally, FAS-RSMA provides clear gains over conventional antenna systems and NOMA, achieving lower OP and higher AC by combining RSMA interference management with FAS spatial diversity.

Paper number 7:
Title: Distributed Integrated Sensing and Edge AI Exploiting Prior Information
Authors: Biao Dong, Bin Cao, Guan Gui, Qinyu Zhang
Abstract: This paper investigates a distributed ISEA system under a Bayesian framework, focusing on incorporating task-relevant priors to maximize inference performance. At the sensing level, an RWB estimator with a GM prior is designed. By weighting class-conditional posterior means with responsibilities, RWB effectively denoises features and outperforms ML at low SNR. At the communication level, two theoretical proxies are introduced: the computation-optimal and decision-optimal proxies. Optimal transceiver designs in terms of closed-form power allocation are derived for both TDM and FDM settings, revealing threshold-based and dual-decomposition structures. Results show that the discriminant-aware allocation yields additional inference gains.

Paper number 8:
Title: MedCondDiff: Lightweight, Robust, Semantically Guided Diffusion for Medical Image Segmentation
Authors: Ruirui Huang, Jiacheng Li
Abstract: We introduce MedCondDiff, a diffusion-based framework for multi-organ medical image segmentation that is efficient and anatomically grounded. The model conditions the denoising process on semantic priors extracted by a Pyramid Vision Transformer (PVT) backbone, yielding a semantically guided and lightweight diffusion architecture. This design improves robustness while reducing both inference time and VRAM usage compared to conventional diffusion models. Experiments on multi-organ, multi-modality datasets demonstrate that MedCondDiff delivers competitive performance across anatomical regions and imaging modalities, underscoring the potential of semantically guided diffusion models as an effective class of architectures for medical imaging tasks.

Paper number 9:
Title: Vision Transformer for Classification of UAV and Helicopters Using Micro-Doppler Spectrograms in Surveillance Radar
Authors: Arkadiusz Czuba
Abstract: Machine learning researchers strive to develop better and better algorithms to solve computer vision problems, such as image classification. In recent years, the classification of micro-Doppler spectrograms has also benefited from these findings. Convolutional neural networks (CNNs) became the gold standard for these tasks. Unfortunately, CNNs can work on fixed-resolution images, or they need to resize mismatched images to fit input dimensions. It can become a problem when micro-Doppler spectrograms are generated with e.g. different integration times. The goal of this work was to classify the UAV and helicopters micro-Doppler spectrograms with different duration times, using the Vision Transformer (ViT) architecture. Before that, spectrograms signal-to-noise-ratio and micro-Doppler features visibility were improved by denoising algorithm based on modified Dual Tree Complex Wavelet Transform. The experiments were conducted on real data collected using surveillance, short range, military radar. As a result, it has been shown that the ViT model achieved 97.76\% accuracy for this task. To further interpret the network performance, the raw self-attention maps were analyzed.

Paper number 10:
Title: Distributed Observer and Controller Design for Linear Systems: A Separation-Based Approach
Authors: Ganghui Cao, Xunyuan Yin
Abstract: This paper investigates the problem of consensus-based distributed control of linear time-invariant multi-channel systems subject to unknown inputs. A distributed observer-based control framework is proposed, within which observer nodes and controller nodes collaboratively perform state estimation and control tasks. Consensus refers to a distributed cooperative mechanism by which each observer node compares its state estimate with those of neighboring nodes, and use the resulting discrepancies to update its own state estimate. One key contribution of this work is to show that the distributed observers and the distributed controllers can be designed independently, which parallels the classical separation principle. This separability within the distributed framework is enabled by a discontinuous consensus strategy and two adaptive algorithms developed specifically for handling the unknown inputs. Theoretical analysis and numerical simulation results demonstrate the effectiveness of the proposed framework in achieving state estimation, stabilization, and tracking control objectives.

Paper number 11:
Title: Rotatable Antenna-array-enhanced Direction-sensing for Low-altitude Communication Network: Method and Performance
Authors: Jinbing Jiang, Feng Shu, Bin Deng, Maolin Li, Jiatong Bai, Yan Wang, Cunhua Pan, Jiangzhou Wang
Abstract: In a practical multi-antenna receiver, each element of the receive antenna array has a directive antenna pattern, which is still not fully explored and investigated in academia and industry until now. When the emitter is deviated greatly from the normal direction of antenna element or is close to the null-point direction, the sensing energy by array will be seriously attenuated such that the direction-sensing performance is degraded significantly. To address such an issue, a rotatable array system is established with the directive antenna pattern of each element taken into account, where each element has the same antenna pattern. Then, the corresponding the Cramer-Rao lower bound (CRLB) is derived. Finally, a recursive rotation Root-MUSIC (RR-Root-MUSIC) direction-sensing method is proposed and its mean-square-error (MSE) performance is evaluated by the derived CRLB. Simulation results show that the proposed rotation method converges rapidly with about ten iterations, and make a significant enhancement on the direction-sensing accuracy in terms of MSE when the target direction departs seriously far away from the normal vector of array. Compared with conventional Root-MUSIC, the sensing performance of the proposed RR-Root-MUSIC method is much closer to the CRLB.

Paper number 12:
Title: A 40 GHz Low-Power Variable-Gain Low Noise Amplifier in 28-nm CMOS Process
Authors: Harshith Reddy, Pankaj Arora
Abstract: A Low-Power Variable Gain (VG) mm-Wave Low Noise Amplifier (LNA) is designed and simulated in a 28-nm CMOS process. The LNA utilizes a simple, yet novel, technique presented in this paper to vary the small-signal output resistance to provide gain control. The amplifier also utilizes forward body biasing to reduce the supply voltage to 0.7 V and enhance power efficiency. A simultaneous noise and input matching (SNIM) technique is used to provide robust input matching and noise performance during gain adjustment. The proposed VG-LNA achieves a peak gain of 21 dB at 40.5 GHz with a noise figure of 2.8 dB and consumes only 4.5 mW. At the highest gain configuration, an input-referred 1-dB compression of -21 dBm and IP3 of -7.8 dBm are achieved, which increase to -14.8 dBm and 1.2 dBm, respectively, at the lowest gain configuration. Regardless of the gain control voltage, the LNA attains a very good FoM as compared to the state-of-the-art.

Paper number 13:
Title: Distributionally Robust Acceleration Control Barrier Filter for Efficient UAV Obstacle Avoidance
Authors: Dnyandeep Mandaokar, Bernhard Rinner
Abstract: Dynamic obstacle avoidance (DOA) for unmanned aerial vehicles (UAVs) requires fast reaction under limited onboard resources. We introduce the distributionally robust acceleration control barrier function (DR-ACBF) as an efficient collision avoidance method maintaining safety regions. The method constructs a second-order control barrier function as linear half-space constraints on commanded acceleration. Latency, actuator limits, and obstacle accelerations are handled through an effective clearance that considers dynamics and delay. Uncertainty is mitigated using Cantelli tightening with per-obstacle risk. A DR-conditional value at risk (DR-CVaR)based early trigger expands margins near violations to improve DOA. Real-time execution is ensured via constant-time Gauss-Southwell projections. Simulation studies achieve similar avoidance performance at substantially lower computational effort than state-of-the-art baseline approaches. Experiments with Crazyflie drones demonstrate the feasibility of our approach.

Paper number 14:
Title: Diffuse scattering measurements and mechanism analysis at 8, 12, and 28 GHz for typical building surfaces
Authors: Tongjia Zhang, Shu Sun, Meixia Tao, Qiuming Zhu, Ruifeng Gao
Abstract: This study investigates the fundamental diffuse scattering mechanisms from three typical building wall surfaces, conducting measurements and model parameterization at 28 GHz and two key FR3 frequencies (8 GHz and 12 GHz). A novel three-dimensional (3D) measurement procedure is proposed to capture comprehensive spatial characteristics, and its effectiveness in improving parameterization accuracy was verified using 28 GHz data. For parameterization, we developed a new method utilizing two dimensions of the high-bandwidth power delay profile-received power and delay spread-thereby fully leveraging the rich information provided by such measurements. Furthermore, we introduce the ER-BK hybrid model, which integrates the Beckmann-Kirchhoff (BK) model's high accuracy and cross-frequency adaptability with the Effective Roughness (ER) model's simplicity, applying it to the building surfaces. Our results show that diffuse scattering at 8 GHz and 12 GHz is highly similar, distinct from that at 28 GHz. A comparison revealed that the BK model provides a better fit for our FR3 measurement data. Crucially, we validated the angular generalization of the parameterized BK model using data from a different incident angle than the one used for fitting. The feasibility of the ER-BK hybrid model was also verified through simulation of the parameterized marble surface.

Paper number 15:
Title: Beyond Performance: Probing Representation Dynamics In Speech Enhancement Models
Authors: Yair Amar, Amir Ivry, Israel Cohen
Abstract: We probe internal representations of a speech enhancement (SE) model across noise conditions. Using MUSE, a transformer-convolutional model trained on VoiceBank DEMAND, we analyze activations in encoder, latent, decoder, and refinement blocks while sweeping input signal-to-noise-ratios (SNRs) from -10 to 30 dB. We use Centered Kernel Alignment (CKA) to measure point-wise representation similarity and diffusion distance to capture distributional shifts across SNRs. Results show that the encoder CKA between noisy and clean inputs remains stable and latent and decoder CKA drop sharply as SNR decreases. Linear fits of CKA versus SNR reveal a depth-dependent robustness-sensitivity trade-off. The diffusion distance varies incrementally with SNR within each layer but differs strongly across layers, especially at low SNRs. Together, these findings indicate that noise levels differentially activate model regions and induce distinct inter-layer dynamics, motivating SNR-aware conditioning and refinement strategies for SE.

Paper number 16:
Title: A Highly Configurable Framework for Large-Scale Thermal Building Data Generation to drive Machine Learning Research
Authors: Thomas Krug, Fabian Raisch, Dominik Aimer, Markus Wirnsberger, Ferdinand Sigg, Felix Koch, Benjamin Schäfer, Benjamin Tischler
Abstract: Data-driven modeling of building thermal dynamics is emerging as an increasingly important field of research for large-scale intelligent building control. However, research in data-driven modeling using machine learning (ML) techniques requires massive amounts of thermal building data, which is not easily available. Neither empirical public datasets nor existing data generators meet the needs of ML research in terms of data quality and quantity. Moreover, existing data generation approaches typically require expert knowledge in building simulation. To fill this gap, we present a thermal building data generation framework which we call BuilDa. BuilDa is designed to produce synthetic data of adequate quality and quantity for ML research. The framework does not require profound building simulation knowledge to generate large volumes of data. BuilDa uses a single-zone Modelica model that is exported as a Functional Mock-up Unit (FMU) and simulated in Python. We demonstrate BuilDa by generating data and utilizing it for a transfer learning study involving the fine-tuning of 486 data-driven models.

Paper number 17:
Title: Large-field-of-view lensless imaging with miniaturized sensors
Authors: Yu Ren, Xiaoling Zhang, Xu Zhan, Xiangdong Ma, Yunqi Wang, Edmund Y. Lam, Tianjiao Zeng
Abstract: Lensless cameras replace bulky optics with thin modulation masks, enabling compact imaging systems. However, existing methods rely on an idealized model that assumes a globally shift-invariant point spread function (PSF) and sufficiently large sensors. In reality, the PSF varies spatially across the field of view (FOV), and finite sensor boundaries truncate modulated light--effects that intensify as sensors shrink, degrading peripheral reconstruction quality and limiting the effective FOV. We address these limitations through a local-to-global hierarchical framework grounded in a locally shift-invariant convolution model that explicitly accounts for PSF variation and sensor truncation. Patch-wise learned deconvolution first adaptively estimates local PSFs and reconstructs regions independently. A hierarchical enhancement network then progressively expands its receptive field--from small patches through intermediate blocks to the full image--integrating fine local details with global contextual information. Experiments on public datasets show that our method achieves superior reconstruction quality over a larger effective FOV with significantly reduced sensor sizes. Under extreme miniaturization--sensors reduced to 8% of the original area--we achieve improvements of 2 dB (PSNR) and 5% (SSIM), with particularly notable gains in structural fidelity. Code is available at this https URL .

Paper number 18:
Title: Cooperative Safety Intelligence in V2X-Enabled Transportation: A Survey
Authors: Jiaxun Zhang, Qian Xu, Zhenning Li, Chengzhong Xu, Keqiang Li
Abstract: Vehicle-to-Everything (V2X) cooperation is reshaping traffic safety from an ego-centric sensing problem into one of collective intelligence. This survey structures recent progress within a unified Sensor-Perception-Decision (SPD) framework that formalizes how safety emerges from the interaction of distributed sensing, cooperative perception, and coordinated decision-making across vehicles and infrastructure. Rather than centering on link protocols or message formats, we focus on how shared evidence, predictive reasoning, and human-aligned interventions jointly enable proactive risk mitigation. Within this SPD lens, we synthesize advances in cooperative perception, multi-modal forecasting, and risk-aware planning, emphasizing how cross-layer coupling turns isolated detections into calibrated, actionable understanding. Timing, trust, and human factors are identified as cross-cutting constraints that determine whether predictive insights are delivered early enough, with reliable confidence, and in forms that humans and automated controllers can use. Compared with prior V2X safety surveys, this work (i) organizes the literature around a formal SPD safety loop and (ii) systematically analyzes research evolution and evaluation gaps through a PRISMA-guided bibliometric study of hundreds of publications from 2016-2025. The survey concludes with a roadmap toward cooperative safety intelligence, outlining SPD-based design principles and evaluation practices for next-generation V2X safety systems.

Paper number 19:
Title: Data-Driven Multi-Emitter Localization Using Spatially Distributed Power Measurements
Authors: H. Nazim Bicer
Abstract: With more devices competing for limited spectrum, dynamic spectrum sharing is increasingly vulnerable to interference from unauthorized emitters. This motivates fast detection and localization of these emitters using low-cost, distributed sensors that do not require precise time synchronization. This paper presents two convolutional neural network (CNN) approaches for multi-emitter detection and localization from sparsely sampled power maps. The first method performs single-stage prediction of existence probabilities and positions. The alternative two-stage method first estimates an occupancy map as an interpretable intermediate representation and then localizes emitters. A unified training objective combines binary cross entropy with coordinate regression loss and can handle an unknown emitter count. Small footprint networks, on the order of 70\,k parameters, are trained and evaluated on simulated free-space and urban scenes. Experiments demonstrate that both approaches localize multiple emitters from sparse measurements across diverse environments, with the logits based two-stage variant remaining competitive, and in some cases superior, under extreme sensor sparsity. The findings indicate that small CNNs with a unified objective can be deployed for spectrum monitoring and localization.

Paper number 20:
Title: A Low-Complexity Speech Codec Using Parametric Dithering for ASR
Authors: Ellison Murray, Morriel Kasher, Predrag Spasojevic
Abstract: Dithering is a technique commonly used to improve the perceptual quality of lossy data compression. In this work, we analytically and experimentally justify the use of dithering for ASR input compression. We formalize an understanding of optimal ASR performance under lossy input compression and leverage this to propose a parametric dithering technique for a low-complexity speech compression pipeline. The method performs well at 1-bit resolution, showing a 25\% relative CER improvement, while also demonstrating improvements of 32.4\% and 33.5\% at 2- and 3-bit resolution, respectively, with our second dither choice yielding a reduced data rate. The proposed codec is adaptable to meet performance targets or stay within entropy constraints.

Paper number 21:
Title: From Range Loss to Recovery - Cold Weather Challenges and Design Strategies for Commercial Electric Vehicle Fleets
Authors: Soham Ghosh, Arpit Bohra, Karthik Saikumar
Abstract: The North American commercial electric vehicle (EV) sector is undergoing rapid expansion, with unit sales rising from 21,120 in 2022 to 36,491 in 2023 - a 73% increase, according to the International Energy Agency. However, this accelerating adoption brings emerging technical challenges. One critical concern is the impact of low to extreme winter temperatures (25 degree F to -25 degree F) on EV performance, including reduced energy efficiency and extended charging times. This paper presents a systematic analysis of commercial EV performance degradation under cold weather conditions and its broader implications on grid operations. Monte Carlo simulations, applied using real-world fleet parameters, indicate that approximately 200 MWh of additional daily energy demand may be required in the U.S. alone to offset efficiency losses during severe cold events. The resulting strain on an already stressed winter grid could exacerbate reliability risks. Moreover, increased harmonic distortion associated with cold weather charging behaviors has also been observed, raising concerns about power quality. To address these challenges, this study proposes two practical mitigation strategies: (1) a 'design-integrated safety' battery swapping station model operating in thermally controlled environments to significantly reduce charging downtime, and (2) a hybrid architecture combining roadside fast charging with depot-based deep charging to support continuous fleet utilization without compromising range. Together, these interventions provide a robust foundation for resilient commercial EV integration in cold climates, supporting fleet operators and utilities in managing seasonal performance variability.

Paper number 22:
Title: GCMCG: A Clustering-Aware Graph Attention and Expert Fusion Network for Multi-Paradigm, Multi-task, and Cross-Subject EEG Decoding
Authors: Yiqiao Chen, Zijian Huang, Juchi He, Fazheng Xu, Zhenghui Feng
Abstract: Brain-Computer Interfaces (BCIs) based on Motor Execution (ME) and Motor Imagery (MI) electroencephalogram (EEG) signals offer a direct pathway for human-machine interaction. However, developing robust decoding models remains challenging due to the complex spatio-temporal dynamics of EEG, its low signal-to-noise ratio, and the limited generalizability of many existing approaches across subjects and paradigms. To address these issues, this paper proposes Graph-guided Clustering Mixture-of-Experts CNN-GRU (GCMCG), a novel unified framework for MI-ME EEG decoding. Our approach integrates a robust preprocessing stage using Independent Component Analysis and Wavelet Transform (ICA-WT) for effective denoising. We further introduce a pre-trainable graph tokenization module that dynamically models electrode relationships via a Graph Attention Network (GAT), followed by unsupervised spectral clustering to decompose signals into interpretable functional brain regions. Each region is processed by a dedicated CNN-GRU expert network, and a gated fusion mechanism with L1 regularization adaptively combines these local features with a global expert. This Mixture-of-Experts (MoE) design enables deep spatio-temporal fusion and enhances representational capacity. A three-stage training strategy incorporating focal loss and progressive sampling is employed to improve cross-subject generalization and handle class imbalance. Evaluated on three public datasets of varying complexity (EEGmmidb-BCI2000, BCI-IV 2a, and M3CV), GCMCG achieves overall accuracies of 86.60%, 98.57%, and 99.61%, respectively, which demonstrates its superior effectiveness and strong generalization capability for practical BCI applications.

Paper number 23:
Title: Deep Broadcast Feedback Codes
Authors: Jacqueline Malayter, Yingyao Zhou, Natasha Devroye, Chih-Chun Wang, Christopher Brinton, David J. Love
Abstract: Recent advances in deep learning for wireless communications have renewed interest in channel output feedback codes. In the additive white Gaussian broadcast channel with feedback (AWGN-BC-F), feedback can expand the channel capacity region beyond that of the no-feedback case, but linear analytical codes perform poorly with even small amounts of feedback noise. Deep learning enables the design of nonlinear feedback codes that are more resilient to feedback noise. We extend single-user learned feedback codes for the AWGN channel to the broadcast setting, and compare their performance with existing analytical codes, as well as a newly proposed analytical scheme inspired by the learned schemes. Our results show that, for a fixed code rate, learned codes outperform analytical codes at the same blocklength by using power-efficient nonlinear structures and are more robust to feedback noise. Analytical codes scale more easily to larger blocklengths with perfect feedback and surpass learned codes at higher SNRs.

Paper number 24:
Title: Outage Analysis of TAS-NOMA Systems With Multi-Antenna Users Over α-μ Fading
Authors: Fernando D. Almeida García, Maria C. Luna Alvarado, Lenin P. Jiménez Jiménez, Gustavo Fraidenraich, Michel D. Yacoub, Nathaly V. Orozco Garzón, José D. Vega-Sánchez, Henry R. Carvajal Mora
Abstract: This paper analyzes the outage performance of downlink NOMA systems with transmit antenna selection (TAS) and multi-antenna users over {\alpha}-{\mu} fading. Maximal-ratio combining (MRC) and equal-gain combining (EGC) are considered, with imperfect successive interference cancellation (ipSIC) explicitly modeled. Exact closed-form outage probability (OP) expressions and asymptotic results are derived, offering insights into diversity and coding gains. Simulations validate the analysis, showing that TAS improves the far user's performance and that MRC outperforms EGC. The results also quantify the loss from ipSIC, and highlight the impact of power allocation on joint OP. The proposed framework serves as a unified tool for evaluating TAS-NOMA systems under generalized fading, providing design insights for B5G/6G networks.

Paper number 25:
Title: KinesCeTI: A Modular and Size-Adaptable Force Feedback Glove with Interchangeable Actuation for the Index and Thumb
Authors: Pablo Alvarez Romeo, Mehmet Ercan Altinsoy
Abstract: Force feedback gloves in haptic applications remain constrained by limited adaptability, simplified feedback and fixed architectures that limit force feedback versatility. To address these challenges, we present KinesCeTI, a modular force feedback exoskeleton for the index and thumb, designed as a multipurpose device adaptable to a wide range of hand sizes. The glove incorporates interchangeable thimbles for fingertip or phalanx attachment and a bidirectional tendon transmission that supports both passive and active feedback. It is combined with a modular actuation design, where different feedback systems may be attached. The system was tested with two actuation modules: a compliant ratchet-pawl braking mechanism for passive feedback and a novel one-way clutch for variable active feedback, newly introduced here. The system was evaluated in three user studies with 20 participants each, assessing ergonomics, actuation performance and usability in both real and virtual tasks. Results indicate that the glove adapts to different hand sizes and provides effective feedback with both mechanisms, highlighting its potential as a versatile platform for haptic research.

Paper number 26:
Title: Data-Driven Computation of Polytopic Invariant Sets for Noisy Nonlinear Systems
Authors: Sahand Kiani, Constantino M. Lagoa
Abstract: This paper presents a data-driven framework for computing robust, convex polytopic contractive set for constrained noisy nonlinear systems where an analytical model is not available. Our approach utilizes a finite set of collected noisy measurements to construct a polytopic set that bounds all possible system parameters compatible to available information. Based on previous results, we contribute to provide a sufficient condition for a set to be contractive using Difference of Convex functions for a noisy nonlinear system, while the model is not available. Robustness with respect to unknown model of system is guaranteed by requiring that the computed contractive set is invariant for all possible system models that are compatible with the noisy measurements. We present a tractable, optimization-based algorithm that implements this condition to compute the largest possible contractive set within the state constraint set for the unknown, noisy nonlinear system which is subjected to both state and input constraints. The effectiveness of the proposed methodology is demonstrated with a numerical example.

Paper number 27:
Title: Constraint-Aware Grid-Forming Control for Current Limiting
Authors: Dominic Groß
Abstract: This work develops a constraint-aware grid-forming (GFM) control that explicitly accounts for current limits and modulation limits within the GFM oscillator dynamics generating the GFM voltage reference (i.e., phase angle and magnitude). Broadly speaking, the voltage reference generated by the constraint-aware GFM control minimizes the deviation from conventional unconstrained GFM droop control, while respecting current and modulation limits. The resulting GFM control achieves fast current limiting while preserving transient stability, e.g., exhibiting infinite critical clearing time. To develop the control, we first characterize and analyze the set of converter voltages that do not result in constraint violations. Next, an efficient algorithm for projecting voltages onto the feasible set is developed. Subsequently, these results are used to restrict the dynamics of GFM droop control to the set of feasible voltages. Finally, detailed simulation studies and hardware experiments are used to illustrate and validate the response to short-circuit faults and phase jumps.

Paper number 28:
Title: Box Decoding with Low-Complexity Sort-free Candidate Pruning for MIMO Detection
Authors: Shengchun Yang, Amit Sravan Bora, Emil Matus, Gerhard Fettweis
Abstract: Box Decoding is a sort-free tree-search MIMO detector whose complexity does not scale with the QAM order, achieved by searching a fixed candidate "box" around a zero-forcing (ZF) estimate. Prior work primarily reports small dimensions (e.g. 2x2), since the search visits an exponentially growing number of nodes as the MIMO order increases when no pruning is applied. This letter introduces three deterministic pruning rules that exploit QAM-grid symmetry and relative displacement between the ZF estimate and the nearby QAM points to eliminate unlikely branches, avoiding metric sorting and reducing full metric distance calculations. Simulations show large complexity savings with only a small impact on error performance. The resulting detector preserves QAM-order independence, scales to larger MIMO sizes, and maps naturally to parallel hardware implementation.

Paper number 29:
Title: Sensing-Aided Near-Field Beam Tracking
Authors: Panagiotis Gavriilidis, George C. Alexandropoulos
Abstract: The interplay between large antenna apertures and high carrier frequencies in future wireless systems gives rise to near-field communications, where the curvature of spherical wavefronts renders traditional far-field beamforming models inadequate. This chapter addresses the following fundamental questions on near-field operation: (i) What is the maximum distance where far-field approximations remain effective for path gain prediction and beam design? (ii) What level of position resolution is needed for accurate near-field beam focusing? (iii) How frequently must channel state information be updated to maintain highly directive bweamforming in dynamic scenarios? We develop an analytical framework for assessing near-field beamforming gain degradation due to mismatches between the focusing point and the coordinates of a user. Closed-form expressions for beam correlation, beam sensitivity to user movement, and the direction of fastest beamforming gain degradation are derived. A dynamic polar coordinate grid is also proposed for low complexity and adaptive near-field beam search. Furthermore, we introduce the novel concept of beam coherence time, quantifying the temporal robustness of focused beams and enabling proactive sensing-aided beam tracking strategies. The effect of microstrip losses on the preceding derivations is also analyzed. Finally, extensive simulation results validate the presented theoretical analysis and beam tracking method over randomly generated user trajectories.

Paper number 30:
Title: Energy-Efficient Aerial Network Slicing for Computation Offloading, Data Gathering, and Content Delivery
Authors: Ahmed A. Al-habob, Octavia A. Dobre, Yindi Jing
Abstract: This paper introduces an unmanned aerial vehicle (UAV)-enabled network slicing problem to provide content delivery, sensing data gathering, and mobile edge computing (MEC) services. Three tenants provide services to their clients by sharing a common infrastructure of a set of UAVs. The content delivery tenant needs to guarantee that each of its clients (users) receives the required content, the sensing tenant aims to gather an adequate amount of uncorrelated data, and the MEC tenant provides computing service to its clients. An energy consumption minimization framework is considered to meet the tenants' requirements by optimizing the number of deployed UAVs, the deployment location of each UAV, the transmit power of each deployed UAV, the user-UAV association, and the transmission power as well as the computing resources of each UAV. Taking into account the spatial correlation among the sensing users, a subset of these users is activated to gather the required sensing information. A solution approach technique inherited from graph theory is presented, in which the Lagrange approach derives the transmission power and computing resource allocation expressions. Simulation results illustrate that the proposed framework significantly reduces the total energy consumption.

Paper number 31:
Title: Active Learning of Fractional-Order Viscoelastic Model Parameters for Realistic Haptic Rendering
Authors: Harun Tolasa, Gorkem Gemalmaz, Volkan Patoglu
Abstract: Effective medical simulators necessitate realistic haptic rendering of biological tissues that display viscoelastic material properties, such as creep and stress relaxation. Fractional-order models provide an effective means of describing intrinsically time-dependent viscoelastic dynamics with few parameters, as these models can naturally capture memory effects. However, due to the unintuitive frequency-dependent coupling between the order of the fractional element and the other parameters, determining appropriate parameters for fractional-order models that yield high perceived realism remains a significant challenge. In this study, we propose a systematic means of determining the parameters of fractional-order viscoelastic models that optimizes the perceived realism of haptic rendering across general populations. First, we demonstrate that the parameters of fractional-order models can be effectively optimized through active learning, via qualitative feedback-based human-in-the-loop~(HiL) optimizations, to ensure consistently high realism ratings for each individual. Second, we propose a rigorous method to combine HiL optimization results to form an aggregate perceptual map trained on the entire dataset and demonstrate the selection of population-level optimal parameters from this representation that are broadly perceived as realistic across general populations. Finally, we provide evidence of the effectiveness of the generalized fractional-order viscoelastic model parameters by characterizing their perceived realism through human-subject experiments. Overall, generalized fractional-order viscoelastic models established through the proposed HiL optimization and aggregation approach possess the potential to significantly improve the sim-to-real transition performance of medical training simulators.

Paper number 32:
Title: Bridging FR1 to FR3: Frequency-Continuous Urban Macro/Microcellular Channel Parameterization Anchored at 4.85 GHz
Authors: Inocent Calist, Minseok Kim
Abstract: The transition from 5G to 6G requires radio channel models that are frequency-continuous across the entire FR1--FR3 span, particularly in the under-explored 4--8 GHz region targeted by WRC-27. Existing 3GPP-style models are often specified at discrete frequencies, introducing discontinuities in large-scale parameters (LSPs) at the 7.125 GHz boundary. To address this, we develop a unified framework anchored by rigorous double-directional measurements at 4.85 GHz in three representative UMa/UMi layouts. We derive route-specific statistics for path loss, delay and angular spreads, K-factor, and spatial consistency using robust distance-binning and bootstrap processing. Subsequently, we construct a log-log frequency-continuous LSP model spanning 4.85 to 28 GHz by anchoring these local statistics to complementary high-frequency datasets. The resulting models ensure smoothness across 7.125 GHz and systematically deviate from 3GPP trends, capturing weaker dispersion in urban macrocells (UMa) and stronger frequency-dependent compaction in urban microcells (UMi). The proposed parameter set fills the measurement gap around 4.85 GHz and provides a practical, implementation-ready basis for wideband 5G/6G simulations, mobility evaluation, and spectrum-planning activities across the FR1--FR3 interface.

Paper number 33:
Title: DM-MPPI: Datamodel for Efficient and Safe Model Path Integral Control
Authors: Jiachen Li, Shihao Li, Xu Duan, Dongmei Chen
Abstract: We extend the Datamodels framework from supervised learning to Model Predictive Path Integral (MPPI) control. Whereas Datamodels estimate sample influence via regression on a fixed dataset, we instead learn to predict influence directly from sample cost features, enabling real-time estimation for newly generated samples without online regression. Our influence predictor is trained offline using influence coefficients computed via the Datamodel framework across diverse MPPI instances, and is then deployed online for efficient sample pruning and adaptive constraint handling. A single learned model simultaneously addresses efficiency and safety: low-influence samples are pruned to reduce computational cost, while monitoring the influence of constraint-violating samples enables adaptive penalty tuning. Experiments on path-tracking with obstacle avoidance demonstrate up to a $5\times$ reduction in the number of samples while maintaining control performance and improving constraint satisfaction.

Paper number 34:
Title: Analysis of Optimal Thrust to Mass Ratio Requirement for Maximizing Payload Mass of Lunar Landing Mission
Authors: Aditya Rallapalli, Suraj Kumar, Rijesh MP, C K Koteswar Rao, Bharat Kumar GVP
Abstract: Recent successful lunar landing missions have generated significant interest among space agencies in establishing a permanent human settlement on the Moon. Building a lunar base requires multiple and frequent landing missions to support logistics and mobility applications. In these missions, maximizing payload mass defined as the useful cargo for human settlement is crucial. The landing mass depends on several factors, with the most critical being the maximum thrust available for braking and the engine's specific impulse (ISP). Generally, increasing engine thrust for braking reduces flight duration and, consequently, gravity losses. However, higher thrust also introduces trade-offs, such as increased engine weight and lower ISP, which can negatively impact payload capacity. Therefore, optimizing the descent trajectory requires careful consideration of these parameters to achieve a global solution that maximizes payload mass. Most existing research focuses on solving optimal control problems that minimize propellant consumption for a given thrust. These problems are typically addressed through trajectory optimization, where a minimum-fuel solution is obtained. The optimized trajectory is then executed onboard using polynomial guidance. In this paper, we propose an outer-layer optimization approach based on a Pareto-optimal solution. This method iterates on the maximum available thrust for descent trajectory optimization while incorporating a loss function that accounts for engine mass and ISP losses. By applying this approach, we identify a globally optimal solution that maximizes payload mass while ensuring an optimal landing trajectory.

Paper number 35:
Title: Planar Diffractive Neural Networks Empowered Communications: A Spatial Modulation Scheme
Authors: Xiaokun Teng, Yanqing Ren, Weicong Chen, Wankai Tang, Xiao Li, Shi Jin
Abstract: Diffractive neural networks, where signal processing is embedded into wave propagation, promise light-speed and energy-efficient computation. However, existing three-dimensional structures, such as stacked intelligent metasurfaces (SIMs), face critical challenges in implementation and integration. In contrast, this work pioneers planar diffractive neural networks (PDNNs) empowered communications, a novel architecture that performs signal processing as signals propagate through artificially designed planar circuits. To demonstrate the capability of PDNN, we propose a PDNN-based space-shift-keying (PDNN-SSK) communication system with a single radio-frequency (RF) chain and a maximum power detector. In this system, PDNNs are deployed at both the transmitter and receiver to jointly execute modulation, beamforming, and detection. We conduct theoretical analyses to provide the maximization condition of correct detection probability and derive the closed-form expression of the symbol error rate (SER) for the proposed system. To approach these theoretical benchmarks, the phase shift parameters of PDNNs are optimized using a surrogate model-based training approach, which effectively navigates the high-dimensional, non-convex optimization landscape. Extensive simulations verify the theoretical analysis framework and uncover fundamental design principles for the PDNN architecture, highlighting its potential to revolutionize RF front-ends by replacing conventional digital baseband modules with this integrable RF computing platform.

Paper number 36:
Title: Covariance-Guided DFT Beam Selection for Beamspace ESPRIT in Hybrid mmWave MIMO Receivers
Authors: Rıfat Volkan Şenyuva
Abstract: We consider direction-of-arrival estimation in hybrid analog/digital mmWave MIMO receivers that employ DFT beamspace processing with a limited number of RF chains. Building on beamspace ESPRIT, we develop a covariance-guided beam selection framework that reconstructs a virtual fully digital subarray, fits a structured signal-plus-noise covariance model, and uses the resulting denoised covariance to select, for each coarse sector, a small contiguous block of DFT beams under a beam-budget constraint. The selected beams feed a sparse beamspace Unitary ESPRIT stage, so that the overall complexity is dominated by a single low-dimensional ESPRIT call while retaining a large effective aperture. Monte Carlo simulations for a 32-element uniform linear array with three paths show that, relative to a standard sectorization-based beam selector built on the same DFT codebook and ESPRIT estimator, the proposed method attains near Cramér--Rao bound accuracy at moderate array signal-to-noise ratios, substantially reduces the gap to the bound and the failure rate, and offers favorable accuracy--runtime trade-offs under dynamic RF budgets and sector-edge stress tests.

Paper number 37:
Title: Mechatronic Design, Dynamic Modeling, and Real-Time Control of a Movable Scaffold
Authors: M. Özgün Güleç, Koray K. Şafak
Abstract: This study presents mechatronic design, dynamic modeling, simulations and real-time control experiments of a new movable scaffolding system. The proposed system consists of a 3 degrees-of-freedom movable platform, which can be positioned on the outer surface of buildings. The platform is supported and driven by cords that are wound on pulleys and coupled to servo controlled dc-motors located at four corners of the building surface. A mathematical model considering the actuator dynamics for this cable-driven mechanism is obtained and its simulation results are presented. Design, manufacture and real-time control tests of a prototype has been done. Both numerical simulations and experiments provide good positioning performance of the proposed cable-driven mechanism.

Paper number 38:
Title: Arabic TTS with FastPitch: Reproducible Baselines, Adversarial Training, and Oversmoothing Analysis
Authors: Lars Nippert
Abstract: Arabic text-to-speech (TTS) remains challenging due to limited resources and complex phonological patterns. We present reproducible baselines for Arabic TTS built on the FastPitch architecture and introduce cepstral-domain metrics for analyzing oversmoothing in mel-spectrogram prediction. While traditional Lp reconstruction losses yield smooth but over-averaged outputs, the proposed metrics reveal their temporal and spectral effects throughout training. To address this, we incorporate a lightweight adversarial spectrogram loss, which trains stably and substantially reduces oversmoothing. We further explore multi-speaker Arabic TTS by augmenting FastPitch with synthetic voices generated using XTTSv2, resulting in improved prosodic diversity without loss of stability. The code, pretrained models, and training recipes are publicly available at: this https URL.

Paper number 39:
Title: Fundamental Advances in Short-Circuit Measurement: A Novel Time-Resolved Diode-Clamp Circuit Paradigm
Authors: Alex Mwololo Kimuya, Dickson Mwenda Kinyua
Abstract: Conventional electrical fault models, which rely on static thresholds and instantaneous trip mechanisms, fail to capture the time-evolving dynamics of real faults, creating vulnerabilities in modern power systems. This paper introduces a diode-clamp circuit architecture that reconceives short-circuits as governed, sustained processes and establishes a physics-consistent, measurement system. An Arduino-based data acquisition system recorded continuous fault evolution across multiple input voltages and durations. Multi-resolution sampling at 10ms, 50ms, and 100ms enabled high-fidelity capture of both transients and sustained-state dynamics. The clamped mechanism constrained the circuit to a bounded regime, enabling repeatable observation. Experiments yielded definitive, measurable minima and maxima for voltage, current, and resistance, empirically refuting the classical assumption of instantaneous, unbounded current. Newly introduced metrics quantify this performance: the Sustained-to-Capacitive Energy Ratio (SCER ~1.53x10^12) proves fault energy originates from sustained dynamics, not transient discharge. The Sustained Fault Efficiency (SFE>1) demonstrates that governed fault power can exceed nominal operating power. This work provides the first fully validated short-circuit quantification system, yielding empirical data for next-generation battery management, adaptive grid protection, and fault-tolerant electronics.

Paper number 40:
Title: Fault-Tolerant Temperature Control of HRSG Superheaters: Stability Analysis Under Valve Leakage Using Physics-Informed Neural Networks
Authors: Mojtaba Fanoodi, Farzaneh Abdollahi, Mahdi Aliyari Shoorehdeli, Mohsen Maboodi
Abstract: Faults and operational disturbances in Heat Recovery Steam Generators (HRSGs), such as valve leakage, present significant challenges, disrupting steam temperature regulation and potentially causing efficiency losses, safety risks, and unit shutdowns. Traditional PI controllers often struggle due to inherent system delays, nonlinear dynamics, and static gain limitations. This paper introduces a fault-tolerant temperature control framework by integrating a PI plus feedforward control strategy with Physics-Informed Neural Networks (PINNs). The feedforward component anticipates disturbances, preemptively adjusting control actions, while the PINN adaptively tunes control gains in real-time, embedding thermodynamic constraints to manage varying operating conditions and valve leakage faults. A Lyapunov-based stability analysis confirms the asymptotic convergence of temperature tracking errors under bounded leakage conditions. Simulation results using operational data from the Pareh-Sar combined cycle power plant demonstrate significantly improved response times, reduced temperature deviations, enhanced fault resilience, and smooth gain adjustments. The proposed adaptive, data-driven methodology shows strong potential for industrial deployment, ensuring reliable operation, autonomous fault recovery, and enhanced performance in HRSG systems.

Paper number 41:
Title: Approximating Analytically-Intractable Likelihood Densities with Deterministic Arithmetic for Optimal Particle Filtering
Authors: Orestis Kaparounakis, Yunqi Zhang, Phillip Stanley-Marbell
Abstract: Particle filtering algorithms have enabled practical solutions to problems in autonomous robotics (self-driving cars, UAVs, warehouse robots), target tracking, and econometrics, with further applications in speech processing and medicine (patient monitoring). Yet, their inherent weakness at representing the likelihood of the observation (which often leads to particle degeneracy) remains unaddressed for high-frequency and resource-constrained systems. Improvements such as the optimal proposal and auxiliary particle filter mitigate this issue under specific circumstances and with increased computational cost. This work presents a new particle filtering method and its implementation, which enables tunably-approximative representation of arbitrary likelihood densities as program transformations of parametric distributions. Our method leverages a recent computing platform that can perform deterministic computation on probability distribution representations (UxHw) without relying on stochastic methods. For non-Gaussian non-linear systems and with an optimal-auxiliary particle filter, we benchmark the likelihood evaluation error and speed for a total of 294840 evaluation points. For such models, the results show that the UxHw method leads to as much as 37.7x speedup compared to the Monte Carlo alternative. For narrow uniform observation noise, the particle filter falsely assigns zero likelihood as much as 81.89% of the time whereas UxHw achieves 1.52% false-zero rate. The UxHw approach achieves filter RMSE improvement of as much as 18.9% (average 3.3%) over the Monte Carlo alternative.

Paper number 42:
Title: The Silence that Speaks: Neural Estimation via Communication Gaps
Authors: Shubham Aggarwal, Dipankar Maity, Tamer Başar
Abstract: Accurate remote state estimation is a fundamental component of many autonomous and networked dynamical systems, where multiple decision-making agents interact and communicate over shared, bandwidth-constrained channels. These communication constraints introduce an additional layer of complexity, namely, the decision of when to communicate. This results in a fundamental trade-off between estimation accuracy and communication resource usage. Traditional extensions of classical estimation algorithms (e.g., the Kalman filter) treat the absence of communication as 'missing' information. However, silence itself can carry implicit information about the system's state, which, if properly interpreted, can enhance the estimation quality even in the absence of explicit communication. Leveraging this implicit structure, however, poses significant analytical challenges, even in relatively simple systems. In this paper, we propose CALM (Communication-Aware Learning and Monitoring), a novel learning-based framework that jointly addresses the dual challenges of communication scheduling and estimator design. Our approach entails learning not only when to communicate but also how to infer useful information from periods of communication silence. We perform comparative case studies on multiple benchmarks to demonstrate that CALM is able to decode the implicit coordination between the estimator and the scheduler to extract information from the instances of 'silence' and enhance the estimation accuracy.

Paper number 43:
Title: Assessing the Viability of Fresnel Lenses for Weed Control in Prickly Pear Cactus Cultivation: A Spatiotemporal Coverage Perspective
Authors: Euzeli C. dos Santos Jr., Josinaldo Lopes Araujo Rocha, Anielson dos Santos Souza, Isaac Soares de Freitas, Hudson E. Alencar Menezes
Abstract: In tropical semiarid regions, prickly pear cactus has emerged as a vital forage resource due to its high drought tolerance and minimal water requirements. However, even limited weed infestation can severely compromise cactus productivity, as the species are highly sensitive to competition for essential resources, which includes water, mineral nutrients, and sun exposure. Conventional herbicide-based weed control strategies face growing limitations due to resistance development and environmental concerns, underscoring the need for sustainable alternatives. This study revisits the historically underexplored application of linear Fresnel lenses for thermal weed control and establishes the technical feasibility of a contemporary autonomous weed management system that incorporates LFL technology within an unmanned ground vehicle platform. Leveraging real-time image processing, georeferencing, and mechanical actuation, the system can perform a two-phase operation-weed mapping during non-optimal solar hours and targeted solar termination during peak irradiance. Analytical modeling quantifies the effective area coverage and time constraints imposed by the solar window. Preliminary results indicate that, while unsuitable for dense weed infestations, the system presents a viable solution for precision, post-emergent weed control in sparse infestations. The favorable solar geometry in tropical zones, especially in the Brazilian semiarid region, and the targeted nature of the approach make this technology particularly well-suited for sustainable agriculture in under-resourced regions.

Paper number 44:
Title: An Acoustic Communication Model in Plants
Authors: Fatih Merdan, Ozgur B. Akan
Abstract: Molecular communication (MC) studies biological signals that are found in nature. Most MC literature focuses on particle properties, even though many natural phenomena exhibit wave-like behavior. One such signal is sound waves. Understanding how sound waves are used in nature can help us better utilize this signal in our interactions with our environment. To take a step in this direction, in this paper, we examine how plants process incoming sound waves and take informed actions. Indeed, plants respond to sound, yet no quantitative communication-theoretic model currently explains this behavior. This study develops the first end-to-end acoustic communication framework for plants. The model is formed following the biological steps of the incoming signal, and a mathematical description is constructed at each step following basic biological models. The resulting end-to-end communication-theoretic model is analyzed using MATLAB. Simulations show that a $200$ $Hz$, $20$ $mu Pa$ stimulus elevates cytosolic $Ca^{2+}$ from $150$ $nM$ to $230 \pm 10$ $nM$ within $50$ seconds which can cause root bending in plants in the long run. This work establishes quantitative phytoacoustics, enabling bio-inspired acoustic connections for precision agriculture and plant signaling research.

Paper number 45:
Title: Negotiating Highway Interchange Traffic with a Decentralized Instability-Driven CBF-based Algorithm
Authors: Mrdjan Jankovic, Shreshta Rajakumar Deshpande, Gopika Ajaykumar
Abstract: In this paper we consider an interchange lane-swap scenario, a limited stretch of highway with two parallel lanes where most vehicles want to change lanes. We show that a particular decentralized Control Barrier Function based algorithm executes lane swaps efficiently, with minimal speed change, within the specified (short) road segment at high traffic densities (3,500 vehicles per hour per lane). Our main point is that controller tuning, the speed of inter-agent instability, plays a major role in the performance of the vehicle group. This is illustrated by comparing two different tunings of the controller and a third one where the lane swap is enforced by virtual guard rails. Like fighter jet dynamic instability improving maneuverability, the inter-agent instability improves agility of a group of vehicles. We emphasize that the controllers considered are decentralized: agents do not know if others want to change lanes or not.

Paper number 46:
Title: Supervisory control synthesis for multilevel DES with local buses
Authors: Marzhan M. Baubekova, Martijn A. Goorden, Michel A. Reniers, Joanna M. v.d. Mortel-Fronczak, Jacobus E. Rooda, Wan J. Fokkink
Abstract: In multilevel supervisor synthesis, dependency structure matrix techniques can be used to transform the models of plants and requirements into a tree-structured hierarchical decomposition of the synthesis problem and thus efficiently synthesize local supervisors. A bus component, which has many dependencies across a system, tends to lead to an undesirable clustering of many components in one synthesis subproblem. Prior work showed how to recognize and properly treat a global bus structure. In this paper we leverage this work from global to local bus structures through a novel multilevel discrete-event system (MLDES) architecture. Specifically, the hierarchical system decomposition is revisited by allowing bus detection not only on the top level but at each level of the system hierarchy. Given this architecture, an algorithm is introduced that constructs a tree-structured MLDES. A case study on a production line shows the effectiveness of the proposed method through significantly improved synthesis performance, measured by the sum of the controlled state-space sizes of the local supervisors.

Paper number 47:
Title: Semantic Communications for Vehicle-Based Mission-Critical Services: Challenges and Solutions
Authors: Hui Zhou, Jiaying Guo, Marios Aristodemou, Zhaoyang Du, Shen Wang, Xiaolan Liu, Soufiene Djahel, Celimuge Wu
Abstract: As mission-critical (MC) services such as Unmanned Aerial Vehicles (UAVs) based emergency communication and Internet of Vehicles (IoVs) enabled autonomous driving emerge, the traditional communication framework can not meet the growing demands for higher reliability and lower latency and the increasing transmission loads. Semantic Communication (SemCom), an emerging communication paradigm that shifts the focus from bit-level data to its context and intended task at the receiver (i.e., semantic level), is envisioned to be a key revolution in Sixth Generation (6G) networks. However, an explicit and systematic SemCom framework specifically tailored for Vehicle-based MC (VbMC) services has yet to be proposed, primarily due to the complexity and lack of analysis on their MC characteristics. In this article, we first present the key information-critical and infrastructure-critical vehicle-based services within the SemCom framework. We then analyze the unique characteristics of MC services and the corresponding challenges they present for SemCom. Building on this, we propose a novel SemCom framework designed to address the specific needs of MC services in vehicle systems, offering potential solutions to existing challenges. Finally, we present a case study on UAV-based rapid congestion relief, utilizing eXplainable AI (XAI) to validate the effectiveness of the proposed SemCom framework.

Paper number 48:
Title: A Neuromodulable Current-Mode Silicon Neuron for Robust and Adaptive Neuromorphic Systems
Authors: Loris Mendolia, Chenxi Wen, Elisabetta Chicca, Giacomo Indiveri, Rodolphe Sepulchre, Jean-Michel Redouté, Alessio Franci
Abstract: Neuromorphic engineering makes use of mixed-signal analog and digital circuits to directly emulate the computational principles of biological brains. Such electronic systems offer a high degree of adaptability, robustness, and energy efficiency across a wide range of tasks, from edge computing to robotics. Within this context, we investigate a key feature of biological neurons: their ability to carry out robust and reliable computation by adapting their input response and spiking pattern to context through neuromodulation. Achieving analogous levels of robustness and adaptation in neuromorphic circuits through modulatory mechanisms is a largely unexplored path. We present a novel current-mode neuron design that supports robust neuromodulation with minimal model complexity, compatible with standard CMOS technologies. We first introduce a mathematical model of the circuit and provide tools to analyze and tune the neuron behavior; we then demonstrate both theoretically and experimentally the biologically plausible neuromodulation adaptation capabilities of the circuit over a wide range of parameters. All the theoretical predictions were verified in experiments on a low-power 180 nm CMOS implementation of the proposed neuron circuit. Due to the analog underlying feedback structure, the proposed adaptive neuromodulable neuron exhibits a high degree of robustness, flexibility, and scalability across operating ranges of currents and temperatures, making it a perfect candidate for real-world neuromorphic applications.

Paper number 49:
Title: Diffusion-Based Synthesis of 3D T1w MPRAGE Images from Multi-Echo GRE with Multi-Parametric MRI Integration
Authors: Sizhe Fang, Deqiang Qiu
Abstract: Multi-echo Gradient Echo (mGRE) sequences provide valuable quantitative parametric maps, such as Quantitative Susceptibility Mapping (QSM) and transverse relaxation rate (R2*), sensitive to tissue iron and myelin. However, structural morphometry typically relies on separate T1-weighted MPRAGE acquisitions, prolonging scan times. We propose a deep learning framework to synthesize high-contrast 3D T1w MPRAGE images directly from mGRE data, streamlining neuroimaging protocols. We developed a novel multi-parametric conditional diffusion model based on the Fast-DDPM architecture. Unlike conventional intensity-based synthesis, our approach integrates iron-sensitive QSM and R2* maps as physical priors to address contrast ambiguity in iron-rich deep gray matter. We trained and validated the model on 175 healthy subjects. Performance was evaluated against established U-Net and GAN-based baselines using perceptual metrics and downstream segmentation accuracy. Uniquely, we assessed the biological plausibility of synthesized images by replicating population-level statistical associations with age and sex. The proposed framework significantly outperformed baselines, achieving superior perceptual quality and segmentation accuracy, particularly in subcortical regions like the thalamus and pallidum. Crucially, synthesized images preserved essential biological dependencies: regression analyses showed high concordance in age-related atrophy rates, aging effect sizes, and sexual dimorphism patterns compared to ground truth. By effectively leveraging quantitative MRI priors, our diffusion-based method generates strictly biologically plausible T1w images suitable for reliable clinical morphometric analysis. This approach offers a promising pathway to reduce acquisition time by deriving structural contrasts retrospectively from quantitative mGRE sequences.

Paper number 50:
Title: Autonomous Navigation and Station-Keeping on Near-Rectilinear Halo Orbits
Authors: Yuri Shimane, Karl Berntorp, Stefano Di Cairano, Avishai Weiss
Abstract: This article develops an optical navigation (OPNAV) and station-keeping pipeline for the near-rectilinear halo orbit (NRHO) in high-fidelity ephemeris model dynamics. The pipeline involves synthetic images used by the non-iterative horizon-based OPNAV algorithm, fed into an extended Kalman filter. The state estimate is used by a controller to maintain the spacecraft's motion within the vicinity of a reference NRHO. We study differential correction-based and minimization-based implementations of the x-axis crossing control scheme, and propose an improved targeting prediction scheme by incorporating the filter's state covariance with an unscented transform. We also introduce a hysteresis mechanism, which improves station-keeping cost and provides insight into the difference in performance between the differential correction-based and minimization-based approaches. We perform Monte-Carlo experiments to assess the pipeline's tracking and {\Delta}V performances. We report several key findings, including the variability of the filter performance with the sensor field of view and measurement locations, station-keeping cost reduction achieved by the unscented transform-based prediction and hysteresis, as well as variability of the cumulative {\Delta}V as a function of maneuver location due to the periodic structure in the OPNAV-based filter's estimation accuracy.

Paper number 51:
Title: Physics-Constrained Neural Dynamics: A Unified Manifold Framework for Large-Scale Power Flow Computation
Authors: Xuezhi Liu
Abstract: Power flow analysis is a fundamental tool for power system analysis, planning, and operational control. Traditional Newton-Raphson methods suffer from limitations such as initial value sensitivity and low efficiency in batch computation, while existing deep learning-based power flow solvers mostly rely on supervised learning, requiring pre-solving of numerous cases and struggling to guarantee physical consistency. This paper proposes a neural physics power flow solving method based on manifold geometry and gradient flow, by describing the power flow equations as a constraint manifold, and constructing an energy function \(V(\mathbf{x}) = \frac{1}{2}\|\mathbf{F}(\mathbf{x})\|^2\) and gradient flow \(\frac{d\mathbf{x}}{dt} = -\nabla V(\mathbf{x})\), transforming power flow solving into an equilibrium point finding problem for dynamical systems. Neural networks are trained in an unsupervised manner by directly minimizing physical residuals, requiring no labeled data, achieving true "end-to-end" physics-constrained learning.

Paper number 52:
Title: Input-Output Data-Driven Representation: Non-Minimality and Stability
Authors: Joowon Lee, Nam Hoon Jo, Hyungbo Shim, Florian Dörfler, Jinsung Kim
Abstract: Many recent data-driven control approaches for linear time-invariant systems are based on finite-horizon prediction of output trajectories using input-output data matrices. When applied recursively, this predictor forms a dynamic system representation. This data-driven representation is generally non-minimal, containing latent poles in addition to the system's original poles. In this article, we show that these latent poles are guaranteed to be stable through the use of the Moore-Penrose inverses of the data matrices, regardless of the system's stability and even in the presence of small noise in data. This result obviates the need to eliminate the latent poles through procedures that resort to low-rank approximation in data-driven control and analysis. It is then applied to construct a stabilizable and detectable realization from data, from which we design an output feedback linear quadratic regulator (LQR) controller. Furthermore, we extend this principle to data-driven inversion, enabling asymptotic unknown input estimation for minimum-phase systems.

Paper number 53:
Title: Bayesian Optimization for Non-Cooperative Game-Based Radio Resource Management
Authors: Yunchuan Zhang, Jiechen Chen, Junshuo Liu, Robert C. Qiu
Abstract: Radio resource management in modern cellular networks often calls for the optimization of complex utility functions that are potentially conflicting between different base stations (BSs). Coordinating the resource allocation strategies efficiently across BSs to ensure stable network service poses significant challenges, especially when each utility is accessible only via costly, black-box evaluations. This paper considers formulating the resource allocation among spectrum sharing BSs as a non-cooperative game, with the goal of aligning their allocation incentives toward a stable outcome. To address this challenge, we propose PPR-UCB, a novel Bayesian optimization (BO) strategy that learns from sequential decision-evaluation pairs to approximate pure Nash equilibrium (PNE) solutions. PPR-UCB applies martingale techniques to Gaussian process (GP) surrogates and constructs high probability confidence bounds for utilities uncertainty quantification. Experiments on downlink transmission power allocation in a multi-cell multi-antenna system demonstrate the efficiency of PPR-UCB in identifying effective equilibrium solutions within a few data samples.

Paper number 54:
Title: Retroreflective Optical ISAC for 6G: Technologies, Applications and Future Directions
Authors: Tiantian Chu, Chen Chen, Jia Ye, Xin Xiong, Sihua Shao, Zhihong Zeng, Dengke Wang, Fengli Yang, Guanjun Xu, Harald Haas
Abstract: Integrated sensing and communication (ISAC) has emerged as a key technological paradigm for sixth generation (6G) mobile networks, aiming to unify sensing and communication in a spectrally efficient and hardware lightweight manner. Radio frequency ISAC (RF-ISAC) is constrained by spectrum crowding, limited sensing resolution, and susceptibility to electromagnetic interference. In contrast, optical ISAC (O-ISAC) leverages the large bandwidth and short wavelength of optical carriers and is regarded as an important complement to RF-ISAC. However, conventional O-ISAC relies on natural optical reflections from target surfaces, which generate weak echoes that are highly dependent on surface materials, thereby limiting the achievable sensing range and sensing accuracy. This article introduces retroreflective optical ISAC (RO-ISAC), which alleviates these limitations by equipping targets with compact retroreflective modules. These modules return incident light approximately back to the source over a useful range of incidence angles, forming a well controlled double pass optical path with strong and stable echoes, and thereby further unlocking the application potential of O-ISAC. The conceptual architecture of RO-ISAC is presented together with the underlying retroreflection mechanism. Key enabling technologies for RO-ISAC systems are discussed, including channel modeling, waveform design, bidirectional transmission, and multi-target sensing and communication, with representative details and experimental validation. The suitability of RO-ISAC is analyzed in indoor, aerial, underwater, and satellite scenarios, and challenges and research directions related to mobility, cooperative networking, intelligent operation, and sustainable deployment are outlined, pointing toward robust and scalable RO-ISAC deployment in future 6G networks.

Paper number 55:
Title: Experimental Methods, Health Indicators, and Diagnostic Strategies for Retired Lithium-ion Batteries: A Comprehensive Review
Authors: Song Zhang, Ruohan Guo, Xiaohua Ge, Perter Mahon, Weixiang Shen
Abstract: Reliable health assessment of retired lithium-ion batteries is essential for safe and economically viable second-life deployment, yet remains difficult due to sparse measurements, incomplete historical records, heterogeneous chemistries, and limited or noisy battery health labels. Conventional laboratory diagnostics, such as full charge-discharge cycling, pulse tests, Electrochemical Impedance Spectroscopy (EIS) measurements, and thermal characterization, provide accurate degradation information but are too time-consuming, equipment-intensive, or condition-sensitive to be applied at scale during retirement-stage sorting, leaving real-world datasets fragmented and inconsistent. This review synthesizes recent advances that address these constraints through physical health indicators, experiment testing methods, data-generation and augmentation techniques, and a spectrum of learning-based modeling routes spanning supervised, semi-supervised, weakly supervised, and unsupervised paradigms. We highlight how minimal-test features, synthetic data, domain-invariant representations, and uncertainty-aware prediction enable robust inference under limited or approximate labels and across mixed chemistries and operating histories. A comparative evaluation further reveals trade-offs in accuracy, interpretability, scalability, and computational burden. Looking forward, progress toward physically constrained generative models, cross-chemistry generalization, calibrated uncertainty estimation, and standardized benchmarks will be crucial for building reliable, scalable, and deployment-ready health prediction tools tailored to the realities of retired-battery applications.

Paper number 56:
Title: Joint CFO-Channel Estimation over CFO-Coherent SS Burst Sets for Low-Altitude Radio Mapping
Authors: Bowen Li, Haotian Zhang, Mu Jia, Junting Chen, Nikolaos Pappas
Abstract: Extending terrestrial networks into low-altitude airspace is a practical way to support aerial services, and accurate low-altitude radio maps are essential for characterizing terrestrial base station (BS) coverage and guiding system design. This work targets per-cell per-beam radio mapping from 5G new radio (NR) synchronization signal (SS) burst sets. Conventional processing treats interference as noise and focuses on the strongest link, which is insufficient to comprehensive awareness of the radio environment and ineffective in dense multi-cell low-altitude scenarios. We propose a successive waveform reconstruction and cancellation framework that iteratively estimates, reconstructs, and subtracts the SSs of stronger BSs, thereby enabling reliable detection and estimation of ultra-weak signals. To support this, we introduce the notion of a carrier frequency offset (CFO)-coherent block within which a common-CFO/per-synchronization signal block (SSB)-channel model holds and design a joint CFO-channel estimator that coherently aggregates multiple SSBs within each CFO-coherent block. We further derive closed-form scaling laws that relate estimation accuracy to unmanned aerial vehicle (UAV) speed, motion geometry, burst periodicity, and the length of the CFO-coherent block. Simulations show that the proposed framework can detect and estimate SSs at signal-to-interference-and-noise ratio (SINR) levels down to -30 dB. Field tests at 150 m altitude demonstrate per-beam coverage maps for more than ten overlapping BSs and reveal that, despite strong received power, the measured SINR rarely exceeds 10 dB, underscoring the need for careful interference management in low-altitude airspace.

Paper number 57:
Title: Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels
Authors: Oguz Bedir (1), Nurullah Sevim (1), Mostafa Ibrahim (2), Sabit Ekin (2 and 1) ((1) Electrical &amp; Computer Engineering, Texas A&amp;M University, USA, (2) Engineering Technology &amp; Industrial Distribution, Texas A&amp;M University, USA)
Abstract: Recent breakthroughs in natural language processing show that attention mechanism in Transformer networks, trained via masked-token prediction, enables models to capture the semantic context of the tokens and internalize the grammar of language. While the application of Transformers to communication systems is a burgeoning field, the notion of context within physical waveforms remains under-explored. This paper addresses that gap by re-examining inter-symbol contribution (ISC) caused by pulse-shaping overlap. Rather than treating ISC as a nuisance, we view it as a deterministic source of contextual information embedded in oversampled complex baseband signals. We propose Masked Symbol Modeling (MSM), a framework for the physical (PHY) layer inspired by Bidirectional Encoder Representations from Transformers methodology. In MSM, a subset of symbol aligned samples is randomly masked, and a Transformer predicts the missing symbol identifiers using the surrounding "in-between" samples. Through this objective, the model learns the latent syntax of complex baseband waveforms. We illustrate MSM's potential by applying it to the task of demodulating signals corrupted by impulsive noise, where the model infers corrupted segments by leveraging the learned context. Our results suggest a path toward receivers that interpret, rather than merely detect communication signals, opening new avenues for context-aware PHY layer design.

Paper number 58:
Title: zea: A Toolbox for Cognitive Ultrasound Imaging
Authors: Tristan S.W. Stevens, Wessel L. van Nierop, Ben Luijten, Vincent van de Schaft, Oisín Nolan, Beatrice Federici, Louis D. van Harten, Simon W. Penninga, Noortje I.P. Schueler, Ruud J.G. van Sloun
Abstract: We present zea (pronounced ze-yah), a Python package for cognitive ultrasound imaging that offers a flexible, modular, and differentiable pipeline for ultrasound data processing. Additionally, it includes a collection of pre-defined models for ultrasound image and signal processing. The toolbox is designed to be easy to use, with a high-level interface that enables users to define custom ultrasound reconstruction pipelines and integrate deep learning models seamlessly. Built on top of Keras 3, it supports all three major deep learning backends: TensorFlow, PyTorch, and JAX, making it straightforward to incorporate custom ultrasound processing pipelines into machine learning workflows. Documentation is available at this https URL.

Paper number 59:
Title: RadioPiT: Radio Map Generation with Pixel Transformer Driven by Ultra-Sparse Real-World Data
Authors: Zeyao Sun, Bohao Fan, Qingyu Liu, Shuhang Zhang, Lingyang Song
Abstract: As wireless communication networks rapidly evolve, spectrum resources are increasingly scarce, making effective spectrum management critically important. Radio map is a spatial representation of signal characteristics across different locations in a given area, which serves as a key tool for enabling precise spectrum management. To generate accurate radio maps, extensive research efforts have been made. However, most existing studies are conducted on simulation data, which differs significantly from real-world data and cannot accurately reflect the spectrum characteristics of practical environments. To tackle this problem, we construct a dataset of real-world radio map with a self-developed measurement system. Due to the limited volume of real-world data and the distributional discrepancies between simulation and real-world data, we propose a Pixel Transformer (PiT)- based model enhanced with the test-time adaptation (TTA) strategy, named RadioPiT, for real-world radio map generation. Experimental results demonstrate that our proposed RadioPiT significantly outperforms baseline methods in real-world scenarios, yielding a 21.9% decrement in the root mean square error (RMSE) compared to RadioUNet.

Paper number 60:
Title: Identifiability Conditions for Acoustic Feedback Cancellation with the Two-Channel Adaptive Feedback Canceller Algorithm
Authors: Arnout Roebben, Toon van Waterschoot, Jan Wouters, Marc Moonen
Abstract: In audio signal processing applications with a microphone and a loudspeaker within the same acoustic environment, the loudspeaker signals can feed back into the microphone, thereby creating a closed-loop system that potentially leads to system instability. To remove this acoustic coupling, prediction error method (PEM) feedback cancellation algorithms aim to identify the feedback path between the loudspeaker and the microphone by assuming that the input signal can be modelled by means of an autoregressive (AR) model. It has previously been shown that this PEM framework and resulting algorithms can identify the feedback path correctly in cases where the forward path from microphone to loudspeaker is sufficiently time-varying or non-linear, or when the forward path delay equals or exceeds the order of the AR model. In this paper, it is shown that this delay-based condition can be generalised for one particular PEM-based algorithm, the so-called two-channel adaptive feedback canceller (2ch-AFC), to an invertibility-based condition, for which it is shown that identifiability can be achieved when the order of the forward path feedforward filter exceeds the order of the AR model. Additionally, the condition number of inversion of the correlation matrix as used in the 2ch-AFC algorithm can serve as a measure for monitoring the identifiability.

Paper number 61:
Title: A Unified Bayesian Framework for Stochastic Data-Driven Smoothing, Prediction, and Control
Authors: Mingzhou Yin, Andrea Iannelli, Seyed Ali Nazari, Matthias A. Müller
Abstract: Extending data-driven algorithms based on Willems' fundamental lemma to stochastic data often requires empirical and customized workarounds. This work presents a unified Bayesian framework that provides a systematic and general method for handling stochastic data-driven tasks, including smoothing, prediction, and control, via maximum a posteriori estimation. %This extends behavioral systems theory to stochastic data. This framework formulates a unified trajectory estimation problem for the three tasks by specifying different types of trajectory knowledge. Then, a Bayesian problem is solved that optimally combines trajectory knowledge with a data-driven characterization of the trajectory from offline data for a general class of stochastic disturbances. Under specific conditions, this problem is shown to generalize existing data-driven prediction and control algorithms. Numerical examples demonstrate the performance of the unified approach for all three tasks against other data-driven and system identification approaches.

Paper number 62:
Title: Spectral-Energy Efficiency Tradeoff of Nearly-Passive RIS in MIMO URLLC Downlink: Diagonal vs. Beyond Diagonal
Authors: Mohammad Soleymani, Alessio Zappone, Eduard Jorswieck, Marco Di Renzo, Ignacio Santamaria
Abstract: This paper investigates the spectral and energy efficiency (EE) tradeoff of nearly-passive (NP), both locally and globally NP (GNP), reconfigurable intelligent surface (RIS), considering diagonal and beyond-diagonal (BD) implementations in multi-user multiple-input multiple-output (MU-MIMO) broadcast channels designed for ultra-reliable low-latency communication (URLLC). We demonstrate that while all RIS architectures enhance the spectral efficiency, GNP BD-RIS achieves the highest gains. However, its EE is highly sensitive to the static circuit power consumption since BD-RIS has many more circuit elements than diagonal architectures. Furthermore, we demonstrate that the benefits of BD-RIS over diagonal RIS diminish as the number of data streams per user increases due to enhanced channel diversity in MIMO systems.

Paper number 63:
Title: In-Context Learning for Deep Joint Source-Channel Coding Over MIMO Channels
Authors: Meng Hua, Wenjing Zhang, Chenghong Bian, Deniz Gunduz
Abstract: Large language models have demonstrated the ability to perform \textit{in-context learning} (ICL), whereby the model performs predictions by directly mapping the query and a few examples from the given task to the output variable. In this paper, we study ICL for deep joint source-channel coding (DeepJSCC) in image transmission over multiple-input multiple-output (MIMO) systems, where an ICL denoiser is employed for MIMO symbol estimation. We first study the transceiver without any hardware impairments and explore the integration of transformer-based ICL with DeepJSCC in both open-loop and closed-loop MIMO systems, depending on the availability of channel state information (CSI) at the transceiver. For both open-loop and closed-loop scenarios, we propose two MIMO transceiver architectures that leverage context information, i.e., pilot sequences and their outputs, as additional inputs, enabling the DeepJSCC encoder, DeepJSCC decoder, and the ICL denoiser to jointly learn encoding, decoding, and estimation strategies tailored to each channel realization. Next, we extend our study to a more challenging scenario where the transceiver suffers from in-phase and quadrature (IQ) imbalance, resulting in nonlinear MIMO estimation. In this case, the context information is also exploited, facilitating joint learning across the DeepJSCC encoder, decoder, and the ICL denoiser under hardware impairments and varying channel conditions. Numerical results demonstrate that the ICL denoiser for MIMO estimation significantly outperforms the conventional least-squares method, with even greater advantages under IQ imbalance. Moreover, the proposed transformer-based ICL framework, integrated with contextual information, achieves significant improvements in end-to-end image reconstruction quality under transceiver IQ imbalance.

Paper number 64:
Title: Cuffless Blood Pressure Estimation from Six Wearable Sensor Modalities in Multi-Motion-State Scenarios
Authors: Yiqiao Chen, Fazheng Xu, Zijian Huang, Juchi He, Zhenghui Feng
Abstract: Cardiovascular disease (CVD) is a leading cause of morbidity and mortality worldwide, and sustained hypertension is an often silent risk factor, making cuffless continuous blood pressure (BP) monitoring with wearable devices important for early screening and long-term management. Most existing cuffless BP estimation methods use only photoplethysmography (PPG) and electrocardiography (ECG) signals, alone or in combination. These models are typically developed under resting or quasi-static conditions and struggle to maintain robust accuracy in multi-motion-state scenarios. In this study, we propose a six-modal BP estimation framework that jointly leverages ECG, multi-channel PPG, attachment pressure, sensor temperature, and triaxial acceleration and angular velocity. Each modality is processed by a lightweight branch encoder, contrastive learning enforces cross-modal semantic alignment, and a mixture-of-experts (MoE) regression head adaptively maps the fused features to BP across motion states. Comprehensive experiments on the public Pulse Transit Time PPG Dataset, which includes running, walking, and sitting data from 22 subjects, show that the proposed method achieves mean absolute errors (MAE) of 3.60 mmHg for systolic BP (SBP) and 3.01 mmHg for diastolic BP (DBP). From a clinical perspective, it attains Grade A for SBP, DBP, and mean arterial pressure (MAP) according to the British Hypertension Society (BHS) protocol and meets the numerical criteria of the Association for the Advancement of Medical Instrumentation (AAMI) standard for mean error (ME) and standard deviation of error (SDE).

Paper number 65:
Title: An innovative circuit for testing hot carrier and trap generation in GaN Devices
Authors: Moshe Azoulay, Gilad Orr, Gady Golan
Abstract: Microelectronic devices in modern systems are working continuously for prolonged periods of many years. Thus, there is a crucial need for reliability model that will enable us to predict precisely the life cycle of the device and point out on the governing failure mechanisms that are responsible for degradation and failure. This is even more important when high power and frequency devices, especially Normally Off Switch Power transistors are concerned, since the reliability research on those devices lay far behind that of low power digital devices. Our main goal in our lab is to investigate the failure mechanisms of GaN transistors, aimed at determining the reliability factors of the innovative MTOL model. The main goal is to understand the reason for the transformation of the failure mechanism. Employing the recorded data may enable us to predict the performance and life time of the device at different operation parameters such as current, voltage, frequency and temperatures. In this study we employ a new different use for the well-known boost convertor circuit, based on GaN Devices in order to stress the transistor to the maximum values of voltage and current which allows us to examine the reliability of the transistor and accelerating Hot Carrier And Trap Generation failures mechanisms. The acceleration of the failure mechanism should be done in a way that will not affect the electronic device detrimentally and on the other hand we would not need to wait a long time in order to observe the degradation. In this work we will present our new boost converter circuit based on high power GaN HEMT.

Paper number 66:
Title: Multimodal Mixture-of-Experts for ISAC in Low-Altitude Wireless Networks
Authors: Kai Zhang, Wentao Yu, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief
Abstract: Integrated sensing and communication (ISAC) is a key enabler for low-altitude wireless networks (LAWNs), providing simultaneous environmental perception and data transmission in complex aerial scenarios. By combining heterogeneous sensing modalities such as visual, radar, lidar, and positional information, multimodal ISAC can improve both situational awareness and robustness of LAWNs. However, most existing multimodal fusion approaches use static fusion strategies that treat all modalities equally and cannot adapt to channel heterogeneity or time-varying modality reliability in dynamic low-altitude environments. To address this fundamental limitation, we propose a mixture-of-experts (MoE) framework for multimodal ISAC in LAWNs. Each modality is processed by a dedicated expert network, and a lightweight gating module adaptively assigns fusion weights according to the instantaneous informativeness and reliability of each modality. To improve scalability under the stringent energy constraints of aerial platforms, we further develop a sparse MoE variant that selectively activates only a subset of experts, thereby reducing computation overhead while preserving the benefits of adaptive fusion. Comprehensive simulations on three typical ISAC tasks in LAWNs demonstrate that the proposed frameworks consistently outperform conventional multimodal fusion baselines in terms of learning performance and training sample efficiency.

Paper number 67:
Title: How to Capture Human Preference: Commissioning of a Robotic Use-Case via Preferential Bayesian Optimisation
Authors: Sander De Witte, Jeroen Taets, Andras Retzler, Guillaume Crevecoeur, Tom Lefebvre
Abstract: The popularity of Bayesian Optimization (BO) to automate or support the commissioning of engineering systems is rising. Conventional BO, however, relies on the availability of a scalar objective function. The latter is often difficult to define and rarely captures the nuanced judgement of expert operators in industrial settings. Preferential Bayesian Optimization (PBO) addresses this limitation by relying solely on pairwise preference feedback of a human expert, so-called duels. In this paper, we study PBO's capacity to commission a particular setup where a manipulator needs to push a block towards a target position. We benchmark state-of-the-art algorithms in both simulations and in the real world. Our results confirm that PBO can commission the set-up to the satisfaction of an expert operator whilst relying solely on binary preference feedback. To evaluate to what extend the same result can be achieved using conventional BO we investigate the experts decision consistency against an expert-designed cost function. Our study reveals that the experts fail to define a cost function that is in full agreement with their own decision process as witnessed in the PBO experiments. We then show that the auxiliary cost function that is constructed as a by-product of the PBO algorithms outperforms the expert-designed cost function in terms of decision consistency. Furthermore we demonstrate that this cost function can be used with conventional BO algorithms in an effort to reproduce the optimal design. This proofs the preference based cost function captures the experts' preferences perhaps more effectively than the experts could articulate preference themselves. In conclusion, we discuss downsides and propose directions for future research.

Paper number 68:
Title: Secure Over-the-Air Computation Against Multiple Eavesdroppers using Correlated Artificial Noise
Authors: David Nordlund, Luis Maßny, Antonia Wachter-Zeh, Erik G. Larsson, Zheng Chen
Abstract: In the era of the Internet of Things and massive connectivity, many engineering applications, such as sensor fusion and federated edge learning, rely on efficient data aggregation from geographically distributed users over wireless networks. Over-the-air computation shows promising potential for enhancing resource efficiency and scalability in such scenarios by leveraging the superposition property of wireless channels. However, due to the use of uncoded transmission with linear mapping, it also suffers from security vulnerabilities that must be dealt with to allow widespread adoption. In this work, we consider a scenario where multiple cooperating eavesdroppers attempt to infer information about the aggregation result. We derive the optimal joint estimator for the eavesdroppers and provide bounds on the achievable estimation accuracy for both the eavesdroppers and the intended receiver. We show that significant inherent security exists against individual eavesdroppers due to channel misalignment. However, the security level is greatly compromised when the eavesdroppers can cooperate, motivating the need for deliberate security measures. A common measure is to add carefully calibrated perturbation signals (artificial noise) prior to data transmission to improve the security level. To this end, we propose a zero-forced artificial noise design that achieves a high level of security against cooperative eavesdroppers without compromising the aggregation accuracy.

Paper number 69:
Title: Insights on the Uplink Operation of a 1-bit Radio-Over-Fiber Architecture in Multi-User D-MIMO Communication
Authors: Lise Aabel, Giuseppe Durisi, Frida Olofsson, Erik Börjeson, Mikael Coldrey, Christian Fager
Abstract: We consider a distributed multiple-input multiple-output (D-MIMO) testbed in which, to enable coherent-phase transmission without over-the-air synchronization, the remote radio heads (RRHs) are connected to a central unit via a 1-bit radio-over-fiber fronthaul. Specifically, 1-bit samples of the radio-frequency signal are exchanged over the fronthaul. We investigate via both measurements and simulations based on an accurate model of the testbed hardware, the capability of the proposed architecture to provide uniform quality of services over the coverage area--one of the promises of D-MIMO. Our results are encouraging: for the case in which two user equipments (UEs) communicate over the same 75MHz signal bandwidth, the measured error-vector magnitude meets the 3GPP New Radio specification of 12.5\% for 16QAM across all tested DMIMO scenarios. We also determine that uplink transmission is a potential bottleneck, due to the limited dynamic range of the automatic gain controller, which prevents the 1-bit quantizer to benefit from dithering. We show that this issue can be mitigated via UE power control.

Paper number 70:
Title: Frequency-Dynamics-Aware Economic Dispatch with Optimal Grid-Forming Inverter Allocation and Reserved Power Headroom
Authors: Fan Jiang, Xingpeng Li
Abstract: The high penetration of inverter-based resources (IBRs) reduces system inertia, leading to frequency stability concerns, especially during synchronous generator (SG) outages. To maintain frequency dynamics within secure limits while ensuring economic efficiency, frequency-constrained optimal power flow (FCOPF) is employed. However, existing studies either neglect the frequency support capability and allocation of grid-forming (GFM) IBRs or suffer from limited accuracy in representing frequency dynamics due to model simplifications. To address this issue, this paper proposes a deep learning (DL)-based FCOPF (DL-FCOPF) framework. A DL model is first developed as a predictor to accurately estimate frequency-related metrics: the required reserved headroom and allocation of GFM IBRs, the rate of change of frequency and frequency nadir. After being trained with data obtained from electromagnetic transient simulations, the DL model is reformulated and incorporated into FCOPF. Case studies conducted on two test systems demonstrate the effectiveness of the proposed approach. Compared with the traditional OPF and linear FCOPF benchmarks, the DL-FCOPF can optimally coordinate SGs and IBRs with minimum cost, achieving desired frequency response, within an acceptable computing time. Further-more, sensitivity analyses are conducted to identify the most suit-able structure and linearization approach of the DL-based frequency predictor.

Paper number 71:
Title: Digital Twin Aided Millimeter Wave MIMO: Site-Specific Beam Codebook Learning
Authors: Hao Luo, Ahmed Alkhateeb
Abstract: Learning site-specific beams that adapt to the deployment environment, interference sources, and hardware imperfections can lead to noticeable performance gains in coverage, data rate, and power saving, among other interesting advantages. This learning process, however, typically requires a large number of active interactions/iterations, which limits its practical feasibility and leads to excessive overhead. To address these challenges, we propose a digital twin aided codebook learning framework, where a site-specific digital twin is leveraged to generate synthetic channel data for codebook learning. We also propose to learn separate codebooks for line-of-sight and non-line-of-sight users, leveraging the geometric information provided by the digital twin. Simulation results demonstrate that the codebook learned from the digital twin can adapt to the environment geometry and user distribution, leading to high received signal-to-noise ratio performance. Moreover, we identify the ray-tracing accuracy as the most critical factor in digital twin fidelity that impacts the learned codebook performance.

Paper number 72:
Title: Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies
Authors: Bailiang Jian, Jiazhen Pan, Rohit Jena, Morteza Ghahremani, Hongwei Bran Li, Daniel Rueckert, Christian Wachinger, Benedikt Wiestler
Abstract: Medical image registration drives quantitative analysis across organs, modalities, and patient populations. Recent deep learning methods often combine low-level "trend-driven" computational blocks from computer vision, such as large-kernel CNNs, Transformers, and state-space models, with high-level registration-specific designs like motion pyramids, correlation layers, and iterative refinement. Yet, their relative contributions remain unclear and entangled. This raises a central question: should future advances in registration focus on importing generic architectural trends or on refining domain-specific design principles? Through a modular framework spanning brain, lung, cardiac, and abdominal registration, we systematically disentangle the influence of these two paradigms. Our evaluation reveals that low-level "trend-driven" computational blocks offer only marginal or inconsistent gains, while high-level registration-specific designs consistently deliver more accurate, smoother, and more robust deformations. These domain priors significantly elevate the performance of a standard U-Net baseline, far more than variants incorporating "trend-driven" blocks, achieving an average relative improvement of $\sim3\%$. All models and experiments are released within a transparent, modular benchmark that enables plug-and-play comparison for new architectures and registration tasks (this https URL). This dynamic and extensible platform establishes a common ground for reproducible and fair evaluation, inviting the community to isolate genuine methodological contributions from domain priors. Our findings advocate a shift in research emphasis: from following architectural trends to embracing domain-specific design principles as the true drivers of progress in learning-based medical image registration.

Paper number 73:
Title: Uncertainty quantification in load profiles with rising EV and PV adoption: the case of residential, industrial, and office buildings
Authors: Aiko Fias, Md Umar Hashmi, Geert Deconinck
Abstract: The integration of photovoltaic (PV) generation and electric vehicle (EV) charging intro- duces significant uncertainty in electricity consumption patterns, particularly at the distribution level. This paper presents a comparative study for selecting metrics for uncertainty quantification (UQ) for net load profiles of residential, industrial, and office buildings under increased DER penetration. A variety of statistical metrics is evaluated for their usefulness in quantifying un- certainty, including, but not limited to, standard deviation, entropy, ramps, and distance metrics. The proposed metrics are classified into baseline-free, with baseline and error-based. These UQ metrics are evaluated for increased penetration of EV and PV. The results highlight suitable metrics to quantify uncertainty per consumer type and demonstrate how net load uncertainty is affected by EV and PV adoption. Additionally, it is observed that joint consideration of EV and PV can reduce overall uncertainty due to compensatory effects of EV charging and PV generation due to temporal alignment during the day. Uncertainty reduction is observed across all datasets and is most pronounced for the office building dataset.

Paper number 74:
Title: Event-triggered control of nonlinear systems from data
Authors: Hailong Chen, Claudio De Persis, Andrea Bisoffi, Pietro Tesi
Abstract: In a recent paper [8], we introduced a data-based approach to design event-triggered controllers for linear systems directly from data. Here, we extend the results in [8] to a class of nonlinear systems. We provide two data-based designs certified by a (classical) Lyapunov function. For these two designs, we devise event-triggered policies that rely on the previously found Lyapunov function, have parameters tuned from data, ensure a positive minimum inter-event time, and act based either on the state error or on the library error. These two different policies, and their respective advantages, are illustrated numerically.

Paper number 75:
Title: The Equivalence of Fast Algorithms for Convolution, Parallel FIR Filters, Polynomial Modular Multiplication, and Pointwise Multiplication in DFT/NTT Domain
Authors: Keshab K. Parhi
Abstract: Fast time-domain algorithms have been developed in signal processing applications to reduce the multiplication complexity. For example, fast convolution structures using Cook-Toom and Winograd algorithms are well understood. Short length fast convolutions can be iterated to obtain fast convolution structures for long lengths. In this paper, we show that well known fast convolution structures form the basis for design of fast algorithms in four other problem domains: fast parallel filters, fast polynomial modular multiplication, and fast pointwise multiplication in the DFT and NTT domains. Fast polynomial modular multiplication and fast pointwise multiplication problems are important for cryptosystem applications such as post-quantum cryptography and homomorphic encryption. By establishing the equivalence of these problems, we show that a fast structure from one domain can be used to design a fast structure for another domain. This understanding is important as there are many well known solutions for fast convolution that can be used in other signal processing and cryptosystem applications.

Paper number 76:
Title: AI-Driven Optimization under Uncertainty for Mineral Processing Operations
Authors: William Xu, Amir Eskanlou, Mansur Arief, David Zhen Yin, Jef K. Caers
Abstract: The global capacity for mineral processing must expand rapidly to meet the demand for critical minerals, which are essential for building the clean energy technologies necessary to mitigate climate change. However, the efficiency of mineral processing is severely limited by uncertainty, which arises from both the variability of feedstock and the complexity of process dynamics. To optimize mineral processing circuits under uncertainty, we introduce an AI-driven approach that formulates mineral processing as a Partially Observable Markov Decision Process (POMDP). We demonstrate the capabilities of this approach in handling both feedstock uncertainty and process model uncertainty to optimize the operation of a simulated, simplified flotation cell as an example. We show that by integrating the process of information gathering (i.e., uncertainty reduction) and process optimization, this approach has the potential to consistently perform better than traditional approaches at maximizing an overall objective, such as net present value (NPV). Our methodological demonstration of this optimization-under-uncertainty approach for a synthetic case provides a mathematical and computational framework for later real-world application, with the potential to improve both the laboratory-scale design of experiments and industrial-scale operation of mineral processing circuits without any additional hardware.

Paper number 77:
Title: ECO: Energy-Constrained Operator Learning for Chaotic Dynamics with Boundedness Guarantees
Authors: Andrea Goertzen, Sunbochen Tang, Navid Azizan
Abstract: Chaos is a fundamental feature of many complex dynamical systems, including weather systems and fluid turbulence. These systems are inherently difficult to predict due to their extreme sensitivity to initial conditions. Many chaotic systems are dissipative and ergodic, motivating data-driven models that aim to learn invariant statistical properties over long time horizons. While recent models have shown empirical success in preserving invariant statistics, they are prone to generating unbounded predictions, which prevent meaningful statistics evaluation. To overcome this, we introduce the Energy-Constrained Operator (ECO) that simultaneously learns the system dynamics while enforcing boundedness in predictions. We leverage concepts from control theory to develop algebraic conditions based on a learnable energy function, ensuring the learned dynamics is dissipative. ECO enforces these algebraic conditions through an efficient closed-form quadratic projection layer, which provides provable trajectory boundedness. To our knowledge, this is the first work establishing such formal guarantees for data-driven chaotic dynamics models. Additionally, the learned invariant level set provides an outer estimate for the strange attractor, a complex structure that is computationally intractable to characterize. We demonstrate empirical success in ECO's ability to generate stable long-horizon forecasts, capturing invariant statistics on systems governed by chaotic PDEs, including the Kuramoto--Sivashinsky and the Navier--Stokes equations.

Paper number 78:
Title: X-SYCON: Xylem-Inspired Passive Gradient Control for Communication-Free Swarm Response in Dynamic Disaster Environments
Authors: Arthur Ji Sung Baek, Geoffrey Martin
Abstract: We present X-SYCON, a xylem-inspired multi-agent architecture in which coordination emerges from passive field dynamics rather than explicit planning or communication. Incidents (demands) and obstructions (hazards) continually write diffusing and decaying scalar fields, and agents greedily ascend a local utility $U=\phi_{\mathrm{DE}}-\kappa\,\phi_{\mathrm{HZ}}$ with light anti-congestion and separation. A beaconing rule triggered on first contact temporarily deepens the local demand sink, accelerating completion without reducing time-to-first-response. Across dynamic, partially blocked simulated environments, we observe low miss rates and stable throughput with interpretable, tunable trade-offs over carrier count, arrival rate, hazard density, and hazard sensitivity $\kappa$. We derive that a characteristic hydraulic length scale $\ell\approx\sqrt{D/\lambda}$ predicts recruitment range in a continuum approximation, and we provide a work-conservation (Ohm-law) bound consistent with sublinear capacity scaling with team size. Empirically: (i) soft hazard penalties yield fewer misses when obstacles already block motion; (ii) throughput saturates sublinearly with carriers while reliability improves sharply; (iii) stronger arrivals can reduce misses by sustaining sinks that recruit help; and (iv) phase-stability regions shrink with hazard density but are recovered by more carriers or higher arrivals. We refer to X-SYCON as an instance of Distributed Passive Computation and Control, and we evaluate it in simulations modeling communication-denied disaster response and other constrained sensing-action regimes.

Paper number 79:
Title: Modeling and Control of Magnetic Forces between Microrobots
Authors: Amelia Fernández Seguel (1), Alejandro I. Maass (1) ((1) School of Engineering, Pontificia Universidad Católica de Chile)
Abstract: The independent control of multiple magnetic microrobots under a shared global signal presents critical challenges in biomedical applications such as targeted drug delivery and microsurgeries. Most existing systems only allow all agents to move synchronously, limiting their use in applications that require differentiated actuation. This research aims to design a controller capable of regulating the radial distance between micro-agents using only the angle \psi of a global magnetic field as the actuation parameter, demonstrating potential for practical applications. The proposed cascade control approach enables faster and more precise adjustment of the inter-agent distance than a proportional controller, while maintaining smooth transitions and avoiding abrupt changes in the orientation of the magnetic field, making it suitable for real-world implementation. A bibliographic review was conducted to develop the physical model, considering magnetic dipole-dipole interactions and velocities in viscous media. A PID controller was implemented to regulate the radial distance, followed by a PD controller in cascade to smooth changes in field orientation. These controllers were simulated in MATLAB, showing that the PID controller reduced convergence time to the desired radius by about 40%. When adding the second controller, the combined PID+PD scheme achieved smooth angular trajectories within similar timeframes, with fluctuations of only \pm 5^\circ. These results validate the feasibility of controlling the radial distance of two microrobots using a shared magnetic field in a fast and precise manner, without abrupt variations in the control angle. However, the model is limited to a 2D environment and two agents, suggesting future research to extend the controller to 3D systems and multiple agents.

Paper number 80:
Title: A CNN-Based Technique to Assist Layout-to-Generator Conversion for Analog Circuits
Authors: Sungyu Jeong, Minsu Kim, Byungsub Kim
Abstract: We propose a technique to assist in converting a reference layout of an analog circuit into the procedural layout generator by efficiently reusing available generators for sub-cell creation. The proposed convolutional neural network (CNN) model automatically detects sub-cells that can be generated by available generator scripts in the library, and suggests using them in the hierarchically correct places of the generator software. In experiments, the CNN model examined sub-cells of a high-speed wireline receiver that has a total of 4,885 sub-cell instances including different 145 sub-cell designs. The CNN model classified the sub-cell instances into 51 generatable and one not-generatable classes. One not-generatable class indicates that no available generator can generate the classified sub-cell. The CNN model achieved 99.3% precision in examining the 145 different sub-cell designs. The CNN model greatly reduced the examination time to 18 seconds from 88 minutes required in manual examination. Also, the proposed CNN model could correctly classify unfamiliar sub-cells that are very different from the training dataset.

Paper number 81:
Title: Adapter Shield: A Unified Framework with Built-in Authentication for Preventing Unauthorized Zero-Shot Image-to-Image Generation
Authors: Jun Jia, Hongyi Miao, Yingjie Zhou, Wangqiu Zhou, Jianbo Zhang, Linhan Cao, Dandan Zhu, Hua Yang, Xiongkuo Min, Wei Sun, Guangtao Zhai
Abstract: With the rapid progress in diffusion models, image synthesis has advanced to the stage of zero-shot image-to-image generation, where high-fidelity replication of facial identities or artistic styles can be achieved using just one portrait or artwork, without modifying any model weights. Although these techniques significantly enhance creative possibilities, they also pose substantial risks related to intellectual property violations, including unauthorized identity cloning and stylistic imitation. To counter such threats, this work presents Adapter Shield, the first universal and authentication-integrated solution aimed at defending personal images from misuse in zero-shot generation scenarios. We first investigate how current zero-shot methods employ image encoders to extract embeddings from input images, which are subsequently fed into the UNet of diffusion models through cross-attention layers. Inspired by this mechanism, we construct a reversible encryption system that maps original embeddings into distinct encrypted representations according to different secret keys. The authorized users can restore the authentic embeddings via a decryption module and the correct key, enabling normal usage for authorized generation tasks. For protection purposes, we design a multi-target adversarial perturbation method that actively shifts the original embeddings toward designated encrypted patterns. Consequently, protected images are embedded with a defensive layer that ensures unauthorized users can only produce distorted or encrypted outputs. Extensive evaluations demonstrate that our method surpasses existing state-of-the-art defenses in blocking unauthorized zero-shot image synthesis, while supporting flexible and secure access control for verified users.

Paper number 82:
Title: From RISC-V Cores to Neuromorphic Arrays: A Tutorial on Building Scalable Digital Neuromorphic Processors
Authors: Amirreza Yousefzadeh
Abstract: Digital neuromorphic processors are emerging as a promising computing substrate for low-power, always-on EdgeAI applications. In this tutorial paper, we outline the main architectural design principles behind fully digital neuromorphic processors and illustrate them using the SENECA platform as a running example. Starting from a flexible array of tiny RISC-V processing cores connected by a simple Network-on-Chip (NoC), we show how to progressively evolve the architecture: from a baseline event-driven implementation of fully connected networks, to versions with dedicated Neural Processing Elements (NPEs) and a loop controller that offloads fine-grained control from the general-purpose cores. Along the way, we discuss software and mapping techniques such as spike grouping, event-driven depth-first convolution for convolutional networks, and hard-attention style processing for high-resolution event-based vision. The focus is on architectural trade-offs, performance and energy bottlenecks, and on leveraging flexibility to incrementally add domain-specific acceleration. This paper assumes familiarity with basic neuromorphic concepts (spikes, event-driven computation, sparse activation) and deep neural network workloads. It does not present new experimental results; instead, it synthesizes and contextualizes findings previously reported in our SENECA publications to provide a coherent, step-by-step architectural perspective for students and practitioners who wish to design their own digital neuromorphic processors.

Paper number 83:
Title: TinyViT: Field Deployable Transformer Pipeline for Solar Panel Surface Fault and Severity Screening
Authors: Ishwaryah Pandiarajan, Mohamed Mansoor Roomi Sindha, Uma Maheswari Pandyan, Sharafia N
Abstract: Sustained operation of solar photovoltaic assets hinges on accurate detection and prioritization of surface faults across vast, geographically distributed modules. While multi modal imaging strategies are popular, they introduce logistical and economic barriers for routine farm level deployment. This work demonstrates that deep learning and classical machine learning may be judiciously combined to achieve robust surface anomaly categorization and severity estimation from planar visible band imagery alone. We introduce TinyViT which is a compact pipeline integrating Transformer based segmentation, spectral-spatial feature engineering, and ensemble regression. The system ingests consumer grade color camera mosaics of PV panels, classifies seven nuanced surface faults, and generates actionable severity grades for maintenance triage. By eliminating reliance on electroluminescence or IR sensors, our method enables affordable, scalable upkeep for resource limited installations, and advances the state of solar health monitoring toward universal field accessibility. Experiments on real public world datasets validate both classification and regression sub modules, achieving accuracy and interpretability competitive with specialized approaches.

Paper number 84:
Title: Ternary-Input Binary-Weight CNN Accelerator Design for Miniature Object Classification System with Query-Driven Spatial DVS
Authors: Yuyang Li, Swasthik Muloor, Jack Laudati, Nickolas Dematteis, Yidam Park, Hana Kim, Nathan Chang, Inhee Lee
Abstract: Miniature imaging systems are essential for space-constrained applications but are limited by memory and power constraints. While machine learning can reduce data size by extracting key features, its high energy demands often exceed the capacity of small batteries. This paper presents a CNN hardware accelerator optimized for object classification in miniature imaging systems. It processes data from a spatial Dynamic Vision Sensor (DVS), reconfigurable to a temporal DVS via pixel sharing, minimizing sensor area. By using ternary DVS outputs and a ternary-input, binary-weight neural network, the design reduces computation and memory needs. Fabricated in 28 nm CMOS, the accelerator cuts data size by 81% and MAC operations by 27%. It achieves 440 ms inference time at just 1.6 mW power consumption, improving the Figure-of-Merit (FoM) by 7.3x over prior CNN accelerators for miniature systems.

Paper number 85:
Title: Efficient Edge-Compatible CNN for Speckle-Based Material Recognition in Laser Cutting Systems
Authors: Mohamed Abdallah Salem (North Dakota State University), Nourhan Zein Diab (New Mansoura University)
Abstract: Accurate material recognition is critical for safe and effective laser cutting, as misidentification can lead to poor cut quality, machine damage, or the release of hazardous fumes. Laser speckle sensing has recently emerged as a low-cost and non-destructive modality for material classification; however, prior work has either relied on computationally expensive backbone networks or addressed only limited subsets of materials. In this study, A lightweight convolutional neural network (CNN) tailored for speckle patterns is proposed, designed to minimize parameters while maintaining high discriminative power. Using the complete SensiCut dataset of 59 material classes spanning woods, acrylics, composites, textiles, metals, and paper-based products, the proposed model achieves 95.05% test accuracy, with macro and weighted F1-scores of 0.951. The network contains only 341k trainable parameters (~1.3 MB) -- over 70X fewer than ResNet-50 -- and achieves an inference speed of 295 images per second, enabling deployment on Raspberry Pi and Jetson-class devices. Furthermore, when materials are regrouped into nine and five practical families, recall exceeds 98% and approaches 100%, directly supporting power and speed preset selection in laser cutters. These results demonstrate that compact, domain-specific CNNs can outperform large backbones for speckle-based material classification, advancing the feasibility of material-aware, edge-deployable laser cutting systems.

Paper number 86:
Title: Variable Point: A Number Format for Area- and Energy-Efficient Multiplication of High-Dynamic-Range Numbers
Authors: Seyed Hadi Mirfarshbafan, Nicolas Filliol, Oscar Castañeda, Christoph Studer
Abstract: Fixed-point number representation is commonly employed in digital VLSI designs that have stringent hardware efficiency constraints. However, fixed-point numbers cover a relatively small dynamic range for a given bitwidth. In contrast, floating-point numbers offer a larger dynamic range at the cost of increased hardware complexity. In this paper, we propose a novel number format called variable-point (VP). VP numbers cover a larger dynamic range than fixed-point numbers with similar bitwidth, without notably increasing hardware complexity -- this allows for a more efficient representation of signals with high dynamic range. To demonstrate the efficacy of the proposed VP number format, we consider a matrix-vector multiplication engine for spatial equalization in multi-antenna wireless communication systems involving high-dynamic-range signals. Through post-layout VLSI implementation results, we demonstrate that the proposed VP-based design achieves 20% and 10% area and power savings, respectively, compared to a fully optimized fixed-point design, without incurring any noticeable performance degradation.

Paper number 87:
Title: Hybrid Context-Fusion Attention (CFA) U-Net and Clustering for Robust Seismic Horizon Interpretation
Authors: Jose Luis Lima de Jesus Silva, Joao Pedro Gomes, Paulo Roberto de Melo Barros Junior, Vitor Hugo Serravalle Reis Rodrigues, Alexsandro Guerra Cerqueira
Abstract: Interpreting seismic horizons is a critical task for characterizing subsurface structures in hydrocarbon exploration. Recent advances in deep learning, particularly U-Net-based architectures, have significantly improved automated horizon tracking. However, challenges remain in accurately segmenting complex geological features and interpolating horizons from sparse annotations. To address these issues, a hybrid framework is presented that integrates advanced U-Net variants with spatial clustering to enhance horizon continuity and geometric fidelity. The core contribution is the Context Fusion Attention (CFA) U-Net, a novel architecture that fuses spatial and Sobel-derived geometric features within attention gates to improve both precision and surface completeness. The performance of five architectures, the U-Net (Standard and compressed), U-Net++, Attention U-Net, and CFA U-Net, was systematically evaluated across various data sparsity regimes (10-, 20-, and 40-line spacing). This approach outperformed existing baselines, achieving state-of-the-art results on the Mexilhao field (Santos Basin, Brazil) dataset with a validation IoU of 0.881 and MAE of 2.49ms, and excellent surface coverage of 97.6% on the F3 Block of the North Sea dataset under sparse conditions. The framework further refines merged horizon predictions (inline and cross-line) using Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to produce geologically plausible surfaces. The results demonstrate the advantages of hybrid methodologies and attention-based architectures enhanced with geometric context, providing a robust and generalizable solution for seismic interpretation in structurally complex and data-scarce environments.

Paper number 88:
Title: AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI
Authors: Zag ElSayed, Grace Westerkamp, Gavin Gammoh, Yanchen Liu, Peyton Siekierski, Craig Erickson, Ernest Pedapati
Abstract: We introduce EEG Autoclean Vision Language AI (ICVision) a first-of-its-kind system that emulates expert-level EEG ICA component classification through AI-agent vision and natural language reasoning. Unlike conventional classifiers such as ICLabel, which rely on handcrafted features, ICVision directly interprets ICA dashboard visualizations topography, time series, power spectra, and ERP plots, using a multimodal large language model (GPT-4 Vision). This allows the AI to see and explain EEG components the way trained neurologists do, making it the first scientific implementation of AI-agent visual cognition in neurophysiology. ICVision classifies each component into one of six canonical categories (brain, eye, heart, muscle, channel noise, and other noise), returning both a confidence score and a human-like explanation. Evaluated on 3,168 ICA components from 124 EEG datasets, ICVision achieved k = 0.677 agreement with expert consensus, surpassing MNE ICLabel, while also preserving clinically relevant brain signals in ambiguous cases. Over 97% of its outputs were rated as interpretable and actionable by expert reviewers. As a core module of the open-source EEG Autoclean platform, ICVision signals a paradigm shift in scientific AI, where models do not just classify, but see, reason, and communicate. It opens the door to globally scalable, explainable, and reproducible EEG workflows, marking the emergence of AI agents capable of expert-level visual decision-making in brain science and beyond.

Paper number 89:
Title: Beyond Expected Goals: A Probabilistic Framework for Shot Occurrences in Soccer
Authors: Jonathan Pipping, Tianshu Feng, R. Paul Sabin
Abstract: Expected goals (xG) models estimate the probability that a shot results in a goal from its context (e.g., location, pressure), but they operate only on observed shots. We propose xG+, a possession-level framework that first estimates the probability that a shot occurs within the next second and its corresponding xG if it were to occur. We also introduce ways to aggregate this joint probability estimate over the course of a possession. By jointly modeling shot-taking behavior and shot quality, xG+ remedies the conditioning-on-shots limitation of standard xG. We show that this improves predictive accuracy at the team level and produces a more persistent player skill signal than standard xG models.

Paper number 90:
Title: TIE: A Training-Inversion-Exclusion Framework for Visually Interpretable and Uncertainty-Guided Out-of-Distribution Detection
Authors: Pirzada Suhail, Rehna Afroz, Amit Sethi
Abstract: Deep neural networks often struggle to recognize when an input lies outside their training experience, leading to unreliable and overconfident predictions. Building dependable machine learning systems therefore requires methods that can both estimate predictive \textit{uncertainty} and detect \textit{out-of-distribution (OOD)} samples in a unified manner. In this paper, we propose \textbf{TIE: a Training--Inversion--Exclusion} framework for visually interpretable and uncertainty-guided anomaly detection that jointly addresses these challenges through iterative refinement. TIE extends a standard $n$-class classifier to an $(n+1)$-class model by introducing a garbage class initialized with Gaussian noise to represent outlier inputs. Within each epoch, TIE performs a closed-loop process of \textit{training, inversion, and exclusion}, where highly uncertain inverted samples reconstructed from the just-trained classifier are excluded into the garbage class. Over successive iterations, the inverted samples transition from noisy artifacts into visually coherent class prototypes, providing transparent insight into how the model organizes its learned manifolds. During inference, TIE rejects OOD inputs by either directly mapping them to the garbage class or producing low-confidence, uncertain misclassifications within the in-distribution classes that are easily separable, all without relying on external OOD datasets. A comprehensive threshold-based evaluation using multiple OOD metrics and performance measures such as \textit{AUROC}, \textit{AUPR}, and \textit{FPR@95\%TPR} demonstrates that TIE offers a unified and interpretable framework for robust anomaly detection and calibrated uncertainty estimation (UE) achieving near-perfect OOD detection with \textbf{\(\!\approx\!\) 0 FPR@95\%TPR} when trained on MNIST or FashionMNIST and tested against diverse unseen datasets.

Paper number 91:
Title: Introducing AI-Driven IoT Energy Management Framework
Authors: Shivani Mruthyunjaya, Anandi Dutta, Kazi Sifatul Islam
Abstract: Power consumption has become a critical aspect of modern life due to the consistent reliance on technological advancements. Reducing power consumption or following power usage predictions can lead to lower monthly costs and improved electrical reliability. The proposal of a holistic framework to establish a foundation for IoT systems with a focus on contextual decision making, proactive adaptation, and scalable structure. A structured process for IoT systems with accuracy and interconnected development would support reducing power consumption and support grid stability. This study presents the feasibility of this proposal through the application of each aspect of the framework. This system would have long term forecasting, short term forecasting, anomaly detection, and consideration of qualitative data with any energy management decisions taken. Performance was evaluated on Power Consumption Time Series data to display the direct application of the framework.

Paper number 92:
Title: Adaptive prediction theory combining offline and online learning
Authors: Haizheng Li, Lei Guo
Abstract: Real-world intelligence systems usually operate by combining offline learning and online adaptation with highly correlated and non-stationary system data or signals, which, however, has rarely been investigated theoretically in the literature. This paper initiates a theoretical investigation on the prediction performance of a two-stage learning framework combining offline and online algorithms for a class of nonlinear stochastic dynamical systems. For the offline-learning phase, we establish an upper bound on the generalization error for approximate nonlinear-least-squares estimation under general datasets with strong correlation and distribution shift, leveraging the Kullback-Leibler divergence to quantify the distributional discrepancies. For the online-adaptation phase, we address, on the basis of the offline-trained model, the possible uncertain parameter drift in real-world target systems by proposing a meta-LMS prediction algorithm. This two-stage framework, integrating offline learning with online adaptation, demonstrates superior prediction performances compared with either purely offline or online methods. Both theoretical guarantees and empirical studies are provided.

Paper number 93:
Title: Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement
Authors: Andrea Procopio, Marco Esposito, Sara Raggiunto, Andrey Gizdov, Alberto Belli, Paola Pierleoni
Abstract: We study on-device time-series analysis for gait detection in Parkinson's disease (PD) from short windows of triaxial acceleration, targeting resource-constrained wearables and edge nodes. We compare magnitude thresholding to three 1D CNNs for time-series analysis: a literature baseline (separable convolutions) and two ultra-light models - one purely separable and one with residual connections. Using the BioStampRC21 dataset, 2 s windows at 30 Hz, and subject-independent leave-one-subject-out (LOSO) validation on 16 PwPD with chest-worn IMUs, our residual separable model (Model 2, 533 params) attains PR-AUC = 94.5%, F1 = 91.2%, MCC = 89.4%, matching or surpassing the baseline (5,552 params; PR-AUC = 93.7%, F1 = 90.5%, MCC = 88.5%) with approximately 10x fewer parameters. The smallest model (Model 1, 305 params) reaches PR-AUC = 94.0%, F1 = 91.0%, MCC = 89.1%. Thresholding obtains high recall (89.0%) but low precision (76.5%), yielding many false positives and high inter-subject variance. Sensor-position analysis (train-on-all) shows chest and thighs are most reliable; forearms degrade precision/recall due to non-gait arm motion; naive fusion of all sites does not outperform the best single site. Both compact CNNs execute within tight memory/latency budgets on STM32-class MCUs (sub-10 ms on low-power boards), enabling on-sensor gating of transmission/storage. Overall, ultra-light separable CNNs provide a superior accuracy-efficiency-generalization trade-off to fixed thresholds for wearable PD gait detection and underscore the value of tailored time-series models for edge deployment.

Paper number 94:
Title: TenonOS: A Self-Generating Intelligent Embedded Operating System Framework for Edge Computing
Authors: Xinkui Zhao, Yifan Zhang, Haidan Zhao, Hao Zhang, Qingyu Ma, Lufei Zhang, Guanjie Cheng, Shuiguang Deng, Jianwei Yin, Zuoning Chen
Abstract: The rapid evolution of edge computing has exposed fundamental limitations in traditional operating system and hypervisor architectures, particularly in managing heterogeneous platforms and meeting the constraints of limited resources. Existing solutions often rely on monolithic or layered combinations of hypervisors and guest OSes, which are difficult to tailor for the diverse and dynamic requirements of edge scenarios. To address these challenges, we propose TenonOS, a demand-driven, self-generating, and lightweight operating system framework that fundamentally rethinks and reconstructs both the hypervisor and OS architectures. TenonOS introduces a novel LibOS-on-LibOS approach, in which both virtualization and OS functionalities are modularized into fine-grained, reusable micro-libraries. A dynamic orchestration engine composes these modules on demand to construct customized, application-specific runtime environments. At the core of TenonOS are two key components: Mortise, a minimal, modularized hypervisor, and Tenon, a real-time LibOS. Mortise provides low-overhead resource isolation, fast inter-VM communication, and manages the full lifecycle of Tenon instances - including on-demand creation, suspension, and termination - enabling TenonOS to flexibly adapt its runtime layout to workload variations. Tenon delivers deterministic scheduling and multi-process support for time-critical applications. Through this unified and modular architecture, TenonOS eliminates redundant layers, reduces system overhead, and enhances scalability, security, and maintainability. Extensive evaluations demonstrate that TenonOS achieves superior real-time scheduling (40.28% improvement), a compact memory footprint (361 KiB), and high adaptability to dynamic edge workloads, making it an ideal foundation for heterogeneous, resource-constrained edge systems.

Paper number 95:
Title: Movable Antenna Empowered Near-Field Sensing via Antenna Position Optimization
Authors: Yushen Wang, Weidong Mei, Xin Wei, Zhi Chen, Boyu Ning
Abstract: Movable antenna (MA) technology exhibits great promise for enhancing the sensing capabilities of future sixth-generation (6G) networks due to its capability to alter antenna array geometry. With the growing prevalence of near-field propagation at ultra-high frequencies, this paper focuses on the application of one-dimensional (1D) and two-dimensional (2D) MA arrays for near-field sensing to jointly estimate the angle and distance information about a target. First, for the 1D MA array scenario, to gain insights into MA-enhanced near-field sensing, we investigate two simplified cases with only angle-of-arrival (AoA) or distance estimation, respectively, assuming that the other information is already known. The worst-case Cramer-Rao bounds (CRBs) on the mean square errors (MSEs) of the AoA estimation and the distance estimation are derived in these two cases. Then, we jointly optimize the positions of the MAs within the 1D array to minimize these CRBs and derive their closed-form solutions, which yield an identical array geometry to MA-enhanced far-field sensing. For the more challenging joint AoA and distance estimation, since the associated worst-case CRB is a highly complex and non-convex function with respect to the MA positions, a discrete sampling-based approach is proposed to sequentially update the MA positions and obtain an efficient suboptimal solution. Furthermore, we investigate the worst-case CRB minimization problems for a 2D MA array under various conditions and extend our proposed algorithms to solve them efficiently. Numerical results demonstrate that the proposed MA-enhanced near-field sensing scheme dramatically outperforms conventional fixed-position antennas (FPAs). Moreover, the joint angle and distance estimation results in a different array geometry from that in the individual estimation of angle/distance or far-field sensing.

Paper number 96:
Title: SAGAS: Semantic-Aware Graph-Assisted Stitching for Offline Temporal Logic Planning
Authors: Ruijia Liu, Ancheng Hou, Shaoyuan Li, Xiang Yin
Abstract: Linear Temporal Logic (LTL) provides a rigorous framework for complex robotic tasks, yet existing methods often rely on accurate dynamics models or expensive online interactions. In this work, we address LTL-constrained control in a challenging offline, model-free setting, utilizing only fixed, task-agnostic datasets of fragmented trajectories. We propose SAGAS, a novel framework combining graph-assisted trajectory stitching with automata-guided planning. First, we construct a latent reachability graph from a learned temporal-distance representation. To bridge the semantic gap, we augment this graph with certified anchor nodes and probabilistic soft labels. We then translate the specification into a Büchi automaton and search the implicit product space to derive a cost-minimal prefix-suffix plan. Finally, a subgoal-conditioned low-level policy is deployed to execute these latent waypoints. Experiments on OGBench locomotion domains demonstrate that SAGAS successfully synthesizes efficient trajectories for diverse LTL tasks, effectively bridging the gap between fragmented offline data and complex logical constraints.

Paper number 97:
Title: A Novel MDP Decomposition Framework for Scalable UAV Mission Planning in Complex and Uncertain Environments
Authors: Md Muzakkir Quamar, Ali Nasir, Sami ELFerik
Abstract: This paper presents a scalable and fault-tolerant framework for unmanned aerial vehicle (UAV) mission management in complex and uncertain environments. The proposed approach addresses the computational bottleneck inherent in solving large-scale Markov Decision Processes (MDPs) by introducing a two-stage decomposition strategy. In the first stage, a factor-based algorithm partitions the global MDP into smaller, goal-specific sub-MDPs by leveraging domain-specific features such as goal priority, fault states, spatial layout, and energy constraints. In the second stage, a priority-based recombination algorithm solves each sub-MDP independently and integrates the results into a unified global policy using a meta-policy for conflict resolution. Importantly, we present a theoretical analysis showing that, under mild probabilistic independence assumptions, the combined policy is provably equivalent to the optimal global MDP policy. Our work advances artificial intelligence (AI) decision scalability by decomposing large MDPs into tractable subproblems with provable global equivalence. The proposed decomposition framework enhances the scalability of Markov Decision Processes, a cornerstone of sequential decision-making in artificial intelligence, enabling real-time policy updates for complex mission environments. Extensive simulations validate the effectiveness of our method, demonstrating orders-of-magnitude reduction in computation time without sacrificing mission reliability or policy optimality. The proposed framework establishes a practical and robust foundation for scalable decision-making in real-time UAV mission execution.

Paper number 98:
Title: Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE
Authors: Felix Saretzky, Lucas Andersen, Thomas Engel, Fazel Ansari
Abstract: The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a "what-if" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.

Paper number 99:
Title: LPWAN based IoT Architecture for Distributed Energy Monitoring in Deep Indoor Environments
Authors: Christof Röhrig, Benz Cramer
Abstract: Continuous energy monitoring is essential for identifying potential savings and predicting the energy requirements of buildings. Energy meters are often located in underground spaces that are difficult to reach with wireless technology. This paper presents an experimental study comparing different Low Power Wide Area Networks (LPWAN) technologies in terms of building penetration and radio coverage. The technologies Low Power Long Range Wide Area Networks (LoRaWAN), Narrow Band Internet of Things (NB-IoT), Sigfox 0G and Wireless Smart Ubiquitous Networks (Wi-SUN) are evaluated experimentally. It also proposes a distributed hybrid IoT architecture that combines multiple LPWAN technologies using an abstraction layer to optimize cost and coverage. Communication is message-based using the publish-subscribe messaging pattern. It is implemented using the MQTT protocol. The abstraction layer decodes the proprietary binary data and converts it to a normalized JSON format.

Paper number 100:
Title: Reinforcement Learning for Gliding Projectile Guidance and Control
Authors: Joel Cahn, Antonin Thomas, Philippe Pastor
Abstract: This paper presents the development of a control law, which is intended to be implemented on an optical guided glider. This guiding law follows an innovative approach, the reinforcement learning. This control law is used to make navigation more flexible and autonomous in a dynamic environment. The final objective is to track a target detected with the camera and then guide the glider to this point with high precision. Already applied on quad-copter drones, we wish by this study to demonstrate the applicability of reinforcement learning for fixed-wing aircraft on all of its axis.

Paper number 101:
Title: Bayesian dynamic scheduling of multipurpose batch processes under incomplete look-ahead information
Authors: Taicheng Zheng, Dan Li, Jie Li
Abstract: Multipurpose batch processes become increasingly popular in manufacturing industries since they adapt to low-volume, high-value products and shifting demands. These processes often operate in a dynamic environment, which faces disturbances such as processing delays and demand changes. To minimise long-term cost and system nervousness (i.e., disruptive changes to schedules), schedulers must design rescheduling strategies to address such disturbances effectively. Existing methods often assume complete look-ahead information over the scheduling horizon. This assumption contrasts with realistic situations where schedulers can only access incomplete look-ahead information. Sticking with existing methods may lead to suboptimal long-term costs and high-level system nervousness. In this work we propose a Bayesian dynamic scheduling method. Our method relies on learning a Bayesian Network from the probability distribution of disturbances. Specifically, the Bayesian Network represents how likely each operation will be impacted by disturbances. During the online execution, when new disturbances become observed, this method updates the posterior distribution and therefore guides the rescheduling strategy. We compare our method with the existing periodic rescheduling strategy (which generates new schedules from scratch at fixed intervals) on four benchmark problems. Computational results show that our method achieves statistically better long-term costs and system nervousness. In the theoretical aspect, we prove that if disturbances are mutually independent, the impact-quantifying variables inherently satisfy the independence assumptions required by Bayesian Networks. As an implication, practitioners can extend the method to other scheduling problems (such as job shop scheduling and continuous processes), given that they define the problem-specific dependencies between operations.

Paper number 102:
Title: Reverse Engineering and Control-Aware Security Analysis of the ArduPilot UAV Framework
Authors: Yasaswini Konapalli, Lotfi Ben Othmane, Cihan Tunc, Feras Benchellal, Likhita Mudagere
Abstract: Unmanned Aerial Vehicle (UAV) technologies are gaining high interest for many domains, which makes UAV security of utmost importance. ArduPilot is among the most widely used open-source autopilot UAV frameworks; yet, many studies demonstrate the vulnerabilities affecting such systems. Vulnerabilities within its communication subsystems (including WiFi, telemetry, or GPS) expose critical entry points, and vulnerabilities in Ardupilot can affect the control procedure. In this paper, we reconstruct the software architecture and the control models implemented by ArduPilot and then examine how these control models could potentially misused to induce malicious behaviors while relying on legitimate inputs.

Paper number 103:
Title: A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems
Authors: Mohamed Abdallah Salem (1), Manuel Cuevas Perez (1), Ahmed Harb Rabia (1) ((1) North Dakota State University)
Abstract: This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.

Paper number 104:
Title: Pascal-Weighted Genetic Algorithms: A Binomially-Structured Recombination Framework
Authors: Otman A. Basir
Abstract: This paper introduces a new family of multi-parent recombination operators for Genetic Algorithms (GAs), based on normalized Pascal (binomial) coefficients. Unlike classical two-parent crossover operators, Pascal-Weighted Recombination (PWR) forms offsprings as structured convex combination of multiple parents, using binomially shaped weights that emphasize central inheritance while suppressing disruptive variance. We develop a mathematical framework for PWR, derive variance-transfer properties, and analyze its effect on schema survival. The operator is extended to real-valued, binary/logit, and permutation representations. We evaluate the proposed method on four representative benchmarks: (i) PID controller tuning evaluated using the ITAE metric, (ii) FIR low-pass filter design under magnitude-response constraints, (iii) wireless power-modulation optimization under SINR coupling, and (iv) the Traveling Salesman Problem (TSP). We demonstrate how, across these benchmarks, PWR consistently yields smoother convergence, reduced variance, and achieves 9-22% performance gains over standard recombination operators. The approach is simple, algorithm-agnostic, and readily integrable into diverse GA architectures.

Paper number 105:
Title: Inferring Dynamic Hidden Graph Structure in Heterogeneous Correlated Time Series
Authors: Jeshwanth Mohan, Bharath Ramsundar, Sandya Subramanian
Abstract: Modeling heterogeneous correlated time series requires the ability to learn hidden dynamic relationships between component time series with possibly varying periodicities and generative processes. To address this challenge, we formulate and evaluate a windowed variance-correlation metric (WVC) designed to quantify time-varying correlations between signals. This method directly recovers hidden relationships in an specified time interval as a weighted adjacency matrix, consequently inferring hidden dynamic graph structure. On simulated data, our method captures correlations that other methods miss. The proposed method expands the ability to learn dynamic graph structure between significantly different signals within a single cohesive dynamical graph model.

Paper number 106:
Title: RE-LLM: Integrating Large Language Models into Renewable Energy Systems
Authors: Ali Forootani, Mohammad Sadr, Danial Esmaeili Aliabadi, Daniela Thraen
Abstract: Energy system models are increasingly employed to guide long-term planning in multi-sectoral environments where decisions span electricity, heat, transport, land use, and industry. While these models provide rigorous quantitative insights, their outputs are often highly technical, making them difficult to interpret for non-expert stakeholders such as policymakers, planners, and the public. This communication gap limits the accessibility and practical impact of scenario-based modeling, particularly as energy transitions grow more complex with rising shares of renewables, sectoral integration, and deep uncertainties. To address this challenge, we propose the Renewable Energy Large Language Model (RE-LLM), a hybrid framework that integrates Large Language Models (LLMs) directly into the energy system modeling workflow. RE-LLM combines three core elements: (i) optimization-based scenario exploration, (ii) machine learning surrogates that accelerate computationally intensive simulations, and (iii) LLM-powered natural language generation that translates complex results into clear, stakeholder-oriented explanations. This integrated design not only reduces computational burden but also enhances inter-pretability, enabling real-time reasoning about trade-offs, sensitivities, and policy implications. The framework is adaptable across different optimization platforms and energy system models, ensuring broad applicability beyond the case study presented. By merging speed, rigor, and interpretability, RE-LLM advances a new paradigm of human-centric energy modeling. It enables interactive, multilingual, and accessible engagement with future energy pathways, ultimately bridging the final gap between data-driven analysis and actionable decision-making for sustainable transitions.

Paper number 107:
Title: Value of Communication in Goal-Oriented Semantic Communications: A Pareto Analysis
Authors: Jiping Luo, Bowen Li, Nikolaos Pappas
Abstract: Emerging cyber-physical systems increasingly operate under stringent communication constraints that preclude the reliable transmission of their extensive machine-type data streams. Since raw measurements often contain correlated or redundant components, effective operation depends not on transmitting all available data but on selecting the information that contributes to achieving the objectives of the system. Beyond accuracy, goal-oriented semantic communication assesses the \emph{value of information} and aims to generate and transmit only what is relevant and at the right time. Motivated by this perspective, this work studies the \emph{value of communication} through the canonical setting of remote estimation of Markov sources, where a value-of-information measure quantifies the relevance of information. We investigate how optimal estimation performance varies with the available communication budget and determine the marginal performance gain attributable to additional communication. Our approach is based on a \emph{Pareto analysis} that characterizes the complete set of policies that achieve optimal trade-offs between estimation performance and communication cost. The value of communication is defined as the absolute slope of the resulting Pareto frontier. Although computing this frontier is non-trivial, we demonstrate that in our setting it admits a notably tractable structure: it is strictly decreasing, convex, and piecewise linear, and its slope is governed by a finite collection of constants. Moreover, each Pareto-optimal operating point is realizable as a convex combination of two stationary deterministic policies, enabling practical implementation. Leveraging these structural insights, we introduce SPLIT, an efficient and provably optimal algorithm for constructing the complete Pareto frontier.

Paper number 108:
Title: On robotic manipulators with time-dependent inertial parameters: From physical consistency to boundedness of the mass matrix
Authors: Tom Kaufmann, Johann Reger
Abstract: We generalize the robotics equation describing the dynamics of an open kinematic chain to include the effect of time-dependent change of inertial parameters as well as the effects of its cause, i.e. time dependency of the distributions of mass originating from parasitic movements of mass-carrying particles. The results generate insight that allows linking the novel concepts of uniform physical consistency and upper boundedness of inertial parameters -- ruling out approaching the edge to physical inconsistency or to diverge -- with the existence of finite, positive uniform bounds of the mass matrix.

Paper number 109:
Title: Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization
Authors: Tal Shuster, Eliya Nachmani
Abstract: Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.

Paper number 110:
Title: Combined Effects of Transient Ionizing and Electromagnetic Pulse on Vertical NPN Bipolar Transistor
Authors: Meiqing Zhong, Cui Meng, Yinong Liu, Lanfeng Yuan, Chicheng Liu, Bolun Feng, Maoxing Zhang
Abstract: Combined effects of transient ionizing and electromagnetic pulse on vertical NPN bipolar transistor were experimentally investigated under pulsed X-ray irradiation. Technology computer-aided design (TCAD) simulation method was also employed to explore the underlying physical mechanisms. The results demonstrate that the combined effect of a positive pulse injected into the collector (CEMP) and pulsed X-ray irradiation exceeds the linear superposition of their individual effects. Conversely, the combined effect of a positive pulse injected into the base (BEMP) and pulsed X-ray irradiation aligns closely with the results observed under BEMP acting alone. Mechanism analysis reveals that when CEMP and pulsed X-ray irradiation act simultaneously, there is a significant increase in both the drift photocurrent at the collector junction and the diffusion photocurrent near the collector junction. However, when BEMP and pulsed X-ray irradiation act simultaneously, these photocurrent components remain small, leading to a combined effect similar to the results observed when BEMP acts alone. These findings provide critical insights for the radiation-hardening design of bipolar circuits in harsh radiation environments.

Paper number 111:
Title: Towards a Multi-Layer Defence Framework for Securing Near-Real-Time Operations in Open RAN
Authors: Hamed Alimohammadi, Samara Mayhoub, Sotiris Chatzimiltis, Mohammad Shojafar, Muhammad Nasir Mumtaz Bhutta
Abstract: Securing the near-real-time (near-RT) control operations in Open Radio Access Networks (Open RAN) is increasingly critical, yet remains insufficiently addressed, as new runtime threats target the control loop while the system is operational. In this paper, we propose a multi-layer defence framework designed to enhance the security of near-RT RAN Intelligent Controller (RIC) operations. We classify operational-time threats into three categories, message-level, data-level, and control logic-level, and design and implement a dedicated detection and mitigation component for each: a signature-based E2 message inspection module performing structural and semantic validation of signalling exchanges, a telemetry poisoning detector based on temporal anomaly scoring using an LSTM network, and a runtime xApp attestation mechanism based on execution-time hash challenge-response. The framework is evaluated on an O-RAN testbed comprising FlexRIC and a commercial RAN emulator, demonstrating effective detection rates, low latency overheads, and practical integration feasibility. Results indicate that the proposed safeguards can operate within near-RT time constraints while significantly improving protection against runtime attacks, introducing less than 80 ms overhead for a network with 500 User Equipment (UEs). Overall, this work lays the foundation for deployable, layered, and policy-driven runtime security architectures for the near-RT RIC control loop in Open RAN, and provides an extensible framework into which future mitigation policies and threat-specific modules can be integrated.

Paper number 112:
Title: Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track
Authors: Mo Chen
Abstract: This work presents a real-time autonomous track navigation framework for nonholonomic differential-drive mobile robots by jointly integrating multi-task visual perception and a provably stable tracking controller. The perception pipeline reconstructs lane centerlines using 2D-to-3D camera projection, arc-length based uniform point resampling, and cubic polynomial fitting solved via robust QR least-squares optimization. The controller regulates robot linear and angular velocities through a Lyapunov-stability grounded design, ensuring bounded error dynamics and asymptotic convergence of position and heading deviations even in dynamic and partially perceived lane scenarios, without relying on HD prior maps or global satellite localization. Real-world experiments on embedded platforms verify system fidelity, real-time execution, trajectory smoothness, and closed-loop stability for reliable autonomous navigation.

Paper number 113:
Title: Bayesian Ambiguity Contraction-based Adaptive Robust Markov Decision Processes for Adversarial Surveillance Missions
Authors: Jimin Choi, Max Z. Li
Abstract: Collaborative Combat Aircraft (CCAs) are envisioned to enable autonomous Intelligence, Surveillance, and Reconnaissance (ISR) missions in contested environments, where adversaries may act strategically to deceive or evade detection. These missions pose challenges due to model uncertainty and the need for safe, real-time decision-making. Robust Markov Decision Processes (RMDPs) provide worst-case guarantees but are limited by static ambiguity sets that capture initial uncertainty without adapting to new observations. This paper presents an adaptive RMDP framework tailored to ISR missions with CCAs. We introduce a mission-specific formulation in which aircraft alternate between movement and sensing states. Adversarial tactics are modeled as a finite set of transition kernels, each capturing assumptions about how adversarial sensing or environmental conditions affect rewards. Our approach incrementally refines policies by eliminating inconsistent threat models, allowing agents to shift from conservative to aggressive behaviors while maintaining robustness. We provide theoretical guarantees showing that the adaptive planner converges as credible sets contract to the true threat and maintains safety under uncertainty. Experiments under Gaussian and non-Gaussian threat models across diverse network topologies show higher mission rewards and fewer exposure events compared to nominal and static robust planners.

Paper number 114:
Title: Dynamic Log-Gaussian Process Control Barrier Function for Safe Robotic Navigation in Dynamic Environments
Authors: Xin Yin, Chenyang Liang, Yanning Guo, Jie Mei
Abstract: Control Barrier Functions (CBFs) have emerged as efficient tools to address the safe navigation problem for robot applications. However, synthesizing informative and obstacle motion-aware CBFs online using real-time sensor data remains challenging, particularly in unknown and dynamic scenarios. Motived by this challenge, this paper aims to propose a novel Gaussian Process-based formulation of CBF, termed the Dynamic Log Gaussian Process Control Barrier Function (DLGP-CBF), to enable real-time construction of CBF which are both spatially informative and responsive to obstacle motion. Firstly, the DLGP-CBF leverages a logarithmic transformation of GP regression to generate smooth and informative barrier values and gradients, even in sparse-data regions. Secondly, by explicitly modeling the DLGP-CBF as a function of obstacle positions, the derived safety constraint integrates predicted obstacle velocities, allowing the controller to proactively respond to dynamic obstacles' motion. Simulation results demonstrate significant improvements in obstacle avoidance performance, including increased safety margins, smoother trajectories, and enhanced responsiveness compared to baseline methods.

Paper number 115:
Title: A unified framework for geometry-independent operator learning in cardiac electrophysiology simulations
Authors: Bei Zhou, Cesare Corrado, Shuang Qian, Maximilian Balmus, Angela W. C. Lee, Cristobal Rodero, Marco J.W. Gotte, Luuk H.G.A. Hopman, Mengyun Qiao, Steven Niederer
Abstract: Accurate maps of atrial electrical activation are essential for personalised treatment of arrhythmias, yet biophysically detailed simulations remain computationally intensive for real-time clinical use or population-scale analyses. Here we introduce a geometry-independent operator-learning framework that predicts local activation time (LAT) fields across diverse left atrial anatomies with near-instantaneous inference. We generated a dataset of 308,700 simulations using a GPU-accelerated electrophysiology solver, systematically varying multiple pacing sites and physiologically varied conduction properties across 147 patient-specific geometries derived from two independent clinical cohorts. All anatomical and functional data are expressed in a Universal Atrium Coordinate system, providing a consistent representation that decouples electrophysiological patterns from mesh topology. Within this coordinate space, we designed a neural operator with a vision-transformer backbone to learn the mapping from structural and electrophysiological inputs to LAT fields. With a mean prediction error of 5.1 ms over a 455 ms maximum simulation time, the model outperforms established operator-learning approaches and performs inference in 0.12 ms per sample. Our framework establishes a general strategy for learning domain-invariant biophysical mappings across variable anatomical domains and enables integration of computational electrophysiology into real-time and large-scale clinical workflows.

Paper number 116:
Title: AgriLiRa4D: A Multi-Sensor UAV Dataset for Robust SLAM in Challenging Agricultural Fields
Authors: Zhihao Zhan, Yuhang Ming, Shaobin Li, Jie Yuan
Abstract: Multi-sensor Simultaneous Localization and Mapping (SLAM) is essential for Unmanned Aerial Vehicles (UAVs) performing agricultural tasks such as spraying, surveying, and inspection. However, real-world, multi-modal agricultural UAV datasets that enable research on robust operation remain scarce. To address this gap, we present AgriLiRa4D, a multi-modal UAV dataset designed for challenging outdoor agricultural environments. AgriLiRa4D spans three representative farmland types-flat, hilly, and terraced-and includes both boundary and coverage operation modes, resulting in six flight sequence groups. The dataset provides high-accuracy ground-truth trajectories from a Fiber Optic Inertial Navigation System with Real-Time Kinematic capability (FINS_RTK), along with synchronized measurements from a 3D LiDAR, a 4D Radar, and an Inertial Measurement Unit (IMU), accompanied by complete intrinsic and extrinsic calibrations. Leveraging its comprehensive sensor suite and diverse real-world scenarios, AgriLiRa4D supports diverse SLAM and localization studies and enables rigorous robustness evaluation against low-texture crops, repetitive patterns, dynamic vegetation, and other challenges of real agricultural environments. To further demonstrate its utility, we benchmark four state-of-the-art multi-sensor SLAM algorithms across different sensor combinations, highlighting the difficulty of the proposed sequences and the necessity of multi-modal approaches for reliable UAV localization. By filling a critical gap in agricultural SLAM datasets, AgriLiRa4D provides a valuable benchmark for the research community and contributes to advancing autonomous navigation technologies for agricultural UAVs. The dataset can be downloaded from: this https URL.

Paper number 117:
Title: Delay Tolerant Networking to Extend Connectivity in Rural Areas Using Public Transport Systems: Design And Analysis
Authors: Salah Abdeljabar, Marco Zennaro, Mohamed-Slim Alouini
Abstract: In today's digital age, access to the Internet is essential, yet a significant digital divide exists, particularly in rural areas of developing nations. This paper presents a Delay Tolerant Networking (DTN) framework that utilizes informal public transportation systems, such as minibus taxis, as mobile data mules to enhance connectivity in these underserved regions. We develop a probabilistic model to capture the randomness in vehicle mobility, including travel times and contact durations at bus stops. Key performance metrics are analyzed, including average data transmission rate and Peak Age of Information (PAoI), to assess the effectiveness of the proposed system. An analytical approximation for the Mean PAoI (MPAoI) is derived and validated through simulations. Case studies from real-world datasets in Nouakchott, Accra, and Addis Ababa demonstrate the practical applicability and scalability of our framework. The findings indicate that leveraging existing transportation networks can significantly bridge the digital divide by providing reliable internet-like connectivity to remote areas.

Paper number 118:
Title: Experiment design using prior knowledge on controllability and stabilizability
Authors: Amir Shakouri, Henk J. van Waarde, M. Kanat Camlibel
Abstract: In this paper, we consider the problem of designing input signals for an unknown linear time-invariant system in such a way that the resulting input-state data is suitable for identification or stabilization. We will take into account prior knowledge on system-theoretic properties of the system, in particular, controllability and stabilizability. For this, we extend the notion of universal inputs to incorporate prior knowledge on the system. An input is called universal for identification (resp., stabilization) if, when applied to any system complying with the prior knowledge, it results in data suitable for identification (resp., stabilization) regardless of the initial condition. We provide a full characterization of such universal inputs. In addition, we discuss online experiment design using prior knowledge, and we study cases where this approach results in the shortest possible experiment for identification and stabilization.

Paper number 119:
Title: NeuroHJR: Hamilton-Jacobi Reachability-based Obstacle Avoidance in Complex Environments with Physics-Informed Neural Networks
Authors: Granthik Halder, Rudrashis Majumder, Rakshith M R, Rahi Shah, Suresh Sundaram
Abstract: Autonomous ground vehicles (AGVs) must navigate safely in cluttered environments while accounting for complex dynamics and environmental uncertainty. Hamilton-Jacobi Reachability (HJR) offers formal safety guarantees through the computation of forward and backward reachable sets, but its application is hindered by poor scalability in environments with numerous obstacles. In this paper, we present a novel framework called NeuroHJR that leverages Physics-Informed Neural Networks (PINNs) to approximate the HJR solution for real-time obstacle avoidance. By embedding system dynamics and safety constraints directly into the neural network loss function, our method bypasses the need for grid-based discretization and enables efficient estimation of reachable sets in continuous state spaces. We demonstrate the effectiveness of our approach through simulation results in densely cluttered scenarios, showing that it achieves safety performance comparable to that of classical HJR solvers while significantly reducing the computational cost. This work provides a new step toward real-time, scalable deployment of reachability-based obstacle avoidance in robotics.

Paper number 120:
Title: Feature-Based Semantics-Aware Scheduling for Energy-Harvesting Federated Learning
Authors: Eunjeong Jeong, Giovanni Perin, Howard H. Yang, Nikolaos Pappas
Abstract: Federated Learning (FL) on resource-constrained edge devices faces a critical challenge: The computational energy required for training Deep Neural Networks (DNNs) often dominates communication costs. However, most existing Energy-Harvesting FL (EHFL) strategies fail to account for this reality, resulting in wasted energy due to redundant local computations. For efficient and proactive resource management, algorithms that predict local update contributions must be devised. We propose a lightweight client scheduling framework using the Version Age of Information (VAoI), a semantics-aware metric that quantifies update timeliness and significance. Crucially, we overcome VAoI's typical prohibitive computational cost, which requires statistical distance over the entire parameter space, by introducing a feature-based proxy. This proxy estimates model redundancy using intermediate-layer extraction from a single forward pass, dramatically reducing computational complexity. Experiments conducted under extreme non-IID data distributions and scarce energy availability demonstrate superior learning performance while achieving energy reduction compared to existing baseline selection policies. Our framework establishes semantics-aware scheduling as a practical and vital solution for EHFL in realistic scenarios where training costs dominate transmission costs.

Paper number 121:
Title: Hidden Markov Models for Stock Market Prediction
Authors: Luigi Catello, Ludovica Ruggiero, Lucia Schiavone, Mario Valentino
Abstract: The stock market presents a challenging environment for accurately predicting future stock prices due to its intricate and ever-changing nature. However, the utilization of advanced methodologies can significantly enhance the precision of stock price predictions. One such method is Hidden Markov Models (HMMs). HMMs are statistical models that can be used to model the behavior of a partially observable system, making them suitable for modeling stock prices based on historical data. Accurate stock price predictions can help traders make better investment decisions, leading to increased profits. In this article, we trained and tested a Hidden Markov Model for the purpose of predicting a stock closing price based on its opening price and the preceding day's prices. The model's performance has been evaluated using two indicators: Mean Average Prediction Error (MAPE), which specifies the average accuracy of our model, and Directional Prediction Accuracy (DPA), a newly introduced indicator that accounts for the number of fractional change predictions that are correct in sign.

Paper number 122:
Title: Beyond Subspace Isolation: Many-to-Many Transformer for Light Field Image Super-resolution
Authors: Zeke Zexi Hu, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen
Abstract: The effective extraction of spatial-angular features plays a crucial role in light field image super-resolution (LFSR) tasks, and the introduction of convolution and Transformers leads to significant improvement in this area. Nevertheless, due to the large 4D data volume of light field images, many existing methods opted to decompose the data into a number of lower-dimensional subspaces and perform Transformers in each sub-space individually. As a side effect, these methods inadvertently restrict the self-attention mechanisms to a One-to-One scheme accessing only a limited subset of LF data, explicitly preventing comprehensive optimization on all spatial and angular cues. In this paper, we identify this limitation as subspace isolation and introduce a novel Many-to-Many Transformer (M2MT) to address it. M2MT aggregates angular information in the spatial subspace before performing the self-attention mechanism. It enables complete access to all information across all sub-aperture images (SAIs) in a light field image. Consequently, M2MT is enabled to comprehensively capture long-range correlation dependencies. With M2MT as the foundational component, we develop a simple yet effective M2MT network for LFSR. Our experimental results demonstrate that M2MT achieves state-of-the-art performance across various public datasets, and it offers a favorable balance between model performance and efficiency, yielding higher-quality LFSR results with substantially lower demand for memory and computation. We further conduct in-depth analysis using local attribution maps (LAM) to obtain visual interpretability, and the results validate that M2MT is empowered with a truly non-local context in both spatial and angular subspaces to mitigate subspace isolation and acquire effective spatial-angular representation.

Paper number 123:
Title: GuideGen: A Text-Guided Framework for Paired Full-torso Anatomy and CT Volume Generation
Authors: Linrui Dai, Rongzhao Zhang, Yongrui Yu, Xiaofan Zhang
Abstract: The recently emerging conditional diffusion models seem promising for mitigating the labor and expenses in building large 3D medical imaging datasets. However, previous studies on 3D CT generation primarily focus on specific organs characterized by a local structure and fixed contrast and have yet to fully capitalize on the benefits of both semantic and textual conditions. In this paper, we present GuideGen, a controllable framework based on easily-acquired text prompts to generate anatomical masks and corresponding CT volumes for the entire torso-from chest to pelvis. Our approach includes three core components: a text-conditional semantic synthesizer for creating realistic full-torso anatomies; an anatomy-aware high-dynamic-range (HDR) autoencoder for high-fidelity feature extraction across varying intensity levels; and a latent feature generator that ensures alignment between CT images, anatomical semantics and input prompts. Combined, these components enable data synthesis for segmentation tasks from only textual instructions. To train and evaluate GuideGen, we compile a multi-modality cancer imaging dataset with paired CT and clinical descriptions from 12 public TCIA datasets and one private real-world dataset. Comprehensive evaluations across generation quality, cross-modality alignment, and data usability on multi-organ and tumor segmentation tasks demonstrate GuideGen's superiority over existing CT generation methods. Relevant materials are available at this https URL.

Paper number 124:
Title: Characterizing Demand Response Capability of Thermostatically Controlled Loads with Reach and Hold Sets
Authors: Mazen Elsaadany, Hamid R. Ossareh, Mads R. Almassalkhi
Abstract: Aggregations of thermostatically controlled loads (TCLs), such as air conditioners, offer valuable flexibility to the power grid. The aggregate power consumption of a TCL fleet can be controlled by adjusting thermostat setpoints. An ex-ante quantification of the flexibility that results from such setpoint change can inform grid operator decisions. This paper develops a rigorous, yet practical method to quantify flexibility in terms of the `reach-and-hold' set of TCL aggregations, which defines how much power can be shifted (reach) and for how long (hold). To quantify the reach-and-hold set, we employ a Markov-chain-based model of the TCL aggregation that captures second-order TCL dynamics, enabling accurate characterization of reach-and-hold sets. A tractable optimization problem is then formulated to numerically compute an inner approximation of these sets. Simulation results validate that our method accurately characterizes the fleet's flexibility and effectively controls its power consumption. Furthermore, a robustness analysis is carried out to investigate the effects of uncertainty in initial conditions and TCL parameters.

Paper number 125:
Title: Self-Supervised One-Step Diffusion Refinement for Snapshot Compressive Imaging
Authors: Shaoguang Huang, Yunzhen Wang, Haijin Zeng, Hongyu Chen, Hongyan Zhang
Abstract: Snapshot compressive imaging (SCI) captures multispectral images (MSIs) using a single coded two-dimensional (2-D) measurement, but reconstructing high-fidelity MSIs from these compressed inputs remains a fundamentally ill-posed challenge. While diffusion-based reconstruction methods have recently raised the bar for quality, they face critical limitations: a lack of large-scale MSI training data, adverse domain shifts from RGB-pretrained models, and inference inefficiencies due to multi-step sampling. These drawbacks restrict their practicality in real-world applications. In contrast to existing methods, which either follow costly iterative refinement or adapt subspace-based embeddings for diffusion models (e.g. DiffSCI, PSR-SCI), we introduce a fundamentally different paradigm: a self-supervised One-Step Diffusion (OSD) framework specifically designed for SCI. The key novelty lies in using a single-step diffusion refiner to correct an initial reconstruction, eliminating iterative denoising entirely while preserving generative quality. Moreover, we adopt a self-supervised equivariant learning strategy to train both the predictor and refiner directly from raw 2-D measurements, enabling generalization to unseen domains without the need for ground-truth MSI. To further address the challenge of limited MSI data, we design a band-selection-driven distillation strategy that transfers core generative priors from large-scale RGB datasets, effectively bridging the domain gap. Extensive experiments confirm that our approach sets a new benchmark, yielding PSNR gains of 3.44 dB, 1.61 dB, and 0.28 dB on the Harvard, NTIRE, and ICVL datasets, respectively, while reducing reconstruction time by 97.5%. This remarkable improvement in efficiency and adaptability makes our method a significant advancement in SCI reconstruction, combining both accuracy and practicality for real-world deployment.

Paper number 126:
Title: Learning Dissipative Chaotic Dynamics with Boundedness Guarantee
Authors: Sunbochen Tang, Themistoklis Sapsis, Navid Azizan
Abstract: Chaotic dynamics, commonly seen in weather systems and fluid turbulence, are characterized by their sensitivity to initial conditions, which makes accurate prediction challenging. Recent approaches have focused on developing data-driven models that attempt to preserve invariant statistics over long horizons since many chaotic systems exhibit dissipative behaviors and ergodicity. Despite the recent progress in such models, they are still often prone to generating unbounded trajectories, leading to invalid statistics evaluation. To address this fundamental challenge, we introduce a modular framework that provides formal guarantees of trajectory boundedness for neural network chaotic dynamics models. Our core contribution is a dissipative projection layer that leverages control-theoretic principles to ensure the learned system is dissipative. Specifically, our framework simultaneously learns a dynamics emulator and an energy-like function, where the latter is used to construct an algebraic dissipative constraint within the projection layer. Furthermore, the learned invariant level set provides an outer estimate for the system's strange attractor, which is known to be difficult to characterize due to its complex geometry. We demonstrate our model's ability to produce bounded long-horizon forecasts that preserve invariant statistics for chaotic dynamical systems, including Lorenz 96 and a reduced-order model of the Kuramoto-Sivashinsky equation.

Paper number 127:
Title: 3D MedDiffusion: A 3D Medical Latent Diffusion Model for Controllable and High-quality Medical Image Generation
Authors: Haoshen Wang, Zhentao Liu, Kaicong Sun, Xiaodong Wang, Dinggang Shen, Zhiming Cui
Abstract: The generation of medical images presents significant challenges due to their high-resolution and three-dimensional nature. Existing methods often yield suboptimal performance in generating high-quality 3D medical images, and there is currently no universal generative framework for medical imaging. In this paper, we introduce a 3D Medical Latent Diffusion (3D MedDiffusion) model for controllable, high-quality 3D medical image generation. 3D MedDiffusion incorporates a novel, highly efficient Patch-Volume Autoencoder that compresses medical images into latent space through patch-wise encoding and recovers back into image space through volume-wise decoding. Additionally, we design a new noise estimator to capture both local details and global structural information during diffusion denoising process. 3D MedDiffusion can generate fine-detailed, high-resolution images (up to 512x512x512) and effectively adapt to various downstream tasks as it is trained on large-scale datasets covering CT and MRI modalities and different anatomical regions (from head to leg). Experimental results demonstrate that 3D MedDiffusion surpasses state-of-the-art methods in generative quality and exhibits strong generalizability across tasks such as sparse-view CT reconstruction, fast MRI reconstruction, and data augmentation for segmentation and classification. Source code and checkpoints are available at this https URL.

Paper number 128:
Title: Aggregative games with bilevel structures: Distributed algorithms and convergence analysis
Authors: Kaihong Lu, Huanshui Zhang, Long Wang
Abstract: In this paper, the problem of distributively seeking the equilibria of aggregative games with bilevel structures is studied. Different from the traditional aggregative games, here the aggregation is determined by the minimizer of a virtual leader's objective function in the inner level, which depends on the actions of the players in the outer level. Moreover, the global objective function of the virtual leader is formed by the sum of some local functions with two arguments, each of which is strongly convex with respect to the second argument. When making decisions, each player in the outer level only has access to a local part of the virtual leader's objective function. To handle this problem, first, we propose a second order gradient-based distributed algorithm, where the Hessian matrices associated with the objective functions of the leader are involved. By the algorithm, players update their actions while cooperatively minimizing the objective function of the virtual leader to estimate the aggregation by communicating with their neighbors via a connected graph. Under mild assumptions on the graph and cost functions, we prove that the actions of players asymptotically converge to the Nash equilibrium point. Then, for the case where the Hessian matrices associated with the objective functions of the virtual leader are not available, we propose a first order gradient-based distributed algorithm, where a distributed two-point estimate strategy is developed to estimate the gradients of players' cost functions in the outer level. Under the same conditions, we prove that the convergence errors of players' actions to the Nash equilibrium point are linear with respect to the estimate parameters. Finally, simulations are provided to demonstrate the effectiveness of our theoretical results.

Paper number 129:
Title: Towards Hierarchical Multi-Agent Decision-Making for Uncertainty-Aware EV Charging
Authors: Lo Pang-Yun Ting, Ali Şenol, Huan-Yang Wang, Hsu-Chao Lai, Kun-Ta Chuang, Huan Liu
Abstract: Recent advances in bidirectional EV charging and discharging systems have spurred interest in workplace applications. However, real-world deployments face various dynamic factors, such as fluctuating electricity prices and uncertain EV departure times, that hinder effective energy management. To address these issues and minimize building electricity costs while meeting EV charging requirements, we design a hierarchical multi-agent structure in which a high-level agent coordinates overall charge or discharge decisions based on real-time pricing, while multiple low-level agents manage individual power level accordingly. For uncertain EV departure times, we propose a novel uncertainty-aware critic augmentation mechanism for low-level agents that improves the evaluation of power-level decisions and ensures robust control under such uncertainty. Building upon these two key designs, we introduce HUCA, a real-time charging control framework that coordinates energy supply among the building and EVs. Experiments on real-world electricity datasets show that HUCA significantly reduces electricity costs and maintains competitive performance in meeting EV charging requirements under both simulated certain and uncertain departure scenarios. The results further highlight the importance of hierarchical control and the proposed critic augmentation under the uncertain departure scenario. A case study illustrates HUCA's capability to allocate energy between the building and EVs in real time, underscoring its potential for practical use.

Paper number 130:
Title: RIFT: Entropy-Optimised Fractional Wavelet Constellations for Ideal Time-Frequency Estimation
Authors: James M. Cozens, Simon J. Godsill
Abstract: We introduce a new method for estimating the Ideal Time-Frequency Representation (ITFR) of complex nonstationary signals. The Reconstructive Ideal Fractional Transform (RIFT) computes a constellation of Continuous Fractional Wavelet Transforms (CFWTs) aligned to different local time-frequency curvatures. This constellation is combined into a single optimised time-frequency energy representation via a localised entropy-based sparsity measure, designed to resolve auto-terms and attenuate cross-terms. Finally, a positivity-constrained Lucy-Richardson deconvolution with total-variation regularisation is applied to estimate the ITFR, achieving auto-term resolution comparable to that of the Wigner-Ville Distribution (WVD), yielding the high-resolution RIFT representation. The required Cohen's class convolutional kernels are fully derived in the paper for the chosen CFWT constellations. Additionally, the optimisation yields an Instantaneous Phase Direction (IPD) field, which allows the localised curvature in speech or music extracts to be visualised and utilised within a Kalman tracking scheme, enabling the extraction of signal component trajectories and the construction of the Spline-RIFT variant. Evaluation on synthetic and real-world signals demonstrates the algorithm's ability to effectively suppress cross-terms and achieve superior time-frequency precision relative to competing methods. This advance holds significant potential for a wide range of applications requiring high-resolution cross-term-free time-frequency analysis.

Paper number 131:
Title: Full-scale Representation Guided Network for Retinal Vessel Segmentation
Authors: Sunyong Seo, Sangwook Yoo, Huisu Yoon
Abstract: The U-Net architecture and its variants have remained state-of-the-art (SOTA) for retinal vessel segmentation over the past decade. In this study, we introduce a Full-Scale Guided Network (FSG-Net), where a novel feature representation module using modernized convolution blocks effectively captures full-scale structural information, while a guided convolution block subsequently refines this information. Specifically, we introduce an attention-guided filter within the guided convolution block, leveraging its similarity to unsharp masking to enhance fine vascular structures. Passing full-scale information to the attention block facilitates the generation of more contextually relevant attention maps, which are then passed to the attention-guided filter, providing further refinement to the segmentation performance. The structure preceding the guided convolution block can be replaced by any U-Net variant, ensuring flexibility and scalability across various segmentation tasks. For a fair comparison, we re-implemented recent studies available in public repositories to evaluate their scalability and reproducibility. Our experiments demonstrate that, despite its compact architecture, FSG-Net delivers performance competitive with SOTA methods across multiple public datasets. Ablation studies further demonstrate that each proposed component meaningfully contributes to this competitive performance. Our code is available on this https URL.

Paper number 132:
Title: Safeguarding Privacy in Edge Speech Understanding with Tiny Foundation Models
Authors: Afsara Benazir, Felix Xiaozhu Lin
Abstract: Robust speech recognition systems rely on cloud service providers for inference. It needs to ensure that an untrustworthy provider cannot deduce the sensitive content in speech. Sanitization can be done on speech content keeping in mind that it has to avoid compromising transcription accuracy. Realizing the under utilized capabilities of tiny speech foundation models (FMs), for the first time, we propose a novel use: enhancing speech privacy on resource-constrained devices. We introduce SpeechShield, an edge/cloud privacy preserving speech inference engine that can filter sensitive entities without compromising transcript accuracy. We utilize a timestamp based on-device masking approach that utilizes a token to entity prediction model to filter sensitive entities. Our choice of mask strategically conceals parts of the input and hides sensitive data. The masked input is sent to a trusted cloud service or to a local hub to generate the masked output. The effectiveness of SpeechShield hinges on how well the entity time segments are masked. Our recovery is a confidence score based approach that chooses the best prediction between cloud and on-device model. We implement SpeechShield on a 64 bit Raspberry Pi 4B. Experiments show that our solution leads to robust speech recognition without forsaking privacy. SpeechShield with < 100 MB memory, achieves state-of-the-art (SOTA) speech transcription performance while filtering about 83% of private entities directly on-device. SpeechShield is 16x smaller in memory, 3.3x faster and 17x more compute efficient than prior privacy preserving speech frameworks and has a relative reduction in word error rate (WER) by 38.8-77.5% when compared to existing offline transcription services.

Paper number 133:
Title: Retrieving Filter Spectra in CNN for Explainable Sleep Stage Classification
Authors: Stephan Goerttler, Yucheng Wang, Fei He, Min Wu
Abstract: Despite significant advances in deep learning-based sleep stage classification, the clinical adoption of automatic classification models remains slow. One key challenge is the lack of explainability, as many models function as black boxes with millions of parameters. In response, recent work has increasingly focussed on enhancing model explainability. This study contributes to these efforts by introducing an explainability tool for spectral processing of individual EEG channels. Specifically, this tools retrieves the filter spectrum of low-level convolutional feature extraction and compares it with the classification-relevant spectral information in the data. We apply our tool on the EEGNet and MSA-CNN models using the ISRUC-S3 and Sleep-EDF-20 datasets. The tool reveals that spectral processing plays a significant role in the lower frequency bands. In addition, comparing the correlation between filter spectrum and data-derived spectral information with univariate performance indicates that the model naturally prioritises the most informative channels in a multimodal setting. We specify how these insights can be leveraged to enhance model performance. The code for the filter spectrum retrieval and its analysis is available at this https URL.

Paper number 134:
Title: Adaptive Experiment Design for Nonlinear System Identification with Operational Constraints
Authors: Jingwei Hu, Dave Zachariah, Torbjörn Wigren, Petre Stoica
Abstract: We consider the joint problem of online experiment design and parameter estimation for identifying nonlinear system models, while adhering to system constraints. We utilize a receding horizon approach and propose a new adaptive input design criterion, which is tailored to continuously updated parameter estimates, along with a new sequential estimator. We demonstrate the ability of the method to design informative experiments online, while steering the system within operational constraints.

Paper number 135:
Title: GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain tumour Segmentation on mp-MRI
Authors: Cecilia Diana-Albelda, Roberto Alcover-Couso, Álvaro García-Martín, Jesus Bescos, Marcos Escudero-Viñolo
Abstract: Gliomas are aggressive brain tumors that require accurate imaging-based diagnosis, with segmentation playing a critical role in evaluating morphology and treatment decisions. Manual delineation of gliomas is time-consuming and prone to variability, motivating the use of deep learning to improve consistency and alleviate clinical workload. However, existing methods often fail to fully exploit the information available in multi-parametric MRI (mp-MRI), particularly inter-slice contextual features, and typically require considerable computational resources while lacking robustness across tumor type variations. We present GBT-SAM, a parameter-efficient deep learning framework that adapts the Segment Anything Model (SAM), a large-scale vision model, to volumetric mp-MRI data. GBT-SAM reduces input complexity by selecting fewer than 2.6\% of slices per scan while incorporating all four MRI modalities, preserving essential tumor-related information with minimal cost. Furthermore, our model is trained by a two-step fine-tuning strategy that incorporates a depth-aware module to capture inter-slice correlations and lightweight adaptation layers, resulting in just 6.5M trainable parameters, which is the lowest among SAM-based approaches. GBT-SAM achieves a Dice Score of 93.54 on the BraTS Adult Glioma dataset and demonstrates robust performance on Meningioma, Pediatric Glioma, and Sub-Saharan Glioma datasets. These results highlight GBT-SAM's potential as a computationally efficient and domain-robust framework for brain tumor segmentation using mp-MRI. Our code and models are available at this https URL .

Paper number 136:
Title: Set-based and Dynamical Feedback-augmented Hands-off Control
Authors: Andrei Sperilă, Sorin Olaru, Stéphane Drobot
Abstract: A novel set-theoretical approach to hands-off control is proposed, focusing on spatial arguments for command limitation rather than temporal ones. By employing dynamical feedback alongside invariant set-based constraints, actuation is employed only to drive the system's state within a "hands-off region" of its state-space, where the plant can freely evolve in open-loop configuration. A computationally-efficient procedure with strong theoretical guarantees is devised, and its effectiveness is showcased via an intuitive practical example.

Paper number 137:
Title: L2RU: a Structured State Space Model with prescribed L2-bound
Authors: Leonardo Massai, Muhammad Zakwan, Giancarlo Ferrari-Trecate
Abstract: Structured state-space models (SSMs) have recently emerged as a powerful architecture at the intersection of machine learning and control, featuring layers composed of discrete-time linear time-invariant (LTI) systems followed by pointwise nonlinearities. These models combine the expressiveness of deep neural networks with the interpretability and inductive bias of dynamical systems, offering strong performance on long-sequence tasks with favorable computational complexity. However, their adoption in applications such as system identification and optimal control remains limited by the difficulty of enforcing stability and robustness in a principled and tractable manner. We introduce L2RU, a class of SSMs endowed with a prescribed $\mathcal{L}_2$-gain bound, guaranteeing input--output stability and robustness for all parameter values. The L2RU architecture is derived from free parametrizations of LTI systems satisfying an $\mathcal{L}_2$ constraint, enabling unconstrained optimization via standard gradient-based methods while preserving rigorous stability guarantees. Specifically, we develop two complementary parametrizations: a non-conservative formulation that provides a complete characterization of square LTI systems with a given $\mathcal{L}_2$-bound, and a conservative formulation that extends the approach to general (possibly non-square) systems while improving computational efficiency through a structured representation of the system matrices. Both parametrizations admit efficient initialization schemes that facilitate training long-memory models. We demonstrate the effectiveness of the proposed framework on a nonlinear system identification benchmark, where L2RU achieves improved performance and training stability compared to existing SSM architectures, highlighting its potential as a principled and robust building block for learning and control.

Paper number 138:
Title: Curvature-Constrained Vector Field for Motion Planning of Nonholonomic Robots
Authors: Yike Qiao, Xiaodong He, An Zhuo, Zhiyong Sun, Weimin Bao, Zhongkui Li
Abstract: Vector fields are advantageous in handling nonholonomic motion planning as they provide reference orientation for robots. However, additionally incorporating curvature constraints becomes challenging, due to the interconnection between the design of the curvature-bounded vector field and the tracking controller under underactuation. In this paper, we present a novel framework to co-develop the vector field and the control laws, guiding the nonholonomic robot to the target configuration with curvature-bounded trajectory. First, we formulate the problem by introducing the target positive limit set, which allows the robot to converge to or pass through the target configuration, depending on different dynamics and tasks. Next, we construct a curvature-constrained vector field (CVF) via blending and distributing basic flow fields in workspace and propose the saturated control laws with a dynamic gain, under which the tracking error's magnitude decreases even when saturation occurs. Under the control laws, kinematically constrained nonholonomic robots are guaranteed to track the reference CVF and converge to the target positive limit set with bounded trajectory curvature. Numerical simulations show that the proposed CVF method outperforms other vector-field-based algorithms. Experiments on Ackermann UGVs and semi-physical fixed-wing UAVs demonstrate that the method can be effectively implemented in real-world scenarios.

Paper number 139:
Title: A Cyber Insurance Policy for Hedging Against Load-Altering Attacks and Extreme Load Variations in Distribution Grids
Authors: Shijie Pan, Zaint A. Alexakis, S Subhash Lakshminarayana, Charalambos Konstantinou
Abstract: Uncertainties in renewable energy resources (RES) and load variations can lead to elevated system operational costs. Moreover, the emergence of large-scale distributed threats, such as load-altering attacks (LAAs), can induce substantial load variations, further exacerbating these costs. Although traditional defense measures can reduce the likelihood of such attacks, considerable residual risks remain. Thus, this paper proposes a cyber insurance framework designed to hedge against additional operational costs resulting from LAAs and substantial load variations in renewable-rich grids. The insurance framework determines both the insurance coverage and premium based on the Value at Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated using the system failure probability and the probability density function (PDF) of the system operation cost. The system failure probability is assessed through a semi-Markov process (SMP), while the cost distribution is estimated through a cost minimization model of a distribution grid combined with a Monte Carlo simulation to capture load variability. Furthermore, we employ a bi-level optimization scheme that identifies the specific load distribution leading to the maximum system cost, thereby enhancing the accuracy of the operation cost PDF estimation. The effectiveness and scalability of the proposed cyber insurance policy are evaluated considering a modified IEEE 118-bus test system and the IEEE European low-voltage (LV) test feeder model. The case study shows that with a relatively low premium, the network operator can hedge against additional operational costs caused by malicious load manipulations.

Paper number 140:
Title: SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses
Authors: Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi
Abstract: Deep learning has shown strong performance in musculoskeletal imaging, but prior work has largely targeted conditions where diagnosis is relatively straightforward. More challenging problems remain underexplored, such as detecting Bankart lesions (anterior-inferior glenoid labral tears) on standard MRIs. These lesions are difficult to diagnose due to subtle imaging features, often necessitating invasive MRI arthrograms (MRAs). We introduce ScopeMRI, the first publicly available, expert-annotated dataset for shoulder pathologies, and present a deep learning framework for Bankart lesion detection on both standard MRIs and MRAs. ScopeMRI contains shoulder MRIs from patients who underwent arthroscopy, providing ground-truth labels from intraoperative findings, the diagnostic gold standard. Separate models were trained for MRIs and MRAs using CNN- and transformer-based architectures, with predictions ensembled across multiple imaging planes. Our models achieved radiologist-level performance, with accuracy on standard MRIs surpassing radiologists interpreting MRAs. External validation on independent hospital data demonstrated initial generalizability across imaging protocols. By releasing ScopeMRI and a modular codebase for training and evaluation, we aim to accelerate research in musculoskeletal imaging and foster development of datasets and models that address clinically challenging diagnostic tasks.

Paper number 141:
Title: Discrete Optimal Transport and Voice Conversion
Authors: Anton Selitskiy, Maitreya Kocharekar
Abstract: In this work, we address the voice conversion (VC) task using a vector-based interface. To align audio embeddings between speakers, we employ discrete optimal transport mapping. Our evaluation results demonstrate the high quality and effectiveness of this method. Additionally, we show that applying discrete optimal transport as a post-processing step in audio generation can lead to the incorrect classification of synthetic audio as real.

Paper number 142:
Title: PhySense: Sensor Placement Optimization for Accurate Physics Sensing
Authors: Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long
Abstract: Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: this https URL.

Paper number 143:
Title: Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention
Authors: TaeJun Ha, Chaehyun Jung, Hyeonuk Kim, Jeongwoo Park, Jeonghun Park
Abstract: In orthogonal frequency division multiplexing (OFDM), accurate channel estimation is crucial. Classical signal processing based approaches, such as minimum mean-squared error (MMSE) estimation, often require second-order statistics that are difficult to obtain in practice. Recent deep neural networks based methods have been introduced to address this; yet they often suffer from high inference complexity. This paper proposes an Attention-aided MMSE (A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter via the Attention Transformer. Once trained, the A-MMSE estimates the channel through a single linear operation for channel estimation, eliminating nonlinear activations during inference and thus reducing computational complexity. To enhance the learning efficiency of the A-MMSE, we develop a two-stage Attention encoder, designed to effectively capture the channel correlation structure. Additionally, a rank-adaptive extension of the proposed A-MMSE allows flexible trade-offs between complexity and channel estimation accuracy. Extensive simulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE consistently outperforms other baseline methods in terms of normalized MSE across a wide range of signal-to-noise ratio (SNR) conditions. In particular, the A-MMSE and its rank-adaptive extension establish a new frontier in the performance-complexity trade-off, providing a powerful yet highly efficient solution for practical channel estimation

Paper number 144:
Title: Real-Time High-Accuracy Digital Wireless Time, Frequency, and Phase Calibration For Coherent Distributed Antenna Arrays
Authors: Jason M. Merlo, Samuel Wagner, John Lancaster, Jeffrey A. Nanzer
Abstract: This work presents a fully-digital high-accuracy real-time calibration procedure for frequency and time alignment of open-loop wirelessly coordinated coherent distributed antenna array (CDA) modems, enabling radio frequency (RF) phase coherence of spatially separated commercial off-the-shelf (COTS) software-defined radios (SDRs) without cables or external references such as global navigation satellite system (GNSS). Building on previous work using high-accuracy spectrally-sparse time of arrival (ToA) waveforms and a multi-step ToA refinement process, a high-accuracy two-way time transfer (TWTT)-based timefrequency coordination approach is demonstrated. Due to the two-way nature of the high-accuracy TWTT approach, the time and frequency estimates are Doppler and multi-path tolerant, so long as the channel is reciprocal over the synchronization epoch. This technique is experimentally verified using COTS SDRs in a lab environment in static and dynamic scenarios and with significant multipath scatterers. Time, frequency, and phase stability were evaluated by beamforming over coaxial cables to an oscilloscope which achieved time and phase precisions of ~60 ps-70 ps, with median coherent gains above 99 % using optimized coordination parameters, and a beamforming frequency root-mean-square error (RMSE) of 3.73 ppb in a dynamic scenario. Finally, experiments were conducted to compare the performance of this technique with previous works using an analog continuous-wave two-tone (CWTT) frequency reference technique in both static and dynamic settings.

Paper number 145:
Title: A distributed motion planning approach to cooperative underwater acoustic source tracking
Authors: Andrea Tiranti, Francesco Wanderlingh, Enrico Simetti, Marco Baglietto, Giovanni Indiveri, Antonio Pascoal
Abstract: Accurate tracking of underwater acoustic sources is critical for a variety of marine applications, yet remains a challenging task due to communication constraints and environmental uncertainties. In this regard, this paper addresses the problem of underwater acoustic source tracking using a team of autonomous underwater vehicles (AUVs). The core idea is to optimize the guidance of each agent to achieve coordinated motion planning that leads to optimal geometric configurations with respect to the target, thereby enhancing tracking performance. To tackle this, we propose a Distributed Model Predictive Control (DMPC) framework to improve performance and robustness. The control problem is formulated as a multi-objective optimization task, incorporating geometric observability, proximity to the target, and communication connectivity. A Receding Horizon Control (RHC) approach, coupled with an Unscented Transform (UT)-based prediction scheme, is employed to ensure longterm tracking accuracy while accounting for uncertainties. The optimization is distributed using the sequential multi-agent decision-making framework, combined with the Time-Division Multiple Access (TDMA) communication protocol. The proposed methodology is implemented in a simulation environment that accounts for the constraints of acoustic communication. The approach is compared with existing methods such as decentralized MPC and Particle Swarm Optimization (PSO).

Paper number 146:
Title: Zero-shot Denoising via Neural Compression: Theoretical and algorithmic framework
Authors: Ali Zafari, Xi Chen, Shirin Jalali
Abstract: Zero-shot denoising aims to denoise observations without access to training samples or clean reference images. This setting is particularly relevant in practical imaging scenarios involving specialized domains such as medical imaging or biology. In this work, we propose the Zero-Shot Neural Compression Denoiser (ZS-NCD), a novel denoising framework based on neural compression. ZS-NCD treats a neural compression network as an untrained model, optimized directly on patches extracted from a single noisy image. The final reconstruction is then obtained by aggregating the outputs of the trained model over overlapping patches. Thanks to the built-in entropy constraints of compression architectures, our method naturally avoids overfitting and does not require manual regularization or early stopping. Through extensive experiments, we show that ZS-NCD achieves state-of-the-art performance among zero-shot denoisers for both Gaussian and Poisson noise, and generalizes well to both natural and non-natural images. Additionally, we provide new finite-sample theoretical results that characterize upper bounds on the achievable reconstruction error of general maximum-likelihood compression-based denoisers. These results further establish the theoretical foundations of compression-based denoising. Our code is available at: this https URL.

Paper number 147:
Title: Make Your AUV Adaptive: An Environment-Aware Reinforcement Learning Framework For Underwater Tasks
Authors: Yimian Ding, Jingzehua Xu, Guanwen Xie, Shuai Zhang, Yi Li
Abstract: This study presents a novel environment-aware reinforcement learning (RL) framework designed to augment the operational capabilities of autonomous underwater vehicles (AUVs) in underwater environments. Departing from traditional RL architectures, the proposed framework integrates an environment-aware network module that dynamically captures flow field data, effectively embedding this critical environmental information into the state space. This integration facilitates real-time environmental adaptation, significantly enhancing the AUV's situational awareness and decision-making capabilities. Furthermore, the framework incorporates AUV structure characteristics into the optimization process, employing a large language model (LLM)-based iterative refinement mechanism that leverages both environmental conditions and training outcomes to optimize task performance. Comprehensive experimental evaluations demonstrate the framework's superior performance, robustness and adaptability.

Paper number 148:
Title: Decision-Focused Learning for Neural Network-Constrained HVAC Scheduling
Authors: Pietro Favaro, Jean-François Toubeau, François Vallée, Yury Dvorkin
Abstract: Heating, Ventilation, and Air Conditioning (HVAC) is a major electricity end-use with a substantial potential for providing grid services, such as demand response. Harnessing this flexibility requires accurate modeling of the thermal dynamics of buildings, a difficult task because nonlinear heat transfer and recurring daily cycles make historical data highly correlated and insufficient to generalize to new weather, occupancy, and control scenarios. This paper presents an HVAC management system formulated as a Mixed Integer Quadratic Program (MIQP), where Neural Network (NN) models of thermal dynamics are embedded as exact mixed-integer linear constraints. Unlike traditional training approaches that minimize prediction errors, we employ Decision-Focused Learning (DFL) to learn the NN parameters with the objective of directly improving the HVAC cost performance. However, the discrete nature of MIQP hinders DFL, as it leads to undefined and discontinuous gradients, thus impeding standard gradient-based training. We leverage Stochastic Smoothing (SS) to enable efficient gradient computation without the need to differentiate the MIQP. Experiments on a realistic five-zone building using a high-fidelity simulator demonstrate that the proposed SS-DFL approach outperforms conventional identify-then-optimize (i.e., the thermal dynamics model is identified on historical data then used in optimization) and relaxed DFL methods in both cost savings and grid service performance, highlighting its potential for scalable, grid-aware building control.

Paper number 149:
Title: The Extended SONICOM HRTF Dataset and Spatial Audio Metrics Toolbox
Authors: Katarina C. Poole, Julie Meyer, Vincent Martin, Rapolas Daugintis, Nils Marggraf-Turley, Jack Webb, Ludovic Pirard, Nicola La Magna, Oliver Turvey, Lorenzo Picinali
Abstract: Headphone-based spatial audio uses head-related transfer functions (HRTFs) to simulate real-world acoustic environments. HRTFs are unique to everyone, due to personal morphology, shaping how sound waves interact with the body before reaching the eardrums. Here we present the extended SONICOM HRTF dataset which expands on the previous version released in 2023. The total number of measured subjects has now been increased to 300, with demographic information for a subset of the participants, providing context for the dataset's population and relevance. The dataset incorporates synthesised HRTFs for 200 of the 300 subjects, generated using Mesh2HRTF, alongside pre-processed 3D scans of the head and ears, optimised for HRTF synthesis. This rich dataset facilitates rapid and iterative optimisation of HRTF synthesis algorithms, allowing the automatic generation of large data. The optimised scans enable seamless morphological modifications, providing insights into how anatomical changes impact HRTFs, and the larger sample size enhances the effectiveness of machine learning approaches. To support analysis, we also introduce the Spatial Audio Metrics (SAM) Toolbox, a Python package designed for efficient analysis and visualisation of HRTF data, offering customisable tools for advanced research. Together, the extended dataset and toolbox offer a comprehensive resource for advancing personalised spatial audio research and development.

Paper number 150:
Title: How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks
Authors: Clement Ruah, Houssem Sifaou, Osvaldo Simeone, Bashir M. Al-Hashimi
Abstract: Training effective artificial intelligence models for telecommunications is challenging due to the scarcity of deployment-specific data. Real data collection is expensive, and available datasets often fail to capture the unique operational conditions and contextual variability of the network environment. Digital twinning provides a potential solution to this problem, as simulators tailored to the current network deployment can generate site-specific data to augment the available training datasets. However, there is a need to develop solutions to bridge the inherent simulation-to-reality (sim-to-real) gap between synthetic and real-world data. This paper reviews recent advances on two complementary strategies: 1) the calibration of digital twins (DTs) through real-world measurements, and 2) the use of sim-to-real gap-aware training strategies to robustly handle residual discrepancies between digital twin-generated and real data. For the latter, we evaluate two conceptually distinct methods that model the sim-to-real gap either at the level of the environment via Bayesian learning or at the level of the training loss via prediction-powered inference.

Paper number 151:
Title: Cross-Cancer Knowledge Transfer in WSI-based Prognosis Prediction
Authors: Pei Liu, Luping Ji, Jiaxiang Gou, Xiangxiang Zeng
Abstract: Whole-Slide Image (WSI) is an important tool for estimating cancer prognosis. Current studies generally follow a conventional cancer-specific paradigm in which each cancer corresponds to a single model. However, this paradigm naturally struggles to scale to rare tumors and cannot leverage knowledge from other cancers. While multi-task learning frameworks have been explored recently, they often place high demands on computational resources and require extensive training on ultra-large, multi-cancer WSI datasets. To this end, this paper shifts the paradigm to knowledge transfer and presents the first preliminary yet systematic study on cross-cancer prognosis knowledge transfer in WSIs, called CROPKT. It comprises three major parts. (1) We curate a large dataset (UNI2-h-DSS) with 26 cancers and use it to measure the transferability of WSI-based prognostic knowledge across different cancers (including rare tumors). (2) Beyond a simple evaluation merely for benchmarking, we design a range of experiments to gain deeper insights into the underlying mechanism behind transferability. (3) We further show the utility of cross-cancer knowledge transfer, by proposing a routing-based baseline approach (ROUPKT) that could often efficiently utilize the knowledge transferred from off-the-shelf models of other cancers. CROPKT could serve as an inception that lays the foundation for this nascent paradigm, i.e., WSI-based prognosis prediction with cross-cancer knowledge transfer. Our source code is available at this https URL.

Paper number 152:
Title: AHAMask: Reliable Task Specification for Large Audio Language Models without Instructions
Authors: Yiwei Guo, Bohan Li, Hankun Wang, Zhihan Li, Shuai Wang, Xie Chen, Kai Yu
Abstract: Although current large audio language models (LALMs) extend text large language models (LLMs) with generic acoustic understanding abilities, they usually suffer from prompt sensitivity, where different instructions of the same intention can yield drastically different outcomes. In this work, we propose AHAMask, where we simply mask some of the attention heads in the decoder-only LLM backbone of LALMs, to trigger specific acoustic task functionalities without instructions. These masks are efficiently obtained by training on an LALM, with the number of trainable parameters equal to the attention head count in its LLM backbone. We show by experiments that applying such selective attention head masks achieves comparable or even better performance than using instructions, either on single or composite tasks. Besides achieving reliable acoustic task specification for LALMs, this also reveals that LALMs exhibit certain "functional pathways" in their attention heads.

Paper number 153:
Title: High-Resolution Sensing in Communication-Centric ISAC: Deep Learning and Parametric Methods
Authors: Salmane Naoumi, Ahmad Bazzi, Roberto Bomfin, Marwa Chafii
Abstract: This paper introduces two novel algorithms designed to address the challenge of super-resolution sensing parameter estimation in bistatic configurations within communication-centric integrated sensing and communication (ISAC) systems. Our approach leverages the estimated channel state information derived from reference symbols originally intended for communication to achieve super-resolution sensing parameter estimation. The first algorithm, IFFT-C2VNN, employs complex-valued convolutional neural networks to estimate the parameters of different targets, achieving significant reductions in computational complexity compared to traditional methods. The second algorithm, PARAMING, utilizes a parametric method that capitalizes on the knowledge of the system model, including the transmit and receive array geometries, to extract the sensing parameters accurately. Through a comprehensive performance analysis, we demonstrate the effectiveness and robustness of both algorithms across a range of signal-to-noise ratios, underscoring their applicability in realistic ISAC scenarios.

Paper number 154:
Title: Fluid-Antenna-aided AAV Secure Communications in Eavesdropper Uncertain Location
Authors: Yingjie Wu, Junshan Luo, Weiyu Chen, Shilian Wang, Fanggang Wang, Haiyang Ding
Abstract: For autonomous aerial vehicle (AAV) secure communications, traditional designs based on fixed position antenna (FPA) lack sufficient spatial degrees of freedom (DoF), which leaves the line-of-sight-dominated AAV links vulnerable to eavesdropping. To overcome this problem, this paper proposes a framework that effectively incorporates the fluid antenna (FA) and the artificial noise (AN) techniques. Specifically, the minimum secrecy rate (MSR) among multiple eavesdroppers is maximized by jointly optimizing AAV deployment, signal and AN precoders, and FA positions. In particular, the worst-case MSR is considered by taking the channel uncertainties due to the uncertainty about eavesdropping locations into account. To tackle the highly coupled optimization variables and the channel uncertainties in the formulated problem, an efficient and robust algorithm is proposed. Particularly, the uncertain regions of eavesdroppers, whose shapes can be arbitrary, are disposed by constructing convex hull. In addition, two movement modes of FAs are considered, namely, free movement mode and zonal movement mode, for which different optimization techniques are applied, respectively. Numerical results show that, the proposed FA schemes boost security by exploiting additional spatial DoF rather than transmit power, while AN provides remarkable gains under high transmit power. Furthermore, the synergy between FA and AN results in a secure advantage that exceeds the sum of their individual contributions, achieving a balance between security and reliability under limited resources.

Paper number 155:
Title: A Linear Programming Framework for Optimal Event-Triggered LQG Control
Authors: Zahra Hashemi, Dipankar Maity
Abstract: This letter explores intelligent scheduling of sensor-to-controller communication in networked control systems, particularly when data transmission incurs a cost. While the optimal controller in a standard linear quadratic Gaussian (LQG) setup can be computed analytically, determining the optimal times to transmit sensor data remains computationally and analytically challenging. We show that, through reformulation and the introduction of auxiliary binary variables, the scheduling problem can be cast as a computationally efficient mixed-integer linear program (MILP). This formulation not only simplifies the analysis but also reveals structural insights and provides clear decision criteria at each step. Embedding the approach within a model predictive control (MPC) framework enables dynamic adaptation, and we prove that the resulting scheduler performs at least as well as any deterministic strategy (e.g., periodic strategy). Simulation results further demonstrate that our method consistently outperforms traditional periodic scheduling.

Paper number 156:
Title: NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems
Authors: Tianqi Mao, Haiyang Li, Shufeng Tan, Pengyu Wang, Guangyao Liu, Ruiqi Liu, Leyi Zhang, Meng Hua, Dezhi Zheng, Zhaocheng Wang, Sheng Chen
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems, operating in the near-field region due to their massive antenna arrays, are key enablers of next-generation wireless communications but face significant challenges in channel state information (CSI) feedback. Deep learning has emerged as a powerful tool by learning compact channel features for feedback. However, existing methods struggle to capture the intricate structure of near-field CSI and incur prohibitive computational overhead on practical mobile devices. To overcome these limitations, we propose the near-field efficient feedback Transformer (NEFT) family for accurate near-field CSI feedback with reduced overhead under diverse hardware constraints. NEFT builds on a hierarchical vision Transformer backbone with progressive token reduction and multi-scale feature extraction, enabling compact and effective modeling of near-field channel characteristics. Furthermore, NEFT is extended with lightweight variants: NEFT-Compact applies multi-level knowledge distillation (KD) to reduce model complexity while preserving accuracy; NEFT-Hybrid adopts an attention-free CNN encoder to reduce encoder-side computation; and NEFT-Edge combines NEFT-Hybrid with KD to enable deployment on highly resource-constrained edge devices. Extensive simulations show that NEFT achieves a 15--21dB improvement in normalized mean-squared error over state-of-the-art methods, NEFT-Compact and NEFT-Edge reduce total FLOPs by 25-36% with negligible accuracy loss, while NEFT-Hybrid reduces encoder-side complexity by up to 64%, enabling deployment in highly asymmetric device scenarios. These results establish NEFT as a practical and scalable solution for near-field CSI feedback in XL-MIMO systems.

Paper number 157:
Title: Semantic-VAE: Semantic-Alignment Latent Representation for Better Speech Synthesis
Authors: Zhikang Niu, Shujie Hu, Jeongsoo Choi, Yushen Chen, Peining Chen, Pengcheng Zhu, Yunting Yang, Bowen Zhang, Jian Zhao, Chunhui Wang, Xie Chen
Abstract: While mel-spectrograms have been widely utilized as intermediate representations in zero-shot text-to-speech (TTS), their inherent redundancy leads to inefficiency in learning text-speech alignment. Compact VAE-based latent representations have recently emerged as a stronger alternative, but they also face a fundamental optimization dilemma: higher-dimensional latent spaces improve reconstruction quality and speaker similarity, but degrade intelligibility, while lower-dimensional spaces improve intelligibility at the expense of reconstruction fidelity. To overcome this dilemma, we propose Semantic-VAE, a novel VAE framework that utilizes semantic alignment regularization in the latent space. This design alleviates the reconstruction-generation trade-off by capturing semantic structure in high-dimensional latent representations. Extensive experiments demonstrate that Semantic-VAE significantly improves synthesis quality and training efficiency. When integrated into F5-TTS, our method achieves 2.10% WER and 0.64 speaker similarity on LibriSpeech-PC, outperforming mel-based systems (2.23%, 0.60) and vanilla acoustic VAE baselines (2.65%, 0.59). We also release the code and models to facilitate further research.

Paper number 158:
Title: Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with Multiplicative Noise
Authors: Gabriel Diaz, Lucky Li, Wenhao Zhang
Abstract: Reinforcement Learning (RL) has emerged as a powerful framework for sequential decision-making in dynamic environments, particularly when system parameters are unknown. This paper investigates RL-based control for entropy-regularized linear-quadratic (LQ) control problems with multiplicative noise over an infinite time horizon. First, we adapt the regularized policy gradient (RPG) algorithm to stochastic optimal control settings, proving that despite the non-convexity of the problem, RPG converges globally under conditions of gradient domination and almost-smoothness. Second, based on zero-order optimization approach, we introduce a novel model free RL algorithm: Sample-based regularized policy gradient (SB-RPG). SB-RPG operates without knowledge of system parameters yet still retains strong theoretical guarantees of global convergence. Our model leverages entropy regularization to address the exploration versus exploitation trade-off inherent in RL. Numerical simulations validate the theoretical results and demonstrate the efficiency of SB-RPG in unknown-parameters environments.

Paper number 159:
Title: MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean Flows
Authors: Guobin Ma, Jixun Yao, Ziqian Ning, Yuepeng Jiang, Lingxin Xiong, Lei Xie, Pengcheng Zhu
Abstract: Zero-shot voice conversion (VC) aims to transfer timbre from a source speaker to any unseen target speaker while preserving linguistic content. Growing application scenarios demand models with streaming inference capabilities. This has created a pressing need for models that are simultaneously fast, lightweight, and high-fidelity. However, existing streaming methods typically rely on either autoregressive (AR) or non-autoregressive (NAR) frameworks, which either require large parameter sizes to achieve strong performance or struggle to generalize to unseen speakers. In this study, we propose MeanVC, a lightweight and streaming zero-shot VC approach. MeanVC introduces a diffusion transformer with a chunk-wise autoregressive denoising strategy, combining the strengths of both AR and NAR paradigms for efficient streaming processing. By introducing mean flows, MeanVC regresses the average velocity field during training, enabling zero-shot VC with superior speech quality and speaker similarity in a single sampling step by directly mapping from the start to the endpoint of the flow trajectory. Additionally, we incorporate diffusion adversarial post-training to mitigate over-smoothing and further enhance speech quality. Experimental results demonstrate that MeanVC significantly outperforms existing zero-shot streaming VC systems, achieving superior conversion quality with higher efficiency and significantly fewer parameters. Audio demos and code are publicly available at this https URL.

Paper number 160:
Title: TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks
Authors: Johannes Kiechle, Stefan M. Fischer, Daniel M. Lang, Cosmin I. Bercea, Matthew J. Nyflot, Lina Felsner, Julia A. Schnabel, Jan C. Peeken
Abstract: The sharp rise in medical tomography examinations has created a demand for automated systems that can reliably extract informative features for downstream tasks such as tumor characterization. Although 3D volumes contain richer information than individual slices, effective 3D classification remains difficult: volumetric data encode complex spatial dependencies, and the scarcity of large-scale 3D datasets has constrained progress toward 3D foundation models. As a result, many recent approaches rely on 2D vision foundation models trained on natural images, repurposing them as feature extractors for medical scans with surprisingly strong performance. Despite their practical success, current methods that apply 2D foundation models to 3D scans via slice-based decomposition remain fundamentally limited. Standard slicing along axial, sagittal, and coronal planes often fails to capture the true spatial extent of a structure when its orientation does not align with these canonical views. More critically, most approaches aggregate slice features independently, ignoring the underlying 3D geometry and losing spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. Instead of restricting the model to axial, sagittal, or coronal planes, our method samples both canonical and non-canonical cross-sections generated from uniformly distributed points on a sphere enclosing the volume. We publicly share our accessible code base at this http URL and provide a user-friendly library for omnidirectional volume slicing at this https URL.

Paper number 161:
Title: MRI Super-Resolution with Deep Learning: A Comprehensive Survey
Authors: Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms, Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi, Alejandra Sierra, Jussi Tohka, Sila Kurugol, Onur Afacan
Abstract: High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: this https URL. IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.

Paper number 162:
Title: PolyOCP.jl -- A Julia Package for Stochastic OCPs and MPC
Authors: Ruchuan Ou, Learta Januzi, Jonas Schießl, Michael Heinrich Baumann, Lars Grüne, Timm Faulwasser
Abstract: The consideration of stochastic uncertainty in optimal and predictive control is a well-explored topic. Recently Polynomial Chaos Expansions (PCE) have seen a lot of considerations for problems involving stochastically uncertain system parameters and also for problems with additive stochastic i.i.d. disturbances. While there exist a number of open-source PCE toolboxes, tailored open-source codes for the solution of OCPs involving additive stochastic i.i.d. disturbances in julia are not available. Hence, this paper introduces the toolbox \texttt{this http URL} which enables to efficiently solve stochastic OCPs for a large class of disturbance distributions. We explain the main mathematical concepts between the PCE transcription of stochastic OCPs and how they are provided in the toolbox. We draw upon two examples to illustrate the functionalities of \texttt{this http URL}.

Paper number 163:
Title: Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports
Authors: Youzhe Yang, Hafiz Majid Hussain, Juha Haakana, Pedro Nardelli
Abstract: A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations.

Paper number 164:
Title: An Exact, Finite Dimensional Representation for Full-Block, Circle Criterion Multipliers
Authors: Felix Biertümpfel, Bin Hu, Geir Dullerud, Peter Seiler
Abstract: This paper provides the first finite-dimensional characterization for the complete set of full-block, circle criterion multipliers. We consider the interconnection of a discrete-time, linear time-invariant system in feedback with a non-repeated, sector-bounded nonlinearity. Sufficient conditions for stability and performance can be derived using: (i) dissipation inequalities, and (ii) Quadratic Constraints (QCs) that bound the input/output pairs of the nonlinearity. Larger classes of QCs (or multipliers) reduce the conservatism of the conditions. Full-block, circle criterion multipliers define the complete set of all possible QCs for non-repeated, sector-bounded nonlinearities. These provide the least conservative conditions. However, full-block multipliers are defined by an uncountably infinite number of constraints and hence do not lead to computationally tractable solutions if left in this raw form. This paper provides a new finite-dimensional characterization for the set of full-block, circle criterion multipliers. The key theoretical insight is: the set of all input/output pairs of non-repeated sector-bounded nonlinearities is equal to the set of all incremental pairs for an appropriately constructed piecewise linear function. Our new description for the complete set of multipliers only requires a finite number of matrix copositivity constraints. These conditions have an exact, computationally tractable implementation for problems where the nonlinearity has small input/output dimensions $(\le 4)$. We illustrate the use of our new characterization via a simple example.

Paper number 165:
Title: Deep Learning for Restoring MPI System Matrices Using Simulated Training Data
Authors: Artyom Tsanda, Sarah Reiss, Konrad Scheffler, Marija Boberg, Tobias Knopp
Abstract: Magnetic particle imaging reconstructs tracer distributions using a system matrix obtained through time-consuming, noise-prone calibration measurements. Methods for addressing imperfections in measured system matrices increasingly rely on deep neural networks, yet curated training data remain scarce. This study evaluates whether physics-based simulated system matrices can be used to train deep learning models for different system matrix restoration tasks, i.e., denoising, accelerated calibration, upsampling, and inpainting, that generalize to measured data. A large system matrices dataset was generated using an equilibrium magnetization model extended with uniaxial anisotropy. The dataset spans particle, scanner, and calibration parameters for 2D and 3D trajectories, and includes background noise injected from empty-frame measurements. For each restoration task, deep learning models were compared with classical non-learning baseline methods. The models trained solely on simulated system matrices generalized to measured data across all tasks: for denoising, DnCNN/RDN/SwinIR outperformed DCT-F baseline by >10 dB PSNR and up to 0.1 SSIM on simulations and led to perceptually better reconstuctions of real data; for 2D upsampling, SMRnet exceeded bicubic by 20 dB PSNR and 0.08 SSIM at $\times 2$-$\times 4$ which did not transfer qualitatively to real measurements. For 3D accelerated calibration, SMRnet matched tricubic in noiseless cases and was more robust under noise, and for 3D inpainting, biharmonic inpainting was superior when noise-free but degraded with noise, while a PConvUNet maintained quality and yielded less blurry reconstructions. The demonstrated transferability of deep learning models trained on simulations to real measurements mitigates the data-scarcity problem and enables the development of new methods beyond current measurement capabilities.

Paper number 166:
Title: Meta-Reinforcement Learning for Building Energy Management System
Authors: Benoit Boulet Huiliang Zhang, Di Wu, Arnaud Zinflou
Abstract: The building sector is one of the largest contributors to global energy consumption. Improving its energy efficiency is essential for reducing operational costs and greenhouse gas emissions. Energy management systems (EMS) play a key role in monitoring and controlling building appliances efficiently and reliably. With the increasing integration of renewable energy, intelligent EMS solutions have received growing attention. Reinforcement learning (RL) has recently been explored for this purpose and shows strong potential. However, most RL-based EMS methods require a large number of training steps to learn effective control policies, especially when adapting to unseen buildings, which limits their practical deployment. This paper introduces MetaEMS, a meta-reinforcement learning framework for EMS. MetaEMS improves learning efficiency by transferring knowledge from previously solved tasks to new ones through group-level and building-level adaptation, enabling fast adaptation and effective control across diverse building environments. Experimental results demonstrate that MetaEMS adapts more rapidly to unseen buildings and consistently outperforms baseline methods across various scenarios.

Paper number 167:
Title: Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks
Authors: Chung-Hsuan Hu, Zheng Chen, Erik G. Larsson
Abstract: Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.

Paper number 168:
Title: Multilingual DistilWhisper: Efficient Distillation of Multi-task Speech Models via Language-Specific Experts
Authors: Thomas Palmeira Ferraz, Marcely Zanon Boito, Caroline Brun, Vassilina Nikoulina
Abstract: Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we propose DistilWhisper, an approach able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.

Paper number 169:
Title: Dynamical State Feedback Control for Linear Input Delay Systems, Part I: Dissipative Stabilization via Semidefinite Programming
Authors: Qian Feng, Cong Zhang, Bo Wei
Abstract: We propose an SDP-based framework to address the stabilization of input delay systems while taking into account dissipative constraints. A key to our approach is the introduction of the concept of parameterized linear dynamical state feedbacks (LDSFs), which draws inspiration from recent advancements in the analyses of distributed delays. The parameterized LDSFs generalize conventional predictor controllers, where the interpretation of state prediction is concealed and their degree of parameterization can be increased by adjusting the integral kernels. A sufficient condition for the existence of dissipative LDSFs is formulated as matrix inequalities by constructing a complete type Krasovski\uı functional. To solve the bilinear matrix inequality in the synthesis condition, we employ an off-line inner convex approximation algorithm that can be initialized using the gains of predictor controllers obtained via explicit construction. So the unknowns of our LTDS can be computed by solving convex semidefinite programs. Numerical examples and simulations were experimented to demonstrate the validity and effectiveness of our methodology.

Paper number 170:
Title: MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition
Authors: Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu
Abstract: Electroencephalography (EEG), a technique that records electrical activity from the scalp using electrodes, plays a vital role in affective computing. However, fully utilizing the multi-domain characteristics of EEG signals remains a significant challenge. Traditional single-perspective analyses often fail to capture the complex interplay of temporal, frequency, and spatial dimensions in EEG data. To address this, we introduce a multi-view graph transformer (MVGT) based on spatial relations that integrates information across three domains: temporal dynamics from continuous series, frequency features extracted from frequency bands, and inter-channel relationships captured through several spatial encodings. This comprehensive approach allows model to capture the nuanced properties inherent in EEG signals, enhancing its flexibility and representational power. Evaluation on publicly available datasets demonstrates that MVGT surpasses state-of-the-art methods in performance. The results highlight its ability to extract multi-domain information and effectively model inter-channel relationships, showcasing its potential for EEG-based emotion recognition tasks.

Paper number 171:
Title: NeKo: Cross-Modality Post-Recognition Error Correction with Tasks-Guided Mixture-of-Experts Language Model
Authors: Yen-Ting Lin, Zhehuai Chen, Piotr Zelasko, Zhen Wan, Xuesong Yang, Zih-Ching Chen, Krishna C Puvvada, Szu-Wei Fu, Ke Hu, Jun Wei Chiu, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Chao-Han Huck Yang
Abstract: Construction of a general-purpose post-recognition error corrector poses a crucial question: how can we most effectively train a model on a large mixture of domain datasets? The answer would lie in learning dataset-specific features and digesting their knowledge in a single model. Previous methods achieve this by having separate correction language models, resulting in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose a Multi-Task Correction MoE, where we train the experts to become an ``expert'' of speech-to-text, language-to-text and vision-to-text datasets by learning to route each dataset's tokens to its mapped expert. Experiments on the Open ASR Leaderboard show that we explore a new state-of-the-art performance by achieving an average relative 5.0% WER reduction and substantial improvements in BLEU scores for speech and translation tasks. On zero-shot evaluation, NeKo outperforms GPT-3.5 and Claude-Opus with 15.5% to 27.6% relative WER reduction in the Hyporadise benchmark. NeKo performs competitively on grammar and post-OCR correction as a multi-task model.

Paper number 172:
Title: U-FaceBP: Uncertainty-aware Bayesian Ensemble Deep Learning for Face Video-based Blood Pressure Measurement
Authors: Yusuke Akamatsu, Akinori F. Ebihara, Terumi Umematsu
Abstract: Blood pressure (BP) measurement is crucial for daily health assessment. Remote photoplethysmography (rPPG), which extracts pulse waves from face videos captured by a camera, has the potential to enable convenient BP measurement without specialized medical devices. However, there are various uncertainties in BP estimation using rPPG, leading to limited estimation performance and reliability. In this paper, we propose U-FaceBP, an uncertainty-aware Bayesian ensemble deep learning method for face video-based BP measurement. U-FaceBP models aleatoric and epistemic uncertainties in face video-based BP estimation with a Bayesian neural network (BNN). Additionally, we design U-FaceBP as an ensemble method, estimating BP from rPPG signals, PPG signals derived from face videos, and face images using multiple BNNs. Large-scale experiments on two datasets involving 1197 subjects from diverse racial groups demonstrate that U-FaceBP outperforms state-of-the-art BP estimation methods. Furthermore, we show that the uncertainty estimates provided by U-FaceBP are informative and useful for guiding modality fusion, assessing prediction reliability, and analyzing performance across racial groups.

Paper number 173:
Title: Beamforming Design for Beyond Diagonal RIS-Aided Cell-Free Massive MIMO Systems
Authors: Yizhuo Li, Jiakang Zheng, Bokai Xu, Yiyang Zhu, Jiayi Zhang, Dusit Niyato, Bo Ai
Abstract: Reconfigurable intelligent surface (RIS)-aided cell-free (CF) massive multiple-input multiple-output (mMIMO) is a promising technology for further improving spectral efficiency (SE) with low cost and power consumption. However, conventional RIS has inevitable limitations due to its diagonal scattering matrix. In contrast, beyond-diagonal RIS (BD-RIS) has gained great attention. This correspondence focuses on integrating a hybrid transmitting and reflecting BD-RIS into CF mMIMO systems to enhance coverage and spatial multiplexing. This requires completing the beamforming design under the transmit power constraints and unitary constraints of the BD-RIS, by optimizing active and passive beamformer simultaneously. To tackle this issue, we introduce an alternating optimization algorithm that decomposes it using fractional programming and solves the subproblems alternatively. Moreover, to address the challenge introduced by the unitary constraint on the beamforming matrix of the BD-RIS, we propose a Riemannian limited-memory Broyden-Fletcher-Goldfarb-Shanno (R-L-BFGS) algorithm to solve the problem optimally. Simulation results show that our algorithm achieves faster convergence and finds higher-quality solutions compared with baselines, while also demonstrating a favorable performance-complexity trade-off.

Paper number 174:
Title: Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow
Authors: Andrew Rosemberg, Michael Klamkin, Pascal Van Hentenryck
Abstract: The growing scale of power systems and the increasing uncertainty introduced by renewable energy sources necessitates novel optimization techniques that are significantly faster and more accurate than existing methods. The AC Optimal Power Flow (AC-OPF) problem, a core component of power grid optimization, is often approximated using linearized DC Optimal Power Flow (DC-OPF) models for computational tractability, albeit at the cost of suboptimal and inefficient decisions. To address these limitations, we propose a novel deep learning-based framework for network equivalency that enhances DC-OPF to more closely mimic the behavior of AC-OPF. The approach utilizes recent advances in differentiable optimization, incorporating a neural network trained to predict adjusted nodal shunt conductances and branch susceptances in order to account for nonlinear power flow behavior. The model can be trained end-to-end using modern deep learning frameworks by leveraging the implicit function theorem. Results demonstrate the framework's ability to significantly improve prediction accuracy.

Paper number 175:
Title: How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane
Authors: Taekyung Kim, Randal W. Beard, Dimitra Panagou
Abstract: In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.

Paper number 176:
Title: Comparative Evaluation of Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2
Authors: Zackary Rackauckas, Julia Hirschberg
Abstract: Synthesizing expressive Japanese character speech poses unique challenges due to pitch-accent sensitivity and stylistic variability. This paper empirically evaluates two open-source text-to-speech models--VITS and Style-BERT-VITS2 JP Extra (SBV2JE)--on in-domain, character-driven Japanese speech. Using three character-specific datasets, we evaluate models across naturalness (mean opinion and comparative mean opinion score), intelligibility (word error rate), and speaker consistency. SBV2JE matches human ground truth in naturalness (MOS 4.37 vs. 4.38), achieves lower WER, and shows slight preference in CMOS. Enhanced by pitch-accent controls and a WavLM-based discriminator, SBV2JE proves effective for applications like language learning and character dialogue generation, despite higher computational demands.

Paper number 177:
Title: Homeostatic Ubiquity of Hebbian Dynamics in Regularized Learning Rules
Authors: David Koplow, Tomaso Poggio, Liu Ziyin
Abstract: Hebbian and anti-Hebbian plasticity are widely observed in the biological brain, yet their theoretical understanding remains limited. In this work, we find that when a learning method is regularized with L2 weight decay, its learning signal will gradually align with the direction of the Hebbian learning signal as it approaches stationarity. This Hebbian-like behavior is not unique to SGD: almost any learning rule, including random ones, can exhibit the same signature long before learning has ceased. We also provide a theoretical explanation for anti-Hebbian plasticity in regression tasks, demonstrating how it can arise naturally from gradient or input noise, and offering a potential reason for the observed anti-Hebbian effects in the brain. Certainly, our proposed mechanisms do not rule out any conventionally established forms of Hebbian plasticity and could coexist with them extensively in the brain. A key insight for neurophysiology is the need to develop ways to experimentally distinguish these two types of Hebbian observations.

Paper number 178:
Title: AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials
Authors: Mohammad El Sakka, Caroline De Pourtales, Lotfi Chaari, Josiane Mothe
Abstract: Remote sensing has emerged as a critical tool for large-scale Earth monitoring and land management. In this paper, we introduce AgriPotential, a novel benchmark dataset composed of Sentinel-2 satellite imagery captured over multiple months. The dataset provides pixel-level annotations of agricultural potentials for three major crop types - viticulture, market gardening, and field crops - across five ordinal classes. AgriPotential supports a broad range of machine learning tasks, including ordinal regression, multi-label classification, and spatio-temporal modeling. The data cover diverse areas in Southern France, offering rich spectral information. AgriPotential is the first public dataset designed specifically for agricultural potential prediction, aiming to improve data-driven approaches to sustainable land use planning. The dataset and the code are freely accessible at: this https URL

Paper number 179:
Title: Multigranular Evaluation for Brain Visual Decoding
Authors: Weihao Xia, Cengiz Oztireli
Abstract: Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground-truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for evaluating brain visual decoding methods.

Paper number 180:
Title: SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models
Authors: Zhen Wan, Chao-Han Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Sadao Kurohashi
Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human cognition-inspired evaluation pipeline for voice understanding large language models, LLM Voice, designed to assess their voice understanding ability. Moving beyond popular voice understanding metrics such as word error rate (WER), SIQ examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy: (1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e., similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy for simulating downstream tasks). We demonstrate that SIQ not only quantifies voice understanding abilities but also provides unified comparisons between cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation errors in existing benchmarks, and detects hallucinations in LLM Voice. Our framework represents a first-of-its-kind intelligence examination that bridges cognitive principles with voice-oriented benchmarks, while exposing overlooked challenges in multi-modal training. Our code and data will be open source to encourage future studies.

Paper number 181:
Title: UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands
Authors: Haoran Lin, Wenrui Chen, Xianchi Chen, Fan Yang, Qiang Diao, Wenxin Xie, Sijie Wu, Kailun Yang, Maojun Li, Yaonan Wang
Abstract: Dexterous grasp datasets are vital for embodied intelligence, but mostly emphasize grasp stability, ignoring functional grasps needed for tasks like opening bottle caps or holding cup handles. Most rely on bulky, costly, and hard-to-control high-DOF Shadow Hands. Inspired by the human hand's underactuated mechanism, we establish UniFucGrasp, a universal functional grasp annotation strategy and dataset for multiple dexterous hand types. Based on biomimicry, it maps natural human motions to diverse hand structures and uses geometry-based force closure to ensure functional, stable, human-like grasps. This method supports low-cost, efficient collection of diverse, high-quality functional grasps. Finally, we establish the first multi-hand functional grasp dataset and provide a synthesis model to validate its effectiveness. Experiments on the UFG dataset, IsaacSim, and complex robotic tasks show that our method improves functional manipulation accuracy and grasp stability, demonstrates improved adaptability across multiple robotic hands, helping to alleviate annotation cost and generalization challenges in dexterous grasping. The project page is at this https URL.

Paper number 182:
Title: Towards Fully Onboard State Estimation and Trajectory Tracking for UAVs with Suspended Payloads
Authors: Martin Jiroušek, Tomáš Báča, Martin Saska
Abstract: This paper addresses the problem of tracking the position of a cable-suspended payload carried by an unmanned aerial vehicle, with a focus on real-world deployment and minimal hardware requirements. In contrast to many existing approaches that rely on motion-capture systems, additional onboard cameras, or instrumented payloads, we propose a framework that uses only standard onboard sensors--specifically, real-time kinematic global navigation satellite system measurements and data from the onboard inertial measurement unit--to estimate and control the payload's position. The system models the full coupled dynamics of the aerial vehicle and payload, and integrates a linear Kalman filter for state estimation, a model predictive contouring control planner, and an incremental model predictive controller. The control architecture is designed to remain effective despite sensing limitations and estimation uncertainty. Extensive simulations demonstrate that the proposed system achieves performance comparable to control based on ground-truth measurements, with only minor degradation (< 6%). The system also shows strong robustness to variations in payload parameters. Field experiments further validate the framework, confirming its practical applicability and reliable performance in outdoor environments using only off-the-shelf aerial vehicle hardware.

Paper number 183:
Title: Distance Between Stochastic Linear Systems
Authors: Venkatraman Renganathan, Sei Zhen Khong
Abstract: While the existing stochastic control theory is well equipped to handle dynamical systems with stochastic uncertainties, a paradigm shift using distance measure based decision making is required for the effective further exploration of the field. As a first step, a distance measure between two stochastic linear time invariant systems is proposed here, extending the existing distance metrics between deterministic linear dynamical systems. In the frequency domain, the proposed distance measure corresponds to the worst-case point-wise in frequency Wasserstein distance between distributions characterising the uncertainties using inverse stereographic projection on the Riemann sphere. For the time domain setting, the proposed distance corresponds to the gap metric induced type-q Wasserstein distance between the distributions characterising the uncertainty of plant models. Apart from providing lower and upper bounds for the proposed distance measures in both frequency and time domain settings, it is proved that the former never exceeds the latter. The proposed distance measures will facilitate the provision of probabilistic guarantees on system robustness and controller performances.

Paper number 184:
Title: Convergence Filters for Efficient Economic MPC of Non-dissipative Systems
Authors: Defeng He, Weiliang Xiong, Shiqiang He, Haiping Du
Abstract: This note presents a novel, efficient economic model predictive control (EMPC) scheme for non-dissipative systems subject to state and input constraints. A new conception of convergence filters is defined to address the stability issue of EMPC for constrained non-dissipative systems. Three convergence filters are designed accordingly to be imposed into the receding horizon optimization problem of EMPC. To improve online computational efficiency, the variable horizon idea without explicit terminal state constraints is adopted to compromise the convergence speed, economic performance, and computational burden of EMPC. Moreover, sufficient conditions are derived to guarantee the recursive feasibility and stability of the EMPC. The advantages of the proposed EMPC are validated by a classical non-dissipative continuous stirred-tank reactor.

Paper number 185:
Title: Differentiable-by-design Nonlinear Optimization for Model Predictive Control
Authors: Riccardo Zuliani, Efe C. Balta, John Lygeros
Abstract: Nonlinear optimization-based control policies, such as those those arising in nonlinear Model Predictive Control, have seen remarkable success in recent years. These policies require solving computationally demanding nonlinear optimization programs online at each time-step. The resulting solution map, viewed as a function of the measured state of the system and design parameters, may not be differentiable, which poses significant challenges if the control policy is embedded in a gradient-based policy optimization scheme. We propose a principled way to regularize the nonlinear optimization problem, obtaining a surrogate derivative even if when the original problem is not differentiable. The surrogate problem is differentiable by design and its solution map coincides with the solution of the unregularized problem. We demonstrate the effectiveness of our approach in a free-final-time optimal control problem and a receding-horizon nonlinear MPC example.

Paper number 186:
Title: HQCNN: A Hybrid Quantum-Classical Neural Network for Medical Image Classification
Authors: Shahjalal, Jahid Karim Fahim, Pintu Chandra Paul, Md Robin Hossain, Md. Tofael Ahmed, Dulal Chakraborty
Abstract: Classification of medical images plays a vital role in medical image analysis; however, it remains challenging due to the limited availability of labeled data, class imbalances, and the complexity of medical patterns. To overcome these challenges, we propose a novel Hybrid Quantum-Classical Neural Network (HQCNN) for both binary and multi-class classification. The architecture of HQCNN integrates a five-layer classical convolutional backbone with a 4-qubit variational quantum circuit that incorporates quantum state encoding, superpositional entanglement, and a Fourier-inspired quantum attention mechanism. We evaluate the model on six MedMNIST v2 benchmark datasets. The HQCNN consistently outperforms classical and quantum baselines, achieving up to 99.91% accuracy and 100.00% AUC on PathMNIST (binary) and 99.95% accuracy on OrganAMNIST (multi-class) with strong robustness on noisy datasets like BreastMNIST (87.18% accuracy). The model demonstrates superior generalization capability and computational efficiency, accomplished with significantly fewer trainable parameters, making it suitable for data-scarce scenarios. Our findings provide strong empirical evidence that hybrid quantum-classical models can advance medical imaging tasks.

Paper number 187:
Title: Hyperparameters are all you need: Using five-step inference for an original diffusion model to generate images comparable to the latest distillation model
Authors: Zilai Li
Abstract: The diffusion model is a state-of-the-art generative model that samples images by applying a neural network iteratively. However, the original sampling algorithm requires substantial computation cost, and reducing the sampling step is a prevailing research area. To cope with this problem, one mainstream approach is to treat the sampling process as an algorithm that solves an ordinary differential equation (ODE). Our study proposes a training-free inference plugin compatible with most few-step ODE solvers. To the best of my knowledge, our algorithm is the first training-free algorithm to sample a 1024 x 1024-resolution image in 6 steps and a 512 x 512-resolution image in 5 steps, with an FID result that outperforms the SOTA distillation models and the 20-step DPM++ 2m solver, respectively. Based on analyses of the latent diffusion model's structure, the diffusion ODE, and the Free-U mechanism, we explain why specific hyperparameter couplings improve stability and inference speed without retraining. Meanwhile, experimental results also reveal a new design space of the latent diffusion ODE solver. Additionally, we also analyze the difference between the original diffusion model and the diffusion distillation model via an information-theoretic study, which shows the reason why the few-step ODE solver designed for the diffusion model can outperform the training-based diffusion distillation algorithm in few-step inference. The tentative results of the experiment prove the mathematical analysis. code base is below: this https URL

Paper number 188:
Title: Towards Ethical AI in Power Electronics: How Engineering Practice and Roles Must Adapt
Authors: Fanfan Lin, Peter Wilson, Xinze Li, Alan Mantooth
Abstract: Artificial intelligence (AI) is rapidly transforming power electronics, with AI-related publications in IEEE Power Electronics Society selected journals increasing more than fourfold from 2020 to 2025. However, the ethical dimensions of this transformation have received limited attention. This article underscores the urgent need for an ethical framework to guide responsible AI integration in power electronics, not only to prevent AI-related incidents but also to comply with legal and regulatory responsibilities. In this context, this article identifies four core pillars of AI ethics in power electronics: Security & Safety, Explainability & Transparency, Energy Sustainability, and Evolving Roles of Engineers. Each pillar is supported by practical and actionable insights to ensure that ethical principles are embedded in algorithm design, system deployment, and the preparation of an AI-ready engineering workforce. The authors advocate for power electronics engineers to lead the ethical discourse, given their deep technical understanding of both AI systems and power conversion technologies. The paper concludes by calling on the IEEE Power Electronics Society to spearhead the establishment of ethical standards, talent development initiatives, and best practices that ensure AI innovations are not only technically advanced but also oriented toward human and societal benefit.

Paper number 189:
Title: Adaptive Legged Locomotion via Online Learning for Model Predictive Control
Authors: Hongyu Zhou, Xiaoyu Zhang, Vasileios Tzoumas
Abstract: We provide an algorithm for adaptive legged locomotion via online learning and model predictive control. The algorithm is composed of two interacting modules: model predictive control (MPC) and online learning of residual dynamics. The residual dynamics can represent modeling errors and external disturbances. We are motivated by the future of autonomy where quadrupeds will autonomously perform complex tasks despite real-world unknown uncertainty, such as unknown payload and uneven terrains. The algorithm uses random Fourier features to approximate the residual dynamics in reproducing kernel Hilbert spaces. Then, it employs MPC based on the current learned model of the residual dynamics. The model is updated online in a self-supervised manner using least squares based on the data collected while controlling the quadruped. The algorithm enjoys sublinear \textit{dynamic regret}, defined as the suboptimality against an optimal clairvoyant controller that knows how the residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations, where the quadruped aims to track reference trajectories. The Gazebo simulations include constant unknown external forces up to $12\boldsymbol{g}$, where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain with $20\degree$ inclination, and rough terrain with $0.25m$ height variation. The MuJoCo simulations include time-varying unknown disturbances with payload up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

Paper number 190:
Title: Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation
Authors: Dawei Dai, Yinxiu Zhou, Chenghang Li, Guolai Jiang, Chengfang Zhang
Abstract: In facial image generation, current text-to-image models often suffer from facial attribute leakage and insufficient physical consistency when responding to local semantic instructions. In this study, we propose Face-MakeUpV2, a facial image generation model that aims to maintain the consistency of face ID and physical characteristics with the reference image. First, we constructed a large-scale dataset FaceCaptionMask-1M comprising approximately one million image-text-masks pairs that provide precise spatial supervision for the local semantic instructions. Second, we employed a general text-to-image pretrained model as the backbone and introduced two complementary facial information injection channels: a 3D facial rendering channel to incorporate the physical characteristics of the image and a global facial feature channel. Third, we formulated two optimization objectives for the supervised learning of our model: semantic alignment in the model's embedding space to mitigate the attribute leakage problem and perceptual loss on facial images to preserve ID consistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves best overall performance in terms of preserving face ID and maintaining physical consistency of the reference images. These results highlight the practical potential of Face-MakeUpV2 for reliable and controllable facial editing in diverse applications.

Paper number 191:
Title: SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning
Authors: Tzu-Yuan Huang, Armin Lederer, Dai-Jie Wu, Xiaobing Dai, Sihua Zhang, Stefan Sosnowski, Shao-Hua Sun, Sandra Hirche
Abstract: Flow matching (FM) has shown promising results in data-driven planning. However, it inherently lacks formal guarantees for ensuring state and action constraints, whose satisfaction is a fundamental and crucial requirement for the safety and admissibility of planned trajectories on various systems. Moreover, existing FM planners do not ensure the dynamical consistency, which potentially renders trajectories inexecutable. We address these shortcomings by proposing SAD-Flower, a novel framework for generating Safe, Admissible, and Dynamically consistent trajectories. Our approach relies on an augmentation of the flow with a virtual control input. Thereby, principled guidance can be derived using techniques from nonlinear control theory, providing formal guarantees for state constraints, action constraints, and dynamic consistency. Crucially, SAD-Flower operates without retraining, enabling test-time satisfaction of unseen constraints. Through extensive experiments across several tasks, we demonstrate that SAD-Flower outperforms various generative-model-based baselines in ensuring constraint satisfaction.

Paper number 192:
Title: PANDA -- Patch And Distribution-Aware Augmentation for Long-Tailed Exemplar-Free Continual Learning
Authors: Siddeshwar Raghavan, Jiangpeng He, Fengqing Zhu
Abstract: Exemplar-Free Continual Learning (EFCL) restricts the storage of previous task data and is highly susceptible to catastrophic forgetting. While pre-trained models (PTMs) are increasingly leveraged for EFCL, existing methods often overlook the inherent imbalance of real-world data distributions. We discovered that real-world data streams commonly exhibit dual-level imbalances, dataset-level distributions combined with extreme or reversed skews within individual tasks, creating both intra-task and inter-task disparities that hinder effective learning and generalization. To address these challenges, we propose PANDA, a Patch-and-Distribution-Aware Augmentation framework that integrates seamlessly with existing PTM-based EFCL methods. PANDA amplifies low-frequency classes by using a CLIP encoder to identify representative regions and transplanting those into frequent-class samples within each task. Furthermore, PANDA incorporates an adaptive balancing strategy that leverages prior task distributions to smooth inter-task imbalances, reducing the overall gap between average samples across tasks and enabling fairer learning with frozen PTMs. Extensive experiments and ablation studies demonstrate PANDA's capability to work with existing PTM-based CL methods, improving accuracy and reducing catastrophic forgetting.

Paper number 193:
Title: SCI: A Metacognitive Control for Signal Dynamics
Authors: Vishal Joshua Meesala
Abstract: Modern deep learning systems are typically deployed as open-loop function approximators: they map inputs to outputs in a single pass, without regulating how much computation or explanatory effort is spent on a given case. In safety-critical settings, this is brittle: easy and ambiguous inputs receive identical processing, and uncertainty is only read off retrospectively from raw probabilities. We introduce the Surgical Cognitive Interpreter (SCI), a lightweight closed-loop metacognitive control layer that wraps an existing stochastic model and turns prediction into an iterative process. SCI monitors a scalar interpretive state SP(t), here instantiated as a normalized entropy-based confidence signal, and adaptively decides whether to stop, continue sampling, or abstain. The goal is not to improve accuracy per se, but to regulate interpretive error {\Delta}SP and expose a safety signal that tracks when the underlying model is likely to fail. We instantiate SCI around Monte Carlo dropout classifiers in three domains: vision (MNIST digits), medical time series (MIT-BIH arrhythmia), and industrial condition monitoring (rolling-element bearings). In all cases, the controller allocates more inference steps to misclassified inputs than to correct ones (up to about 3-4x on MNIST and bearings, and 1.4x on MIT-BIH). The resulting {\Delta}SP acts as a usable safety signal for detecting misclassifications (AUROC 0.63 on MNIST, 0.70 on MIT-BIH, 0.86 on bearings). Code and reproducibility: this https URL

Paper number 194:
Title: APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs
Authors: Nuno Soares, António Grilo
Abstract: The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.
    