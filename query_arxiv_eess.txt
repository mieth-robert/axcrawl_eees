
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Quantum Deception: Honey-X Deception using Quantum Games
Authors: Efstratios Reppas, Ali Wadi, Brendan Gould, Kyriakos G. Vamvoudakis
Abstract: In this paper, we develop a framework for deception in quantum games, extending the Honey-X paradigm from classical zero-sum settings into the quantum domain. Building on a view of deception in classical games as manipulation of a player's perception of the payoff matrix, we formalize quantum deception as controlled perturbations of the payoff Hamiltonian subject to a deception budget. We show that when victims are aware of possible deception, their equilibrium strategies surprisingly coincide with those of naive victims who fully trust the deceptive Hamiltonian. This equivalence allows us to cast quantum deception as a bilevel optimization problem, which can be reformulated into a bilinear semidefinite program. To illustrate the framework, we present simulations on quantum versions of the Penny Flip game, demonstrating how quantum strategy spaces and non-classical payoffs can amplify the impact of deception relative to classical formulations.

Paper number 2:
Title: A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission
Authors: Zelin Gan, Henrique Buglia, Romulo Aparecido, Mindaugas Jarmoloviƒçius, Eric Sillekens, Jiaqian Yang, Ronit Sohanpal, Robert I. Killey, Polina Bayvel
Abstract: We present a novel closed-form model for nonlinear interference (NLI) estimation in low-dispersion O-band transmission systems. The formulation incorporates the four-wave mixing (FWM) efficiency term as well as the coherent contributions of self- and cross-phase modulation (SPM/XPM) across multiple identical spans. This extension enables accurate evaluation of the NLI in scenarios where conventional closed-form Gaussian Noise (GN) models are limited. The proposed model is validated against split-step Fourier method (SSFM) simulations and numerical integration across 41-161 channels, with a 96 GBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances from 80 to 800 km. Results show a mean absolute error of the NLI signal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model offers an efficient and accurate tool for system optimisation in O-band coherent transmission.

Paper number 3:
Title: Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems
Authors: Haoran He
Abstract: This paper proposes a machine learning-assisted channel estimation approach for massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE methods. In 5G and beyond, accurate channel estimation mitigates pilot contamination and high mobility issues that harm system reliability. The proposed DNN architecture includes multi-layer perceptrons with ReLU activation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam optimizer (learning rate 1e-4) and MSE loss function. It learns from pilot signals to predict channel matrices, achieving lower NMSE and BER across different SNR levels. Simulations use the COST 2100 public standard dataset (a well-recognized MIMO channel dataset for 5G, not synthetic datasets) with 10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show the DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust performance in high-mobility scenarios. The study evaluates metrics like NMSE vs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations, and computational complexity. The DNN has 2.3 GFlOPs computational complexity, 15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying deployment feasibility. This work advances ML integration in wireless communications, facilitating efficient resource allocation and improved spectral efficiency in next-generation networks. Future work may use more real-world datasets and hybrid architectures for better generalization.

Paper number 4:
Title: Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation
Authors: Yanan Du, Zeyang Sun, Yilan Zhang, Sai Xu, Beiyuan Liu
Abstract: This paper proposes a secure indoor communication scheme based on simultaneous transmitting and reflecting intelligent reflecting surface (STAR-IRS). Specifically, a transmitter (Alice) sends confidential information to its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk outside. To safeguard the transmission from eavesdropping, the STAR-IRS is deployed on walls or windows. Upon impinging on the STAR-IRS, the incoming electromagnetic wave is dynamically partitioned into two components, enabling both transmission through and reflection from the surface. The reflected signal is controlled to enhance reception at Bob, while the transmitted signal is modulated with symbol-level random phase shifts to degrade the signal quality at Eves. Based on such a setting, the secrecy rate maximization problem is formulated. To solve it, a graph neural network (GNN)-based scheme is developed. Furthermore, a field-programmable gate array (FPGA)-based GNN accelerator is designed to reduce computational latency. Simulation results demonstrate that the proposed strategy outperforms both the conventional scheme and the reflection-only scheme in terms of secrecy performance. Moreover, the GNN-based approach achieves superior results compared to benchmark techniques such as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean square error (MMSE) in solving the optimization problem. Finally, experimental evaluations confirm that the FPGA-based accelerator enables low inference latency.

Paper number 5:
Title: Normalization-equivariant Diffusion Models: Learning Posterior Samplers From Noisy And Partial Measurements
Authors: Brett Levac, Jon Tamir, Marcelo Pereyra, Julian Tachella
Abstract: Diffusion models (DMs) have rapidly emerged as a powerful framework for image generation and restoration. However, existing DMs are primarily trained in a supervised manner by using a large corpus of clean images. This reliance on clean data poses fundamental challenges in many real-world scenarios, where acquiring noise-free data is hard or infeasible, and only noisy and potentially incomplete measurements are available. While some methods can train DMs using noisy data, they are generally effective only when the amount of noise is very mild or when some additional noise-free data is available. In addition, existing methods for training DMs from incomplete measurements require access to multiple complementary acquisition processes, an assumption that poses a significant practical limitation. Here we introduce the first approach for learning DMs for image restoration using only noisy measurement data from a single operator. As a first key contribution, we show that DMs, and more broadly minimum mean squared error denoisers, exhibit a weak form of scale equivariance linking rescaling in signal amplitude to changes in noise intensity. We then leverage this theoretical insight to develop a denoising score-matching strategy that generalizes robustly to noise levels lower than those present in the training data, thereby enabling the learning of DMs from noisy measurements. To further address the challenges of incomplete and noisy data, we integrate our method with equivariant imaging, a complementary self-supervised learning framework that exploits the inherent invariants of imaging problems, to train DMs for image restoration from single-operator measurements that are both incomplete and noisy. We validate the effectiveness of our approach through extensive experiments on image denoising, demosaicing, and inpainting, along with comparisons with the state of the art.

Paper number 6:
Title: 62.6 GHz ScAlN Solidly Mounted Acoustic Resonators
Authors: Yinan Wang, Byeongjin Kim, Nishanth Ravi, Kapil Saha, Supratik Dasgupta, Vakhtang Chulukhadze, Eugene Kwon, Lezli Matto, Pietro Simeoni, Omar Barrera, Ian Anderson, Tzu-Hsuan Hsu, Jue Hou, Matteo Rinaldi, Mark S. Goorsky, Ruochen Lu
Abstract: We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator (SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N) piezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode, positioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2 nm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and piezoelectric stack above are designed to confine a third-order thickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently transducing with thickness-field excitation. The fabricated SMR exhibits an extracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode quality factor (Q) of 51 at 63 GHz, representing the highest operating frequency reported for an SMR to date. These results establish a pathway toward mmWave SMR devices for filters and resonators in next-generation RF front ends.

Paper number 7:
Title: FakeMark: Deepfake Speech Attribution With Watermarked Artifacts
Authors: Wanying Ge, Xin Wang, Junichi Yamagishi
Abstract: Deepfake speech attribution remains challenging for existing solutions. Classifier-based solutions often fail to generalize to domain-shifted samples, and watermarking-based solutions are easily compromised by distortions like codec compression or malicious removal attacks. To address these issues, we propose FakeMark, a novel watermarking framework that injects artifact-correlated watermarks associated with deepfake systems rather than pre-assigned bitstring messages. This design allows a detector to attribute the source system by leveraging both injected watermark and intrinsic deepfake artifacts, remaining effective even if one of these cues is elusive or removed. Experimental results show that FakeMark improves generalization to cross-dataset samples where classifier-based solutions struggle and maintains high accuracy under various distortions where conventional watermarking-based solutions fail.

Paper number 8:
Title: A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation
Authors: Abdullahi Mohammad, Bdah Eya, Bassant Selim
Abstract: Impulsive noise poses a significant challenge to the reliability of wireless communication systems, necessitating accurate estimation of its statistical parameters for effective mitigation. This paper introduces a multitask learning (MTL) framework based on a CNN-LSTM architecture enhanced with an attention mechanism for the joint estimation of impulsive noise parameters. The proposed model leverages a unified weighted-loss function to enable simultaneous learning of multiple parameters within a shared representation space, improving learning efficiency and generalization across related tasks. Experimental results show that the proposed MTL framework achieves stable convergence, faster training, and enhanced scalability with modest computational overhead. Benchmarking against conventional single-task learning (STL) models confirms its favorable complexity-performance trade-off and significant memory savings, indicating the effectiveness of the MTL approach for real-time impulsive noise parameter estimation in wireless systems.

Paper number 9:
Title: Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering
Authors: Zhen Du, Jingjing Xu, Yifeng Xiong, Jie Wang, Musa Furkan Keskin, Henk Wymeersch, Fan Liu, Shi Jin
Abstract: Integrated sensing and communications (ISAC) is considered an innovative technology in sixth-generation (6G) wireless networks, where utilizing orthogonal frequency division multiplexing (OFDM) communication signals for sensing provides a cost-effective solution for implementing ISAC. However, the sensing performance of matched and mismatched filtering schemes can be significantly deteriorated due to the signaling randomness induced by finite-alphabet modulations with nonconstant modulus, such as quadrature amplitude modulation (QAM) constellations. Therefore, improving sensing performance without significantly compromising communication capability (i.e., maintaining randomness), remains a challenging task. To that end, we propose a unified probabilistic constellation shaping (PCS) framework that is compatible with both matched and mismatched filtering schemes, by maximizing the communication rate while imposing constraints on mean square error (MSE) of sensing channel state information (CSI), power, and probability distribution. Specifically, the MSE of sensing CSI is leveraged to optimize sensing capability, which is illustrated to be a more comprehensive metric compared to the output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR). Additionally, the internal relationships among these three sensing metrics are explicitly analyzed. Finally, both simulations and field measurements validate the efficiency of proposed PCS approach in achieving a flexible S&C trade-off, as well as its credibility in enhancing 6G wireless transmission in real-world scenarios.

Paper number 10:
Title: Sleepy Chauffeur Detection and Alert Techniques for Road Safety
Authors: Himel Ghosh, Sayak Chatterjee, Antik Ganguly, Shreetama Karmakar, Koushik Sarkar
Abstract: The most startling of the contemporary problems is the sleepiness of chauffeur which causes lots of car accidents. Prevention of those impending accidents by detecting and alerting the sleepy chauffeur is vital, otherwise that would lead to loss of lives and various traumas along with severe injuries. The slumber or sleep may be caused by huge stress, pressure, relentless work load or alcoholism, for which sleep deprivation occurs and the chauffeur while driving gets drowsy. So far, considerable amount of systems has been developed to detect drowsiness of drivers, most of which mainly depend on image processing algorithms using cameras. Some of them also incorporate artificial intelligence and machine learning based algorithms. This paper presents a review of the existing systems and also proposes an easy and cheap system using sensors and Arduino, capable of detecting sleepiness and generates siren alarm and send alert message to take precautionary measures.

Paper number 11:
Title: DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation
Authors: Yakun Song, Xiaobin Zhuang, Jiawei Chen, Zhikang Niu, Guanrou Yang, Chenpeng Du, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen
Abstract: Recent attempts to interleave autoregressive (AR) sketchers with diffusion-based refiners over continuous speech representations have shown promise, but they remain brittle under distribution shift and offer limited levers for controllability. We introduce DISTAR, a zero-shot text-to-speech framework that operates entirely in a discrete residual vector quantization (RVQ) code space and tightly couples an AR language model with a masked diffusion model, without forced alignment or a duration predictor. Concretely, DISTAR drafts block-level RVQ tokens with an AR language model and then performs parallel masked-diffusion infilling conditioned on the draft to complete the next block, yielding long-form synthesis with blockwise parallelism while mitigating classic AR exposure bias. The discrete code space affords explicit control at inference: DISTAR produces high-quality audio under both greedy and sample-based decoding using classifier-free guidance, supports trade-offs between robustness and diversity, and enables variable bit-rate and controllable computation via RVQ layer pruning at test time. Extensive experiments and ablations demonstrate that DISTAR surpasses state-of-the-art zero-shot TTS systems in robustness, naturalness, and speaker/style consistency, while maintaining rich output diversity. Audio samples are provided on this https URL.

Paper number 12:
Title: Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models
Authors: Benedikt B√∂ck, Amar Kasibovic, Wolfgang Utschick
Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models are frequently used to evaluate machine learning (ML)-based physical-layer methods. However, in this work, we argue that a link-level perspective incorporates limiting assumptions, causing unwanted distributional shifts or necessitating impractical online training. An additional drawback is that this perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based models, trained on link-level channel data, do not outperform classical approaches for a variety of physical-layer applications. Particularly, we demonstrate the optimality of simple linear methods for channel compression, estimation, and modeling, revealing the unsuitability of link-level channel models for evaluating ML models. On the upside, adopting a scenario-level perspective offers a solution to this problem and unlocks the relative gains enabled by ML.

Paper number 13:
Title: A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS
Authors: Piyush Priyanshu, Sudhan Majhi, Subhabrata Paul
Abstract: A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\pm 1$, such that $HH^\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A circulant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in cyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and here, we provide a novel construction of all such $8$ circulant Hadamard matrices using a linear operator and generalized Boolean function (GBF). The constructed circulant Hadamard matrices are used recursively to construct a binary cross Z-complementary set (CZCS) of all lengths with an even phase, a binary Golay complementary set (GCS) of all lengths, and Hadamard matrices of order $2^{n+2}$, where $n\geq1$. The construction of a binary CZCS covering all lengths was not available before. We also propose an alternative, lower-complexity construction of binary GCSs of all lengths and Hadamard matrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c \geq 0$. The proposed binary GCS covers all lengths with a flexible flock size. The constructions of GCS are further extended to form binary complete complementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where $N=2^a10^b26^c, a,b,c \geq 0$. The constructed binary CCC provides a flexible flock size. The construction of CZCS is further extended to form a binary optimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2}, 2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\geq1$. Finally, we provide a relation between Hadamard matrices and GCS, which enables the study of the Hadamard conjecture in a new direction. We also provided a few properties of circulant matrices over aperiodic cross-correlation (ACCF) and aperiodic auto-correlation (AACF), which are used to prove the theorems. All proposed constructions are novel, and their parameters are compared with the existing state-of-the-art.

Paper number 14:
Title: Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints
Authors: P√•l Forr Austnes, Matthieu Jacobs, Lu Wang, Mario Paolone
Abstract: Since the 1990s, widespread introduction of central (wholesale) electricity markets has been seen across multiple continents, driven by the search for efficient operation of the power grid through competition. The increase of renewables has made significant impacts both on central electricity markets and distribution-level grids as renewable power generation is often connected to the latter. These stochastic renewable technologies have both advantages and disadvantages. On one hand they offer very low marginal cost and carbon emissions, while on the other hand, their output is uncertain, requiring flexible backup power with high marginal cost. Flexibility from end-prosumers or smaller market participants is therefore seen as a key enabler of large-scale integration of renewables. However, current central electricity markets do not directly include uncertainty into the market clearing and do not account for physical constraints of distribution grids. In this paper we propose a local electricity market framework based on probabilistic locational marginal pricing, effectively accounting for uncertainties in production, consumption and grid variables. The model includes a representation of the grid using the lindistflow equations and accounts for the propagation of uncertainty using general Polynomial Chaos (gPC). A two-stage convex model is proposed; in the day-ahead stage, probability distributions of prices are calculated for every timestep, where the expected values represent the day-ahead (spot) prices. In the real-time stage, uncertainties are realized (measured) and a trivial calculation reveals the real-time price. Through four instructive case-studies we highlight the effectiveness of the method to incentivize end-prosumers' participation in the market, while ensuring that their behavior does not have an adverse impact on the operation of the grid.

Paper number 15:
Title: DeePAQ: A Perceptual Audio Quality Metric Based On Foundational Models and Weakly Supervised Learning
Authors: Guanxin Jiang, Andreas Brendel, Pablo M. Delgado, J√ºrgen Herre
Abstract: This paper presents the Deep learning-based Perceptual Audio Quality metric (DeePAQ) for evaluating general audio quality. Our approach leverages metric learning together with the music foundation model MERT, guided by surrogate labels, to construct an embedding space that captures distortion intensity in general audio. To the best of our knowledge, DeePAQ is the first in the general audio quality domain to leverage weakly supervised labels and metric learning for fine-tuning a music foundation model with Low-Rank Adaptation (LoRA), a direction not yet explored by other state-of-the-art methods. We benchmark the proposed model against state-of-the-art objective audio quality metrics across listening tests spanning audio coding and source separation. Results show that our method surpasses existing metrics in detecting coding artifacts and generalizes well to unseen distortions such as source separation, highlighting its robustness and versatility.

Paper number 16:
Title: Physics-Informed Reinforcement Learning for Large-Scale EV Smart Charging Considering Distribution Network Voltage Constraints
Authors: Stavros Orfanoudakis, Frans Oliehoek, Peter Palesnky, Pedro P. Vergara
Abstract: Electric Vehicles (EVs) offer substantial flexibility for grid services, yet large-scale, uncoordinated charging can threaten voltage stability in distribution networks. Existing Reinforcement Learning (RL) approaches for smart charging often disregard physical grid constraints or have limited performance for complex large-scale tasks, limiting their scalability and real-world applicability. This paper introduces a physics-informed (PI) RL algorithm that integrates a differentiable power flow model and voltage-based reward design into the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm, enabling EVs to deliver real-time voltage support while meeting user demands. The resulting PI-TD3 algorithm achieves faster convergence, improved sample efficiency, and reliable voltage magnitude regulation under uncertain and overloaded conditions. Benchmarks on the IEEE 34-bus and 123-bus networks show that the proposed PI-TD3 outperforms both model-free RL and optimization-based baselines in grid constraint management, user satisfaction, and economic metrics, even as the system scales to hundreds of EVs. These advances enable robust, scalable, and practical EV charging strategies that enhance grid resilience and support distribution networks operation.

Paper number 17:
Title: Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems
Authors: Mohamed Abdalmoaty, Verena H√§berle, Xiuqiang He, Florian D√∂rfler
Abstract: We propose a non-parametric frequency-domain method to identify small-signal $dq$-asymmetric grid impedances, over a wide frequency band, using grid-connected converters. Existing identification methods are faced with significant trade-offs: e.g., passive approaches rely on ambient harmonics and rare grid events and thus can only provide estimates at a few frequencies, while many active approaches that intentionally perturb grid operation require long time series measurement and specialized equipment. Although active time-domain methods reduce the measurement time, they either make crude simplifying assumptions or require laborious model order tuning. Our approach effectively addresses these challenges: it does not require specialized excitation signals or hardware and achieves ultrafast ($<1$ s) identification, drastically reducing measurement time. Being non-parametric, our approach also makes no assumptions on the grid structure. A detailed electromagnetic transient simulation is used to validate the method and demonstrate its clear superiority over existing alternatives.

Paper number 18:
Title: A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control
Authors: Weijie Ren, Haowen Liu, Guang-Ren Duan
Abstract: This paper proposes a unidirectionally connected fully actuated system (UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF quadrotors, tackling limitations both in state-space and FAS framework to some extent. The framework systematically converts underactuated quadrotor dynamics into a UC-FAS model, unifying the existing different FAS transformation ways. By eliminating estimation of the high-order derivatives of control inputs, a drawback of current methods, the UC-FAS model simplifies controller design and enables direct eigenstructure assignment for closed-loop dynamics. Simulations demonstrate precise 6-DOF tracking performance. This work bridges theoretical FAS approach advancements with practical implementation needs, offering a standardized paradigm for nonlinear quadrotor control.

Paper number 19:
Title: Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models
Authors: Zheyu Wu, Matteo Nerini, Bruno Clerckx
Abstract: Reconfigurable intelligent surface (RIS) is a promising technology for future wireless communication systems. Conventional RIS is constrained to a diagonal scattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS (BD-RIS) has been proposed as a more general RIS architecture class that allows inter-element connections and shows great potential for performance improvement. Despite extensive progress on BD-RIS, most existing studies rely on simplified channel models that ignore practical electromagnetic (EM) effects such as mutual coupling and impedance mismatching. To address this gap, this paper investigates the architecture design and optimization of BD-RIS under the general physics-consistent model derived with multiport network theory in recent literature. Building on a compact reformulation of this model, we show that band-connected RIS achieves the same channel-shaping capability as fully-connected RIS, which extends existing results obtained for conventional channel models. We then develop optimization methods under the general physics-consistent model; specifically, we derive closed-form solutions for single-input single-output (SISO) systems, propose a globally optimal semidefinite relaxation (SDR)-based algorithm for single-stream multi-input multi-output (MIMO) systems, and design an efficient alternating direction method of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using the proposed algorithms, we conduct comprehensive simulations to evaluate the impact of various EM effects and approximations, including mutual coupling among RIS antennas and the commonly adopted unilateral approximation, on system performance.

Paper number 20:
Title: A Phase Synthesizer for Decorrelation to Improve Acoustic Feedback Cancellation
Authors: Klaus Linhard, Philipp Bulling
Abstract: Undesired acoustic feedback is a known issue in communication systems, such as speech in-car communication, public address systems, or hearing aids. Without additional precautions, there is a high risk that the adaptive filter - intended to cancel the feedback path - also suppresses parts of the desired signal. One solution is to decorrelate the loudspeaker and microphone signals. In this work, we combine the two decorrelation approaches frequency shifting and phase modulation in a unified framework: a so-called \textit{phase synthesizer}, implemented in a discrete Fourier transform (DFT) filter bank. Furthermore, we extend the phase modulation technique using variable delay lines, as known from vibrato and chorus effects. We demonstrate the benefits of the proposed phase synthesizer using an example from speech in-car communication, employing an adaptive frequency-domain Kalman filter. Improvements in system stability, speech quality measured by perceptual evaluation of speech quality (PESQ) are presented.

Paper number 21:
Title: LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications
Authors: Vibhoothi Vibhoothi, Fran√ßois Piti√©, Anil Kokaram
Abstract: In the last decade, video workflows in the cinema production ecosystem have presented new use cases for video streaming technology. These new workflows, e.g. in On-set Virtual Production, present the challenge of requiring precise quality control and energy efficiency. Existing approaches to transcoding often fall short of these requirements, either due to a lack of quality control or computational overhead. To fill this gap, we present a lightweight neural network (LiteVPNet) for accurately predicting Quantisation Parameters for NVENC AV1 encoders that achieve a specified VMAF score. We use low-complexity features, including bitstream characteristics, video complexity measures, and CLIP-based semantic embeddings. Our results demonstrate that LiteVPNet achieves mean VMAF errors below 1.2 points across a wide range of quality targets. Notably, LiteVPNet achieves VMAF errors within 2 points for over 87% of our test corpus, c.f. approx 61% with state-of-the-art methods. LiteVPNet's performance across various quality regions highlights its applicability for enhancing high-value content transport and streaming for more energy-efficient, high-quality media experiences.

Paper number 22:
Title: An Empirical Study of Reducing AV1 Decoder Complexity and Energy Consumption via Encoder Parameter Tuning
Authors: Vibhoothi Vibhoothi, Julien Zouein, Shanker Shreejith, Jean-Baptiste Kempf, Anil Kokaram
Abstract: The widespread adoption of advanced video codecs such as AV1 is often hindered by their high decoding complexity, posing a challenge for battery-constrained devices. While encoders can be configured to produce bitstreams that are decoder-friendly, estimating the decoding complexity and energy overhead for a given video is non-trivial. In this study, we systematically analyse the impact of disabling various coding tools and adjusting coding parameters in two AV1 encoders, libaom-av1 and SVT-AV1. Using system-level energy measurement tools like RAPL (Running Average Power Limit), Intel SoC Watch (integrated with VTune profiler), we quantify the resulting trade-offs between decoding complexity, energy consumption, and compression efficiency for decoding a bitstream. Our results demonstrate that specific encoder configurations can substantially reduce decoding complexity with minimal perceptual quality degradation. For libaom-av1, disabling CDEF, an in-loop filter gives us a mean reduction in decoding cycles by 10%. For SVT-AV1, using the in-built, fast-decode=2 preset achieves a more substantial 24% reduction in decoding cycles. These findings provide strategies for content providers to lower the energy footprint of AV1 video streaming.

Paper number 23:
Title: Pooling Probabilistic Forecasts for Cooperative Wind Power Offering
Authors: Honglin Wen, Pierre Pinson
Abstract: Wind power producers can benefit from forming coalitions to participate cooperatively in electricity markets. To support such collaboration, various profit allocation rules rooted in cooperative game theory have been proposed. However, existing approaches overlook the lack of coherence among producers regarding forecast information, which may lead to ambiguity in offering and allocations. In this paper, we introduce a ``reconcile-then-optimize'' framework for cooperative market offerings. This framework first aligns the individual forecasts into a coherent joint forecast before determining market offers. With such forecasts, we formulate and solve a two-stage stochastic programming problem to derive both the aggregate offer and the corresponding scenario-based dual values for each trading hour. Based on these dual values, we construct a profit allocation rule that is budget-balanced and stable. Finally, we validate the proposed method through empirical case studies, demonstrating its practical effectiveness and theoretical soundness.

Paper number 24:
Title: High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization
Authors: Fabrizio Orlando, Deborah Volpe, Giacomo Orlandi, Mariagrazia Graziano, Fabrizio Riente, Marco Vacca
Abstract: Combinatorial Optimization (CO) problems exhibit exponential complexity, making their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a quantum-inspired algorithm to obtain approximate solutions to largescale CO problems written in the Ising form. It explores the solution space by emulating the adiabatic evolution of a network of Kerr-nonlinear parametric oscillators (KPOs), where each oscillator represents a variable in the problem. The optimal solution corresponds to the ground state of this system. A key advantage of this approach is the possibility of updating multiple variables simultaneously, making it particularly suited for hardware implementation. To enhance solution quality and convergence speed, variations of the algorithm have been proposed in the literature, including ballistic (bSB), discrete (dSB), and thermal (HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and HbSB using dedicated software models, evaluating the feasibility of using a fixed-point representation for hardware implementation. We then present an opensource hardware architecture implementing the dSB algorithm for Field-Programmable Gate Arrays (FPGAs). The design allows users to adjust the degree of algorithmic parallelization based on their specific requirements. A proof-of-concept implementation that solves 256-variable problems was achieved on an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut and knapsack problems.

Paper number 25:
Title: MH-LVC: Multi-Hypothesis Temporal Prediction for Learned Conditional Residual Video Coding
Authors: Huu-Tai Phung, Zong-Lin Gao, Yi-Chen Yao, Kuan-Wei Ho, Yi-Hsin Chen, Yu-Hsiang Lin, Alessandro Gnutti, Wen-Hsiao Peng
Abstract: This work, termed MH-LVC, presents a multi-hypothesis temporal prediction scheme that employs long- and short-term reference frames in a conditional residual video coding framework. Recent temporal context mining approaches to conditional video coding offer superior coding performance. However, the need to store and access a large amount of implicit contextual information extracted from past decoded frames in decoding a video frame poses a challenge due to excessive memory access. Our MH-LVC overcomes this issue by storing multiple long- and short-term reference frames but limiting the number of reference frames used at a time for temporal prediction to two. Our decoded frame buffer management allows the encoder to flexibly utilize the long-term key frames to mitigate temporal cascading errors and the short-term reference frames to minimize prediction errors. Moreover, our buffering scheme enables the temporal prediction structure to be adapted to individual input videos. While this flexibility is common in traditional video codecs, it has not been fully explored for learned video codecs. Extensive experiments show that the proposed method outperforms VTM-17.0 under the low-delay B configuration in terms of PSNR-RGB across commonly used test datasets, and performs comparably to the state-of-the-art learned codecs (e.g.~DCVC-FM) while requiring less decoded frame buffer and similar decoding time.

Paper number 26:
Title: I-DCCRN-VAE: An Improved Deep Representation Learning Framework for Complex VAE-based Single-channel Speech Enhancement
Authors: Jiatong Li, Simon Doclo
Abstract: Recently, a complex variational autoencoder (VAE)-based single-channel speech enhancement system based on the DCCRN architecture has been proposed. In this system, a noise suppression VAE (NSVAE) learns to extract clean speech representations from noisy speech using pretrained clean speech and noise VAEs with skip connections. In this paper, we improve DCCRN-VAE by incorporating three key modifications: 1) removing the skip connections in the pretrained VAEs to encourage more informative speech and noise latent representations; 2) using $\beta$-VAE in pretraining to better balance reconstruction and latent space regularization; and 3) a NSVAE generating both speech and noise latent representations. Experiments show that the proposed system achieves comparable performance as the DCCRN and DCCRN-VAE baselines on the matched DNS3 dataset but outperforms the baselines on mismatched datasets (WSJ0-QUT, Voicebank-DEMEND), demonstrating improved generalization ability. In addition, an ablation study shows that a similar performance can be achieved with classical fine-tuning instead of adversarial training, resulting in a simpler training pipeline.

Paper number 27:
Title: HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation
Authors: Zhige Chen, Chengxuan Qin, Wenlong You, Rui Liu, Congying Chu, Rui Yang, Kay Chen Tan, Jibin Wu
Abstract: Electroencephalography (EEG) is an essential technique for neuroscience research and brain-computer interface (BCI) applications. Recently, large-scale EEG foundation models have been developed, exhibiting robust generalization capabilities across diverse tasks and subjects. However, the heterogeneity of EEG devices not only hinders the widespread adoption of these models but also poses significant challenges to their further scaling and development. In this paper, we introduce HEAR, the first EEG foundation model explicitly designed to support heterogeneous EEG devices, accommodating varying electrode layouts and electrode counts. HEAR employs a learnable, coordinate-based spatial embedding to map electrodes with diverse layouts and varying counts into a unified representational space. This unified spatial representation is then processed by a novel spatially-guided transformer, which effectively captures spatiotemporal dependencies across electrodes. To support the development of HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data collected from over 150 distinct electrode layouts with up to 1,132 electrodes. Experimental results demonstrate that HEAR substantially outperforms existing EEG foundation models in supporting heterogeneous EEG devices and generalizing across diverse cognitive tasks and subjects.

Paper number 28:
Title: Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X
Authors: Zhanle Zhao, Son Dinh-Van, Yuen Kwan Mo, Siddartha Khastgir, Matthew D. Higgins
Abstract: Connected braking can reduce fatal collisions in connected and autonomous vehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links, especially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side units are sparse and power-constrained or off-grid, so energy efficiency must be considered alongside safety. This paper studies how three communication control factors including subcarrier spacing ($\mathrm{SCS}$), modulation and coding scheme ($\mathrm{MCS}$), and transmit power ($P_{\mathrm{t}}$) should be configured to balance safety and energy consumption in rural line-of-sight (LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by the packet receive ratio ($\mathrm{PRR}$) against the minimum communication distance $D_{\mathrm{comm}}$, defined as the distance that the vehicle travels during the transmission of the safety message. Results show that, under heavy traffic, increasing $P_{\mathrm{t}}$ and selecting a low-rate $\mathrm{MCS}$ at $\mathrm{SCS} = 30$ kHz sustains high $\mathrm{PRR}$ at $D_{\mathrm{comm}}$, albeit with higher energy cost. In light traffic, maintaining lower $P_\mathrm{t}$ with low $\mathrm{MCS}$ levels achieves a favorable reliability-energy trade-off while preserving acceptable $\mathrm{PRR}$ at $D_{\mathrm{comm}}$. These findings demonstrate the necessity of adaptive, energy-aware strategy to guarantee both safety and energy efficiency in rural V2X systems.

Paper number 29:
Title: Privacy-Preserving Distributed Estimation with Limited Data Rate
Authors: Jieming Ke, Jimin Wang, Ji-Feng Zhang
Abstract: This paper focuses on the privacy-preserving distributed estimation problem with a limited data rate, where the observations are the sensitive information. Specifically, a binary-valued quantizer-based privacy-preserving distributed estimation algorithm is developed, which improves the algorithm's privacy-preserving capability and simultaneously reduces the communication costs. The algorithm's privacy-preserving capability, measured by the Fisher information matrix, is dynamically enhanced over time. Notably, the Fisher information matrix of the output signals with respect to the sensitive information converges to zero at a polynomial rate, and the improvement in privacy brought by the quantizers is quantitatively characterized as a multiplicative effect. Regarding the communication costs, each sensor transmits only 1 bit of information to its neighbours at each time step. Additionally, the assumption on the negligible quantization error for real-valued messages is not required. While achieving the requirements of privacy preservation and reducing communication costs, the algorithm ensures that its estimates converge almost surely to the true value of the unknown parameter by establishing a co-design guideline for the time-varying privacy noises and step-sizes. A polynomial almost sure convergence rate is obtained, and then the trade-off between privacy and convergence rate is established. Numerical examples demonstrate the main results.

Paper number 30:
Title: Enhancing Robust Multi-Market Participation of Renewable-Based VPPs through Flexible Resources
Authors: Hadi Nemati, √Ålvaro Ortega, Pedro S√°nchez-Mart√≠n, Lukas Sigrist, Luis Rouco, Ignacio Egido
Abstract: In the transition toward a sustainable power system, renewable-based Virtual Power Plants (RVPPs) have emerged as a promising solution to the challenges of integrating renewable energy sources into electricity markets. Their viability, however, depends on effective market participation strategies and the ability to manage uncertainties while leveraging flexible resources. This paper analyzes the impact of different flexible resources - such as concentrated solar power plants, hydro plants, biomass plants, and flexible demand - on the participation of RVPPs in energy and reserve markets. Multiple sources of uncertainty in generation, consumption, and electricity prices are addressed using a two-stage robust optimization approach. The contribution of different technologies to RVPP profitability is evaluated through a marginal contribution method, ensuring fair allocation of profits among them according to their actual role in energy and reserve provision across markets. Simulations for an RVPP in southern Spain demonstrate how strategic decisions and the availability of flexible resources influence viability, market participation, and unit scheduling.

Paper number 31:
Title: A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks
Authors: Abdelali Arous, Hamza Haif, Arman Farhang, Huseyin Arslan
Abstract: The emergence of alternative multiplexing domains to the time-frequency domains, e.g., the delay-Doppler and chirp domains, offers a promising approach for addressing the challenges posed by complex propagation environments and next-generation applications. Unlike the time and frequency domains, these domains offer unique channel representations which provide additional degrees of freedom (DoF) for modeling, characterizing, and exploiting wireless channel features. This article provides a comprehensive analysis of channel characteristics, including delay, Doppler shifts, and channel coefficients across various domains, with an emphasis on their inter-domain relationships, shared characteristics, and domain-specific distinctions. We further evaluate the comparative advantages of each domain under specific channel conditions. Building on this analysis, we propose a generalized and adaptive transform domain framework that leverages the pre- and post-processing of the discrete Fourier transform (DFT) matrix, to enable dynamic transitions between various domains in response to the channel conditions and system requirements. Finally, several representative use cases are presented to demonstrate the applicability of the proposed cross-domain waveform processing framework in diverse scenarios, along with future directions and challenges.

Paper number 32:
Title: Moment-based Posterior Sampling for Multi-reference Alignment
Authors: Axel Janson, Joakim And√©n
Abstract: We propose a Bayesian approach to the problem of multi-reference alignment -- the recovery of signals from noisy, randomly shifted observations. While existing frequentist methods accurately recover the signal at arbitrarily low signal-to-noise ratios, they require a large number of samples to do so. In contrast, our proposed method leverages diffusion models as data-driven plug-and-play priors, conditioning these on the sample power spectrum (a shift-invariant statistic) enabling both accurate posterior sampling and uncertainty quantification. The use of an appropriate prior significantly reduces the required number of samples, as illustrated in simulation experiments with comparisons to state-of-the-art methods such as expectation--maximization and bispectrum inversion. These findings establish our approach as a promising framework for other orbit recovery problems, such as cryogenic electron microscopy (cryo-EM).

Paper number 33:
Title: Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems
Authors: Muhammad Talha, Besma Smida, David Gonz√°lez G
Abstract: This work studies an integrated sensing and communication (ISAC) framework for targets that are spread both in the angle and range domains. We model each target using a cluster of rays parameterized by a specific density function, and propose a truncated Multiple Signal Classification (MUSIC) spread (TMS) algorithm to accurately estimate the parameters of the density function. Unlike the conventional MUSIC spread (CMS), TMS restricts the signal subspace rank based on the eigen decomposition of the received-signal autocorrelation. We also propose a discrete Fourier transform (DFT) based algorithm for estimating the distance and range spread of each target. Leveraging these estimates, we then develop a dynamic transmit beamforming algorithm that successfully illuminates multiple targets while also serving multiple downlink (DL) users. Simulation results demonstrate the superiority of our proposed algorithms over baseline schemes in both low and high signal-to-noise ratio (SNR) regimes as well as under a wide angular spread regime.

Paper number 34:
Title: A High-Level Feature Model to Predict the Encoding Energy of a Hardware Video Encoder
Authors: Diwakara Reddy, Christian Herglotz, Andr√© Kaup
Abstract: In today's society, live video streaming and user generated content streamed from battery powered devices are ubiquitous. Live streaming requires real-time video encoding, and hardware video encoders are well suited for such an encoding task. In this paper, we introduce a high-level feature model using Gaussian process regression that can predict the encoding energy of a hardware video encoder. In an evaluation setup restricted to only P-frames and a single keyframe, the model can predict the encoding energy with a mean absolute percentage error of approximately 9%. Further, we demonstrate with an ablation study that spatial resolution is a key high-level feature for encoding energy prediction of a hardware encoder. A practical application of our model is that it can be used to perform a prior estimation of the energy required to encode a video at various spatial resolutions, with different coding standards and codec presets.

Paper number 35:
Title: Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective
Authors: Saurabh Sihag, Gonzalo Mateos, Alejandro Ribeiro
Abstract: Neurodegeneration, characterized by the progressive loss of neuronal structure or function, is commonly assessed in clinical practice through reductions in cortical thickness or brain volume, as visualized by structural MRI. While informative, these conventional approaches lack the statistical sophistication required to fully capture the spatially correlated and heterogeneous nature of neurodegeneration, which manifests both in healthy aging and in neurological disorders. To address these limitations, brain age gap has emerged as a promising data-driven biomarker of brain health. The brain age gap prediction (BAGP) models estimate the difference between a person's predicted brain age from neuroimaging data and their chronological age. The resulting brain age gap serves as a compact biomarker of brain health, with recent studies demonstrating its predictive utility for disease progression and severity. However, practical adoption of BAGP models is hindered by their methodological obscurities and limited generalizability across diverse clinical populations. This tutorial article provides an overview of BAGP and introduces a principled framework for this application based on recent advancements in graph signal processing (GSP). In particular, we focus on graph neural networks (GNNs) and introduce the coVariance neural network (VNN), which leverages the anatomical covariance matrices derived from structural MRI. VNNs offer strong theoretical grounding and operational interpretability, enabling robust estimation of brain age gap predictions. By integrating perspectives from GSP, machine learning, and network neuroscience, this work clarifies the path forward for reliable and interpretable BAGP models and outlines future research directions in personalized medicine.

Paper number 36:
Title: Serial-Parallel Dual-Path Architecture for Speaking Style Recognition
Authors: Guojian Li, Qijie Shao, Zhixian Zhao, Shuiyuan Wang, Zhonghua Fu, Lei Xie
Abstract: Speaking Style Recognition (SSR) identifies a speaker's speaking style characteristics from speech. Existing style recognition approaches primarily rely on linguistic information, with limited integration of acoustic information, which restricts recognition accuracy improvements. The fusion of acoustic and linguistic modalities offers significant potential to enhance recognition performance. In this paper, we propose a novel serial-parallel dual-path architecture for SSR that leverages acoustic-linguistic bimodal information. The serial path follows the ASR+STYLE serial paradigm, reflecting a sequential temporal dependency, while the parallel path integrates our designed Acoustic-Linguistic Similarity Module (ALSM) to facilitate cross-modal interaction with temporal simultaneity. Compared to the existing SSR baseline -- the OSUM model, our approach reduces parameter size by 88.4% and achieves a 30.3% improvement in SSR accuracy for eight styles on the test set.

Paper number 37:
Title: Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair
Authors: Akshay Naik, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu
Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible paths while accounting for spatially varying soil strength and slope hazards in real time. We present a continuous state--cost metric that combines a Bekker pressure--sinkage model with elevation-derived slope and attitude penalties. The resulting terrain cost field is analytic, bounded, and monotonic in soil modulus and slope, ensuring well-posed discretization and stable updates under sensor noise. This metric is evaluated on a lattice with exact steering primitives: Dubins and Reeds--Shepp motions for differential drive and time-parameterized bicycle arcs for Ackermann steering. Global exploration is performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without heuristic smoothing. By separating the terrain--vehicle model from the planner, the framework provides a reusable basis for deterministic, sampling-based, or learning-driven planning in deformable terrain. Hardware trials on an off-road platform demonstrate real-time navigation across soft soil and slope transitions, supporting reliable autonomy in unstructured environments.

Paper number 38:
Title: Audio Palette: A Diffusion Transformer with Multi-Signal Conditioning for Controllable Foley Synthesis
Authors: Junnuo Wang
Abstract: Recent advances in diffusion-based generative models have enabled high-quality text-to-audio synthesis, but fine-grained acoustic control remains a significant challenge in open-source research. We present Audio Palette, a diffusion transformer (DiT) based model that extends the Stable Audio Open architecture to address this "control gap" in controllable audio generation. Unlike prior approaches that rely solely on semantic conditioning, Audio Palette introduces four time-varying control signals: loudness, pitch, spectral centroid, and timbre, for precise and interpretable manipulation of acoustic features. The model is efficiently adapted for the nuanced domain of Foley synthesis using Low-Rank Adaptation (LoRA) on a curated subset of AudioSet, requiring only 0.85 percent of the original parameters to be trained. Experiments demonstrate that Audio Palette achieves fine-grained, interpretable control of sound attributes. Crucially, it accomplishes this novel controllability while maintaining high audio quality and strong semantic alignment to text prompts, with performance on standard metrics such as Frechet Audio Distance (FAD) and LAION-CLAP scores remaining comparable to the original baseline model. We provide a scalable, modular pipeline for audio research, emphasizing sequence-based conditioning, memory efficiency, and a three-scale classifier-free guidance mechanism for nuanced inference-time control. This work establishes a robust foundation for controllable sound design and performative audio synthesis in open-source settings, enabling a more artist-centric workflow.

Paper number 39:
Title: Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection
Authors: Yuehui Li, Yahao Lu, Haoyuan Wu, Sen Zhang, Liang Lin, Yukai Shi
Abstract: In the multimedia domain, Infrared Small Target Detection (ISTD) plays a important role in drone-based multi-modality sensing. To address the dual challenges of cross-domain shift and heteroscedastic noise perturbations in ISTD, we propose a doubly wavelet-guided Invariance learning framework(Ivan-ISTD). In the first stage, we generate training samples aligned with the target domain using Wavelet-guided Cross-domain Synthesis. This wavelet-guided alignment machine accurately separates the target background through multi-frequency wavelet filtering. In the second stage, we introduce Real-domain Noise Invariance Learning, which extracts real noise characteristics from the target domain to build a dynamic noise library. The model learns noise invariance through self-supervised loss, thereby overcoming the limitations of distribution bias in traditional artificial noise modeling. Finally, we create the Dynamic-ISTD Benchmark, a cross-domain dynamic degradation dataset that simulates the distribution shifts encountered in real-world applications. Additionally, we validate the versatility of our method using other real-world datasets. Experimental results demonstrate that our approach outperforms existing state-of-the-art methods in terms of many quantitative metrics. In particular, Ivan-ISTD demonstrates excellent robustness in cross-domain scenarios. The code for this work can be found at: this https URL.

Paper number 40:
Title: AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion
Authors: Xiaopeng Liu, Yupei Lin, Sen Zhang, Xiao Wang, Yukai Shi, Liang Lin
Abstract: Visible-infrared image fusion is crucial in key applications such as autonomous driving and nighttime surveillance. Its main goal is to integrate multimodal information to produce enhanced images that are better suited for downstream tasks. Although deep learning based fusion methods have made significant progress, mainstream unsupervised approaches still face serious challenges in practical applications. Existing methods mostly rely on manually designed loss functions to guide the fusion process. However, these loss functions have obvious limitations. On one hand, the reference images constructed by existing methods often lack details and have uneven brightness. On the other hand, the widely used gradient losses focus only on gradient magnitude. To address these challenges, this paper proposes an angle-based perception framework for spatial-sensitive image fusion (AngularFuse). At first, we design a cross-modal complementary mask module to force the network to learn complementary information between modalities. Then, a fine-grained reference image synthesis strategy is introduced. By combining Laplacian edge enhancement with adaptive histogram equalization, reference images with richer details and more balanced brightness are generated. Last but not least, we introduce an angle-aware loss, which for the first time constrains both gradient magnitude and direction simultaneously in the gradient domain. AngularFuse ensures that the fused images preserve both texture intensity and correct edge orientation. Comprehensive experiments on the MSRS, RoadScene, and M3FD public datasets show that AngularFuse outperforms existing mainstream methods with clear margin. Visual comparisons further confirm that our method produces sharper and more detailed results in challenging scenes, demonstrating superior fusion capability.

Paper number 41:
Title: Human-in-the-Loop Bandwidth Estimation for Quality of Experience Optimization in Real-Time Video Communication
Authors: Sami Khairy, Gabriel Mittag, Vishak Gopal, Ross Cutler
Abstract: The quality of experience (QoE) delivered by video conferencing systems is significantly influenced by accurately estimating the time-varying available bandwidth between the sender and receiver. Bandwidth estimation for real-time communications remains an open challenge due to rapidly evolving network architectures, increasingly complex protocol stacks, and the difficulty of defining QoE metrics that reliably improve user experience. In this work, we propose a deployed, human-in-the-loop, data-driven framework for bandwidth estimation to address these challenges. Our approach begins with training objective QoE reward models derived from subjective user evaluations to measure audio and video quality in real-time video conferencing systems. Subsequently, we collect roughly $1$M network traces with objective QoE rewards from real-world Microsoft Teams calls to curate a bandwidth estimation training dataset. We then introduce a novel distributional offline reinforcement learning (RL) algorithm to train a neural-network-based bandwidth estimator aimed at improving QoE for users. Our real-world A/B test demonstrates that the proposed approach reduces the subjective poor call ratio by $11.41\%$ compared to the baseline bandwidth estimator. Furthermore, the proposed offline RL algorithm is benchmarked on D4RL tasks to demonstrate its generalization beyond bandwidth estimation.

Paper number 42:
Title: Targeted Pooled Latent-Space Steganalysis Applied to Generative Steganography, with a Fix
Authors: Etienne Levecque (LIST3N), Aur√©lien Noirault (CRIStAL), Tom√°≈° Pevn√Ω (CTU), Jan Butora (CRIStAL), Patrick Bas (CRIStAL), R√©mi Cogranne (LIST3N)
Abstract: Steganographic schemes dedicated to generated images modify the seed vector in the latent space to embed a message, whereas most steganalysis methods attempt to detect the embedding in the image space. This paper proposes to perform steganalysis in the latent space by modeling the statistical distribution of the norm of the latent vector. Specifically, we analyze the practical security of a scheme proposed by Hu et. al. for latent diffusion models, which is both robust and practically undetectable when steganalysis is performed on generated images. We show that after embedding, the Stego (latent) vector is distributed on a hypersphere while the Cover vector is i.i.d. Gaussian. By going from the image space to the latent space, we show that it is possible to model the norm of the vector in the latent space under the Cover or Stego hypothesis as Gaussian distributions with different variances. A Likelihood Ratio Test is then derived to perform pooled steganalysis. The impact of the potential knowledge of the prompt and the number of diffusion steps, is also studied. Additionally, we also show how, by randomly sampling the norm of the latent vector before generation, the initial Stego scheme becomes undetectable in the latent space.

Paper number 43:
Title: The value of storage in electricity distribution: The role of storage
Authors: Dirk Lauinger, Deepjyoti Deka, Sungho Shin
Abstract: Electricity distribution companies deploy battery storage to defer grid upgrades by reducing peak demand. In deregulated jurisdictions, such storage often sits idle because regulatory constraints bar participation in electricity markets. Here, we develop an optimization framework that, to our knowledge, provides the first formal model of market participation constraints within storage investment and operation planning. Applying the framework to a Massachusetts case study, we find that market participation could deliver similar savings as peak demand reduction. Under current conditions, market participation does not increase storage investment, but at very low storage costs, could incentivize deployment beyond local distribution needs. This might run contrary to the separation of distribution from generation in deregulated markets. Our framework can identify investment levels appropriate for local distribution needs.

Paper number 44:
Title: Micro-Macro Backstepping Control of Large-Scale Hyperbolic Systems (Extended Version)
Authors: Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis
Abstract: We introduce a control design and analysis framework for micro-macro, boundary control of large-scale, $n+m$ hyperbolic PDE systems. Specifically, we develop feedback laws for stabilization of hyperbolic systems at the micro level (i.e., of the large-scale system) that employ a) measurements obtained from the $n+m$ system (i.e., at micro level) and kernels constructed based on an $\infty+\infty$ continuum system counterpart (i.e., at macro level), or b) kernels and measurements both stemming from a continuum counterpart, or c) averaged-continuum kernels/measurements. We also address (d)) stabilization of the continuum (macro) system, employing continuum kernels and measurements. Towards addressing d) we derive in a constructive manner an $\infty+\infty$ continuum approximation of $n+m$ hyperbolic systems and establish that its solutions approximate, for large $n$ and $m$, the solutions of the $n+m$ system. We then construct a feedback law for stabilization of the $\infty+\infty$ system via introduction of a continuum-PDE backstepping transformation. We establish well-posedness of the resulting 4-D kernel equations and prove closed-loop stability via construction of a novel Lyapunov functional. Furthermore, under control configuration a) we establish that the closed-loop system is exponentially stable provided that $n$ and $m$ are large, by proving that the exact, stabilizing $n+m$ control kernels can be accurately approximated by the continuum kernels. While under control configurations b) and c), we establish closed-loop stability capitalizing on the established solutions' and kernels' approximation properties via employment of infinite-dimensional ISS arguments. We provide two numerical simulation examples to illustrate the effectiveness and potential limitations of our design approach.

Paper number 45:
Title: DarTwin made precise by SysMLv2 -- An Experiment
Authors: √òystein Haugen, Stefan Klikovits, Martin Arthur Andersen, Jonathan Beaulieu, Francis Bordeleau, Joachim Denil, Joost Mertens
Abstract: The new SysMLv2 adds mechanisms for the built-in specification of domain-specific concepts and language extensions. This feature promises to facilitate the creation of Domain-Specific Languages (DSLs) and interfacing with existing system descriptions and technical designs. In this paper, we review these features and evaluate SysMLv2's capabilities using concrete use cases. We develop DarTwin DSL, a DSL that formalizes the existing DarTwin notation for Digital Twin (DT) evolution, through SysMLv2, thereby supposedly enabling the wide application of DarTwin's evolution templates using any SysMLv2 tool. We demonstrate DarTwin DSL, but also point out limitations in the currently available tooling of SysMLv2 in terms of graphical notation capabilities. This work contributes to the growing field of Model-Driven Engineering (MDE) for DTs and combines it with the release of SysMLv2, thus integrating a systematic approach with DT evolution management in systems engineering.

Paper number 46:
Title: Temporal Variabilities Limit Convergence Rates in Gradient-Based Online Optimization
Authors: Bryan Van Scoy, Gianluca Bianchin
Abstract: This paper investigates the fundamental performance limits of gradient-based algorithms for time-varying optimization. Leveraging the internal model principle and root locus techniques, we show that temporal variabilities impose intrinsic limits on the achievable rate of convergence. For a problem with condition ratio $\kappa$ and time variation whose model has degree $n$, we show that the worst-case convergence rate of any minimal-order gradient-based algorithm is $\rho_\text{TV} = (\frac{\kappa-1}{\kappa+1})^{1/n}$. This bound reveals a fundamental tradeoff between problem conditioning, temporal complexity, and rate of convergence. We further construct explicit controllers that attain the bound for low-degree models of time variation.

Paper number 47:
Title: Learning Robust Agile Flight Control with Stability Guarantees
Authors: Lukas Pries, Markus Ryll
Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving precise trajectory tracking at the platform's operational limits is paramount. Controllers must handle actuator constraints, exhibit robustness to disturbances, and remain computationally efficient for safety-critical applications. In this work, we present a novel neural-augmented feedback controller for agile flight control. The controller addresses individual limitations of existing state-of-the-art control paradigms and unifies their strengths. We demonstrate the controller's capabilities, including the accurate tracking of highly aggressive trajectories that surpass the feasibility of the actuators. Notably, the controller provides universal stability guarantees, enhancing its robustness and tracking performance even in exceedingly disturbance-prone settings. Its nonlinear feedback structure is highly efficient enabling fast computation at high update rates. Moreover, the learning process in simulation is both fast and stable, and the controller's inherent robustness allows direct deployment to real-world platforms without the need for training augmentations or fine-tuning.

Paper number 48:
Title: Variational Quantum Eigensolver Models of Molecular Quantum Dot Cellular Automata
Authors: Nischal Binod Gautam, Enrique P. Blair
Abstract: Molecular quantum-dot Cellular Automata (QCA) may provide low-power, high-speed computational hardware for processing classical information. Simulation and modeling play an important role in the design of QCA circuits because fully-coherent models of QCA scale exponentially with the number of devices, and such models are severely limited in size. For larger circuits, approximations become necessary. In the era of fault-tolerant quantum computation, however, it may become possible to model large QCA circuits without such limitations. Presently, this work explores the use of the noisy-intermediate scale quantum (NISQ) variational quantum eigensolver (VQE) method for estimating the ground state of QCA circuits. This is relevant because the computational result of a QCA calculation is encoded in the circuit's ground state. In this study, VQE is used to model logic circuits, including binary wires, inverters, and majority gates. VQE models are performed ideal simulators, noisy simulators, and actual quantum hardware. This study demonstrates that VQE may indeed be used to model molecular QCA circuits. It is observed that using modern NISQ hardware, results are still quite sensitive to noise, so measures should be taken to minimize noise. These include simplifying the ansatz circuit whenever possible, and using low-noise hardware.

Paper number 49:
Title: Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning
Authors: Alvaro Belmonte-Baeza, Miguel Cazorla, Gabriel J. Garc√≠a, Carlos J. P√©rez-Del-Pulgar, Jorge Pomares
Abstract: Robotics plays a pivotal role in planetary science and exploration, where autonomous and reliable systems are crucial due to the risks and challenges inherent to space environments. The establishment of permanent lunar bases demands robotic platforms capable of navigating and manipulating in the harsh lunar terrain. While wheeled rovers have been the mainstay for planetary exploration, their limitations in unstructured and steep terrains motivate the adoption of legged robots, which offer superior mobility and adaptability. This paper introduces a constrained reinforcement learning framework designed for autonomous quadrupedal mobile manipulators operating in lunar environments. The proposed framework integrates whole-body locomotion and manipulation capabilities while explicitly addressing critical safety constraints, including collision avoidance, dynamic stability, and power efficiency, in order to ensure robust performance under lunar-specific conditions, such as reduced gravity and irregular terrain. Experimental results demonstrate the framework's effectiveness in achieving precise 6D task-space end-effector pose tracking, achieving an average positional accuracy of 4 cm and orientation accuracy of 8.1 degrees. The system consistently respects both soft and hard constraints, exhibiting adaptive behaviors optimized for lunar gravity conditions. This work effectively bridges adaptive learning with essential mission-critical safety requirements, paving the way for advanced autonomous robotic explorers for future lunar missions.

Paper number 50:
Title: Optical communication-based identification for multi-UAV systems: theory and practice
Authors: Daniel Bonilla Licea, Viktor Walter, Mounir Ghogho, Martin Saska
Abstract: Mutual relative localization and identification is an important feature for the stabilization and navigation of multi-Unmanned Aerial Vehicle (UAV) systems. Camera-based communications technology, also referred to as Optical Camera Communications (OCC) in the literature, is a novel approach that could bring a valuable solution to such a complex task. In such system, the UAVs are equipped with LEDs that act as beacons and with cameras allowing them to locate the LEDs of other UAVs. Specific blinking sequences are assigned to the LEDs of each of the UAVs in order to uniquely identify them. This camera-based relative localization and identification system is immune to Radio Frequency (RF) electromagnetic interference and operates in Global Navigation satellite (GNSS) denied environments. In addition, since many UAVs are already equipped with cameras, the implementation of this system is inexpensive. In this article, we study in detail the capacity of this system and its limitations. Furthermore, we show how to construct blinking sequences for UAV LEDs in order to improve system performance. Finally, experimental results are presented to corroborate the analytical derivations.

Paper number 51:
Title: Logarithmic Mathematical Morphology: theory and applications
Authors: Guillaume Noyel (CRESTIC)
Abstract: In Mathematical Morphology for grey-level functions, an image is analysed by another image named the structuring function. This structuring function is translated over the image domain and summed to the image. However, in an image presenting lighting variations, the amplitude of the structuring function should vary according to the image intensity. Such a property is not verified in Mathematical Morphology for grey level functions, when the structuring function is summed to the image with the usual additive law. In order to address this issue, a new framework is defined with an additive law for which the amplitude of the structuring function varies according to the image amplitude. This additive law is chosen within the Logarithmic Image Processing framework and models the lighting variations with a physical cause such as a change of light intensity. The new framework is named Logarithmic Mathematical Morphology (LMM) and allows the definition of operators which are robust to such lighting variations.

Paper number 52:
Title: BAAF: A benchmark attention adaptive framework for medical ultrasound image segmentation tasks
Authors: Gongping Chen, Lei Zhao, Xiaotao Yin, Liang Cui, Jianxun Zhang, Yu Dai, Ningning Liu
Abstract: The AI-based assisted diagnosis programs have been widely investigated on medical ultrasound images. Complex scenario of ultrasound image, in which the coupled interference of internal and external factors is severe, brings a unique challenge for localize the object region automatically and precisely in ultrasound images. In this study, we seek to propose a more general and robust Benchmark Attention Adaptive Framework (BAAF) to assist doctors segment or diagnose lesions and tissues in ultrasound images more quickly and accurately. Different from existing attention schemes, the BAAF consists of a parallel hybrid attention module (PHAM) and an adaptive calibration mechanism (ACM). Specifically, BAAF first coarsely calibrates the input features from the channel and spatial dimensions, and then adaptively selects more robust lesion or tissue characterizations from the coarse-calibrated feature maps. The design of BAAF further optimizes the "what" and "where" focus and selection problems in CNNs and seeks to improve the segmentation accuracy of lesions or tissues in medical ultrasound images. The method is evaluated on four medical ultrasound segmentation tasks, and the adequate experimental results demonstrate the remarkable performance improvement over existing state-of-the-art methods. In addition, the comparison with existing attention mechanisms also demonstrates the superiority of BAAF. This work provides the possibility for automated medical ultrasound assisted diagnosis and reduces reliance on human accuracy and precision.

Paper number 53:
Title: RIS-Assisted Millimeter Wave Communications for Indoor Scenarios: Modeling and Coverage Analysis
Authors: Zhi Chai, Jiajie Xu, Justin P. Coon, Mohamed-Slim Alouini
Abstract: Millimeter wave (mmWave) communications and reconfigurable intelligent surfaces (RIS) are two critical technologies for next-generation networks, especially in dense indoor environments. However, existing analyses often oversimplify the indoor environment by neglecting some of the key characteristics, such as height variations, boundary effects, blockage effects, and user spatial distributions. In this paper, we develop an improved stochastic geometry-based model for RIS-assisted mmWave communications in indoor scenarios like conference centers, hospitals, and shopping malls. The proposed model incorporates the height factor for all the nodes in the network (e.g., transmitters, users, RISs, and obstacles) and captures the user clustering behavior in these scenarios. In addition, the boundary effect is also being considered for line-of-sight (LOS) probability calculation. Analytical expressions for distance distributions, LOS probabilities, and the coverage probability (CP) are derived. The CP is then validated through Monte Carlo simulations. Our results reveal deployment insights by approximating and simplifying the derived CP expressions, showing how transmitter density, obstacle density, RIS density, and user cluster radius impact network coverage. Notably, we show that RISs significantly improve coverage when transmitters or transmit power are limited but offer marginal benefits when transmitter density is high. These findings provide practical guidelines for the design and deployment of RIS-assisted indoor mmWave networks.

Paper number 54:
Title: Stimulus Modality Matters: Impact of Perceptual Evaluations from Different Modalities on Speech Emotion Recognition System Performance
Authors: Huang-Cheng Chou, Haibin Wu, Hung-yi Lee, Chi-Chun Lee
Abstract: Speech Emotion Recognition (SER) systems rely on speech input and emotional labels annotated by humans. However, various emotion databases collect perceptional evaluations in different ways. For instance, the IEMOCAP dataset uses video clips with sounds for annotators to provide their emotional perceptions. However, the most significant English emotion dataset, the MSP-PODCAST, only provides speech for raters to choose the emotional ratings. Nevertheless, using speech as input is the standard approach to training SER systems. Therefore, the open question is the emotional labels elicited by which scenarios are the most effective for training SER systems. We comprehensively compare the effectiveness of SER systems trained with labels elicited by different modality stimuli and evaluate the SER systems on various testing conditions. Also, we introduce an all-inclusive label that combines all labels elicited by various modalities. We show that using labels elicited by voice-only stimuli for training yields better performance on the test set, whereas labels elicited by voice-only stimuli.

Paper number 55:
Title: Robust Real-Time Endoscopic Stereo Matching under Fuzzy Tissue Boundaries
Authors: Yang Ding, Can Han, Sijia Du, Yaqi Wang, Dahong Qian
Abstract: Real-time acquisition of accurate scene depth is essential for automated robotic minimally invasive surgery. Stereo matching with binocular endoscopy can provide this depth information. However, existing stereo matching methods, designed primarily for natural images, often struggle with endoscopic images due to fuzzy tissue boundaries and typically fail to meet real-time requirements for high-resolution endoscopic image inputs. To address these challenges, we propose \textbf{RRESM}, a real-time stereo matching method tailored for endoscopic images. Our approach integrates a 3D Mamba Coordinate Attention module that enhances cost aggregation through position-sensitive attention maps and long-range spatial dependency modeling via the Mamba block, generating a robust cost volume without substantial computational overhead. Additionally, we introduce a High-Frequency Disparity Optimization module that refines disparity predictions near tissue boundaries by amplifying high-frequency details in the wavelet domain. Evaluations on the SCARED and SERV-CT datasets demonstrate state-of-the-art matching accuracy with a real-time inference speed of 42 FPS. The code is available at this https URL.

Paper number 56:
Title: Anatomically and Metabolically Informed Diffusion for Unified Denoising and Segmentation in Low-Count PET Imaging
Authors: Menghua Xia, Kuan-Yin Ko, Der-Shiun Wang, Ming-Kai Chen, Qiong Liu, Huidong Xie, Liang Guo, Wei Ji, Jinsong Ouyang, Reimund Bayerlein, Benjamin A. Spencer, Quanzheng Li, Ramsey D. Badawi, Georges El Fakhri, Chi Liu
Abstract: Positron emission tomography (PET) image denoising, along with lesion and organ segmentation, are critical steps in PET-aided diagnosis. However, existing methods typically treat these tasks independently, overlooking inherent synergies between them as correlated steps in the analysis pipeline. In this work, we present the anatomically and metabolically informed diffusion (AMDiff) model, a unified framework for denoising and lesion/organ segmentation in low-count PET imaging. By integrating multi-task functionality and exploiting the mutual benefits of these tasks, AMDiff enables direct quantification of clinical metrics, such as total lesion glycolysis (TLG), from low-count inputs. The AMDiff model incorporates a semantic-informed denoiser based on diffusion strategy and a denoising-informed segmenter utilizing nnMamba architecture. The segmenter constrains denoised outputs via a lesion-organ-specific regularizer, while the denoiser enhances the segmenter by providing enriched image information through a denoising revision module. These components are connected via a warming-up mechanism to optimize multi-task interactions. Experiments on multi-vendor, multi-center, and multi-noise-level datasets demonstrate the superior performance of AMDiff.

Paper number 57:
Title: A Cyber Insurance Policy for Hedging Against Load-Altering Attacks and Extreme Load Variations in Distribution Grids
Authors: Shijie Pan, Zaint A. Alexakis, S Subhash Lakshminarayana, Charalambos Konstantinou
Abstract: Uncertainties in renewable energy resources (RES) and load variations can lead to elevated system operational costs. Moreover, the emergence of large-scale distributed threats, such as load-altering attacks (LAAs), can induce substantial load variations, further exacerbating these costs. Although traditional defense measures can reduce the likelihood of such attacks, considerable residual risks remain. Thus, this paper proposes a cyber insurance framework designed to hedge against additional operational costs resulting from LAAs and substantial load variations in renewable-rich grids. The insurance framework determines both the insurance coverage and premium based on the Value at Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated using the system failure probability and the probability density function (PDF) of the system operation cost. The system failure probability is assessed through a semi-Markov process (SMP), while the cost distribution is estimated through a cost minimization model of a distribution grid combined with a Monte-Carlo simulation to capture load variability. Furthermore, we employ a bi-level optimization scheme that identifies the specific load distribution leading to the maximum system cost, thereby enhancing the accuracy of the operation cost PDF estimation. The effectiveness and scalability of the proposed cyber insurance policy are evaluated considering a modified IEEE-118 test bus system and the IEEE European low-voltage (LV) test feeders model. The case study shows that with a relatively low premium, the network operator can hedge against additional operational costs caused by malicious load manipulations.

Paper number 58:
Title: Adaptive DRL for IRS Mirror Orientation in Dynamic OWC Networks
Authors: Ahrar N. Hamad, Ahmad Adnan Qidan, Taisir E.H. El-Gorashi, Jaafar M. H. Elmirghani
Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a promising solution to mitigate line-of-sight (LoS) blockages and enhance signal coverage in optical wireless communication (OWC) systems with minimal additional power. In this work, we consider a mirror-based IRS to assist a dynamic indoor visible light communication (VLC) environment. We formulate an optimization problem that aims to maximize the sum rate by adjusting the orientation of the IRS mirrors. To enable real-time adaptability, the problem is modelled as a Markov decision process (MDP), and a deep reinforcement learning (DRL) algorithm is developed based on the deterministic policy gradient for real-time mirror-based IRS optimization in dynamic VLC networks. The proposed DRL is employed to optimize mirror orientation toward mobile users under blockage and mobility constraints. Simulation results demonstrate that our proposed DRL algorithm outperforms the conventional deep Q- learning (DQL) algorithm and achieves substantial improvements in sum rate compared to random-orientation IRS configurations

Paper number 59:
Title: On Multiangle Discrete Fractional Periodic Transforms
Authors: Christian Oswald, Franz Pernkopf
Abstract: The efficient multiangle centered discrete fractional Fourier transform (MA-CDFRFT) [1] has proven to be a useful tool for time-frequency analysis; in this paper, we generalize the MA-CDFRFT to general M-periodic transforms, which, among others, include the standard discrete Fourier, discrete sine, discrete cosine, Hadamard and discrete Hartley transform. Furthermore, we exploit the symmetries inherent to the MA-CDFRFT and our novel multiangle standard discrete fractional Fourier transform (MA-DFRFT) to halve the number of FFTs needed to compute these transforms, which paves the way for applications in resource-constrained environments.

Paper number 60:
Title: BrainOmni: A Brain Foundation Model for Unified EEG and MEG Signals
Authors: Qinfan Xiao, Ziyun Cui, Chi Zhang, Siqi Chen, Wen Wu, Andrew Thwaites, Alexandra Woolgar, Bowen Zhou, Chao Zhang
Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) measure neural activity non-invasively by capturing electromagnetic fields generated by dendritic currents. Although rooted in the same biophysics, EEG and MEG exhibit distinct signal patterns, further complicated by variations in sensor configurations across modalities and recording devices. Existing approaches typically rely on separate, modality- and dataset-specific models, which limits the performance and cross-domain scalability. This paper proposes BrainOmni, the first brain foundation model that generalises across heterogeneous EEG and MEG recordings. To unify diverse data sources, we introduce BrainTokenizer,the first tokenizer that quantises spatiotemporal brain activity into discrete representations. Central to BrainTokenizer is a novel Sensor Encoder that encodes sensor properties such as spatial layout, orientation, and type, enabling compatibility across devices and modalities. Building upon the discrete representations, BrainOmni learns unified semantic embeddings of brain signals by self-supervised pretraining. To the best of our knowledge, it is the first foundation model to support both EEG and MEG signals, as well as the first to incorporate large-scale MEG pretraining. A total of 1,997 hours of EEG and 656 hours of MEG data are curated and standardised from publicly available sources for pretraining. Experiments show that BrainOmni outperforms both existing foundation models and state-of-the-art task-specific models on a range of downstream tasks. It also demonstrates strong generalisation to unseen EEG and MEG devices. Further analysis reveals that joint EEG-MEG (EMEG) training yields consistent improvements across both modalities. Code and model checkpoints will be released upon acceptance.

Paper number 61:
Title: Unsupervised patch-based dynamic MRI reconstruction using learnable tensor function with implicit neural representation
Authors: Yuanyuan Liu, Yuanbiao Yang, Jing Cheng, Zhuo-Xu Cui, Qingyong Zhu, Congcong Liu, Yuliang Zhu, Jingran Xu, Hairong Zheng, Dong Liang, Yanjie Zhu
Abstract: Dynamic MRI suffers from limited spatiotemporal resolution due to long acquisition times. Undersampling k-space accelerates imaging but makes accurate reconstruction challenging. Supervised deep learning methods achieve impressive results but rely on large fully sampled datasets, which are difficult to obtain. Recently, implicit neural representations (INR) have emerged as a powerful unsupervised paradigm that reconstructs images from a single undersampled dataset without external training data. However, existing INR-based methods still face challenges when applied to highly undersampled dynamic MRI, mainly due to their inefficient representation capacity and high computational cost. To address these issues, we propose TenF-INR, a novel unsupervised framework that integrates low-rank tensor modeling with INR, where each factor matrix in the tensor decomposition is modeled as a learnable factor function. Specifically,we employ INR to model learnable tensor functions within a low-rank decomposition, reducing the parameter space and computational burden. A patch-based nonlocal tensor modeling strategy further exploits temporal correlations and inter-patch similarities, enhancing the recovery of fine spatiotemporal details. Experiments on dynamic cardiac and abdominal datasets demonstrate that TenF-INR achieves up to 21-fold acceleration, outperforming both supervised and unsupervised state-of-the-art methods in image quality, temporal fidelity, and quantitative accuracy.

Paper number 62:
Title: Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT
Authors: Megan Harris, Ehsanoddin Ghorbanichemazkati, Mohammad Mahdi Naderi, John C. Little, Amro M. Farid
Abstract: Worsening global challenges in the Anthropocene demand complex, adaptive solutions grounded in a systems-level understanding of coupled social and environmental dynamics. However, existing modeling approaches often fall short due to disciplinary silos, limited scalability, and the absence of shared ontological frameworks. Model-Based Systems Engineering (MBSE), when integrated with Hetero-functional Graph Theory (HFGT), offers a powerful methodology for modeling systems of systems while preserving subsystem heterogeneity and enabling cross-disciplinary integration. This paper presents the first application of the MBSE-HFGT methodology to environmental systems, using a series of worked examples involving flow through lake and land segments. These examples demonstrate how the approach enables consistent, scalable, and integrative modeling of complex environmental processes.

Paper number 63:
Title: Adaptive Decentralized Queue Disclosure for Impatient Tenants in Edge and Non-terrestrial Systems
Authors: Anthony Kiggundu, Bin Han, Hans D. Schotten
Abstract: We study how queue-state information disclosures affect impatient tenants in multi-tenant edge systems. We propose an information-bulletin strategy in which each queue periodically broadcasts two Markov models. One is a model of steady-state service-rate behavior and the other a model of the queue length inter-change times. Tenants autonomously decide to renege or jockey based on this information. The queues observe tenant responses and adapt service rates via a learned, rule-based predictive policy designed for decentralized, partially-observed, and time-varying environments. We compare this decentralized, information-driven policy to the classical, centralized Markov Decision Process (MDP) hedging-point policy for M/M/2 systems. Numerical experiments quantify the tradeoffs in average delay, impatience and robustness to stale information. Results show that when full, instantaneous state information and stationarity hold, the hedging-point policy yields less impatience but this diminishes as information becomes partial or stale. The rule-based predictive policy on the other hand is more robust to staleness in dispatched information, making it conducive for conditions typical of edge cloud and non-terrestrial deployments.

Paper number 64:
Title: Semi-Unsupervised Microscopy Segmentation with Fuzzy Logic and Spatial Statistics for Cross-Domain Analysis Using a GUI
Authors: Surajit Das, Pavel Zun
Abstract: Brightfield microscopy of unstained live cells is challenging due to low contrast, dynamic morphology, uneven illumination, and lack of labels. Deep learning achieved SOTA performance on stained, high-contrast images but needs large labeled datasets, expensive hardware, and fails under uneven illumination. This study presents a low-cost, lightweight, annotation-free segmentation method by introducing one-time calibration-assisted unsupervised framework adaptable across imaging modalities and image type. The framework determines background via spatial standard deviation from the local mean. Uncertain pixels are resolved using fuzzy logic, cumulative squared shift of nodal intensity, statistical features, followed by post-segmentation denoising calibration which is saved as a profile for reuse until noise pattern or object type substantially change. The program runs as a script or graphical interface for non-programmers. The method was rigorously evaluated using \textit{IoU}, \textit{F1-score}, and other metrics, with statistical significance confirmed via Wilcoxon signed-rank tests. On unstained brightfield myoblast (C2C12) images, it outperformed \textit{Cellpose 3.0} and \textit{StarDist}, improving IoU by up to 48\% (average IoU = 0.43, F1 = 0.60). In phase-contrast microscopy, it achieved a mean IoU of 0.69 and an F1-score of 0.81 on the \textit{LIVECell} dataset ($n = 3178$), with substantial expert agreement ($\kappa > 0.75$) confirming cross-modality robustness. Successful segmentation of laser-affected polymer surfaces further confirmed cross-domain robustness. By introducing the \textit{Homogeneous Image Plane} concept, this work provides a new theoretical foundation for training-free, annotation-free segmentation. The framework operates efficiently on CPU, avoids cell staining, and is practical for live-cell imaging and biomedical applications.

Paper number 65:
Title: Globally Stable Discrete Time PID Passivity-based Control of Power Converters: Simulation and Experimental Results
Authors: Alessio Moreschini, Wei He, Romeo Ortega, Yiheng Lu, Tao Li
Abstract: The key idea behind PID Passivity-based Control (PID-PBC) is to leverage the passivity property of PIDs (for all positive gains) and wrap the PID controller around a passive output to ensure global stability in closed-loop. However, the practical applicability of PID-PBC is stymied by two key facts: (i) the vast majority of practical implementations of PIDs is carried-out in discrete time -- discretizing the continuous time dynamical system of the PID; (ii) the well-known problem that passivity is not preserved upon discretization, even with small sampling times. Therefore, two aspects of the PID-PBC must be revisited for its safe practical application. First, we propose a discretization of the PID that ensures its passivity. Second, since the output that is identified as passive for the continuous time system is not necessarily passive for its discrete time version, we construct a new output that ensures the passivity property for the discretization of the system. In this paper, we provide a constructive answer to both issues for the case of power converter models. Instrumental to achieve this objective is the use of the implicit midpoint discretization method -- which is a symplectic integration technique that preserves system invariants. Since the reference value for the output to be regulated in power converters is non-zero, we are henceforth interested in the property of passivity of the incremental model -- currently known as shifted passivity. Therefore, we demonstrate that the resulting discrete-time PID-PBC defines a passive map for the incremental model and establish shifted passivity for the discretized power converter model. Combining these properties, we prove global stability for the feedback interconnection of the power converter with the discretized PID-PBC. The paper also presents simulations and experiments that demonstrate the performance of the proposed discretization.

Paper number 66:
Title: Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification (MIDOG 2025 Task 2 Winner)
Authors: Guillaume Balezo, Hana Feki, Rapha√´l Bourgade, Lily Monnier, Matthieu Blons, Alice Blondel, Etienne Decenci√®re, Albert Pla Planas, Thomas Walter
Abstract: Atypical mitotic figures (AMFs) represent abnormal cell division associated with poor prognosis. Yet their detection remains difficult due to low prevalence, subtle morphology, and inter-observer variability. The MIDOG 2025 challenge introduces a benchmark for AMF classification across multiple domains. In this work, we fine-tuned the recently published DINOv3-H+ vision transformer, pretrained on natural images, using low-rank adaptation (LoRA), training only ~1.3M parameters in combination with extensive augmentation and a domain-weighted Focal Loss to handle domain heterogeneity. Despite the domain gap, our fine-tuned DINOv3 transfers effectively to histopathology, reaching first place on the final test set. These results highlight the advantages of DINOv3 pretraining and underline the efficiency and robustness of our fine-tuning strategy, yielding state-of-the-art results for the atypical mitosis classification challenge in MIDOG 2025.

Paper number 67:
Title: Evaluating the Impact of Radiographic Noise on Chest X-ray Semantic Segmentation and Disease Classification Using a Scalable Noise Injection Framework
Authors: Derek Jiu, Kiran Nijjer, Nishant Chinta, Ryan Bui, Kevin Zhu
Abstract: Deep learning models are increasingly used for radiographic analysis, but their reliability is challenged by the stochastic noise inherent in clinical imaging. A systematic, cross-task understanding of how different noise types impact these models is lacking. Here, we evaluate the robustness of state-of-the-art convolutional neural networks (CNNs) to simulated quantum (Poisson) and electronic (Gaussian) noise in two key chest X-ray tasks: semantic segmentation and pulmonary disease classification. Using a novel, scalable noise injection framework, we applied controlled, clinically-motivated noise severities to common architectures (UNet, DeepLabV3, FPN; ResNet, DenseNet, EfficientNet) on public datasets (Landmark, ChestX-ray14). Our results reveal a stark dichotomy in task robustness. Semantic segmentation models proved highly vulnerable, with lung segmentation performance collapsing under severe electronic noise (Dice Similarity Coefficient drop of 0.843), signifying a near-total model failure. In contrast, classification tasks demonstrated greater overall resilience, but this robustness was not uniform. We discovered a differential vulnerability: certain tasks, such as distinguishing Pneumothorax from Atelectasis, failed catastrophically under quantum noise (AUROC drop of 0.355), while others were more susceptible to electronic noise. These findings demonstrate that while classification models possess a degree of inherent robustness, pixel-level segmentation tasks are far more brittle. The task- and noise-specific nature of model failure underscores the critical need for targeted validation and mitigation strategies before the safe clinical deployment of diagnostic AI.

Paper number 68:
Title: PowerPlots.jl: An Open Source Power Grid Visualization and Data Analysis Framework for Academic Research
Authors: Noah Rhodes
Abstract: Data visualization is essential for developing an understanding of a complex system. The power grid is one of the most complex systems in the world and effective power grid research visualization software must 1) be easy to use, 2) support unique data that may arise in research, and 3) be capable of creating custom figures for publication and presentation. However, no current software addresses all three of these needs. PowerPlots is an open-source data visualization tool for power grids that does address these needs. In addition, several tools created to support this software facilitate the analysis of power grid data by transforming the data into graph topology or data-frame data formats that are more compatible for some analyses. In this work, we use PowerPlots to investigate several case studies that involve exploring power grid data. These case studies demonstrate the valuable insights that are possible when using network visualization and how it can be applied to research applications.

Paper number 69:
Title: Optimization of High-Order Quarter-Wave Plate for Birefringence Suppression in FOCS
Authors: Yuechen Liu, Boqi Meng
Abstract: Fiber optic current sensors (FOCS) are widely adopted in modern power grids due to high sensitivity, excellent insulation, and strong immunity to electromagnetic interference. This prominence necessitates precise investigation into their error sources and corresponding optimization. This study examines reflective FOCS based on the Faraday effect. A theoretical model is established to simulate phase error caused by linear birefringence from the quarter-wave plate. Conventional methods using circular birefringence are analyzed, revealing inherent limitations. Innovatively, a compensation strategy employing high-order quarter-wave plates is proposed to effectively eliminate linear birefringence effects. This approach significantly enhances the accuracy and practicality of FOCS in precision metrology.

Paper number 70:
Title: Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach
Authors: Yinchao Yang, Yahao Ding, Zhaohui Yang, Chongwen Huang, Zhaoyang Zhang, Dusit Niyato, Mohammad Shikh-Bahaei
Abstract: Real-time and contactless monitoring of vital signs, such as respiration and heartbeat, alongside reliable communication, is essential for modern healthcare systems, especially in remote and privacy-sensitive environments. Traditional wireless communication and sensing networks fall short in meeting all the stringent demands of eHealth, including accurate sensing, high data efficiency, and privacy preservation. To overcome the challenges, we propose a novel integrated sensing, computing, and semantic communication (ISCSC) framework. In the proposed system, a service robot utilises radar to detect patient positions and monitor their vital signs, while sending updates to the medical devices. Instead of transmitting raw physiological information, the robot computes and communicates semantically extracted health features to medical devices. This semantic processing improves data throughput and preserves the clinical relevance of the messages, while enhancing data privacy by avoiding the transmission of sensitive data. Leveraging the estimated patient locations, the robot employs an interacting multiple model (IMM) filter to actively track patient motion, thereby enabling robust beam steering for continuous and reliable monitoring. We then propose a joint optimisation of the beamforming matrices and the semantic extraction ratio, subject to computing capability and power budget constraints, with the objective of maximising both the semantic secrecy rate and sensing accuracy. Simulation results validate that the ISCSC framework achieves superior sensing accuracy, improved semantic transmission efficiency, and enhanced privacy preservation compared to conventional joint sensing and communication methods.

Paper number 71:
Title: OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation
Authors: Qi Jiang, Yao Gao, Shaohua Gao, Zhonghua Yi, Xiaolong Qian, Hao Shi, Kailun Yang, Lei Sun, Kaiwei Wang
Abstract: Emerging universal Computational Aberration Correction (CAC) paradigms provide an inspiring solution to light-weight and high-quality imaging with a universal model trained on a lens library (LensLib) to address arbitrary lens aberrations blindly. However, the limited coverage of existing LensLibs leads to poor generalization of the trained models to unseen lenses, whose fine-tuning pipeline is also confined to the lens-descriptions-known case. In this work, we introduce OmniLens, a flexible solution to universal CAC via (i) establishing a convincing LensLib with comprehensive coverage for pre-training a robust base model, and (ii) adapting the model to any specific lens designs with unknown lens descriptions via fast LensLib-to-specific domain adaptation. To achieve these, an Evolution-based Automatic Optical Design (EAOD) pipeline is proposed to generate a rich variety of lens samples with realistic aberration behaviors. Then, we design an unsupervised regularization term for efficient domain adaptation on a few easily accessible real-captured images based on the statistical observation of dark channel priors in degradation induced by lens aberrations. Extensive experiments demonstrate that the LensLib generated by EAOD effectively develops a universal CAC model with strong generalization capabilities, which can also improve the non-blind lens-specific methods by 0.35-1.81dB in PSNR. Additionally, the proposed domain adaptation method significantly improves the base model, especially in severe aberration cases (at most 2.59dB in PSNR). The code and data will be available at this https URL.

Paper number 72:
Title: Eco-driving Incentive Mechanisms for Mitigating Emissions in Urban Transportation
Authors: M. Umar B. Niazi, Jung-Hoon Cho, Munther A. Dahleh, Roy Dong, Cathy Wu
Abstract: This paper develops incentive mechanisms for promoting eco-driving with the overarching goal of minimizing emissions in transportation networks. The system operator provides drivers with energy-efficient driving guidance throughout their trips and measures compliance through vehicle telematics that capture how closely drivers follow this guidance. Drivers optimize their behaviors based on personal trade-offs between travel times and emissions. To design effective incentives, the operator elicits driver preferences regarding trip urgency and willingness to eco-drive, while determining optimal budget allocations and eco-driving recommendations. Two distinct settings based on driver behavior are analyzed. When drivers report their preferences truthfully, an incentive mechanism ensuring obedience (drivers find it optimal to follow recommendations) is designed by implementing eco-driving recommendations as a Nash equilibrium. When drivers may report strategically, the mechanism is extended to be both obedient and truthful (drivers find it optimal to report truthfully). Unlike existing works that focus on congestion or routing decisions in transportation networks, our framework explicitly targets emissions reduction by incentivizing drivers. The proposed mechanism addresses both strategic behavior and network effects arising from driver interactions, without requiring the operator to reveal system parameters to the drivers. Numerical simulations demonstrate the effects of budget constraints, driver types, and strategic misreporting on equilibrium outcomes and emissions reduction.

Paper number 73:
Title: DarkIR: Robust Low-Light Image Restoration
Authors: Daniel Feijoo, Juan C. Benito, Alvaro Garcia, Marcos V. Conde
Abstract: Photography during night or in dark conditions typically suffers from noise, low light and blurring issues due to the dim environment and the common use of long exposure. Although Deblurring and Low-light Image Enhancement (LLIE) are related under these conditions, most approaches in image restoration solve these tasks separately. In this paper, we present an efficient and robust neural network for multi-task low-light image restoration. Instead of following the current tendency of Transformer-based models, we propose new attention mechanisms to enhance the receptive field of efficient CNNs. Our method reduces the computational costs in terms of parameters and MAC operations compared to previous methods. Our model, DarkIR, achieves new state-of-the-art results on the popular LOLBlur, LOLv2 and Real-LOLBlur datasets, being able to generalize on real-world night and dark images. Code and models at this https URL

Paper number 74:
Title: AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars
Authors: Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, Zhaoxin Fan, Wenjun Wu, Xuelong Li
Abstract: Whole-body audio-driven avatar pose and expression generation is a critical task for creating lifelike digital humans and enhancing the capabilities of interactive virtual agents, with wide-ranging applications in virtual reality, digital entertainment, and remote communication. Existing approaches often generate audio-driven facial expressions and gestures independently, which introduces a significant limitation: the lack of seamless coordination between facial and gestural elements, resulting in less natural and cohesive animations. To address this limitation, we propose AsynFusion, a novel framework that leverages diffusion transformers to achieve harmonious expression and gesture synthesis. The proposed method is built upon a dual-branch DiT architecture, which enables the parallel generation of facial expressions and gestures. Within the model, we introduce a Cooperative Synchronization Module to facilitate bidirectional feature interaction between the two modalities, and an Asynchronous LCM Sampling strategy to reduce computational overhead while maintaining high-quality outputs. Extensive experiments demonstrate that AsynFusion achieves state-of-the-art performance in generating real-time, synchronized whole-body animations, consistently outperforming existing methods in both quantitative and qualitative evaluations.

Paper number 75:
Title: A Fast and Lightweight Model for Causal Audio-Visual Speech Separation
Authors: Wendi Sang, Kai Li, Runxuan Yang, Jianqiang Huang, Xiaolin Hu
Abstract: Audio-visual speech separation (AVSS) aims to extract a target speech signal from a mixed signal by leveraging both auditory and visual (lip movement) cues. However, most existing AVSS methods exhibit complex architectures and rely on future context, operating offline, which renders them unsuitable for real-time applications. Inspired by the pipeline of RTFSNet, we propose a novel streaming AVSS model, named Swift-Net, which enhances the causal processing capabilities required for real-time applications. Swift-Net adopts a lightweight visual feature extraction module and an efficient fusion module for audio-visual integration. Additionally, Swift-Net employs Grouped SRUs to integrate historical information across different feature spaces, thereby improving the utilization efficiency of historical information. We further propose a causal transformation template to facilitate the conversion of non-causal AVSS models into causal counterparts. Experiments on three standard benchmark datasets (LRS2, LRS3, and VoxCeleb2) demonstrated that under causal conditions, our proposed Swift-Net exhibited outstanding performance, highlighting the potential of this method for processing speech in complex environments.

Paper number 76:
Title: Generative Resource Allocation for 6G O-RAN with Diffusion Policies
Authors: Salar Nouri, Mojdeh Karbalaeimotaleb, Vahid Shah-Mansouri, Tarik Taleb
Abstract: Dynamic resource allocation in O-RAN is critical for managing the conflicting QoS requirements of 6G network slices. Conventional reinforcement learning agents often fail in this domain, as their unimodal policy structures cannot model the multi-modal nature of optimal allocation strategies. This paper introduces Diffusion Q-Learning (Diffusion-QL), a novel framework that represents the policy as a conditional diffusion model. Our approach generates resource allocation actions by iteratively reversing a noising process, with each step guided by the gradient of a learned Q-function. This method enables the policy to learn and sample from the complex distribution of near-optimal actions. Simulations demonstrate that the Diffusion-QL approach consistently outperforms state-of-the-art DRL baselines, offering a robust solution for the intricate resource management challenges in next-generation wireless networks.

Paper number 77:
Title: Pad√© Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data
Authors: Sertac Kilickaya, Levent Eren
Abstract: Purpose: The primary aim of this study is to enhance fault diagnosis in induction machines by leveraging the Pad√© Approximant Neuron (PAON) model. While accelerometers and microphones are standard in motor condition monitoring, deep learning models with nonlinear neuron architectures offer promising improvements in diagnostic performance. This research investigates whether Pad√© Approximant Neural Networks (Pad√©Nets) can outperform conventional Convolutional Neural Networks (CNNs) and Self-Organized Operational Neural Networks (Self-ONNs) in the diagnosis of electrical and mechanical faults from vibration and acoustic data. Methods: We evaluate and compare the diagnostic capabilities of three deep learning architectures: one-dimensional CNNs, Self-ONNs, and Pad√©Nets. These models are tested on the University of Ottawa's publicly available constant-speed induction motor datasets, which include both vibration and acoustic sensor data. The Pad√©Net model is designed to introduce enhanced nonlinearity and is compatible with unbounded activation functions such as LeakyReLU. Results and Conclusion: Pad√©Nets consistently outperformed the baseline models, achieving diagnostic accuracies of 99.96%, 98.26%, 97.61%, and 98.33% for accelerometers 1, 2, 3, and the acoustic sensor, respectively. The enhanced nonlinearity of Pad√©Nets, together with their compatibility with unbounded activation functions, significantly improves fault diagnosis performance in induction motor condition monitoring.

Paper number 78:
Title: Algorithmic Implementation: An Introduction to a Low-Cost, GUI-Based, Semi-Unsupervised Microscopy Segmentation Framework
Authors: Surajit Das, Pavel Zun
Abstract: This article presents a novel microscopy image analysis framework designed for low-budget labs equipped with a standard CPU desktop. The Python-based program enables cytometric analysis of live, unstained cells in culture through an advanced computer vision and machine learning pipeline. Crucially, the framework operates on label-free data, requiring no manually annotated training data or training phase. It is accessible via a user-friendly, cross-platform GUI that requires no programming skills, while also providing a scripting interface for programmatic control and integration by developers. The end-to-end workflow performs semantic and instance segmentation, feature extraction, analysis, evaluation, and automated report generation. Its modular architecture supports easy maintenance and flexible integration while supporting both single-image and batch processing. Validated on several unstained cell types from the public dataset of livecells, the framework demonstrates superior accuracy and reproducibility compared to contemporary tools like Cellpose and StarDist. Its competitive segmentation speed on a CPU-based platform highlights its significant potential for basic research and clinical application-particularly in cell transplantation for personalised medicine and muscle regeneration therapies. The access to the application is available for reproducibility.

Paper number 79:
Title: TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation
Authors: Yongsheng Feng, Yuetonghui Xu, Jiehui Luo, Hongjia Liu, Xiaobing Li, Feng Yu, Wei Li
Abstract: Source separation is a fundamental task in speech, music, and audio processing, and it also provides cleaner and larger data for training generative models. However, improving separation performance in practice often depends on increasingly large networks, inflating training and deployment costs. Motivated by recent advances in inference-time scaling for generative modeling, we propose Training-Time and Inference-Time Scalable Discriminative Source Separation (TISDiSS), a unified framework that integrates early-split multi-loss supervision, shared-parameter design, and dynamic inference repetitions. TISDiSS enables flexible speed-performance trade-offs by adjusting inference depth without retraining additional models. We further provide systematic analyses of architectural and training choices and show that training with more inference repetitions improves shallow-inference performance, benefiting low-latency applications. Experiments on standard speech separation benchmarks demonstrate state-of-the-art performance with a reduced parameter count, establishing TISDiSS as a scalable and practical framework for adaptive source separation. Code is available at this https URL.

Paper number 80:
Title: Investigating Faithfulness in Large Audio Language Models
Authors: Lovenya Jain, Pooneh Mousavi, Mirco Ravanelli, Cem Subakan
Abstract: Faithfulness measures whether chain-of-thought (CoT) representations accurately reflect a model's decision process and can be used as reliable explanations. Prior work has shown that CoTs from text-based LLMs are often unfaithful. This question has not been explored for large audio-language models (LALMs), where faithfulness is critical for safety-sensitive applications. Reasoning in LALMs is also more challenging, as models must first extract relevant clues from audio before reasoning over them. In this paper, we investigate the faithfulness of CoTs produced by several LALMs by applying targeted interventions, including paraphrasing, filler token injection, early answering, and introducing mistakes, on two challenging reasoning datasets: SAKURA and MMAR. After going through the aforementioned interventions across several datasets and tasks, our experiments suggest that, LALMs generally produce CoTs that appear to be faithful to their underlying decision processes.

Paper number 81:
Title: Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell
Authors: Sara Strakosova, Petr Novak, Petr Kadera
Abstract: Current products, especially in the automotive sector, pose complex technical systems having a multi-disciplinary mechatronic nature. Industrial standards supporting system engineering and production typically (i) address the production phase only, but do not cover the complete product life cycle, and (ii) focus on production processes and resources rather than the products themselves. The presented approach is motivated by incorporating the impacts of the end-of-life phase of the product life cycle into the engineering phase. This paper proposes a modeling approach coming up from the Product-Process-Resource (PPR) modeling paradigm. It combines requirements on (i) respecting the product structure as a basis for the model, and (ii) incorporates repairing, remanufacturing, or upcycling within cyber-physical production systems. The proposed model called PoPAN should accompany the product during the entire life cycle as a digital shadow encapsulated within the Asset Administration Shell of a product. To facilitate the adoption of the proposed paradigm, the paper also proposes serialization of the model in the AutomationML data format. The model is demonstrated on a use-case for disassembling electric vehicle batteries to support their remanufacturing for stationary battery applications.

Paper number 82:
Title: The Algorithmic Regulator
Authors: Giulio Ruffini
Abstract: The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\Delta > 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] making low $M(W{:}R)$ exponentially unlikely as $\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout.
    