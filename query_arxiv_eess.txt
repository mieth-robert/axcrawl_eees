
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection
Authors: Yassine Habchi, Hamza Kheddar, Yassine Himeur, Adel Belouchrani, Erchin Serpedin, Fouad Khelifi, Muhammad E.H. Chowdhury
Abstract: The rapid advancement of deep learning (DL) has transformed healthcare, particularly in cancer detection and diagnosis. DL surpasses traditional machine learning and human accuracy, making it a critical tool for identifying diseases. Despite numerous reviews on DL in healthcare, a comprehensive analysis of its role in cancer detection remains limited. Existing studies focus on specific aspects, leaving gaps in understanding its broader impact. This paper addresses these gaps by reviewing advanced DL techniques, including transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These approaches enhance accuracy, tackle data scarcity, and enable decentralized learning while maintaining data privacy. TL adapts pre-trained models to new datasets, improving performance with limited labeled data. RL optimizes diagnostic pathways and treatment strategies, while FL fosters collaborative model development without sharing sensitive data. Transformers and LLMs, traditionally used in natural language processing, are now applied to medical data for improved interpretability. Additionally, this review examines these techniques' efficiency in cancer diagnosis, addresses challenges like data imbalance, and proposes solutions. It serves as a resource for researchers and practitioners, providing insights into current trends and guiding future research in advanced DL for cancer detection.

Paper number 2:
Title: Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)
Authors: Mohammad Mahdi Danesh Pajouh
Abstract: Cancer remains one of the leading causes of mortality worldwide, and among its many forms, brain tumors are particularly notorious due to their aggressive nature and the critical challenges involved in early diagnosis. Recent advances in artificial intelligence have shown great promise in assisting medical professionals with precise tumor segmentation, a key step in timely diagnosis and treatment planning. However, many state-of-the-art segmentation methods require extensive computational resources and prolonged training times, limiting their practical application in resource-constrained settings. In this work, we present a novel dual-decoder U-Net architecture enhanced with attention-gated skip connections, designed specifically for brain tumor segmentation from MRI scans. Our approach balances efficiency and accuracy by achieving competitive segmentation performance while significantly reducing training demands. Evaluated on the BraTS 2020 dataset, the proposed model achieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core (TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several commonly used U-Net variants. Our model demonstrates that high-quality brain tumor segmentation is attainable even under limited computational resources, thereby offering a viable solution for researchers and clinicians operating with modest hardware. This resource-efficient model has the potential to improve early detection and diagnosis of brain tumors, ultimately contributing to better patient outcomes

Paper number 3:
Title: Strategic Planning of Stealthy Backdoor Attacks in Markov Decision Processes
Authors: Xinyi Wei, Shuo Han, Ahmed H. Hemida, Charles A. Kamhoua, Jie Fu
Abstract: This paper investigates backdoor attack planning in stochastic control systems modeled as Markov Decision Processes (MDPs). In a backdoor attack, the adversary provides a control policy that behaves well in the original MDP to pass the testing phase. However, when such a policy is deployed with a trigger policy, which perturbs the system dynamics at runtime, it optimizes the attacker's objective instead. To solve jointly the control policy and its trigger, we formulate the attack planning problem as a constrained optimal planning problem in an MDP with augmented state space, with the objective to maximize the attacker's total rewards in the system with an activated trigger, subject to the constraint that the control policy is near optimal in the original MDP. We then introduce a gradient-based optimization method to solve the optimal backdoor attack policy as a pair of coordinated control and trigger policies. Experimental results from a case study validate the effectiveness of our approach in achieving stealthy backdoor attacks.

Paper number 4:
Title: A Model Predictive Control Approach for Quadrotor Cruise Control
Authors: Zekai Chen, Leon Kehler
Abstract: This paper investigates the application of a Model Predictive Controller (MPC) for the cruise control system of a quadrotor, focusing on hovering point stabilization and reference tracking. Initially, a full-state-feedback MPC is designed for the ideal scenario. To account for real-world conditions, a constant disturbance is introduced to the quadrotor, simulating a gust of wind in a specific direction. In response, an output-feedback offset-free MPC is developed to stabilize the quadrotor while rejecting the disturbance. We validate the design of the controller by conducting stability analysis, as well as numerical simulations under different circumstances. It is shown that the designed controller can achieve all the expected goals for the cruise control, including reference tracking and disturbance rejection. This project was implemented using Python and the CVXPY library for convex optimization.

Paper number 5:
Title: Integrated Control and Active Perception in POMDPs for Temporal Logic Tasks and Information Acquisition
Authors: Chongyang Shi, Michael R. Dorothy, Jie Fu
Abstract: This paper studies the synthesis of a joint control and active perception policy for a stochastic system modeled as a partially observable Markov decision process (POMDP), subject to temporal logic specifications. The POMDP actions influence both system dynamics (control) and the emission function (perception). Beyond task completion, the planner seeks to maximize information gain about certain temporal events (the secret) through coordinated perception and control. To enable active information acquisition, we introduce minimizing the Shannon conditional entropy of the secret as a planning objective, alongside maximizing the probability of satisfying the temporal logic formula within a finite horizon. Using a variant of observable operators in hidden Markov models (HMMs) and POMDPs, we establish key properties of the conditional entropy gradient with respect to policy parameters. These properties facilitate efficient policy gradient computation. We validate our approach through graph-based examples, inspired by common security applications with UAV surveillance.

Paper number 6:
Title: Implementation of Field Programmable Gate Arrays (FPGAs) in Extremely Cold Environments for Space and Cryogenic Computing Applications
Authors: Christopher Lewis, Drew Sellers, Michael Hamilton
Abstract: The operation of CMOS Field Programmable Gate Arrays (FPGAs) at extremely cold environments as low as 4 K is demonstrated. Various FPGA and periphery hardware design techniques spanning from HDL design to improvements of peripheral circuitry such as discrete voltage regulators are displayed, and their respective performances are reported. While general operating conditions for voltage regulators are widened, FPGAs see a broader temperature range with improved jitter performance, reduced LUT delays, and enhanced transceiver performance at extremely low temperatures.

Paper number 7:
Title: Focus3D: A Practical Method to Adaptively Focus ISAR Data and Provide 3-D Information for Automatic Target Recognition
Authors: John R. Bennett
Abstract: To improve ATR identification of ships at sea requires an advanced ISAR processor - one that not only provides focused images but can also determine the pose of the ship. This tells us whether the image shows a profile (vertical plane) view, a plan (horizontal plane) view or some view in between. If the processor can provide this information, then the ATR processor can try to match the images with known vertical or horizontal features of ships and, in conjunction with estimated ship length, narrow the set of possible identifications. This paper extends the work of Melendez and Bennett [M-B, Ref. 1] by combining a focus algorithm with a method that models the angles of the ship relative to the radar. In M-B the algorithm was limited to a single angle and the plane of rotation was not determined. This assumption may be fine for a short time image where there is limited data available to determine the pose. However, the present paper models the ship rotation with two angles - aspect angle, representing rotation in the horizontal plane, and tilt angle, representing variations in the effective grazing angle to the ship.

Paper number 8:
Title: Robust Estimation of Battery State of Health Using Reference Voltage Trajectory
Authors: Rui Huang, Jackson Fogelquist, Xinfan Lin
Abstract: Accurate estimation of state of health (SOH) is critical for battery applications. Current model-based SOH estimation methods typically rely on low C-rate constant current tests to extract health parameters like solid phase volume fraction and lithium-ion stoichiometry, which are often impractical in real-world scenarios due to time and operational constraints. Additionally, these methods are susceptible to modeling uncertainties that can significantly degrade the estimation accuracy, especially when jointly estimating multiple parameters. In this paper, we present a novel reference voltage-based method for robust battery SOH estimation. This method utilizes the voltage response of a battery under a predefined current excitation at the beginning of life (BOL) as a reference to compensate for modeling uncertainty. As the battery degrades, the same excitation is applied to generate the voltage response, which is compared with the BOL trajectory to estimate the key health parameters accurately. The current excitation is optimally designed using the Particle Swarm Optimization algorithm to maximize the information content of the target parameters. Simulation results demonstrate that our proposed method significantly improves parameter estimation accuracy under different degradation levels, compared to conventional methods relying only on direct voltage measurements. Furthermore, our method jointly estimates four key SOH parameters in only 10 minutes, making it practical for real-world battery health diagnostics, e.g., fast testing to enable battery repurposing.

Paper number 9:
Title: Putting the Segment Anything Model to the Test with 3D Knee MRI -- A Comparison with State-of-the-Art Performance
Authors: Oliver Mills, Philip Conaghan, Nishant Ravikumar, Samuel Relton
Abstract: Menisci are cartilaginous tissue found within the knee that contribute to joint lubrication and weight dispersal. Damage to menisci can lead to onset and progression of knee osteoarthritis (OA), a condition that is a leading cause of disability, and for which there are few effective therapies. Accurate automated segmentation of menisci would allow for earlier detection and treatment of meniscal abnormalities, as well as shedding more light on the role the menisci play in OA pathogenesis. Focus in this area has mainly used variants of convolutional networks, but there has been no attempt to utilise recent large vision transformer segmentation models. The Segment Anything Model (SAM) is a so-called foundation segmentation model, which has been found useful across a range of different tasks due to the large volume of data used for training the model. In this study, SAM was adapted to perform fully-automated segmentation of menisci from 3D knee magnetic resonance images. A 3D U-Net was also trained as a baseline. It was found that, when fine-tuning only the decoder, SAM was unable to compete with 3D U-Net, achieving a Dice score of $0.81\pm0.03$, compared to $0.87\pm0.03$, on a held-out test set. When fine-tuning SAM end-to-end, a Dice score of $0.87\pm0.03$ was achieved. The performance of both the end-to-end trained SAM configuration and the 3D U-Net were comparable to the winning Dice score ($0.88\pm0.03$) in the IWOAI Knee MRI Segmentation Challenge 2019. Performance in terms of the Hausdorff Distance showed that both configurations of SAM were inferior to 3D U-Net in matching the meniscus morphology. Results demonstrated that, despite its generalisability, SAM was unable to outperform a basic 3D U-Net in meniscus segmentation, and may not be suitable for similar 3D medical image segmentation tasks also involving fine anatomical structures with low contrast and poorly-defined boundaries.

Paper number 10:
Title: Integration of a Graph-Based Path Planner and Mixed-Integer MPC for Robot Navigation in Cluttered Environments
Authors: Joshua A. Robbins, Stephen J. Harnett, Andrew F. Thompson, Sean Brennan, Herschel C. Pangborn
Abstract: The ability to update a path plan is a required capability for autonomous mobile robots navigating through uncertain environments. This paper proposes a re-planning strategy using a multilayer planning and control framework for cases where the robot's environment is partially known. A medial axis graph-based planner defines a global path plan based on known obstacles where each edge in the graph corresponds to a unique corridor. A mixed-integer model predictive control (MPC) method detects if a terminal constraint derived from the global plan is infeasible, subject to a non-convex description of the local environment. Infeasibility detection is used to trigger efficient global re-planning via medial axis graph edge deletion. The proposed re-planning strategy is demonstrated experimentally.

Paper number 11:
Title: Accelerated Optimization of Implicit Neural Representations for CT Reconstruction
Authors: Mahrokh Najaf, Gregory Ongie
Abstract: Inspired by their success in solving challenging inverse problems in computer vision, implicit neural representations (INRs) have been recently proposed for reconstruction in low-dose/sparse-view X-ray computed tomography (CT). An INR represents a CT image as a small-scale neural network that takes spatial coordinates as inputs and outputs attenuation values. Fitting an INR to sinogram data is similar to classical model-based iterative reconstruction methods. However, training INRs with losses and gradient-based algorithms can be prohibitively slow, taking many thousands of iterations to converge. This paper investigates strategies to accelerate the optimization of INRs for CT reconstruction. In particular, we propose two approaches: (1) using a modified loss function with improved conditioning, and (2) an algorithm based on the alternating direction method of multipliers. We illustrate that both of these approaches significantly accelerate INR-based reconstruction of a synthetic breast CT phantom in a sparse-view setting.

Paper number 12:
Title: Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning
Authors: Racheal Mukisa, Arvind K. Bansal
Abstract: Automated noninvasive cardiac diagnosis plays a critical role in the early detection of cardiac disorders and cost-effective clinical management. Automated diagnosis involves the automated segmentation and analysis of cardiac images. Precise delineation of cardiac substructures and extraction of their morphological attributes are essential for evaluating the cardiac function, and diagnosing cardiovascular disease such as cardiomyopathy, valvular diseases, abnormalities related to septum perforations, and blood-flow rate. Semantic segmentation labels the CMR image at the pixel level, and localizes its subcomponents to facilitate the detection of abnormalities, including abnormalities in cardiac wall motion in an aging heart with muscle abnormalities, vascular abnormalities, and valvular abnormalities. In this paper, we describe a model to improve semantic segmentation of CMR images. The model extracts edge-attributes and context information during down-sampling of the U-Net and infuses this information during up-sampling to localize three major cardiac structures: left ventricle cavity (LV); right ventricle cavity (RV); and LV myocardium (LMyo). We present an algorithm and performance results. A comparison of our model with previous leading models, using similarity metrics between actual image and segmented image, shows that our approach improves Dice similarity coefficient (DSC) by 2%-11% and lowers Hausdorff distance (HD) by 1.6 to 5.7 mm.

Paper number 13:
Title: A Deep Learning-Based Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections
Authors: Bo Zhou, Kaijie Xu, Yinghui Quan, Mengdao Xing
Abstract: In practical scenarios, processes such as sensor design, manufacturing, and installation will introduce certain errors. Furthermore, mutual interference occurs when the sensors receive signals. These defects in array systems are referred to as array imperfections, which can significantly degrade the performance of Direction of Arrival (DOA) estimation. In this study, we propose a deep-learning based transfer learning approach, which effectively mitigates the degradation of deep-learning based DOA estimation performance caused by array imperfections. In the proposed approach, we highlight three major contributions. First, we propose a Vision Transformer (ViT) based method for DOA estimation, which achieves excellent performance in scenarios with low signal-to-noise ratios (SNR) and limited snapshots. Second, we introduce a transfer learning framework that extends deep learning models from ideal simulation scenarios to complex real-world scenarios with array imperfections. By leveraging prior knowledge from ideal simulation data, the proposed transfer learning framework significantly improves deep learning-based DOA estimation performance in the presence of array imperfections, without the need for extensive real-world data. Finally, we incorporate visualization and evaluation metrics to assess the performance of DOA estimation algorithms, which allow for a more thorough evaluation of algorithms and further validate the proposed method. Our code can be accessed at this https URL.

Paper number 14:
Title: Documentation on Encrypted Dynamic Control Simulation Code using Ring-LWE based Cryptosystems
Authors: Yeongjun Jang, Joowon Lee, Junsoo Kim
Abstract: Encrypted controllers offer secure computation by employing modern cryptosystems to execute control operations directly over encrypted data without decryption. However, incorporating cryptosystems into dynamic controllers significantly increases the computational load. This paper aims to provide an accessible guideline for running encrypted controllers using an open-source library Lattigo, which supports an efficient implementation of Ring-Learing With Errors (LWE) based encrypted controllers, and our explanations are assisted with example codes that are fully available at this https URL.

Paper number 15:
Title: DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images
Authors: Racheal Mukisa, Arvind K. Bansal
Abstract: We propose an enhanced deep learning-based model for image segmentation of the left and right ventricles and myocardium scar tissue from cardiac magnetic resonance (CMR) images. The proposed technique integrates UNet, channel and spatial attention, edge-detection based skip-connection and deep supervised learning to improve the accuracy of the CMR image-segmentation. Images are processed using multiple channels to generate multiple feature-maps. We built a dual attention-based model to integrate channel and spatial attention. The use of extracted edges in skip connection improves the reconstructed images from feature-maps. The use of deep supervision reduces vanishing gradient problems inherent in classification based on deep neural networks. The algorithms for dual attention-based model, corresponding implementation and performance results are described. The performance results show that this approach has attained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower Hausdorff Distance (HD). The performance results outperform other leading techniques both in DSC and HD.

Paper number 16:
Title: Modular XL-Array-Enabled 3-D Localization based on Hybrid Spherical-Planar Wave Model in Terahertz Systems
Authors: Yang Zhang, Ruidong Li, Cunhua Pan, Hong Ren, Tuo Wu, Changhong Wang
Abstract: This work considers the three-dimensional (3-D) positioning problem in a Terahertz (THz) system enabled by a modular extra-large (XL) array with sub-connected architecture. Our purpose is to estimate the Cartesian Coordinates of multiple user equipments (UEs) with the received signal of the RF chains while considering the spatial non-stationarity (SNS). We apply the hybrid spherical-planar wave model (HSPWM) as the channel model owing to the structual feature of the modular array, and propose a 3-D localization algorithm with relatively high accuracy and low complexity. Specifically, we first distinguish the visible sub-arrays (SAs) located in the VR and estimate the angles-of-arrival (AoAs) from each UE to typical visible SAs with the largest receive power via compressed sensing (CS) method. In addition, we apply the weighted least square (WLS) method to obtain a coarse 3-D position estimation of each UE according to the AoA estimations. Then, we estimate the AoAs of the other SAs with a reduced dictionary (RD)-CS-based method for lower computational complexity, and utilize all the efficient AoA estimations to derive a fine position estimation. Simulation results indicate that the proposed positioning framework based on modular XL-array can achieve satisfactory accuracy with evident reduction in complexity. Furthermore, the deployment of SAs and the allocation of antenna elements need to be specially designed for better positioning performance.

Paper number 17:
Title: Accurate semiclassical analysis of light propagation on tilted hyperplanes
Authors: Patrick Gioia, San Vu Ngoc (IUF, IRMAR)
Abstract: In the scalar light model given by Helmholtz' equation in R^{1+d} , we consider the transformation of an initial scene (a hologram) in {0}xR^d by an arbitrary affine transformation (which can be viewed as a propagation into a tilted hyperplane). In the high frequency regime, we use microlocal and semiclassical analysis to describe the propagator as a semiclassical Fourier integral operator, thus generalising the well-known Angular Spectrum formula from optics. We then prove new precise Egorov theorems, including subprincipal terms, which indicate how to take into account the propagation along rays of geometric optics.

Paper number 18:
Title: Block-Weighted Lasso for Joint Optimization of Memory Depth and Kernels in Wideband DPD
Authors: Jinfei Wang, Yi Ma, Fei Tong, Ziming He
Abstract: The optimizations of both memory depth and kernel functions are critical for wideband digital pre-distortion (DPD). However, the memory depth is usually determined via exhaustive search over a wide range for the sake of linearization optimality, followed by the kernel selection of each memory depth, yielding excessive computational cost. In this letter, we aim to provide an efficient solution that jointly optimizes the memory depth and kernels while preserving reasonable linearization performance. Specifically, we propose to formulate this optimization as a blockweighted least absolute shrinkage and selection operator (Lasso) problem, where kernels are assigned regularization weights based on their polynomial orders. Then, a block coordinate descent algorithm is introduced to solve the block-weighted Lasso problem. Measurement results on a generalized memory polynomial (GMP) model demonstrates that our proposed solution reduces memory depth by 31.6% and kernel count by 85% compared to the full GMP, while achieving -46.4 dB error vector magnitude (EVM) for signals of 80 MHz bandwidth. In addition, the proposed solution outperforms both the full GMP and the GMP pruned by standard Lasso by at least 0.7 dB in EVM.

Paper number 19:
Title: Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for Low-Dose CT with Attention-Guided Bilateral Filtering
Authors: Yipeng Sun, Linda-Sophie Schneider, Mingxuan Gu, Siyuan Mei, Chengze Ye, Fabian Wagner, Siming Bayer, Andreas Maier
Abstract: Effective denoising is crucial in low-dose CT to enhance subtle structures and low-contrast lesions while preventing diagnostic errors. Supervised methods struggle with limited paired datasets, and self-supervised approaches often require multiple noisy images and rely on deep networks like U-Net, offering little insight into the denoising mechanism. To address these challenges, we propose an interpretable self-supervised single-image denoising framework -- Filter2Noise (F2N). Our approach introduces an Attention-Guided Bilateral Filter that adapted to each noisy input through a lightweight module that predicts spatially varying filter parameters, which can be visualized and adjusted post-training for user-controlled denoising in specific regions of interest. To enable single-image training, we introduce a novel downsampling shuffle strategy with a new self-supervised loss function that extends the concept of Noise2Noise to a single image and addresses spatially correlated noise. On the Mayo Clinic 2016 low-dose CT dataset, F2N outperforms the leading self-supervised single-image method (ZS-N2N) by 4.59 dB PSNR while improving transparency, user control, and parametric efficiency. These features provide key advantages for medical applications that require precise and interpretable noise reduction. Our code is demonstrated at this https URL .

Paper number 20:
Title: A Novel Hybrid Approach for Retinal Vessel Segmentation with Dynamic Long-Range Dependency and Multi-Scale Retinal Edge Fusion Enhancement
Authors: Yihao Ouyang, Xunheng Kuang, Mengjia Xiong, Zhida Wang, Yuanquan Wang
Abstract: Accurate retinal vessel segmentation provides essential structural information for ophthalmic image analysis. However, existing methods struggle with challenges such as multi-scale vessel variability, complex curvatures, and ambiguous boundaries. While Convolutional Neural Networks (CNNs), Transformer-based models and Mamba-based architectures have advanced the field, they often suffer from vascular discontinuities or edge feature ambiguity. To address these limitations, we propose a novel hybrid framework that synergistically integrates CNNs and Mamba for high-precision retinal vessel segmentation. Our approach introduces three key innovations: 1) The proposed High-Resolution Edge Fuse Network is a high-resolution preserving hybrid segmentation framework that combines a multi-scale backbone with the Multi-scale Retina Edge Fusion (MREF) module to enhance edge features, ensuring accurate and robust vessel segmentation. 2) The Dynamic Snake Visual State Space block combines Dynamic Snake Convolution with Mamba to adaptively capture vessel curvature details and long-range dependencies. An improved eight-directional 2D Snake-Selective Scan mechanism and a dynamic weighting strategy enhance the perception of complex vascular topologies. 3) The MREF module enhances boundary precision through multi-scale edge feature aggregation, suppressing noise while emphasizing critical vessel structures across scales. Experiments on three public datasets demonstrate that our method achieves state-of-the-art performance, particularly in maintaining vascular continuity and effectively segmenting vessels in low-contrast regions. This work provides a robust method for clinical applications requiring accurate retinal vessel analysis. The code is available at this https URL.

Paper number 21:
Title: Integrated Super-resolution Sensing and Symbiotic Communication with 3D Sparse MIMO for Low-Altitude UAV Swarm
Authors: Jingran Xu, Hongqi Min, Yong Zeng
Abstract: Low-altitude unmanned aerial vehicle (UAV) swarms are expected to play important role for future intelligent aerial systems due to their great potential to cooperatively accomplish complicated missions effectively. However, there are important challenges to be addressed to enable their efficient operation: the large-scale nature of swarms usually leads to excessive spectrum consumption, and ultra-low cost requirements for individual UAVs renders it necessary to develop more cost-effective communication modules. In addition, the densely located swarm UAVs require high resolution for localization and sensing. To address the above challenges and simultaneously achieve spectrum and energy-efficient communication and accurate sensing, we investigate low-altitude UAV swarm with integrated super-resolution sensing and symbiotic communication technology. Specifically, one leading UAV may act as a primary transmitter (PT) to transmit communication signals to the base station (BS), and the remaining nearby UAVs in the swarm act as passive backscatter devices (BDs), which can modulate their information by efficiently backscattering the radio frequency (RF) signals from the PT without consuming extra spectrum or power. In addition, to achieve efficient three-dimensional (3D) super-resolution sensing for the densely located UAV swarm, 3D sparse multiple-input multiple-output (MIMO) technology and super-resolution signal processing algorithms are further exploited, where both L-shaped nested array (LNA) and planar nested arrays (PNA) are considered at the BS. To evaluate the communication and sensing performance for the UAV-symbiotic radio (SR) system, the achievable rates of UAV swarm are derived and the beam patterns of sparse LNA, PNA and the benchmarking compact uniform planar array (UPA) are compared.

Paper number 22:
Title: FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention
Authors: Jun Zeng, KC Santosh, Deepak Rajan Nayak, Thomas de Lange, Jonas Varkey, Tyler Berzin, Debesh Jha
Abstract: Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular screenings can effectively prevent benign polyps from progressing to CRC. While deep learning has made impressive strides in polyp segmentation, most existing models are trained on single-modality and single-center data, making them less effective in real-world clinical environments. To overcome these limitations, we propose FocusNet, a Transformer-enhanced focus attention network designed to improve polyp segmentation. FocusNet incorporates three essential modules: the Cross-semantic Interaction Decoder Module (CIDM) for generating coarse segmentation maps, the Detail Enhancement Module (DEM) for refining shallow features, and the Focus Attention Module (FAM), to balance local detail and global context through local and pooling attention mechanisms. We evaluate our model on PolypDB, a newly introduced dataset with multi-modality and multi-center data for building more reliable segmentation methods. Extensive experiments showed that FocusNet consistently outperforms existing state-of-the-art approaches with a high dice coefficients of 82.47% on the BLI modality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI modality, demonstrating its accuracy and robustness across five different modalities. The source code for FocusNet is available at this https URL.

Paper number 23:
Title: ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation
Authors: Bowen Liu, Chunlei Meng, Wei Lin, Hongda Zhang, Ziqing Zhou, Zhongxue Gan, Chun Ouyang
Abstract: Accurate vascular segmentation is essential for coronary visualization and the diagnosis of coronary heart disease. This task involves the extraction of sparse tree-like vascular branches from the volumetric space. However, existing methods have faced significant challenges due to discontinuous vascular segmentation and missing endpoints. To address this issue, a 3D vision graph neural network framework, named ViG3D-UNet, was introduced. This method integrates 3D graph representation and aggregation within a U-shaped architecture to facilitate continuous vascular segmentation. The ViG3D module captures volumetric vascular connectivity and topology, while the convolutional module extracts fine vascular details. These two branches are combined through channel attention to form the encoder feature. Subsequently, a paperclip-shaped offset decoder minimizes redundant computations in the sparse feature space and restores the feature map size to match the original input dimensions. To evaluate the effectiveness of the proposed approach for continuous vascular segmentation, evaluations were performed on two public datasets, ASOCA and ImageCAS. The segmentation results show that the ViG3D-UNet surpassed competing methods in maintaining vascular segmentation connectivity while achieving high segmentation accuracy. Our code will be available soon.

Paper number 24:
Title: Design Of a Dual-band Patch Antenna with Stacked Structure
Authors: Xunchi Ma
Abstract: This project presents the design, simulation, and fabrication of a compact dual-band patch antenna using a stacked structure, targeting 2.25 to 2.35 GHz and 5.6 to 5.8 GHz ISM bands. A stacked configuration was chosen over a slotted design for its better performance, featuring two copper patches separated by dielectrics, with a single feed line and a 5 mm patch offset to enhance coupling. Simulations showed strong return loss and directional gain in both bands. Although physical testing was limited due to equipment constraints, the prototype met design expectations, demonstrating potential for use in compact wireless and embedded systems.

Paper number 25:
Title: SupResDiffGAN a new approach for the Super-Resolution task
Authors: Dawid Kopeć, Wojciech Kozłowski, Maciej Wizerkaniuk, Dawid Krutul, Jan Kocoń, Maciej Zięba
Abstract: In this work, we present SupResDiffGAN, a novel hybrid architecture that combines the strengths of Generative Adversarial Networks (GANs) and diffusion models for super-resolution tasks. By leveraging latent space representations and reducing the number of diffusion steps, SupResDiffGAN achieves significantly faster inference times than other diffusion-based super-resolution models while maintaining competitive perceptual quality. To prevent discriminator overfitting, we propose adaptive noise corruption, ensuring a stable balance between the generator and the discriminator during training. Extensive experiments on benchmark datasets show that our approach outperforms traditional diffusion models such as SR3 and I$^2$SB in efficiency and image quality. This work bridges the performance gap between diffusion- and GAN-based methods, laying the foundation for real-time applications of diffusion models in high-resolution image generation.

Paper number 26:
Title: PV-VLM: A Multimodal Vision-Language Approach Incorporating Sky Images for Intra-Hour Photovoltaic Power Forecasting
Authors: Huapeng Lin, Miao Yu
Abstract: The rapid proliferation of solar energy has significantly expedited the integration of photovoltaic (PV) systems into contemporary power grids. Considering that the cloud dynamics frequently induce rapid fluctuations in solar irradiance, accurate intra-hour forecasting is critical for ensuring grid stability and facilitating effective energy management. To leverage complementary temporal, textual, and visual information, this paper has proposed PV-VLM, a multimodal forecasting framework that integrates temporal, textual, and visual information by three modules. The Time-Aware Module employed a PatchTST-inspired Transformer to capture both local and global dependencies in PV power time series. Meanwhile, the Prompt-Aware Module encodes textual prompts from historical statistics and dataset descriptors via a large language model. Additionally, the Vision-Aware Module utilizes a pretrained vision-language model to extract high-level semantic features from sky images, emphasizing cloud motion and irradiance fluctuations. The proposed PV-VLM is evaluated using data from a 30-kW rooftop array at Stanford University and through a transfer study on PV systems at the University of Wollongong in Australia. Comparative experiments reveal an average RMSE reduction of approximately 5% and a MAE improvement of nearly 6%, while the transfer study shows average RMSE and MAE reductions of about 7% and 9.5%, respectively. Overall, PV-VLM leverages complementary modalities to provide a robust solution for grid scheduling and energy market participation, enhancing the stability and reliability of PV integration.

Paper number 27:
Title: Physical Layer Authentication With Colored RIS in Visible Light Communications
Authors: Besra Cetindere Vela, Serkan Vela, Stefano Tomasin
Abstract: We study a visible light communication (VLC) system that employs a colored reconfigurable intelligent surface (CRIS) based on dichroic mirrors that reflect light at tunable frequencies. A verifier can use the CRIS to authenticate transmissions by comparing received multicolor power profiles with expected patterns. Four CRIS configuration strategies are evaluated: a deterministic cyclic pattern, static random reflectance, dynamic random reflectance, and dynamic random permutation of fixed profiles. Randomized configurations, especially dynamic ones, achieve superior authentication, enabling a novel challenge-response physical-layer authentication scheme over CRIS.

Paper number 28:
Title: Pinching-Antenna Systems (PASS)-enabled Secure Wireless Communications
Authors: Guangyu Zhu, Xidong Mu, Li Guo, Shibiao Xu, Yuanwei Liu, Naofal Al-Dhahir
Abstract: A novel pinching-antenna systems (PASS)-enabled secure wireless communication framework is proposed. By dynamically adjusting the positions of dielectric particles, namely pinching antennas (PAs), along the waveguides, PASS introduces a novel concept of pinching beamforming to enhance the performance of physical layer security. A fundamental PASS-enabled secure communication system is considered with one legitimate user and one eavesdropper. Both single-waveguide and multiple-waveguide scenarios are studied. 1) For the single-waveguide scenario, the secrecy rate (SR) maximization is formulated to optimize the pinching beamforming. A PA-wise successive tuning (PAST) algorithm is proposed, which ensures constructive signal superposition at the legitimate user while inducing a destructive legitimate signal at the eavesdropper. 2) For the multiple-waveguide scenario, artificial noise (AN) is employed to further improve secrecy performance. A pair of practical transmission architectures are developed: waveguide division (WD) and waveguide multiplexing (WM). The key difference lies in whether each waveguide carries a single type of signal or a mixture of signals with baseband beamforming. For the SR maximization problem under the WD case, a two-stage algorithm is developed, where the pinching beamforming is designed with the PAST algorithm and the baseband power allocation among AN and legitimate signals is solved using successive convex approximation (SCA). For the WM case, an alternating optimization algorithm is developed, where the baseband beamforming is optimized with SCA and the pinching beamforming is designed employing particle swarm optimization.

Paper number 29:
Title: Inverse Inference on Cooperative Control of Networked Dynamical Systems
Authors: Yushan Li, Jianping He, Dimos V. Dimarogonas
Abstract: Recent years have witnessed the rapid advancement of understanding the control mechanism of networked dynamical systems (NDSs), which are governed by components such as nodal dynamics and topology. This paper reveals that the critical components in continuous-time state feedback cooperative control of NDSs can be inferred merely from discrete observations. In particular, we advocate a bi-level inference framework to estimate the global closed-loop system and extract the components, respectively. The novelty lies in bridging the gap from discrete observations to the continuous-time model and effectively decoupling the concerned components. Specifically, in the first level, we design a causality-based estimator for the discrete-time closed-loop system matrix, which can achieve asymptotically unbiased performance when the NDS is stable. In the second level, we introduce a matrix logarithm based method to recover the continuous-time counterpart matrix, providing new sampling period guarantees and establishing the recovery error bound. By utilizing graph properties of the NDS, we develop least square based procedures to decouple the concerned components with up to a scalar ambiguity. Furthermore, we employ inverse optimal control techniques to reconstruct the objective function driving the control process, deriving necessary conditions for the solutions. Numerical simulations demonstrate the effectiveness of the proposed method.

Paper number 30:
Title: QoS-Aware NOMA Design for Downlink Pinching-Antenna Systems
Authors: Yanqing Xu, Zhiguo Ding, Donghong Cai, Vincent W.S. Wong
Abstract: Pinching antennas, implemented by applying small dielectric particles on a waveguide, have emerged as a promising flexible-antenna technology ideal for next-generation wireless communications systems. Unlike conventional flexible-antenna systems, pinching antennas offer the advantage of creating line-of-sight links by enabling antennas to be activated on the waveguide at a location close to the user. This paper investigates a typical two-user non-orthogonal multiple access (NOMA) downlink scenario, where multiple pinching antennas are activated on a single dielectric waveguide to assist NOMA transmission. We formulate the problem of maximizing the data rate of one user subject to the quality-of-service requirement of the other user by jointly optimizing the antenna locations and power allocation coefficients. The formulated problem is nonconvex and difficult to solve due to the impact of antenna locations on large-scale path loss and two types of phase shifts, namely in-waveguide phase shifts and free space propagation phase shifts. To this end, we propose an iterative algorithm based on block coordinate descent and successive convex approximation techniques. Moreover, we consider the special case with a single pinching antenna, which is a simplified version of the multi-antenna case. Although the formulated problem is still nonconvex, by using the inherent features of the formulated problem, we derive the global optimal solution in closed-form, which offers important insights on the performance of pinching-antenna systems. Simulation results demonstrate that the pinching-antenna system significantly outperforms conventional fixed-position antenna systems, and the proposed algorithm achieves performance comparable to the computationally intensive exhaustive search based approach.

Paper number 31:
Title: Modeling L1 Influence on L2 Pronunciation: An MFCC-Based Framework for Explainable Machine Learning and Pedagogical Feedback
Authors: Peyman Jahanbin
Abstract: This study investigates the extent to which Mel-Frequency Cepstral Coefficients (MFCCs) capture first language (L1) transfer in extended second language (L2) English speech. Speech samples from Mandarin and American English L1 speakers were extracted from the GMU Speech Accent Archive, converted to WAV format, and processed to obtain thirteen MFCCs per speaker. A multi-method analytic framework combining inferential statistics (t-tests, MANOVA, Canonical Discriminant Analysis) and machine learning (Random Forest classification) identified MFCC-1 (broadband energy), MFCC-2 (first formant region), and MFCC-5 (voicing and fricative energy) as the most discriminative features for distinguishing L1 backgrounds. A reduced-feature model using these MFCCs significantly outperformed the full-feature model, as confirmed by McNemar's test and non-overlapping confidence intervals. The findings empirically support the Perceptual Assimilation Model for L2 (PAM-L2) and the Speech Learning Model (SLM), demonstrating that L1-conditioned variation in L2 speech is both perceptually grounded and acoustically quantifiable. Methodologically, the study contributes to applied linguistics and explainable AI by proposing a transparent, data-efficient pipeline for L2 pronunciation modeling. The results also offer pedagogical implications for ESL/EFL instruction by highlighting L1-specific features that can inform intelligibility-oriented instruction, curriculum design, and speech assessment tools.

Paper number 32:
Title: Cellular-X: An LLM-empowered Cellular Agent for Efficient Base Station Operations
Authors: Liujianfu Wang, Xinyi Long, Yuyang Du, Xiaoyan Liu, Kexin Chen, Soung Chang Liew
Abstract: This paper introduces Cellular-X, an LLM-powered agent designed to automate cellular base station (BS) maintenance. Leveraging multimodal LLM and retrieval-augmented generation (RAG) techniques, Cellular-X significantly enhances field engineer efficiency by quickly interpreting user intents, retrieving relevant technical information, and configuring a BS through iterative self-correction. Key features of the demo include automatic customized BS setup, document-based query answering, and voice-controlled configuration reporting and revision. We implemented Cellular-X on a USRP X310 testbed for demonstration. Demo videos and implementation details are available at this https URL.

Paper number 33:
Title: Wavelet-based Variational Autoencoders for High-Resolution Image Generation
Authors: Andrew Kiruluta
Abstract: Variational Autoencoders (VAEs) are powerful generative models capable of learning compact latent representations. However, conventional VAEs often generate relatively blurry images due to their assumption of an isotropic Gaussian latent space and constraints in capturing high-frequency details. In this paper, we explore a novel wavelet-based approach (Wavelet-VAE) in which the latent space is constructed using multi-scale Haar wavelet coefficients. We propose a comprehensive method to encode the image features into multi-scale detail and approximation coefficients and introduce a learnable noise parameter to maintain stochasticity. We thoroughly discuss how to reformulate the reparameterization trick, address the KL divergence term, and integrate wavelet sparsity principles into the training objective. Our experimental evaluation on CIFAR-10 and other high-resolution datasets demonstrates that the Wavelet-VAE improves visual fidelity and recovers higher-resolution details compared to conventional VAEs. We conclude with a discussion of advantages, potential limitations, and future research directions for wavelet-based generative modeling.

Paper number 34:
Title: Leveraging Functional Encryption and Deep Learning for Privacy-Preserving Traffic Forecasting
Authors: Isaac Adom, Mohammmad Iqbal Hossain, Hassan Mahmoud, Ahmad Alsharif, Mahmoud Nabil Mahmoud, Yang Xiao
Abstract: Over the past few years, traffic congestion has continuously plagued the nation's transportation system creating several negative impacts including longer travel times, increased pollution rates, and higher collision risks. To overcome these challenges, Intelligent Transportation Systems (ITS) aim to improve mobility and vehicular systems, ensuring higher levels of safety by utilizing cutting-edge technologies, sophisticated sensing capabilities, and innovative algorithms. Drivers' participatory sensing, current/future location reporting, and machine learning algorithms have considerably improved real-time congestion monitoring and future traffic management. However, each driver's sensitive spatiotemporal location information can create serious privacy concerns. To address these challenges, we propose in this paper a secure, privacy-preserving location reporting and traffic forecasting system that guarantees privacy protection of driver data while maintaining high traffic forecasting accuracy. Our novel k-anonymity scheme utilizes functional encryption to aggregate encrypted location information submitted by drivers while ensuring the privacy of driver location data. Additionally, using the aggregated encrypted location information as input, this research proposes a deep learning model that incorporates a Convolutional-Long Short-Term Memory (Conv-LSTM) module to capture spatial and short-term temporal features and a Bidirectional Long Short-Term Memory (Bi-LSTM) module to recover long-term periodic patterns for traffic forecasting. With extensive evaluation on real datasets, we demonstrate the effectiveness of the proposed scheme with less than 10% mean absolute error for a 60-minute forecasting horizon, all while protecting driver privacy.

Paper number 35:
Title: Acoustic to Articulatory Inversion of Speech; Data Driven Approaches, Challenges, Applications, and Future Scope
Authors: Leena G Pillai, D. Muhammad Noorul Mubarak
Abstract: This review is focused on the data-driven approaches applied in different applications of Acoustic-to-Articulatory Inversion (AAI) of speech. This review paper considered the relevant works published in the last ten years (2011-2021). The selection criteria includes (a) type of AAI - Speaker Dependent and Speaker Independent AAI, (b) objectives of the work - Articulatory approximation, Articulatory Feature space selection and Automatic Speech Recognition (ASR), explore the correlation between acoustic and articulatory features, and framework for Computer-assisted language training, (c) Corpus - Simultaneously recorded speech (wav) and medical imaging models such as ElectroMagnetic Articulography (EMA), Electropalatography (EPG), Laryngography, Electroglottography (EGG), X-ray Cineradiography, Ultrasound, and real-time Magnetic Resonance Imaging (rtMRI), (d) Methods or models - recent works are considered, and therefore all the works are based on machine learning, (e) Evaluation - as AAI is a non-linear regression problem, the performance evaluation is mostly done by Correlation Coefficient (CC), Root Mean Square Error (RMSE), and also considered Mean Square Error (MSE), and Mean Format Error (MFE). The practical application of the AAI model can provide a better and user-friendly interpretable image feedback system of articulatory positions, especially tongue movement. Such trajectory feedback system can be used to provide phonetic, language, and speech therapy for pathological subjects.

Paper number 36:
Title: Stability of Polling Systems for a Large Class of Markovian Switching Policies
Authors: Konstantin Avrachenkov, Kousik Das, Veeraruna Kavitha, Vartika Singh
Abstract: We consider a polling system with two queues, where a single server is attending the queues in a cyclic order and requires non-zero switching times to switch between the queues. Our aim is to identify a fairly general and comprehensive class of Markovian switching policies that renders the system stable. Potentially a class of policies that can cover the Pareto frontier related to individual-queue-centric performance measures like the stationary expected number of waiting customers in each queue; for instance, such a class of policies is identified recently for a polling system near the fluid regime (with large arrival and departure rates), and we aim to include that class. We also aim to include a second class that facilitates switching between the queues at the instance the occupancy in the opposite queue crosses a threshold and when that in the visiting queue is below a threshold (this inclusion facilitates design of `robust' polling systems). Towards this, we consider a class of two-phase switching policies, which includes the above mentioned classes. In the maximum generality, our policies can be represented by eight parameters, while two parameters are sufficient to represent the aforementioned classes. We provide simple conditions to identify the sub-class of switching policies that ensure system stability. By numerically tuning the parameters of the proposed class, we illustrate that the proposed class can cover the Pareto frontier for the stationary expected number of customers in the two queues.

Paper number 37:
Title: AI-Empowered Integrated Sensing and Communications
Authors: Mojtaba Vaezi, Gayan Aruma Baduge, Esa Ollila, Sergiy A. Vorobyov
Abstract: Integrating sensing and communication (ISAC) can help overcome the challenges of limited spectrum and expensive hardware, leading to improved energy and cost efficiency. While full cooperation between sensing and communication can result in significant performance gains, achieving optimal performance requires efficient designs of unified waveforms and beamformers for joint sensing and communication. Sophisticated statistical signal processing and multi-objective optimization techniques are necessary to balance the competing design requirements of joint sensing and communication tasks. Since model-based analytical approaches may be suboptimal or overly complex, deep learning emerges as a powerful tool for developing data-driven signal processing algorithms, particularly when optimal algorithms are unknown or when known algorithms are too complex for real-time implementation. Unified waveform and beamformer design problems for ISAC fall into this category, where fundamental design trade-offs exist between sensing and communication performance metrics, and the underlying models may be inadequate or incomplete. This article explores the application of artificial intelligence (AI) in ISAC designs to enhance efficiency and reduce complexity. We emphasize the integration benefits through AI-driven ISAC designs, prioritizing the development of unified waveforms, constellations, and beamforming strategies for both sensing and communication. To illustrate the practical potential of AI-driven ISAC, we present two case studies on waveform and beamforming design, demonstrating how unsupervised learning and neural network-based optimization can effectively balance performance, complexity, and implementation constraints.

Paper number 38:
Title: A Model-Based Approach to Imitation Learning through Multi-Step Predictions
Authors: Haldun Balim, Yang Hu, Yuyang Zhang, Na Li
Abstract: Imitation learning is a widely used approach for training agents to replicate expert behavior in complex decision-making tasks. However, existing methods often struggle with compounding errors and limited generalization, due to the inherent challenge of error correction and the distribution shift between training and deployment. In this paper, we present a novel model-based imitation learning framework inspired by model predictive control, which addresses these limitations by integrating predictive modeling through multi-step state predictions. Our method outperforms traditional behavior cloning numerical benchmarks, demonstrating superior robustness to distribution shift and measurement noise both in available data and during execution. Furthermore, we provide theoretical guarantees on the sample complexity and error bounds of our method, offering insights into its convergence properties.

Paper number 39:
Title: Neural Ganglion Sensors: Learning Task-specific Event Cameras Inspired by the Neural Circuit of the Human Retina
Authors: Haley M. So, Gordon Wetzstein
Abstract: Inspired by the data-efficient spiking mechanism of neurons in the human eye, event cameras were created to achieve high temporal resolution with minimal power and bandwidth requirements by emitting asynchronous, per-pixel intensity changes rather than conventional fixed-frame rate images. Unlike retinal ganglion cells (RGCs) in the human eye, however, which integrate signals from multiple photoreceptors within a receptive field to extract spatio-temporal features, conventional event cameras do not leverage local spatial context when deciding which events to fire. Moreover, the eye contains around 20 different kinds of RGCs operating in parallel, each attuned to different features or conditions. Inspired by this biological design, we introduce Neural Ganglion Sensors, an extension of traditional event cameras that learns task-specific spatio-temporal retinal kernels (i.e., RGC "events"). We evaluate our design on two challenging tasks: video interpolation and optical flow. Our results demonstrate that our biologically inspired sensing improves performance relative to conventional event cameras while reducing overall event bandwidth. These findings highlight the promise of RGC-inspired event sensors for edge devices and other low-power, real-time applications requiring efficient, high-resolution visual streams.

Paper number 40:
Title: An Addendum to NeBula: Towards Extending TEAM CoSTAR's Solution to Larger Scale Environments
Authors: Ali Agha, Kyohei Otsu, Benjamin Morrell, David D. Fan, Sung-Kyun Kim, Muhammad Fadhil Ginting, Xianmei Lei, Jeffrey Edlund, Seyed Fakoorian, Amanda Bouman, Fernando Chavez, Taeyeon Kim, Gustavo J. Correa, Maira Saboia, Angel Santamaria-Navarro, Brett Lopez, Boseong Kim, Chanyoung Jung, Mamoru Sobue, Oriana Claudia Peltzer, Joshua Ott, Robert Trybula, Thomas Touma, Marcel Kaufmann, Tiago Stegun Vaquero, Torkom Pailevanian, Matteo Palieri, Yun Chang, Andrzej Reinke, Matthew Anderson, Frederik E.T. Schöller, Patrick Spieler, Lillian M. Clark, Avak Archanian, Kenny Chen, Hovhannes Melikyan, Anushri Dixit, Harrison Delecki, Daniel Pastor, Barry Ridge, Nicolas Marchal, Jose Uribe, Sharmita Dey, Kamak Ebadi, Kyle Coble, Alexander Nikitas Dimopoulos, Vivek Thangavelu, Vivek S. Varadharajan, Nicholas Palomo, Antoni Rosinol, Arghya Chatterjee, Christoforos Kanellakis, Bjorn Lindqvist, Micah Corah, Kyle Strickland, Ryan Stonebraker, Michael Milano, Christopher E. Denniston, Sami Sahnoune, Thomas Claudet, Seungwook Lee, Gautam Salhotra, Edward Terry, Rithvik Musuku, Robin Schmid, Tony Tran, Ara Kourchians, Justin Schachter, Hector Azpurua, Levi Resende, Arash Kalantari, Jeremy Nash, Josh Lee, Christopher Patterson, Jennifer G. Blank, Kartik Patath, Yuki Kubo, Ryan Alimo, Yasin Almalioglu, Aaron Curtis, Jacqueline Sly, Tesla Wells, Nhut T. Ho, Mykel Kochenderfer, Giovanni Beltrame, George Nikolakopoulos, David Shim, Luca Carlone, Joel Burdick
Abstract: This paper presents an appendix to the original NeBula autonomy solution developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), participating in the DARPA Subterranean Challenge. Specifically, this paper presents extensions to NeBula's hardware, software, and algorithmic components that focus on increasing the range and scale of the exploration environment. From the algorithmic perspective, we discuss the following extensions to the original NeBula framework: (i) large-scale geometric and semantic environment mapping; (ii) an adaptive positioning system; (iii) probabilistic traversability analysis and local planning; (iv) large-scale POMDP-based global motion planning and exploration behavior; (v) large-scale networking and decentralized reasoning; (vi) communication-aware mission planning; and (vii) multi-modal ground-aerial exploration solutions. We demonstrate the application and deployment of the presented systems and solutions in various large-scale underground environments, including limestone mine exploration scenarios as well as deployment in the DARPA Subterranean challenge.

Paper number 41:
Title: Variational Autoencoder Framework for Hyperspectral Retrievals (Hyper-VAE) of Phytoplankton Absorption and Chlorophyll a in Coastal Waters for NASA's EMIT and PACE Missions
Authors: Jiadong Lou, Bingqing Liu, Yuanheng Xiong, Xiaodong Zhang, Xu Yuan
Abstract: Phytoplankton absorb and scatter light in unique ways, subtly altering the color of water, changes that are often minor for human eyes to detect but can be captured by sensitive ocean color instruments onboard satellites from space. Hyperspectral sensors, paired with advanced algorithms, are expected to significantly enhance the characterization of phytoplankton community composition, especially in coastal waters where ocean color remote sensing applications have historically encountered significant challenges. This study presents novel machine learning-based solutions for NASA's hyperspectral missions, including EMIT and PACE, tackling high-fidelity retrievals of phytoplankton absorption coefficient and chlorophyll a from their hyperspectral remote sensing reflectance. Given that a single Rrs spectrum may correspond to varied combinations of inherent optical properties and associated concentrations, the Variational Autoencoder (VAE) is used as a backbone in this study to handle such multi-distribution prediction problems. We first time tailor the VAE model with innovative designs to achieve hyperspectral retrievals of aphy and of Chl-a from hyperspectral Rrs in optically complex estuarine-coastal waters. Validation with extensive experimental observation demonstrates superior performance of the VAE models with high precision and low bias. The in-depth analysis of VAE's advanced model structures and learning designs highlights the improvement and advantages of VAE-based solutions over the mixture density network (MDN) approach, particularly on high-dimensional data, such as PACE. Our study provides strong evidence that current EMIT and PACE hyperspectral data as well as the upcoming Surface Biology Geology mission will open new pathways toward a better understanding of phytoplankton community dynamics in aquatic ecosystems when integrated with AI technologies.

Paper number 42:
Title: Continuous-time filtering in Lie groups: estimation via the Fr{é}chet mean of solutions to stochastic differential equations
Authors: Magalie Bénéfice (IECL, UL), Marc Arnaudon (IMB, UB), Audrey Giremus (IMS, UB)
Abstract: We compute the Fréchet mean $\mathscr{E}_t$ of the solution $X_{t}$ to a continuous-time stochastic differential equation in a Lie group. It provides an estimator with minimal variance of $X_{t}$. We use it in the context of Kalman filtering and more precisely to infer rotation matrices. In this paper, we focus on the prediction step between two consecutive observations. Compared to state-of-the-art approaches, our assumptions on the model are minimal.

Paper number 43:
Title: Beyond-Diagonal Dynamic Metasurface Antenna
Authors: Hugo Prod'homme, Philipp del Hougne
Abstract: Dynamic metasurface antennas (DMAs) are an emerging technology for next-generation wireless base stations, distinguished by hybrid analog/digital beamforming capabilities with low hardware complexity. However, the coupling between meta-atoms is fixed in existing DMAs, which fundamentally constrains the achievable performance. Here, we introduce reconfigurable coupling mechanisms between meta-atoms, yielding finer control over the DMA's analog signal processing capabilities. This novel hardware is coined "beyond-diagonal DMA" (BD-DMA), in line with established BD-RIS terminology. We derive a physics-consistent system model revealing (correlated) "beyond-diagonal" programmability in a reduced basis. We also present an equivalent formulation in a non-reduced basis with (uncorrelated) "diagonal" programmability. Based on the diagonal representation, we propose a general and efficient mutual-coupling-aware optimization algorithm. Physics-consistent simulations validate the performance enhancement enabled by reconfigurable coupling mechanisms in BD-DMAs. The BD-DMA benefits grow with the mutual coupling strength.

Paper number 44:
Title: Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator
Authors: Zinuo You, John Cartlidge, Karen Elliott, Menghan Ge, Daniel Gold
Abstract: Existing portfolio management approaches are often black-box models due to safety and commercial issues in the industry. However, their performance can vary considerably whenever market conditions or internal trading strategies change. Furthermore, evaluating these non-transparent systems is expensive, where certain budgets limit observations of the systems. Therefore, optimizing performance while controlling the potential risk of these financial systems has become a critical challenge. This work presents a novel Bayesian optimization framework to optimize black-box portfolio management models under limited observations. In conventional Bayesian optimization settings, the objective function is to maximize the expectation of performance metrics. However, simply maximizing performance expectations leads to erratic optimization trajectories, which exacerbate risk accumulation in portfolio management. Meanwhile, this can lead to misalignment between the target distribution and the actual distribution of the black-box model. To mitigate this problem, we propose an adaptive weight Lagrangian estimator considering dual objective, which incorporates maximizing model performance and minimizing variance of model observations. Extensive experiments demonstrate the superiority of our approach over five backtest settings with three black-box stock portfolio management models. Ablation studies further verify the effectiveness of the proposed estimator.

Paper number 45:
Title: MusFlow: Multimodal Music Generation via Conditional Flow Matching
Authors: Jiahao Song, Yuzhao Wang
Abstract: Music generation aims to create music segments that align with human aesthetics based on diverse conditional information. Despite advancements in generating music from specific textual descriptions (e.g., style, genre, instruments), the practical application is still hindered by ordinary users' limited expertise or time to write accurate prompts. To bridge this application gap, this paper introduces MusFlow, a novel multimodal music generation model using Conditional Flow Matching. We employ multiple Multi-Layer Perceptrons (MLPs) to align multimodal conditional information into the audio's CLAP embedding space. Conditional flow matching is trained to reconstruct the compressed Mel-spectrogram in the pretrained VAE latent space guided by aligned feature embedding. MusFlow can generate music from images, story texts, and music captions. To collect data for model training, inspired by multi-agent collaboration, we construct an intelligent data annotation workflow centered around a fine-tuned Qwen2-VL model. Using this workflow, we build a new multimodal music dataset, MMusSet, with each sample containing a quadruple of image, story text, music caption, and music piece. We conduct four sets of experiments: image-to-music, story-to-music, caption-to-music, and multimodal music generation. Experimental results demonstrate that MusFlow can generate high-quality music pieces whether the input conditions are unimodal or multimodal. We hope this work can advance the application of music generation in multimedia field, making music creation more accessible. Our generated samples, code and dataset are available at this http URL.

Paper number 46:
Title: MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework
Authors: Zhenkai Qin, Feng Zhu, Huan Zeng, Xunyi Nong
Abstract: The demand for lightweight models in image classification tasks under resource-constrained environments necessitates a balance between computational efficiency and robust feature representation. Traditional attention mechanisms, despite their strong feature modeling capability, often struggle with high computational complexity and structural rigidity, limiting their applicability in scenarios with limited computational resources (e.g., edge devices or real-time systems). To address this, we propose the Multi-Agent Aggregation Module (MAAM), a lightweight attention architecture integrated with the MindSpore framework. MAAM employs three parallel agent branches with independently parameterized operations to extract heterogeneous features, adaptively fused via learnable scalar weights, and refined through a convolutional compression layer. Leveraging MindSpore's dynamic computational graph and operator fusion, MAAM achieves 87.0% accuracy on the CIFAR-10 dataset, significantly outperforming conventional CNN (58.3%) and MLP (49.6%) models, while improving training efficiency by 30%. Ablation studies confirm the critical role of agent attention (accuracy drops to 32.0% if removed) and compression modules (25.5% if omitted), validating their necessity for maintaining discriminative feature learning. The framework's hardware acceleration capabilities and minimal memory footprint further demonstrate its practicality, offering a deployable solution for image classification in resource-constrained scenarios without compromising accuracy.

Paper number 47:
Title: Efficient algorithms for the Hadamard decomposition
Authors: Samuel Wertz, Arnaud Vandaele, Nicolas Gillis
Abstract: The Hadamard decomposition is a powerful technique for data analysis and matrix compression, which decomposes a given matrix into the element-wise product of two or more low-rank matrices. In this paper, we develop an efficient algorithm to solve this problem, leveraging an alternating optimization approach that decomposes the global non-convex problem into a series of convex sub-problems. To improve performance, we explore advanced initialization strategies inspired by the singular value decomposition (SVD) and incorporate acceleration techniques by introducing momentum-based updates. Beyond optimizing the two-matrix case, we also extend the Hadamard decomposition framework to support more than two low-rank matrices, enabling approximations with higher effective ranks while preserving computational efficiency. Finally, we conduct extensive experiments to compare our method with the existing gradient descent-based approaches for the Hadamard decomposition and with traditional low-rank approximation techniques. The results highlight the effectiveness of our proposed method across diverse datasets.

Paper number 48:
Title: Robot Navigation in Dynamic Environments using Acceleration Obstacles
Authors: Asher Stern, Zvi Shiller
Abstract: This paper addresses the issue of motion planning in dynamic environments by extending the concept of Velocity Obstacle and Nonlinear Velocity Obstacle to Acceleration Obstacle AO and Nonlinear Acceleration Obstacle NAO. Similarly to VO and NLVO, the AO and NAO represent the set of colliding constant accelerations of the maneuvering robot with obstacles moving along linear and nonlinear trajectories, respectively. Contrary to prior works, we derive analytically the exact boundaries of AO and NAO. To enhance an intuitive understanding of these representations, we first derive the AO in several steps: first extending the VO to the Basic Acceleration Obstacle BAO that consists of the set of constant accelerations of the robot that would collide with an obstacle moving at constant accelerations, while assuming zero initial velocities of the robot and obstacle. This is then extended to the AO while assuming arbitrary initial velocities of the robot and obstacle. And finally, we derive the NAO that in addition to the prior assumptions, accounts for obstacles moving along arbitrary trajectories. The introduction of NAO allows the generation of safe avoidance maneuvers that directly account for the robot's second-order dynamics, with acceleration as its control input. The AO and NAO are demonstrated in several examples of selecting avoidance maneuvers in challenging road traffic. It is shown that the use of NAO drastically reduces the adjustment rate of the maneuvering robot's acceleration while moving in complex road traffic scenarios. The presented approach enables reactive and efficient navigation for multiple robots, with potential application for autonomous vehicles operating in complex dynamic environments.

Paper number 49:
Title: Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems
Authors: Uthman Baroudi, Alala BaHamid, Yasser Elalfy, Ziad Al Alami
Abstract: Road anomaly detection plays a crucial role in road maintenance and in enhancing the safety of both drivers and vehicles. Recent machine learning approaches for road anomaly detection have overcome the tedious and time-consuming process of manual analysis and anomaly counting; however, they often fall short in providing a complete characterization of road potholes. In this paper, we leverage transfer learning by adopting a pre-trained YOLOv8-seg model for the automatic characterization of potholes using digital images captured from a dashboard-mounted camera. Our work includes the creation of a novel dataset, comprising both images and their corresponding depth maps, collected from diverse road environments in Al-Khobar city and the KFUPM campus in Saudi Arabia. Our approach performs pothole detection and segmentation to precisely localize potholes and calculate their area. Subsequently, the segmented image is merged with its depth map to extract detailed depth information about the potholes. This integration of segmentation and depth data offers a more comprehensive characterization compared to previous deep learning-based road anomaly detection systems. Overall, this method not only has the potential to significantly enhance autonomous vehicle navigation by improving the detection and characterization of road hazards but also assists road maintenance authorities in responding more effectively to road damage.

Paper number 50:
Title: Green Robotic Mixed Reality with Gaussian Splatting
Authors: Chenxuan Liu, He Li, Zongze Li, Shuai Wang, Wei Xu, Kejiang Ye, Derrick Wing Kwan Ng, Chengzhong Xu
Abstract: Realizing green communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images at high frequencies through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSRMR), which achieves a lower energy consumption and makes a concrete step towards green RoboMR. The crux to GSRMR is to build a GS model which enables the simulator to opportunistically render a photo-realistic view from the robot's pose, thereby reducing the need for excessive image uploads. Since the GS model may involve discrepancies compared to the actual environments, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation across different frames. The GSCLO problem is solved by an accelerated penalty optimization (APO) algorithm. Experiments demonstrate that the proposed GSRMR reduces the communication energy by over 10x compared with RoboMR. Furthermore, the proposed GSRMR with APO outperforms extensive baseline schemes, in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).

Paper number 51:
Title: Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration
Authors: Gianluca Carloni
Abstract: This work aligns deep learning (DL) with human reasoning capabilities and needs to enable more efficient, interpretable, and robust image classification. We approach this from three perspectives: explainability, causality, and biological vision. Introduction and background open this work before diving into operative chapters. First, we assess neural networks' visualization techniques for medical images and validate an explainable-by-design method for breast mass classification. A comprehensive review at the intersection of XAI and causality follows, where we introduce a general scaffold to organize past and future research, laying the groundwork for our second perspective. In the causality direction, we propose novel modules that exploit feature co-occurrence in medical images, leading to more effective and explainable predictions. We further introduce CROCODILE, a general framework that integrates causal concepts, contrastive learning, feature disentanglement, and prior knowledge to enhance generalization. Lastly, we explore biological vision, examining how humans recognize objects, and propose CoCoReco, a connectivity-inspired network with context-aware attention mechanisms. Overall, our key findings include: (i) simple activation maximization lacks insight for medical imaging DL models; (ii) prototypical-part learning is effective and radiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak causal signals can be leveraged without a priori information to improve performance and interpretability; (v) our framework generalizes across medical domains and out-of-distribution data; (vi) incorporating biological circuit motifs improves human-aligned recognition. This work contributes toward human-aligned DL and highlights pathways to bridge the gap between research and clinical adoption, with implications for improved trust, diagnostic accuracy, and safe deployment.

Paper number 52:
Title: The relativity of color perception
Authors: Michel Berthier, Valerie Garcin, Nicoletta Prencipe, Edoardo Provenzi
Abstract: Physical colors, i.e. reflected or emitted lights entering the eyes from a visual environment, are converted into perceived colors sensed by humans by neurophysiological mechanisms. These processes involve both three types of photoreceptors, the LMS cones, and spectrally opponent and non-opponent interactions resulting from the activity rates of ganglion and lateral geniculate nucleus cells. Thus, color perception is a phenomenon inherently linked to an experimental environment (the visual scene) and an observing apparatus (the human visual system). This is clearly reminiscent of the conceptual foundation of both relativity and quantum mechanics, where the link is between a physical system and the measuring instruments. The relationship between color perception and relativity was explicitly examined for the first time by the physicist H. Yilmaz in 1962 from an experimental point of view. The main purpose of this contribution is to present a rigorous mathematical model that, by taking into account both trichromacy and color opponency, permits to explain on a purely theoretical basis the relativistic color perception phenomena argued by Yilmaz. Instead of relying directly on relativistic considerations, we base our theory on a quantum interpretation of color perception together with just one assumption, called trichromacy axiom, that summarizes well-established properties of trichromatic color vision within the framework of Jordan algebras. We show how this approach allows us to reconcile trichromacy with Hering's opponency and also to derive the relativistic properties of perceived colors without any additional mathematical or experimental assumption.

Paper number 53:
Title: LimitNet: Progressive, Content-Aware Image Offloading for Extremely Weak Devices & Networks
Authors: Ali Hojjat, Janek Haberer, Tayyaba Zainab, Olaf Landsiedel
Abstract: IoT devices have limited hardware capabilities and are often deployed in remote areas. Consequently, advanced vision models surpass such devices' processing and storage capabilities, requiring offloading of such tasks to the cloud. However, remote areas often rely on LPWANs technology with limited bandwidth, high packet loss rates, and extremely low duty cycles, which makes fast offloading for time-sensitive inference challenging. Today's approaches, which are deployable on weak devices, generate a non-progressive bit stream, and therefore, their decoding quality suffers strongly when data is only partially available on the cloud at a deadline due to limited bandwidth or packet losses. In this paper, we introduce LimitNet, a progressive, content-aware image compression model designed for extremely weak devices and networks. LimitNet's lightweight progressive encoder prioritizes critical data during transmission based on the content of the image, which gives the cloud the opportunity to run inference even with partial data availability. Experimental results demonstrate that LimitNet, on average, compared to SOTA, achieves 14.01 p.p. (percentage point) higher accuracy on ImageNet1000, 18.01 pp on CIFAR100, and 0.1 higher mAP@0.5 on COCO. Also, on average, LimitNet saves 61.24% bandwidth on ImageNet1000, 83.68% on CIFAR100, and 42.25% on the COCO dataset compared to SOTA, while it only has 4% more encoding time compared to JPEG (with a fixed quality) on STM32F7 (Cortex-M7).

Paper number 54:
Title: Sensing-Then-Beamforming: Robust Transmission Design for RIS-Empowered Integrated Sensing and Covert Communication
Authors: Xingyu Zhao, Min Li, Ming-Min Zhao, Shihao Yan, Min-Jian Zhao
Abstract: Traditional covert communication often relies on the knowledge of the warden's channel state information, which is inherently challenging to obtain due to the non-cooperative nature and potential mobility of the warden. The integration of sensing and communication technology provides a promising solution by enabling the legitimate transmitter to sense and track the warden, thereby enhancing transmission covertness. In this paper, we develop a framework for sensing-then-beamforming in reconfigurable intelligent surface (RIS)-empowered integrated sensing and covert communication (ISCC) systems, where the transmitter (Alice) estimates and tracks the mobile aerial warden's channel using sensing echo signals while simultaneously sending covert information to multiple legitimate users (Bobs) with the assistance of RIS, under the surveillance of the warden (Willie). Considering channel estimation errors, we formulate a robust non-convex optimization problem that jointly designs the communication beamformers, the sensing signal covariance matrix at Alice, and the phase shifts at the RIS to maximize the covert sum rate of Bobs while satisfying the constraints related to covert communication, sensing, transmitter power, and the unit modulus of the RIS elements. To solve this complex problem, we develop an efficient algorithm using alternating optimization, successive convex approximation, S-procedure, sequential rank-one constraint relaxation, and semidefinite relaxation techniques. Numerical results confirm the convergence of the proposed algorithm and demonstrate its effectiveness in tracking the warden's channel while ensuring robust covert transmission. Furthermore, the results highlight the advantages of using RIS to enhance the covert transmission rate compared to baseline schemes, and also illustrate the intricate trade-off between communication and sensing in ISCC systems.

Paper number 55:
Title: Fighting Fires from Space: Leveraging Vision Transformers for Enhanced Wildfire Detection and Characterization
Authors: Aman Agarwal, James Gearon, Raksha Rank, Etienne Chenevert
Abstract: Wildfires are increasing in intensity, frequency, and duration across large parts of the world as a result of anthropogenic climate change. Modern hazard detection and response systems that deal with wildfires are under-equipped for sustained wildfire seasons. Recent work has proved automated wildfire detection using Convolutional Neural Networks (CNNs) trained on satellite imagery are capable of high-accuracy results. However, CNNs are computationally expensive to train and only incorporate local image context. Recently, Vision Transformers (ViTs) have gained popularity for their efficient training and their ability to include both local and global contextual information. In this work, we show that ViT can outperform well-trained and specialized CNNs to detect wildfires on a previously published dataset of LandSat-8 imagery. One of our ViTs outperforms the baseline CNN comparison by 0.92%. However, we find our own implementation of CNN-based UNet to perform best in every category, showing their sustained utility in image tasks. Overall, ViTs are comparably capable in detecting wildfires as CNNs, though well-tuned CNNs are still the best technique for detecting wildfire with our UNet providing an IoU of 93.58%, better than the baseline UNet by some 4.58%.

Paper number 56:
Title: Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion
Authors: Sandipan Dhar, Md. Tousin Akhter, Nanda Dulal Jana, Swagatam Das
Abstract: After demonstrating significant success in image synthesis, Generative Adversarial Network (GAN) models have likewise made significant progress in the field of speech synthesis, leveraging their capacity to adapt the precise distribution of target data through adversarial learning processes. Notably, in the realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models, there exists a substantial disparity in naturalness between real and GAN-generated speech samples. Furthermore, while many GAN models currently operate on a single generator discriminator learning approach, optimizing target data distribution is more effectively achievable through a single generator multi-discriminator learning scheme. Hence, this study introduces a novel GAN model named Collective Learning Mechanism-based Optimal Transport GAN (CLOT-GAN) model, incorporating multiple discriminators, including the Deep Convolutional Neural Network (DCNN) model, Vision Transformer (ViT), and conformer. The objective of integrating various discriminators lies in their ability to comprehend the formant distribution of mel-spectrograms, facilitated by a collective learning mechanism. Simultaneously, the inclusion of Optimal Transport (OT) loss aims to precisely bridge the gap between the source and target data distribution, employing the principles of OT theory. The experimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms that the CLOT-GAN-VC model outperforms existing VC models in objective and subjective assessments.

Paper number 57:
Title: Joint Oscillation Damping and Inertia Provision Service for Converter-Interfaced Generation
Authors: Cheng Feng, Linbin Huang, Xiuqiang He, Yi Wang, Florian Dörfler, Chongqing Kang
Abstract: Power systems dominated by converter-interfaced distributed energy resources (DERs) typically exhibit weaker damping capabilities and lower inertia, compromising system stability. Although individual DER controllers are evolving to provide superior oscillation damping capabilities and inertia supports, there is a lack of network-wide coordinated management measures for multiple DERs, potentially leading to unexpected instability and cost-effectiveness problems. To address this gap, this paper introduces a hybrid oscillation damping and inertia management strategy for multiple DERs, considering network coupling effects, and seeks to encourage DERs to provide enhanced damping and inertia with appropriate economic incentives. We first formulate an optimization problem to tune and allocate damping and inertia coefficients for DERs, minimizing associated power and energy costs while ensuring hard constraints for system frequency stability and small-signal stability. The problem is built upon a novel convex parametric formulation that integrates oscillation mode location and frequency trajectory requirements, equipped with a theoretical guarantee, and eliminating the need for iterative tuning and computation burdens. Furthermore, to increase the willingness of DERs to cooperate, we further design appropriate economic incentives to compensate for DERs' costs based on the proposed cost minimization problem, and assess its impact on system cost-efficiency. Numerical tests highlight the effectiveness of the proposed method in promoting system stability and offer insights into potential economic benefits.

Paper number 58:
Title: Friedkin-Johnsen Model with Diminishing Competition
Authors: Luca Ballotta, Áron Vékássy, Stephanie Gil, Michal Yemini
Abstract: This letter studies the Friedkin-Johnsen (FJ) model with diminishing competition, or stubbornness. The original FJ model assumes that each agent assigns a constant competition weight to its initial opinion. In contrast, we investigate the effect of diminishing competition on the convergence point and speed of the FJ dynamics. We prove that, if the competition is uniform across agents and vanishes asymptotically, the convergence point coincides with the nominal consensus reached with no competition. However, the diminishing competition slows down convergence according to its own rate of decay. We study this phenomenon analytically and provide upper and lower bounds on the convergence rate. Further, if competition is not uniform across agents, we show that the convergence point may not coincide with the nominal consensus point. Finally, we evaluate our analytical insights numerically.

Paper number 59:
Title: BUPTCMCC-6G-CMG+: A GBSM-Based ISAC Standard Channel Model Generator
Authors: Changsheng Zhao, Jianhua Zhang, Yuxiang Zhang, Lei Tian, Heng Wang, Hanyuan Jiang, Yameng Liu, Wenjun Chen, Tao Jiang, Guangyi Liu
Abstract: Integrated sensing and communication (ISAC) has been recognized as the key technology in the vision of the sixth generation (6G) era. With the emergence of new concepts in mobile communications, the channel model is the prerequisite for system design and performance evaluation. Currently, 3GPP Release 19 is advancing the standardization of ISAC channel models. Nevertheless, a unified modeling framework has yet to be established. This paper provides a simulation diagram of ISAC channel modeling extended based on the Geometry-Based Stochastic Model (GBSM), compatible with existing 5G channel models and the latest progress in the 3rd Generation Partnership Project (3GPP) standardization. We first introduce the progress of the ISAC channel model standardization in general. Then, a concatenated channel modeling approach is presented considering the team's standardization proposals, which is implemented on the BUPTCMCC-6G-CMG+ channel model generator. We validated the model in cumulative probability density function (CDF) in statistical extension of angle and delay, and radar cross section (RCS). Simulation results show that the proposed model can realistically characterize the feature of channel concatenation and RCS within the ISAC channel.

Paper number 60:
Title: Beneath the Surface: The Role of Underwater Image Enhancement in Object Detection
Authors: Ali Awad (1), Ashraf Saleem (1), Sidike Paheding (2), Evan Lucas (1), Serein Al-Ratrout (1), Timothy C. Havens (1) ((1) Michigan Technological University, (2) Fairfield University)
Abstract: Underwater imagery often suffers from severe degradation resulting in low visual quality and reduced object detection performance. This work aims to evaluate state-of-the-art image enhancement models, investigate their effects on underwater object detection, and explore their potential to improve detection performance. To this end, we apply nine recent underwater image enhancement models, covering physical, non-physical and learning-based categories, to two recent underwater image datasets. Following this, we conduct joint qualitative and quantitative analyses on the original and enhanced images, revealing the discrepancy between the two analyses, and analyzing changes in the quality distribution of the images after enhancement. We then train three recent object detection models on the original datasets, selecting the best-performing detector for further analysis. This detector is subsequently re-trained on the enhanced datasets to evaluate changes in detection performance, highlighting the adverse effect of enhancement on detection performance at the dataset level. Next, we perform a correlation study to examine the relationship between various enhancement metrics and the mean Average Precision (mAP). Finally, we conduct an image-level analysis that reveals images of improved detection performance after enhancement. The findings of this study demonstrate the potential of image enhancement to improve detection performance and provide valuable insights for researchers to further explore the effects of enhancement on detection at the individual image level, rather than at the dataset level. This could enable the selective application of enhancement for improved detection. The data generated, code developed, and supplementary materials are publicly available at: this https URL.

Paper number 61:
Title: Exploring the Limitations of Structured Orthogonal Dictionary Learning
Authors: Anirudh Dash, Aditya Siripuram
Abstract: This work is motivated by recent applications of structured dictionary learning, in particular when the dictionary is assumed to be the product of a few Householder atoms. We investigate the following two problems: 1) How do we approximate an orthogonal matrix $\mathbf{V}$ with a product of a specified number of Householder matrices, and 2) How many samples are required to learn a structured (Householder) dictionary from data? For 1) we discuss an algorithm that decomposes $\mathbf{V}$ as a product of a specified number of Householder matrices. We see that the algorithm outputs the decomposition when it exists, and give bounds on the approximation error of the algorithm when such a decomposition does not exist. For 2) given data $\mathbf{Y}=\mathbf{HX}$, we show that when assuming a binary coefficient matrix $\mathbf{X}$, the structured (Householder) dictionary learning problem can be solved with just $2$ samples (columns) in $\mathbf{Y}$.

Paper number 62:
Title: RIS Meets O-RAN: A Practical Demonstration of Multi-user RIS Optimization through RIC
Authors: Ali Fuat Sahin, Onur Salan, Ibrahim Hokelek, Ali Gorcin
Abstract: Open Radio Access Network (O-RAN) along with artificial intelligence, machine learning, cloud and edge networking, and virtualization are important enablers for designing flexible and software-driven programmable wireless networks. In addition, Reconfigurable Intelligent Surfaces (RIS) represent an innovative technology to direct incoming radio signals toward desired locations by software-controlled passive reflecting antenna elements. Despite their distinctive potential, there has been limited exploration of integrating RIS with the O-RAN framework, an area that holds promise for enhancing next-generation wireless systems. This paper addresses this gap by designing and developing the RIS optimization xApps within an O-RAN-based real-time 5G environment. We perform extensive measurement experiments using an end-to-end 5G testbed including the RIS prototype in a multi-user scenario. The results demonstrate that the RIS can be utilized either to boost the performance of the selected user or to provide the fairness among the users or to balance the tradeoff between the performance and fairness.

Paper number 63:
Title: Pricing is All You Need to Improve Traffic Routing
Authors: Yu Tang, Kaan Ozbay, Li Jin
Abstract: We investigate the design of pricing policies that enhance driver adherence to route guidance, ensuring effective routing control. The major novelty lies in that we adopt a Markov chain to model drivers' compliance rates conditioned on both traffic states and tolls. By formulating the managed traffic network as a nonlinear stochastic dynamical system, we can quantify in a more realistic way the impacts of driver route choices and thus determine appropriate tolls. Specially, we focus on a network comprised of one corridor and one local street. We assume that a reasonable routing policy is specified in advance. However, drivers could be reluctant to be detoured. Thus a fixed toll is set on the corridor to give drivers incentives to choose the local street. We evaluate the effectiveness of the given routing and pricing policies via stability analysis. We suggest using the stability and instability conditions to establish lower and upper bounds on throughput. This allows us to select suitable tolls that maximize these bounds.

Paper number 64:
Title: Rotatable Antenna-Enabled Secure Wireless Communication
Authors: Liang Dai, Beixiong Zheng, Qingjie Wu, Changsheng You
Abstract: Rotatable antenna (RA) is a promising technology that exploits new spatial degrees of freedom (DoFs) to improve wireless communication and sensing performance. In this letter, we investigate an RA-enabled secure communication system where confidential information is transmitted from an RA-based access point (AP) to a single-antenna legitimate user in the presence of multiple eavesdroppers. We aim to maximize the achievable secrecy rate by jointly optimizing the transmit beamforming and the deflection angles of all RAs. Accordingly, we propose an efficient alternating optimization (AO) algorithm to obtain a high-quality suboptimal solution in an iterative manner, where the generalized Rayleigh quotient-based beamforming is applied and the RAs' deflection angles are optimized by the successive convex approximation (SCA) technique. Simulation results show that the proposed RA-enabled secure communication system achieves significant improvement in achievable secrecy rate as compared to various benchmark schemes.

Paper number 65:
Title: WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion
Authors: Vinay Shukla, Prachee Sharma, Ryan Rossi, Sungchul Kim, Tong Yu, Aditya Grover
Abstract: The ability to embed watermarks in images is a fundamental problem of interest for computer vision, and is exacerbated by the rapid rise of generated imagery in recent times. Current state-of-the-art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments. In addition, other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality. In this work, we propose WaterFlow (WF), a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent-dependent watermark. Our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the Fourier Domain of the latent. The transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre-trained model to better preserve image quality while permitting robust and tractable detection. Most notably, WaterFlow demonstrates state-of-the-art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks. We validate our findings on three widely used real and generated datasets: MS-COCO, DiffusionDB, and WikiArt.

Paper number 66:
Title: EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting
Authors: Guanrou Yang, Chen Yang, Qian Chen, Ziyang Ma, Wenxi Chen, Wen Wang, Tianrui Wang, Yifan Yang, Zhikang Niu, Wenrui Liu, Fan Yu, Zhihao Du, Zhifu Gao, ShiLiang Zhang, Xie Chen
Abstract: Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at this https URL. Dataset, code, and checkpoints will be released.

Paper number 67:
Title: Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond
Authors: Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan
Abstract: Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.

Paper number 68:
Title: On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural Networks
Authors: Hubert Leterme, Kévin Polisano, Valérie Perrier, Karteek Alahari
Abstract: This paper focuses on improving the mathematical interpretability of convolutional neural networks (CNNs) in the context of image classification. Specifically, we tackle the instability issue arising in their first layer, which tends to learn parameters that closely resemble oriented band-pass filters when trained on datasets like ImageNet. Subsampled convolutions with such Gabor-like filters are prone to aliasing, causing sensitivity to small input shifts. In this context, we establish conditions under which the max pooling operator approximates a complex modulus, which is nearly shift invariant. We then derive a measure of shift invariance for subsampled convolutions followed by max pooling. In particular, we highlight the crucial role played by the filter's frequency and orientation in achieving stability. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree complex wavelet packet transform, a particular case of discrete Gabor-like decomposition.

Paper number 69:
Title: Block Backstepping for Isotachic Hyperbolic PDEs and Multilayer Timoshenko Beams
Authors: Guangwei Chen, Rafael Vazquez, Junfei Qiao, Miroslav Krstic
Abstract: In this paper, we investigate the rapid stabilization of N-layer Timoshenko composite beams with anti-damping and anti-stiffness at the uncontrolled boundaries. The problem of stabilization for a two-layer composite beam has been previously studied by transforming the model into a 1-D hyperbolic PIDE-ODE form and then applying backstepping to this new system. In principle this approach is generalizable to any number of layers. However, when some of the layers have the same physical properties (as e.g. in lamination of repeated layers), the approach leads to isotachic hyperbolic PDEs (i.e. where some states have the same transport speed). This particular yet physical and interesting case has not received much attention beyond a few remarks in the early hyperbolic design. Thus, this work starts by extending the theory of backstepping control of (m + n) hyperbolic PIDEs and m ODEs to blocks of isotachic states, leading to a block backstepping design. Then, returning to multilayer Timoshenko beams, the Riemann transformation is used to transform the states of N-layer Timoshenko beams into a 1-D hyperbolic PIDE-ODE system. The block backstepping method is then applied to this model, obtaining closed-loop stability of the origin in the L2 sense. An arbitrarily rapid convergence rate can be obtained by adjusting control parameters. Finally, numerical simulations are presented corroborating the theoretical developments.

Paper number 70:
Title: SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems
Authors: Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen
Abstract: Surrogate models are used to predict the behavior of complex energy systems that are too expensive to simulate with traditional numerical methods. Our work introduces the use of language descriptions, which we call ``system captions'' or SysCaps, to interface with such surrogates. We argue that interacting with surrogates through text, particularly natural language, makes these models more accessible for both experts and non-experts. We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata. Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities, such as handling semantically related descriptions of the same test system. Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.

Paper number 71:
Title: Stochastic Trajectory Optimization for Robotic Skill Acquisition From a Suboptimal Demonstration
Authors: Chenlin Ming, Zitong Wang, Boxuan Zhang, Zhanxiang Cao, Xiaoming Duan, Jianping He
Abstract: Learning from Demonstration (LfD) has emerged as a crucial method for robots to acquire new skills. However, when given suboptimal task trajectory demonstrations with shape characteristics reflecting human preferences but subpar dynamic attributes such as slow motion, robots not only need to mimic the behaviors but also optimize the dynamic performance. In this work, we leverage optimization-based methods to search for a superior-performing trajectory whose shape is similar to that of the demonstrated trajectory. Specifically, we use Dynamic Time Warping (DTW) to quantify the difference between two trajectories and combine it with additional performance metrics, such as collision cost, to construct the cost function. Moreover, we develop a multi-policy version of the Stochastic Trajectory Optimization for Motion Planning (STOMP), called MSTOMP, which is more stable and robust to parameter changes. To deal with the jitter in the demonstrated trajectory, we further utilize the gain-controlling method in the frequency domain to denoise the demonstration and propose a computationally more efficient metric, called Mean Square Error in the Spectrum (MSES), that measures the trajectories' differences in the frequency domain. We also theoretically highlight the connections between the time domain and the frequency domain methods. Finally, we verify our method in both simulation experiments and real-world experiments, showcasing its improved optimization performance and stability compared to existing methods.

Paper number 72:
Title: An OpenMind for 3D medical vision self-supervised learning
Authors: Tassilo Wald, Constantin Ulrich, Jonathan Suprijadi, Sebastian Ziegler, Michal Nohel, Robin Peretzke, Gregor Köhler, Klaus H. Maier-Hein
Abstract: The field of self-supervised learning (SSL) for 3D medical images lacks consistency and standardization. While many methods have been developed, it is impossible to identify the current state-of-the-art, due to i) varying and small pretraining datasets, ii) varying architectures, and iii) being evaluated on differing downstream datasets. In this paper, we bring clarity to this field and lay the foundation for further method advancements through three key contributions: We a) publish the largest publicly available pre-training dataset comprising 114k 3D brain MRI volumes, enabling all practitioners to pre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised learning methods on this dataset for a state-of-the-art CNN and Transformer architecture, clarifying the state of 3D SSL pre-training. Among many findings, we show that pre-trained methods can exceed a strong from-scratch nnU-Net ResEnc-L baseline. Lastly, we c) publish the code of our pre-training and fine-tuning frameworks and provide the pre-trained models created during the benchmarking process to facilitate rapid adoption and reproduction.

Paper number 73:
Title: BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response
Authors: Hongruixuan Chen, Jian Song, Olivier Dietrich, Clifford Broni-Bediako, Weihao Xuan, Junjue Wang, Xinlei Shao, Yimin Wei, Junshi Xia, Cuiling Lan, Konrad Schindler, Naoto Yokoya
Abstract: Disaster events occur around the world and cause significant damage to human life and property. Earth observation (EO) data enables rapid and comprehensive building damage assessment (BDA), an essential capability in the aftermath of a disaster to reduce human casualties and to inform disaster relief efforts. Recent research focuses on the development of AI models to achieve accurate mapping of unseen disaster events, mostly using optical EO data. However, solutions based on optical data are limited to clear skies and daylight hours, preventing a prompt response to disasters. Integrating multimodal (MM) EO data, particularly the combination of optical and SAR imagery, makes it possible to provide all-weather, day-and-night disaster responses. Despite this potential, the development of robust multimodal AI models has been constrained by the lack of suitable benchmark datasets. In this paper, we present a BDA dataset using veRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based all-weather disaster response. To the best of our knowledge, BRIGHT is the first open-access, globally distributed, event-diverse MM dataset specifically curated to support AI-based disaster response. It covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries where external assistance is most needed. The optical and SAR imagery in BRIGHT, with a spatial resolution between 0.3-1 meters, provides detailed representations of individual buildings, making it ideal for precise BDA. In our experiments, we have tested seven advanced AI models trained with our BRIGHT to validate the transferability and robustness. The dataset and code are available at this https URL. BRIGHT also serves as the official dataset for the 2025 IEEE GRSS Data Fusion Contest.

Paper number 74:
Title: Stability and performance guarantees for misspecified multivariate score-driven filters
Authors: Simon Donker van Heel, Rutger-Jan Lange, Dick van Dijk, Bram van Os
Abstract: We address the problem of tracking multivariate unobserved time-varying parameters under potential model misspecification. Specifically, we examine implicit and explicit score-driven (ISD and ESD) filters, which update parameter predictions using the gradient of the postulated logarithmic observation density (commonly referred to as the score). For both filter types, we derive novel sufficient conditions that ensure the invertibility of the filtered parameter path and the existence of a finite mean squared error (MSE) bound relative to the pseudo-true parameter path. Our (non-)asymptotic MSE bounds rely on mild moment conditions on the data-generating process, while our invertibility result is agnostic about the true process. For the ISD filter, concavity of the postulated log density combined with simple parameter restrictions is sufficient (though not necessary) to guarantee stability. In contrast, the ESD filter additionally requires the score to be Lipschitz continuous. We validate our theoretical findings and highlight the superior stability and performance of ISD over ESD filters through extensive simulation studies. Finally, we demonstrate the practical relevance of our approach through an empirical application to U.S. Treasury-bill rates.

Paper number 75:
Title: Reinforcement Learning with Graph Attention for Routing and Wavelength Assignment with Lightpath Reuse
Authors: Michael Doherty, Alejandra Beghelli
Abstract: Many works have investigated reinforcement learning (RL) for routing and spectrum assignment on flex-grid networks but only one work to date has examined RL for fixed-grid with flex-rate transponders, despite production systems using this paradigm. Flex-rate transponders allow existing lightpaths to accommodate new services, a task we term routing and wavelength assignment with lightpath reuse (RWA-LR). We re-examine this problem and present a thorough benchmarking of heuristic algorithms for RWA-LR, which are shown to have 6% increased throughput when candidate paths are ordered by number of hops, rather than total length. We train an RL agent for RWA-LR with graph attention networks for the policy and value functions to exploit the graph-structured data. We provide details of our methodology and open source all of our code for reproduction. We outperform the previous state-of-the-art RL approach by 2.5% (17.4 Tbps mean additional throughput) and the best heuristic by 1.2% (8.5 Tbps mean additional throughput). This marginal gain highlights the difficulty in learning effective RL policies on long horizon resource allocation tasks.

Paper number 76:
Title: CTorch: PyTorch-Compatible GPU-Accelerated Auto-Differentiable Projector Toolbox for Computed Tomography
Authors: Xiao Jiang, Grace J. Gang, J. Webster Stayman
Abstract: This work introduces CTorch, a PyTorch-compatible, GPU-accelerated, and auto-differentiable projector toolbox designed to handle various CT geometries with configurable projector algorithms. CTorch provides flexible scanner geometry definition, supporting 2D fan-beam, 3D circular cone-beam, and 3D non-circular cone-beam geometries. Each geometry allows view-specific definitions to accommodate variations during scanning. Both flat- and curved-detector models may be specified to accommodate various clinical devices. CTorch implements four projector algorithms: voxel-driven, ray-driven, distance-driven (DD), and separable footprint (SF), allowing users to balance accuracy and computational efficiency based on their needs. All the projectors are primarily built using CUDA C for GPU acceleration, then compiled as Python-callable functions, and wrapped as PyTorch network module. This design allows direct use of PyTorch tensors, enabling seamless integration into PyTorch's auto-differentiation framework. These features make CTorch an flexible and efficient tool for CT imaging research, with potential applications in accurate CT simulations, efficient iterative reconstruction, and advanced deep-learning-based CT reconstruction.

Paper number 77:
Title: Mind2Matter: Creating 3D Models from EEG Signals
Authors: Xia Deng, Shen Chen, Jiale Zhou, Lei Li
Abstract: The reconstruction of 3D objects from brain signals has gained significant attention in brain-computer interface (BCI) research. Current research predominantly utilizes functional magnetic resonance imaging (fMRI) for 3D reconstruction tasks due to its excellent spatial resolution. Nevertheless, the clinical utility of fMRI is limited by its prohibitive costs and inability to support real-time operations. In comparison, electroencephalography (EEG) presents distinct advantages as an affordable, non-invasive, and mobile solution for real-time brain-computer interaction systems. While recent advances in deep learning have enabled remarkable progress in image generation from neural data, decoding EEG signals into structured 3D representations remains largely unexplored. In this paper, we propose a novel framework that translates EEG recordings into 3D object reconstructions by leveraging neural decoding techniques and generative models. Our approach involves training an EEG encoder to extract spatiotemporal visual features, fine-tuning a large language model to interpret these features into descriptive multimodal outputs, and leveraging generative 3D Gaussians with layout-guided control to synthesize the final 3D structures. Experiments demonstrate that our model captures salient geometric and semantic features, paving the way for applications in brain-computer interfaces (BCIs), virtual reality, and neuroprosthetics. Our code is available in this https URL.
    