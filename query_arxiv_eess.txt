
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Sequential Convex Programming for 6-DoF Powered Descent Guidance with Continuous-Time Compound State-Triggered Constraints
Authors: Samet Uzun, Behcet Acikmese, John M. Carson III
Abstract: This paper presents a sequential convex programming (SCP) framework for ensuring the continuous-time satisfaction of compound state-triggered constraints, a subset of logical specifications, in the powered descent guidance (PDG) problem. The proposed framework combines the generalized mean-based smooth robustness measure (D-GMSR), a parameterization technique tailored for expressing discrete-time temporal and logical specifications through smooth functions, with the continuous-time successive convexification (CT-SCvx) method, a real-time solution for constrained trajectory optimization that guarantees continuous-time constraint satisfaction and convergence. The smoothness of the temporal and logical specifications parameterized via D-GMSR enables solving the resulting optimization problem with robust and efficient SCP algorithms while preserving theoretical guarantees. In addition to their smoothness, the parameterized specifications are sound and complete, meaning the specification holds if and only if the constraint defined by the parameterized function is satisfied. The CT-SCvx framework is then applied to solve the parameterized problem, incorporating: (1) reformulation for continuous-time path constraint satisfaction, (2) time-dilation to transform the free-final-time PDG problem into a fixed-final-time problem, (3) multiple shooting for exact discretization, (4) exact penalty functions for penalizing nonconvex constraints, and (5) the prox-linear method, a convergence-guaranteed SCP algorithm, to solve the resulting finite-dimensional nonconvex PDG problem. The effectiveness of the framework is demonstrated through a numerical simulation. The implementation is available at this https URL

Paper number 2:
Title: Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery
Authors: Antonio Martínez-Ibarra, Aurora González-Vidal, Adrián Cánovas-Rodríguez, Antonio F. Skarmeta
Abstract: The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems.

Paper number 3:
Title: Designing Control Barrier Functions Using a Dynamic Backup Policy
Authors: Victor Freire, Marco M. Nicotra
Abstract: This paper presents a systematic approach to construct control barrier functions for nonlinear control affine systems subject to arbitrary state and input constraints. Taking inspiration from the reference governor literature, the proposed method defines a family of backup policies, parametrized by the equilibrium manifold of the system. The control barrier function is defined on the augmented state-and-reference space: given a state-reference pair, the approach quantifies the distance to constraint violation at any time in the future, should the current backup policy reference remain constant. Sensitivity analysis is then used to compute the (possibly nonsmooth) Jacobian with respect to the augmented state vector. To showcase its simple yet general nature, the proposed method is applied to an inverted pendulum on cart.

Paper number 4:
Title: Latent-Feature-Informed Neural ODE Modeling for Lightweight Stability Evaluation of Black-box Grid-Tied Inverters
Authors: Jialin Zheng, Zhong Liu, Xiaonan Lu
Abstract: Stability evaluation of black-box grid-tied inverters is vital for grid reliability, yet identification techniques are both data-hungry and blocked by proprietary internals. {To solve this, this letter proposes a latent-feature-informed neural ordinary differential equation (LFI-NODE) modeling method that can achieve lightweight stability evaluation directly from trajectory data.} LFI-NODE parameterizes the entire system ODE with a single continuous-time neural network, allowing each new sample to refine a unified global model. It faithfully captures nonlinear large-signal dynamics to preserve uniform predictive accuracy as the inverter transitions between operating points. Meanwhile, latent perturbation features distilled from every trajectory steer the learning process and concurrently reveal the small-signal eigenstructure essential for rigorous stability analysis. Validated on a grid-forming inverter, {The LFI-NODE requires one to two orders of magnitude fewer training samples compared with traditional methods, collected from short time-domain trajectories instead of extensive frequency-domain measurements.} {Furthermore, the LFI-NODE requires only 48 short transients to achieve a trajectory prediction error at the hundredth level and an eigenvalue estimation error at the tenth level, outperforming benchmark methods by one to two orders of magnitude.} This makes LFI-NODE a practical and lightweight approach for achieving high-fidelity stability assessment of complex black-box power-electronic systems.

Paper number 5:
Title: Cyber-Physical Systems on the Megawatt Scale: The impact of battery control on grid frequency stability
Authors: Carsten Hartmann, Edoardo De Din, Daniele Carta, Florian Middelkoop, Arndt Neubauer, Johannes Kruse, Ulrich Oberhofer, Richard Jumar, Benjamin Schäfer, Thiemo Pesch, Andrea Benigni, Dirk Witthaut
Abstract: Electric power systems are undergoing fundamental change. The shift to inverter-based generation challenges frequency stability, while growing digitalisation heightens vulnerability to errors and attacks. Here we identify an emerging risk at the intersection of cyber-physical coupling and control system design. We show that grid frequency time series worldwide exhibit a persistent one-minute oscillatory pattern, whose origin has remained largely unexplained. We trace this pattern back to the energy management systems of battery electric storage systems and demonstrate that the pattern amplitude has increased substantially in the Nordic and British grids. We argue that this effect is a potential burden for stability in future grids with low inertia and an increasing penetration with batteries and smart devices, though it can be mitigated by a revision of battery control algorithms.

Paper number 6:
Title: Computing Safe Control Inputs using Discrete-Time Matrix Control Barrier Functions via Convex Optimization
Authors: James Usevitch, Juan Augusto Paredes Salazar, Ankit Goel
Abstract: Control barrier functions (CBFs) have seen widespread success in providing forward invariance and safety guarantees for dynamical control systems. A crucial limitation of discrete-time formulations is that CBFs that are nonconcave in their argument require the solution of nonconvex optimization problems to compute safety-preserving control inputs, which inhibits real-time computation of control inputs guaranteeing forward invariance. This paper presents a novel method for computing safety-preserving control inputs for discrete-time systems with nonconvex safety sets, utilizing convex optimization and the recently developed class of matrix control barrier function techniques. The efficacy of our methods is demonstrated through numerical simulations on a bicopter system.

Paper number 7:
Title: Viscosity CBFs: Bridging the Control Barrier Function and Hamilton-Jacobi Reachability Frameworks in Safe Control Theory
Authors: Dylan Hirsch, Jaime Fernández Fisac, Sylvia Herbert
Abstract: Control barrier functions (CBFs) and Hamilton-Jacobi reachability (HJR) are central frameworks in safe control. Traditionally, these frameworks have been viewed as distinct, with the former focusing on optimally safe controller design and the latter providing sufficient conditions for safety. A previous work introduced the notion of a control barrier value function (CB-VF), which is defined similarly to the other value functions studied in HJR but has certain CBF-like properties. In this work, we proceed the other direction by generalizing CBFs to non-differentiable ``viscosity'' CBFs. We show the deep connection between viscosity CBFs and CB-VFs, bridging the CBF and HJR frameworks. Through this bridge, we characterize the viscosity CBFs as precisely those functions which provide CBF-like safety guarantees (control invariance and smooth approach to the boundary). We then further show nice theoretical properties of viscosity CBFs, including their desirable closure under maximum and limit operations. In the process, we also extend CB-VFs to non-exponential anti-discounting and update the corresponding theory for CB-VFs along these lines.

Paper number 8:
Title: Bluetooth Fingerprint Identification Under Domain Shift Through Transient Phase Derivative
Authors: Haytham Albousayri, Bechir Hamdaoui, Weng-Keen Wong, Nora Basha
Abstract: Deep learning-based radio frequency fingerprinting (RFFP) has become an enabling physical-layer security technology, allowing device identification and authentication through received RF signals. This technology, however, faces significant challenges when it comes to adapting to domain variations, such as time, location, environment, receiver and channel. For Bluetooth Low Energy (BLE) devices, addressing these challenges is particularly crucial due to the BLE protocol's frequency-hopping nature. In this work, and for the first time, we investigated the frequency hopping effect on RFFP of BLE devices, and proposed a novel, low-cost, domain-adaptive feature extraction method. Our approach improves the classification accuracy by up to 58\% across environments and up to 80\% across receivers compared to existing benchmarks.

Paper number 9:
Title: Modeling the Impact of Communication and Human Uncertainties on Runway Capacity in Terminal Airspace
Authors: Yutian Pang, Andrew Kendall, John-Paul Clarke
Abstract: We investigate the potential impact of communication and human performance uncertainties on runway operations. Specifically, we consider these impacts within the context of an arrival scenario with two converging flows: a straight-in approach stream and a downwind stream merging into it. Both arrival stream are modeled using a modified Possion distribution that incorporate the separation minima as well as the runway occupancy time. Various system level uncertainties are addressed in this process, including communication link- and human-related uncertainties. In this research, we first build a Monte Carlo-based discrete-time simulation, where aircraft arrivals are generated by modified Poisson processes subject to minimum separation constraints, simulating various traffic operations. The merging logic incorporates standard bank angle continuous turn-to-final, pilot response delays, and dynamic gap availability in real time. Then, we investigate an automated final approach vectoring model (i.e., Auto-ATC), in which inverse optimal control is used to learn decision advisories from human expert records. By augmenting trajectories and incorporating the aforementioned uncertainties into the planning scenario, we create a setup analogous to the discrete event simulation. For both studies, runway capacity is measured by runway throughput, the fraction of downwind arrivals that merge immediately without holding, and the average delay (i.e., holding time/distance) experienced on the downwind leg. This research provides a method for runway capacity estimation in merging scenarios, and demonstrates that aeronautical communication link uncertainties significantly affect runway capacity in current voice-based operations, whereas the impact can be mitigated in autonomous operational settings.

Paper number 10:
Title: Movable Antenna Enhanced Covert Dual-Functional Radar-Communication: Joint Beamforming and Antenna Position Optimization
Authors: Ran Yang, Zheng Dong, Peng Cheng, Lin Zhang, Wanting Lyu, Yue Xiu, Ning Wei, Chadi Assi
Abstract: Movable antenna (MA) has emerged as a promising technology to flexibly reconfigure wireless channels by adjusting antenna placement. In this paper, we study a dual-functional radar-communication (DFRC) system enhanced with movable antennas. To ensure communication security, we aim to maximize the achievable sum rate by jointly optimizing the transmit beamforming vectors, receiving filter, and antenna placement, subject to radar signal-to-noise ratio (SNR) performance and transmission covertness constraints. To tackle this challenging optimization problem, we first employ a Lagrangian dual transformation process to reformulate it into a more tractable form. Subsequently, the problem is solved by introducing a block coordinate descent (BCD) algorithm, incorporating semidefinite relaxation (SDR), projected gradient descent (PGD), and successive convex approximation (SCA) techniques. Simulation results demonstrate that the proposed method can significantly improve the covert sum rate, and achieve a satisfactory balance between the communication and radar performance compared with existing benchmark schemes by leveraging the flexibility of movable antennas.

Paper number 11:
Title: Generative Latent Video Compression
Authors: Zongyu Guo, Zhaoyang Jia, Jiahao Li, Xiaoyi Zhang, Bin Li, Yan Lu
Abstract: Perceptual optimization is widely recognized as essential for neural compression, yet balancing the rate-distortion-perception tradeoff remains challenging. This difficulty is especially pronounced in video compression, where frame-wise quality fluctuations often cause perceptually optimized neural video codecs to suffer from flickering artifacts. In this paper, inspired by the success of latent generative models, we present Generative Latent Video Compression (GLVC), an effective framework for perceptual video compression. GLVC employs a pretrained continuous tokenizer to project video frames into a perceptually aligned latent space, thereby offloading perceptual constraints from the rate-distortion optimization. We redesign the codec architecture explicitly for the latent domain, drawing on extensive insights from prior neural video codecs, and further equip it with innovations such as unified intra/inter coding and a recurrent memory mechanism. Experimental results across multiple benchmarks show that GLVC achieves state-of-the-art performance in terms of DISTS and LPIPS metrics. Notably, our user study confirms GLVC rivals the latest neural video codecs at nearly half their rate while maintaining stable temporal coherence, marking a step toward practical perceptual video compression.

Paper number 12:
Title: Active IRS Assisted Joint Uplink and Downlink Communications
Authors: Qiaoyan Peng, Qingqing Wu, Guangji Chen, Wen Chen, Shaodan Ma
Abstract: In this paper, we investigate an intelligent reflecting surface (IRS) aided wireless communication system, where active IRSs (AIRSs) are deployed to assist communication between a base station (BS) and users of both the uplink (UL) and downlink (DL). We aim to maximize the weighted sum rate (WSR) of UL and DL communications through joint optimization of BS, AIRS beamforming, and AIRS element allocation. First, we study three deployment schemes, namely distributed AIRSs, BS-side AIRS, and user-side AIRS. For distributed AIRSs, both optimal and near-optimal solutions are derived in closed form. To draw useful insights, we analytically compare the deployment schemes in terms of the rate performance under the single-user setup. For the multi-user case, we consider two beamforming setups at the distributed AIRSs to balance performance and complexity tradeoffs. Regarding the user-adaptive AIRS beamforming, different AIRS beamforming vectors are adopted for each user; while for the static AIRS beamforming, all users share the same beamforming vectors, with identical phase shifts but different amplitudes for UL and DL. With the user-adaptive AIRS beamforming, we focus on the optimization of element allocation for rate maximization. With static AIRS beamforming, we solve the rate maximization problem by optimizing the BS transmit/receive beamformers, user beamforming, and AIRS beamforming. Despite its non-convexity, we develop an efficient alternating optimization (AO) based algorithm that solves each sub-problem optimally. Numerical results validate the practical advantages of distributed AIRSs compared to passive IRS (PIRS), BS-side AIRS, and user-side AIRS, and highlight the benefits of dynamic IRS beamforming.

Paper number 13:
Title: Performance Index Shaping for Closed-loop Optimal Control
Authors: Ayush Rai, Shaoshuai Mou, Brian D. O. Anderson
Abstract: The design of the performance index, also referred to as cost or reward shaping, is central to both optimal control and reinforcement learning, as it directly determines the behaviors, trade-offs, and objectives that the resulting control laws seek to achieve. A commonly used approach for this inference task in recent years is differentiable trajectory optimization, which allows gradients to be computed with respect to cost parameters by differentiating through an optimal control solver. However, this method often requires repeated solving of the underlying optimal control problem at every iteration, making the method computationally expensive. In this work, assuming known dynamics, we propose a novel framework that analytically links the performance index to the resulting closed-loop optimal control law, thereby transforming a typically bi-level inverse problem into a tractable single-level formulation. Our approach is motivated by the question: given a closed-loop control law that solves an infinite-horizon optimal control problem, how does this law change when the performance index is modified with additional terms? This formulation yields closed-form characterizations for broad classes of systems and performance indices, which not only facilitate interpretation and stability analysis, but also provide insight into the robust stability and input-to-state stable behavior of the resulting nonlinear closed-loop system. Moreover, this analytical perspective enables the generalization of our approach to diverse design objectives, yielding a unifying framework for performance index shaping. Given specific design objectives, we propose a systematic methodology to guide the shaping of the performance index and thereby design the resulting optimal control law.

Paper number 14:
Title: Bounds of Validity for Bifurcations of Equilibria in a Class of Networked Dynamical Systems
Authors: Pranav Gupta, Ravi Banavar, Anastasia Bizyaeva
Abstract: Local bifurcation analysis plays a central role in understanding qualitative transitions in networked nonlinear dynamical systems, including dynamic neural network and opinion dynamics models. In this article we establish explicit bounds of validity for the classification of bifurcation diagrams in two classes of continuous-time networked dynamical systems, analogous in structure to the Hopfield and the Firing Rate dynamic neural network models. Our approach leverages recent advances in computing the bounds for the validity of Lyapunov-Schmidt reduction, a reduction method widely employed in nonlinear systems analysis. Using these bounds we rigorously characterize neighborhoods around bifurcation points where predictions from reduced-order models remain reliable. We further demonstrate how these bounds can be applied to an illustrative family of nonlinear opinion dynamics on k-regular graphs, which emerges as a special case of the general framework. These results provide new analytical tools for quantifying the robustness of bifurcation phenomena in dynamics over networked systems and highlight the interplay between network structure and nonlinear dynamical behavior.

Paper number 15:
Title: MIMO Radar Meets Polarization-Reconfigurable Antennas: A BCRB Perspective
Authors: Jinpeng Xu, Shuowen Zhang
Abstract: In this paper, we investigate a novel multiple-input multiple-output (MIMO) radar system aided by phase shifter based polarization-reconfigurable antennas (PRAs). Specifically, a base station (BS) equipped with multiple PRAs at both the transmitter and the receiver aims to sense the unknown and random angular location parameter of a point target via sending wireless signals and processing the received echo signals reflected by the target, where only prior distribution information about the location parameter is available for exploitation. Firstly, we characterize the sensing performance of this novel PRA-based MIMO radar system by deriving the Bayesian Cramér-Rao bound (BCRB) of the mean-squared error (MSE) in estimating the desired location parameter with prior distribution information. Then, to fully exploit the new design degrees-of-freedom (DoF) empowered by PRAs, we study the joint optimization of the transmit sample covariance matrix as well as the transmit and receive phase shift vectors to minimize the sensing BCRB subject to a transmit power constraint. This problem is non-convex and difficult to solve due to the coupling among optimization variables. To resolve this issue, we develop an alternating optimization (AO) based algorithm which iteratively obtains the closed-form optimal solution to each variable with the others being fixed at each time, thus being guaranteed to converge to at least a stationary point of the joint optimization problem. Numerical results validate the effectiveness of the proposed algorithm.

Paper number 16:
Title: Optimal monophasic, asymmetric electric field pulses for selective transcranial magnetic stimulation (TMS) with minimised power and coil heating
Authors: Ke Ma, Andrey Vlasov, Zeynep B. Simsek, Jinshui Zhang, Yiru Li, Boshuo Wang, David L. K. Murphy, Jessica Y. Choi, Maya E. Clinton, Noreen Bukhari-Parlakturk, Angel V. Peterchev, Stephan M. Goetz
Abstract: Transcranial magnetic stimulation (TMS) with asymmetric electric field pulses, such as monophasic, offers directional selectivity for neural activation but requires excessive energy. Previous pulse shape optimisation has been limited to symmetric pulses or heavily constrained variations of conventional waveforms without achieving general optimality in energy efficiency or neural selectivity. We implemented an optimisation framework that incorporates neuron model activation constraints and flexible control of pulse asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 % reduction in energy loss and thus coil heating respectively compared to conventional monophasic pulses and previously improved monophasic-equivalent pulses. In the human experiments, OUR pulses showed similar motor thresholds to monophasic pulses in both AP and PA directions with significantly lower energy loss, particularly in the AP direction. Moreover, there was a significant MEP latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR pulses, which suggests directional selectivity. Our framework successfully identified highly energy-efficient asymmetric pulses for directionally-selective neural engagement. These pulses can enable selective rapid-rate repetitive TMS protocols with reduced power consumption and coil heating, with potential benefits for precision and potency of neuro-modulation.

Paper number 17:
Title: Low-cost Pyranometer-Based ANN Approach for MPPT in Solar PV Systems
Authors: Luiz Fernando M. Arruda, Moises Ferber, Diego Greff
Abstract: This article presents a study on the application of artificial neural networks (ANNs) for maximum power point tracking (MPPT) in photovoltaic (PV) systems using low-cost pyranometer sensors. The proposed approach integrates pyranometers, temperature sensors, and an ANN to estimate the duty cycle of a DC/DC converter, enabling the system to consistently operate at its maximum power point. The strategy was implemented in the local control of a Cuk converter and experimentally validated against the conventional Perturb and Observe (P&O) method. Results demonstrate that the ANN-based technique, leveraging affordable sensor technology, achieves accurate MPPT performance with reduced fluctuations, enhancing the responsiveness and efficiency of PV tracking systems.

Paper number 18:
Title: Discovering interpretable piecewise nonlinear model predictive control laws via symbolic decision trees
Authors: Ilias Mitrai
Abstract: In this paper, we propose symbolic decision trees as surrogate models for approximating model predictive control laws. The proposed approach learns simultaneously the partition of the input domain (splitting logic) as well as local nonlinear expressions for predicting the control action leading to interpretable piecewise nonlinear control laws. The local nonlinear expressions are determined by the learning problem and are modeled using a set of basis functions. The learning task is posed as a mixed integer optimization, which is solved to global optimality with state-of-the-art global optimization solvers. We apply the proposed approach to a case study regarding the control of an isothermal reactor. The results show that the proposed approach can learn the control law accurately, leading to closed-loop performance comparable to that of a standard model predictive controller. Finally, comparison with existing interpretable models shows that the symbolic trees achieve both lower prediction error and superior closed-loop performance.

Paper number 19:
Title: Synchrosqueezed windowed linear canonical transform: A method for mode retrieval from multicomponent signals with crossing instantaneous frequencies
Authors: Shuixin Li, Jiecheng Chen, Qingtang Jiang, Jian Lu
Abstract: In nature, signals often appear in the form of the superposition of multiple non-stationary signals. The overlap of signal components in the time-frequency domain poses a significant challenge for signal analysis. One approach to addressing this problem is to introduce an additional chirprate parameter and use the chirplet transform (CT) to elevate the two-dimensional time-frequency representation to a three-dimensional time-frequency-chirprate representation. From a certain point of view, the CT of a signal can be regarded as a windowed special linear canonical transform of that signal, undergoing a shift and a modulation. In this paper, we develop this idea to propose a novel windowed linear canonical transform (WLCT), which provides a new time-frequency-chirprate representation. We discuss four types of WLCTs. In addition, we use a special X-ray transform to further sharpen the time-frequency-chirprate representation. Furthermore, we derive the corresponding three-dimensional synchrosqueezed transform, demonstrating that the WLCTs have great potential for three-dimensional signal separation.

Paper number 20:
Title: Risk-Budgeted Control Framework for Balanced Performance and Safety in Autonomous Vehicles
Authors: Pei Yu Chang, Vishnu Renganathan, Qadeer Ahmed
Abstract: This paper presents a risk-budgeted monitor with a control framework that certifies safety for autonomous driving. In this process, a sliding window is proposed to monitor for insufficient barrier residuals or nonzero tail risk, ensuring system safety. When the safety margin deteriorates, it triggers switching the safety constraint from a performance-based relaxed-control barrier function (R-CBF) to a conservative conditional value at risk (CVaR-CBF) to address the safety concern. This switching is governed by two real-time triggers: Feasibility-Triggered (FT) and Quality-Triggered (QT) conditions. In the FT condition, if the R-CBF constraint becomes infeasible or yields a suboptimal solution, the risk monitor triggers the use of the CVaR constraints for the controller. In the QT condition, the risk monitor observes the safety margin of the R-CBF solution at every step, regardless of feasibility. If it falls below the safety margin, the safety filter switches to the CVaR-CBF constraints. The proposed framework is evaluated using a model predictive controller (MPC) for autonomous driving in the presence of autonomous vehicle (AV) localization noise and obstacle position uncertainties. Multiple AV-pedestrian interaction scenarios are considered, with 1,500 Monte Carlo runs conducted for all scenarios. In the most challenging setting with pedestrian detection uncertainty of 5 m, the proposed framework achieves a 94-96% success rate of not colliding with the pedestrians over 300 trials while maintaining the lowest mean cross-track error (CTE = 3.2-3.6 m) to the reference path. The reduced CTE indicates faster trajectory recovery after obstacle avoidance, demonstrating a balance between safety and performance.

Paper number 21:
Title: Controller for Incremental Input-to-State Practical Stabilization of Partially Unknown systems with Invariance Guarantees
Authors: P Sangeerth, David Smith Sundarsingh, Bhabani Shankar Dey, Pushpak Jagtap
Abstract: Incremental stability is a property of dynamical systems that ensures the convergence of trajectories with respect to each other rather than a fixed equilibrium point or a fixed trajectory. In this paper, we introduce a related stability notion called incremental input-to-state practical stability ({\delta}-ISpS), ensuring safety guarantees. We also present a feedback linearization based control design scheme that renders a partially unknown system incrementally input-to-state practically stable and safe with formal guarantees. To deal with the unknown dynamics, we utilize Gaussian process regression to approximate the model. Finally, we implement the controller synthesized by the proposed scheme on a manipulator example

Paper number 22:
Title: Multi-Carrier Rydberg Atomic Quantum Receivers with Enhanced Bandwidth Feature for Communication and Sensing
Authors: Huizhi Wang, Tierui Gong, Emil Björnson, Chau Yuen
Abstract: Rydberg atomic quantum receivers (RAQRs) have attracted significant attention in recent years due to their ultra-high sensitivity. Although capable of precisely detecting the amplitude and phase of weak signals, conventional RAQRs face inherent limitations in accurately receiving wideband RF signals, due to the discrete nature of atomic energy levels and their intrinsic instantaneous bandwidth constraints. These limitations hinder their direct application to multi-carrier communication and sensing. To address this issue, this paper proposes a multi-carrier Rydberg atomic quantum receiver (MC-RAQR) structure with five energy levels. We derive the amplitude and phase of the MC-RAQR and extract the baseband electrical signal for signal processing. In terms of multi-carrier communication and sensing, we analyze the channel capacity and accuracy of angle of arrival (AoA) and distance parameters, respectively. Numerical results validate our proposed model, showing that the MC-RAQR can achieve up to a bandwidth of 14 MHz, which is 56-fold larger than the conventional RAQRs. As a result, the channel capacity and the resolution for multi-target sensing are improved significantly. Specifically, the channel capacity of MC-RAQR is 22-fold and 3-fold larger than the conventional antennas and RAQRs, respectively. For sensing performance, the MSE of AoA estimation for MC-RAQR is 0.16% of the conventional RAQR and the MSE of distance estimation is 0.01% of the CRB of conventional antennas, showing the superior performance of the MC-RAQR. This demonstrates its compatibility with waveforms such as orthogonal frequency-division multiplexing (OFDM) and its significant advantages for multi-carrier signal reception.

Paper number 23:
Title: Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework
Authors: Shanzhi Yin, Bolin Chen, Xinju Wu, Ru-Ling Liao, Jie Chen, Shiqi Wang, Yan Ye
Abstract: This paper proposes an efficient 3D avatar coding framework that leverages compact human priors and canonical-to-target transformation to enable high-quality 3D human avatar video compression at ultra-low bit rates. The framework begins by training a canonical Gaussian avatar using articulated splatting in a network-free manner, which serves as the foundation for avatar appearance modeling. Simultaneously, a human-prior template is employed to capture temporal body movements through compact parametric representations. This decomposition of appearance and temporal evolution minimizes redundancy, enabling efficient compression: the canonical avatar is shared across the sequence, requiring compression only once, while the temporal parameters, consisting of just 94 parameters per frame, are transmitted with minimal bit-rate. For each frame, the target human avatar is generated by deforming canonical avatar via Linear Blend Skinning transformation, facilitating temporal coherent video reconstruction and novel view synthesis. Experimental results demonstrate that the proposed method significantly outperforms conventional 2D/3D codecs and existing learnable dynamic 3D Gaussian splatting compression method in terms of rate-distortion performance on mainstream multi-view human video datasets, paving the way for seamless immersive multimedia experiences in meta-verse applications.

Paper number 24:
Title: Graph Signal Wiener Filtering in the Linear Canonical Domain: Theory and Method Design
Authors: Xiaopeng Cheng, Zhichao Zhang
Abstract: The graph linear canonical transform (GLCT)-based filtering methods often optimize transform parameters and filters separately, which results in high computational costs and limited stability. To address this issue, this paper proposes a trainable joint optimization framework that combines GLCT parameters and Wiener filtering into an end-to-end learning process, allowing for synergistic optimization between transform domain construction and filtering operations. The proposed method not only eliminates the cumbersome grid search required by traditional strategies but also significantly enhances the flexibility and training stability of the filtering system. Experimental results on real-world graph data show the proposed method outperforms existing methods in denoising tasks, featuring superior denoising performance, higher robustness and lower computational complexity.

Paper number 25:
Title: SVD-based ugmt-gft on directed product graphs
Authors: Guoyun Xie, Zhichao Zhang
Abstract: Traditional directed graph signal processing generally depends on fixed representation matrices, whose rigid structures limit the model's ability to adapt to complex graph topologies. To address this issue, this study employed the unified graph representation matrix (UGRM) to propose a generalized graph Fourier transform (UGRM-GFT) method based on singular value decomposition (SVD) for signal analysis on directed graphs and Cartesian product graphs. We defined UGRM-GFT for general directed graphs by introducing a parameterized UGRM that incorporates traditional representations such as the Laplacian matrix and adjacency matrix. The SVD is used to construct spectral transform pairs with both left and right singular vectors. We extended this approach to two types of UGRM-GFTs applied to directed Cartesian product graphs. UGRM-GFT-I performs SVD directly on the composite UGRM matrix of the two-dimensional graph structure, suitable for globally coupled graph signals. UGRM-GFT-II separately applies SVD to the UGRMs of the two-factor graphs and then combines the results, significantly reducing computational complexity while preserving spectral expressiveness. Theoretical analysis confirmed the monotonicity of the proposed method with respect to the parameters alpha and k embedded in the UGRM. Experimental results on real-world datasets demonstrated that the proposed method significantly outperforms traditional fixed-matrix approaches in denoising tasks, with a particular emphasis on signal-to-noise ratio and bandwidth efficiency.

Paper number 26:
Title: Data Integration Using Multivariate Mode Decomposition for Physiological Sensing with Multiple Millimeter-Wave Radar Systems
Authors: Kimitaka Sumi, Takuya Sakamoto
Abstract: This study proposes a multi-radar system for non-contact physiological sensing across arbitrary body orientations. In integrating signals obtained from different radar viewpoints, we adopt a multivariate variational mode decomposition method to extract the common respiratory component. Experiments conducted with six subjects under varying distances and orientations demonstrate that, compared with a single-radar setup, the proposed system reduced the root mean square error of the respiratory interval by 35.5%, decreased the mean absolute error of the respiratory rate by 30.8%, and improved accuracy by 9.4 percentage points. These results highlight that combining multiple radar viewpoints with signal integration enables stable respiratory measurement regardless of body orientation.

Paper number 27:
Title: Transforming Tarlac State University (TSU) Gymnasium to a Nearly Zero-Energy Building through Integration of a Solar Photovoltaic (PV) System
Authors: Rafael R. Yumul, Enalyn T. Domingo
Abstract: The study is anchored to the principles of Nearly-Zero Energy Building (NZEB). It aimed to transform the Tarlac State University Gymnasium into a facility with energy-efficient equipment to contribute to reducing carbon footprints by integrating a solar PV system as its renewable energy source. The researchers found out that the electrical infrastructure of the Gym was outdated, and the lighting was not energy efficient, and there were too few convenience or power outlets. There was also insufficient cooling equipment to maintain a comfortable temperature. Analysis shows that the payback period is within the average range, making it a cost-effective investment for the University. Aside from the cost of the PV System, adherence to engineering design standards will mean additional costs to replace the metal halides with LED high bay lamps, installation of additional air conditioning units, and provision of additional convenience outlets. These additional costs should be considered when evaluating the feasibility of the project. It is recommended that the integrity of the existing roof system of the Gymnasium be considered. The total cost of putting up the whole electrical system, including new lighting, cooling, and convenience loads, must be calculated to determine the total cost of implementing the whole NZEB project. Other factors in the economic evaluation may be considered to determine a more stringent result.

Paper number 28:
Title: Large Language Model-Empowered Channel Prediction and Predictive Beamforming for LEO Satellite Communications
Authors: Zhixiong Chen, Hyundong Shin, Arumugam Nallanathan, Jonathon Chambers
Abstract: Accurate channel prediction and effective beamforming are essential for low Earth orbit (LEO) satellite communications to enhance system capacity and enable high-speed connectivity. Most existing channel prediction and predictive beamforming methods are limited by model generalization capabilities and struggle to adapt to time-varying wireless propagation environments. Inspired by the remarkable generalization and reasoning capabilities of large language models (LLMs), this work proposes an LLM-based channel prediction framework, namely CPLLM, to forecast future channel state information (CSI) for LEO satellites based on historical CSI data. In the proposed CPLLM, a dedicated CSI encoder is designed to map raw CSI data into the textual embedding space, effectively bridging the modality gap and enabling the LLM to perform reliable reasoning over CSI data. Additionally, a CSI decoder is introduced to simultaneously predict CSI for multiple future time slots, substantially reducing the computational burden and inference latency associated with the inherent autoregressive decoding process of LLMs. Then, instead of training the LLM from scratch, we adopt a parameter-efficient fine-tuning strategy, i.e., LoRA, for CPLLM, where the pretrained LLM remains frozen and trainable low-rank matrices are injected into each Transformer decoder layer to enable effective fine-tuning. Furthermore, we extend CPLLM to directly generate beamforming strategies for future time slots based on historical CSI data, namely BFLLM. This extended framework retains the same architecture as CPLLM, while introducing a dedicated beamforming decoder to output beamforming strategies. Finally, extensive simulation results validate the effectiveness of the proposed approaches in channel prediction and predictive beamforming for LEO satellite communications.

Paper number 29:
Title: Covert Waveform Design for Integrated Sensing and Communication System in Clutter Environment
Authors: Xuyang Zhao, Jiangtao Wang, Xinyu Zhang
Abstract: This paper proposes an integrated sensing and communication (ISAC) system covert waveform design method for complex clutter environments, with the core objective of maximizing the signal-to-clutter-plus-noise ratio (SCNR). The design achieves efficient clutter suppression while meeting the covertness requirement through joint optimization of the transmit waveform and receive filter, enabling cooperative radar detection and wireless communication. This study presents key innovations that explicitly address target Doppler shift uncertainty, significantly enhancing system robustness against Doppler effects. To ensure communication reliability, the method incorporates phase difference constraints between communication signal elements in the waveform design, along with energy constraint, covert constraint, and peak-to-average power ratio (PAPR) constraint. The original non-convex optimization problem is transformed into a tractable convex optimization form through convex optimization technique. Simulation results demonstrate that the optimized waveform not only satisfies the covertness requirement in complex clutter environment, but also achieves superior target detection performance. It also ensures reliable communication and confirms the effectiveness of propose method.

Paper number 30:
Title: A Parametric Power Model of Upper Mid-Band (FR3) Base Stations for 6G
Authors: Emanuele Peschiera, Sangbu Yun, Youngjoo Lee, Liesbet Van der Perre, François Rottenberg
Abstract: Increasing attention is given to the upper mid-band or Frequency Range 3 (FR3), from 7 to 24 GHz, in the research towards sixth-generation (6G) networks. Promises of offering large data rates at favorable propagation conditions are leading to novel FR3 base station (BS) architectures, with up to thousands of antenna elements and radio-frequency (RF) chains. This work investigates the power consumption of prospective FR3 BSs and its relation to the delivered data rates. We model the power consumed by digital and analog signal processing, power amplifiers (PAs), and supply and cooling during four phases (data, signaling, micro-sleep, and idle) in downlink and uplink. Hybrid partially-connected beamforming is compared to fully-digital one. Results show that, for BS arrays with $1024$ antennas at $30\%$ of load, the PA consumes most of the power when $64$ or less RF chains are utilized, while the digital and analog processing consumption takes over when the number of RF chains is $512$ or more. The digital plus analog processing consumes $2\times$ to $4\times$ more than the PA for fully-digital beamforming. Hybrid beamforming achieves $1.3$ Gbit/s/user in downlink while improving the energy efficiency by $1.4\times$ compared to fully-digital beamforming.

Paper number 31:
Title: JND-Guided Light-Weight Neural Pre-Filter for Perceptual Image Coding
Authors: Chenlong He, Zijing Dong, Min Li, Zhijian Hao, Leilei Huang, Xiaoyang Zeng, Yibo Fan
Abstract: Just Noticeable Distortion (JND)-guided pre-filter is a promising technique for improving the perceptual compression efficiency of image coding. However, existing methods are often computationally expensive, and the field lacks standardized benchmarks for fair comparison. To address these challenges, this paper introduces a twofold contribution. First, we develop and open-source FJNDF-Pytorch, a unified benchmark for frequency-domain JND-Guided pre-filters. Second, leveraging this platform, we propose a complete learning framework for a novel, lightweight Convolutional Neural Network (CNN). Experimental results demonstrate that our proposed method achieves state-of-the-art compression efficiency, consistently outperforming competitors across multiple datasets and encoders. In terms of computational cost, our model is exceptionally lightweight, requiring only 7.15 GFLOPs to process a 1080p image, which is merely 14.1% of the cost of recent lightweight network. Our work presents a robust, state-of-the-art solution that excels in both performance and efficiency, supported by a reproducible research platform. The open-source implementation is available at this https URL.

Paper number 32:
Title: Aggregate Modeling of Air-Conditioner Loads Under Packet-based Control with Both On and Off Grid Access Requests
Authors: Mohammad Hassan, Mads R. Almassalkhi
Abstract: Coordination of distributed energy resources (DERs) can engender flexibility necessary to improve grid reliability. Packetized Energy Management (PEM) is a method for coordinating DERs, such as thermostatically controlled loads (TCLs) and electric vehicles, within customer quality-of-service (QoS) limits. In PEM, a DER uses local information to offer flexibility by sending a request to the DER coordinator to turn-ON or turn-OFF. Much work has focused on modeling and analyzing aggregations of DERs under PEM with fixed packet durations and only turn-ON requests. Different recent efforts to enable variable packet lengths have shown an increase in available flexibility and ramping capability, but have not been modeled in aggregate, which limits systematic analyses. To address this issue, this paper presents a new aggregate bin-based (macro) model of PEM loads that incorporates both turn-ON and turn-OFF request features, enabling the model to accurately characterize the capability of the fleet of DERs to track a power reference signal, population temperature dynamics, aggregate request rates, and variable packet lengths. Simulation-based validation is performed against an agent-based (micro) model to evaluate robustness and quantify model accuracy. Finally, the distribution of variable packet lengths from macro-model simulations are applied to inform past work on PEM with randomized packet lengths

Paper number 33:
Title: HYPERDOA: Robust and Efficient DoA Estimation using Hyperdimensional Computing
Authors: Rajat Bhattacharjya, Woohyeok Park, Arnab Sarkar, Hyunwoo Oh, Mohsen Imani, Nikil Dutt
Abstract: Direction of Arrival (DoA) estimation techniques face a critical trade-off, as classical methods often lack accuracy in challenging, low signal-to-noise ratio (SNR) conditions, while modern deep learning approaches are too energy-intensive and opaque for resource-constrained, safety-critical systems. We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Computing (HDC). The framework introduces two distinct feature extraction strategies -- Mean Spatial-Lag Autocorrelation and Spatial Smoothing -- for its HDC pipeline, and then reframes DoA estimation as a pattern recognition problem. This approach leverages HDC's inherent robustness to noise and its transparent algebraic operations to bypass the expensive matrix decompositions and ``black-box'' nature of classical and deep learning methods, respectively. Our evaluation demonstrates that HYPERDOA achieves ~35.39% higher accuracy than state-of-the-art methods in low-SNR, coherent-source scenarios. Crucially, it also consumes ~93% less energy than competing neural baselines on an embedded NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and efficiency establishes HYPERDOA as a robust and viable solution for mission-critical applications on edge devices.

Paper number 34:
Title: Spatially Filtered Sparse Bayesian Learning for Direction-of-Arrival Estimation with Leaky-Wave Antennas
Authors: R. Maydani, Y. Wang, J. Sarrazin, B. Ma
Abstract: Direction-of-arrival (DoA) estimation with leaky-wave antennas (LWAs) offers a compact and cost-effective alternative to conventional antenna arrays but remains challenging in the presence of coherent sources. To address this issue, we propose a spatially filtered sparse Bayesian learning (SF-SBL) framework. Firstly, the field of view (FoV) is divided into angular sectors according to the frequency beam-scanning property of LWAs, and Bayesian inverse problems are then solved within each sector to improve efficiency and reduce computational cost. Both on-grid SBL and off-grid SBL formulations are developed. Simulation results show that the proposed approach achieves robust and accurate DoA estimation, even with coherent sources.

Paper number 35:
Title: Structured identification of multivariable modal systems
Authors: Maarten van der Hulst, Rodrigo A. González, Koen Classens, Paul Tacx, Nick Dirkx, Jeroen van de Wijdeven, Tom Oomen
Abstract: Physically interpretable models are essential for next-generation industrial systems, as these representations enable effective control, support design validation, and provide a foundation for monitoring strategies. The aim of this paper is to develop a system identification framework for estimating modal models of complex multivariable mechanical systems from frequency response data. To achieve this, a two-step structured identification algorithm is presented, where an additive model is first estimated using a refined instrumental variable method and subsequently projected onto a modal form. The developed identification method provides accurate, physically-relevant, minimal-order models, for both generally-damped and proportionally damped modal systems. The effectiveness of the proposed method is demonstrated through experimental validation on a prototype wafer-stage system, which features a large number of spatially distributed actuators and sensors and exhibits complex flexible dynamics.

Paper number 36:
Title: Perceptual Compensation of Ambisonics Recordings for Reproduction in Room
Authors: Ali Fallah, Shun Nakamura, Steven van de Par
Abstract: Ambisonics is a method for capturing and rendering a sound field accurately, assuming that the acoustics of the playback room does not significantly influence the sound field. However, in practice, the acoustics of the playback room may lead to a noticeable degradation in sound quality. We propose a recording and rendering method based on Ambisonics that utilizes a perceptually-motivated approach to compensate for the reverberation of the playback room. The recorded direct and reverberant sound field components in the spherical harmonics (SHs) domain are spectrally and spatially compensated to preserve the relevant auditory cues including the direction of arrival of the direct sound, the spectral energy of the direct and reverberant sound components, and the Interaural Coherence (IC) across each auditory band. In contrast to the conventional Ambisonics, a flexible number of Ambisonics channels can be used for audio rendering. Listening test results show that the proposed method provides a perceptually accurate rendering of the originally recorded sound field, outperforming both conventional Ambisonics without compensation and even ideal Ambisonics rendering in a simulated anechoic room. Additionally, subjective evaluations of listeners seated at the center of the loudspeaker array demonstrate that the method remains robust to head rotation and minor displacements.

Paper number 37:
Title: Observability and parameter estimation of a generic model for aggregated distributed energy resources
Authors: Bukunmi Gabriel Odunlami, Marcos Netto
Abstract: We propose a novel framework for estimating the parameters of an aggregated distributed energy resources (der_a) model. First, we introduce a rigorous method to determine whether all model parameters are estimable. When they are not, our approach identifies the subset of parameters that can be estimated. The proposed framework offers new insights into the number and specific parameters that can be reliably estimated based on commonly available measurements. It also highlights the limitations of calibrating such models. Second, we introduce a Kalman filtering method to calibrate the der_a model. Since we account for nonlinear effects such as saturation and deadbands, we develop a specific mechanism to handle smoothing functions within the Kalman filter. Specifically, we consider the extended and the unscented Kalman filter. We demonstrate the effectiveness of the proposed framework on a modified IEEE 34-node distribution feeder with inverter-based resources. Our findings align with the North American Electric Reliability Corporation's parameterization guideline and underscore the importance of model calibration in accurately capturing the collective dynamics of distributed energy resources installed on distribution systems.

Paper number 38:
Title: Optimal Multi-Modal Transportation and Electric Power Flow: The Value of Coordinated Dynamic Operation
Authors: Jiajie Qiu, Dakota Thompson, Kamal Youcef-Toumi, Amro M. Farid
Abstract: The electrification of transportation represents a critical challenge in the global transition toward net-zero emissions, as the sector often accounts for more than one-quarter of national energy consumption. Achieving this transformation requires not only widespread adoption of electric vehicles (EVs) but also their seamless integration into interdependent infrastructure systems-specifically, the transportation-electricity nexus (TEN). This paper develops an optimal multi-modal transportation and electric power flow (OMTEPF) model to evaluate the benefits of coordinated, dynamic system operation. Building on recent advances in hetero-functional graph theory, the framework enables joint optimization of five key operational decisions in intelligent TEN management: vehicle dispatch, route choice, charging station queuing, coordinated charging, and vehicle-to-grid stabilization. The mesoscopic, dynamic model explicitly represents individual EVs and their state-of-charge trajectories, thereby extending beyond the prevailing literature's focus on static, macroscopic traffic assignment. It further captures the full scope of the TEN as a system-of-systems, incorporating five distinct charging modalities: private residential, private commercial, wired public commercial, inductive public, and discharging. On the power system side, an IV-ACOPF formulation ensures globally optimal solutions to the electrical subproblems. Comparative analysis demonstrates the substantial value of coordinated TEN operation relative to the status quo of siloed, uncoordinated infrastructure management. This work provides both a novel methodological contribution and actionable insights for the co-design and operation of next-generation sustainable mobility-energy systems.

Paper number 39:
Title: Spatial Signal Focusing and Noise Suppression for Direction-of-Arrival Estimation in Large-Aperture 2D Arrays under Demanding Conditions
Authors: Xuyao Deng, Yong Dou, Kele Xu
Abstract: Direction-of-Arrival (DOA) estimation in sensor arrays faces limitations under demanding conditions, including low signal-to-noise ratio, single-snapshot scenarios, coherent sources, and unknown source counts. Conventional beamforming suffers from sidelobe interference, adaptive methods (e.g., MVDR) and subspace algorithms (e.g., MUSIC) degrade with limited snapshots or coherent signals, while sparse-recovery approaches (e.g., L1-SVD) incur high computational complexity for large arrays. In this article, we construct the concept of the optimal spatial filter to solve the DOA estimation problem under demanding conditions by utilizing the sparsity of spatial signals. By utilizing the concept of the optimal spatial filter, we have transformed the DOA estimation problem into a solution problem for the optimal spatial filter. We propose the Spatial Signal Focusing and Noise Suppression (SSFNS) algorithm, which is a novel DOA estimation framework grounded in the theoretical existence of an optimal spatial filter, to solve for the optimal spatial filter and obtain DOA. Through experiments, it was found that the proposed algorithm is suitable for large aperture two-dimensional arrays and experiments have shown that our proposed algorithm performs better than other algorithms in scenarios with few snapshots or even a single snapshot, low signal-to-noise ratio, coherent signals, and unknown signal numbers in two-dimensional large aperture arrays.

Paper number 40:
Title: Bit Allocation Transfer for Perceptual Quality Enhancement of VVC Intra Coding
Authors: Runyu Yang, Ivan V. Bajić
Abstract: Mainstream image and video coding standards -- including state-of-the-art codecs like H.266/VVC, AVS3, and AV1 -- adopt a block-based hybrid coding framework. While this framework facilitates straightforward optimization for Peak Signal-to-Noise Ratio (PSNR), it struggles to effectively optimize perceptually-aligned metrics such as Multi-Scale Structural Similarity (MS-SSIM). To address this challenge, this paper proposes a low-complexity method to enhance perceptual quality in VVC intra coding by transferring bit allocation knowledge from end-to-end image compression. We introduce a lightweight model trained with perceptual losses to generate a quantization step map. This map implicitly captures block-level perceptual importance, enabling efficient derivation of a QP map for VVC. Experiments on Kodak and CLIC datasets demonstrate significant advantages, both in execution time and perceptual metric performance, with more than 11% BD-rate reduction in terms of MS-SSIM. Our scheme provides an efficient, practical pathway for perceptual enhancement of traditional codecs.

Paper number 41:
Title: Dual-Waveguide Pinching Antennas for PLS: Parallel Placement or Orthogonal Placement?
Authors: Yang Lu, Xinke Xie, Yanqing Xu, Bo Ai, Octavia A. Dobre, Dusit Niyato
Abstract: Pinching antennas (PAs), as an emerging flexible-antenna technology, enables movable PAs deployed along waveguides to customize channel conditions over a large scale. This paper investigates an application of PAs to enable physical-layer security (PLS) by enlarging the channel condition diversity between legitimate users (LUs) and eavesdroppers (Eves). Particularly, we focus on the dual-waveguide scenario, where the two waveguides employs multiple PAs to serve multiple LUs in the presence of an Eve. Specifically, we consider two waveguide placement strategies, i.e., parallel placement and orthogonal placement. Meanwhile, we incorporate two channel models, i.e., in-waveguide phase shifts, and in-waveguide phase shifts and attenuation. We formulate the secure sum rate (SSR) and secure energy efficiency (SEE) maximization problems, and propose a two-stage algorithm to solve them. The first stage adopts a particle swarm optimization (PSO) method with an improved feasibility module, termed FeaPSO, for PA placement, and the second stage employs the successive convex approximate (SCA) method to optimize beamforming and artificial noise vectors. Furthermore, we conduct numerical comparisons between the two placement strategies in terms of average performance and a special case where an Eve is positioned in front of LUs. Numerical results validate the effectiveness of the proposed algorithm and demonstrate that PAs can significantly improve both SSR and SEE. Additionally, the necessity of orthogonal waveguide placement is explicitly verified.

Paper number 42:
Title: Establishing assembly-oriented modular product architectures through Design for Assembly enhanced Modular Function Deployment
Authors: Fabio Marco Monetti, Adam Lundström, Colin de Kwant, Magnus Gyllenskepp, Antonio Maffei
Abstract: Modular product design has become a strategic enabler for companies seeking to balance product variety, operational efficiency, and market responsiveness, making the alignment between modular architecture and manufacturing considerations increasingly critical. Modular Function Deployment (MFD) is a widely adopted method for defining modular product architectures, yet it lacks systematic support for assembly considerations during early concept and system-level development. This limitation increases the risk of delayed production ramp-up and lifecycle inefficiencies. This paper proposes a set of enhancements to MFD that integrate Design for Assembly (DFA) logic into architectural synthesis. The extended method introduces structured heuristics, assembly-oriented module drivers, a coded interface taxonomy, and quantitative metrics for assessing assembly feasibility and automation readiness. These additions preserve compatibility with standard MFD workflows while enriching decision-making with traceable, production-informed reasoning. An illustrative case study involving a handheld leaf blower demonstrates the method's usability and effectiveness. The redesigned architecture shows reduced assembly effort, simplified interfaces, and increased automation potential. By supporting early-stage evaluation of architectural alternatives through an assembly lens, the method enables faster transition to efficient volume production and provides a foundation for continuous improvement throughout the product lifecycle.

Paper number 43:
Title: The Post-Electromagnetic Era: A Vision for Wireless Communication Beyond 6G
Authors: Shumaila Javaid, Nasir Saeed
Abstract: Electromagnetic (EM) communication is nearing its physical and thermodynamic limits, where further performance gains through spectrum optimization alone have become increasingly unsustainable. Finite bandwidth, propagation loss at higher frequencies, and the inherent trade-offs between energy and information constrain the scalability of 6G and beyond systems. These limitations drive the search for alternative mechanisms for information transfer beyond conventional EM propagation. This work introduces a state-centric framework for post-6G communication, in which information is conveyed by manipulating physical, biological, and cognitive states rather than EM waves. It identifies ten foundational paradigms that define potential carriers and interaction mechanisms for the post-electromagnetic era and outlines a research roadmap toward self-organizing, cognitively integrated networks. Together, these developments envision a new class of communication systems that are energy-aware, adaptive, and capable of uniting matter, life, and intelligence within a single informational continuum. By establishing the conceptual basis for this transition, the work provides a foundation for future research aimed at realizing communication paradigms that transcend the limitations of spectrum-bound systems.

Paper number 44:
Title: Navigating the Dual-Use Nature and Security Implications of Reconfigurable Intelligent Surfaces in Next-Generation Wireless Systems
Authors: Hetong Wang, Tiejun Lv, Yashuai Cao, Weicai Li, Jie Zeng, Pingmu Huang, Muhammad Khurram Khan
Abstract: Reconfigurable intelligent surface (RIS) technology offers significant promise in enhancing wireless communication systems, but its dual-use potential also introduces substantial security risks. This survey explores the security implications of RIS in next-generation wireless networks. We first highlight the dual-use nature of RIS, demonstrating how its communication-enhancing capabilities can be exploited by adversaries to compromise legitimate users. We identify a new class of security vulnerabilities termed ``passive-active hybrid attacks,'' where RIS, despite passively handling signals, can be reconfigured to actively engage in malicious activities, enabling various RIS-assisted attacks, such as eavesdropping, man-in-the-middle (MITM), replay, reflection jamming, and side-channel attacks. Furthermore, we reveal how adversaries can exploit the openness of wireless channels to introduce adversarial perturbations in artificial intelligence-driven RIS networks, disrupting communication terminals and causing misclassifications or errors in RIS reflection predictions. Despite these risks, RIS technology also plays a critical role in enhancing security and privacy across radio frequency (RF) and visible light communication (VLC) systems. By synthesizing current insights and highlighting emerging threats, we provide actionable insights into cross-layer collaboration, advanced adversarial defenses, and the balance between security and cost. This survey provides a comprehensive overview of RIS technology's security landscape and underscores the urgent need for robust security frameworks in the development of future wireless systems.

Paper number 45:
Title: WiNPA: Wireless Neural Processing Architecture
Authors: Sai Xu, Yanan Du
Abstract: This article presents a wireless neural processing architecture (WiNPA), providing a novel perspective for accelerating edge inference of deep neural network (DNN) workloads via joint optimization of wireless and computing resources. WiNPA enables fine-grained integration of wireless communication and edge computing, bridging the research gap between wireless and edge intelligence and significantly improving DNN inference performance. To fully realize its potential, we explore a set of fundamental research issues, including mathematical modeling, optimization, and unified hardware--software platforms. Additionally, key research directions are discussed to guide future development and practical implementation. A case study demonstrates WiNPA's workflow and effectiveness in accelerating DNN inference through simulations.

Paper number 46:
Title: Utilizing Bayesian Optimization for Timetable-Independent Railway Junction Performance Determination
Authors: Tamme Emunds, Paul Brunzema, Sebastian Trimpe, Nils Nießen
Abstract: The efficiency of railway infrastructure is significantly influenced by the mix of trains that utilize it, as different service types have competing operational requirements. While freight services might require extended service times, passenger services demand more predictable schedules. Traditional methods for addressing long-term traffic assignment problems often rely on fixed-value capacity limitations, determined based on specific assumptions about traffic composition. This paper introduces a methodology for determining timetable-independent capacity within the traffic rate assignment problem, enabling the calculation of junction capacities under dynamic traffic distributions. We solve the underlying non-linear constrained optimization problem maximizing the traffic throughput using Bayesian optimization (BO). This setting combines a known objective function with expensive- to-compute capacity constraints, motivating an adaption of standard BO problems, where objective functions are usually unknown. We tailor the acquisition process in BO to this specific setting and increase performance by incorporating prior knowledge about the shape of the constraint functions into the Gaussian process surrogate model. Our derived approaches are benchmarked on a railway junction near Paris, significantly outperforming fixed traffic composition models and highlighting the benefits of dynamic capacity allocation.

Paper number 47:
Title: Generalisation of automatic tumour segmentation in histopathological whole-slide images across multiple cancer types
Authors: Ole-Johan Skrede, Manohar Pradhan, Maria Xepapadakis Isaksen, Tarjei Sveinsgjerd Hveem, Ljiljana Vlatkovic, Arild Nesbakken, Kristina Lindemann, Gunnar B Kristensen, Jenneke Kasius, Alain G Zeimet, Odd Terje Brustugun, Lill-Tove Rasmussen Busund, Elin H Richardsen, Erik Skaaheim Haug, Bjørn Brennhovd, Emma Rewcastle, Melinda Lillesand, Vebjørn Kvikstad, Emiel Janssen, David J Kerr, Knut Liestøl, Fritz Albregtsen, Andreas Kleppe
Abstract: Deep learning is expected to aid pathologists by automating tasks such as tumour segmentation. We aimed to develop one universal tumour segmentation model for histopathological images and examine its performance in different cancer types. The model was developed using over 20 000 whole-slide images from over 4 000 patients with colorectal, endometrial, lung, or prostate carcinoma. Performance was validated in pre-planned analyses on external cohorts with over 3 000 patients across six cancer types. Exploratory analyses included over 1 500 additional patients from The Cancer Genome Atlas. Average Dice coefficient was over 80% in all validation cohorts with en bloc resection specimens and in The Cancer Genome Atlas cohorts. No loss of performance was observed when comparing the universal model with models specialised on single cancer types. In conclusion, extensive and rigorous evaluations demonstrate that generic tumour segmentation by a single model is possible across cancer types, patient populations, sample preparations, and slide scanners.

Paper number 48:
Title: CSI Prediction Using Diffusion Models
Authors: Mehdi Sattari, Javad Aliakbari, Alexandre Graell i Amat, Tommy Svensson
Abstract: Acquiring accurate channel state information (CSI) is critical for reliable and efficient wireless communication, but challenges such as high pilot overhead and channel aging hinder timely and accurate CSI acquisition. CSI prediction, which forecasts future CSI from historical observations, offers a promising solution. Recent deep learning approaches, including recurrent neural networks and Transformers, have achieved notable success but typically learn deterministic mappings, limiting their ability to capture the stochastic and multimodal nature of wireless channels. In this paper, we introduce a novel probabilistic framework for CSI prediction based on diffusion models, offering a flexible design that supports integration of diverse prediction schemes. We decompose the CSI prediction task into two components: a temporal encoder, which extracts channel dynamics, and a diffusion-based generator, which produces future CSI samples. We investigate two inference schemes-autoregressive and sequence-to-sequence- and explore multiple diffusion backbones, including U-Net and Transformer-based architectures. Furthermore, we examine a diffusion-based approach without an explicit temporal encoder and utilize the DDIM scheduling to reduce model complexity. Extensive simulations demonstrate that our diffusion-based models significantly outperform state-of-the-art baselines.

Paper number 49:
Title: Normalized Ambiguity Function Characteristics of OFDM, OTFS, AFDM, and CP-AFDM for ISAC
Authors: Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu
Abstract: This paper presents a unified and system-agnostic analysis of the ambiguity function (AF) characteristics of four representative multicarrier waveforms, orthogonal frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS), affine frequency division multiplexing (AFDM), and chirp-permuted AFDM (CP-AFDM), which are considered as key candidates for enabling integrated sensing and communications (ISAC) in future sixth generation (6G) networks. The AF of each waveform is obtained directly from its discrete-time definition and enhanced via ideal fractional interpolation, enabling precise characterization of its continuous-time delay-Doppler response. Two signaling modes are examined: a communication-oriented case with random information symbols suitable only for monostatic scenarios, and a sensing-oriented case with fixed unimodular symbols suitable for general multi-static scenarios. Furthermore, the AFs and the ambiguity metrics including the 3dB mainlobe width, peak-to-sidelobe ratio (PSLR), and integrated sidelobe ratio (ISLR), are evaluated in normalized delay-Doppler units, enabling direct translation to any physical system configuration defined by bandwidth, sampling frequency, or symbol duration, while ensuring straightforward and consistent comparison across waveforms. The results establish a consistent benchmark for comparing waveform sensing capabilities in ISAC design, consolidating known behaviors: OFDM exhibits excellent delay resolution and sidelobe behavior but poor Doppler response, whereas advanced waveforms achieve improved balance between delay and Doppler resolution with varying sidelobe characteristics. The simulation code of the smooth AFs, is openly shared to promote reproducibility and support future ISAC waveform research.

Paper number 50:
Title: Two-Dimensional Graph Bi-Fractional Fourier Transform
Authors: Mingzhi Wang, Zhichao Zhang
Abstract: Graph signal processing (GSP) advances spectral analysis on irregular domains. However, existing two-dimensional graph fractional Fourier transform (2D-GFRFT) employs a single fractional order for both factor graphs, thereby limiting its adaptability to heterogeneous signals. We proposed the two-dimensional graph bi-fractional Fourier transform (2D-GBFRFT), which assigns independent fractional orders to the factor graphs of a Cartesian product while preserving separability. We established invertibility, unitarity, and index additivity, and developed two filtering schemes: a Wiener-style design through grid search and a differentiable framework that jointly optimizes transform orders and diagonal spectral filters. We further introduced a hybrid interpolation with the joint time-vertex fractional Fourier transform (JFRFT), controlled by a tunable parameter that balances the two methods. In the domains of synthetic Cartesian product graph signals, authentic temporal graph datasets, and dynamic image deblurring, 2D-GBFRFT consistently surpasses 2D-GFRFT and enhances JFRFT. Experimental results confirmed the versatility and superior performance of 2D-GBFRFT for filtering in GSP.

Paper number 51:
Title: Edge-to-Cloud Computations-as-a-Service in Software-Defined Energy Networks for Smart Grids
Authors: Jack Jackman, David Ryan, Arun Narayanan, Pedro Nardelli, Indrakshi Dey
Abstract: Modern power grids face an acute mismatch between where data is generated and where it can be processed: protection relays, EV (Electric Vehicle) charging, and distributed renewables demand millisecond analytics at the edge, while energy-hungry workloads often sit in distant clouds leading to missed real-time deadlines and wasted power. We address this by proposing, to our knowledge, the first-ever SDEN (Software Defined Energy Network) for CaaS (Computations-as-a-Service) that unifies edge, fog, and cloud compute with 5G URLLC (Ultra-Reliable Low-Latency Communications), SDN (Software Defined Networking), and NFV (Network Functions Virtualization) to co-optimize energy, latency, and reliability end-to-end. Our contributions are threefold: (i) a joint task offloading formulation that couples computation placement with network capacity under explicit URLLC constraints; (ii) a feasibility preserving, lightweight greedy heuristic that scales while closely tracking optimal energy and latency trade-offs; and (iii) a tiered AI (Artificial Intelligence) pipeline-reactive at the edge, predictive in the fog, strategic in the cloud-featuring privacy-preserving, federated GNNs (Graph Neural Networks) for fault detection and microgrid coordination. Unlike prior edge-only or cloud-only schemes, SDEN turns fragmented grid compute into a single, programmable substrate that delivers dependable, energy-aware, real time analytics establishing a first-ever, software defined path to practical, grid-scale CaaS.

Paper number 52:
Title: Channel-Aware Deep Learning for Superimposed Pilot Power Allocation and Receiver Design
Authors: Run Gu, Renjie Xie, Wei Xu, Zhaohui Yang, Kaibin Huang
Abstract: Superimposed pilot (SIP) schemes face significant challenges in effectively superimposing and separating pilot and data signals, especially in multiuser mobility scenarios with rapidly varying channels. To address these challenges, we propose a novel channel-aware learning framework for SIP schemes, termed CaSIP, that jointly optimizes pilot-data power (PDP) allocation and a receiver network for pilot-data interference (PDI) elimination, by leveraging channel path gain information, a form of large-scale channel state information (CSI). The proposed framework identifies user-specific, resource element-wise PDP factors and develops a deep neural network-based SIP receiver comprising explicit channel estimation and data detection components. To properly leverage path gain data, we devise an embedding generator that projects it into embeddings, which are then fused with intermediate feature maps of the channel estimation network. Simulation results demonstrate that CaSIP efficiently outperforms traditional pilot schemes and state-of-the-art SIP schemes in terms of sum throughput and channel estimation accuracy, particularly under high-mobility and low signal-to-noise ratio (SNR) conditions.

Paper number 53:
Title: pyspect: An Extensible Toolbox for Automatic Construction of Temporal Logic Trees via Reachability Analysis
Authors: Kaj Munhoz Arfvidsson, Loizos Hadjiloizou, Frank J. Jiang, Karl H. Johansson, Jonas Mårtensson
Abstract: In this paper, we present pyspect, a Python toolbox that simplifies the use of reachability analysis for temporal logic problems. Currently, satisfying complex requirements in cyber-physical systems requires significant manual effort and domain expertise to develop the underlying reachability programs. This high development effort limits the broader adoption of reachability analysis for complex verification problems. To address this, pyspect provides a method-agnostic approach to performing reachability analysis for verifying a temporal logic specification via temporal logic trees (TLTs). It enables the specification of complex safety and liveness requirements using high-level logic formulations that are independent of any particular reachability technique or set representation. As a result, pyspect allows for the comparison of different reachability implementations, such as Hamilton-Jacobi and Hybrid Zonotope-based reachability analysis, for the same temporal logic specification. This design separates the concerns of implementation developers (who develop numerical procedures for reachability) and end-users (who write specifications). Through a simple vehicle example, we demonstrate how pyspect simplifies the synthesis of reachability programs, promotes specification reusability, and facilitates side-by-side comparisons of reachability techniques for complex tasks.

Paper number 54:
Title: Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding
Authors: Bingjie Zhu, Zhixiong Chen, Liqiang Zhao, Hyundong Shin, Arumugam Nallanathan
Abstract: Large language model (LLM) inference at the network edge is a promising serving paradigm that leverages distributed edge resources to run inference near users and enhance privacy. Existing edge-based LLM inference systems typically adopt autoregressive decoding (AD), which only generates one token per forward pass. This iterative process, compounded by the limited computational resources of edge nodes, results in high serving latency and constrains the system's ability to support multiple users under growing this http URL address these challenges, we propose a speculative decoding (SD)-based LLM serving framework that deploys small and large models across heterogeneous edge nodes to collaboratively deliver inference services. Specifically, the small model rapidly generates draft tokens that the large model verifies in parallel, enabling multi-token generation per forward pass and thus reducing serving latency. To improve resource utilization of edge nodes, we incorporate pipeline parallelism to overlap drafting and verification across multiple inference tasks. Based on this framework, we analyze and derive a comprehensive latency model incorporating both communication and inference latency. Then, we formulate a joint optimization problem for speculation length, task batching, and wireless communication resource allocation to minimize total serving latency. To address this problem, we derive the closed-form solutions for wireless communication resource allocation, and develop a dynamic programming algorithm for joint batching and speculation control strategies. Experimental results demonstrate that the proposed framework achieves lower serving latency compared to AD-based serving systems. In addition,the proposed joint optimization method delivers up to 44.9% latency reduction compared to benchmark schemes.

Paper number 55:
Title: A Dynamic Watermarking Technique for Matching Communication Addresses with Cars in a Visual Field
Authors: Woo-Hyun Ko, Jaewon Kim, Tzu-Hsiang Lin, Samin Moosavi, P. R. Kumar
Abstract: We consider a problem faced by an intelligent roadside unit (RSU) monitoring a roadway by a video camera. Suppose the RSU notices that a particular car in its visual field needs to execute a specific evasive maneuver to avoid danger. It would like to send a packet addressed to that particular car with this suggestion. The problem is that while all the cars are communicating with the RSU, the RSU does not know which car in the video is associated with what IP address. So, it does not know which IP address to send the packet to. Indeed, the problem of matching addresses with cars in the visual field is a fundamental open problem. We provide an active solution employing dynamic watermarking that was originally developed for the security of cyber-physical systems. This technique calls for a car to superpose a small random excitation onto its actuation commands for steering angle or throttle/brake positions. The car sends this random waveform to the RSU in a packet containing its IP address. By signal processing of the video stream of a car at the RSU it can verify whether it matches with the waveform in the packet and thereby associates that the IP address of the packet with that car in the visual field. The RSU thereby determines which IP address is associated with which car in its visual field. We present two demonstrations of performance. We demonstrate experimental results on a laboratory transportation automated vehicles, a vision system, and a network, as well as on the field with two passenger sedans in practice. The results demonstrate that employing the dynamic watermarking method enables an RSU to distinguish the communication of a target vehicle from that of other IP addresses of nearby vehicles.

Paper number 56:
Title: Phase Aware Ear-Conditioned Learning for Multi-Channel Binaural Speaker Separation
Authors: Ruben Johnson Robert Jeremiah, Peyman Goli, Steven van de Par
Abstract: Separating competing speech in reverberant environments requires models that preserve spatial cues while maintaining separation efficiency. We present a Phase-aware Ear-conditioned speaker Separation network using eight microphones (PEASE-8) that consumes complex STFTs and directly introduces a raw-STFT input to the early decoder layer, bypassing the entire encoder pathway to improve reconstruction. The model is trained end-to-end with an SI-SDR-based objective against direct-path ear targets, jointly performing separation and dereverberation for two speakers in a fixed azimuth, eliminating the need for permutation invariant training. On spatialized two-speaker mixtures spanning anechoic, reverberant, and noisy conditions, PEASE-8 delivers strong separation and intelligibility. In reverberant environments, it achieves 12.37 dB SI-SDR, 0.87 STOI, and 1.86 PESQ at T60 = 0.6 s, while remaining competitive under anechoic conditions.

Paper number 57:
Title: CIRSense: Rethinking WiFi Sensing with Channel Impulse Response
Authors: Ruiqi Kong, He Chen
Abstract: WiFi sensing based on channel state information (CSI) collected from commodity WiFi devices has shown great potential across a wide range of applications, including vital sign monitoring and indoor localization. Existing WiFi sensing approaches typically estimate motion information directly from CSI. However, they often overlook the inherent advantages of channel impulse response (CIR), a delay-domain representation that enables more intuitive and principled motion sensing by naturally concentrating motion energy and separating multipath components. Motivated by this, we revisit WiFi sensing and introduce CIRSense, a new framework that enhances the performance and interpretability of WiFi sensing with CIR. CIRSense is built upon a new motion model that characterizes fractional delay effects, a fundamental challenge in CIR-based sensing. This theoretical model underpins technical advances for the three challenges in WiFi sensing: hardware distortion compensation, high-resolution distance estimation, and subcarrier aggregation for extended range sensing. CIRSense, operating with a 160 MHz channel bandwidth, demonstrates versatile sensing capabilities through its dual-mode design, achieving a mean error of approximately 0.25 bpm in respiration monitoring and 0.09 m in distance estimation. Comprehensive evaluations across residential spaces, far-range scenarios, and multi-target settings demonstrate CIRSense's superior performance over state-of-the-art CSI-based baselines. Notably, at a challenging sensing distance of 20 m, CIRSense achieves at least 3x higher average accuracy with more than 4.5x higher computational efficiency.

Paper number 58:
Title: Uncertainty Propagation in Finite Impulse Response Filters: Evaluating the Gaussian Assumption
Authors: Jennie Couchman, Phillip Stanley-Marbell
Abstract: A common assumption in signal processing is that underlying data numerically conforms to a Gaussian distribution. It is commonly utilized in signal processing to describe unknown additive noise in a system and is often justified by citing the central limit theorem for sums of random variables, although the central limit theorem applies only to sums of independent identically distributed random variables. However, many linear operations in signal processing take the form of weighted sums, which transforms the random variables such that their distributions are no longer identical. One such operation is a finite impulse response (FIR) filter. FIR filters are commonly used in signal processing applications as a pre-processing step. FIR output noise is generally assumed to be Gaussian. This article examines the FIR output response in the presence of uniformly distributed quantization noise. We express the FIR output uncertainty in terms of the input quantization uncertainty and filter coefficients. We show that the output uncertainty cannot be assumed to be Gaussian, but depending on the application a Gaussian estimation may still be useful. Then, we show through detailed numerical simulations that the output uncertainty distribution of the filter can be estimated through its most dominant coefficients.

Paper number 59:
Title: High-Order Quarter-Wave Plate Optimization for Linear Birefringence Suppression in Reflective FOCS
Authors: Yuechen Liu, Boqi Meng
Abstract: Fiber optic current sensors (FOCS) are widely adopted in modern power grids due to high sensitivity, excellent insulation, and strong immunity to electromagnetic interference. This prominence necessitates precise investigation into their error sources and corresponding optimization. This study examines reflective FOCS based on the Faraday effect. A theoretical model is established to simulate phase error caused by linear birefringence from the quarter-wave plate. Conventional methods using circular birefringence are analyzed, revealing inherent limitations. Innovatively, a compensation strategy employing high-order quarter-wave plates is proposed to effectively eliminate linear birefringence effects. This approach significantly enhances the accuracy and practicality of FOCS in precision metrology.

Paper number 60:
Title: Data-Driven Estimation of Quadrotor Motor Efficiency via Residual Minimization
Authors: Sheng-Wen Cheng, Teng-Hu Cheng
Abstract: A data-driven framework is proposed for online estimation of quadrotor motor efficiency via residual minimization. The problem is formulated as a constrained nonlinear optimization that minimizes trajectory residuals between measured flight data and predictions generated by a quadrotor dynamics model. A sliding-window strategy enables online estimation, and the optimization is efficiently solved using an iteratively reweighted least squares (IRLS) scheme combined with a primal-dual interior-point method, with inequality constraints enforced through a logarithmic barrier function. Robust z-score weighting is employed to reject outliers, which is particularly effective in motor clipping scenarios where the proposed estimator exhibits smaller spikes than an EKF baseline. Compared to traditional filter-based approaches, the batch-mode formulation offers greater flexibility by selectively incorporating informative data segments. This structure is well-suited for onboard implementation, particularly for applications such as fault detection and isolation (FDI), health monitoring, and predictive maintenance in aerial robotic systems. Simulation results under various degradation scenarios demonstrate the accuracy and robustness of the proposed estimator.

Paper number 61:
Title: Robust Closed-Form Control for MIMO Nonlinear Systems under Conflicting Time-Varying Hard and Soft Constraints
Authors: Farhad Mehdifar, Charalampos P. Bechlioulis, Dimos V. Dimarogonas
Abstract: This paper introduces a novel robust closed-form control law to handle time-varying hard and soft constraints in uncertain high-relative-degree nonlinear MIMO systems. These constraints represent spatiotemporal specifications in mechanical systems' operational space, with hard constraints ensuring safety-critical requirements and soft constraints encoding performance or task objectives. Initially, all constraints are consolidated into two separate scalar time-varying hard and soft constraint functions, whose positive level sets define feasible regions. A closed-form control law is developed to enforce these constraints using appropriately designed reciprocal barriers and nonlinear transformation functions. When conflicts between hard and soft constraints arise, the control law prioritizes hard constraints by virtually relaxing soft constraints via a dynamic relaxation law. Notably, the proposed control law maintains low complexity by avoiding approximation schemes for coping with system uncertainties. Simulation results confirm the effectiveness of the proposed method.

Paper number 62:
Title: Dynamically Slimmable Speech Enhancement Network with Metric-Guided Training
Authors: Haixin Zhao, Kaixuan Yang, Nilesh Madhu
Abstract: To further reduce the complexity of lightweight speech enhancement models, we introduce a gating-based Dynamically Slimmable Network (DSN). The DSN comprises static and dynamic components. For architecture-independent applicability, we introduce distinct dynamic structures targeting the commonly used components, namely, grouped recurrent neural network units, multi-head attention, convolutional, and fully connected layers. A policy module adaptively governs the use of dynamic parts at a frame-wise resolution according to the input signal quality, controlling computational load. We further propose Metric-Guided Training (MGT) to explicitly guide the policy module in assessing input speech quality. Experimental results demonstrate that the DSN achieves comparable enhancement performance in instrumental metrics to the state-of-the-art lightweight baseline, while using only 73% of its computational load on average. Evaluations of dynamic component usage ratios indicate that the MGT-DSN can appropriately allocate network resources according to the severity of input signal distortion.

Paper number 63:
Title: Robust Recovery and Control of Cyber-physical Discrete Event Systems under Actuator Attacks
Authors: Samuel Oliveira, Mostafa Tavakkoli Anbarani, Gregory Beal, Ilya Kovalenko, Marcelo Teixeira, André B. Leal, Rômulo Meira-Góes
Abstract: Critical real-world applications strongly rely on Cyber-physical systems (CPS), but their dependence on communication networks introduces significant security risks, as attackers can exploit vulnerabilities to compromise their integrity and availability. This work explores the topic of cybersecurity in the context of CPS modeled as discrete event systems (DES), focusing on recovery strategies following the detection of cyberattacks. Specifically, we address actuator enablement attacks and propose a method that preserves the system's full valid behavior under normal conditions. Upon detecting an attack, our proposed solution aims to guide the system toward a restricted yet robust behavior, ensuring operational continuity and resilience. Additionally, we introduce a property termed AE-robust recoverability, which characterizes the necessary and sufficient conditions for recovering a system from attacks while preventing further vulnerabilities. Finally, we showcase the proposed solution through a case study based on a manufacturing system.

Paper number 64:
Title: Trajectory control of a suspended load with non-stopping flying carriers
Authors: Sofia Girardello, Giulia Michieletto, Angelo Cenedese, Antonio Franchi, Chiara Gabellieri
Abstract: This paper presents the first closed-loop control framework for cooperative payload transportation with non-stopping flying carriers. Building upon grasp-matrix formulations and internal force redundancy, we propose a feedback wrench controller that actively regulates the payload's pose while an optimization layer dynamically shapes internal-force oscillations to guarantee persistent carrier motion. Preliminary experimental results on multirotor UAVs validate the model assumptions, and numerical simulations demonstrate that the method successfully prevents carrier stagnation, achieves accurate load tracking, and generates physically feasible trajectories with smooth velocity profiles. The proposed framework not only advances the state of the art but also offers a reliable, versatile solution for future real-world applications requiring load transportation by coordinated non-stopping flying carriers.

Paper number 65:
Title: GADA: Graph Attention-based Detection Aggregation for Ultrasound Video Classification
Authors: Li Chen, Naveen Balaraju, Jochen Kruecker, Balasundar Raju, Alvin Chen
Abstract: Medical ultrasound video analysis is challenging due to variable sequence lengths, subtle spatial cues, and the need for interpretable video-level assessment. We introduce GADA, a Graph Attention-based Detection Aggregation framework that reformulates video classification as a graph reasoning problem over spatially localized regions of interest. Rather than relying on 3D CNNs or full-frame analysis, GADA detects pathology-relevant regions across frames and represents them as nodes in a spatiotemporal graph, with edges encoding spatial and temporal dependencies. A graph attention network aggregates these node-level predictions through edge-aware attention to generate a compact, discriminative video-level output. Evaluated on a large-scale, multi-center clinical lung ultrasound dataset, GADA outperforms conventional baselines on two pathology video classification tasks while providing interpretable region- and frame-level attention.

Paper number 66:
Title: ILD-VIT: A Unified Vision Transformer Architecture for Detection of Interstitial Lung Disease from Respiratory Sounds
Authors: Soubhagya Ranjan Hota, Arka Roy, Udit Satija
Abstract: Interstitial lung disease (ILD) represents a group of restrictive chronic pulmonary diseases that impair oxygen acquisition by causing irreversible changes in the lungs such as fibrosis, scarring of parenchyma, etc. ILD conditions are often diagnosed by various clinical modalities such as spirometry, high-resolution lung imaging techniques, crackling respiratory sounds (RSs), etc. In this letter, we develop a novel vision transformer (VIT)-based deep learning framework namely, ILD-VIT, to detect the ILD condition using the RS recordings. The proposed framework comprises three major stages: pre-processing, mel spectrogram extraction, and classification using the proposed VIT architecture using the mel spectrogram image patches. Experimental results using the publicly available BRACETS and KAUH databases show that our proposed ILD-VIT achieves an accuracy, sensitivity, and specificity of 84.86%, 82.67%, and 86.91%, respectively, for subject-independent blind testing. The successful onboard implantation of the proposed framework on a Raspberry-pi-4 microcontroller indicates its potential as a standalone clinical system for ILD screening in a real clinical scenario.

Paper number 67:
Title: Thermal Analysis of 3D GPU-Memory Architectures with Boron Nitride Interposer
Authors: Eric Han Wang, Weijia Yan, Ruihong Huang
Abstract: As artificial intelligence (AI) chips become more powerful, the thermal management capabilities of conventional silicon (Si) substrates become insufficient for 3D-stacked designs. This work integrates electrically insulative and thermally conductive hexagonal boron nitride (h-BN) interposers into AI chips for effective thermal management. Using COMSOL Multiphysics, the effects of High-Bandwidth Memory (HBM) distributions and thermal interface material configurations on heat dissipation and hotspot mitigation were studied. A 20 °C reduction in hot spots was achieved using h-BN interposers compared to Si interposers. Such an improvement could reduce AI chips' power leakage by 22% and significantly enhance their thermal performance.

Paper number 68:
Title: Control Requirements for Robust Beamforming in Multi-Satellite Systems
Authors: Diego Tuzi, Thomas Delamotte, Andreas Knopp
Abstract: This work investigates the impact of position and attitude perturbations on the beamforming performance of multi-satellite systems. The system under analysis is a formation of small satellites equipped with direct radiating arrays that synthesise a large virtual antenna aperture. The results show that performance is highly sensitive to the considered perturbations. However, by incorporating position and attitude information into the beamforming process, nominal performance can be effectively restored. These findings support the development of control-aware beamforming strategies that tightly integrate the attitude and orbit control system with signal processing to enable robust beamforming and autonomous coordination.

Paper number 69:
Title: The Role of Flexible Connection in Accelerating Load Interconnection in Distribution Networks
Authors: Nan Gu, Ge Chen, Junjie Qin
Abstract: This paper investigates the role of flexible connection in accelerating the interconnection of large loads amid rising electricity demand from data centers and electrification. Flexible connection allows new loads to defer or curtail consumption during rare, grid-constrained periods, enabling faster access without major infrastructure upgrades. To quantify how flexible connection unlocks load hosting capacity, we formulate a flexibility-aware hosting capacity analysis problem that explicitly limits the number of utility-controlled interventions per year, ensuring infrequent disruption. Efficient solution methods are developed for this nonconvex problem and applied to real load data and test feeders. Empirical results reveal that modest flexibility, i.e., few interventions with small curtailments or delays, can unlock substantial hosting capacity. Theoretical analysis further explains and generalizes these findings, highlighting the broad potential of flexible connection.

Paper number 70:
Title: Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach
Authors: Yinchao Yang, Yahao Ding, Zhaohui Yang, Chongwen Huang, Zhaoyang Zhang, Dusit Niyato, Mohammad Shikh-Bahaei
Abstract: Real-time and contactless monitoring of vital signs, such as respiration and heartbeat, alongside reliable communication, is essential for modern healthcare systems, especially in remote and privacy-sensitive environments. Traditional wireless communication and sensing networks fall short in meeting all the stringent demands of eHealth, including accurate sensing, high data efficiency, and privacy preservation. To overcome the challenges, we propose a novel integrated sensing, computing, and semantic communication (ISCSC) framework. In the proposed system, a service robot utilises radar to detect patient positions and monitor their vital signs, while sending updates to the medical devices. Instead of transmitting raw physiological information, the robot computes and communicates semantically extracted health features to medical devices. This semantic processing improves data throughput and preserves the clinical relevance of the messages, while enhancing data privacy by avoiding the transmission of sensitive data. Leveraging the estimated patient locations, the robot employs an interacting multiple model (IMM) filter to actively track patient motion, thereby enabling robust beam steering for continuous and reliable monitoring. We then propose a joint optimisation of the beamforming matrices and the semantic extraction ratio, subject to computing capability and power budget constraints, with the objective of maximising both the semantic secrecy rate and sensing accuracy. Simulation results validate that the ISCSC framework achieves superior sensing accuracy, improved semantic transmission efficiency, and enhanced privacy preservation compared to conventional joint sensing and communication methods.

Paper number 71:
Title: A Physics-Informed Reinforcement Learning Approach for Degradation-Aware Long-Term Charging Optimization in Batteries
Authors: Shanthan Kumar Padisala, Bharatkumar Hegde, Ibrahim Haskara, Satadru Dey
Abstract: Batteries degrade with usage and continuous cycling. This aging is typically reflected through the resistance growth and the capacity fade of battery cells. Over the years, various charging methods have been presented in the literature that proposed current profiles in order to enable optimal, fast, and/or health-conscious charging. However, very few works have attempted to make the ubiquitous Constant Current Constant Voltage (CCCV) charging protocol adaptive to the changing battery health as it cycles. This work aims to address this gap and proposes a framework that optimizes the constant current part of the CCCV protocol adapting to long-term battery degradation. Specifically, a physics-informed Reinforcement Learning (RL) approach has been used that not only estimates a key battery degradation mechanism, namely, Loss of Active Material (LAM), but also adjusts the current magnitude of CCCV as a result of this particular degradation. The proposed framework has been implemented by combining PyBamm, an open-source battery modeling tool, and Stable-baselines where the RL agent was trained using a Proximal Policy Optimization (PPO) network. Simulation results show the potential of the proposed framework for enhancing the widely used CCCV protocol by embedding physics information in RL algorithm. A comparative study of this proposed agent has also been discussed with 2 other charging protocols generated by a non-physics-based RL agent and a constant CCCV for all the cycles.

Paper number 72:
Title: Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control
Authors: Renato Luis Garrido Cavalcante, Noor Ul Ain, Lorenzo Miretti, Slawomir Stanczak
Abstract: We introduce mathematical tools and fixed point algorithms for optimal statistical max-min power control in cellular and cell-less massive MIMO systems. Unlike previous studies that rely on the use-and-then-forget (UatF) lower bound on Shannon achievable (ergodic) rates, our proposed framework can deal with alternative bounds that explicitly consider perfect or imperfect channel state information (CSI) at the decoder. In doing so, we address limitations of UatF-based algorithms, which inherit the shortcomings of the UatF bound. For example, the UatF bound can be overly conservative: in extreme cases, under fully statistical (nonadaptive) beamforming in zero-mean channels, the UatF bound produces trivial (zero) rate bounds. It also lacks scale invariance: merely scaling the beamformers can change the bound drastically, especially when simple beamforming strategies are employed. In contrast, our framework is compatible with information-theoretic bounds that do not suffer from the above drawbacks. We illustrate the framework by solving a max-min power control problem considering a standard bound that exploits instantaneous CSI at the decoder.

Paper number 73:
Title: Smooth Spatiotemporal Tube Synthesis for Prescribed-Time Reach-Avoid-Stay Control
Authors: Siddhartha Upadhyay, Ratnangshu Das, Pushpak Jagtap
Abstract: In this work, we address the issue of controller synthesis for a control-affine nonlinear system to meet prescribed time reach-avoid-stay specifications. Our goal is to improve upon previous methods based on spatiotemporal tubes (STTs) by eliminating the need for circumvent functions, which often lead to abrupt tube modifications and high control effort. We propose an adaptive framework that constructs smooth STTs around static unsafe sets, enabling continuous avoidance while guiding the system toward the target within the prescribed time. A closed-form, approximation-free control law is derived to ensure the system trajectory remains within the tube and satisfies the RAS task. The effectiveness of the proposed approach is demonstrated through a case study, showing a significant reduction in control effort compared to prior methods.

Paper number 74:
Title: Bayesian Self-Calibration and Parametric Channel Estimation for 6G Antenna Arrays
Authors: Patrick Hödl, Jakob Möderl, Erik Leitinger, Klaus Witrisal
Abstract: Accurate channel estimation is essential for both high-rate communication and high-precision sensing in 6G wireless systems. However, a major performance limitation arises from calibration mismatches when operating phased-array antennas under real-world conditions. To address this issue, we propose to integrate antenna element self-calibration into a variational sparse Bayesian learning (VSBL) algorithm for parametric channel estimation. We model antenna gain and phase deviations as latent variables and derive explicit update equations to jointly infer these calibration parameters and the channel parameters: the model order, complex amplitudes, delays, angles, and the noise variance. The resulting algorithm operates online and adapts in real time to hardware-induced mismatches. We assess its performance in terms of the root mean square error (RMSE) and the optimal subpattern-assignment (OSPA) metric, demonstrating consistent improvements over conventional VSBL without calibration. Our results demonstrate that embedding self-calibration within Bayesian inference significantly enhances the robustness of channel estimation.

Paper number 75:
Title: Leaky Wave Antennas for Next Generation Wireless Applications in sub-THz Frequencies: Current Status and Research Challenges
Authors: Natalie Lang, Atsutse K. Kludze, Nir Shlezinger, Yasaman Ghasempour, Tirza Routtenberg, George C. Alexandropoulos, Yonina C. Eldar
Abstract: The ever-growing demand for ultra-high data rates, massive connectivity, and joint communication-sensing capabilities in future wireless networks is driving research into sub-terahertz (sub-THz) communications. While these frequency bands offer abundant spectrum, they also pose severe propagation and hardware design challenges, motivating the search for alternative antenna solutions beyond conventional antenna arrays. Leaky-wave antennas (LWAs) have emerged as a promising candidate for sub-THz systems due to their simple feed structure, low fabrication cost, and inherent angle-frequency coupling, which enables frequency-controlled beamsteering with simple hardware. In this article, we review the fundamentals of the LWA technology, highlight their unique properties, and showcase their potential in multi-user wideband sub-THz wireless communications. We present representative studies demonstrating that LWAs can simultaneously support high-rate multi-user communications and accurate localization using only a single antenna element. Finally, several key open challenges are outlined, spanning algorithm design, signal processing, information theory, standardization, and hardware implementation, that need to be addressed to fully harness LWAs as a cost-effective and scalable enabler of next generations of wireless systems.

Paper number 76:
Title: Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real-Time with Convergence Guarantees
Authors: Samuel G. Gessow, Brett T. Lopez
Abstract: We present an analysis on the convergence properties of the so-called geometric heat flow equation for computing geodesics (shortest-path~curves) on Riemannian manifolds. Computing geodesics numerically in real-time has become an important capability in several fields, including control and motion planning. The geometric heat flow equation involves solving a parabolic partial differential equation whose solution is a geodesic. In practice, solving this PDE numerically can be done efficiently, and tends to be more numerically stable and exhibit a better rate of convergence compared to numerical optimization. We prove that the geometric heat flow equation is globally exponentially stable in $L_2$ if the curvature of the Riemannian manifold is not too positive, and that asymptotic convergence in $L_2$ is always guaranteed. We also present a pseudospectral method that leverages Chebyshev polynomials to accurately compute geodesics in only a few milliseconds for non-contrived manifolds. Our analysis was verified with our custom pseudospectral method by computing geodesics on common non-Euclidean surfaces, and in feedback for a contraction-based controller with a non-flat metric for a nonlinear system.

Paper number 77:
Title: Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials
Authors: Riccardo Fosco Gramaccioni, Christian Marinoni, Fabrizio Frezza, Aurelio Uncini, Danilo Comminiello
Abstract: Accurate simulation of wave propagation in complex acoustic materials is crucial for applications in sound design, noise control, and material engineering. Traditional numerical solvers, such as finite element methods, are computationally expensive, especially when dealing with large-scale or real-time scenarios. In this work, we introduce a dataset of 31,000 acoustic materials, named HA30K, designed and simulated solving the Helmholtz equations. For each material, we provide the geometric configuration and the corresponding pressure field solution, enabling data-driven approaches to learn Helmholtz equation solutions. As a baseline, we explore a deep learning approach based on Stable Diffusion with ControlNet, a state-of-the-art model for image generation. Unlike classical solvers, our approach leverages GPU parallelization to process multiple simulations simultaneously, drastically reducing computation time. By representing solutions as images, we bypass the need for complex simulation software and explicit equation-solving. Additionally, the number of diffusion steps can be adjusted at inference time, balancing speed and quality. We aim to demonstrate that deep learning-based methods are particularly useful in early-stage research, where rapid exploration is more critical than absolute accuracy.

Paper number 78:
Title: Science ouverte et collaborative pour l'élaboration d'un banc automatisé de caractérisation de pertes en commutation par opposition
Authors: Nicolas Rouger, Luiz Villa, Matthieu Masson, Pauline Kergus, Joseph Kemdeg, Lorenzo Leijnen, Jean Alinei, Adrien Colomb, Ayoub Farah-Hassan, Arnauld Biganzoli
Abstract: The switching losses of power transistors are generally measured using the so-called double pulse method. Measuring the opposition of two switching cells is a complementary method that is more accurate but indirect. However, implementing this method can be more complex and requires calibration steps and comprehensive control, with the added issue of thermal management. In this context, we proposed to address this topic through open and collaborative science, first in the form of a two-day hackathon, followed by monthly open sessions. More than 20 participants contributed to the two-day hackathon, followed by monthly sessions for those wishing to continue working together. This enabled us to set up an automated bench, in open science, including the generation of switching commands, the configuration and control of measuring instruments, and the hardware part. Here we present and share our work and this open approach.

Paper number 79:
Title: Secret-Key Agreement Through Hidden Markov Modeling of Wavelet Scattering Embeddings
Authors: Nora Basha, Bechir Hamdaoui, Attila A. Yavuz, Thang Hoang, Mehran Mozaffari Kermani
Abstract: Secret-key generation and agreement based on wireless channel reciprocity offers a promising avenue for securing IoT networks. However, existing approaches predominantly rely on the similarity of instantaneous channel measurement samples between communicating devices. This narrow view of reciprocity is often impractical, as it is highly susceptible to noise, asynchronous sampling, channel fading, and other system-level imperfections -- all of which significantly impair key generation performance. Furthermore, the quantization step common in traditional schemes introduces irreversible errors, further limiting efficiency. In this work, we propose a novel approach for secret-key generation by using wavelet scattering networks to extract robust and reciprocal CSI features. Dimensionality reduction is applied to uncover hidden cluster structures, which are then used to build hidden Markov models for efficient key agreement. Our approach eliminates the need for quantization and effectively captures channel randomness. It achieves a 5x improvement in key generation rate compared to traditional benchmarks, providing a secure and efficient solution for key generation in resource-constrained IoT environments.

Paper number 80:
Title: Exploration of Incremental Synthetic Non-Morphed Images for Single Morphing Attack Detection
Authors: David Benavente-Rios, Juan Ruiz Rodriguez, Gustavo Gatica
Abstract: This paper investigates the use of synthetic face data to enhance Single-Morphing Attack Detection (S-MAD), addressing the limitations of availability of large-scale datasets of bona fide images due to privacy concerns. Various morphing tools and cross-dataset evaluation schemes were utilized to conduct this study. An incremental testing protocol was implemented to assess the generalization capabilities as more and more synthetic images were added. The results of the experiments show that generalization can be improved by carefully incorporating a controlled number of synthetic images into existing datasets or by gradually adding bona fide images during training. However, indiscriminate use of synthetic data can lead to sub-optimal performance. Evenmore, the use of only synthetic data (morphed and non-morphed images) achieves the highest Equal Error Rate (EER), which means in operational scenarios the best option is not relying only on synthetic data for S-MAD.

Paper number 81:
Title: Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective
Authors: Shahbaz P Qadri Syed, He Bai
Abstract: The empirical success of multi-agent reinforcement learning (MARL) has motivated the search for more efficient and scalable algorithms for large scale multi-agent systems. However, existing state-of-the-art algorithms do not fully exploit inter-agent coupling information to develop MARL algorithms. In this paper, we propose a systematic approach to leverage structures in the inter-agent couplings for efficient model-free reinforcement learning. We model the cooperative MARL problem via a Bayesian network and characterize the subset of agents, termed as the value dependency set, whose information is required by each agent to estimate its local action value function exactly. Moreover, we propose a partially decentralized training decentralized execution (P-DTDE) paradigm based on the value dependency set. We theoretically establish that the total variance of our P-DTDE policy gradient estimator is less than the centralized training decentralized execution (CTDE) policy gradient estimator. We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and develop a scalable actor-critic algorithm. We demonstrate the efficiency and scalability of the proposed algorithm on multi-warehouse resource allocation and multi-zone temperature control examples. For dense value dependency sets, we propose an approximation scheme based on truncation of the Bayesian network and empirically show that it achieves a faster convergence than the exact value dependence set for applications with a large number of agents.

Paper number 82:
Title: Causal-Guided Dimension Reduction for Efficient Pareto Optimization
Authors: Dinithi Jayasuriya, Divake Kumar, Sureshkumar Senthilkumar, Devashri Naik, Nastaran Darabi, Amit Ranjan Trivedi
Abstract: Multi-objective optimization of analog circuits is hindered by high-dimensional parameter spaces, strong feedback couplings, and expensive transistor-level simulations. Evolutionary algorithms such as Non-dominated Sorting Genetic Algorithm II (NSGA-II) are widely used but treat all parameters equally, thereby wasting effort on variables with little impact on performance, which limits their scalability. We introduce CaDRO, a causal-guided dimensionality reduction framework that embeds causal discovery into the optimization pipeline. CaDRO builds a quantitative causal map through a hybrid observational-interventional process, ranking parameters by their causal effect on the objectives. Low-impact parameters are fixed to values from high-quality solutions, while critical drivers remain active in the search. The reduced design space enables focused evolutionary optimization without modifying the underlying algorithm. Across amplifiers, regulators, and RF circuits, CaDRO converges up to 10$\times$ faster than NSGA-II while preserving or improving Pareto quality. For instance, on the Folded-Cascode Amplifier, hypervolume improves from 0.56 to 0.94, and on the LDO regulator from 0.65 to 0.81, with large gains in non-dominated solutions.

Paper number 83:
Title: Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals
Authors: Pouya Shaeri, Ryan T. Woo, Yasaman Mohammadpour, Ariane Middel
Abstract: Segmentation models achieve high accuracy on benchmarks but often fail in real-world domains by relying on spurious correlations instead of true object boundaries. We propose a human-in-the-loop interactive framework that enables interventional learning through targeted human corrections of segmentation outputs. Our approach treats human corrections as interventional signals that show when reliance on superficial features (e.g., color or texture) is inappropriate. The system learns from these interventions by propagating correction-informed edits across visually similar images, effectively steering the model toward robust, semantically meaningful features rather than dataset-specific artifacts. Unlike traditional annotation approaches that simply provide more training data, our method explicitly identifies when and why the model fails and then systematically corrects these failure modes across the entire dataset. Through iterative human feedback, the system develops increasingly robust representations that generalize better to novel domains and resist artifactual correlations. We demonstrate that our framework improves segmentation accuracy by up to 9 mIoU points (12-15\% relative improvement) on challenging cubemap data and yields 3-4$\times$ reductions in annotation effort compared to standard retraining, while maintaining competitive performance on benchmark datasets. This work provides a practical framework for researchers and practitioners seeking to build segmentation systems that are accurate, robust to dataset biases, data-efficient, and adaptable to real-world domains such as urban climate monitoring and autonomous driving.

Paper number 84:
Title: Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making
Authors: Fan Zuo, Donglin Zhou, Jingqin Gao, Kaan Ozbay
Abstract: Accurate, scalable traffic monitoring is critical for real-time and long-term transportation management, particularly during disruptions such as natural disasters, large construction projects, or major policy changes like New York City's first-in-the-nation congestion pricing program. However, widespread sensor deployment remains limited due to high installation, maintenance, and data management costs. While traffic cameras offer a cost-effective alternative, existing video analytics struggle with dynamic camera viewpoints and massive data volumes from large camera networks. This study presents an end-to-end AI-based framework leveraging existing traffic camera infrastructure for high-resolution, longitudinal analysis at scale. A fine-tuned YOLOv11 model, trained on localized urban scenes, extracts multimodal traffic density and classification metrics in real time. To address inconsistencies from non-stationary pan-tilt-zoom cameras, we introduce a novel graph-based viewpoint normalization method. A domain-specific large language model was also integrated to process massive data from a 24/7 video stream to generate frequent, automated summaries of evolving traffic patterns, a task far exceeding manual capabilities. We validated the system using over 9 million images from roughly 1,000 traffic cameras during the early rollout of NYC congestion pricing in 2025. Results show a 9% decline in weekday passenger vehicle density within the Congestion Relief Zone, early truck volume reductions with signs of rebound, and consistent increases in pedestrian and cyclist activity at corridor and zonal scales. Experiments showed that example-based prompts improved LLM's numerical accuracy and reduced hallucinations. These findings demonstrate the framework's potential as a practical, infrastructure-ready solution for large-scale, policy-relevant traffic monitoring with minimal human intervention.

Paper number 85:
Title: MTP-S2UT: Enhancing Speech-to-Speech Translation Quality with Multi-token Prediction
Authors: Jianjin Wang, Runsong Zhao, Xiaoqian Liu, Yuan Ge, Ziqiang Xu, Tong Xiao, Shengxiang Gao, Zhengtao Yu, Jingbo Zhu
Abstract: Current direct speech-to-speech translation methods predominantly employ speech tokens as intermediate representations. However, a single speech token is not dense in semantics, so we generally need multiple tokens to express a complete semantic unit. To address this limitation, we introduce multi-token prediction (MTP) loss into speech-to-unit translation (S2UT) models, enabling models to predict multiple subsequent tokens at each position, thereby capturing more complete semantics and enhancing information density per position. Initial MTP implementations apply the loss at the final layer, which improves output representation but initiates information enrichment too late. We hypothesize that advancing the information enrichment process to intermediate layers can achieve earlier and more effective enhancement of hidden representation. Consequently, we propose MTP-S2UT loss, applying MTP loss to hidden representation where CTC loss is computed. Experiments demonstrate that all MTP loss variants consistently improve the quality of S2UT translation, with MTP-S2UT achieving the best performance.

Paper number 86:
Title: Uncertainty-Aware Post-Detection Framework for Enhanced Fire and Smoke Detection in Compact Deep Learning Models
Authors: Aniruddha Srinivas Joshi, Godwyn James William, Shreyas Srinivas Joshi
Abstract: Accurate fire and smoke detection is critical for safety and disaster response, yet existing vision-based methods face challenges in balancing efficiency and reliability. Compact deep learning models such as YOLOv5n and YOLOv8n are widely adopted for deployment on UAVs, CCTV systems, and IoT devices, but their reduced capacity often results in false positives and missed detections. Conventional post-detection methods such as Non-Maximum Suppression and Soft-NMS rely only on spatial overlap, which can suppress true positives or retain false alarms in cluttered or ambiguous fire scenes. To address these limitations, we propose an uncertainty aware post-detection framework that rescales detection confidences using both statistical uncertainty and domain relevant visual cues. A lightweight Confidence Refinement Network integrates uncertainty estimates with color, edge, and texture features to adjust detection scores without modifying the base model. Experiments on the D-Fire dataset demonstrate improved precision, recall, and mean average precision compared to existing baselines, with only modest computational overhead. These results highlight the effectiveness of post-detection rescoring in enhancing the robustness of compact deep learning models for real-world fire and smoke detection.

Paper number 87:
Title: YOLOv11-Litchi: Efficient Litchi Fruit Detection based on UAV-Captured Agricultural Imagery in Complex Orchard Environments
Authors: Hongxing Peng, Haopei Xie, Weijia Lia, Huanai Liuc, Ximing Li
Abstract: Litchi is a high-value fruit, yet traditional manual selection methods are increasingly inadequate for modern production demands. Integrating UAV-based aerial imagery with deep learning offers a promising solution to enhance efficiency and reduce costs. This paper introduces YOLOv11-Litchi, a lightweight and robust detection model specifically designed for UAV-based litchi detection. Built upon the YOLOv11 framework, the proposed model addresses key challenges such as small target size, large model parameters hindering deployment, and frequent target occlusion. To tackle these issues, three major innovations are incorporated: a multi-scale residual module to improve contextual feature extraction across scales, a lightweight feature fusion method to reduce model size and computational costs while maintaining high accuracy, and a litchi occlusion detection head to mitigate occlusion effects by emphasizing target regions and suppressing background interference. Experimental results validate the model's effectiveness. YOLOv11-Litchi achieves a parameter size of 6.35 MB - 32.5% smaller than the YOLOv11 baseline - while improving mAP by 2.5% to 90.1% and F1-Score by 1.4% to 85.5%. Additionally, the model achieves a frame rate of 57.2 FPS, meeting real-time detection requirements. These findings demonstrate the suitability of YOLOv11-Litchi for UAV-based litchi detection in complex orchard environments, showcasing its potential for broader applications in precision agriculture.

Paper number 88:
Title: Chord Colourizer: A Near Real-Time System for Visualizing Musical Key
Authors: Paul Haimes
Abstract: This paper introduces Chord Colourizer, a near real-time system that detects the musical key of an audio signal and visually represents it through a novel graphical user interface (GUI). The system assigns colours to musical notes based on Isaac Newton's original colour wheel, preserving historical links between pitch and hue, and also integrates an Arduino-controlled LED display using 3D-printed star-shaped diffusers to offer a physical ambient media representation. The method employs Constant-Q Transform (CQT) chroma features for chord estimation and visualization, followed by threshold-based filtering and tonal enhancement to isolate the root, third, and fifth. A confidence score is computed for each detection to ensure reliability, and only chords with moderate to very strong certainty are visualized. The graphical interface dynamically updates a colour-coded keyboard layout, while the LED display provides the same colour information via spatial feedback. This multi-modal system enhances user interaction with harmonic content, offering innovative possibilities for education and artistic performance. Limitations include slight latency and the inability to detect extended chords, which future development will aim to address through refined filtering, adaptive thresholds, and support for more complex harmonies such as sevenths and augmented chords. Future work will also explore integration with alternative visualization styles, and the comparison of audio analysis libraries to improve detection speed and precision. Plans also include formal user testing to evaluate perception, usability, and cross-cultural interpretations of colour-pitch mappings.

Paper number 89:
Title: Peransformer: Improving Low-informed Expressive Performance Rendering with Score-aware Discriminator
Authors: Xian He, Wei Zeng, Ye Wang
Abstract: Highly-informed Expressive Performance Rendering (EPR) systems transform music scores with rich musical annotations into human-like expressive performance MIDI files. While these systems have achieved promising results, the availability of detailed music scores is limited compared to MIDI files and are less flexible to work with using a digital audio workstation (DAW). Recent advancements in low-informed EPR systems offer a more accessible alternative by directly utilizing score-derived MIDI as input, but these systems often exhibit suboptimal performance. Meanwhile, existing works are evaluated with diverse automatic metrics and data formats, hindering direct objective comparisons between EPR systems. In this study, we introduce Peransformer, a transformer-based low-informed EPR system designed to bridge the gap between low-informed and highly-informed EPR systems. Our approach incorporates a score-aware discriminator that leverages the underlying score-derived MIDI files and is trained on a score-to-performance paired, note-to-note aligned MIDI dataset. Experimental results demonstrate that Peransformer achieves state-of-the-art performance among low-informed systems, as validated by subjective evaluations. Furthermore, we extend existing automatic evaluation metrics for EPR systems and introduce generalized EPR metrics (GEM), enabling more direct, accurate, and reliable comparisons across EPR systems.

Paper number 90:
Title: Distributionally Robust Control with End-to-End Statistically Guaranteed Metric Learning
Authors: Jingyi Wu, Chao Ning, Yang Shi
Abstract: Wasserstein distributionally robust control (DRC) recently emerges as a principled paradigm for handling uncertainty in stochastic dynamical systems. However, it constructs data-driven ambiguity sets via uniform distribution shifts before sequentially incorporating them into downstream control synthesis. This segregation between ambiguity set construction and control objectives inherently introduces a structural misalignment, which undesirably leads to conservative control policies with sub-optimal performance. To address this limitation, we propose a novel end-to-end finite-horizon Wasserstein DRC framework that integrates the learning of anisotropic Wasserstein metrics with downstream control tasks in a closed-loop manner, thus enabling ambiguity sets to be systematically adjusted along performance-critical directions and yielding more effective control policies. This framework is formulated as a bilevel program: the inner level characterizes dynamical system evolution under DRC, while the outer level refines the anisotropic metric leveraging control-performance feedback across a range of initial conditions. To solve this program efficiently, we develop a stochastic augmented Lagrangian algorithm tailored to the bilevel structure. Theoretically, we prove that the learned ambiguity sets preserve statistical finite-sample guarantees under a novel radius adjustment mechanism, and we establish the well-posedness of the bilevel formulation by demonstrating its continuity with respect to the learnable metric. Furthermore, we show that the algorithm converges to stationary points of the outer level problem, which are statistically consistent with the optimal metric at a non-asymptotic convergence rate. Experiments on both numerical and inventory control tasks verify that the proposed framework achieves superior closed-loop performance and robustness compared against state-of-the-art methods.

Paper number 91:
Title: Hybrid MAC Protocol with Integrated Multi-Layered Security for Resource-Constrained UAV Swarm Communications
Authors: Dhrumil Bhatt, Siddharth Penumatsa, Vidushi Kumar
Abstract: Flying Ad Hoc Networks (FANETs) present unique challenges due to high node mobility, dynamic topologies, and strict resource constraints. Existing routing protocols often optimize for a single metric, such as path length or energy, while neglecting the complex dependencies between network performance, security, and MAC layer efficiency. This paper introduces a novel hardware software co design framework for secure and adaptive UAV swarm communications, featuring an energy aware protocol stack. The architecture employs a multicast, clustered organization where routing decisions integrate dynamic trust scores, historical link quality, and internodal distance. A hybrid MAC protocol combines contention based and scheduled channel access for optimized throughput. Security is ensured through a zero trust model that fuses cryptographic authentication with a behavioral reputation system, alongside hardware accelerated AES GCM encryption. Comparative analysis in an NS 3 simulation environment demonstrates the framework's superiority in packet delivery ratio, latency, resilience, and overhead, providing a scalable foundation for high performance swarm operations.

Paper number 92:
Title: ProGress: Structured Music Generation via Graph Diffusion and Hierarchical Music Analysis
Authors: Stephen Ni-Hahn, Chao Péter Yang, Mingchen Ma, Cynthia Rudin, Simon Mak, Yue Jiang
Abstract: Artificial Intelligence (AI) for music generation is undergoing rapid developments, with recent symbolic models leveraging sophisticated deep learning and diffusion model algorithms. One drawback with existing models is that they lack structural cohesion, particularly on harmonic-melodic structure. Furthermore, such existing models are largely "black-box" in nature and are not musically interpretable. This paper addresses these limitations via a novel generative music framework that incorporates concepts of Schenkerian analysis (SchA) in concert with a diffusion modeling framework. This framework, which we call ProGress (Prolongation-enhanced DiGress), adapts state-of-the-art deep models for discrete diffusion (in particular, the DiGress model of Vignac et al., 2023) for interpretable and structured music generation. Concretely, our contributions include 1) novel adaptations of the DiGress model for music generation, 2) a novel SchA-inspired phrase fusion methodology, and 3) a framework allowing users to control various aspects of the generation process to create coherent musical compositions. Results from human experiments suggest superior performance to existing state-of-the-art methods.

Paper number 93:
Title: The algorithmic regulator
Authors: Giulio Ruffini
Abstract: The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\Delta > 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] making low $M(W{:}R)$ exponentially unlikely as $\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout.

Paper number 94:
Title: MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation
Authors: Max Sokolich, Yanda Yang, Subrahmanyam Cherukumilli, Fatma Ceren Kirmizitas, Sambeeta Das
Abstract: This paper presents MicroRoboScope, a portable, compact, and versatile microrobotic experimentation platform designed for real-time, closed-loop control of both magnetic and acoustic microrobots. The system integrates an embedded computer, microscope, power supplies, and control circuitry into a single, low-cost and fully integrated apparatus. Custom control software developed in Python and Arduino C++ handles live video acquisition, microrobot tracking, and generation of control signals for electromagnetic coils and acoustic transducers. The platform's multi-modal actuation, accessibility, and portability make it suitable not only for specialized research laboratories but also for educational and outreach settings. By lowering the barrier to entry for microrobotic experimentation, this system enables new opportunities for research, education, and translational applications in biomedicine, tissue engineering, and robotics.

Paper number 95:
Title: Guided Image Feature Matching using Feature Spatial Order
Authors: Chin-Hung Teng, Ben-Jian Dong
Abstract: Image feature matching plays a vital role in many computer vision tasks. Although many image feature detection and matching techniques have been proposed over the past few decades, it is still time-consuming to match feature points in two images, especially for images with a large number of detected features. Feature spatial order can estimate the probability that a pair of features is correct. Since it is a completely independent concept from epipolar geometry, it can be used to complement epipolar geometry in guiding feature match in a target region so as to improve matching efficiency. In this paper, we integrate the concept of feature spatial order into a progressive matching framework. We use some of the initially matched features to build a computational model of feature spatial order and employs it to calculates the possible spatial range of subsequent feature matches, thus filtering out unnecessary feature matches. We also integrate it with epipolar geometry to further improve matching efficiency and accuracy. Since the spatial order of feature points is affected by image rotation, we propose a suitable image alignment method from the fundamental matrix of epipolar geometry to remove the effect of image rotation. To verify the feasibility of the proposed method, we conduct a series of experiments, including a standard benchmark dataset, self-generated simulated images, and real images. The results demonstrate that our proposed method is significantly more efficient and has more accurate feature matching than the traditional method.

Paper number 96:
Title: Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds
Authors: Jiayu Ding, Xulin Chen, Garrett E. Katz, Zhenyu Gan
Abstract: Quadrupedal robots exhibit a wide range of viable gaits, but generating specific footfall sequences often requires laborious expert tuning of numerous variables, such as touch-down and lift-off events and holonomic constraints for each leg. This paper presents a unified reinforcement learning framework for generating versatile quadrupedal gaits by leveraging the intrinsic symmetries and velocity-period relationship of dynamic legged systems. We propose a symmetry-guided reward function design that incorporates temporal, morphological, and time-reversal symmetries. By focusing on preserved symmetries and natural dynamics, our approach eliminates the need for predefined trajectories, enabling smooth transitions between diverse locomotion patterns such as trotting, bounding, half-bounding, and galloping. Implemented on the Unitree Go2 robot, our method demonstrates robust performance across a range of speeds in both simulations and hardware tests, significantly improving gait adaptability without extensive reward tuning or explicit foot placement control. This work provides insights into dynamic locomotion strategies and underscores the crucial role of symmetries in robotic gait design.

Paper number 97:
Title: Galilean Symmetry in Robotics
Authors: Robert Mahony, Jonathan Kelly, Stephan Weiss
Abstract: Galilean symmetry is the natural symmetry of inertial motion that underpins Newtonian physics. Although rigid-body symmetry is one of the most established and fundamental tools in robotics, there appears to be no comparable treatment of Galilean symmetry for a robotics audience. In this paper, we present a robotics-tailored exposition of Galilean symmetry that leverages the community's familiarity with and understanding of rigid-body transformations and pose representations. Our approach contrasts with common treatments in the physics literature that introduce Galilean symmetry as a stepping stone to Einstein's relativity. A key insight is that the Galilean matrix Lie group can be used to describe two different pose representations, Galilean frames, that use inertial velocity in the state definition, and extended poses, that use coordinate velocity. We provide three examples where applying the Galilean matrix Lie-group algebra to robotics problems is straightforward and yields significant insights: inertial navigation above the rotating Earth, manipulator kinematics, and sensor data fusion under temporal uncertainty. We believe that the time is right for the robotics community to benefit from rediscovering and extending this classical material and applying it to modern problems.

Paper number 98:
Title: A Verified High-Performance Composable Object Library for Remote Direct Memory Access (Extended Version)
Authors: Guillaume Ambal, George Hodgkins, Mark Madler, Gregory Chockler, Brijesh Dongol, Joseph Izraelevitz, Azalea Raad, Viktor Vafeiadis
Abstract: Remote Direct Memory Access (RDMA) is a memory technology that allows remote devices to directly write to and read from each other's memory, bypassing components such as the CPU and operating system. This enables low-latency high-throughput networking, as required for many modern data centres, HPC applications and AI/ML workloads. However, baseline RDMA comprises a highly permissive weak memory model that is difficult to use in practice and has only recently been formalised. In this paper, we introduce the Library of Composable Objects (LOCO), a formally verified library for building multi-node objects on RDMA, filling the gap between shared memory and distributed system programming. LOCO objects are well-encapsulated and take advantage of the strong locality and the weak consistency characteristics of RDMA. They have performance comparable to custom RDMA systems (e.g. distributed maps), but with a far simpler programming model amenable to formal proofs of correctness. To support verification, we develop a novel modular declarative verification framework, called Mowgli, that is flexible enough to model multinode objects and is independent of a memory consistency model. We instantiate Mowgli with the RDMA memory model, and use it to verify correctness of LOCO libraries.

Paper number 99:
Title: Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix
Authors: Koki Yamane, Sho Sakaino, Toshiaki Tsuji
Abstract: Four-channel bilateral control is a method for achieving remote control with force feedback and adjustment operability by synchronizing the positions and forces of two manipulators. This is expected to significantly improve the operability of the remote control in contact-rich tasks. Among these, 4-channel bilateral control on the Cartesian coordinate system is advantageous owing to its suitability for manipulators with different structures and because it allows the dynamics in the Cartesian coordinate system to be adjusted by adjusting the control parameters, thus achieving intuitive operability for humans. This paper proposes a 4-channel bilateral control method that achieves the desired dynamics by decoupling each dimension in the Cartesian coordinate system regardless of the scaling factor.

Paper number 100:
Title: Bhasha-Rupantarika: Algorithm-Hardware Co-design approach for Multilingual Neural Machine Translation
Authors: Mukul Lokhande, Tanushree Dewangan, Mohd Sharik Mansoori, Tejas Chaudhari, Akarsh J., Damayanti Lokhande, Adam Teman, Santosh Kumar Vishvakarma
Abstract: This paper introduces Bhasha-Rupantarika, a light and efficient multilingual translation system tailored through algorithm-hardware codesign for resource-limited settings. The method investigates model deployment at sub-octet precision levels (FP8, INT8, INT4, and FP4), with experimental results indicating a 4.1x reduction in model size (FP4) and a 4.2x speedup in inference speed, which correlates with an increased throughput of 66 tokens/s (improvement by 4.8x). This underscores the importance of ultra-low precision quantization for real-time deployment in IoT devices using FPGA accelerators, achieving performance on par with expectations. Our evaluation covers bidirectional translation between Indian and international languages, showcasing its adaptability in low-resource linguistic contexts. The FPGA deployment demonstrated a 1.96x reduction in LUTs and a 1.65x decrease in FFs, resulting in a 2.2x enhancement in throughput compared to OPU and a 4.6x enhancement compared to HPTA. Overall, the evaluation provides a viable solution based on quantisation-aware translation along with hardware efficiency suitable for deployable multilingual AI systems. The entire codes [this https URL] and dataset for reproducibility are publicly available, facilitating rapid integration and further development by researchers.

Paper number 101:
Title: A High-Performance Training-Free Pipeline for Robust Random Telegraph Signal Characterization via Adaptive Wavelet-Based Denoising and Bayesian Digitization Methods
Authors: Tonghe Bai, Ayush Kapoor, Na Young Kim
Abstract: Random telegraph signal (RTS) analysis is increasingly important for characterizing meaningful temporal fluctuations in physical, chemical, and biological systems. The simplest RTS arises from discrete stochastic switching events between two binary states, quantified by their transition amplitude and dwell times in each state. Quantitative analysis of RTSs provides valuable insights into microscopic processes such as charge trapping in semiconductors. However, analyzing RTS becomes considerably complex when signals exhibit multi-level structures or are corrupted by background white or pink noise. To address these challenges and support high-throughput RTS analysis, we introduce a modular and scalable signal processing pipeline combining dual-tree complex wavelet transform (DTCWT) denoising with a Bayesian digitization strategy. The adaptive DTCWT-based denoiser incorporates autonomous parameter selection rules for its decomposition level and thresholds, optimizing white noise suppression without manual tuning. Complementing this denoiser, our probabilistic digitizer effectively resolves binary trap states even under residual notorious background pink noise. The overall approach enables robust performance across varying noise levels and multi-trap scenarios, improving mean dwell time estimation and RTS reconstruction over classical and neural baselines. The method is up to 83x faster, training-free, and suitable for real-time or large-scale analysis. Evaluations confirm its generalizability, speed, and reliability, providing a strong foundation for future fully adaptive and automated RTS pipelines.

Paper number 102:
Title: GPS Spoofing Attack Detection in Autonomous Vehicles Using Adaptive DBSCAN
Authors: Ahmad Mohammadi, Reza Ahmari, Vahid Hemmati, Frederick Owusu-Ambrose, Mahmoud Nabil Mahmoud, Parham Kebria, Abdollah Homaifar, Mehrdad Saif
Abstract: As autonomous vehicles become an essential component of modern transportation, they are increasingly vulnerable to threats such as GPS spoofing attacks. This study presents an adaptive detection approach utilizing a dynamically tuned Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, designed to adjust the detection threshold ({\epsilon}) in real-time. The threshold is updated based on the recursive mean and standard deviation of displacement errors between GPS and in-vehicle sensors data, but only at instances classified as non-anomalous. Furthermore, an initial threshold, determined from 120,000 clean data samples, ensures the capability to identify even subtle and gradual GPS spoofing attempts from the beginning. To assess the performance of the proposed method, five different subsets from the real-world Honda Research Institute Driving Dataset (HDD) are selected to simulate both large and small magnitude GPS spoofing attacks. The modified algorithm effectively identifies turn-by-turn, stop, overshoot, and multiple small biased spoofing attacks, achieving detection accuracies of 98.621%, 99.960.1%, 99.880.1%, and 98.380.1%, respectively. This work provides a substantial advancement in enhancing the security and safety of AVs against GPS spoofing threats.

Paper number 103:
Title: Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis
Authors: Douglas Hutchings, Luai Abuelsamen, Karthik Rajgopal
Abstract: We present a comprehensive two-layer Voronoi coverage control approach for coordinating hybrid aerial-ground robot teams in hazardous material emergency response scenarios. Traditional Voronoi coverage control methods face three critical limitations in emergency contexts: heterogeneous agent capabilities with vastly different velocities, clustered initial deployment configurations, and urgent time constraints requiring rapid response rather than eventual convergence. Our method addresses these challenges through a decoupled two-layer architecture that separately optimizes aerial and ground robot positioning, with aerial agents delivering ground sensors via airdrop to high-priority locations. We provide detailed implementation of bounded Voronoi cell computation, efficient numerical integration techniques for importance-weighted centroids, and robust control strategies that prevent agent trapping. Simulation results demonstrate an 88% reduction in response time, achieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds compared to 220 seconds for ground-only deployment. Complete implementation code is available at this https URL.

Paper number 104:
Title: Storage Participation in Electricity Markets: Arbitrage and Ancillary Services
Authors: Dirk Lauinger, Luc Coté, Andy Sun
Abstract: Electricity storage is used for intertemporal price arbitrage and for ancillary services that balance unforeseen supply and demand fluctuations via frequency regulation. We present an optimization model that computes bids for both arbitrage and frequency regulation and ensures that storage operators can honor their market commitments at all times for all fluctuation signals in an uncertainty set inspired by market rules. This requirement, initially expressed by an infinite number of nonconvex functional constraints, is shown to be equivalent to a finite number of deterministic constraints. The resulting formulation is a mixed-integer bilinear program that admits mixed-integer linear relaxations and restrictions. Empirical tests on European electricity markets show a negligible optimality gap between the relaxation and the restriction. The model can account for intraday trading and, with a solution time of under 5 seconds, may serve as a building block for more complex trading strategies. Such strategies become necessary as battery capacity exceeds the demand for ancillary services. In a backtest from 1 July 2020 through 30 June 2024 joint market participation more than doubles profits and almost halves energy storage output compared to arbitrage alone.

Paper number 105:
Title: SceneTextStylizer: A Training-Free Scene Text Style Transfer Framework with Diffusion Model
Authors: Honghui Yuan, Keiji Yanai
Abstract: With the rapid development of diffusion models, style transfer has made remarkable progress. However, flexible and localized style editing for scene text remains an unsolved challenge. Although existing scene text editing methods have achieved text region editing, they are typically limited to content replacement and simple styles, which lack the ability of free-style transfer. In this paper, we introduce SceneTextStylizer, a novel training-free diffusion-based framework for flexible and high-fidelity style transfer of text in scene images. Unlike prior approaches that either perform global style transfer or focus solely on textual content modification, our method enables prompt-guided style transformation specifically for text regions, while preserving both text readability and stylistic consistency. To achieve this, we design a feature injection module that leverages diffusion model inversion and self-attention to transfer style features effectively. Additionally, a region control mechanism is introduced by applying a distance-based changing mask at each denoising step, enabling precise spatial control. To further enhance visual quality, we incorporate a style enhancement module based on the Fourier transform to reinforce stylistic richness. Extensive experiments demonstrate that our method achieves superior performance in scene text style transformation, outperforming existing state-of-the-art methods in both visual fidelity and text preservation.

Paper number 106:
Title: Delayed 1T to 2H Phase Transition Upon Electrochemical Delithiation of LiMoS2
Authors: Yerin Hong, Juhwan Lim, Jinhong Min, Nishkarsh Agarwal, Robert Hovden, Ageeth A. Bol, Yiyang Li
Abstract: Molybdenum disulfide (MoS2) is a widely studied layered material for electronic, optical, and catalytic applications. It can host lithium ions between the van der Waals layers, which triggers a phase transition between the semiconducting 2H phase and metallic 1T phase. While lithium insertion triggers a phase transition to the 1T phase, the phase behavior upon electrochemical lithium removal is not resolved. In this work, we conduct single-flake electrochemical (de)lithiation of MoS2 using microelectrode arrays. Through both electrochemical voltage analysis and correlative Raman spectroscopy, we show that an electrochemically cycled and delithiated MoS2 flake initially remains in the 1T phase. However, over the course of several days, it transitions back into the thermodynamically stable 2H phase. This result resolves the phase transformation pathway upon delithiation and showcases the ability to electrochemically synthesize the metastable 1T-MoS2 phase.

Paper number 107:
Title: Unify Variables in Neural Scaling Laws for General Audio Representations via Embedding Effective Rank
Authors: Xuyao Deng, Yanjie Sun, Yong Dou, Kele Xu
Abstract: Scaling laws have profoundly shaped our understanding of model performance in computer vision and natural language processing, yet their application to general audio representation learning remains underexplored. A key challenge lies in the multifactorial nature of general audio representation-representation quality is jointly influenced by variables such as audio length, embedding dimensionality, model depth, model architecture, data volume, etc., many of which are difficult to isolate or express analytically. In this work, we present a systematic study of scaling laws for general audio representations by utilizing embedding effective rank (RankMe) as a unifying metric that encapsulates the impact of diverse variables on representation quality. RankMe enables a label-free, information-theoretic quantification of audio embeddings, allowing us to examine scaling behaviors across a wide hyper-parameter space, including model size, training data volume, computational budget, architectural configurations, etc. Our empirical findings reveal a consistent power-law relationship between RankMe and representation quality, suggesting that embedding effective rank serves as a reliable proxy for assessing and predicting model performance in audio representation learning. This work not only validates the applicability of classical scaling principles to the general audio domain but also offers a theoretically grounded and empirically robust framework for guiding future model scaling strategies in audio foundation models.

Paper number 108:
Title: Conformal Inference for Time Series over Graphs
Authors: Sonakshi Dua, Gonzalo Mateos, Sundeep Prabhakar Chepuri
Abstract: Trustworthy decision making in networked, dynamic environments calls for innovative uncertainty quantification substrates in predictive models for graph time series. Existing conformal prediction (CP) methods have been applied separately to multivariate time series and static graphs, but they either ignore the underlying graph topology or neglect temporal dynamics. To bridge this gap, here we develop a CP-based sequential prediction region framework tailored for graph time series. A key technical innovation is to leverage the graph structure and thus capture pairwise dependencies across nodes, while providing user-specified coverage guarantees on the predictive outcomes. We formally establish that our scheme yields an exponential shrinkage in the volume of the ellipsoidal prediction set relative to its graph-agnostic counterpart. Using real-world datasets, we demonstrate that the novel uncertainty quantification framework maintains desired empirical coverage while achieving markedly smaller (up to 80% reduction) prediction regions than existing approaches.

Paper number 109:
Title: Robust Photoplethysmography Signal Denoising via Mamba Networks
Authors: I Chiu, Yu-Tung Liu, Kuan-Chen Wang, Hung-Yu Wei, Yu Tsao
Abstract: Photoplethysmography (PPG) is widely used in wearable health monitoring, but its reliability is often degraded by noise and motion artifacts, limiting downstream applications such as heart rate (HR) estimation. This paper presents a deep learning framework for PPG denoising with an emphasis on preserving physiological information. In this framework, we propose DPNet, a Mamba-based denoising backbone designed for effective temporal modeling. To further enhance denoising performance, the framework also incorporates a scale-invariant signal-to-distortion ratio (SI-SDR) loss to promote waveform fidelity and an auxiliary HR predictor (HRP) that provides physiological consistency through HR-based supervision. Experiments on the BIDMC dataset show that our method achieves strong robustness against both synthetic noise and real-world motion artifacts, outperforming conventional filtering and existing neural models. Our method can effectively restore PPG signals while maintaining HR accuracy, highlighting the complementary roles of SI-SDR loss and HR-guided supervision. These results demonstrate the potential of our approach for practical deployment in wearable healthcare systems.

Paper number 110:
Title: Basis for a hands free blood flow measurement with automated vessel focus
Authors: Reinhard Fuchs, Nathalie Sumrah, Johannes Schwerdt, Michael Unger, Georg Stachel, Michael Schultz, Karsten Lenk, Thomas Neumuth
Abstract: Cardiopulmonary resuscitation (CPR) is one of the essential tools to ensure oxygen supply during cardiac arrest. However, the precise effects of chest compression are not quantifiable to this day. This often results in a low quality of chest compressions even if performed by health-care professionals. One solution could be provided by quantification of blood flow via ultrasonic Doppler measurements, to guide first responders in their efforts. This paper presents an approach to address the issue of limited time, anatomical know how and limitations of system configuration during emergency scenarios. An approach for automated vessel identification with three different phases was developed, featuring a new sensor probe for ultrasonic measurements with non symmetrically angled piezo ceramics. The probe was used with prototype ultrasound hardware in a laboratory setup for Pulsed Wave Doppler (PW Doppler). In an initial measurement a qualitative flow was approximated to examine valuable measurement positions on a phantom. Afterwards an iterative mode was used for depth depending frequency measurements with score calculation of flow periodicity and signal power. The configuration with the best score was used for a prolonged monitoring mode. Flow values were compared to data of an industrial flow-sensor. Flow-sensor data showed an average coefficient of determination of 0.97 with an average root mean square error of 3.84 ml/s. With the proposed hardware and software solutions a basis for future developments was made, which could lead to a fully automated vessel identification during CPR. This device could provide first responders as well as clinical staff with vital information about CPR efficiency that has yet to be included into the therapy of people during cardiac arrest.

Paper number 111:
Title: Efficient Edge Test-Time Adaptation via Latent Feature Coordinate Correction
Authors: Xinyu Luo, Jie Liu, Kecheng Chen, Junyi Yang, Bo Ding, Arindam Basu, Haoliang Li
Abstract: Edge devices face significant challenges due to limited computational resources and distribution shifts, making efficient and adaptable machine learning essential. Existing test-time adaptation (TTA) methods often rely on gradient-based optimization or batch processing, which are inherently unsuitable for resource-constrained edge scenarios due to their reliance on backpropagation and high computational demands. Gradient-free alternatives address these issues but often suffer from limited learning capacity, lack flexibility, or impose architectural constraints. To overcome these limitations, we propose a novel single-instance TTA method tailored for edge devices (TED), which employs forward-only coordinate optimization in the principal subspace of latent using the covariance matrix adaptation evolution strategy (CMA-ES). By updating a compact low-dimensional vector, TED not only enhances output confidence but also aligns the latent representation closer to the source latent distribution within the latent principal subspace. This is achieved without backpropagation, keeping the model parameters frozen, and enabling efficient, forgetting-free adaptation with minimal memory and computational overhead. Experiments on image classification and keyword spotting tasks across the ImageNet and Google Speech Commands series datasets demonstrate that TED achieves state-of-the-art performance while $\textit{reducing computational complexity by up to 63 times}$, offering a practical and scalable solution for real-world edge applications. Furthermore, we successfully $\textit{deployed TED on the ZYNQ-7020 platform}$, demonstrating its feasibility and effectiveness for resource-constrained edge devices in real-world deployments.

Paper number 112:
Title: PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System
Authors: Huayi Wang, Wentao Zhang, Runyi Yu, Tao Huang, Junli Ren, Feiyu Jia, Zirui Wang, Xiaojie Niu, Xiao Chen, Jiahe Chen, Qifeng Chen, Jingbo Wang, Jiangmiao Pang
Abstract: Deploying humanoid robots to interact with real-world environments--such as carrying objects or sitting on chairs--requires generalizable, lifelike motions and robust scene perception. Although prior approaches have advanced each capability individually, combining them in a unified system is still an ongoing challenge. In this work, we present a physical-world humanoid-scene interaction system, PhysHSI, that enables humanoids to autonomously perform diverse interaction tasks while maintaining natural and lifelike behaviors. PhysHSI comprises a simulation training pipeline and a real-world deployment system. In simulation, we adopt adversarial motion prior-based policy learning to imitate natural humanoid-scene interaction data across diverse scenarios, achieving both generalization and lifelike behaviors. For real-world deployment, we introduce a coarse-to-fine object localization module that combines LiDAR and camera inputs to provide continuous and robust scene perception. We validate PhysHSI on four representative interactive tasks--box carrying, sitting, lying, and standing up--in both simulation and real-world settings, demonstrating consistently high success rates, strong generalization across diverse task goals, and natural motion patterns.

Paper number 113:
Title: Visible Light Communication for Vehicular Networks: A Tutorial
Authors: Pedro E. Gória Silva, Eduardo S. Lima, Jules M. Moualeu, Mohamed Korium, Pedro H. J. Nardelli
Abstract: The advent of the fifth-generation technology promises to bring about more vertical applications and emerging services that include vehicular networks and intelligent transportation systems (ITSs). To achieve their vision of real-time and safetyapplications, vehicular networks rely on short-range to medium-range communications. One emerging technology that aims to provide reliability and high-data rate in short-range communications is the visible light communications (VLC). Due to its remarkable advantages, some studies have recently investigated the integration of VLC in vehicular networks and ITSs. Despite their attractive features, such networks also face several implementation issues. This paper provides an extended tutorial on the implementation of VLC-based vehicular networks. To begin with, we present the implementation characteristics of these systems and discuss some related issues. The underlying system considers a general structure with transmitters, channels, and receivers based on photodetectors and cameras, as well as standardization efforts and types of topologies. In addition, we discuss the impact of the sun and artificial light sources, flickering, dimming, throughput enhancement, uplink security, and mobility on practical implementation. Finally, we highlight some key challenges and potential solutions and provide some directions for future research investigations that could constitute an advancement toward the development of commercial VLC-based vehicular systems.

Paper number 114:
Title: Learning the Structure of Connection Graphs
Authors: Leonardo Di Nino, Gabriele D'Acunto, Sergio Barbarossa, Paolo Di Lorenzo
Abstract: Connection graphs (CGs) extend traditional graph models by coupling network topology with orthogonal transformations, enabling the representation of global geometric consistency. They play a key role in applications such as synchronization, Riemannian signal processing, and neural sheaf diffusion. In this work, we address the inverse problem of learning CGs directly from observed signals. We propose a principled framework based on maximum pseudo-likelihood under a consistency assumption, which enforces spectral properties linking the connection Laplacian to the underlying combinatorial Laplacian. Based on this formulation, we introduce the Structured Connection Graph Learning (SCGL) algorithm, a block-optimization procedure over Riemannian manifolds that jointly infers network topology, edge weights, and geometric structure. Our experiments show that SCGL consistently outperforms existing baselines in both topological recovery and geometric fidelity, while remaining computationally efficient.

Paper number 115:
Title: Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap
Authors: KiHyun Nam, Jongmin Choi, Hyeongkeun Lee, Jungwoo Heo, Joon Son Chung
Abstract: Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance this https URL

Paper number 116:
Title: Exponential convergence of multiagent systems with lack of connection
Authors: Fabio Ancona, Mohamed Bentaibi, Francesco Rossi
Abstract: Finding conditions ensuring consensus, i.e. convergence to a common value, for a networked system is of crucial interest, both for theoretical reasons and applications. This goal is harder to achieve when connections between agents are temporarily lost. Here, we prove that known conditions (introduced by Moreau) ensure an exponential convergence to consensus, with explicit rate of convergence. The key result is related to the length of the graph (i.e. the number of connections to reach a common agent): if this is large, then convergence is slow. This general result also provides conditions for convergence of second-order cooperative systems with lack of connections.

Paper number 117:
Title: Repeated-and-Offset QPSK for DFT-s-OFDM in Satellite Access
Authors: Renaud-Alexandre Pitaval
Abstract: Motivated by the convergence of terrestrial cellular networks with satellite networks, we consider an adaptation of offset quadrature phase shift keying (OQPSK), used with single-carrier waveform in traditional satellite systems, to discrete Fourier transform spread (DFT-s-) orthogonal frequency-division multiplexed (OFDM) waveform employed in the uplink of terrestrial systems. We introduce a new order-one constellation modulation, termed repeated-and-offset QPSK (RO-QPSK), derive its basic properties, and compare it with pi/2-BPSK with frequency-domain spectral shaping (FDSS), as supported in 5G. RO-QPSK naturally produces a Hann-window-shaped spectrum, resulting in a very low maximum peak-to-average power ratio (PAPR) on the order of 2 dB. Moreover, with single-tap equalization and symbol combining at the receiver, RO-QSPK can improve the signal-to-interference-plus-noise (SINR) compared to pi/2-BPSK with FDSS, in narrowband and/or moderately frequency-selective channels, as encountered in satellite communications. A moderate FDSS can also be combined with RO-QSPK to further reduce the PAPR while providing similar performance. Of independent interest, general SINR expressions for DFT-s-OFDM are also provided.

Paper number 118:
Title: A Faster and More Reliable Middleware for Autonomous Driving Systems
Authors: Yuankai He, Hanlin Chen, Weisong Shi
Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control loops and tightly bounded delays from perception to actuation. Many open-source autonomy systems rely on ROS 2 middleware; when multiple sensor and control nodes share one compute unit, ROS 2 and its DDS transports add significant (de)serialization, copying, and discovery overheads, shrinking the available time budget. We present Sensor-in-Memory (SIM), a shared-memory transport designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double buffers that overwrite old data to prioritize freshness, and integrates into ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM operates beside ROS 2 and is optimized for applications where data freshness and minimal latency outweigh guaranteed completeness. SIM provides sequence numbers, a writer heartbeat, and optional checksums to ensure ordering, liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces data-transport latency by up to 98% compared to ROS 2 zero-copy transports such as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows 95th/99th-percentile tail latencies by around 96%. In tests on a production-ready Level 4 vehicle running this http URL, SIM increased localization frequency from 7.5 Hz to 9.5 Hz. Applied across all latency-critical modules, SIM cut average perception-to-decision latency from 521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h) on dry concrete by 13.6 ft (4.14 m).

Paper number 119:
Title: Constraint-Aware Reinforcement Learning via Adaptive Action Scaling
Authors: Murad Dawood, Usama Ahmed Siddiquie, Shahram Khorshidi, Maren Bennewitz
Abstract: Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that arise from exploration during training by reducing constraint violations while maintaining task performance. Existing approaches typically rely on a single policy to jointly optimize reward and safety, which can cause instability due to conflicting objectives, or they use external safety filters that override actions and require prior system knowledge. In this paper, we propose a modular cost-aware regulator that scales the agent's actions based on predicted constraint violations, preserving exploration through smooth action modulation rather than overriding the policy. The regulator is trained to minimize constraint violations while avoiding degenerate suppression of actions. Our approach integrates seamlessly with off-policy RL methods such as SAC and TD3, and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion tasks with sparse costs, reducing constraint violations by up to 126 times while increasing returns by over an order of magnitude compared to prior methods.

Paper number 120:
Title: Automatic Music Sample Identification with Multi-Track Contrastive Learning
Authors: Alain Riou, Joan Serrà, Yuki Mitsufuji
Abstract: Sampling, the technique of reusing pieces of existing audio tracks to create new music content, is a very common practice in modern music production. In this paper, we tackle the challenging task of automatic sample identification, that is, detecting such sampled content and retrieving the material from which it originates. To do so, we adopt a self-supervised learning approach that leverages a multi-track dataset to create positive pairs of artificial mixes, and design a novel contrastive learning objective. We show that such method significantly outperforms previous state-of-the-art baselines, that is robust to various genres, and that scales well when increasing the number of noise songs in the reference database. In addition, we extensively analyze the contribution of the different components of our training pipeline and highlight, in particular, the need for high-quality separated stems for this task.

Paper number 121:
Title: IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy
Authors: Enli Lin, Ziyuan Yang, Qiujing Lu, Jianming Hu, Shuo Feng
Abstract: Realistic traffic simulation is critical for ensuring the safety and reliability of autonomous vehicles (AVs), especially in complex and diverse urban traffic environments. However, existing data-driven simulators face two key challenges: a limited focus on modeling dense, heterogeneous interactions at urban intersections - which are prevalent, crucial, and practically significant in countries like China, featuring diverse agents including motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and the inherent difficulty in robustly learning high-dimensional joint distributions for such high-density scenes, often leading to mode collapse and long-term simulation instability. We introduce City Crossings Dataset (CiCross), a large-scale dataset collected from a real-world urban intersection, uniquely capturing dense, heterogeneous multi-agent interactions, particularly with a substantial proportion of MVs, NMVs and pedestrians. Based on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving Environment), a data-driven simulator tailored for complex urban intersection scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a training paradigm that learns compositional dynamics from agent subsets, enabling the marginal-to-joint simulation. Integrated into a scene-aware Transformer network with specialized training techniques, IDS significantly enhances simulation robustness and long-term stability for modeling heterogeneous interactions. Experiments on CiCross show that IntersectioNDE outperforms baseline methods in simulation fidelity, stability, and its ability to replicate complex, distribution-level urban traffic dynamics.

Paper number 122:
Title: Ego-Vision World Model for Humanoid Contact Planning
Authors: Hang Liu, Yuman Gao, Sangli Teng, Yufeng Chi, Yakun Sophia Shao, Zhongyu Li, Maani Ghaffari, Koushil Sreenath
Abstract: Enabling humanoid robots to exploit physical contact, rather than simply avoid collisions, is crucial for autonomy in unstructured environments. Traditional optimization-based planners struggle with contact complexity, while on-policy reinforcement learning (RL) is sample-inefficient and has limited multi-task ability. We propose a framework combining a learned world model with sampling-based Model Predictive Control (MPC), trained on a demonstration-free offline dataset to predict future outcomes in a compressed latent space. To address sparse contact rewards and sensor noise, the MPC uses a learned surrogate value function for dense, robust planning. Our single, scalable model supports contact-aware tasks, including wall support after perturbation, blocking incoming objects, and traversing height-limited arches, with improved data efficiency and multi-task capability over on-policy RL. Deployed on a physical humanoid, our system achieves robust, real-time contact planning from proprioception and ego-centric depth images. Website: this https URL

Paper number 123:
Title: Speech Enhancement and Dereverberation with Diffusion-based Generative Models
Authors: Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Timo Gerkmann
Abstract: In this work, we build upon our previous publication and use diffusion-based generative models for speech enhancement. We present a detailed overview of the diffusion process that is based on a stochastic differential equation and delve into an extensive theoretical examination of its implications. Opposed to usual conditional generation tasks, we do not start the reverse process from pure Gaussian noise but from a mixture of noisy speech and Gaussian noise. This matches our forward process which moves from clean speech to noisy speech by including a drift term. We show that this procedure enables using only 30 diffusion steps to generate high-quality clean speech estimates. By adapting the network architecture, we are able to significantly improve the speech enhancement performance, indicating that the network, rather than the formalism, was the main limitation of our original approach. In an extensive cross-dataset evaluation, we show that the improved method can compete with recent discriminative models and achieves better generalization when evaluating on a different corpus than used for training. We complement the results with an instrumental evaluation using real-world noisy recordings and a listening experiment, in which our proposed method is rated best. Examining different sampler configurations for solving the reverse process allows us to balance the performance and computational speed of the proposed method. Moreover, we show that the proposed method is also suitable for dereverberation and thus not limited to additive background noise removal. Code and audio examples are available online, see this https URL.

Paper number 124:
Title: Optimal Planning of Electric Vehicle Charging Stations: Integrating Public Charging Networks and Transportation Congestion
Authors: Jingbo Wang, Harshal D. Kaushik, Jie Zhang
Abstract: The adoption of electric vehicles (EVs) represents a critical shift in personal mobility, fueled by policy support and advancements in automotive technology. However, the expansion of EVs for long-distance travel is hindered by charging time concerns, the sparse distribution of charging stations, and the worsening waiting times due to congestion. The main objective of this work is two-fold: 1) first, to comprehensively analyze the existing public charging station robustness and effectively strategize for the new ones, and 2) secondly, to select the optimal chargers for long-distance journeys, by estimating the waiting time from current traffic congestion. This is achieved by accompanying effective EV charging strategies, pinpointing on the congestion points from the existing traffic, and the robustness of the current charging station infrastructure. Utilizing a real-time transportation and charging station dataset in Texas, we identify optimal charger placement strategies to minimize travel time by examining the congestion and charging time trade-offs. Our findings suggest that maximizing the constant current phase during charging enhances efficiency, crucial for long-distance travel. On the contrary, we also explore the negative impact of congestion on travel times and we conclude that sometimes it might be beneficial to exceed the constant current phase to avoid the congested charging stations.

Paper number 125:
Title: Optimal Assignment and Motion Control in Two-Class Continuum Swarms
Authors: Max Emerick, Stacy Patterson, Bassam Bamieh
Abstract: We consider optimal swarm control problems where two different classes of agents are present. Continuum idealizations of large-scale swarms are used where the dynamics describe the evolution of the spatially-distributed densities of each agent class. The problem formulation we adopt is motivated by applications where agents of one class are assigned to agents of the other class, which we refer to as demand and resource agents respectively. Assignments have costs related to the distances between mutually assigned agents, and the overall cost of an assignment is quantified by a Wasserstein distance between the densities of the two agent classes. When agents can move, the assignment cost can decrease at the expense of a physical motion cost, and this tradeoff sets up a nonlinear infinite-dimensional optimal control problem. We show that in one spatial dimension, this problem can be converted to an infinite-dimensional, but decoupled, linear-quadratic (LQ) tracking problem when expressed in terms of the quantile functions of the respective agent densities. Solutions are given in the general one-dimensional case, as well as in the special cases of constant and periodically time-varying demands.

Paper number 126:
Title: DUST: A Framework for Data-Driven Density Steering
Authors: Joshua Pilipovsky, Panagiotis Tsiotras
Abstract: We consider the problem of data-driven stochastic optimal control of an unknown LTI dynamical system. Assuming the process noise is normally distributed, we pose the problem of steering the state's mean and covariance to a target normal distribution, under noisy data collected from the underlying system, a problem commonly referred to as covariance steering (CS). A novel framework for Data-driven Uncertainty quantification and density STeering (DUST) is presented that simultaneously characterizes the noise affecting the measured data and designs an optimal affine-feedback controller to steer the density of the state to a prescribed terminal value. We use both indirect and direct data-driven design approaches based on the notions of persistency of excitation and subspace identification to exactly represent the mean and covariance dynamics of the state in terms of the data and noise realizations. Since both the mean and the covariance steering sub-problems are plagued with stochastic uncertainty arising from noisy data collection, we first estimate the noise realization from this dataset and subsequently compute tractable upper bounds on the estimation errors. The first and second moment steering problems are then solved to optimality using techniques from robust control and robust optimization. Lastly, we present an alternative control design approach based on the certainty equivalence principle and interpret the problem as one of CS under multiplicative uncertainty. We analyze the performance and efficacy of each of these data-driven approaches using a case study and compare them with their model-based counterparts.

Paper number 127:
Title: Rethinking Medical Anomaly Detection in Brain MRI: An Image Quality Assessment Perspective
Authors: Zixuan Pan, Jun Xia, Zheyu Yan, Guoyue Xu, Yifan Qin, Xueyang Li, Yawen Wu, Zhenge Jia, Jianxu Chen, Yiyu Shi
Abstract: Reconstruction-based methods, particularly those leveraging autoencoders, have been widely adopted for anomaly detection task in brain MRI. Unlike most existing works try to improve the task accuracy through architectural or algorithmic innovations, we tackle this task from image quality assessment (IQA) perspective, an under-explored direction in the field. Due to the limitations of conventional metrics such as l1 in capturing the nuanced differences in reconstructed images for medical anomaly detection, we propose fusion quality, a novel metric that wisely integrates the structure-level sensitivity of Structural Similarity Index Measure (SSIM) with the pixel-level precision of l1. The metric offers a more comprehensive assessment of reconstruction quality, considering intensity (subtractive property of l1 and divisive property of SSIM), contrast, and structural similarity. Furthermore, the proposed metric makes subtle regional variations more impactful in the final assessment. Thus, considering the inherent divisive properties of SSIM, we design an average intensity ratio (AIR)-based data transformation that amplifies the divisive discrepancies between normal and abnormal regions, thereby enhancing anomaly detection. By fusing the aforementioned two components, we devise the IQA approach. Experimental results on two distinct brain MRI datasets show that our IQA approach significantly enhances medical anomaly detection performance when integrated with state-of-the-art baselines.

Paper number 128:
Title: Stimulus Modality Matters: Impact of Perceptual Evaluations from Different Modalities on Speech Emotion Recognition System Performance
Authors: Huang-Cheng Chou, Haibin Wu, Chi-Chun Lee
Abstract: Speech Emotion Recognition (SER) systems rely on speech input and emotional labels annotated by humans. However, various emotion databases collect perceptional evaluations in different ways. For instance, the IEMOCAP dataset uses video clips with sounds for annotators to provide their emotional perceptions. However, the most significant English emotion dataset, the MSP-PODCAST, only provides speech for raters to choose the emotional ratings. Nevertheless, using speech as input is the standard approach to training SER systems. Therefore, the open question is the emotional labels elicited by which scenarios are the most effective for training SER systems. We comprehensively compare the effectiveness of SER systems trained with labels elicited by different modality stimuli and evaluate the SER systems on various testing conditions. Also, we introduce an all-inclusive label that combines all labels elicited by various modalities. We show that using labels elicited by voice-only stimuli for training yields better performance on the test set, whereas labels elicited by voice-only stimuli.

Paper number 129:
Title: A Systematic Review on Foundation Models for Electrocardiogram Analysis: Initial Strides and Expansive Horizons
Authors: Yu Han, Vittorio Murino, Xiaofeng Liu, Xiang Zhang, Cheng Ding
Abstract: Electrocardiogram (ECG) is widely used in healthcare applications, such as arrhythmia detection and sleep monitoring, making accurate ECG analysis critically essential. Traditional deep learning models for ECG are task-specific, with limited generalization and narrow functionality. Foundation models (FMs), or large pre-training models, have recently advanced representation learning, enabling strong performance across diverse tasks and motivating their adoption for ECG analysis. Here, we present the first comprehensive review dedicated to ECG foundation models (ECG-FMs). We map the current landscape of architectures, pre-training paradigms, and adaptation strategies, and critically examine their strengths, limitations, and clinical potential. By consolidating this emerging field, we aim to accelerate the development of robust, generalizable ECG-FMs and chart future directions for their integration into healthcare practice.

Paper number 130:
Title: Multiple input tangential interpolation-driven damage detection of a jet trainer aircraft
Authors: Gabriele Dessena, Marco Civera, Andrés Marcos, Bernardino Chiaia, Oscar E. Bonilla-Manrique
Abstract: The problem of damage detection and identification is of interest for many aerospace and aeronautical engineering systems. However, relevant literature mostly focuses on subsystems and parts, rather than full airframes. In structural dynamics, modal parameters, such as natural frequencies and mode shapes, from any structure are the main building blocks of vibration-based damage detection. However, traditional comparisons of these parameters are often ambiguous in complex systems, complicating damage detection and assessment. The modified total modal assurance criterion (MTMAC), an index well-known in the field of finite element model updating, is extended to address this challenge and is proposed as an index for damage identification and severity assessment. To support the requirement for precise and robust modal identification of Structural Health Monitoring (SHM), the improved Loewner Framework (iLF), known for its reliability and computational performance, is pioneeringly employed within SHM. Since the MTMAC is proposed solely as a damage identification and severity assessment index, the coordinate modal assurance criterion (COMAC), also a well-established tool, but for damage localisation using mode shapes, is used for completeness. The iLF SHM capabilities are validated through comparisons with traditional methods, including least-squares complex exponential and stochastic subspace identification with canonical variate analysis on a numerical case study of a cantilever beam. Furthermore, the MTMAC is validated against the traditional vibration-based approach, which involves directly comparing natural frequencies and mode shapes. Finally, an experimental dataset from a BAE Systems Hawk T1A jet trainer ground vibration test is used to demonstrate the iLF and MTMAC capabilities on a real-life, real-size SHM problem, showing their effectiveness in detecting and assessing damage.

Paper number 131:
Title: Movable Antenna Enhanced Networked Integrated Sensing and Communication System
Authors: Yuan Guo, Wen Chen, Qingqing Wu, Yang Liu, Qiong Wu, Kunlun Wang, Jun Li, Lexi Xu
Abstract: Integrated sensing and communication (ISAC) is a key technology for future 6G networks. Most existing studies focus on monostatic and/or bistatic setups with limited coverage and capabilities. Networked ISAC systems with distributed base stations (BSs) can overcome these limitations. Moreover, movable antenna (MA) architectures offer improved ISAC performance over fixed-position antennas (FPAs) by enabling adaptable antenna movement. In this paper, we utilize the MA to promote communication capability with guaranteed sensing performance via jointly designing beamforming, power allocation, receiving filters and position configuration of transmit/receive MA towards maximizing the sum rate for both downlink (DL) and uplink (UL) users. The optimization problem is highly difficult due to the unique channel model derived from the position coefficient of the MA. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) method, we develop an efficient solution that optimizes all variables via convex optimization techniques. Extensive simulation results verify the effectiveness of our proposed algorithms and demonstrate the substantial performance promotion by deploying the MA framework in the networked ISAC system.

Paper number 132:
Title: Cell as Point: One-Stage Framework for Efficient Cell Tracking
Authors: Yaxuan Song, Jianan Fan, Heng Huang, Mei Chen, Weidong Cai
Abstract: Conventional multi-stage cell tracking approaches rely heavily on detection or segmentation in each frame as a prerequisite, requiring substantial resources for high-quality segmentation masks and increasing the overall prediction time. To address these limitations, we propose CAP, a novel end-to-end one-stage framework that reimagines cell tracking by treating Cell as Point. Unlike traditional methods, CAP eliminates the need for explicit detection or segmentation, instead jointly tracking cells for sequences in one stage by leveraging the inherent correlations among their trajectories. This simplification reduces both labeling requirements and pipeline complexity. However, directly processing the entire sequence in one stage poses challenges related to data imbalance in capturing cell division events and long sequence inference. To solve these challenges, CAP introduces two key innovations: (1) adaptive event-guided (AEG) sampling, which prioritizes cell division events to mitigate the occurrence imbalance of cell events, and (2) the rolling-as-window (RAW) inference strategy, which ensures continuous and stable tracking of newly emerging cells over extended sequences. By removing the dependency on segmentation-based preprocessing while addressing the challenges of imbalanced occurrence of cell events and long-sequence tracking, CAP demonstrates promising cell tracking performance and is 8 to 32 times more efficient than existing methods. The code and model checkpoints will be available soon.

Paper number 133:
Title: Global Attitude Synchronization for Heterogeneous Multi-agent Systems on SO(3)
Authors: Mouaad Boughellaba, Soulaimane Berkane, Abdelhamid Tayebi
Abstract: In this paper, we address the problem of attitude synchronization for a group of rigid body systems evolving on SO(3). The interaction among these systems is modeled through an undirected, connected, and acyclic graph topology. First, we present an almost global continuous distributed attitude synchronization scheme with rigorously proven stability guarantees. Thereafter, we propose two global distributed hybrid attitude synchronization schemes on SO(3). The first scheme is a hybrid control law that leverages angular velocities and relative orientations to achieve global alignment to a common orientation. The second scheme eliminates the dependence on angular velocities by introducing dynamic auxiliary variables, while ensuring global asymptotic attitude synchronization. This velocity-free control scheme relies exclusively on attitude information. The proposed schemes are applicable to heterogeneous multi-agent systems, where agents may have distinct inertia matrices. Simulation results are provided to illustrate the effectiveness of the proposed distributed attitude synchronization schemes.

Paper number 134:
Title: A New Interpretation of the Time-Interleaved ADC Mismatch Problem: A Tracking-Based Hybrid Calibration Approach
Authors: Jiwon Sung, Jinseok Choi
Abstract: Time-interleaved ADCs (TI-ADCs) achieve high sampling rates by interleaving multiple sub-ADCs in parallel. Mismatch errors between the sub-ADCs, however, can significantly degrade the signal quality, which is a main performance bottleneck. This paper presents a hybrid calibration approach by interpreting the mismatch problem as a tracking problem, and uses the extended Kalman filter for online estimation and compensation of the mismatch errors. After estimation, the desired signal is reconstructed using a truncated fractional delay filter and a high-pass filter. Simulations demonstrate that our algorithm substantially outperforms the existing hybrid calibration method in both mismatch estimation and compensation.

Paper number 135:
Title: A Unified Framework for Innovation-based Stochastic and Deterministic Event Triggers
Authors: Eva Julia Schmitt, Benjamin Noack
Abstract: Resources such as bandwidth and energy are limited in many wireless communications use cases, especially when large numbers of sensors and fusion centers need to exchange information frequently. One opportunity to overcome resource constraints is the use of event-based transmissions and estimation to transmit only information that contributes significantly to the reconstruction of the system's state. The design of efficient triggering policies and estimators is crucial for successful event-based transmissions. While previously deterministic and stochastic event triggering policies have been treated separately, this paper unifies the two approaches and gives insights into the design of consistent trigger-matching estimators. Two different estimators are presented, and different pairs of triggers and estimators are evaluated through simulation studies.

Paper number 136:
Title: Topology optimization of decoupling feeding networks for antenna arrays
Authors: Pan Lu, Eddie Wadbro, Jonas Starck, Martin Berggren, Emadeldeen Hassan
Abstract: Near-field and radiation coupling between nearby radiating elements is unavoidable, and it is considered a limiting factor for applications in wireless communications and active sensing. This article proposes a density-based topology optimization approach to design decoupling networks for such systems. The decoupling networks are designed based on a multi-objective optimization problem with the radiating elements replaced by their time-domain impulse response for efficient computations and to enable the solution of the design problem using gradient-based optimization methods. We use the adjoint-field method to compute the gradients of the optimization objectives. Additionally, nonlinear filters are applied during the optimization procedure to impose minimum-size control on the optimized designs. We demonstrate the concept by designing the decoupling network for a two-element planar antenna array; the antenna is designed in a separate optimization problem. The optimized decoupling networks provide a signal path that destructively interferes with the coupling between the radiating elements while preserving their individual matching to the feeding ports. Compact decoupling networks capable of suppressing the mutual coupling by more than 10 dB between two closely separated planar antennas operating around 2.45 GHz are presented and validated experimentally.

Paper number 137:
Title: A Taylor Series Approach to Correction of Input Errors in Gaussian Process Regression
Authors: Muzaffar Qureshi, Tochukwu Elijah Ogri, Zachary I. Bell, Wanjiku A. Makumi, Rushikesh Kamalapurkar
Abstract: Gaussian Processes (GPs) are widely recognized as powerful non-parametric models for regression and classification. Traditional GP frameworks predominantly operate under the assumption that the inputs are either accurately known or subject to zero-mean noise. However, several real-world applications such as mobile sensors have imperfect localization, leading to inputs with biased errors. These biases can typically be estimated through measurements collected over time using, for example, Kalman filters. To avoid recomputation of the entire GP model when better estimates of the inputs used in the training data become available, we introduce a technique for updating a trained GP model to incorporate updated estimates of the inputs. By leveraging the differentiability of the mean and covariance functions derived from the squared exponential kernel, a second-order correction algorithm is developed to update the trained GP models. Precomputed Jacobians and Hessians of kernels enable real-time refinement of the mean and covariance predictions. The efficacy of the developed approach is demonstrated using two simulation studies, with error analyses revealing improvements in both predictive accuracy and uncertainty quantification.

Paper number 138:
Title: Data-driven Model Predictive Control using MATLAB
Authors: Midhun T. Augustine
Abstract: This paper presents a comprehensive overview of data-driven model predictive control, highlighting state-of-the-art methodologies and their numerical implementation. The discussion begins with a brief review of conventional model predictive control (MPC), which discusses both linear MPC (LMPC) and nonlinear MPC (NMPC). This is followed by a section on data-driven LMPC, outlining fundamental concepts and the implementation of various approaches, including subspace predictive control and prediction error methods. Subsequently, the focus shifts to data-driven NMPC, emphasizing approaches based on neural network models. The paper concludes with a review of recent advancements in data-driven MPC and explores potential directions for future research.

Paper number 139:
Title: MedVKAN: Efficient Feature Extraction with Mamba and KAN for Medical Image Segmentation
Authors: Hancan Zhu, Jinhao Chen, Guanghua He
Abstract: Medical image segmentation has traditionally relied on convolutional neural networks (CNNs) and Transformer-based models. CNNs, however, are constrained by limited receptive fields, while Transformers face scalability challenges due to quadratic computational complexity. To over-come these issues, recent studies have explored alternative architectures. The Mamba model, a selective state-space design, achieves near-linear complexity and effectively captures long-range dependencies. Its vision-oriented variant, the Visual State Space (VSS) model, extends these strengths to image feature learning. In parallel, the Kolmogorov-Arnold Network (KAN) enhanc-es nonlinear expressiveness by replacing fixed activation functions with learnable ones. Moti-vated by these advances, we propose the VSS-Enhanced KAN (VKAN) module, which integrates VSS with the Expanded Field Convolutional KAN (EFC-KAN) as a replacement for Transformer modules, thereby strengthening feature extraction. We further embed VKAN into a U-Net frame-work, resulting in MedVKAN, an efficient medical image segmentation model. Extensive exper-iments on five public datasets demonstrate that MedVKAN achieves state-of-the-art performance on four datasets and ranks second on the remaining one. These results underscore the effective-ness of combining Mamba and KAN while introducing a novel and computationally efficient feature extraction framework. The source code is available at: this https URL.

Paper number 140:
Title: Connecting the Equinoctial Elements and Rodrigues Parameters: A New Set of Elements
Authors: Joseph T.A. Peterson, Vishala Arya, John L. Junkins
Abstract: A geometric interpretation of the equinoctial elements is given with a connection to orthogonal rotations and attitude dynamics in Euclidean 3-space. An identification is made between the equinoctial elements and classic Rodrigues parameters. A new set of equinoctial elements are developed using the modified Rodrigues parameters, thereby removing the coordinate singularity for retrograde equatorial orbits present in previous versions of these elements. A low-thrust trajectory optimization problem is set up using the new elements to numerically verify convergence for the two-point boundary problem, as compared to their predecessors.

Paper number 141:
Title: OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates
Authors: Jinpei Guo, Yifei Ji, Zheng Chen, Kai Liu, Min Liu, Wang Rao, Wenbo Li, Yong Guo, Yulun Zhang
Abstract: Pretrained latent diffusion models have shown strong potential for lossy image compression, owing to their powerful generative priors. Most existing diffusion-based methods reconstruct images by iteratively denoising from random noise, guided by compressed latent representations. While these approaches have achieved high reconstruction quality, their multi-step sampling process incurs substantial computational overhead. Moreover, they typically require training separate models for different compression bit-rates, leading to significant training and storage costs. To address these challenges, we propose a one-step diffusion codec across multiple bit-rates. termed OSCAR. Specifically, our method views compressed latents as noisy variants of the original latents, where the level of distortion depends on the bit-rate. This perspective allows them to be modeled as intermediate states along a diffusion trajectory. By establishing a mapping from the compression bit-rate to a pseudo diffusion timestep, we condition a single generative model to support reconstructions at multiple bit-rates. Meanwhile, we argue that the compressed latents retain rich structural information, thereby making one-step denoising feasible. Thus, OSCAR replaces iterative sampling with a single denoising pass, significantly improving inference efficiency. Extensive experiments demonstrate that OSCAR achieves superior performance in both quantitative and visual quality metrics. The code and models are available at this https URL.

Paper number 142:
Title: Context-Aware Deep Learning for Robust Channel Extrapolation in Fluid Antenna Systems
Authors: Yanliang Jin, Runze Yu, Yuan Gao, Shengli Liu, Xiaoli Chu, Kai-Kit Wong, Chan-Byoung Chae
Abstract: Fluid antenna systems (FAS) offer remarkable spatial flexibility but face significant challenges in acquiring high-resolution channel state information (CSI), leading to considerable overhead. To address this issue, we propose CANet, a robust deep learning model for channel extrapolation in FAS. CANet combines context-adaptive modeling with a cross-scale attention mechanism and is built on a ConvNeXt v2 backbone to improve extrapolation accuracy for unobserved antenna ports. To further enhance robustness, we introduce a novel spatial amplitude perturbation strategy, inspired by frequency-domain augmentation techniques in image processing. This motivates the incorporation of a Fourier-domain loss function, capturing frequency-domain consistency, alongside a spectral structure consistency loss that reinforces learning stability under perturbations. Our simulation results demonstrate that CANet outperforms benchmark models across a wide range of signal-to-noise ratio (SNR) levels.

Paper number 143:
Title: Deep Learning-Based Beamforming Design Using Target Beam Patterns
Authors: Hongpu Zhang, Shu Sun, Hangsong Yan, Jianhua Mo
Abstract: This paper proposes a deep learning-based beamforming design framework that directly maps a target beam pattern to optimal beamforming vectors across multiple antenna array architectures, including digital, analog, and hybrid beamforming. The proposed method employs a lightweight encoder-decoder network where the encoder compresses the complex beam pattern into a low-dimensional feature vector and the decoder reconstructs the beamforming vector while satisfying hardware constraints. To address training challenges under diverse and limited channel station information (CSI) conditions, a two-stage training process is introduced, which consists of an offline pre-training for robust feature extraction using an auxiliary module, followed by online training of the decoder with a composite loss function that ensures alignment between the synthesized and target beam patterns in terms of the main lobe shape and side lobe suppression. Simulation results based on NYUSIM-generated channels show that the proposed method can achieve spectral efficiency close to that of fully digital beamforming under limited CSI and outperforms representative existing methods.

Paper number 144:
Title: Towards channel foundation models (CFMs): Motivations, methodologies and opportunities
Authors: Jun Jiang, Yuan Gao, Xinyi Wu, Shugong Xu
Abstract: Artificial intelligence (AI) has emerged as a pivotal enabler for next-generation wireless communication systems. However, conventional AI-based models encounter several limitations, such as heavy reliance on labeled data, limited generalization capability, and task-specific design. To address these challenges, this paper introduces, for the first time, the concept of channel foundation models (CFMs)-a novel and unified framework designed to tackle a wide range of channel-related tasks through a pretrained, universal channel feature extractor. By leveraging advanced AI architectures and self-supervised learning techniques, CFMs are capable of effectively exploiting large-scale unlabeled data without the need for extensive manual annotation. We further analyze the evolution of AI methodologies, from supervised learning and multi-task learning to self-supervised learning, emphasizing the distinct advantages of the latter in facilitating the development of CFMs. Additionally, we provide a comprehensive review of existing studies on self-supervised learning in this domain, categorizing them into generative, discriminative and the combined paradigms. Given that the research on CFMs is still at an early stage, we identify several promising future research directions, focusing on model architecture innovation and the construction of high-quality, diverse channel datasets.

Paper number 145:
Title: Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model
Authors: Jiayu Ding, Benjamin Seleb, Heather J. Huson, Saad Bhamla, Zhenyu Gan
Abstract: Quadrupedal animals employ diverse galloping strategies to optimize speed, stability, and energy efficiency. However, the biomechanical mechanisms that enable adaptive gait transitions during high-speed locomotion under load remain poorly understood. In this study, we present new empirical and modeling insights into the biomechanics of load-pulling quadrupeds, using sprint sled dogs as a model system. High-speed video and force recordings reveal that sled dogs often switch between rotary and transverse galloping gaits within just a few strides and without any observable changes in speed, stride duration, or terrain, providing clear evidence of locomotor multistability during high-speed load-pulling. To investigate the mechanical basis of these transitions, a physics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid dynamics and prescribed footfall sequences to reproduce the asymmetric galloping patterns observed in racing sled dogs. Through trajectory optimization, we replicate experimentally observed gait sequences and identify swing-leg stiffness modulation as a key control mechanism for inducing transitions. This work provides a much-needed biomechanical perspective on high-speed animal draft and establishes a modeling framework for studying locomotion in pulling quadrupeds, with implications for both biological understanding and the design of adaptive legged systems.

Paper number 146:
Title: Adaptive Network Security Policies via Belief Aggregation and Rollout
Authors: Kim Hammar, Yuchao Li, Tansu Alpcan, Emil C. Lupu, Dimitri Bertsekas
Abstract: Evolving security vulnerabilities and shifting operational conditions require frequent updates to network security policies. These updates include adjustments to incident response procedures and modifications to access controls, among others. Reinforcement learning methods have been proposed for automating such policy adaptations, but most of the methods in the research literature lack performance guarantees and adapt slowly to changes. In this paper, we address these limitations and present a method for computing security policies that is scalable, offers theoretical guarantees, and adapts quickly to changes. It assumes a model or simulator of the system and comprises three components: belief estimation through particle filtering, offline policy computation through aggregation, and online policy adaptation through rollout. Central to our method is a new feature-based aggregation technique, which improves scalability and flexibility. We analyze the approximation error of aggregation and show that rollout efficiently adapts policies to changes under certain conditions. Simulations and testbed results demonstrate that our method outperforms state-of-the-art methods on several benchmarks, including CAGE-2.

Paper number 147:
Title: Joint Active and Passive Beamforming for Energy-Efficient STARS with Quantization and Element Selection in ISAC Systems
Authors: Li-Hsiang Shen, Yi-Hsuan Chiu
Abstract: This paper investigates a simultaneously transmitting and reflecting reconfigurable intelligent surface (STARS)-aided integrated sensing and communication (ISAC) systems in support of full-space energy-efficient data transmissions and target sensing. We formulate an energy efficiency (EE) maximization problem that jointly optimizes a dual-functional radar-communication (DFRC)-empowered base station (BS), considering its ISAC-based active beamforming, along with the passive STARS beamforming configurations of amplitudes, phase shifts, quantization levels, and element selection. Furthermore, relaxed/independent/coupled STARS are considered to examine architectural flexibility. To tackle the non-convex and mixed-integer problem, we propose a joint active-passive beamforming, quantization and element selection (AQUES) scheme based on the alternating optimization: Lagrangian dual and Dinkelbach's transformation tackle fractional equations, whereas successive convex approximation (SCA) convexifies the non-solvable problem; Penalty dual decomposition (PDD) framework and penalty-based convex-concave programming (PCCP) procedure solve amplitude and phase-shifts with the equality constraint; Heuristic search iteratively decides the optimal quantization level; Integer relaxation deals with the discrete element selection variables. Simulation results demonstrate that STARS-ISAC with the proposed AQUES scheme significantly enhances EE while meeting communication rates and sensing quality requirements. The coupled STARS further highlights its superior EE performance over independent and relaxed STARS thanks to its reduced hardware complexity. Moreover, AQUES outperforms existing configurations and benchmark methods in the open literature across various network parameters and deployment scenarios.

Paper number 148:
Title: Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification
Authors: Gevindu Ganganath, Pasindu Sankalpa, Samal Punsara, Demitha Pasindu, Chamira U. S. Edussooriya, Ranga Rodrigo, Udaya S. K. P. Miriya Thanthrige
Abstract: The use of drones in a wide range of applications is steadily increasing. However, this has also raised critical security concerns such as unauthorized drone intrusions into restricted zones. Therefore, robust and accurate drone detection and classification mechanisms are required despite significant challenges due to small size of drones, low-altitude flight, and environmental noise. In this letter, we propose a multi-modal approach combining radar and acoustic sensing for detecting and classifying drones. We employ radar due to its long-range capabilities, and robustness to different weather conditions. We utilize raw acoustic signals without converting them to other domains such as spectrograms or Mel-frequency cepstral coefficients. This enables us to use fewer number of parameters compared to the stateof-the-art approaches. Furthermore, we explore the effectiveness of the transformer encoder architecture in fusing these sensors. Experimental results obtained in outdoor settings verify the superior performance of the proposed approach compared to the state-of-the-art methods.

Paper number 149:
Title: Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion
Authors: Timothy Oladunni, Ehimen Aneni
Abstract: The limitations of unimodal deep learning models, particularly their tendency to overfit and limited generalizability, have renewed interest in multimodal fusion strategies. Multimodal deep neural networks (MDNN) have the capability of integrating diverse data domains and offer a promising solution for robust and accurate predictions. However, the optimal fusion strategy, intermediate fusion (feature-level) versus late fusion (decision-level) remains insufficiently examined, especially in high-stakes clinical contexts such as ECG-based cardiovascular disease (CVD) classification. This study investigates the comparative effectiveness of intermediate and late fusion strategies using ECG signals across three domains: time, frequency, and time-frequency. A series of experiments were conducted to identify the highest-performing fusion architecture. Results demonstrate that intermediate fusion consistently outperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's d > 0.8 relative to standalone models and d = 0.40 compared to late fusion. Interpretability analyses using saliency maps reveal that both models align with the discretized ECG signals. Statistical dependency between the discretized ECG signals and corresponding saliency maps for each class was confirmed using Mutual Information (MI). The proposed ECG domain-based multimodal model offers superior predictive capability and enhanced explainability, crucial attributes in medical AI applications, surpassing state-of-the-art models.

Paper number 150:
Title: Instantaneous Polarimetry with Zak-OTFS
Authors: Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank
Abstract: Polarimetry, which is the ability to measure the scattering response of the environment across orthogonal polarizations, is fundamental to enhancing wireless communication and radar system performance. In this paper, we utilize the Zak-OTFS modulation to enable instantaneous polarimetry within a single transmission frame. We transmit a Zak-OTFS carrier waveform and a spread carrier waveform mutually unbiased to it simultaneously over orthogonal polarizations. The mutual unbiasedness of the two waveforms enables the receiver to estimate the full polarimetric response of the scattering environment from a single received frame. Unlike existing methods for instantaneous polarimetry with computational complexity quadratic in the time-bandwidth product, the proposed method enables instantaneous polarimetry at near-linear complexity in the time-bandwidth product. Via numerical simulations, we show ideal polarimetric target detection and parameter estimation results with the proposed method, with improvements in computational complexity and greater clutter resilience over comparable baselines.

Paper number 151:
Title: Enhancing Noise Robustness for Neural Speech Codecs through Resource-Efficient Progressive Quantization Perturbation Simulation
Authors: Rui-Chen Zheng, Yang Ai, Hui-Peng Du, Li-Rong Dai
Abstract: Noise robustness remains a critical challenge for deploying neural speech codecs in real-world acoustic scenarios where background noise is often inevitable. A key observation we make is that even slight input noise perturbations can cause unintended shifts in quantized codewords, thereby degrading the quality of reconstructed speech. Motivated by this finding, we propose a novel and resource-efficient training strategy to enhance the noise robustness of speech codecs by simulating such perturbations directly at the quantization level. Our approach introduces two core mechanisms: (1) a distance-weighted probabilistic top-K sampling strategy that replaces the conventional deterministic nearest-neighbor selection in residual vector quantization (RVQ); and (2) a progressive training scheme that introduces perturbations from the last to the first quantizer in a controlled manner. Crucially, our method is trained exclusively on clean speech, eliminating the need for any paired noisy-clean data. Experiments on two advanced neural speech codecs, Encodec and WavTokenizer, demonstrate that the proposed strategy substantially improves robustness under noisy conditions-for example, boosting UTMOS from 3.475 to 3.586 at 15 dB SNR on Encodec-while also enhancing coding quality for clean speech.

Paper number 152:
Title: SongFormer: Scaling Music Structure Analysis with Heterogeneous Supervision
Authors: Chunbo Hao, Ruibin Yuan, Jixun Yao, Qixin Deng, Xinyi Bai, Wei Xue, Lei Xie
Abstract: Music structure analysis (MSA) underpins music understanding and controllable generation, yet progress has been limited by small, inconsistent corpora. We present SongFormer, a scalable framework that learns from heterogeneous supervision. SongFormer (i) fuses short- and long-window self-supervised audio representations to capture both fine-grained and long-range dependencies, and (ii) introduces a learned source embedding to enable training with partial, noisy, and schema-mismatched labels. To support scaling and fair evaluation, we release SongFormDB, the largest MSA corpus to date (over 10k tracks spanning languages and genres), and SongFormBench, a 300-song expert-verified benchmark. On SongFormBench, SongFormer sets a new state of the art in strict boundary detection (HR.5F) and achieves the highest functional label accuracy, while remaining computationally efficient; it surpasses strong baselines and Gemini 2.5 Pro on these metrics and remains competitive under relaxed tolerance (HR3F). Code, datasets, and model are publicly available.

Paper number 153:
Title: Enhancing Speaker Verification with w2v-BERT 2.0 and Knowledge Distillation guided Structured Pruning
Authors: Ze Li, Ming Cheng, Ming Li
Abstract: Large-scale self-supervised Pre-Trained Models (PTMs) have shown significant improvements in the speaker verification (SV) task by providing rich feature representations. In this paper, we utilize w2v-BERT 2.0, a model with approximately 600 million parameters trained on 4.5 million hours of unlabeled data across 143 languages, for the SV task. The MFA structure with Layer Adapter is employed to process the multi-layer feature outputs from the PTM and extract speaker embeddings. Additionally, we incorporate LoRA for efficient fine-tuning. Our model achieves state-of-the-art results with 0.12% and 0.55% EER on the Vox1-O and Vox1-H test sets, respectively. Furthermore, we apply knowledge distillation guided structured pruning, reducing the model size by 80% while achieving only a 0.04% EER degradation. Source code and models are released at this https URL.

Paper number 154:
Title: Coordinated Beamforming for Networked Integrated Communication and Multi-TMT Localization
Authors: Meidong Xia, Zhenyao He, Wei Xu, Yongming Huang, Derrick Wing Kwan Ng, Naofal Al-Dhahir
Abstract: Networked integrated sensing and communication (ISAC) has gained significant attention as a promising technology for enabling next-generation wireless systems. To further enhance networked ISAC, delegating the reception of sensing signals to dedicated target monitoring terminals (TMTs) instead of base stations (BSs) offers significant advantages in terms of sensing capability and deployment flexibility. Despite its potential, the coordinated beamforming design for networked integrated communication and time-of-arrival (ToA)-based multi-TMT localization remains largely unexplored. In this paper, we present a comprehensive study to fill this gap. Specifically, we first establish signal models for both communication and localization, and, for the first time, derive a closed-form Cramér-Rao lower bound (CRLB) to characterize the localization performance. Subsequently, we exploit this CRLB to formulate two optimization problems, focusing on sensing-centric and communication-centric criteria, respectively. For the sensing-centric problem, we develop a globally optimal algorithm based on semidefinite relaxation (SDR) when each BS is equipped with more antennas than the total number of communication users. While for the communication-centric problem, we design a globally optimal algorithm for the single-BS case using bisection search. For the general case of both problems, we propose a unified successive convex approximation (SCA)-based algorithm, which is suboptimal yet efficient, and further extend it from single-target scenarios to more practical multi-target scenarios. Finally, simulation results demonstrate the effectiveness of our proposed algorithms, reveal the intrinsic performance trade-offs between communication and localization, and further show that deploying more TMTs is always preferable to deploying more BSs in networked ISAC systems.

Paper number 155:
Title: General formulation of an analytic, Lipschitz continuous control allocation for thrust-vectored controlled rigid-bodies
Authors: Frank Mukwege, Tam Willy Nguyen, Emanuele Garone
Abstract: This study introduces a systematic and scalable method for arbitrary rigid-bodies equipped with vectorized thrusters. Two novel solutions are proposed: a closed-form, Lipschitz continuous mapping that ensures smooth actuator orientation references, and a convex optimization formulation capable of handling practical actuator constraints such as thrust saturation and angular rate limits. Both methods leverage the null-space structure of the allocation mapping to perform singularity avoidance while generating sub-optimal yet practical solutions. The effectiveness and generality of the proposed framework are demonstrated through numerical simulations on a 3DOF marine vessel and a 6DOF aerial quadcopter.

Paper number 156:
Title: Continuous body 3-D reconstruction of limbless animals
Authors: Qiyuan Fu, Thomas W. Mitchel, Jin Seob Kim, Gregory S. Chirikjian, Chen Li
Abstract: Limbless animals such as snakes, limbless lizards, worms, eels, and lampreys move their slender, long bodies in three dimensions to traverse diverse environments. Accurately quantifying their continuous body's 3-D shape and motion is important for understanding body-environment interactions in complex terrain, but this is difficult to achieve (especially for local orientation and rotation). Here, we describe an interpolation method to quantify continuous body 3-D position and orientation. We simplify the body as an elastic rod and apply a backbone optimization method to interpolate continuous body shape between end constraints imposed by tracked markers. Despite over-simplifying the biomechanics, our method achieves a higher interpolation accuracy (~50% error) in both 3-D position and orientation compared with the widely-used cubic B-spline interpolation method. Beyond snakes traversing large obstacles as demonstrated, our method applies to other long, slender, limbless animals and continuum robots. We provide codes and demo files for easy application of our method.

Paper number 157:
Title: Model Predictive Inferential Control of Neural State-Space Models for Autonomous Vehicle Motion Planning
Authors: Iman Askari, Ali Vaziri, Xuemin Tu, Shen Zeng, Huazhen Fang
Abstract: Model predictive control (MPC) has proven useful in enabling safe and optimal motion planning for autonomous vehicles. In this paper, we investigate how to achieve MPC-based motion planning when a neural state-space model represents the vehicle dynamics. As the neural state-space model will lead to highly complex, nonlinear and nonconvex optimization landscapes, mainstream gradient-based MPC methods will be computationally too heavy to be a viable solution. In a departure, we propose the idea of model predictive inferential control (MPIC), which seeks to infer the best control decisions from the control objectives and constraints. Following the idea, we convert the MPC problem for motion planning into a Bayesian state estimation problem. Then, we develop a new particle filtering/smoothing approach to perform the estimation. This approach is implemented as banks of unscented Kalman filters/smoothers and offers high sampling efficiency, fast computation, and estimation accuracy. We evaluate the MPIC approach through a simulation study of autonomous driving in different scenarios, along with an exhaustive comparison with gradient-based MPC. The results show that the MPIC approach has considerable computational efficiency, regardless of complex neural network architectures, and shows the capability to solve large-scale MPC problems for neural state-space models.

Paper number 158:
Title: Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs
Authors: Haifeng Wen, Hong Xing, Osvaldo Simeone
Abstract: For modern artificial intelligence (AI) applications such as large language models (LLMs), the training paradigm has recently shifted to pre-training followed by fine-tuning. Furthermore, owing to dwindling open repositories of data and thanks to efforts to democratize access to AI models, pre-training is expected to increasingly migrate from the current centralized deployments to federated learning (FL) implementations. Meta-learning provides a general framework in which pre-training and fine-tuning can be formalized. Meta-learning-based personalized FL (meta-pFL) moves beyond basic personalization by targeting generalization to new agents and tasks. This paper studies the generalization performance of meta-pFL for a wireless setting in which the agents participating in the pre-training phase, i.e., meta-learning, are connected via a shared wireless channel to the server. Adopting over-the-air computing, we study the trade-off between generalization to new agents and tasks, on the one hand, and convergence, on the other hand. The trade-off arises from the fact that channel impairments may enhance generalization, while degrading convergence. Extensive numerical results validate the theory.

Paper number 159:
Title: AI-powered skin spectral imaging enables instant sepsis diagnosis and outcome prediction in critically ill patients
Authors: Silvia Seidlitz, Katharina Hölzl, Ayca von Garrel, Jan Sellner, Stephan Katzenschlager, Tobias Hölle, Dania Fischer, Maik von der Forst, Felix C.F. Schmitt, Alexander Studier-Fischer, Markus A. Weigand, Lena Maier-Hein, Maximilian Dietrich
Abstract: With sepsis remaining a leading cause of mortality, early identification of patients with sepsis and those at high risk of death is a challenge of high socioeconomic importance. Given the potential of hyperspectral imaging (HSI) to monitor microcirculatory alterations, we propose a deep learning approach to automated sepsis diagnosis and mortality prediction using a single HSI cube acquired within seconds. In a prospective observational study, we collected HSI data from the palms and fingers of more than 480 intensive care unit patients. Neural networks applied to HSI measurements predicted sepsis and mortality with areas under the receiver operating characteristic curve (AUROCs) of 0.80 and 0.72, respectively. Performance improved substantially with additional clinical data, reaching AUROCs of 0.94 for sepsis and 0.83 for mortality. We conclude that deep learning-based HSI analysis enables rapid and noninvasive prediction of sepsis and mortality, with a potential clinical value for enhancing diagnosis and treatment.

Paper number 160:
Title: Tokenizing Motion: A Generative Approach for Scene Dynamics Compression
Authors: Shanzhi Yin, Zihan Zhang, Bolin Chen, Shiqi Wang, Yan Ye
Abstract: This paper proposes a novel generative video compression framework that leverages motion pattern priors, derived from subtle dynamics in common scenes (e.g., swaying flowers or a boat drifting on water), rather than relying on video content priors (e.g., talking faces or human bodies). These compact motion priors enable a new approach to ultra-low bitrate communication while achieving high-quality reconstruction across diverse scene contents. At the encoder side, motion priors can be streamlined into compact representations via a dense-to-sparse transformation. At the decoder side, these priors facilitate the reconstruction of scene dynamics using an advanced flow-driven diffusion model. Experimental results illustrate that the proposed method can achieve superior rate-distortion-performance and outperform the state-of-the-art conventional-video codec Enhanced Compression Model (ECM) on-scene dynamics sequences. The project page can be found at-this https URL.

Paper number 161:
Title: Modeling nonuniform energy decay through the modal decomposition of acoustic radiance transfer (MoD-ART)
Authors: Matteo Scerbo, Sebastian J. Schlecht, Randall Ali, Lauri Savioja, Enzo De Sena
Abstract: Modeling late reverberation in real-time interactive applications is a challenging task when multiple sound sources and listeners are present in the same environment. This is especially problematic when the environment is geometrically complex and/or features uneven energy absorption (e.g. coupled volumes), because in such cases the late reverberation is dependent on the sound sources' and listeners' positions, and therefore must be adapted to their movements in real time. We present a novel approach to the task, named modal decomposition of acoustic radiance transfer (MoD-ART), which can handle highly complex scenarios with efficiency. The approach is based on the geometrical acoustics method of acoustic radiance transfer, from which we extract a set of energy decay modes and their positional relationships with sources and listeners. In this paper, we describe the physical and mathematical significance of MoD-ART, highlighting its advantages and applicability to different scenarios. Through an analysis of the method's computational complexity, we show that it compares very favorably with ray-tracing. We also present simulation results showing that MoD-ART can capture multiple decay slopes and flutter echoes.

Paper number 162:
Title: The IBEX Imaging Knowledge-Base: A Community Resource Enabling Adoption and Development of Immunofluoresence Imaging Methods
Authors: Ziv Yaniv (1), Ifeanyichukwu U. Anidi (2), Leanne Arakkal (3), Armando J. Arroyo-Mejías (3), Rebecca T. Beuschel (3), Katy Börner (4), Colin J. Chu (5), Beatrice Clark (3), Menna R. Clatworthy (6), Jake Colautti (7), Fabian Coscia (8), Joshua Croteau (9), Saven Denha (7), Rose Dever (10), Walderez O. Dutra (11), Sonja Fritzsche (8 and 35), Spencer Fullam (12), Michael Y. Gerner (13), Anita Gola (14), Kenneth J. Gollob (15), Jonathan M. Hernandez (16), Jyh Liang Hor (3), Hiroshi Ichise (3), Zhixin Jing (3), Danny Jonigk (17 and 18), Evelyn Kandov (3), Wolfgang Kastenmüller (19), Joshua F.E. Koenig (7), Aanandita Kothurkar (5), Rosa K. Kortekaas (20), Alexandra Y. Kreins (21), Ian T. Lamborn (3), Yuri Lin (16), Katia Luciano Pereira Morais (15), Aleksandra Lunich (2), Jean C.S. Luz (22), Ryan B. MacDonald (5), Chen Makranz (23), Vivien I. Maltez (24), John E. McDonough (20), Ryan V. Moriarty (25), Juan M. Ocampo-Godinez (21 and 26), Vitoria M. Olyntho (7), Annette Oxenius (33), Kartika Padhan (3 and 27), Kirsten Remmert (16), Nathan Richoz (6), Edward C. Schrom (3), Wanjing Shang (3), Lihong Shi (28), Rochelle M. Shih (3), Emily Speranza (29), Salome Stierli (30), Sarah A. Teichmann (31), Tibor Z. Veres (3), Megan Vierhout (7 and 20), Brianna T. Wachter (32), Adam K. Wade-Vallance (3), Margaret Williams (2), Nathan Zangger (33), Ronald N. Germain (3 and 27), Andrea J. Radtke (3 and 27 and 34) ((1) Bioinformatics and Computational Bioscience Branch, National Institute of Allergy and Infectious Diseases, National Institutes of Health, Bethesda, MD, USA, (2) Critical Care Medicine and Pulmonary Branch, National Heart, Lung and Blood Institute, National Institutes of Health, Bethesda, MD, USA, (3) Lymphocyte Biology Section, Laboratory of Immune System Biology, NIAID, NIH, Bethesda, MD, USA, (4) Department of Intelligent Systems Engineering, Indiana University, Bloomington, IN, USA, (5) UCL Institute of Ophthalmology and NIHR Moorfields Biomedical Research Centre, London, UK, (6) Cambridge Institute for Therapeutic Immunology and Infectious Diseases, University of Cambridge Department of Medicine, Molecular Immunity Unit, Laboratory of Molecular Biology, Cambridge, UK, (7) McMaster Immunology Research Centre, Schroeder Allergy and Immunology Research Institute, Department of Medicine, Faculty of Health Sciences, McMaster University, Hamilton, ON, Canada, (8) Max-Delbrueck-Center for Molecular Medicine in the Helmholtz Association (MDC), Spatial Proteomics Group, Berlin, Germany, (9) Department of Business Development, BioLegend Inc., San Diego, CA, USA, (10) Functional Immunogenomics Unit, National Institute of Arthritis and Musculoskeletal and Skin Diseases, National Institutes of Health, Bethesda, MD, USA, (11) Laboratory of Cell-Cell Interactions, Department of Morphology, Institute of Biological Sciences, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil, (12) Division of Rheumatology, Rush University Medical Center, Chicago, IL, USA, (13) Department of Immunology, University of Washington School of Medicine, Seattle, WA, USA, (14) Robin Chemers Neustein Laboratory of Mammalian Cell Biology and Development, The Rockefeller University, New York, NY, USA, (15) Center for Research in Immuno-oncology (CRIO), Hospital Israelita Albert Einstein, Sao Paulo, SP, Brazil, (16) Surgical Oncology Program, National Cancer Institute, National Institutes of Health, Bethesda, MD, USA, (17) Institute of Pathology, Aachen Medical University, RWTH Aachen, Aachen, Germany, (18) German Center for Lung Research (DZL), Biomedical Research in Endstage and Obstructive Lung Disease (BREATH), Hannover, Hannover, Germany, (19) Würzburg Institute of Systems Immunology, Max Planck Research Group at the Julius-Maximilians-Universität Würzburg, Würzburg, Germany, (20) Department of Medicine, McMaster University, Firestone Institute for Respiratory Health, St Joseph's Healthcare, Hamilton, ON, Canada, (21) Infection Immunity and Inflammation Research and Teaching Department, University College London Great Ormond Street Institute of Child Health, London, UK, (22) Viral Vector Laboratory, Cancer Institute of São Paulo, University of São Paulo, SP, Brazil, (23) Neuro-Oncology Branch, National Cancer Institute, National Institutes of Health, Bethesda, MD, USA, (24) Division of Allergy, Immunology and Rheumatology, Department of Pediatrics, University of California San Diego, La Jolla, CA, USA, (25) Department of Cellular and Developmental Biology, Northwestern University, Chicago, IL, USA, (26) Laboratorio de Bioingeniería de Tejidos, Departamento de Estudios de Posgrado e Investigación, Universidad Nacional Autónoma de México, Mexico City, Mexico, (27) Center for Advanced Tissue Imaging Laboratory of Immune System Biology, NIAID, NIH, Bethesda, MD, USA, (28) Laboratory of Immune System Biology, National Institute of Allergy and Infectious Diseases, National Institutes of Health, Bethesda, MD, USA, (29) Florida Research and Innovation Center, Cleveland Clinic Lerner Research Institute, Port Saint Lucie, FL, USA, (30) Institute of Anatomy, University of Zurich, Zurich, Switzerland, (31) Cambridge Stem Cell Institute, Jeffrey Cheah Biomedical Centre, Puddicombe Way, Cambridge Biomedical Campus, Cambridge, UK, (32) Laboratory of Clinical Immunology and Microbiology, National Institute of Allergy and Infectious Diseases, National Institutes of Health, Bethesda, MD, USA, (33) Institute of Microbiology, ETH Zurich, Zurich, Switzerland (34) Leica Microsystems, Wetzlar, Germany (35) Humboldt-Universitat zu Berlin, Institute of Biology, Berlin, Germany)
Abstract: The iterative bleaching extends multiplexity (IBEX) Knowledge-Base is a central portal for researchers adopting IBEX and related 2D and 3D immunofluorescence imaging methods. The design of the Knowledge-Base is modeled after efforts in the open-source software community and includes three facets: a development platform (GitHub), static website, and service for data archiving. The Knowledge-Base facilitates the practice of open science throughout the research life cycle by providing validation data for recommended and non-recommended reagents, such as primary and secondary antibodies. In addition to reporting negative data, the Knowledge-Base empowers method adoption and evolution by providing a venue for sharing protocols, videos, datasets, software, and publications. A dedicated discussion forum fosters a sense of community among researchers while addressing questions not covered in published manuscripts. Together, scientists from around the world are advancing scientific discovery at a faster pace, reducing wasted time and effort, and instilling greater confidence in the resulting data.

Paper number 163:
Title: Manipulation of Elasto-Flexible Cables with Single or Multiple UAVs
Authors: Chiara Gabellieri, Lars Teeuwen, Yaolei Shen, Antonio Franchi
Abstract: This work considers a large class of systems composed of multiple quadrotors manipulating deformable and extensible cables. The cable is described via a discretized representation, which decomposes it into linear springs interconnected through lumped-mass passive spherical joints. Sets of flat outputs are found for the systems. Numerical simulations support the findings by showing cable manipulation relying on flatness-based trajectories. Eventually, we present an experimental validation of the effectiveness of the proposed discretized cable model for a two-robot example. Moreover, a closed-loop controller based on the identified model and using cable-output feedback is experimentally tested.

Paper number 164:
Title: Joint Source-Environment Adaptation of Data-Driven Underwater Acoustic Source Ranging Based on Model Uncertainty
Authors: Dariush Kari, Hari Vishnu, Andrew C. Singer
Abstract: Adapting pre-trained deep learning models to new and unknown environments remains a major challenge in underwater acoustic localization. We show that although the performance of pre-trained models suffers from mismatch between the training and test data, they generally exhibit a higher uncertainty in environments where there is more mismatch. Additionally, in the presence of environmental mismatch, spurious peaks can appear in the output of classification-based localization approaches, which inspires us to define and use a method to quantify the "implied uncertainty" based on the number of model output peaks. Leveraging this notion of implied uncertainty, we partition the test samples into sets with more certain and less certain samples, and implement a method to adapt the model to new environments by using the certain samples to improve the labeling for uncertain samples, which helps to adapt the model. Thus, using this efficient method for model uncertainty quantification, we showcase an innovative approach to adapt a pre-trained model to unseen underwater environments at test time. This eliminates the need for labeled data from the target environment or the original training data. This adaptation is enhanced by integrating an independent estimate based on the received signal energy. We validate the approach extensively using real experimental data, as well as synthetic data consisting of model-generated signals with real ocean noise. The results demonstrate significant improvements in model prediction accuracy, underscoring the potential of the method to enhance underwater acoustic localization in diverse, noisy, and unknown environments.

Paper number 165:
Title: Data Standards in Audiology: A Mixed-Methods Exploration of Community Perspectives and Implementation Considerations
Authors: Charlotte Vercammen, Antje Heinrich, Christophe Lesimple, Alessia Paglialonga, Jan-Willem A. Wasmann, Mareike Buhl
Abstract: Objective: This study addresses conceptual issues around data standardisation in audiology, and outlines steps toward achieving it. It reports a survey of the computational audiology community on their current understanding, needs, and preferences concerning data standards. Based on survey findings and a panel discussion, recommendations are made concerning moving forward with standardisation in audiology. Design: Mixed-methods: 1) review of existing standardisation efforts; 2) a survey of the computational audiology community; 3) expert panel discussion in a dedicated session at the 2024 Virtual Conference of Computational Audiology. Sample: Survey: 82 members of the global community; Panel discussion: five experts. Results: A prerequisite for any global audiology database are agreed data standards. Although many are familiar with the general idea, few know of existing initiatives, or have actively participated in them. Ninety percent of respondents expressed willingness to follow or contribute to standardisation efforts. The panel discussed relevant initiatives (e.g. OMOP, openEHR, NOAH) and explored both challenges (around harmonisation) and opportunities (alignment with other medical fields and conversion among approaches). Conclusions: Combining conceptual discussion with stakeholder views, the study offers guidance for implementing interoperable data standards in audiology. It highlights community support, key issues to address, and suggests paths for future work.

Paper number 166:
Title: Lightweight and Interpretable Transformer via Mixed Graph Algorithm Unrolling for Traffic Forecast
Authors: Ji Qi, Tam Thuc Do, Mingxiao Liu, Zhuoshi Pan, Yuzhe Li, Gene Cheung, H. Vicky Zhao
Abstract: Unlike conventional "black-box" transformers with classical self-attention mechanism, we build a lightweight and interpretable transformer-like neural net by unrolling a mixed-graph-based optimization algorithm to forecast traffic with spatial and temporal dimensions. We construct two graphs: an undirected graph $\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\mathcal{G}^d$ capturing sequential relationships over time. We predict future samples of signal $\mathbf{x}$, assuming it is "smooth" with respect to both $\mathcal{G}^u$ and $\mathcal{G}^d$, where we design new $\ell_2$ and $\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We design an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We insert graph learning modules for $\mathcal{G}^u$ and $\mathcal{G}^d$ that play the role of self-attention. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically. Our code is available in this https URL .

Paper number 167:
Title: MGE-LDM: Joint Latent Diffusion for Simultaneous Music Generation and Source Extraction
Authors: Yunkee Chae, Kyogu Lee
Abstract: We present MGE-LDM, a unified latent diffusion framework for simultaneous music generation, source imputation, and query-driven source separation. Unlike prior approaches constrained to fixed instrument classes, MGE-LDM learns a joint distribution over full mixtures, submixtures, and individual stems within a single compact latent diffusion model. At inference, MGE-LDM enables (1) complete mixture generation, (2) partial generation (i.e., source imputation), and (3) text-conditioned extraction of arbitrary sources. By formulating both separation and imputation as conditional inpainting tasks in the latent space, our approach supports flexible, class-agnostic manipulation of arbitrary instrument sources. Notably, MGE-LDM can be trained jointly across heterogeneous multi-track datasets (e.g., Slakh2100, MUSDB18, MoisesDB) without relying on predefined instrument categories. Audio samples are available at our project page: this https URL.

Paper number 168:
Title: $\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time
Authors: Sarthak Kumar Maharana, Saksham Singh Kushwaha, Baoming Zhang, Adrian Rodriguez, Songtao Wei, Yapeng Tian, Yunhui Guo
Abstract: While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur $\textit{simultaneously}$ in both audio and visual modalities, we introduce $\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the test-time robustness of audio-visual recognition models. $\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets, $\texttt{AUDIOSET-2C}$, $\texttt{VGGSOUND-2C}$, $\texttt{KINETICS-2C}$, and $\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual corruptions that are $\textit{co-occurring}$ and $\textit{correlated}$. Through extensive evaluations, we observe that state-of-the-art supervised and self-supervised audio-visual models exhibit declining robustness as corruption severity increases. Furthermore, online test-time adaptation (TTA) methods, on $\texttt{VGGSOUND-2C}$ and $\texttt{KINETICS-2C}$, offer minimal improvements in performance under bimodal corruptions. We further propose $\texttt{AV2C}$, a simple TTA approach enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which achieves improvements on $\texttt{VGGSOUND-2C}$. We hope that $\texttt{AVROBUSTBENCH}$ will steer the development of more effective and robust audio-visual TTA approaches. Our code is available $\href{this https URL}{here}$.

Paper number 169:
Title: GRAM: Spatial general-purpose audio representation models for real-world applications
Authors: Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden
Abstract: Although audio foundations models have seen great progress on a wide variety of tasks, their application in real-world acoustic environments with reverberation and noise has been less successful. Moreover, as audio foundation models are typically trained on dry, single-channel audio clips, the inherent spatial nature of real-world sound scenes is overlooked and tasks involving sound localization ruled out. To address these limitations, we propose GRAM: a General-purpose Real-world Audio Model utilizing a multi-channel masked auto-encoder approach to efficiently learn spatial audio representations from high-quality simulated real-world scenes. To evaluate the performance of GRAM and other audio foundation models in real-world sound scenes, we release Nat-HEAR: A naturalistic version of the HEAR benchmark suite comprising a simulated real-world version, as well as two new sound localization tasks. We show that the performance of GRAM surpasses all state-of-the-art self-supervised audio foundation models and speech models on both HEAR and Nat-HEAR, while using only a fraction of the training data. GRAM also showcases state-of-the-art localization performance, surpassing even supervised sound localization approaches, and can be flexibly applied either to a two-channel, binaural sound format or a four-channel, Ambisonics format. Validating GRAM's performance on real-world sound recordings demonstrates robust transfer to real-world scenes. Taken together, GRAM presents a significant advancement towards robust, spatial audio foundation models for real-world applications.

Paper number 170:
Title: A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory
Authors: Liubing Hu, Pu Wang, Guangwei Gao, Chunyan Wang, Zhuoran Zheng
Abstract: This paper introduces a novel partial differential equation (PDE) framework for single-image dehazing. We embed the atmospheric scattering model into a PDE featuring edge-preserving diffusion and a nonlocal operator to maintain both local details and global structures. A key innovation is an adaptive regularization mechanism guided by the dark channel prior, which adjusts smoothing strength based on haze density. The framework's mathematical well-posedness is rigorously established by proving the existence and uniqueness of its weak solution in $H_0^1(\Omega)$. An efficient, GPU-accelerated fixed-point solver is used for implementation. Experiments confirm our method achieves effective haze removal while preserving high image fidelity, offering a principled alternative to purely data-driven techniques.

Paper number 171:
Title: Optimal Voltage Control Using Online Exponential Barrier Method
Authors: Peng Zhang, Baosen Zhang
Abstract: This paper address the optimal voltage control problem of distribution systems with high penetration of inverter-based renewable energy resources, under inaccurate model information. We propose the online exponential barrier method that explicitly leverages the online feedback from grids to enhance the robustness to model inaccuracy and incorporates the voltage constraints to maintain the safety requirements. We provide analytical results on the optimal barrier parameter selection and sufficient conditions for the safety guarantee of converged voltages. We also establish theoretical results on the exponential convergence rate with proper step-size. The effectiveness of the proposed framework is validated on a 56-bus radial network, where we significantly improve the robustness against model inaccuracy compared to existing methods.

Paper number 172:
Title: TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity
Authors: Yuzhuo Chen, Zehua Ma, Han Fang, Weiming Zhang, Nenghai Yu
Abstract: AI-generated content (AIGC) enables efficient visual creation but raises copyright and authenticity risks. As a common technique for integrity verification and source tracing, digital image watermarking is regarded as a potential solution to above issues. However, the widespread adoption and advancing capabilities of generative image editing tools have amplified malicious tampering risks, while simultaneously posing new challenges to passive tampering detection and watermark robustness. To address these challenges, this paper proposes a Tamper-Aware Generative image WaterMarking method named TAG-WM. The proposed method comprises four key modules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright and localization watermarks into the latent space while preserving generative quality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a dense variation region detector (DVRD) leveraging diffusion inversion sensitivity to identify tampered areas via statistical deviation analysis, and the tamper-aware decoding (TAD) guided by localization results. The experimental results demonstrate that TAG-WM achieves state-of-the-art performance in both tampering robustness and localization capability even under distortion, while preserving lossless generation quality and maintaining a watermark capacity of 256 bits. The code is available at: this https URL.

Paper number 173:
Title: A Novel Hybrid Grey Wolf Differential Evolution Algorithm
Authors: Ioannis D. Bougas, Pavlos Doanis, Maria S. Papadopoulou, Achilles D. Boursianis, Sotirios P. Sotiroudis, Zaharias D. Zaharis, George Koudouridis, Panagiotis Sarigiannidis, Mohammad Abdul Matint, George Karagiannidis, Sotirios K. Goudos
Abstract: Grey wolf optimizer (GWO) is a nature-inspired stochastic meta-heuristic of the swarm intelligence field that mimics the hunting behavior of grey wolves. Differential evolution (DE) is a popular stochastic algorithm of the evolutionary computation field that is well suited for global optimization. In this part, we introduce a new algorithm based on the hybridization of GWO and two DE variants, namely the GWO-DE algorithm. We evaluate the new algorithm by applying various numerical benchmark functions. The numerical results of the comparative study are quite satisfactory in terms of performance and solution quality.

Paper number 174:
Title: RoHOI: Robustness Benchmark for Human-Object Interaction Detection
Authors: Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Danda Pani Paudel, Luc Van Gool, Rainer Stiefelhagen
Abstract: Human-Object Interaction (HOI) detection is crucial for robot-human assistance, enabling context-aware support. However, models trained on clean datasets degrade in real-world conditions due to unforeseen corruptions, leading to inaccurate predictions. To address this, we introduce the first robustness benchmark for HOI detection, evaluating model resilience under diverse challenges. Despite advances, current models struggle with environmental variability, occlusions, and noise. Our benchmark, RoHOI, includes 20 corruption types based on the HICO-DET and V-COCO datasets and a new robustness-focused metric. We systematically analyze existing models in the HOI field, revealing significant performance drops under corruptions. To improve robustness, we propose a Semantic-Aware Masking-based Progressive Learning (SAMPL) strategy to guide the model to be optimized based on holistic and partial cues, thus dynamically adjusting the model's optimization to enhance robust feature learning. Extensive experiments show that our approach outperforms state-of-the-art methods, setting a new standard for robust HOI detection. Benchmarks, datasets, and code are available at this https URL.

Paper number 175:
Title: Multi-Functional RIS-Enabled in SAGIN for IoT: A Hybrid Deep Reinforcement Learning Approach with Compressed Twin-Models
Authors: Li-Hsiang Shen, Jyun-Jhe Huang
Abstract: A space-air-ground integrated network (SAGIN) for Internet of Things (IoT) network architecture is investigated, empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS) capable of simultaneously reflecting, amplifying, and harvesting wireless energy. The MF-RIS plays a pivotal role in addressing the energy shortages of low-Earth orbit (LEO) satellites operating in the shadowed regions, while accounting for both communication and computing energy consumption across the SAGIN nodes. To maximize the long-term energy efficiency (EE) of IoT devices, we formulate a joint optimization problem over the MF-RIS parameters, including signal amplification, phase-shifts, energy harvesting ratio, and active element selection as well as the SAGIN parameters of beamforming vectors, high-altitude platform station (HAPS) deployment, IoT device association, and computing capability. The formulated problem is highly non-convex and non-linear and contains mixed discrete-continuous parameters. To tackle this, we conceive a compressed hybrid twin-model enhanced multi-agent deep reinforcement learning (CHIMERA) framework, which integrates semantic state-action compression and parametrized sharing under hybrid reinforcement learning to efficiently explore suitable complex actions. The simulation results have demonstrated that the proposed CHIMERA scheme substantially outperforms the conventional benchmarks, including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and no-RIS cases, as well as centralized and multi-agent deep reinforcement learning baselines in terms of the highest EE. Moreover, the proposed SAGIN-MF-RIS architecture in IoT network achieves superior EE performance due to its complementary coverage, offering notable advantages over either standalone satellite, aerial, or ground-only deployments.

Paper number 176:
Title: Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning
Authors: Zhiyuan Han, Beier Zhu, Yanlong Xu, Peipei Song, Xun Yang
Abstract: Despite their strong performance in multimodal emotion reasoning, existing Multimodal Large Language Models (MLLMs) often overlook the scenarios involving emotion conflicts, where emotional cues from different modalities are inconsistent. To fill this gap, we first introduce CA-MER, a new benchmark designed to examine MLLMs under realistic emotion conflicts. It consists of three subsets: video-aligned, audio-aligned, and consistent, where only one or all modalities reflect the true emotion. However, evaluations on our CA-MER reveal that current state-of-the-art emotion MLLMs systematically over-rely on audio signal during emotion conflicts, neglecting critical cues from visual modality. To mitigate this bias, we propose MoSEAR, a parameter-efficient framework that promotes balanced modality integration. MoSEAR consists of two modules: (1)MoSE, modality-specific experts with a regularized gating mechanism that reduces modality bias in the fine-tuning heads; and (2)AR, an attention reallocation mechanism that rebalances modality contributions in frozen backbones during inference. Our framework offers two key advantages: it mitigates emotion conflicts and improves performance on consistent samples-without incurring a trade-off between audio and visual modalities. Experiments on multiple benchmarks-including MER2023, EMER, DFEW, and our CA-MER-demonstrate that MoSEAR achieves state-of-the-art performance, particularly under modality conflict conditions.

Paper number 177:
Title: Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval
Authors: Junan Lin, Daizong Liu, Xianke Chen, Xiaoye Qu, Xun Yang, Jixiang Zhu, Sanyuan Zhang, Jianfeng Dong
Abstract: Video Moment Retrieval (VMR) aims to retrieve a specific moment semantically related to the given query. To tackle this task, most existing VMR methods solely focus on the visual and textual modalities while neglecting the complementary but important audio modality. Although a few recent works try to tackle the joint audio-vision-text reasoning, they treat all modalities equally and simply embed them without fine-grained interaction for moment retrieval. These designs are counter-practical as: Not all audios are helpful for video moment retrieval, and the audio of some videos may be complete noise or background sound that is meaningless to the moment determination. To this end, we propose a novel Importance-aware Multi-Granularity fusion model (IMG), which learns to dynamically and selectively aggregate the audio-vision-text contexts for VMR. Specifically, after integrating the textual guidance with vision and audio separately, we first design a pseudo-label-supervised audio importance predictor that predicts the importance score of the audio, and accordingly assigns weights to mitigate the interference caused by noisy audio. Then, we design a multi-granularity audio fusion module that adaptively fuses audio and visual modalities at local-, event-, and global-level, fully capturing their complementary contexts. We further propose a cross-modal knowledge distillation strategy to address the challenge of missing audio modality during inference. To evaluate our method, we further construct a new VMR dataset, i.e., Charades-AudioMatter, where audio-related samples are manually selected and re-organized from the original Charades-STA to validate the model's capability in utilizing audio modality. Extensive experiments validate the effectiveness of our method, achieving state-of-the-art with audio-video fusion in VMR methods. Our code is available at this https URL.

Paper number 178:
Title: Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow
Authors: Carlo Cena, Mauro Martini, Marcello Chiaberge
Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model Predictive Control (MPC) has emerged as a powerful strategy for these tasks, relying on accurate models of the system dynamics to optimize control actions over a prediction horizon. In scenarios where physics models are incomplete, difficult to derive, or computationally expensive, machine learning offers a flexible alternative by learning the system behavior directly from data. However, purely data-driven models often struggle with generalization and stability, especially when applied to inputs outside their training domain. To address these limitations, we investigate the benefits of incorporating Physics-Informed Neural Networks (PINNs) into the learning of spacecraft attitude dynamics, comparing their performance with that of purely data-driven approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network architecture with a self-attention mechanism, we trained several models on simulated data generated with the Basilisk simulator. Two training strategies were considered: a purely data-driven baseline and a physics-informed variant to improve robustness and stability. Our results demonstrate that the inclusion of physics-based information significantly enhances the performance in terms of the mean relative error of the best architectures found by 27.08%. These advantages are particularly evident when the learned models are integrated into an MPC framework, where PINN-based models consistently outperform their purely data-driven counterparts in terms of control accuracy and robustness, yielding improvements of up to 42.86% in performance stability error and increased robustness-to-noise.

Paper number 179:
Title: ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding
Authors: Andreas Zunker, Marvin Rübenacke, Stephan ten Brink
Abstract: Motivated by the need for channel codes with low-complexity soft-decision decoding algorithms, we consider the recursive Plotkin concatenation of optimal low-rate and high-rate codes based on simplex codes and their duals. These component codes come with low-complexity maximum likelihood (ML) decoding which, in turn, enables efficient successive cancellation (SC)-based decoding. As a result, the proposed optimally recursively concatenated simplex (ORCAS) codes achieve a performance that is at least as good as that of polar codes. For practical parameters, the proposed construction significantly outperforms polar codes in terms of block error rate by up to 0.5 dB while maintaining similar decoding complexity. Furthermore, the codes offer greater flexibility in codeword length than conventional polar codes.

Paper number 180:
Title: A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot
Authors: Murilo Vinicius da Silva, Matheus Hipolito Carvalho, Juliano Negri, Thiago Segreto, Gustavo J. G. Lahr, Ricardo V. Godoy, Marcelo Becker
Abstract: In hazardous and remote environments, robotic systems perform critical tasks demanding improved safety and efficiency. Among these, quadruped robots with manipulator arms offer mobility and versatility for complex operations. However, teleoperating quadruped robots is challenging due to the lack of integrated obstacle detection and intuitive control methods for the robotic arm, increasing collision risks in confined or dynamically changing workspaces. Teleoperation via joysticks or pads can be non-intuitive and demands a high level of expertise due to its complexity, culminating in a high cognitive load on the operator. To address this challenge, a teleoperation approach that directly maps human arm movements to the robotic manipulator offers a simpler and more accessible solution. This work proposes an intuitive remote control by leveraging a vision-based pose estimation pipeline that utilizes an external camera with a machine learning-based model to detect the operator's wrist position. The system maps these wrist movements into robotic arm commands to control the robot's arm in real-time. A trajectory planner ensures safe teleoperation by detecting and preventing collisions with both obstacles and the robotic arm itself. The system was validated on the real robot, demonstrating robust performance in real-time control. This teleoperation approach provides a cost-effective solution for industrial applications where safety, precision, and ease of use are paramount, ensuring reliable and intuitive robotic control in high-risk environments.

Paper number 181:
Title: Autonomous UAV Flight Navigation in Confined Spaces: A Reinforcement Learning Approach
Authors: Marco S. Tayar, Lucas K. de Oliveira, Felipe Andrade G. Tommaselli, Juliano D. Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker
Abstract: Autonomous UAV inspection of confined industrial infrastructure, such as ventilation ducts, demands robust navigation policies where collisions are unacceptable. While Deep Reinforcement Learning (DRL) offers a powerful paradigm for developing such policies, it presents a critical trade-off between on-policy and off-policy algorithms. Off-policy methods promise high sample efficiency, a vital trait for minimizing costly and unsafe real-world fine-tuning. In contrast, on-policy methods often exhibit greater training stability, which is essential for reliable convergence in hazard-dense environments. This paper directly investigates this trade-off by comparing a leading on-policy algorithm, Proximal Policy Optimization (PPO), against an off-policy counterpart, Soft Actor-Critic (SAC), for precision flight in procedurally generated ducts within a high-fidelity simulator. Our results show that PPO consistently learned a stable, collision-free policy that completed the entire course. In contrast, SAC failed to find a complete solution, converging to a suboptimal policy that navigated only the initial segments before failure. This work provides evidence that for high-precision, safety-critical navigation tasks, the reliable convergence of a well-established on-policy method can be more decisive than the nominal sample efficiency of an off-policy algorithm.

Paper number 182:
Title: Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation
Authors: Dilermando Almeida, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker
Abstract: This paper presents a deep learning framework designed to enhance the grasping capabilities of quadrupeds equipped with arms, with a focus on improving precision and adaptability. Our approach centers on a sim-to-real methodology that minimizes reliance on physical data collection. We developed a pipeline within the Genesis simulation environment to generate a synthetic dataset of grasp attempts on common objects. By simulating thousands of interactions from various perspectives, we created pixel-wise annotated grasp-quality maps to serve as the ground truth for our model. This dataset was used to train a custom CNN with a U-Net-like architecture that processes multi-modal input from an onboard RGB and depth cameras, including RGB images, depth maps, segmentation masks, and surface normal maps. The trained model outputs a grasp-quality heatmap to identify the optimal grasp point. We validated the complete framework on a four-legged robot. The system successfully executed a full loco-manipulation task: autonomously navigating to a target object, perceiving it with its sensors, predicting the optimal grasp pose using our model, and performing a precise grasp. This work proves that leveraging simulated training with advanced sensing offers a scalable and effective solution for object handling.

Paper number 183:
Title: PicoAudio2: Temporal Controllable Text-to-Audio Generation with Natural Language Description
Authors: Zihao Zheng, Zeyu Xie, Xuenan Xu, Wen Wu, Chao Zhang, Mengyue Wu
Abstract: While recent work in controllable text-to-audio (TTA) generation has achieved fine-grained control through timestamp conditioning, its scope remains limited by audio quality and input format. These models often suffer from poor audio quality in real datasets due to sole reliance on synthetic data. Moreover, some models are constrained to a closed vocabulary of sound events, preventing them from controlling audio generation for open-ended, free-text queries. This paper introduces PicoAudio2, a framework that advances temporal-controllable TTA by mitigating these data and architectural limitations. Specifically, we use a grounding model to annotate event timestamps of real audio-text datasets to curate temporally-strong real data, in addition to simulation data from existing works. The model is trained on the combination of real and simulation data. Moreover, we propose an enhanced architecture that integrates the fine-grained information from a timestamp matrix with coarse-grained free-text input. Experiments show that PicoAudio2 exhibits superior performance in terms of temporal controllability and audio quality.

Paper number 184:
Title: ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy
Authors: Alejandro D. Mousist
Abstract: This paper presents ASTREA, the first agentic system executed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations, with on-orbit operation aboard the International Space Station (ISS). Using thermal control as a representative use case, we integrate a resource-constrained Large Language Model (LLM) agent with a reinforcement learning controller in an asynchronous architecture tailored for space-qualified platforms. Ground experiments show that LLM-guided supervision improves thermal stability and reduces violations, confirming the feasibility of combining semantic reasoning with adaptive control under hardware constraints. On-orbit validation aboard the ISS initially faced challenges due to inference latency misaligned with the rapid thermal cycles of Low Earth Orbit (LEO) satellites. Synchronization with the orbit length successfully surpassed the baseline with reduced violations, extended episode durations, and improved CPU utilization. These findings demonstrate the potential for scalable agentic supervision architectures in future autonomous spacecraft.

Paper number 185:
Title: Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping
Authors: Jonas Buchli, Brendan Tracey, Tomislav Andric, Christopher Wipf, Yu Him Justin Chiu, Matthias Lochbrunner, Craig Donner, Rana X. Adhikari, Jan Harms, Iain Barr, Roland Hafner, Andrea Huber, Abbas Abdolmaleki, Charlie Beattie, Joseph Betzwieser, Serkan Cabi, Jonas Degrave, Yuzhu Dong, Leslie Fritz, Anchal Gupta, Oliver Groth, Sandy Huang, Tamara Norman, Hannah Openshaw, Jameson Rollins, Greg Thornton, George Van Den Driessche, Markus Wulfmeier, Pushmeet Kohli, Martin Riedmiller, LIGO Instrument Team
Abstract: Improved low-frequency sensitivity of gravitational wave observatories would unlock study of intermediate-mass black hole mergers, binary black hole eccentricity, and provide early warnings for multi-messenger observations of binary neutron star mergers. Today's mirror stabilization control injects harmful noise, constituting a major obstacle to sensitivity improvements. We eliminated this noise through Deep Loop Shaping, a reinforcement learning method using frequency domain rewards. We proved our methodology on the LIGO Livingston Observatory (LLO). Our controller reduced control noise in the 10--30Hz band by over 30x, and up to 100x in sub-bands surpassing the design goal motivated by the quantum limit. These results highlight the potential of Deep Loop Shaping to improve current and future GW observatories, and more broadly instrumentation and control systems.

Paper number 186:
Title: ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks
Authors: Bojan Derajić, Sebastian Bernhard, Wolfgang Hönig
Abstract: Control barrier functions (CBFs) have been demonstrated as an effective method for safety-critical control of autonomous systems. Although CBFs are simple to deploy, their design remains challenging, motivating the development of learning-based approaches. Yet, issues such as suboptimal safe sets, applicability in partially observable environments, and lack of rigorous safety guarantees persist. In this work, we propose observation-conditioned neural CBFs based on Hamilton-Jacobi (HJ) reachability analysis, which approximately recover the maximal safe sets. We exploit certain mathematical properties of the HJ value function, ensuring that the predicted safe set never intersects with the observed failure set. Moreover, we leverage a hypernetwork-based architecture that is particularly suitable for the design of observation-conditioned safety filters. The proposed method is examined both in simulation and hardware experiments for a ground robot and a quadcopter. The results show improved success rates and generalization to out-of-domain environments compared to the baselines.

Paper number 187:
Title: Discrete-Time Diffusion-Like Models for Speech Synthesis
Authors: Xiaozhou Tan, Minghui Zhao, Anton Ragni
Abstract: Diffusion models have attracted a lot of attention in recent years. These models view speech generation as a continuous-time process. For efficient training, this process is typically restricted to additive Gaussian noising, which is limiting. For inference, the time is typically discretized, leading to the mismatch between continuous training and discrete sampling conditions. Recently proposed discrete-time processes, on the other hand, usually do not have these limitations, may require substantially fewer inference steps, and are fully consistent between training/inference conditions. This paper explores some diffusion-like discrete-time processes and proposes some new variants. These include processes applying additive Gaussian noise, multiplicative Gaussian noise, blurring noise and a mixture of blurring and Gaussian noises. The experimental results suggest that discrete-time processes offer comparable subjective and objective speech quality to their widely popular continuous counterpart, with more efficient and consistent training and inference schemas.

Paper number 188:
Title: WavJEPA: Semantic learning unlocks robust audio foundation models for raw waveforms
Authors: Goksenin Yuksel, Pierre Guetschel, Michael Tangermann, Marcel van Gerven, Kiki van der Heijden
Abstract: Learning audio representations from raw waveforms overcomes key limitations of spectrogram-based audio representation learning, such as the long latency of spectrogram computation and the loss of phase information. Yet, while self-supervised speech representation learning from raw waveforms has been remarkably successful, these approaches have not achieved similar feats for general-purpose audio representation learning from waveforms. Here, we propose WavJEPA, a waveform-based version of the Joint-Embedding Predictive Architecture. WavJEPA leverages high-level semantic representation learning to tackle the shortcomings of representation learning at the speech unit or token level. We show that this approach substantially outperforms state-of-the-art time-domain audio foundation models across a wide variety of downstream benchmark tasks, while requiring considerably fewer computational resources. Additionally, to overcome the performance drop that time-domain models typically exhibit in noisy and reverberant real-world acoustic environments, we present WavJEPA-Nat. WavJEPA-Nat is a multi-channel extension of the WavJEPA architecture trained on simulated naturalistic scenes. We find that WavJEPA-Nat is highly robust to reverberation and noise. These results highlight the feasibility and computational efficiency of general-purpose audio representation learning from raw waveforms, showcasing the potential for low-latency, robust time-domain audio foundation models for real-world applications.

Paper number 189:
Title: Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network
Authors: Sara Strakosova, Petr Novak, Petr Kadera
Abstract: In a circular economy, products in their end-of-life phase should be either remanufactured or recycled. Both of these processes are crucial for sustainability and environmental conservation. However, manufacturers frequently do not support these processes enough in terms of not sharing relevant data about the products nor their (re-)manufacturing processes. This paper proposes to accompany each product with a digital twin technology, specifically the Product Digital Twin (PDT), which can carry information for facilitating and optimizing production and remanufacturing processes. This paper introduces a knowledge representation called Bi-Flow Product-Process-Resource Asset Network (Bi-PAN). Bi-PAN extends a well-proven Product-Process-Resource Asset Network (PAN) paradigm by integrating both assembly and disassembly workflows into a single information model. Such networks enable capturing relevant relationships across products, production resources, manufacturing processes, and specific production operations that have to be done in the manufacturing phase of a product. The proposed approach is demonstrated in a use-case of disassembling electric vehicle (EV) batteries. By utilizing PDTs with Bi-PAN knowledge models, challenges associated with disassembling of EV batteries can be solved flexibly and efficiently for various battery types, enhancing the sustainability of the EV battery life-cycle management.

Paper number 190:
Title: Detecting Malicious Pilot Contamination in Multiuser Massive MIMO Using Decision Trees
Authors: Pedro Ivo da Cruz, Dimitri Silva, Tito Spadini, Ricardo Suyama, Murilo Bellezoni Loiola
Abstract: Massive multiple-input multiple-output (MMIMO) is essential to modern wireless communication systems, like 5G and 6G, but it is vulnerable to active eavesdropping attacks. One type of such attack is the pilot contamination attack (PCA), where a malicious user copies pilot signals from an authentic user during uplink, intentionally interfering with the base station's (BS) channel estimation accuracy. In this work, we propose to use a Decision Tree (DT) algorithm for PCA detection at the BS in a multi-user system. We present a methodology to generate training data for the DT classifier and select the best DT according to their depth. Then, we simulate different scenarios that could be encountered in practice and compare the DT to a classical technique based on likelihood ratio testing (LRT) submitted to the same scenarios. The results revealed that a DT with only one level of depth is sufficient to outperform the LRT. The DT shows a good performance regarding the probability of detection in noisy scenarios and when the malicious user transmits with low power, in which case the LRT fails to detect the PCA. We also show that the reason for the good performance of the DT is its ability to compute a threshold that separates PCA data from non-PCA data better than the LRT's threshold. Moreover, the DT does not necessitate prior knowledge of noise power or assumptions regarding the signal power of malicious users, prerequisites typically essential for LRT and other hypothesis testing methodologies.

Paper number 191:
Title: Local MAP Sampling for Diffusion Models
Authors: Shaorong Zhang, Rob Brekelmans, Greg Ver Steeg
Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the goal of inverse problem solving is not to cover the posterior but to recover the most accurate reconstruction, where optimization-based diffusion solvers often excel despite lacking a clear probabilistic foundation. We introduce Local MAP Sampling (LMAPS), a new inference framework that iteratively solving local MAP subproblems along the diffusion trajectory. This perspective clarifies their connection to global MAP estimation and DPS, offering a unified probabilistic interpretation for optimization-based methods. Building on this foundation, we develop practical algorithms with a probabilistically interpretable covariance approximation, a reformulated objective for stability and interpretability, and a gradient approximation for non-differentiable operators. Across a broad set of image restoration and scientific tasks, LMAPS achieves state-of-the-art performance, including $\geq 2$ dB gains on motion deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on inverse scattering benchmarks.
    