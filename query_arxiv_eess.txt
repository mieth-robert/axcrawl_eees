
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy
Authors: Cunmin Zhao, Ziyuan Luo, Guoye Guan, Zelin Li, Yiming Ma, Zhongying Zhao, Renjie Wan
Abstract: 4D live fluorescence microscopy is often compromised by prolonged high intensity illumination which induces photobleaching and phototoxic effects that generate photo-induced artifacts and severely impair image continuity and detail recovery. To address this challenge, we propose the CellINR framework, a case-specific optimization approach based on implicit neural representation. The method employs blind convolution and structure amplification strategies to map 3D spatial coordinates into the high frequency domain, enabling precise modeling and high-accuracy reconstruction of cellular structures while effectively distinguishing true signals from artifacts. Experimental results demonstrate that CellINR significantly outperforms existing techniques in artifact removal and restoration of structural continuity, and for the first time, a paired 4D live cell imaging dataset is provided for evaluating reconstruction performance, thereby offering a solid foundation for subsequent quantitative analyses and biological research. The code and dataset will be public.

Paper number 2:
Title: 2D Ultrasound Elasticity Imaging of Abdominal Aortic Aneurysms Using Deep Neural Networks
Authors: Utsav Ratna Tuladhar, Richard Simon, Doran Mix, Michael Richards
Abstract: Abdominal aortic aneurysms (AAA) pose a significant clinical risk due to their potential for rupture, which is often asymptomatic but can be fatal. Although maximum diameter is commonly used for risk assessment, diameter alone is insufficient as it does not capture the properties of the underlying material of the vessel wall, which play a critical role in determining the risk of rupture. To overcome this limitation, we propose a deep learning-based framework for elasticity imaging of AAAs with 2D ultrasound. Leveraging finite element simulations, we generate a diverse dataset of displacement fields with their corresponding modulus distributions. We train a model with U-Net architecture and normalized mean squared error (NMSE) to infer the spatial modulus distribution from the axial and lateral components of the displacement fields. This model is evaluated across three experimental domains: digital phantom data from 3D COMSOL simulations, physical phantom experiments using biomechanically distinct vessel models, and clinical ultrasound exams from AAA patients. Our simulated results demonstrate that the proposed deep learning model is able to reconstruct modulus distributions, achieving an NMSE score of 0.73\%. Similarly, in phantom data, the predicted modular ratio closely matches the expected values, affirming the model's ability to generalize to phantom data. We compare our approach with an iterative method which shows comparable performance but higher computation time. In contrast, the deep learning method can provide quick and effective estimates of tissue stiffness from ultrasound images, which could help assess the risk of AAA rupture without invasive procedures.

Paper number 3:
Title: MedVQA-TREE: A Multimodal Reasoning and Retrieval Framework for Sarcopenia Prediction
Authors: Pardis Moradbeiki, Nasser Ghadiri, Sayed Jalal Zahabi, Uffe Kock Wiil, Kristoffer Kittelmann Brockhattingen, Ali Ebrahimi
Abstract: Accurate sarcopenia diagnosis via ultrasound remains challenging due to subtle imaging cues, limited labeled data, and the absence of clinical context in most models. We propose MedVQA-TREE, a multimodal framework that integrates a hierarchical image interpretation module, a gated feature-level fusion mechanism, and a novel multi-hop, multi-query retrieval strategy. The vision module includes anatomical classification, region segmentation, and graph-based spatial reasoning to capture coarse, mid-level, and fine-grained structures. A gated fusion mechanism selectively integrates visual features with textual queries, while clinical knowledge is retrieved through a UMLS-guided pipeline accessing PubMed and a sarcopenia-specific external knowledge base. MedVQA-TREE was trained and evaluated on two public MedVQA datasets (VQA-RAD and PathVQA) and a custom sarcopenia ultrasound dataset. The model achieved up to 99% diagnostic accuracy and outperformed previous state-of-the-art methods by over 10%. These results underscore the benefit of combining structured visual understanding with guided knowledge retrieval for effective AI-assisted diagnosis in sarcopenia.

Paper number 4:
Title: AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays
Authors: Xueyang Li, Mingze Jiang, Gelei Xu, Jun Xia, Mengzhao Jia, Danny Chen, Yiyu Shi
Abstract: Agentic AI is advancing rapidly, yet truly autonomous medical-imaging triage, where a system decides when to stop, escalate, or defer under real constraints, remains relatively underexplored. To address this gap, we introduce AT-CXR, an uncertainty-aware agent for chest X-rays. The system estimates per-case confidence and distributional fit, then follows a stepwise policy to issue an automated decision or abstain with a suggested label for human intervention. We evaluate two router designs that share the same inputs and actions: a deterministic rule-based router and an LLM-decided router. Across five-fold evaluation on a balanced subset of NIH ChestX-ray14 dataset, both variants outperform strong zero-shot vision-language models and state-of-the-art supervised classifiers, achieving higher full-coverage accuracy and superior selective-prediction performance, evidenced by a lower area under the risk-coverage curve (AURC) and a lower error rate at high coverage, while operating with lower latency that meets practical clinical constraints. The two routers provide complementary operating points, enabling deployments to prioritize maximal throughput or maximal accuracy. Our code is available at this https URL.

Paper number 5:
Title: Privacy-Preserving Distributed Control for a Networked Battery Energy Storage System
Authors: Mihitha Maithripala, Zongli Lin
Abstract: The increasing deployment of distributed Battery Energy Storage Systems (BESSs) in modern power grids necessitates effective coordination strategies to ensure state-of-charge (SoC) balancing and accurate power delivery. While distributed control frameworks offer scalability and resilience, they also raise significant privacy concerns due to the need for inter-agent information exchange. This paper presents a novel privacy-preserving distributed control algorithm for SoC balancing in a networked BESS. The proposed framework includes distributed power allocation law that is designed based on two privacy-preserving distributed estimators, one for the average unit state and the other for the average desired power. The average unit state estimator is designed via the state decomposition method without disclosing sensitive internal states. The proposed power allocation law based on these estimators ensures asymptotic SoC balancing and global power delivery while safeguarding agent privacy from external eavesdroppers. The effectiveness and privacy-preserving properties of the proposed control strategy are demonstrated through simulation results.

Paper number 6:
Title: Set-membership identification of continuous-time MIMO systems via Tustin discretization
Authors: Vito Cerone, Sophie M. Fosson, Simone Pirrera, Diego Regruto
Abstract: In this paper, we deal with the identification of continuous-time systems from sampled data corrupted by unknown but bounded errors. A significant challenge in continuous-time identification is the estimation of the input and output data derivatives. In this paper, we propose a novel method based on set-membership techniques and Tustin discretization, which overcomes the derivative measurement problem and the presence of bounded errors affecting all the measured signals. First, we derive the proposed method and prove that it becomes an affordable polynomial optimization problem. Then, we present some numerical results based on simulation and experimental data to explore the effectiveness of the proposed method.

Paper number 7:
Title: Towards Reliable Neural Optimizers: Permutation-Equivariant Neural Approximation in Dynamic Data Driven Applications Systems
Authors: Meiyi Li, Javad Mohammadi
Abstract: Dynamic Data Driven Applications Systems (DDDAS) motivate the development of optimization approaches capable of adapting to streaming, heterogeneous, and asynchronous data from sensor networks. Many established optimization solvers, such as branch-and-bound, gradient descent, and Newton-Raphson methods, rely on iterative algorithms whose step-by-step convergence makes them too slow for real-time, multi-sensor environments. In our recent work, we introduced LOOP-PE (Learning to Optimize the Optimization Process, Permutation Equivariance version), a feed-forward neural approximation model with an integrated feasibility recovery function. LOOP-PE processes inputs from a variable number of sensors in arbitrary order, making it robust to sensor dropout, communication delays, and system scaling. Its permutation-equivariant architecture ensures that reordering the input data reorders the corresponding dispatch decisions consistently, without retraining or pre-alignment. Feasibility is enforced via a generalized gauge map, guaranteeing that outputs satisfy physical and operational constraints. We illustrate the approach in a DDDAS-inspired case study of a Virtual Power Plant (VPP) managing multiple distributed generation agents (DERs) to maximize renewable utilization while respecting system limits. Results show that LOOP-PE produces near-optimal, feasible, and highly adaptable decisions under dynamic, unordered, and distributed sensing conditions, significantly outperforming iterative algorithm based solvers in both speed and flexibility. Here, we extend our earlier work by providing additional analysis and explanation of LOOP-PE design and operation, with particular emphasis on its feasibility guarantee and permutation equivariance feature.

Paper number 8:
Title: Climate-Resilient Ports and Waterborne Transport Systems: Current Status and Future Prospects
Authors: Nadia Pourmohammad-Zia, Mark van Koningsveld
Abstract: The increasing challenges posed by climate change necessitate a comprehensive examination of the resilience of waterborne transport systems. This paper explores the nexus of climate resilience, and waterborne transport, addressing the challenges faced by ports and their connecting waterborne transport systems. It provides an in-depth analysis of the current status of climate-resilient infrastructure and operations while emphasizing the transformative potential of emerging technologies. Through a systematic review, the paper identifies critical gaps and opportunities. Research predominantly emphasizes port infrastructure over supply chain resilience, neglecting the interconnected vulnerabilities of maritime networks. There is limited focus on specific climate-induced disruptions, such as drought and compounded events, which complicate resilience planning. Methodologically, risk assessments and case studies dominate the field, while advanced technologies such as digital twins, artificial intelligence, and satellite monitoring remain underutilized. Geographic disparities in research output and a tendency toward short- to medium-term planning further constrain global and long-term resilience efforts. To address these gaps, the study advocates for systems-based approaches that integrate infrastructure, operations, and supply chains. It highlights collaborative frameworks and advanced tools, including digital twins, machine learning, and participatory modeling, as crucial for enabling predictive and adaptive risk management. This study stands as one of the first comprehensive reviews exclusively focused on climate resilience in ports and waterborne transport systems. It provides actionable insights for policymakers, researchers, and industry stakeholders, proposing a future research agenda to advance waterborne transport systems capable of withstanding multifaceted climate impacts.

Paper number 9:
Title: Depression diagnosis from patient interviews using multimodal machine learning
Authors: Jana Weber, Marcel Weber, Juan Miguel Lopez Alcaraz
Abstract: Background: Depression is a major public health concern, affecting an estimated five percent of the global population. Early and accurate diagnosis is essential to initiate effective treatment, yet recognition remains challenging in many clinical contexts. Speech, language, and behavioral cues collected during patient interviews may provide objective markers that support clinical assessment. Methods: We developed a diagnostic approach that integrates features derived from patient interviews, including speech patterns, linguistic characteristics, and structured clinical information. Separate models were trained for each modality and subsequently combined through multimodal fusion to reflect the complexity of real-world psychiatric assessment. Model validity was assessed with established performance metrics, and further evaluated using calibration and decision-analytic approaches to estimate potential clinical utility. Results: The multimodal model achieved superior diagnostic accuracy compared to single-modality models, with an AUROC of 0.88 and an F1-score of 0.75. Importantly, the fused model demonstrated good calibration and offered higher net clinical benefit compared to baseline strategies, highlighting its potential to assist clinicians in identifying patients with depression more reliably. Conclusion: Multimodal analysis of patient interviews using machine learning may serve as a valuable adjunct to psychiatric evaluation. By combining speech, language, and clinical features, this approach provides a robust framework that could enhance early detection of depressive disorders and support evidence-based decision-making in mental healthcare.

Paper number 10:
Title: Learning Robust Regions of Attraction Using Rollout-Enhanced Physics-Informed Neural Networks with Policy Iteration
Authors: Junkai Wang, Yuxuan Zhao, Mi Zhou, Fumin Zhang
Abstract: The region of attraction is a key metric of the robustness of systems. This paper addresses the numerical solution of the generalized Zubov's equation, which produces a special Lyapunov function characterizing the robust region of attraction for perturbed systems. To handle the highly nonlinear characteristic of the generalized Zubov's equation, we propose a physics-informed neural network framework that employs a policy iteration training scheme with rollout to approximate the viscosity solution. In addition to computing the optimal disturbance during the policy improvement process, we incorporate neural network-generated value estimates as anchor points to facilitate the training procedure to prevent singularities in both low- and high-dimensional systems. Numerical simulations validate the effectiveness of the proposed approach.

Paper number 11:
Title: Comparison of Droop-Based Single-Loop Grid-Forming Wind Turbines: High-Frequency Open-Loop Unstable Behavior and Damping
Authors: Meng Chen, Yufei Xi, Lin Cheng, Xiongfei Wang, Ioannis Lestas
Abstract: The integration of inverter-interfaced generators introduces new instability phenomena into modern power systems. This paper conducts a comparative analysis of two widely used droop-based grid-forming controls, namely droop control and droop-I control, in wind turbines. Although both approaches provide steady-state reactive power-voltage droop characteristics, their impacts on high-frequency (HF) stability differ significantly. Firstly, on open-loop (OL) comparison reveals that droop-I control alters HF pole locations. The application of Routh's Stability Criterion further analytically demonstrates that such pole shifts inevitably lead to OL instability. This HF OL instability is identified as a structural phenomenon in purely inductive grids and cannot be mitigated through control parameter tuning. As a result, droop-I control significantly degrades HF stability, making conventional gain and phase margins insufficient for evaluating robustness against parameter variations. Then, the performance of established active damping (AD) is assessed for both control schemes. The finding indicates that AD designs effective for droop control may fail to suppress HF resonance under droop-I control due to the presence of unstable OL poles. Case studies performed on the IEEE 14-Bus Test System validate the analysis and emphasize the critical role of HF OL instability in determining the overall power system stability.

Paper number 12:
Title: 1-Bit Unlimited Sampling Beyond Fourier Domain: Low-Resolution Sampling of Quantization Noise
Authors: Vaclav Pavlicek, Ayush Bhandari
Abstract: Analog-to-digital converters (ADCs) play a critical role in digital signal acquisition across various applications, but their performance is inherently constrained by sampling rates and bit budgets. This bit budget imposes a trade-off between dynamic range (DR) and digital resolution, with ADC energy consumption scaling linearly with sampling rate and exponentially with bit depth. To bypass this, numerous approaches, including oversampling with low-resolution ADCs, have been explored. A prominent example is 1-Bit ADCs with Sigma-Delta Quantization (SDQ), a widely used consumer-grade solution. However, SDQs suffer from overloading or saturation issues, limiting their ability to handle inputs with arbitrary DR. The Unlimited Sensing Framework (USF) addresses this challenge by injecting modulo non-linearity in hardware, resulting in a new digital sensing technology. In this paper, we introduce a novel 1-Bit sampling architecture that extends both conventional 1-Bit SDQ and USF. Our contributions are twofold: (1) We generalize the concept of noise shaping beyond the Fourier domain, allowing the inclusion of non-bandlimited signals in the Fourier domain but bandlimited in alternative transform domains. (2) Building on this generalization, we develop a new transform-domain recovery method for 1-Bit USF. When applied to the Fourier domain, our method demonstrates superior performance compared to existing time-domain techniques, offering reduced oversampling requirements and improved robustness. Extensive numerical experiments validate our findings, laying the groundwork for a broader generalization of 1-Bit sampling systems.

Paper number 13:
Title: In-Lab Carrier Aggregation Testbed for Satellite Communication Systems
Authors: Jorge L. Gonzalez-Rios, Eva Lagunas, Hayder Al-Hraishawi, Luis M. Garces-Socarras, Symeon Chatzinotas
Abstract: Carrier Aggregation (CA) is a technique used in 5G and previous cellular generations to temporarily increase the data rate of a specific user during peak demand periods or to reduce carrier congestion. CA is achieved by combining two or more carriers and providing a virtual, wider overall bandwidth to high-demand users of the system. CA was introduced in the 4G/LTE wireless era and has been proven effective in 5G as well, where it is said to play a significant role in efficient network capacity management. Given this success, the satellite communication (SatCom) community has put its attention into CA and the potential benefits it can bring in terms of better spectrum utilization and better meeting the user traffic demand. While the theoretical evaluation of CA for SatCom has already been presented in several works, this article presents the design and results obtained with an experimentation testbed based on Software Defined Radio (SDR) and a satellite channel emulator. We first present the detailed implementation design, which includes a Gateway (GW) module responsible for PDU-scheduling across the aggregated carriers, and a User Terminal (UT) module responsible for aggregating the multiple received streams. The second part of the article presents the experimental evaluation, including CA over a single Geostationary (GEO) satellite, CA over a single Medium Earth Orbit (MEO) satellite, and CA combining carriers sent over GEO and MEO satellites. A key contribution of this work is the explicit consideration of multi-orbit scenarios in the testbed design and validation. The testing results show promising benefits of CA over SatCom systems, motivating potential upcoming testing on over-the-air systems.

Paper number 14:
Title: MRExtrap: Longitudinal Aging of Brain MRIs using Linear Modeling in Latent Space
Authors: Jaivardhan Kapoor, Jakob H. Macke, Christian F. Baumgartner
Abstract: Simulating aging in 3D brain MRI scans can reveal disease progression patterns in neurological disorders such as Alzheimer's disease. Current deep learning-based generative models typically approach this problem by predicting future scans from a single observed scan. We investigate modeling brain aging via linear models in the latent space of convolutional autoencoders (MRExtrap). Our approach, MRExtrap, is based on our observation that autoencoders trained on brain MRIs create latent spaces where aging trajectories appear approximately linear. We train autoencoders on brain MRIs to create latent spaces, and investigate how these latent spaces allow predicting future MRIs through linear extrapolation based on age, using an estimated latent progression rate $\boldsymbol{\beta}$. For single-scan prediction, we propose using population-averaged and subject-specific priors on linear progression rates. We also demonstrate that predictions in the presence of additional scans can be flexibly updated using Bayesian posterior sampling, providing a mechanism for subject-specific refinement. On the ADNI dataset, MRExtrap predicts aging patterns accurately and beats a GAN-based baseline for single-volume prediction of brain aging. We also demonstrate and analyze multi-scan conditioning to incorporate subject-specific progression rates. Finally, we show that the latent progression rates in MRExtrap's linear framework correlate with disease and age-based aging patterns from previously studied structural atrophy rates. MRExtrap offers a simple and robust method for the age-based generation of 3D brain MRIs, particularly valuable in scenarios with multiple longitudinal observations.

Paper number 15:
Title: Audio-Visual Feature Synchronization for Robust Speech Enhancement in Hearing Aids
Authors: Nasir Saleem, Mandar Gogate, Kia Dashtipour, Adeel Hussain, Usman Anwar, Adewale Adetomi, Tughrul Arslan, Amir Hussain
Abstract: Audio-visual feature synchronization for real-time speech enhancement in hearing aids represents a progressive approach to improving speech intelligibility and user experience, particularly in strong noisy backgrounds. This approach integrates auditory signals with visual cues, utilizing the complementary description of these modalities to improve speech intelligibility. Audio-visual feature synchronization for real-time SE in hearing aids can be further optimized using an efficient feature alignment module. In this study, a lightweight cross-attentional model learns robust audio-visual representations by exploiting large-scale data and simple architecture. By incorporating the lightweight cross-attentional model in an AVSE framework, the neural system dynamically emphasizes critical features across audio and visual modalities, enabling defined synchronization and improved speech intelligibility. The proposed AVSE model not only ensures high performance in noise suppression and feature alignment but also achieves real-time processing with minimal latency (36ms) and energy consumption. Evaluations on the AVSEC3 dataset show the efficiency of the model, achieving significant gains over baselines in perceptual quality (PESQ:0.52), intelligibility (STOI:19\%), and fidelity (SI-SDR:10.10dB).

Paper number 16:
Title: Fourth-Order Hierarchical Array: A Novel Scheme for Sparse Array Design Based on Fourth-Order Difference Co-Array
Authors: Si Wang, Guoqiang Xiao
Abstract: Conventional array designs based on circular fourth-order cumulant typically adopt a single expression form of the fourth-order difference co-array (FODCA), which limits the achievable degrees of freedom (DOFs) and neglects the impact of mutual coupling among physical sensors. To address above issues, this paper proposes a novel scheme to design arrays with increased DOFs by combining different forms of FODCA while accounting for mutual coupling. A novel fourth-order hierarchical array (FOHA) based on different forms of FODCA is constructed using an arbitrary generator set. The analytical expression between the coupling leakage of the generator and the resulting FOHA is derived. Two specific FOHA configurations are presented with closed-form sensor placements. The arrays not only offer increased DOFs for resolving more sources in direction of-arrival (DOA) estimation but also effectively suppress mutual coupling. Moreover, the redundancy of FODCA is examined, and it is shown that arrays based on the proposed scheme achieve lower redundancy compared to existing arrays based on FODCA. Meanwhile, the necessary and sufficient conditions for signal reconstruction by FOHA are derived. Compared with existing arrays based on FODCA, the proposed arrays provide enhanced DOFs and improved robustness against mutual coupling. Numerical simulations verify that FOHAs achieve superior DOA estimation performance compared with other sparse linear arrays.

Paper number 17:
Title: FLASepformer: Efficient Speech Separation with Gated Focused Linear Attention Transformer
Authors: Haoxu Wang, Yiheng Jiang, Gang Qiao, Pengteng Shi, Biao Tian
Abstract: Speech separation always faces the challenge of handling prolonged time sequences. Past methods try to reduce sequence lengths and use the Transformer to capture global information. However, due to the quadratic time complexity of the attention module, memory usage and inference time still increase significantly with longer segments. To tackle this, we introduce Focused Linear Attention and build FLASepformer with linear complexity for efficient speech separation. Inspired by SepReformer and TF-Locoformer, we have two variants: FLA-SepReformer and FLA-TFLocoformer. We also add a new Gated module to improve performance further. Experimental results on various datasets show that FLASepformer matches state-of-the-art performance with less memory consumption and faster inference. FLA-SepReformer-T/B/L increases speed by 2.29x, 1.91x, and 1.49x, with 15.8%, 20.9%, and 31.9% GPU memory usage, proving our model's effectiveness.

Paper number 18:
Title: Pinching Antenna System for Integrated Sensing and Communications
Authors: Haochen Li, Ruikang Zhong, Jiayi Lei, Yuanwei Liu
Abstract: Recently, the pinching antenna system (PASS) has attracted considerable attention due to their advantages in flexible deployment and reduction of signal propagation loss. In this work, a multiple waveguide PASS assisted integrated sensing and communication (ISAC) system is proposed, where the base station (BS) is equipped with transmitting pinching antennas (PAs) and receiving uniform linear array (ULA) antennas. The full-duplex (FD) BS transmits the communication and sensing signals through the PAs on waveguides and collects the echo sensing signals with the mounted ULA. Based on this configuration, a target sensing Cramer Rao Bound (CRB) minimization problem is formulated under communication quality-of-service (QoS) constraints, power budget constraint, and PA deployment constraints. The alternating optimization (AO) method is employed to address the formulated non-convex optimization problem. In each iteration, the overall optimization problem is decomposed into a digital beamforming sub-problem and a pinching beamforming sub-problem. The sensing covariance matrix and communication beamforming matrix at the BS are optimized by solving the digital beamforming sub-problem with semidefinite relaxation (SDR). The PA deployment is updated by solving the pinching beamforming sub-problem with the successive convex approximation (SCA) method, penalty method, and element-wise optimization. Simulation results show that the proposed PASS assisted ISAC framework achieves superior performance over benchmark schemes, is less affected by stringent communication constraints compared to conventional MIMO-ISAC, and benefits further from increasing the number of waveguides and PAs per waveguide.

Paper number 19:
Title: Hybrid ML-RL Approach for Smart Grid Stability Prediction and Optimized Control Strategy
Authors: Kazi Sifatul Islam, Anandi Dutta, Shivani Mruthyunjaya
Abstract: Electrical grids are now much more complex due to the rapid integration of distributed generation and alternative energy sources, which makes forecasting grid stability with optimized control a crucial task for operators. Traditional statistical, physics-based, and ML models can learn the pattern of the grid features, but have limitations in optimal strategy control with instability prediction. This work proposes a hybrid ML-RL framework that leverages ML for rapid stability prediction and RL for dynamic control and optimization. The first stage of this study created a baseline that explored the potential of various ML models for stability prediction. Out of them, the stacking classifiers of several fundamental models show a significant performance in classifying the instability, leading to the second stage, where reinforcement learning algorithms (PPO, A2C, and DQN) optimize power control actions. Experimental results demonstrate that the hybrid ML-RL model effectively stabilizes the grid, achieves rapid convergence, and significantly reduces training time. The integration of ML-based stability classification with RL-based dynamic control enhances decision-making efficiency while lowering computational complexity, making it well-suited for real-time smart grid applications.

Paper number 20:
Title: CSRD2025: A Large-Scale Synthetic Radio Dataset for Spectrum Sensing in Wireless Communications
Authors: Shuo Chang, Rui Sun, Jiashuo He, Sai Huang, Kan Yu, Zhiyong Feng
Abstract: The development of Large AI Models (LAMs) for wireless communications, particularly for complex tasks like spectrum sensing, is critically dependent on the availability of vast, diverse, and realistic datasets. Addressing this need, this paper introduces the ChangShuoRadioData (CSRD) framework, an open-source, modular simulation platform designed for generating large-scale synthetic radio frequency (RF) data. CSRD simulates the end-to-end transmission and reception process, incorporating an extensive range of modulation schemes (100 types, including analog, digital, OFDM, and OTFS), configurable channel models featuring both statistical fading and site-specific ray tracing using OpenStreetMap data, and detailed modeling of realistic RF front-end impairments for various antenna configurations (SISO/MISO/MIMO). Using this framework, we characterize CSRD2025, a substantial dataset benchmark comprising over 25,000,000 frames (approx. 200TB), which is approximately 10,000 times larger than the widely used RML2018 dataset. CSRD2025 offers unprecedented signal diversity and complexity, specifically engineered to bridge the Sim2Real gap. Furthermore, we provide processing pipelines to convert IQ data into spectrograms annotated in COCO format, facilitating object detection approaches for time-frequency signal analysis. The dataset specification includes standardized 8:1:1 training, validation, and test splits (via frame indices) to ensure reproducible research. The CSRD framework is released at this https URL to accelerate the advancement of AI-driven spectrum sensing and management.

Paper number 21:
Title: Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks
Authors: Chen Shang, Jiadong Yu, Dinh Thai Hoang
Abstract: This work proposes an energy-efficient, learning-based beamforming scheme for integrated sensing and communication (ISAC)-enabled V2X networks. Specifically, we first model the dynamic and uncertain nature of V2X environments as a Markov Decision Process. This formulation allows the roadside unit to generate beamforming decisions based solely on current sensing information, thereby eliminating the need for frequent pilot transmissions and extensive channel state information acquisition. We then develop a deep reinforcement learning (DRL) algorithm to jointly optimize beamforming and power allocation, ensuring both communication throughput and sensing accuracy in highly dynamic scenario. To address the high energy demands of conventional learning-based schemes, we embed spiking neural networks (SNNs) into the DRL framework. Leveraging their event-driven and sparsely activated architecture, SNNs significantly enhance energy efficiency while maintaining robust performance. Simulation results confirm that the proposed method achieves substantial energy savings and superior communication performance, demonstrating its potential to support green and sustainable connectivity in future V2X systems.

Paper number 22:
Title: Lightweight speech enhancement guided target speech extraction in noisy multi-speaker scenarios
Authors: Ziling Huang, Junnan Wu, Lichun Fan, Zhenbo Luo, Jian Luan, Haixin Guan, Yanhua Long
Abstract: Target speech extraction (TSE) has achieved strong performance in relatively simple conditions such as one-speaker-plus-noise and two-speaker mixtures, but its performance remains unsatisfactory in noisy multi-speaker scenarios. To address this issue, we introduce a lightweight speech enhancement model, GTCRN, to better guide TSE in noisy environments. Building on our competitive previous speaker embedding/encoder-free framework SEF-PNet, we propose two extensions: LGTSE and D-LGTSE. LGTSE incorporates noise-agnostic enrollment guidance by denoising the input noisy speech before context interaction with enrollment speech, thereby reducing noise interference. D-LGTSE further improves system robustness against speech distortion by leveraging denoised speech as an additional noisy input during training, expanding the dynamic range of noisy conditions and enabling the model to directly learn from distorted signals. Furthermore, we propose a two-stage training strategy, first with GTCRN enhancement-guided pre-training and then joint fine-tuning, to fully exploit model this http URL on the Libri2Mix dataset demonstrate significant improvements of 0.89 dB in SISDR, 0.16 in PESQ, and 1.97% in STOI, validating the effectiveness of our approach. Our code is publicly available at this https URL.

Paper number 23:
Title: Symbolic Equation Modeling of Composite Loads: A Kolmogorov-Arnold Network based Learning Approach
Authors: Sonam Dorji, Yongkang Sun, Yuchen Zhang, Ghavameddin Nourbakhsh, Yateendra Mishra, Yan Xu
Abstract: With increasing penetration of distributed energy resources installed behind the meter, there is a growing need for adequate modelling of composite loads to enable accurate power system simulation analysis. Existing measurement based load modeling methods either fit fixed-structure physical models, which limits adaptability to evolving load mixes, or employ flexible machine learning methods which are however black boxes and offer limited interpretability. This paper presents a new learning based load modelling method based on Kolmogorov Arnold Networks towards modelling flexibility and interpretability. By actively learning activation functions on edges, KANs automatically derive free form symbolic equations that capture nonlinear relationships among measured variables without prior assumptions about load structure. Case studies demonstrate that the proposed approach outperforms other methods in both accuracy and generalization ability, while uniquely representing composite loads into transparent, interpretable mathematical equations.

Paper number 24:
Title: Code-Weight Sphere Decoding
Authors: Yubeen Jo, Geon Choi, Yongjune Kim, Namyoon Lee
Abstract: Ultra-reliable low-latency communications (URLLC) demand high-performance error-correcting codes and decoders in the finite blocklength regime. This letter introduces a novel two-stage near-maximum likelihood (near-ML) decoding framework applicable to any linear block code. Our approach first employs a low-complexity initial decoder. If this initial stage fails a cyclic redundancy check, it triggers a second stage: the proposed code-weight sphere decoding (WSD). WSD iteratively refines the codeword estimate by exploring a localized sphere of candidates constructed from pre-computed low-weight codewords. This strategy adaptively minimizes computational overhead at high signal-to-noise ratios while achieving near-ML performance, especially for low-rate codes. Extensive simulations demonstrate that our two-stage decoder provides an excellent trade-off between decoding reliability and complexity, establishing it as a promising solution for next-generation URLLC systems.

Paper number 25:
Title: Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge
Authors: Maha Shatta, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Georgios Panagopoulos, Mehdi B. Tahoori, Georgios Zervakis
Abstract: Flexible Electronics (FE) offer a promising alternative to rigid silicon-based hardware for wearable healthcare devices, enabling lightweight, conformable, and low-cost systems. However, their limited integration density and large feature sizes impose strict area and power constraints, making ML-based healthcare systems-integrating analog frontend, feature extraction and classifier-particularly challenging. Existing FE solutions often neglect potential system-wide solutions and focus on the classifier, overlooking the substantial hardware cost of feature extraction and Analog-to-Digital Converters (ADCs)-both major contributors to area and power consumption. In this work, we present a holistic mixed-signal feature-to-classifier co-design framework for flexible smart wearable systems. To the best of our knowledge, we design the first analog feature extractors in FE, significantly reducing feature extraction cost. We further propose an hardware-aware NAS-inspired feature selection strategy within ML training, enabling efficient, application-specific designs. Our evaluation on healthcare benchmarks shows our approach delivers highly accurate, ultra-area-efficient flexible systems-ideal for disposable, low-power wearable monitoring.

Paper number 26:
Title: Low-Cost Architecture and Efficient Pattern Synthesis for Polarimetric Phased Array Based on Polarization Coding Reconfigurable Elements
Authors: Yiqing Wang, Jian Zhou, Chen Pang, Wenyang Man, Zixiang Xiong, Ke Meng, Zhanling Wang, Yongzhen Li
Abstract: Polarimetric phased arrays (PPAs) enhance radar target detection and anti-jamming capabilities. However, the dual transmit/receive (T/R) channel requirement leads to high costs and system complexity. To address this, this paper introduces a polarization-coding reconfigurable phased array (PCRPA) and associated pattern synthesis techniques to reduce PPA costs while minimizing performance degradation. Each PCRPA element connects to a single T/R channel and incorporates two-level RF switches for real-time control of polarization states and waveforms. By adjusting element codes and excitation weights, the PCRPA can generate arbitrarily polarized and dual-polarized beams. Efficient beam pattern synthesis methods are also proposed, featuring novel optimization constraints derived from theoretical and analytical analysis of PCRPAs. Simulations demonstrate that the approach achieves low cross-polarization and sidelobe levels comparable to conventional architectures within the scan range, particularly for large arrays. However, the channel reduction inevitably incurs power and directivity loss. Experiments conducted on an $8\times 8$ X-band array antenna validate the effectiveness of the proposed system. The PCRPA and synthesis methods are well-suited for large-scale PPA systems, offering significant cost-effectiveness while maintaining good sidelobe suppression and polarization control performance.

Paper number 27:
Title: Demonstrator Testbed for Effective Precoding in MEO Multibeam Satellites
Authors: Jorge L. González-Rios, Liz Martínez Marrero, Juan Duncan, Luis M. Garcés-Socarrás, Raudel Cuiman Marquez, Juan A. Vásquez Peralvo, Jevgenij Krivochiza, Symeon Chatzinotas, Björn Ottersten
Abstract: The use of communication satellites in medium Earth orbit (MEO) is foreseen to provide quasi-global broadband Internet connectivity in the coming networking ecosystems. Multi-user multiple-input single-output (MU-MISO) digital signal processing techniques, such as precoding, emerge as appealing technological enablers in the forward link of multi-beam satellite systems operating in full frequency reuse (FFR). However, the orbit dynamics of MEO satellites pose additional challenges that must be carefully evaluated and addressed. This work presents the design of an in-lab testbed based on software-defined radio (SDR) platforms and the corresponding adaptations required for efficient precoding in a MEO scenario. The setup incorporates a precise orbit model and the radiation pattern of a custom-designed direct radiating array (DRA). We analyze the main impairments affecting precoding performance, including Doppler shifts and payload phase noise, and propose a synchronization loop to mitigate these effects. Preliminary experimental results validate the feasibility and effectiveness of the proposed solution.

Paper number 28:
Title: Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation
Authors: Vojtech Mrazek, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Zdenek Vasicek, Mehdi B. Tahoori, Georgios Zervakis
Abstract: Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs.

Paper number 29:
Title: Hybrid Decoding: Rapid Pass and Selective Detailed Correction for Sequence Models
Authors: Yunkyu Lim, Jihwan Park, Hyung Yong Kim, Hanbin Lee, Byeong-Yeol Kim
Abstract: Recently, Transformer-based encoder-decoder models have demonstrated strong performance in multilingual speech recognition. However, the decoder's autoregressive nature and large size introduce significant bottlenecks during inference. Additionally, although rare, repetition can occur and negatively affect recognition accuracy. To tackle these challenges, we propose a novel Hybrid Decoding approach that both accelerates inference and alleviates the issue of repetition. Our method extends the transformer encoder-decoder architecture by attaching a lightweight, fast decoder to the pretrained encoder. During inference, the fast decoder rapidly generates an output, which is then verified and, if necessary, selectively corrected by the Transformer decoder. This results in faster decoding and improved robustness against repetitive errors. Experiments on the LibriSpeech and GigaSpeech test sets indicate that, with fine-tuning limited to the added decoder, our method achieves word error rates comparable to or better than the baseline, while more than doubling the inference speed.

Paper number 30:
Title: Distributed Safety-Critical MPC for Multi-Agent Formation Control and Obstacle Avoidance
Authors: Chao Wang, Shuyuan Zhang, Lei Wang
Abstract: For nonlinear multi-agent systems with high relative degrees, achieving formation control and obstacle avoidance in a distributed manner remains a significant challenge. To address this issue, we propose a novel distributed safety-critical model predictive control (DSMPC) algorithm that incorporates discrete-time high-order control barrier functions (DHCBFs) to enforce safety constraints, alongside discrete-time control Lyapunov functions (DCLFs) to establish terminal constraints. To facilitate distributed implementation, we develop estimated neighbor states for formulating DHCBFs and DCLFs, while also devising a bound constraint to limit estimation errors and ensure convergence. Additionally, we provide theoretical guarantees regarding the feasibility and stability of the proposed DSMPC algorithm based on a mild assumption. The effectiveness of the proposed method is evidenced by the simulation results, demonstrating improved performance and reduced computation time compared to existing approaches.

Paper number 31:
Title: CAVEMOVE: An Acoustic Database for the Study of Voice-enabled Technologies inside Moving Vehicles
Authors: Nikolaos Stefanakis, Marinos Kalaitzakis, Andreas Symiakakis, Stefanos Papadakis, Despoina Pavlidi
Abstract: In this paper, we present an acoustic database, designed to drive and support research on voiced enabled technologies inside moving vehicles. The recording process involves (i) recordings of acoustic impulse responses, acquired under static conditions to provide the means for modeling the speech and car-audio components (ii) recordings of acoustic noise at a wide range of static and in-motion conditions. Data are recorded with two different microphone configurations, particularly (i) a compact microphone array and (ii) a distributed microphone setup. We briefly describe the conditions under which the recordings were acquired, and we provide insight into a Python API that we designed to support the research and development of voice-enabled technologies inside moving vehicles. The first version of this Python API and part of the described dataset are available for free download.

Paper number 32:
Title: MC for Gastroretentive Drug Delivery
Authors: Sebastian Lotter, Marco Seiter, Maryam Pirmoradi, Lukas Brand, Dagmar Fischer, Robert Schober
Abstract: Recently, bacterial nanocellulose (BNC), a biological material produced by non-pathogenic bacteria that possesses excellent material properties for various medical applications, has received increased interest as a carrier system for drug delivery. However, the vast majority of existing studies on drug release from BNC are feasibility studies with modeling and design aspects remaining largely unexplored. To narrow this research gap, this paper proposes a novel model for the drug release from BNC. Specifically, the drug delivery system considered in this paper consists of a BNC fleece coated with a polymer. The polymer coating is used as an additional diffusion barrier, enabling the controlled release of an active pharmaceutical ingredient. The proposed physics-based model reflects the geometry of the BNC and incorporates the impact of the polymer coating on the drug release. Hence, it can be useful for designing BNC-based drug delivery systems in the future. The accuracy of the model is validated with experimental data obtained in wet lab experiments.

Paper number 33:
Title: Uncertainty-Based Perturb and Observe for Fast Optimization of Unknown, Time-Varying Processes
Authors: Leontine Aarnoudse, Mark Haring, Nathan van de Wouw, Alexey Pavlov
Abstract: Model-free adaptive optimization methods are capable of optimizing unknown, time-varying processes even when other optimization methods are not. However, their practical application is often limited by perturbations that are used to gather information on the unknown cost and its gradient. The aim of this paper is to develop a perturb-and-observe (P&O) method that reduces the need for such perturbations while still achieving fast and accurate tracking of time-varying optima. To this end, a (time-varying) model of the cost is constructed in an online fashion, taking into account the uncertainty on the measured performance cost as well as the decreasing reliability of older measurements. Perturbations are only used when this is expected to lead to improved performance over a certain time horizon. Convergence conditions are provided under which the strategy converges to a neighborhood of the optimum. Finally, simulation results demonstrate that uncertainty-based P\&O can reduce the number of perturbations significantly while still tracking a time-varying optimum accurately.

Paper number 34:
Title: Limited Preemption of the 3-Phase Task Model using Preemption Thresholds
Authors: Thilanka Thilakasiri, Matthias Becker
Abstract: Phased execution models are a well-known solution to tackle the unpredictability of today's complex COTS multi-core platforms. The semantics of these models dedicate phases for a task's execution and shared memory accesses. Memory phases are solely dedicated to load all necessary instructions and data to private local memory, and to write back the results of the computation. During execution phases, only the private local memory is accessed. While non-preemptive execution phases utilize the local memory well, schedulability is reduced due to blocking. On the other hand, fully preemptive execution phases allow for better schedulability, but require local memory to be large enough to hold all tasks involved in preemption simultaneously. Limited preemption is a promising approach that provides moderation between non-preemptive and fully preemptive scheduling. In this paper, we propose using preemption thresholds to limit the number of preemptions to minimize local memory usage while maintaining schedulability. We propose a worst-case response time and a worst-case memory requirement analysis for sporadic 3-phase tasks under partitioned fixed-priority scheduling with preemption thresholds. We further show how the state-of-the-art algorithm to assign preemption thresholds can be applied to the considered task model. Evaluations demonstrate that preemption thresholds can significantly reduce the memory usage (by $2.5\times$) compared to fully preemptive scheduling, while maintaining high schedulability ratios ($13\times$) compared to non-preemptive scheduling.

Paper number 35:
Title: On Minimization/Maximization of the Generalized Multi-Order Complex Quadratic Form With Constant-Modulus Constraints
Authors: Chunxuan Shi, Yongzhe Li, Ran Tao
Abstract: In this paper, we study the generalized problem that minimizes or maximizes a multi-order complex quadratic form with constant-modulus constraints on all elements of its optimization variable. Such a mathematical problem is commonly encountered in various applications of signal processing. We term it as the constant-modulus multi-order complex quadratic programming (CMCQP) in this paper. In general, the CMCQP is non-convex and difficult to solve. Its objective function typically relates to metrics such as signal-to-noise ratio, Cramér-Rao bound, integrated sidelobe level, etc., and constraints normally correspond to requirements on similarity to desired aspects, peak-to-average-power ratio, or constant-modulus property in practical scenarios. In order to find efficient solutions to the CMCQP, we first reformulate it into an unconstrained optimization problem with respect to phase values of the studied variable only. Then, we devise a steepest descent/ascent method with fast determinations on its optimal step sizes. Specifically, we convert the step-size searching problem into a polynomial form that leads to closed-form solutions of high accuracy, wherein the third-order Taylor expansion of the search function is conducted. Our major contributions also lie in investigating the effect of the order and specific form of matrices embedded in the CMCQP, for which two representative cases are identified. Examples of related applications associated with the two cases are also provided for completeness. The proposed methods are summarized into algorithms, whose convergence speeds are verified to be fast by comprehensive simulations and comparisons to existing methods. The accuracy of our proposed fast step-size determination is also evaluated.

Paper number 36:
Title: Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission
Authors: Sergio Hernandez, Christophe Peucheret, Francesco Da Ros, Darko Zibar
Abstract: Directly modulated lasers (DMLs) are an attractive technology for short-reach intensity modulation and direct detection communication systems. However, their complex nonlinear dynamics make the modeling and optimization of DML-based systems challenging. In this paper, we study the end-to-end optimization of DML-based systems based on a data-driven surrogate model trained on experimental data. The end-to-end optimization includes the pulse shaping and equalizer filters, the bias current and the modulation radio-frequency (RF) power applied to the laser. The performance of the end-to-end optimization scheme is tested on the experimental setup and compared to 4 different benchmark schemes based on linear and nonlinear receiver-side equalization. The results show that the proposed end-to-end scheme is able to deliver better performance throughout the studied symbol rates and transmission distances while employing lower modulation RF power, fewer filter taps and utilizing a smaller signal bandwidth.

Paper number 37:
Title: Cell-Free Massive MIMO-Based Physical-Layer Authentication
Authors: Isabella W. G. da Silva, Zahra Mobini, Hien Quoc Ngo, Michail Matthaiou
Abstract: In this paper, we exploit the cell-free massive multiple-input multiple-output (CF-mMIMO) architecture to design a physical-layer authentication (PLA) framework that can simultaneously authenticate multiple distributed users across the coverage area. Our proposed scheme remains effective even in the presence of active adversaries attempting impersonation attacks to disrupt the authentication process. Specifically, we introduce a tag-based PLA CFmMIMO system, wherein the access points (APs) first estimate their channels with the legitimate users during an uplink training phase. Subsequently, a unique secret key is generated and securely shared between each user and the APs. We then formulate a hypothesis testing problem and derive a closed-form expression for the probability of detection for each user in the network. Numerical results validate the effectiveness of the proposed approach, demonstrating that it maintains a high detection probability even as the number of users in the system increases.

Paper number 38:
Title: Combined Stochastic and Robust Optimization for Electric Autonomous Mobility-on-Demand with Nested Benders Decomposition
Authors: Sten Elling Tingstad Jacobsen, Balázs Kulcsár, Anders Lindman
Abstract: The electrification and automation of mobility are reshaping how cities operate on-demand transport systems. Managing Electric Autonomous Mobility-on-Demand (EAMoD) fleets effectively requires coordinating dispatch, rebalancing, and charging decisions under multiple uncertainties, including travel demand, travel time, energy consumption, and charger availability. We address this challenge with a combined stochastic and robust model predictive control (MPC) framework. The framework integrates spatio-temporal Bayesian neural network forecasts with a multi-stage stochastic optimization model, formulated as a large-scale mixed-integer linear program. To ensure real-time applicability, we develop a tailored Nested Benders Decomposition that exploits the scenario tree structure and enables efficient parallelized solution. Stochastic optimization is employed to anticipate demand and infrastructure variability, while robust constraints on energy consumption and travel times safeguard feasibility under worst-case realizations. We evaluate the framework using high-fidelity simulations of San Francisco and Chicago. Compared with deterministic, reactive, and robust baselines, the combined stochastic and robust approach reduces median passenger waiting times by up to 36% and 95th-percentile delays by nearly 20%, while also lowering rebalancing distance by 27% and electricity costs by more than 35%. We also conduct a sensitivity analysis of battery size and vehicle efficiency, finding that energy-efficient vehicles maintain stable performance even with small batteries, whereas less efficient vehicles require larger batteries and greater infrastructure support. Our results emphasize the importance of jointly optimizing predictive control, vehicle capabilities, and infrastructure planning to enable scalable, cost-efficient EAMoD operations.

Paper number 39:
Title: The Coherent Multiplex: Scalable Real-Time Wavelet Coherence Architecture
Authors: Noah Shore
Abstract: The Coherent Multiplex is formalized and validated as a scalable, real-time system for identifying, analyzing, and visualizing coherence among multiple time series. Its architecture comprises a fast spectral similarity layer based on cosine similarity metrics of Fourier-transformed signals, and a sparse time-frequency layer for wavelet coherence. The system constructs and evolves a multilayer graph representing inter-signal relationships, enabling low-latency inference and monitoring. A simulation prototype demonstrates functionality across 8 synthetic channels with a high similarity threshold for further computation, with additional opportunities for scaling the architecture up to support thousands of input signals with constrained hardware. Applications discussed include neuroscience, finance, and biomedical signal analysis.

Paper number 40:
Title: Large Language Models (LLMs) for Electronic Design Automation (EDA)
Authors: Kangwei Xu, Denis Schwachhofer, Jason Blocklove, Ilia Polian, Peter Domanski, Dirk Pflüger, Siddharth Garg, Ramesh Karri, Ozgur Sinanoglu, Johann Knechtel, Zhuorui Zhao, Ulf Schlichtmann, Bing Li
Abstract: With the growing complexity of modern integrated circuits, hardware engineers are required to devote more effort to the full design-to-manufacturing workflow. This workflow involves numerous iterations, making it both labor-intensive and error-prone. Therefore, there is an urgent demand for more efficient Electronic Design Automation (EDA) solutions to accelerate hardware development. Recently, large language models (LLMs) have shown remarkable advancements in contextual comprehension, logical reasoning, and generative capabilities. Since hardware designs and intermediate scripts can be represented as text, integrating LLM for EDA offers a promising opportunity to simplify and even automate the entire workflow. Accordingly, this paper provides a comprehensive overview of incorporating LLMs into EDA, with emphasis on their capabilities, limitations, and future opportunities. Three case studies, along with their outlook, are introduced to demonstrate the capabilities of LLMs in hardware design, testing, and optimization. Finally, future directions and challenges are highlighted to further explore the potential of LLMs in shaping the next-generation EDA, providing valuable insights for researchers interested in leveraging advanced AI technologies for EDA.

Paper number 41:
Title: MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks
Authors: Qian Liang, Menghaoran Tang, Yi Zeng
Abstract: Symbolic music generation has seen rapid progress with artificial neural networks, yet remains underexplored in the biologically plausible domain of spiking neural networks (SNNs), where both standardized benchmarks and comprehensive evaluation methods are lacking. To address this gap, we introduce MuSpike, a unified benchmark and evaluation framework that systematically assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM, SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal, structural, emotional, and stylistic variations. MuSpike emphasizes comprehensive evaluation, combining established objective metrics with a large-scale listening study. We propose new subjective metrics, targeting musical impression, autobiographical association, and personal preference, that capture perceptual dimensions often overlooked in prior work. Results reveal that (1) different SNN models exhibit distinct strengths across evaluation dimensions; (2) participants with different musical backgrounds exhibit diverse perceptual patterns, with experts showing greater tolerance toward AI-composed music; and (3) a noticeable misalignment exists between objective and subjective evaluations, highlighting the limitations of purely statistical metrics and underscoring the value of human perceptual judgment in assessing musical quality. MuSpike provides the first systematic benchmark and systemic evaluation framework for SNN models in symbolic music generation, establishing a solid foundation for future research into biologically plausible and cognitively grounded music generation.

Paper number 42:
Title: Beat-Based Rhythm Quantization of MIDI Performances
Authors: Maximilian Wachter, Sebastian Murgul, Michael Heizmann
Abstract: We propose a transformer-based rhythm quantization model that incorporates beat and downbeat information to quantize MIDI performances into metrically-aligned, human-readable scores. We propose a beat-based preprocessing method that transfers score and performance data into a unified token representation. We optimize our model architecture and data representation and train on piano and guitar performances. Our model exceeds state-of-the-art performance based on the MUSTER metric.

Paper number 43:
Title: SNIC bifurcation and its Application to MEMS
Authors: Joshua Shay Kricheli
Abstract: This project focuses on a method to extract a frequency comb in mechanical means, for general interest and numerous practical applications in MEMS. The method of execution is the implementation of a beam that is exhibiting non-linear dynamics that is perturbed and analyzed for its transverse vibrations. The perturbation is an external harmonic driver with a chosen small amplitude and frequency (which is slightly detuned from the beam eigenfrequency), that when engaged with the unperturbed beam oscillations, causes it reach a state of "injection pulling" - an effect that occurs when one harmonic oscillator is coupled with a second one and causes it to oscillate in a frequency near its own. This causes the beam to reach SNIC bifurcation, rendering a frequency comb as desired. Theoretical analysis showed that the problem can be modelled using a non-linear equation of the beam, that translates to a form of the non-linear Duffing equation. While a solution to the dynamics function of the beam is hard to obtain in practice due to mathematical difficulties, a slow evolution model is suggested that is composed of functions of a amplitude and phase. Using several additional mathematical assumptions, the amplitude is seen to be related to the phase, while the phase equation solution is seen to be of the form of Adler's equation. These assumptions ultimately reduce the entire behaviour of the beam to a relatively simple solution to the Adler equation, which has a known analytical solution. Computerized numerical simulations are run on it to check the results and compare them to the theory and desired outcome. The results agreed with the theory and produce the expected frequency comb, showing the assumptions to be valid in extracting the comb.

Paper number 44:
Title: Deep Data Hiding for ICAO-Compliant Face Images: A Survey
Authors: Jefferson David Rodriguez Chivata, Davide Ghiani, Simone Maurizio La Cava, Marco Micheletto, Giulia Orrù, Federico Lama, Gian Luca Marcialis
Abstract: ICAO-compliant facial images, initially designed for secure biometric passports, are increasingly becoming central to identity verification in a wide range of application contexts, including border control, digital travel credentials, and financial services. While their standardization enables global interoperability, it also facilitates practices such as morphing and deepfakes, which can be exploited for harmful purposes like identity theft and illegal sharing of identity documents. Traditional countermeasures like Presentation Attack Detection (PAD) are limited to real-time capture and offer no post-capture protection. This survey paper investigates digital watermarking and steganography as complementary solutions that embed tamper-evident signals directly into the image, enabling persistent verification without compromising ICAO compliance. We provide the first comprehensive analysis of state-of-the-art techniques to evaluate the potential and drawbacks of the underlying approaches concerning the applications involving ICAO-compliant images and their suitability under standard constraints. We highlight key trade-offs, offering guidance for secure deployment in real-world identity systems.

Paper number 45:
Title: Aggregate Fictitious Play for Learning in Anonymous Polymatrix Games (Extended Version)
Authors: Semih Kara, Tamer Başar
Abstract: Fictitious play (FP) is a well-studied algorithm that enables agents to learn Nash equilibrium in games with certain reward structures. However, when agents have no prior knowledge of the reward functions, FP faces a major challenge: the joint action space grows exponentially with the number of agents, which slows down reward exploration. Anonymous games offer a structure that mitigates this issue. In these games, the rewards depend only on the actions taken; not on who is taking which action. Under such a structure, we introduce aggregate fictitious play (agg-FP), a variant of FP where each agent tracks the frequency of the number of other agents playing each action, rather than these agents' individual actions. We show that in anonymous polymatrix games, agg-FP converges to a Nash equilibrium under the same conditions as classical FP. In essence, by aggregating the agents' actions, we reduce the action space without losing the convergence guarantees. Using simulations, we provide empirical evidence on how this reduction accelerates convergence.

Paper number 46:
Title: Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science
Authors: Daoyuan Jin, Nick Gunner, Niko Carvajal Janke, Shivranjani Baruah, Kaitlin M. Gold, Yu Jiang
Abstract: Modern plant science increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integrates domain knowledge, data analysis, and machine learning within a structured framework to autonomously conduct data-driven scientific discovery. Once provided with a research question and dataset, Aleks iteratively formulated problems, explored alternative modeling strategies, and refined solutions across multiple cycles without human intervention. In a case study on grapevine red blotch disease, Aleks progressively identified biologically meaningful features and converged on interpretable models with robust performance. Ablation studies underscored the importance of domain knowledge and memory for coherent outcomes. This exploratory work highlights the promise of agentic AI as an autonomous collaborator for accelerating scientific discovery in plant sciences.

Paper number 47:
Title: Optimal Control of ODE Car-Following Models: Applications to Mixed-Autonomy Platoon Control via Coupled Autonomous Vehicles
Authors: Arwa Alanqary, Alexandre M. Bayen, Xiaoqian Gong, Anish Gollakota, Alexander Keimer, Ashish Pandian
Abstract: In this paper, we study the optimal control of a mixed-autonomy platoon driving on a single lane to smooth traffic flow. The platoon consists of autonomous vehicles, whose acceleration is controlled, and human-driven vehicles, whose behavior is described using a microscopic car-following model. We formulate the optimal control problem where the dynamics of the platoon are describing through a system of non-linear ODEs, with explicit constraints on both the state and the control variables. Theoretically, we analyze the well-posedness of the system dynamics under a reasonable set of admissible controls and establish the existence of minimizers for the optimal control problem. To solve the problem numerically, we propose a gradient descent-based algorithm that leverages the adjoint method, along with a penalty approach to handle state constraints. We demonstrate the effectiveness of the proposed numerical scheme through several experiments, exploring various scenarios with different penetration rates and distributions of controlled vehicles within the platoon.

Paper number 48:
Title: Shining light on degeneracies and uncertainties in quantifying both exchange and restriction with time-dependent diffusion MRI using Bayesian inference
Authors: Maëliss Jallais, Quentin Uhl, Tommaso Pavan, Malwina Molendowska, Derek K. Jones, Ileana Jelescu, Marco Palombo
Abstract: Diffusion MRI (dMRI) biophysical models hold promise for characterizing gray matter tissue microstructure. Yet, the reliability of estimated parameters remains largely under-studied, especially in models that incorporate water exchange. In this study, we investigate the accuracy, precision, and presence of degeneracy of two recently proposed gray matter models, NEXI and SANDIX, using two acquisition protocols from the literature, on both simulated and in vivo data. We employ $\mu$GUIDE, a Bayesian inference framework based on deep learning, to quantify model uncertainty and detect parameter degeneracies, enabling a more interpretable assessment of fitted parameters. Our results show that while some microstructural parameters, such as extra-cellular diffusivity and neurite signal fraction, are robustly estimated, others, such as exchange time and soma radius, are often associated with high uncertainty and estimation bias, especially under realistic noise conditions and reduced acquisition protocols. Comparisons with non-linear least squares fitting underscore the added value of uncertainty-aware methods, which allow for the identification and filtering of unreliable estimates. These findings emphasize the need to report uncertainty and consider model degeneracies when interpreting model-based estimates. Our study advocates for the integration of probabilistic fitting approaches in neuroscience imaging pipelines to improve reproducibility and biological interpretability.

Paper number 49:
Title: Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks
Authors: Muhammad Ahmed Mohsin, Junaid Ahmad, Muhammad Hamza Nawaz, Muhammad Ali Jamshed
Abstract: Ambient intelligence (AmI) is a computing paradigm in which physical environments are embedded with sensing, computation, and communication so they can perceive people and context, decide appropriate actions, and respond autonomously. Realizing AmI at global scale requires sixth generation (6G) wireless networks with capabilities for real time perception, reasoning, and action aligned with human behavior and mobility patterns. We argue that Generative Artificial Intelligence (GenAI) is the creative core of such environments. Unlike traditional AI, GenAI learns data distributions and can generate realistic samples, making it well suited to close key AmI gaps, including generating synthetic sensor and channel data in under observed areas, translating user intent into compact, semantic messages, predicting future network conditions for proactive control, and updating digital twins without compromising privacy. This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models, and generative transformers, and connects them to practical AmI use cases, including spectrum sharing, ultra reliable low latency communication, intelligent security, and context aware digital twins. We also examine how 6G enablers, such as edge and fog computing, IoT device swarms, intelligent reflecting surfaces (IRS), and non terrestrial networks, can host or accelerate distributed GenAI. Finally, we outline open challenges in energy efficient on device training, trustworthy synthetic data, federated generative learning, and AmI specific standardization. We show that GenAI is not a peripheral addition, but a foundational element for transforming 6G from a faster network into an ambient intelligent ecosystem.

Paper number 50:
Title: Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed Criticality Systems
Authors: Diogo Costa, Jose Martins, Sandro Pinto
Abstract: As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate heterogeneous computing platforms, combining general-purpose processors with specialized accelerators such as AI engines, GPUs, and high-speed networking interfaces. This heterogeneity introduces challenges, as these accelerators and DMA-capable devices act as independent bus masters, directly accessing memory. Consequently, ensuring both security and timing predictability in such environments becomes critical. To address these concerns, the Input-Output Memory Management Unit (IOMMU) plays a key role in mediating and regulating memory access, preventing unauthorized transactions while enforcing isolation and access control policies. While prior work has explored IOMMU-related side-channel vulnerabilities from a security standpoint, its role in performance interference remains largely unexplored. Moreover, many of the same architectural properties that enable side-channel leakage, such as shared TLBs, caching effects, and translation overheads, can also introduce timing unpredictability. In this work, we analyze the contention effects within IOMMU structures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how their shared nature introduce unpredictable delays. Our findings reveal that IOMMU-induced interference primarily affects small memory transactions, where translation overheads significantly impact execution time. Additionally, we hypothesize that contention effects arising from IOTLBs exhibit similar behavior across architectures due to shared caching principles, such as prefetching and hierarchical TLB structures. Notably, our experiments show that IOMMU interference can delay DMA transactions by up to 1.79x for lower-size transfers on the Arm SMMUv2 implementation.

Paper number 51:
Title: CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese
Authors: Carlos Carvalho, Francisco Teixeira, Catarina Botelho, Anna Pompili, Rubén Solera-Ureña, Sérgio Paulo, Mariana Julião, Thomas Rolland, John Mendonça, Diogo Pereira, Isabel Trancoso, Alberto Abad
Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly focused on Brazilian Portuguese, leaving European Portuguese (EP) and other varieties under-explored. To bridge this gap, we introduce CAMÕES, the first open framework for EP and other Portuguese varieties. It consists of (1) a comprehensive evaluation benchmark, including 46h of EP test data spanning multiple domains; and (2) a collection of state-of-the-art models. For the latter, we consider multiple foundation models, evaluating their zero-shot and fine-tuned performances, as well as E-Branchformer models trained from scratch. A curated set of 425h of EP was used for both fine-tuning and training. Our results show comparable performance for EP between fine-tuned foundation models and the E-Branchformer. Furthermore, the best-performing models achieve relative improvements above 35% WER, compared to the strongest zero-shot foundation model, establishing a new state-of-the-art for EP and other varieties.

Paper number 52:
Title: TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation
Authors: Shashi Kumar, Srikanth Madikeri, Esaú Villatoro-Tello, Sergio Burdisso, Pradeep Rangappa, Andrés Carofilis, Petr Motlicek, Karthik Pandia, Shankar Venkatesan, Kadri Hacioğlu, Andreas Stolcke
Abstract: Token-based multitasking frameworks like TokenVerse require all training utterances to have labels for all tasks, hindering their ability to leverage partially annotated datasets and scale effectively. We propose TokenVerse++, which introduces learnable vectors in the acoustic embedding space of the XLSR-Transducer ASR model for dynamic task activation. This core mechanism enables training with utterances labeled for only a subset of tasks, a key advantage over TokenVerse. We demonstrate this by successfully integrating a dataset with partial labels, specifically for ASR and an additional task, language identification, improving overall performance. TokenVerse++ achieves results on par with or exceeding TokenVerse across multiple tasks, establishing it as a more practical multitask alternative without sacrificing ASR performance.

Paper number 53:
Title: Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions
Authors: Zhouyu Zhang, Chih-Yuan Chiu, Glen Chou
Abstract: We present an inverse dynamic game-based algorithm to learn parametric constraints from a given dataset of local generalized Nash equilibrium interactions between multiple agents. Specifically, we introduce mixed-integer linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the interacting agents, which recover constraints consistent with the Nash stationarity of the interaction demonstrations. We establish theoretical guarantees that our method learns inner approximations of the true safe and unsafe sets, as well as limitations of constraint learnability from demonstrations of Nash equilibrium interactions. We also use the interaction constraints recovered by our method to design motion plans that robustly satisfy the underlying constraints. Across simulations and hardware experiments, our methods proved capable of inferring constraints and designing interactive motion plans for various classes of constraints, both convex and non-convex, from interaction demonstrations of agents with nonlinear dynamics.

Paper number 54:
Title: On the Outage Probability of Multiuser Multiple Antenna Systems with Non-Orthogonal Multiple Access for Air-Ground Communications
Authors: Ayten Gürbüz, Giuseppe Caire, Alexander Steingass
Abstract: This paper explores multiuser multiple antenna systems as a means to enhance the spectral efficiency of aeronautical communications systems. To this end, the outage regime for a multiuser multiple antenna system is studied within a realistic geometry-based stochastic air-ground (AG) channel model. In this application, users (aircraft) transmit air traffic management data to the ground station at a predefined target rate. Due to the nature of the AG propagation, we argue that the relevant performance metric in this context is the information outage probability. We consider the outage probability under three decoding approaches. The first is based on successive interference cancellation (SIC). The second extends the first approach by considering joint group decoding. The third is a version of the second that limits the size of the jointly decoded user groups in order to lower the decoding complexity. The results show that joint group decoding, even in groups of only two, can significantly increase the spectral efficiency in the AG channel by allowing a large number of aircraft to transmit over a non-orthogonal channel with very low outage probabilities.

Paper number 55:
Title: HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling
Authors: Matthias Maiterth, Wesley H. Brewer, Jaya S. Kuruvella, Arunavo Dey, Tanzima Z. Islam, Kevin Menear, Dmitry Duplyakin, Rashadul Kabir, Tapasya Patki, Terry Jones, Feiyi Wang
Abstract: Schedulers are critical for optimal resource utilization in high-performance computing. Traditional methods to evaluate schedulers are limited to post-deployment analysis, or simulators, which do not model associated infrastructure. In this work, we present the first-of-its-kind integration of scheduling and digital twins in HPC. This enables what-if studies to understand the impact of parameter configurations and scheduling decisions on the physical assets, even before deployment, or regarching changes not easily realizable in production. We (1) provide the first digital twin framework extended with scheduling capabilities, (2) integrate various top-tier HPC systems given their publicly available datasets, (3) implement extensions to integrate external scheduling simulators. Finally, we show how to (4) implement and evaluate incentive structures, as-well-as (5) evaluate machine learning based scheduling, in such novel digital-twin based meta-framework to prototype scheduling. Our work enables what-if scenarios of HPC systems to evaluate sustainability, and the impact on the simulated system.

Paper number 56:
Title: Secure Set-based State Estimation for Safety-Critical Applications under Adversarial Attacks on Sensors
Authors: M. Umar B. Niazi, Michelle S. Chong, Amr Alanwar, Karl H. Johansson
Abstract: Set-based state estimation provides guaranteed state inclusion certificates that are crucial for the safety verification of dynamical systems. However, when system sensors are subject to cyberattacks, maintaining both safety and security guarantees becomes a fundamental challenge that existing point-based secure state estimation methods cannot adequately address due to their inherent inability to provide state inclusion certificates. This paper introduces a novel approach that simultaneously ensures safety guarantees through guaranteed state inclusion and security guarantees against sensor attacks, without imposing conservative restrictions on system operation. We propose a Secure Set-based State Estimation (S3E) algorithm that maintains the true system state within the estimated set under sensor attacks, provided the initialization set contains the initial state and the system remains observable from the uncompromised sensor subset. The algorithm gives the estimated set as a collection of constrained zonotopes (agreement sets), which can be employed as robust certificates for verifying whether the system adheres to safety constraints. Furthermore, we demonstrate that the estimated set remains unaffected by attack signals of sufficiently large magnitude and also establish sufficient conditions for attack detection, identification, and filtering. This compels the attacker to only inject signals of small magnitudes to evade detection, thus preserving the accuracy of the estimated set. To address the computational complexity of the algorithm, we offer several strategies for complexity-performance trade-offs. The efficacy of the proposed algorithm is illustrated through several examples, including its application to a three-story building model.

Paper number 57:
Title: MTS-Net: Dual-Enhanced Positional Multi-Head Self-Attention for 3D CT Diagnosis of May-Thurner Syndrome
Authors: Yixin Huang, Yiqi Jin, Ke Tao, Kaijian Xia, Jianfeng Gu, Lei Yu, Lan Du, Cunjian Chen
Abstract: May-Thurner Syndrome (MTS) is a vascular condition that affects over 20\% of the population and significantly increases the risk of iliofemoral deep venous thrombosis. Accurate and early diagnosis of MTS using computed tomography (CT) remains a clinical challenge due to the subtle anatomical compression and variability across patients. In this paper, we propose MTS-Net, an end-to-end 3D deep learning framework designed to capture spatial-temporal patterns from CT volumes for reliable MTS diagnosis. MTS-Net builds upon 3D ResNet-18 by embedding a novel dual-enhanced positional multi-head self-attention (DEP-MHSA) module into the Transformer encoder of the network's final stages. The proposed DEP-MHSA employs multi-scale convolution and integrates positional embeddings into both attention weights and residual paths, enhancing spatial context preservation, which is crucial for identifying venous compression. To validate our approach, we curate the first publicly available dataset for MTS, MTS-CT, containing over 747 gender-balanced subjects with standard and enhanced CT scans. Experimental results demonstrate that MTS-Net achieves average 0.79 accuracy, 0.84 AUC, and 0.78 F1-score, outperforming baseline models including 3D ResNet, DenseNet-BC, and BabyNet. Our work not only introduces a new diagnostic architecture for MTS but also provides a high-quality benchmark dataset to facilitate future research in automated vascular syndrome detection. We make our code and dataset publicly available at:this https URL.

Paper number 58:
Title: Regularized autoregressive modeling and its application to audio signal reconstruction
Authors: Ondřej Mokrý, Pavel Rajmic
Abstract: Autoregressive (AR) modeling is invaluable in signal processing, in particular in speech and audio fields. Attempts in the literature can be found that regularize or constrain either the time-domain signal values or the AR coefficients, which is done for various reasons, including the incorporation of prior information or numerical stabilization. Although these attempts are appealing, an encompassing and generic modeling framework is still missing. We propose such a framework and the related optimization problem and algorithm. We discuss the computational demands of the algorithm and explore the effects of various improvements on its convergence speed. In the experimental part, we demonstrate the usefulness of our approach on the audio declipping and the audio dequantization problems. We compare its performance against the state-of-the-art methods and demonstrate the competitiveness of the proposed method, especially for mildly clipped signals. The evaluation is extended by considering a heuristic algorithm of generalized linear prediction (GLP), a strong competitor which has only been presented as a patent and is new in the scientific community.

Paper number 59:
Title: Bidding in Ancillary Service Markets: An Analytical Approach Using Extreme Value Theory
Authors: Torine Reed Herstad, Jalal Kazempour, Lesia Mitridati, Bert Zwart
Abstract: To enable the participation of stochastic distributed energy resources in ancillary service markets, the Danish transmission system operator, Energinet, mandates that flexibility providers satisfy a minimum 90% reliability requirement for reserve bids. This paper examines the bidding strategy of an electric vehicle aggregator under this regulation and develops a chance-constrained optimization model. In contrast to conventional sample-based approaches that demand large datasets to capture uncertainty, we propose an analytical reformulation that leverages extreme value theory to characterize the tail behavior of flexibility distributions. A case study with real-world charging data from 1400 residential electric vehicles in Denmark demonstrates that the analytical solution improves out-of-sample reliability, reducing bid violation rates by up to 8% relative to a sample-based benchmark. The method is also computationally more efficient, solving optimization problems up to 4.8 times faster while requiring substantially fewer samples to ensure compliance. Moreover, the proposed approach enables the construction of feasible bids with reliability levels as high as 99.95%, which would otherwise require prohibitively large scenario sets under the sample-based method. Beyond its computational and reliability advantages, the framework also provides actionable insights into how reliability thresholds influence aggregator bidding behavior and market participation. This study establishes a regulation-compliant, tractable, and risk-aware bidding methodology for stochastic flexibility aggregators, enhancing both market efficiency and power system security.

Paper number 60:
Title: Towards Understanding of Frequency Dependence on Sound Event Detection
Authors: Hyeonuk Nam, Seong-Hu Kim, Deokki Min, Byeong-Yun Ko, Yong-Hwa Park
Abstract: In this work, we conduct an in-depth analysis of two frequency-dependent methods for sound event detection (SED): FilterAugment and frequency dynamic convolution (FDY conv). The goal is to better understand their characteristics and behaviors in the context of SED. While SED has been rapidly advancing through the adoption of various deep learning techniques from other pattern recognition fields, such adopted techniques are often not suitable for SED. To address this issue, two frequency-dependent SED methods were previously proposed: FilterAugment, a data augmentation randomly weighting frequency bands, and FDY conv, an architecture applying frequency adaptive convolution kernels. These methods have demonstrated superior performance in SED, and we aim to further analyze their detailed effectiveness and characteristics in SED. We compare class-wise performance to find out specific pros and cons of FilterAugment and FDY conv. We apply Gradient-weighted Class Activation Mapping (Grad-CAM), which highlights time-frequency region that is more inferred by the model, on SED models with and without frequency masking and two types of FilterAugment to observe their detailed characteristics. We propose simpler frequency dependent convolution methods and compare them with FDY conv to further understand which components of FDY conv affects SED performance. Lastly, we apply PCA to show how FDY conv adapts dynamic kernel across frequency dimensions on different sound event classes. The results and discussions demonstrate that frequency dependency plays a significant role in sound event detection and further confirms the effectiveness of frequency dependent methods on SED.

Paper number 61:
Title: PGAD: Prototype-Guided Adaptive Distillation for Multi-Modal Learning in AD Diagnosis
Authors: Yanfei Li, Teng Yin, Wenyi Shang, Jingyu Liu, Xi Wang, Kaiyang Zhao
Abstract: Missing modalities pose a major issue in Alzheimer's Disease (AD) diagnosis, as many subjects lack full imaging data due to cost and clinical constraints. While multi-modal learning leverages complementary information, most existing methods train only on complete data, ignoring the large proportion of incomplete samples in real-world datasets like ADNI. This reduces the effective training set and limits the full use of valuable medical data. While some methods incorporate incomplete samples, they fail to effectively address inter-modal feature alignment and knowledge transfer challenges under high missing rates. To address this, we propose a Prototype-Guided Adaptive Distillation (PGAD) framework that directly incorporates incomplete multi-modal data into training. PGAD enhances missing modality representations through prototype matching and balances learning with a dynamic sampling strategy. We validate PGAD on the ADNI dataset with varying missing rates (20%, 50%, and 70%) and demonstrate that it significantly outperforms state-of-the-art approaches. Ablation studies confirm the effectiveness of prototype matching and adaptive sampling, highlighting the potential of our framework for robust and scalable AD diagnosis in real-world clinical settings.

Paper number 62:
Title: TAGS: 3D Tumor-Adaptive Guidance for SAM
Authors: Sirui Li, Linkai Peng, Zheyuan Zhang, Gorkem Durak, Ulas Bagci
Abstract: Foundation models (FMs) such as CLIP and SAM have recently shown great promise in image segmentation tasks, yet their adaptation to 3D medical imaging-particularly for pathology detection and segmentation-remains underexplored. A critical challenge arises from the domain gap between natural images and medical volumes: existing FMs, pre-trained on 2D data, struggle to capture 3D anatomical context, limiting their utility in clinical applications like tumor segmentation. To address this, we propose an adaptation framework called TAGS: Tumor Adaptive Guidance for SAM, which unlocks 2D FMs for 3D medical tasks through multi-prompt fusion. By preserving most of the pre-trained weights, our approach enhances SAM's spatial feature extraction using CLIP's semantic insights and anatomy-specific prompts. Extensive experiments on three open-source tumor segmentation datasets prove that our model surpasses the state-of-the-art medical image segmentation models (+46.88% over nnUNet), interactive segmentation frameworks, and other established medical FMs, including SAM-Med2D, SAM-Med3D, SegVol, Universal, 3D-Adapter, and SAM-B (at least +13% over them). This highlights the robustness and adaptability of our proposed framework across diverse medical segmentation tasks.

Paper number 63:
Title: Future Deployment and Flexibility of Distributed Energy Resources in the Distribution Grids of Switzerland
Authors: Lorenzo Zapparoli, Alfredo Oneto, María Parajeles Herrera, Blazhe Gjorgiev, Gabriela Hug, Giovanni Sansavini
Abstract: The decarbonization goals worldwide drive the energy transition of power distribution grids, which operate under increasingly volatile conditions and closer to their technical limits. In this context, localized operational data with high temporal and spatial resolution is essential for their effective planning and regulation. Nevertheless, information on grid-connected distributed energy resources, such as electric vehicles, photovoltaic systems, and heat pumps, is often fragmented, inconsistent, and unavailable. This work introduces a comprehensive database of distributed energy resources and non-controllable loads allocated in Switzerland's medium- and low-voltage distribution grid models, covering over 2 million points of connection. Remarkably, this data specifies the flexibility capabilities of the controllable devices, with a set of projections aligned with national forecasts for 2030, 2040, and 2050. The database supports studies on flexibility provision of distributed energy resources, distribution grid resilience, and national energy policy, among other topics. Importantly, its modular structure allows users to extract national- and local-scale information across medium- and low-voltage systems, enabling broad applicability across locations.

Paper number 64:
Title: Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems
Authors: Kesav Kaza, Ramachandran Anantharaman, Rahul Meshram
Abstract: This paper introduces a two-timescale hierarchical decentralized control architecture for Cyber-Physical Systems (CPS). The system consists of a global controller (GC), and N local controllers (LCs). The GC operates at a slower timescale, imposing budget constraints on the actions of LCs, which function at a faster timescale. Applications can be found in energy grid planning, wildfire management, and other decentralized resource allocation problems. We propose and analyze two optimization frameworks for this setting: COpt and FOpt. In COpt, both GC and LCs together optimize infinite-horizon discounted rewards, while in FOpt the LCs optimize finite-horizon episodic rewards, and the GC optimizes infinite-horizon rewards. Although both frameworks share identical reward functions, their differing horizons can lead to different optimal policies. In particular, FOpt grants greater autonomy to LCs by allowing their policies to be determined only by local objectives, unlike COpt. To our knowledge, these frameworks have not been studied in the literature. We establish the formulations, prove the existence of optimal policies, and prove the convergence of their value iteration algorithms. We further show that COpt always achieves a higher value function than FOpt and derive explicit bounds on their difference. Finally, we establish a set of sufficient structural conditions under which the two frameworks become equivalent.

Paper number 65:
Title: Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN
Authors: Abdelaziz Salama, Zeinab Nezami, Mohammed M. H. Qazzaz, Maryam Hafeez, Syed Ali Raza Zaidi
Abstract: The deployment of AI agents within legacy Radio Access Network (RAN) infrastructure poses significant safety and reliability challenges for future 6G networks. This paper presents a novel Edge AI framework for autonomous network optimisation in Open RAN environments, addressing these challenges through three core innovations: (1) a persona-based multi-tools architecture enabling distributed, context-aware decision-making; (2) proactive anomaly detection agent powered by traffic predictive tool; and (3) a safety, aligned reward mechanism that balances performance with operational stability. Integrated into the RAN Intelligent Controller (RIC), our framework leverages multimodal data fusion, including network KPIs, a traffic prediction model, and external information sources, to anticipate and respond to dynamic network conditions. Extensive evaluation using realistic 5G scenarios demonstrates that the edge framework achieves zero network outages under high-stress conditions, compared to 8.4% for traditional fixed-power networks and 3.3% for large language model (LLM) agent-based approaches, while maintaining near real-time responsiveness and consistent QoS. These results establish that, when equipped with the right tools and contextual awareness, AI agents can be safely and effectively deployed in critical network infrastructure, laying the framework for intelligent and autonomous 5G and beyond network operations.

Paper number 66:
Title: RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach
Authors: Bile Peng, Karl-Ludwig Besser, Shanpu Shen, Finn Siegismund-Poschmann, Ramprasad Raghunath, Daniel M. Mittleman, Vahid Jamali, Eduard A. Jorswieck
Abstract: Non-orthogonal multiple access (NOMA) is a promising multiple access technique. Its performance depends strongly on the wireless channel property, which can be enhanced by reconfigurable intelligent surfaces (RISs). In this paper, we jointly optimize base station (BS) precoding and RIS configuration with unsupervised machine learning (ML), which looks for the optimal solution autonomously. In particular, we propose a dedicated neural network (NN) architecture RISnet inspired by domain knowledge in communication. Compared to state-of-the-art, the proposed approach combines analytical optimal BS precoding and ML-enabled RIS, has a high scalability to control more than 1000 RIS elements, has a low requirement for channel state information (CSI) in input, and addresses the mutual coupling between RIS elements. Beyond the considered problem, this work is an early contribution to domain knowledge enabled ML, which exploit the domain expertise of communication systems to design better approaches than general ML methods.

Paper number 67:
Title: Robust Optimization for Movable Antenna-aided Cell-Free ISAC with Time Synchronization Errors
Authors: Yue Xiu, Yang Zhao, Ran Yang, Wanting Lyu, Dusit Niyato, Dong In Kim, Guangyi Liu, Ning Wei
Abstract: The cell-free integrated sensing and communication (CF-ISAC) system, which effectively mitigates intra-cell interference and provides precise sensing accuracy, is a promising technology for future 6G networks. However, to fully capitalize on the potential of CF-ISAC, accurate time synchronization (TS) between access points (APs) is critical. Due to the limitations of current synchronization technologies, TS errors have become a significant challenge in the development of the CF-ISAC system. In this paper, we propose a novel CF-ISAC architecture based on movable antennas (MAs), which exploits spatial diversity to enhance communication rates, maintain sensing accuracy, and reduce the impact of TS errors. We formulate a worst-case sensing accuracy optimization problem for TS errors to address this challenge, deriving the worst-case Cramér-Rao lower bound (CRLB). Subsequently, we develop a joint optimization framework for AP beamforming and MA positions to satisfy communication rate constraints while improving sensing accuracy. A robust optimization framework is designed for the highly complex and non-convex problem. Specifically, we employ manifold optimization (MO) to solve the worst-case sensing accuracy optimization problem. Then, we propose an MA-enabled meta-reinforcement learning (MA-MetaRL) to design optimization variables while satisfying constraints on MA positions, communication rate, and transmit power, thereby improving sensing accuracy. The simulation results demonstrate that the proposed robust optimization algorithm significantly improves the accuracy of the detection and is strong against TS errors. Moreover, compared to conventional fixed position antenna (FPA) technologies, the proposed MA-aided CF-ISAC architecture achieves higher system capacity, thus validating its effectiveness.

Paper number 68:
Title: Towards Diagnostic Quality Flat-Panel Detector CT Imaging Using Diffusion Models
Authors: Hélène Corbaz, Anh Nguyen, Victor Schulze-Zachau, Paul Friedrich, Alicia Durrer, Florentin Bieder, Philippe C. Cattin, Marios N Psychogios
Abstract: Patients undergoing a mechanical thrombectomy procedure usually have a multi-detector CT (MDCT) scan before and after the intervention. The image quality of the flat panel detector CT (FDCT) present in the intervention room is generally much lower than that of a MDCT due to significant artifacts. However, using only FDCT images could improve patient management as the patient would not need to be moved to the MDCT room. Several studies have evaluated the potential use of FDCT imaging alone and the time that could be saved by acquiring the images before and/or after the intervention only with the FDCT. This study proposes using a denoising diffusion probabilistic model (DDPM) to improve the image quality of FDCT scans, making them comparable to MDCT scans. Clinicans evaluated FDCT, MDCT, and our model's predictions for diagnostic purposes using a questionnaire. The DDPM eliminated most artifacts and improved anatomical visibility without reducing bleeding detection, provided that the input FDCT image quality is not too low. Our code can be found on github.

Paper number 69:
Title: Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution
Authors: Tainyi Zhang, Zheng-Peng Duan, Peng-Tao Jiang, Bo Li, Ming-Ming Cheng, Chun-Le Guo, Chongyi Li
Abstract: Diffusion-based real-world image super-resolution (Real-ISR) methods have demonstrated impressive performance. To achieve efficient Real-ISR, many works employ Variational Score Distillation (VSD) to distill pre-trained stable-diffusion (SD) model for one-step SR with a fixed timestep. However, due to the different noise injection timesteps, the SD will perform different generative priors. Therefore, a fixed timestep is difficult for these methods to fully leverage the generative priors in SD, leading to suboptimal performance. To address this, we propose a Time-Aware one-step Diffusion Network for Real-ISR (TADSR). We first introduce a Time-Aware VAE Encoder, which projects the same image into different latent features based on timesteps. Through joint dynamic variation of timesteps and latent features, the student model can better align with the input pattern distribution of the pre-trained SD, thereby enabling more effective utilization of SD's generative capabilities. To better activate the generative prior of SD at different timesteps, we propose a Time-Aware VSD loss that bridges the timesteps of the student model and those of the teacher model, thereby producing more consistent generative prior guidance conditioned on timesteps. Additionally, though utilizing the generative prior in SD at different timesteps, our method can naturally achieve controllable trade-offs between fidelity and realism by changing the timestep condition. Experimental results demonstrate that our method achieves both state-of-the-art performance and controllable SR results with only a single step.

Paper number 70:
Title: A Synoptic Review of High-Frequency Oscillations as a Biomarker in Neurodegenerative Disease
Authors: Samin Yaser, Mahad Ali, Yang Jiang, VP Nguyen, Jing Xiang, Laura J. Brattain
Abstract: High Frequency Oscillations (HFOs), rapid bursts of brain activity above 80 Hz, have emerged as a highly specific biomarker for epileptogenic tissue. Recent evidence suggests that HFOs are also present in Alzheimer's Disease (AD), reflecting underlying network hyperexcitability and offering a promising, noninvasive tool for early diagnosis and disease tracking. This synoptic review provides a comprehensive analysis of publicly available electroencephalography (EEG) datasets relevant to HFO research in neurodegenerative disorders. We conducted a bibliometric analysis of 1,222 articles, revealing a significant and growing research interest in HFOs, particularly within the last ten years. We then systematically profile and compare key public datasets, evaluating their participant cohorts, data acquisition parameters, and accessibility, with a specific focus on their technical suitability for HFO analysis. Our comparative synthesis highlights critical methodological heterogeneity across datasets, particularly in sampling frequency and recording paradigms, which poses challenges for cross-study validation, but also offers opportunities for robustness testing. By consolidating disparate information, clarifying nomenclature, and providing a detailed methodological framework, this review serves as a guide for researchers aiming to leverage public data to advance the role of HFOs as a cross-disease biomarker for AD and related conditions.

Paper number 71:
Title: From Optimization to Control: Quasi Policy Iteration
Authors: Mohammad Amin Sharifi Kolarijani, Peyman Mohajerin Esfahani
Abstract: Recent control algorithms for Markov decision processes (MDPs) have been designed using an implicit analogy with well-established optimization algorithms. In this paper, we adopt the quasi-Newton method (QNM) from convex optimization to introduce a novel control algorithm coined as quasi-policy iteration (QPI). In particular, QPI is based on a novel approximation of the ``Hessian'' matrix in the policy iteration algorithm, which exploits two linear structural constraints specific to MDPs and allows for the incorporation of prior information on the transition probability kernel. While the proposed algorithm has the same computational complexity as value iteration, it exhibits an empirical convergence behavior similar to that of QNM with a low sensitivity to the discount factor.

Paper number 72:
Title: Training with Explanations Alone: A New Paradigm to Prevent Shortcut Learning
Authors: Pedro R. A. S. Bassi, Haydr A. H. Ali, Andrea Cavalli, Sergio Decherchi
Abstract: Application of Artificial Intelligence (AI) in critical domains, like the medical one, is often hampered by shortcut learning, which hinders AI generalization to diverse hospitals and patients. Shortcut learning can be caused, for example, by background biases -- features in image backgrounds that are spuriously correlated to classification labels (e.g., words in X-rays). To mitigate the influence of image background and foreground bias on AI, we introduce a new training paradigm, dubbed Training with Explanations Alone (TEA). TEA trains a classifier (TEA student) only by making its explanation heatmaps match target heatmaps from a larger teacher model. By learning from its explanation heatmaps, the TEA student pays attention to the same image features as the teacher. For example, a teacher uses a large segmenter to remove image backgrounds before classification, thus ignoring background bias. By learning from the teacher's explanation heatmaps, the TEA student learns to also ignore backgrounds -- but it does not need a segmenter. With different teachers, the TEA student can also resist bias in the image foreground. Surprisingly, by training with heatmaps alone the student output naturally matches the teacher output -- with no loss function applied to the student output. We compared the TEA student against 14 state-of-the-art methods in 5 datasets with strong background or foreground bias, including Waterbirds and an X-Ray dataset for COVID-19 and pneumonia classification. The TEA student had better resistance to bias, strongly surpassing state-of-the-art methods, and generalizing better to hospitals not seen in training.

Paper number 73:
Title: Suppressing Beam Squint Effect For Near-Field Wideband Communication Through Movable Antennas
Authors: Yanze Zhu, Qingqing Wu, Yang Liu, Qingjiang Shi, Wen Chen
Abstract: In this correspondence, we study deploying movable antenna (MA) array in a wideband multiple-input-single-output (MISO) communication system, where near-field (NF) channel model is considered. To alleviate beam squint effect, we propose to maximize the minimum analog beamforming gain across the entire wideband spectrum by appropriately adjusting MAs' positions, which is a highly challenging task. By introducing a slack variable and adopting the cutting-the-edge smoothed-gradient-descent-ascent (SGDA) method, we develop algorithms to resolve the aforementioned challenge. Numerical results verify the effectiveness of our proposed algorithms and demonstrate the benefit of utilizing MA array to mitigate beam squint effect in NF wideband system.

Paper number 74:
Title: Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks
Authors: Ferdous Pervej, Minseok Choi, Andreas F. Molisch
Abstract: While federated learning (FL) is a widely popular distributed machine learning (ML) strategy that protects data privacy, time-varying wireless network parameters and heterogeneous configurations of the wireless devices pose significant challenges. Although the limited radio and computational resources of the network and the clients, respectively, are widely acknowledged, two critical yet often ignored aspects are (a) wireless devices can only dedicate a small chunk of their limited storage for the FL task and (b) new training samples may arrive in an online manner in many practical wireless applications. Therefore, we propose a new FL algorithm called online-score-aided federated learning (OSAFL), specifically designed to learn tasks relevant to wireless applications under these practical considerations. Since clients' local training steps differ under resource constraints, which may lead to client drift under statistically heterogeneous data distributions, we leverage normalized gradient similarities and exploit weighting clients' updates based on optimized scores that facilitate the convergence rate of the proposed OSAFL algorithm without incurring any communication overheads to the clients or requiring any statistical data information from them. We theoretically show how the new factors, i.e., online score and local data distribution shifts, affect the convergence bound and derive the necessary conditions for a sublinear convergence rate. Our extensive simulation results on two different tasks with multiple popular ML models validate the effectiveness of the proposed OSAFL algorithm compared to modified state-of-the-art FL baselines.

Paper number 75:
Title: Human-Inspired Computing for Robust and Efficient Audio-Visual Speech Recognition
Authors: Qianhui Liu, Jiadong Wang, Yang Wang, Xin Yang, Gang Pan, Haizhou Li
Abstract: Humans naturally perform audiovisual speech recognition (AVSR), enhancing the accuracy and robustness by integrating auditory and visual information. Spiking neural networks (SNNs), which mimic the brain's information-processing mechanisms, are well-suited for emulating the human capability of AVSR. Despite their potential, research on SNNs for AVSR is scarce, with most existing audio-visual multimodal methods focused on object or digit recognition. These models simply integrate features from both modalities, neglecting their unique characteristics and interactions. Additionally, they often rely on future information for current processing, which increases recognition latency and limits real-time applicability. Inspired by human speech perception, this paper proposes a novel human-inspired SNN named HI-AVSNN for AVSR, incorporating three key characteristics: cueing interaction, causal processing and spike activity. For cueing interaction, we propose a visual-cued auditory attention module (VCA2M) that leverages visual cues to guide attention to auditory features. We achieve causal processing by aligning the SNN's temporal dimension with that of visual and auditory features and applying temporal masking to utilize only past and current information. To implement spike activity, in addition to using SNNs, we leverage the event camera to capture lip movement as spikes, mimicking the human retina and providing efficient visual data. We evaluate HI-AVSNN on an audiovisual speech recognition dataset combining the DVS-Lip dataset with its corresponding audio samples. Experimental results demonstrate the superiority of our proposed fusion method, outperforming existing audio-visual SNN fusion methods and achieving a 2.27% improvement in accuracy over the only existing SNN-based AVSR method.

Paper number 76:
Title: Machine Learning for Asymptomatic Ratoon Stunting Disease Detection With Freely Available Satellite Based Multispectral Imaging
Authors: Ethan Kane Waters, Carla Chia-ming Chen, Mostafa Rahimi Azghadi
Abstract: Disease detection in sugarcane, particularly the identification of asymptomatic infectious diseases such as Ratoon Stunting Disease (RSD), is critical for effective crop management. This study employed various machine learning techniques to detect the presence of RSD in different sugarcane varieties, using vegetation indices derived from freely available satellite-based spectral data. Our results show that the Support Vector Machine with a Radial Basis Function Kernel (SVM-RBF) was the most effective algorithm, achieving classification accuracy between 85.64% and 96.55%, depending on the variety. Gradient Boosting and Random Forest also demonstrated high performance achieving accuracy between 83.33% to 96.55%, while Logistic Regression and Quadratic Discriminant Analysis showed variable results across different varieties. The inclusion of sugarcane variety and vegetation indices was important in the detection of RSD. This agreed with what was identified in the current literature. Our study highlights the potential of satellite-based remote sensing as a cost-effective and efficient method for large-scale sugarcane disease detection alternative to traditional manual laboratory testing methods.

Paper number 77:
Title: Analysis and Synthesis Denoisers for Forward-Backward Plug-and-Play Algorithms
Authors: Matthieu Kowalski, Benoît Malézieux, Thomas Moreau, Audrey Repetti
Abstract: In this work we study the behavior of the forward-backward (FB) algorithm when the proximity operator is replaced by a sub-iterative procedure to approximate a Gaussian denoiser, in a Plug-and-Play (PnP) fashion. In particular, we consider both analysis and synthesis Gaussian denoisers within a dictionary framework, obtained by unrolling dual-FB iterations or FB iterations, respectively. We analyze the associated minimization problems as well as the asymptotic behavior of the resulting FB-PnP iterations. In particular, we show that the synthesis Gaussian denoising problem can be viewed as a proximity operator. For each case, analysis and synthesis, we show that the FB-PnP algorithms solve the same problem whether we use only one or an infinite number of sub-iteration to solve the denoising problem at each iteration. To this aim, we show that each "one sub-iteration" strategy within the FB-PnP can be interpreted as a primal-dual algorithm when a warm-restart strategy is used. We further present similar results when using a Moreau-Yosida smoothing of the global problem, for an arbitrary number of sub-iterations. Finally, we provide numerical simulations to illustrate our theoretical results. In particular we first consider a toy compressive sensing example, as well as an image restoration problem in a deep dictionary framework.

Paper number 78:
Title: DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging
Authors: Mohamed Youssef, Jian Peng, Oliver Bimber
Abstract: Access to below-canopy volumetric vegetation data is crucial for understanding ecosystem dynamics. We address the long-standing limitation of remote sensing to penetrate deep into dense canopy layers. LiDAR and radar are currently considered the primary options for measuring 3D vegetation structures, while cameras can only extract the reflectance and depth of top layers. Using conventional, high-resolution aerial images, our approach allows sensing deep into self-occluding vegetation volumes, such as forests. It is similar in spirit to the imaging process of wide-field microscopy, but can handle much larger scales and strong occlusion. We scan focal stacks by synthetic-aperture imaging with drones and reduce out-of-focus signal contributions using pre-trained 3D convolutional neural networks with mean squared error (MSE) as the loss function. The resulting volumetric reflectance stacks contain low-frequency representations of the vegetation volume. Combining multiple reflectance stacks from various spectral channels provides insights into plant health, growth, and environmental conditions throughout the entire vegetation volume. Compared with simulated ground truth, our correction leads to ~x7 average improvements (min: ~x2, max: ~x12) for forest densities of 220 trees/ha - 1680 trees/ha. In our field experiment, we achieved an MSE of 0.05 when comparing with the top-vegetation layer that was measured with classical multispectral aerial imaging.

Paper number 79:
Title: End-to-End Action Segmentation Transformer
Authors: Tieqiao Wang, Sinisa Todorovic
Abstract: Most recent work on action segmentation relies on pre-computed frame features from models trained on other tasks and typically focuses on framewise encoding and labeling without explicitly modeling action segments. To overcome these limitations, we introduce the End-to-End Action Segmentation Transformer (EAST), which processes raw video frames directly -- eliminating the need for pre-extracted features and enabling true end-to-end training. Our contributions are as follows: (1) a lightweight adapter design for effective fine-tuning of large backbones; (2) an efficient segmentation-by-detection framework for leveraging action proposals predicted over a coarsely downsampled video; and (3) a novel action-proposal-based data augmentation strategy. EAST achieves SOTA performance on standard benchmarks, including GTEA, 50Salads, Breakfast, and Assembly-101.

Paper number 80:
Title: NAPER: Fault Protection for Real-Time Resource-Constrained Deep Neural Networks
Authors: Rian Adam Rajagede, Muhammad Husni Santriaji, Muhammad Arya Fikriansyah, Hilal Hudan Nuha, Yanjie Fu, Yan Solihin
Abstract: Fault tolerance in Deep Neural Networks (DNNs) deployed on resource-constrained systems presents unique challenges for high-accuracy applications with strict timing requirements. Memory bit-flips can severely degrade DNN accuracy, while traditional protection approaches like Triple Modular Redundancy (TMR) often sacrifice accuracy to maintain reliability, creating a three-way dilemma between reliability, accuracy, and timeliness. We introduce NAPER, a novel protection approach that addresses this challenge through ensemble learning. Unlike conventional redundancy methods, NAPER employs heterogeneous model redundancy, where diverse models collectively achieve higher accuracy than any individual model. This is complemented by an efficient fault detection mechanism and a real-time scheduler that prioritizes meeting deadlines by intelligently scheduling recovery operations without interrupting inference. Our evaluations demonstrate NAPER's superiority: 40% faster inference in both normal and fault conditions, maintained accuracy 4.2% higher than TMR-based strategies, and guaranteed uninterrupted operation even during fault recovery. NAPER effectively balances the competing demands of accuracy, reliability, and timeliness in real-time DNN applications

Paper number 81:
Title: Towards a Spatiotemporal Fusion Approach to Precipitation Nowcasting
Authors: Felipe Curcio, Pedro Castro, Augusto Fonseca, Rafaela Castro, Raquel Franco, Eduardo Ogasawara, Victor Stepanenko, Fabio Porto, Mariza Ferro, Eduardo Bezerra
Abstract: With the increasing availability of meteorological data from various sensors, numerical models and reanalysis products, the need for efficient data integration methods has become paramount for improving weather forecasts and hydrometeorological studies. In this work, we propose a data fusion approach for precipitation nowcasting by integrating data from meteorological and rain gauge stations in Rio de Janeiro metropolitan area with ERA5 reanalysis data and GFS numerical weather prediction. We employ the spatiotemporal deep learning architecture called STConvS2S, leveraging a structured dataset covering a 9 x 11 grid. The study spans from January 2011 to October 2024, and we evaluate the impact of integrating three surface station systems. Among the tested configurations, the fusion-based model achieves an F1-score of 0.2033 for forecasting heavy precipitation events (greater than 25 mm/h) at a one-hour lead time. Additionally, we present an ablation study to assess the contribution of each station network and propose a refined inference strategy for precipitation nowcasting, integrating the GFS numerical weather prediction (NWP) data with in-situ observations.

Paper number 82:
Title: Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles
Authors: Ferdous Pervej, Richeng Jin, Md Moin Uddin Chowdhury, Simran Singh, İsmail Güvenç, Huaiyu Dai
Abstract: Privacy-preserving distributed machine learning (ML) and aerial connected vehicle (ACV)-assisted edge computing have drawn significant attention lately. Since the onboard sensors of ACVs can capture new data as they move along their trajectories, the continual arrival of such 'newly' sensed data leads to online learning and demands carefully crafting the trajectories. Besides, as typical ACVs are inherently resource-constrained, computation- and communication-efficient ML solutions are needed. Therefore, we propose a computation- and communication-efficient online aerial federated learning (2CEOAFL) algorithm to take the benefits of continual sensed data and limited onboard resources of the ACVs. In particular, considering independently owned ACVs act as selfish data collectors, we first model their trajectories according to their respective time-varying data distributions. We then propose a 2CEOAFL algorithm that allows the flying ACVs to (a) prune the received dense ML model to make it shallow, (b) train the pruned model, and (c) probabilistically quantize and offload their trained accumulated gradients to the central server (CS). Our extensive simulation results show that the proposed 2CEOAFL algorithm delivers comparable performances to its non-pruned and nonquantized, hence, computation- and communication-inefficient counterparts.

Paper number 83:
Title: mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks
Authors: Luel Hagos Beyene, Vivek Verma, Min Ma, Jesujoba O. Alabi, Fabian David Schmidt, Joyce Nakatumba-Nabende, David Ifeoluwa Adelani
Abstract: Large Language models (LLMs) have demonstrated impressive performance on a wide range of tasks, including in multimodal settings such as speech. However, their evaluation is often limited to English and a few high-resource languages. For low-resource languages, there is no standardized evaluation benchmark. In this paper, we address this gap by introducing mSTEB, a new benchmark to evaluate the performance of LLMs on a wide range of tasks covering language identification, text classification, question answering, and translation tasks on both speech and text modalities. We evaluated the performance of leading LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in performance between high-resource and low-resource languages, especially for languages spoken in Africa and Americas/Oceania. Our findings show that more investment is needed to address their under-representation in LLMs coverage.

Paper number 84:
Title: LABNet: A Lightweight Attentive Beamforming Network for Ad-hoc Multichannel Microphone Invariant Real-Time Speech Enhancement
Authors: Haoyin Yan, Jie Zhang, Chengqian Jiang, Shuang Zhang
Abstract: Multichannel speech enhancement (SE) aims to restore clean speech from noisy measurements by leveraging spatiotemporal signal features. In ad-hoc array conditions, microphone invariance (MI) requires systems to handle different microphone numbers and array geometries. From a practical perspective, multichannel recordings inevitably increase the computational burden for edge-device applications, highlighting the necessity of lightweight and efficient deployments. In this work, we propose a lightweight attentive beamforming network (LABNet) to integrate MI in a low-complexity real-time SE system. We design a three-stage framework for efficient intra-channel modeling and inter-channel interaction. A cross-channel attention module is developed to aggregate features from each channel selectively. Experimental results demonstrate our LABNet achieves impressive performance with ultra-light resource overhead while maintaining the MI, indicating great potential for ad-hoc array processing. The code is available:this https URL

Paper number 85:
Title: Step-Audio 2 Technical Report
Authors: Boyong Wu, Chao Yan, Chen Hu, Cheng Yi, Chengli Feng, Fei Tian, Feiyu Shen, Gang Yu, Haoyang Zhang, Jingbei Li, Mingrui Chen, Peng Liu, Wang You, Xiangyu Tony Zhang, Xingyuan Li, Xuerui Yang, Yayue Deng, Yechang Huang, Yuxin Li, Yuxin Zhang, Zhao You, Brian Li, Changyi Wan, Hanpeng Hu, Jiangjie Zhen, Siyu Chen, Song Yuan, Xuelin Zhang, Yimin Jiang, Yu Zhou, Yuxiang Yang, Bingxin Li, Buyun Ma, Changhe Song, Dongqing Pang, Guoqiang Hu, Haiyang Sun, Kang An, Na Wang, Shuli Gao, Wei Ji, Wen Li, Wen Sun, Xuan Wen, Yong Ren, Yuankai Ma, Yufan Lu, Bin Wang, Bo Li, Changxin Miao, Che Liu, Chen Xu, Dapeng Shi, Dingyuan Hu, Donghang Wu, Enle Liu, Guanzhe Huang, Gulin Yan, Han Zhang, Hao Nie, Haonan Jia, Hongyu Zhou, Jianjian Sun, Jiaoren Wu, Jie Wu, Jie Yang, Jin Yang, Junzhe Lin, Kaixiang Li, Lei Yang, Liying Shi, Li Zhou, Longlong Gu, Ming Li, Mingliang Li, Mingxiao Li, Nan Wu, Qi Han, Qinyuan Tan, Shaoliang Pang, Shengjie Fan, Siqi Liu, Tiancheng Cao, Wanying Lu, Wenqing He, Wuxun Xie, Xu Zhao, Xueqi Li, Yanbo Yu, Yang Yang, Yi Liu, Yifan Lu, Yilei Wang, Yuanhao Ding, Yuanwei Liang, Yuanwei Lu, Yuchu Luo, Yuhe Yin, Yumeng Zhan, Yuxiang Zhang
Abstract: This paper presents Step-Audio 2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automatic speech recognition (ASR) and audio understanding. To facilitate genuine end-to-end speech conversation, Step-Audio 2 incorporates the generation of discrete audio tokens into language modeling, significantly enhancing its responsiveness to paralinguistic information such as speaking styles and emotions. To effectively leverage the rich textual and acoustic knowledge in real-world data, Step-Audio 2 integrates retrieval-augmented generation (RAG) and is able to call external tools such as web search to mitigate hallucination and audio search to switch timbres. Trained on millions of hours of speech and audio data, Step-Audio 2 delivers intelligence and expressiveness across diverse conversational scenarios. Evaluation results demonstrate that Step-Audio 2 achieves state-of-the-art performance on various audio understanding and conversational benchmarks compared to other open-source and commercial solutions. Please visit this https URL for more information.

Paper number 86:
Title: From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving
Authors: Antonio Guillen-Perez
Abstract: Learning robust driving policies from large-scale, real-world datasets is a central challenge in autonomous driving, as online data collection is often unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward approach to imitation learning, policies trained with BC are notoriously brittle and suffer from compounding errors in closed-loop execution. This work presents a comprehensive pipeline and a comparative study to address this limitation. We first develop a series of increasingly sophisticated BC baselines, culminating in a Transformer-based model that operates on a structured, entity-centric state representation. While this model achieves low imitation loss, we show that it still fails in long-horizon simulations. We then demonstrate that by applying a state-of-the-art Offline Reinforcement Learning algorithm, Conservative Q-Learning (CQL), to the same data and architecture, we can learn a significantly more robust policy. Using a carefully engineered reward function, the CQL agent learns a conservative value function that enables it to recover from minor errors and avoid out-of-distribution states. In a large-scale evaluation on 1,000 unseen scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a 3.2x higher success rate and a 7.4x lower collision rate than the strongest BC baseline, proving that an offline RL approach is critical for learning robust, long-horizon driving policies from static expert data.

Paper number 87:
Title: Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing
Authors: Gokul Puthumanaillam, Aditya Penumarti, Manav Vora, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla, Jane Shin, Melkior Ornik
Abstract: Robots equipped with rich sensor suites can localize reliably in partially-observable environments, but powering every sensor continuously is wasteful and often infeasible. Belief-space planners address this by propagating pose-belief covariance through analytic models and switching sensors heuristically--a brittle, runtime-expensive approach. Data-driven approaches--including diffusion models--learn multi-modal trajectories from demonstrations, but presuppose an accurate, always-on state estimate. We address the largely open problem: for a given task in a mapped environment, which \textit{minimal sensor subset} must be active at each location to maintain state uncertainty \textit{just low enough} to complete the task? Our key insight is that when a diffusion planner is explicitly conditioned on a pose-belief raster and a sensor mask, the spread of its denoising trajectories yields a calibrated, differentiable proxy for the expected localisation error. Building on this insight, we present Belief-Conditioned One-Step Diffusion (B-COD), the first planner that, in a 10 ms forward pass, returns a short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for localisation error--eliminating external covariance rollouts. We show that this single proxy suffices for a soft-actor-critic to choose sensors online, optimising energy while bounding pose-covariance growth. We deploy B-COD in real-time marine trials on an unmanned surface vehicle and show that it reduces sensing energy consumption while matching the goal-reach performance of an always-on baseline.

Paper number 88:
Title: Harnessing the Full Potential of RRAMs through Scalable and Distributed In-Memory Computing with Integrated Error Correction
Authors: Huynh Q. N. Vo, Md Tawsif Rahman Chowdhury, Paritosh Ramanan, Murat Yildirim, Gozde Tutuncuoglu
Abstract: Exponential growth in global computing demand is exacerbated due to the higher-energy requirements of conventional architectures, primarily due to energy-intensive data movement. In-memory computing with Resistive Random Access Memory (RRAM) addresses this by co-integrating memory and processing, but faces significant hurdles related to device-level non-idealities and poor scalability for large computing tasks. Here, we introduce MELISO+ (In-Memory Linear Solver), a full-stack, distributed framework for energy-efficient in-memory computing. MELISO+ proposes a novel two-tier error correction mechanism to mitigate device non-idealities and develops a distributed RRAM computing framework to enable matrix computations exceeding dimensions of $65,000\times65,000$. This approach reduces first- and second-order arithmetic errors due to device non-idealities by over $90\%$, enhances energy efficiency by three to five orders of magnitude, and decreases latency 100-fold. Hence, MELISO+ allows lower-precision RRAM devices to outperform high-precision device alternatives in accuracy, energy and latency metrics. By unifying algorithm-hardware co-design with scalable architecture, MELISO+ significantly advances sustainable, high-dimensional computing suitable for applications like large language models and generative AI.

Paper number 89:
Title: Vocoder-Projected Feature Discriminator
Authors: Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Yuto Kondo
Abstract: In text-to-speech (TTS) and voice conversion (VC), acoustic features, such as mel spectrograms, are typically used as synthesis or conversion targets owing to their compactness and ease of learning. However, because the ultimate goal is to generate high-quality waveforms, employing a vocoder to convert these features into waveforms and applying adversarial training in the time domain is reasonable. Nevertheless, upsampling the waveform introduces significant time and memory overheads. To address this issue, we propose a vocoder-projected feature discriminator (VPFD), which uses vocoder features for adversarial training. Experiments on diffusion-based VC distillation demonstrated that a pretrained and frozen vocoder feature extractor with a single upsampling step is necessary and sufficient to achieve a VC performance comparable to that of waveform discriminators while reducing the training time and memory consumption by 9.6 and 11.4 times, respectively.
    