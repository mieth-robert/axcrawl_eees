
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Does Language Matter for Early Detection of Parkinson's Disease from Speech?
Authors: Peter Plantinga, Briac Cordelle, Dominique Louër, Mirco Ravanelli, Denise Klein
Abstract: Using speech samples as a biomarker is a promising avenue for detecting and monitoring the progression of Parkinson's disease (PD), but there is considerable disagreement in the literature about how best to collect and analyze such data. Early research in detecting PD from speech used a sustained vowel phonation (SVP) task, while some recent research has explored recordings of more cognitively demanding tasks. To assess the role of language in PD detection, we tested pretrained models with varying data types and pretraining objectives and found that (1) text-only models match the performance of vocal-feature models, (2) multilingual Whisper outperforms self-supervised models whereas monolingual Whisper does worse, and (3) AudioSet pretraining improves performance on SVP but not spontaneous speech. These findings together highlight the critical role of language for the early detection of Parkinson's disease.

Paper number 2:
Title: Towards Robust Speech Recognition for Jamaican Patois Music Transcription
Authors: Jordan Madden, Matthew Stone, Dimitri Johnson, Daniel Geddez
Abstract: Although Jamaican Patois is a widely spoken language, current speech recognition systems perform poorly on Patois music, producing inaccurate captions that limit accessibility and hinder downstream applications. In this work, we take a data-centric approach to this problem by curating more than 40 hours of manually transcribed Patois music. We use this dataset to fine-tune state-of-the-art automatic speech recognition (ASR) models, and use the results to develop scaling laws for the performance of Whisper models on Jamaican Patois audio. We hope that this work will have a positive impact on the accessibility of Jamaican Patois music and the future of Jamaican Patois language modeling.

Paper number 3:
Title: Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems
Authors: Nima Yazdani, Ali Ansari, Aruj Mahajan, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi
Abstract: Voice-based conversational AI systems increasingly rely on cascaded architectures combining speech-to-text (STT), large language models (LLMs), and text-to-speech (TTS) components. However, systematic evaluation of different component combinations in production settings remains understudied. We present a large-scale empirical comparison of STT x LLM x TTS stacks using data from over 300,000 AI-conducted job interviews. We develop an automated evaluation framework using LLM-as-a-Judge to assess conversational quality, technical accuracy, and skill assessment capabilities. Our analysis of four production configurations reveals that Google STT paired with GPT-4.1 significantly outperforms alternatives in both conversational and technical quality metrics. Surprisingly, we find that objective quality metrics correlate weakly with user satisfaction scores, suggesting that user experience in voice-based AI systems depends on factors beyond technical performance. Our findings provide practical guidance for selecting components in multimodal conversational AI systems and contribute a validated evaluation methodology for voice-based interactions.

Paper number 4:
Title: From Black Box to Biomarker: Sparse Autoencoders for Interpreting Speech Models of Parkinson's Disease
Authors: Peter Plantinga, Jen-Kai Chen, Roozbeh Sattari, Mirco Ravanelli, Denise Klein
Abstract: Speech holds promise as a cost-effective and non-invasive biomarker for neurological conditions such as Parkinson's disease (PD). While deep learning systems trained on raw audio can find subtle signals not available from hand-crafted features, their black-box nature hinders clinical adoption. To address this, we apply sparse autoencoders (SAEs) to uncover interpretable internal representations from a speech-based PD detection system. We introduce a novel mask-based activation for adapting SAEs to small biomedical datasets, creating sparse disentangled dictionary representations. These dictionary entries are found to have strong associations with characteristic articulatory deficits in PD speech, such as reduced spectral flux and increased spectral flatness in the low-energy regions highlighted by the model attention. We further show that the spectral flux is related to volumetric measurements of the putamen from MRI scans, demonstrating the potential of SAEs to reveal clinically relevant biomarkers for disease monitoring and diagnosis.

Paper number 5:
Title: Segmentation-free Goodness of Pronunciation
Authors: Xinwei Cao, Zijian Fan, Torbjørn Svendsen, Giampiero Salvi
Abstract: Mispronunciation detection and diagnosis (MDD) is a significant part in modern computer aided language learning (CALL) systems. Within MDD, phoneme-level pronunciation assessment is key to helping L2 learners improve their pronunciation. However, most systems are based on a form of goodness of pronunciation (GOP) which requires pre-segmentation of speech into phonetic units. This limits the accuracy of these methods and the possibility to use modern CTC-based acoustic models for their evaluation. In this study, we first propose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR models for MDD. Next, we define a more general alignment-free method that takes all possible alignments of the target phoneme into account (GOP-AF). We give a theoretical account of our definition of GOP-AF, an implementation that solves potential numerical issues as well as a proper normalization which makes the method applicable with acoustic models with different peakiness over time. We provide extensive experimental results on the CMU Kids and Speechocean762 datasets comparing the different definitions of our methods, estimating the dependency of GOP-AF on the peakiness of the acoustic models and on the amount of context around the target phoneme. Finally, we compare our methods with recent studies over the Speechocean762 data showing that the feature vectors derived from the proposed method achieve state-of-the-art results on phoneme-level pronunciation assessment.

Paper number 6:
Title: Enhancing Lung Disease Diagnosis via Semi-Supervised Machine Learning
Authors: Xiaoran Xua, In-Ho Rab, Ravi Sankarc
Abstract: Lung diseases, including lung cancer and COPD, are significant health concerns globally. Traditional diagnostic methods can be costly, time-consuming, and invasive. This study investigates the use of semi supervised learning methods for lung sound signal detection using a model combination of MFCC+CNN. By introducing semi supervised learning modules such as Mix Match, Co-Refinement, and Co Refurbishing, we aim to enhance the detection performance while reducing dependence on manual annotations. With the add-on semi-supervised modules, the accuracy rate of the MFCC+CNN model is 92.9%, an increase of 3.8% to the baseline model. The research contributes to the field of lung disease sound detection by addressing challenges such as individual differences, feature insufficient labeled data.

Paper number 7:
Title: Technical report: Impact of Duration Prediction on Speaker-specific TTS for Indian Languages
Authors: Isha Pandey, Pranav Gaikwad, Amruta Parulekar, Ganesh Ramakrishnan
Abstract: High-quality speech generation for low-resource languages, such as many Indian languages, remains a significant challenge due to limited data and diverse linguistic structures. Duration prediction is a critical component in many speech generation pipelines, playing a key role in modeling prosody and speech rhythm. While some recent generative approaches choose to omit explicit duration modeling, often at the cost of longer training times. We retain and explore this module to better understand its impact in the linguistically rich and data-scarce landscape of India. We train a non-autoregressive Continuous Normalizing Flow (CNF) based speech model using publicly available Indian language data and evaluate multiple duration prediction strategies for zero-shot, speaker-specific generation. Our comparative analysis on speech-infilling tasks reveals nuanced trade-offs: infilling based predictors improve intelligibility in some languages, while speaker-prompted predictors better preserve speaker characteristics in others. These findings inform the design and selection of duration strategies tailored to specific languages and tasks, underscoring the continued value of interpretable components like duration prediction in adapting advanced generative architectures to low-resource, multilingual settings.

Paper number 8:
Title: Stable and Fair Benefit Allocation in Mixed-Energy Truck Platooning: A Coalitional Game Approach
Authors: Ting Bai, Karl Henrik Johansson, Jonas Mårtensson, Andreas A. Malikopoulos
Abstract: This paper addresses the benefit allocation in a mixed-energy truck platoon composed of fuel-powered and electric trucks. The interactions among trucks during platoon formation are modeled as a coalitional game with transferable utility. We first design a stable payoff allocation scheme that accounts for truck heterogeneity in energy savings and platoon roles (leader or follower), establishing core-stability conditions to ensure that no subset of trucks has an incentive to deviate for greater benefit. To enhance payoff fairness, we then propose a closed-form, Shapley value-based allocation approach that is computationally efficient and independent of the platoon size. Sufficient conditions under which the allocation is both fair and core-stable are provided. In scenarios where the Shapley value falls outside the core, we develop an alternative allocation based on the stable payoff that minimizes the mean relative deviation from the Shapley value while preserving core stability. This deviation is further proved to be upper-bounded by $1$, showing a favorable trade-off between stability and fairness. Finally, extensive numerical studies validate the theoretical results and demonstrate the effectiveness of the proposed framework in facilitating stable, equitable, and sustainable cooperation in mixed-energy truck platooning.

Paper number 9:
Title: Fast Distribution Grid Topology Estimation via Subset Sum
Authors: Yueyao Xu, Yize Chen
Abstract: Faced with increasing penetration of distributed energy resources and fast development of distribution grid energy management, topology identification of distribution grid becomes an important and fundamental task. As the underlying grid topology is usually unknown or incomplete to the utilities, it is becoming a fundamental task to efficiently identify the distribution grid network topology using limited measurements. A fast and accurate topology identification can help achieving the tasks of load monitoring, operation and control of power distribution system as well as outage detection. In this paper, we propose a novel and ultra-fast topology identification method. By adapting the subset sum method with a hierarchical structure, the overall grid topology can be inferred from fewer samples of smart meter power measurements. Such techniques can be applied in real time under the scenarios with fast topology change, and the proposed hierarchical algorithm is also robust against measurement noises.

Paper number 10:
Title: A Hybrid CNN-VSSM model for Multi-View, Multi-Task Mammography Analysis: Robust Diagnosis with Attention-Based Fusion
Authors: Yalda Zafari, Roaa Elalfy, Mohamed Mabrok, Somaya Al-Maadeed, Tamer Khattab, Essam A. Rashed
Abstract: Early and accurate interpretation of screening mammograms is essential for effective breast cancer detection, yet it remains a complex challenge due to subtle imaging findings and diagnostic ambiguity. Many existing AI approaches fall short by focusing on single view inputs or single-task outputs, limiting their clinical utility. To address these limitations, we propose a novel multi-view, multitask hybrid deep learning framework that processes all four standard mammography views and jointly predicts diagnostic labels and BI-RADS scores for each breast. Our architecture integrates a hybrid CNN VSSM backbone, combining convolutional encoders for rich local feature extraction with Visual State Space Models (VSSMs) to capture global contextual dependencies. To improve robustness and interpretability, we incorporate a gated attention-based fusion module that dynamically weights information across views, effectively handling cases with missing data. We conduct extensive experiments across diagnostic tasks of varying complexity, benchmarking our proposed hybrid models against baseline CNN architectures and VSSM models in both single task and multi task learning settings. Across all tasks, the hybrid models consistently outperform the baselines. In the binary BI-RADS 1 vs. 5 classification task, the shared hybrid model achieves an AUC of 0.9967 and an F1 score of 0.9830. For the more challenging ternary classification, it attains an F1 score of 0.7790, while in the five-class BI-RADS task, the best F1 score reaches 0.4904. These results highlight the effectiveness of the proposed hybrid framework and underscore both the potential and limitations of multitask learning for improving diagnostic performance and enabling clinically meaningful mammography analysis.

Paper number 11:
Title: Harmonization in Magnetic Resonance Imaging: A Survey of Acquisition, Image-level, and Feature-level Methods
Authors: Qinqin Yang, Firoozeh Shomal-Zadeh, Ali Gholipour
Abstract: Modern medical imaging technologies have greatly advanced neuroscience research and clinical diagnostics. However, imaging data collected across different scanners, acquisition protocols, or imaging sites often exhibit substantial heterogeneity, known as "batch effects" or "site effects". These non-biological sources of variability can obscure true biological signals, reduce reproducibility and statistical power, and severely impair the generalizability of learning-based models across datasets. Image harmonization aims to eliminate or mitigate such site-related biases while preserving meaningful biological information, thereby improving data comparability and consistency. This review provides a comprehensive overview of key concepts, methodological advances, publicly available datasets, current challenges, and future directions in the field of medical image harmonization, with a focus on magnetic resonance imaging (MRI). We systematically cover the full imaging pipeline, and categorize harmonization approaches into prospective acquisition and reconstruction strategies, retrospective image-level and feature-level methods, and traveling-subject-based techniques. Rather than providing an exhaustive survey, we focus on representative methods, with particular emphasis on deep learning-based approaches. Finally, we summarize the major challenges that remain and outline promising avenues for future research.

Paper number 12:
Title: Impact of Communication Delay and Sampling on Small-Signal Stability of IBR-rich Power Systems
Authors: Saugat Ghimire, Vaithianathan "Mani" Venkatasubramanian, Gilles Torresan
Abstract: The growing adoption of inverter-based resources (IBRs) has introduced unprecedented dynamics in power systems, resulting in oscillations across a broad spectrum of frequencies. Communication delay between the plant-level control and the inverter-level control in IBR plants has been recognized as one of the causes of such oscillations and a factor that impacts the system's stability. The control signals from the plant-level controller also experience sampling, with the sampled values held constant by the hold elements for the duration of the sampling period. This also has a bearing on the response of IBR plants. In this paper, we analyze the impacts of communication delay and sampling of control signals between plant-level control and inverter-level control of grid-following IBR plants on the small-signal stability of power systems. The underlying fundamentals of communication delay and sampling are revisited to explain the observed responses. Our findings emphasize the unique effects of communication delay and sampling period on the stability of IBR-rich power systems and suggest strategies to mitigate their detrimental impacts. The work also highlights the need for more accurate approaches for small-signal stability analysis of such systems.

Paper number 13:
Title: Extension of Simple and Accurate Inductance Estimation for Rectangular Planar Windings
Authors: Theofilos Papadopoulos, Antonios Antonopoulos
Abstract: This paper proposes a method to generalize the equations estimating the inductance of square-shape planar windings to rectangle shape. This is done by utilizing the optimal p-norm of the Generalized Mean Value or Power Mean (PM). Three well-established equations with verified accuracy are examined, namely Wheeler, Rosa, and the Monomial, which by definition consider only regular polygons. One critical parameter of the original equations is the outer-side length of the winding, which for the rectangle case, can be substituted by the PM of the two outer-side lengths, without the need for any further modifications. A methodology to select the optimal p-norm for the PM is presented in terms of achieving the best accuracy for this estimation. The selection of the optimal p is based on results from datasets containing more than 2600 simulations of different rectangle-shaped windings. Finally, the estimation accuracy is verified by laboratory measurements for a selection of planar inductors.

Paper number 14:
Title: PPAAS: PVT and Pareto Aware Analog Sizing via Goal-conditioned Reinforcement Learning
Authors: Seunggeun Kim, Ziyi Wang, Sungyoung Lee, Youngmin Oh, Hanqing Zhu, Doyun Kim, David Z. Pan
Abstract: Device sizing is a critical yet challenging step in analog and mixed-signal circuit design, requiring careful optimization to meet diverse performance specifications. This challenge is further amplified under process, voltage, and temperature (PVT) variations, which cause circuit behavior to shift across different corners. While reinforcement learning (RL) has shown promise in automating sizing for fixed targets, training a generalized policy that can adapt to a wide range of design specifications under PVT variations requires much more training samples and resources. To address these challenges, we propose a \textbf{Goal-conditioned RL framework} that enables efficient policy training for analog device sizing across PVT corners, with strong generalization capability. To improve sample efficiency, we introduce Pareto-front Dominance Goal Sampling, which constructs an automatic curriculum by sampling goals from the Pareto frontier of previously achieved goals. This strategy is further enhanced by integrating Conservative Hindsight Experience Replay, which assigns relabeled goals with conservative virtual rewards to stabilize training and accelerate convergence. To reduce simulation overhead, our framework incorporates a Skip-on-Fail simulation strategy, which skips full-corner simulations when nominal-corner simulation fails to meet target specifications. Experiments on benchmark circuits demonstrate $\sim$1.6$\times$ improvement in sample efficiency and $\sim$4.1$\times$ improvement in simulation efficiency compared to existing sizing methods. Code and benchmarks are publicly available at this https URL

Paper number 15:
Title: An Energy-Autonomous and Battery-Free Resistive Sensor using a Time-Domain to Digital Conversion with Bluetooth Low Energy connectivity
Authors: Mario Costanza, Antonino Pagano, Samuel Margueron, Ilenia Tinnirello, Roberto La Rosa
Abstract: This paper introduces an innovative Energy-Autonomous Wireless Sensing Node (EAWSN) that addresses power constraints by harnessing ambient light for energy. It combines this energy harvesting capability with the Time Domain to Digital Conversion (TDDC) technique for efficient and accurate measurements of resistive sensors. Bluetooth Low Energy (BLE) communication ensures data can be transmitted wirelessly to a base station, providing a promising solution for various applications, particularly in environments with limited access to wired power sources, enabling long-term, maintenance-free operation by eliminating batteries. Experimental results showed a linear relationship between the test resistance R_m and the measured number of clock pulses N_m within the sensor's operating range.

Paper number 16:
Title: Efficient and Distortion-less Spectrum Multiplexer via Neural Network-based Filter Banks
Authors: Jiazhao Wang, Wenchao Jiang
Abstract: Spectrum multiplexer enables simultaneous transmission of multiple narrow-band IoT signals through gateway devices, thereby enhancing overall spectrum utilization. We propose a novel solution based on filter banks that offer increased efficiency and minimal distortion compared with conventional methods. We follow a model-driven approach to integrate the neural networks into the filter bank design by interpreting the neural network models as filter banks. The proposed NN-based filter banks can leverage advanced learning capabilities to achieve distortionless multiplexing and harness hardware acceleration for high efficiency. Then, we evaluate the performance of the spectrum multiplexer implemented by NN-based filter banks for various types of signals and environmental conditions. The results show that it can achieve a low distortion level down to $-39$dB normalized mean squared error. Furthermore, it achieves up to $35$ times execution efficiency gain and $10$dB SNR gain compared with the conventional methods. The field applications show that it can handle both the heterogeneous and homogeneous IoT networks, resulting in high packet reception ratio at the standard receivers up to $98\%$.

Paper number 17:
Title: Transient Stability-Driven Planning for the Optimal Sizing of Resilient AC/DC Hybrid Microgrids
Authors: Yi Wang, Goran Strbac
Abstract: This paper proposes a transient stability-driven planning framework for the optimal sizing problem of resilient AC/DC hybrid microgrids (HMGs) under different types of contingencies, capturing frequency and voltage stability requirements as well as the frequency-voltage coupling dynamics of AC/DC interlinking converters (ICs). The planning model is formulated into a defender-attacker-defender (DAD) architecture, which can be further merged into two levels, i.e., upper-level and low-level problems, and then iteratively solved by an enhanced genetic algorithm with sparsity calculation and local search. Regarding the operation stage, a novel transient stability-constrained optimal power flow (TSC-OPF) algorithm is proposed for static and transient operations of HMGs, capturing governor dynamics and automatic voltage regulator of conventional generators as well as the droop control dynamics of inverter-based resources (IBRs) for frequency control and voltage control, respectively. Furthermore, a Lyapunov optimisation approach is developed to capture the time-coupling property of energy storages (ESs) and then allow the TSC-OPF to be solved on an hourly basis with a second-scale resolution, achieving the co-optimisation of static and transient stability requirements. Case studies have been conducted to verify the effectiveness of the proposed planning framework in obtaining cost-effective investment decisions for various resources while respecting transient stability requirements under different contingencies.

Paper number 18:
Title: Stacked Intelligent Metasurface Assisted Multiuser Communications: From a Rate Fairness Perspective
Authors: Junjie Fang, Chao Zhang, Jiancheng An, Hongwen Yu, Qingqing Wu, Mérouane Debbah, Chau Yuen
Abstract: Stacked intelligent metasurface (SIM) extends the concept of single-layer reconfigurable holographic surfaces (RHS) by incorporating a multi-layered structure, thereby providing enhanced control over electromagnetic wave propagation and improved signal processing capabilities. This study investigates the potential of SIM in enhancing the rate fairness in multiuser downlink systems by addressing two key optimization problems: maximizing the minimum rate (MR) and maximizing the geometric mean of rates (GMR). {The former strives to enhance the minimum user rate, thereby ensuring fairness among users, while the latter relaxes fairness requirements to strike a better trade-off between user fairness and system sum-rate (SR).} For the MR maximization, we adopt a consensus alternating direction method of multipliers (ADMM)-based approach, which decomposes the approximated problem into sub-problems with closed-form solutions. {For GMR maximization, we develop an alternating optimization (AO)-based algorithm that also yields closed-form solutions and can be seamlessly adapted for SR maximization. Numerical results validate the effectiveness and convergence of the proposed algorithms.} Comparative evaluations show that MR maximization ensures near-perfect fairness, while GMR maximization balances fairness and system SR. Furthermore, the two proposed algorithms respectively outperform existing related works in terms of MR and SR performance. Lastly, SIM with lower power consumption achieves performance comparable to that of multi-antenna digital beamforming.

Paper number 19:
Title: Design of a Noval Wearable ECG Monitoring Device
Authors: Ruihua Wang, Mingtong Chen, Zhengbao Yang
Abstract: The aim of this project is to develop a new wireless powered wearable ECG monitoring device. The main goal of the project is to provide a wireless, small-sized ECG monitoring device that can be worn for a long period of time by the monitored person. Electrocardiogram ECG reflects physiological and pathological information about heart activity and is commonly used to diagnose heart disease. Existing wearable smart ECG solutions suffer from high power consumption in both ECG diagnosis and transmission for high accuracy. Monitoring of ECG devices is mainly done by data extraction and acquisition, pre-processing, feature extraction, processing and analysis, visualisation and auxiliary procedures. During the pre-processing of the information, different kinds of noise generated during the signal collection need to be taken into account. The quality of the signal-to-noise ratio can usually be improved by optimising algorithms and reducing the noise power. The choice of electrodes usually has a direct impact on the signal-to-noise ratio and the user experience, and conventional Ag/AgCl gel electrodes are not suitable for long-term and dynamic monitoring as they are prone to skin irritation, inflammation and allergic reactions. Therefore, a completely new way of combining electrodes and wires will be used in the report. The electrodes and wires are cut in one piece from a silver-plated fabric. The wire portion is cut into a curved structure close to an S shape to ensure that it has good ductility for comfort and signal integrity during daily movement of the garment.

Paper number 20:
Title: Multi-Angle Rotational Actuation in a 0.8-mm-Thick Preload-Free Piezoelectric Micromotor
Authors: Haijia Yu, Mingtong Chen, Zhengbao Yang
Abstract: Micro motors can be used in numerous fields like Micro medical testing and treatment. To achieve a smaller size, micro piezoelectric motors in laboratories often omit the outer casing, which can lead to functional defects such as rotation only in one fixed direction or the need for external weights (which are not counted within the motors volume) to increase preload. However, this significantly reduces the practical value of micro piezoelectric motors. This paper proposes a new driving principle for piezoelectric motors to design a micro piezoelectric motor that can rotate at a wide range of angles (e.g. up to 80)without increasing the motors casing and does not require external weights, with a stator thickness of only 0.8 mm. This motor has significant application potential in OCT endoscopes and thrombectomy grinding heads

Paper number 21:
Title: Maintenance-free condition monitoring system based on lora
Authors: Honglin Zhang, Mingtong Chen, Zhengbao Yang
Abstract: With the rising volume of railroad transportation, the traditional track inspection mainly relies on manual inspection and large-scale inspection equipment, which not only has low inspection frequency and lagging response, but also has the defects of high risk, high cost and easy to miss inspection. To this end, this study designs and realizes a maintenance-free railroad track wireless monitoring system based on LoRa module LM401. Each monitoring node consists of an STM32 microcontroller, an LM401 LoRa transceiver, a low-power ADXL362 triaxial acceleration sensor, a digital temperature sensor (LMT85), and a digital barometric pressure sensor (RSCM17100KP101). The system collects vibration data through the SPI1 interface at the node end, periodically reads the temperature and barometric pressure information, and packages and sends the data to a centralized gateway within a range of 500 m using the LoRa star topology; the gateway then uploads the data in real time to a cloud server through a 4G module, which supports the MQTT protocol. MQTT protocol is supported. Laboratory tests and field deployments show that the system can realize acceleration resolution of 0.01 g, reduce maintenance cost by about 70%, and improve monitoring efficiency by more than 5 times. The system provides a reliable means for intelligent rail health management, and in the future, it is planned to introduce RF energy collection technology to realize automatic wake-up without battery, and expand to urban bridges, tunnels and environmental monitoring and other multi-scenario applications.

Paper number 22:
Title: Ontological Definition of Seamless Digital Engineering Based on ISO/IEC 25000-Series SQuaRE Product Quality Model
Authors: James S. Wheaton, Daniel R. Herber
Abstract: Since the introduction of Digital Engineering (DE) as a well-defined concept in 2018, organizations and industry groups have been working to interpret the DE concepts to establish consistent meta-models of those interrelated concepts for integration into their DE processes and tools. To reach the breadth and depth of DE concept definitions, the interpretation of international standard sources is necessary, including ISO/IEC/IEEE 15288, 24765, 42000-series, 15408, 15206, 27000-series, and 25000-series, to effectively model the knowledge domain where digital engineering applies. The harmonization of the concepts used in these international standards continues to improve with each revision, but it may be more effectively accomplished by relying on the descriptive logic formalized in the Web Ontology Language (OWL 2 DL). This paper presents a verified and consistent ontology based on the Basic Formal Ontology (BFO) and Common Core Ontologies (CCO) that defines Seamless Digital Engineering as a digital tooling paradigm that relies on formal verification of digital interfaces to provide a system-level qualification of the assured integrity of a Digital Engineering Environment. The present work defines classes and equivalence axioms, while using only the BFO- and CCO-defined object properties that relate them, to provide a baseline analysis that may inform future DE-related ontology development, using a case study to formally define the `seamless' quality in relation to the updated ISO 25010 SQuaRE product quality model. We identified ISO meta-model inconsistencies that are resolvable using the BFO/CCO ontological framework, and define `seamless' as both a system integration quality and a Human-Computer Interface quality-in-use, working to disambiguate this concept in the context of DE.

Paper number 23:
Title: Dispatch-Aware Deep Neural Network for Optimal Transmission Switching: Toward Real-Time and Feasibility Guaranteed Operation
Authors: Minsoo Kim, Jip Kim
Abstract: Optimal transmission switching (OTS) improves optimal power flow (OPF) by selectively opening transmission lines, but its mixed-integer formulation increases computational complexity, especially on large grids. To deal with this, we propose a dispatch-aware deep neural network (DA-DNN) that accelerates DC-OTS without relying on pre-solved labels. DA-DNN predicts line states and passes them through a differentiable DC-OPF layer, using the resulting generation cost as the loss function so that all physical network constraints are enforced throughout training and inference. In addition, we adopt a customized weight-bias initialization that keeps every forward pass feasible from the first iteration, which allows stable learning on large grids. Once trained, the proposed DA-DNN produces a provably feasible topology and dispatch pair in the same time as solving the DCOPF, whereas conventional mixed-integer solvers become intractable. As a result, the proposed method successfully captures the economic advantages of OTS while maintaining scalability.

Paper number 24:
Title: Hybrid Semantic-Complementary Transmission for High-Fidelity Image Reconstruction
Authors: Hyelin Nam, Jihong Park, Jinho Choi, Seong-Lyun Kim
Abstract: Recent advances in semantic communication (SC) have introduced neural network (NN)-based transceivers that convey semantic representation (SR) of signals such as images. However, these NNs are trained over diverse image distributions and thus often fail to reconstruct fine-grained image-specific details. To overcome this limited reconstruction fidelity, we propose an extended SC framework, hybrid semantic communication (HSC), which supplements SR with complementary representation (CR) capturing residual image-specific information. The CR is constructed at the transmitter, and is combined with the actual SC outcome at the receiver to yield a high-fidelity recomposed image. While the transmission load of SR is fixed due to its NN-based structure, the load of CR can be flexibly adjusted to achieve a desirable fidelity. This controllability directly influences the final reconstruction error, for which we derive a closed-form expression and the corresponding optimal CR. Simulation results demonstrate that HSC substantially reduces MSE compared to the baseline SC without CR transmission across various channels and NN architectures.

Paper number 25:
Title: SLASH: Self-Supervised Speech Pitch Estimation Leveraging DSP-derived Absolute Pitch
Authors: Ryo Terashima, Yuma Shirahata, Masaya Kawamura
Abstract: We present SLASH, a pitch estimation method of speech signals based on self-supervised learning (SSL). To enhance the performance of conventional SSL-based approaches that primarily depend on the relative pitch difference derived from pitch shifting, our method incorporates absolute pitch values by 1) introducing a prior pitch distribution derived from digital signal processing (DSP), and 2) optimizing absolute pitch through gradient descent with a loss between the target and differentiable DSP-derived spectrograms. To stabilize the optimization, a novel spectrogram generation method is used that skips complicated waveform generation. In addition, the aperiodic components in speech are accurately predicted through differentiable DSP, enhancing the method's applicability to speech signal processing. Experimental results showed that the proposed method outperformed both baseline DSP and SSL-based pitch estimation methods, attributed to the effective integration of SSL and DSP.

Paper number 26:
Title: On the Construction of Barrier Certificate: A Dynamic Programming Perspective
Authors: Yu Chen, Shaoyuan Li, Xiang Yin
Abstract: In this paper, we revisit the formal verification problem for stochastic dynamical systems over finite horizon using barrier certificates. Most existing work on this topic focuses on safety properties by constructing barrier certificates based on the notion of $c$-martingales. In this work, we first provide a new insight into the conditions of existing martingale-based barrier certificates from the perspective of dynamic programming operators. Specifically, we show that the existing conditions essentially provide a bound on the dynamic programming solution, which exactly characterizes the safety probability. Based on this new perspective, we demonstrate that the barrier conditions in existing approaches are unnecessarily conservative over unsafe states. To address this, we propose a new set of safety barrier certificate conditions that are strictly less conservative than existing ones, thereby providing tighter probability bounds for safety verification. We further extend our approach to the case of reach-avoid specifications by providing a set of new barrier certificate conditions. We also illustrate how to search for these new barrier certificates using sum-of-squares (SOS) programming. Finally, we use two numerical examples to demonstrate the advantages of our method compared to existing approaches.

Paper number 27:
Title: HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes
Authors: Feng Cao, Zishuo Feng
Abstract: Extracellular recordings are brief voltage fluctuations recorded near neurons, widely used in neuroscience as the basis for decoding brain activity at single-neuron resolution. Spike sorting, which assigns each spike to its source neuron, is a critical step in brain sensing pipelines. However, it remains challenging under low signal-to-noise ratio (SNR), electrode drift, and cross-session variability. In this paper, we propose HuiduRep, a robust self-supervised representation learning framework that extracts discriminative and generalizable features from extracellular spike waveforms. By combining contrastive learning with a denoising autoencoder, HuiduRep learns latent representations that are robust to noise and drift. Built on HuiduRep, we develop a spike sorting pipeline that clusters spike representations without supervision. Experiments on hybrid and real-world datasets demonstrate that HuiduRep achieves strong robustness and the pipeline matches or outperforms state-of-the-art tools such as KiloSort4 and MountainSort5. These findings demonstrate the potential of self-supervised spike representation learning as a foundational tool for robust and generalizable processing of extracellular recordings.

Paper number 28:
Title: Joint Resource Optimization Over Licensed and Unlicensed Spectrum in Spectrum Sharing UAV Networks Against Jamming Attacks
Authors: Rui Ding, Fuhui Zhou, Yuhang Wu, Qihui Wu, Tony Q. S. Quek
Abstract: Unmanned aerial vehicle (UAV) communication is of crucial importance in realizing heterogeneous practical wireless application scenarios. However, the densely populated users and diverse services with high data rate demands has triggered an increasing scarcity of UAV spectrum utilization. To tackle this problem, it is promising to incorporate the underutilized unlicensed spectrum with the licensed spectrum to boost network capacity. However, the openness of unlicensed spectrum makes UAVs susceptible to security threats from potential jammers. Therefore, a spectrum sharing UAV network coexisting with licensed cellular network and unlicensed Wi-Fi network is considered with the anti-jamming technique in this paper. The sum rate maximization of the secondary network is studied by jointly optimizing the transmit power, subchannel allocation, and UAV trajectory. We first decompose the challenging non-convex problem into two subproblems, 1) the joint power and subchannel allocation and 2) UAV trajectory design subproblems. A low-complexity iterative algorithm is proposed in a alternating optimization manner over these two subproblems to solve the formulated problem. Specifically, the Lagrange dual decomposition is exploited to jointly optimize the transmit power and subchannel allocation iteratively. Then, an efficient iterative algorithm capitalizing on successive convex approximation is designed to get a suboptimal solution for UAV trajectory. Simulation results demonstrate that our proposed algorithm can significantly improve the sum transmission rate compared with the benchmark schemes.

Paper number 29:
Title: MyGO: Make your Goals Obvious, Avoiding Semantic Confusion in Prostate Cancer Lesion Region Segmentation
Authors: Zhengcheng Lin (1), Zuobin Ying (2), Zhenyu Li (3), Zhenyu Liu (4), Jian Lu (5), Weiping Ding (6) ((1), (2) City University of Macau, (3) Shandong University, (4) Chinese Academy of Sciences, (5) Peking University, (6) Nantong University)
Abstract: Early diagnosis and accurate identification of lesion location and progression in prostate cancer (PCa) are critical for assisting clinicians in formulating effective treatment strategies. However, due to the high semantic homogeneity between lesion and non-lesion areas, existing medical image segmentation methods often struggle to accurately comprehend lesion semantics, resulting in the problem of semantic confusion. To address this challenge, we propose a novel Pixel Anchor Module, which guides the model to discover a sparse set of feature anchors that serve to capture and interpret global contextual information. This mechanism enhances the model's nonlinear representation capacity and improves segmentation accuracy within lesion regions. Moreover, we design a self-attention-based Top_k selection strategy to further refine the identification of these feature anchors, and incorporate a focal loss function to mitigate class imbalance, thereby facilitating more precise semantic interpretation across diverse regions. Our method achieves state-of-the-art performance on the PI-CAI dataset, demonstrating 69.73% IoU and 74.32% Dice scores, and significantly improving prostate cancer lesion detection.

Paper number 30:
Title: State Estimation with 1-Bit Observations and Imperfect Models: Bussgang Meets Kalman in Neural Networks
Authors: Chaehyun Jung, TaeJun Ha, Hyeonuk Kim, Jeonghun Park
Abstract: State estimation from noisy observations is a fundamental problem in many applications of signal processing. Traditional methods, such as the extended Kalman filter, work well under fully-known Gaussian models, while recent hybrid deep learning frameworks, combining model-based and data-driven approaches, can also handle partially known models and non-Gaussian noise. However, existing studies commonly assume the absence of quantization distortion, which is inevitable, especially with non-ideal analog-to-digital converters. In this work, we consider a state estimation problem with 1-bit quantization. 1-bit quantization causes significant quantization distortion and severe information loss, rendering conventional state estimation strategies unsuitable. To address this, inspired by the Bussgang decomposition technique, we first develop the Bussgang-aided Kalman filter by assuming perfectly known models. The proposed method suitably captures quantization distortion into the state estimation process. In addition, we propose a computationally efficient variant, referred to as the reduced Bussgang-aided Kalman filter and, building upon it, introduce a deep learning-based approach for handling partially known models, termed the Bussgang-aided KalmanNet. In particular, the Bussgang-aided KalmanNet jointly uses a dithering technique and a gated recurrent unit (GRU) architecture to effectively mitigate the effects of 1-bit quantization and model mismatch. Through simulations on the Lorenz-Attractor model and the Michigan NCLT dataset, we demonstrate that our proposed methods achieve accurate state estimation performance even under highly nonlinear, mismatched models and 1-bit observations.

Paper number 31:
Title: Non-Orthogonal AFDM: A Promising Spectrum-Efficient Waveform for 6G High-Mobility Communications
Authors: Yu Zhang, Qin Yi, Leila Musavian, Tongyang Xu, Zilong Liu
Abstract: This paper proposes a spectrum-efficient nonorthogonal affine frequency division multiplexing (AFDM) waveform for reliable high-mobility communications in the upcoming sixth-generation (6G) mobile systems. Our core idea is to introduce a compression factor to enable controllable subcarrier overlapping in chirp-based AFDM modulation. To mitigate intercarrier interference (ICI), we introduce linear precoding at the transmitter and an iterative detection scheme at the receiver. Simulation results demonstrate that these techniques can effectively reduce interference and maintain robust bit error rate (BER) performance even under aggressive compression factors and high-mobility channel conditions. The proposed non-orthogonal AFDM waveform offers a promising solution for next-generation wireless networks, balancing spectrum efficiency and Doppler resilience in highly dynamic environments.

Paper number 32:
Title: A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model
Authors: Zhe Xu, Ziyi Liu, Junlin Hou, Jiabo Ma, Cheng Jin, Yihui Wang, Zhixuan Chen, Zhengyu Zhang, Zhengrui Guo, Fengtao Zhou, Yingxue Xu, Xi Wang, Ronald Cheong Kin Chan, Li Liang, Hao Chen
Abstract: Multimodal large language models (MLLMs) have emerged as powerful tools for computational pathology, offering unprecedented opportunities to integrate pathological images with language context for comprehensive diagnostic analysis. These models hold particular promise for automating complex tasks that traditionally require expert interpretation of pathologists. However, current MLLM approaches in pathology demonstrate significantly constrained reasoning capabilities, primarily due to their reliance on expensive chain-of-thought annotations. Additionally, existing methods remain limited to simplex application of visual question answering (VQA) at region-of-interest (ROI) level, failing to address the full spectrum of diagnostic needs such as ROI classification, detection, segmentation, whole-slide-image (WSI) classification and VQA in clinical practice. In this study, we present SmartPath-R1, a versatile MLLM capable of simultaneously addressing both ROI-level and WSI-level tasks while demonstrating robust pathological reasoning capability. Our framework combines scale-dependent supervised fine-tuning and task-aware reinforcement fine-tuning, which circumvents the requirement for chain-of-thought supervision by leveraging the intrinsic knowledge within MLLM. Furthermore, SmartPath-R1 integrates multiscale and multitask analysis through a mixture-of-experts mechanism, enabling dynamic processing for diverse tasks. We curate a large-scale dataset comprising 2.3M ROI samples and 188K WSI samples for training and evaluation. Extensive experiments across 72 tasks validate the effectiveness and superiority of the proposed approach. This work represents a significant step toward developing versatile, reasoning-enhanced AI systems for precision pathology.

Paper number 33:
Title: Integrating Grid impedance estimation method into Advanced Angle Estimation Kalman Filter in GFL inverter
Authors: Phuoc Sang Nguyen, Ghavameddin Nourbakhsh, Gerard Ledwich
Abstract: The growing integration of power electronic converter-interfaced distributed energy resources into modern power systems presents significant challenges for system monitoring, protection, and control. Grid impedance plays a critical role in the operation and stability assessment of grid-connected inverter systems. This study presents a real-time grid impedance estimation method based on the Discrete Fourier Transform. The proposed method is integrated with the Advanced Angle Estimation Kalman Filter using a Linear Quadratic Regulator current controller (AAEKF-LQR), assisting the use of impedance information for accurate instantaneous phase angle estimation. Simulation results confirm that the proposed impedance estimation method interacts effectively with the AAEKF-LQR controller, maintaining stable system performance under weak grid conditions. The approach also demonstrates the ability to deliver fast and accurate impedance estimation during operational variations in grid conditions, thereby supporting stable inverter operation.

Paper number 34:
Title: LightCom: A Generative AI-Augmented Framework for QoE-Oriented Communications
Authors: Chunmei Xu, Siqi Zhang, Yi Ma, Rahim Tafazolli
Abstract: Data-intensive and immersive applications, such as virtual reality, impose stringent quality of experience (QoE) requirements that challenge traditional quality of service (QoS)-driven communication systems. This paper presents LightCom, a lightweight encoding and generative AI (GenAI)-augmented decoding framework, designed for QoE-oriented communications under low signal-to-noise ratio (SNR) conditions. LightCom simplifies transmitter design by applying basic low-pass filtering for source coding and minimal channel coding, significantly reducing processing complexity and energy consumption. At the receiver, GenAI models reconstruct high-fidelity content from highly compressed and degraded signals by leveraging generative priors to infer semantic and structural information beyond traditional decoding capabilities. The key design principles are analyzed, along with the sufficiency and error-resilience of the source representation. We also develop importance-aware power allocation strategies to enhance QoE and extend perceived coverage. Simulation results demonstrate that LightCom achieves up to a $14$ dB improvement in robustness and a $9$ dB gain in perceived coverage, outperforming traditional QoS-driven systems relying on sophisticated source and channel coding. This paradigm shift moves communication systems towards human-centric QoE metrics rather than bit-level fidelity, paving the way for more efficient and resilient wireless networks.

Paper number 35:
Title: Partially Reflected Surface (PRS)-Loaded Graphene-Based Patch Antenna for 6G
Authors: Omar Osman, Abdullah Qayyum, Maziar Nekovee
Abstract: This work investigates a slotted patch antenna integrated with a partially reflected surface (PRS) to operate in the TeraHertz (THz) frequency range for 6G. The antenna is based on graphene material, on a Rogers RT Duroid 6010 substrate. The proposed antenna achieves a bandwidth of 70 GHz (750 GHz to 820 GHz). The PRS sheet consists of 5x4 unit cells, which are optimised to enhance the overall realized gain of the antenna. The overall realized gain has increased by 1.07 dBi. Also, the PRS enhanced the antenna radiation pattern, showing stable properties over the operating bandwidth. The improved antenna performance is validated via simulations.

Paper number 36:
Title: Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation
Authors: Junlang Huang, Hao Chen, Zhong Guan
Abstract: This paper proposes a neural framework for power and timing prediction of multi-stage data path, distinguishing itself from traditional lib-based analytical methods dependent on driver characterization and load simplifications. To the best of our knowledge, this is the first language-based, netlist-aware neural network designed explicitly for standard cells. Our approach employs two pre-trained neural models of waveform prediction and delay estimation that directly infer transient waveforms and propagation delays from SPICE netlists, conditioned on critical physical parameters such as load capacitance, input slew, and gate size. This method accurately captures both intrinsic and coupling-induced delay effects without requiring simplification or interpolation. For multi-stage timing prediction, we implement a recursive propagation strategy where predicted waveforms from each stage feed into subsequent stages, cumulatively capturing delays across the logic chain. This approach ensures precise timing alignment and complete waveform visibility throughout complex signal pathways. The waveform prediction utilizes a hybrid CNN-Transformer architecture with netlist-aware node-level encoding, addressing traditional Transformers' fixed input dimensionality constraints. Additionally, specialized subnetworks separately handle primary delay estimation and crosstalk correction. Experimental results demonstrate SPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse industrial circuits. The proposed framework provides a scalable, structurally adaptable neural alternative to conventional power and timing engines, demonstrating high fidelity to physical circuit behaviors.

Paper number 37:
Title: Efficient and Robust Semantic Image Communication via Stable Cascade
Authors: Bilal Khalid, Pedro Freire, Sergei K. Turitsyn, Jaroslaw E. Prilepsky
Abstract: Diffusion Model (DM) based Semantic Image Communication (SIC) systems face significant challenges, such as slow inference speed and generation randomness, that limit their reliability and practicality. To overcome these issues, we propose a novel SIC framework inspired by Stable Cascade, where extremely compact latent image embeddings are used as conditioning to the diffusion process. Our approach drastically reduces the data transmission overhead, compressing the transmitted embedding to just 0.29% of the original image size. It outperforms three benchmark approaches - the diffusion SIC model conditioned on segmentation maps (GESCO), the recent Stable Diffusion (SD)-based SIC framework (Img2Img-SC), and the conventional JPEG2000 + LDPC coding - by achieving superior reconstruction quality under noisy channel conditions, as validated across multiple metrics. Notably, it also delivers significant computational efficiency, enabling over 3x faster reconstruction for 512 x 512 images and more than 16x faster for 1024 x 1024 images as compared to the approach adopted in Img2Img-SC.

Paper number 38:
Title: Power Allocation and RIS Elements Optimisation for Reconfigurable Intelligent Surfaces assisted RSMA
Authors: Abdullah Qayyum, Maziar Nekovee
Abstract: This paper proposes power allocation and the number of reconfigurable intelligent surfaces (RIS) elements optimisation in a RIS-assisted rate splitting multiple access (RSMA) system. The optimised RIS-RSMA (ORIS-RSMA) method determines the optimal number of RIS elements and the power allocation factors for both common and private parts of a message. Additionally, it maximises the sum rate while ensuring that a target common rate is satisfied. The performance of the proposed ORIS-RSMA is compared to that of the conventional RIS-RSMA and RSMA. Simulation results show that ORIS-RSMA achieves a higher sum rate.

Paper number 39:
Title: Optimizing Car Resequencing on Mixed-Model Assembly Lines: Algorithm Development and Deployment
Authors: Andreas Karrenbauer, Bernd Kuhn, Kurt Mehlhorn, Paolo Luigi Rinaldi
Abstract: The mixed-model assembly line (MMAL) is a production system used in the automobile industry to manufacture different car models on the same conveyor, offering a high degree of product customization and flexibility. However, the MMAL also poses challenges, such as finding optimal sequences of models satisfying multiple constraints and objectives related to production performance, quality, and delivery -- including minimizing the number of color changeovers in the Paint Shop, balancing the workload and setup times on the assembly line, and meeting customer demand and delivery deadlines. We propose a multi-objective algorithm to solve the MMAL resequencing problem under consideration of all these aspects simultaneously. We also present empirical results obtained from recorded event data of the production process over $4$ weeks following the deployment of our algorithm in the Saarlouis plant of Ford-Werke GmbH. We achieved an improvement of the average batch size of about $30\%$ over the old control software translating to a $23\%$ reduction of color changeovers. Moreover, we reduced the spread of cars planned for a specific date by $10\%$, reducing the risk of delays in delivery. We discuss effectiveness and robustness of our algorithm in improving production performance and quality as well as trade-offs and limitations.

Paper number 40:
Title: Detecting Multiple Targets with Distributed Sensing and Communication in Cell-Free Massive MIMO
Authors: Zinat Behdad, Ozlem Tugfe Demir, Ki Won Sung, Cicek Cavdar
Abstract: This paper investigates multi-target detection in an integrated sensing and communication (ISAC) system within a cell-free massive MIMO (CF-mMIMO) framework. We adopt a user-centric approach for communication user equipments (UEs) and a distributed sensing approach for multi-target detection. A heuristic access point (AP) mode selection algorithm and a channel-aware distributed sensing scheme are proposed, where local measurements at receive APs (RX-APs) are weighted based on the received signals signal-to-interference ratio (SIR). A maximum a posteriori ratio test (MAPRT) detector is applied under two awareness levels at RX-APs. To balance the communication-sensing trade-off, we develop a power allocation algorithm to jointly maximize the minimum detection probability and communication signal-to-interference-plus-noise ratio (SINR) while satisfying power constraints. The proposed scheme outperforms non-weighted methods. Adding test statistics from more RX-APs can degrade sensing performance due to weaker channels, but this effect can be mitigated by optimizing the weighting exponent. Additionally, assigning more sensing RX-APs to a sensing area results in approximately 10 dB loss in minimum communication SINR due to limited communication resources.

Paper number 41:
Title: Output Feedback Design for Parameter Varying Systems subject to Persistent Disturbances and Control Rate Constraints
Authors: Jackson G. Ernesto, Eugenio B. Castelan, Walter Lucia
Abstract: This paper presents a technique for designing output feedback controllers for constrained linear parameter-varying systems that are subject to persistent disturbances. Specifically, we develop an incremental parameter-varying output feedback control law to address control rate constraints, as well as state and control amplitude constraints. The proposal is based on the concept of robust positively invariant sets and applies the extended Farkas' lemma to derive a set of algebraic conditions that define both the control gains and a robust positively invariant polyhedron that satisfies the control and state constraints. These algebraic conditions are formulated into a bilinear optimization problem aimed at determining the output feedback gains and the associated polyedral robust positively invariant region. The obtained controller ensures that any closed-loop trajectory originating from the polyhedron converges to another smaller inner polyhedral set around the origin in finite time, where the trajectory remains ultimately bounded regardless of the persistent disturbances and variations in system parameters. Furthermore, by including the sizes of the two polyhedral sets inside the objective function, the proposed optimization can also jointly enlarge the outer set while minimizing the inner one. Numerical examples are presented to demonstrate the effectiveness of our proposal in managing the specified constraints, disturbances, and parameter variations.

Paper number 42:
Title: Slow Fluid Antenna Multiple Access with Multiport Receivers
Authors: José P. González-Coma, F. Javier López-Martínez
Abstract: We investigate whether equipping fluid-antenna (FA) receivers with multiple ($L>1$) radiofrequency (RF) chains can improve the performance of the slow fluid-antenna multiple access (FAMA) technique, which enables open-loop connectivity with channel state information (CSI) available only at the receiver side. We analyze the case of slow-FAMA users equipped with multiport receivers, so that $L$ ports of the FA are selected and combined to reduce interference. We show that a joint design of the port selection matrix and the combining vector at each receiver yields significant performance gains over reference schemes, demonstrating the potential of multiport reception in FA systems with a limited number of RF chains.

Paper number 43:
Title: Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP
Authors: Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux
Abstract: This correspondence presents a power-aware cognitive radar framework for joint detection and tracking of multiple targets in a massive multiple-input multiple-output (MIMO) radar environment. Building on a previous single-target algorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend it to the multi-target case by assigning each target an independent POMCP tree, enabling scalable and efficient planning. Departing from uniform power allocation-which is often suboptimal with varying signal-to-noise ratios (SNRs)-our approach predicts each target's future angular position and expected received power, based on its estimated range and radar cross-section (RCS). These predictions guide adaptive waveform design via a constrained optimization problem that allocates transmit energy to enhance the detectability of weaker or distant targets, while ensuring sufficient power for high-SNR targets. The reward function in the underlying partially observable Markov decision process (POMDP) is also modified to prioritize accurate spatial and power estimation. Simulations involving multiple targets with different SNRs confirm the effectiveness of our method. The proposed framework for the cognitive radar improves detection probability for low-SNR targets and achieves more accurate tracking compared to approaches using uniform or orthogonal waveforms. These results demonstrate the potential of the POMCP-based framework for adaptive, efficient multi-target radar systems.

Paper number 44:
Title: Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling
Authors: Leandro Von Krannichfeldt, Kristina Orehounig, Olga Fink
Abstract: Building energy modeling is a key tool for optimizing the performance of building energy systems. Historically, a wide spectrum of methods has been explored -- ranging from conventional physics-based models to purely data-driven techniques. Recently, hybrid approaches that combine the strengths of both paradigms have gained attention. These include strategies such as learning surrogates for physics-based models, modeling residuals between simulated and observed data, fine-tuning surrogates with real-world measurements, using physics-based outputs as additional inputs for data-driven models, and integrating the physics-based output into the loss function the data-driven model. Despite this progress, two significant research gaps remain. First, most hybrid methods focus on deterministic modeling, often neglecting the inherent uncertainties caused by factors like weather fluctuations and occupant behavior. Second, there has been little systematic comparison within a probabilistic modeling framework. This study addresses these gaps by evaluating five representative hybrid approaches for probabilistic building energy modeling, focusing on quantile predictions of building thermodynamics in a real-world case study. Our results highlight two main findings. First, the performance of hybrid approaches varies across different building room types, but residual learning with a Feedforward Neural Network performs best on average. Notably, the residual approach is the only model that produces physically intuitive predictions when applied to out-of-distribution test data. Second, Quantile Conformal Prediction is an effective procedure for calibrating quantile predictions in case of indoor temperature modeling.

Paper number 45:
Title: Clustering-based hard negative sampling for supervised contrastive speaker verification
Authors: Piotr Masztalski, Michał Romaniuk, Jakub Żak, Mateusz Matuszewski, Konrad Kowalczyk
Abstract: In speaker verification, contrastive learning is gaining popularity as an alternative to the traditionally used classification-based approaches. Contrastive methods can benefit from an effective use of hard negative pairs, which are different-class samples particularly challenging for a verification model due to their similarity. In this paper, we propose CHNS - a clustering-based hard negative sampling method, dedicated for supervised contrastive speaker representation learning. Our approach clusters embeddings of similar speakers, and adjusts batch composition to obtain an optimal ratio of hard and easy negatives during contrastive loss calculation. Experimental evaluation shows that CHNS outperforms a baseline supervised contrastive approach with and without loss-based hard negative sampling, as well as a state-of-the-art classification-based approach to speaker verification by as much as 18 % relative EER and minDCF on the VoxCeleb dataset using two lightweight model architectures.

Paper number 46:
Title: Model Predictive Control for Unlocking Energy Flexibility of Heat Pump and Thermal Energy Storage Systems: Experimental Results
Authors: Weihong Tang, Yun Li, Shalika Walker, Tamas Keviczky
Abstract: Increasing penetration of renewable energy sources (RES) and electrification of energy systems necessitates the engagement of demand-side management (DSM) to help alleviate congestion in electricity grid. Heat pump and thermal energy storage (HPTES) systems, being energy efficient solutions, are becoming popular in modern buildings and are promising to contribute to demand-side management (DSM) due to their significant share in household electricity consumption. For typical HPTES systems, this paper presents a systematic design framework covering a control-oriented modeling process and energy-flexible model predictive control (MPC) design. The proposed MPC-based DSM strategy offers an innovative solution for efficient DSM by following a two-step DSM framework. In the first step, flexibility assessment is performed to quantitatively evaluate the flexibility potential of the HPTES system by solving a mixed-integer economic MPC problem. In the second step, flexibility exploitation is achieved through reacting to feasible demand response (DR) requests while respecting system constraints. Both numerical simulations and real-world experiments are performed based on a real HPTES installation to showcase the viability and effectiveness of the proposed design.

Paper number 47:
Title: A Joint Planning Model for Fixed and Mobile Electric Vehicle Charging Stations Considering Flexible Capacity Strategy
Authors: Zhe Yu, Xue Hu, Qin Wang
Abstract: The widespread adoption of electric vehicles (EVs) has significantly increased demand on both transportation and power systems, posing challenges to their stable operation. To support the growing need for EV charging, both fixed charging stations (FCSs) and mobile charging stations (MCSs) have been introduced, serving as key interfaces between the power grid and traffic network. Recognizing the importance of collaborative planning across these sectors, this paper presents a two-stage joint planning model for FCSs and MCSs, utilizing an improved alternating direction method of multipliers (ADMM) algorithm. The primary goal of the proposed model is to transform the potential negative impacts of large-scale EV integration into positive outcomes, thereby enhancing social welfare through collaboration among multiple stakeholders. In the first stage, we develop a framework for evaluating FCS locations, incorporating assessments of EV hosting capacity and voltage stability. The second stage introduces a joint planning model for FCSs and MCSs, aiming to minimize the overall social costs of the EV charging system while maintaining a reliable power supply. To solve the planning problem, we employ a combination of mixed-integer linear programming, queueing theory, and sequential quadratic programming. The improved ADMM algorithm couples the siting and sizing decisions consistently by introducing coupling constraints, and supports a distributed optimization framework that coordinates the interests of EV users, MCS operators, and distribution system operators. Additionally, a flexible capacity planning strategy that accounts for the multi-period development potential of EVCS is proposed to reduce both the complexity and the investment required for FCS construction. Finally, a case study with comparative experiments demonstrates the effectiveness of the proposed models and solution methods.

Paper number 48:
Title: Toward Federated DeePC: borrowing data from similar systems
Authors: Gert Vankan, Valentina Breschi, Simone Formentin
Abstract: Data-driven predictive control approaches, in general, and Data-enabled Predictive Control (DeePC), in particular, exploit matrices of raw input/output trajectories for control design. These data are typically gathered only from the system to be controlled. Nonetheless, the increasing connectivity and inherent similarity of (mass-produced) systems have the potential to generate a considerable amount of information that can be exploited to undertake a control task. In light of this, we propose a preliminary federated extension of DeePC that leverages a combination of input/output trajectories from multiple similar systems for predictive control. Supported by a suite of numerical examples, our analysis unveils the potential benefits of exploiting information from similar systems and its possible downsides.

Paper number 49:
Title: SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices
Authors: Guangteng Liu, Xiayue Liu, Zhixiang Xu, Yufeng Yuan, Hui Zhao, Yuxuan Liu, Yufei Jiang
Abstract: Wi-Fi sensing offers a promising technique for contactless human respiration monitoring. A key challenge, however, is the blind spot problem caused by random phase offsets that corrupt the complementarity of respiratory signals. To address the challenge, we propose a single-antenna-Wi-Fi-sensing (SA-WiSense) framework to improve accuracy of human respiration monitoring, robust against random phase offsets. The proposed SA-WiSense framework is cost-efficient, as only a single antenna is used rather than multiple antennas as in the previous works. Therefore, the proposed framework is applicable to Internet of Thing (IoT), where most of sensors are equipped with a single antenna. On one hand, we propose a cross-subcarrier channel state information (CSI) ratio (CSCR) based blind spot mitigation approach for IoT, where the ratios of two values of CSI between subcarriers are leveraged to mitigate random phase offsets. We prove that the random phase offsets can be cancelled by the proposed CSCR approach, thereby restoring the inherent complementarity of signals for blind-spot-free sensing. On the other hand, we propose a genetic algorithm (GA) based subcarrier selection (GASS) approach by formulating an optimization problem in terms of the sensing-signal-to-noise ratio (SSNR) of CSCR between subcarriers. GA is utilized to solve the formulated optimization problem. We use commodity ESP32 microcontrollers to build an experiment test. The proposed works are validated to achieve an detection rate of 91.2% for respiration monitoring at distances up to 8.0 meters, substantially more accurate than the state-of-the-art methods with a single antenna.

Paper number 50:
Title: Learning clusters of partially observed linear dynamical systems
Authors: Maryann Rui, Munther A. Dahleh
Abstract: We study the problem of learning clusters of partially observed linear dynamical systems from multiple input-output trajectories. This setting is particularly relevant when there are limited observations (e.g., short trajectories) from individual data sources, making direct estimation challenging. In such cases, incorporating data from multiple related sources can improve learning. We propose an estimation algorithm that leverages different data requirements for the tasks of clustering and system identification. First, short impulse responses are estimated from individual trajectories and clustered. Then, refined models for each cluster are jointly estimated using multiple trajectories. We establish end-to-end finite sample guarantees for estimating Markov parameters and state space realizations and highlight trade-offs among the number of observed systems, the trajectory lengths, and the complexity of the underlying models.

Paper number 51:
Title: Quaternion-Domain Super MDS for Robust 3D Localization
Authors: Alessio Lukaj, Keigo Masuoka, Takumi Takahashi, Giuseppe Thadeu Freitas de Abreu, Hideki Ochiai
Abstract: This paper proposes a novel low-complexity three-dimensional (3D) localization algorithm for wireless sensor networks, termed quanternion-domain super multi-dimensional scaling (QD-SMDS). The algorithm is based on a reformulation of the SMDS, originally developed in the real domain, using quaternion algebra. By representing 3D coordinates as quaternions, the method constructs a rank-1 Gram edge kernel (GEK) matrix that integrates both relative distance and angular information between nodes, which enhances the noise reduction effect achieved through low-rank truncation employing singular value decomposition (SVD), thereby improving robustness against information loss. To further reduce computational complexity, we also propose a variant of QD-SMDS that eliminates the need for the computationally expensive SVD by leveraging the inherent structure of the quaternion-domain GEK matrix. This alternative directly estimates node coordinates using only matrix multiplications within the quaternion domain. Simulation results demonstrate that the proposed method significantly improves localization accuracy compared to the original SMDS algorithm, especially in scenarios with substantial measurement errors. The proposed method also achieves comparable localization accuracy without requiring SVD.

Paper number 52:
Title: Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography
Authors: Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi
Abstract: Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.

Paper number 53:
Title: MCM: Mamba-based Cardiac Motion Tracking using Sequential Images in MRI
Authors: Jiahui Yin, Xinxing Cheng, Jinming Duan, Yan Pang, Declan O'Regan, Hadrien Reynaud, Qingjie Meng
Abstract: Myocardial motion tracking is important for assessing cardiac function and diagnosing cardiovascular diseases, for which cine cardiac magnetic resonance (CMR) has been established as the gold standard imaging modality. Many existing methods learn motion from single image pairs consisting of a reference frame and a randomly selected target frame from the cardiac cycle. However, these methods overlook the continuous nature of cardiac motion and often yield inconsistent and non-smooth motion estimations. In this work, we propose a novel Mamba-based cardiac motion tracking network (MCM) that explicitly incorporates target image sequence from the cardiac cycle to achieve smooth and temporally consistent motion tracking. By developing a bi-directional Mamba block equipped with a bi-directional scanning mechanism, our method facilitates the estimation of plausible deformation fields. With our proposed motion decoder that integrates motion information from frames adjacent to the target frame, our method further enhances temporal coherence. Moreover, by taking advantage of Mamba's structured state-space formulation, the proposed method learns the continuous dynamics of the myocardium from sequential images without increasing computational complexity. We evaluate the proposed method on two public datasets. The experimental results demonstrate that the proposed method quantitatively and qualitatively outperforms both conventional and state-of-the-art learning-based cardiac motion tracking methods. The code is available at this https URL.

Paper number 54:
Title: Piecewise Control Barrier Functions for Stochastic Systems
Authors: Rayan Mazouz, Luca Laurenti, Morteza Lahijanian
Abstract: This paper presents a method for the simultaneous synthesis of a barrier certificate and a safe controller for discrete-time nonlinear stochastic systems. Our approach, based on piecewise stochastic control barrier functions, reduces the synthesis problem to a minimax optimization, which we solve exactly using a dual linear program with zero gap. This enables the joint optimization of the barrier certificate and safe controller within a single formulation. The method accommodates stochastic dynamics with additive noise and a bounded continuous control set. The synthesized controllers and barrier certificates provide a formally guaranteed lower bound on probabilistic safety. Case studies on linear and nonlinear stochastic systems validate the effectiveness of our approach.

Paper number 55:
Title: Accent Normalization Using Self-Supervised Discrete Tokens with Non-Parallel Data
Authors: Qibing Bai, Sho Inoue, Shuai Wang, Zhongjie Jiang, Yannan Wang, Haizhou Li
Abstract: Accent normalization converts foreign-accented speech into native-like speech while preserving speaker identity. We propose a novel pipeline using self-supervised discrete tokens and non-parallel training data. The system extracts tokens from source speech, converts them through a dedicated model, and synthesizes the output using flow matching. Our method demonstrates superior performance over a frame-to-frame baseline in naturalness, accentedness reduction, and timbre preservation across multiple English accents. Through token-level phonetic analysis, we validate the effectiveness of our token-based approach. We also develop two duration preservation methods, suitable for applications such as dubbing.

Paper number 56:
Title: Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems
Authors: Zhongsheng Wang, Sijie Wang, Jia Wang, Yung-I Liang, Yuxi Zhang, Jiamou Liu
Abstract: In the design of customer relationship management (CRM) systems, accurately identifying customer types and offering personalized services are key to enhancing customer satisfaction and loyalty. However, this process faces the challenge of discerning customer voices and intentions, and general pre-trained automatic speech recognition (ASR) models make it difficult to effectively address industry-specific speech recognition tasks. To address this issue, we innovatively proposed a solution for fine-tuning industry-specific ASR models, which significantly improved the performance of the fine-tuned ASR models in industry applications. Experimental results show that our method substantially improves the crucial auxiliary role of the ASR model in industry CRM systems, and this approach has also been adopted in actual industrial applications.

Paper number 57:
Title: Coarse-to-fine crack cue for robust crack detection
Authors: Zelong Liu, Yuliang Gu, Zhichao Sun, Huachao Zhu, Xin Xiao, Bo Du, Laurent Najman (LIGM), Yongchao Xu
Abstract: Crack detection is an important task in computer vision. Despite impressive in-dataset performance, deep learning-based methods still struggle in generalizing to unseen domains. The thin structure property of cracks is usually overlooked by previous methods. In this work, we introduce CrackCue, a novel method for robust crack detection based on coarse-to-fine crack cue generation. The core concept lies on leveraging the thin structure property to generate a robust crack cue, guiding the crack detection. Specifically, we first employ a simple max-pooling and upsampling operation on the crack image. This results in a coarse crack-free background, based on which a fine crack-free background can be obtained via a reconstruction network. The difference between the original image and fine crack-free background provides a fine crack cue. This fine cue embeds robust crack prior information which is unaffected by complex backgrounds, shadow, and varied lighting. As a plug-and-play method, we incorporate the proposed CrackCue into three advanced crack detection networks. Extensive experimental results demonstrate that the proposed CrackCue significantly improves the generalization ability and robustness of the baseline methods. The source code will be publicly available.

Paper number 58:
Title: A tissue and cell-level annotated H&E and PD-L1 histopathology image dataset in non-small cell lung cancer
Authors: Joey Spronck, Leander van Eekelen, Dominique van Midden, Joep Bogaerts, Leslie Tessier, Valerie Dechering, Muradije Demirel-Andishmand, Gabriel Silva de Souza, Roland Nemeth, Enrico Munari, Giuseppe Bogina, Ilaria Girolami, Albino Eccher, Balazs Acs, Ceren Boyaci, Natalie Klubickova, Monika Looijen-Salamon, Shoko Vos, Francesco Ciompi
Abstract: The tumor immune microenvironment (TIME) in non-small cell lung cancer (NSCLC) histopathology contains morphological and molecular characteristics predictive of immunotherapy response. Computational quantification of TIME characteristics, such as cell detection and tissue segmentation, can support biomarker development. However, currently available digital pathology datasets of NSCLC for the development of cell detection or tissue segmentation algorithms are limited in scope, lack annotations of clinically prevalent metastatic sites, and forgo molecular information such as PD-L1 immunohistochemistry (IHC). To fill this gap, we introduce the IGNITE data toolkit, a multi-stain, multi-centric, and multi-scanner dataset of annotated NSCLC whole-slide images. We publicly release 887 fully annotated regions of interest from 155 unique patients across three complementary tasks: (i) multi-class semantic segmentation of tissue compartments in H&E-stained slides, with 16 classes spanning primary and metastatic NSCLC, (ii) nuclei detection, and (iii) PD-L1 positive tumor cell detection in PD-L1 IHC slides. To the best of our knowledge, this is the first public NSCLC dataset with manual annotations of H&E in metastatic sites and PD-L1 IHC.

Paper number 59:
Title: Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation
Authors: Juntao Lin, Xianghao Zhan
Abstract: Due to environmental changes and sensor aging, sensor drift challenges the performance of electronic nose systems in gas classification during real-world deployment. Previous studies using the UCI Gas Sensor Array Drift Dataset reported promising drift compensation results but lacked robust statistical experimental validation and may overcompensate for sensor drift, losing class-related this http URL address these limitations and improve sensor drift compensation with statistical rigor, we first designed two domain adaptation tasks based on the same electronic nose dataset: using the first batch to predict the remaining batches, simulating a controlled laboratory setting; and predicting the next batch using all prior batches, simulating continuous training data updates for online training. We then systematically tested three methods: our proposed novel Knowledge Distillation (KD) method, the benchmark method Domain Regularized Component Analysis (DRCA), and a hybrid method KD-DRCA, across 30 random test set partitions on the UCI dataset. We showed that KD consistently outperformed both DRCA and KD-DRCA, achieving up to an 18% improvement in accuracy and 15% in F1-score, demonstrating KD's superior effectiveness in drift compensation. This is the first application of KD for electronic nose drift mitigation, significantly outperforming the previous state-of-the-art DRCA method and enhancing the reliability of sensor drift compensation in real-world environments.

Paper number 60:
Title: ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search
Authors: Olivia Dry, Timothy L. Molloy, Wanxin Jin, Iman Shames
Abstract: We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations (ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of constrained optimal control problems, in both continuous and discrete time, to be learned from expert demonstrations without requiring smoothness of the learning-loss landscape. In contrast, existing state-of-the-art first-order methods require the existence and computation of gradients of the costs, constraints, dynamics, and learning loss with respect to states, controls and/or parameters. Most existing methods are also tailored to discrete time, with constrained problems in continuous time receiving only cursory attention. We demonstrate that ZORMS-LfD matches or surpasses the performance of state-of-the-art methods in terms of both learning loss and compute time across a variety of benchmark problems. On unconstrained continuous-time benchmark problems, ZORMS-LfD achieves similar loss performance to state-of-the-art first-order methods with an over $80$\% reduction in compute time. On constrained continuous-time benchmark problems where there is no specialized state-of-the-art method, ZORMS-LfD is shown to outperform the commonly used gradient-free Nelder-Mead optimization method.

Paper number 61:
Title: Stochastically Structured Reservoir Computers for Financial and Economic System Identification
Authors: Lendy Banegas, Fredy Vides
Abstract: This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The proposed framework leverages structure-preserving embeddings and graph-informed coupling matrices to model inter-agent dynamics with enhanced interpretability. A constrained optimization scheme ensures that the learned models satisfy both stochastic and structural constraints. Two empirical case studies, a dynamic behavioral model of resource competition among agents, and regional inflation network dynamics, illustrate the effectiveness of the approach in capturing and anticipating complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.

Paper number 62:
Title: Our Cars Can Talk: How IoT Brings AI to Vehicles
Authors: Amod Kant Agrawal
Abstract: Bringing AI to vehicles and enabling them as sensing platforms is key to transforming maintenance from reactive to proactive. Now is the time to integrate AI copilots that speak both languages: machine and driver. This article offers a conceptual and technical perspective intended to spark interdisciplinary dialogue and guide future research and development in intelligent vehicle systems, predictive maintenance, and AI-powered user interaction.

Paper number 63:
Title: High-Density EEG Enables the Fastest Visual Brain-Computer Interfaces
Authors: Gege Ming (1), Weihua Pei (2 and 3), Sen Tian (4), Xiaogang Chen (5), Xiaorong Gao (1), Yijun Wang (2, 3 and 6) ((1) Department of Biomedical Engineering, Tsinghua University, (2) Laboratory of Solid-State Optoelectronics Information Technology, Institute of Semiconductors, Chinese Academy of Sciences, (3) School of Future Technology, University of Chinese Academy of Sciences, (4) Suzhou Nianji Intelligent Technology Co., Ltd., (5) Institute of Biomedical Engineering, Chinese Academy of Medical Sciences and Peking Union Medical College, (6) Chinese Institute for Brain Research)
Abstract: Brain-computer interface (BCI) technology establishes a direct communication pathway between the brain and external devices. Current visual BCI systems suffer from insufficient information transfer rates (ITRs) for practical use. Spatial information, a critical component of visual perception, remains underexploited in existing systems because the limited spatial resolution of recording methods hinders the capture of the rich spatiotemporal dynamics of brain signals. This study proposed a frequency-phase-space fusion encoding method, integrated with 256-channel high-density electroencephalogram (EEG) recordings, to develop high-speed BCI systems. In the classical frequency-phase encoding 40-target BCI paradigm, the 256-66, 128-32, and 64-21 electrode configurations brought theoretical ITR increases of 83.66%, 79.99%, and 55.50% over the traditional 64-9 setup. In the proposed frequency-phase-space encoding 200-target BCI paradigm, these increases climbed to 195.56%, 153.08%, and 103.07%. The online BCI system achieved an average actual ITR of 472.7 bpm. This study demonstrates the essential role and immense potential of high-density EEG in decoding the spatiotemporal information of visual stimuli.

Paper number 64:
Title: Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge
Authors: Miaomiao Gao, Xiaoxiao Xiang, Yiwen Guo
Abstract: This paper describes our Triple X speech recognition system submitted to Task 1 of the Multi-Lingual Conversational Speech Language Modeling (MLC-SLM) Challenge. Our work focuses on optimizing speech recognition accuracy in multilingual conversational scenarios through an innovative encoder-adapter-LLM architecture. This framework harnesses the powerful reasoning capabilities of text-based large language models while incorporating domain-specific adaptations. To further enhance multilingual recognition performance, we adopted a meticulously designed multi-stage training strategy leveraging extensive multilingual audio datasets. Experimental results demonstrate that our approach achieves competitive Word Error Rate (WER) performance on both dev and test sets, obtaining second place in the challenge ranking.

Paper number 65:
Title: On Temporal Guidance and Iterative Refinement in Audio Source Separation
Authors: Tobias Morocutti, Jonathan Greif, Paul Primus, Florian Schmid, Gerhard Widmer
Abstract: Spatial semantic segmentation of sound scenes (S5) involves the accurate identification of active sound classes and the precise separation of their sources from complex acoustic mixtures. Conventional systems rely on a two-stage pipeline - audio tagging followed by label-conditioned source separation - but are often constrained by the absence of fine-grained temporal information critical for effective separation. In this work, we address this limitation by introducing a novel approach for S5 that enhances the synergy between the event detection and source separation stages. Our key contributions are threefold. First, we fine-tune a pre-trained Transformer to detect active sound classes. Second, we utilize a separate instance of this fine-tuned Transformer to perform sound event detection (SED), providing the separation module with detailed, time-varying guidance. Third, we implement an iterative refinement mechanism that progressively enhances separation quality by recursively reusing the separator's output from previous iterations. These advancements lead to significant improvements in both audio tagging and source separation performance, as demonstrated by our system's second-place finish in Task 4 of the DCASE Challenge 2025. Our implementation and model checkpoints are available in our GitHub repository: this https URL .

Paper number 66:
Title: EndoGen: Conditional Autoregressive Endoscopic Video Generation
Authors: Xinyu Liu, Hengyu Liu, Cheng Wang, Tianming Liu, Yixuan Yuan
Abstract: Endoscopic video generation is crucial for advancing medical imaging and enhancing diagnostic capabilities. However, prior efforts in this field have either focused on static images, lacking the dynamic context required for practical applications, or have relied on unconditional generation that fails to provide meaningful references for clinicians. Therefore, in this paper, we propose the first conditional endoscopic video generation framework, namely EndoGen. Specifically, we build an autoregressive model with a tailored Spatiotemporal Grid-Frame Patterning (SGP) strategy. It reformulates the learning of generating multiple frames as a grid-based image generation pattern, which effectively capitalizes the inherent global dependency modeling capabilities of autoregressive architectures. Furthermore, we propose a Semantic-Aware Token Masking (SAT) mechanism, which enhances the model's ability to produce rich and diverse content by selectively focusing on semantically meaningful regions during the generation process. Through extensive experiments, we demonstrate the effectiveness of our framework in generating high-quality, conditionally guided endoscopic content, and improves the performance of downstream task of polyp segmentation. Code released at this https URL.

Paper number 67:
Title: DFDNet: Dynamic Frequency-Guided De-Flare Network
Authors: Minglong Xue, Aoxiang Ning, Shivakumara Palaiahnakote, Mingliang Zhou
Abstract: Strong light sources in nighttime photography frequently produce flares in images, significantly degrading visual quality and impacting the performance of downstream tasks. While some progress has been made, existing methods continue to struggle with removing large-scale flare artifacts and repairing structural damage in regions near the light source. We observe that these challenging flare artifacts exhibit more significant discrepancies from the reference images in the frequency domain compared to the spatial domain. Therefore, this paper presents a novel dynamic frequency-guided deflare network (DFDNet) that decouples content information from flare artifacts in the frequency domain, effectively removing large-scale flare artifacts. Specifically, DFDNet consists mainly of a global dynamic frequency-domain guidance (GDFG) module and a local detail guidance module (LDGM). The GDFG module guides the network to perceive the frequency characteristics of flare artifacts by dynamically optimizing global frequency domain features, effectively separating flare information from content information. Additionally, we design an LDGM via a contrastive learning strategy that aligns the local features of the light source with the reference image, reduces local detail damage from flare removal, and improves fine-grained image restoration. The experimental results demonstrate that the proposed method outperforms existing state-of-the-art methods in terms of performance. The code is available at \href{this https URL}{this https URL}.

Paper number 68:
Title: To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks
Authors: Rashika Raina, Nidhi Simmons, David E. Simmons, Michel Daoud Yacoub, Trung Q. Duong
Abstract: In next-generation communications and networks, machine learning (ML) models are expected to deliver not only accurate predictions but also well-calibrated confidence scores that reflect the true likelihood of correct decisions. This paper studies the calibration performance of an ML-based outage predictor within a single-user, multi-resource allocation framework. We first establish key theoretical properties of this system's outage probability (OP) under perfect calibration. Importantly, we show that as the number of resources grows, the OP of a perfectly calibrated predictor approaches the expected output conditioned on it being below the classification threshold. In contrast, when only one resource is available, the system's OP equals the model's overall expected output. We then derive the OP conditions for a perfectly calibrated predictor. These findings guide the choice of the classification threshold to achieve a desired OP, helping system designers meet specific reliability requirements. We also demonstrate that post-processing calibration cannot improve the system's minimum achievable OP, as it does not introduce new information about future channel states. Additionally, we show that well-calibrated models are part of a broader class of predictors that necessarily improve OP. In particular, we establish a monotonicity condition that the accuracy-confidence function must satisfy for such improvement to occur. To demonstrate these theoretical properties, we conduct a rigorous simulation-based analysis using post-processing calibration techniques: Platt scaling and isotonic regression. As part of this framework, the predictor is trained using an outage loss function specifically designed for this system. Furthermore, this analysis is performed on Rayleigh fading channels with temporal correlation captured by Clarke's 2D model, which accounts for receiver mobility.

Paper number 69:
Title: STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds
Authors: Tian Guo, Hui Yuan, Xiaolong Mao, Shiqi Jiang, Raouf Hamzaoui, Sam Kwong
Abstract: Very few studies have addressed quality enhancement for compressed dynamic point clouds. In particular, the effective exploitation of spatial-temporal correlations between point cloud frames remains largely unexplored. Addressing this gap, we propose a spatial-temporal attribute quality enhancement (STQE) network that exploits both spatial and temporal correlations to improve the visual quality of G-PCC compressed dynamic point clouds. Our contributions include a recoloring-based motion compensation module that remaps reference attribute information to the current frame geometry to achieve precise inter-frame geometric alignment, a channel-aware temporal attention module that dynamically highlights relevant regions across bidirectional reference frames, a Gaussian-guided neighborhood feature aggregation module that efficiently captures spatial dependencies between geometry and color attributes, and a joint loss function based on the Pearson correlation coefficient, designed to alleviate over-smoothing effects typical of point-wise mean squared error optimization. When applied to the latest G-PCC test model, STQE achieved improvements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, with Bjøntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5% for the Luma, Cb, and Cr components, respectively.

Paper number 70:
Title: Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice
Authors: Shanbo Cheng, Yu Bao, Zhichao Huang, Yu Lu, Ningxin Peng, Lu Xu, Runsheng Yu, Rong Cao, Ting Han, Zeyang Li, Sitong Liu, Shengtao Ma, Shiguang Pan, Jiongchen Xiao, Nuo Xu, Meng Yang, Rong Ye, Yiming Yu, Ruofei Zhang, Wanyi Zhang, Wenhao Zhu, Liehao Zou, Lu Lu, Yuxuan Wang, Yonghui Wu
Abstract: Simultaneous Interpretation (SI) represents one of the most daunting frontiers in the translation industry, with product-level automatic systems long plagued by intractable challenges: subpar transcription and translation quality, lack of real-time speech generation, multi-speaker confusion, and translated speech inflation, especially in long-form discourses. In this study, we introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers high-fidelity, ultra-low-latency speech-to-speech generation with voice cloning capabilities. As a fully operational product-level solution, Seed-LiveInterpret 2.0 tackles these challenges head-on through our novel duplex speech-to-speech understanding-generating framework. Experimental results demonstrate that through large-scale pretraining and reinforcement learning, the model achieves a significantly better balance between translation accuracy and latency, validated by human interpreters to exceed 70% correctness in complex scenarios. Notably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by significant margins in translation quality, while slashing the average latency of cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is around a near 70% reduction that drastically enhances practical usability.

Paper number 71:
Title: Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning
Authors: Xinyao Liu, Diping Song
Abstract: Multimodal large language models (MLLMs) demonstrate significant potential in the field of medical diagnosis. However, they face critical challenges in specialized domains such as ophthalmology, particularly the fragmentation of annotation granularity and inconsistencies in clinical reasoning logic, which hinder precise cross-modal understanding. This paper introduces FundusExpert, an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning capabilities, along with FundusGen, a dataset constructed through the intelligent Fundus-Engine system. Fundus-Engine automates localization and leverages MLLM-based semantic expansion to integrate global disease classification, local object detection, and fine-grained feature analysis within a single fundus image. Additionally, by constructing a clinically aligned cognitive chain, it guides the model to generate interpretable reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen, achieves the best performance in ophthalmic question-answering tasks, surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in zero-shot report generation tasks, achieving a clinical consistency of 77.0%, significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling law between data quality and model capability ($L \propto N^{0.068}$), demonstrating that the cognitive alignment annotations in FundusGen enhance data utilization efficiency. By integrating region-level localization with diagnostic reasoning chains, our work develops a scalable, clinically-aligned MLLM and explores a pathway toward bridging the visual-language gap in specific MLLMs. Our project can be found at this https URL.

Paper number 72:
Title: BoSS: Beyond-Semantic Speech
Authors: Qing Wang, Zehan Li, Hang Lv, Hongjie Chen, Yaodong Song, Jian Kang, Jie Lian, Jie Li, Yongxiang Li, Zhongjiang He, Xuelong Li
Abstract: Human communication involves more than explicit semantics, with implicit signals and contextual cues playing a critical role in shaping meaning. However, modern speech technologies, such as Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) often fail to capture these beyond-semantic dimensions. To better characterize and benchmark the progression of speech intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5), a hierarchical framework illustrated the evolution of spoken dialogue systems from basic command recognition to human-like social interaction. To support these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which refers to the set of information in speech communication that encompasses but transcends explicit semantics. It conveys emotions, contexts, and modifies or extends meanings through multidimensional features such as affective cues, contextual dynamics, and implicit semantics, thereby enhancing the understanding of communicative intentions and scenarios. We present a formalized framework for BoSS, leveraging cognitive relevance theories and machine learning models to analyze temporal and contextual speech dynamics. We evaluate BoSS-related attributes across five different dimensions, reveals that current spoken language models (SLMs) are hard to fully interpret beyond-semantic signals. These findings highlight the need for advancing BoSS research to enable richer, more context-aware human-machine communication.

Paper number 73:
Title: Audio-Vision Contrastive Learning for Phonological Class Recognition
Authors: Daiqi Liu, Tomás Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea Pérez-Toro
Abstract: Accurate classification of articulatory-phonological features plays a vital role in understanding human speech production and developing robust speech technologies, particularly in clinical contexts where targeted phonemic analysis and therapy can improve disease diagnosis accuracy and personalized rehabilitation. In this work, we propose a multimodal deep learning framework that combines real-time magnetic resonance imaging (rtMRI) and speech signals to classify three key articulatory dimensions: manner of articulation, place of articulation, and voicing. We perform classification on 15 phonological classes derived from the aforementioned articulatory dimensions and evaluate the system with four audio/vision configurations: unimodal rtMRI, unimodal audio signals, multimodal middle fusion, and contrastive learning-based audio-vision fusion. Experimental results on the USC-TIMIT dataset show that our contrastive learning-based approach achieves state-of-the-art performance, with an average F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal baseline. The results confirm the effectiveness of contrastive representation learning for multimodal articulatory analysis. Our code and processed dataset will be made publicly available at this https URL to support future research.

Paper number 74:
Title: Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems
Authors: Shreya Meel, Sennur Ulukus
Abstract: We introduce the problem of symmetric private information retrieval (SPIR) on replicated databases modeled by a simple graph. In this model, each vertex corresponds to a server, and a message is replicated on two servers if and only if there is an edge between them. We consider the setting where the server-side common randomness necessary to accomplish SPIR is also replicated at the servers according to the graph, and we call this as message-specific common randomness. In this setting, we establish a lower bound on the SPIR capacity, i.e., the maximum download rate, for general graphs, by proposing an achievable SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the minimum size of message-specific randomness should be equal to the size of a message. Finally, by providing matching upper bounds, we derive the exact SPIR capacity for the class of path and regular graphs.

Paper number 75:
Title: Blind Source Separation of Single-Channel Mixtures via Multi-Encoder Autoencoders
Authors: Matthew B. Webster, Joonnyong Lee
Abstract: The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. Single-channel mixtures and non-linear mixtures are a particularly challenging problem in BSS. In this paper, we propose a novel method for addressing BSS with single-channel non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a sparse mixing loss that encourages sparse remixing of source encodings throughout the decoder and a so-called zero reconstruction loss on the decoder for coherent source estimations. To analyze and evaluate our method, we conduct experiments on a toy dataset, designed to demonstrate this property of feature subspace specialization, and with real-world biosignal recordings from a polysomnography sleep study for extracting respiration from electrocardiogram and photoplethysmography signals.

Paper number 76:
Title: Coordinate-based Speed of Sound Recovery for Aberration-Corrected Photoacoustic Computed Tomography
Authors: Tianao Li, Manxiu Cui, Cheng Ma, Emma Alexander
Abstract: Photoacoustic computed tomography (PACT) is a non-invasive imaging modality, similar to ultrasound, with wide-ranging medical applications. Conventional PACT images are degraded by wavefront distortion caused by the heterogeneous speed of sound (SOS) in tissue. Accounting for these effects can improve image quality and provide medically useful information, but measuring the SOS directly is burdensome and the existing joint reconstruction method is computationally expensive. Traditional supervised learning techniques are currently inaccessible in this data-starved domain. In this work, we introduce an efficient, self-supervised joint reconstruction method that recovers SOS and high-quality images for ring array PACT systems. To solve this semi-blind inverse problem, we parametrize the SOS using either a pixel grid or a neural field (NF) and update it directly by backpropagating the gradients through a differentiable imaging forward model. Our method removes SOS aberrations more accurately and 35x faster than the current SOTA. We demonstrate the success of our method quantitatively in simulation and qualitatively on experimentally-collected and in vivo data. Our code and synthetic numerical phantoms are available on our project page: this https URL.

Paper number 77:
Title: Vascular Segmentation of Functional Ultrasound Images using Deep Learning
Authors: Hana Sebia (AISTROSIGHT), Thomas Guyet (AISTROSIGHT), Mickaël Pereira (CERMEP - imagerie du vivant), Marco Valdebenito (CERMEP - imagerie du vivant), Hugues Berry (AISTROSIGHT), Benjamin Vidal (CERMEP - imagerie du vivant, CRNL, UCBL)
Abstract: Segmentation of medical images is a fundamental task with numerous applications. While MRI, CT, and PET modalities have significantly benefited from deep learning segmentation techniques, more recent modalities, like functional ultrasound (fUS), have seen limited progress. fUS is a non invasive imaging method that measures changes in cerebral blood volume (CBV) with high spatio-temporal resolution. However, distinguishing arterioles from venules in fUS is challenging due to opposing blood flow directions within the same pixel. Ultrasound localization microscopy (ULM) can enhance resolution by tracking microbubble contrast agents but is invasive, and lacks dynamic CBV quantification. In this paper, we introduce the first deep learning-based segmentation tool for fUS images, capable of differentiating signals from different vascular compartments, based on ULM automatic annotation and enabling dynamic CBV quantification. We evaluate various UNet architectures on fUS images of rat brains, achieving competitive segmentation performance, with 90% accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames from a fUS stack. These results are comparable to those from tubular structure segmentation in other imaging modalities. Additionally, models trained on resting-state data generalize well to images captured during visual stimulation, highlighting robustness. This work offers a non-invasive, cost-effective alternative to ULM, enhancing fUS data interpretation and improving understanding of vessel function. Our pipeline shows high linear correlation coefficients between signals from predicted and actual compartments in both cortical and deeper regions, showcasing its ability to accurately capture blood flow dynamics.

Paper number 78:
Title: AI and Deep Learning for Terahertz Ultra-Massive MIMO: From Model-Driven Approaches to Foundation Models
Authors: Wentao Yu, Hengtao He, Shenghui Song, Jun Zhang, Linglong Dai, Lizhong Zheng, Khaled B. Letaief
Abstract: This study explored the transformative potential of artificial intelligence (AI) in addressing the challenges posed by terahertz ultra-massive multiple-input multiple-output (UM-MIMO) systems. It begins by outlining the characteristics of terahertz UM-MIMO systems and identifies three primary challenges for transceiver design: computational complexity, modeling difficulty, and measurement limitations. The study posits that AI provides a promising solution to these challenges. Three systematic research roadmaps are proposed for developing AI algorithms tailored to terahertz UM-MIMO systems. The first roadmap, model-driven deep learning (DL), emphasizes the importance of leveraging available domain knowledge and advocates the adoption of AI only to enhance bottleneck modules within an established signal processing or optimization framework. Four essential steps are discussed: algorithmic frameworks, basis algorithms, loss-function design, and neural architecture design. The second roadmap presents channel state information (CSI) foundation models, aimed at unifying the design of different transceiver modules by focusing on their shared foundation, that is, the wireless channel. The training of a single compact foundation model is proposed to estimate the score function of wireless channels, which serve as a versatile prior for designing a wide variety of transceiver modules. Four essential steps are outlined: general frameworks, conditioning, site-specific adaptation, joint design of CSI foundation models, and model-driven DL. The third roadmap aims to explore potential directions for applying pretrained large language models (LLMs) to terahertz UM-MIMO systems. Several application scenarios are envisioned, including LLM-based estimation, optimization, search, network management, and protocol understanding. Finally, the study highlights open problems and future research directions.

Paper number 79:
Title: Safe Trajectory Sets for Online Operation of Power Systems under Uncertainty
Authors: Florian Klein-Helmkamp, Tina Möllemann, Irina Zettl, Steffen Kortmann, Andreas Ulbig
Abstract: Flexibility provision from active distribution grids requires efficient and robust methods of optimization and control suitable to online operation. In this paper we introduce conditions for the safe operation of feedback optimization based controllers. We use the feasible operating region of a controlled system as bounds for safe system states and evaluate the trajectories of the controller based on the projection of the full system state onto the two-dimensional PQ-plane. We demonstrate the defined conditions for an exemplary sub-transmission system. We show that the proposed method is suitable to evaluate controller performance and robustness for systems subject to disturbances.

Paper number 80:
Title: Pinching-Antenna Systems (PASS): Architecture Designs, Opportunities, and Outlook
Authors: Yuanwei Liu, Zhaolin Wang, Xidong Mu, Chongjun Ouyang, Xiaoxia Xu, Zhiguo Ding
Abstract: Flexible-antenna systems have recently attracted significant research attention due to their potential to intelligently reconfigure wireless channels. However, the current flexible-antenna systems still suffer from fundamental limitations, such as free-space path loss and line-of-sight blockage. This article introduces a novel flexible-antenna system, termed the Pinching-Antenna SyStem (PASS). PASS adopts the dielectric waveguides as the primary transmission medium and radiates signals into free space by flexibly pinching discrete dielectric particles, referred to as pinching antennas, along the waveguide. By combining the strengths of both wireless and wired communication, PASS effectively mitigates inherent wireless limitations while offering high antenna reconfigurability. This article reviews the key features of PASS in comparison with conventional wireless systems, analyzes its main advantages, and discusses potential designs, transmission architectures, and application scenarios. Finally, it outlines promising research directions and open challenges associated with PASS.

Paper number 81:
Title: LanPaint: Training-Free Diffusion Inpainting with Asymptotically Exact and Fast Conditional Sampling
Authors: Candi Zheng, Yuan Lan, Yang Wang
Abstract: Diffusion models excel at joint pixel sampling for image generation but lack efficient training-free methods for partial conditional sampling (e.g., inpainting with known pixels). Prior work typically formulates this as an intractable inverse problem, relying on coarse variational approximations, heuristic losses requiring expensive backpropagation, or slow stochastic sampling. These limitations preclude: (1) accurate distributional matching in inpainting results, (2) efficient inference modes without gradient, (3) compatibility with fast ODE-based samplers. To address these limitations, we propose \textbf{LanPaint}: a training-free, asymptotically exact partial conditional sampling methods for ODE-based and rectified flow diffusion models. By leveraging carefully designed Langevin dynamics, LanPaint enables fast, backpropagation-free Monte Carlo sampling. Experiments demonstrate that our approach achieves superior performance with precise partial conditioning and visually coherent inpainting across diverse tasks.

Paper number 82:
Title: System Level Synthesis for Affine Control Policies: Model Based and Data-Driven Settings
Authors: Lukas Schüepp, Giulia De Pasquale, Florian Dörfler, Carmen Amo Alonso
Abstract: There is an increasing need for effective control of systems with complex dynamics, particularly through data-driven approaches. System Level Synthesis (SLS) has emerged as a powerful framework that facilitates the control of large-scale systems while accounting for model uncertainties. SLS approaches are currently limited to linear systems and time-varying linear control policies, thus limiting the class of achievable control strategies. We introduce a novel closed-loop parameterization for time-varying affine control policies, extending the SLS framework to a broader class of systems and policies. We show that the closed-loop behavior under affine policies can be equivalently characterized using past system trajectories, enabling a fully data-driven formulation. This parameterization seamlessly integrates affine policies into optimal control problems, allowing for a closed-loop formulation of general Model Predictive Control (MPC) problems. To the best of our knowledge, this is the first work to extend SLS to affine policies in both model-based and data-driven settings, enabling an equivalent formulation of MPC problems using closed-loop maps. We validate our approach through numerical experiments, demonstrating that our model-based and data-driven affine SLS formulations achieve performance on par with traditional model-based MPC.

Paper number 83:
Title: Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis
Authors: Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen
Abstract: Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual this http URL demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at this https URL.

Paper number 84:
Title: Coherent Source Enumeration with Compact ULAs
Authors: Dibakar Sil, Sunder Ram Krishnan, Kumar Vijay Mishra
Abstract: Source enumeration typically relies on subspace-based techniques that require accurate separation of signal and noise subspaces. However, prior works do not address coherent sources in small uniform linear arrays, where ambiguities arise in the spatial spectrum. We address this by decomposing the forward-backward smoothed covariance matrix into a sum of a rank-constrained Toeplitz matrix and a diagonal matrix with non-negative entries representing the signal and noise subspaces, respectively. The resulting non-convex optimization problem is solved by proposing Toeplitz approach for rank-based target estimation (TARgEt) that employs the alternating direction method of multipliers. Numerical results on both synthetic and real-world datasets demonstrate the effectiveness and robustness of TARgEt over the state-of-the-art.

Paper number 85:
Title: ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting
Authors: Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Tao Jin, Zhou Zhao
Abstract: Multimodal immersive spatial drama generation focuses on creating continuous multi-speaker binaural speech with dramatic prosody based on multimodal prompts, with potential applications in AR, VR, and others. This task requires simultaneous modeling of spatial information and dramatic prosody based on multimodal inputs, with high data collection costs. To the best of our knowledge, our work is the first attempt to address these challenges. We construct MRSDrama, the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. Then, we propose ISDrama, the first immersive spatial drama generation model through multimodal prompting. ISDrama comprises these primary components: 1) Multimodal Pose Encoder, based on contrastive learning, considering the Doppler effect caused by moving speakers to extract unified pose information from multimodal prompts. 2) Immersive Drama Transformer, a flow-based mamba-transformer model that generates high-quality drama, incorporating Drama-MOE to select proper experts for enhanced prosody and pose control. We also design a context-consistent classifier-free guidance strategy to coherently generate complete drama. Experimental results show that ISDrama outperforms baseline models on objective and subjective metrics. The demos are available at this https URL. We provide the dataset and the evaluation code at this https URL and this https URL.

Paper number 86:
Title: Beyond Single-Channel: Multichannel Signal Imaging for PPG-to-ECG Reconstruction with Vision Transformers
Authors: Xiaoyan Li, Shixin Xu, Faisal Habib, Arvind Gupta, Huaxiong Huang
Abstract: Reconstructing ECG from PPG is a promising yet challenging task. While recent advancements in generative models have significantly improved ECG reconstruction, accurately capturing fine-grained waveform features remains a key challenge. To address this, we propose a novel PPG-to-ECG reconstruction method that leverages a Vision Transformer (ViT) as the core network. Unlike conventional approaches that rely on single-channel PPG, our method employs a four-channel signal image representation, incorporating the original PPG, its first-order difference, second-order difference, and area under the curve. This multi-channel design enriches feature extraction by preserving both temporal and physiological variations within the PPG. By leveraging the self-attention mechanism in ViT, our approach effectively captures both inter-beat and intra-beat dependencies, leading to more robust and accurate ECG reconstruction. Experimental results demonstrate that our method consistently outperforms existing 1D convolution-based approaches, achieving up to 29% reduction in PRD and 15% reduction in RMSE. The proposed approach also produces improvements in other evaluation metrics, highlighting its robustness and effectiveness in reconstructing ECG signals. Furthermore, to ensure a clinically relevant evaluation, we introduce new performance metrics, including QRS area error, PR interval error, RT interval error, and RT amplitude difference error. Our findings suggest that integrating a four-channel signal image representation with the self-attention mechanism of ViT enables more effective extraction of informative PPG features and improved modeling of beat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the potential of PPG as a viable alternative for heart activity monitoring, our approach opens new avenues for cyclic signal analysis and prediction.

Paper number 87:
Title: Channel Estimation for RIS-Assisted mmWave Systems via Diffusion Models
Authors: Yang Wang, Yin Xu, Cixiao Zhang, Zhiyong Chen, Mingzeng Dai, Haiming Wang, Bingchao Liu, Dazhi He, Meixia Tao
Abstract: Reconfigurable intelligent surface (RIS) has been recognized as a promising technology for next-generation wireless communications. However, the performance of RIS-assisted systems critically depends on accurate channel state information (CSI). To address this challenge, this letter proposes a novel channel estimation method for RIS-aided millimeter-wave (mmWave) systems based on diffusion models (DMs). Specifically, the forward diffusion process of the original signal is formulated to model the received signal as a noisy observation within the framework of DMs. Subsequently, the channel estimation task is formulated as the reverse diffusion process, and a sampling algorithm based on denoising diffusion implicit models (DDIMs) is developed to enable effective inference. Furthermore, a lightweight neural network, termed BRCNet, is introduced to replace the conventional U-Net, significantly reducing the number of parameters and computational complexity. Extensive experiments conducted under various scenarios demonstrate that the proposed method consistently outperforms existing baselines.

Paper number 88:
Title: MRI-CORE: A Foundation Model for Magnetic Resonance Imaging
Authors: Haoyu Dong, Yuwen Chen, Hanxue Gu, Nicholas Konz, Yaqian Chen, Qihang Li, Maciej A. Mazurowski
Abstract: The widespread use of Magnetic Resonance Imaging (MRI) in combination with deep learning shows promise for many high-impact automated diagnostic and prognostic tools. However, training new models requires large amounts of labeled data, a challenge due to high cost of precise annotations and data privacy. To address this issue, we introduce the MRI-CORE, a vision foundation model trained using more than 6 million slices from over 110 thousand MRI volumes across 18 body locations. Our experiments show notable improvements in performance over state-of-the-art methods in 13 data-restricted segmentation tasks, as well as in image classification, and zero-shot segmentation, showing the strong potential of MRI-CORE to enable data-efficient development of artificial intelligence models. We also present data on which strategies yield most useful foundation models and a novel analysis relating similarity between pre-training and downstream task data with transfer learning performance. Our model is publicly available with a permissive license.

Paper number 89:
Title: Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images
Authors: Alireza Golkarieh, Kiana Kiashemshaki, Sajjad Rezvani Boroujeni, Nasibeh Asadi Isakan
Abstract: This study investigates the effectiveness of U-Net architectures integrated with various convolutional neural network (CNN) backbones for automated lung cancer detection and segmentation in chest CT images, addressing the critical need for accurate diagnostic tools in clinical settings. A balanced dataset of 832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed using Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to 128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50, VGG16, and Xception, to segment lung regions. After segmentation, CNN-based classifiers and hybrid models combining CNN feature extraction with traditional machine learning classifiers (Support Vector Machine, Random Forest, and Gradient Boosting) were evaluated using 5-fold cross-validation. Metrics included accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC. U-Net with ResNet50 achieved the best performance for cancerous lungs (Dice: 0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for non-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For classification, the CNN model using U-Net with Xception achieved 99.1 percent accuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid CNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent F1-score. Compared to prior methods, our framework consistently outperformed existing models. In conclusion, combining U-Net with advanced CNN backbones provides a powerful method for both segmentation and classification of lung cancer in CT scans, supporting early diagnosis and clinical decision-making.

Paper number 90:
Title: NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment
Authors: ZhengXiao He, Jinghao Wen, Huayu Li, Siyuan Tian, Ao Li
Abstract: We present a novel and interpretable framework for electrocardiogram (ECG)-based disease detection that combines hyperdimensional computing (HDC) with learnable neural encoding. Unlike conventional HDC approaches that rely on static, random projections, our method introduces a rhythm-aware and trainable encoding pipeline based on RR intervals, a physiological signal segmentation strategy that aligns with cardiac cycles. The core of our design is a neural-distilled HDC architecture, featuring a learnable RR-block encoder and a BinaryLinear hyperdimensional projection layer, optimized jointly with cross-entropy and proxy-based metric loss. This hybrid framework preserves the symbolic interpretability of HDC while enabling task-adaptive representation learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model significantly outperforms traditional HDC and classical ML baselines, achieving 73.09\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable robustness on PTB-XL. Our framework offers an efficient and scalable solution for edge-compatible ECG classification, with strong potential for interpretable and personalized health monitoring.

Paper number 91:
Title: Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion
Authors: Yu Zhang, Baotong Tian, Zhiyao Duan
Abstract: Zero-shot online voice conversion (VC) holds significant promise for real-time communications and entertainment. However, current VC models struggle to preserve semantic fidelity under real-time constraints, deliver natural-sounding conversions, and adapt effectively to unseen speaker characteristics. To address these challenges, we introduce Conan, a chunkwise online zero-shot voice conversion model that preserves the content of the source while matching the voice timbre and styles of reference speech. Conan comprises three core components: 1) a Stream Content Extractor that leverages Emformer for low-latency streaming content encoding; 2) an Adaptive Style Encoder that extracts fine-grained stylistic features from reference speech for enhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully causal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations demonstrate that Conan outperforms baseline models in subjective and objective metrics. Audio samples can be found at this https URL.

Paper number 92:
Title: EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro
Authors: An Wang, Rulin Zhou, Mengya Xu, Yiru Ye, Longfei Gou, Yiting Chang, Hao Chen, Chwee Ming Lim, Jiankun Wang, Hongliang Ren
Abstract: Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at this https URL.

Paper number 93:
Title: SFNet: A Spatial-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis
Authors: Xinyue Yang, Meiliang Liu, Yunfang Xu, Xiaoxiao Yang, Zhengye Si, Zijin Li, Zhiwen Zhao
Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that predominantly affects the elderly population and currently has no cure. Magnetic Resonance Imaging (MRI), as a non-invasive imaging technique, is essential for the early diagnosis of AD. MRI inherently contains both spatial and frequency information, as raw signals are acquired in the frequency domain and reconstructed into spatial images via the Fourier transform. However, most existing AD diagnostic models extract features from a single domain, limiting their capacity to fully capture the complex neuroimaging characteristics of the disease. While some studies have combined spatial and frequency information, they are mostly confined to 2D MRI, leaving the potential of dual-domain analysis in 3D MRI unexplored. To overcome this limitation, we propose Spatio-Frequency Network (SFNet), the first end-to-end deep learning framework that simultaneously leverages spatial and frequency domain information to enhance 3D MRI-based AD diagnosis. SFNet integrates an enhanced dense convolutional network to extract local spatial features and a global frequency module to capture global frequency-domain representations. Additionally, a novel multi-scale attention module is proposed to further refine spatial feature extraction. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that SFNet outperforms existing baselines and reduces computational overhead in classifying cognitively normal (CN) and AD, achieving an accuracy of 95.1%.

Paper number 94:
Title: First, Learn What You Don't Know: Active Information Gathering for Driving at the Limits of Handling
Authors: Alexander Davydov, Franck Djeumou, Marcus Greiff, Makoto Suminaka, Michael Thompson, John Subosits, Thomas Lew
Abstract: Combining data-driven models that adapt online and model predictive control (MPC) has enabled effective control of nonlinear systems. However, when deployed on unstable systems, online adaptation may not be fast enough to ensure reliable simultaneous learning and control. For example, a controller on a vehicle executing highly dynamic maneuvers--such as drifting to avoid an obstacle--may push the vehicle's tires to their friction limits, destabilizing the vehicle and allowing modeling errors to quickly compound and cause a loss of control. To address this challenge, we present an active information gathering framework for identifying vehicle dynamics as quickly as possible. We propose an expressive vehicle dynamics model that leverages Bayesian last-layer meta-learning to enable rapid online adaptation. The model's uncertainty estimates are used to guide informative data collection and quickly improve the model prior to deployment. Dynamic drifting experiments on a Toyota Supra show that (i) the framework enables reliable control of a vehicle at the edge of stability, (ii) online adaptation alone may not suffice for zero-shot control and can lead to undesirable transient errors or spin-outs, and (iii) active data collection helps achieve reliable performance.

Paper number 95:
Title: Exact Model Reduction for Continuous-Time Open Quantum Dynamics
Authors: Tommaso Grigoletto, Yukuan Tao, Francesco Ticozzi, Lorenza Viola
Abstract: We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.

Paper number 96:
Title: NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References
Authors: Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Weidong Cai, Tongliang Liu
Abstract: Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting, effectively creates photorealistic scenes from sparse viewpoints, typically evaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However, these full-reference methods, which compare synthesized views to reference views, may not fully capture the perceptual quality of neurally synthesized scenes (NSS), particularly due to the limited availability of dense reference views. Furthermore, the challenges in acquiring human perceptual labels hinder the creation of extensive labeled datasets, risking model overfitting and reduced generalizability. To address these issues, we propose NVS-SQA, a NSS quality assessment method to learn no-reference quality representations through self-supervision without reliance on human labels. Traditional self-supervised learning predominantly relies on the "same instance, similar representation" assumption and extensive datasets. However, given that these conditions do not apply in NSS quality assessment, we employ heuristic cues and quality scores as learning objectives, along with a specialized contrastive pair preparation process to improve the effectiveness and efficiency of learning. The results show that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e., on average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second best) and even exceeds 16 full-reference methods across all evaluation metrics (i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).

Paper number 97:
Title: Alleviating Seasickness through Brain-Computer Interface-based Attention Shift
Authors: Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li
Abstract: Seasickness poses a widespread problem that adversely impacts both passenger comfort and the operational efficiency of maritime crews. Although attention shift has been proposed as a potential method to alleviate symptoms of motion sickness, its efficacy remains to be rigorously validated, especially in maritime environments. In this study, we develop an AI-driven brain-computer interface (BCI) to realize sustained and practical attention shift by incorporating tasks such as breath counting. Forty-three participants completed a real-world nautical experiment consisting of a real-feedback session, a resting session, and a pseudo-feedback session. Notably, 81.39\% of the participants reported that the BCI intervention was effective. EEG analysis revealed that the proposed system can effectively regulate motion sickness EEG signatures, such as an decrease in total band power, along with an increase in theta relative power and a decrease in beta relative power. Furthermore, an indicator of attentional focus, the theta/beta ratio, exhibited a significant reduction during the real-feedback session, providing further evidence to support the effectiveness of the BCI in shifting attention. Collectively, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, which has the potential to open up a brand-new application domain for BCIs.

Paper number 98:
Title: Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance
Authors: Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Mikyas T. Desta, Roy Fejgin, Rafael Valle, Jason Li
Abstract: While autoregressive speech token generation models produce speech with remarkable variety and naturalness, their inherent lack of controllability often results in issues such as hallucinations and undesired vocalizations that do not conform to conditioning inputs. We introduce Koel-TTS, a suite of enhanced encoder-decoder Transformer TTS models that address these challenges by incorporating preference alignment techniques guided by automatic speech recognition and speaker verification models. Additionally, we incorporate classifier-free guidance to further improve synthesis adherence to the transcript and reference speaker audio. Our experiments demonstrate that these optimizations significantly enhance target speaker similarity, intelligibility, and naturalness of synthesized speech. Notably, Koel-TTS directly maps text and context audio to acoustic tokens, and on the aforementioned metrics, outperforms state-of-the-art TTS models, despite being trained on a significantly smaller dataset. Audio samples and demos are available on our website.

Paper number 99:
Title: HiFi-Stream: Streaming Speech Enhancement with Generative Adversarial Networks
Authors: Ekaterina Dmitrieva, Maksim Kaledin
Abstract: Speech Enhancement techniques have become core technologies in mobile devices and voice software. Still, modern deep learning solutions often require high amount of computational resources what makes their usage on low-resource devices challenging. We present HiFi-Stream, an optimized version of recently published HiFi++ model. Our experiments demonstrate that HiFi-Stream saves most of the qualities of the original model despite its size and computational complexity improved in comparison to the original HiFi++ making it one of the smallest and fastest models available. The model is evaluated in streaming setting where it demonstrates its superior performance in comparison to modern baselines.

Paper number 100:
Title: How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane
Authors: Taekyung Kim, Randal W. Beard, Dimitra Panagou
Abstract: In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.

Paper number 101:
Title: Accelerating Ray Tracing-Based Wireless Channels Generation for Real-Time Network Digital Twins
Authors: Cláudio Modesto, Lucas Mozart, Pedro Batista, André Cavalcante, Aldebaro Klautau
Abstract: Ray tracing (RT) simulation is a widely used approach to enable modeling wireless channels in applications such as network digital twins. However, the computational cost to execute ray tracing (RT) is proportional to factors such as the level of detail used in the adopted 3D scenario. This work proposes RT pre-processing algorithms that aim at simplifying the 3D scene without distorting the channel, by reducing the scenario area and/or simplifying object shapes in the scenario. It also proposes a post-processing method that augments a set of RT results to achieve an improved time resolution. These methods enable using RT in applications that use a detailed and photorealistic 3D scenario while generating consistent wireless channels over time. Our simulation results with different urban scenarios scales, in terms of area and object details, demonstrate that it is possible to reduce the simulation time by more than 50% without compromising the accuracy of the multipath RT parameters, such as angles of arrival and departure, delay, phase, and path gain.

Paper number 102:
Title: Correct Estimation of Higher-Order Spectra: From Theoretical Challenges to Practical Multi-Channel Implementation in SignalSnap
Authors: Markus Sifft, Armin Ghorbanietemad, Fabian Wagner, Daniel Hägele
Abstract: Higher-order spectra (Brillinger's polyspectra) offer powerful methods for solving critical problems in signal processing and data analysis. Despite their significant potential, their practical use has remained limited due to unresolved mathematical issues in spectral estimation, including the absence of unbiased and consistent estimators and the high computational cost associated with evaluating multidimensional spectra. Consequently, existing tools frequently produce artifacts, no existing software library correctly implements Brillinger's cumulant-based trispectrum, or fail to scale effectively to real-world data volumes, leaving crucial applications like multi-detector spectral analysis largely unexplored. In this paper, we revisit higher-order spectra from a modern perspective, addressing the root causes of their historical underuse. We reformulate higher-order spectral estimation using recently derived multivariate k-statistics, yielding unbiased and consistent estimators that eliminate spurious artifacts and precisely align with Brillinger's theoretical definitions. Our methodology covers single- and multi-channel spectral analysis up to the bispectrum (third order) and trispectrum (fourth order), enabling robust investigations of inter-frequency coupling, non-Gaussian behavior, and time-reversal symmetry breaking. Additionally, we introduce quasi-polyspectra to uncover non-stationary, time-dependent higher-order features. We implement these new estimators in SignalSnap, an open-source GPU-accelerated library capable of efficiently analyzing datasets exceeding hundreds of gigabytes within minutes. In applications such as continuous quantum measurements, SignalSnap's rigorous estimators enable precise quantitative matching between experimental data and theoretical models.

Paper number 103:
Title: Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration
Authors: Shigeki Karita, Yuma Koizumi, Heiga Zen, Haruko Ishikawa, Robin Scheibler, Michiel Bacchiani
Abstract: Training data cleaning is a new application for generative model-based speech restoration (SR). This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models. Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor. To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaveFit neural vocoder for waveform synthesis. These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed. Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages. Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators.

Paper number 104:
Title: Robot Operation of Home Appliances by Reading User Manuals
Authors: Jian Zhang, Hanbo Zhang, Anxing Xiao, David Hsu
Abstract: Operating home appliances, among the most common tools in every household, is a critical capability for assistive home robots. This paper presents ApBot, a robot system that operates novel household appliances by "reading" their user manuals. ApBot faces multiple challenges: (i) infer goal-conditioned partial policies from their unstructured, textual descriptions in a user manual document, (ii) ground the policies to the appliance in the physical world, and (iii) execute the policies reliably over potentially many steps, despite compounding errors. To tackle these challenges, ApBot constructs a structured, symbolic model of an appliance from its manual, with the help of a large vision-language model (VLM). It grounds the symbolic actions visually to control panel elements. Finally, ApBot closes the loop by updating the model based on visual feedback. Our experiments show that across a wide range of simulated and real-world appliances, ApBot achieves consistent and statistically significant improvements in task success rate, compared with state-of-the-art large VLMs used directly as control policies. These results suggest that a structured internal representations plays an important role in robust robot operation of home appliances, especially, complex ones.

Paper number 105:
Title: UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation
Authors: Jinting Wang, Shan Yang, Li Liu
Abstract: Cued Speech (CS) enhances lipreading through hand coding, providing precise speech perception support for the hearing-impaired. CS Video-to-Speech generation (CSV2S) task aims to convert the CS visual expressions (CS videos) of hearing-impaired individuals into comprehensible speech signals. Direct generation of speech from CS video (called single CSV2S) yields poor performance due to insufficient CS data. Current research mostly focuses on CS Recognition (CSR), which convert video content into linguistic text. Based on this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech system. This combined architecture relies on text as an intermediate medium for stepwise cross-modal alignment, which may lead to error propagation and temporal misalignment between speech and video dynamics. To address these challenges, we propose a novel approach that directly generates speech from CS videos without relying on intermediate text. Building upon this, we propose UniCUE, the first unified framework for CSV2S, whose core innovation lies in the integration of the CSR task that provides fine-grained visual-semantic information to facilitate speech generation from CS videos. More precisely, (1) a novel fine-grained semantic alignment pool to ensure precise mapping between visual features and speech contents; (2) a VisioPhonetic adapter to bridge cross-task representations, ensuring seamless compatibility between two distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is introduced to enhance fine-grained spatiotemporal correlations between lip and hand movements in CS video. Experiments on our new established Chinese CS dataset show that our UniCUE achieves state-of-the-art performance across various metrics.

Paper number 106:
Title: Data-Driven Exploration for a Class of Continuous-Time Indefinite Linear--Quadratic Reinforcement Learning Problems
Authors: Yilie Huang, Xun Yu Zhou
Abstract: We study reinforcement learning (RL) for the same class of continuous-time stochastic linear--quadratic (LQ) control problems as in \cite{huang2024sublinear}, where volatilities depend on both states and controls while states are scalar-valued and running control rewards are absent. We propose a model-free, data-driven exploration mechanism that adaptively adjusts entropy regularization by the critic and policy variance by the actor. Unlike the constant or deterministic exploration schedules employed in \cite{huang2024sublinear}, which require extensive tuning for implementations and ignore learning progresses during iterations, our adaptive exploratory approach boosts learning efficiency with minimal tuning. Despite its flexibility, our method achieves a sublinear regret bound that matches the best-known model-free results for this class of LQ problems, which were previously derived only with fixed exploration schedules. Numerical experiments demonstrate that adaptive explorations accelerate convergence and improve regret performance compared to the non-adaptive model-free and model-based counterparts.

Paper number 107:
Title: Emerging Frameworks for Objective Task-based Evaluation of Quantitative Medical Imaging Methods
Authors: Yan Liu, Huitian Xia, Nancy A. Obuchowski, Richard Laforest, Arman Rahmim, Barry A. Siegel, Abhinav K. Jha
Abstract: Quantitative imaging (QI) is demonstrating strong promise across multiple clinical applications. For clinical translation of QI methods, objective evaluation on clinically relevant tasks is essential. To address this need, multiple evaluation strategies are being developed. In this paper, based on previous literature, we outline four emerging frameworks to perform evaluation studies of QI methods. We first discuss the use of virtual imaging trials (VITs) to evaluate QI methods. Next, we outline a no-gold-standard evaluation framework to clinically evaluate QI methods without ground truth. Third, a framework to evaluate QI methods for joint detection and quantification tasks is outlined. Finally, we outline a framework to evaluate QI methods that output multi-dimensional parameters, such as radiomic features. We review these frameworks, discussing their utilities and limitations. Further, we examine future research areas in evaluation of QI methods. Given the recent advancements in PET, including long axial field-of-view scanners and the development of artificial-intelligence algorithms, we present these frameworks in the context of PET.

Paper number 108:
Title: Active Probing with Multimodal Predictions for Motion Planning
Authors: Darshan Gadginmath, Farhad Nawaz, Minjun Sung, Faizan M Tariq, Sangjae Bae, David Isele, Fabio Pasqualetti, Jovin D'sa
Abstract: Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at this https URL.

Paper number 109:
Title: Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman
Authors: Obumneme Zimuzor Nwafor, Mohammed Abdul Majeed Al Hooti
Abstract: As nations seek sustainable alternatives to fossil fuels, green hydrogen has emerged as a promising strategic pathway toward decarbonisation, particularly in solar-rich arid regions. However, identifying optimal locations for hydrogen production requires the integration of complex environmental, atmospheric, and infrastructural factors, often compounded by limited availability of direct hydrogen yield data. This study presents a novel Artificial Intelligence (AI) framework for computing green hydrogen yield and site suitability index using mean absolute SHAP (SHapley Additive exPlanations) values. This framework consists of a multi-stage pipeline of unsupervised multi-variable clustering, supervised machine learning classifier and SHAP algorithm. The pipeline trains on an integrated meteorological, topographic and temporal dataset and the results revealed distinct spatial patterns of suitability and relative influence of the variables. With model predictive accuracy of 98%, the result also showed that water proximity, elevation and seasonal variation are the most influential factors determining green hydrogen site suitability in Oman with mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively. Given limited or absence of ground-truth yield data in many countries that have green hydrogen prospects and ambitions, this study offers an objective and reproducible alternative to subjective expert weightings, thus allowing the data to speak for itself and potentially discover novel latent groupings without pre-imposed assumptions. This study offers industry stakeholders and policymakers a replicable and scalable tool for green hydrogen infrastructure planning and other decision making in data-scarce regions.

Paper number 110:
Title: Constrained Control Allocation With Continuous-Time Rate Constraints: Three-Dimensional Case
Authors: Süleyman Özkurt, Adrian Grimm, Walter Fichter
Abstract: This paper presents a novel quadratic programming (QP) approach for constrained control allocation that directly incorporates continuous-time actuator rate constraints without requiring slack variables. Over-actuated aircraft configurations, particularly prevalent in eVTOL and military applications, require control allocation algorithms to distribute commanded control moments among available actuators while respecting position and rate constraints. Existing methods such as direct allocation, pseudo-inverse, cascaded generalized inverse, and exact redistributed pseudo-inverse either cannot handle rate constraints in continuous time or require discretization approaches that compromise performance. Current QP methods that incorporate rate constraints rely on slack variables to ensure feasibility, which prevents full utilization of the attainable moment set and degrades allocation performance. The proposed methodology addresses this limitation by calculating the attainable moment set from both position and rate constraints through convex hull operations, then ensuring feasibility by scaling unattainable commanded moments to the boundary of the attainable moment set while preserving their direction. This approach guarantees the feasibility of the optimization problem without slack variables. The method is validated through simulation on an F-18 fighter aircraft control allocation problem, demonstrating equivalent performance to the established exact redistributed pseudo-inverse method while providing smoother actuator behavior and enhanced constraint satisfaction. Results show that incorporating continuous-time rate constraints leads to improved actuator tracking, reduced overshoot, and more precise adherence to position limits, which is essential for aircraft safety, ride comfort, and actuator longevity.

Paper number 111:
Title: RIS-aided Latent Space Alignment for Semantic Channel Equalization
Authors: Tomás Hüttebräucker, Mario Edoardo Pandolfo, Simone Fiorellino, Emilio Calvanese Strinati, Paolo Di Lorenzo
Abstract: Semantic communication systems introduce a new paradigm in wireless communications, focusing on transmitting the intended meaning rather than ensuring strict bit-level accuracy. These systems often rely on Deep Neural Networks (DNNs) to learn and encode meaning directly from data, enabling more efficient communication. However, in multi-user settings where interacting agents are trained independently-without shared context or joint optimization-divergent latent representations across AI-native devices can lead to semantic mismatches, impeding mutual understanding even in the absence of traditional transmission errors. In this work, we address semantic mismatch in Multiple-Input Multiple-Output (MIMO) channels by proposing a joint physical and semantic channel equalization framework that leverages the presence of Reconfigurable Intelligent Surfaces (RIS). The semantic equalization is implemented as a sequence of transformations: (i) a pre-equalization stage at the transmitter; (ii) propagation through the RIS-aided channel; and (iii) a post-equalization stage at the receiver. We formulate the problem as a constrained Minimum Mean Squared Error (MMSE) optimization and propose two solutions: (i) a linear semantic equalization chain, and (ii) a non-linear DNN-based semantic equalizer. Both methods are designed to operate under semantic compression in the latent space and adhere to transmit power constraints. Through extensive evaluations, we show that the proposed joint equalization strategies consistently outperform conventional, disjoint approaches to physical and semantic channel equalization across a broad range of scenarios and wireless channel conditions.
    