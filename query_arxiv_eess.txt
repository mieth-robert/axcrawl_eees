
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain
Authors: Ziqing Zhu
Abstract: The rapid decentralization and digitalization of local electricity markets have introduced new cyber-physical vulnerabilities, including key leakage, data tampering, and identity spoofing. Existing blockchain-based solutions provide transparency and traceability but still depend on classical cryptographic primitives that are vulnerable to quantum attacks. To address these challenges, this paper proposes Q-EnergyDEX, a zero-trust distributed energy trading framework driven by quantum key distribution and blockchain. The framework integrates physical-layer quantum randomness with market-level operations, providing an end-to-end quantum-secured infrastructure. A cloud-based Quantum Key Management Service continuously generates verifiable entropy and regulates key generation through a rate-adaptive algorithm to sustain high-quality randomness. A symmetric authentication protocol (Q-SAH) establishes secure and low-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite) achieves probabilistic ledger finality within a few seconds. Furthermore, a Stackelberg-constrained bilateral auction couples market clearing with entropy availability, ensuring both economic efficiency and cryptographic security. Simulation results show that Q-EnergyDEX maintains robust key stability and near-optimal social welfare, demonstrating its feasibility for large-scale decentralized energy markets.

Paper number 2:
Title: A Structured Family of Grassmannian Constellations via Geodesic Mapping for MIMO Noncoherent Communications
Authors: Álvaro Pendás-Recondo, Enrique Pendás-Recondo
Abstract: This work presents a novel structured family of Grassmannian constellations for multiple-input multiple-output (MIMO) noncoherent communications over Rayleigh block-fading channels, where neither the transmitter nor the receiver has channel state information (CSI). The proposed constellation design is built upon the geodesic curves of the Grassmann manifold, thereby exploiting its underlying geometric structure. The resulting solution is limited in spectral efficiency (with a maximum constellation size of $4M^2$ points, where $M$ is the number of transmit antennas), targeting a rate in the range of $0.25$-$1$ bps/Hz. However, all space-time matrices resulting from this design exhibit the remarkable property of having a single nonzero entry per row, meaning that only one transmit antenna is active per time slot. This property significantly reduces hardware complexity and implementation cost, while also lowering power consumption, as only a single power amplifier is required for transmission. Furthermore, within the constellation size limits, the proposed design achieves error performance comparable to state-of-the-art optimization-based unstructured designs, as validated through symbol error rate (SER) numerical results. It also enables simple yet effective bit labeling, confirmed by comparisons of bit error rate (BER) and SER, and reduces the computational complexity of the maximum-likelihood (ML) detector for Grassmannian constellations by a factor of $M$.

Paper number 3:
Title: Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control
Authors: Ahmed Ali, Chiara Gabellieri, Antonio Franchi
Abstract: This paper presents a novel concept for achieving omnidirectionality in a multirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal forces at the equilibria. The concept integrates a single actively-tilting propeller along with 3 pendulum-like links, each carrying a propeller, connected by passive universal joints to the main body. We show that this design ensures omnidirectionality while minimizing the internal forces and without resorting to overactuation (i.e., more than 6 inputs). A detailed dynamic model of the multi-link MAV is first developed. Afterwards, the analysis identifies the equilibrium configurations and illustrates that a forced equilibrium exists for every pose of the MAV's main platform. In order to render this equilibrium asymptotically stable for the closed-loop system, a geometric nonlinear controller is constructed using dynamic feedback linearization and backstepping techniques with the main platform configuration error being the left-trivialized error on SE(3). The stability of the closed-loop system is then investigated by employing standard Lyapunov arguments on the zero dynamics. We conclude by providing numerical simulations validating the proposed approach. They demonstrate the MAV capability to perform decoupled attitude and translational motions under non-zero initial conditions, parametric uncertainty, and actuators noise.

Paper number 4:
Title: Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics
Authors: Tina Gao, Shimiao Li, Lawrence Pileggi
Abstract: Advances in leveraging Gaussian processes (GP) have enabled learning and inferring dynamic grid behavior from scarce PMU measurements. However, real measurements can be corrupted by various random and targeted threats, leading to inaccurate and meaningless results. This paper develops robust transient learning to overcome this challenge by exploiting the sparse corruption patterns in the data flow. Specifically, we integrate sparse optimization with method of moments (MoM) to make learning robust to a sparse distribution of data corruptions; then, we optimize sparse weights to identify corrupted meter locations. To improve inference speed on large-scale systems, we further adopt K-medoid clustering of locations to develop dimension reduction (DR) and aggregate representation (AR) heuristics. Experimental results demonstrate robustness against random large errors, targeted false data injections, and local PMU clock drifts. On a 1354-bus system, inference turns out to be 18x faster using DR and 400x faster when further combined with AR heuristics.

Paper number 5:
Title: Tail-Optimized Caching for LLM Inference
Authors: Wenxin Zhang, Yueying Li, Ciamac C. Moallemi, Tianyi Peng
Abstract: Prompt caching is critical for reducing latency and cost in LLM inference: OpenAI and Anthropic report up to 50-90% cost savings through prompt reuse. Despite its widespread success, little is known about what constitutes an optimal prompt caching policy, particularly when optimizing tail latency, a metric of central importance to practitioners. The widely used Least Recently Used (LRU) policy can perform arbitrarily poor on this metric, as it is oblivious to the heterogeneity of conversation lengths. To address this gap, we propose Tail-Optimized LRU, a simple two-line modification that reallocates KV cache capacity to prioritize high-latency conversations by evicting cache entries that are unlikely to affect future turns. Though the implementation is simple, we prove its optimality under a natural stochastic model of conversation dynamics, providing the first theoretical justification for LRU in this setting, a result that may be of independent interest to the caching community. Experimentally, on real conversation data WildChat, Tail-Optimized LRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and 23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in SLO violations of 200ms. We believe this provides a practical and theoretically grounded option for practitioners seeking to optimize tail latency in real-world LLM deployments.

Paper number 6:
Title: A Comparative Study of Oscillatory Perturbations in Car-Following Models
Authors: Oumaima Barhoumi, Ghazal Farhani, Taufiq Rahman, Mohamed H. Zaki, Sofiène Tahar
Abstract: As connected and autonomous vehicles become more widespread, platooning has emerged as a key strategy to improve road capacity, reduce fuel consumption, and enhance traffic flow. However, the benefits of platoons strongly depend on their ability to maintain stability. Instability can lead to unsafe spacing and increased energy usage. In this work, we study platoon instability and analyze the root cause of its occurrence, as well as its impacts on the following vehicle. To achieve this, we propose a comparative study between different car-following models such as the Intelligent Driver Model (IDM), the Optimal Velocity Model (OVM), the General Motors Model (GMM), and the Cooperative Adaptive Cruise Control (CACC). In our approach, we introduce a disruption in the model by varying the velocity of the leading vehicle to visualize the behavior of the following vehicles. To evaluate the dynamic response of each model, we introduce controlled perturbations in the velocity of the leading vehicle, specifically, sinusoidal oscillations and discrete velocity changes. The resulting vehicle trajectories and variations in inter-vehicle spacing are analyzed to assess the robustness of each model to disturbance propagation. The findings offer insight into model sensitivity, stability characteristics, and implications for designing resilient platooning control strategies.

Paper number 7:
Title: Pulse Shaping Filter Design for Integrated Sensing & Communication with Zak-OTFS
Authors: Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank
Abstract: Zak-OTFS is an emerging framework for integrated sensing & communication (ISAC) in high delay and Doppler spread environments. A critical enabler for ISAC with Zak-OTFS is the design of pulse shaping filters. For sensing, a localized pulse shaping filter enables ideal input-output (I/O) relation estimates close to the physical scattering channel. For communication, orthogonality of the pulse shape on the information lattice prevents inter-symbol interference, and no time and bandwidth expansion enables full spectral efficiency. A filter simultaneously meeting all three objectives is ideal for ISAC. Existing filter designs achieve two of the above objectives, but not all three simultaneously. For instance, the sinc filter is orthogonal and bandwidth/time-limited, but is not localized. The Gaussian filter is localized and bandwidth/time-limited, but not orthogonal. The RRC filter is localized and orthogonal, but not bandwidth/time-limited. A recently proposed hybrid Gaussian-sinc filter is more localized than the sinc filter and bandwidth/time-limited, but is not orthogonal. In this work, we design optimal pulse shaping filters meeting all three objectives via the Isotropic Orthogonal Transform Algorithm. The proposed pulse shaping filters offer improved data detection (communication) and I/O relation estimation (sensing) performance compared to existing filter choices in the literature.

Paper number 8:
Title: LongCat-Audio-Codec: An Audio Tokenizer and Detokenizer Solution Designed for Speech Large Language Models
Authors: Xiaohan Zhao, Hongyu Xiang, Shengze Ye, Song Li, Zhengkun Tian, Guanyu Chen, Ke Ding, Guanglu Wan
Abstract: This paper presents LongCat-Audio-Codec, an audio tokenizer and detokenizer solution designed for industrial grade end-to-end speech large language models. By leveraging a decoupled model architecture and a multistage training strategy, LongCat-Audio-Codec exhibits robust semantic modeling capabilities, flexible acoustic feature extraction capabilities, and low-latency streaming synthesis capabilities. It encodes speech at an ultra-low frame rate of 16.67 Hz, with a minimum bitrate of 0.43 kbps and a maximum bitrate of 0.87 kbps. Evaluation results demonstrate that LongCat-Audio-Codec achieves strong speech intelligibility and is capable of synthesizing highquality speech at low bitrate, thus effectively balancing coding efficiency and decoding quality. The inference code and model checkpoints of LongCat-Audio-Codec are available at: this https URL.

Paper number 9:
Title: Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants
Authors: Ziqing Zhu
Abstract: The proliferation of distributed energy resources (DERs) and demand-side flexibility has made virtual power plants (VPPs) central to modern grid operation. Yet their end-to-end business pipeline, covering bidding, dispatch, metering, settlement, and archival, forms a tightly coupled cyber-physical-economic system where secure and timely communication is critical. Under the combined stress of sophisticated cyberattacks and extreme weather shocks, conventional cryptography offers limited long-term protection. Quantum key distribution (QKD), with information-theoretic guarantees, is viewed as a gold standard for securing critical infrastructures. However, limited key generation rates, routing capacity, and system overhead render key allocation a pressing challenge: scarce quantum keys must be scheduled across heterogeneous processes to minimize residual risk while maintaining latency guarantees. This paper introduces a quantum-authenticated aggregation and settlement framework for VPPs. We first develop a system-threat model that connects QKD key generation and routing with business-layer security strategies, authentication strength, refresh frequency, and delay constraints. Building on this, we formulate a key-budgeted risk minimization problem that jointly accounts for economic risk, service-level violations, and key-budget feasibility, and reveal a threshold property linking marginal security value to shadow prices. Case studies on a representative VPP system demonstrate that the proposed approach significantly reduces residual risk and SLA violations, enhances key efficiency and robustness, and aligns observed dynamics with the theoretical shadow price mechanism.

Paper number 10:
Title: Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications
Authors: Ziqing Zhu
Abstract: The accelerating digitalization and decentralization of modern power systems expose critical communication infrastructures to escalating cyber risks, particularly under emerging quantum computing threats. This paper presents an integrated techno-economic framework to evaluate the feasibility of Quantum Key Distribution (QKD) for secure power-system communications. A stochastic system model is developed to jointly capture time-varying key demand, QKD supply under optical-loss constraints, station-side buffering, and post-quantum cryptography (PQC) fallback mechanisms. Analytical conditions are derived for service-level assurance, including buffer stability, outage probability, and availability bounds. Building on this, two quantitative metrics, including the Levelized Cost of Security (LCoSec) and Cost of Incremental Security (CIS), are formulated to unify capital, operational, and risk-related expenditures within a discounted net-present-value framework. Using IEEE 118-bus, 123-node, and 39-bus test systems, we conduct discrete-event simulations comparing PQC-only, QKD-only, and Hybrid architectures across multiple topologies and service profiles. Results show that Hybrid architectures dominated by QKD significantly reduce key-outage probability and SLA shortfalls, achieving near-unit availability for real-time and confidentiality-critical services. Economic analyses reveal clear breakeven zones where QKD-enhanced deployments become cost-effective, primarily in metropolitan and distribution-level networks under moderate optical loss and buffer sizing. The proposed framework provides a reproducible, risk-aware decision tool for guiding large-scale, economically justified QKD adoption in future resilient power-system infrastructures.

Paper number 11:
Title: Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells
Authors: Mostafaali Ayubirad, Zeng Qiu, Hao Wang, Chris Weinkauf, Michiel Van Nieuwstadt, Hamid R. Ossareh
Abstract: In this paper, a predictive constraint-aware control scheme is formulated within the Command Governor (CG) framework for localized hydration management of a proton exchange membrane (PEM) fuel cell system. First, a comprehensive nonlinear dynamic model of the fuel cell system is presented which includes a pseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling subsystems. The model captures the couplings among the various subsystems and serves as the basis for designing output feedback controllers to track the optimal set-points of the air supply and cooling systems for power optimization. The closed-loop nonlinear model is then used to analyze the dynamic behavior of membrane hydration near the anode inlet, the driest region of the membrane in a counter-flow configuration, under various operating conditions. A reduced-order linearized model is then derived to approximate hydration behavior with sufficient fidelity for constraint enforcement. This model is used within the CG framework to adjust the air supply set-points when necessary to prevent membrane dry-out. The effectiveness of the proposed approach in maintaining local membrane hydration while closely tracking the requested net power is demonstrated through realistic drive-cycle simulations.

Paper number 12:
Title: Multidimensional Physiology-Inspired Enhanced Vital Sign Monitoring Using MIMO mmWave Bio-radar
Authors: Heyao Zhu, Yimeng Zhao, Zirui Zhang, Huansheng Yi, Chenbin Gao, Canhua Xu, Jianqi Wang, Fugui Qi
Abstract: With the intensiffcation of population aging and increasing burden of chronic diseases, the demand for vital signs monitoring is becoming increasingly urgent. A key challenge facing current non-contact detection technologies using millimeter wave (mmWave) radar is the low efffciency of multi-channel signal fusion in array radar systems based on equal weighting. To address this challenge, this paper proposes a vital sign enhancement detection method for multiple input and multiple output (MIMO) bio-radar, driven by multidimensional physiological characteristics, which overcomes traditional limitations through a two-stage fusion strategy. Stage 1: Enhanced Vital Sign Detection Using Single-Channel Signals Based on Physiological Characteristics. First, a chest wall multi-scattering point model is constructed. For single channel time-distance two-dimensional echo signals, effective range bins are selected based on the respiratory/cardiac physiological frequency band energy ratio, and the signal-to-noise ratio (SNR) of respiration/heart signals is enhanced using phase-aligned maximal ratio combining (MRC). Stage 2: Multi-Channel Fusion Based on Organ Radiation Spatial Distribution Characteristics. The spatial radiation characteristics of cardiopulmonary organs are introduced for the ffrst time as the theoretical foundation for SNR-based channel screening, channel attribute identiffcation, and multi-channel weighted fusion. Then, we propose a template matching method to extract respiratory rate (RR) and heart rate (HR) by adopting physical models of respiration and cardiac activities. The experimental results demonstrate the existence of the spatial distribution characteristics of organ radiation. In addition, we analyzed the impact of distance and state on the algorithm from these two aspects.

Paper number 13:
Title: Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform
Authors: Saeid Bayat, Jerry Zuo, Jing Sun
Abstract: Offshore renewable energy systems offer promising solutions for sustainable power generation, yet most existing platforms harvest either wind or wave energy in isolation. This study presents a hybrid floating offshore platform that integrates a wind turbine with three oscillating surge wave energy converters (WECs) into a hexagonal semi-submersible structure. In this configuration, the flaps are integrated with the platform geometry to provide both energy extraction and hydrodynamic stability. A modeling and simulation framework was developed using WEC-Sim and benchmarked against the NREL 5 MW semisubmersible reference. Metacentric height analysis confirmed hydrostatic stability across a range of prescribed flap angles. Sensitivity analysis of twelve geometric variables identified flap dimensions and tower length as dominant drivers of stability, energy capture, and tower stress. Time-domain simulations revealed dependence on wave incidence angle, with variations in flap power sharing, capture width ratio (CWR), and platform response. The feasibility of using flap sweeps to modulate pitch motion was also demonstrated. Annual energy production (AEP) estimates based on site-specific data indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs contributing about 18% of the total. These results highlight the potential of integrated wind-wave platforms and point toward future studies on structural modeling and advanced control.

Paper number 14:
Title: Symmetric Entropy-Constrained Video Coding for Machines
Authors: Yuxiao Sun, Yao Zhao, Meiqin Liu, Chao Yao, Jian Jin, Weisi Lin
Abstract: As video transmission increasingly serves machine vision systems (MVS) instead of human vision systems (HVS), video coding for machines (VCM) has become a critical research topic. Existing VCM methods often bind codecs to specific downstream models, requiring retraining or supervised data and thus limiting generalization in multi-task scenarios. Recently, unified VCM frameworks have employed visual backbones (VB) and visual foundation models (VFM) to support multiple video understanding tasks with a single codec. They mainly utilize VB/VFM to maintain semantic consistency or suppress non-semantic information, but seldom explore how to directly link video coding with understanding under VB/VFM guidance. Hence, we propose a Symmetric Entropy-Constrained Video Coding framework for Machines (SEC-VCM). It establishes a symmetric alignment between the video codec and VB, allowing the codec to leverage VB's representation capabilities to preserve semantics and discard MVS-irrelevant information. Specifically, a bi-directional entropy-constraint (BiEC) mechanism ensures symmetry between the process of video decoding and VB encoding by suppressing conditional entropy. This helps the codec to explicitly handle semantic information beneficial for MVS while squeezing useless information. Furthermore, a semantic-pixel dual-path fusion (SPDF) module injects pixel-level priors into the final reconstruction. Through semantic-pixel fusion, it suppresses artifacts harmful to MVS and improves machine-oriented reconstruction quality. Experimental results show our framework achieves state-of-the-art (SOTA) in rate-task performance, with significant bitrate savings over VTM on video instance segmentation (37.41%), video object segmentation (29.83%), object detection (46.22%), and multiple object tracking (44.94%). We will release our code.

Paper number 15:
Title: Confidence-Weighted Semi-Supervised Learning for Skin Lesion Segmentation Using Hybrid CNN-Transformer Networks
Authors: Saqib Qamar
Abstract: Automated skin lesion segmentation through dermoscopic analysis is essential for early skin cancer detection, yet remains challenging due to limited annotated training data. We present MIRA-U, a semi-supervised framework that combines uncertainty-aware teacher-student pseudo-labeling with a hybrid CNN-Transformer architecture. Our approach employs a teacher network pre-trained via masked image modeling to generate confidence-weighted soft pseudo-labels, which guide a U-shaped CNN-Transformer student network featuring cross-attention skip connections. This design enhances pseudo-label quality and boundary delineation, surpassing reconstruction-based and CNN-only baselines, particularly in low-annotation regimes. Extensive evaluation on ISIC-2016 and PH2 datasets demonstrates superior performance, achieving a Dice Similarity Coefficient (DSC) of 0.9153 and Intersection over Union (IoU) of 0.8552 using only 50% labeled data. Code is publicly available on GitHub.

Paper number 16:
Title: LDCodec: A high quality neural audio codec with low-complexity decoder
Authors: Jiawei Jiang, Linping Xu, Dejun Zhang, Qingbo Huang, Xianjun Xia, Yijian Xiao
Abstract: Neural audio coding has been shown to outperform classical audio coding at extremely low bitrates. However, the practical application of neural audio codecs is still limited by their elevated complexity. To address this challenge, we have developed a high-quality neural audio codec with a low-complexity decoder, named LDCodec (Low-complexity Decoder Neural Audio Codec), specifically designed for on-demand streaming media clients, such as smartphones. Specifically, we introduced a novel residual unit combined with Long-term and Short-term Residual Vector Quantization (LSRVQ), subband-fullband frequency discriminators, and perceptual loss functions. This combination results in high-quality audio reconstruction with lower complexity. Both our subjective and objective tests demonstrated that our proposed LDCodec at 6kbps outperforms Opus at 12kbps.

Paper number 17:
Title: TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making
Authors: Maonan Wang, Yirong Chen, Yuxin Cai, Aoyu Pang, Yuejiao Xie, Zian Ma, Chengcheng Xu, Kemou Jiang, Ding Wang, Laurent Roullet, Chung Shue Chen, Zhiyong Cui, Yuheng Kan, Michael Lepech, Man-On Pun
Abstract: Air-ground collaborative intelligence is becoming a key approach for next-generation urban intelligent transportation management, where aerial and ground systems work together on perception, communication, and decision-making. However, the lack of a unified multi-modal simulation environment has limited progress in studying cross-domain perception, coordination under communication constraints, and joint decision optimization. To address this gap, we present TranSimHub, a unified simulation platform for air-ground collaborative intelligence. TranSimHub offers synchronized multi-view rendering across RGB, depth, and semantic segmentation modalities, ensuring consistent perception between aerial and ground viewpoints. It also supports information exchange between the two domains and includes a causal scene editor that enables controllable scenario creation and counterfactual analysis under diverse conditions such as different weather, emergency events, and dynamic obstacles. We release TranSimHub as an open-source platform that supports end-to-end research on perception, fusion, and control across realistic air and ground traffic scenes. Our code is available at this https URL.

Paper number 18:
Title: DroneAudioset: An Audio Dataset for Drone-based Search and Rescue
Authors: Chitralekha Gupta, Soundarya Ramesh, Praveen Sasikumar, Kian Peen Yeo, Suranga Nanayakkara
Abstract: Unmanned Aerial Vehicles (UAVs) or drones, are increasingly used in search and rescue missions to detect human presence. Existing systems primarily leverage vision-based methods which are prone to fail under low-visibility or occlusion. Drone-based audio perception offers promise but suffers from extreme ego-noise that masks sounds indicating human presence. Existing datasets are either limited in diversity or synthetic, lacking real acoustic interactions, and there are no standardized setups for drone audition. To this end, we present DroneAudioset (The dataset is publicly available at this https URL under the MIT license), a comprehensive drone audition dataset featuring 23.5 hours of annotated recordings, covering a wide range of signal-to-noise ratios (SNRs) from -57.2 dB to -2.5 dB, across various drone types, throttles, microphone configurations as well as environments. The dataset enables development and systematic evaluation of noise suppression and classification methods for human-presence detection under challenging conditions, while also informing practical design considerations for drone audition systems, such as microphone placement trade-offs, and development of drone noise-aware audio processing. This dataset is an important step towards enabling design and deployment of drone-audition systems.

Paper number 19:
Title: Towards Blind Data Cleaning: A Case Study in Music Source Separation
Authors: Azalea Gui, Woosung Choi, Junghyun Koo, Kazuki Shimada, Takashi Shibuya, Joan Serrà, Wei-Hsiang Liao, Yuki Mitsufuji
Abstract: The performance of deep learning models for music source separation heavily depends on training data quality. However, datasets are often corrupted by difficult-to-detect artifacts such as audio bleeding and label noise. Since the type and extent of contamination are typically unknown, cleaning methods targeting specific corruptions are often impractical. This paper proposes and evaluates two distinct, noise-agnostic data cleaning methods to address this challenge. The first approach uses data attribution via unlearning to identify and filter out training samples that contribute the least to producing clean outputs. The second leverages the Fréchet Audio Distance to measure and remove samples that are perceptually dissimilar to a small and trusted clean reference set. On a dataset contaminated with a simulated distribution of real-world noise, our unlearning-based methods produced a cleaned dataset and a corresponding model that outperforms both the original contaminated data and the small clean reference set used for cleaning. This result closes approximately 66.7\% of the performance gap between the contaminated baseline and a model trained on the same dataset without any contamination. Unlike methods tailored for specific artifacts, our noise-agnostic approaches offer a more generic and broadly applicable solution for curating high-quality training data.

Paper number 20:
Title: A Cross-Framework Study of Temporal Information Buffering Strategies for Learned Video Compression
Authors: Kuan-Wei Ho, Yi-Hsin Chen, Martin Benjak, Jörn Ostermann, Wen-Hsiao Peng
Abstract: Recent advances in learned video codecs have demonstrated remarkable compression efficiency. Two fundamental design aspects are critical: the choice of inter-frame coding framework and the temporal information propagation strategy. Inter-frame coding frameworks include residual coding, conditional coding, conditional residual coding, and masked conditional residual coding, each with distinct mechanisms for utilizing temporal predictions. Temporal propagation methods can be categorized as explicit, implicit, or hybrid buffering, differing in how past decoded information is stored and used. However, a comprehensive study covering all possible combinations is still lacking. This work systematically evaluates the impact of explicit, implicit, and hybrid buffering on coding performance across four inter-frame coding frameworks under a unified experimental setup, providing a thorough understanding of their effectiveness.

Paper number 21:
Title: Quantization-Based Score Calibration for Few-Shot Keyword Spotting with Dynamic Time Warping in Noisy Environments
Authors: Kevin Wilkinghoff, Alessia Cornaggia-Urrigshardt, Zheng-Hua Tan
Abstract: Detecting occurrences of keywords with keyword spotting (KWS) systems requires thresholding continuous detection scores. Selecting appropriate thresholds is a non-trivial task, typically relying on optimizing the performance on a validation dataset. However, such greedy threshold selection often leads to suboptimal performance on unseen data, particularly in varying or noisy acoustic environments or few-shot settings. In this work, we investigate detection threshold estimation for template-based open-set few-shot KWS using dynamic time warping on noisy speech data. To mitigate the performance degradation caused by suboptimal thresholds, we propose a score calibration approach consisting of two different steps: quantizing embeddings and normalizing detection scores using the quantization error prior to thresholding. Experiments on KWS-DailyTalk with simulated high frequency radio channels show that the proposed calibration approach simplifies the choice of detection thresholds and significantly improves the resulting performance.

Paper number 22:
Title: MC-LExt: Multi-Channel Target Speaker Extraction with Onset-Prompted Speaker Conditioning Mechanism
Authors: Tongtao Ling, Shulin He, Pengjie Shen, Zhong-Qiu Wang
Abstract: Multi-channel target speaker extraction (MC-TSE) aims to extract a target speaker's voice from multi-speaker signals captured by multiple microphones. Existing methods often rely on auxiliary clues such as direction-of-arrival (DOA) or speaker embeddings. However, DOA-based approaches depend on explicit direction estimation and are sensitive to microphone array geometry, while methods based on speaker embeddings model speaker identity in an implicit manner and may degrade in noisy-reverberant conditions. To address these limitations, we propose multi-channel listen to extract (MC-LExt), a simple but highly-effective framework for MC-TSE. Our key idea is to prepend a short enrollment utterance of the target speaker to each channel of the multi-channel mixture, providing an onset-prompted conditioning signal that can guide TSE. This design allows the deep neural network (DNN) to learn spatial and speaker identity cues jointly in a fully end-to-end manner. Experiments on noisy-reverberant benchmarks, including WHAMR! and MC-Libri2Mix, demonstrate the effectiveness of MC-TSE.

Paper number 23:
Title: Multi-Target Flexible Angular Emulation for ISAC Base Station Testing Using a Conductive Amplitude and Phase Matrix Setup: Framework and Experimental Validation
Authors: Chunhui Li, Chengrui Wang, Zhiqiang Yuan, Wei Fan
Abstract: Comprehensive evaluation of the functionalities, algorithms, hardware components, and performance characteristics of future integrated sensing and communication (ISAC) base stations (BSs) under realistic deployment scenarios in controlled laboratory environments represents a critical requirement for ISAC technology advancement. A primary challenge in achieving this objective involves the emulation of multiple targets with arbitrary radar cross-section (RCS), range, angle, and Doppler profiles for ISAC BS equipped with large-scale antenna arrays using radar target simulator (RTS) with limited interface ports. In this work, we introduce a simple yet highly effective and practical conductive amplitude and phase matrix framework to address this fundamental challenge. The core concept involves introducing a tunable conductive amplitude and phase modulation network in the test configuration between the ISAC BS under test and a RTS. Based on this structure, we subsequently investigate the corresponding configurations for different sensing operational modes of ISAC BSs, specifically the array duplex transmission and reception (ADTR) mode and the split-array transmission and reception (SATR) mode. For experimental validation, we design two distinct monostatic sensing scenarios to demonstrate the framework capabilities across both operational modes. The first scenario involves dynamic multi-drone sensing validation for ADTR mode operation, while the second scenario addresses static single-drone sensing for SATR mode validation. The experimental results demonstrate that the proposed framework can accurately emulate the joint RCS, range, velocity, and angular characteristics of multiple sensing targets within the conductive test environment, highlighting its significant potential for testing applications in sub-6 GHz ISAC BS development and validation.

Paper number 24:
Title: A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate
Authors: Yushu Qin, Marcos L. L. Sartori, Shengyu Duan, Emre Ozer, Rishad Shafik, Alex Yakovlev
Abstract: This paper introduces the first implementation of digital Tsetlin Machines (TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm IGZO-based FlexIC technology. TMs, known for their energy efficiency, interpretability, and suitability for edge computing, have previously been limited by the rigidity of conventional silicon-based chips. We develop two TM inference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2 equivalent logic gates with an area of 8X8 mm2, and a second more compact version achieving slightly lower prediction accuracy of 93% but using only 1420 NAND2 equivalent gates with an area of 4X4 mm2, both of which are custom-designed for an 8X8-pixel handwritten digit recognition dataset. The paper demonstrates the feasibility of deploying flexible TM inference engines into wearable healthcare and edge computing applications.

Paper number 25:
Title: Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic
Authors: Jianguo Chen, Zhengqin Liu, Jinlong Lei, Peng Yi, Yiguang Hong, Hong Chen
Abstract: With the practical implementation of connected and autonomous vehicles (CAVs), the traffic system is expected to remain a mix of CAVs and human-driven vehicles (HVs) for the foreseeable future. To enhance safety and traffic efficiency, the trajectory planning strategies of CAVs must account for the influence of HVs, necessitating accurate HV trajectory prediction. Current research often assumes that human drivers have perfect knowledge of all vehicles' objectives, an unrealistic premise. This paper bridges the gap by leveraging hypergame theory to account for cognitive and perception limitations in HVs. We model human bounded rationality without assuming them to be merely passive followers and propose a hierarchical cognition modeling framework that captures cognitive relationships among vehicles. We further analyze the cognitive stability of the system, proving that the strategy profile where all vehicles adopt cognitively equilibrium strategies constitutes a hyper Nash equilibrium when CAVs accurately learn HV parameters. To achieve this, we develop an inverse learning algorithm for distributed intention interpretation via vehicle-to-everything (V2X) communication, which extends the framework to both offline and online scenarios. Additionally, we introduce a distributed trajectory prediction and planning approach for CAVs, leveraging the learned parameters in real time. Simulations in highway lane-changing scenarios demonstrate the proposed method's accuracy in parameter learning, robustness to noisy trajectory observations, and safety in HV trajectory prediction. The results validate the effectiveness of our method in both offline and online implementations.

Paper number 26:
Title: Pseudo-Random TDM-MIMO FMCW Based Millimeter-Wave Sensing and Communication Integration for UAV Swarm
Authors: Yi Tao, Zhen Gao, Zhuoran Li, Ziwei Wan, Tuan Li, Chunli Zhu, Lei Chen, Guanghui Wen, Dezhi Zheng, Dusit Niyato
Abstract: The integrated sensing and communications (ISAC) can achieve the sharing of hardware and spectrum resources, enabling efficient data transmission and environmental sensing. This fusion is particularly important for unmanned aerial vehicle (UAV) swarms, as it enhances the overall performance, flexibility, and efficiency of such systems. To facilitate the collaborative operations among UAVs, this paper proposes an ISAC solution based on the pseudo-random time-division multiplexing (TDM)-multiple input multiple output (MIMO) millimeter-wave (mmWave) frequency modulated continuous wave (FMCW). Specifically, a novel ISAC chirp waveform is proposed to modulate data in both the delay domain and complex amplitude, while also possessing high-precision sensing capabilities. To address challenges in the TDM-MIMO, we utilize the pseudo-random antenna selection and compressed sensing algorithms, ensuring that the maximum unambiguous velocity is not compromised. Moreover, by employing a chirp-division multiple access scheme, we propose an interference-free multiple antenna transmission scheme to achieve dynamic allocation of time-frequency resources and multi-user transmission. Finally, we propose a communication and sensing fusion-based dynamic iterative computation scheme, simultaneously achieving data demodulation and sensing parameter estimation. Simulation results show that the proposed scheme can achieve ISAC under the dynamic flight scenarios of UAVs. Meanwhile, the scheme outperforms the mmWave-LoRadar in communication and sensing performance, yet its sensing performance is slightly lower than that of the traditional FMCW. Under the urban clutter modeling, the scheme still maintains favorable robustness despite a certain degree of performance degradation.

Paper number 27:
Title: Observer Design over Hypercomplex Quaternions
Authors: Michael Sebek
Abstract: We develop observer design over hypercomplex quaternions in a characteristic-polynomial-free framework. Using the standard right-module convention, we derive a right observable companion form and its companion polynomial that encodes error dynamics via right-eigenvalue similarity classes. The design mirrors the real/complex case - coefficient updates in companion coordinates, followed by a similarity back - yet avoids determinants, characteristic/minimal polynomials, and Cayley-Hamilton identities that do not transfer to quaternions. We also give an Ackermann-type construction for the important case of closed-loop companion polynomials with real coefficients, ensuring similarity-equivariant evaluation. The results yield simple recipes for full-order observers directly over quaternions, clarify the role of right spectra and their similarity classes, and pinpoint when classical one-shot formulas remain valid. Numerical examples illustrate the method and advantages over vectorized or complex-adjoint surrogates.

Paper number 28:
Title: A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control
Authors: Clément Moureau, Thomas Stegen, Mevludin Glavic, Bertrand Cornélusse
Abstract: This paper presents a predictive control strategy to manage low-voltage distribution systems. The proposed approach relies on an aggregate of the flexibility at the residential unit level into a three-dimensional chart that represents the injected active and reactive power, and the flexibility cost. First, this method solves a multiparametric optimization problem offline at the residential unit level to aggregate the flexibility of the assets. Then, a semi-explicit model predictive control problem is solved to account for forecasts. By combining the results of these problems with measurements, the method generates the desired flexibility chart. The proposed approach is compatible with realtime control requirements, as heavy computations are performed offline locally, making it naturally parallelizable. By linking realtime flexibility assessment with energy scheduling, our approach enables efficient, low-cost, and privacy-preserving management of low-voltage distribution systems. We validate this method on a low-voltage network of 5 buses by comparing it with an ideal technique.

Paper number 29:
Title: Magnitude and Phase-based Feature Fusion Using Co-attention Mechanism for Speaker recognition
Authors: Rongfeng Su, Mengjie Du, Xiaokang Liu, Lan Wang, Nan Yan
Abstract: Phase-based features related to vocal source characteristics can be incorporated into magnitude-based speaker recognition systems to improve the system performance. However, traditional feature-level fusion methods typically ignore the unique contributions of speaker semantics in the magnitude and phase domains. To address this issue, this paper proposed a feature-level fusion framework using the co-attention mechanism for speaker recognition. The framework consists of two separate sub-networks for the magnitude and phase domains respectively. Then, the intermediate high-level outputs of both domains are fused by the co-attention mechanism before a pooling layer. A correlation matrix from the co-attention module is supposed to re-assign the weights for dynamically scaling contributions in the magnitude and phase domains according to different pronunciations. Experiments on VoxCeleb showed that the proposed feature-level fusion strategy using the co-attention mechanism gave the Top-1 accuracy of 97.20%, outperforming the state-of-the-art system with 0.82% absolutely, and obtained EER reduction of 0.45% compared to single feature system using FBank.

Paper number 30:
Title: More on Boundary Behavior of Univalent Harmonic Mappings
Authors: Gebreslassie atsbha weldegebrial, hunduma legesse geleta
Abstract: Many authors have examined various boundary behaviors of injective harmonic mappings in the open unit disk. Building on Laugesen's work, Bshouty and others explored the boundary behavior of harmonic mappings under different conditions. In this paper, we extend their work and find out the angular limits of the arguments and logarithms of analytic functions under various conditions. We also examined the dilatation possesses only a finite set of zeros within any stolz angle if the first derivative of harmonic function $f$ at the boundary is positive infinity.

Paper number 31:
Title: Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition
Authors: Sheng Wang, Muhammad Maladoh Bah
Abstract: European countries are ambitious in both the net-zero transition and offshore energy resource development. The Irish and UK governments announced their commitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050, more than two times higher than their projected power demands. While other continental countries, such as Germany, are calling for cleaner fuel resources. Exporting surplus offshore green hydrogen and bridging supply and demand could be pivotal in carbon emission mitigation for Europe. Yet, the potentials of these Island countries, are usually underestimated. This paper developed a bottom-up method to investigate the role of offshore hydrogen from Ireland and the UK in the decarbonisation of the entire Europe. We evaluate the future hydrogen/ammonia trading and the contributions of each country in carbon emission mitigation, considering their relative cost-competitiveness in offshore hydrogen production, domestic hourly power and gas system operation, and international shipping costs. Results indicate that the offshore green hydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The UK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by Ireland in 2050, with 161 TWh of hydrogen exports to France and Spain. The offshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide emission reductions in total. This general flow of hydrogen from the West to the East not only facilitates Europe's net-zero progress, but also reshapes the energy supply structure and helps to ensure energy security across the European continent.

Paper number 32:
Title: Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control
Authors: Martín de Frutos, Laura Botero-Bolívar, Esteban Ferrer
Abstract: This paper proposes a pitch control strategy to mitigate the underwater acoustic footprint of offshore wind turbines, a measure that will soon become necessary to minimize impacts on marine life, which rely on sound for communication, navigation, and survival. First, we quantify the underwater acoustic signature of blade-generated aerodynamic noise from three reference turbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element momentum and coupled air-water acoustic propagation modeling. Second, we propose and implement an open-loop individual pitch control (IPC) strategy that modulates the pitch of the blade at the blade passing frequency to attenuate the overall sound pressure level (OSPL) and the amplitude modulation (AM) of the transmitted noise. Third, we benchmark IPC performance against conventional pitch schemes. The results indicate that up to 5 dB reductions in OSPL and a decrease in AM depth 20% can be achieved with a pitch variation of $\Delta\theta\approx 5^\circ$, with small losses (5-10%) in energy capture. These findings highlight a previously underappreciated noise pathway and demonstrate that targeted blade-pitch modulation can mitigate its impact.

Paper number 33:
Title: Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System
Authors: Thomas Bernard, François Grondin, Jean-Michel Lavoie
Abstract: This paper presents a practical alternative to programmable-logic-controller-centric automation by implementing an event-driven architecture built with industrial Internet of Things tools. A layered design on a local edge server (i) abstracts actuators, (ii) enforces mutual exclusion of shared physical resources through an interlock with priority queueing, (iii) composes deterministic singular operations, and (iv) orchestrates complete workflows as state machines in Node-RED, with communication over MQTT. The device layer uses low-cost ESP32-based gateways to interface sensors and actuators, while all automation logic is offloaded to the server side. As part of a larger project involving the first scientifically-documented integration of Industry 4.0 technologies in a maple syrup boiling center, this work demonstrates the deployment of the proposed system as a case-study. Evaluation over an entire production season shows median message time of flight around one tenth of a second, command issuance-to-motion latencies of about two to three seconds, and command completion near six seconds dominated by actuator mechanics; operation runtimes span tens of seconds to minutes. These results indicate that network and orchestration overheads are negligible relative to process dynamics, enabling modular, distributed control without compromising determinism or fault isolation. The approach reduces material and integration effort, supports portable containerized deployment, and naturally enables an edge/cloud split in which persistence and analytics are offloaded while automation remains at the edge.

Paper number 34:
Title: Detection Seizure Onset Zone Using Circadian Fluctuating Epileptic Biomarkers: A Signal Processing and Machine Learning Approach
Authors: Mehdi Zekriyapanah Gashti, Mostafa Mohammadpour, Hassan Eshkiki
Abstract: Epileptic biomarkers play a crucial role in identifying the origin of seizures, an essential aspect of pre-surgical planning for epilepsy treatment. These biomarkers can vary significantly over time. By studying these temporal fluctuations, we can enhance their effectiveness in guiding surgical planning. This research focuses on examining how circadian rhythms influence epilepsy biomarkers and aims to determine the optimal times for their analysis. To investigate the relationship between epilepsy biomarkers and circadian rhythm, the sleep/wake states first need to be classified. After the biomarkers are identified, they are compared across these states. A retrospective analysis was conducted on intracranial electroencephalography data from patients with focal epilepsy. The biomarkers spike, sequence of spikes, high-frequency oscillations (HFOs), and pathological HFOs were identified through automatic detection. The alpha/delta ratio was also calculated to distinguish between asleep and awake stages. Data from 9 patients were analyzed, and the classification of sleep and wake states was achieved with an area under the curve of 84%. All biomarker rates were higher during the sleep stage compared to the wake stage. Pathological HFOs and the sequence of spikes proved to be more precise indicators regarding distance to seizure onset than spikes or HFOs. Unlike previous studies that relied predominantly on long-term spike biomarker analysis, this study is the first to utilize a comprehensive set of biomarkers, including HFOs, spike sequences, and pathological HFOs, to enhance seizure onset zone prediction. The rates of epilepsy biomarkers during sleep vary considerably from those seen while awake, making sleep data analysis more effective for accurately predicting the seizure onset zone.

Paper number 35:
Title: Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty
Authors: Geon Roh, Jip Kim
Abstract: Dynamic line rating (DLR) enables greater utilization of existing transmission lines by leveraging real-time weather data. However, the elevated temperature operation (ETO) of conductors under DLR is often overlooked, despite its long-term impact on conductor health. This paper addresses this issue by 1) quantifying depreciation costs associated with ETO and 2) proposing a Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs in operational decisions. The CHA-UC incorporates a robust linear approximation of conductor temperature and integration of expected depreciation costs due to hourly ETO into the objective function. Case studies on the Texas 123-bus backbone test system using NOAA weather data demonstrate that the proposed CHA-UC model reduces the total cost by 0.8% and renewable curtailment by 84%compared to static line rating (SLR), while conventional DLR operation without risk consideration resulted in higher costs due to excessive ETO. Further analysis of the commitment decisions and the line temperature statistics confirms that the CHA-UC achieves safer line flows by shifting generator commitments. Finally, we examine the emergent correlation between wind generation and DLR forecast errors, and show that CHA-UC adaptively manages this effect by relaxing flows for risk-hedging conditions while tightening flows for risk-amplifying ones.

Paper number 36:
Title: On the Impact of Electromagnetic Interference and Inter-RIS Reflections in Indoor Factory Local 6G Networks
Authors: Ishan Rangajith Koralege, Nurul Huda Mahmood, Arthur Sousa de Sena, Italo Atzeni
Abstract: The Sixth Generation (6G) radio technology is expected to include local 6G networks as a special use case, extending the capabilities of `generic' 6G networks towards more demanding performance requirements. Reconfigurable intelligent surfaces (RISs) offer a novel paradigm for next-generation wireless communications, especially in the context of local 6G networks, enabling advanced signal propagation control through intelligent phase-shift configurations. However, in practical deployments, their performance can be adversely affected by electromagnetic interference (EMI) from external sources and inter-RIS reflections (IRR) caused by signal reflections between multiple colocated RIS units. This paper presents a comprehensive analysis of the joint impact of EMI and IRR in a multi-RIS multi-cell system deployed within an indoor factory environment. A detailed evaluation study is first carried out to investigate their impact on system performance. System-level simulations demonstrate that the joint impact of EMI and IRR degrades system performance more significantly than their individual effects, particularly as RIS dimensions and transmit power increase. To address these adverse effects, an alternate optimization algorithm using the Riemannian conjugate gradient method is then proposed. The novel algorithm optimizes the phase shifts of the RIS elements considering the spatial correlation among their associated channels, and is found to provide up to several orders of magnitude gains in terms of the system sum rate and the outage probability.

Paper number 37:
Title: RIS-assisted Atomic MIMO Receiver
Authors: Qihao Peng, Jiuyu Liu, Qu Luo, Yi Ma, Pei Xiao, Maged Elkashlan, George K. Karagiannidis
Abstract: In this paper, we propose a novel and low-complexity atomic multiple-input multiple-output (MIMO) receiver architecture assisted by a reconfigurable intelligent surface (RIS). By introducing RIS and utilizing pulse amplitude modulation (PAM), the phase of the transmitted signal is effectively aligned with that of the local oscillator (LO), thereby mitigating phase ambiguity and substantially reducing both signal detection complexity and overall receiver this http URL tackle the resulting non-convex optimization problem, we reformulate it into a tractable form by minimizing the Frobenius norm of an equivalent matrix, which is efficiently solved using an Adam-based gradient descent algorithm.

Paper number 38:
Title: Rydberg Atomic Quantum Satellites for Enhanced Ground-to-Space Direct Uplink Access
Authors: Qihao Peng Tierui Gong, Zihang Song, Qu Luo, Cunhua Pan, Pei Xiao, Chau Yuen
Abstract: This paper investigates the performance advantages of Rydberg atomic quantum (RAQ)-based multiple-input multiple-output (MIMO) satellites for enhancing direct ground-to-space uplink this http URL analytically evaluate the impact of Rydberg atoms on channel estimation by deriving closed-form expressions for the mean-square error (MSE) and normalized mean-square error (NMSE). Based on the estimated channels, we further derive lower bounds on the achievable data rates for maximum ratio combining (MRC) and zero-forcing (ZF) detection schemes. Rigorous analysis demonstrates that RAQ-MIMO outperforms conventional radio-frequency (RF) MIMO under both Rayleigh and satellite channel conditions. Specifically, compared with conventional MIMO, RAQR achieves a ``squaring" gain under Rayleigh fading, especially in long-distance transmission scenarios with stringent power constraints. In contrast, under line-of-sight (LoS)-dominated satellite channels, this gain saturates as channel-estimation benefits diminish, with the remaining improvement primarily arising from the normalized noise background. Monte Carlo simulations validate the analytical results and show that the performance gains of RAQ-MIMO satellites translate into smaller antenna apertures, lower transmit power, and longer communication ranges, thereby paving the way for next-generation satellite networks.

Paper number 39:
Title: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
Authors: Gai Zhang, Xinfeng Zhang, Lv Tang, Hongyu An, Li Zhang, Qingming Huang
Abstract: Light field images capture multi-view scene information and play a crucial role in 3D scene reconstruction. However, their high-dimensional nature results in enormous data volumes, posing a significant challenge for efficient compression in practical storage and transmission scenarios. Although neural representation-based methods have shown promise in light field image compression, most approaches rely on direct coordinate-to-pixel mapping through implicit neural representation (INR), often neglecting the explicit modeling of scene structure. Moreover, they typically lack end-to-end rate-distortion optimization, limiting their compression efficiency. To address these limitations, we propose SANR, a Scene-Aware Neural Representation framework for light field image compression with end-to-end rate-distortion optimization. For scene awareness, SANR introduces a hierarchical scene modeling block that leverages multi-scale latent codes to capture intrinsic scene structures, thereby reducing the information gap between INR input coordinates and the target light field image. From a compression perspective, SANR is the first to incorporate entropy-constrained quantization-aware training (QAT) into neural representation-based light field image compression, enabling end-to-end rate-distortion optimization. Extensive experiment results demonstrate that SANR significantly outperforms state-of-the-art techniques regarding rate-distortion performance with a 65.62\% BD-rate saving against HEVC.

Paper number 40:
Title: From Active to Battery-Free: Rydberg Atomic Quantum Receivers for Self-Sustained SWIPT-MIMO Networks
Authors: Qihao Peng, Qu Luo, Zheng Chu, Neng Ye, Hong Ren, Cunhua Pan, Lixia Xiao, Pei Xiao
Abstract: In this paper, we proposed a hybrid simultaneous wireless information and power transfer (SWIPT)-enabled multiple-input multiple-output (MIMO) architecture, where the base station (BS) uses a conventional RF transmitter for downlink transmission and a Rydberg atomic quantum receiver (RAQR) for receiving uplink signal from Internet of Things (IoT) devices. To fully exploit this integration, we jointly design the transmission scheme and the power-splitting strategy to maximize the sum rate, which leads to a non-convex problem. To address this challenge, we first derive closed-form lower bounds on the uplink achievable rates for maximum ratio combining (MRC) and zero-forcing (ZF), as well as on the downlink rate and harvested energy for maximum ratio transmission (MRT) and ZF precoding. Building upon these bounds, we propose an iterative algorithm relying on the best monomial approximation and geometric programming (GP) to solve the non-convex problem. Finally, simulations validate the tightness of our derived lower bounds and demonstrate the superiority of the proposed algorithm over benchmark schemes. Importantly, by integrating RAQR with SWIPT-enabled MIMO, the BS can reliably detect weak uplink signals from IoT devices powered only by harvested energy, enabling battery-free communication.

Paper number 41:
Title: Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method
Authors: Laszlo Gacsi, Adam K. Kiss, Tamas G. Molnar
Abstract: This paper presents a safety-critical control framework to maintain bounded lateral motions for vehicles braking on asymmetric surfaces. We synthesize a brake controller that assists drivers and guarantees safety against excessive lateral motions (i.e., prevents the vehicle from spinning out) while minimizing the stopping distance. We address this safety-critical control problem in the presence of input constraints, since braking forces are limited by the available friction on the road. We use backup control barrier functions for safe control design. As this approach requires the construction of a backup set and a backup controller, we propose a novel, systematic method to creating valid backup set-backup controller pairs based on feedback linearization and continuous-time Lyapunov equations. We use simple examples to demonstrate our proposed safety-critical control method. Finally, we implement our approach on a four-wheel vehicle model for braking on asymmetric surfaces and present simulation results.

Paper number 42:
Title: Resilient Full-Duplex ISAC in the Face of Imperfect SI Cancellation: Globally Optimal Timeslot Allocation and Beam Selection
Authors: Luis F. Abanto-Leon, Setareh Maghsudi
Abstract: This work addresses the radio resource management (RRM) design in downlink full-duplex integrated sensing and communications (ISAC) systems, jointly optimizing timeslot allocation and beam selection under imperfect self-interference cancellation. Timeslot allocation governs the distribution of discrete channel uses between sensing and communication tasks, while beam selection determines transmit and receive directions along with adaptive beamwidths. The joint design leads to a semi-infinite, nonconvex mixed-integer nonlinear program (MINLP), which is difficult to solve. To overcome this, we develop a tailored reformulation strategy that transforms the problem into a tractable mixed-integer linear program (MILP), enabling globally optimal solutions. Our approach provides insights into the coordinated optimization of timeslot allocation and beam selection, enhancing the efficiency of full-duplex ISAC systems while ensuring resilience against residual self-interference.

Paper number 43:
Title: Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating
Authors: Panos C. Papageorgiou, Anastasios E. Giannopoulos, Sotirios T. Spantideas
Abstract: Microgrids are emerging as key enablers of resilient, sustainable, and intelligent power systems, but they continue to face challenges in dynamic disturbance handling, protection coordination, and uncertainty. Recent efforts have explored Brain Emotional Learning (BEL) controllers as bio-inspired solutions for microgrid control. Building on this growing trajectory, this article introduces a new paradigm for Neuro-Microgrids, inspired by the brain's sensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and Prepulse Facilitation (PPF). Sensorimotor gating offers a biological model for selectively suppressing or amplifying responses depending on contextual relevance. By mapping these principles onto the hierarchical control architecture of microgrids, we propose a Sensorimotor Gating-Inspired Neuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control decisions correspond to protective damping in primary and secondary management of microgrids, whereas PPF-like decisions correspond to adaptive amplification of corrective control actions. The framework is presented through analytical workflow design, neuro-circuitry analogies, and integration with machine learning methods. Finally, open challenges and research directions are outlined, including the mathematical modeling of gating, digital twin validation, and cross-disciplinary collaboration between neuroscience and industrial power systems. The resulting paradigm highlights sensorimotor gating as a promising framework for designing self-protective, adaptive, and resilient microgrids.

Paper number 44:
Title: Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators
Authors: Oskar Triebe, Fletcher Passow, Simon Wittner, Leonie Wagner, Julio Arend, Tao Sun, Chad Zanocco, Marek Miltner, Arezou Ghesmati, Chen-Hao Tsai, Christoph Bergmeir, Ram Rajagopal
Abstract: The reliability of local power grid infrastructure is challenged by sustainable energy developments increasing electric load uncertainty. Transmission System Operators (TSOs) need load forecasts of higher spatial resolution, extending current forecasting operations from zonal aggregates to individual nodes. However, nodal loads are less accurate to forecast and require a large number of individual forecasts, which are hard to manage for the human experts assessing risks in the control room's daily operations (operator). In collaboration with a TSO, we design a multi-level system that meets the needs of operators for hourly day-ahead load forecasting. Utilizing a uniquely extensive dataset of zonal and nodal net loads, we experimentally evaluate our system components. First, we develop an interpretable and scalable forecasting model that allows for TSOs to gradually extend zonal operations to include nodal forecasts. Second, we evaluate solutions to address the heterogeneity and volatility of nodal load, subject to a trade-off. Third, our system is manageable with a fully parallelized single-model forecasting workflow. Our results show accuracy and interpretability improvements for zonal forecasts, and substantial improvements for nodal forecasts. In practice, our multi-level forecasting system allows operators to adjust forecasts with unprecedented confidence and accuracy, and to diagnose otherwise opaque errors precisely.

Paper number 45:
Title: Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks
Authors: Utku Demir, Tugba Erpek, Yalin E. Sagduyu, Sastry Kompella, Mengran Xue
Abstract: In emerging networked systems, mobile edge devices such as ground vehicles and unmanned aerial system (UAS) swarms collectively aggregate vast amounts of data to make machine learning decisions such as threat detection in remote, dynamic, and infrastructure-constrained environments where power and bandwidth are scarce. Federated learning (FL) addresses these constraints and privacy concerns by enabling nodes to share local model weights for deep neural networks instead of raw data, facilitating more reliable decision-making than individual learning. However, conventional FL relies on a central server to coordinate model updates in each learning round, which imposes significant computational burdens on the central node and may not be feasible due to the connectivity constraints. By eliminating dependence on a central server, distributed federated learning (DFL) offers scalability, resilience to node failures, learning robustness, and more effective defense strategies. Despite these advantages, DFL remains vulnerable to increasingly advanced and stealthy cyberattacks. In this paper, we design sophisticated targeted training data poisoning and backdoor (Trojan) attacks, and characterize the emerging vulnerabilities in a vehicular network. We analyze how DFL provides resilience against such attacks compared to individual learning and present effective defense mechanisms to further strengthen DFL against the emerging cyber threats.

Paper number 46:
Title: Two Roads to Koopman Operator Theory for Control: Infinite Input Sequences and Operator Families
Authors: Masih Haseli, Igor Mezić, Jorge Cortés
Abstract: The Koopman operator, originally defined for dynamical systems without input, has inspired many applications in control. Yet, the theoretical foundations underpinning this progress in control remain underdeveloped. This paper investigates the theoretical structure and connections between two extensions of Koopman theory to control: (i) Koopman operator via infinite input sequences and (ii) the Koopman control family. Although these frameworks encode system information in fundamentally different ways, we show that under certain conditions on the function spaces they operate on, they are equivalent. The equivalence is both in terms of the actions of the Koopman-based formulations in each framework as well as the function values on the system trajectories. Our analysis provides constructive tools to translate between the frameworks, offering a unified perspective for Koopman methods in control.

Paper number 47:
Title: HyperAIRI: a plug-and-play algorithm for precise hyperspectral image reconstruction in radio interferometry
Authors: Chao Tang, Arwa Dabbech, Adrian Jackson, Yves Wiaux
Abstract: The next-generation radio-interferometric (RI) telescopes require imaging algorithms capable of forming high-resolution high-dynamic-range images from large data volumes spanning wide frequency bands. Recently, AIRI, a plug-and-play (PnP) approach taking the forward-backward algorithmic structure (FB), has demonstrated state-of-the-art performance in monochromatic RI imaging by alternating a data-fidelity step with a regularisation step via learned denoisers. In this work, we introduce HyperAIRI, its hyperspectral extension, underpinned by learned hyperspectral denoisers enforcing a power-law spectral model. For each spectral channel, the HyperAIRI denoiser takes as input its current image estimate, alongside estimates of its two immediate neighbouring channels and the spectral index map, and provides as output its associated denoised image. To ensure convergence of HyperAIRI, the denoisers are trained with a Jacobian regularisation enforcing non-expansiveness. To accommodate varying dynamic ranges, we assemble a shelf of pre-trained denoisers, each tailored to a specific dynamic range. At each HyperAIRI iteration, the spectral channels of the target image cube are updated in parallel using dynamic-range-matched denoisers from the pre-trained shelf. The denoisers are also endowed with a spatial image faceting functionality, enabling scalability to varied image sizes. Additionally, we formally introduce Hyper-uSARA, a variant of the optimisation-based algorithm HyperSARA, promoting joint sparsity across spectral channels via the l2,1-norm, also adopting FB. We evaluate HyperAIRI's performance on simulated and real observations. We showcase its superior performance compared to its optimisation-based counterpart Hyper-uSARA, CLEAN's hyperspectral variant in WSClean, and the monochromatic imaging algorithms AIRI and uSARA.

Paper number 48:
Title: Extending Audio Context for Long-Form Understanding in Large Audio-Language Models
Authors: Yuatyong Chaichana, Pittawat Taveekitworachai, Warit Sirichotedumrong, Potsawee Manakul, Kunat Pipatanakul
Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio context windows, even when their text backbones support long contexts, limiting long-form audio understanding. Prior work has introduced context-extension methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains unexplored. First, building on RoPE-based context extension, we introduce Partial YaRN, a training-free, audio-only extension method that modifies only audio token positions, leaving text positions intact to preserve the base LLM's text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a training strategy that extends Partial YaRN into a training-time positional augmentation. VLAT simulates diverse audio lengths during training, enabling generalization to inputs far longer than those seen in training and improving robustness for long-context audio understanding. Our experiments on SALMONN and Qwen2-Audio show that Partial YaRN outperforms the original models across wide range of settings, and VLAT training strategy provides substantial improvement, achieving strong performance on long audio of unseen lengths.

Paper number 49:
Title: An Iterative Problem-Driven Scenario Reduction Framework for Stochastic Optimization with Conditional Value-at-Risk
Authors: Yingrui Zhuang, Lin Cheng, Ning Qi, Mads R. Almassalkhi, Feng Liu
Abstract: Scenario reduction (SR) alleviates the computational complexity of scenario-based stochastic optimization with conditional value-at-risk (SBSO-CVaR) by identifying representative scenarios to depict the underlying uncertainty and tail risks. Existing distribution-driven SR methods emphasize statistical similarity but often exclude extreme scenarios, leading to weak tail-risk awareness and insufficient problem-specific representativeness. Instead, this paper proposes an iterative problem-driven scenario reduction framework. Specifically, we integrate the SBSO-CVaR problem structure into SR process and project the original scenario set from the distribution space onto the problem space. Subsequently, to minimize the SR optimality gap with acceptable computation complexity, we propose a tractable iterative problem-driven scenario reduction (IPDSR) method that selects representative scenarios that best approximate the optimality distribution of the original scenario set while preserving tail risks. Furthermore, the iteration process is rendered as a mixed-integer program to enable scenario partitioning and representative scenarios selection. And ex-post problem-driven evaluation indices are proposed to evaluate the SR performance. Numerical experiments show IPDSR significantly outperforms existing SR methods by achieving an optimality gap of less than 1% within an acceptable computation time.

Paper number 50:
Title: Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles
Authors: Liviu-Mihai Stan, Ranulfo Bezerra, Shotaro Kojima, Tsige Tadesse Alemayoh, Satoshi Tadokoro, Masashi Konyo, Kazunori Ohno
Abstract: Reliable navigation in disaster-response and other unstructured indoor settings requires robots not only to avoid obstacles but also to recognise when those obstacles can be pushed aside. We present an adaptive, LiDAR and odometry-based path-planning framework that embeds this capability into the ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing from a prior static map as tentatively movable and assigns a reduced traversal cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to actual velocity; when the robot slows appreciably, the local cost is raised from light to heavy, and on a stall to lethal, prompting the global planner to back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated objects and cluttered corridors, show higher goal-reach rates and fewer deadlocks than a no-layer baseline, with traversal times broadly comparable. Because the method relies only on planar scans and CPU-level computation, it suits resource-constrained search and rescue robots and integrates into heterogeneous platforms with minimal engineering. Overall, the results indicate that interaction-aware cost maps are a lightweight, ROS2-native extension for navigating among potentially movable obstacles in unstructured settings. The full implementation will be released as open source athttps://costmapthis http URL.

Paper number 51:
Title: Singularity-free dynamical invariants-based quantum control
Authors: Ritik Sareen, Akram Youssry, Alberto Peruzzo
Abstract: State preparation is a cornerstone of quantum technologies, underpinning applications in computation, communication, and sensing. Its importance becomes even more pronounced in non-Markovian open quantum systems, where environmental memory and model uncertainties pose significant challenges to achieving high-fidelity control. Invariant-based inverse engineering provides a principled framework for synthesizing analytic control fields, yet existing parameterizations often lead to experimentally infeasible, singular pulses and are limited to simplified noise models such as those of Lindblad form. Here, we introduce a generalized invariant-based protocol for single-qubit state preparation under arbitrary noise conditions. The control proceeds in two-stages: first, we construct a family of bounded pulses that achieve perfect state preparation in a closed system; second, we identify the optimal member of this family that minimizes the effect of noise. The framework accommodates both (i) characterized noise, enabling noise-aware control synthesis, and (ii) uncharacterized noise, where a noise-agnostic variant preserves robustness without requiring a master-equation description. Numerical simulations demonstrate high-fidelity state preparation across diverse targets while producing smooth, hardware-feasible control fields. This singularity-free framework extends invariant-based control to realistic open-system regimes, providing a versatile route toward robust quantum state engineering on NISQ hardware and other platforms exhibiting non-Markovian dynamics.

Paper number 52:
Title: Bilinear Compressive Security
Authors: Axel Flinth, Hubert Orlicki, Semira Einsele, Gerhard Wunder
Abstract: Beyond its widespread application in signal and image processing, \emph{compressed sensing} principles have been greatly applied to secure information transmission (often termed 'compressive security'). In this scenario, the measurement matrix $Q$ acts as a one time pad encryption key (in complex number domain) which can achieve perfect information-theoretic security together with other benefits such as reduced complexity and energy efficiency particularly useful in IoT. However, unless the matrix is changed for every message it is vulnerable towards known plain text attacks: only $n$ observations suffices to recover a key $Q$ with $n$ columns. In this paper, we invent and analyze a new method (termed 'Bilinear Compressive Security (BCS)') addressing these shortcomings: In addition to the linear encoding of the message $x$ with a matrix $Q$, the sender convolves the resulting vector with a randomly generated filter $h$. Assuming that $h$ and $x$ are sparse, the receiver can then recover $x$ without knowledge of $h$ from $y=h*Qx$ through blind deconvolution. We study a rather idealized known plaintext attack for recovering $Q$ from repeated observations of $y$'s for different, known $x_k$, with varying and unknown $h$ ,giving Eve a number of advantages not present in practice. Our main result for BCS states that under a weak symmetry condition on the filter $h$, recovering $Q$ will require extensive sampling from transmissions of $\Omega\left(\max\left(n,(n/s)^2\right)\right)$ messages $x_k$ if they are $s$-sparse. Remarkably, with $s=1$ it is impossible to recover the key. In this way, the scheme is much safer than standard compressed sensing even though our assumptions are much in favor towards a potential attacker.

Paper number 53:
Title: Recursive Inference for Heterogeneous Multi-Output GP State-Space Models with Arbitrary Moment Matching
Authors: Tengjie Zheng, Jilan Mei, Di Wu, Lin Cheng, Shengping Gong
Abstract: Accurate learning of system dynamics is becoming increasingly crucial for advanced control and decision-making in engineering. However, real-world systems often exhibit multiple channels and highly nonlinear transition dynamics, challenging traditional modeling methods. To enable online learning for these systems, this paper formulates the system as Gaussian process state-space models (GPSSMs) and develops a recursive learning method. The main contributions are threefold. First, a heterogeneous multi-output kernel is designed, allowing each output dimension to adopt distinct kernel types, hyperparameters, and input variables, improving expressiveness in multi-dimensional dynamics learning. Second, an inducing-point management algorithm enhances computational efficiency through independent selection and pruning for each output dimension. Third, a unified recursive inference framework for GPSSMs is derived, supporting general moment matching approaches, including the extended Kalman filter (EKF), unscented Kalman filter (UKF), and assumed density filtering (ADF), enabling accurate learning under strong nonlinearity and significant noise. Experiments on synthetic and real-world datasets show that the proposed method matches the accuracy of SOTA offline GPSSMs with only 1/100 of the runtime, and surpasses SOTA online GPSSMs by around 70% in accuracy under heavy noise while using only 1/20 of the runtime.

Paper number 54:
Title: Balancing Fairness and Performance in Multi-User Spark Workloads with Dynamic Scheduling (extended version)
Authors: Dāvis Kažemaks, Laurens Versluis, Burcu Kulahcioglu Ozkan, Jérémie Decouchant
Abstract: Apache Spark is a widely adopted framework for large-scale data processing. However, in industrial analytics environments, Spark's built-in schedulers, such as FIFO and fair scheduling, struggle to maintain both user-level fairness and low mean response time, particularly in long-running shared applications. Existing solutions typically focus on job-level fairness which unintentionally favors users who submit more jobs. Although Spark offers a built-in fair scheduler, it lacks adaptability to dynamic user workloads and may degrade overall job performance. We present the User Weighted Fair Queuing (UWFQ) scheduler, designed to minimize job response times while ensuring equitable resource distribution across users and their respective jobs. UWFQ simulates a virtual fair queuing system and schedules jobs based on their estimated finish times under a bounded fairness model. To further address task skew and reduce priority inversions, which are common in Spark workloads, we introduce runtime partitioning, a method that dynamically refines task granularity based on expected runtime. We implement UWFQ within the Spark framework and evaluate its performance using multi-user synthetic workloads and Google cluster traces. We show that UWFQ reduces the average response time of small jobs by up to 74% compared to existing built-in Spark schedulers and to state-of-the-art fair scheduling algorithms.

Paper number 55:
Title: Modelling-driven requirements for Error Field Control Coil application to initial JT-60SA plasmas
Authors: L. Pigatto, G. Frello, Y.Q. Liu, L. Novello, M. Takechi, E. Tomasina, T. Bolzonella
Abstract: JT-60SA is a large superconducting tokamak built in Naka, Japan. After the successful achievement of its first MA-class plasma, the installation of several additional sub-systems, including a set of non-axisymmetric Error Field Correction Coils (EFCC), is ongoing. Optimization of future JT-60SA plasma scenarios will critically depend on the correct use of EFCC, including careful fulfillment of system specifications. In addition to that, preparation and risk mitigation of early ITER operations will greatly benefit from the experience gained by early EFCC application to JT-60SA experiments, in particular to optimize error field detection and control strategies. In this work, EFCC application in JT-60SA Initial Research Phase I perspective scenarios is modeled including plasma response. Impact of (Resonant) Magnetic Perturbations on the different plasma scenarios is assessed for both core and pedestal regions by the linear resistive MHD code MARS-F. The dominant core response to EFs is discussed case by case and compared to mode locking thresholds from literature. Typical current/voltage amplitudes and wave-forms are then compared to EFCC specifications in order to assess a safe operational space.

Paper number 56:
Title: An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation
Authors: Saumya B
Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and treatment planning. Although Monte Carlo (MC) Dropout is widely used to estimate model uncertainty, its effectiveness in identifying segmentation errors -- especially near tumor boundaries -- remains unclear. This study empirically examines the relationship between MC Dropout--based uncertainty and segmentation error in 2D brain tumor MRI segmentation using a U-Net trained under four augmentation settings: none, horizontal flip, rotation, and scaling. Uncertainty was computed from 50 stochastic forward passes and correlated with pixel-wise errors using Pearson and Spearman coefficients. Results show weak global correlations ($r \approx 0.30$--$0.38$) and negligible boundary correlations ($|r| < 0.05$). Although differences across augmentations were statistically significant ($p < 0.001$), they lacked practical relevance. These findings suggest that MC Dropout uncertainty provides limited cues for boundary error localization, underscoring the need for alternative or hybrid uncertainty estimation methods in medical image segmentation.

Paper number 57:
Title: Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors
Authors: Usman Ali, Ali Zia, Waqas Ali, Umer Ramzan, Abdul Rehman, Muhammad Tayyab Chaudhry, Wei Xiang
Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety and operational continuity, mitigating costly unplanned downtime. Conventional approaches often struggle to capture complex multimodal signal relationships, are constrained to unimodal data or single fault types, and exhibit performance degradation under noisy or cross-domain conditions. This paper proposes the Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is the first to integrate contrastive learning within a hypergraph topology specifically designed for multimodal sensor fusion, enabling the joint modelling of intra- and inter-modal dependencies and enhancing generalisation beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis of bearing, stator, and rotor faults, addressing the engineering need for consolidated di- agnostic capabilities. Evaluated on three real-world benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain generalisation and resilience to noise, demonstrating its suitability for real-world deployment. An ablation study validates the contribution of each component. MM-HCAN provides a scalable and robust solution for comprehensive multi-fault diagnosis, supporting predictive maintenance and extended asset longevity in industrial environments.

Paper number 58:
Title: ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents
Authors: Tingyu Lin, Marco Peer, Florian Kleber, Robert Sablatnig
Abstract: This paper presents ClapperText, a benchmark dataset for handwritten and printed text recognition in visually degraded and low-resource settings. The dataset is derived from 127 World War II-era archival video segments containing clapperboards that record structured production metadata such as date, location, and camera-operator identity. ClapperText includes 9,813 annotated frames and 94,573 word-level text instances, 67% of which are handwritten and 1,566 are partially occluded. Each instance includes transcription, semantic category, text type, and occlusion status, with annotations available as rotated bounding boxes represented as 4-point polygons to support spatially precise OCR applications. Recognizing clapperboard text poses significant challenges, including motion blur, handwriting variation, exposure fluctuations, and cluttered backgrounds, mirroring broader challenges in historical document analysis where structured content appears in degraded, non-standard forms. We provide both full-frame annotations and cropped word images to support downstream tasks. Using a consistent per-video evaluation protocol, we benchmark six representative recognition and seven detection models under zero-shot and fine-tuned conditions. Despite the small training set (18 videos), fine-tuning leads to substantial performance gains, highlighting ClapperText's suitability for few-shot learning scenarios. The dataset offers a realistic and culturally grounded resource for advancing robust OCR and document understanding in low-resource archival contexts. The dataset and evaluation code are available at this https URL.

Paper number 59:
Title: Active Inverse Methods in Stackelberg Games with Bounded Rationality
Authors: Jianguo Chen, Jinlong Lei, Biqiang Mu, Yiguang Hong, Hongsheng Qi
Abstract: Inverse game theory is utilized to infer the cost functions of all players based on game outcomes. However, existing inverse game theory methods do not consider the learner as an active participant in the game, which could significantly enhance the learning process. In this paper, we extend inverse game theory to active inverse methods. For Stackelberg games with bounded rationality, the leader, acting as a learner, actively chooses actions to better understand the follower's cost functions. First, we develop a method of active learning by leveraging Fisher information to maximize information gain about the unknown parameters and prove the consistency and asymptotic normality. Additionally, when leaders consider its cost, we develop a method of active inverse game to balance exploration and exploitation, and prove the consistency and asymptotic Stackelberg equilibrium with quadratic cost functions. Finally, we verify the properties of these methods through simulations in the quadratic case and demonstrate that the active inverse game method can achieve Stackelberg equilibrium more quickly through active exploration.

Paper number 60:
Title: Adaptive Legged Locomotion via Online Learning for Model Predictive Control
Authors: Hongyu Zhou, Xiaoyu Zhang, Vasileios Tzoumas
Abstract: We provide an algorithm for adaptive legged locomotion via online learning and model predictive control. The algorithm is composed of two interacting modules: model predictive control (MPC) and online learning of residual dynamics. The residual dynamics can represent modeling errors and external disturbances. We are motivated by the future of autonomy where quadrupeds will autonomously perform complex tasks despite real-world unknown uncertainty, such as unknown payload and uneven terrains. The algorithm uses random Fourier features to approximate the residual dynamics in reproducing kernel Hilbert spaces. Then, it employs MPC based on the current learned model of the residual dynamics. The model is updated online in a self-supervised manner using least squares based on the data collected while controlling the quadruped. The algorithm enjoys sublinear \textit{dynamic regret}, defined as the suboptimality against an optimal clairvoyant controller that knows how the residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations, where the quadruped aims to track reference trajectories. The Gazebo simulations include constant unknown external forces up to $12\boldsymbol{g}$, where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain with $20\degree$ inclination, and rough terrain with $0.25m$ height variation. The MuJoCo simulations include time-varying unknown disturbances with payload up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

Paper number 61:
Title: Decentralized Parameter-Free Online Learning
Authors: Tomas Ortega, Hamid Jafarkhani
Abstract: We propose the first parameter-free decentralized online learning algorithms with network regret guarantees, which achieve sublinear regret without requiring hyperparameter tuning. This family of algorithms connects multi-agent coin-betting and decentralized online learning via gossip steps. To enable our decentralized analysis, we introduce a novel "betting function" formulation for coin-betting that simplifies the multi-agent regret analysis. Our analysis shows sublinear network regret bounds and is validated through experiments on synthetic and real datasets. This family of algorithms is applicable to distributed sensing, decentralized optimization, and collaborative ML applications.

Paper number 62:
Title: Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing
Authors: Yameng Zhang, Dianye Huang, Max Q.-H. Meng, Nassir Navab, Zhongliang Jiang
Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers flexibility and accessibility for diverse clinical applications but faces challenges in accurate probe pose estimation. Traditional methods depend on costly tracking systems, while neural network-based methods struggle with image noise and error accumulation, compromising reconstruction precision. We propose a cost-effective and versatile solution that leverages lightweight cameras and visual servoing in simulated environments for precise 3D US imaging. These cameras capture visual feedback from a textured planar workspace. To counter occlusions and lighting issues, we introduce an image restoration method that reconstructs occluded regions by matching surrounding texture patterns. For pose estimation, we develop a simulation-in-the-loop approach, which replicates the system setup in simulation and iteratively minimizes pose errors between simulated and real-world observations. A visual servoing controller refines the alignment of camera views, improving translational estimation by optimizing image alignment. Validations on a soft vascular phantom, a 3D-printed conical model, and a human arm demonstrate the robustness and accuracy of our approach, with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171 mm, and 0.858 mm, respectively. These results confirm the method's potential for reliable freehand 3D US reconstruction.

Paper number 63:
Title: Beyond-Diagonal RIS Under Non-Idealities: Learning-Based Architecture Discovery and Optimization
Authors: Binggui Zhou, Bruno Clerckx
Abstract: Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has recently been introduced to enable advanced control over electromagnetic waves to further increase the benefits of traditional RIS in enhancing signal quality and improving spectral and energy efficiency for next-generation wireless networks. A significant issue in designing and deploying BD-RIS is the tradeoff between its performance and circuit complexity. Despite some efforts in exploring optimal architectures with the lowest circuit complexities for ideal BD-RIS, architecture discovery for non-ideal BD-RIS remains uninvestigated. Therefore, how non-idealities and circuit complexity jointly affect the performance of BD-RIS remains unclear, making it difficult to achieve the performance - circuit complexity tradeoff in the presence of non-idealities. Essentially, architecture discovery for non-ideal BD-RIS faces challenges from both the computational complexity of global architecture search and the difficulty in achieving global optima. To tackle these challenges, we propose a learning-based two-tier architecture discovery framework (LTTADF) consisting of an architecture generator and a performance optimizer to jointly discover optimal architectures of non-ideal BD-RIS given specific circuit complexities, which can effectively explore over a large architecture space while avoiding getting trapped in poor local optima and thus achieving near-optimal solutions for the performance optimization. Numerical results provide valuable insights for deploying non-ideal BD-RIS considering the performance - circuit complexity tradeoff.

Paper number 64:
Title: DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification
Authors: Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig
Abstract: Camera movement classification (CMC) models trained on contemporary, high-quality footage often degrade when applied to archival film, where noise, missing frames, and low contrast obscure motion cues. We bridge this gap by assembling a unified benchmark that consolidates two modern corpora into four canonical classes and restructures the HISTORIAN collection into five balanced categories. Building on this benchmark, we introduce DGME-T, a lightweight extension to the Video Swin Transformer that injects directional grid motion encoding, derived from optical flow, via a learnable and normalised late-fusion layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and its macro F1 from 82.08% to 87.81% on modern clips, while still improving the demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72% to 82.63% macro F1. A cross-domain study further shows that an intermediate fine-tuning stage on modern data increases historical performance by more than five percentage points. These results demonstrate that structured motion priors and transformer representations are complementary and that even a small, carefully calibrated motion head can substantially enhance robustness in degraded film analysis. Related resources are available at this https URL.

Paper number 65:
Title: Cavity Duplexer Tuning with 1d Resnet-like Neural Networks
Authors: Anton Raskovalov
Abstract: This paper presents machine learning method for tuning of cavity duplexer with a large amount of adjustment screws. After testing we declined conventional reinforcement learning approach and reformulated our task in the supervised learning setup. The suggested neural network architecture includes 1d ResNet-like backbone and processing of some additional information about S-parameters, like the shape of curve and peaks positions and amplitudes. This neural network with external control algorithm is capable to reach almost the tuned state of the duplexer within 4-5 rotations per screw.

Paper number 66:
Title: A New Time Series Similarity Measure and Its Smart Grid Applications
Authors: Rui Yuan, Hossein Ranjbar, S. Ali Pourmousavi, Wen L. Soong, Andrew J. Black, Jon A. R. Liisberg, Julian Lemos-Vinasco
Abstract: Many smart grid applications involve data mining, clustering, classification, identification, and anomaly detection, among others. These applications primarily depend on the measurement of similarity, which is the distance between different time series or subsequences of a time series. The commonly used time series distance measures, namely Euclidean Distance (ED) and Dynamic Time Warping (DTW), do not quantify the flexible nature of electricity usage data in terms of temporal dynamics. As a result, there is a need for a new distance measure that can quantify both the amplitude and temporal changes of electricity time series for smart grid applications, e.g., demand response and load profiling. This paper introduces a novel distance measure to compare electricity usage patterns. The method consists of two phases that quantify the effort required to reshape one time series into another, considering both amplitude and temporal changes. The proposed method is evaluated against ED and DTW using real-world data in three smart grid applications. Overall, the proposed measure outperforms ED and DTW in accurately identifying the best load scheduling strategy, anomalous days with irregular electricity usage, and determining electricity users' behind-the-meter (BTM) equipment.

Paper number 67:
Title: Grid-Aware Real-Time Dispatch of Microgrid with Generalized Energy Storage: A Prediction-Free Online Optimization Approach
Authors: Kaidi Huang, Lin Cheng, Ning Qi, David Wenzhong Gao, Asad Mujeeb, Qinglai Guo
Abstract: This paper proposes a novel prediction-free two-stage coordinated dispatch framework for the real-time dispatch of grid-connected microgrid with generalized energy storages (GES). The proposed framework explicitly addresses grid awareness, non-anticipativity constraints, and the time-coupling characteristics of GES, providing microgrid operators with a near-optimal, reliable, and adaptable dispatch tool. In the offline stage, we generate the hindsight state-of-charge (SoC) trajectories of GES by solving the multi-period economic dispatch with historical scenarios. Subsequently, leveraging this historical information (SoC trajectories, net loads, and electricity prices), we synthesize and dynamically update online references for both SoC and opportunity cost through kernel regression. We propose an adaptive Lagrange multiplier-based online convex optimization algorithm, which innovatively incorporates reference tracking for global vision and expert-tracking for step-size updates. We provide theoretical proof to show that the proposed OCO algorithm achieves a sublinear bound of both dynamic regret and time-varying hard constraint violation. Numerical studies using ground-truth data from the Australian Energy Market Operator demonstrate that the proposed method outperforms state-of-the-art methods, reducing operational costs by 5.0-6.2% and voltage violations by 0.8-9.1%. These improvements mainly result from mitigating myopia by reference tracking and the adaptive capability provided by dynamically updated references and adaptive Lagrange multipliers. Sensitivity analysis demonstrates the robustness, computational efficiency, and scalability of the proposed method.

Paper number 68:
Title: Real-Time Linear MPC for Quadrotors on SE(3): An Analytical Koopman-based Realization
Authors: Santosh M. Rajkumar, Chengyu Yang, Yuliang Gu, Sheng Cheng, Naira Hovakimyan, Debdipta Goswami
Abstract: This letter presents an analytical linear parameter-varying (LPV) representation of quadrotor dynamics utilizing Koopman theory, facilitating computationally efficient linear model predictive control (LMPC) for real-time trajectory tracking. By leveraging carefully designed Koopman observables, the proposed approach enables a compact lifted-space evolution that mitigates the curse of dimensionality while preserving the nonlinear characteristics of the system. Although model predictive control (MPC) is a powerful strategy for quadrotor control, it faces a trade-off between the high computational cost of nonlinear MPC (NMPC) and the reduced accuracy of LMPC. To address this gap, we introduce KQ-LMPC (Koopman Quasilinear LPV MPC), which leverages the Koopman-lifted LPV formulation to enforce constraints, ensure lower computational burden and real-time feasibility, and deliver tracking performance comparable to NMPC. Experimental validation confirms the effectiveness of the framework in reasonably agile flight. To the best of our knowledge, this is the first experimentally validated LMPC for quadrotors that employs analytically derived Koopman observables without requiring training data.

Paper number 69:
Title: Towards Fault Diagnosis in Induction Motor using Fractional Fourier Transform
Authors: Usman Ali
Abstract: A method for determining the current signature faults using Fractional Fourier Transform (FrFT) has been developed. The method has been applied to the real-time steady-state current of the inverter-fed high power induction motor for fault determination. The method incorporates calculating the relative norm error to find the threshold value between healthy and unhealthy induction motor at different operating frequencies. The experimental results demonstrate that the total harmonics distortion of unhealthy motor is much larger than the healthy motor, and the threshold relative norm error value of different healthy induction motors is less than 0.3, and the threshold relative norm error value of unhealthy induction motor is greater than 0.5. The developed method can function as a simple operator-assisted tool for determining induction motor faults in real-time.

Paper number 70:
Title: Reducing Latency by Eliminating CSIT Feedback: FDD Downlink MIMO Precoding Without CSIT Feedback for Internet-of-Things Communications
Authors: Juntaek Han, Namhyun Kim, Jeonghun Park
Abstract: This paper presents a novel framework for low-latency frequency division duplex (FDD) multi-input multi-output (MIMO) transmission with Internet of Things (IoT) communications. Our key idea is eliminating feedback associated with downlink channel state information at the transmitter (CSIT) acquisition. Instead, we propose to reconstruct downlink CSIT from uplink reference signals by exploiting the frequency invariance property of channel parameters. Nonetheless, the frequency disparity between the uplink and downlink makes it impossible to get perfect downlink CSIT, resulting in substantial interference. To address this, we formulate a max-min fairness problem and propose a rate-splitting multiple access (RSMA)-aided efficient precoding method. In particular, to fully harness the potential benefits of RSMA, we propose a method that approximates the error covariance matrix and incorporates it into the precoder optimization process. This approach effectively accounts for the impact of imperfect CSIT, enabling the design of a robust precoder that efficiently handles CSIT inaccuracies. Simulation results demonstrate that our framework outperforms other baseline methods in terms of the minimum spectral efficiency when no direct CSI feedback is used. Moreover, we show that our framework significantly reduces communication latency compared to conventional CSI feedback-based methods, underscoring its effectiveness in enhancing latency performance for IoT communications.

Paper number 71:
Title: Efficient reconstruction and denoising of cryo-ET data with end-to-end localized deep learning
Authors: Vinith Kishore, Valentin Debarnot, AmirEhsan Khorashadizadeh, Ricardo D. Righetto, Benjamin D. Engel, Ivan Dokmanić
Abstract: Cryo-electron tomography (cryo-ET) enables 3D visualization of cellular structures. Accurate reconstruction of high-resolution volumes is complicated by the very low signal-to-noise ratio and a restricted range of sample tilts. Recent self-supervised deep learning approaches, which post-process initial reconstructions by filtered backprojection (FBP), have significantly improved reconstruction quality with respect to signal processing iterative algorithms, but they are slow, taking dozens of hours for an expert to reconstruct tomogram and demand large memory. We present CryoLithe, an end-to-end network that directly estimates the volume from an aligned tilt-series. CryoLithe achieves denoising and missing wedge correction comparable or better than state-of-the-art self-supervised deep learning approaches such as Cryo-CARE, IsoNet or DeepDeWedge, while being two order of magnitude faster. To achieve this, we implement a local, memory-efficient reconstruction network. We demonstrate that leveraging transform-domain locality makes our network robust to distribution shifts, enabling effective supervised training and giving excellent results on real data--without retraining or fine-tuning. CryoLithe reconstructions facilitate downstream cryo-ET analysis, including segmentation and subtomogram averaging and is openly available: this https URL.

Paper number 72:
Title: Skull-stripping induces shortcut learning in MRI-based Alzheimer's disease classification
Authors: Christian Tinauer, Maximilian Sackl, Rudolf Stollberger, Reinhold Schmidt, Stefan Ropele, Christian Langkammer
Abstract: Objectives: High classification accuracy of Alzheimer's disease (AD) from structural MRI has been achieved using deep neural networks, yet the specific image features contributing to these decisions remain unclear. In this study, the contributions of T1-weighted (T1w) gray-white matter texture, volumetric information, and preprocessing -- particularly skull-stripping -- were systematically assessed. Methods: A dataset of 990 matched T1w MRIs from AD patients and cognitively normal controls from the ADNI database were used. Preprocessing was varied through skull-stripping and intensity binarization to isolate texture and shape contributions. A 3D convolutional neural network was trained on each configuration, and classification performance was compared using exact McNemar tests with discrete Bonferroni-Holm correction. Feature relevance was analyzed using Layer-wise Relevance Propagation, image similarity metrics, and spectral clustering of relevance maps. Results: Despite substantial differences in image content, classification accuracy, sensitivity, and specificity remained stable across preprocessing conditions. Models trained on binarized images preserved performance, indicating minimal reliance on gray-white matter texture. Instead, volumetric features -- particularly brain contours introduced through skull-stripping -- were consistently used by the models. Conclusions: This behavior reflects a shortcut learning phenomenon, where preprocessing artifacts act as potentially unintended cues. The resulting Clever Hans effect emphasizes the critical importance of interpretability tools to reveal hidden biases and to ensure robust and trustworthy deep learning in medical imaging.

Paper number 73:
Title: End-to-End Learning Framework for Solving Non-Markovian Optimal Control
Authors: Xiaole Zhang, Peiyu Zhang, Xiongye Xiao, Shixuan Li, Vasileios Tzoumas, Vijay Gupta, Paul Bogdan
Abstract: Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems pose substantial challenges in system identification and optimal control due to the lack of standard control methodologies. In this paper, we theoretically derive the optimal control via linear quadratic regulator (LQR) for fractional-order linear time-invariant (FOLTI) systems and develop an end-to-end deep learning framework based on this theoretical foundation. Our approach establishes a rigorous mathematical model, derives analytical solutions, and incorporates deep learning to achieve data-driven optimal control of FOLTI systems. Our key contributions include: (i) proposing an innovative system identification method control strategy for FOLTI systems, (ii) developing the first end-to-end data-driven learning framework, Fractional-Order Learning for Optimal Control (FOLOC), that learns control policies from observed trajectories, and (iii) deriving a theoretical analysis of sample complexity to quantify the number of samples required for accurate optimal control in complex real-world problems. Experimental results indicate that our method accurately approximates fractional-order system behaviors without relying on Gaussian noise assumptions, pointing to promising avenues for advanced optimal control.

Paper number 74:
Title: Universal Vessel Segmentation for Multi-Modality Retinal Images
Authors: Bo Wen, Anna Heinke, Akshay Agnihotri, Dirk-Uwe Bartsch, William Freeman, Truong Nguyen, Cheolhong An
Abstract: We identify two major limitations in the existing studies on retinal vessel segmentation: (1) Most existing works are restricted to one modality, i.e., the Color Fundus (CF). However, multi-modality retinal images are used every day in the study of the retina and diagnosis of retinal diseases, and the study of vessel segmentation on other modalities is scarce; (2) Even though a few works extended their experiments to new modalities such as the Multi-Color Scanning Laser Ophthalmoscopy (MC), these works still require fine-tuning a separate model for the new modality. The fine-tuning will require extra training data, which is difficult to acquire. In this work, we present a novel universal vessel segmentation model (URVSM) for multi-modality retinal images. In addition to performing the study on a much wider range of image modalities, we also propose a universal model to segment the vessels in all these commonly used modalities. While being much more versatile compared with existing methods, our universal model also demonstrates comparable performance to the state-of-the-art fine-tuned methods. To the best of our knowledge, this is the first work that achieves modality-agnostic retinal vessel segmentation and the first to study retinal vessel segmentation in several novel modalities.

Paper number 75:
Title: Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation
Authors: Bálint Tóth, Dominik Senti, Thorir Mar Ingolfsson, Jeffrey Zweidler, Alexandre Elsig, Luca Benini, Yawei Li
Abstract: Blood pressure (BP) is a key indicator of cardiovascular health. As hypertension remains a global cause of morbidity and mortality, accurate, continuous, and non-invasive BP monitoring is therefore of paramount importance. Photoplethysmography (PPG) and electrocardiography (ECG) can potentially enable continuous BP monitoring, yet training accurate and robust machine learning (ML) models remains challenging due to variability in data quality and patient-specific factors. Recently, multiple research groups explored Electroencephalographic (EEG)--based foundation models and demonstrated their exceptional ability to learn rich temporal resolution. Considering the morphological similarities between different biosignals, the question arises of whether a model pre-trained on one modality can effectively be exploited to improve the accuracy of a different signal type. In this work, we take an initial step towards generalized biosignal foundation models by investigating whether model representations learned from abundant EEG data can effectively be transferred to ECG/PPG data solely with fine-tuning, without the need for large-scale additional pre-training, for the BP estimation task. Evaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach achieves near state-of-the-art accuracy for diastolic BP (mean absolute error of 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP (mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8 quantization, reducing the smallest model size by over 3.5x (from 13.73 MB down to 3.83 MB) while preserving performance, thereby enabling unobtrusive, real-time BP monitoring on resource-constrained wearable devices.

Paper number 76:
Title: Stochastic Model Predictive Control for Sub-Gaussian Noise
Authors: Yunke Ao, Johannes Köhler, Manish Prajapat, Yarden As, Melanie Zeilinger, Philipp Fürnstahl, Andreas Krause
Abstract: We propose a stochastic Model Predictive Control (MPC) framework that ensures closed-loop chance constraint satisfaction for linear systems with general sub-Gaussian process and measurement noise. By considering sub-Gaussian noise, we can provide guarantees for a large class of distributions, including time-varying distributions. Specifically, we first provide a new characterization of sub-Gaussian random vectors using matrix variance proxy, which can more accurately represent the predicted state distribution. We then derive tail bounds under linear propagation for the new characterization, enabling tractable computation of probabilistic reachable sets of linear systems. Lastly, we utilize these probabilistic reachable sets to formulate a stochastic MPC scheme that provides closed-loop guarantees for general sub-Gaussian noise. We further demonstrate our approach in simulations, including a challenging task of surgical planning from image observations.

Paper number 77:
Title: EAGLE: Contextual Point Cloud Generation via Adaptive Continuous Normalizing Flow with Self-Attention
Authors: Linhao Wang, Qichang Zhang, Yifan Yang, Hao Wang, Ye Su
Abstract: As 3D point clouds become the prevailing shape representation in computer vision, how to generate high-resolution point clouds has become a pressing issue. Flow-based generative models can effectively perform point cloud generation tasks. However, traditional CNN-based flow architectures rely only on local information to extract features, making it difficult to capture global contextual information. Inspired by the wide adoption of Transformers, we explored the complementary roles of self-attention mechanisms in Transformers, CNN, and continuous normalizing flows. To this end, we propose a probabilistic model via adaptive normalizing flows and self-attention. Our idea leverages self-attention mechanisms to capture global contextual information. We also propose adaptive continuous normalizing flows by introducing adaptive bias correction mechanism. Combined with normalization, the mechanism dynamically handles different input contexts and mitigates potential bias-shift issues from standard initialization. Experimental results demonstrate that EAGLE achieves competitive performance in point cloud generation.

Paper number 78:
Title: Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models
Authors: Collin R. Johnson, Stijn de Vries, Kerstin Wohlgemuth, Sergio Lucia
Abstract: This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.

Paper number 79:
Title: TransVFC: A Transformable Video Feature Compression Framework for Machines
Authors: Yuxiao Sun, Yao Zhao, Meiqin Liu, Chao Yao, Huihui Bai, Chunyu Lin, Weisi Lin
Abstract: Nowadays, more and more video transmissions primarily aim at downstream machine vision tasks rather than humans. While widely deployed Human Visual System (HVS) oriented video coding standards like H.265/HEVC and H.264/AVC are efficient, they are not the optimal approaches for Video Coding for Machines (VCM) scenarios, leading to unnecessary bitrate expenditure. The academic and technical exploration within the VCM domain has led to the development of several strategies, and yet, conspicuous limitations remain in their adaptability for multi-task scenarios. To address the challenge, we propose a Transformable Video Feature Compression (TransVFC) framework. It offers a compress-then-transfer solution and includes a video feature codec and Feature Space Transform (FST) modules. In particular, the temporal redundancy of video features is squeezed by the codec through the scheme-based inter-prediction module. Then, the codec implements perception-guided conditional coding to minimize spatial redundancy and help the reconstructed features align with downstream machine this http URL that, the reconstructed features are transferred to new feature spaces for diverse downstream tasks by FST modules. To accommodate a new downstream task, it only requires training one lightweight FST module, avoiding retraining and redeploying the upstream codec and downstream task networks. Experiments show that TransVFC achieves high rate-task performance for diverse tasks of different granularities. We expect our work can provide valuable insights for video feature compression in multi-task scenarios. The codes are at this https URL.

Paper number 80:
Title: A Set-Theoretic Robust Control Approach for Linear Quadratic Games with Unknown Counterparts
Authors: Francesco Bianchin, Robert Lefringhausen, Elisa Gaetan, Samuel Tesfazgi, Sandra Hirche
Abstract: Ensuring robust decision-making in multi-agent systems is challenging when agents have distinct, possibly conflicting objectives and lack full knowledge of each other's strategies. This is apparent in safety-critical applications such as human-robot interaction and assisted driving, where uncertainty arises not only from unknown adversary strategies but also from external disturbances. To address this, the paper proposes a robust adaptive control approach based on linear quadratic differential games. Our method allows a controlled agent to iteratively refine its belief about the adversary strategy and disturbances using a set-membership approach, while simultaneously adapting its policy to guarantee robustness against the uncertain adversary policy and improve performance over time. We formally derive theoretical guarantees on the robustness of the proposed control scheme and its convergence to $\epsilon$-Nash strategies. The effectiveness of our approach is demonstrated in a numerical simulation.

Paper number 81:
Title: A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography
Authors: Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Fan Zhang, Weidong Cai, Lauren J. O'Donnell
Abstract: Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) features to predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model to predict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis.

Paper number 82:
Title: UNet with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning for Medical Image Segmentation
Authors: Saqib Qamar, Mohd Fazil, Parvez Ahmad, Shakir Khan, Abu Taha Zamani
Abstract: Medical image segmentation plays an important role in various clinical applications; however, existing deep learning models face trade-offs between efficiency and accuracy. Convolutional Neural Networks (CNNs) capture local details well but miss the global context, whereas transformers handle the global context but at a high computational cost. Recently, State Space Sequence Models (SSMs) have shown potential for capturing long-range dependencies with linear complexity; however, their direct use in medical image segmentation remains limited due to incompatibility with image structures and autoregressive assumptions. To overcome these challenges, we propose SAMA-UNet, a novel U-shaped architecture that introduces two key innovations. First, the Self-Adaptive Mamba-like Aggregated Attention (SAMA) block adaptively integrates local and global features through dynamic attention weighting, enabling an efficient representation of complex anatomical patterns. Second, the causal resonance multi-scale module (CR-MSM) improves encoder-decoder interactions by adjusting feature resolution and causal dependencies across scales, enhancing the semantic alignment between low- and high-level features. Extensive experiments on MRI, CT, and endoscopy datasets demonstrate that SAMA-UNet consistently outperforms CNN, Transformer, and Mamba-based methods. It achieves 85.38% DSC and 87.82% NSD on BTCV, 92.16% and 96.54% on ACDC, 67.14% and 68.70% on EndoVis17, and 84.06% and 88.47% on ATLAS23, establishing new benchmarks across modalities. These results confirm the effectiveness of SAMA-UNet in combining efficiency and accuracy, making it a promising solution for real-world clinical segmentation tasks. The source code is available on GitHub.

Paper number 83:
Title: VLMLight: Safety-Critical Traffic Signal Control via Vision-Language Meta-Control and Dual-Branch Reasoning Architecture
Authors: Maonan Wang, Yirong Chen, Aoyu Pang, Yuxin Cai, Chung Shue Chen, Yuheng Kan, Man-On Pun
Abstract: Traffic signal control (TSC) is a core challenge in urban mobility, where real-time decisions must balance efficiency and safety. Existing methods - ranging from rule-based heuristics to reinforcement learning (RL) - often struggle to generalize to complex, dynamic, and safety-critical scenarios. We introduce VLMLight, a novel TSC framework that integrates vision-language meta-control with dual-branch reasoning. At the core of VLMLight is the first image-based traffic simulator that enables multi-view visual perception at intersections, allowing policies to reason over rich cues such as vehicle type, motion, and spatial density. A large language model (LLM) serves as a safety-prioritized meta-controller, selecting between a fast RL policy for routine traffic and a structured reasoning branch for critical cases. In the latter, multiple LLM agents collaborate to assess traffic phases, prioritize emergency vehicles, and verify rule compliance. Experiments show that VLMLight reduces waiting times for emergency vehicles by up to 65% over RL-only systems, while preserving real-time performance in standard conditions with less than 1% degradation. VLMLight offers a scalable, interpretable, and safety-aware solution for next-generation traffic signal control.

Paper number 84:
Title: Implicit neural representations for accurate estimation of the standard model of white matter
Authors: Tom Hendriks, Gerrit Arends, Edwin Versteeg, Anna Vilanova, Maxime Chamberland, Chantal M.W. Tax
Abstract: Diffusion magnetic resonance imaging (dMRI) enables non-invasive investigation of tissue microstructure. The Standard Model (SM) of white matter aims to disentangle dMRI signal contributions from intra- and extra-axonal water compartments. However, due to the model its high-dimensional nature, accurately estimating its parameters poses a complex problem and remains an active field of research, in which different (machine learning) strategies have been proposed. This work introduces an estimation framework based on implicit neural representations (INRs), which incorporate spatial regularization through the sinusoidal encoding of the input coordinates. The INR method is evaluated on both synthetic and in vivo datasets and compared to existing methods. Results demonstrate superior accuracy of the INR method in estimating SM parameters, particularly in low signal-to-noise conditions. Additionally, spatial upsampling of the INR can represent the underlying dataset anatomically plausibly in a continuous way. The INR is self-supervised, eliminating the need for labeled training data. It achieves fast inference, is robust to noise, supports joint estimation of SM kernel parameters and the fiber orientation distribution function with spherical harmonics orders up to at least 8, and accommodates gradient non-uniformity corrections. The combination of these properties positions INRs as a potentially important tool for analyzing and interpreting diffusion MRI data.

Paper number 85:
Title: Physiology-informed layered sensing for intelligent human-exoskeleton interaction
Authors: Chenyu Tang, Yu Zhu, Josée Mallah, Wentian Yi, Luyao Jin, Zibo Zhang, Shengbo Wang, Muzi Xu, Ming Shen, Calvin Kalun Or, Shuo Gao, Shaoping Bai, Luigi G. Occhipinti
Abstract: Wearable exoskeletons hold transformative promise for restoring mobility across diverse users with muscular weakness or other impairments. However, their translation beyond laboratory environments remains limited by sensing systems that capture movement but not underlying physiology. Here, we present a soft, lightweight smart leg sleeve that achieves anatomically aligned, layered multimodal sensing by integrating textile-based surface electromyography (sEMG) electrodes, ultrasensitive textile strain sensors, and inertial measurement units (IMUs). Each sensing modality targets a distinct physiological layer: IMUs track joint kinematics at the skeletal level, sEMG monitors muscle activation at the muscular level, and strain sensors detect skin deformation at the cutaneous level. Together, these sensors provide real-time perception to support three core objectives: controlling personalized assistance, optimizing user effort, and safeguarding against injury risks. The system is skin-conformal, mechanically compliant, and seamlessly integrated with a custom exoskeleton ($<20$~g total sensor and electronics weight). We demonstrate: (1) accurate ankle joint moment estimation (RMSE = 0.13~Nm/kg), (2) real-time classification of metabolic trends (accuracy = 97.1\%), and (3) injury risk detection within 100~ms (recall = 0.96), all validated on unseen users using a leave-one-subject-out protocol. This work establishes a physiology-aligned sensing architecture that reframes exoskeleton perception from motion tracking to real-time physiological decoding, offering a pathway towards intelligent, adaptive, and personalized wearable robotics.

Paper number 86:
Title: Foundation Model-Driven Classification of Atypical Mitotic Figures with Domain-Aware Training Strategies
Authors: Piotr Giedziun, Jan Sołtysik, Mateusz Górczany, Norbert Ropiak, Marcin Przymus, Piotr Krajewski, Jarosław Kwiecień, Artur Bartczak, Izabela Wasiak, Mateusz Maniewski
Abstract: We present a solution for the MIDOG 2025 Challenge Track~2, addressing binary classification of normal mitotic figures (NMFs) versus atypical mitotic figures (AMFs). The approach leverages pathology-specific foundation model H-optimus-0, selected based on recent cross-domain generalization benchmarks and our empirical testing, with Low-Rank Adaptation (LoRA) fine-tuning and MixUp augmentation. Implementation includes soft labels based on multi-expert consensus, hard negative mining, and adaptive focal loss, metric learning and domain adaptation. The method demonstrates both the promise and challenges of applying foundation models to this complex classification task, achieving reasonable performance in the preliminary evaluation phase.

Paper number 87:
Title: A kernel-based approach to physics-informed nonlinear system identification
Authors: Cesare Donati, Martina Mammarella, Giuseppe C. Calafiore, Fabrizio Dabbene, Constantino Lagoa, Carlo Novara
Abstract: This paper presents a kernel-based framework for physics-informed nonlinear system identification. The key contribution is a structured methodology that extends kernel-based techniques to seamlessly embed partially known physics-based models, improving parameter estimation and overall model accuracy. The proposed method enhances traditional modeling approaches by embedding a parametric model, which provides physical interpretability, with a kernel-based function, which accounts for unmodeled dynamics. The two models' components are identified from the data simultaneously, thereby minimizing a suitable cost that balances the relative importance of the physical and the black-box parts of the model. Additionally, nonlinear state smoothing is employed to address scenarios involving state-space models with not fully measurable states. Numerical simulations on an experimental benchmark system demonstrate the effectiveness of the proposed approach, achieving up to 51% reduction in simulation root mean square error compared to physics-only models and 31% performance improvement over state-of-the-art identification techniques.

Paper number 88:
Title: RadarLLM: Adapting Pretrained Large Language Models for Marine Radar Target Detection with Preference-aware Loss
Authors: Qiying Hu
Abstract: Recent advances in pre-trained large language models (LLMs) have demonstrated their capacities to capture universal knowledge, making them promising general-purpose optimization solvers for wireless signal processing. Motivated by these findings, we take the first step towards fine-tuning pre-trained LLMs for the effective analysis of radar signal features in marine target detection tasks. Nevertheless, directly fine-tuning pre-trained LLMs on marine target detection tasks tends to suffer from pronounced overfitting, particularly in challenging low signal-to-clutter ratio (SCR) scenarios. This overfitting is mainly due to the model's tendency to memorize noisy feature patterns rather than learning discriminative structures that generalize well to unseen data. To address this challenge, we introduce RadarLLM, a novel fine-tuning framework that utilizes an effective preference-aware loss. Unlike conventional training strategies that uniformly optimize all feature tokens, this loss function selectively optimizes different feature patches based on their online evaluated learning values, thus guiding the model to focus on the most generalizable patterns during optimization. We theoretically demonstrate the effectiveness of the evaluated learning values by transforming the problem as selecting useful feature tokens. Extensive experiments on real-world marine radar datasets show that 1) the proposed loss function outperforms the original one, showing particularly significant improvements under challenging low SCR conditions, with an average performance gain of 9.9% and 2) RadarLLM consistently outperforms state-of-the-art baselines in diverse detection scenarios, with particularly notable gains under limited training data conditions.

Paper number 89:
Title: Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist Kinematic Tracking
Authors: Giusy Spacone, Sebastian Frey, Mattia Orlandi, Pierangelo Maria Rapa, Victor Kartsch, Simone Benatti, Luca Benini, Andrea Cossettini
Abstract: Hand gesture recognition based on biosignals has shown strong potential for developing intuitive human-machine interaction strategies that closely mimic natural human behavior. In particular, sensor fusion approaches have gained attention for combining complementary information and overcoming the limitations of individual sensing modalities, thereby enabling more robust and reliable systems. Among them, the fusion of surface electromyography (EMG) and A-mode ultrasound (US) is very promising. However, prior solutions rely on power-hungry platforms unsuitable for multi-day use and are limited to discrete gesture classification. In this work, we present an ultra-low-power (sub-50 mW) system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US signals, integrating two state-of-the-art platforms into fully wearable, dry-contact armbands. We propose a framework for continuous tracking of 23 degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a kinematic glove for ground-truth labeling. Our method employs lightweight encoder-decoder architectures with multi-task learning to simultaneously estimate hand and wrist joint angles. Experimental results under realistic sensor repositioning conditions demonstrate that EMG-US fusion achieves a root mean squared error of $10.6^\circ\pm2.0^\circ$, compared to $12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$ score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US.

Paper number 90:
Title: Optical Link Tomography: First Field Trial and 4D Extension
Authors: Takeo Sasai, Giacomo Borraccini, Yue-Kai Huang, Hideki Nishizawa, Zehao Wang, Tingjun Chen, Yoshiaki Sone, Minami Takahashi, Tatsuya Matsumura, Masanori Nakamura, Etsushi Yamazaki, Koichi Takasugi, Ting Wang, Yoshiaki Kisaka
Abstract: Optical link tomography (OLT) is a rapidly evolving field that allows the multi-span, end-to-end visualization of optical power along fiber links in multiple dimensions from network endpoints, solely by processing signals received at coherent receivers. This paper has two objectives: (1) to report the first field trial of OLT, using a commercial transponder under standard DWDM transmission, and (2) to extend its capability to visualize across 4D (distance, time, frequency, and polarization), allowing for locating and measuring multiple QoT degradation causes, including time-varying power anomalies, spectral anomalies, and excessive polarization dependent loss. We also address a critical aspect of OLT, i.e., its need for high fiber launch power, by improving power profile signal-to-noise ratio through averaging across all available dimensions. Consequently, multiple loss anomalies in a field-deployed link are observed even at launch power lower than the system-optimal level. The applications and use cases of OLT from network commissioning to provisioning and operation for current and near-term network scenarios are also discussed.

Paper number 91:
Title: Through-the-Earth Magnetic Induction Communication and Networking: A Comprehensive Survey
Authors: Honglei Ma, Erwu Liu, Wei Ni, Zhijun Fang, Rui Wang, Yongbin Gao, Dusit Niyato, Ekram Hossain
Abstract: Magnetic induction (MI) communication (MIC) has emerged as a promising candidate for underground communication networks due to its excellent penetration capabilities. Integration with Space-Air-Ground-Underground (SAGUI) networks in next-generation mobile communication systems requires a well-defined network architecture. A recent discovery in MIC research, MI fast fading, remains in its early stages and presents unique challenges. This paper provides a comprehensive survey on through-the-earth (TTE) MIC, covering MI applications, channel modeling, point-to-point MIC design, relay techniques, network frameworks, and emerging technologies. We compare various MIC applications to highlight TTE-specific challenges and review the principles of channel modeling, addressing both MI slow fading and MI fast fading, along with its potential impact on existing MIC theories. We conduct a fine-grained decomposition of MI channel power gain into four distinct physical parameters, and propose a novel geometric model to analyze MI fast fading. We also summarize MI relay techniques, examine crosstalk effects in relay and high-density networks, and explore key research tasks within the OSI framework for a holistic MI network protocol in SAGUI. To bridge the gaps identified, we propose a MIC framework that supports TCP/IP and Linux, enabling full implementation of existing and emerging MIC solutions. This framework empowers researchers to leverage Linux resources and deep learning platforms for accelerated development of MIC in SAGUI networks. Remaining research challenges, open issues, and promising novel techniques are further identified to advance MIC research.

Paper number 92:
Title: Decentralized non-convex optimization via bi-level SQP and ADMM
Authors: Gösta Stomberg, Alexander Engelmann, Timm Faulwasser
Abstract: Decentralized non-convex optimization is important in many problems of practical relevance. Existing decentralized methods, however, typically either lack convergence guarantees for general non-convex problems, or they suffer from a high subproblem complexity. We present a novel bi-level SQP method, where the inner quadratic problems are solved via ADMM. A decentralized stopping criterion from inexact Newton methods allows the early termination of ADMM as an inner algorithm to improve computational efficiency. The method has local convergence guarantees for non-convex problems. Moreover, it only solves sequences of Quadratic Programs, whereas many existing algorithms solve sequences of Nonlinear Programs. The method shows competitive numerical performance for an optimal power flow problem.

Paper number 93:
Title: Decentralized Real-Time Iterations for Distributed NMPC
Authors: Gösta Stomberg, Alexander Engelmann, Moritz Diehl, Timm Faulwasser
Abstract: This article presents a Real-Time Iteration (RTI) scheme for distributed Nonlinear Model Predictive Control (NMPC). The scheme transfers the well-known RTI approach, a key enabler for many industrial real-time NMPC implementations, to the setting of cooperative distributed control. At each sampling instant, one outer iteration of a bi-level decentralized Sequential Quadratic Programming (dSQP) method is applied to a centralized optimal control problem. This ensures that real-time requirements are met and it facilitates cooperation between subsystems. Combining novel dSQP convergence results with RTI stability guarantees, we prove local exponential stability under standard assumptions on the MPC design with and without terminal constraints. The proposed scheme only requires neighbor-to-neighbor communication and avoids a central coordinator. A numerical example with coupled inverted pendulums demonstrates the efficacy of the approach.

Paper number 94:
Title: BandCondiNet: Parallel Transformers-based Conditional Popular Music Generation with Multi-View Features
Authors: Jing Luo, Xinyu Yang, Dorien Herremans
Abstract: Conditional music generation offers significant advantages in terms of user convenience and control, presenting great potential in AI-generated content research. However, building conditional generative systems for multitrack popular songs presents three primary challenges: insufficient fidelity of input conditions, poor structural modeling, and inadequate inter-track harmony learning in generative models. To address these issues, we propose BandCondiNet, a conditional model based on parallel Transformers, designed to process the multiple music sequences and generate high-quality multitrack samples. Specifically, we propose multi-view features across time and instruments as high-fidelity conditions. Moreover, we propose two specialized modules for BandCondiNet: Structure Enhanced Attention (SEA) to strengthen the musical structure, and Cross-Track Transformer (CTT) to enhance inter-track harmony. We conducted both objective and subjective evaluations on two popular music datasets with different sequence lengths. Objective results on the shorter dataset show that BandCondiNet outperforms other conditional models in 9 out of 10 metrics related to fidelity and inference speed, with the exception of Chord Accuracy. On the longer dataset, BandCondiNet surpasses all conditional models across all 10 metrics. Subjective evaluations across four criteria reveal that BandCondiNet trained on the shorter dataset performs best in Richness and performs comparably to state-of-the-art models in the other three criteria, while significantly outperforming them across all criteria when trained on the longer dataset. To further expand the application scope of BandCondiNet, future work should focus on developing an advanced conditional model capable of adapting to more user-friendly input conditions and supporting flexible instrumentation.

Paper number 95:
Title: Pseudo-Kinematic Trajectory Control and Planning of Tracked Vehicles
Authors: Michele Focchi, Daniele Fontanelli, Davide Stocco, Riccardo Bussola, Luigi Palopoli
Abstract: Tracked vehicles distribute their weight continuously over a large surface area (the tracks). This distinctive feature makes them the preferred choice for vehicles required to traverse soft and uneven terrain. From a robotics perspective, however, this flexibility comes at a cost: the complexity of modelling the system and the resulting difficulty in designing theoretically sound navigation solutions. In this paper, we aim to bridge this gap by proposing a framework for the navigation of tracked vehicles, built upon three key pillars. The first pillar comprises two models: a simulation model and a control-oriented model. The simulation model captures the intricate terramechanics dynamics arising from soil-track interaction and is employed to develop faithful digital twins of the system across a wide range of operating conditions. The control-oriented model is pseudo-kinematic and mathematically tractable, enabling the design of efficient and theoretically robust control schemes. The second pillar is a Lyapunov-based feedback trajectory controller that provides certifiable tracking guarantees. The third pillar is a portfolio of motion planning solutions, each offering different complexity-accuracy trade-offs. The various components of the proposed approach are validated through an extensive set of simulation and experimental data.

Paper number 96:
Title: Recursive Gaussian Process State Space Model
Authors: Tengjie Zheng, Haipeng Chen, Lin Cheng, Shengping Gong, Xu Huang
Abstract: Learning dynamical models from data is not only fundamental but also holds great promise for advancing principle discovery, time-series prediction, and controller design. Among various approaches, Gaussian Process State-Space Models (GPSSMs) have recently gained significant attention due to their combination of flexibility and interpretability. However, for online learning, the field lacks an efficient method suitable for scenarios where prior information regarding data distribution and model function is limited. To address this issue, this paper proposes a recursive GPSSM method with adaptive capabilities for both operating domains and Gaussian process (GP) hyperparameters. Specifically, we first utilize first-order linearization to derive a Bayesian update equation for the joint distribution between the system state and the GP model, enabling closed-form and domain-independent learning. Second, an online selection algorithm for inducing points is developed based on informative criteria to achieve lightweight learning. Third, to support online hyperparameter optimization, we recover historical measurement information from the current filtering distribution. Comprehensive evaluations on both synthetic and real-world datasets demonstrate the superior accuracy, computational efficiency, and adaptability of our method compared to state-of-the-art online GPSSM techniques.

Paper number 97:
Title: Kernel-based Koopman approximants for control: Flexible sampling, error analysis, and stability
Authors: Lea Bold, Friedrich M. Philipp, Manuel Schaller, Karl Worthmann
Abstract: Data-driven techniques for analysis, modeling, and control of complex dynamical systems are on the uptake. Koopman theory provides the theoretical foundation for the popular kernel extended dynamic mode decomposition (kEDMD). In this work, we propose a novel kEDMD scheme to approximate nonlinear control systems accompanied by an in-depth error analysis. Key features are regularization-based robustness and an adroit decomposition into micro and macro grids enabling flexible sampling. But foremost, we prove proportionality, i.e., explicit dependence on the distance to the (controlled) equilibrium, of the derived bound on the full approximation error. Leveraging this key property, we rigorously show that asymptotic stability of the data-driven surrogate (control) system implies asymptotic stability of the original (control) system and vice versa.

Paper number 98:
Title: A Multimodal Lightweight Approach to Fault Diagnosis of Induction Motors in High-Dimensional Dataset
Authors: Usman Ali
Abstract: An accurate AI-based diagnostic system for induction motors (IMs) holds the potential to enhance proactive maintenance, mitigating unplanned downtime and curbing overall maintenance costs within an industrial environment. Notably, among the prevalent faults in IMs, a Broken Rotor Bar (BRB) fault is frequently encountered. Researchers have proposed various fault diagnosis approaches using signal processing (SP), machine learning (ML), deep learning (DL), and hybrid architectures for BRB faults. One limitation in the existing literature is the training of these architectures on relatively small datasets, risking overfitting when implementing such systems in industrial environments. This paper addresses this limitation by implementing large-scale data of BRB faults by using a transfer-learning-based lightweight DL model named ShuffleNetV2 for diagnosing one, two, three, and four BRB faults using current and vibration signal data. Spectral images for training and testing are generated using a Short-Time Fourier Transform (STFT). The dataset comprises 57,500 images, with 47,500 used for training and 10,000 for testing. Remarkably, the ShuffleNetV2 model exhibited superior performance, in less computational cost as well as accurately classifying 98.856% of spectral images. To further enhance the visualization of harmonic sidebands resulting from broken bars, Fast Fourier Transform (FFT) is applied to current and vibration data. The paper also provides insights into the training and testing times for each model, contributing to a comprehensive understanding of the proposed fault diagnosis methodology. The findings of our research provide valuable insights into the performance and efficiency of different ML and DL models, offering a foundation for the development of robust fault diagnosis systems for induction motors in industrial settings.

Paper number 99:
Title: Towards smart and adaptive agents for active sensing on edge devices
Authors: Devendra Vyas, Nikola Pižurica, Nikola Milović, Igor Jovančević, Miguel de Prado, Tim Verbelen
Abstract: TinyML has made deploying deep learning models on low-power edge devices feasible, creating new opportunities for real-time perception in constrained environments. However, the adaptability of such deep learning methods remains limited to data drift adaptation, lacking broader capabilities that account for the environment's underlying dynamics and inherent uncertainty. Deep learning's scaling laws, which counterbalance this limitation by massively up-scaling data and model size, cannot be applied when deploying on the Edge, where deep learning limitations are further amplified as models are scaled down for deployment on resource-constrained devices. This paper presents an innovative agentic system capable of performing on-device perception and planning, enabling active sensing on the edge. By incorporating active inference into our solution, our approach extends beyond deep learning capabilities, allowing the system to plan in dynamic environments while operating in real-time with a compact memory footprint of as little as 300 MB. We showcase our proposed system by creating and deploying a saccade agent connected to an IoT camera with pan and tilt capabilities on an NVIDIA Jetson embedded device. The saccade agent controls the camera's field of view following optimal policies derived from the active inference principles, simulating human-like saccadic motion for surveillance and robotics applications.

Paper number 100:
Title: Summarizing Speech: A Comprehensive Survey
Authors: Fabian Retkowski, Maike Züfle, Andreas Sudmann, Dinah Pfau, Shinji Watanabe, Jan Niehues, Alexander Waibel
Abstract: Speech summarization has become an essential tool for efficiently managing and accessing the growing volume of spoken and audiovisual content. However, despite its increasing importance, speech summarization remains loosely defined. The field intersects with several research areas, including speech recognition, text summarization, and specific applications like meeting summarization. This survey not only examines existing datasets and evaluation protocols, which are crucial for assessing the quality of summarization approaches, but also synthesizes recent developments in the field, highlighting the shift from traditional systems to advanced models like fine-tuned cascaded architectures and end-to-end solutions. In doing so, we surface the ongoing challenges, such as the need for realistic evaluation benchmarks, multilingual datasets, and long-context handling.

Paper number 101:
Title: Feedback Stackelberg-Nash equilibria in difference games with quasi-hierarchical interactions and inequality constraints
Authors: Partha Sarathi Mohapatra, Puduru Viswanadha Reddy, Georges Zaccour
Abstract: In this paper, we study a class of two-player deterministic finite-horizon difference games with coupled inequality constraints, where each player has two types of decision variables: one involving sequential interactions and the other simultaneous interactions. We refer to this class of games as quasi-hierarchical dynamic games and define a solution concept called the feedback Stackelberg-Nash (FSN) equilibrium. Under separability assumption on cost functions, we provide a recursive formulation of the FSN solution using dynamic programming. We show that the FSN solution can be derived from the parametric feedback Stackelberg solution of an associated unconstrained game involving only sequential interactions, with a specific choice of the parameters that satisfy certain implicit complementarity conditions. For the linear-quadratic case, we show that an FSN solution is obtained by reformulating these complementarity conditions as a single large-scale linear complementarity problem. Finally, we illustrate our results using a dynamic duopoly game with production constraints.

Paper number 102:
Title: RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction
Authors: Xiucheng Wang, Qiming Zhang, Nan Cheng, Ruijin Sun, Zan Li, Shuguang Cui, Xuemin Shen
Abstract: In this paper, we propose a novel physics-informed generative learning approach, named RadioDiff-$k^2$, for accurate and efficient multipath-aware radio map (RM) construction. As future wireless communication evolves towards environment-aware paradigms, the accurate construction of RMs becomes crucial yet highly challenging. Conventional electromagnetic (EM)-based methods, such as full-wave solvers and ray-tracing approaches, exhibit substantial computational overhead and limited adaptability to dynamic scenarios. Although existing neural network (NN) approaches have efficient inferencing speed, they lack sufficient consideration of the underlying physics of EM wave propagation, limiting their effectiveness in accurately modeling critical EM singularities induced by complex multipath environments. To address these fundamental limitations, we propose a novel physics-inspired RM construction method guided explicitly by the Helmholtz equation, which inherently governs EM wave propagation. Specifically, based on the analysis of partial differential equations (PDEs), we theoretically establish a direct correspondence between EM singularities, which correspond to the critical spatial features influencing wireless propagation, and regions defined by negative wave numbers in the Helmholtz equation. We then design an innovative dual diffusion model (DM)-based large artificial intelligence framework comprising one DM dedicated to accurately inferring EM singularities and another DM responsible for reconstructing the complete RM using these singularities along with environmental contextual information. Experimental results demonstrate that the proposed RadioDiff-$k^2$ framework achieves state-of-the-art (SOTA) performance in both image-level RM construction and localization tasks, while maintaining inference latency within a few hundred milliseconds.

Paper number 103:
Title: A Markov Chain Monte Carlo Method for Efficient Finite-Length LDPC Code Design
Authors: Ata Tanrıkulu, Mete Yıldırım, Ahmed Hareedy
Abstract: Low-density parity-check (LDPC) codes are among the most prominent error-correction schemes. They find application to fortify various modern storage, communication, and computing systems. Protograph-based (PB) LDPC codes offer many degrees of freedom in the code design and enable fast encoding and decoding. In particular, spatially-coupled (SC) and multi-dimensional (MD) circulant-based codes are PB-LDPC codes with excellent performance. Efficient finite-length (FL) algorithms are required in order to effectively exploit the available degrees of freedom offered by SC partitioning, lifting, and MD relocations. In this paper, we propose a novel Markov chain Monte Carlo (MCMC or MC$^2$) method to perform this FL optimization, addressing the removal of short cycles. While iterating, we draw samples from a defined distribution where the probability decreases as the number of short cycles from the previous iteration increases. We analyze our MC$^2$ method theoretically as we prove the invariance of the Markov chain where each state represents a possible partitioning or lifting arrangement. Via our simulations, we then fit the distribution of the number of cycles resulting from a given arrangement on a Gaussian distribution. We derive estimates for cycle counts that are close to the actual counts. Furthermore, we derive the order of the expected number of iterations required by our approach to reach a local minimum as well as the size of the Markov chain recurrent class. Our approach is compatible with code design techniques based on gradient-descent. Numerical results show that our MC$^2$ method generates SC codes with remarkably less number of short cycles compared with the current state-of-the-art. Moreover, to reach the same number of cycles, our method requires orders of magnitude less overall time compared with the available literature methods.

Paper number 104:
Title: PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification
Authors: Huiling Zheng, Xian Zhong, Bin Liu, Yi Xiao, Bihan Wen, Xiaofeng Li
Abstract: The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover classification remains challenging due to modality heterogeneity and underexploited spectral complementarity. Existing approaches often fail to decouple shared structural features from modality-complementary radiometric attributes, resulting in feature conflicts and information loss. To address this, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework that separates phase (modality-shared) and amplitude (modality-complementary) components in the Fourier domain. This design reinforces shared structures while preserving complementary characteristics, thereby enhancing fusion quality. Unlike previous methods that overlook the distinct physical properties encoded in frequency spectra, PAD explicitly introduces amplitude-phase decoupling for multi-modal fusion. Specifically, PAD comprises two key components: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase features via convolution-guided scaling to improve geometric consistency; and 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates high- and low-frequency patterns using frequency-adaptive multilayer perceptrons, effectively exploiting SAR's morphological sensitivity and RGB's spectral richness. Extensive experiments on WHU-OPT-SAR and DDHR-SK demonstrate state-of-the-art performance. This work establishes a new paradigm for physics-aware multi-modal fusion in remote sensing. The code will be available at this https URL.

Paper number 105:
Title: Euclidean Distance Matrix Completion via Asymmetric Projected Gradient Descent
Authors: Yicheng Li, Xinghua Sun
Abstract: This paper proposes and analyzes a gradient-type algorithm based on Burer-Monteiro factorization, called the Asymmetric Projected Gradient Descent (APGD), for reconstructing the point set configuration from partial Euclidean distance measurements, known as the Euclidean Distance Matrix Completion (EDMC) problem. By paralleling the incoherence matrix completion framework, we show for the first time that global convergence guarantee with exact recovery of this routine can be established given $\mathcal{O}(\mu^2 r^3 \kappa^2 n \log n)$ Bernoulli random observations without any sample splitting. Unlike leveraging the tangent space Restricted Isometry Property (RIP) and local curvature of the low-rank embedding manifold in some very recent works, our proof provides extra upper bounds that act as analogies of the random graph lemma under EDMC setting. The APGD works surprisingly well and numerical experiments demonstrate exact linear convergence behavior in rich-sample regions yet deteriorates rapidly when compared with the performance obtained by optimizing the s-stress function, i.e., the standard but unexplained non-convex approach for EDMC, if the sample size is limited. While virtually matching our theoretical prediction, this unusual phenomenon might indicate that: (i) the power of implicit regularization is weakened when specified in the APGD case; (ii) the stabilization of such new gradient direction requires substantially more samples than the information-theoretic limit would suggest.

Paper number 106:
Title: Contact-Aware Safety in Soft Robots Using High-Order Control Barrier and Lyapunov Functions
Authors: Kiwan Wong, Maximilian Stölzle, Wei Xiao, Cosimo Della Santina, Daniela Rus, Gioele Zardini
Abstract: Robots operating alongside people, particularly in sensitive scenarios such as aiding the elderly with daily tasks or collaborating with workers in manufacturing, must guarantee safety and cultivate user trust. Continuum soft manipulators promise safety through material compliance, but as designs evolve for greater precision, payload capacity, and speed, and increasingly incorporate rigid elements, their injury risk resurfaces. In this letter, we introduce a comprehensive High-Order Control Barrier Function (HOCBF) + High-Order Control Lyapunov Function (HOCLF) framework that enforces strict contact force limits across the entire soft-robot body during environmental interactions. Our approach combines a differentiable Piecewise Cosserat-Segment (PCS) dynamics model with a convex-polygon distance approximation metric, named Differentiable Conservative Separating Axis Theorem (DCSAT), based on the soft robot geometry to enable real-time, whole-body collision detection, resolution, and enforcement of the safety constraints. By embedding HOCBFs into our optimization routine, we guarantee safety, allowing, for instance, safe navigation in operational space under HOCLF-driven motion objectives. Extensive planar simulations demonstrate that our method maintains safety-bounded contacts while achieving precise shape and task-space regulation. This work thus lays a foundation for the deployment of soft robots in human-centric environments with provable safety and performance.

Paper number 107:
Title: Improving Inference-Time Optimisation for Vocal Effects Style Transfer with a Gaussian Prior
Authors: Chin-Yun Yu, Marco A. Martínez-Ramírez, Junghyun Koo, Wei-Hsiang Liao, Yuki Mitsufuji, György Fazekas
Abstract: Style Transfer with Inference-Time Optimisation (ST-ITO) is a recent approach for transferring the applied effects of a reference audio to an audio track. It optimises the effect parameters to minimise the distance between the style embeddings of the processed audio and the reference. However, this method treats all possible configurations equally and relies solely on the embedding space, which can result in unrealistic configurations or biased outcomes. We address this pitfall by introducing a Gaussian prior derived from the DiffVox vocal preset dataset over the parameter space. The resulting optimisation is equivalent to maximum-a-posteriori estimation. Evaluations on vocal effects transfer on the MedleyDB dataset show significant improvements across metrics compared to baselines, including a blind audio effects estimator, nearest-neighbour approaches, and uncalibrated ST-ITO. The proposed calibration reduces the parameter mean squared error by up to 33% and more closely matches the reference style. Subjective evaluations with 16 participants confirm the superiority of our method in limited data regimes. This work demonstrates how incorporating prior knowledge at inference time enhances audio effects transfer, paving the way for more effective and realistic audio processing systems.

Paper number 108:
Title: DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech
Authors: Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee
Abstract: Cross-speaker emotion transfer in speech synthesis relies on extracting speaker-independent emotion embeddings for accurate emotion modeling without retaining speaker traits. However, existing timbre compression methods fail to fully separate speaker and emotion characteristics, causing speaker leakage and degraded synthesis quality. To address this, we propose DiEmo-TTS, a self-supervised distillation method to minimize emotional information loss and preserve speaker identity. We introduce cluster-driven sampling and information perturbation to preserve emotion while removing irrelevant factors. To facilitate this process, we propose an emotion clustering and matching approach using emotional attribute prediction and speaker embeddings, enabling generalization to unlabeled data. Additionally, we designed a dual conditioning transformer to integrate style features better. Experimental results confirm the effectiveness of our method in learning speaker-irrelevant emotion embeddings.

Paper number 109:
Title: EmoSphere-SER: Enhancing Speech Emotion Recognition Through Spherical Representation with Auxiliary Classification
Authors: Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee
Abstract: Speech emotion recognition predicts a speaker's emotional state from speech signals using discrete labels or continuous dimensions such as arousal, valence, and dominance (VAD). We propose EmoSphere-SER, a joint model that integrates spherical VAD region classification to guide VAD regression for improved emotion prediction. In our framework, VAD values are transformed into spherical coordinates that are divided into multiple spherical regions, and an auxiliary classification task predicts which spherical region each point belongs to, guiding the regression process. Additionally, we incorporate a dynamic weighting scheme and a style pooling layer with multi-head self-attention to capture spectral and temporal dynamics, further boosting performance. This combined training strategy reinforces structured learning and improves prediction consistency. Experimental results show that our approach exceeds baseline methods, confirming the validity of the proposed framework.

Paper number 110:
Title: Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox
Authors: Malikussaid, Sutiyo
Abstract: The convergence of Information Technology and Operational Technology has exposed Industrial Control Systems to adaptive, intelligent adversaries that render static defenses obsolete. This paper introduces the Adversarial Resilience Co-evolution (ARC) framework, addressing the "Trinity of Trust" comprising model fidelity, data integrity, and analytical resilience. ARC establishes a co-evolutionary arms race within a Fortified Secure Digital Twin (F-SCDT), where a Deep Reinforcement Learning "Red Agent" autonomously discovers attack paths while an ensemble-based "Blue Agent" is continuously hardened against these threats. Experimental validation on the Tennessee Eastman Process (TEP) and Secure Water Treatment (SWaT) testbeds demonstrates superior performance in detecting novel attacks, with F1-scores improving from 0.65 to 0.89 and detection latency reduced from over 1200 seconds to 210 seconds. A comprehensive ablation study reveals that the co-evolutionary process itself contributes a 27% performance improvement. By integrating Explainable AI and proposing a Federated ARC architecture, this work presents a necessary paradigm shift toward dynamic, self-improving security for critical infrastructure.

Paper number 111:
Title: PowerChain: A Verifiable Agentic AI System for Automating Distribution Grid Analyses
Authors: Emmanuel O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey
Abstract: Rapid electrification and decarbonization are increasing the complexity of distribution grid (DG) operation and planning, necessitating advanced computational analyses to ensure reliability and resilience. These analyses depend on disparate workflows comprising complex models, function calls, and data pipelines that require substantial expert knowledge and remain difficult to automate. Workforce and budget constraints further limit utilities' ability to apply such analyses at scale. To address this gap, we build an agentic system PowerChain, which is capable of autonomously performing complex grid analyses. Existing agentic AI systems are typically developed in a bottom-up manner with customized context for predefined analysis tasks; therefore, they do not generalize to tasks that the agent has never seen. In comparison, to generalize to unseen DG analysis tasks, PowerChain dynamically generates structured context by leveraging supervisory signals from self-contained power systems tools (e.g., GridLAB-D) and an optimized set of expert-annotated and verified reasoning trajectories. For complex DG tasks defined in natural language, empirical results on real utility data demonstrate that PowerChain achieves up to a 144/% improvement in performance over baselines.

Paper number 112:
Title: Soft Graph Transformer for MIMO Detection
Authors: Jiadong Hong, Lei Liu, Xinyu Bian, Wenjie Wang, Zhaoyang Zhang
Abstract: We propose the Soft Graph Transformer (SGT), a soft-input-soft-output neural architecture designed for MIMO detection. While Maximum Likelihood (ML) detection achieves optimal accuracy, its exponential complexity makes it infeasible in large systems, and conventional message-passing algorithms rely on asymptotic assumptions that often fail in finite dimensions. Recent Transformer-based detectors show strong performance but typically overlook the MIMO factor graph structure and cannot exploit prior soft information. SGT addresses these limitations by combining self-attention, which encodes contextual dependencies within symbol and constraint subgraphs, with graph-aware cross-attention, which performs structured message passing across subgraphs. Its soft-input interface allows the integration of auxiliary priors, producing effective soft outputs while maintaining computational efficiency. Experiments demonstrate that SGT achieves near-ML performance and offers a flexible and interpretable framework for receiver systems that leverage soft priors.

Paper number 113:
Title: Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation
Authors: Amirmasoud Molaei, Mohammad Heravi, Reza Ghabcheloo
Abstract: Rock capturing with standard excavator buckets is a challenging task typically requiring the expertise of skilled operators. Unlike soil digging, it involves manipulating large, irregular rocks in unstructured environments where complex contact interactions with granular material make model-based control impractical. Existing autonomous excavation methods focus mainly on continuous media or rely on specialized grippers, limiting their applicability to real-world construction sites. This paper introduces a fully data-driven control framework for rock capturing that eliminates the need for explicit modeling of rock or soil properties. A model-free reinforcement learning agent is trained in the AGX Dynamics simulator using the Proximal Policy Optimization (PPO) algorithm and a guiding reward formulation. The learned policy outputs joint velocity commands directly to the boom, arm, and bucket of a CAT365 excavator model. Robustness is enhanced through extensive domain randomization of rock geometry, density, and mass, as well as the initial configurations of the bucket, rock, and goal position. To the best of our knowledge, this is the first study to develop and evaluate an RL-based controller for the rock capturing task. Experimental results show that the policy generalizes well to unseen rocks and varying soil conditions, achieving high success rates comparable to those of human participants while maintaining machine stability. These findings demonstrate the feasibility of learning-based excavation strategies for discrete object manipulation without requiring specialized hardware or detailed material models.

Paper number 114:
Title: Benchmarking Fake Voice Detection in the Fake Voice Generation Arms Race
Authors: Xutao Mao, Ke Li, Cameron Baird, Ezra Xuanru Tao, Dan Lin
Abstract: The rapid advancement of fake voice generation technology has ignited a race with detection systems, creating an urgent need to secure the audio ecosystem. However, existing benchmarks suffer from a critical limitation: they typically aggregate diverse fake voice samples into a single dataset for evaluation. This practice masks method-specific artifacts and obscures the varying performance of detectors against different generation paradigms, preventing a nuanced understanding of their true vulnerabilities. To address this gap, we introduce the first ecosystem-level benchmark that systematically evaluates the interplay between 17 state-of-the-art fake voice generators and 8 leading detectors through a novel one-to-one evaluation protocol. This fine-grained analysis exposes previously hidden vulnerabilities and sensitivities that are missed by traditional aggregated testing. We also propose unified scoring systems to quantify both the evasiveness of generators and the robustness of detectors, enabling fair and direct comparisons. Our extensive cross-domain evaluation reveals that modern generators, particularly those based on neural audio codecs and flow matching, consistently evade top-tier detectors. We found that no single detector is universally robust; their effectiveness varies dramatically depending on the generator's architecture, highlighting a significant generalization gap in current defenses. This work provides a more realistic assessment of the threat landscape and offers actionable insights for building the next generation of detection systems.
    