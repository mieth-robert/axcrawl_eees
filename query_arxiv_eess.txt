
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: SEAL: Speech Embedding Alignment Learning for Speech Large Language Model with Retrieval-Augmented Generation
Authors: Chunyu Sun, Bingyu Liu, Zhichao Cui, Anbin Qi, Tian-hao Zhang, Dinghao Zhou, Lewei Lu
Abstract: Embedding-based retrieval models have made significant strides in retrieval-augmented generation (RAG) techniques for text and multimodal large language models (LLMs) applications. However, when it comes to speech larage language models (SLLMs), these methods are limited to a two-stage process, where automatic speech recognition (ASR) is combined with text-based retrieval. This sequential architecture suffers from high latency and error propagation. To address these limitations, we propose a unified embedding framework that eliminates the need for intermediate text representations. Specifically, the framework includes separate speech and text encoders, followed by a shared scaling layer that maps both modalities into a common embedding space. Our model reduces pipeline latency by 50\% while achieving higher retrieval accuracy compared to traditional two-stage methods. We also provide a theoretical analysis of the challenges inherent in end-to-end speech retrieval and introduce architectural principles for effective speech-to-document matching. Extensive experiments demonstrate the robustness of our approach across diverse acoustic conditions and speaker variations, paving the way for a new paradigm in multimodal SLLMs retrieval systems.

Paper number 2:
Title: Muographic Image Upsampling with Machine Learning for Built Infrastructure Applications
Authors: William O'Donnell, David Mahon, Guangliang Yang, Simon Gardner
Abstract: The civil engineering industry faces a critical need for innovative non-destructive evaluation methods, particularly for ageing critical infrastructure, such as bridges, where current techniques fall short. Muography, a non-invasive imaging technique, constructs three-dimensional density maps by detecting interactions of naturally occurring cosmic-ray muons within the scanned volume. Cosmic-ray muons provide deep penetration and inherent safety due to their high momenta and natural source. However, the technology's reliance on this source results in constrained muon flux, leading to prolonged acquisition times, noisy reconstructions and image interpretation challenges. To address these limitations, we developed a two-model deep learning approach. First, we employed a conditional Wasserstein generative adversarial network with gradient penalty (cWGAN-GP) to perform predictive upsampling of undersampled muography images. Using the structural similarity index measure (SSIM), 1-day sampled images matched the perceptual qualities of a 21-day image, while the peak signal-to-noise ratio (PSNR) indicated noise improvement equivalent to 31 days of sampling. A second cWGAN-GP model, trained for semantic segmentation, quantitatively assessed the upsampling model's impact on concrete sample features. This model achieved segmentation of rebar grids and tendon ducts, with Dice-Sørensen accuracy coefficients of 0.8174 and 0.8663. Notably, it could mitigate or remove z-plane smearing artifacts caused by muography's inverse imaging problem. Both models were trained on a comprehensive Geant4 Monte-Carlo simulation dataset reflecting realistic civil infrastructure scenarios. Our results demonstrate significant improvements in acquisition speed and image quality, marking a substantial step toward making muography more practical for reinforced concrete infrastructure monitoring applications.

Paper number 3:
Title: Distributed Prescribed-Time Observer for Nonlinear Systems
Authors: Vincent de Heij, M. Umar B. Niazi, Karl H. Johansson, Saeed Ahmed
Abstract: This paper proposes a distributed prescribed-time observer for nonlinear systems representable in a block-triangular observable canonical form. Using a weighted average of neighbor estimates exchanged over a strongly connected digraph, each observer estimates the system state despite limited local sensor measurements. The proposed design guarantees that distributed state estimation errors converge to zero at a user-specified convergence time, irrespective of observers' initial conditions. To achieve this prescribed-time convergence, distributed observers implement time-varying local output injection gains that asymptotically approach infinity as the prescribed time is approached. The theoretical convergence is rigorously proven and validated through numerical simulations.

Paper number 4:
Title: Three-dimensional signal processing: a new approach in dynamical sampling via tensor products
Authors: Yisen Wang, Hanqin Cai, Longxiu Huang
Abstract: The dynamical sampling problem is centered around reconstructing signals that evolve over time according to a dynamical process, from spatial-temporal samples that may be noisy. This topic has been thoroughly explored for one-dimensional signals. Multidimensional signal recovery has also been studied, but primarily in scenarios where the driving operator is a convolution operator. In this work, we shift our focus to the dynamical sampling problem in the context of three-dimensional signal recovery, where the evolution system can be characterized by tensor products. Specifically, we provide a necessary condition for the sampling set that ensures successful recovery of the three-dimensional signal. Furthermore, we reformulate the reconstruction problem as an optimization task, which can be solved efficiently. To demonstrate the effectiveness of our approach, we include some straightforward numerical simulations that showcase the reconstruction performance.

Paper number 5:
Title: NDKF: A Neural-Enhanced Distributed Kalman Filter for Nonlinear Multi-Sensor Estimation
Authors: Siavash Farzan
Abstract: We propose a Neural-Enhanced Distributed Kalman Filter (NDKF) for multi-sensor state estimation in nonlinear systems. Unlike traditional Kalman filters that rely on explicit, linear models and centralized data fusion, the NDKF leverages neural networks to learn both the system dynamics and measurement functions directly from data. Each sensor node performs local prediction and update steps using these learned models and exchanges only compact summary information with its neighbors via a consensus-based fusion process, which reduces communication overhead and eliminates a single point of failure. Our theoretical convergence analysis establishes sufficient conditions under which the local linearizations of the neural models guarantee overall filter stability and provides a solid foundation for the proposed approach. Simulation studies on a 2D system with four partially observing nodes demonstrate that the NDKF significantly outperforms a distributed Extended Kalman Filter. These outcomes, as yielded by the proposed NDKF method, highlight its potential to improve the scalability, robustness, and accuracy of distributed state estimation in complex nonlinear environments.

Paper number 6:
Title: Multidimensional Swarm Flight Approach For Chasing Unauthorized UAVs Leveraging Asynchronous Deep Learning
Authors: Tae-Won Ban, Kyu-Min Kang, Bang Chul Jung
Abstract: This paper introduces a novel unmanned aerial vehicles (UAV) chasing system designed to track and chase unauthorized UAVs, significantly enhancing their neutralization effectiveness.

Paper number 7:
Title: Estimation of Blood Flow Parameters in the Left Atrial Appendage from 4DCT Dynamic Contrast Enhancement
Authors: Lauren M. Severance, Andrew M. Kahn, Juan C. del Alamo, Elliot R. McVeigh
Abstract: Cardiac CT is often used clinically in electrophysiology to evaluate cardiac morphology. One such case is to evaluate patients with Atrial Fibrillation (AF). AF can cause regions of slow blood flow and blood stasis through the left atrial appendage (LAA), and therefore, it may be preferable to evaluate blood flow through the LAA in addition to morphology. Although CT cannot measure flow directly, CT data has been used to estimate flow using modeling approaches such as Computational Fluid Dynamics, which take into account the cardiac geometry to simulate flow. Advances in CT technology now enable high-resolution imaging of the whole heart with low radiation doses. With multi-heartbeat imaging during a contrast injection, we can obtain 4-dimentional CT (4DCT) images to measure dynamic contrast enhancement directly. In this study, we use high-resolution 4DCT to acquire images of contrast enhancement across the LAA over multiple heartbeats. The CT contrast signal at each voxel over time is used to create dynamic contrast enhancement maps of parameters derived from a gamma-variate fit. These contrast enhancement maps enable quantification and visualization of spatial-temporal characteristics of flow parameters across the LAA.

Paper number 8:
Title: A Modal-Based Approach for System Frequency Response and Frequency Nadir Prediction
Authors: Francisco Zelaya-Arrazabal, Sebastian Martinez-Lizana, Héctor Pulgar-Painemal
Abstract: This letter introduces a novel approach for predicting system frequency response and frequency nadir by leveraging modal information. It significantly differentiates from traditional methods rooted in the average system frequency model. The proposed methodology targets system modes associated with the slower dynamics of the grid, enabling precise predictions through modal decomposition applied to the full system model. This decomposition facilitates an analytical solution for the frequency at the center of inertia, resulting in highly accurate predictions of both frequency response and nadir. Numerical results from a 39-bus, 10-machine test system verify the method's effectiveness and accuracy. This methodology represents a shift from observing a simplified average system frequency response to a more detailed analysis focusing on system dynamics.

Paper number 9:
Title: Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images
Authors: Obed Korshie Dzikunu, Shadab Ahamed, Amirhossein Toosi, Xiaoxiao Li, Arman Rahmim
Abstract: This study proposes a new loss function for deep neural networks, L1-weighted Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of voxels based on their classification difficulty, towards automated detection and segmentation of metastatic prostate cancer lesions in PET/CT scans. We obtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with biochemical recurrence metastatic prostate cancer. We trained two 3D convolutional neural networks, Attention U-Net and SegResNet, and concatenated the PET and CT volumes channel-wise as input. The performance of our custom loss function was evaluated against the Dice and Dice Focal Loss functions. For clinical significance, we considered a detected region of interest (ROI) as a true positive if at least the voxel with the maximum standardized uptake value falls within the ROI. We assessed the models' performance based on the number of lesions in an image, tumour volume, activity, and extent of spread. The L1DFL outperformed the comparative loss functions by at least 13% on the test set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were lower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal Loss yielded more false positives, whereas the Dice Loss was more sensitive to smaller volumes and struggled to segment larger lesions accurately. They also exhibited network-specific variations and yielded declines in segmentation accuracy with increased tumour spread. Our results demonstrate the potential of L1DFL to yield robust segmentation of metastatic prostate cancer lesions in PSMA PET/CT images. The results further highlight potential complexities arising from the variations in lesion characteristics that may influence automated prostate cancer tumour detection and segmentation. The code is publicly available at: this https URL.

Paper number 10:
Title: LUCAS: A CMOS-Based Fast Readout ASIC for Silicon Photomultipliers -- Measurement and Performance Evaluation
Authors: Seyed Arash Katourani
Abstract: This paper presents the design, implementation, and performance evaluation of LUCAS, a low-power, ultra-low jitter ASIC optimized for SiPM readout in Time-of-Flight Computed Tomography (ToF-CT) applications. Leveraging a novel preamplifier design with low input impedance and current-mode operation, LUCAS addresses challenges such as parasitic capacitance of SiPMs and high-speed detection requirements. The ASIC, fabricated in TSMC 65nm CMOS technology, features eight channels with an integrated preamplifier and comparator, achieving an SPTR of 201 ps FWHM at 3.2 mW/ch. Experimental validation includes input impedance measurements, SPTR testing with a pulsed laser source, and energy-to-Time-over-Threshold calibration using monoenergetic X-ray sources. The results demonstrate the effectiveness of LUCAS in enhancing timing resolution while minimizing power consumption, offering significant advancements for high-resolution ToF-CT imaging.

Paper number 11:
Title: A Comprehensive Survey on Feature Extraction Techniques Using I/Q Imbalance in RFFI
Authors: Muhammad Aqib Khan, Muhammad Usman Siddiqui
Abstract: The proliferation of Internet of Things (IoT) devices has increased the need for secure authentication. While traditional encryption-based solutions can be robust, they often impose high computational and energy overhead on resource-limited IoT nodes. As an alternative, radio frequency fingerprint identification (RFFI) leverages hardware-induced imperfections-such as Inphase/Quadrature (I/Q) imbalance-in Radio Frequency (RF) front-end components as unique identifiers that are inherently difficult to clone or spoof. Despite recent advances, significant challenges remain in standardizing feature extraction methods, maintaining high accuracy across diverse environments, and efficiently handling large-scale IoT deployments. This paper addresses these gaps by providing a comprehensive review of feature extraction techniques that utilize I/Q imbalance for RFFI. We also discuss other hardware-based RF fingerprinting sources, including power amplifier nonlinearity and oscillator imperfections, and examine modern machine learning (ML) and deep learning (DL) approaches that enhance device identification performance.

Paper number 12:
Title: Runway capacity expansion planning for public airports under demand uncertainty
Authors: Ziyue Li, Joseph Y.J. Chow, Qianwen Guo
Abstract: Flight delay is a significant issue affecting air travel. The runway system, frequently falling short of demand, serves as a bottleneck. As demand increases, runway capacity expansion becomes imperative to mitigate congestion. However, the decision to expand runway capacity is challenging due to inherent uncertainties in demand forecasts. This paper presents a novel approach to modeling air traffic demand growth as a jump diffusion process, incorporating two layers of uncertainty: Geometric Brownian Motion (GBM) for continuous variability and a Poisson process to capture the impact of crisis events, such as natural disasters or public health emergencies, on decision-making. We propose a real options model to jointly evaluate the interrelated factors of optimal runway capacity and investment timing under uncertainty, with investment timing linked to trigger demand. The findings suggest that increased uncertainty indicates more conservative decision-making. Furthermore, the relationship between optimal investment timing and expansion size is complex: if the expansion size remains unchanged, the trigger demand decreases as the demand growth rate increases; if the expansion size experiences a jump, the trigger demand also exhibits a sharp rise. This work provides valuable insights for airport authorities for informed capacity expansion decision-making.

Paper number 13:
Title: Optimal No-Fly Zone Design for the Coexistence of Drone and Satellite Networks
Authors: Xiangliu Tu, Chiranjib Saha Harpreet S. Dhillon
Abstract: Constructing a no-fly zone (NFZ) is a straightforward and effective way to facilitate the coexistence of unmanned aerial vehicles (drones) and existing systems (typically satellite systems). However, there has been little work on understanding the optimal design of such NFZs. In the absence of this design, one invariably ends up overestimating this region, hence significantly limiting the allowed airspace for the drones. To optimize the volume of the NFZ, we formulate this task as a variational problem and utilize the calculus of variations to rigorously obtain the NFZ as a function of the antenna pattern of victim receivers and the spatial distribution of drones. This approach parallels the matched filter design in the sense that the NFZ extends in directions where the antenna gain and/or the density of drones is high. Numerical simulations demonstrate the effectiveness of our optimal design compared to the known baselines in reducing the volume of the NFZ without compromising the protective performance.

Paper number 14:
Title: Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations
Authors: Peiyan Yue, Die Cai, Chu Guo, Mengxing Liu, Jun Xia, Yi Wang
Abstract: Accurate automated segmentation of tibial plateau fractures (TPF) from computed tomography (CT) requires large amounts of annotated data to train deep learning models, but obtaining such annotations presents unique challenges. The process demands expert knowledge to identify diverse fracture patterns, assess severity, and account for individual anatomical variations, making the annotation process highly time-consuming and expensive. Although semi-supervised learning methods can utilize unlabeled data, existing approaches often struggle with the complexity and variability of fracture morphologies, as well as limited generalizability across datasets. To tackle these issues, we propose an effective training strategy based on masked autoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages MAE pretraining to capture global skeletal structures and fine-grained fracture details from unlabeled data, followed by fine-tuning with a small set of labeled data. This strategy reduces the dependence on extensive annotations while enhancing the model's ability to learn generalizable and transferable features. The proposed method is evaluated on an in-house dataset containing 180 CT scans with TPF. Experimental results demonstrate that our method consistently outperforms semi-supervised methods, achieving an average Dice similarity coefficient (DSC) of 95.81%, average symmetric surface distance (ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20 annotated cases. Moreover, our method exhibits strong transferability when applying to another public pelvic CT dataset with hip fractures, highlighting its potential for broader applications in fracture segmentation tasks.

Paper number 15:
Title: GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling
Authors: Jixun Yao, Hexin Liu, Chen Chen, Yuchen Hu, EngSiong Chng, Lei Xie
Abstract: Semantic information refers to the meaning conveyed through words, phrases, and contextual relationships within a given linguistic structure. Humans can leverage semantic information, such as familiar linguistic patterns and contextual cues, to reconstruct incomplete or masked speech signals in noisy environments. However, existing speech enhancement (SE) approaches often overlook the rich semantic information embedded in speech, which is crucial for improving intelligibility, speaker consistency, and overall quality of enhanced speech signals. To enrich the SE model with semantic information, we employ language models as an efficient semantic learner and propose a comprehensive framework tailored for language model-based speech enhancement, called \textit{GenSE}. Specifically, we approach SE as a conditional language modeling task rather than a continuous signal regression problem defined in existing works. This is achieved by tokenizing speech signals into semantic tokens using a pre-trained self-supervised model and into acoustic tokens using a custom-designed single-quantizer neural codec model. To improve the stability of language model predictions, we propose a hierarchical modeling method that decouples the generation of clean semantic tokens and clean acoustic tokens into two distinct stages. Moreover, we introduce a token chain prompting mechanism during the acoustic token generation stage to ensure timbre consistency throughout the speech enhancement process. Experimental results on benchmark datasets demonstrate that our proposed approach outperforms state-of-the-art SE systems in terms of speech quality and generalization capability.

Paper number 16:
Title: Fine-grained Preference Optimization Improves Zero-shot Text-to-Speech
Authors: Jixun Yao, Yuguang Yang, Yu Pan, Yuan Feng, Ziqian Ning, Jianhao Ye, Hongbin Zhou, Lei Xie
Abstract: Integrating human feedback to align text-to-speech (TTS) system outputs with human preferences has proven to be an effective approach for enhancing the robustness of language model-based TTS systems. Current approaches primarily focus on using preference data annotated at the utterance level. However, frequent issues that affect the listening experience often only arise in specific segments of audio samples, while other segments are well-generated. In this study, we propose a fine-grained preference optimization approach (FPO) to enhance the robustness of TTS systems. FPO focuses on addressing localized issues in generated samples rather than uniformly optimizing the entire utterance. Specifically, we first analyze the types of issues in generated samples, categorize them into two groups, and propose a selective training loss strategy to optimize preferences based on fine-grained labels for each issue type. Experimental results show that FPO enhances the robustness of zero-shot TTS systems by effectively addressing local issues, significantly reducing the bad case ratio, and improving intelligibility. Furthermore, FPO exhibits superior data efficiency compared with baseline systems, achieving similar performance with fewer training samples.

Paper number 17:
Title: Asymptotic Analysis of One-bit Quantized Box-Constrained Precoding in Large-Scale Multi-User Systems
Authors: Xiuxiu Ma, Abla Kammoun, Mohamed-Slim Alouini, Tareq Y. Al-Naffouri
Abstract: This paper addresses the design of multi-antenna precoding strategies, considering hardware limitations such as low-resolution digital-to-analog converters (DACs), which necessitate the quantization of transmitted signals. The typical approach starts with optimizing a precoder, followed by a quantization step to meet hardware requirements. This study analyzes the performance of a quantization scheme applied to the box-constrained regularized zero-forcing (RZF) precoder in the asymptotic regime, where the number of antennas and users grows proportionally. The box constraint, initially designed to cope with low-dynamic range amplifiers, is used here to control quantization noise rather than for amplifier compatibility. A significant challenge in analyzing the quantized precoder is that the input to the quantization operation does not follow a Gaussian distribution, making traditional methods such as Bussgang's decomposition unsuitable. To overcome this, the paper extends the Gordon's inequality and introduces a novel Gaussian Min-Max Theorem to model the distribution of the channel-distorted precoded signal. The analysis derives the tight lower bound for the signal-to-distortion-plus-noise ratio (SDNR) and the bit error rate (BER), showing that optimal tuning of the amplitude constraint improves performance.

Paper number 18:
Title: A Corrugated All-Metal Vivaldi Antenna for 5G Phased Array Applications
Authors: Mahyar Mehri Pashaki, Mohammad Hossein Koohi Ghamsari, Alireza Mallahzadeh, Gabriele Gradoni, Mohsen Khalily
Abstract: In this paper, a corrugated Vivaldi phased array antenna in the 28 GHz frequency band is proposed for 5G communication applications. The presented configuration features an all-metal antipodal antenna structure with a broad bandwidth ranging from 26 to 30 GHz and beam steering capabilities from -30 to +30 degrees. The proposed antenna consists of a 4x4 array configuration, where each element has dimensions of 6.46x6.46x14.25 mm, resulting in an overall antenna structure with dimensions of 25.84x25.84x14.25 mm. The corrugation method is applied to minimize surface currents, resulting in a reduction in interelement mutual couplings. Therefore, the return loss in the array structure for central elements is decreased, and the antenna gain and radiation efficiency are improved. Moreover, the improved radiation efficiency allows for higher power transmission and reception from an antenna, resulting in potentially higher data rates and better performance.

Paper number 19:
Title: Optimizing Electric Vehicles Charging using Large Language Models and Graph Neural Networks
Authors: Stavros Orfanoudakis, Peter Palensky, Pedro P. Vergara
Abstract: Maintaining grid stability amid widespread electric vehicle (EV) adoption is vital for sustainable transportation. Traditional optimization methods and Reinforcement Learning (RL) approaches often struggle with the high dimensionality and dynamic nature of real-time EV charging, leading to sub-optimal solutions. To address these challenges, this study demonstrates that combining Large Language Models (LLMs), for sequence modeling, with Graph Neural Networks (GNNs), for relational information extraction, not only outperforms conventional EV smart charging methods, but also paves the way for entirely new research directions and innovative solutions.

Paper number 20:
Title: Perfect matching of reactive loads through complex frequencies: from circuital analysis to experiments
Authors: Angelica V. Marini, Davide Ramaccia, Alessandro Toscano, Filiberto Bilotti
Abstract: The experimental evidence of purely reactive loads impedance matching is here provided by exploiting the special scattering response under complex excitations. The study starts with a theoretical analysis of the reflection properties of an arbitrary reactive load and identifies the proper excitation able to transform the purely reactive load into a virtual resistive load during the time the signal is applied. To minimize reflections between the load and the transmission line, the excitation must have a complex frequency, leading to a propagating signal with a tailored temporal envelope. The aim of this work is to design and, for the first time,experimentally demonstrate this anomalous scattering behavior in microwave circuits, showing that the time-modulated signals can be exploited as a new degree of freedom for achieving impedance matching without introducing neither a matching network nor resistive elements, that are typically used for ensuring power dissipation and, thus, zero reflection. The proposed matching strategy does not alter the reactive load that is still lossless, enabling an anomalous termination condition where the energy is not dissipated nor reflected, but indefinitely accumulated in the reactive load. The stored energy leaks out the load as soon as the applied signal changes or stops.

Paper number 21:
Title: Poisson Flow Joint Model for Multiphase contrast-enhanced CT
Authors: Rongjun Ge, Ge Wang
Abstract: In clinical practice, multiphase contrast-enhanced CT (MCCT) is important for physiological and pathological imaging with contrast injection, which undergoes non-contrast, venous, and delayed phases. Inevitably, the accumulated radiation dose to a patient is higher for multiphase scans than for a plain CT scan. Low-dose CECT is thus highly desirable, but it often leads to suboptimal image quality due to reduced radiation dose. Recently, a generalized Poisson flow generative model (PFGM++) was proposed to unify the diffusion model and the Poisson flow generative models (PFGM), and outperform either of them with an optimized dimensionality of the augmentation data space, holding a significant promise for generic or conditional image generation. In this paper, we propose a Poisson flow joint model (PFJM) for low-dose MCCT to suppress image noise and preserve clinical features. Our model is built on the PFGM++ architecture to transform the multiphase imaging problem into learning the joint distribution of routine-dose MCCT images by optimizing a task-specific generation path with respect to the dimensionality D of the augmented data space. Then, our PFJM model takes the joint low-dose MCCT images as the condition and robustly drives the generative trajectory towards the solution in the routine-dose MCCT domain. Extensive experiments demonstrate that our model is favorably compared with competing models, with MAE of 8.99 HU, SSIM of 98.75% and PSNR of 48.24db, as averaged over all the phases.

Paper number 22:
Title: Dual-Polarized Intelligent Omni-Surfaces for Independent Reflective-Refractive Transmission
Authors: Zizhou Zheng
Abstract: Intelligent omni-surface (IOS), which are capable of providing service coverage to mobile users (MUs) in a reflective and a refractive manner, has recently attracted widespread attention. However, the performance of traditionally IOS-aid systems is limited by the intimate coupling between the refraction and reflection behavior of IOS elements. In this letter, to overcome this challenge, we introduce the concept of dual-polarized IOS-assisted communication. More precisely, by employing the polarization domain in the design of IOS, full independent refraction and reflection modes can be delivered. We consider a downlink dual-polarized IOS-aided system, while also accounting for the leakage between different polarizations. To maximize the sum rate, we formulate a joint IOS phase shift and BS beamforming problem and proposed an iterative algorithm to solve the non-convex program. Simulation results validate that dual-polarized IOS significantly enhances the performance than the traditional one.

Paper number 23:
Title: Levelised Cost of Demand Response: Estimating the Cost-Competitiveness of Flexible Demand
Authors: Jacob Thrän, Tim C. Green, Robert Shorten
Abstract: To make well-informed investment decisions, energy system stakeholders require reliable cost frameworks for demand response (DR) and storage technologies. While the levelised cost of storage (LCOS) permits comprehensive cost comparisons between different storage technologies, no generic cost measure for the comparison of different DR schemes exists. This paper introduces the levelised cost of demand response (LCODR) which is an analogous measure to the LCOS but crucially differs from it by considering consumer reward payments. Additionally, the value factor from cost estimations of variable renewable energy is adapted to account for the variable availability of DR. The LCODRs for four direct load control (DLC) schemes and twelve storage applications are estimated and contrasted against LCOS literature values for the most competitive storage technologies. The DLC schemes are vehicle-to-grid, smart charging, smart heat pumps, and heat pumps with thermal storage. The results show that only heat pumps with thermal storage consistently outcompete storage technologies with EV-based DR schemes being competitive for some applications. The results and the underlying methodology offer a tool for energy system stakeholders to assess the competitiveness of DR schemes even with limited user data.

Paper number 24:
Title: Antenna Position Optimization for Movable Antenna-Empowered Near-Field Sensing
Authors: Yushen Wang, Weidong Mei, Xin Wei, Boyu Ning, Zhi Chen
Abstract: Movable antennas (MAs) show great promise for enhancing the sensing capabilities of future sixth-generation (6G) networks. With the growing prevalence of near-field propagation at ultra-high frequencies, this paper focuses on the application of MAs for near-field sensing to jointly estimate the angle and distance information of a target. First, to gain essential insights into MA-enhanced near-field sensing, we investigate two simplified cases with only the spatial angle-of-arrival (AoA) or distance estimation, respectively, assuming that the other information is already known. We derive the worst-case Cramer-Rao bounds (CRBs) on the mean square errors (MSEs) of the AoA estimation and the distance estimation via the multiple signal classification (MUSIC) algorithm in these two cases. Then, we jointly optimize the positions of the MAs within a linear array to minimize these CRBs and derive their closed-form solutions, which yield an identical array geometry to MA-aided far-field sensing. Furthermore, we proceed to the more challenging case with the joint AoA and distance estimation and derive the worst-case CRB under the two-dimensional (2D) MUSIC algorithm. The corresponding CRB minimization problem is efficiently solved by adopting a discrete sampling-based approach. Numerical results demonstrate that the proposed MA-enhanced near-field sensing significantly outperforms conventional sensing with fixed-position antennas (FPAs). Moreover, the joint angle and distance estimation results in a different array geometry from that in the individual estimation of angle or distance.

Paper number 25:
Title: Hybrid Near-Field and Far-Field Localization with Multiple Holographic MIMO Surfaces
Authors: Mengyuan Cao
Abstract: Localization methods based on holographic multiple input multiple output (HMIMO) have gained much attention for its potential to achieve high accuracy. By deploying multiple HMIMOs, we can improve the link quality and system coverage. As the scale of HMIMO increases to improve beam control capability, the near-field (NF) region of each HMIMO expands. However, existing multiple HMIMO-enabled methods mainly focus on the far-field (FF) of each HMIMO, which leads to low localization accuracy when applied in the NF. In this paper, a hybrid NF and FF localization method aided by multiple RISs, a low cost implementation of HMIMO, is proposed. In such a scenario, it is difficult to achieve user localization and RIS optimization since the equivalent NF of all RISs expands, which results in high complexity, and we need to handle the interference caused by multiple RISs. To tackle this challenge, we propose a two-phase RIS-enabled localization method that first estimate the relative locations of the user to each RIS and fuse the results to obtain the global estimation. In this way, the algorithm complexity is reduced. We formulate the RIS optimization problem to keep the RIS sidelobe as low as possible to minimize the interference. The effectiveness of the proposed method is verified through simulations.

Paper number 26:
Title: Low-cost analog signal chain for transmit-receive circuits of passive induction-based resonators
Authors: Fabian Mohn, Florian Thieben, Tobias Knopp
Abstract: Passive wireless sensors are crucial in modern medical and industrial settings to monitor procedures and conditions. We demonstrate a circuit to inductively excite passive resonators and to conduct their decaying signal response to a low noise amplifier. Two design variations of a generic transmit-receive signal chain are proposed, measured, and described in detail for the purpose of facilitating replication. Instrumentation and design aim to be scalable for multi-channel array configurations, using either off-the-shelf class-D audio amplifiers or a custom full H-bridge. Measurements are conducted on miniature magneto-mechanical resonators in the ultra low frequency range to enable sensing and tracking applications of such devices in different environments.

Paper number 27:
Title: Leveraging Broadcast Media Subtitle Transcripts for Automatic Speech Recognition and Subtitling
Authors: Jakob Poncelet, Hugo Van hamme
Abstract: The recent advancement of speech recognition technology has been driven by large-scale datasets and attention-based architectures, but many challenges still remain, especially for low-resource languages and dialects. This paper explores the integration of weakly supervised transcripts from TV subtitles into automatic speech recognition (ASR) systems, aiming to improve both verbatim transcriptions and automatically generated subtitles. To this end, verbatim data and subtitles are regarded as different domains or languages, due to their distinct characteristics. We propose and compare several end-to-end architectures that are designed to jointly model both modalities with separate or shared encoders and decoders. The proposed methods are able to jointly generate a verbatim transcription and a subtitle. Evaluation on Flemish (Belgian Dutch) demonstrates that a model with cascaded encoders and separate decoders allows to represent the differences between the two data types most efficiently while improving on both domains. Despite differences in domain and linguistic variations, combining verbatim transcripts with subtitle data leads to notable ASR improvements without the need for extensive preprocessing. Additionally, experiments with a large-scale subtitle dataset show the scalability of the proposed approach. The methods not only improve ASR accuracy but also generate subtitles that closely match standard written text, offering several potential applications.

Paper number 28:
Title: A Data Pilot-Aided Temporal Convolutional Network for Channel Estimation in IEEE 802.11p Vehicle-to-Vehicle Communications
Authors: Simbarashe Aldrin Ngorima, Albert Helberg, Marelie H. Davel
Abstract: In modern communication systems, having an accurate channel estimator is crucial. However, when there is mobility, it becomes difficult to estimate the channel and the pilot signals, which are used for channel estimation, become insufficient. In this paper, we introduce the use of Temporal Convolutional Networks (TCNs) with data pilot-aided (DPA) channel estimation and temporal averaging (TA) to estimate vehicle-to-vehicle same direction with Wall (VTV-SDWW) channels. The TCN-DPA-TA estimator showed an improvement in Bit Error Rate (BER) performance of up to 1 order of magnitude. Furthermore, the BER performance of the TCN-DPA without TA also improved by up to 0.7 magnitude compared to the best classical estimator.

Paper number 29:
Title: Should Audio Front-ends be Adaptive? Comparing Learnable and Adaptive Front-ends
Authors: Qiquan Zhang, Buddhi Wickramasinghe, Eliathamby Ambikairajah, Vidhyasaharan Sethu, Haizhou Li
Abstract: Hand-crafted features, such as Mel-filterbanks, have traditionally been the choice for many audio processing applications. Recently, there has been a growing interest in learnable front-ends that extract representations directly from the raw audio waveform. \textcolor{black}{However, both hand-crafted filterbanks and current learnable front-ends lead to fixed computation graphs at inference time, failing to dynamically adapt to varying acoustic environments, a key feature of human auditory systems.} To this end, we explore the question of whether audio front-ends should be adaptive by comparing the Ada-FE front-end (a recently developed adaptive front-end that employs a neural adaptive feedback controller to dynamically adjust the Q-factors of its spectral decomposition filters) to established learnable front-ends. Specifically, we systematically investigate learnable front-ends and Ada-FE across two commonly used back-end backbones and a wide range of audio benchmarks including speech, sound event, and music. The comprehensive results show that our Ada-FE outperforms advanced learnable front-ends, and more importantly, it exhibits impressive stability or robustness on test samples over various training epochs.

Paper number 30:
Title: Model Reference-Based Control with Guaranteed Predefined Performance for Uncertain Strict-Feedback Systems
Authors: Mehdi Heydari Shahna, Jukka-Pekka Humaloja, Jouni Mattila
Abstract: To address the complexities posed by time- and state-varying uncertainties and the computation of analytic derivatives in strict-feedback form (SFF) systems, this study introduces a novel model reference-based control (MRBC) framework which applies locally to each subsystem (SS), to ensure output tracking performance within the specified transient and steady-state response criteria. This framework includes 1) novel homogeneous adaptive estimators (HAEs) designed to match the uncertain nonlinear SFF system to a reference model, enabling easier analysis and control design at the $SS$ level, and 2) model-based homogeneous adaptive controllers enhanced by logarithmic barrier Lyapunov functions (HAC-BLFs), intended to control the reference model provided by HAEs in each SS, while ensuring the prescribed tracking responses under control amplitude saturation. The inherently robust MRBC achieves uniformly exponential stability using a generic stability connector term, which addresses dynamic interactions between the adjacent SSs. The parameter sensitivities of HAEs and HAC-BLFs in the MRBC framework are analyzed, focusing on the system's robustness and responsiveness. The proposed MRBC framework is experimentally validated through several scenarios involving an electromechanical linear actuator system with an uncertain SFF, subjected loading disturbance forces challenging 0-95% of its capacity.

Paper number 31:
Title: Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans
Authors: Matthias Schwab, Mathias Pamminger, Christian Kremser, Agnes Mayr
Abstract: Purpose: To develop and evaluate a deep learning-based method that allows to perform myocardial infarct segmentation in a fully-automated way. Materials and Methods: For this retrospective study, a cascaded framework of two and three-dimensional convolutional neural networks (CNNs), specialized on identifying ischemic myocardial scars on late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) images, was trained on an in-house training dataset consisting of 144 examinations. On a separate test dataset from the same institution, including images from 152 examinations obtained between 2021 and 2023, a quantitative comparison between artificial intelligence (AI)-based segmentations and manual segmentations was performed. Further, qualitative assessment of segmentation accuracy was evaluated for both human and AI-generated contours by two CMR experts in a blinded experiment. Results: Excellent agreement could be found between manually and automatically calculated infarct volumes ($\rho_c$ = 0.9). The qualitative evaluation showed that compared to human-based measurements, the experts rated the AI-based segmentations to better represent the actual extent of infarction significantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On the contrary, for segmentation of microvascular obstruction (MVO), manual measurements were still preferred (11.3% AI, 55.6% human, 33.1% equal). Conclusion: This fully-automated segmentation pipeline enables CMR infarct size to be calculated in a very short time and without requiring any pre-processing of the input images while matching the segmentation quality of trained human observers. In a blinded experiment, experts preferred automated infarct segmentations more often than manual segmentations, paving the way for a potential clinical application.

Paper number 32:
Title: Fault-Tolerant Control for System Availability and Continuous Operation in Heavy-Duty Wheeled Mobile Robots
Authors: Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila
Abstract: When the control system in a heavy-duty wheeled mobile robot (HD-WMR) malfunctions, deviations from ideal motion occur, significantly heightening the risks of off-road instability and costly damage. To meet the demands for safety, reliability, and controllability in HD-WMRs, the control system must tolerate faults to a certain extent, ensuring continuous operation. To this end, this paper introduces a model-free hierarchical control with fault accommodation (MFHCA) framework designed to address sensor and actuator faults in hydraulically powered HD-WMRs with independently controlled wheels. To begin, a novel mathematical representation of the motion dynamics of HD-WMRs, incorporating both sensor and actuator fault modes, is investigated. Subsequently, the MFHCA framework is proposed to manage all wheels under various fault modes, ensuring that each wheel tracks the reference driving velocities and steering angles, which are inverse kinematically mapped from the angular and linear velocities commanded in the HD-WMR's base frame. To do so, this framework generates appropriate power efforts in independently valve-regulated wheels to accommodate the adaptively isolated faults, thereby ensuring exponential stability. The experimental analysis of a 6,500-kg hydraulic-powered HD-WMR under various fault modes and rough terrains demonstrates the validity of the MFHCA framework.

Paper number 33:
Title: Chirp-Permuted AFDM for Quantum-Resilient Physical-Layer Secure Communications
Authors: Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu
Abstract: This article presents a novel physical-layer secure communications scheme based on the recently discovered chirp-permuted affine frequency division multiplexing (AFDM) waveform, which results in a completely different received signal to the eavesdropper with the incorrect chirp-permutation order, even under co-located eavesdropping with perfect channel information. The security of the proposed scheme is studied in terms of the complexity required to find the correct permutation via classical and quantum search algorithms, which are shown to be infeasible due the factorially-scaling search space, as well as theoretical and simulated analyses of a random-guess approach, indicating an infeasible probability of breach by chance.

Paper number 34:
Title: Single Antenna Terahertz Sensing using Preconfigured Metasurfaces
Authors: Furkan Ilgac, Aydin Sezgin
Abstract: The development of mobile terahertz (THz) sensing and localization with minimal infrastructure has garnered significant attention due to its substantial practical implications. Single-antenna radar systems are a favored choice for mobile platforms, as they offer notable advantages in terms of cost, weight, and simplicity. However, these systems face a critical limitation: the inability to extract angular information using a single antenna, which consequently prevents the achievement of complete localization. This paper proposes an angular estimation method for a single-antenna radar augmented with a pair of preconfigured metasurfaces. The metasurface pair is used for creating an interference pattern in the scene, which depends on the target angles and operating frequency. Moreover, the beam squint effects caused by the wide frequency range in the THz band provides suitable conditions for using sparse reconstruction techniques to obtain angular estimates. We utilize these properties to perform angular estimation with a single antenna. The simulation results show that with this method it is possible to perform fast and accurate multi-target estimation for a broad operating range.

Paper number 35:
Title: ScNeuGM: Scalable Neural Graph Modeling for Coloring-Based Contention and Interference Management in Wi-Fi 7
Authors: Zhouyou Gu, Jihong Park, Jinho Choi
Abstract: Carrier-sense multiple access with collision avoidance in Wi-Fi often leads to contention and interference, thereby increasing packet losses. These challenges have traditionally been modeled as a graph, with stations (STAs) represented as vertices and contention or interference as edges. Graph coloring assigns orthogonal transmission slots to STAs, managing contention and interference, e.g., using the restricted target wake time (RTWT) mechanism introduced in Wi-Fi 7 standards. However, legacy graph models lack flexibility in optimizing these assignments, often failing to minimize slot usage while maintaining reliable transmissions. To address this issue, we propose ScNeuGM, a neural graph modeling (NGM) framework that flexibly trains a neural network (NN) to construct optimal graph models whose coloring corresponds to optimal slot assignments. ScNeuGM is highly scalable to large Wi-Fi networks with massive STA pairs: 1) it utilizes an evolution strategy (ES) to directly optimize the NN parameters based on one network-wise reward signal, avoiding exhaustive edge-wise feedback estimations in all STA pairs; 2) ScNeuGM also leverages a deep hashing function (DHF) to group contending or interfering STA pairs and restricts NGM NN training and inference to pairs within these groups, significantly reducing complexity. Simulations show that the ES-trained NN in ScNeuGM returns near-optimal graphs 4-10 times more often than algorithms requiring edge-wise feedback and reduces 25\% slots than legacy graph constructions. Furthermore, the DHF in ScNeuGM reduces the training and the inference time of NGM by 4 and 8 times, respectively, and the online slot assignment time by 3 times in large networks, and up to 30\% fewer packet losses in dynamic scenarios due to the timely assignments.

Paper number 36:
Title: Optimal PMU Placement for Kalman Filtering of DAE Power System Models
Authors: Milos Katanic, Yi Guo, John Lygeros, Gabriela Hug
Abstract: Optimal sensor placement is essential for minimizing costs and ensuring accurate state estimation in power systems. This paper introduces a novel method for optimal sensor placement for dynamic state estimation of power systems modeled by differential-algebraic equations. The method identifies optimal sensor locations by minimizing the steady-state covariance matrix of the Kalman filter, thus minimizing the error of joint differential and algebraic state estimation. The problem is reformulated as a mixed-integer semidefinite program and effectively solved using off-the-shelf numerical solvers. Numerical results demonstrate the merits of the proposed approach by benchmarking its performance in phasor measurement unit placement in comparison to greedy algorithms.

Paper number 37:
Title: A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning
Authors: Simon Arberet, Florin C. Ghesu, Riqiang Gao, Martin Kraus, Jonathan Sackett, Esa Kuusela, Ali Kamen
Abstract: Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by precisely delivering radiation while sparing healthy tissues. Fluence maps generation, crucial in VMAT planning, traditionally involves complex and iterative, and thus time consuming processes. These fluence maps are subsequently leveraged for leaf-sequence. The deep-learning approach presented in this article aims to expedite this by directly predicting fluence maps from patient data. We developed a 3D network which we trained in a supervised way using a combination of L1 and L2 losses, and RT plans generated by Eclipse and from the REQUITE dataset, taking the RT dose map as input and the fluence maps computed from the corresponding RT plans as target. Our network predicts jointly the 180 fluence maps corresponding to the 180 control points (CP) of single arc VMAT plans. In order to help the network, we pre-process the input dose by computing the projections of the 3D dose map to the beam's eye view (BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We generated over 2000 VMAT plans using Eclipse to scale up the dataset size. Additionally, we evaluated various network architectures and analyzed the impact of increasing the dataset size. We are measuring the performance in the 2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D dose domain using the dose-volume histogram (DVH) on a validation dataset. The network inference, which does not include the data loading and processing, is less than 20ms. Using our proposed 3D network architecture as well as increasing the dataset size using Eclipse improved the fluence map reconstruction performance by approximately 8 dB in PSNR compared to a U-Net architecture trained on the original REQUITE dataset. The resulting DVHs are very close to the one of the input target dose.

Paper number 38:
Title: On the Conditional Phase Distribution of the TWDP Multipath Fading Process
Authors: Almir Maric, Pamela Njemcevic
Abstract: In this paper, the conditional phase distribution of the two-wave with diffuse power (TWDP) process is derived as a closed-form and as an infinite-series expression. For the obtained infinite series expression, a truncation analysis is performed and the truncated expression is used to examine the influence of different channel conditions on the behavior of the TWDP phase. All the results are verified through Monte Carlo simulations.

Paper number 39:
Title: On the Simulation and Correlation Properties of TWDP Fading Process
Authors: Almir Maric, Pamela Njemcevic
Abstract: This paper introduces a novel statistical simulator designed to model propagation in two-way diffuse power (TWDP) fading channels. The simulator employs two zero-mean stochastic sinusoids to simulate specular components, while a sum of sinusoids is used to model the diffuse one. Using the developed simulator, the autocorrelation and cross-correlation functions of the quadrature components, as well as the autocorrelation of the complex and squared envelope, are derived for the first time in literature for channels experiencing TWDP fading. The statistical properties of the proposed simulator are thoroughly validated through extensive simulations, which closely align with the theoretical results.

Paper number 40:
Title: Verification and Synthesis Methods for High-Order Control Barrier Functions
Authors: Ellie Pond, Matthew Hale
Abstract: High-order control barrier functions (HOCBFs) can be used to provide autonomous systems with safety, though computational methods to verify and synthesize these functions remain lacking. In this work, we address this need by formulating SOS programs that verify and synthesize HOCBFs, such that continued safety is always guaranteed forward in time. We first propose a verification SOS program for systems with (i) one or multiple HOCBFs, (ii) a control Lyapunov function (CLF), and (iii) input constraints, and we show that a solution to this problem guarantees that the online implementation of the system is always safe. Next, we propose a sequence of SOS programs that synthesize the class K functions used in an HOCBF, and we show that this sequence of problems ensures that a system is guaranteed to remain safe while running. After that, a synthesis framework is given that ensures real-time safety for systems with (i) multiple HOCBFs, (ii) a CLF, and (iii) input constraints. Our developments are illustrated in numerical simulations for a system with seven HOCBFs of maximum relative degree two, with 14 total unknown class K functions, all of which are successfully synthesized in a way that produces safe autonomy.

Paper number 41:
Title: Deep Reinforcement Learning-Based Optimization of Second-Life Battery Utilization in Electric Vehicles Charging Stations
Authors: Rouzbeh Haghighi, Ali Hassan, Van-Hai Bui, Akhtar Hussain, Wencong Su
Abstract: The rapid rise in electric vehicle (EV) adoption presents significant challenges in managing the vast number of retired EV batteries. Research indicates that second-life batteries (SLBs) from EVs typically retain considerable residual capacity, offering extended utility. These batteries can be effectively repurposed for use in EV charging stations (EVCS), providing a cost-effective alternative to new batteries and reducing overall planning costs. Integrating battery energy storage systems (BESS) with SLBs into EVCS is a promising strategy to alleviate system overload. However, efficient operation of EVCS with integrated BESS is hindered by uncertainties such as fluctuating EV arrival and departure times and variable power prices from the grid. This paper presents a deep reinforcement learning-based (DRL) planning framework for EV charging stations with BESS, leveraging SLBs. We employ the advanced soft actor-critic (SAC) approach, training the model on a year's worth of data to account for seasonal variations, including weekdays and holidays. A tailored reward function enables effective offline training, allowing real-time optimization of EVCS operations under uncertainty.

Paper number 42:
Title: Offshore Wind Turbine Tower Design and Optimization: A Review and AI-Driven Future Directions
Authors: João Alves Ribeiro, Bruno Alves Ribeiro, Francisco Pimenta, Sérgio M. O. Tavares, Jie Zhang, Faez Ahmed
Abstract: Offshore wind energy leverages the high intensity and consistency of oceanic winds, playing a key role in the transition to renewable energy. As energy demands grow, larger turbines are required to optimize power generation and reduce the Levelized Cost of Energy (LCoE), which represents the average cost of electricity over a project's lifetime. However, upscaling turbines introduces engineering challenges, particularly in the design of supporting structures, especially towers. These towers must support increased loads while maintaining structural integrity, cost-efficiency, and transportability, making them essential to offshore wind projects' success. This paper presents a comprehensive review of the latest advancements, challenges, and future directions driven by Artificial Intelligence (AI) in the design optimization of Offshore Wind Turbine (OWT) structures, with a focus on towers. It provides an in-depth background on key areas such as design types, load types, analysis methods, design processes, monitoring systems, Digital Twin (DT), software, standards, reference turbines, economic factors, and optimization techniques. Additionally, it includes a state-of-the-art review of optimization studies related to tower design optimization, presenting a detailed examination of turbine, software, loads, optimization method, design variables and constraints, analysis, and findings, motivating future research to refine design approaches for effective turbine upscaling and improved efficiency. Lastly, the paper explores future directions where AI can revolutionize tower design optimization, enabling the development of efficient, scalable, and sustainable structures. By addressing the upscaling challenges and supporting the growth of renewable energy, this work contributes to shaping the future of offshore wind turbine towers and others supporting structures.

Paper number 43:
Title: Backcasting the Optimal Decisions in Transport Systems: An Example with Electric Vehicle Purchase Incentives
Authors: Vinith Lakshmanan, Xavier Guichet, Antonio Sciarretta
Abstract: This study represents a first attempt to build a backcasting methodology to identify the optimal policy roadmaps in transport systems. In this methodology, desired objectives are set by decision makers at a given time horizon, and then the optimal combinations of policies to achieve these objectives are computed as a function of time (i.e., ``backcasted''). This approach is illustrated on the transportation sector by considering a specific subsystem with a single policy decision. The subsystem describes the evolution of the passenger car fleet within a given region and its impact on greenhouse gas emissions. The optimized policy is a monetary incentive for the purchase of electric vehicles while minimizing the total budget of the state and achieving a desired CO$_2$ target. A case study applied to Metropolitan France is presented to illustrate the approach. Additionally, alternative policy scenarios are also analyzed to provide further insights.

Paper number 44:
Title: Streaming Speaker Change Detection and Gender Classification for Transducer-Based Multi-Talker Speech Translation
Authors: Peidong Wang, Naoyuki Kanda, Jian Xue, Jinyu Li, Xiaofei Wang, Aswin Shanmugam Subramanian, Junkun Chen, Sunit Sivasankaran, Xiong Xiao, Yong Zhao
Abstract: Streaming multi-talker speech translation is a task that involves not only generating accurate and fluent translations with low latency but also recognizing when a speaker change occurs and what the speaker's gender is. Speaker change information can be used to create audio prompts for a zero-shot text-to-speech system, and gender can help to select speaker profiles in a conventional text-to-speech model. We propose to tackle streaming speaker change detection and gender classification by incorporating speaker embeddings into a transducer-based streaming end-to-end speech translation model. Our experiments demonstrate that the proposed methods can achieve high accuracy for both speaker change detection and gender classification.

Paper number 45:
Title: A Methodology for Process Design Kit Re-Centering Using TCAD and Experimental Data for Cryogenic Temperatures
Authors: Tapas Dutta, Fikru Adamu-Lema, Djamel Bensouiah, Asen Asenov
Abstract: In this work, we describe and demonstrate a novel Technology Computer Aided Design (TCAD) driven methodology that allows measurement data from 'non-ideal' silicon wafers to be used for re-centering a room temperature-based Process Design Kit (PDK) to cryogenic temperatures. This comprehensive approach holds promise for advancing cryogenic CMOS design in the absence of foundry supplied cryogenic PDKs.

Paper number 46:
Title: Developing multilingual speech synthesis system for Ojibwe, Mi'kmaq, and Maliseet
Authors: Shenran Wang, Changbing Yang, Mike Parkhill, Chad Quinn, Christopher Hammerly, Jian Zhu
Abstract: We present lightweight flow matching multilingual text-to-speech (TTS) systems for Ojibwe, Mi'kmaq, and Maliseet, three Indigenous languages in North America. Our results show that training a multilingual TTS model on three typologically similar languages can improve the performance over monolingual models, especially when data are scarce. Attention-free architectures are highly competitive with self-attention architecture with higher memory efficiency. Our research not only advances technical development for the revitalization of low-resource languages but also highlights the cultural gap in human evaluation protocols, calling for a more community-centered approach to human evaluation.

Paper number 47:
Title: When are Diffusion Priors Helpful in Sparse Reconstruction? A Study with Sparse-view CT
Authors: Matt Y. Cheung, Sophia Zorek, Tucker J. Netherton, Laurence E. Court, Sadeer Al-Kindi, Ashok Veeraraghavan, Guha Balakrishnan
Abstract: Diffusion models demonstrate state-of-the-art performance on image generation, and are gaining traction for sparse medical image reconstruction tasks. However, compared to classical reconstruction algorithms relying on simple analytical priors, diffusion models have the dangerous property of producing realistic looking results \emph{even when incorrect}, particularly with few observations. We investigate the utility of diffusion models as priors for image reconstruction by varying the number of observations and comparing their performance to classical priors (sparse and Tikhonov regularization) using pixel-based, structural, and downstream metrics. We make comparisons on low-dose chest wall computed tomography (CT) for fat mass quantification. First, we find that classical priors are superior to diffusion priors when the number of projections is ``sufficient''. Second, we find that diffusion priors can capture a large amount of detail with very few observations, significantly outperforming classical priors. However, they fall short of capturing all details, even with many observations. Finally, we find that the performance of diffusion priors plateau after extremely few ($\approx$10-15) projections. Ultimately, our work highlights potential issues with diffusion-based sparse reconstruction and underscores the importance of further investigation, particularly in high-stakes clinical settings.

Paper number 48:
Title: Covert Communications in Active-IOS Aided Uplink NOMA Systems With Full-Duplex Receiver
Authors: Xueyu Kang, Nan Qi, Lu Lv, Alexandros-Apostolos A. Boulogeorgos, Theodoros A. Tsiftsis, Hongwu Liu
Abstract: In this paper, an active intelligent omni-surface (A-IOS) is deployed to aid uplink transmissions in a non-orthogonal multiple access (NOMA) system. In order to shelter the covert signal embedded in the superposition transmissions, a multi-antenna full-duplex (FD) receiver is utilized at the base-station to recover signal in addition to jamming the warden. With the aim of maximizing the covert rate, the FD transmit and receive beamforming, A-IOS refraction and reflection beamforming, NOMA transmit power, and FD jamming power are jointly optimized. To tackle the non-convex covert rate maximization problem subject to the highly coupled system parameters, an alternating optimization algorithm is designed to iteratively solve the decoupled sub-problems of optimizing the system parameters. The optimal solutions for the sub-problems of the NOMA transmit power and FD jamming power optimizations are derived in closed-form. To tackle the rank-one constrained non-convex fractional programming of the A-IOS beamforming and FD beamforming, a penalized Dinkelbach transformation approach is proposed to resort to the optimal solutions via semidefinite programming. Numerical results clarify that the deployment of the A-IOS significantly improves the covert rate compared with the passive-IOS aided uplink NOMA system. It is also found that the proposed scheme provides better covert communication performance with the optimized NOMA transmit power and FD jamming power compared with the benchmark schemes.

Paper number 49:
Title: From DeepSense to Open RAN: AI/ML Advancements in Dynamic Spectrum Sensing and Their Applications
Authors: Ryan Barker
Abstract: The integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communication systems has become a cornerstone for advancing intelligent, adaptive, and scalable networks. This reading report examines key innovations in dynamic spectrum sensing (DSS), beginning with the foundational DeepSense framework, which uses convolutional neural networks (CNNs) and spectrogram-based analysis for real-time wideband spectrum monitoring. Building on this groundwork, it highlights advancements such as DeepSweep and Wideband Signal Stitching, which address the challenges of scalability, latency, and dataset diversity through parallel processing, semantic segmentation, and robust data augmentation strategies. The report then explores Open Radio Access Networks (ORAN), focusing on AI/ML-driven enhancements for UAV experimentation, digital twin-based optimization, network slicing, and self-healing xApp development. By bridging AI-based DSS methodologies with ORAN's open, vendor-neutral architecture, these studies underscore the potential of software-defined, intelligent infrastructures in enabling efficient, resilient, and self-optimizing networks for 5G/6G ecosystems. Through this synthesis, the report highlights AI's transformative role in shaping the future of wireless communication and autonomous systems.

Paper number 50:
Title: AudioMiXR: Spatial Audio Object Manipulation with 6DoF for Sound Design in Augmented Reality
Authors: Brandon Woodard, Margarita Geleta, Joseph J. LaViola Jr., Andrea Fanelli, Rhonda Wilson
Abstract: We present AudioMiXR, an augmented reality (AR) interface intended to assess how users manipulate virtual audio objects situated in their physical space using six degrees of freedom (6DoF) deployed on a head-mounted display (Apple Vision Pro) for 3D sound design. Existing tools for 3D sound design are typically constrained to desktop displays, which may limit spatial awareness of mixing within the execution environment. Utilizing an XR HMD to create soundscapes may provide a real-time test environment for 3D sound design, as modern HMDs can provide precise spatial localization assisted by cross-modal interactions. However, there is no research on design guidelines specific to sound design with six degrees of freedom (6DoF) in XR. To provide a first step toward identifying design-related research directions in this space, we conducted an exploratory study where we recruited 27 participants, consisting of expert and non-expert sound designers. The goal was to assess design lessons that can be used to inform future research venues in 3D sound design. We ran a within-subjects study where users designed both a music and cinematic soundscapes. After thematically analyzing participant data, we constructed two design lessons: 1. Proprioception for AR Sound Design, and 2. Balancing Audio-Visual Modalities in AR GUIs. Additionally, we provide application domains that can benefit most from 6DoF sound design based on our results.

Paper number 51:
Title: Dominance Regions of Pursuit-evasion Games in Non-anticipative Information Patterns
Authors: Weiwen Huang, Li Liang, Ningsheng Xu, Fang Deng
Abstract: The evader's dominance region is an important concept and the foundation of geometric methods for pursuit-evasion games. This article mainly reveals the relevant properties of the evader's dominance region, especially in non-anticipative information patterns. We can use these properties to research pursuit-evasion games in non-anticipative information patterns. The core problem is under what condition the pursuer has a non-anticipative strategy to prevent the evader leaving its initial dominance region before being captured regardless of the evader's strategy. We first define the evader's dominance region by the shortest path distance, and we rigorously prove for the first time that the initial dominance region of the evader is the reachable region of the evader in the open-loop sense. Subsequently, we prove that there exists a non-anticipative strategy by which the pursuer can capture the evader before the evader leaves its initial dominance region's closure in the absence of obstacles. For cases with obstacles, we provide a counter example to illustrate that such a non-anticipative strategy does not always exist, and provide a necessary condition for the existence of such strategy. Finally, we consider a scenario with a single corner obstacle and provide a sufficient condition for the existence of such a non-anticipative strategy. At the end of this article, we discuss the application of the evader's dominance region in target defense games. This article has important reference significance for the design of non-anticipative strategies in pursuit-evasion games with obstacles.

Paper number 52:
Title: Gait-Net-augmented Implicit Kino-dynamic MPC for Dynamic Variable-frequency Humanoid Locomotion over Discrete Terrains
Authors: Junheng Li, Ziwei Duan, Junchao Ma, Quan Nguyen
Abstract: Current optimization-based control techniques for humanoid locomotion struggle to adapt step duration and placement simultaneously in dynamic walking gaits due to their reliance on fixed-time discretization, which limits responsiveness to terrain conditions and results in suboptimal performance in challenging environments. In this work, we propose a Gait-Net-augmented implicit kino-dynamic model-predictive control (MPC) to simultaneously optimize step location, step duration, and contact forces for natural variable-frequency locomotion. The proposed method incorporates a Gait-Net-augmented Sequential Convex MPC algorithm to solve multi-linearly constrained variables by iterative quadratic programs. At its core, a lightweight Gait-frequency Network (Gait-Net) determines the preferred step duration in terms of variable MPC sampling times, simplifying step duration optimization to the parameter level. Additionally, it enhances and updates the spatial reference trajectory within each sequential iteration by incorporating local solutions, allowing the projection of kinematic constraints to the design of reference trajectories. We validate the proposed algorithm in high-fidelity simulations and on small-size humanoid hardware, demonstrating its capability for variable-frequency and 3-D discrete terrain locomotion with only a one-step preview of terrain data.

Paper number 53:
Title: Demonstrating a Control Framework for Physical Human-Robot Interaction Toward Industrial Applications
Authors: Bastien Muraccioli (CNRS-AIST JRL), Celerier Mathieu (CNRS-AIST JRL), Benallegue Mehdi (CNRS-AIST JRL), Venture Gentiane (CNRS-AIST JRL, UTokyo)
Abstract: Human-Robot Interaction (pHRI) is critical for implementing Industry 5.0 which focuses on human-centric approaches. However, few studies explore the practical alignment of pHRI to industrial grade performance. This paper introduces a versatile control framework designed to bridge this gap by incorporating the torque-based control modes: compliance control, null-space compliance, dual compliance, all in static and dynamic scenarios. Thanks to our second-order Quadratic Programming (QP) formulation, strict kinematic and collision constraints are integrated into the system as safety features, and a weighted hierarchy guarantees singularity-robust task tracking performance. The framework is implemented on a Kinova Gen3 collaborative robot (cobot) equipped with a Bota force/torque sensor. A DualShock 4 game controller is attached at the robot's end-effector to demonstrate the framework's capabilities. This setup enables seamless dynamic switching between the modes, and real-time adjustment of parameters, such as transitioning between position and torque control or selecting a more robust custom-developed low-level torque controller over the default this http URL on the open-source robotic control software mc_rtc, to ensure reproducibility for both research and industrial deployment, this framework demonstrates industrial-grade performance and repeatability, showcasing its potential as a robust pHRI control system for industrial environments.

Paper number 54:
Title: Learning Efficient Flocking Control based on Gibbs Random Fields
Authors: Dengyu Zhang, Chenghao, Feng Xue, Qingrui Zhang
Abstract: Flocking control is essential for multi-robot systems in diverse applications, yet achieving efficient flocking in congested environments poses challenges regarding computation burdens, performance optimality, and motion safety. This paper addresses these challenges through a multi-agent reinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs). With GRFs, a multi-robot system is represented by a set of random variables conforming to a joint probability distribution, thus offering a fresh perspective on flocking reward design. A decentralized training and execution mechanism, which enhances the scalability of MARL concerning robot quantity, is realized using a GRF-based credit assignment method. An action attention module is introduced to implicitly anticipate the motion intentions of neighboring robots, consequently mitigating potential non-stationarity issues in MARL. The proposed framework enables learning an efficient distributed control policy for multi-robot systems in challenging environments with success rate around $99\%$, as demonstrated through thorough comparisons with state-of-the-art solutions in simulations and experiments. Ablation studies are also performed to validate the efficiency of different framework modules.

Paper number 55:
Title: Comparison of 2D Regular Lattices for the CPWL Approximation of Functions
Authors: Mehrsa Pourya, Maïka Nogarotto, Michael Unser
Abstract: We investigate the approximation error of functions with continuous and piecewise-linear (CPWL) representations. We focus on the CPWL search spaces generated by translates of box splines on two-dimensional regular lattices. We compute the approximation error in terms of the stepsize and angles that define the lattice. Our results show that hexagonal lattices are optimal, in the sense that they minimize the asymptotic approximation error.

Paper number 56:
Title: Meta-Learning-Based People Counting and Localization Models Employing CSI from Commodity WiFi NICs
Authors: Jihoon Cha, Hwanjin Kim, Junil Choi
Abstract: In this paper, we consider people counting and localization systems exploiting channel state information (CSI) measured from commodity WiFi network interface cards (NICs). While CSI has useful information of amplitude and phase to describe signal propagation in a measurement environment of interest, CSI measurement suffers from offsets due to various uncertainties. Moreover, an uncontrollable external environment where other WiFi devices communicate each other induces interfering signals, resulting in erroneous CSI captured at a receiver. In this paper, preprocessing of CSI is first proposed for offset removal, and it guarantees low-latency operation without any filtering process. Afterwards, we design people counting and localization models based on pre-training. To be adaptive to different measurement environments, meta-learning-based people counting and localization models are also proposed. Numerical results show that the proposed meta-learning-based people counting and localization models can achieve high sensing accuracy, compared to other learning schemes that follow simple training and test procedures.

Paper number 57:
Title: Tell2Reg: Establishing spatial correspondence between images by the same language prompts
Authors: Wen Yan, Qianye Yang, Shiqi Huang, Yipei Wang, Shonit Punwani, Mark Emberton, Vasilis Stavrinides, Yipeng Hu, Dean Barratt
Abstract: Spatial correspondence can be represented by pairs of segmented regions, such that the image registration networks aim to segment corresponding regions rather than predicting displacement fields or transformation parameters. In this work, we show that such a corresponding region pair can be predicted by the same language prompt on two different images using the pre-trained large multimodal models based on GroundingDINO and SAM. This enables a fully automated and training-free registration algorithm, potentially generalisable to a wide range of image registration tasks. In this paper, we present experimental results using one of the challenging tasks, registering inter-subject prostate MR images, which involves both highly variable intensity and morphology between patients. Tell2Reg is training-free, eliminating the need for costly and time-consuming data curation and labelling that was previously required for this registration task. This approach outperforms unsupervised learning-based registration methods tested, and has a performance comparable to weakly-supervised methods. Additional qualitative results are also presented to suggest that, for the first time, there is a potential correlation between language semantics and spatial correspondence, including the spatial invariance in language-prompted regions and the difference in language prompts between the obtained local and global correspondences. Code is available at this https URL.

Paper number 58:
Title: Metis: A Foundation Speech Generation Model with Masked Generative Pre-training
Authors: Yuancheng Wang, Jiachen Zheng, Junan Zhang, Xueyao Zhang, Huan Liao, Zhizheng Wu
Abstract: We introduce Metis, a foundation model for unified speech generation. Unlike previous task-specific or multi-task models, Metis follows a pre-training and fine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data using masked generative modeling and then fine-tuned to adapt to diverse speech generation tasks. Specifically, 1) Metis utilizes two discrete speech representations: SSL tokens derived from speech self-supervised learning (SSL) features, and acoustic tokens directly quantized from waveforms. 2) Metis performs masked generative pre-training on SSL tokens, utilizing 300K hours of diverse speech data, without any additional condition. 3) Through fine-tuning with task-specific conditions, Metis achieves efficient adaptation to various speech generation tasks while supporting multimodal input, even when using limited data and trainable parameters. Experiments demonstrate that Metis can serve as a foundation model for unified speech generation: Metis outperforms state-of-the-art task-specific or multi-task systems across five speech generation tasks, including zero-shot text-to-speech, voice conversion, target speaker extraction, speech enhancement, and lip-to-speech, even with fewer than 20M trainable parameters or 300 times less training data. Audio samples are are available at this https URL.

Paper number 59:
Title: SPARK: A Modular Benchmark for Humanoid Robot Safety
Authors: Yifan Sun, Rui Chen, Kai S. Yun, Yikuan Fang, Sebin Jung, Feihan Li, Bowei Li, Weiye Zhao, Changliu Liu
Abstract: This paper introduces the Safe Protective and Assistive Robot Kit (SPARK), a comprehensive benchmark designed to ensure safety in humanoid autonomy and teleoperation. Humanoid robots pose significant safety risks due to their physical capabilities of interacting with complex environments. The physical structures of humanoid robots further add complexity to the design of general safety solutions. To facilitate the safe deployment of complex robot systems, SPARK can be used as a toolbox that comes with state-of-the-art safe control algorithms in a modular and composable robot control framework. Users can easily configure safety criteria and sensitivity levels to optimize the balance between safety and performance. To accelerate humanoid safety research and development, SPARK provides a simulation benchmark that compares safety approaches in a variety of environments, tasks, and robot models. Furthermore, SPARK allows quick deployment of synthesized safe controllers on real robots. For hardware deployment, SPARK supports Apple Vision Pro (AVP) or a Motion Capture System as external sensors, while also offering interfaces for seamless integration with alternative hardware setups. This paper demonstrates SPARK's capability with both simulation experiments and case studies with a Unitree G1 humanoid robot. Leveraging these advantages of SPARK, users and researchers can significantly improve the safety of their humanoid systems as well as accelerate relevant research. The open-source code is available at this https URL.

Paper number 60:
Title: Low-Complexity Cram\'er-Rao Lower Bound and Sum Rate Optimization in ISAC Systems
Authors: Tianyu Fang, Nhan Thanh Nguyen, Markku Juntti
Abstract: While Cramér-Rao lower bound is an important metric in sensing functions in integrated sensing and communications (ISAC) designs, its optimization usually involves a computationally expensive solution such as semidefinite relaxation. In this paper, we aim to develop a low-complexity yet efficient algorithm for CRLB optimization. We focus on a beamforming design that maximizes the weighted sum between the communications sum rate and the sensing CRLB, subject to a transmit power constraint. Given the non-convexity of this problem, we propose a novel method that combines successive convex approximation (SCA) with a shifted generalized power iteration (SGPI) approach, termed SCA-SGPI. The SCA technique is utilized to approximate the non-convex objective function with convex surrogates, while the SGPI efficiently solves the resulting quadratic subproblems. Simulation results demonstrate that the proposed SCA-SGPI algorithm not only achieves superior tradeoff performance compared to existing method but also significantly reduces computational time, making it a promising solution for practical ISAC applications.

Paper number 61:
Title: Calibrated Unsupervised Anomaly Detection in Multivariate Time-series using Reinforcement Learning
Authors: Saba Sanami, Amir G. Aghdam
Abstract: This paper investigates unsupervised anomaly detection in multivariate time-series data using reinforcement learning (RL) in the latent space of an autoencoder. A significant challenge is the limited availability of anomalous data, often leading to misclassifying anomalies as normal events, thus raising false negatives. RL can help overcome this limitation by promoting exploration and balancing exploitation during training, effectively preventing overfitting. Wavelet analysis is also utilized to enhance anomaly detection, enabling time-series data decomposition into both time and frequency domains. This approach captures anomalies at multiple resolutions, with wavelet coefficients extracted to detect both sudden and subtle shifts in the data, thereby refining the anomaly detection process. We calibrate the decision boundary by generating synthetic anomalies and embedding a supervised framework within the model. This supervised element aids the unsupervised learning process by fine-tuning the decision boundary and increasing the model's capacity to distinguish between normal and anomalous patterns effectively.

Paper number 62:
Title: Deep Learning-based Event Data Coding: A Joint Spatiotemporal and Polarity Solution
Authors: Abdelrahman Seleem (1, 2, 3), André F. R. Guarda (2), Nuno M. M. Rodrigues (2, 4), Fernando Pereira (1, 2) ((1) Instituto Superior Técnico - Universidade de Lisboa, Lisbon, Portugal, (2) Instituto de Telecomunicações, Portugal, (3) Faculty of Computers and Information, South Valley University, Qena, Egypt, (4) ESTG, Politécnico de Leiria, Leiria, Portugal)
Abstract: Neuromorphic vision sensors, commonly referred to as event cameras, have recently gained relevance for applications requiring high-speed, high dynamic range and low-latency data acquisition. Unlike traditional frame-based cameras that capture 2D images, event cameras generate a massive number of pixel-level events, composed by spatiotemporal and polarity information, with very high temporal resolution, thus demanding highly efficient coding solutions. Existing solutions focus on lossless coding of event data, assuming that no distortion is acceptable for the target use cases, mostly including computer vision tasks. One promising coding approach exploits the similarity between event data and point clouds, thus allowing to use current point cloud coding solutions to code event data, typically adopting a two-point clouds representation, one for each event polarity. This paper proposes a novel lossy Deep Learning-based Joint Event data Coding (DL-JEC) solution adopting a single-point cloud representation, thus enabling to exploit the correlation between the spatiotemporal and polarity event information. DL-JEC can achieve significant compression performance gains when compared with relevant conventional and DL-based state-of-the-art event data coding solutions. Moreover, it is shown that it is possible to use lossy event data coding with its reduced rate regarding lossless coding without compromising the target computer vision task performance, notably for event classification. The use of novel adaptive voxel binarization strategies, adapted to the target task, further enables DL-JEC to reach a superior performance.

Paper number 63:
Title: MAP Image Recovery with Guarantees using Locally Convex Multi-Scale Energy (LC-MUSE) Model
Authors: Jyothi Rikhab Chand, Mathews Jacob
Abstract: We propose a multi-scale deep energy model that is strongly convex in the local neighbourhood around the data manifold to represent its probability density, with application in inverse problems. In particular, we represent the negative log-prior as a multi-scale energy model parameterized by a Convolutional Neural Network (CNN). We restrict the gradient of the CNN to be locally monotone, which constrains the model as a Locally Convex Multi-Scale Energy (LC-MuSE). We use the learned energy model in image-based inverse problems, where the formulation offers several desirable properties: i) uniqueness of the solution, ii) convergence guarantees to a minimum of the inverse problem, and iii) robustness to input perturbations. In the context of parallel Magnetic Resonance (MR) image reconstruction, we show that the proposed method performs better than the state-of-the-art convex regularizers, while the performance is comparable to plug-and-play regularizers and end-to-end trained methods.

Paper number 64:
Title: High-Fidelity Simultaneous Speech-To-Speech Translation
Authors: Tom Labiausse, Laurent Mazaré, Edouard Grave, Patrick Pérez, Alexandre Défossez, Neil Zeghidour
Abstract: We introduce Hibiki, a decoder-only model for simultaneous speech translation. Hibiki leverages a multistream language model to synchronously process source and target speech, and jointly produces text and audio tokens to perform speech-to-text and speech-to-speech translation. We furthermore address the fundamental challenge of simultaneous interpretation, which unlike its consecutive counterpart, where one waits for the end of the source utterance to start translating, adapts its flow to accumulate just enough context to produce a correct translation in real-time, chunk by chunk. To do so, we introduce a weakly-supervised method that leverages the perplexity of an off-the-shelf text translation system to identify optimal delays on a per-word basis and create aligned synthetic data. After supervised training, Hibiki performs adaptive, simultaneous speech translation with vanilla temperature sampling. On a French-English simultaneous speech translation task, Hibiki demonstrates state-of-the-art performance in translation quality, speaker fidelity and naturalness. Moreover, the simplicity of its inference process makes it compatible with batched translation and even real-time on-device deployment. We provide examples as well as models and inference code.

Paper number 65:
Title: Performance Analysis of 5G FR2 (mmWave) Downlink 256QAM on Commercial 5G Networks
Authors: Kasidis Arunruangsirilert, Pasapong Wongprasert, Jiro Katto
Abstract: The 5G New Radio (NR) standard introduces new frequency bands allocated in Frequency Range 2 (FR2) to support enhanced Mobile Broadband (eMBB) in congested environments and enables new use cases such as Ultra-Reliable Low Latency Communication (URLLC). The 3GPP introduced 256QAM support for FR2 frequency bands to further enhance downlink capacity. However, sustaining 256QAM on FR2 in practical environments is challenging due to strong path loss and susceptibility to distortion. While 256QAM can improve theoretical throughput by 33%, compared to 64QAM, and is widely adopted in FR1, its real-world impact when utilized in FR2 is questionable, given the significant path loss and distortions experienced in the FR2 range. Additionally, using higher modulation correlates to higher BLER, increased instability, and retransmission. Moreover, 256QAM also utilizes a different MCS table defining the modulation and code rate at different Channel Quality Indexes (CQI), affecting the UE's link adaptation behavior. This paper investigates the real-world performance of 256QAM utilization on FR2 bands in two countries, across three RAN manufacturers, and in both NSA (EN-DC) and SA (NR-DC) configurations, under various scenarios, including open-air plazas, city centers, footbridges, train station platforms, and stationary environments. The results show that 256QAM provides a reasonable throughput gain when stationary but marginal improvements when there is UE mobility while increasing the probability of NACK responses, increasing BLER, and the number of retransmissions. Finally, MATLAB simulations are run to validate the findings as well as explore the effect of the recently introduced 1024QAM on FR2.

Paper number 66:
Title: A Temporal Convolutional Network-Based Approach and a Benchmark Dataset for Colonoscopy Video Temporal Segmentation
Authors: Carlo Biffi, Giorgio Roffo, Pietro Salvagnini, Andrea Cherubini
Abstract: Following recent advancements in computer-aided detection and diagnosis systems for colonoscopy, the automated reporting of colonoscopy procedures is set to further revolutionize clinical practice. A crucial yet underexplored aspect in the development of these systems is the creation of computer vision models capable of autonomously segmenting full-procedure colonoscopy videos into anatomical sections and procedural phases. In this work, we aim to create the first open-access dataset for this task and propose a state-of-the-art approach, benchmarked against competitive models. We annotated the publicly available REAL-Colon dataset, consisting of 2.7 million frames from 60 complete colonoscopy videos, with frame-level labels for anatomical locations and colonoscopy phases across nine categories. We then present ColonTCN, a learning-based architecture that employs custom temporal convolutional blocks designed to efficiently capture long temporal dependencies for the temporal segmentation of colonoscopy videos. We also propose a dual k-fold cross-validation evaluation protocol for this benchmark, which includes model assessment on unseen, multi-center this http URL achieves state-of-the-art performance in classification accuracy while maintaining a low parameter count when evaluated using the two proposed k-fold cross-validation settings, outperforming competitive models. We report ablation studies to provide insights into the challenges of this task and highlight the benefits of the custom temporal convolutional blocks, which enhance learning and improve model efficiency. We believe that the proposed open-access benchmark and the ColonTCN approach represent a significant advancement in the temporal segmentation of colonoscopy procedures, fostering further open-access research to address this clinical need.

Paper number 67:
Title: Practical X-ray Gastric Cancer Diagnostic Support Using Refined Stochastic Data Augmentation and Hard Boundary Box Training
Authors: Hideaki Okamoto, Quan Huu Cap, Takakiyo Nomura, Kazuhito Nabeshima, Jun Hashimoto, Hitoshi Iyatomi
Abstract: Endoscopy is widely used to diagnose gastric cancer and has a high diagnostic performance, but it must be performed by a physician, which limits the number of people who can be diagnosed. In contrast, gastric X-rays can be taken by radiographers, thus allowing a much larger number of patients to undergo imaging. However, the diagnosis of X-ray images relies heavily on the expertise and experience of physicians, and few machine learning methods have been developed to assist in this process. We propose a novel and practical gastric cancer diagnostic support system for gastric X-ray images that will enable more people to be screened. The system is based on a general deep learning-based object detection model and incorporates two novel techniques: refined probabilistic stomach image augmentation (R-sGAIA) and hard boundary box training (HBBT). R-sGAIA enhances the probabilistic gastric fold region and provides more learning patterns for cancer detection models. HBBT is an efficient training method that improves model performance by allowing the use of unannotated negative (i.e., healthy control) samples, which are typically unusable in conventional detection models. The proposed system achieved a sensitivity (SE) for gastric cancer of 90.2\%, higher than that of an expert (85.5%). Under these conditions, two out of five candidate boxes identified by the system were cancerous (precision = 42.5%), with an image processing speed of 0.51 seconds per image. The system also outperformed methods using the same object detection model and state-of-the-art data augmentation by showing a 5.9-point improvement in the F1 score. In summary, this system efficiently identifies areas for radiologists to examine within a practical time frame, thus significantly reducing their workload.

Paper number 68:
Title: Predicting Global HRTFs From Scanned Head Geometry Using Deep Learning and Compact Representations
Authors: Yuxiang Wang, You Zhang, Zhiyao Duan, Mark Bocko
Abstract: In the growing field of virtual auditory display, personalized head-related transfer functions (HRTFs) play a vital role in establishing an accurate sound image for mixed and augmented reality applications. In this work, we propose an HRTF personalization method employing convolutional neural networks (CNN) to predict a subject HRTFs for all directions from their scanned head geometry. To ease the training of the CNN models, we propose novel pre-processing methods for both the head scans and HRTF data to achieve compact representations. For the head scan, we use truncated spherical cap harmonic (SCH) coefficients to represent the pinna area, which is important in the acoustic scattering process. For the HRTF data, we use truncated spherical harmonic (SH) coefficients to represent the HRTF magnitudes and onsets. One CNN model is trained to predict the SH coefficients of the HRTF magnitudes from the SCH coefficients of the scanned ear geometry and other anthropometric measurements of the head. The other CNN model is trained to predict SH coefficients of the HRTF onsets from only the anthropometric measurements of the ear, head, and torso. Combining the magnitude and onset predictions, our method is able to predict the complete and global HRTF data. A leave-one-out validation with the log-spectral distortion (LSD) metric is used for objective evaluation. The results show a decent LSD level at both spatial \& temporal dimensions compared to the ground-truth HRTFs and a lower LSD than the boundary element method (BEM) simulation of HRTFs that the database provides. The localization simulation results with an auditory model are also consistent with the objective evaluation metrics, showing the localization responses with our predicted HRTFs are significantly better than with the BEM-calculated ones.

Paper number 69:
Title: GeXSe (Generative Explanatory Sensor System): An Interpretable Deep Generative Model for Human Activity Recognition in Smart Spaces
Authors: Sun Yuan, Salami Pargoo Navid, Ortiz Jorge
Abstract: We introduce GeXSe (Generative Explanatory Sensor System), a novel framework designed to extract interpretable sensor-based and vision domain features from non-invasive smart space sensors. We combine these to provide a comprehensive explanation of sensor-activation patterns in activity recognition tasks. This system leverages advanced machine learning architectures, including transformer blocks, Fast Fourier Convolution (FFC), and diffusion models, to provide a more detailed understanding of sensor-based human activity data. A standout feature of GeXSe is our unique Multi-Layer Perceptron (MLP) with linear, ReLU, and normalization layers, specially devised for optimal performance on small datasets. It also yields meaningful activation maps to explain sensor-based activation patterns. The standard approach is based on a CNN model, which our MLP model this http URL offers two types of explanations: sensor-based activation maps and visual domain explanations using short videos. These methods offer a comprehensive interpretation of the output from non-interpretable sensor data, thereby augmenting the interpretability of our model. Utilizing the Frechet Inception Distance (FID) for evaluation, it outperforms established methods, improving baseline performance by about 6\%. GeXSe also achieves a high F1 score of up to 0.85, demonstrating precision, recall, and noise resistance, marking significant progress in reliable and explainable smart space sensing systems.

Paper number 70:
Title: User Equipment Assisted Localization for 6G Integrated Sensing and Communication
Authors: Xianzhen Guo, Qin Shi, Shuowen Zhang, Chengwen Xing, Liang Liu
Abstract: This paper investigates user equipment (UE) assisted device-free networked sensing in the sixth-generation (6G) integrated sensing and communication (ISAC) system, where one base station (BS) and multiple UEs, such as unmanned aerial vehicles (UAVs), serve as anchors to cooperatively localize multiple passive targets based on the range information. Three challenges arise from the above scheme. First, the UEs are not perfectly synchronized with the BSs. Second, the UE (anchor) positions are usually estimated by the Global Positioning System (GPS) and subject to unknown errors. Third, data association is challenging, since it is hard for each anchor to associate each rang estimation to the right target under device-free sensing. We first tackle the above three challenges under a passive UE based sensing mode, where UEs only passively hear the signals over the BS-target-UE paths. A two-phase UE assisted localization protocol is proposed. In Phase I, we design an efficient method to accurately estimate the ranges from the BS to the targets and those from the BS to the targets to the UEs in the presence of synchronization errors between the BS and the UEs. In Phase II, an efficient algorithm is proposed to localize the targets via jointly removing the UEs with quite inaccurate position information from the anchor set and matching the estimated ranges at the BS and the remaining UEs with the targets. Next, we also consider an active UE based sensing mode, where the UEs can actively emit signals to obtain additional range information from them to the targets. We show that this additional range information can be utilized to significantly reduce the complexity of Phase II in the aforementioned two-phase localization protocol. Numerical results show that our proposed UE assisted networked sensing scheme can achieve very high localization accuracy.

Paper number 71:
Title: One Model to Rule them All: Towards Universal Segmentation for Medical Images with Text Prompts
Authors: Ziheng Zhao, Yao Zhang, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie
Abstract: In this study, we aim to build up a model that can Segment Anything in radiology scans, driven by medical terminologies as Text prompts, termed as SAT. Our main contributions are three folds: (i) for dataset construction, we construct the first multi-modal knowledge tree on human anatomy, including 6502 anatomical terminologies; Then, we build up the largest and most comprehensive segmentation dataset for training, by collecting over 22K 3D medical image scans from72 segmentation datasets, across 497 classes, with careful standardization on both image scans and label space; (ii) for architecture design, we propose to inject medical knowledge into a text encoder via contrastive learning, and then formulate a universal segmentation model, that can be prompted by feeding in medical terminologies in text form; (iii) As a result, we have trained SAT-Nano (110M parameters) and SAT-Pro (447M parameters), demonstrating superior or comparable performance to 72 specialist models, i.e., nnU-Nets, U-Mamba or SwinUNETR, trained on each dataset/subsets. We validate SAT as a foundational segmentation model, with better generalization on external (cross-center) datasets, and can be further improved on specific tasks after fine-tuning adaptation. Comparing with state-of-the-art interactive segmentation model MedSAM, SAT demonstrate superior performance, scalability and robustness. We further compare SAT with BiomedParse, and observe SAT is significantly superior in both internal and external evaluation. Through extensive ablation study, we validate the benefit of domain knowledge on universal segmentation, especially on tail categories. As a use case, we demonstrate that SAT can act as a powerful out-of-the-box agent for large language models, enabling visual grounding in versatile application scenarios. All the data, codes, and models in this work have been released.

Paper number 72:
Title: SSAMBA: Self-Supervised Audio Representation Learning with Mamba State Space Model
Authors: Siavash Shams, Sukru Samet Dindar, Xilin Jiang, Nima Mesgarani
Abstract: Transformers have revolutionized deep learning across various tasks, including audio representation learning, due to their powerful modeling capabilities. However, they often suffer from quadratic complexity in both GPU memory usage and computational inference time, affecting their efficiency. Recently, state space models (SSMs) like Mamba have emerged as a promising alternative, offering a more efficient approach by avoiding these complexities. Given these advantages, we explore the potential of SSM-based models in audio tasks. In this paper, we introduce Self-Supervised Audio Mamba (SSAMBA), the first self-supervised, attention-free, and SSM-based model for audio representation learning. SSAMBA leverages the bidirectional Mamba to capture complex audio patterns effectively. We incorporate a self-supervised pretraining framework that optimizes both discriminative and generative objectives, enabling the model to learn robust audio representations from large-scale, unlabeled datasets. We evaluated SSAMBA on various tasks such as audio classification, keyword spotting, and speaker identification. Our results demonstrate that SSAMBA outperforms the Self-Supervised Audio Spectrogram Transformer (SSAST) in most tasks. Notably, SSAMBA is approximately 92.7% faster in batch inference speed and 95.4% more memory-efficient than SSAST for the tiny model size with an input token size of 22k. These efficiency gains, combined with superior performance, underscore the effectiveness of SSAMBA's architectural innovation, making it a compelling choice for a wide range of audio processing applications.

Paper number 73:
Title: Capacity Credit Evaluation of Generalized Energy Storage Considering Strategic Capacity Withholding and Decision-Dependent Uncertainty
Authors: Ning Qi, Pierre Pinson, Mads R. Almassalkhi, Yingrui Zhuang, Yifan Su, Feng Liu
Abstract: This paper proposes a novel capacity credit evaluation framework to accurately quantify the contribution of generalized energy storage (GES) to resource adequacy, considering both strategic capacity withholding and decision-dependent uncertainty (DDU). To this end, we establish a market-oriented risk-averse coordinated dispatch method to capture the cross-market reliable operation of GES. The proposed method is sequentially implemented along with the Monte Carlo simulation process, coordinating the pre-dispatched price arbitrage and capacity withholding in the energy market with adequacy-oriented re-dispatch during capacity market calls. In addition to decision-independent uncertainties in operational states and baseline behavior, we explicitly address the inherent DDU of GES (i.e., the uncertainty of available discharge capacity affected by the incentives and accumulated discomfort) during the re-dispatch stage using the proposed distributional robust chance-constrained approach. Furthermore, a capacity credit metric called equivalent storage capacity substitution is introduced to quantify the equivalent deterministic storage capacity of uncertain GES. Simulations on the modified IEEE RTS-79 benchmark system with 20 years real-world data from Elia demonstrate that the proposed method yields accurate capacity credit and improved economic performance. We show that the capacity credit of GES increases with more strategic capacity withholding but decreases with more DDU levels. Key factors, such as capacity withholding and DDU structure impacting GES's capacity credit are analyzed with insights into capacity market decision-making.

Paper number 74:
Title: A Mirror Descent-Based Algorithm for Corruption-Tolerant Distributed Gradient Descent
Authors: Shuche Wang, Vincent Y. F. Tan
Abstract: Distributed gradient descent algorithms have come to the fore in modern machine learning, especially in parallelizing the handling of large datasets that are distributed across several workers. However, scant attention has been paid to analyzing the behavior of distributed gradient descent algorithms in the presence of adversarial corruptions instead of random noise. In this paper, we formulate a novel problem in which adversarial corruptions are present in a distributed learning system. We show how to use ideas from (lazy) mirror descent to design a corruption-tolerant distributed optimization algorithm. Extensive convergence analysis for (strongly) convex loss functions is provided for different choices of the stepsize. We carefully optimize the stepsize schedule to accelerate the convergence of the algorithm, while at the same time amortizing the effect of the corruption over time. Experiments based on linear regression, support vector classification, and softmax classification on the MNIST dataset corroborate our theoretical findings.

Paper number 75:
Title: Model-Free Generic Robust Control for Servo-Driven Actuation Mechanisms with Layered Insight into Energy Conversions
Authors: Mehdi Heydari Shahna, Jouni Mattila
Abstract: To advance theoretical solutions and address limitations in modeling complex servo-driven actuation systems experiencing high non-linearity and load disturbances, this paper aims to design a practical model-free generic robust control (GRC) framework for these mechanisms. This framework is intended to be applicable across all actuator systems encompassing electrical, hydraulic, or pneumatic servomechanisms, while also functioning within complex interactions among dynamic components and adhering to control input constraints. In this respect, the state-space model of actuator systems is decomposed into smaller subsystems that incorporate the first principle equation of actuator motion dynamics and interactive energy conversion equations. This decomposition operates under the assumption that the comprehensive model of the servo-driven actuator system and energy conversion, uncertainties, load disturbances, and their bounds are unknown. Then, the GRC employs subsystem-based adaptive control strategies for each state-variant subsystem separately. Despite control input constraints and the unknown interactive system model, the GRC-applied actuator mechanism ensures uniform exponential stability and robustness in tracking desired motions. It features straightforward implementation, experimentally evaluated by applying it to two industrial applications.

Paper number 76:
Title: Efficient Training of Self-Supervised Speech Foundation Models on a Compute Budget
Authors: Andy T. Liu, Yi-Cheng Lin, Haibin Wu, Stefan Winkler, Hung-yi Lee
Abstract: Despite their impressive success, training foundation models remains computationally costly. This paper investigates how to efficiently train speech foundation models with self-supervised learning (SSL) under a limited compute budget. We examine critical factors in SSL that impact the budget, including model architecture, model size, and data size. Our goal is to make analytical steps toward understanding the training dynamics of speech foundation models. We benchmark SSL objectives in an entirely comparable setting and find that other factors contribute more significantly to the success of SSL. Our results show that slimmer model architectures outperform common small architectures under the same compute and parameter budget. We demonstrate that the size of the pre-training data remains crucial, even with data augmentation during SSL training, as performance suffers when iterating over limited data. Finally, we identify a trade-off between model size and data size, highlighting an optimal model size for a given compute budget.

Paper number 77:
Title: Digital and Hybrid Precoding Designs in Massive MIMO with Low-Resolution ADCs
Authors: Mengyuan Ma, Nhan Thanh Nguyen, Italo Atzeni, A. Lee Swindlehurst, Markku Juntti
Abstract: Low-resolution analog-to-digital converters (ADCs) have emerged as an efficient solution for massive multiple-input multiple-output (MIMO) systems to reap high data rates with reasonable power consumption and hardware complexity. In this paper, we study precoding designs for digital, fully connected (FC) hybrid, and partially connected (PC) hybrid beamforming architectures in massive MIMO systems with low-resolution ADCs at the receiver. We aim to maximize the spectral efficiency (SE) subject to a transmit power budget and hardware constraints on the analog components. The resulting problems are nonconvex and the quantization distortion introduces additional challenges. To address them, we first derive a tight lower bound for the SE, based on which we optimize the precoders for the three beamforming architectures under the majorization-minorization framework. Numerical results validate the superiority of the proposed precoding designs over their state-of-the-art counterparts in systems with low-resolution ADCs, particularly those with 1-bit resolution. The results show that the PC hybrid precoding design can achieve an SE close to those of the digital and FC hybrid precoding designs in 1-bit systems, highlighting the potential of the PC hybrid beamforming architectures.

Paper number 78:
Title: Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering
Authors: Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong
Abstract: Medical Visual Question Answering (MedVQA) has attracted growing interest at the intersection of computer vision and natural language processing. By interpreting medical images and providing precise answers to relevant clinical inquiries, MedVQA has the potential to support diagnostic decision-making and reduce workload across various domains, particularly radiology. While recent approaches rely heavily on unified large pre-trained Visual-Language Models, research on more efficient fusion mechanisms remains relatively limited in this domain. In this paper, we introduce a novel fusion model, OMniBAN, that integrates Orthogonality loss, Multi-head attention, and a Bilinear Attention Network to achieve high computational efficiency alongside solid performance. We conduct comprehensive experiments and provide insights into how bilinear attention fusion can approximate the performance of larger fusion models like cross-modal Transformer. Our results demonstrate that OMniBAN outperforms traditional approaches on key MedVQA benchmarks while maintaining a lower computational cost. This balance between efficiency and accuracy suggests that OMniBAN could be a viable option for real-world medical image question answering, where computational resources are often constrained.

Paper number 79:
Title: Preemptive Holistic Collaborative System and Its Application in Road Transportation
Authors: Ting Peng, Yuan Li, Tao Li, Xiaoxue Xu, Xiang Dong, Yincai Cai
Abstract: Numerous real-world systems, including manufacturing processes, supply chains, and robotic systems, involve multiple independent entities with diverse objectives. The potential for conflicts arises from the inability of these entities to accurately predict and anticipate each other's actions. To address this challenge, we propose the Preemptive Holistic Collaborative System (PHCS) framework. By enabling information sharing and collaborative planning among independent entities, the PHCS facilitates the preemptive resolution of potential conflicts. We apply the PHCS framework to the specific context of road transportation, resulting in the Preemptive Holistic Collaborative Road Transportation System (PHCRTS). This system leverages shared driving intentions and pre-planned trajectories to optimize traffic flow and enhance safety. Simulation experiments in a two-lane merging scenario demonstrate the effectiveness of PHCRTS, reducing vehicle time delays by 90%, increasing traffic capacity by 300%, and eliminating accidents. The PHCS framework offers a promising approach to optimize the performance and safety of complex systems with multiple independent entities.

Paper number 80:
Title: Reconfigurable Holographic Surface-aided Distributed MIMO Radar Systems
Authors: Qian Li, Ziang Yang, Dou Li, Hongliang Zhang
Abstract: Distributed phased Multiple-Input Multiple-Output (phased-MIMO) radar systems have attracted wide attention in target detection and tracking. However, the phase-shifting circuits in phased subarrays contribute to high power consumption and hardware cost. To address this issue, an energy-efficient and cost-efficient metamaterial antenna array, i.e., reconfigurable holographic surface (RHS), has been developed. In this letter, we propose RHS-aided distributed MIMO radar systems to achieve more accurate multi-target detection under equivalent power consumption and hardware cost as that of distributed phased-MIMO radar systems. Different from phased arrays, the RHS achieves beam steering by regulating the radiation amplitude of its elements, and thus conventional beamforming schemes designed for phased arrays are no longer applicable. Aiming to maximize detection accuracy, we design an amplitude-controlled beamforming scheme for multiple RHS transceiver subarrays. The simulations validate the superiority of the proposed scheme over the distributed phased-MIMO radar scheme and reveal the optimal allocation of spatial diversity and coherent processing gain that leads to the best system performance when hardware resources are fixed.

Paper number 81:
Title: Beamforming Design for Wideband Near-Field Communications With Reconfigurable Refractive Surfaces
Authors: Zicheng Lin, Shuhao Zeng, Aryan Kaushik, Hongliang Zhang
Abstract: To meet the growing demand for high data rates, cellular systems are expected to evolve towards higher carrier frequencies and larger antenna arrays, but conventional phased arrays face challenges in supporting such a prospection due to their excessive power consumption induced by numerous phase shifters required. Reconfigurable Refractive Surface (RRS) is an energy efficient solution to address this issue without relying on phase shifters. However, the increased radiation aperture size extends the range of the Fresnel region, leading the users to lie in the near-field zone. Moreover, given the wideband communications in higher frequency bands, we cannot ignore the frequency selectivity of the RRS. These two effects collectively exacerbate the beam-split issue, where different frequency components fail to converge on the user simultaneously, and finally result in a degradation of the data rate. In this paper, we investigate an RRS-based wideband near-field multi-user communication system. Unlike most existing studies on wideband communications, which consider the beam-split effect only with the near-field condition, we study the beam-split effect under the influence of both the near-field condition and the frequency selectivity of the RRS. To mitigate the beam-split effect, we propose a Delayed-RRS structure, based on which a beamforming scheme is proposed to optimize the user's data rate. Through theoretical analysis and simulation results, we analyze the influence of the RRS's frequency selectivity, demonstrate the effectiveness of the proposed beamforming scheme, and reveal the importance of jointly considering the near-field condition and the frequency selectivity of RRS.

Paper number 82:
Title: Calibrating Wireless AI via Meta-Learned Context-Dependent Conformal Prediction
Authors: Seonghoon Yoo, Sangwoo Park, Petar Popovski, Joonhyuk Kang, Osvaldo Simeone
Abstract: Modern software-defined networks, such as Open Radio Access Network (O-RAN) systems, rely on artificial intelligence (AI)-powered applications running on controllers interfaced with the radio access network. To ensure that these AI applications operate reliably at runtime, they must be properly calibrated before deployment. A promising and theoretically grounded approach to calibration is conformal prediction (CP), which enhances any AI model by transforming it into a provably reliable set predictor that provides error bars for estimates and decisions. CP requires calibration data that matches the distribution of the environment encountered during runtime. However, in practical scenarios, network controllers often have access only to data collected under different contexts -- such as varying traffic patterns and network conditions -- leading to a mismatch between the calibration and runtime distributions. This paper introduces a novel methodology to address this calibration-test distribution shift. The approach leverages meta-learning to develop a zero-shot estimator of distribution shifts, relying solely on contextual information. The proposed method, called meta-learned context-dependent weighted conformal prediction (ML-WCP), enables effective calibration of AI applications without requiring data from the current context. Additionally, it can incorporate data from multiple contexts to further enhance calibration reliability.

Paper number 83:
Title: Non-Asymptotic Analysis of Subspace Identification for Stochastic Systems Using Multiple Trajectories
Authors: Shuai Sun
Abstract: This paper is concerned with the analysis of identification errors for $n$-dimensional discrete-time Linear Time-Invariant (LTI) systems with $m$ outputs and no external inputs, using Subspace Identification Methods (SIM) with finite sample data. We provide non-asymptotic high-probability upper bounds for matrices $A,C$, the Kalman filter gain $K$, and the closed loop matrix $A-KC $, based on multiple sample trajectories, and further give the first non-asymptotic high-probability upper bounds for the system poles, which cover both (marginally) stable systems and unstable systems. We show that, with high probability, the non-asymptotic estimation errors of these matrices decay at a rate of at least $ \mathcal{O}(\sqrt{1/N}) $, while the estimation error of the system poles decays at a rate of at least $ \mathcal{O}(N^{-\frac{1}{2n}}) $, where $ N $ represents the number of sample trajectories. Furthermore, we prove that SIMs become ill-conditioned when the ratio $n/m$ is large, regardless of the system parameters. Numerical experiments are conducted to validate the non-asymptotic results and the ill-conditionedness of SIM.

Paper number 84:
Title: AAD-DCE: An Aggregated Multimodal Attention Mechanism for Early and Late Dynamic Contrast Enhanced Prostate MRI Synthesis
Authors: Divya Bharti, Sriprabha Ramanarayanan, Sadhana S, Kishore Kumar M, Keerthi Ram, Harsh Agarwal, Ramesh Venkatesan, Mohanasankar Sivaprakasam
Abstract: Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) is a medical imaging technique that plays a crucial role in the detailed visualization and identification of tissue perfusion in abnormal lesions and radiological suggestions for biopsy. However, DCE-MRI involves the administration of a Gadolinium based (Gad) contrast agent, which is associated with a risk of toxicity in the body. Previous deep learning approaches that synthesize DCE-MR images employ unimodal non-contrast or low-dose contrast MRI images lacking focus on the local perfusion information within the anatomy of interest. We propose AAD-DCE, a generative adversarial network (GAN) with an aggregated attention discriminator module consisting of global and local discriminators. The discriminators provide a spatial embedded attention map to drive the generator to synthesize early and late response DCE-MRI images. Our method employs multimodal inputs - T2 weighted (T2W), Apparent Diffusion Coefficient (ADC), and T1 pre-contrast for image synthesis. Extensive comparative and ablation studies on the ProstateX dataset show that our model (i) is agnostic to various generator benchmarks and (ii) outperforms other DCE-MRI synthesis approaches with improvement margins of +0.64 dB PSNR, +0.0518 SSIM, -0.015 MAE for early response and +0.1 dB PSNR, +0.0424 SSIM, -0.021 MAE for late response, and (ii) emphasize the importance of attention ensembling. Our code is available at this https URL.

Paper number 85:
Title: Mixed-integer linear programming approaches for tree partitioning of power networks
Authors: Leon Lan, Alessandro Zocca
Abstract: In transmission networks, power flows and network topology are deeply intertwined due to power flow physics. Recent literature shows that a specific more hierarchical network structure can effectively inhibit the propagation of line failures across the entire system. In particular, a novel approach named tree partitioning has been proposed, which seeks to bolster the robustness of power networks through strategic alterations in network topology, accomplished via targeted line switching actions. Several tree partitioning problem formulations have been proposed by considering different objectives, among which power flow disruption and network congestion. Furthermore, various heuristic methods based on a two-stage and recursive approach have been proposed. The present work provides a general framework for tree partitioning problems based on mixed-integer linear programming (MILP). In particular, we present a novel MILP formulation to optimally solve tree partitioning problems and also propose a two-stage heuristic based on MILP. We perform extensive numerical experiments to solve two tree partitioning problem variants, demonstrating the excellent performance of our solution methods. Lastly, through exhaustive cascading failure simulations, we compare the effectiveness of various tree partitioning strategies and show that, on average, they can achieve a substantial reduction in lost load compared to the original topologies.

Paper number 86:
Title: Spoken Language Intelligence of Large Language Models for Language Learning
Authors: Linkai Peng, Baorian Nuchged, Yingming Gao
Abstract: People have long hoped for a conversational system that can assist in real-life situations, and recent progress on large language models (LLMs) is bringing this idea closer to reality. While LLMs are often impressive in performance, their efficacy in real-world scenarios that demand expert knowledge remains unclear. LLMs are believed to hold the most potential and value in education, especially in the development of Artificial intelligence (AI) based virtual teachers capable of facilitating language learning. Our focus is centered on evaluating the efficacy of LLMs in the realm of education, specifically in the areas of spoken language learning which encompass phonetics, phonology, and second language acquisition. We introduce a new multiple-choice question dataset to evaluate the effectiveness of LLMs in the aforementioned scenarios, including understanding and application of spoken language knowledge. In addition, we investigate the influence of various prompting techniques such as zero- and few-shot method (prepending the question with question-answer exemplars), chain-of-thought (CoT, think step-by-step), in-domain exampler and external tools (Google, Wikipedia). We conducted large-scale evaluation on popular LLMs (20 distinct models) using these methods. We achieved significant performance improvements compared to the zero-shot baseline in the practical questions reasoning (GPT-3.5, 49.1% -> 63.1%; LLaMA2-70B-Chat, 42.2% -> 48.6%). We found that models of different sizes have good understanding of concepts in phonetics, phonology, and second language acquisition, but show limitations in reasoning for real-world problems. Additionally, we also explore preliminary findings on conversational communication.

Paper number 87:
Title: Limitations of Data-Driven Spectral Reconstruction -- Optics-Aware Analysis and Mitigation
Authors: Qiang Fu, Matheus Souza, Eunsue Choi, Suhyun Shin, Seung-Hwan Baek, Wolfgang Heidrich
Abstract: Hyperspectral imaging empowers machine vision systems with the distinct capability of identifying materials through recording their spectral signatures. Recent efforts in data-driven spectral reconstruction aim at extracting spectral information from RGB images captured by cost-effective RGB cameras, instead of dedicated hardware. In this paper we systematically analyze the performance of such methods, evaluating both the practical limitations with respect to current datasets and overfitting, as well as fundamental limitations with respect to the nature of the information encoded in the RGB images, and the dependency of this information on the optical system of the camera. We find that, the current models are not robust under slight variations, e.g., in noise level or compression of the RGB file. Without modeling underrepresented spectral content, existing datasets and the models trained on them are limited in their ability to cope with challenging metameric colors. To mitigate this issue, we propose to exploit the combination of metameric data augmentation and optical lens aberrations to improve the encoding of the metameric information into the RGB image, which paves the road towards higher performing spectral imaging and reconstruction approaches.

Paper number 88:
Title: Detection Schemes with Low-Resolution ADCs and Spatial Oversampling for Transmission with Higher-Order Constellations in the Terahertz Band
Authors: Christian Forsch, Peter Zillmann, Osama Alrabadi, Stefan Brueck, Wolfgang Gerstacker
Abstract: In this work, we consider Terahertz (THz) communications with low-resolution uniform quantization and spatial oversampling at the receiver side, corresponding to a single-input multiple-output (SIMO) transmission. We fairly compare different analog-to-digital converter (ADC) parametrizations by keeping the ADC power consumption constant. Here, 1-, 2-, and 3-bit quantization is investigated with different oversampling factors. We analytically compute the statistics of the detection variable, and we propose the optimal and several suboptimal detection schemes for arbitrary quantization resolutions. Then, we evaluate the symbol error rate (SER) of the different detectors for 16- and 64-ary quadrature amplitude modulation (QAM). The results indicate that there is a noticeable performance degradation of the suboptimal detectors compared to the optimal detector when the constellation size is larger than the number of quantization levels. Furthermore, at low signal-to-noise ratios (SNRs), 1-bit quantization outperforms 2- and 3-bit quantization, respectively, even when employing higher-order constellations. We confirm our analytical results by Monte Carlo simulations. Both a pure line-of-sight (LoS) and a more realistically modeled indoor THz channel are considered. Then, we optimize the input signal constellation with respect to SER for 1- and 2-bit quantization. The results give insights for optimizing higher-order constellations for arbitrary quantization resolutions and show that the minimum SER can be lowered significantly by appropriately placing the constellation points.

Paper number 89:
Title: Nonparametric Sparse Online Learning of the Koopman Operator
Authors: Boya Hou, Sina Sanjari, Nathan Dahlin, Alec Koppel, Subhonmesh Bose
Abstract: The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm.

Paper number 90:
Title: Images that Sound: Composing Images and Sounds on a Single Canvas
Authors: Ziyang Chen, Daniel Geng, Andrew Owens
Abstract: Spectrograms are 2D representations of sound that look very different from the images found in our visual world. And natural images, when played as spectrograms, make unnatural sounds. In this paper, we show that it is possible to synthesize spectrograms that simultaneously look like natural images and sound like natural audio. We call these visual spectrograms images that sound. Our approach is simple and zero-shot, and it leverages pre-trained text-to-image and text-to-spectrogram diffusion models that operate in a shared latent space. During the reverse process, we denoise noisy latents with both the audio and image diffusion models in parallel, resulting in a sample that is likely under both models. Through quantitative evaluations and perceptual studies, we find that our method successfully generates spectrograms that align with a desired audio prompt while also taking the visual appearance of a desired image prompt. Please see our project page for video results: this https URL

Paper number 91:
Title: Towards Realistic Data Generation for Real-World Super-Resolution
Authors: Long Peng, Wenbo Li, Renjing Pei, Jingjing Ren, Jiaqi Xu, Yang Wang, Yang Cao, Zheng-Jun Zha
Abstract: Existing image super-resolution (SR) techniques often fail to generalize effectively in complex real-world settings due to the significant divergence between training data and practical scenarios. To address this challenge, previous efforts have either manually simulated intricate physical-based degradations or utilized learning-based techniques, yet these approaches remain inadequate for producing large-scale, realistic, and diverse data simultaneously. In this paper, we introduce a novel Realistic Decoupled Data Generator (RealDGen), an unsupervised learning data generation framework designed for real-world super-resolution. We meticulously develop content and degradation extraction strategies, which are integrated into a novel content-degradation decoupled diffusion model to create realistic low-resolution images from unpaired real LR and HR images. Extensive experiments demonstrate that RealDGen excels in generating large-scale, high-quality paired data that mirrors real-world degradations, significantly advancing the performance of popular SR models on various real-world benchmarks.

Paper number 92:
Title: Managing O-RAN Networks: xApp Development from Zero to Hero
Authors: Joao F. Santos, Alexandre Huff, Daniel Campos, Kleber V. Cardoso, Cristiano B. Both, Luiz A. DaSilva
Abstract: The Open Radio Access Network (O-RAN) Alliance proposes an open architecture that disaggregates the RAN and supports executing custom control logic in near-real time from third-party applications, the xApps. Despite O-RAN's efforts, the creation of xApps remains a complex and time-consuming endeavor, aggravated by the sometimes fragmented, outdated, or deprecated documentation from the O-RAN Software Community (OSC). These challenges hinder academia and industry from developing and validating solutions and algorithms on O-RAN networks. This tutorial addresses this gap by providing the first comprehensive guide for developing xApps to manage the O-RAN ecosystem from theory to practice. We provide a thorough theoretical foundation of the O-RAN architecture and detail the functionality offered by Near Real-Time RAN Intelligent Controller (Near-RT RIC) components. We examine the xApp design and configuration. We explore the xApp lifecycle and demonstrate how to deploy and manage xApps on a Near-RT RIC. We address the xApps' interfaces and capabilities, accompanied by practical examples. We provide comprehensive details on how xApps can control the RAN. We discuss debugging strategies and good practices to aid the xApp developers in testing their xApps. Finally, we review the current landscape and open challenges for creating xApps.

Paper number 93:
Title: PSC: Posterior Sampling-Based Compression
Authors: Noam Elata, Tomer Michaeli, Michael Elad
Abstract: Diffusion models have transformed the landscape of image generation and now show remarkable potential for image compression. Most of the recent diffusion-based compression methods require training and are tailored for a specific bit-rate. In this work, we propose Posterior Sampling-based Compression (PSC) - a zero-shot compression method that leverages a pre-trained diffusion model as its sole neural network component, thus enabling the use of diverse, publicly available models without additional training. Our approach is inspired by transform coding methods, which encode the image in some pre-chosen transform domain. However, PSC constructs a transform that is adaptive to the image. This is done by employing a zero-shot diffusion-based posterior sampler so as to progressively construct the rows of the transform matrix. Each new chunk of rows is chosen to reduce the uncertainty about the image given the quantized measurements collected thus far. Importantly, the same adaptive scheme can be replicated at the decoder, thus avoiding the need to encode the transform itself. We demonstrate that even with basic quantization and entropy coding, PSC's performance is comparable to established training-based methods in terms of rate, distortion, and perceptual quality. This is while providing greater flexibility, allowing to choose at inference time any desired rate or distortion.

Paper number 94:
Title: PixelShuffler: A Simple Image Translation Through Pixel Rearrangement
Authors: Omar Zamzam
Abstract: Image-to-image translation is a topic in computer vision that has a vast range of use cases ranging from medical image translation, such as converting MRI scans to CT scans or to other MRI contrasts, to image colorization, super-resolution, domain adaptation, and generating photorealistic images from sketches or semantic maps. Image style transfer is also a widely researched application of image-to-image translation, where the goal is to synthesize an image that combines the content of one image with the style of another. Existing state-of-the-art methods often rely on complex neural networks, including diffusion models and language models, to achieve high-quality style transfer, but these methods can be computationally expensive and intricate to implement. In this paper, we propose a novel pixel shuffle method that addresses the image-to-image translation problem generally with a specific demonstrative application in style transfer. The proposed method approaches style transfer by shuffling the pixels of the style image such that the mutual information between the shuffled image and the content image is maximized. This approach inherently preserves the colors of the style image while ensuring that the structural details of the content image are retained in the stylized output. We demonstrate that this simple and straightforward method produces results that are comparable to state-of-the-art techniques, as measured by the Learned Perceptual Image Patch Similarity (LPIPS) loss for content preservation and the Fréchet Inception Distance (FID) score for style similarity. Our experiments validate that the proposed pixel shuffle method achieves competitive performance with significantly reduced complexity, offering a promising alternative for efficient image style transfer, as well as a promise in usability of the method in general image-to-image translation tasks.

Paper number 95:
Title: Hybrid LLM-DDQN based Joint Optimization of V2I Communication and Autonomous Driving
Authors: Zijiang Yan, Hao Zhou, Hina Tabassum, Xue Liu
Abstract: Large language models (LLMs) have received considerable interest recently due to their outstanding reasoning and comprehension capabilities. This work explores applying LLMs to vehicular networks, aiming to jointly optimize vehicle-to-infrastructure (V2I) communications and autonomous driving (AD) policies. We deploy LLMs for AD decision-making to maximize traffic flow and avoid collisions for road safety, and a double deep Q-learning algorithm (DDQN) is used for V2I optimization to maximize the received data rate and reduce frequent handovers. In particular, for LLM-enabled AD, we employ the Euclidean distance to identify previously explored AD experiences, and then LLMs can learn from past good and bad decisions for further improvement. Then, LLM-based AD decisions will become part of states in V2I problems, and DDQN will optimize the V2I decisions accordingly. After that, the AD and V2I decisions are iteratively optimized until convergence. Such an iterative optimization approach can better explore the interactions between LLMs and conventional reinforcement learning techniques, revealing the potential of using LLMs for network optimization and management. Finally, the simulations demonstrate that our proposed hybrid LLM-DDQN approach outperforms the conventional DDQN algorithm, showing faster convergence and higher average rewards.

Paper number 96:
Title: Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection
Authors: Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara
Abstract: In human conversations, short backchannel utterances such as "yeah" and "oh" play a crucial role in facilitating smooth and engaging dialogue. These backchannels signal attentiveness and understanding without interrupting the speaker, making their accurate prediction essential for creating more natural conversational agents. This paper proposes a novel method for real-time, continuous backchannel prediction using a fine-tuned Voice Activity Projection (VAP) model. While existing approaches have relied on turn-based or artificially balanced datasets, our approach predicts both the timing and type of backchannels in a continuous and frame-wise manner on unbalanced, real-world datasets. We first pre-train the VAP model on a general dialogue corpus to capture conversational dynamics and then fine-tune it on a specialized dataset focused on backchannel behavior. Experimental results demonstrate that our model outperforms baseline methods in both timing and type prediction tasks, achieving robust performance in real-time environments. This research offers a promising step toward more responsive and human-like dialogue systems, with implications for interactive spoken dialogue applications such as virtual assistants and robots.

Paper number 97:
Title: PaPaGei: Open Foundation Models for Optical Physiological Signals
Authors: Arvind Pillai, Dimitris Spathis, Fahim Kawsar, Mohammad Malekzadeh
Abstract: Photoplethysmography (PPG) is the leading non-invasive technique for monitoring biosignals and cardiovascular health, with widespread adoption in both clinical settings and consumer wearable devices. While machine learning models trained on PPG signals have shown promise, they tend to be task-specific and struggle with generalization. Current research is limited by the use of single-device datasets, insufficient exploration of out-of-domain generalization, and a lack of publicly available models, which hampers reproducibility. To address these limitations, we present PaPaGei, the first open foundation model for PPG signals. The model is pre-trained on over 57,000 hours of data, comprising 20 million unlabeled PPG segments from publicly available datasets. We introduce a novel representation learning approach that leverages domain knowledge of PPG signal morphology across individuals, enabling the capture of richer representations compared to traditional contrastive learning methods. We evaluate PaPaGei against state-of-the-art time-series foundation models and self-supervised learning benchmarks across 20 tasks from 10 diverse datasets, spanning cardiovascular health, sleep disorders, pregnancy monitoring, and wellbeing assessment. Our model demonstrates superior performance, improving classification and regression metrics by 6.3% and 2.9% respectively in at least 14 tasks. Notably, PaPaGei achieves these results while being more data- and parameter-efficient, outperforming models that are 70x larger. Beyond accuracy, we examine model robustness across different skin tones, establishing a benchmark for bias evaluation in future models. PaPaGei can serve as both a feature extractor and an encoder for multimodal models, opening up new opportunities for multimodal health monitoring.

Paper number 98:
Title: MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation Models, Convolutional Neural Networks, and Uncertainty Quantification for High-Speed Video Phase Detection Data
Authors: Chika Maduabuchi, Ericmoore Jossou, Matteo Bucci
Abstract: High-speed video (HSV) phase detection (PD) segmentation is crucial for monitoring vapor, liquid, and microlayer phases in industrial processes. While CNN-based models like U-Net have shown success in simplified shadowgraphy-based two-phase flow (TPF) analysis, their application to complex HSV PD tasks remains unexplored, and vision foundation models (VFMs) have yet to address the complexities of either shadowgraphy-based or PD TPF video segmentation. Existing uncertainty quantification (UQ) methods lack pixel-level reliability for critical metrics like contact line density and dry area fraction, and the absence of large-scale, multimodal experimental datasets tailored to PD segmentation further impedes progress. To address these gaps, we propose MSEG-VCUQ. This hybrid framework integrates U-Net CNNs with the transformer-based Segment Anything Model (SAM) to achieve enhanced segmentation accuracy and cross-modality generalization. Our approach incorporates systematic UQ for robust error assessment and introduces the first open-source multimodal HSV PD datasets. Empirical results demonstrate that MSEG-VCUQ outperforms baseline CNNs and VFMs, enabling scalable and reliable PD segmentation for real-world boiling dynamics.

Paper number 99:
Title: Prepending or Cross-Attention for Speech-to-Text? An Empirical Comparison
Authors: Tsz Kin Lam, Marco Gaido, Sara Papi, Luisa Bentivogli, Barry Haddow
Abstract: Following the remarkable success of Large Language Models (LLMs) in NLP tasks, there is increasing interest in extending their capabilities to speech -- the most common form of communication. The most widespread approach to integrating speech into LLMs is dense feature prepending (DFP), which prepends the projected speech representations to the textual representations, allowing end-to-end training with a speech encoder. This raises questions about the need for a sophisticated speech encoder for DFP and how its performance compares with a standard encoder-decoder (i.e., cross-attention) architecture. We compare DFP and cross-attention under a variety of configurations, such as CTC compression, sequence-level knowledge distillation, on monolingual, bilingual, and multilingual models. To perform a controlled architectural comparison, we train all models from scratch rather than using large pretrained models and use comparable data and parameter settings, testing speech-to-text recognition (ASR) and translation (ST) on MuST-C v1.0 and CoVoST2 datasets. Despite the wide adoption of DFP, our results do not indicate a clear advantage of DFP over cross-attention.

Paper number 100:
Title: CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks
Authors: Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang
Abstract: Efficient resource allocation is essential for optimizing various tasks in wireless networks, which are usually formulated as generalized assignment problems (GAP). GAP, as a generalized version of the linear sum assignment problem, involves both equality and inequality constraints that add computational challenges. In this work, we present a novel Conditional Value at Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address GAP in vehicular networks (VNets). Our approach leverages a hybrid quantum-classical structure, integrating a tailored cost function that balances both objective and constraint-specific penalties to improve solution quality and stability. Using the CVaR-VQE model, we handle the GAP efficiently by focusing optimization on the lower tail of the solution space, enhancing both convergence and resilience on noisy intermediate-scale quantum (NISQ) devices. We apply this framework to a user-association problem in VNets, where our method achieves 23.5% improvement compared to the deep neural network (DNN) approach.

Paper number 101:
Title: GS-LiDAR: Generating Realistic LiDAR Point Clouds with Panoramic Gaussian Splatting
Authors: Junzhe Jiang, Chun Gu, Yurui Chen, Li Zhang
Abstract: LiDAR novel view synthesis (NVS) has emerged as a novel task within LiDAR simulation, offering valuable simulated point cloud data from novel viewpoints to aid in autonomous driving systems. However, existing LiDAR NVS methods typically rely on neural radiance fields (NeRF) as their 3D representation, which incurs significant computational costs in both training and rendering. Moreover, NeRF and its variants are designed for symmetrical scenes, making them ill-suited for driving scenarios. To address these challenges, we propose GS-LiDAR, a novel framework for generating realistic LiDAR point clouds with panoramic Gaussian splatting. Our approach employs 2D Gaussian primitives with periodic vibration properties, allowing for precise geometric reconstruction of both static and dynamic elements in driving scenarios. We further introduce a novel panoramic rendering technique with explicit ray-splat intersection, guided by panoramic LiDAR supervision. By incorporating intensity and ray-drop spherical harmonic (SH) coefficients into the Gaussian primitives, we enhance the realism of the rendered point clouds. Extensive experiments on KITTI-360 and nuScenes demonstrate the superiority of our method in terms of quantitative metrics, visual quality, as well as training and rendering efficiency.

Paper number 102:
Title: Foundation Models for CPS-IoT: Opportunities and Challenges
Authors: Ozan Baris, Yizhuo Chen, Gaofeng Dong, Liying Han, Tomoyoshi Kimura, Pengrui Quan, Ruijie Wang, Tianchen Wang, Tarek Abdelzaher, Mario Bergés, Paul Pu Liang, Mani Srivastava
Abstract: Methods from machine learning (ML) have transformed the implementation of Perception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS) and the Internet of Things (IoT), replacing mechanistic and basic statistical models with those derived from data. However, the first generation of ML approaches, which depend on supervised learning with annotated data to create task-specific models, faces significant limitations in scaling to the diverse sensor modalities, deployment configurations, application tasks, and operating dynamics characterizing real-world CPS-IoT systems. The success of task-agnostic foundation models (FMs), including multimodal large language models (LLMs), in addressing similar challenges across natural language, computer vision, and human speech has generated considerable enthusiasm for and exploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics pipelines, promising to reduce the need for costly task-specific engineering. Nonetheless, a significant gap persists between the current capabilities of FMs and LLMs in the CPS-IoT domain and the requirements they must meet to be viable for CPS-IoT applications. In this paper, we analyze and characterize this gap through a thorough examination of the state of the art and our research, which extends beyond it in various dimensions. Based on the results of our analysis and research, we identify essential desiderata that CPS-IoT domain-specific FMs and LLMs must satisfy to bridge this gap. We also propose actions by CPS-IoT researchers to collaborate in developing key community resources necessary for establishing FMs and LLMs as foundational tools for the next generation of CPS-IoT systems.

Paper number 103:
Title: Nonparametric Sparse Online Learning of the Koopman Operator
Authors: Boya Hou, Sina Sanjari, Nathan Dahlin, Alec Koppel, Subhonmesh Bose
Abstract: The Koopman operator provides a powerful framework for representing the dynamics of general nonlinear dynamical systems. Data-driven techniques to learn the Koopman operator typically assume that the chosen function space is closed under system dynamics. In this paper, we study the Koopman operator via its action on the reproducing kernel Hilbert space (RKHS), and explore the mis-specified scenario where the dynamics may escape the chosen function space. We relate the Koopman operator to the conditional mean embeddings (CME) operator and then present an operator stochastic approximation algorithm to learn the Koopman operator iteratively with control over the complexity of the representation. We provide both asymptotic and finite-time last-iterate guarantees of the online sparse learning algorithm with trajectory-based sampling with an analysis that is substantially more involved than that for finite-dimensional stochastic approximation. Numerical examples confirm the effectiveness of the proposed algorithm.
    