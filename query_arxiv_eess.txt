
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions
Authors: Huan Liu, Michel Gendreau, Binjie Xu, Guohua Wu, Yi Gu
Abstract: In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods.

Paper number 2:
Title: Newton-Direction-Based ReLU-Thresholding Methods for Nonnegative Sparse Signal Recovery
Authors: Ning Bian, Zhong-Feng Sun, Yun-Bin Zhao, Jin-Chuan Zhou, Nan Meng
Abstract: Nonnegative sparse signal recovery has been extensively studied due to its broad applications. Recent work has integrated rectified linear unit (ReLU) techniques to enhance existing recovery algorithms. We merge Newton-type thresholding with ReLU-based approaches to propose two algorithms: Newton-Direction-Based ReLU-Thresholding (NDRT) and its enhanced variant, Newton-Direction-Based ReLU-Thresholding Pursuit (NDRTP). Theoretical analysis iindicates that both algorithms can guarantee exact recovery of nonnegative sparse signals when the measurement matrix satisfies a certain condition.. Numerical experiments demonstrate NDRTP achieves competitive performance compared to several existing methods in both noisy and noiseless scenarios.

Paper number 3:
Title: NeuroSleep: Neuromorphic Event-Driven Single-Channel EEG Sleep Staging for Edge-Efficient Sensing
Authors: Boyu Li, Xingchun Zhu, Yonghui Wu
Abstract: Reliable, continuous neural sensing on wearable edge platforms is fundamental to long-term health monitoring; however, for electroencephalography (EEG)-based sleep monitoring, dense high-frequency processing is often computationally prohibitive under tight energy budgets. To address this bottleneck, this paper proposes NeuroSleep, an integrated event-driven sensing and inference system for energy-efficient sleep staging. NeuroSleep first converts raw EEG into complementary multi-scale bipolar event streams using Residual Adaptive Multi-Scale Delta Modulation (R-AMSDM), enabling an explicit fidelity-sparsity trade-off at the sensing front end. Furthermore, NeuroSleep adopts a hierarchical inference architecture that comprises an Event-based Adaptive Multi-scale Response (EAMR) module for local feature extraction, a Local Temporal-Attention Module (LTAM) for context aggregation, and an Epoch-Leaky Integrate-and-Fire (ELIF) module to capture long-term state persistence. Experimental results using subject-independent 5-fold cross-validation on the Sleep-EDF Expanded dataset demonstrate that NeuroSleep achieves a mean accuracy of 74.2% with only 0.932 M parameters while reducing sparsity-adjusted effective operations by approximately 53.6% relative to dense processing. Compared with the representative dense Transformer baseline, NeuroSleep improves accuracy by 7.5% with a 45.8% reduction in computational load. By bridging neuromorphic encoding with state-aware modeling, NeuroSleep provides a scalable solution for always-on sleep analysis in resource-constrained wearable scenarios.

Paper number 4:
Title: Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis
Authors: Pengfei Zhang, Tianxin Xie, Minghao Yang, Li Liu
Abstract: Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. To address the representation gap, we introduce a Modality-Weaving Diagnoser that weaves EHR data with audio tokens via Strategic Global Attention and sparse audio anchors, capturing both long-range clinical context and millisecond-level transients. To address the data gap, we design a Flow Matching Generator that adapts a text-only Large Language Model (LLM) via modality injection, decoupling pathological content from acoustic style to synthesize hard-to-diagnose samples. As a foundation for these efforts, we introduce Resp-229k, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that Resp-Agent consistently outperforms prior approaches across diverse evaluation settings, improving diagnostic robustness under data scarcity and long-tailed class imbalance. Our code and data are available at this https URL.

Paper number 5:
Title: Foundation Models for Medical Imaging: Status, Challenges, and Directions
Authors: Chuang Niu, Pengwei Wu, Bruno De Man, Ge Wang
Abstract: Foundation models (FMs) are rapidly reshaping medical imaging, shifting the field from narrowly trained, task-specific networks toward large, general-purpose models that can be adapted across modalities, anatomies, and clinical tasks. In this review, we synthesize the emerging landscape of medical imaging FMs along three major axes: principles of FM design, applications of FMs, and forward-looking challenges and opportunities. Taken together, this review provides a technically grounded, clinically aware, and future-facing roadmap for developing FMs that are not only powerful and versatile but also trustworthy and ready for responsible translation into clinical practice.

Paper number 6:
Title: ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction
Authors: Amarjit Singh, Kento Sato, Kohei Yoshida, Kentaro Uesugi, Yasumasa Joti, Takaki Hatsui, Andrès Rubio Proaño
Abstract: In high-performance computing (HPC) environments, particularly in synchrotron radiation facilities, vast amounts of X-ray images are generated. Processing large-scale X-ray Computed Tomography (X-CT) datasets presents significant computational and storage challenges due to their high dimensionality and data volume. Traditional approaches often require extensive storage capacity and high transmission bandwidth, limiting real-time processing capabilities and workflow efficiency. To address these constraints, we introduce a region-of-interest (ROI)-driven extraction framework (ROIX-Comp) that intelligently compresses X-CT data by identifying and retaining only essential features. Our work reduces data volume while preserving critical information for downstream processing tasks. At pre-processing stage, we utilize error-bounded quantization to reduce the amount of data to be processed and therefore improve computational efficiencies. At the compression stage, our methodology combines object extraction with multiple state-of-the-art lossless and lossy compressors, resulting in significantly improved compression ratios. We evaluated this framework against seven X-CT datasets and observed a relative compression ratio improvement of 12.34x compared to the standard compression.

Paper number 7:
Title: Automated Assessment of Kidney Ureteroscopy Exploration for Training
Authors: Fangjie Li, Nicholas Kavoussi, Charan Mohan, Matthieu Chabanas, Jie Ying Wu
Abstract: Purpose: Kidney ureteroscopic navigation is challenging with a steep learning curve. However, current clinical training has major deficiencies, as it requires one-on-one feedback from experts and occurs in the operating room (OR). Therefore, there is a need for a phantom training system with automated feedback to greatly \revision{expand} training opportunities. Methods: We propose a novel, purely ureteroscope video-based scope localization framework that automatically identifies calyces missed by the trainee in a phantom kidney exploration. We use a slow, thorough, prior exploration video of the kidney to generate a reference reconstruction. Then, this reference reconstruction can be used to localize any exploration video of the same phantom. Results: In 15 exploration videos, a total of 69 out of 74 calyces were correctly classified. We achieve < 4mm camera pose localization error. Given the reference reconstruction, the system takes 10 minutes to generate the results for a typical exploration (1-2 minute long). Conclusion: We demonstrate a novel camera localization framework that can provide accurate and automatic feedback for kidney phantom explorations. We show its ability as a valid tool that enables out-of-OR training without requiring supervision from an expert.

Paper number 8:
Title: Stability and convergence of multi-converter systems using projection-free power-limiting droop control
Authors: Amirhossein Iraniparast, Dominic Groß
Abstract: In this paper, we propose a projection-free power-limiting droop control for grid-connected power electronics and an associated constrained flow problem. In contrast to projection-based power-limiting droop control, the novel projection-free power-limiting droop control results in networked dynamics that are semi-globally exponentially stable with respect to the set of optimizers of the constrained flow problem. Under a change to edge coordinates, the overall networked dynamics arising from projection-free power-limiting droop control coincide with the projection-free primal-dual dynamics associated with an augmented Lagrangian of the constrained flow problem. Leveraging this result, we (i) provide a bound on the convergence rate of the projection-free networked dynamics, (ii) propose a tuning method for controller parameters to improve the bound on the convergence rate, and (iii) analyze the relationship of the bound on the convergence rate and connectivity of the network. Finally, the analytical results are illustrated using an Electromagnetic transient (EMT) simulation.

Paper number 9:
Title: Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets
Authors: Nelson Salazar-Pena, Alejandra Tabares, Andres Gonzalez-Mancera
Abstract: This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that simplifies grid regulation. Furthermore, topological analysis reveals emergent spatial clustering, where decentralized agents self-organize into stable trading communities to minimize congestion penalties. While SAC excelled in hybrid settings, it failed in decentralized environments due to entropy-driven instability. This research proves that stigmergic signaling provides sufficient context for complex grid coordination, offering a robust, privacy-preserving alternative to expensive centralized communication infrastructure.

Paper number 10:
Title: MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets
Authors: Nelson Salazar-Pena, Alejandra Tabares, Andres Gonzalez-Mancera
Abstract: This paper introduces a novel, open-source MARL simulation framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery storage), a realistic grid network, and a comprehensive analytics suite to evaluate emergent coordination. The main contribution is a novel method to foster implicit cooperation, where agents' observations and rewards are enhanced with system-level key performance indicators to enable them to independently learn strategies that benefit the entire system and aim for collectively beneficial outcomes without explicit communication. Through representative case studies (available in a dedicated GitHub repository in this https URL, we show the framework's ability to analyze how different market configurations (such as varying storage deployment) impact system performance. This illustrates its potential to facilitate emergent coordination, improve market efficiency, and strengthen grid stability. The proposed simulation framework is a flexible, extensible, and reproducible tool for researchers and practitioners to design, test, and validate strategies for future intelligent, decentralized energy systems.

Paper number 11:
Title: Tunable Ferroelectric Acoustic Resonators in Monolithic Thin-Film Barium Titanate
Authors: Ian Anderson, Agham Posadas, Alexander A. Demkov, Ruochen Lu
Abstract: The increasing development of wireless communication bands has motivated the development of compact, low-loss, and frequency adjustable RF filtering technologies. Acoustic resonators are the ideal solution to these requirements, and tunable implementations offer a path toward reconfigurable front ends. In this work, we investigate epitaxial barium titanate (BTO) grown on silicon as a platform for tunable acoustic resonators operating in the sub-GHz regime. We demonstrate lateral excitation of symmetric lamb (S0) modes in X-cut BTO membranes, in contrast to prior thickness-defined ferroelectric resonators. Devices are designed using finite-element simulations and fabricated with laterally patterned electrodes that enable overtone coupling to multiple resonant modes. Under applied DC bias, ferroelectric domains align, allowing electrical excitation, frequency tuning, and quality-factor enhancement of acoustic modes. Resonances near 300 MHz and 700 MHz exhibit electromechanical coupling up to 8% and bias-dependent frequency tuning, with a distinct transition in behavior near 20 V. These results highlight monolithic BTO on silicon as a promising material system for laterally excited, tunable acoustic resonators for reconfigurable RF applications.

Paper number 12:
Title: Advancing Industry 4.0: Multimodal Sensor Fusion for AI-Based Fault Detection in 3D Printing
Authors: Muhammad Fasih Waheed, Shonda Bernadin, Ali Hassan
Abstract: Additive manufacturing, particularly fused deposition modeling, is transforming modern production by enabling rapid prototyping and complex part fabrication. However, its layer-by-layer process remains vulnerable to faults such as nozzle clogging, filament runout, and layer misalignment, which compromise print quality and reliability. Traditional inspection methods are costly, time-intensive, and often limited to post-process analysis, making them unsuitable for real-time intervention. In this current study, the authors developed a novel, low-cost, and portable faultdetection system that leverages multimodal sensor fusion and artificial intelligence for real-time monitoring in FDM-based 3D printing. The system integrates acoustic, vibration, and thermal sensing into a non-intrusive architecture, capturing complementary data streams that reflect both mechanical and process-related anomalies. Acoustic and thermal sensors operate in a fully contactless manner, while the vibration sensor requires minimal attachment such that it will not interfere with printer hardware, thereby preserving portability and ease of deployment. The multimodal signals are processed into spectrograms and time-frequency features, which are classified using convolutional neural networks for intelligent fault detection. The proposed system advances Industry 4.0 objectives by offering an affordable, scalable, and practical monitoring solution that improves faultdetection accuracy, reduces waste, and supports sustainable, adaptive manufacturing.

Paper number 13:
Title: Real time fault detection in 3D printers using Convolutional Neural Networks and acoustic signals
Authors: Muhammad Fasih Waheed, Shonda Bernadin
Abstract: The reliability and quality of 3D printing processes are critically dependent on the timely detection of mechanical faults. Traditional monitoring methods often rely on visual inspection and hardware sensors, which can be both costly and limited in scope. This paper explores a scalable and contactless method for the use of real-time audio signal analysis for detecting mechanical faults in 3D printers. By capturing and classifying acoustic emissions during the printing process, we aim to identify common faults such as nozzle clogging, filament breakage, pully skipping and various other mechanical faults. Utilizing Convolutional neural networks, we implement algorithms capable of real-time audio classification to detect these faults promptly. Our methodology involves conducting a series of controlled experiments to gather audio data, followed by the application of advanced machine learning models for fault detection. Additionally, we review existing literature on audio-based fault detection in manufacturing and 3D printing to contextualize our research within the broader field. Preliminary results demonstrate that audio signals, when analyzed with machine learning techniques, provide a reliable and cost-effective means of enhancing real-time fault detection.

Paper number 14:
Title: In-Situ Analysis of Vibration and Acoustic Data in Additive Manufacturing
Authors: Muhammad Fasih Waheed, Shonda Bernadin
Abstract: Vibration from an erroneous disturbance harms the manufactured components and lowers the output quality of an FDM printer. For moving machinery, vibration analysis and control are crucial. Additive manufacturing is the basis of 3D printing, which utilizes mechanical movement of the extruder to fabricate objects, and faults occur due to unwanted vibrations. Therefore, it is vital to examine the vibration patterns of a 3D printer. In this work, we observe these parameters of an FDM printer, exemplified by the MakerBot Method X. To analyze the system, it is necessary to understand the motion it generates and select appropriate sensors to detect those motions. The sensor measurement values can be used to determine the condition of the printer. We used an accelerometer and an acoustic sensor to measure the vibration and sound produced by the printer. The outputs from these sensors were examined individually. The findings show that vibration occurs at relatively low levels during continuous motion because it mainly appears at component transition edges. Due to abrupt acceleration and deceleration during zigzag motion, vibration reaches its peak.

Paper number 15:
Title: Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning
Authors: Jialin Zheng, Ruhaan Batta, Zhong Liu, Xiaonan Lu
Abstract: Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.

Paper number 16:
Title: Collaborative Safe Bayesian Optimization
Authors: Alina Castell Blasco, Maxime Bouton
Abstract: Mobile networks require safe optimization to adapt to changing conditions in traffic demand and signal transmission quality, in addition to improving service performance metrics. With the increasing complexity of emerging mobile networks, traditional parameter tuning methods become too conservative or complex to evaluate. For the first time, we apply safe Bayesian optimization to mobile networks. Moreover, we develop a new safe collaborative optimization algorithm called CoSBO, leveraging information from multiple optimization tasks in the network and considering multiple safety constraints. The resulting algorithm is capable of safely tuning the network parameter online with very few iterations. We demonstrate that the proposed method improves sample efficiency in the early stages of the optimization process by comparing it against the SafeOpt-MC algorithm in a mobile network scenario.

Paper number 17:
Title: Pinching Antennas-Aided Integrated Sensing and Multicast Communication Systems
Authors: Shan Shan, Chongjun Ouyang, Xiaohang Yang, Yong Li, Zhiqin Wang, Yuanwei Liu
Abstract: A pinching antennas (PAs)-aided integrated sensing and multicast communication framework is proposed. In this framework, the communication performance is measured by the multicast rate considering max-min fairness. Moreover, the sensing performance is quantified by the Bayesian Cramér-Rao bound (BCRB), where a Gauss-Hermite quadrature-based approach is proposed to compute the Bayesian Fisher information matrix. Based on these metrics, PA placement is optimized under three criteria: communications-centric (C-C), sensing-centric (S-C), and Pareto-optimal designs. These designs are investigated in two scenarios: the single-PA case and the multi-PA case. 1) For the single-PA case, a closed-form solution is derived for the location of the C-C transmit PA, while the S-C design yields optimal transmit and receive PA placements that are symmetric about the target location. Leveraging this geometric insight, the Pareto-optimal design is solved by enforcing this PA placement symmetry, thereby reducing the joint transmit and receive PA placement to the transmit PA optimization. 2) For the general multi-PA case, the PA placements constitute a highly non-convex optimization problem. To solve this, an element-wise alternating optimization-based method is proposed to sequentially optimize all PA placements for the S-C design, and is further incorporated into an augmented Lagrangian (AL) framework and a rate-profile formulation to solve the C-C and Pareto-optimal design problems, respectively. Numerical results show that: i) PASS substantially outperforms fixed-antenna baselines in both multicast rate and sensing accuracy; ii) the multicasting gain becomes more pronounced as the user density increases; and iii) the sensing accuracy improves with the number of deployed PAs.

Paper number 18:
Title: How Much Does Machine Identity Matter in Anomalous Sound Detection at Test Time?
Authors: Kevin Wilkinghoff, Keisuke Imoto, Zheng-Hua Tan
Abstract: Anomalous sound detection (ASD) benchmarks typically assume that the identity of the monitored machine is known at test time and that recordings are evaluated in a machine-wise manner. However, in realistic monitoring scenarios with multiple known machines operating concurrently, test recordings may not be reliably attributable to a specific machine, and requiring machine identity imposes deployment constraints such as dedicated sensors per machine. To reveal performance degradations and method-specific differences in robustness that are hidden under standard machine-wise evaluation, we consider a minimal modification of the ASD evaluation protocol in which test recordings from multiple machines are merged and evaluated jointly without access to machine identity at inference time. Training data and evaluation metrics remain unchanged, and machine identity labels are used only for post hoc evaluation. Experiments with representative ASD methods show that relaxing this assumption reveals performance degradations and method-specific differences in robustness that are hidden under standard machine-wise evaluation, and that these degradations are strongly related to implicit machine identification accuracy.

Paper number 19:
Title: Color-based Emotion Representation for Speech Emotion Recognition
Authors: Ryotaro Nagase, Ryoichi Takashima, Yoichi Yamashita
Abstract: Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.

Paper number 20:
Title: SeaSpoofFinder -- Potential GNSS Spoofing Event Detection Using AIS
Authors: Jón Winkel, Tom Willems, Cillian O'Driscoll, Ignacio Fernandez-Hernandez
Abstract: This paper investigates whether large-scale GNSS spoofing activity can be inferred from maritime Automatic Identification System (AIS) position reports. A data-processing framework, called SeaSpoofFinder, available here: this http URL, was developed to ingest and post-process global AIS streams and to detect candidate anomalies through a two-stage procedure. In Stage 1, implausible position jumps are identified using kinematic and data-quality filters; in Stage 2, events are retained only when multiple vessels exhibit spatially consistent source and target clustering, thereby reducing false positives from single-vessel artifacts. The resulting final potential spoofing events (FPSEs) reveal recurrent patterns in several regions, including the Baltic Sea, the Black Sea, Murmansk, Moscow, and the Haifa area, with affected footprints that can span large maritime areas. The analysis also highlights recurring non-spoofing artifacts (e.g., back-to-port jumps and data gaps) that can still pass heuristic filters in dense traffic regions. These results indicate that AIS-based monitoring can provide useful evidence for identifying and characterizing potential spoofing activity at scale, while emphasizing that AIS-only evidence does not provide definitive attribution.

Paper number 21:
Title: Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems
Authors: Miguel A. Trujillo, Rodrigo Aldana-López, David Gomez Gutierrez, Michael Defoort, Javier Ruiz Leon, Hector M. Becerra
Abstract: This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.

Paper number 22:
Title: Impact of Preprocessing on Neural Network-Based RSS/AoA Positioning
Authors: Omid Abbassi Aghda, Slavisa Tomic, Oussama Ben Haj Belkacem, Joao Guerreiro, Nuno Souto, Michal Szczachor, Rui Dinis
Abstract: Hybrid received signal strength (RSS)-angle of arrival (AoA)-based positioning offers low-cost distance estimation and high-resolution angular measurements. Still, it comes at a cost of inherent nonlinearities, geometry-dependent noise, and suboptimal weighting in conventional linear estimators that might limit accuracy. In this paper, we propose a neural network-based approach using a multilayer perceptron (MLP) to directly map RSS-AoA measurements to 3D positions, capturing nonlinear relationships that are difficult to model with traditional methods. We evaluate the impact of input representation by comparing networks trained on raw measurements versus preprocessed features derived from a linearization method. Simulation results show that the learning-based approach consistently outperforms existing linear methods under RSS noise across all noise levels, and matches or surpasses state-of-the-art performance under increasing AoA noise. Furthermore, preprocessing measurements using the linearization method provides a clear advantage over raw data, demonstrating the benefit of geometry-aware feature extraction.

Paper number 23:
Title: RefineFormer3D: Efficient 3D Medical Image Segmentation via Adaptive Multi-Scale Transformer with Cross Attention Fusion
Authors: Kavyansh Tyagi, Vishwas Rathi, Puneet Goyal
Abstract: Accurate and computationally efficient 3D medical image segmentation remains a critical challenge in clinical workflows. Transformer-based architectures often demonstrate superior global contextual modeling but at the expense of excessive parameter counts and memory demands, restricting their clinical deployment. We propose RefineFormer3D, a lightweight hierarchical transformer architecture that balances segmentation accuracy and computational efficiency for volumetric medical imaging. The architecture integrates three key components: (i) GhostConv3D-based patch embedding for efficient feature extraction with minimal redundancy, (ii) MixFFN3D module with low-rank projections and depthwise convolutions for parameter-efficient feature extraction, and (iii) a cross-attention fusion decoder enabling adaptive multi-scale skip connection integration. RefineFormer3D contains only 2.94M parameters, substantially fewer than contemporary transformer-based methods. Extensive experiments on ACDC and BraTS benchmarks demonstrate that RefineFormer3D achieves 93.44\% and 85.9\% average Dice scores respectively, outperforming or matching state-of-the-art methods while requiring significantly fewer parameters. Furthermore, the model achieves fast inference (8.35 ms per volume on GPU) with low memory requirements, supporting deployment in resource-constrained clinical environments. These results establish RefineFormer3D as an effective and scalable solution for practical 3D medical image segmentation.

Paper number 24:
Title: Joint beamforming and mode optimization for multi-functional STAR-RIS-aided integrated sensing and communication networks
Authors: Ziming Liu, Tao Chen, Giacinto Gelli, Vincenzo Galdi, Francesco Verde
Abstract: This paper investigates the design of integrated sensing and communication (ISAC) systems assisted by simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs), which act as multi-functional programmable metasurfaces capable of supporting concurrent communication and sensing within a unified architecture. We propose a two-stage ISAC protocol, in which the preparation phase performs direction estimation for outdoor users located in the reflection space, while maintaining communication with both outdoor and indoor users in the transmission space. The subsequent communication phase exploits the estimated directions to enhance information transfer. The directions of outdoor users are modeled as Gaussian random variables to capture estimation uncertainty, and the corresponding average communication performance is incorporated into the design. Building on this framework, we formulate a performance-balanced optimization problem that maximizes the communication sum-rate while guaranteeing the required sensing accuracy, jointly determining the beamforming vectors at the base station (BS), the STAR-RIS transmission and reflection coefficients, and the metasurface partition between energy-splitting and transmit-only modes. The physical constraints of STAR-RIS elements and the required sensing performance are explicitly enforced. To address the non-convex nature of the problem, we combine fractional programming, Lagrangian dual reformulation, and successive convex approximation. The binary metasurface partition is ultimately recovered via continuous relaxation followed by projection-based binarization. Numerical results demonstrate that the proposed design achieves an effective trade-off between sensing accuracy and communication throughput, by significantly outperforming conventional STAR-RIS-aided ISAC schemes.

Paper number 25:
Title: Multi-Channel Replay Speech Detection using Acoustic Maps
Authors: Michael Neri, Tuomas Virtanen
Abstract: Replay attacks remain a critical vulnerability for automatic speaker verification systems, particularly in real-time voice assistant applications. In this work, we propose acoustic maps as a novel spatial feature representation for replay speech detection from multi-channel recordings. Derived from classical beamforming over discrete azimuth and elevation grids, acoustic maps encode directional energy distributions that reflect physical differences between human speech radiation and loudspeaker-based replay. A lightweight convolutional neural network is designed to operate on this representation, achieving competitive performance on the ReMASC dataset with approximately 6k trainable parameters. Experimental results show that acoustic maps provide a compact and physically interpretable feature space for replay attack detection across different devices and acoustic environments.

Paper number 26:
Title: Online Single-Channel Audio-Based Sound Speed Estimation for Robust Multi-Channel Audio Control
Authors: Andreas Jonas Fuglsig, Mads Græsbøll Christensen, Jesper Rindom Jensen
Abstract: Robust spatial audio control relies on accurate acoustic propagation models, yet environmental variations, especially changes in the speed of sound, cause systematic mismatches that degrade performance. Existing methods either assume known sound speed, require multiple microphones, or rely on separate calibration, making them impractical for systems with minimal sensing. We propose an online sound speed estimator that operates during general multichannel audio playback and requires only a single observation microphone. The method exploits the structured effect of sound speed on the reproduced signal and estimates it by minimizing the mismatch between the measured audio and a parametric acoustic model. Simulations show accurate tracking of sound speed for diverse input signals and improved spatial control performance when the estimates are used to compensate propagation errors in a sound zone control framework.

Paper number 27:
Title: Reconstruction of Piecewise-Constant Sparse Signals for Modulo Sampling
Authors: Haruka Kobayashi, Ryo Hayakawa
Abstract: Modulo sampling is a promising technology to preserve amplitude information that exceeds the observable range of analog-to-digital converters during the digitization of analog signals. Since conventional methods typically reconstruct the original signal by estimating the differences of the residual signal and computing their cumulative sum, each estimation error inevitably propagates through subsequent time samples. In this paper, to eliminate this error-propagation problem, we propose an algorithm that reconstructs the residual signal directly. The proposed method takes advantage of the high-frequency characteristics of the modulo samples and the sparsity of both the residual signal and its difference. Simulation results show that the proposed method reconstructs the original signal more accurately than a conventional method based on the differences of the residual signal.

Paper number 28:
Title: SELEBI: Percussion-aware Time Stretching via Selective Magnitude Spectrogram Compression by Nonstationary Gabor Transform
Authors: Natsuki Akaishi, Nicki Holighaus, Kohei Yatabe
Abstract: Phase vocoder-based time-stretching is a widely used technique for the time-scale modification of audio signals. However, conventional implementations suffer from ``percussion smearing,'' a well-known artifact that significantly degrades the quality of percussive components. We attribute this artifact to a fundamental time-scale mismatch between the temporally smeared magnitude spectrogram and the localized, newly generated phase. To address this, we propose SELEBI, a signal-adaptive phase vocoder algorithm that significantly reduces percussion smearing while preserving stability and the perfect reconstruction property. Unlike conventional methods that rely on heuristic processing or component separation, our approach leverages the nonstationary Gabor transform. By dynamically adapting analysis window lengths to assign short windows to intervals containing significant energy associated with percussive components, we directly compute a temporally localized magnitude spectrogram from the time-domain signal. This approach ensures greater consistency between the temporal structures of the magnitude and phase. Furthermore, the perfect reconstruction property of the nonstationary Gabor transform guarantees stable, high-fidelity signal synthesis, in contrast to previous heuristic approaches. Experimental results demonstrate that the proposed method effectively mitigates percussion smearing and yields natural sound quality.

Paper number 29:
Title: Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model
Authors: Ahmet Halici, Ece Tugba Cebeci, Musa Balci, Mustafa Cini, Serkan Sokmen
Abstract: Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.

Paper number 30:
Title: Proof of Concept: Local TX Real-Time Phase Calibration in MIMO Systems
Authors: Carl Collmann, Ahmad Nimr, Gerhard Fettweis
Abstract: Channel measurements in MIMO systems hinge on precise synchronization. While methods for time and frequency synchronization are well established, maintaining real-time phase coherence remains an open requirement for many MIMO systems. Phase coherence in MIMO systems is crucial for beamforming in digital arrays and enables precise parameter estimates such as Angle-of-Arrival/Departure. This work presents and validates a simple local real-time phase calibration method for a digital array. We compare two different approaches, instantaneous and smoothed calibration, to determine the optimal interval between synchronization procedures. To quantitatively assess calibration performance, we use two metrics: the average beamforming power loss and the RMS cycle-to-cycle jitter. Our results indicate that both approaches for phase calibration are effective and yield RMS of jitter in the 2.1 ps to 124 fs range for different SDR models. This level of precision enables coherent transmission on commonly available SDR platforms, allowing investigation on advanced MIMO techniques and transmit beamforming in practical testbeds.

Paper number 31:
Title: Certifying Hamilton-Jacobi Reachability Learned via Reinforcement Learning
Authors: Prashant Solanki, Isabelle El-Hajj, Jasper J. van Beers, Erik-Jan van Kampen, Coen C. de Visser
Abstract: We present a framework to \emph{certify} Hamilton--Jacobi (HJ) reachability learned by reinforcement learning (RL). Building on a discounted initial time \emph{travel-cost} formulation that makes small-step RL value iteration provably equivalent to a forward Hamilton--Jacobi (HJ) equation with damping, we convert certified learning errors into calibrated inner/outer enclosures of strict backward reachable tube. The core device is an additive-offset identity: if $W_\lambda$ solves the discounted travel-cost Hamilton--Jacobi--Bellman (HJB) equation, then $W_\varepsilon:=W_\lambda + \varepsilon$ solves the same PDE with a constant offset $\lambda\varepsilon$. This means that a uniform value error is \emph{exactly} equal to a constant HJB offset. We establish this uniform value error via two routes: (A) a Bellman operator-residual bound, and (B) a HJB PDE-slack bound. Our framework preserves HJ-level safety semantics and is compatible with deep RL. We demonstrate the approach on a double-integrator system by formally certifying, via satisfiability modulo theories (SMT), a value function learned through reinforcement learning to induce provably correct inner and outer backward-reachable set enclosures over a compact region of interest.

Paper number 32:
Title: Failure-Aware Access Point Selection for Resilient Cell-Free Massive MIMO Networks
Authors: Mostafa Rahmani Ghourtani, Junbo Zhao, Yi Chu, Hamed Ahmadi, David Grace, Alister G. Burr
Abstract: This paper presents a Failure-Aware Access Point Selection (FAAS) method aimed at improving hardware resilience in cell-free massive MIMO (CF-mMIMO) networks. FAAS selects APs for each user by jointly considering channel strength and the failure probability of each AP. A tunable parameter \(\alpha \in [0,1]\) scales these failure probabilities to model different levels of network stress. We evaluate resilience using two key metrics: the minimum-user spectral efficiency, which captures worst-case user performance, and the outage probability, defined as the fraction of users left without any active APs. Simulation results show that FAAS maintains significantly better performance under failure conditions compared to failure-agnostic clustering. At high failure levels, FAAS reduces outage by over 85\% and improves worst-case user rates. These results confirm that FAAS is a practical and efficient solution for building more reliable CF-mMIMO networks.

Paper number 33:
Title: Optimal Placement and Sizing of PV-Based DG Units in a Distribution Network Considering Loading Capacity
Authors: Abhinav Sharma, Pratyush Chakraborty, Manoj Datta, Kazi N. Hasan
Abstract: This research paper proposes an efficient methodology for the allocation of multiple photovoltaic (PV)-based distributed generation (DG) units in the radial distribution network (RDN), while considering the loading capacity of the network. The proposed method is structured using a two-stage approach. In the first stage, the additional active power loading capacity of the network and each individual bus is determined using an iterative approach. This analysis quantifies the network's additional active loadability limits and identifies buses with high active power loading capacity, which are considered candidate nodes for the placement of DG units. Subsequently, in the second stage, the optimal locations and sizes of DG units are determined using the Monte Carlo method, with the objectives of minimizing voltage deviation and reducing active power losses in the network. The methodology is validated on the standard IEEE 33-bus RDN to determine the optimal locations and sizes of DG units. The results demonstrate that the optimal allocation of one, two, and three DG units, achieved from proposed method, reduces network active power losses by 50.37%, 58.62%, and 65.16%, respectively, and also significantly enhances the voltage profile across all buses. When the obtained results are compared with the results of several existing studies, it is found that the proposed method allows for larger DG capacities and maintains better voltage profiles throughout the RDN.

Paper number 34:
Title: WindDensity-MBIR: Model-Based Iterative Reconstruction for Wind Tunnel 3D Density Estimation
Authors: Karl J. Weisenburger, Gregery T. Buzzard, Charles A. Bouman, Matthew R. Kemnetz
Abstract: Experimentalists often use wind tunnels to study aerodynamic turbulence, but most wind tunnel imaging techniques are limited in their ability to take non-invasive 3D density measurements of turbulence. Wavefront tomography is a technique that uses multiple wavefront measurements from various viewing angles to non-invasively measure the 3D density field of a turbulent medium. Existing methods make strong assumptions, such as a spline basis representation, to address the ill-conditioned nature of this problem. We formulate this problem as a Bayesian, sparse-view tomographic reconstruction problem and develop a model-based iterative reconstruction algorithm for measuring the volumetric 3D density field inside a wind tunnel. We call this method WindDensity-MBIR and apply it using simulated data to difficult reconstruction scenarios with sparse data, small projection field of view, and limited angular extent. WindDensity-MBIR can recover high-order features in these scenarios within 10% to 25% error even when the tip, tilt, and piston are removed from the wavefront measurements.

Paper number 35:
Title: Active RIS-Assisted MIMO System for Vital Signs Extraction: ISAC Modeling, Deep Learning, and Prototype Measurements
Authors: De-Ming Chian, Chao-Kai Wen, Feng-Ji Chen, Yi-Jie Sun, Fu-Kang Wang
Abstract: We present the RIS-VSign system, an active reconfigurable intelligent surface (RIS)-assisted multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) framework for vital signs extraction under an integrated sensing and communication (ISAC) model. The system consists of two stages: the phase selector of RIS and the extraction of respiration rate. To mitigate synchronization-induced common phase drifts, the difference of Möbius transformation (DMT) is integrated into the deep learning framework, named DMTNet, to jointly configure multiple active RIS elements. Notably, the training data are generated in simulation without collecting real-world measurements, and the resulting phase selector is validated experimentally. For sensing, multi-antenna measurements are fused by the DC-offset calibration and the DeepMining-MMV processing with CA-CFAR detection and Newton's refinements. Prototype experiments indicate that active RIS deployment improves respiration detectability while simultaneously enabling higher-order modulation; without RIS, respiration detection is unreliable and only lower-order modulation is supported.

Paper number 36:
Title: A Koopman-Bayesian Framework for High-Fidelity, Perceptually Optimized Haptic Surgical Simulation
Authors: Rohit Kaushik, Eva Kaushik
Abstract: We introduce a unified framework that combines nonlinear dynamics, perceptual psychophysics and high frequency haptic rendering to enhance realism in surgical simulation. The interaction of the surgical device with soft tissue is elevated to an augmented state space with a Koopman operator formulation, allowing linear prediction and control of the dynamics that are nonlinear by nature. To make the rendered forces consistent with human perceptual limits, we put forward a Bayesian calibration module based on WeberFechner and Stevens scaling laws, which progressively shape force signals relative to each individual's discrimination thresholds. For various simulated surgical tasks such as palpation, incision, and bone milling, the proposed system attains an average rendering latency of 4.3 ms, a force error of less than 2.8% and a 20% improvement in perceptual discrimination. Multivariate statistical analyses (MANOVA and regression) reveal that the system's performance is significantly better than that of conventional spring-damper and energy, based rendering methods. We end by discussing the potential impact on surgical training and VR, based medical education, as well as sketching future work toward closed, loop neural feedback in haptic interfaces.

Paper number 37:
Title: VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation
Authors: Anna Gelencsér-Horváth, Gergely Dinya, Dorka Boglárka Erős, Péter Halász, Islam Muhammad Muqsit, Kristóf Karacs
Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

Paper number 38:
Title: Including Node Textual Metadata in Laplacian-constrained Gaussian Graphical Models
Authors: Jianhua Wang, Killian Cressant, Pedro Braconnot Velloso, Arnaud Breloy
Abstract: This paper addresses graph learning in Gaussian Graphical Models (GGMs). In this context, data matrices often come with auxiliary metadata (e.g., textual descriptions associated with each node) that is usually ignored in traditional graph estimation processes. To fill this gap, we propose a graph learning approach based on Laplacian-constrained GGMs that jointly leverages the node signals and such metadata. The resulting formulation yields an optimization problem, for which we develop an efficient majorization-minimization (MM) algorithm with closed-form updates at each iteration. Experimental results on a real-world financial dataset demonstrate that the proposed method significantly improves graph clustering performance compared to state-of-the-art approaches that use either signals or metadata alone, thus illustrating the interest of fusing both sources of information.

Paper number 39:
Title: ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios
Authors: Kevin Kai-Chun Chang, Ekin Beyazit, Alberto Sangiovanni-Vincentelli, Tichakorn Wongpiromsarn, Sanjit A. Seshia
Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at this https URL.

Paper number 40:
Title: Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization
Authors: Théo Ayral, Saifeddine Aloui, Mathieu Grossard
Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

Paper number 41:
Title: ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding
Authors: Megan Lee, Seung Ha Hwang, Inhyeok Choi, Shreyas Darade, Mengchun Zhang, Kateryna Shapovalenko
Abstract: Cross-subject generalization in EEG-based brain-computer interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features exhibit consistently higher cross-subject similarity than temporal signals. Motivated by this observation, we introduce ASPEN, a hybrid architecture that combines spectral and temporal feature streams via multiplicative fusion, requiring cross-modal agreement for features to propagate. Experiments across six benchmark datasets reveal that ASPEN is able to dynamically achieve the optimal spectral-temporal balance depending on the paradigm. ASPEN achieves the best unseen-subject accuracy on three of six datasets and competitive performance on others, demonstrating that multiplicative multimodal fusion enables effective cross-subject generalization.

Paper number 42:
Title: SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks
Authors: Zirui Zang, Ahmad Amine, Nick-Marios T. Kokolakis, Truong X. Nghiem, Ugo Rosolia, Rahul Mangharam
Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

Paper number 43:
Title: Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics
Authors: Ahmad Amine, Kabir Puri, Viet-Anh Le, Rahul Mangharam
Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

Paper number 44:
Title: How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability
Authors: MHD Saria Allahham, Hossam S. Hassanein
Abstract: Extreme Edge Computing (XEC) distributes streaming workloads across consumer-owned devices, exploiting their proximity to users and ubiquitous availability. Many such workloads are AI-driven, requiring continuous neural network inference for tasks like object detection and video analytics. Distributed Inference (DI), which partitions model execution across multiple edge devices, enables these streaming services to meet strict throughput and latency requirements. Yet consumer devices exhibit volatile computational availability due to competing applications and unpredictable usage patterns. This volatility poses a fundamental challenge: how can we quantify the probability that a device, or ensemble of devices, will maintain the processing rate required by a streaming service? This paper presents an analytical framework for computational reliability in XEC, defined as the probability that instantaneous capacity meets demand at a specified Quality of Service (QoS) threshold. We derive closed-form reliability expressions under two information regimes: Minimal Information (MI), requiring only declared operational bounds, and historical data, which refines estimates via Maximum Likelihood Estimation from past observations. The framework extends to multi-device deployments, providing reliability expressions for series, parallel, and partitioned workload configurations. We derive optimal workload allocation rules and analytical bounds for device selection, equipping orchestrators with tractable tools to evaluate deployment feasibility and configure distributed streaming systems. We validate the framework using real-time object detection with YOLO11m model as a representative DI streaming workload; experiments on emulated XED environments demonstrate close agreement between analytical predictions, Monte Carlo sampling, and empirical measurements across diverse capacity and demand configurations.

Paper number 45:
Title: Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA
Authors: Kamil Jeziorek, Piotr Wzorek, Krzysztof Blachut, Hiroshi Nakano, Manon Dampfhoffer, Thomas Mesquida, Hiroaki Nishi, Thomas Dalgaty, Tomasz Kryjak
Abstract: As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.

Paper number 46:
Title: Enhanced Connectivity in Ambient Backscatter Communications via Fluid Antenna Readers
Authors: Masoud Kaveh, Farshad Rostami Ghadi, Riku Jantti, Kai-Kit Wong, F. Javier Lopez-Martinez
Abstract: Ambient backscatter communication (AmBC) enables ultra-low-power connectivity by allowing passive backscatter devices (BDs) to convey information through reflection of ambient signals. However, the cascaded AmBC channel suffers from severe double path loss and multiplicative fading, while accurate channel state information (CSI) acquisition is highly challenging due to the weak backscattered signal and the resource-limited nature of BDs. To address these challenges, this paper considers an AmBC system in which the reader is equipped with a pixel-based fluid antenna system (FAS). By dynamically selecting one antenna position from a dense set of pixels within a compact aperture, the FAS-enabled reader exploits spatial diversity through measurement-driven port selection, without requiring explicit CSI acquisition or multiple RF chains. The intrinsic rate-energy tradeoff at the BD is also incorporated by jointly optimizing the backscatter modulation coefficient under an energy harvesting (EH) neutrality constraint. To efficiently solve this problem, a particle swarm optimization (PSO)-based framework is developed to jointly determine the FAS port selection and modulation coefficient on an optimize-then-average (OTA) basis. Simulation results show that the proposed scheme significantly improves the achievable rate compared with conventional single-antenna readers, with gains preserved under imperfect observations, stringent EH constraints, and different pixel spacings.

Paper number 47:
Title: Continuous Fluid Antenna Sampling for Channel Estimation in Cell-Free Massive MIMO
Authors: Masoud Kaveh, Farshad Rostami Ghadi, Francisco Hernando-Gallego, Diego Martin, Riku Jantti, Kai-Kit Wong
Abstract: In this letter, we develop a continuous fluid antenna (FA) framework for uplink channel estimation in cell-free massive multiple-input and multiple-output (CF-mMIMO) systems. By modeling the wireless channel as a spatially correlated Gaussian random field, channel estimation is formulated as a Gaussian process (GP) regression problem with motion-constrained spatial sampling. Closed-form expressions for the linear minimum mean squared error (LMMSE) estimator and the corresponding estimation error are derived. A fundamental comparison with discrete port-based architectures is established under identical position constraints, showing that continuous FA sampling achieves equal or lower estimation error for any finite pilot budget, with strict improvement for non-degenerate spatial correlation models. Numerical results validate the analysis and show the performance gains of continuous FA sampling over discrete baselines.

Paper number 48:
Title: Nonparametric Kernel Regression for Coordinated Energy Storage Peak Shaving with Stacked Services
Authors: Emily Logan, Ning Qi, Bolun Xu
Abstract: Developing effective control strategies for behind-the-meter energy storage to coordinate peak shaving and stacked services is essential for reducing electricity costs and extending battery lifetime in commercial buildings. This work proposes an end-to-end, two-stage framework for coordinating peak shaving and energy arbitrage with a theoretical decomposition guarantee. In the first stage, a non-parametric kernel regression model constructs state-of-charge trajectory bounds from historical data that satisfy peak-shaving requirements. The second stage utilizes the remaining capacity for energy arbitrage via a transfer learning method. Case studies using New York City commercial building demand data show that our method achieves a 1.3 times improvement in performance over the state-of-the-art forecast-based method, achieving cost savings and effective peak management without relying on predictions.

Paper number 49:
Title: Consensus Based Task Allocation for Angles-Only Local Catalog Maintenance of Satellite Systems
Authors: Harrison Perone, Christopher W. Hays
Abstract: In order for close proximity satellites to safely perform their missions, the relative states of all satellites and pieces of debris must be well understood. This presents a problem for ground based tracking and orbit determination since it may not be practical to achieve the required accuracy. Using space-based sensors allows for more accurate relative state estimates, especially if multiple satellites are allowed to communicate. Of interest to this work is the case where several communicating satellites each need to maintain a local catalog of communicating and non-communicating objects using angles-only limited field of view (FOV) measurements. However, this introduces the problem of efficiently scheduling and coordinating observations among the agents. This paper presents a decentralized task allocation algorithm to address this problem and quantifies its performance in terms of fuel usage and overall catalog uncertainty via numerical simulation. It was found that the new method significantly outperforms the uncertainty-fuel Pareto frontier formed by current approaches.

Paper number 50:
Title: Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens
Authors: Potsawee Manakul, Woody Haosheng Gan, Martijn Bartelds, Guangzhi Sun, William Held, Diyi Yang
Abstract: Current audio language models are predominantly text-first, either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, limiting general audio modeling. This paper presents a systematic empirical study of native audio foundation models that apply next-token prediction to audio at scale, jointly modeling semantic content, acoustic details, and text to support both general audio generation and cross-modal capabilities. We provide comprehensive empirical insights for building such models: (1) We systematically investigate design choices -- data sources, text mixture ratios, and token composition -- establishing a validated training recipe. (2) We conduct the first scaling law study for discrete audio models via IsoFLOP analysis on 64 models spanning $3{\times}10^{18}$ to $3{\times}10^{20}$ FLOPs, finding that optimal data grows 1.6$\times$ faster than optimal model size. (3) We apply these lessons to train SODA (Scaling Open Discrete Audio), a suite of models from 135M to 4B parameters on 500B tokens, comparing against our scaling predictions and existing models. SODA serves as a flexible backbone for diverse audio/text tasks -- we demonstrate this by fine-tuning for voice-preserving speech-to-speech translation, using the same unified architecture.

Paper number 51:
Title: The Role of Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems
Authors: Shreya Meel, Sennur Ulukus
Abstract: In symmetric private information retrieval (SPIR), a user communicates with multiple servers to retrieve from them a message in a database, while not revealing the message index to any individual server (user privacy), and learning no additional information about the database (database privacy). We study the problem of SPIR on graph-replicated database systems, where each node of the graph represents a server and each link represents a message. Each message is replicated at exactly two servers; those at which the link representing the message is incident. To ensure database privacy, the servers share a set of common randomness, independent of the database and the user's desired message index. We study two cases of common randomness distribution to the servers: i) graph-replicated common randomness, and ii) fully-replicated common randomness. Given a graph-replicated database system, in i), we assign one randomness variable independently to every pair of servers sharing a message, while in ii), we assign an identical set of randomness variable to all servers, irrespective of the underlying graph. In both settings, our goal is to characterize the SPIR capacity, i.e., the maximum number of desired message symbols retrieved per downloaded symbol, and quantify the minimum amount of common randomness required to achieve the capacity. To this goal, in setting i), we derive a general lower bound on the SPIR capacity, and show it to be tight for path and regular graphs through a matching converse. Moreover, we establish that the minimum size of common randomness required for SPIR is equal to the message size. In setting ii), the SPIR capacity improves over the first, more restrictive setting. We show this through capacity lower bounds for a class of graphs, by constructing SPIR schemes from PIR schemes.

Paper number 52:
Title: Less is More: Skim Transformer for Light Field Image Super-resolution
Authors: Zeke Zexi Hu, Haodong Chen, Hui Ye, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen, Weidong Cai
Abstract: A light field image captures scenes through its micro-lens array, providing a rich representation that encompasses spatial and angular information. While this richness comes at significant data redundancy, most existing methods tend to indiscriminately utilize all the information from sub-aperture images (SAIs) in an attempt to harness every visual cue regardless of their disparity significance. However, this paradigm inevitably leads to disparity entanglement, a fundamental cause of inefficiency in light field image processing. To address this limitation, we introduce the Skim Transformer, a novel architecture inspired by the "less is more" philosophy. It features a multi-branch structure where each branch is dedicated to a specific disparity range by constructing its attention score matrix over a skimmed subset of SAIs, rather than all of them. Building upon it, we present SkimLFSR, an efficient yet powerful network for light field image super-resolution. Requiring only 67% of the prior leading method's parameters}, SkimLFSR achieves state-of-the-art results surpassing the best existing method by 0.63 dB and 0.35 dB PSNR at the 2x and 4x tasks, respectively. Through in-depth analyses, we reveal that SkimLFSR, guided by the predefined skimmed SAI sets as prior knowledge, demonstrates distinct disparity-aware behaviors in attending to visual cues. Last but not least, we conduct an experiment to validate SkimLFSR's generalizability across different angular resolutions, where it achieves competitive performance on a larger angular resolution without any retraining or major network modifications. These findings highlight its effectiveness and adaptability as a promising paradigm for light field image processing.

Paper number 53:
Title: Probabilistic Flexibility Aggregation of DERs for Ancillary Services Provision
Authors: Matthieu Jacobs, Mario Paolone
Abstract: This paper presents a grid-aware probabilistic approach to compute the aggregated flexibility at the grid connection point (GCP) of active distribution networks (ADNs) to allow the participation of DERs in ancillary services (AS) markets. Specifically an optimal power flow (OPF) method using a linear network model is used to compute the aggregated capability for the provision of multiple AS. We start from the method proposed in [1] and extend it to allow for optimizing the provision of multiple services simultaneously, ensure cost-effectiveness of the used DERs and handle uncertainties in a probabilistic way. The allocation of individual DERs power flexibilities accounts for the operational costs associated to the provision of different services and ensures cost-effectiveness while maximizing the value of the advertised aggregated flexibility, assuming known service prices. Empirical uncertainty sets are obtained to achieve a predefined coverage of the probability distribution in line with recent developments in the Nordic AS markets. Finally, a feeder-decomposition approach is proposed to ensure the methods applicability to realistic distribution networks with a large number of buses. Different case studies show the effectiveness of the method, highlight the importance of accounting for network constraints and illustrate its applicability to realistic distribution systems.

Paper number 54:
Title: Filter2Noise: A Framework for Interpretable and Zero-Shot Low-Dose CT Image Denoising
Authors: Yipeng Sun, Linda-Sophie Schneider, Siyuan Mei, Jinhua Wang, Ge Hu, Mingxuan Gu, Chengze Ye, Fabian Wagner, Lan Song, Siming Bayer, Andreas Maier
Abstract: Noise in low-dose computed tomography (LDCT) can obscure important diagnostic details. While deep learning offers powerful denoising, supervised methods require impractical paired data, and self-supervised alternatives often use opaque, parameter-heavy networks that limit clinical trust. We propose Filter2Noise (F2N), a novel self-supervised framework for interpretable, zero-shot denoising from a single LDCT image. Instead of a black-box network, its core is an Attention-Guided Bilateral Filter, a transparent, content-aware mathematical operator. A lightweight attention module predicts spatially varying filter parameters, making the process transparent and allowing interactive radiologist control. To learn from a single image with correlated noise, we introduce a multi-scale self-supervised loss coupled with Euclidean Local Shuffle (ELS) to disrupt noise patterns while preserving anatomical integrity. On the Mayo Clinic LDCT Challenge, F2N achieves state-of-the-art results, outperforming competing zero-shot methods by up to 3.68 dB in PSNR. It accomplishes this with only 3.6k parameters, orders of magnitude fewer than competing models, which accelerates inference and simplifies deployment. By combining high performance with transparency, user control, and high parameter efficiency, F2N offers a trustworthy solution for LDCT enhancement. We further demonstrate its applicability by validating it on clinical photon-counting CT data. Code is available at: this https URL.

Paper number 55:
Title: On the Robustness of RSMA to Adversarial BD-RIS-Induced Interference
Authors: Arthur S. de Sena, Jacek Kibilda, Nurul H. Mahmood, Andre Gomes, Luiz A. DaSilva, Matti Latva-aho
Abstract: This article investigates the robustness of rate-splitting multiple access (RSMA) in multi-user multiple-input single-output (MISO) systems to interference attacks against channel acquisition induced by beyond-diagonal RISs (BD-RISs). Two primary attack strategies, random and aligned interference, are proposed for fully connected and group-connected reconfigurable intelligent surface (RIS) architectures. Valid random reflection coefficients are generated exploiting the Takagi factorization, while potent aligned interference attacks are achieved through optimization strategies based on a quadratically constrained quadratic program (QCQP) reformulation followed by projections onto the unitary manifold. Our numerical findings reveal that, when perfect channel state information (CSI) is available, RSMA behaves similarly to space-division multiple access (SDMA) and thus is highly susceptible to the attack, with BD-RIS inducing severe performance loss and significantly outperforming diagonal RIS. However, under imperfect CSI, RSMA consistently demonstrates significantly greater robustness than SDMA, particularly as the system's transmit power increases.

Paper number 56:
Title: Spiking control systems for soft robotics: a rhythmic case study in a soft robotic crawler
Authors: Juncal Arbelaiz, Alessio Franci, Naomi Ehrich Leonard, Rodolphe Sepulchre, Bassam Bamieh
Abstract: Inspired by spiking neural feedback, we propose a spiking controller for efficient locomotion in a soft robotic crawler. Its bistability, akin to neural fast positive feedback, combined with a sensorimotor slow negative feedback loop, generates rhythmic spiking. The closed-loop system is robust through the quantized actuation, and negative feedback ensures efficient locomotion with minimal external tuning. Using bifurcation analysis, we characterize how the sensorimotor gain-coupling body and controller dynamics-governs the emergence of qualitatively distinct dynamical regimes, including resting and crawling behaviors associated with peristaltic waves. Dimensional analysis formalizes a separation of mechanical and electrical timescales, and Geometric Singular Perturbation theory explains the geometry of the relaxation oscillations leading to endogenous crawling. Within this singularly perturbed framework, we further formulate and analytically solve an optimization problem, proving that locomotion speed is maximized when mechanical resonance is achieved via a matching of neuromechanical scales. Given the importance and ubiquity of rhythms and waves in soft-bodied locomotion, we envision that spiking control systems could be utilized in a variety of soft-robotic morphologies and modular distributed architectures, yielding significant robustness, adaptability, and energetic gains across scales.

Paper number 57:
Title: Extended Version: Characterizing Distributed Photovoltaic Panel Investment Equilibria
Authors: Mehdi Davoudi, Junjie Qin, Xiaojun Lin
Abstract: This study investigates long-term investment decisions in distributed photovoltaic panels by individual investors. We consider a setting where investment decisions are driven by expected revenue from participating in short-term electricity markets over the panel lifespan. These revenues depend on short-term market equilibria, i.e., prices and allocations, which are influenced by aggregate invested panel capacity participating in the markets. We model the interactions among investors by a non-atomic game and develop a framework that links short-term market equilibria to the resulting long-term investment equilibrium. Then, within this framework, we analyze three market mechanisms: (a) a single-product real-time energy market, (b) a product-differentiated real-time energy market that treats solar energy and grid energy as different products, and (c) a contract-based panel market that trades claims/rights to the production of certain panel capacity ex-ante, rather than the realized solar production ex-post. For each, we derive expressions for short-term equilibria and the associated expected revenues, and analytically characterize the corresponding long-term Nash equilibrium aggregate capacity. We compare the solutions of these characterizing equations under different conditions and theoretically establish that the product-differentiated market always supports socially optimal investment, while the single-product market consistently results in under-investment. We also establish that the contract-based market leads to over-investment when the extra valuations of users for solar energy are small. Finally, we validate our theoretical results through numerical experiments.

Paper number 58:
Title: Strategic Data Center Load Shifting: Implications for Market Efficiency and Transmission Value
Authors: Aron Brenner, Line Roald, Saurabh Amin
Abstract: Data center electricity use may reach 12% of U.S. demand by 2030, alongside growing ability to shift workloads geographically in response to prices or carbon signals. We examine the system-level implications of such strategic flexibility using a bilevel two-zone model that couples economic dispatch with consumer cost minimization. Two market failures emerge. First, discontinuous price changes at generator capacity limits can induce flexible consumers to shift load in socially inefficient directions; for example, toward a higher-cost region to trigger a price drop elsewhere. Second, by positioning near capacity boundaries, consumers can counteract the marginal benefit of transmission expansion: although shadow prices suggest additional capacity is valuable, strategic consumers reoptimize to offset resulting flow changes, leaving dispatch and costs unchanged. We derive conditions under which these effects arise and show that conventional price signals can misrepresent system value in the presence of large spatially flexible loads.

Paper number 59:
Title: Reliability entails input-selective contraction and regulation in excitable networks
Authors: Michelangelo Bin, Alessandro Cecconi, Lorenzo Marconi
Abstract: The animal nervous system offers a model of computation combining digital reliability and analog efficiency. Understanding how this sweet spot can be realized is a core question of neuromorphic engineering. To this aim, this paper explores the connection between reliability, contraction, and regulation in excitable systems. Using the FitzHugh-Nagumo model of excitable behavior as a proof-of-concept, it is shown that neuronal reliability can be formalized as an average trajectory contraction property induced by the input. In excitable networks, reliability is shown to enable regulation of the network to a robustly stable steady state. It is thus posited that regulation provides a notion of dynamical analog computation, and that stability makes such a computation model robust.

Paper number 60:
Title: ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC
Authors: Mehdi Zafari, A. Lee Swindlehurst
Abstract: Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.

Paper number 61:
Title: BEST-STD2.0: Balanced and Efficient Speech Tokenizer for Spoken Term Detection
Authors: Anup Singh, Vipul Arora, Kris Demuynck
Abstract: Fast and accurate spoken content retrieval is vital for applications such as voice search. Query-by-Example Spoken Term Detection (STD) involves retrieving matching segments from an audio database given a spoken query. Token-based STD systems, which use discrete speech representations, enable efficient search but struggle with robustness to noise and reverberation, and with inefficient token utilization. We address these challenges by proposing a noise and reverberation-augmented training strategy to improve tokenizer robustness. In addition, we introduce optimal transport-based regularization to ensure balanced token usage and enhance token efficiency. To further speed up retrieval, we adopt a TF-IDF-based search mechanism. Empirical evaluations demonstrate that the proposed method outperforms STD baselines across various distortion levels while maintaining high search efficiency.

Paper number 62:
Title: Rotterdam artery-vein segmentation (RAV) dataset
Authors: Jose Vargas Quiros, Bart Liefers, Karin van Garderen, Jeroen Vermeulen, Eyened Reading Center, Caroline Klaver
Abstract: Purpose: To provide a diverse, high-quality dataset of color fundus images (CFIs) with detailed artery-vein (A/V) segmentation annotations, supporting the development and evaluation of machine learning algorithms for vascular analysis in ophthalmology. Methods: CFIs were sampled from the longitudinal Rotterdam Study (RS), encompassing a wide range of ages, devices, and capture conditions. Images were annotated using a custom interface that allowed graders to label arteries, veins, and unknown vessels on separate layers, starting from an initial vessel segmentation mask. Connectivity was explicitly verified and corrected using connected component visualization tools. Results: The dataset includes 1024x1024-pixel PNG images in three modalities: original RGB fundus images, contrast-enhanced versions, and RGB-encoded A/V masks. Image quality varied widely, including challenging samples typically excluded by automated quality assessment systems, but judged to contain valuable vascular information. Conclusion: This dataset offers a rich and heterogeneous source of CFIs with high-quality segmentations. It supports robust benchmarking and training of machine learning models under real-world variability in image quality and acquisition settings. Translational Relevance: By including connectivity-validated A/V masks and diverse image conditions, this dataset enables the development of clinically applicable, generalizable machine learning tools for retinal vascular analysis, potentially improving automated screening and diagnosis of systemic and ocular diseases.

Paper number 63:
Title: Spatial Interpolation of Room Impulse Responses based on Deeper Physics-Informed Neural Networks with Residual Connections
Authors: Ken Kurata, Gen Sato, Izumi Tsunokuni, Yusuke Ikeda
Abstract: The room impulse response (RIR) characterizes sound propagation in a room from a loudspeaker to a microphone under the linear time-invariant assumption. Estimating RIRs from a limited number of measurement points is crucial for sound propagation analysis and visualization. Physics-informed neural networks (PINNs) have recently been introduced for accurate RIR estimation by embedding governing physical laws into deep learning models; however, the role of network depth has not been systematically investigated. In this study, we developed a deeper PINN architecture with residual connections and analyzed how network depth affects estimation performance. We further compared activation functions, including tanh and sinusoidal activations. Our results indicate that the residual PINN with sinusoidal activations achieves the highest accuracy for both interpolation and extrapolation of RIRs. Moreover, the proposed architecture enables stable training as the depth increases and yields notable improvements in estimating reflection components. These results provide practical guidelines for designing deep and stable PINNs for acoustic-inverse problems.

Paper number 64:
Title: Weather Estimation for Integrated Sensing and Communication
Authors: Victoria Palhares, Artjom Grudnitsky, Silvio Mandelli
Abstract: One of the key features of sixth-generation (6G) mobile communications will be integrated sensing and communication (ISAC). While the main goal of ISAC in standardization efforts is to detect objects, the byproducts of radar operations can be used to enable new services in 6G, such as weather sensing. Even though weather radars are the most prominent technology for weather detection and monitoring, they are expensive and usually neglect areas in close vicinity. To this end, we propose reusing the dense deployment of 6G base stations for weather sensing purposes by detecting and estimating weather conditions. We implement both a classifier and a regressor as a convolutional neural network trained across measurements with varying precipitation rates and wind speeds. We implement our approach in an ISAC proof-of-concept and conduct a multi-week experiment campaign. Experimental results show that we are able to jointly and accurately classify weather conditions with accuracies of 99.38% and 98.99% for precipitation rate and wind speed, respectively. For estimation, we obtain errors of 1.2 mm/h and 1.5 km/h, for precipitation rate and wind speed, respectively. These findings indicate that weather sensing services can be reliably deployed in 6G ISAC networks, broadening their service portfolio and boosting their market value.

Paper number 65:
Title: Spatial Angular Pseudo-Derivative Search: A Single Snapshot Super-resolution Sparse DOA Scheme with Potential for Practical Application
Authors: Longxin Bai, Jingchao Zhang, Liyan Qiao
Abstract: Accurate, high-resolution, and real-time DOA estimation is a cornerstone of environmental perception in automotive radar systems. While sparse signal recovery techniques offer super-resolution and high-precision estimation, their prohibitive computational complexity remains a primary bottleneck for practical deployment. This paper proposes a sparse DOA estimation scheme specifically tailored for the stringent requirements of automotive radar such as limited computational resources, restricted array apertures, and single-snapshot constraints. By introducing the concept of the spatial angular pseudo-derivative and incorporating this property as a constraint into a standard L0-norm minimization problem, we formulate an objective function that more faithfully characterizes the physical properties of the DOA problem. The associated solver, designated as the SAPD search algorithm, naturally transforms the high-dimensional optimization task into an efficient grid-search scheme. The SAPD algorithm circumvents high-order matrix inversions and computationally intensive iterations. We provide an analysis of the computational complexity and convergence properties of the proposed algorithm. Numerical simulations and experimental validation demonstrate that the SAPD method achieves a superior balance of real-time efficiency, high precision, and super-resolution, making it highly suitable for next-generation automotive radar applications.

Paper number 66:
Title: Learning to Select Like Humans: Explainable Active Learning for Medical Imaging
Authors: Ifrat Ikhtear Uddin, Longwei Wang, Xiao Qin, Yang Zhou, KC Santosh
Abstract: Medical image analysis requires substantial labeled data for model training, yet expert annotation is expensive and time-consuming. Active learning (AL) addresses this challenge by strategically selecting the most informative samples for the annotation purpose, but traditional methods solely rely on predictive uncertainty while ignoring whether models learn from clinically meaningful features a critical requirement for clinical deployment. We propose an explainability-guided active learning framework that integrates spatial attention alignment into a sample acquisition process. Our approach advocates for a dual-criterion selection strategy combining: (i) classification uncertainty to identify informative examples, and (ii) attention misalignment with radiologist-defined regions-of-interest (ROIs) to target samples where the model focuses on incorrect features. By measuring misalignment between Grad-CAM attention maps and expert annotations using Dice similarity, our acquisition function judiciously identifies samples that enhance both predictive performance and spatial interpretability. We evaluate the framework using three expert-annotated medical imaging datasets, namely, BraTS (MRI brain tumors), VinDr-CXR (chest X-rays), and SIIM-COVID-19 (chest X-rays). Using only 570 strategically selected samples, our explainability-guided approach consistently outperforms random sampling across all the datasets, achieving 77.22% accuracy on BraTS, 52.37% on VinDr-CXR, and 52.66% on SIIM-COVID. Grad-CAM visualizations confirm that the models trained by our dual-criterion selection focus on diagnostically relevant regions, demonstrating that incorporating explanation guidance into sample acquisition yields superior data efficiency while maintaining clinical interpretability.

Paper number 67:
Title: Noncooperative Coordination for Decentralized Air Traffic Management
Authors: Jaehan Im
Abstract: Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems.

Paper number 68:
Title: Monaural Multi-Speaker Speech Separation Using Efficient Transformer Model
Authors: S. Rijal, R. Neupane, S. P. Mainali, S. K. Regmi, S. Maharjan
Abstract: Cocktail party problem is the scenario where it is difficult to separate or distinguish individual speaker from a mixed speech from several speakers. There have been several researches going on in this field but the size and complexity of the model is being traded off with the accuracy and robustness of speech separation. "Monaural multi-speaker speech separation" presents a speech-separation model based on the Transformer architecture and its efficient forms. The model has been trained with the LibriMix dataset containing diverse speakers' utterances. The model separates 2 distinct speaker sources from a mixed audio input. The developed model approaches the reduction in computational complexity of the speech separation model, with minimum tradeoff with the performance of prevalent speech separation model and it has shown significant movement towards that goal. This project foresees, a rise in contribution towards the ongoing research in the field of speech separation with computational efficiency at its core.

Paper number 69:
Title: Voice Impression Control in Zero-Shot TTS
Authors: Kenichi Fujita, Shota Horiguchi, Yusuke Ijima
Abstract: Para-/non-linguistic information in speech is pivotal in shaping the listeners' impression. Although zero-shot text-to-speech (TTS) has achieved high speaker fidelity, modulating subtle para-/non-linguistic information to control perceived voice characteristics, i.e., impressions, remains challenging. We have therefore developed a voice impression control method in zero-shot TTS that utilizes a low-dimensional vector to represent the intensities of various voice impression pairs (e.g., dark-bright). The results of both objective and subjective evaluations have demonstrated our method's effectiveness in impression control. Furthermore, generating this vector via a large language model enables target-impression generation from a natural language description of the desired impression, thus eliminating the need for manual optimization. Audio examples are available on our demo page (this https URL).

Paper number 70:
Title: Optimal Control and Neural Porkchop Analysis for Low-Thrust Asteroid Rendezvous Mission
Authors: Zhong Zhang, Niccolò Michelotti, Gonçalo Oliveira Pinho, Yilin Zou, Francesco Topputo
Abstract: This paper presents a comparative study of the applicability and accuracy of optimal control methods and neural network-based estimators in the context of porkchop plots for preliminary asteroid rendezvous mission design. The scenario considered involves a deep-space CubeSat equipped with a low-thrust engine, departing from Earth and rendezvousing with a near-Earth asteroid within a three-year launch window. A low-thrust trajectory optimization model is formulated, incorporating variable specific impulse, maximum thrust, and path constraints. The optimal control problem is efficiently solved using Sequential Convex Programming (SCP) combined with a solution continuation strategy. The neural network framework consists of two models: one predicts the minimum fuel consumption ($\Delta v$), while the other estimates the minimum flight time ($\Delta t$) which is used to assess transfer feasibility. Case results demonstrate that, in simplified scenarios without path constraints, the neural network approach achieves low relative errors across most of the design space and successfully captures the main structural features of the porkchop plots. In cases where the SCP-based continuation method fails due to the presence of multiple local optima, the neural network still provides smooth and globally consistent predictions, significantly improving the efficiency of early-stage asteroid candidate screening. However, the deformation of the feasible region caused by path constraints leads to noticeable discrepancies in certain boundary regions, thereby limiting the applicability of the network in detailed mission design phases. Overall, the integration of neural networks with porkchop plot analysis offers an effective decision-making tool for mission designers and planetary scientists, with significant potential for engineering applications.

Paper number 71:
Title: Deep Reinforcement Learning Approach to QoSAware Load Balancing in 5G Cellular Networks under User Mobility and Observation Uncertainty
Authors: Mehrshad Eskandarpour, Hossein Soleimani
Abstract: Efficient mobility management and load balancing are critical to sustaining Quality of Service (QoS) in dense, highly dynamic 5G radio access networks. We present a deep reinforcement learning framework based on Proximal Policy Optimization (PPO) for autonomous, QoS-aware load balancing implemented end-to-end in a lightweight, pure-Python simulation environment. The control problem is formulated as a Markov Decision Process in which the agent periodically adjusts Cell Individual Offset (CIO) values to steer user-cell associations. A multi-objective reward captures key performance indicators (aggregate throughput, latency, jitter, packet loss rate, Jain's fairness index, and handover count), so the learned policy explicitly balances efficiency and stability under user mobility and noisy observations. The PPO agent uses an actor-critic neural network trained from trajectories generated by the Python simulator with configurable mobility (e.g., Gauss-Markov) and stochastic measurement noise. Across 500+ training episodes and stress tests with increasing user density, the PPO policy consistently improves KPI trends (higher throughput and fairness, lower delay, jitter, packet loss, and handovers) and exhibits rapid, stable convergence. Comparative evaluations show that PPO outperforms rule-based ReBuHa and A3 as well as the learning-based CDQL baseline across all KPIs while maintaining smoother learning dynamics and stronger generalization as load increases. These results indicate that PPO's clipped policy updates and advantage-based training yield robust, deployable control for next-generation RAN load balancing using an entirely Python-based toolchain.

Paper number 72:
Title: KANELÉ: Kolmogorov-Arnold Networks for Efficient LUT-based Evaluation
Authors: Duc Hoang, Aarush Gupta, Philip Harris
Abstract: Low-latency, resource-efficient neural network inference on FPGAs is essential for applications demanding real-time capability and low power. Lookup table (LUT)-based neural networks are a common solution, combining strong representational power with efficient FPGA implementation. In this work, we introduce KANELÉ, a framework that exploits the unique properties of Kolmogorov-Arnold Networks (KANs) for FPGA deployment. Unlike traditional multilayer perceptrons (MLPs), KANs employ learnable one-dimensional splines with fixed domains as edge activations, a structure naturally suited to discretization and efficient LUT mapping. We present the first systematic design flow for implementing KANs on FPGAs, co-optimizing training with quantization and pruning to enable compact, high-throughput, and low-latency KAN architectures. Our results demonstrate up to a 2700x speedup and orders of magnitude resource savings compared to prior KAN-on-FPGA approaches. Moreover, KANELÉ matches or surpasses other LUT-based architectures on widely used benchmarks, particularly for tasks involving symbolic or physical formulas, while balancing resource usage across FPGA hardware. Finally, we showcase the versatility of the framework by extending it to real-time, power-efficient control systems.

Paper number 73:
Title: Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback
Authors: Tomas Ortega, Chun-Yin Huang, Xiaoxiao Li, Hamid Jafarkhani
Abstract: Distributed learning, particularly Federated Learning (FL), faces a significant bottleneck in the communication cost, particularly the uplink transmission of client-to-server updates, which is often constrained by asymmetric bandwidth limits at the edge. Biased compression techniques are effective in practice, but require error feedback mechanisms to provide theoretical guarantees and to ensure convergence when compression is aggressive. Standard error feedback, however, relies on client-specific control variates, which violates user privacy and is incompatible with stateless clients common in large-scale FL. This paper proposes two novel frameworks that enable biased compression without client-side state or control variates. The first, Compressed Aggregate Feedback (CAFe), uses the globally aggregated update from the previous round as a shared control variate for all clients. The second, Server-Guided Compressed Aggregate Feedback (CAFe-S), extends this idea to scenarios where the server possesses a small private dataset; it generates a server-guided candidate update to be used as a more accurate predictor. We consider Distributed Gradient Descent (DGD) as a representative algorithm and analytically prove CAFe's superiority to Distributed Compressed Gradient Descent (DCGD) with biased compression in the non-convex regime with bounded gradient dissimilarity. We further prove that CAFe-S converges to a stationary point, with a rate that improves as the server's data become more representative. Experimental results in FL scenarios validate the superiority of our approaches over existing compression schemes.

Paper number 74:
Title: Lyapunov Functions can Exactly Quantify Rate Performance of Nonlinear Differential Equations
Authors: Declan S. Jagt, Matthew M. Peet
Abstract: Pointwise-in-time stability notions for Ordinary Differential Equations (ODEs) provide quantitative metrics for system performance by establishing bounds on the rate of decay of the system state in terms of initial condition -- allowing stability to be quantified by e.g. the maximum provable decay rate. Such bounds may be obtained by finding suitable Lyapunov functions using, e.g. Sum-of-Squares (SOS) optimization. While Lyapunov tests have been proposed for numerous pointwise-in-time stability notions, including exponential, rational, and finite-time stability, it is unclear whether these characterizations are able to provide accurate bounds on system performance. In this paper, we start by proposing a generalized notion of rate performance -- with exponential, rational, and finite-time decay rates being special cases. Then, for any such notion and rate, we associate a Lyapunov condition which is shown to be necessary and sufficient for a system to achieve that rate. Finally, we show how the proposed conditions can be enforced using SOS programming in the case of exponential, rational, and finite-time stability. Numerical examples in each case demonstrate that the corresponding SOS test can achieve tight bounds on the rate performance with accurate inner bounds on the associated regions of performance.

Paper number 75:
Title: Agonist-Antagonist Neural Coordination without Mechanical Coupling after Targeted Muscle Reinnervation
Authors: Laura Ferrante, Anna Boesendorfer, Benedikt Baumgartner, Manuel Catalano, Antonio Bicchi, Oskar Aszmann, Dario Farina
Abstract: Following limb amputation and targeted muscle reinnervation (TMR), nerves that originally innervated agonist and antagonist muscles are rerouted into one or more residual target muscles. This rerouting profoundly alters the natural mechanical coupling and afferent signalling that normally link muscle groups in intact limbs. Despite this disruption, in this study we demonstrate, using high-density intramuscular microelectrode arrays implanted in reinnervated muscles of three TMR participants, that motor units (MUs) associated with agonist and antagonist tasks remain functionally coupled. Specifically, over 40% of motor units active during agonist tasks were also recruited during the corresponding antagonist tasks, even though no visual feedback on antagonist neural activity was provided. These motor units exhibited significantly different firing rates depending on their functional role. These results provide the first motor-unit-level evidence that the central nervous system preserves coordinated agonist-antagonist control after TMR and inform restorative surgical strategies and prosthetic systems capable of regulating both limb kinematics and dynamics based on agonist-antagonist commands interplay.

Paper number 76:
Title: Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment
Authors: Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini, Chelsea Finn, Marco Pavone
Abstract: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap." We first characterize the test-time scaling laws for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce CoVer-VLA, a hierarchical test-time verification pipeline using the trained verifier. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses the verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer-VLA achieves 14% gains in task progress and 9% in success rate.
    