
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Nonlinear Modeling of a PEM Fuel Cell System; a Practical Study with Experimental Validation
Authors: Seyed Mehdi Rakhtala, Roja Eini
Abstract: In this paper, a nonlinear six order model is proposed for a proton exchange membrane fuel cell (PEMFC) as a control-oriented electrochemical model. Its validation is performed on a specific single cell PEMFC with effective dimension of 5 cm5 cm. This model is described in the nonlinear state space form with 6 state variables. Load current and DC voltage are considered as measurable disturbance and control input respectively. Besides, the model includes fuel cell stack and its auxiliary components as well. In this survey, a nonlinear state space representation is derived by arranging nonlinear equations and combining them with auxiliary components model. The proposed model can be successfully used to design nonlinear controller and nonlinear observer systems. The analyzed PEMFC system consists of air compressor motor dynamic equations, air and fuel supply subsystems, a perfect air humidifier and a fuel cell stack. An experimentally validated nonlinear model that reproduces the most typical features of a laboratory PEMFC system is presented. This model is derived based on physics law in stack, including system gases dynamics. The objective of this paper is to introduce a fully analytical model which has been fully validated on a fuel cell system and its auxiliary components. The proposed method can be used as a general modeling guideline for control-oriented purposes. Moreover, it can be successfully implemented in composing a dynamic subsystem, like hydrogen subsystem, as part of the whole nonlinear model.

Paper number 2:
Title: SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models
Authors: Anurag Kumar, Rohit Paturi, Amber Afshan, Sundararajan Srinivasan
Abstract: Speaker Diarization (SD) is a crucial component of modern end-to-end ASR pipelines. Traditional SD systems, which are typically audio-based and operate independently of ASR, often introduce speaker errors, particularly during speaker transitions and overlapping speech. Recently, language models including fine-tuned large language models (LLMs) have shown to be effective as a second-pass speaker error corrector by leveraging lexical context in the transcribed output. In this work, we introduce a novel acoustic conditioning approach to provide more fine-grained information from the acoustic diarizer to the LLM. We also show that a simpler constrained decoding strategy reduces LLM hallucinations, while avoiding complicated post-processing. Our approach significantly reduces the speaker error rates by 24-43% across Fisher, Callhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.

Paper number 3:
Title: RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation
Authors: Juntao Jiang, Jiangning Zhang, Weixuan Liu, Muxuan Gao, Xiaobin Hu, Xiaoxiao Yan, Feiyue Huang, Yong Liu
Abstract: In recent years, there have been significant advancements in deep learning for medical image analysis, especially with convolutional neural networks (CNNs) and transformer models. However, CNNs face limitations in capturing long-range dependencies while transformers suffer high computational complexities. To address this, we propose RWKV-UNet, a novel model that integrates the RWKV (Receptance Weighted Key Value) structure into the U-Net architecture. This integration enhances the model's ability to capture long-range dependencies and improve contextual understanding, which is crucial for accurate medical image segmentation. We build a strong encoder with developed inverted residual RWKV (IR-RWKV) blocks combining CNNs and RWKVs. We also propose a Cross-Channel Mix (CCM) module to improve skip connections with multi-scale feature fusion, achieving global channel information integration. Experiments on benchmark datasets, including Synapse, ACDC, BUSI, CVC-ClinicDB, CVC-ColonDB, Kvasir-SEG, ISIC 2017 and GLAS show that RWKV-UNet achieves state-of-the-art performance on various types of medical image segmentation. Additionally, smaller variants, RWKV-UNet-S and RWKV-UNet-T, balance accuracy and computational efficiency, making them suitable for broader clinical applications.

Paper number 4:
Title: Head Motion Degrades Machine Learning Classification of Alzheimer's Disease from Positron Emission Tomography
Authors: Eléonore V. Lieffrig, Takuya Toyonaga, Jiazhen Zhang, John A. Onofrey
Abstract: Brain positron emission tomography (PET) imaging is broadly used in research and clinical routines to study, diagnose, and stage Alzheimer's disease (AD). However, its potential cannot be fully exploited yet due to the lack of portable motion correction solutions, especially in clinical settings. Head motion during data acquisition has indeed been shown to degrade image quality and induces tracer uptake quantification error. In this study, we demonstrate that it also biases machine learning-based AD classification. We start by proposing a binary classification algorithm solely based on PET images. We find that it reaches a high accuracy in classifying motion corrected images into cognitive normal or AD. We demonstrate that the classification accuracy substantially decreases when images lack motion correction, thereby limiting the algorithm's effectiveness and biasing image interpretation. We validate these findings in cohorts of 128 $^{11}$C-UCB-J and 173 $^{18}$F-FDG scans, two tracers highly relevant to the study of AD. Classification accuracies decreased by 10% and 5% on 20 $^{18}$F-FDG and 20 $^{11}$C-UCB-J testing cases, respectively. Our findings underscore the critical need for efficient motion correction methods to make the most of the diagnostic capabilities of PET-based machine learning.

Paper number 5:
Title: Automotive Elevation Mapping with Interferometric Synthetic Aperture Radar
Authors: Leyla A. Kabuli, Griffin Foster
Abstract: Radar is a low-cost and ubiquitous automotive sensor, but is limited by array resolution and sensitivity when performing direction of arrival analysis. Synthetic Aperture Radar (SAR) is a class of techniques to improve azimuth resolution and sensitivity for radar. Interferometric SAR (InSAR) can be used to extract elevation from the variations in phase measurements in SAR images. Utilizing InSAR we show that a typical, low-resolution radar array mounted on a vehicle can be used to accurately localize detections in 3D space for both urban and agricultural environments. We generate point clouds in each environment by combining InSAR with a signal processing scheme tailored to automotive driving. This low-compute approach allows radar to be used as a primary sensor to map fine details in complex driving environments, and be used to make autonomous perception decisions.

Paper number 6:
Title: A Survey on IBR Penetrated Power System Stability Analysis Using Frequency Scanning
Authors: Shuvangkar Chandra Das, Lokesh Saravana, Le Minh Vu, Manh Bui, Tuyen Vu, Jianhua Zhang, Thomas Ortmeyer
Abstract: The rapid rise in inverter-based renewable resources has heightened concerns over subsynchronous resonance and oscillations, thereby challenging grid stability. This paper reviews approaches to identify and mitigate these issues, focusing on frequency scanning methods for stability assessment. It categorizes white-, black-, and gray-box modeling techniques, compares positive-sequence, dq-frame, and alpha-beta domain scanning, and examines perturbation shapes like step, ramp, and chirp. A comparative study highlights their strengths, limitations, and suitability for specific scenarios. By summarizing past events and surveying available tools, this work guides operators and researchers toward more effective, reliable stability analysis methods in grids with high renewable penetration.

Paper number 7:
Title: A Novel Multiple Interval Prediction Method for Electricity Prices based on Scenarios Generation: Definition and Method
Authors: Lu Xin
Abstract: This paper presents interval prediction methodology to address limitations in existing evaluation indicators and improve prediction accuracy and reliability. First, new evaluation indicators are proposed to comprehensively assess interval prediction methods, considering both all-sample and single-sample scenarios. Second, a novel Pattern-Diversity Conditional Time-Series Generative Adversarial Network (PDCTSGAN) is introduced to generate realistic scenarios, enabling a new interval prediction approach based on scenario generation. The PDCTSGAN model innovatively incorporates modifications to random noise inputs, allowing the generation of pattern-diverse realistic scenarios. These scenarios are further utilized to construct multiple interval patterns with high coverage probability and low average width. The effectiveness of the proposed methodology is demonstrated through comprehensive case studies. The paper concludes by highlighting future research directions to further enhance interval prediction methods.

Paper number 8:
Title: A Novel Multiple Interval Prediction Method for Electricity Prices based on Scenarios Generation: Results
Authors: Lu Xin
Abstract: This paper introduces an innovative interval prediction methodology aimed at addressing the limitations of current evaluation indicators while enhancing prediction accuracy and reliability. To achieve this, new evaluation metrics are proposed, offering a comprehensive assessment of interval prediction methods across both all-sample and single-sample scenarios. Additionally, a novel Pattern-Diversity Conditional Time-Series Generative Adversarial Network (PDCTSGAN) is developed, designed to generate realistic scenarios and support a new interval prediction framework based on scenario generation. The PDCTSGAN model incorporates unique modifications to random noise inputs, enabling the creation of pattern-diverse and realistic scenarios. These scenarios are then utilized to produce multiple interval patterns characterized by high coverage probability and reduced average width. The proposed approach is validated through detailed case studies, and the paper concludes with a discussion of future research directions to further refine interval prediction techniques.

Paper number 9:
Title: Low-Complex Waveform, Modulation and Coding Designs for 3GPP Ambient IoT
Authors: Mingxi Yin, Chao Wei, Kazuki Takeda, Yinhua Jia, Changlong Xu, Chengjin Zhang, Hao Xu
Abstract: This paper presents a comprehensive study on low-complexity waveform, modulation and coding (WMC) designs for the 3rd Generation Partnership Project (3GPP) Ambient Internet of Things (A-IoT). A-IoT is a low-cost, low-power IoT system inspired by Ultra High Frequency (UHF) Radio Frequency Identification (RFID) and aims to leverage existing cellular network infrastructure for efficient RF tag management. The paper compares the physical layer (PHY) design challenges and requirements of RFID and A-IoT, particularly focusing on backscatter communications. An overview of the standardization for PHY designs in Release 19 A-IoT is provided, along with detailed schemes of the proposed low-complex WMC designs. The performance of device-to-reader link designs is validated through simulations, demonstrating 6 dB improvements of the proposed baseband waveform with coherent receivers compared to RFID line coding-based solutions with non-coherent receivers when channel coding is adopted.

Paper number 10:
Title: Intelligent Reflecting Surfaces Aided Wireless Network: Deployment Architectures and Solutions
Authors: Qingqing Wu, Guangji Chen, Qiaoyan Peng, Wen Chen, Yifei Yuan, Zhenqiao Cheng, Jianwu Dou, Zhiyong Zhao, Ping Li
Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a transformative technology for wireless networks by improving coverage, capacity, and energy efficiency through intelligent manipulation of wireless propagation environments. This paper provides a comprehensive study on the deployment and coordination of IRSs for wireless networks. By addressing both single- and multi-reflection IRS architectures, we examine their deployment strategies across diverse scenarios, including point-to-point, point-to-multipoint, and point-to-area setups. For the single-reflection case, we highlight the trade-offs between passive and active IRS architectures in terms of beamforming gain, coverage extension, and spatial multiplexing. For the multi-reflection case, we discuss practical strategies to optimize IRS deployment and element allocation, balancing cooperative beamforming gains and path loss. The paper further discusses practical challenges in IRS implementation, including environmental conditions, system compatibility, and hardware limitations. Numerical results and field tests validate the effectiveness of IRS-aided wireless networks and demonstrate their capacity and coverage improvements. Lastly, promising research directions, including movable IRSs, near-field deployments, and network-level optimization, are outlined to guide future investigations.

Paper number 11:
Title: A Systematic Review of Machine Learning Methods for Multimodal EEG Data in Clinical Application
Authors: Siqi Zhao (1), Wangyang Li (1), Xiru Wang (1), Stevie Foglia (2), Hongzhao Tan (1), Bohan Zhang (1), Ameer Hamoodi (2), Aimee Nelson (2 and 3), Zhen Gao (1 and 2) ((1) WBooth School of Engineering Practice and Technology, McMaster University, Hamilton, Ontario Canada, (2) School of Biomedical Engineering, McMaster University, Hamilton, Ontario, Canada, (3) Department of Kinesiology, McMaster University, Hamilton, Ontario, Canada)
Abstract: Machine learning (ML) and deep learning (DL) techniques have been widely applied to analyze electroencephalography (EEG) signals for disease diagnosis and brain-computer interfaces (BCI). The integration of multimodal data has been shown to enhance the accuracy of ML and DL models. Combining EEG with other modalities can improve clinical decision-making by addressing complex tasks in clinical populations. This systematic literature review explores the use of multimodal EEG data in ML and DL models for clinical applications. A comprehensive search was conducted across PubMed, Web of Science, and Google Scholar, yielding 16 relevant studies after three rounds of filtering. These studies demonstrate the application of multimodal EEG data in addressing clinical challenges, including neuropsychiatric disorders, neurological conditions (e.g., seizure detection), neurodevelopmental disorders (e.g., autism spectrum disorder), and sleep stage classification. Data fusion occurred at three levels: signal, feature, and decision levels. The most commonly used ML models were support vector machines (SVM) and decision trees. Notably, 11 out of the 16 studies reported improvements in model accuracy with multimodal EEG data. This review highlights the potential of multimodal EEG-based ML models in enhancing clinical diagnostics and problem-solving.

Paper number 12:
Title: IITKGP-ABSP Submission to LRE22: Language Recognition in Low-Resource Settings
Authors: Spandan Dey, Md Sahidullah, Goutam Saha
Abstract: This is the detailed system description of the IITKGP-ABSP lab's submission to the NIST language recognition evaluation (LRE) 2022. The objective of this LRE (LRE22) is focused on recognizing 14 low-resourced African languages. Even though NIST has provided additional training and development data, we develop our systems with additional constraints of extreme low-resource. Our primary fixed-set submission ensures the usage of only the LRE 22 development data that contains the utterances of 14 target languages. We further restrict our system from using any pre-trained models for feature extraction or classifier fine-tuning. To address the issue of low-resource, our system relies on diverse audio augmentations followed by classifier fusions. Abiding by all the constraints, the proposed methods achieve an EER of 11.43% and cost metric of 0.41 in the LRE22 development set. For users with limited computational resources or limited storage/network capabilities, the proposed system will help achieve efficient LID performance.

Paper number 13:
Title: Broadband measurements and analysis of human blocking in a 60 GHz indoor radio channel
Authors: Mbissane Dieng (IETR), Gheorghe I. Zaharia (IETR), Ghaïs El Zein (IETR)
Abstract: New millimeter-wave wireless communication systems can be strongly impacted by the blockage introduced by the human body. At 60 GHz, the coverage of these systems is relatively limited due to high propagation losses. Thus, beamforming allows to find a reflective path to replace the blocked one. In this work, the study focuses on the impact of a human blocker in a meeting room, to evaluate the blocking losses introduced by the human body at 60 GHz. The results obtained in terms of path loss and channel impulse response show that the attenuation by the human body is between 24 and 26 dB. Moreover, the results show that the use of beamforming allows to exploit the reflected paths to replace the direct link that can be blocked by the human body.

Paper number 14:
Title: Product of Gaussian Mixture Diffusion Model for non-linear MRI Inversion
Authors: Laurenz Nagler, Martin Zach, Thomas Pock
Abstract: Diffusion models have recently shown remarkable results in magnetic resonance imaging reconstruction. However, the employed networks typically are black-box estimators of the (smoothed) prior score with tens of millions of parameters, restricting interpretability and increasing reconstruction time. Furthermore, parallel imaging reconstruction algorithms either rely on off-line coil sensitivity estimation, which is prone to misalignment and restricting sampling trajectories, or perform per-coil reconstruction, making the computational cost proportional to the number of coils. To overcome this, we jointly reconstruct the image and the coil sensitivities using the lightweight, parameter-efficient, and interpretable product of Gaussian mixture diffusion model as an image prior and a classical smoothness priors on the coil sensitivities. The proposed method delivers promising results while allowing for fast inference and demonstrating robustness to contrast out-of-distribution data and sampling trajectories, comparable to classical variational penalties such as total variation. Finally, the probabilistic formulation allows the calculation of the posterior expectation and pixel-wise variance.

Paper number 15:
Title: TimeFlow: Longitudinal Brain Image Registration and Aging Progression Analysis
Authors: Bailiang Jian, Jiazhen Pan, Yitong Li, Fabian Bongratz, Ruochen Li, Daniel Rueckert, Benedikt Wiestler, Christian Wachinger
Abstract: Predicting future brain states is crucial for understanding healthy aging and neurodegenerative diseases. Longitudinal brain MRI registration, a cornerstone for such analyses, has long been limited by its inability to forecast future developments, reliance on extensive, dense longitudinal data, and the need to balance registration accuracy with temporal smoothness. In this work, we present \emph{TimeFlow}, a novel framework for longitudinal brain MRI registration that overcomes all these challenges. Leveraging a U-Net architecture with temporal conditioning inspired by diffusion models, TimeFlow enables accurate longitudinal registration and facilitates prospective analyses through future image prediction. Unlike traditional methods that depend on explicit smoothness regularizers and dense sequential data, TimeFlow achieves temporal consistency and continuity without these constraints. Experimental results highlight its superior performance in both future timepoint prediction and registration accuracy compared to state-of-the-art methods. Additionally, TimeFlow supports novel biological brain aging analyses, effectively differentiating neurodegenerative conditions from healthy aging. It eliminates the need for segmentation, thereby avoiding the challenges of non-trivial annotation and inconsistent segmentation errors. TimeFlow paves the way for accurate, data-efficient, and annotation-free prospective analyses of brain aging and chronic diseases.

Paper number 16:
Title: Digital Twin Online Channel Modeling: Challenges,Principles, and Applications
Authors: Junling Li, Cheng-Xiang Wang, Chen Huang, Tianrun Qi, Tong Wu
Abstract: Different from traditional offline channel modeling, digital twin online channel modeling can sense and accurately characterize dynamic wireless channels in real time, and can therefore greatly assist 6G network optimization. This article proposes a novel promising framework and a step-by-step design procedure of digital twin online channel models (DTOCM). By enabling continuous visualization and accurate prediction of dynamic channel variations, DTOCM can synchronize the performance between simulated and real networks. We first explore the evolution and conceptual advancements of DTOCM, highlighting its visions and associated challenges. Then, we explain its operational principles, construction mechanisms, and applications to typical 6G scenarios. Subsequently, the real-time channel information provisioning and visualization capabilities of DTOCM are illustrated through our DTOCM platform based on practical scenarios. Finally, future research directions and open issues are discussed.

Paper number 17:
Title: Some remarks on practical stabilization via CLF-based control under measurement noise
Authors: Patrick Schmidt, Pavel Osinenko, Stefan Streif
Abstract: Practical stabilization of input-affine systems in the presence of measurement errors and input constraints is considered in this brief note. Assuming that a Lyapunov function and a stabilizing control exist for an input-affine system, the required measurement accuracy at each point of the state space is computed. This is done via the Lyapunov function-based decay condition, which describes along with the input constraints a set of admissible controls. Afterwards, the measurement time points are computed based on the system dynamics. It is shown that between these self-triggered measurement time points, the system evolves and converges into the so-called target ball, i.e. a vicinity of the origin, where it remains. Furthermore, it is shown that the approach ensures the existence of a control law, which is admissible for all possible states and it introduces a connection between measurement time points, measurement accuracy, target ball, and decay. The results of the approach are shown in three examples.

Paper number 18:
Title: Subject Disentanglement Neural Network for Speech Envelope Reconstruction from EEG
Authors: Li Zhang, Jiyao Liu
Abstract: Reconstructing speech envelopes from EEG signals is essential for exploring neural mechanisms underlying speech perception. Yet, EEG variability across subjects and physiological artifacts complicate accurate reconstruction. To address this problem, we introduce Subject Disentangling Neural Network (SDN-Net), which disentangles subject identity information from reconstructed speech envelopes to enhance cross-subject reconstruction accuracy. SDN-Net integrates three key components: MLA-Codec, MPN-MI, and CTA-MTDNN. The MLA-Codec, a fully convolutional neural network, decodes EEG signals into speech envelopes. The CTA-MTDNN module, a multi-scale time-delay neural network with channel and temporal attention, extracts subject identity features from EEG signals. Lastly, the MPN-MI module, a mutual information estimator with a multi-layer perceptron, supervises the removal of subject identity information from the reconstructed speech envelope. Experiments on the Auditory EEG Decoding Dataset demonstrate that SDN-Net achieves superior performance in inner- and cross-subject speech envelope reconstruction compared to recent state-of-the-art methods.

Paper number 19:
Title: Bayesian Multifractal Image Segmentation
Authors: Kareth M. León-López, Abderrahim Halimi, Jean-Yves Tourneret, Herwig Wendt
Abstract: Multifractal analysis (MFA) provides a framework for the global characterization of image textures by describing the spatial fluctuations of their local regularity based on the multifractal spectrum. Several works have shown the interest of using MFA for the description of homogeneous textures in images. Nevertheless, natural images can be composed of several textures and, in turn, multifractal properties associated with those textures. This paper introduces a Bayesian multifractal segmentation method to model and segment multifractal textures by jointly estimating the multifractal parameters and labels on images. For this, a computationally and statistically efficient multifractal parameter estimation model for wavelet leaders is firstly developed, defining different multifractality parameters to different regions of an image. Then, a multiscale Potts Markov random field is introduced as a prior to model the inherent spatial and scale correlations between the labels of the wavelet leaders. A Gibbs sampling methodology is employed to draw samples from the posterior distribution of the parameters. Numerical experiments are conducted on synthetic multifractal images to evaluate the performance of the proposed segmentation approach. The proposed method achieves superior performance compared to traditional unsupervised segmentation techniques as well as modern deep learning-based approaches, showing its effectiveness for multifractal image segmentation.

Paper number 20:
Title: A Systematic Method for Optimum Biomedical Wireless Power Transfer using Inductive Links in Area-Constrained Implants
Authors: Asif Iftekhar Omi, Anyu Jiang, Baibhab Chatterjee
Abstract: In the context of implantable bioelectronics, this work provides new insights into maximizing biomedical wireless power transfer (BWPT) via the systematic development of inductive links. This approach addresses the specific challenges of power transfer efficiency (PTE) optimization within the area constraints of bio-implants embedded in tissue. Key contributions include the derivation of an optimal self-inductance with S-parameter-based analyses leading to the co-design of planar spiral coils and L-section impedance matching networks. To validate the proposed design methodology, two coil prototypes -- one symmetric (type-1) and one asymmetric (type-2) -- were fabricated and tested for PTE in pork tissue. Targeting a 20 MHz design frequency, the type-1 coil demonstrated a state-of-the-art PTE of $\sim$ 4\% (channel length = 15 mm) with a return loss (RL) $>$ 20 dB on both the input and output sides, within an area constraint of $<$ 18 $ \times $ 18 mm$^{2}$. In contrast, the type-2 coil achieved a PTE of $\sim$ 2\% with an RL $>$ 15 dB, for a smaller receiving coil area of $<$ 5x5 mm$^{2}$ for the same tissue environment. To complement the coils, we demonstrate a 65 nm test chip with an integrated energy harvester, which includes \asif{a} 30-stage rectifier and low-dropout regulator (LDO), producing a stable $\sim$ 1V DC output within tissue medium, matching theoretical predictions and simulations. Furthermore, we provide a robust and comprehensive guideline for advancing efficient inductive links for various BWPT applications, with shared resources in GitHub available for utilization by the broader community.

Paper number 21:
Title: Near-Field ISAC: Synergy of Dual-Purpose Codebooks and Space-Time Adaptive Processing
Authors: Ahmed Hussain, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil
Abstract: Integrated sensing and communication (ISAC) has emerged as a transformative paradigm, enabling situationally aware and perceptive next-generation wireless networks through the co-design of shared network resources. With the adoption of millimeter-wave (mmWave) and terahertz (THz) frequency bands, ultra-massive MIMO (UM-MIMO) systems and holographic surfaces unlock the potential of near-field (NF) propagation, characterized by spherical wavefronts that facilitate beam manipulation in both angular and range domains. This paper presents a unified approach to near-field beam-training and sensing, introducing a dual-purpose codebook design that employs discrete Fourier transform (DFT)-based codebooks for coarse estimation of sensing parameters and polar codebooks for parameter refinement. Leveraging these range and angle estimates, a customized low-complexity space-time adaptive processing (STAP) technique is proposed for NF-ISAC to detect slow-moving targets and efficiently mitigate clutter. The interplay between codebooks and NF-STAP framework offers three key advantages: reduced communication beam training overhead, improved estimation accuracy, and minimal STAP computational complexity. Simulation results show that the proposed framework can reduce STAP complexity by three orders of magnitude, validating efficacy, and highlighting the potential of the proposed approach to seamlessly integrate NF communication and sensing functionalities in future wireless networks.

Paper number 22:
Title: Cultivating Precision: Comparative Analysis of Sensor-Based Yogurt Fermentation Monitoring Techniques
Authors: Ege Keskin, İhsan Ozan Yıldırım
Abstract: Fermented dairy products, including yogurt, are widely consumed for their nutritional and health benefits. While numerous methods exist to monitor and understand yogurt fermentation, the literature lacks an integrated evaluation of diverse sensing approaches within a single experimental framework. To address this gap, this study systematically examines and compares multiple measurement techniques--electrical impedance, DC resistance, pH, optical transparency, carbon dioxide concentration, ambient temperature, and relative humidity--in tracking the yogurt fermentation process. By presenting a unified set of experimental results and assessing each method's observational characteristics, this work offers an encompassing reference point for researchers seeking to understand the relative merits and limitations of different sensing modalities. Rather than establishing definitive guidelines or practical recommendations, the findings provide a foundation for subsequent investigations into sensor-based fermentation monitoring, thereby contributing to a more comprehensive understanding of yogurt fermentation dynamics.

Paper number 23:
Title: Speech Synthesis along Perceptual Voice Quality Dimensions
Authors: Frederik Rautenberg, Michael Kuhlmann, Fritz Seebauer, Jana Wiechmann, Petra Wagner, Reinhold Haeb-Umbach
Abstract: While expressive speech synthesis or voice conversion systems mainly focus on controlling or manipulating abstract prosodic characteristics of speech, such as emotion or accent, we here address the control of perceptual voice qualities (PVQs) recognized by phonetic experts, which are speech properties at a lower level of abstraction. The ability to manipulate PVQs can be a valuable tool for teaching speech pathologists in training or voice actors. In this paper, we integrate a Conditional Continuous-Normalizing-Flow-based method into a Text-to-Speech system to modify perceptual voice attributes on a continuous scale. Unlike previous approaches, our system avoids direct manipulation of acoustic correlates and instead learns from examples. We demonstrate the system's capability by manipulating four voice qualities: Roughness, breathiness, resonance and weight. Phonetic experts evaluated these modifications, both for seen and unseen speaker conditions. The results highlight both the system's strengths and areas for improvement.

Paper number 24:
Title: The first calibration model for bluetooth angle of arrival: Enhancing positioning accuracy in indoor environments
Authors: Ma'mon Saeed Alghananim, Yuxiang Feng, Washington Yotto Ochieng
Abstract: Internet of Things (IoT) applications are increasingly reliant on indoor positioning systems to deliver precise and reliable navigation in GNSS-denied environments, including urban areas, smart warehouses, hospitals, and underground or multi-level parking systems. Bluetooth Angle of Arrival (AoA) positioning offers cost-effective solutions with the potential to provide users with sub-meter position accuracy, which is crucial for applications such as underground navigation, firefighters, and robotic navigation. Bluetooth AoA positioning uses angles to determine the position of Bluetooth tags; these angles, measured in the anchor coordinate system, need to be transferred to the user's coordinate system. This requires models or techniques to compute 3D rotation matrices between the anchor and user coordinate system. Until now, no model or technique has been developed to compute these rotation matrices. Therefore, the development of the AoA positioning model focuses on simulated scenarios. This paper introduces the first model, named the AoA calibration model, capable of estimating these rotation matrices, thereby facilitating the practical application of this technology. In addition, this paper tests the Bluetooth AoA calibration and positioning model on a real dataset and presents end-toend functional architectures for AoA positioning. The results demonstrate that the proposed calibration model can estimate the 3D transformation rotation angles with a standard deviation better than 2.5 degrees. The findings also reveal that AoA positioning can achieve sub-meter accuracy in both static and kinematic modes, with accuracy significantly influenced by the distance to the anchors and the geometry factor.

Paper number 25:
Title: A Bayesian Hierarchical Model for Generating Synthetic Unbalanced Power Distribution Grids
Authors: Henrique O. Caetano, Rahul K. Gupta, Marco Aiello, Carlos Dias Maciel
Abstract: The real-world data of power networks is often inaccessible due to privacy and security concerns, highlighting the need for tools to generate realistic synthetic network data. Existing methods leverage geographic tools like OpenStreetMap with heuristic rules to model system topology and typically focus on single-phase, balanced systems, limiting their applicability to real-world distribution systems, which are usually unbalanced. This work proposes a Bayesian Hierarchical Model (BHM) to generate unbalanced three-phase distribution systems learning from existing networks. The scheme takes as input the base topology and aggregated demand per node and outputs a three-phase unbalanced system. The proposed scheme achieves a Mean Absolute Percentage Error (MAPE) of less than $8\%$ across all phases, with computation times of 20.4 seconds for model training and 3.1 seconds per sample generation. The tool is applied to learn from publicly available SMART-DS dataset and applied to generate European 906 and IEEE-123 systems. We demonstrate the transfer learning capability of the proposed tool by leveraging a model trained on an observed system to generate a synthetic network for an unobserved system. Specifically, the tool is trained using the publicly available SMART-DS dataset and subsequently applied to generate synthetic networks for the European 906-bus system and the IEEE 123-bus system. This tool allows researchers to simulate realistic unbalanced three-phase power data with high accuracy and speed, enhancing planning and operational analysis for modern power grids.

Paper number 26:
Title: Boosting Diffusion Guidance via Learning Degradation-Aware Models for Blind Super Resolution
Authors: Shao-Hao Lu, Ren Wang, Ching-Chun Huang, Wei-Chen Chiu
Abstract: Recently, diffusion-based blind super-resolution (SR) methods have shown great ability to generate high-resolution images with abundant high-frequency detail, but the detail is often achieved at the expense of fidelity. Meanwhile, another line of research focusing on rectifying the reverse process of diffusion models (i.e., diffusion guidance), has demonstrated the power to generate high-fidelity results for non-blind SR. However, these methods rely on known degradation kernels, making them difficult to apply to blind SR. To address these issues, we introduce degradation-aware models that can be integrated into the diffusion guidance framework, eliminating the need to know degradation kernels. Additionally, we propose two novel techniques input perturbation and guidance scalar to further improve our performance. Extensive experimental results show that our proposed method has superior performance over state-of-the-art methods on blind SR benchmarks

Paper number 27:
Title: A Multi-modal Intelligent Channel Model for 6G Multi-UAV-to-Multi-Vehicle Communications
Authors: Lu Bai, Mengyuan Lu, Ziwei Huang, Xiang Cheng
Abstract: In this paper, a novel multi-modal intelligent channel model for sixth-generation (6G) multiple-unmanned aerial vehicle (multi-UAV)-to-multi-vehicle communications is proposed. To thoroughly explore the mapping relationship between the physical environment and the electromagnetic space in the complex multi-UAV-to-multi-vehicle scenario, two new parameters, i.e., terrestrial traffic density (TTD) and aerial traffic density (ATD), are developed and a new sensing-communication intelligent integrated dataset is constructed in suburban scenario under different TTD and ATD conditions. With the aid of sensing data, i.e., light detection and ranging (LiDAR) point clouds, the parameters of static scatterers, terrestrial dynamic scatterers, and aerial dynamic scatterers in the electromagnetic space, e.g., number, distance, angle, and power, are quantified under different TTD and ATD conditions in the physical environment. In the proposed model, the channel non-stationarity and consistency on the time and space domains and the channel non-stationarity on the frequency domain are simultaneously mimicked. The channel statistical properties, such as time-space-frequency correlation function (TSF-CF), time stationary interval (TSI), and Doppler power spectral density (DPSD), are derived and simulated. Simulation results match ray-tracing (RT) results well, which verifies the accuracy of the proposed multi-UAV-to-multi-vehicle channel model.

Paper number 28:
Title: Achieving Stability and Optimality: Control Strategy for a Wind Turbine Supplying an Electrolyzer in the Islanded Storage-less Microgrid
Authors: Bosen Yang, Kang Ma, Jin Lin, Mingjun Zhang, QiweiDuan, Zhendong Ji, Zhi Liu, Yonghua Song
Abstract: Wind power generation supplying electrolyzers in islanded microgrids is an essential technical pathway for green hydrogen production, attracting growing attention in the transition towards net zero carbon emissions. Both academia and industry widely recognize that islanded AC microgrids normally rely on battery energy storage systems (BESSs) for grid-forming functions. However, the high cost of BESS significantly increases the levelized cost of hydrogen (LCOH), compromising economic feasibility. To address this challenge and reduce the LCOH, this paper focuses on a wind turbine (WT) supplying an electrolyzer in a storage-less microgrid and identifies a unique characteristic that challenges the conventional understanding of this microgrid: active power is coupled with microgrid voltage rather than frequency, the latter being entirely decoupled from active power balance. Based on this unique characteristic, this paper develops a new control strategy that maintains power balance, stabilizes the voltage and frequency, and maximizes hydrogen production. The effectiveness of the control strategy is validated through case studies conducted in Matlab/Simulink, especially its capability to maintain stability while maximizing hydrogen production under various conditions.

Paper number 29:
Title: Processing and Analyzing Real-World Driving Data: Insights on Trips, Scenarios, and Human Driving Behaviors
Authors: Jihun Han, Dominik Karbowski, Ayman Moawad, Namdoo Kim, Aymeric Rousseau, Shihong Fan, Jason Hoon Lee, Jinho Ha
Abstract: Analyzing large volumes of real-world driving data is essential for providing meaningful and reliable insights into real-world trips, scenarios, and human driving behaviors. To this end, we developed a multi-level data processing approach that adds new information, segments data, and extracts desired parameters. Leveraging a confidential but extensive dataset (over 1 million km), this approach leads to three levels of in-depth analysis: trip, scenario, and driving. The trip-level analysis explains representative properties observed in real-world trips, while the scenario-level analysis focuses on scenario conditions resulting from road events that reduce vehicle speed. The driving-level analysis identifies the cause of driving regimes for specific situations and characterizes typical human driving behaviors. Such analyses can support the design of both trip- and scenario-based tests, the modeling of human drivers, and the establishment of guidelines for connected and automated vehicles.

Paper number 30:
Title: Multi-View Transformers for Airway-To-Lung Ratio Inference on Cardiac CT Scans: The C4R Study
Authors: Sneha N. Naik, Elsa D. Angelini, Eric A. Hoffman, Elizabeth C. Oelsner, R. Graham Barr, Benjamin M. Smith, Andrew F. Laine
Abstract: The ratio of airway tree lumen to lung size (ALR), assessed at full inspiration on high resolution full-lung computed tomography (CT), is a major risk factor for chronic obstructive pulmonary disease (COPD). There is growing interest to infer ALR from cardiac CT images, which are widely available in epidemiological cohorts, to investigate the relationship of ALR to severe COVID-19 and post-acute sequelae of SARS-CoV-2 infection (PASC). Previously, cardiac scans included approximately 2/3 of the total lung volume with 5-6x greater slice thickness than high-resolution (HR) full-lung (FL) CT. In this study, we present a novel attention-based Multi-view Swin Transformer to infer FL ALR values from segmented cardiac CT scans. For the supervised training we exploit paired full-lung and cardiac CTs acquired in the Multi-Ethnic Study of Atherosclerosis (MESA). Our network significantly outperforms a proxy direct ALR inference on segmented cardiac CT scans and achieves accuracy and reproducibility comparable with a scan-rescan reproducibility of the FL ALR ground-truth.

Paper number 31:
Title: Integrating Cybersecurity in Predictive Cost-Benefit Power Scheduling: A DeepStack Model with Dynamic Defense Mechanism
Authors: Ali Peivand, Seyyed Mostafa Nosratabadi
Abstract: This paper introduces a novel, deep learning-based predictive model tailored to address wind curtailment in contemporary power systems, while enhancing cybersecurity measures through the implementation of a Dynamic Defense Mechanism (DDM). The augmented BiLSTM architecture facilitates accurate short-term predictions for wind power. In addition, a ConvGAN-driven step for stochastic scenario generation and a hierarchical, multi-stage optimization framework, which includes cases with and without Battery Energy Storage (BES), significantly minimizes operational costs. The inclusion of DDM strategically alters network reactances, thereby obfuscating the system's operational parameters to deter cyber threats. This robust solution not only integrates wind power more efficiently into power grids, leveraging BES potential to improve the economic efficiency of the system, but also boosting the cyber security of the system. Validation using the Illinois 200-bus system demonstrates the model's potential, achieving a 98% accuracy in forecasting and substantial cost reductions of over 3.8%. The results underscore the dual benefits of enhancing system reliability and security through advanced deep learning architectures and the strategic application of cybersecurity measures.

Paper number 32:
Title: Efficient Planning in Large-scale Systems Using Hierarchical Finite State Machines
Authors: Elis Stefansson, Karl H. Johansson
Abstract: We consider optimal planning in a large-scale system formalised as a hierarchical finite state machine (HFSM). A planning algorithm is proposed computing an optimal plan between any two states in the HFSM, consisting of two steps: A pre-processing step that computes optimal exit costs of the machines in the HFSM, with time complexity scaling with the number of machines; and a query step that efficiently computes an optimal plan by removing irrelevant subtrees of the HFSM using the optimal exit costs. The algorithm is reconfigurable in the sense that changes in the HFSM are handled with ease, where the pre-processing step recomputes only the optimal exit costs affected by the change. The algorithm can also exploit compact representations that groups together identical machines in the HFSM, where the algorithm only needs to compute the optimal exit costs for one of the identical machines within each group, thereby avoid unnecessary recomputations. We validate the algorithm on large systems with millions of states and a robotic application. It is shown that our approach outperforms Dijkstra's algorithm, Bidirectional Dijkstra and Contraction Hierarchies.

Paper number 33:
Title: Neuromorphic Retina: An FPGA-based Emulator
Authors: Prince Phillip, Pallab Kumar Nath, Kapil Jainwal, Andre van Schaik, Chetan Singh Thakur
Abstract: Implementing accurate models of the retina is a challenging task, particularly in the context of creating visual prosthetics and devices. Notwithstanding the presence of diverse artificial renditions of the retina, the imperative task persists to pursue a more realistic model. In this work, we are emulating a neuromorphic retina model on an FPGA. The key feature of this model is its powerful adaptation to luminance and contrast, which allows it to accurately emulate the sensitivity of the biological retina to changes in light levels. Phasic and tonic cells are realizable in the retina in the simplest way possible. Our FPGA implementation of the proposed biologically inspired digital retina, incorporating a receptive field with a center-surround structure, is reconfigurable and can support 128*128 pixel images at a frame rate of 200fps. It consumes 1720 slices, approximately 3.7k Look-Up Tables (LUTs), and Flip-Flops (FFs) on the FPGA. This implementation provides a high-performance, low-power, and small-area solution and could be a significant step forward in the development of biologically plausible retinal prostheses with enhanced information processing capabilities

Paper number 34:
Title: Spectral Eigenfunction Decomposition for Kernel Adaptive Filtering
Authors: Kan Li, Jose C. Principe
Abstract: Kernel adaptive filtering (KAF) integrates traditional linear algorithms with kernel methods to generate nonlinear solutions in the input space. The standard approach relies on the representer theorem and the kernel trick to perform pairwise evaluations of a kernel function in place of the inner product, which leads to scalability issues for large datasets due to its linear and superlinear growth with respect to the size of the training data. Explicit features have been proposed to tackle this problem, exploiting the properties of the Gaussian-type kernel functions. These approximation methods address the implicitness and infinite dimensional representation of conventional kernel methods. However, achieving an accurate finite approximation for the kernel evaluation requires a sufficiently large vector representation for the dot products. An increase in the input-space dimension leads to a combinatorial explosion in the dimensionality of the explicit space, i.e., it trades one dimensionality problem (implicit, infinite dimensional RKHS) for another (curse of dimensionality). This paper introduces a construction that simultaneously solves these two problems in a principled way, by providing an explicit Euclidean representation of the RKHS while reducing its dimensionality. We present SPEctral Eigenfunction Decomposition (SPEED) along with an efficient incremental approach for fast calculation of the dominant kernel eigenbasis, which enables us to track the kernel eigenspace dynamically for adaptive filtering. Simulation results on chaotic time series prediction demonstrate this novel construction outperforms existing explicit kernel features with greater efficiency.

Paper number 35:
Title: Vision Foundation Models for Computed Tomography
Authors: Suraj Pai (1 and 2 and 3), Ibrahim Hadzic (1 and 2 and 3), Dennis Bontempi (1 and 2 and 3), Keno Bressem (4 and 5), Benjamin H. Kann (1 and 3), Andriy Fedorov (6), Raymond H. Mak (1 and 3), Hugo J. W. L. Aerts (1 and 2 and 3 and 6) ((1) Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard Medical School, (2) Radiology and Nuclear Medicine, CARIM &amp; GROW, Maastricht University, (3) Department of Radiation Oncology, Brigham and Women's Hospital, Dana-Farber Cancer Institute, Harvard Medical School, (4) Department of Diagnostic and Interventional Radiology, Technical University of Munich, School of Medicine and Health, Klinikum rechts der Isar, TUM University Hospital, (5) Department of Cardiovascular Radiology and Nuclear Medicine, Technical University of Munich, School of Medicine and Health, German Heart Center, TUM University Hospital, (6) Department of Radiology, Brigham and Women's Hospital, Dana-Farber Cancer Institute, Harvard Medical School)
Abstract: Foundation models (FMs) have shown transformative potential in radiology by performing diverse, complex tasks across imaging modalities. Here, we developed CT-FM, a large-scale 3D image-based pre-trained model designed explicitly for various radiological tasks. CT-FM was pre-trained using 148,000 computed tomography (CT) scans from the Imaging Data Commons through label-agnostic contrastive learning. We evaluated CT-FM across four categories of tasks, namely, whole-body and tumor segmentation, head CT triage, medical image retrieval, and semantic understanding, showing superior performance against state-of-the-art models. Beyond quantitative success, CT-FM demonstrated the ability to cluster regions anatomically and identify similar anatomical and structural concepts across scans. Furthermore, it remained robust across test-retest settings and indicated reasonable salient regions attached to its embeddings. This study demonstrates the value of large-scale medical imaging foundation models and by open-sourcing the model weights, code, and data, aims to support more adaptable, reliable, and interpretable AI solutions in radiology.

Paper number 36:
Title: CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks
Authors: Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang
Abstract: Efficient resource allocation is essential for optimizing various tasks in wireless networks, which are usually formulated as generalized assignment problems (GAP). GAP, as a generalized version of the linear sum assignment problem, involves both equality and inequality constraints that add computational challenges. In this work, we present a novel Conditional Value at Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address GAP in vehicular networks (VNets). Our approach leverages a hybrid quantum-classical structure, integrating a tailored cost function that balances both objective and constraint-specific penalties to improve solution quality and stability. Using the CVaR-VQE model, we handle the GAP efficiently by focusing optimization on the lower tail of the solution space, enhancing both convergence and resilience on noisy intermediate-scale quantum (NISQ) devices. We apply this framework to a user-association problem in VNets, where our method achieves 23.5% improvement compared to the deep neural network (DNN) approach.

Paper number 37:
Title: FARE: A Deep Learning-Based Framework for Radar-based Face Recognition and Out-of-distribution Detection
Authors: Sabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, Eckehard Steinbach
Abstract: In this work, we propose a novel pipeline for face recognition and out-of-distribution (OOD) detection using short-range FMCW radar. The proposed system utilizes Range-Doppler and micro Range-Doppler Images. The architecture features a primary path (PP) responsible for the classification of in-distribution (ID) faces, complemented by intermediate paths (IPs) dedicated to OOD detection. The network is trained in two stages: first, the PP is trained using triplet loss to optimize ID face classification. In the second stage, the PP is frozen, and the IPs-comprising simple linear autoencoder networks-are trained specifically for OOD detection. Using our dataset generated with a 60 GHz FMCW radar, our method achieves an ID classification accuracy of 99.30% and an OOD detection AUROC of 96.91%.

Paper number 38:
Title: Time series forecasting for multidimensional telemetry data using GAN and BiLSTM in a Digital Twin
Authors: Joao Carmo de Almeida Neto, Claudio Miceli de Farias, Leandro Santiago de Araujo, Leopoldo Andre Dutra Lusquino Filho
Abstract: The research related to digital twins has been increasing in recent years. Besides the mirroring of the physical word into the digital, there is the need of providing services related to the data collected and transferred to the virtual world. One of these services is the forecasting of physical part future behavior, that could lead to applications, like preventing harmful events or designing improvements to get better performance. One strategy used to predict any system operation it is the use of time series models like ARIMA or LSTM, and improvements were implemented using these algorithms. Recently, deep learning techniques based on generative models such as Generative Adversarial Networks (GANs) have been proposed to create time series and the use of LSTM has gained more relevance in time series forecasting, but both have limitations that restrict the forecasting results. Another issue found in the literature is the challenge of handling multivariate environments/applications in time series generation. Therefore, new methods need to be studied in order to fill these gaps and, consequently, provide better resources for creating useful digital twins. In this proposal, it is going to be studied the integration of a BiLSTM layer with a time series obtained by GAN in order to improve the forecasting of all the features provided by the dataset in terms of accuracy and, consequently, improving behaviour prediction.

Paper number 39:
Title: Selective Attention Merging for low resource tasks: A case study of Child ASR
Authors: Natarajan Balaji Shankar, Zilai Wang, Eray Eren, Abeer Alwan
Abstract: While Speech Foundation Models (SFMs) excel in various speech tasks, their performance for low-resource tasks such as child Automatic Speech Recognition (ASR) is hampered by limited pretraining data. To address this, we explore different model merging techniques to leverage knowledge from models trained on larger, more diverse speech corpora. This paper also introduces Selective Attention (SA) Merge, a novel method that selectively merges task vectors from attention matrices to enhance SFM performance on low-resource tasks. Experiments on the MyST database show significant reductions in relative word error rate of up to 14%, outperforming existing model merging and data augmentation techniques. By combining data augmentation techniques with SA Merge, we achieve a new state-of-the-art WER of 8.69 on the MyST database for the Whisper-small model, highlighting the potential of SA Merge for improving low-resource ASR.

Paper number 40:
Title: Electrostatic Clutches Enable High-Force Mechanical Multiplexing: Demonstrating Single-Motor Full-Actuation of a 4-DoF Hand
Authors: Timothy E. Amish, Jeffrey T. Auletta, Chad C. Kessens, Joshua R. Smith, Jeffrey I. Lipton
Abstract: This paper introduces a novel mechanical multiplexing system powered by electrostatic capstan clutches, enabling high-force, single-motor control of multiple degrees of freedom (DoF). The system is capable of both bidirectional single-input single-output time-division and single-input multiple-output multiplexing to actuate a commercial 4-DoF robotic hand with a single motor. Our mechanical multiplexer is also capable of powerless position holding owing to its use of a leadscrew nut acting as the output. Experimental results demonstrate the effectiveness of this approach, achieving individual and simultaneous actuation. This innovation offers a scalable solution for high-DoF robotic systems, providing a path to efficient actuation in robotic platforms.

Paper number 41:
Title: Energy Storage Arbitrage Under Price Uncertainty: Market Risks and Opportunities
Authors: Yiqian Wu, Bolun Xu, James Anderson
Abstract: We investigate the profitability and risk of energy storage arbitrage in electricity markets under price uncertainty, exploring both robust and chance-constrained optimization approaches. We analyze various uncertainty representations, including polyhedral, ellipsoidal uncertainty sets and probabilistic approximations, to model price fluctuations and construct efficient frontiers that highlight the tradeoff between risk and profit. Using historical electricity price data, we quantify the impact of uncertainty on arbitrage strategies and compare their performance under distinct market conditions. The results reveal that arbitrage strategies under uncertainties can effectively secure expected profits, and robust strategies perform better in risk management across varying levels of conservativeness, especially under highly volatile market conditions. This work provides insights into storage arbitrage strategy selection for market participants with differing risk preferences, emphasizing the adaptability of efficient frontiers to the electricity market.

Paper number 42:
Title: Yuan: Yielding Unblemished Aesthetics Through A Unified Network for Visual Imperfections Removal in Generated Images
Authors: Zhenyu Yu, Chee Seng Chan
Abstract: Generative AI presents transformative potential across various domains, from creative arts to scientific visualization. However, the utility of AI-generated imagery is often compromised by visual flaws, including anatomical inaccuracies, improper object placements, and misplaced textual elements. These imperfections pose significant challenges for practical applications. To overcome these limitations, we introduce \textit{Yuan}, a novel framework that autonomously corrects visual imperfections in text-to-image synthesis. \textit{Yuan} uniquely conditions on both the textual prompt and the segmented image, generating precise masks that identify areas in need of refinement without requiring manual intervention -- a common constraint in previous methodologies. Following the automated masking process, an advanced inpainting module seamlessly integrates contextually coherent content into the identified regions, preserving the integrity and fidelity of the original image and associated text prompts. Through extensive experimentation on publicly available datasets such as ImageNet100 and Stanford Dogs, along with a custom-generated dataset, \textit{Yuan} demonstrated superior performance in eliminating visual imperfections. Our approach consistently achieved higher scores in quantitative metrics, including NIQE, BRISQUE, and PI, alongside favorable qualitative evaluations. These results underscore \textit{Yuan}'s potential to significantly enhance the quality and applicability of AI-generated images across diverse fields.

Paper number 43:
Title: Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface
Authors: Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li
Abstract: Seasickness is a prevalent issue that adversely impacts both passenger experiences and the operational efficiency of maritime crews. While techniques that redirect attention have proven effective in alleviating motion sickness symptoms in terrestrial environments, applying similar strategies to manage seasickness poses unique challenges due to the prolonged and intense motion environment associated with maritime travel. In this study, we propose a mindfulness brain-computer interface (BCI), specifically designed to redirect attention with the aim of mitigating seasickness symptoms in real-world settings. Our system utilizes a single-channel headband to capture prefrontal EEG signals, which are then wirelessly transmitted to computing devices for the assessment of mindfulness states. The results are transferred into real-time feedback as mindfulness scores and audiovisual stimuli, facilitating a shift in attentional focus from physiological discomfort to mindfulness practices. A total of 43 individuals participated in a real-world maritime experiment consisted of three sessions: a real-feedback mindfulness session, a resting session, and a pseudofeedback mindfulness session. Notably, 81.39% of participants reported that the mindfulness BCI intervention was effective, and there was a significant reduction in the severity of seasickness, as measured by the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in the theta/beta ratio, corresponding with the alleviation of seasickness symptoms. A decrease in overall EEG band power during the real-feedback mindfulness session suggests that the mindfulness BCI fosters a more tranquil and downregulated state of brain activity. Together, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, with the potential to enhance the cruising experience for both passengers and crews.

Paper number 44:
Title: Chance-Constrained Sampling-Based MPC for Collision Avoidance in Uncertain Dynamic Environments
Authors: Ihab S. Mohamed, Mahmoud Ali, Lantao Liu
Abstract: Navigating safely in dynamic and uncertain environments is challenging due to uncertainties in perception and motion. This letter presents C2U-MPPI, a robust sampling-based Model Predictive Control (MPC) framework that addresses these challenges by leveraging the Unscented Model Predictive Path Integral (U-MPPI) control strategy with integrated probabilistic chance constraints, ensuring more reliable and efficient navigation under uncertainty. Unlike gradient-based MPC methods, our approach (i) avoids linearization of system dynamics and directly applies non-convex and nonlinear chance constraints, enabling more accurate and flexible optimization, and (ii) enhances computational efficiency by reformulating probabilistic constraints into a deterministic form and employing a layered dynamic obstacle representation, enabling real-time handling of multiple obstacles. Extensive experiments in simulated and real-world human-shared environments validate the effectiveness of our algorithm against baseline methods, showcasing its capability to generate feasible trajectories and control inputs that adhere to system dynamics and constraints in dynamic settings, enabled by unscented-based sampling strategy and risk-sensitive trajectory evaluation. A supplementary video is available at: this https URL

Paper number 45:
Title: Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement
Authors: Qianniu Chen, Xiaoyang Hao, Bowen Li, Yue Liu, Li Lu
Abstract: Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized voice customization through voice cloning. However, current methods for achieving zero-shot TTS heavily rely on large model scales and extensive training datasets to ensure satisfactory performance and generalizability across various speakers. This raises concerns regarding both deployment costs and data security. In this paper, we present a lightweight and stable zero-shot TTS system. We introduce a novel TTS architecture designed to effectively model linguistic content and various speaker attributes from source speech and prompt speech, respectively. Furthermore, we present a two-stage self-distillation framework that constructs parallel data pairs for effectively disentangling linguistic content and speakers from the perspective of training data. Extensive experiments show that our system exhibits excellent performance and superior stability on the zero-shot TTS tasks. Moreover, it shows markedly superior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and GPU, respectively.

Paper number 46:
Title: Sound Scene Synthesis at the DCASE 2024 Challenge
Authors: Mathieu Lagrange, Junwon Lee, Modan Tailleur, Laurie M. Heller, Keunwoo Choi, Brian McFee, Keisuke Imoto, Yuki Okamoto
Abstract: This paper presents Task 7 at the DCASE 2024 Challenge: sound scene synthesis. Recent advances in sound synthesis and generative models have enabled the creation of realistic and diverse audio content. We introduce a standardized evaluation framework for comparing different sound scene synthesis systems, incorporating both objective and subjective metrics. The challenge attracted four submissions, which are evaluated using the Fréchet Audio Distance (FAD) and human perceptual ratings. Our analysis reveals significant insights into the current capabilities and limitations of sound scene synthesis systems, while also highlighting areas for future improvement in this rapidly evolving field.

Paper number 47:
Title: Double reflections Assisted RIS Deployment and Energy-efficient Group Selection in mmWaves D2D Communication
Authors: Lakshmikanta Sau, Sasthi C. Ghosh
Abstract: Reconfigurable intelligent surfaces (RISs) offer a viable way to improve the performance of multi-hop device-to-device (D2D) communication. However, due to the substantial propagation and penetration losses of the millimeter waves (mmWaves), a direct line of sight (LoS) link and close proximity of a device pair are required for a high data rate. Static obstacles like trees and buildings can easily impede the direct LoS connectivity between a device pair. Hence, RIS placement plays a crucial role in establishing an indirect LoS link between them. Therefore, in this work, we propose a set cover-based RIS deployment strategy for both single and double RIS-assisted D2D communication. In particular, we have demonstrated that permitting reflections via two consecutive RISs can greatly lower the RIS density in the environment, preventing resource waste and enabling the service of more obstructed device pairs. After the RIS deployment, for information transfer, we also propose an energy-efficient group selection criteria. Moreover, we prove that sometimes double reflections are more beneficial than single reflection, which is counter-intuitive. Numerical results show that our approach outperforms a random and a recent deployment strategy.

Paper number 48:
Title: A Bioplausible Model for the Expanding Hole Illusion: Insights into Retinal Processing and Illusory Motion
Authors: Nasim Nematzadeh, David M. W. Powers
Abstract: The Expanding Hole Illusion is a compelling visual phenomenon in which a static, concentric pattern evokes a strong perception of continuous forward motion. Despite its simplicity, this illusion challenges our understanding of how the brain processes visual information, particularly motion derived from static cues. While the neural basis of this illusion has remained elusive, recent psychophysical studies [1] reveal that this illusion induces not only a perceptual effect but also physiological responses, such as pupil dilation. This paper presents a computational model based on Difference of Gaussians (DoG) filtering and a classical receptive field (CRF) implementation to simulate early retinal processing and to explain the underlying mechanisms of this illusion. Based on our results we hypothesize that the illusion arises from contrast-dependent lateral inhibition in early visual processing. Our results demonstrate that contrast gradients and multi-layered spatial processing contribute to the perception of expansion, aligning closely with psychophysical findings and supporting the role of retinal ganglion cells in generating this illusory motion signal. Our findings provide insights into the perceptual biases driving dynamic illusions and offer a new framework for studying complex visual phenomena.

Paper number 49:
Title: Detecting Wildfire Flame and Smoke through Edge Computing using Transfer Learning Enhanced Deep Learning Models
Authors: Giovanny Vazquez, Shengjie Zhai, Mei Yang
Abstract: Autonomous unmanned aerial vehicles (UAVs) integrated with edge computing capabilities empower real-time data processing directly on the device, dramatically reducing latency in critical scenarios such as wildfire detection. This study underscores Transfer Learning's (TL) significance in boosting the performance of object detectors for identifying wildfire smoke and flames, especially when trained on limited datasets, and investigates the impact TL has on edge computing metrics. With the latter focusing how TL-enhanced You Only Look Once (YOLO) models perform in terms of inference time, power usage, and energy consumption when using edge computing devices. This study utilizes the Aerial Fire and Smoke Essential (AFSE) dataset as the target, with the Flame and Smoke Detection Dataset (FASDD) and the Microsoft Common Objects in Context (COCO) dataset serving as source datasets. We explore a two-stage cascaded TL method, utilizing D-Fire or FASDD as initial stage target datasets and AFSE as the subsequent stage. Through fine-tuning, TL significantly enhances detection precision, achieving up to 79.2% mean Average Precision (mAP@0.5), reduces training time, and increases model generalizability across the AFSE dataset. However, cascaded TL yielded no notable improvements and TL alone did not benefit the edge computing metrics evaluated. Lastly, this work found that YOLOv5n remains a powerful model when lacking hardware acceleration, finding that YOLOv5n can process images nearly twice as fast as its newer counterpart, YOLO11n. Overall, the results affirm TL's role in augmenting the accuracy of object detectors while also illustrating that additional enhancements are needed to improve edge computing performance.

Paper number 50:
Title: Adaptive Data Augmentation with NaturalSpeech3 for Far-field Speaker Verification
Authors: Li Zhang, Jiyao Liu, Lei Xie
Abstract: The scarcity of speaker-annotated far-field speech presents a significant challenge in developing high-performance far-field speaker verification (SV) systems. While data augmentation using large-scale near-field speech has been a common strategy to address this limitation, the mismatch in acoustic environments between near-field and far-field speech significantly hinders the improvement of far-field SV effectiveness. In this paper, we propose an adaptive speech augmentation approach leveraging NaturalSpeech3, a pre-trained foundation text-to-speech (TTS) model, to convert near-field speech into far-field speech by incorporating far-field acoustic ambient noise for data augmentation. Specifically, we utilize FACodec from NaturalSpeech3 to decompose the speech waveform into distinct embedding subspaces-content, prosody, speaker, and residual (acoustic details) embeddings-and reconstruct the speech waveform from these disentangled representations. In our method, the prosody, content, and residual embeddings of far-field speech are combined with speaker embeddings from near-field speech to generate augmented pseudo far-field speech that maintains the speaker identity from the out-domain near-field speech while preserving the acoustic environment of the in-domain far-field speech. This approach not only serves as an effective strategy for augmenting training data for far-field speaker verification but also extends to cross-data augmentation for enrollment and test speech in evaluation this http URL results on FFSVC demonstrate that the adaptive data augmentation method significantly outperforms traditional approaches, such as random noise addition and reverberation, as well as other competitive data augmentation strategies.

Paper number 51:
Title: XMusic: Towards a Generalized and Controllable Symbolic Music Generation Framework
Authors: Sida Tian, Can Zhang, Wei Yuan, Wei Tan, Wenjie Zhu
Abstract: In recent years, remarkable advancements in artificial intelligence-generated content (AIGC) have been achieved in the fields of image synthesis and text generation, generating content comparable to that produced by humans. However, the quality of AI-generated music has not yet reached this standard, primarily due to the challenge of effectively controlling musical emotions and ensuring high-quality outputs. This paper presents a generalized symbolic music generation framework, XMusic, which supports flexible prompts (i.e., images, videos, texts, tags, and humming) to generate emotionally controllable and high-quality symbolic music. XMusic consists of two core components, XProjector and XComposer. XProjector parses the prompts of various modalities into symbolic music elements (i.e., emotions, genres, rhythms and notes) within the projection space to generate matching music. XComposer contains a Generator and a Selector. The Generator generates emotionally controllable and melodious music based on our innovative symbolic music representation, whereas the Selector identifies high-quality symbolic music by constructing a multi-task learning scheme involving quality assessment, emotion recognition, and genre recognition tasks. In addition, we build XMIDI, a large-scale symbolic music dataset that contains 108,023 MIDI files annotated with precise emotion and genre labels. Objective and subjective evaluations show that XMusic significantly outperforms the current state-of-the-art methods with impressive music quality. Our XMusic has been awarded as one of the nine Highlights of Collectibles at WAIC 2023. The project homepage of XMusic is this https URL.

Paper number 52:
Title: Discrimination loss vs. SRT: A model-based approach towards harmonizing speech test interpretations
Authors: Mareike Buhl, Eugen Kludt, Lena Schell-Majoor, Paul Avan, Marta Campi
Abstract: Objective: Speech tests aim to estimate discrimination loss or speech recognition threshold (SRT). This paper investigates the potential to estimate SRTs from clinical data that target at characterizing the discrimination loss. Knowledge about the relationship between the speech test outcome variables--conceptually linked via the psychometric function--is important towards integration of data from different databases. Design: Depending on the available data, different SRT estimation procedures were compared and evaluated. A novel, model-based SRT estimation procedure was proposed that deals with incomplete patient data. Interpretations of supra-threshold deficits were assessed for the two interpretation modes. Study sample: Data for 27009 patients with Freiburg monosyllabic speech test (FMST) and audiogram (AG) results from the same day were included in the retrospective analysis. Results: The model-based SRT estimation procedure provided accurate SRTs, but with large deviations in the estimated slope. Supra-threshold hearing loss components differed between the two interpretation modes. Conclusions: The model-based procedure can be used for SRT estimation, and its properties relate to data availability for individual patients. All SRT procedures are influenced by the uncertainty of the word recognition scores. In the future, the proposed approach can be used to assess additional differences between speech tests.

Paper number 53:
Title: Learning Joint Denoising, Demosaicing, and Compression from the Raw Natural Image Noise Dataset
Authors: Benoit Brummer, Christophe De Vleeschouwer
Abstract: This paper introduces the Raw Natural Image Noise Dataset (RawNIND), a diverse collection of paired raw images designed to support the development of denoising models that generalize across sensors, image development workflows, and styles. Two denoising methods are proposed: one operates directly on raw Bayer data, leveraging computational efficiency, while the other processes linear RGB images for improved generalization to different sensors, with both preserving flexibility for subsequent development. Both methods outperform traditional approaches which rely on developed images. Additionally, the integration of denoising and compression at the raw data level significantly enhances rate-distortion performance and computational efficiency. These findings suggest a paradigm shift toward raw data workflows for efficient and flexible image processing.

Paper number 54:
Title: AI-RAN: Transforming RAN with AI-driven Computing Infrastructure
Authors: Lopamudra Kundu, Xingqin Lin, Rajesh Gadiyar, Jean-Francois Lacasse, Shuvo Chowdhury
Abstract: The radio access network (RAN) landscape is undergoing a transformative shift from traditional, communication-centric infrastructures towards converged compute-communication platforms. This article introduces AI-RAN which integrates both RAN and artificial intelligence (AI) workloads on the same infrastructure. By doing so, AI-RAN not only meets the performance demands of future networks but also improves asset utilization. We begin by examining how RANs have evolved beyond mobile broadband towards AI-RAN and articulating manifestations of AI-RAN into three forms: AI-for-RAN, AI-on-RAN, and AI-and-RAN. Next, we identify the key requirements and enablers for the convergence of communication and computing in AI-RAN. We then provide a reference architecture for advancing AI-RAN from concept to practice. To illustrate the practical potential of AI-RAN, we present a proof-of-concept that concurrently processes RAN and AI workloads utilizing NVIDIA Grace-Hopper GH200 servers. Finally, we conclude the article by outlining future work directions to guide further developments of AI-RAN.

Paper number 55:
Title: Cyclic Delay-Doppler Shift: A Simple Transmit Diversity Technique for Delay-Doppler Waveforms in Doubly Selective Channels
Authors: Haoran Yin, Jiaojiao Xiong, Yu Zhou, Chi Zhang, Di Zhang, Xizhang Wei, Yanqun Tang
Abstract: Delay-Doppler waveform design has been considered as a promising solution to achieve reliable communication under high-mobility channels for the space-air-ground-integrated networks (SAGIN). In this paper, we introduce the cyclic delay-Doppler shift (CDDS) technique for delay-Doppler waveforms to extract transmit diversity in doubly selective channels. Two simple CDDS schemes, named time-domain CDDS (TD-CDDS) and modulation-domain CDDS (MD-CDDS), are proposed in the setting of multiple-input multiple-output (MIMO). We demonstrate the applications of CDDS on two representative delay-Doppler waveforms, namely orthogonal time frequency space (OTFS) and affine frequency division multiplexing (AFDM), by deriving their corresponding CDDS matrices. Furthermore, we prove theoretically and experimentally that CDDS can provide OTFS and AFDM with full transmit diversity gain on most occasions.

Paper number 56:
Title: A design of Convolutional Neural Network model for the Diagnosis of the COVID-19
Authors: Xinyuan Song
Abstract: With the spread of COVID-19 around the globe over the past year, the usage of artificial intelligence (AI) algorithms and image processing methods to analyze the X-ray images of patients' chest with COVID-19 has become essential. The COVID-19 virus recognition in the lung area of a patient is one of the basic and essential needs of clicical centers and hospitals. Most research in this field has been devoted to papers on the basis of deep learning methods utilizing CNNs (Convolutional Neural Network), which mainly deal with the screening of sick and healthy this http URL this study, a new structure of a 19-layer CNN has been recommended for accurately recognition of the COVID-19 from the X-ray pictures of chest. The offered CNN is developed to serve as a precise diagnosis system for a three class (viral pneumonia, Normal, COVID) and a four classclassification (Lung opacity, Normal, COVID-19, and pneumonia). A comparison is conducted among the outcomes of the offered procedure and some popular pretrained networks, including Inception, Alexnet, ResNet50, Squeezenet, and VGG19 and based on Specificity, Accuracy, Precision, Sensitivity, Confusion Matrix, and F1-score. The experimental results of the offered CNN method specify its dominance over the existing published procedures. This method can be a useful tool for clinicians in deciding properly about COVID-19.

Paper number 57:
Title: Enforcing contraction via data
Authors: Zhongjie Hu, Claudio De Persis, Pietro Tesi
Abstract: We present data-based conditions for enforcing contractivity via feedback control and obtain desired asymptotic properties of the closed-loop system. We focus on unknown nonlinear control systems whose vector fields are expressible via a dictionary of functions and derive data-dependent semidefinite programs whose solution returns the controller that guarantees contractivity. When data are perturbed by disturbances that are linear combinations of sinusoids of known frequencies (but unknown amplitude and phase) and constants, we remarkably obtain conditions for contractivity that do not depend on the magnitude of the disturbances, with imaginable positive consequences for the synthesis of the controller. Finally, we show how to design from data an integral controller for nonlinear systems that achieves constant reference tracking and constant disturbance rejection.

Paper number 58:
Title: Implications of Zoning Ordinances for Rural Utility-Scale Solar Deployment and Power System Decarbonization in the Great Lakes Region
Authors: Papa Yaw Owusu-Obeng, Sarah Banas Mills, Michael T. Craig
Abstract: Local zoning ordinances across the United States have the impact of restricting development of energy infrastructure, including utility-scale solar photovoltaics. While these ordinances may be developed for legitimate purposes to protect public health and safety, they could impede or increase costs of power sector decarbonization. We quantify the role of utility-scale solar zoning ordinances on power sector decarbonization across the Great Lakes region (Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin) by integrating 6,300 rural community zoning ordinances into a power system planning model. Relative to no ordinances, solar zoning ordinances reduce total potential deployment of solar PV by 52% (or 1.6 TW) across our region. Currently, however, the biggest zoning barrier to deployment is zoning ordinances which are silent on utility-scale solar. Deployment restrictions translate to up to 4 GW greater investment needs and 5.6% greater PV investment costs to achieve a 10% PV generation target. Starker shifts occur at the state level, e.g. Wisconsin sees a 40% reduction in PV investments due to zoning restrictions. Our results underscore the need for planning that aligns local zoning laws with state and regional goals.

Paper number 59:
Title: EdgeSight: Enabling Modeless and Cost-Efficient Inference at the Edge
Authors: ChonLam Lao, Jiaqi Gao, Ganesh Ananthanarayanan, Aditya Akella, Minlan Yu
Abstract: Traditional ML inference is evolving toward modeless inference, which abstracts the complexity of model selection from users, allowing the system to automatically choose the most appropriate model for each request based on accuracy and resource requirements. While prior studies have focused on modeless inference within data centers, this paper tackles the pressing need for cost-efficient modeless inference at the edge -- particularly within its unique constraints of limited device memory, volatile network conditions, and restricted power consumption. To overcome these challenges, we propose EdgeSight, a system that provides cost-efficient EdgeSight serving for diverse DNNs at the edge. EdgeSight employs an edge-data center (edge-DC) architecture, utilizing confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. Additionally, it supports lossy inference in volatile network environments. Our experimental results show that EdgeSight outperforms existing systems by up to 1.6x in P99 latency for modeless services. Furthermore, our FPGA prototype demonstrates similar performance at certain accuracy levels, with a power consumption reduction of up to 3.34x.

Paper number 60:
Title: Audio-Visual Approach For Multimodal Concurrent Speaker Detection
Authors: Amit Eliav, Sharon Gannot
Abstract: Concurrent Speaker Detection (CSD), the task of identifying active speakers and their overlaps in an audio signal, is essential for various audio applications, including meeting transcription, speaker diarization, and speech separation. This study presents a multimodal deep learning approach that integrates audio and visual information. The proposed model utilizes an early fusion strategy, combining audio and visual features through cross-modal attention mechanisms with a learnable [CLS] token to capture key audio-visual relationships. The model is extensively evaluated on two real-world datasets, the established AMI dataset and the recently introduced EasyCom dataset. Experiments validate the effectiveness of the multimodal fusion strategy. An ablation study further supports the design choices and the model's training procedure. As this is the first work reporting CSD results on the challenging EasyCom dataset, the findings demonstrate the potential of the proposed multimodal approach for \ac{CSD} in real-world scenarios.

Paper number 61:
Title: Performance-Barrier Event-Triggered Control of a Class of Reaction-Diffusion PDEs
Authors: Bhathiya Rathnayake, Mamadou Diagne, Jorge Cortes, Miroslav Krstic
Abstract: We employ the recent performance-barrier event-triggered control (P-ETC) for achieving global exponential convergence of a class of reaction-diffusion PDEs via PDE backstepping control. Rather than insisting on a strictly monotonic decrease of the Lyapunov function for the closed-loop system, P-ETC allows the Lyapunov function to increase as long as it remains below an acceptable performance-barrier. This approach integrates a performance residual, the difference between the value of the performance-barrier and the Lyapunov function, into the triggering mechanism. The integration adds flexibility and results in fewer control updates than with regular ETC (R-ETC) that demands a monotonic decrease of the Lyapunov function. Our P-ETC PDE backstepping design ensures global exponential convergence of the closed-loop system in the spatial L^2 norm, without encountering Zeno phenomenon. To avoid continuous monitoring of the triggering function that generates events, we develop periodic event-triggered and self-triggered variants (P-PETC and P-STC, respectively) of the P-ETC. The P-PETC only requires periodic evaluation of the triggering function whereas the P-STC preemptively computes the time of the next event at the current event time using the system model and continuously available system states. The P-PETC and P-STC also ensure a Zeno-free behavior and deliver performance equivalent to that of the continuous-time P-ETC which requires continuous evaluation of the triggering function, in addition to the continuous sensing of the state. We provide numerical simulations to illustrate the proposed technique and to compare it with R-ETC associated with strictly decreasing Lyapunov functions.

Paper number 62:
Title: $T\bar{a}laGen:$ A System for Automatic $T\bar{a}la$ Identification and Generation
Authors: Rahul Bapusaheb Kodag, Himanshu Jindal, Vipul Arora
Abstract: In Hindustani classical music, the tabla plays an important role as a rhythmic backbone and accompaniment. In applications like computer-based music analysis, learning singing, and learning musical instruments, tabla stroke transcription, $t\bar{a}la$ identification, and generation are crucial. This paper proposes a comprehensive system aimed at addressing these challenges. For tabla stroke transcription, we propose a novel approach based on model-agnostic meta-learning (MAML) that facilitates the accurate identification of tabla strokes using minimal data. Leveraging these transcriptions, the system introduces two novel $t\bar{a}la$ identification methods based on the sequence analysis of tabla strokes. \par Furthermore, the paper proposes a framework for $t\bar{a}la$ generation to bridge traditional and modern learning methods. This framework utilizes finite state transducers (FST) and linear time-invariant (LTI) filters to generate $t\bar{a}las$ with real-time tempo control through user interaction, enhancing practice sessions and musical education. Experimental evaluations on tabla solo and concert datasets demonstrate the system's exceptional performance on real-world data and its ability to outperform existing methods. Additionally, the proposed $t\bar{a}la$ identification methods surpass state-of-the-art techniques. The contributions of this paper include a combined approach to tabla stroke transcription, innovative $t\bar{a}la$ identification techniques, and a robust framework for $t\bar{a}la$ generation that handles the rhythmic complexities of Hindustani music.

Paper number 63:
Title: Conformal Prediction for Manifold-based Source Localization with Gaussian Processes
Authors: Vadim Rozenfeld, Bracha Laufer Goldshtein
Abstract: We address the problem of uncertainty quantification (UQ) in the localization of a sound source within adverse acoustic environments. Estimating the position of the source is influenced by various factors, such as noise and reverberation, leading to significant uncertainty. Quantifying this uncertainty is essential, particularly when localization outcomes impact critical decision-making processes, such as in robot audition, where the accuracy of location estimates directly influences subsequent actions. Despite this, common localization methods offer point estimates without quantifying the estimation uncertainty. To address this, we employ conformal prediction (CP)-a framework that delivers statistically valid prediction intervals (PIs) with finite-sample guarantees, independent of the data distribution. However, commonly used Inductive CP (ICP) methods require a large amount of labeled data, which can be difficult to obtain in the localization setting. To mitigate this limitation, we incorporate a semi-supervised manifold-based localization method using Gaussian process regression (GPR), with an efficient Transductive CP (TCP) technique, specifically designed for GPR. We demonstrate that our method generates statistically valid PIs across different acoustic conditions, while producing smaller intervals compared to baselines.

Paper number 64:
Title: The Conformer Encoder May Reverse the Time Dimension
Authors: Robin Schmitt, Albert Zeyer, Mohammad Zeineldeen, Ralf Schlüter, Hermann Ney
Abstract: We sometimes observe monotonically decreasing cross-attention weights in our Conformer-based global attention-based encoder-decoder (AED) models, Further investigation shows that the Conformer encoder reverses the sequence in the time dimension. We analyze the initial behavior of the decoder cross-attention mechanism and find that it encourages the Conformer encoder self-attention to build a connection between the initial frames and all other informative frames. Furthermore, we show that, at some point in training, the self-attention module of the Conformer starts dominating the output over the preceding feed-forward module, which then only allows the reversed information to pass through. We propose methods and ideas of how this flipping can be avoided and investigate a novel method to obtain label-frame-position alignments by using the gradients of the label log probabilities w.r.t. the encoder input frames.

Paper number 65:
Title: An Integer-N Frequency Synthesizer for Flexible On-Chip Clock Generation
Authors: Soumyajit Mandal, Piotr Maj, Grzegorz W. Deptuch
Abstract: A low-power integer-N frequency synthesizer for flexible on-chip clock generation has been designed in 65 nm CMOS technology. The circuit can be programmed to generate two independent low-jitter clocks between 30 MHz and 3 GHz that are locked a 10-50 MHz reference input. The design uses a phase-locked loop (PLL) with a dual-tuned LC voltage-controlled oscillator (VCO), programmable feedback divider, and dual output dividers. The total power consumption from 1.2 V and 0.8 V supplies is 4.0 mW. Experimental results confirm the functionality of the proposed synthesizer over a wide range of output frequencies.

Paper number 66:
Title: CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls
Authors: Li Chai, Donglin Wang
Abstract: Lyric-to-melody generation is a highly challenging task in the field of AI music generation. Due to the difficulty of learning strict yet weak correlations between lyrics and melodies, previous methods have suffered from weak controllability, low-quality and poorly structured generation. To address these challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody generation method based on an in-attention Transformer decoder with fine-grained lyric and musical controls, which is able to generate full-song melodies matched with the given lyrics and user-specified musical attributes. Specifically, we first introduce REMI-Aligned, a novel music representation that incorporates strict syllable- and sentence-level alignments between lyrics and melodies, facilitating precise alignment modeling. Subsequently, sentence-level semantic lyric embeddings independently extracted from a sentence-wise Transformer encoder are combined with word-level part-of-speech embeddings and syllable-level tone embeddings as fine-grained controls to enhance the controllability of lyrics over melody generation. Then we introduce human-labeled musical tags, sentence-level statistical musical attributes, and learned musical features extracted from a pre-trained VQ-VAE as coarse-grained, fine-grained and high-fidelity controls, respectively, to the generation process, thereby enabling user control over melody generation. Finally, an in-attention Transformer decoder technique is leveraged to exert fine-grained control over the full-song melody generation with the aforementioned lyric and musical conditions. Experimental results demonstrate that our proposed CSL-L2M outperforms the state-of-the-art models, generating melodies with higher quality, better controllability and enhanced structure. Demos and source code are available at this https URL.

Paper number 67:
Title: Performance-Barrier Event-Triggered PDE Control of Traffic Flow
Authors: Peihan Zhang, Bhathiya Rathnayake, Mamadou Diagne, Miroslav Krstic
Abstract: For stabilizing stop-and-go oscillations in traffic flow by actuating a variable speed limit (VSL) at a downstream boundary of a freeway segment, we introduce event-triggered PDE backstepping designs employing the recent concept of performance-barrier event-triggered control (P-ETC). Our design is for linearized hyperbolic Aw-Rascle-Zhang (ARZ) PDEs governing traffic velocity and density. Compared to continuous feedback, ETC provides a piecewise-constant VSL commands-more likely to be obeyed by human drivers. Unlike the existing regular ETC (R-ETC), which enforces conservatively a strict decrease of a Lyapunov function, our performance-barrier (P-ETC) approach permits an increase, as long as the Lyapunov function remains below a performance barrier, resulting in fewer control updates than R-ETC. To relieve VSL from continuously monitoring the triggering function, we also develop periodic event-triggered (PETC) and self-triggered (STC) versions of both R-ETC and P-ETC. These are referred to as R/P-PETC and R/P-STC, respectively, and we show that they both guarantee Zeno-free behavior and exponential convergence in the spatial $L^2$ norm. With comparative simulations, we illustrate the benefits of the performance-barrier designs through traffic metrics (driver comfort, safety, travel time, fuel consumption). The proposed algorithms reduce discomfort nearly in half relative to driver behavior without VSL, while tripling the driver safety, measured by the average dwell time, relative to the R-ETC frequent-switching VSL schedule.

Paper number 68:
Title: Resilient Distributed Optimization for Multi-Agent Cyberphysical Systems
Authors: Michal Yemini, Angelia Nedić, Andrea J. Goldsmith, Stephanie Gil
Abstract: This work focuses on the problem of distributed optimization in multi-agent cyberphysical systems, where a legitimate agent's iterates are influenced both by the values it receives from potentially malicious neighboring agents, and by its own self-serving target function. We develop a new algorithmic and analytical framework to achieve resilience for the class of problems where stochastic values of trust between agents exist and can be exploited. In this case, we show that convergence to the true global optimal point can be recovered, both in mean and almost surely, even in the presence of malicious agents. Furthermore, we provide expected convergence rate guarantees in the form of upper bounds on the expected squared distance to the optimal value. Finally, numerical results are presented that validate our analytical convergence guarantees even when the malicious agents compose the majority of agents in the network and where existing methods fail to converge to the optimal nominal points.

Paper number 69:
Title: Delay Sensitive Hierarchical Federated Learning with Stochastic Local Updates
Authors: Abdulmoneam Ali, Ahmed Arafa
Abstract: The impact of local averaging on the performance of federated learning (FL) systems is studied in the presence of communication delay between the clients and the parameter server. To minimize the effect of delay, clients are assigned into different groups, each having its own local parameter server (LPS) that aggregates its clients' models. The groups' models are then aggregated at a global parameter server (GPS) that only communicates with the LPSs. Such setting is known as hierarchical FL (HFL). Unlike most works in the literature, the number of local and global communication rounds in our work is randomly determined by the (different) delays experienced by each group of clients. Specifically, the number of local averaging rounds is tied to a wall-clock time period coined the sync time $S$, after which the LPSs synchronize their models by sharing them with the GPS. Such sync time $S$ is then reapplied until a global wall-clock time is exhausted. First, an upper bound on the deviation between the updated model at each LPS with respect to that available at the GPS is derived. This is then used as a tool to derive the convergence analysis of our proposed delay-sensitive HFL algorithm, first at each LPS individually, and then at the GPS. Our theoretical convergence bound showcases the effects of the whole system's parameters, including the number of groups, the number of clients per group, and the value of $S$. Our results show that the value of $S$ should be carefully chosen, especially since it implicitly governs how the delay statistics affect the performance of HFL in situations where training time is restricted.

Paper number 70:
Title: Observer-based Periodic Event-triggered and Self-triggered Boundary Control of a Class of Parabolic PDEs
Authors: Bhathiya Rathnayake, Mamadou Diagne
Abstract: This paper introduces the first observer-based periodic event-triggered control (PETC) and self-triggered control (STC) for boundary control of a class of parabolic PDEs using PDE backstepping control. We introduce techniques to convert a certain class of continuous-time event-triggered control into PETC and STC, eliminating the need for continuous monitoring of the event-triggering function. For the PETC, the event-triggering function requires only periodic evaluations to detect events, while the STC proactively computes the time of the next event right at the current event time using the system model and the continuously available measurements. For both strategies, the control input is updated exclusively at events and is maintained using a zero-order hold between events. We demonstrate that the closed-loop system is Zeno-free. We offer criteria for selecting an appropriate sampling period for the PETC and for determining the time until the next event under the STC. We prove the system's global exponential convergence to zero in the spatial $L^2$ norm for both anti-collocated and collocated sensing and actuation under the PETC. For the STC, local exponential convergence to zero in the spatial $L^2$ norm for collocated sensing and actuation is proven. Simulations are provided to illustrate the theoretical claims.

Paper number 71:
Title: Performance Analysis of Holographic MIMO Based Integrated Sensing and Communications
Authors: Boqun Zhao, Chongjun Ouyang, Xingqi Zhang, Yuanwei Liu
Abstract: A holographic multiple-input multiple-output (MIMO)-based integrated sensing and communications (ISAC) framework is proposed for both downlink and uplink scenarios. The spatial correlation is incorporated into the communication channel modeling, while a spherical wave-based model is used to characterize the sensing link. By considering both instantaneous and statistical channel state information, closed-form expressions are derived for sensing rates (SRs), communication rates (CRs), and outage probabilities under various ISAC designs. This enables an investigation into the theoretical performance limits of the proposed holographic MIMO-based ISAC (HISAC) framework. Further insights are gained by examining the high signal-to-noise ratio (SNR) slopes and diversity orders. Specifically: i) for the downlink case, a sensing-centric (S-C) design and a communications-centric (C-C) design are investigated using different beamforming strategies, and a Pareto optimal design is proposed to characterize the attainable SR-CR region; ii) for the uplink case, the S-C design and the C-C design differ in the interference cancellation order between the communication and sensing signals, with the rate region obtained through a time-sharing strategy. Numerical results are provided to demonstrate that HISAC systems outperform both conventional MIMO-based ISAC systems and holographic MIMO-based frequency-division sensing and communications systems, underscoring the superior performance of the HISAC framework.

Paper number 72:
Title: SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph Neural Networks
Authors: Azmine Toushik Wasi, MD Shafikul Islam, Adipto Raihan Akib
Abstract: Graph Neural Networks (GNNs) have gained traction across different domains such as transportation, bio-informatics, language processing, and computer vision. However, there is a noticeable absence of research on applying GNNs to supply chain networks. Supply chain networks are inherently graph-like in structure, making them prime candidates for applying GNN methodologies. This opens up a world of possibilities for optimizing, predicting, and solving even the most complex supply chain problems. A major setback in this approach lies in the absence of real-world benchmark datasets to facilitate the research and resolution of supply chain problems using GNNs. To address the issue, we present a real-world benchmark dataset for temporal tasks, obtained from one of the leading FMCG companies in Bangladesh, focusing on supply chain planning for production purposes. The dataset includes temporal data as node features to enable sales predictions, production planning, and the identification of factory issues. By utilizing this dataset, researchers can employ GNNs to address numerous supply chain problems, thereby advancing the field of supply chain analytics and planning. Source: this https URL

Paper number 73:
Title: Approximation properties relative to continuous scale space for hybrid discretizations of Gaussian derivative operators
Authors: Tony Lindeberg
Abstract: This paper presents an analysis of properties of two hybrid discretization methods for Gaussian derivatives, based on convolutions with either the normalized sampled Gaussian kernel or the integrated Gaussian kernel followed by central differences. The motivation for studying these discretization methods is that in situations when multiple spatial derivatives of different order are needed at the same scale level, they can be computed significantly more efficiently compared to more direct derivative approximations based on explicit convolutions with either sampled Gaussian kernels or integrated Gaussian kernels. While these computational benefits do also hold for the genuinely discrete approach for computing discrete analogues of Gaussian derivatives, based on convolution with the discrete analogue of the Gaussian kernel followed by central differences, the underlying mathematical primitives for the discrete analogue of the Gaussian kernel, in terms of modified Bessel functions of integer order, may not be available in certain frameworks for image processing, such as when performing deep learning based on scale-parameterized filters in terms of Gaussian derivatives, with learning of the scale levels. In this paper, we present a characterization of the properties of these hybrid discretization methods, in terms of quantitative performance measures concerning the amount of spatial smoothing that they imply, as well as the relative consistency of scale estimates obtained from scale-invariant feature detectors with automatic scale selection, with an emphasis on the behaviour for very small values of the scale parameter, which may differ significantly from corresponding results obtained from the fully continuous scale-space theory, as well as between different types of discretization methods.

Paper number 74:
Title: Let Network Decide What to Learn: Symbolic Music Understanding Model Based on Large-scale Adversarial Pre-training
Authors: Zijian Zhao
Abstract: As a crucial aspect of Music Information Retrieval (MIR), Symbolic Music Understanding (SMU) has garnered significant attention for its potential to assist both musicians and enthusiasts in learning and creating music. Recently, pre-trained language models have been widely adopted in SMU due to the substantial similarities between symbolic music and natural language, as well as the ability of these models to leverage limited music data effectively. However, some studies have shown the common pre-trained methods like Mask Language Model (MLM) may introduce bias issues like racism discrimination in Natural Language Process (NLP) and affects the performance of downstream tasks, which also happens in SMU. This bias often arises when masked tokens cannot be inferred from their context, forcing the model to overfit the training set instead of generalizing. To address this challenge, we propose Adversarial-MidiBERT for SMU, which adaptively determines what to mask during MLM via a masker network, rather than employing random masking. By avoiding the masking of tokens that are difficult to infer from context, our model is better equipped to capture contextual structures and relationships, rather than merely conforming to the training data distribution. We evaluate our method across four SMU tasks, and our approach demonstrates excellent performance in all cases. The code for our model is publicly available at this https URL.

Paper number 75:
Title: Exploring the 6G Potentials: Immersive, Hyper Reliable, and Low-Latency Communication
Authors: Afsoon Alidadi Shamsabadi, Animesh Yadav, Yasser Gadallah, Halim Yanikomeroglu
Abstract: The transition towards the sixth-generation (6G) wireless telecommunications networks introduces significant challenges for researchers and industry stakeholders. The 6G technology aims to enhance existing usage scenarios through supporting innovative applications that require stringent key performance indicators (KPIs). In some critical use cases of 6G, multiple KPIs, including immersive throughput, with an envisioned peak data rate of $1$ Tbps, hyper-reliability, in the range of $10^{-5}$ to $10^{-7}$, and hyper low-latency, between $0.1$ and $1$ ms, must be achieved simultaneously to deliver the expected service experience. However, this is challenging due to the conflicting nature of these KPIs. This article proposes a new service class of 6G as immersive, hyper reliable, and low-latency communication (IHRLLC), and introduces a potential network architecture to achieve the associated KPIs. Specifically, enhanced technologies, such as ultra-massive multiple-input multiple-output (umMIMO)-aided terahertz (THz) communications, reconfigurable intelligent surfaces (RIS), and non-terrestrial networks (NTN), are viewed as the key enablers for achieving immersive data rates and hyper reliability. Given the computational complexity involved in employing these technologies, we propose mathematical and computational enabling technologies, such as learn-to-optimize (L2O), generative-AI (GenAI), quantum computing, and network digital twin (NDT), to complement the proposed architecture and optimize the latency.

Paper number 76:
Title: CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network
Authors: Zijian Zhao, Tingwei Chen, Zhijie Cai, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu
Abstract: In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. The code for our model is publicly available at this https URL.

Paper number 77:
Title: Salmon: A Suite for Acoustic Language Model Evaluation
Authors: Gallil Maimon, Amit Roth, Yossi Adi
Abstract: Speech language models have recently demonstrated great potential as universal speech processing systems. Such models have the ability to model the rich acoustic information existing in audio signals, beyond spoken content, such as emotion, background noise, etc. Despite this, evaluation benchmarks which evaluate awareness to a wide range of acoustic aspects, are lacking. To help bridge this gap, we introduce SALMon, a novel evaluation suite encompassing background noise, emotion, speaker identity and room impulse response. The proposed benchmarks both evaluate the consistency of the inspected element and how much it matches the spoken text. We follow a modelling based approach, measuring whether a model gives correct samples higher scores than incorrect ones. This approach makes the benchmark fast to compute even for large models. We evaluated several speech language models on SALMon, thus highlighting the strengths and weaknesses of each evaluated method. We make the code and data publicly available at this https URL .

Paper number 78:
Title: Sparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers
Authors: Dominic Schneider, Lutz Rapp
Abstract: Optical fiber amplifiers are key elements in present optical networks. Failures of these components result in high financial loss of income of the network operator as the communication traffic over an affected link is interrupted. Applying Remaining useful lifetime (RUL) prediction in the context of Predictive Maintenance (PdM) to optical fiber amplifiers to predict upcoming system failures at an early stage, so that network outages can be minimized through planning of targeted maintenance actions, ensures reliability and safety. Optical fiber amplifier are complex systems, that work under various operating conditions, which makes correct forecasting a difficult task. Increased monitoring capabilities of systems results in datasets that facilitate the application of data-driven RUL prediction methods. Deep learning models in particular have shown good performance, but generalization based on comparatively small datasets for RUL prediction is difficult. In this paper, we propose Sparse Low-ranked self-Attention Transformer (SLAT) as a novel RUL prediction method. SLAT is based on an encoder-decoder architecture, wherein two parallel working encoders extract features for sensors and time steps. By utilizing the self-attention mechanism, long-term dependencies can be learned from long sequences. The implementation of sparsity in the attention matrix and a low-rank parametrization reduce overfitting and increase generalization. Experimental application to optical fiber amplifiers exemplified on EDFA, as well as a reference dataset from turbofan engines, shows that SLAT outperforms the state-of-the-art methods.

Paper number 79:
Title: Diffusion-based Unsupervised Audio-visual Speech Enhancement
Authors: Jean-Eudes Ayilo (MULTISPEECH), Mostafa Sadeghi (MULTISPEECH), Romain Serizel (MULTISPEECH), Xavier Alameda-Pineda (ROBOTLEARN)
Abstract: This paper proposes a new unsupervised audio-visual speech enhancement (AVSE) approach that combines a diffusion-based audio-visual speech generative model with a non-negative matrix factorization (NMF) noise model. First, the diffusion model is pre-trained on clean speech conditioned on corresponding video data to simulate the speech generative distribution. This pre-trained model is then paired with the NMF-based noise model to estimate clean speech iteratively. Specifically, a diffusion-based posterior sampling approach is implemented within the reverse diffusion process, where after each iteration, a speech estimate is obtained and used to update the noise parameters. Experimental results confirm that the proposed AVSE approach not only outperforms its audio-only counterpart but also generalizes better than a recent supervised-generative AVSE method. Additionally, the new inference algorithm offers a better balance between inference speed and performance compared to the previous diffusion-based method. Code and demo available at: this https URL

Paper number 80:
Title: SCOREQ: Speech Quality Assessment with Contrastive Regression
Authors: Alessandro Ragano, Jan Skoglund, Andrew Hines
Abstract: In this paper, we present SCOREQ, a novel approach for speech quality prediction. SCOREQ is a triplet loss function for contrastive regression that addresses the domain generalisation shortcoming exhibited by state of the art no-reference speech quality metrics. In the paper we: (i) illustrate the problem of L2 loss training failing at capturing the continuous nature of the mean opinion score (MOS) labels; (ii) demonstrate the lack of generalisation through a benchmarking evaluation across several speech domains; (iii) outline our approach and explore the impact of the architectural design decisions through incremental evaluation; (iv) evaluate the final model against state of the art models for a wide variety of data and domains. The results show that the lack of generalisation observed in state of the art speech quality metrics is addressed by SCOREQ. We conclude that using a triplet loss function for contrastive regression improves generalisation for speech quality prediction models but also has potential utility across a wide range of applications using regression-based predictive models.

Paper number 81:
Title: A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series
Authors: Lucas Correia, Jan-Christoph Goos, Thomas Bäck, Anna V. Kononova
Abstract: Benchmarking anomaly detection approaches for multivariate time series is challenging due to the lack of high-quality datasets. Current publicly available datasets are too small, not diverse and feature trivial anomalies, which hinders measurable progress in this research area. We propose a solution: a diverse, extensive, and non-trivial dataset generated via state-of-the-art simulation tools that reflects realistic behaviour of an automotive powertrain, including its multivariate, dynamic and variable-state properties. To cater for both unsupervised and semi-supervised anomaly detection settings, as well as time series generation and forecasting, we make different versions of the dataset available, where training and test subsets are offered in contaminated and clean versions, depending on the task. We also provide baseline results from a small selection of approaches based on deterministic and variational autoencoders, as well as a non-parametric approach. As expected, the baseline experimentation shows that the approaches trained on the semi-supervised version of the dataset outperform their unsupervised counterparts, highlighting a need for approaches more robust to contaminated training data.

Paper number 82:
Title: MSA-ASR: Efficient Multilingual Speaker Attribution with frozen ASR Models
Authors: Thai-Binh Nguyen, Alexander Waibel
Abstract: Speaker-attributed automatic speech recognition (SA-ASR) aims to transcribe speech while assigning transcripts to the corresponding speakers accurately. Existing methods often rely on complex modular systems or require extensive fine-tuning of joint modules, limiting their adaptability and general efficiency. This paper introduces a novel approach, leveraging a frozen multilingual ASR model to incorporate speaker attribution into the transcriptions, using only standard monolingual ASR datasets. Our method involves training a speaker module to predict speaker embeddings based on weak labels without requiring additional ASR model modifications. Despite being trained exclusively with non-overlapping monolingual data, our approach effectively extracts speaker attributes across diverse multilingual datasets, including those with overlapping speech. Experimental results demonstrate competitive performance compared to strong baselines, highlighting the model's robustness and potential for practical applications.

Paper number 83:
Title: On the Surprising Effectiveness of Spectrum Clipping in Learning Stable Linear Dynamics
Authors: Hanyao Guo, Yunhai Han, Harish Ravichandar
Abstract: When learning stable linear dynamical systems from data, three important properties are desirable: i) predictive accuracy, ii) provable stability, and iii) computational efficiency. Unconstrained minimization of reconstruction errors leads to high accuracy and efficiency but cannot guarantee stability. Existing methods to remedy this focus on enforcing stability while also ensuring accuracy, but do so only at the cost of increased computation. In this work, we investigate if a straightforward approach can simultaneously offer all three desiderata of learning stable linear systems. Specifically, we consider a post-hoc approach that manipulates the spectrum of the learned system matrix after it is learned in an unconstrained fashion. We call this approach spectrum clipping (SC) as it involves eigen decomposition and subsequent reconstruction of the system matrix after clipping all of its eigenvalues that are larger than one to one (without altering the eigenvectors). Through detailed experiments involving two different applications and publicly available benchmark datasets, we demonstrate that this simple technique can simultaneously learn highly accurate linear systems that are provably stable. Notably, we demonstrate that SC can achieve similar or better performance than strong baselines while being orders-of-magnitude faster. We also show that SC can be readily combined with Koopman operators to learn stable nonlinear dynamics, such as those underlying complex dexterous manipulation skills involving multi-fingered robotic hands. Further, we find that SC can learn stable robot policies even when the training data includes unsuccessful or truncated demonstrations. Our codes and dataset can be found at this https URL.

Paper number 84:
Title: AoI in Context-Aware Hybrid Radio-Optical IoT Networks
Authors: Aymen Hamrouni, Sofie Pollin, Hazem Sallouha
Abstract: With the surge in IoT devices ranging from wearables to smart homes, prompt transmission is crucial. The Age of Information (AoI) emerges as a critical metric in this context, representing the freshness of the information transmitted across the network. This paper studies hybrid IoT networks that employ Optical Communication (OC) as a reinforcement medium to Radio Frequency (RF). We formulate a non-linear convex optimization that adopts a multi-objective optimization strategy to dynamically schedule the communication between devices and select their corresponding communication technology, aiming to balance the maximization of network throughput with the minimization of energy usage and the frequency of switching between technologies. To mitigate the impact of dominant sub-objectives and their scale disparity, the designed approach employs a regularization method that approximates adequate sub-objective scaling weights. Simulation results show that the OC supplementary integration alongside RF enhances the network's overall performances and significantly reduces the Mean AoI and Peak AoI, allowing the collection of the freshest possible data using the best available communication technology.

Paper number 85:
Title: A Tractable Approach for Queueing Analysis on Buffer-Aware Scheduling
Authors: Lintao Li, Wei Chen
Abstract: Low-latency communication has recently attracted considerable attention owing to its potential of enabling delay-sensitive services in next-generation industrial cyber-physical systems. To achieve target average or maximum delay given random arrivals and time-varying channels, buffer-aware scheduling is expected to play a vital role. Evaluating and optimizing buffer-aware scheduling relies on its queueing analysis, while existing tools are not sufficiently tractable. Particularly, Markov chain and Monte-Carlo based approaches are computationally intensive, while large deviation theory (LDT) and extreme value theory (EVT) fail in providing satisfactory accuracy in the small-queue-length (SQL) regime. To tackle these challenges, a tractable yet accurate queueing analysis is presented by judiciously bridging Markovian analysis for the computationally manageable SQL regime and LDT/EVT for large-queue-length (LQL) regime where approximation error diminishes asymptotically. Specifically, we leverage censored Markov chain augmentation to approximate the original one in the SQL regime, while a piecewise approach is conceived to apply LDT/EVT across various queue-length intervals with different scheduling parameters. Furthermore, we derive closed-form bounds on approximation errors, validating the rigor and accuracy of our approach. As a case study, the approach is applied to analytically analyze a Lyapunov-drift-based cross-layer scheduling for wireless transmissions. Numerical results demonstrate its potential in balancing accuracy and complexity.

Paper number 86:
Title: The Silent Majority: Demystifying Memorization Effect in the Presence of Spurious Correlations
Authors: Chenyu You, Haocheng Dai, Yifei Min, Jasjeet S. Sekhon, Sarang Joshi, James S. Duncan
Abstract: Machine learning models often rely on simple spurious features -- patterns in training data that correlate with targets but are not causally related to them, like image backgrounds in foreground classification. This reliance typically leads to imbalanced test performance across minority and majority groups. In this work, we take a closer look at the fundamental cause of such imbalanced performance through the lens of memorization, which refers to the ability to predict accurately on \textit{atypical} examples (minority groups) in the training set but failing in achieving the same accuracy in the testing set. This paper systematically shows the ubiquitous existence of spurious features in a small set of neurons within the network, providing the first-ever evidence that memorization may contribute to imbalanced group performance. Through three experimental sources of converging empirical evidence, we find the property of a small subset of neurons or channels in memorizing minority group information. Inspired by these findings, we articulate the hypothesis: the imbalanced group performance is a byproduct of ``noisy'' spurious memorization confined to a small set of neurons. To further substantiate this hypothesis, we show that eliminating these unnecessary spurious memorization patterns via a novel framework during training can significantly affect the model performance on minority groups. Our experimental results across various architectures and benchmarks offer new insights on how neural networks encode core and spurious knowledge, laying the groundwork for future research in demystifying robustness to spurious correlation.
    