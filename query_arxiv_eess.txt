
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Control of dynamical systems with neural networks
Authors: Lucas Böttcher
Abstract: Control problems frequently arise in scientific and industrial applications, where the objective is to steer a dynamical system from an initial state to a desired target state. Recent advances in deep learning and automatic differentiation have made applying these methods to control problems increasingly practical. In this paper, we examine the use of neural networks and modern machine-learning libraries to parameterize control inputs across discrete-time and continuous-time systems, as well as deterministic and stochastic dynamics. We highlight applications in multiple domains, including biology, engineering, physics, and medicine. For continuous-time dynamical systems, neural ordinary differential equations (neural ODEs) offer a useful approach to parameterizing control inputs. For discrete-time systems, we show how custom control-input parameterizations can be implemented and optimized using automatic-differentiation methods. Overall, the methods presented provide practical solutions for control tasks that are computationally demanding or analytically intractable, making them valuable for complex real-world applications.

Paper number 2:
Title: Automatic Speech Recognition in the Modern Era: Architectures, Training, and Evaluation
Authors: Md. Nayeem, Md Shamse Tabrej, Kabbojit Jit Deb, Shaonti Goswami, Md. Azizul Hakim
Abstract: Automatic Speech Recognition (ASR) has undergone a profound transformation over the past decade, driven by advances in deep learning. This survey provides a comprehensive overview of the modern era of ASR, charting its evolution from traditional hybrid systems, such as Gaussian Mixture Model-Hidden Markov Models (GMM-HMMs) and Deep Neural Network-HMMs (DNN-HMMs), to the now-dominant end-to-end neural architectures. We systematically review the foundational end-to-end paradigms: Connectionist Temporal Classification (CTC), attention-based encoder-decoder models, and the Recurrent Neural Network Transducer (RNN-T), which established the groundwork for fully integrated speech-to-text systems. We then detail the subsequent architectural shift towards Transformer and Conformer models, which leverage self-attention to capture long-range dependencies with high computational efficiency. A central theme of this survey is the parallel revolution in training paradigms. We examine the progression from fully supervised learning, augmented by techniques like SpecAugment, to the rise of self-supervised learning (SSL) with foundation models such as wav2vec 2.0, which drastically reduce the reliance on transcribed data. Furthermore, we analyze the impact of largescale, weakly supervised models like Whisper, which achieve unprecedented robustness through massive data diversity. The paper also covers essential ecosystem components, including key datasets and benchmarks (e.g., LibriSpeech, Switchboard, CHiME), standard evaluation metrics (e.g., Word Error Rate), and critical considerations for real-world deployment, such as streaming inference, on-device efficiency, and the ethical imperatives of fairness and robustness. We conclude by outlining open challenges and future research directions.

Paper number 3:
Title: Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation
Authors: Alistair Brash, Junyi Lu, Bruce Stephen, Blair Brown, Robert Atkinson, Craig Michie, Fraser MacIntyre, Christos Tachtatzis
Abstract: Limited visibility of power distribution network power flows at the low voltage level presents challenges to both distribution network operators from a planning perspective and distribution system operators from a congestion management perspective. Forestalling these challenges through scenario analysis is confounded by the lack of realistic and coherent load data across representative distribution feeders. Load profiling approaches often rely on summarising demand through typical profiles, which oversimplifies the complexity of substation-level operations and limits their applicability in specific power system studies. Sampling methods, and more recently generative models, have attempted to address this through synthesising representative loads from historical exemplars; however, while these approaches can approximate load shapes to a convincing degree of fidelity, the co-behaviour between substations, which ultimately impacts higher voltage level network operation, is often overlooked. This limitation will become even more pronounced with the increasing integration of low-carbon technologies, as estimates of base loads fail to capture load diversity. To address this gap, a Conditional Diffusion model for synthesising daily active and reactive power profiles at the low voltage distribution substation level is proposed. The evaluation of fidelity is demonstrated through conventional metrics capturing temporal and statistical realism, as well as power flow modelling. The results show synthesised load profiles are plausible both independently and as a cohort in a wider power systems context. The Conditional Diffusion model is benchmarked against both naive and state-of-the-art models to demonstrate its effectiveness in producing realistic scenarios on which to base sub-regional power distribution network planning and operations.

Paper number 4:
Title: ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization
Authors: Sanjay Johnson, Dirk Lauinger, Sungho Shin, François Pacaud
Abstract: As GPU-accelerated mathematical programming techniques mature, there is growing interest in utilizing them to address the computational challenges of power system optimization. This paper introduces this http URL, an open-source modeling library for creating GPU-compatible nonlinear AC optimal power flow models. Built on this http URL, this http URL provides a high-level interface that automatically generates all necessary callback functions for GPU solvers. The library is designed for large-scale problem instances, which may include multiple time periods and security constraints. Using this http URL, we benchmark GPU and CPU solvers on open-source test cases. Our results show that GPU solvers can deliver up to two orders of magnitude speedups compared to alternative tools on CPU for problems with more than 20,000 variables and a solution precision of up to $10^{-4}$, while performance for smaller instances or tighter tolerances may vary.

Paper number 5:
Title: Effective Connectivity-Based Unsupervised Channel Selection Method for EEG
Authors: Neda Abdollahpour, N. Sertac Artan, Ian Daly, Mohammadreza Yazdchi, Zahra Baharlouei
Abstract: Analyzing neural data such as Electroencephalography (EEG) data often involves dealing with high-dimensional datasets, where not all channels provide equally meaningful informa- tion. Selecting the most relevant channels is crucial for improving computational efficiency and ensuring robust insights into neural dynamics. This study introduces the Importance of Channels based on Effective Connectivity (ICEC) criterion for quantifying effective connectivity (EC) in each channel. Effective connectivity refers to the causal influence one neural region exerts over another, providing insights into the directional flow of information. Using this criterion, we propose an unsupervised channel selection method that accounts for the intensity of interactions among channels. To evaluate the proposed channel selection method, we applied it to three well-known EEG datasets across four categories. The assessment involved calculating the ICEC criterion using five effective connectivity metrics: partial directed coherence (PDC), generalized PDC (GPDC), renormalized PDC (RPDC), directed transfer function (DTF), and direct DTF (dDTF). To focus on the effect of channel selection, we employed the Common Spatial Pattern (CSP) algorithm for feature extraction and a Support Vector Machine (SVM) for classification across all participants. Results were compared with other CSP-based methods. The evaluation included comparing participant- specific accuracies with and without the proposed method across five effective connectivity metrics. The results showed consistent performance improvements and a significant reduction in the number of selected electrodes for all participants. Compared to state-of-the-art methods, our approach achieved the highest accuracies: 82% (13 out of 22 channels), 86.01% (29 out of 59 channels), and 87.56% (48 out of 118 channels) across three datasets.

Paper number 6:
Title: Enabling Full Duplex ISAC Leveraging Waveform Domain Separability
Authors: Abdelali Arous, Hamza Haif, Huseyin Arslan
Abstract: Integrated sensing and communication (ISAC) in monostatic in-band full-duplex (IBFD) systems encounters significant challenges due to self-interference (SI) at the radar receiver during concurrent communication and radar operations. This paper proposes a novel waveform-domain self-interference cancellation (SIC) technique that leverages the unique properties of orthogonal frequency division multiplexing (OFDM) and affine frequency division multiplexing (AFDM) signals. The proposed approach designs the integrated dual-functionality frame to utilize OFDM for communication and AFDM for radar sensing, both generated using the same modulator block. Then, we establish the conditions under which a wide sense stationary (WSS) process in the time domain appears as WSS in the affine domain and demonstrate that the interfering OFDM signal behaves as an additive white Gaussian noise (AWGN) in this domain. Exploiting this property, the received signal is projected into the affine domain, where the SI appears as AWGN, enabling its subtraction with minimal residual interference. To further mitigate the residual SI, an iterative low-complexity windowing scheme is applied, selectively locking onto the radar signal to reduce the processed signal space. A subsequent time-domain spreading step is applied after converting the SIC-processed signal into the post-coded time domain, wherein the SI diminishes separately across the delay and Doppler axes. The proposed method demonstrates superior performance in terms of detection probability, target range and velocity root mean square error (RMSE), while maintaining high spectral efficiency and minimal computational complexity.

Paper number 7:
Title: A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems
Authors: Zhi Liu, Chengxi Liu, Jiangbei Han, Rui Qiu, Mingyuan Liu
Abstract: This paper proposes a wideband composite sequence impedance model (WCSIM)-based analysis method to evaluate the interactions in power-electronic-based power systems subjected to unbalanced grid faults or with unbalanced loads. The WCSIM-based method intuitively assesses the impact of the small-signal interconnection among the positive-, negative-, and zero-sequence circuits on the interaction stability of unbalanced power systems. The effectiveness of this method is demonstrated using a permanent magnet synchronous generator-based weak grid system under a single-line-to-ground fault (SLGF). Frequency scanning results and controller hardware-in-loop tests validate both the correctness of the WCSIM and the effectiveness of the WCSIM-based analysis method.

Paper number 8:
Title: Passive Microwave Tag Classification Using RF Fingerprinting and Machine Learning
Authors: Cory Hilton, Mohammad Rashid, Faiz Sherman, Steven Bush, Jeffrey A. Nanzer
Abstract: We present an approach to identifying wireless microwave tags using radio frequency (RF) fingerprinting and machine learning. The tags are designed for low cost and simplicity, consisting of only two antennas and a single nonlinear element (a diode). An interrogating transceiver transmits a signal consisting of a set of individual frequency tones that is captured by the tag. The signal response of the diode is nonlinear, and can be represented by an infinite power series, the coefficients of which are similar but not identical for different physical diodes due to small manufacturing perturbations. The small differences in the signal responses manifest in the spectral signal response of the tag, which is retransmitted back to the interrogating transceiver. Input into machine learning algorithms, the slight differences in the spectral responses of the diodes can be used to uniquely identify devices. To demonstrate the concept, we designed 2.0 GHz tags consisting of patch antennas and a single diode, along with a bi-static radar system operating at the 2.0 GHz 802.11 Wi-Fi band transmitting multi-tone continuous wave signals representing common 802.11 training fields. The received signals were processed using a set of algorithms for comparison purposes. A real-time classification accuracy of 95% between two tags was achieved.

Paper number 9:
Title: Computationally Efficient Neural Receivers via Axial Self-Attention
Authors: SaiKrishna Saketh Yellapragada, Atchutaram K. Kocharlakota, Mário Costa, Esa Ollila, Sergiy A. Vorobyov
Abstract: Deep learning-based neural receivers are redefining physical-layer signal processing for next-generation wireless systems. We propose an axial self-attention transformer neural receiver designed for applicability to 6G and beyond wireless systems, validated through 5G-compliant experimental configurations, that achieves state-of-the-art block error rate (BLER) performance with significantly improved computational efficiency. By factorizing attention operations along temporal and spectral axes, the proposed architecture reduces the quadratic complexity of conventional multi-head self-attention from $O((TF)^2)$ to $O(T^2F+TF^2)$, yielding substantially fewer total floating-point operations and attention matrix multiplications per transformer block compared to global self-attention. Relative to convolutional neural receiver baselines, the axial neural receiver achieves significantly lower computational cost with a fraction of the parameters. Experimental validation under 3GPP Clustered Delay Line (CDL) channels demonstrates consistent performance gains across varying mobility scenarios. Under non-line-of-sight CDL-C conditions, the axial neural receiver consistently outperforms all evaluated receiver architectures, including global self-attention, convolutional neural receivers, and traditional LS-LMMSE at 10\% BLER with reduced computational complexity per inference. At stringent reliability targets of 1\% BLER, the axial receiver maintains robust symbol detection at high user speeds, whereas the traditional LS-LMMSE receiver fails to converge, underscoring its suitability for ultra-reliable low-latency (URLLC) communication in dynamic 6G environments and beyond. These results establish the axial neural receiver as a structured, scalable, and efficient framework for AI-Native 6G RAN systems, enabling deployment in resource-constrained edge environments.

Paper number 10:
Title: Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation
Authors: Daniel C. Qi, Kenshiro Oguri, Puneet Singla, Maruthi R. Akella
Abstract: In highly nonlinear systems such as the ones commonly found in astrodynamics, Gaussian distributions generally evolve into non-Gaussian distributions. This paper introduces a method for effectively controlling non-Gaussian distributions in nonlinear environments using optimized linear feedback control. This paper utilizes Conjugate Unscented Transformation to quantify the higher-order statistical moments of non-Gaussian distributions. The formulation focuses on controlling and constraining the sigma points associated with the uncertainty quantification, which would thereby reflect the control of the entire distribution and constraints on the moments themselves. This paper develops an algorithm to solve this problem with sequential convex programming, and it is demonstrated through a two-body and three-body example. The examples show that individual moments can be directly controlled, and the moments are accurately approximated for non-Gaussian distributions throughout the controller's time horizon in nonlinear dynamics.

Paper number 11:
Title: HyWA: Hypernetwork Weight Adapting Personalized Voice Activity Detection
Authors: Mahsa Ghazvini Nejad, Hamed Jafarzadeh Asl, Amin Edraki, Mohammadreza Sadeghi, Masoud Asgharian, Yuanhao Yu, Vahid Partovi Nia
Abstract: Personalized Voice Activity Detection (PVAD) systems activate only in response to a specific target speaker by incorporating speaker embeddings from enrollment utterances. Unlike existing methods that require architectural changes, such as FiLM layers, our approach employs a hypernetwork to modify the weights of a few selected layers within a standard voice activity detection (VAD) model. This enables speaker conditioning without changing the VAD architecture, allowing the same VAD model to adapt to different speakers by updating only a small subset of the layers. We propose HyWA-PVAD, a hypernetwork weight adaptation method, and evaluate it against multiple baseline conditioning techniques. Our comparison shows consistent improvements in PVAD performance. HyWA also offers practical advantages for deployment by preserving the core VAD architecture. Our new approach improves the current conditioning techniques in two ways: i) increases the mean average precision, ii) simplifies deployment by reusing the same VAD architecture.

Paper number 12:
Title: Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility
Authors: Zhiyuan Fan, Elizabeth Dentzer, James Glynn, David S. Goldberg, Julio Friedmann, Bolun Xu
Abstract: Current decarbonization efforts are falling short of meeting the net-zero greenhouse gas (GHG) emission target, highlighting the need for substantial carbon dioxide removal methods such as direct air capture (DAC). However, integrating DACs poses challenges due to their enormous power consumption. This study assesses the commercial operation of various DAC technologies that earn revenue using monetized carbon incentives while purchasing electricity from wholesale power markets. We model four commercial DAC technologies and examine their operation in three representative locations including California, Texas, and New York. Our findings reveal that commercial DAC operations can take financial advantage of the volatile power market to operate only during low-price periods strategically, offering a pathway to facilitate a cost-efficient decarbonization transition. The ambient operational environment such as temperature and relative humidity has non-trivial impact on abatement capacity. Profit-driven decisions introduce climate-economic trade-offs that might decrease the capacity factor of DAC and reduce total CO2 removal. These implications extend throughout the entire lifecycle of DAC developments and influence power systems and policies related to full-scale DAC implementation. Our study shows that DAC technologies with shorter cycle spans and higher flexibility can better exploit the electricity price volatility, while power markets demonstrate persistent low-price windows that often synergize with low grid emission periods, like during the solar "duck curve" in California. An optimal incentive design exists for profit-driven operations while carbon-tax policy in electricity pricing is counterproductive for DAC systems.

Paper number 13:
Title: Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study
Authors: Levi D. Reyes Premer, Elias N. Pergantis, Leo Semmelmann, Davide Ziviani, Kevin J. Kircher
Abstract: Electric heat-pump water heaters (HPWHs) could reduce the energy costs, emissions, and power grid impacts associated with water heating, the second-largest energy use in United States housing. However, most HPWHs today require 240 V circuits to power the backup resistance heating elements they use to maintain comfort during large water draws. Installing a 240 V circuit can increase the up-front cost of a HPWH by half or more. This paper develops and field-tests the first control system that enables a 120 V HPWH to efficiently maintain comfort without resistance heating elements. The novel model predictive control (MPC) system enables pre-heating in anticipation of large water draws, which it forecasts using an ensemble of machine learning predictors. By shifting electrical load over time, MPC also reduces energy costs on average by 23% and 28% under time-of-use pricing and hourly pricing, respectively, relative to a 240 V HPWH with standard controls. Compared to the increasingly common practice in 120 V HPWHs of storing water at a constant, high temperature (60 °C) to ensure comfort, MPC saves 37% energy on average. In addition to demonstrating MPC's benefits in a real, occupied house, this paper discusses implementation challenges and costs. A simple payback analysis suggests that a 120 V HPWH, operated by the MPC system developed here, would be economically attractive in most installation scenarios.

Paper number 14:
Title: Competitive EV charging station location with queues
Authors: The Minh Nguyen, Nagisa Sugishita, Margarida Carvalho, Amira Dems
Abstract: Electric vehicle (EV) public charging infrastructure planning faces significant challenges in competitive markets, where multiple service providers affect congestion and user behavior. This work extends existing modeling frameworks by incorporating the presence of competitors' stations and more realistic queueing systems. First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and M/Er/s/K, with varying numbers of servers (charging outlets) and service time distributions, deriving analytic expressions for user behavior metrics. Second, we embed the queueing-based user behavior model into a bilevel program, where the upper level locates new charging stations to maximize accessibility (throughput), and the lower level captures users' station choices via a user equilibrium. Third, we apply a reformulation from competitive congested user-choice facility location models to approximately solve the bilevel problem and introduce a surrogate-based heuristic to enhance scalability. Fourth, we showcase our methodology on a real-world case study of an urban area in Montreal (Canada), offering managerial insights into how user-choice behavior assumptions and competition affect throughput and location decisions. The results demonstrate that our model yields (re)location strategies that outperform the existing network. More broadly, this approach provides a tool for incorporating charging service quality-through queueing metrics-and existing competition into station planning.

Paper number 15:
Title: Towards Spectrally Efficient and Physically Reconfigurable Architectures for Multibeam-Waveform Co-Design in Joint Communication and Sensing
Authors: Najme Ebrahimi, Arun Paidmarri, Alexandra Gallyas-Sanhueza, Yuan Ma, Haoling Li, Basem Abdelaziz Abdelmagid, Tzu-Yuan Huang, Hua Wang
Abstract: Joint Communication and Sensing (JCAS) platforms are emerging as a foundation of next-generation mmWave (MMW) and sub-THz systems, enabling both high-throughput data transfer and angular localization within a shared signal path. This paper investigates multibeam architectures for JCAS that simultaneously optimize waveform shaping and beamforming across the time, frequency, code, and direct analog/ radio frequency (RF) domains. The paper compares Orthogonal Frequency-Division Multiplexing (OFDM), Frequency Modulated Arrays (FMA), Time-Modulated Arrays (TMA), direct RF/MMW modulation, and Code-Division Multiple Access (CDMA)-based systems with respect to spectral efficiency, beam orthogonality, latency, and Angle-of-Arrival (AoA) estimation accuracy. The results highlight architecture-specific tradeoffs among beam agility, efficiency, accuracy and resolution, and complexity. It also provides a framework for selecting JCAS front ends optimized for power, latency, inter-beam and multi-user interference, and rapid system reconfiguration

Paper number 16:
Title: Continuous-Token Diffusion for Speaker-Referenced TTS in Multimodal LLMs
Authors: Xinlu He, Swayambhu Nath Ray, Harish Mallidi, Jia-Hong Huang, Ashwin Bellur, Chander Chandak, M. Maruf, Venkatesh Ravichandran
Abstract: Unified architectures in multimodal large language models (MLLM) have shown promise in handling diverse tasks within a single framework. In the text-to-speech (TTS) task, current MLLM-based approaches rely on discrete token representations, which disregard the inherently continuous nature of speech and can lead to loss of fine-grained acoustic this http URL this work, we investigate the TTS within the MLLM paradigm using continuous speech representations. We design a dual-head architecture and implement two complementary training strategies for a robust model. (1) A diffusion head generating continuous speech representations is added on the MLLM, which is on frame-level and strictly autoregressive. (2) The original language model head is retained to preserve multitask capability and to control the start and end of speech synthesis. (3) Masked training is employed to address exposure bias in autoregressive decoding. (4) To stabilize optimization, we propose a two-stage scheme where the LM is frozen in the second stage, ensuring the diffusion head learns from a fixed input distribution. Evaluations on LibriSpeech(PC) test-clean show that our approach achieves state-of-the-art autoregressive performance, with a WER of 1.95%, speaker similarity of 0.54, and UTMOS of 4.00. The two-stage training yields a 46% relative WER reduction over the one-stage training baseline. These results highlight the effectiveness of combining autoregressive modeling with continuous-token diffusion, supported by a two-stage training procedure.

Paper number 17:
Title: Identifying Best Candidates for Busbar Splitting
Authors: Giacomo Bastianel, Dirk Van Hertem, Hakan Ergun, Line Roald
Abstract: Rising electricity demand and the growing integration of renewables are intensifying congestion in transmission grids. Grid topology optimization through busbar splitting (BuS) and optimal transmission switching can alleviate grid congestion and reduce the generation costs in a power system. However, BuS optimization requires a large number of binary variables, and analyzing all the substations for potential new topological actions is computationally intractable, particularly in large grids. To tackle this issue, we propose a set of metrics to identify and rank promising candidates for BuS, focusing on finding buses where topology optimization can reduce generation costs. To assess the effect of BuS on the identified buses, we use a combined mixed-integer convex-quadratic BuS model to compute the optimal topology and test it with the non-linear non-convex AC optimal power flow (OPF) simulation to show its AC feasibility. By testing and validating the proposed metrics on test cases of different sizes, we show that they are able to identify busbars that reduce the total generation costs when their topology is optimized. Thus, the metrics enable effective selection of busbars for BuS, with no need to test every busbar in the grid, one at a time.

Paper number 18:
Title: Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch
Authors: Robert Muldrow, Channing Ludden, Christopher Petersen
Abstract: This paper compares the required fuel usage for forced and unforced motion of a chaser satellite engaged in Rendezvous, Proximity Operations, and Docking (RPOD) maneuvers. Improved RPOD models are vital, particularly as the space industry expands and demands for improved fuel efficiency, cost effectiveness, and mission life span increase. This paper specifically examines the Clohessy- Wiltshire (CW) Equations and the extent of model mismatch by comparing pre- dicted trajectories from this model with a more computationally complex, higher fidelity RPOD model. This paper assesses several test cases of similar mission parameters, in each case comparing natural motion circumnavigation (NMC) with comparable forced motion circumnavigation. The Guidance, Navigation, and Con- trol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW trajectories is representative of the extent of CW model mismatch. This paper demonstrates that unforced motions are not inherently more fuel efficient than forced motions, thus permitting extended orbital operations given the higher fuel efficiency.

Paper number 19:
Title: Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification
Authors: Shahab Ataei, Dipankar Maity, Debdipta Goswami
Abstract: Cloud-assisted system identification and control have emerged as practical solutions for low-power, resource-constrained control systems such as micro-UAVs. In a typical cloud-assisted setting, state and input data are transmitted from local agents to a central computer over low-bandwidth wireless links, leading to quantization. This paper investigates the impact of state and input data quantization on a linear time invariant (LTI) system identification, derives a worst-case bound on the identification error, and develops a robust controller for guaranteed cost control. We establish a fundamental bound on the model error that depends only on the quantized data and quantization resolution, and develop a linear matrix inequality (LMI) based guaranteed cost robust controller under this error bound.

Paper number 20:
Title: Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment
Authors: Yifu Ding, Ruicheng Ao, Pablo Duenas-Martinez, Thomas Magnanti
Abstract: Many industrial sites rely on diesel-powered light-duty trucks to transport workers and small-scale facilities, which has resulted in a significant amount of greenhouse emissions (GHGs). To address this, we developed a two-stage robust charging infrastructure planning model for electrifying light-duty trucks at industrial sites. The model is formulated as a mixed-integer linear programming (MILP) that optimizes the charging infrastructure, selected from multiple charger types and potential locations, and determines opportunity charging schedules for each truck based on the chosen infrastructure. Given the strict stopping points and schedules at industrial sites, we introduced a scheduling problem with abandonment, where trucks forgo charging if their waiting times exceed a maximum threshold. We also further incorporated the impacts of overnight charging and range anxiety on waiting and abandonment behaviors. To represent the stochastic and heterogeneous parking durations of trucks, we constructed a decision-dependent robust uncertainty set in which parking time variability flexibly depends on charging choices. We applied the model in a case study of an open-pit mining site, which plans charger installations in eight zones and schedules a fleet of around 200 trucks. By decomposing the problem into monthly subproblems and using heuristic approaches, for the whole-year dataset, the model achieves an optimality gap of less than 0.1 % within a reasonable computation time under diverse uncertainty scenarios.

Paper number 21:
Title: Constellation Design in OFDM-ISAC over Data Payloads: From MSE Analysis to Experimentation
Authors: Kawon Han, Kaitao Meng, Alexandra Chatzicharistou, Christos Masouros
Abstract: Orthogonal frequency division multiplexing (OFDM) is one of the most widely adopted waveforms for integrated sensing and communication (ISAC) systems, owing to its high spectral efficiency and compatibility with modern communication standards. This paper investigates the sensing performance of OFDM-based ISAC for multi-target delay (range) estimation under specific radar receiver processing schemes. An estimation-theoretic framework is developed to characterize sensing performance with random communication payloads. We establish the fundamental limit of delay estimation accuracy by deriving the closed-form expression of the mean-square error (MSE) achieved using matched filtering (MF) and reciprocal filtering (RF) receivers. The results show that, in multi-target scenarios, the impact of signal constellations on the delay estimation MSE differs across receivers: MF performance depends on the fourth-order moment of the zero-mean, unit-power constellation in the presence of multiple targets, whereas RF performance depends on its inverse second-order moment, irrespective of the number of targets. Building on this analysis, we present a ISAC constellation design under specific receiver architecture that brings a receiver-dependent flexible trade-off between sensing and communication in OFDM-ISAC systems. The theoretical findings are validated through simulations and proof-of-concept experiments, and also the sensing and communication performance trade-off is experimentally shown with the proposed constellation design.

Paper number 22:
Title: Safe Driving in Occluded Environments
Authors: Zhuoyuan Wang, Tongyao Jia, Pharuj Rajborirug, Neeraj Ramesh, Hiroyuki Okuda, Tatsuya Suzuki, Soummya Kar, Yorie Nakahira
Abstract: Ensuring safe autonomous driving in the presence of occlusions poses a significant challenge in its policy design. While existing model-driven control techniques based on set invariance can handle visible risks, occlusions create latent risks in which safety-critical states are not observable. Data-driven techniques also struggle to handle latent risks because direct mappings from risk-critical objects in sensor inputs to safe actions cannot be learned without visible risk-critical objects. Motivated by these challenges, in this paper, we propose a probabilistic safety certificate for latent risk. Our key technical enabler is the application of probabilistic invariance: It relaxes the strict observability requirements imposed by set-invariance methods that demand the knowledge of risk-critical states. The proposed techniques provide linear action constraints that confine the latent risk probability within tolerance. Such constraints can be integrated into model predictive controllers or embedded in data-driven policies to mitigate latent risks. The proposed method is tested using the CARLA simulator and compared with a few existing techniques. The theoretical and empirical analysis jointly demonstrate that the proposed methods assure long-term safety in real-time control in occluded environments without being overly conservative and with transparency to exposed risks.

Paper number 23:
Title: Approximate Bilevel Graph Structure Learning for Histopathology Image Classification
Authors: Sudipta Paul, Amanda W. Lund, George Jour, Iman Osman, Bülent Yener
Abstract: The structural and spatial arrangements of cells within tissues represent their functional states, making graph-based learning highly suitable for histopathology image analysis. Existing methods often rely on fixed graphs with predefined edges, limiting their ability to capture the true biological complexity of tissue interactions. In this work, we propose ABiG-Net (Approximate Bilevel Optimization for Graph Structure Learning via Neural Networks), a novel framework designed to learn optimal interactions between patches within whole slide images (WSI) or large regions of interest (ROI) while simultaneously learning discriminative node embeddings for the downstream image classification task. Our approach hierarchically models the tissue architecture at local and global scales. At the local scale, we construct patch-level graphs from cellular orientation within each patch and extract features to quantify local structures. At the global scale, we learn an image-level graph that captures sparse, biologically meaningful connections between patches through a first-order approximate bilevel optimization strategy. The learned global graph is optimized in response to classification performance, capturing the long-range contextual dependencies across the image. By unifying local structural information with global contextual relationships, ABiG-Net enhances interpretability and downstream performance. Experiments on two histopathology datasets demonstrate its effectiveness: on the Extended CRC dataset, ABiG-Net achieves 97.33 $\pm$ 1.15 % accuracy for three-class colorectal cancer grading and 98.33 $\pm$ 0.58 % for binary classification; on the melanoma dataset, it attains 96.27 $\pm$ 0.74 % for tumor-lymphocyte ROI classification.

Paper number 24:
Title: Acoustic Teleportation via Disentangled Neural Audio Codec Representations
Authors: Philipp Grundhuber, Mhd Modar Halimeh, Emanuël A. P. Habets
Abstract: This paper presents an approach for acoustic teleportation by disentangling speech content from acoustic environment characteristics in neural audio codec representations. Acoustic teleportation transfers room characteristics between speech recordings while preserving content and speaker identity. We build upon previous work using the EnCodec architecture, achieving substantial objective quality improvements with non-intrusive ScoreQ scores of 3.03, compared to 2.44 for prior methods. Our training strategy incorporates five tasks: clean reconstruction, reverberated reconstruction, dereverberation, and two variants of acoustic teleportation. We demonstrate that temporal downsampling of the acoustic embedding significantly degrades performance, with even 2x downsampling resulting in a statistically significant reduction in quality. The learned acoustic embeddings exhibit strong correlations with RT60. Effective disentanglement is demonstrated using t-SNE clustering analysis, where acoustic embeddings cluster by room while speech embeddings cluster by speaker.

Paper number 25:
Title: DIGITWISE: Digital Twin-based Modeling of Adaptive Video Streaming Engagement
Authors: Emanuele Artioli, Farzad Tashtarian, Christian Timmerer
Abstract: As the popularity of video streaming entertainment continues to grow, understanding how users engage with the content and react to its changes becomes a critical success factor for every stakeholder. User engagement, i.e., the percentage of video the user watches before quitting, is central to customer loyalty, content personalization, ad relevance, and A/B testing. This paper presents DIGITWISE, a digital twin-based approach for modeling adaptive video streaming engagement. Traditional adaptive bitrate (ABR) algorithms assume that all users react similarly to video streaming artifacts and network issues, neglecting individual user sensitivities. DIGITWISE leverages the concept of a digital twin, a digital replica of a physical entity, to model user engagement based on past viewing sessions. The digital twin receives input about streaming events and utilizes supervised machine learning to predict user engagement for a given session. The system model consists of a data processing pipeline, machine learning models acting as digital twins, and a unified model to predict engagement. DIGITWISE employs the XGBoost model in both digital twins and unified models. The proposed architecture demonstrates the importance of personal user sensitivities, reducing user engagement prediction error by up to 5.8% compared to non-user-aware models. Furthermore, DIGITWISE can optimize content provisioning and delivery by identifying the features that maximize engagement, providing an average engagement increase of up to 8.6%.

Paper number 26:
Title: Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time
Authors: Fuma Omori, Atsushi Yano, Takuya Azumi
Abstract: Autonomous driving systems, critical for safety, require real-time guarantees and can be modeled as DAGs. Their acceleration features, such as caches and pipelining, often result in execution times below the worst-case. Thus, a probabilistic approach ensuring constraint satisfaction within a probability threshold is more suitable than worst-case guarantees for these systems. This paper considers probabilistic guarantees for DAG tasks by utilizing the results of probabilistic guarantees for single processors, which have been relatively more advanced than those for multi-core processors. This paper proposes a task set partitioning method that guarantees schedulability under the partitioned scheduling. The evaluation on randomly generated DAG task sets demonstrates that the proposed method schedules more task sets with a smaller mean analysis time compared to existing probabilistic schedulability analysis for DAGs. The evaluation also compares four bin-packing heuristics, revealing Item-Centric Worst-Fit-Decreasing schedules the most task sets.

Paper number 27:
Title: Two Heads Are Better Than One: Audio-Visual Speech Error Correction with Dual Hypotheses
Authors: Sungnyun Kim, Kangwook Jang, Sungwoo Cho, Joon Son Chung, Hoirin Kim, Se-Young Yun
Abstract: This paper introduces a new paradigm for generative error correction (GER) framework in audio-visual speech recognition (AVSR) that reasons over modality-specific evidences directly in the language space. Our framework, DualHyp, empowers a large language model (LLM) to compose independent N-best hypotheses from separate automatic speech recognition (ASR) and visual speech recognition (VSR) models. To maximize the effectiveness of DualHyp, we further introduce RelPrompt, a noise-aware guidance mechanism that provides modality-grounded prompts to the LLM. RelPrompt offers the temporal reliability of each modality stream, guiding the model to dynamically switch its focus between ASR and VSR hypotheses for an accurate correction. Under various corruption scenarios, our framework attains up to 57.7% error rate gain on the LRS2 benchmark over standard ASR baseline, contrary to single-stream GER approaches that achieve only 10% gain. To facilitate research within our DualHyp framework, we release the code and the dataset comprising ASR and VSR hypotheses at this https URL.

Paper number 28:
Title: Towards Multimodal Query-Based Spatial Audio Source Extraction
Authors: Chenxin Yu, Hao Ma, Xu Li, Xiao-Lei Zhang, Mingjie Shao, Chi Zhang, Xuelong Li
Abstract: Query-based audio source extraction seeks to recover a target source from a mixture conditioned on a query. Existing approaches are largely confined to single-channel audio, leaving the spatial information in multi-channel recordings underexploited. We introduce a query-based spatial audio source extraction framework for recovering dry target signals from first-order ambisonics (FOA) mixtures. Our method accepts either an audio prompt or a text prompt as condition input, enabling flexible end-to-end extraction. The core of our proposed model lies in a tri-axial Transformer that jointly models temporal, frequency, and spatial channel dependencies. The model uses contrastive language-audio pretraining (CLAP) embeddings to enable unified audio-text conditioning via feature-wise linear modulation (FiLM). To eliminate costly annotations and improve generalization, we propose a label-free data pipeline that dynamically generates spatial mixtures and corresponding targets for training. The result of our experiment with high separation quality demonstrates the efficacy of multimodal conditioning and tri-axial modeling. This work establishes a new paradigm for high-fidelity spatial audio separation in immersive applications.

Paper number 29:
Title: Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics
Authors: Luka Baković, David Ohlin, Emma Tegling
Abstract: We perform a validation analysis on the multipolar model of opinion dynamics. A general methodology for using the model on datasets of two correlated variables is proposed and tested using data on the relationship between COVID-19 vaccination rates and political participation in Sweden. The model is shown to successfully capture the opinion segregation demonstrated by the data and spatial correlation of biases is demonstrated as necessary for the result. A mixing of the biases on the other hand leads to a more homogeneous opinion distribution, and greater penetration of the majority opinion, which here corresponds to a decision to vote or vaccinate.

Paper number 30:
Title: Working Memory Functional Connectivity Analysis for Dementia Classification using EEG
Authors: Shivani Ranjan, Anant Jain, Robin Badal, Amit Kumar, Harshal Shende, Deepak Joshi, Pramod Yadav, Lalan Kumar
Abstract: Background: Dementia, particularly Alzheimer's Disease (AD), is a progressive neurodegenerative disorder marked by cognitive decline. Early detection, especially at the Mild Cognitive Impairment (MCI) stage, is essential for timely intervention. Working Memory (WM) impairment is a key early indicator of neurodegeneration, affecting higher cognitive processes. Electroencephalography (EEG), with its high temporal resolution, offers a cost-effective method to assess brain dynamics. This study investigates WM-related EEG functional connectivity (FC) to identify brain network alterations across dementia stages. Methods: EEG signals were recorded from 24 participants (8 AD, 8 MCI, and 8 healthy controls) during WM tasks, including encoding, recall, and retrieval stages. Data preprocessing involved noise reduction and feature extraction using Spherical and Head Harmonic Decomposition (SHD, HHD). FC was quantified using Cross-Plot Transition Entropy (CPTE) and Phase Lag Index (PLI). Network metrics such as Degree and Eigenvector Centrality were analyzed using Support Vector Machine, Random Forest, and XGBoost classifiers. Results: The CPTE-based connectivity metrics outperformed the traditional PLI approach in differentiating dementia stages, attaining a peak classification accuracy of 97.53% during the retrieval phase with the Random Forest model. A connectivity threshold of 0.5 was optimal for network discrimination. SHD and HHD features also demonstrated strong discriminative potential. AD subjects exhibited higher synchronization patterns during WM tasks than healthy controls. Conclusions: The integration of WM tasks with EEG-based FC analysis provides a robust framework for dementia classification. The proposed CPTE-based approach offers a robust, scalable, non-invasive, and effective diagnostic tool for early detection and monitoring of neurodegenerative diseases.

Paper number 31:
Title: Semantic Communication Enabled Holographic Video Processing and Transmission
Authors: Jingkai Ying, Zhiyuan Qi, Yulong Feng, Zhijin Qin, Zhu Han, Rahim Tafazolli, Yonina C. Eldar
Abstract: Holographic video communication is considered a paradigm shift in visual communications, becoming increasingly popular for its ability to offer immersive experiences. This article provides an overview of holographic video communication and outlines the requirements of a holographic video communication system. Particularly, following a brief review of semantic com- munication, an architecture for a semantic-enabled holographic video communication system is presented. Key technologies, including semantic sampling, joint semantic-channel coding, and semantic-aware transmission, are designed based on the proposed architecture. Two related use cases are presented to demonstrate the performance gain of the proposed methods. Finally, potential research topics are discussed to pave the way for the realization of semantic-enabled holographic video communications.

Paper number 32:
Title: How to Adapt Wireless DJSCC Symbols to Rate Constrained Wired Networks?
Authors: Jiangyuan Guo, Wei Chen, Yuxuan Sun, Bo Ai
Abstract: Deep joint source-channel coding (DJSCC) has emerged as a robust alternative to traditional separate coding for communications through wireless channels. Existing DJSCC approaches focus primarily on point-to-point wireless communication scenarios, while neglecting end-to-end communication efficiency in hybrid wireless-wired networks such as 5G and 6G communication systems. Considerable redundancy in DJSCC symbols against wireless channels becomes inefficient for long-distance wired transmission. Furthermore, DJSCC symbols must adapt to the varying transmission rate of the wired network to avoid congestion. In this paper, we propose a novel framework designed for efficient wired transmission of DJSCC symbols within hybrid wireless-wired networks, namely Rate-Controllable Wired Adaptor (RCWA). RCWA achieves redundancy-aware coding for DJSCC symbols to improve transmission efficiency, which removes considerable redundancy present in DJSCC symbols for wireless channels and encodes only source-relevant information into bits. Moreover, we leverage the Lagrangian multiplier method to achieve controllable and continuous variable-rate coding, which can encode given features into expected rates, thereby minimizing end-to-end distortion while satisfying given constraints. Extensive experiments on diverse datasets demonstrate the superior RD performance and robustness of RCWA compared to existing baselines, validating its potential for wired resource utilization in hybrid transmission scenarios. Specifically, our method can obtain peak signal-to-noise ratio gain of up to 0.7dB and 4dB compared to neural network-based methods and digital baselines on CIFAR-10 dataset, respectively.

Paper number 33:
Title: Oscillator Drift Compensation by Line-of-Sight Tracking for Distributed Multisensor ISAC
Authors: Lorenz Mohr, Marc Miranda, Sebastian Semper, Julia Beuster, Carsten Andrich, Sebastian Giehl, Christian Schneider, Reiner S. Thomä
Abstract: We observed synchronization mismatches in the form of non-smooth phase progressions and drifts within mobile multisensor channel sounding measurements. However, performing Doppler estimation in a distributed multisensor integrated sensing and communications (ISAC) system requires coherence among the nodes, which implies a continuously differentiable phase progression of the received signals. To correct the sounding data in post-processing, we extend traditional geometry-based drift compensation algorithms by utilizing Kalman filtering for line-of-sight (LoS) tracking, which improves the robustness of the LoS estimate in multipath scenarios. This approach smooths the phase progression and enables the correction of time-varying drifts while preserving relative sensor motion. Furthermore, we propose using the relative residual power after high-resolution parameter estimation (HRPE) as a metric for ground-truth-independent comparison of post-processing synchronization methods for recorded channel sounding data. Results show that the proposed approach outperforms traditional LoS estimation heuristics, reducing the relative residual power by more than 5 dB and the delay-Doppler estimate root mean square errors (RMSEs) by approximately 60 %.

Paper number 34:
Title: On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations
Authors: Jan Brändle, Julie Rousseau, Pulkit Nahata, Gabriela Hug
Abstract: The growing integration of distributed renewable generation and the electrification of heating and transportation are rapidly increasing the number of flexible devices within modern distribution grids. Leveraging the aggregated flexibility of these small-scale distributed resources is essential to maintaining future grid-wide stability. This work uses the Swiss distribution grid of Walenstadt as a case study to provide insights into the aggregated flexibility potential of distribution grids. It demonstrates that incorporating devices such as heat pumps and photovoltaic systems significantly enhances distribution grid flexibility. It investigates the time-varying nature of aggregated flexibility and highlights how it can vary seasonally. Furthermore, simulations of future scenarios reveal that aggregated flexibility does not increase linearly or monotonically with higher levels of flexible device penetration. This is primarily due to the overloading of individual feeders, which underscores the impact of grid topology and network constraints on the aggregated flexibility potential.

Paper number 35:
Title: Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers
Authors: Yangye Jiang, Jiachen Wang, Daofei Li
Abstract: Accurate prediction of vehicle collision dynamics is crucial for advanced safety systems and post-impact control applications, yet existing methods face inherent trade-offs among computational efficiency, prediction accuracy, and data requirements. This paper proposes a dual Physics-Informed Neural Network framework addressing these challenges through two complementary networks. The first network integrates Gaussian Mixture Models with PINN architecture to learn impact force distributions from finite element analysis data while enforcing momentum conservation and energy consistency constraints. The second network employs an adaptive PINN with dynamic constraint weighting to predict post-collision vehicle dynamics, featuring an adaptive physics guard layer that prevents unrealistic predictions whil e preserving data-driven learning capabilities. The framework incorporates uncertainty quantification through time-varying parameters and enables rapid adaptation via fine-tuning strategies. Validation demonstrates significant improvements: the impact force model achieves relative errors below 15.0% for force prediction on finite element analysis (FEA) datasets, while the vehicle dynamics model reduces average trajectory prediction error by 63.6% compared to traditional four-degree-of-freedom models in scaled vehicle experiments. The integrated system maintains millisecond-level computational efficiency suitable for real-time applications while providing probabilistic confidence bounds essential for safety-critical control. Comprehensive validation through FEA simulation, dynamic modeling, and scaled vehicle experiments confirms the framework's effectiveness for Precision Immobilization Technique scenarios and general collision dynamics prediction.

Paper number 36:
Title: Radio over Fiber with Cascaded Structure: Algorithm for Uplink Positioning
Authors: Dexin Kong, Diana Pamela Moya Osorio, Erik G. Larsson
Abstract: Recent advancements in polymer microwave fiber (PMF) technology have created significant opportunities for robust, low-cost, and high-speed sub-terahertz (THz) radio-over- fiber communications. Recognizing these potential benefits, this paper explores a novel radio-over-fiber (RoF) structure that interconnects multiple radio units (RUs) in cascade via fiber, envi- sioning its application in indoor scenarios. This structure creates a number of research opportunities when considering cascaded distortion effects introduced by non-linear power amplifiers (PAs) at the RUs and the propagation channel over the fiber. We propose maximum-likelihood and non-linear least-squares algorithms to estimate the propagation distance along the RoF and the time-of-arrival between the RoF and the user equipment. For the case of linear PAs, we derive the Cramér-Rao lower bound to benchmark the performance of the estimators. Finally, we investigate the use of the system for uplink positioning. Our simulation results demonstrate that the proposed estimators perform satisfactorily even with the cascaded effects of non- linear PAs, and that the deployment of this RoF structure can enable new cost-effective opportunities for high-resolution positioning in indoor scenarios. In the numerical evaluation, we also use measured PMF characteristics for high-density polyethylene fibers.

Paper number 37:
Title: A Robust EDM Optimization Approach for 3D Single-Source Localization with Angle and Range Measurements
Authors: Mingyu Zhao, Qingna Li, Hou-Duo Qi
Abstract: For the problem of source localization, three elements usually play a very important role in accurate localization. They are the range measurements, the angle measurements and the least absolute deviation criterion, which is regarded as a robust metric for denoising the measurements. Building the three elements into a computationally tractable model is challenging. In this paper, we introduce a robust Euclidean Distance Matrix (EDM) optimization model that simultaneously incorporates the three elements. For the first time, we show that for the case of 3D single-source localization (3DSSL), the angle measurements can be represented as a simple box constraint of distances. It is achieved by reducing each of the 3D angle measurements to a two-dimensional nonlinear optimization problem, whose global minimum and maximum solutions can be characterized and utilized to get the lower and upper bounds of the distances from the unknown source to the sensors. We further develop an efficient algorithm. The high quality of the localization by the new EDM model is assessed through extensive numerical experiments in comparison with leading solvers for 3DSSL.

Paper number 38:
Title: Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage
Authors: Andreas C. Makrides, Adam Suski, Elina Spyrou
Abstract: The transition to a fully decarbonised electricity system depends on integrating new technologies that ensure reliability alongside sustainability. However, missing risk markets hinder investment in reliability-enhancing technologies by exposing investors to revenue uncertainty. This study provides the first quantitative assessment of how missing risk markets affect investment decisions in power systems that depend on long-duration energy storage (LDES) for reliability. We develop a two-stage stochastic equilibrium model with risk-averse market participants, which independently sizes power and energy capacity. We apply the method to a case study of a deeply decarbonised power system in Great Britain. The results show that incomplete risk markets reduce social welfare, harm reliability, and discourage investment in LDES and other technologies with volatile revenue streams. Revenue volatility leads to substantial risk premiums and higher financing costs for LDES, creating a barrier to its large-scale deployment. These findings demonstrate the importance of policy mechanisms that hedge revenue risk to lower the cost of capital and accelerate investment in reliability-enhancing, zero-carbon technologies

Paper number 39:
Title: Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications
Authors: Ayten Gürbüz, Giuseppe Caire
Abstract: This paper investigates a multiple antenna system with non-orthogonal multiple access (NOMA) for the exchange of air traffic management data between commercial aircraft pilots and ground-based air traffic controllers. While NOMA techniques enhance spectral efficiency, their application to aircraft communications is challenged by the high speed of the aircraft (up to 214 m/s) and the long communication ranges (up to 250 km), resulting in significant Doppler shifts and low signal-to-noise ratios, respectively. To accurately assess these challenges, we employ a realistic geometry-based stochastic air-ground channel model, derived from dedicated flight measurement campaigns. In this paper, multiple aircraft simultaneously transmit data to the ground station. We focus on the channel estimation problem at the ground station under high carrier frequency offsets and the effects of channel aging due to channel's time-varying nature. For the channel estimation problem, we compare the Zadoff-Chu sequences with time-division approach under varying carrier frequency offset pre-compensation accuracies at the aircraft transmitter. For the channel aging problem and performance evaluation of channel estimators, we compute the outage probability for both the zero-forcing detector and the minimum mean squared error detector with successive interference cancellation. The results show that the favorable channel estimator-detector combinations differ between the takeoff & landing phase and the enroute cruise phase of the flight, due to the distinct channel propagation characteristics of each phase.

Paper number 40:
Title: A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array
Authors: Jiayang Li, Qingyu Zhang, Sohmyung Ha, Dai Jiang, Andreas Demosthenous, Yu Wu
Abstract: This paper presents a fast impedance measurement IC for large-scale piezo-resistive sensor array. It features a unified differential time-to-digital demodulation architecture that readout impedance directly through the excitation circuit. The proposed pre-saturation adaptive bias technique further improves power efficiency. The chip scans 253 sensors in 12.2 ms (82 fps) at 125 kHz, consuming 158 {\mu}W (7.5 nJ/sensor). With loads from 20 {\Omega} to 500 k{\Omega}, it achieves 0.5% error and up to 71.1 dB SNR.

Paper number 41:
Title: Dedelayed: Deleting remote inference delay via on-device correction
Authors: Dan Jacobellis, Mateen Ulhaq, Fabien Racapé, Hyomin Choi, Neeraja J. Yadwadkar
Abstract: Remote inference allows lightweight devices to leverage powerful cloud models. However, communication network latency makes predictions stale and unsuitable for real-time tasks. To address this, we introduce Dedelayed, a delay-corrective method that mitigates arbitrary remote inference delays, allowing the local device to produce low-latency outputs in real time. Our method employs a lightweight local model that processes the current frame and fuses in features that a heavyweight remote model computes from past frames. On video from the BDD100K driving dataset, Dedelayed improves semantic segmentation accuracy over the stronger of the local-only and remote-only baselines across all realistic communication network delays beyond 33 ms. Without incurring additional delay, it improves accuracy by 6.4 mIoU compared to fully local inference and 9.8 mIoU compared to remote inference, for a round-trip delay of 100 ms. The advantage grows under longer delays and higher-motion scenes, as delay-mitigated split inference sustains accuracy more effectively, providing clear advantages for real-time tasks that must remain aligned with the current world state.

Paper number 42:
Title: Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge
Authors: Mikolaj Walczak, Uttej Kallakuri, Edward Humes, Xiaomin Lin, Tinoosh Mohsenin
Abstract: Vision Transformers (ViTs) have demonstrated strong capabilities in interpreting complex medical imaging data. However, their significant computational and memory demands pose challenges for deployment in real-time, resource-constrained mobile and wearable devices used in clinical environments. We introduce, BiTMedViT, a new class of Edge ViTs serving as medical AI assistants that perform structured analysis of medical images directly on the edge. BiTMedViT utilizes ternary- quantized linear layers tailored for medical imaging and com- bines a training procedure with multi-query attention, preserving stability under ternary weights with low-precision activations. Furthermore, BiTMedViT employs task-aware distillation from a high-capacity teacher to recover accuracy lost due to extreme quantization. Lastly, we also present a pipeline that maps the ternarized ViTs to a custom CUDA kernel for efficient memory bandwidth utilization and latency reduction on the Jetson Orin Nano. Finally, BiTMedViT achieves 86% diagnostic accuracy (89% SOTA) on MedMNIST across 12 datasets, while reducing model size by 43x, memory traffic by 39x, and enabling 16.8 ms inference at an energy efficiency up to 41x that of SOTA models at 183.62 GOPs/J on the Orin Nano. Our results demonstrate a practical and scientifically grounded route for extreme-precision medical imaging ViTs deployable on the edge, narrowing the gap between algorithmic advances and deployable clinical tools.

Paper number 43:
Title: Beyond Discrete Categories: Multi-Task Valence-Arousal Modeling for Pet Vocalization Analysis
Authors: Junyao Huang, Rumin Situ
Abstract: Traditional pet emotion recognition from vocalizations, based on discrete classification, struggles with ambiguity and capturing intensity variations. We propose a continuous Valence-Arousal (VA) model that represents emotions in a two-dimensional space. Our method uses an automatic VA label generation algorithm, enabling large-scale annotation of 42,553 pet vocalization samples. A multi-task learning framework jointly trains VA regression with auxiliary tasks (emotion, body size, gender) to enhance prediction by improving feature learning. Our Audio Transformer model achieves a validation Valence Pearson correlation of r = 0.9024 and an Arousal r = 0.7155, effectively resolving confusion between discrete categories like "territorial" and "happy." This work introduces the first continuous VA framework for pet vocalization analysis, offering a more expressive representation for human-pet interaction, veterinary diagnostics, and behavioral training. The approach shows strong potential for deployment in consumer products like AI pet emotion translators.

Paper number 44:
Title: Production and Manufacturing of 3D Printed Acoustic Guitars
Authors: Timothy Tran, William Schiesser
Abstract: This research investigates the feasibility of producing affordable, functional acoustic guitars using 3D printing, with a focus on producing structural designs with proper tonal performance. Conducted in collaboration with William Schiesser, the study uses a classical guitar model, chosen for its lower string tension, to evaluate the tonal characteristics of a 3D-printed prototype made from polylactic acid (PLA). Due to the build plate size constraints of the Prusa Mark 4 printer, the guitar body was divided into multiple sections joined with press-fit tolerances and minimal cyanoacrylate adhesive. CAD modeling in Fusion 360 ensured dimensional accuracy in press-fit connections and the overall assembly. Following assembly, the guitar was strung with nylon strings and tested using Audacity software to compare recorded frequencies and notes with standard reference values. Results showed large deviations in lower string frequencies, likely caused by the material choice utilized in printing. Accurate pitches were reached with all strings despite frequency differences through tuning, demonstrating that PLA and modern manufacturing methods can produce affordable, playable acoustic guitars despite inevitable challenges. Further research may investigate alternative plastics for superior frequency matching. This approach holds significant potential for expanding access to quality instruments while reducing reliance on endangered tonewoods, thereby encouraging both sustainable instrument production and increased musical participation. This also creates opportunities for disadvantaged communities where access to musical instruments remains a challenge. Keywords: Luthiery, Stereolithography, 3D-Print, Guitar Making

Paper number 45:
Title: Gelina: Unified Speech and Gesture Synthesis via Interleaved Token Prediction
Authors: Téo Guichoux, Théodor Lemerle, Shivam Mehta, Jonas Beskow, Gustave Eje Henter, Laure Soulier, Catherine Pelachaud, Nicolas Obin
Abstract: Human communication is multimodal, with speech and gestures tightly coupled, yet most computational methods for generating speech and gestures synthesize them sequentially, weakening synchrony and prosody alignment. We introduce Gelina, a unified framework that jointly synthesizes speech and co-speech gestures from text using interleaved token sequences in a discrete autoregressive backbone, with modality-specific decoders. Gelina supports multi-speaker and multi-style cloning and enables gesture-only synthesis from speech inputs. Subjective and objective evaluations demonstrate competitive speech quality and improved gesture generation over unimodal baselines.

Paper number 46:
Title: Adaptive vector steering: A training-free, layer-wise intervention for hallucination mitigation in large audio and multimodal models
Authors: Tsung-En Lin, Kuan-Yi Lee, Hung-Yi Lee
Abstract: Large Audio-Language Models and Multi-Modal Large Language Models have demonstrated strong capabilities in tasks such as Audio Question Answering (AQA), Audio Captioning, and Automatic Speech Recognition (ASR). However, there is growing evidence that these models can hallucinate about the content of the audio. To address this issue, we probe the models' internal states and propose Adaptive Vector Steering (AVS), a method that better grounds generation in audio content. We also identify a strong correlation between output correctness and internal representations. Experiments show consistent performance gains across two models and two benchmarks. On the Audio Hallucination QA dataset, our method boosts the F1-score of Gemma from 0.550 to 0.619 and Qwen from 0.626 to 0.632. Furthermore, our method increases the accuracy of Qwen on MMAU from 0.548 to 0.592, marking an 8% relative increase. To the best of our knowledge, this is the first work to apply vector steering to mitigate hallucination in audio.

Paper number 47:
Title: Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation
Authors: Mouhyemen Khan, Tatsuya Ibuki, Abhijit Chatterjee
Abstract: Level set methods underpin modern safety techniques such as control barrier functions (CBFs), while also serving as implicit surface representations for geometric shapes via distance fields. Inspired by these two paradigms, we propose a unified framework where the implicit surface itself acts as a CBF. We leverage Gaussian process (GP) implicit surface (GPIS) to represent the safety boundaries, using safety samples which are derived from sensor measurements to condition the GP. The GP posterior mean defines the implicit safety surface (safety belief), while the posterior variance provides a robust safety margin. Although GPs have favorable properties such as uncertainty estimation and analytical tractability, they scale cubically with data. To alleviate this issue, we develop a sparse solution called sparse Gaussian CBFs. To the best of our knowledge, GPIS have not been explicitly used to synthesize CBFs. We validate the approach on collision avoidance tasks in two settings: a simulated 7-DOF manipulator operating around the Stanford bunny, and a quadrotor navigating in 3D around a physical chair. In both cases, Gaussian CBFs (with and without sparsity) enable safe interaction and collision-free execution of trajectories that would otherwise intersect the objects.

Paper number 48:
Title: Simplicial Gaussian Models: Representation and Inference
Authors: Lorenzo Marinucci, Gabriele D'Acunto, Paolo Di Lorenzo, Sergio Barbarossa
Abstract: Probabilistic graphical models (PGMs) are powerful tools for representing statistical dependencies through graphs in high-dimensional systems. However, they are limited to pairwise interactions. In this work, we propose the simplicial Gaussian model (SGM), which extends Gaussian PGM to simplicial complexes. SGM jointly models random variables supported on vertices, edges, and triangles, within a single parametrized Gaussian distribution. Our model builds upon discrete Hodge theory and incorporates uncertainty at every topological level through independent random components. Motivated by applications, we focus on the marginal edge-level distribution while treating node- and triangle-level variables as latent. We then develop a maximum-likelihood inference algorithm to recover the parameters of the full SGM and the induced conditional dependence structure. Numerical experiments on synthetic simplicial complexes with varying size and sparsity confirm the effectiveness of our algorithm.

Paper number 49:
Title: Information Shapes Koopman Representation
Authors: Xiaoyuan Cheng, Wenxuan Yuan, Yiming Yang, Yuanzhao Zhang, Sibo Cheng, Yi He, Zhuo Sun
Abstract: The Koopman operator provides a powerful framework for modeling dynamical systems and has attracted growing interest from the machine learning community. However, its infinite-dimensional nature makes identifying suitable finite-dimensional subspaces challenging, especially for deep architectures. We argue that these difficulties come from suboptimal representation learning, where latent variables fail to balance expressivity and simplicity. This tension is closely related to the information bottleneck (IB) dilemma: constructing compressed representations that are both compact and predictive. Rethinking Koopman learning through this lens, we demonstrate that latent mutual information promotes simplicity, yet an overemphasis on simplicity may cause latent space to collapse onto a few dominant modes. In contrast, expressiveness is sustained by the von Neumann entropy, which prevents such collapse and encourages mode diversity. This insight leads us to propose an information-theoretic Lagrangian formulation that explicitly balances this tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian formulation that encourages both simplicity and expressiveness, leading to a stable and interpretable Koopman representation. Beyond quantitative evaluations, we further visualize the learned manifolds under our representations, observing empirical results consistent with our theoretical predictions. Finally, we validate our approach across a diverse range of dynamical systems, demonstrating improved performance over existing Koopman learning methods. The implementation is publicly available at this https URL.

Paper number 50:
Title: Towards xApp Conflict Evaluation with Explainable Machine Learning and Causal Inference in O-RAN
Authors: Pragya Sharma, Shihua Sun, Shachi Deshpande, Angelos Stavrou, Haining Wang
Abstract: The Open Radio Access Network (O-RAN) architecture enables a flexible, vendor-neutral deployment of 5G networks by disaggregating base station components and supporting third-party xApps for near real-time RAN control. However, the concurrent operation of multiple xApps can lead to conflicting control actions, which may cause network performance degradation. In this work, we propose a framework for xApp conflict management that combines explainable machine learning and causal inference to evaluate the causal relationships between RAN Control Parameters (RCPs) and Key Performance Indicators (KPIs). We use model explainability tools such as SHAP to identify RCPs that jointly affect the same KPI, signaling potential conflicts, and represent these interactions as a causal Directed Acyclic Graph (DAG). We then estimate the causal impact of each of these RCPs on their associated KPIs using metrics such as Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE). This approach offers network operators guided insights into identifying conflicts and quantifying their impacts, enabling more informed and effective conflict resolution strategies across diverse xApp deployments.

Paper number 51:
Title: Time-Varying Optimization for Streaming Data Via Temporal Weighting
Authors: Muhammad Faraz Ul Abrar, Nicolò Michelusi, Erik G. Larsson
Abstract: Classical optimization theory deals with fixed, time-invariant objective functions. However, time-varying optimization has emerged as an important subject for decision-making in dynamic environments. In this work, we study the problem of learning from streaming data through a time-varying optimization lens. Unlike prior works that focus on generic formulations, we introduce a structured, \emph{weight-based} formulation that explicitly captures the streaming-data origin of the time-varying objective, where at each time step, an agent aims to minimize a weighted average loss over all the past data samples. We focus on two specific weighting strategies: (1) uniform weights, which treat all samples equally, and (2) discounted weights, which geometrically decay the influence of older data. For both schemes, we derive tight bounds on the ``tracking error'' (TE), defined as the deviation between the model parameter and the time-varying optimum at a given time step, under gradient descent (GD) updates. We show that under uniform weighting, the TE vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas discounted weighting incurs a nonzero error floor controlled by the discount factor and the number of gradient updates performed at each time step. Our theoretical findings are validated through numerical simulations.

Paper number 52:
Title: Transformer-based Scalable Beamforming Optimization via Deep Residual Learning
Authors: Yubo Zhang, Xiao-Yang Liu, Xiaodong Wang
Abstract: We develop an unsupervised deep learning framework for downlink beamforming in large-scale MU-MISO channels. The model is trained offline, allowing real-time inference through lightweight feedforward computations in dynamic communication environments. Following the learning-to-optimize (L2O) paradigm, a multi-layer Transformer iteratively refines both channel and beamformer features via residual connections. To enhance training, three strategies are introduced: (i) curriculum learning (CL) to improve early-stage convergence and avoid local optima, (ii) semi-amortized learning to refine each Transformer block with a few gradient ascent steps, and (iii) sliding-window training to stabilize optimization by training only a subset of Transformer blocks at a time. Extensive simulations show that the proposed scheme outperforms existing baselines at low-to-medium SNRs and closely approaches WMMSE performance at high SNRs, while achieving substantially faster inference than iterative and online learning approaches.

Paper number 53:
Title: Movable and Reconfigurable Antennas for 6G: Unlocking Electromagnetic-Domain Design and Optimization
Authors: Lipeng Zhu, Haobin Mao, Ge Yan, Wenyan Ma, Zhenyu Xiao, Rui Zhang
Abstract: The growing demands of 6G mobile communication networks necessitate advanced antenna technologies. Movable antennas (MAs) and reconfigurable antennas (RAs) enable dynamic control over antenna's position, orientation, radiation, polarization, and frequency response, introducing rich electromagnetic-domain degrees of freedom for the design and performance enhancement of wireless systems. This article overviews their application scenarios, hardware architectures, and design methods. Field test and simulation results highlight their performance benefits over conventional fixed/non-reconfigurable antennas.

Paper number 54:
Title: Performance Comparison of Gate-Based and Adiabatic Quantum Computing for Power Flow Analysis
Authors: Zeynab Kaseb, Matthias Moller, Peter Palensky, Pedro P. Vergara
Abstract: In this paper, we present the first direct comparison between gate-based quantum computing (GQC) and adiabatic quantum computing (AQC) for solving the AC power flow (PF) equations. Building on the Adiabatic Quantum Power Flow (AQPF) algorithm originally designed for annealing platforms, we adapt it to the Quantum Approximate Optimization Algorithm (QAOA). The PF equations are reformulated as a combinatorial optimization problem. Numerical experiments on a 4-bus test system assess solution accuracy and computational time. Results from QAOA are benchmarked against those obtained using D-Wave's Advantage system and Fujitsu's latest generation Digital Annealer, i.e., Quantum-Inspired Integrated Optimization software (QIIO). The findings provide quantitative insights into the performance trade-offs, scalability, and practical viability of GQC versus AQC paradigms for PF analysis, highlighting the potential of quantum algorithms to address the computational challenges associated with modern electricity networks in the Noisy Intermediate-Scale Quantum (NISQ).

Paper number 55:
Title: Data-driven learning of feedback maps for explicit robust predictive control: an approximation theoretic view
Authors: Siddhartha Ganguly, Shubham Gupta, Debasish Chatterjee
Abstract: We establish an algorithm to learn feedback maps from data for a class of robust model predictive control (MPC) problems. The algorithm accounts for the approximation errors due to the learning directly at the synthesis stage, ensuring recursive feasibility by construction. The optimal control problem consists of a linear noisy dynamical system, a quadratic stage and quadratic terminal costs as the objective, and convex constraints on the state, control, and disturbance sequences; the control minimizes and the disturbance maximizes the objective. We proceed via two steps -- (a) Data generation: First, we reformulate the given minmax problem into a convex semi-infinite program and employ recently developed tools to solve it in an exact fashion on grid points of the state space to generate (state, action) data. (b) Learning approximate feedback maps: We employ a couple of approximation schemes that furnish tight approximations within preassigned uniform error bounds on the admissible state space to learn the unknown feedback policy. The stability of the closed-loop system under the approximate feedback policies is also guaranteed under a standard set of hypotheses. Two benchmark numerical examples are provided to illustrate the results.

Paper number 56:
Title: Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor
Authors: Preston Fairchild, Claudia Chen, Xiaobo Tan
Abstract: Properly handling delicate produce with robotic manipulators is a major part of the future role of automation in agricultural harvesting and processing. Grasping with the correct amount of force is crucial in not only ensuring proper grip on the object, but also to avoid damaging or bruising the product. In this work, a flexible pressure sensor that is both low cost and easy to fabricate is integrated with robotic grippers for working with produce of varying shapes, sizes, and stiffnesses. The sensor is successfully integrated with both a rigid robotic gripper, as well as a pneumatically actuated soft finger. Furthermore, an algorithm is proposed for accelerated estimation of the steady-state value of the sensor output based on the transient response data, to enable real-time applications. The sensor is shown to be effective in incorporating feedback to correctly grasp objects of unknown sizes and stiffnesses. At the same time, the sensor provides estimates for these values which can be utilized for identification of qualities such as ripeness levels and bruising. It is also shown to be able to provide force feedback for objects of variable stiffnesses. This enables future use not only for produce identification, but also for tasks such as quality control and selective distribution based on ripeness levels.

Paper number 57:
Title: Cryo-CMOS Antenna for Wireless Communications within a Quantum Computer Cryostat
Authors: Viviana Centritto, Ama Bandara, Heqi Deng, Masoud Babaie, Evgenii Vinogradov, Sergi Abadal, Eduard Alarcon
Abstract: Scaling quantum computers from a few qubits to large numbers remains one of the critical challenges in realizing practical quantum advantage. Multi-core quantum architectures have emerged as a promising solution, enabling scalability through distributed quantum processing units (QPUs) interconnected via classical and quantum links. However, the bottleneck of wired connections persists, as densely packed wired interconnects, both vertically across temperature stages and horizontally within the same layer, introduce spatial constraints, power dissipation, and latency, which could hinder performance as the number of QPUs increases. To overcome these limitations, this work proposes a cryo-compatible on-chip differential dipole antenna operating at 28 GHz to enable short-range wireless communication within a quantum computer cryostat. Temperature-dependent material properties are incorporated to accurately capture antenna behavior at 4 K. Moreover, by embedding the antenna in a realistic cryostat structure, we evaluate the feasibility of antenna operation within the cryogenic environment. The proposed antenna achieves a reflection coefficient of -20.8 dB in free space and -18.38 dB within the cryostat, demonstrating efficient impedance matching.

Paper number 58:
Title: Closing the Gap Between Text and Speech Understanding in LLMs
Authors: Santiago Cuervo, Skyler Seto, Maureen de Seyssel, Richard He Bai, Zijin Gu, Tatiana Likhomanenko, Navdeep Jaitly, Zakaria Aldeneh
Abstract: Large Language Models (LLMs) can be adapted to extend their text capabilities to speech inputs. However, these speech-adapted LLMs consistently underperform their text-based counterparts--and even cascaded pipelines--on language understanding tasks. We term this shortfall the text-speech understanding gap: the performance drop observed when a speech-adapted LLM processes spoken inputs relative to when the original text-based LLM processes the equivalent text. Recent approaches to narrowing this gap either rely on large-scale speech synthesis of text corpora, which is costly and heavily dependent on synthetic data, or on large-scale proprietary speech datasets, which are not reproducible. As a result, there remains a need for more data-efficient alternatives for closing the text-speech understanding gap. In this work, we analyze the gap as driven by two factors: (i) forgetting of text capabilities during adaptation, and (ii) cross-modal misalignment between speech and text. Based on this analysis, we introduce SALAD--Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation--which combines cross-modal distillation with targeted synthetic data to improve alignment while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves competitive performance with a strong open-weight model across broad-domain benchmarks in knowledge, language understanding, and reasoning, while training on over an order of magnitude less speech data from public corpora.

Paper number 59:
Title: Multi Timescale Stochastic Approximation: Stability and Convergence
Authors: Rohan Deb, Swetha Ganesh, Shalabh Bhatnagar
Abstract: This paper presents the first sufficient conditions that guarantee the stability and almost sure convergence of multi-timescale stochastic approximation (SA) iterates. It extends the existing results on one-timescale and two-timescale SA iterates to general $N$-timescale stochastic recursions, for any $N \geq 1$, using the ordinary differential equation (ODE) method. As an application, we study SA algorithms augmented with heavy-ball momentum in the context of Gradient Temporal Difference (GTD) learning. The added momentum introduces an auxiliary state evolving on an intermediate timescale, yielding a three-timescale recursion. We show that with appropriate momentum parameters, the scheme fits within our framework and converges almost surely to the same fixed point as baseline GTD. The stability and convergence of all iterates including the momentum state follow from our main results without ad hoc bounds. We then study off-policy actor-critic algorithms with a baseline learner, actor, and critic updated on separate timescales. In contrast to prior work, we eliminate projection steps from the actor update and instead use our framework to guarantee stability and almost sure convergence of all components. Finally, we extend the analysis to constrained policy optimization in the average reward setting, where the actor, critic, and dual variables evolve on three distinct timescales, and we verify that the resulting dynamics satisfy the conditions of our general theorem. These examples show how diverse reinforcement learning algorithms covering momentum acceleration, off-policy learning, and primal-dual methods-fit naturally into the proposed multi-timescale framework.

Paper number 60:
Title: Learning Power Flow with Confidence: A Probabilistic Guarantee Framework for Voltage Risk
Authors: Parikshit Pareek, Sidhant Misra, Deepjyoti Deka
Abstract: The absence of formal performance guarantees in machine learning (ML) has limited its adoption for safety-critical power system applications, where confidence and interpretability are as vital as accuracy. In this work, we present a probabilistic guarantee for power flow learning and voltage risk estimation, derived through the framework of Gaussian Process (GP) regression. Specifically, we establish a bound on the expected estimation error that connects the GP's predictive variance to confidence in voltage risk estimates, ensuring statistical equivalence with Monte Carlo-based ACPF risk quantification. To enhance model learnability in the low-data regime, we first design the Vertex-Degree Kernel (VDK), a topology-aware additive kernel that decomposes voltage-load interactions into local neighborhoods for efficient large-scale learning. Building on this, we introduce a network-swipe active learning (AL) algorithm that adaptively samples informative operating points and provides a principled stopping criterion without requiring out-of-sample validation. Together, these developments mitigate the principal bottleneck of ML-based power flow-its lack of guaranteed reliability-by combining data efficiency with analytical assurance. Empirical evaluations across IEEE 118-, 500-, and 1354-bus systems confirm that the proposed VDK-GP achieves mean absolute voltage errors below 1E-03 p.u., reproduces Monte Carlo-level voltage risk estimates with 15x fewer ACPF computations, and achieves over 120x reduction in evaluation time while conservatively bounding violation probabilities.

Paper number 61:
Title: Far- versus Near-Field RIS Modeling and Beam Design
Authors: Mohamadreza Delbari, George C. Alexandropoulos, Robert Schober, Vahid Jamali
Abstract: In this chapter, we investigate the mathematical foundation of the modeling and design of reconfigurable intelligent surfaces (RIS) in both the far- and near-field regimes. More specifically, we first present RIS-assisted wireless channel models for the far- and near-field regimes, discussing relevant phenomena, such as line-of-sight (LOS) and non-LOS links, rich and poor scattering, channel correlation, and array manifold. Subsequently, we introduce two general approaches for the RIS reflective beam design, namely optimization-based and analytical, which offer different degrees of design flexibility and computational complexity. Furthermore, we provide a comprehensive set of simulation results for the performance evaluation of the studied RIS beam designs and the investigation of the impact of the system parameters.

Paper number 62:
Title: A Framework for Holistic KLD-based Waveform Design for Multi-User-Multi-Target ISAC Systems
Authors: Yousef Kloob, Mohammad Al-Jarrah, Emad Alsusa
Abstract: This paper introduces a novel framework aimed at designing integrated waveforms for robust integrated sensing and communication (ISAC) systems. The system model consists of a multiple-input multiple-output (MIMO) base station that simultaneously serves communication user equipments (UEs) and detects multiple targets using a shared-antenna deployment scenario. By leveraging Kullback-Leibler divergence (KLD) to holistically characterise both communication and sensing subsystems, three optimisation problems are formulated: (i) radar waveform KLD maximisation under communication constraints, (ii) communication waveform KLD maximisation subject to radar KLD requirements, and (iii) an integrated waveform KLD-based optimisation for ISAC that jointly balances both subsystems. The first two problems are solved using a projected gradient method with adaptive penalties for the radar waveforms and a gradient-assisted interior point method (IPM) for the communication waveforms. The third, integrated waveform optimisation approach adopts an alternating direction method of multipliers (ADMM) framework to unify radar and communication waveform designs into a single integrated optimisation, thereby synergising sensing and communication objectives and achieving higher overall performance than either radar- or communication-only techniques. Unlike most existing ISAC waveform designs that regard communication signals solely as interference for sensing, the proposed framework utilises the holistic ISAC waveform-that is, the superimposed communication and sensing signals-to boost detection performance in the radar subsystem. Simulation results show significant improvements in both radar detection and communication reliability compared with conventional zero-forcing beamforming, identity-covariance radar baselines, and traditional optimisation approaches,..

Paper number 63:
Title: Propagation Distance Estimation for Radio over Fiber with Cascaded Structure
Authors: Dexin Kong, Diana Pamela Moya Osorio, Erik G. Larsson
Abstract: Recent developments in polymer microwave fiber (PMF) have opened great opportunities for robust, low-cost, and high-speed sub-terahertz (THz) communications. Noticing this great potential, this paper addresses the problem of estimation of the propagation distance of a sub-Thz signal along a radio over fiber structure. Particularly, this paper considers a novel cascaded structure that interconnects multiple radio units (RUs) via fiber for applications in indoor scenarios. Herein, we consider the cascaded effects of distortions introduced by non-linear power amplifiers at the RUs, and the propagation channel over the fiber is based on measurements obtained from transmissions of sub-THz signals on high-density polyethylene fibers. For the estimation of the propagation distance, non-linear least-squares algorithms are proposed, and our simulation results demonstrate that the proposed estimators present a good performance on the propagation distance estimation even in the presence of the cascaded effect of non-linear PAs.

Paper number 64:
Title: Spectrum Efficiency and Processing Latency Trade-offs in Panel-Based LIS
Authors: Lina Tinnerberg, Dumitra Iancu, Ove Edfors, Liang Liu, Juan Vidal Alegría
Abstract: The next generation wireless systems will face stringent new requirements, including ultra-low latency, high data rates and enhanced reliability. Large Intelligent Surfaces, is one proposed solution that has the potential to solve these high demands. The real-life deployment of such systems involves different design considerations with non-trivial trade-offs. This paper investigates the trade-off between spectral efficiency and processing latency, considering different antenna distribution schemes and detection algorithms. A latency model for the physical layer processing has been developed, using real FPGA and application-specific instruction processor (ASIP) hardware implementation results. Simulation results using an indoor environment show that distributing antennas throughout the scenario improves overall reliability, while the impact from this on latency is limited both when using zero-forcing (ZF) and Minimum Mean Square Error (MMSE) detection. Changing the detection algorithm to maximum-ratio combining (MRC) from ZF or MMSE, however, reduces the latency significantly, even if a larger number of antennas are needed to achieve a similar spectrum efficiency.

Paper number 65:
Title: Exploring the Advantages of Sparse Arrays in Near-Field XL-MIMO Systems: Beam Analysis and EDoF Function
Authors: Xianzhe Chen, Hong Ren, Cunhua Pan, Cheng-Xiang Wang, Jiangzhou Wang
Abstract: This paper investigates near-field XL-MIMO systems with sparse uniform planar arrays (UPAs). Based on the Green's function-based channel model, the paper derives closed-form expressions for the signal beam power when the distance coordinate or the angular coordinates varies with respective to the focused position. Based on that, closed-form expressions for the lobe length and the suppressing ratio are obtained, indicating that both the distance-focusing property and the grating lobe behavior can be enhanced as the focal distance decreases or the antenna spacing increases. Furthermore, the paper introduces a crucial constraint on system parameters, under which effective degrees-of-freedom (EDoF) of XL-MIMO systems with sparse UPAs can be precisely estimated. Then, the paper proposes an algorithm to obtain a closed-form expression, which can estimate EDoF with high accuracy and low computational complexity. The numerical results verifies the correctness of the main results of this paper.

Paper number 66:
Title: A Neural Network-based Multi-timestep Command Governor for Nonlinear Systems with Constraints
Authors: Mostafaali Ayubirad, Hamid R. Ossareh
Abstract: The multi-timestep command governor (MCG) is an add-on algorithm that enforces constraints by modifying, at each timestep, the reference command to a pre-stabilized control system. The MCG can be interpreted as a Model-Predictive Control scheme operating on the reference command. The implementation of MCG on nonlinear systems carries a heavy computational burden as it requires solving a nonlinear program with multiple decision variables at each timestep. This paper proposes a less computationally demanding alternative, based on approximating the MCG control law using a neural network (NN) trained on offline data. However, since the NN output may not always be constraint-admissible due to training errors, its output is adjusted using a sensitivity-based method. We thus refer to the resulting control strategy as the neural network-based MCG (NN-MCG). As validation, the proposed controller is applied as a load governor for constraint management in an automotive fuel cell system. It is shown that the proposed strategy is significantly more computationally efficient than the traditional MCG, while achieving nearly identical performance if the NN is well-trained.

Paper number 67:
Title: Stacked Intelligent Metasurfaces-Enhanced MIMO OFDM Wideband Communication Systems
Authors: Zheao Li, Jiancheng An, Chau Yuen
Abstract: Multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) systems rely on digital or hybrid digital and analog designs for beamforming against frequency-selective fading, which suffer from high hardware complexity and energy consumption. To address this, this work introduces a fully-analog stacked intelligent metasurfaces (SIM) architecture that directly performs wave-domain beamforming, enabling diagonalization of the end-to-end channel matrix and inherently eliminating inter-antenna interference (IAI) for MIMO OFDM transmission. By leveraging cascaded programmable metasurface layers, the proposed system establishes multiple parallel subchannels, significantly improving multi-carrier transmission efficiency while reducing hardware complexity. To optimize the SIM phase shift matrices, a block coordinate descent and penalty convex-concave procedure (BCD-PCCP) algorithm is developed to iteratively minimize the channel fitting error across subcarriers. Simulation results validate the proposed approach, determining the maximum effective bandwidth and demonstrating substantial performance improvements. Moreover, for a MIMO OFDM system operating at 28 GHz with 16 subcarriers, the proposed SIM configuration method achieves over 300% enhancement in channel capacity compared to conventional SIM configuration that only accounts for the center frequency.

Paper number 68:
Title: Robust Real-Time Endoscopic Stereo Matching under Fuzzy Tissue Boundaries
Authors: Yang Ding, Can Han, Sijia Du, Yaqi Wang, Dahong Qian
Abstract: Real-time acquisition of accurate scene depth is essential for automated robotic minimally invasive surgery. Stereo matching with binocular endoscopy can provide this depth information. However, existing stereo matching methods, designed primarily for natural images, often struggle with endoscopic images due to fuzzy tissue boundaries and typically fail to meet real-time requirements for high-resolution endoscopic image inputs. To address these challenges, we propose \textbf{RRESM}, a real-time stereo matching method tailored for endoscopic images. Our approach integrates a 3D Mamba Coordinate Attention module that enhances cost aggregation through position-sensitive attention maps and long-range spatial dependency modeling via the Mamba block, generating a robust cost volume without substantial computational overhead. Additionally, we introduce a High-Frequency Disparity Optimization module that refines disparity predictions near tissue boundaries by amplifying high-frequency details in the wavelet domain. Evaluations on the SCARED and SERV-CT datasets demonstrate state-of-the-art matching accuracy with a real-time inference speed of 42 FPS. The code is available at this https URL.

Paper number 69:
Title: The Untapped Potential of Smart Charging: How EV Owners Can Save Money and Reduce Emissions Without Behavioral Change
Authors: Yash Gupta, William Vreeland, Andrew Peterman, Coley Girouard, Brian Wang
Abstract: The transportation sector is the single largest contributor to US emissions and the second largest globally. Electric vehicles (EVs) are expected to represent half of global car sales by 2035, emerging as a pivotal solution to reduce emissions and enhance grid flexibility. The electrification of buildings, manufacturing, and transportation is expected to grow electricity demand substantially over the next decade. Without effectively managed EV charging, EVs could strain energy grid infrastructure and increase electricity costs. Drawing on de-identified 2023 EV telematics data from Rivian Automotive, this study found that 72% of home charging commenced after the customer plugged in their vehicle regardless of utility time of use (TOU) tariffs or managed charging programs. In fewer than 26% of charging sessions in the sample, EV owners actively scheduled charging times to align or participate in utility tariffs or programs. With a majority of drivers concurrently plugged in during optimal charging periods yet not actively charging, the study identified an opportunity to reduce individual EV owner costs and carbon emissions through smarter charging habits without significant behavioral modifications or sacrifice in user preferences. By optimizing home charging schedules within existing plug-in and plug-out windows, the study suggests that EV owners can save an average of $140 annually and reduce the associated carbon emissions of charging their EV by as much as 28%.

Paper number 70:
Title: Dissipativity-Based Distributed Control and Communication Topology Co-Design for Voltage Regulation and Current Sharing in DC Microgrids
Authors: Mohammad Javad Najafirad, Shirantha Welikala
Abstract: This paper presents a novel dissipativity-based distributed droop-free control approach for voltage regulation and current sharing in DC microgrids (MGs) comprised of an interconnected set of distributed generators (DGs), loads, and power lines. First, we describe the closed-loop DC MG as a networked system where the DGs and lines (i.e., subsystems) are interconnected via a static interconnection matrix. This interconnection matrix demonstrates how the inputs, outputs, and disturbances of DGs and lines are connected in a DC MG. Each DG is equipped with a local controller for voltage regulation and a distributed global controller for current sharing, where the local controllers ensure individual voltage tracking while the global controllers coordinate among DGs to achieve proportional current sharing. To design the distributed global controllers, we use the dissipativity properties of the subsystems and formulate a linear matrix inequality (LMI) problem. To support the feasibility of this problem, we identify a set of necessary local and global conditions to enforce in a specifically developed LMI-based local controller design process. In contrast to existing DC MG control solutions, our approach proposes a unified framework for co-designing the distributed controller and communication topology. As the co-design process is LMI-based, it can be efficiently implemented and evaluated using existing convex optimization tools. The effectiveness of the proposed solution is verified by simulating an islanded DC MG in a MATLAB/Simulink environment under different scenarios, such as load changes and topological constraint changes, and then comparing the performance with the droop control algorithm.

Paper number 71:
Title: End-to-End Semantic Preservation in Text-Aware Image Compression Systems
Authors: Stefano Della Fiore, Alessandro Gnutti, Marco Dalai, Pierangelo Migliorati, Riccardo Leonardi
Abstract: Traditional image compression methods aim to reconstruct images for human perception, prioritizing visual fidelity over task relevance. In contrast, Coding for Machines focuses on preserving information essential for automated understanding. Building on this principle, we present an end-to-end compression framework that retains text-specific features for Optical Character Recognition (OCR). The encoder operates at roughly half the computational cost of the OCR module, making it suitable for resource-limited devices. When on-device OCR is infeasible, images can be efficiently compressed and later decoded to recover textual content. Experiments show significant improvements in text extraction accuracy at low bitrates, even outperforming OCR on uncompressed images. We further extend this study to general-purpose encoders, exploring their capacity to preserve hidden semantics under extreme compression. Instead of optimizing for visual fidelity, we examine whether compact, visually degraded representations can retain recoverable meaning through learned enhancement and recognition modules. Results demonstrate that semantic information can persist despite severe compression, bridging text-oriented compression and general-purpose semantic preservation in machine-centered image coding.

Paper number 72:
Title: Dissipativity-Based Distributed Control and Communication Topology Co-Design for DC Microgrids with ZIP Loads
Authors: Mohammad Javad Najafirad, Shirantha Welikala
Abstract: This paper presents a novel dissipativity-based distributed droop-free control and communication topology co-design approach for voltage regulation and current sharing in DC microgrids (DC MGs) with generic ``ZIP'' (constant impedance (Z), current (I) and power (P)) loads. While ZIP loads accurately capture the varied nature of the consumer loads, its constant power load (CPL) component is particularly challenging (and destabilizing) due to its non-linear form. Moreover, ensuring simultaneous voltage regulation and current sharing and co-designing controllers and topology are also challenging when designing control solutions for DC MGs. To address these three challenges, we model the DC MG as a networked system comprised of distributed generators (DGs), ZIP loads, and lines interconnected according to a static interconnection matrix. Next, we equip each DG with a local controller and a distributed global controller (over an arbitrary topology) to derive the error dynamic model of the DC MG as a networked ``error'' system, including disturbance inputs and performance outputs. Subsequently, to co-design the controllers and the topology ensuring robust (dissipative) voltage regulation and current sharing performance, we use the dissipativity and sector boundedness properties of the involved subsystems and formulate Linear Matrix Inequality (LMI) problems to be solved locally and globally. To support the feasibility of the global LMI problem, we identify and embed several crucial necessary conditions in the corresponding local LMI problems, thus providing a one-shot approach to solve the LMI problems. Overall, the proposed approach in this paper provides a unified framework for designing DC MGs. The effectiveness of the proposed solution was verified by simulating an islanded DC MG under different scenarios, demonstrating superior performance compared to traditional control approaches.

Paper number 73:
Title: Design and benchmarking of a two degree of freedom tendon driver unit for cable-driven wearable technologies
Authors: Adrian Esser, Chiara Basla, Peter Wolf, Robert Riener
Abstract: Exosuits have recently been developed as alternatives to rigid exoskeletons and are increasingly adopted for both upper and lower limb therapy and assistance in clinical and home environments. Many cable-driven exosuits have been developed but little has been published on their electromechanical designs and performance. Therefore, this paper presents a comprehensive design and performance analysis of a two degree of freedom tendon driver unit (TDU) for cable-driven wearable exosuits. Detailed methodologies are presented to benchmark the functionality of the TDU. A static torque output test compares the commanded and measured torques. A velocity control test evaluates the attenuation and phase shift across velocities. A noise test evaluates how loud the TDU is for the wearer under different speeds. A thermal stress test captures the cooling performance of the TDU to ensure safe operation at higher loads. Finally, a battery endurance test evaluates the runtime of the TDU under various loading conditions to inform the usable time. To demonstrate these tests, a modular TDU system for cable-driven applications is introduced, which allows components such as motors, pulleys, and sensors to be adapted based on the requirements of the intended application. By sharing detailed methodologies and performance results, this study aims to provide a TDU design that may be leveraged by others and resources for researchers and engineers to better document the capabilities of their TDU designs.

Paper number 74:
Title: BrainOmni: A Brain Foundation Model for Unified EEG and MEG Signals
Authors: Qinfan Xiao, Ziyun Cui, Chi Zhang, Siqi Chen, Wen Wu, Andrew Thwaites, Alexandra Woolgar, Bowen Zhou, Chao Zhang
Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) measure neural activity non-invasively by capturing electromagnetic fields generated by dendritic currents. Although rooted in the same biophysics, EEG and MEG exhibit distinct signal patterns, further complicated by variations in sensor configurations across modalities and recording devices. Existing approaches typically rely on separate, modality- and dataset-specific models, which limits the performance and cross-domain scalability. This paper proposes BrainOmni, the first brain foundation model that generalises across heterogeneous EEG and MEG recordings. To unify diverse data sources, we introduce BrainTokenizer,the first tokenizer that quantises spatiotemporal brain activity into discrete representations. Central to BrainTokenizer is a novel Sensor Encoder that encodes sensor properties such as spatial layout, orientation, and type, enabling compatibility across devices and modalities. Building upon the discrete representations, BrainOmni learns unified semantic embeddings of brain signals by self-supervised pretraining. To the best of our knowledge, it is the first foundation model to support both EEG and MEG signals, as well as the first to incorporate large-scale MEG pretraining. A total of 1,997 hours of EEG and 656 hours of MEG data are curated and standardised from publicly available sources for pretraining. Experiments show that BrainOmni outperforms both existing foundation models and state-of-the-art task-specific models on a range of downstream tasks. It also demonstrates strong generalisation to unseen EEG and MEG devices. Further analysis reveals that joint EEG-MEG (EMEG) training yields consistent improvements across both modalities. Code and checkpoints are publicly available at this https URL.

Paper number 75:
Title: Joint Denoising of Cryo-EM Projection Images using Polar Transformers
Authors: Joakim andén, Justus Sagemüller
Abstract: Many imaging modalities involve reconstruction of unknown objects from collections of noisy projections related by random rotations. In one of these modalities, cryogenic electron microscopy (cryo-EM), the extremely low signal-to-noise ratio (SNR) makes integration of information from multiple images crucial. Existing approaches to cryo-EM processing, however, either rely on handcrafted priors or apply deep learning only on select portions of the pipeline, such as particle picking, micrograph denoising, or refinement. A fully end-to-end reconstruction approach requires a neural network architecture that integrates information from multiple images while respecting the rotational symmetry of the measurement process. In this work, we introduce the polar transformer, a new neural network architecture that combines polar representations and transformers along with a convolutional attention mechanism that preserves the rotational symmetry of the problem. We apply it to the particle-level denoising problem, where it is able to learn discriminative features in the images, enabling optimal clustering, alignment, and denoising. On simulated datasets, this achieves up to a $2\times$ reduction in mean squared error (MSE) at a signal-to-noise ratio (SNR) of $0.02$, suggesting new opportunities for data-driven approaches to reconstruction in cryo-EM and related tomographic modalities.

Paper number 76:
Title: Deep Learning-based mmWave MIMO Channel Estimation using sub-6 GHz Channel Information: CNN and UNet Approaches
Authors: Faruk Pasic, Lukas Eller, Stefan Schwarz, Markus Rupp, Christoph F. Mecklenbräuker
Abstract: Future wireless multiple-input multiple-output (MIMO) systems will integrate both sub-6 GHz and millimeter wave (mmWave) frequency bands to meet the growing demands for high data rates. MIMO link establishment typically requires accurate channel estimation, which is particularly challenging at mmWave frequencies due to the low signal-to-noise ratio (SNR). In this paper, we propose two novel deep learning-based methods for estimating mmWave MIMO channels by leveraging out-of-band information from the sub-6 GHz band. The first method employs a convolutional neural network (CNN), while the second method utilizes a UNet architecture. We compare these proposed methods against deep-learning methods that rely solely on in-band information and with other state-of-the-art out-of-band aided methods. Simulation results show that our proposed out-of-band aided deep-learning methods outperform existing alternatives in terms of achievable spectral efficiency.

Paper number 77:
Title: Integrated Polarimetric Sensing and Communication with Polarization-Reconfigurable Arrays
Authors: Byunghyun Lee, Rang Liu, David J. Love, James V. Krogmeier, A. Lee Swindlehurst
Abstract: Polarization diversity offers a cost- and space-efficient solution to enhance the performance of integrated sensing and communication systems. Polarimetric sensing exploits the signal's polarity to extract details about the target such as shape, pose, and material composition. From a communication perspective, polarization diversity can enhance the reliability and throughput of communication channels. This paper proposes an integrated polarimetric sensing and communication (IPSAC) system that jointly conducts polarimetric sensing and communications. We study the use of single-port polarization-reconfigurable antennas to adapt to channel depolarization effects, without the need for separate RF chains for each polarization. We address two core sensing tasks in IPSAC systems, target parameter estimation and target detection. For parameter estimation, we consider the problem of minimizing the mean-squared error (MSE) of the target depolarization parameter estimate, which is a critical task for various polarimetric radar applications such as rainfall forecasting, vegetation identification, and target classification. To address this nonconvex problem, we apply semi-definite relaxation (SDR) and majorization-minimization (MM) optimization techniques. Next, we consider a design that maximizes the target SINR leveraging prior knowledge of the target and clutter depolarization statistics to enhance the target detection performance. To tackle this problem, we modify the solution developed for MSE minimization subject to the same quality-of-service (QoS) constraints. Extensive simulations show that the proposed polarization reconfiguration method substantially improves the depolarization parameter MSE. Furthermore, the proposed method considerably boosts the target SINR due to polarization diversity, particularly in cluttered environments.

Paper number 78:
Title: Quantize-Sample-and-Verify: LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding
Authors: Guangyi Zhang, Yunlong Cai, Guanding Yu, Petar Popovski, Osvaldo Simeone
Abstract: In edge-cloud speculative decoding (SD), edge devices equipped with small language models (SLMs) generate draft tokens that are verified by large language models (LLMs) in the cloud. A key bottleneck in such systems is the limited communication bandwidth between edge and cloud, which necessitates quantization of the information transmitted about generated tokens. In this work, we introduce a novel quantize-sample (Q-S) strategy that provably preserves the output distribution of the cloud-based model, ensuring that the verified tokens match the distribution of those that would have been generated directly by the LLM. We develop a throughput model for edge-cloud SD that explicitly accounts for communication latency. Leveraging this model, we propose an adaptive mechanism that optimizes token throughput by dynamically adjusting the draft length and quantization precision in response to both semantic uncertainty and channel conditions. Simulations demonstrate that the proposed Q-S approach significantly improves decoding efficiency in realistic edge-cloud deployment scenarios.

Paper number 79:
Title: MSR-Codec: A Low-Bitrate Multi-Stream Residual Codec for High-Fidelity Speech Generation with Information Disentanglement
Authors: Jingyu Li, Guangyan Zhang, Zhen Ye, Yiwen Guo
Abstract: Audio codecs are a critical component of modern speech generation systems. This paper introduces a low-bitrate, multi-scale residual codec that encodes speech into four distinct streams: semantic, timbre, prosody, and residual. This architecture achieves high-fidelity speech reconstruction at competitive low bitrates while demonstrating an inherent ability for information disentanglement. We construct a two-stage language model for text-to-speech (TTS) synthesis using this codec, which, despite its lightweight design and minimal data requirements, achieves a state-of-the-art Word Error Rate (WER) and superior speaker similarity compared to several larger models. Furthermore, the codec's design proves highly effective for voice conversion, enabling independent manipulation of speaker timbre and prosody. Our inference code, pre-trained models, and audio samples are available at this https URL.

Paper number 80:
Title: On the Fast Nonlinear Filtering with Matrix Fisher Distributions on SO(3)
Authors: Shijie Wang, Haichao Gui, Rui Zhong
Abstract: This paper addresses two interrelated problems: the nonlinear filtering mechanism and fast attitude filtering with the matrix Fisher distribution (MFD) on the special orthogonal group. By analyzing the distribution evolution along Bayes' rule, we reveal two essential properties that enhance the performance of Bayesian attitude filters with MFDs, particularly in challenging conditions from a theoretical viewpoint. Benefiting from the new understanding of the filtering mechanism associated with MFDs, two closed-form filters with MFDs are then proposed. The filters avoids the burdensome computations in previous MFD-based filters by introducing linearized error systems with invariant errors but retaining the two advantageous properties. Numerical simulations demonstrate that the proposed filters are more accurate than the classic invariant Kalman filter. Besides, it is also as accurate as recent MFD-based Bayesian filters in challenging circumstances with large initial error and measurement uncertainty, but it consumes far less computation time (about 1/5 to 1/100 of previous MFD-based attitude filters).

Paper number 81:
Title: Addressing Model Inaccuracies in Transmission Network Reconfiguration via Diverse Alternatives
Authors: Paul Bannmüller, Périne Cunat, Ali Rajaei, Jochen Cremer
Abstract: The ongoing energy transition places significant pressure on the transmission network due to increasing shares of renewables and electrification. To mitigate grid congestion, transmission system operators need decision support tools to suggest remedial actions, such as transmission network reconfigurations or redispatch. However, these tools are prone to model inaccuracies and may not provide relevant suggestions with regard to important unmodeled constraints or operator preferences. We propose a human-in-the-loop modeling-to-generate alternatives (HITL-MGA) approach to address these shortcomings by generating diverse topology reconfiguration alternatives. Case studies on the IEEE 57-bus and IEEE 118-bus systems show the method can leverage expert feedback and improve the quality of the suggested topology reconfigurations.

Paper number 82:
Title: LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition
Authors: Zejun Liu, Yunshan Chen, Chengxi Xie, Yugui Xie, Huan Liu
Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant attention and witnessed notable advancements, the inherent complexity of human neural systems has motivated substantial efforts toward multimodal approaches. However, this field currently suffers from three critical limitations: (i) the absence of open-source implementations. (ii) the lack of standardized and transparent benchmarks for fair performance analysis. (iii) in-depth discussion regarding main challenges and promising research directions is a notable scarcity. To address these challenges, we introduce LibEMER, a unified evaluation framework that provides fully reproducible PyTorch implementations of curated deep learning methods alongside standardized protocols for data preprocessing, model realization, and experimental setups. This framework enables unbiased performance assessment on three widely-used public datasets across two learning tasks. The open-source library is publicly accessible at: this https URL

Paper number 83:
Title: Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems
Authors: Haoran He
Abstract: This paper proposes a machine learning-assisted channel estimation approach for massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE methods. In 5G and beyond, accurate channel estimation mitigates pilot contamination and high mobility issues that harm system reliability. The proposed DNN architecture includes multi-layer perceptrons with ReLU activation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam optimizer (learning rate 1e-4) and MSE loss function. It learns from pilot signals to predict channel matrices, achieving lower NMSE and BER across different SNR levels. Simulations use the COST 2100 public standard dataset (a well-recognized MIMO channel dataset for 5G, not synthetic datasets) with 10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show the DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust performance in high-mobility scenarios. The study evaluates metrics like NMSE vs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations, and computational complexity. The DNN has 2.3 GFlOPs computational complexity, 15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying deployment feasibility. This work advances ML integration in wireless communications, facilitating efficient resource allocation and improved spectral efficiency in next-generation networks. Future work may use more real-world datasets and hybrid architectures for better generalization.

Paper number 84:
Title: FakeMark: Deepfake Speech Attribution With Watermarked Artifacts
Authors: Wanying Ge, Xin Wang, Junichi Yamagishi
Abstract: Deepfake speech attribution remains challenging for existing solutions. Classifier-based solutions often fail to generalize to domain-shifted samples, and watermarking-based solutions are easily compromised by distortions like codec compression or malicious removal attacks. To address these issues, we propose FakeMark, a novel watermarking framework that injects artifact-correlated watermarks associated with deepfake systems rather than pre-assigned bitstring messages. This design allows a detector to attribute the source system by leveraging both injected watermark and intrinsic deepfake artifacts, remaining effective even if one of these cues is elusive or removed. Experimental results show that FakeMark improves generalization to cross-dataset samples where classifier-based solutions struggle and maintains high accuracy under various distortions where conventional watermarking-based solutions fail.

Paper number 85:
Title: High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization
Authors: Fabrizio Orlando, Deborah Volpe, Giacomo Orlandi, Mariagrazia Graziano, Fabrizio Riente, Marco Vacca
Abstract: Combinatorial Optimization (CO) problems exhibit exponential complexity, making their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a quantum-inspired algorithm to obtain approximate solutions to largescale CO problems written in the Ising form. It explores the solution space by emulating the adiabatic evolution of a network of Kerr-nonlinear parametric oscillators (KPOs), where each oscillator represents a variable in the problem. The optimal solution corresponds to the ground state of this system. A key advantage of this approach is the possibility of updating multiple variables simultaneously, making it particularly suited for hardware implementation. To enhance solution quality and convergence speed, variations of the algorithm have been proposed in the literature, including ballistic (bSB), discrete (dSB), and thermal (HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and HbSB using dedicated software models, evaluating the feasibility of using a fixed-point representation for hardware implementation. We then present an opensource hardware architecture implementing the dSB algorithm for Field-Programmable Gate Arrays (FPGAs). The design allows users to adjust the degree of algorithmic parallelization based on their specific requirements. A proof-of-concept implementation that solves 256-variable problems was achieved on an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut and knapsack problems.

Paper number 86:
Title: Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs
Authors: Dongsheng Ding, Kaiqing Zhang, Jiali Duan, Tamer Başar, Mihailo R. Jovanović
Abstract: We study the sequential decision making problem of maximizing the expected total reward while satisfying a constraint on the expected total utility. We employ the natural policy gradient method to solve the discounted infinite-horizon optimal control problem for Constrained Markov Decision Processes (constrained MDPs). Specifically, we propose a new Natural Policy Gradient Primal-Dual (NPG-PD) method that updates the primal variable via natural policy gradient ascent and the dual variable via projected subgradient descent. Although the underlying maximization involves a nonconcave objective function and a nonconvex constraint set, under the softmax policy parametrization, we prove that our method achieves global convergence with sublinear rates regarding both the optimality gap and the constraint violation. Such convergence is independent of the size of the state-action space, i.e., it is~dimension-free. Furthermore, for log-linear and general smooth policy parametrizations, we establish sublinear convergence rates up to a function approximation error caused by restricted policy parametrization. We also provide convergence and finite-sample complexity guarantees for two sample-based NPG-PD algorithms. We use a set of computational experiments to showcase the effectiveness of our approach.

Paper number 87:
Title: Latent-Domain Predictive Neural Speech Coding
Authors: Xue Jiang, Xiulian Peng, Huaying Xue, Yuan Zhang, Yan Lu
Abstract: Neural audio/speech coding has recently demonstrated its capability to deliver high quality at much lower bitrates than traditional methods. However, existing neural audio/speech codecs employ either acoustic features or learned blind features with a convolutional neural network for encoding, by which there are still temporal redundancies within encoded features. This paper introduces latent-domain predictive coding into the VQ-VAE framework to fully remove such redundancies and proposes the TF-Codec for low-latency neural speech coding in an end-to-end manner. Specifically, the extracted features are encoded conditioned on a prediction from past quantized latent frames so that temporal correlations are further removed. Moreover, we introduce a learnable compression on the time-frequency input to adaptively adjust the attention paid to main frequencies and details at different bitrates. A differentiable vector quantization scheme based on distance-to-soft mapping and Gumbel-Softmax is proposed to better model the latent distributions with rate constraint. Subjective results on multilingual speech datasets show that, with low latency, the proposed TF-Codec at 1 kbps achieves significantly better quality than Opus at 9 kbps, and TF-Codec at 3 kbps outperforms both EVS at 9.6 kbps and Opus at 12 kbps. Numerous studies are conducted to demonstrate the effectiveness of these techniques. Code and models are available at this https URL.

Paper number 88:
Title: Streaming Neural Images
Authors: Marcos V. Conde, Andy Bigos, Radu Timofte
Abstract: Implicit Neural Representations (INRs) are a novel paradigm for signal representation that have attracted considerable interest for image compression. INRs offer unprecedented advantages in signal resolution and memory efficiency, enabling new possibilities for compression techniques. However, the existing limitations of INRs for image compression have not been sufficiently addressed in the literature. In this work, we explore the critical yet overlooked limiting factors of INRs, such as computational cost, unstable performance, and robustness. Through extensive experiments and empirical analysis, we provide a deeper and more nuanced understanding of implicit neural image compression methods such as Fourier Feature Networks and Siren. Our work also offers valuable insights for future research in this area.

Paper number 89:
Title: Tiny Learning-Based MPC for Multirotors: Solver-Aware Learning for Efficient Embedded Predictive Control
Authors: Babak Akbari, Justin Frank, Melissa Greeff
Abstract: Tiny aerial robots hold great promise for applications such as environmental monitoring and search-and-rescue, yet face significant control challenges due to limited onboard computing power and nonlinear dynamics. Model Predictive Control (MPC) enables agile trajectory tracking and constraint handling but depends on an accurate dynamics model. While existing Learning-Based (LB) MPC methods, such as Gaussian Process (GP) MPC, enhance performance by learning residual dynamics, their high computational cost restricts onboard deployment on tiny robots. This paper introduces Tiny LB MPC, a co-designed MPC framework and optimization solver for resource-constrained micro multirotor platforms. The proposed approach achieves 100 Hz control on a Crazyflie 2.1 equipped with a Teensy 4.0 microcontroller, demonstrating a 43% average improvement in tracking performance over existing embedded MPC methods under model uncertainty, and achieving the first onboard implementation of LB MPC on a 53 g multirotor.

Paper number 90:
Title: CSI-BERT2: A BERT-inspired Framework for Efficient CSI Prediction and Classification in Wireless Communication and Sensing
Authors: Zijian Zhao, Fanyi Meng, Zhonghao Lyu, Hang Li, Xiaoyang Li, Guangxu Zhu
Abstract: Channel state information (CSI) is a fundamental component in both wireless communication and sensing systems, enabling critical functions such as radio resource optimization and environmental perception. In wireless sensing, data scarcity and packet loss hinder efficient model training, while in wireless communication, high-dimensional CSI matrices and short coherent times caused by high mobility present challenges in CSI this http URL address these issues, we propose a unified framework named CSI-BERT2 for CSI prediction and classification tasks, built on CSI-BERT, which adapts BERT to capture the complex relationships among CSI sequences through a bidirectional self-attention mechanism. We introduce a two-stage training method that first uses a mask language model (MLM) to enable the model to learn general feature extraction from scarce datasets in an unsupervised manner, followed by fine-tuning for specific downstream tasks. Specifically, we extend MLM into a mask prediction model (MPM), which efficiently addresses the CSI prediction task. To further enhance the representation capacity of CSI data, we modify the structure of the original CSI-BERT. We introduce an adaptive re-weighting layer (ARL) to enhance subcarrier representation and a multi-layer perceptron (MLP)-based temporal embedding module to mitigate temporal information loss problem inherent in the original this http URL experiments on both real-world collected and simulated datasets demonstrate that CSI-BERT2 achieves state-of-the-art performance across all tasks. Our results further show that CSI-BERT2 generalizes effectively across varying sampling rates and robustly handles discontinuous CSI sequences caused by packet loss-challenges that conventional methods fail to address. The dataset and code are publicly available at this https URL .

Paper number 91:
Title: ASE: Practical Acoustic Speed Estimation Beyond Doppler via Sound Diffusion Field
Authors: Sheng Lyu, Chenshu Wu
Abstract: Passive human speed estimation plays a critical role in acoustic sensing. Despite extensive study, existing systems, however, suffer from various limitations: First, the channel measurement rate proves inadequate to estimate high moving speeds. Second, previous acoustic speed estimation exploits Doppler Frequency Shifts (DFS) created by moving targets and relies on microphone arrays, making them only capable of sensing the radial speed within a constrained distance. To overcome these issues, we present ASE, an accurate and robust Acoustic Speed Estimation system on a single commodity microphone. We propose a novel Orthogonal Time-Delayed Multiplexing (OTDM) scheme for acoustic channel estimation at a high rate that was previously infeasible, making it possible to estimate high speeds. We then model the sound propagation from a unique perspective of the acoustic diffusion field, and infer the speed from the acoustic spatial distribution, a completely different way of thinking about speed estimation beyond prior DFS-based approaches. We further develop novel techniques for motion detection and signal enhancement to deliver a robust and practical system. We implement and evaluate ASE through extensive real-world experiments. Our results show that ASE reliably tracks walking speed, independently of target location and direction, with a mean error of 0.13 m/s, a reduction of 2.5x from DFS, and a detection rate of 97.4% for large coverage, e.g., free walking in a 4m x 4m room. We believe ASE pushes acoustic speed estimation beyond the conventional DFS-based paradigm and inspires exciting research in acoustic sensing. Code is available at this https URL.

Paper number 92:
Title: Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations
Authors: Xue Jiang, Xiulian Peng, Yuan Zhang, Yan Lu
Abstract: Current large speech language models are mainly based on semantic tokens from discretization of self-supervised learned representations and acoustic tokens from a neural codec, following a semantic-modeling and acoustic-synthesis paradigm. However, semantic tokens discard paralinguistic attributes of speakers that is important for natural spoken communication, while prompt-based acoustic synthesis from semantic tokens has limits in recovering paralinguistic details and suffers from robustness issues, especially when there are domain gaps between the prompt and the target. This paper unifies two types of tokens and proposes the UniCodec, a universal speech token learning that encapsulates all semantics of speech, including linguistic and paralinguistic information, into a compact and semantically-disentangled unified token. Such a unified token can not only benefit speech language models in understanding with paralinguistic hints but also help speech generation with high-quality output. A low-bitrate neural codec is leveraged to learn such disentangled discrete representations at global and local scales, with knowledge distilled from self-supervised learned features. Extensive evaluations on multilingual datasets demonstrate its effectiveness in generating natural, expressive and long-term consistent output quality with paralinguistic attributes well preserved in several speech processing tasks.

Paper number 93:
Title: A Personalized Data-Driven Generative Model of Human Repetitive Motion
Authors: Angelo Di Porzio, Marco Coraggio
Abstract: The deployment of autonomous virtual avatars (in extended reality) and robots in human group activities -- such as rehabilitation therapy, sports, and manufacturing -- is expected to increase as these technologies become more pervasive. Designing cognitive architectures and control strategies to drive these agents requires realistic models of human motion. Furthermore, recent research has shown that each person exhibits a unique velocity signature, highlighting how individual motor behaviors are both rich in variability and internally consistent. However, existing models only provide simplified descriptions of human motor behavior, hindering the development of effective cognitive architectures. In this work, we first show that motion amplitude provides a valid and complementary characterization of individual motor signatures. Then, we propose a fully data-driven approach, based on long short-term memory neural networks, to generate original motion that captures the unique features of specific individuals. We validate the architecture using real human data from participants performing spontaneous oscillatory motion. Extensive analyses show that state-of-the-art Kuramoto-like models fail to replicate individual motor signatures, whereas our model accurately reproduces the velocity distribution and amplitude envelopes of the individual it was trained on, while remaining distinct from others.

Paper number 94:
Title: VRS-UIE: Value-Driven Reordering Scanning for Underwater Image Enhancement
Authors: Kui Jiang, Yan Luo, Junjun Jiang, Ke Gu, Nan Ma, Xianming Liu
Abstract: State Space Models (SSMs) have emerged as a promising backbone for vision tasks due to their linear complexity and global receptive field. However, in the context of Underwater Image Enhancement (UIE), the standard sequential scanning mechanism is fundamentally challenged by the unique statistical distribution characteristics of underwater scenes. The predominance of large-portion, homogeneous but useless oceanic backgrounds can dilute the feature representation responses of sparse yet valuable targets, thereby impeding effective state propagation and compromising the model's ability to preserve both local semantics and global structure. To address this limitation, we propose a novel Value-Driven Reordering Scanning framework for UIE, termed VRS-UIE. Its core innovation is a Multi-Granularity Value Guidance Learning (MVGL) module that generates a pixel-aligned value map to dynamically reorder the SSM's scanning sequence. This prioritizes informative regions to facilitate the long-range state propagation of salient features. Building upon the MVGL, we design a Mamba-Conv Mixer (MCM) block that synergistically integrates priority-driven global sequencing with dynamically adjusted local convolutions, thereby effectively modeling both large-portion oceanic backgrounds and high-value semantic targets. A Cross-Feature Bridge (CFB) further refines multi-level feature fusion. Extensive experiments demonstrate that our VRS-UIE framework sets a new state-of-the-art, delivering superior enhancement performance (surpassing WMamba by 0.89 dB on average) by effectively suppressing water bias and preserving structural and color fidelity. Furthermore, by incorporating efficient convolutional operators and resolution rescaling, we construct a light-weight yet effective scheme, VRS-UIE-S, suitable for real-time UIE applications.

Paper number 95:
Title: PAL: Probing Audio Encoders via LLMs - Audio Information Transfer into LLMs
Authors: Tony Alex, Wish Suharitdamrong, Sara Atito, Armin Mustafa, Philip J. B. Jackson, Imran Razzak, Muhammad Awais
Abstract: Integration of audio perception into large language models (LLMs) is an emerging research area for enabling machine listening applications, yet efficient transfer of rich audio semantics from audio encoders to LLMs remains underexplored. The most widely used integration paradigm projects the audio encoder output tokens into the LLM input space (e.g., via an MLP or a Q-Former), then prepends or inserts them to the text tokens. We refer to this generic scheme as Prepend to the LLM's input token space (PLITS) integration. We propose an efficient alternative, Lightweight Audio LLM Integration (LAL). LAL introduces audio representations solely via the attention mechanism within different layers of the LLM, bypassing its feedforward module. LAL encodes rich audio semantics at an appropriate level of abstraction for integration into different blocks of LLMs. Our design significantly reduces computational overhead compared to existing integration approaches. Observing with Whisper that the speech encoder benefits from PLITS integration, we propose an audio encoder aware approach for efficiently Probing Audio encoders via LLM (PAL), which employs PLITS integration for Whisper and LAL for general audio encoders. Under an identical training curriculum, LAL consistently maintains performance or outperforms existing integration approaches across multiple base LLMs and tasks. For general audio tasks, LAL improvement is up to 30% over a strong PLITS baseline while reducing memory usage by up to 64.1% and increasing throughput by up to 247.5%. Furthermore, for general audio-music-speech LLM, PAL performs on par with a fully PLITS integration-based system but with substantially improved computational and memory efficiency. Project page: this https URL

Paper number 96:
Title: A Verification Methodology for Safety Assurance of Robotic Autonomous Systems
Authors: Mustafa Adam, David A. Anisi, Pedro Ribeiro
Abstract: Autonomous robots deployed in shared human environments, such as agricultural settings, require rigorous safety assurance to meet both functional reliability and regulatory compliance. These systems must operate in dynamic, unstructured environments, interact safely with humans, and respond effectively to a wide range of potential hazards. This paper presents a verification workflow for the safety assurance of an autonomous agricultural robot, covering the entire development life-cycle, from concept study and design to runtime verification. The outlined methodology begins with a systematic hazard analysis and risk assessment to identify potential risks and derive corresponding safety requirements. A formal model of the safety controller is then developed to capture its behaviour and verify that the controller satisfies the specified safety properties with respect to these requirements. The proposed approach is demonstrated on a field robot operating in an agricultural setting. The results show that the methodology can be effectively used to verify safety-critical properties and facilitate the early identification of design issues, contributing to the development of safer robots and autonomous systems.

Paper number 97:
Title: Deep Feature-specific Imaging
Authors: Yizhou Lu, Andreas Velten
Abstract: Modern photon-counting sensors are increasingly dominated by Poisson noise, yet conventional Feature-Specific Imaging (FSI) is optimized for additive Gaussian noise, leading to suboptimal performance and a loss of its advantages under Poisson noise. To address this, we introduce DeepFSI, a novel end-to-end optical-electronic framework. DeepFSI "unfreezes" traditional FSI masks, enabling a deep neural network to learn globally optimal measurement masks by computing gradients directly under realistic Poisson and additive noise conditions. Our simulations demonstrate DeepFSI's superior feature fidelity and task performance compared to conventional FSI with predefined masks, especially in Poisson-Noise-dominant environments. DeepFSI also exhibits enhanced robustness to design choices and performs well under additive Gaussian noise, representing a significant advance for noise-robust computational imaging in photon-limited applications.

Paper number 98:
Title: QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots
Authors: Sheng Wu, Fei Teng, Hao Shi, Qi Jiang, Kai Luo, Kaiwei Wang, Kailun Yang
Abstract: Panoramic cameras, capturing comprehensive 360-degree environmental data, are suitable for quadruped robots in surrounding perception and interaction with complex environments. However, the scarcity of high-quality panoramic training data-caused by inherent kinematic constraints and complex sensor calibration challenges-fundamentally limits the development of robust perception systems tailored to these embodied platforms. To address this issue, we propose QuaDreamer-the first panoramic data generation engine specifically designed for quadruped robots. QuaDreamer focuses on mimicking the motion paradigm of quadruped robots to generate highly controllable, realistic panoramic videos, providing a data source for downstream tasks. Specifically, to effectively capture the unique vertical vibration characteristics exhibited during quadruped locomotion, we introduce Vertical Jitter Encoding (VJE). VJE extracts controllable vertical signals through frequency-domain feature filtering and provides high-quality prompts. To facilitate high-quality panoramic video generation under jitter signal control, we propose a Scene-Object Controller (SOC) that effectively manages object motion and boosts background jitter control through the attention mechanism. To address panoramic distortions in wide-FoV video generation, we propose the Panoramic Enhancer (PE)-a dual-stream architecture that synergizes frequency-texture refinement for local detail enhancement with spatial-structure correction for global geometric consistency. We further demonstrate that the generated video sequences can serve as training data for the quadruped robot's panoramic visual perception model, enhancing the performance of multi-object tracking in 360-degree scenes. The source code and model weights will be publicly available at this https URL.

Paper number 99:
Title: Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer
Authors: Kaiqiang Lin, Mohamed-Slim Alouini
Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing and monitoring of underground resources by underground devices (UDs), hold great promise for delivering substantial social and economic benefits across various verticals. However, due to the harsh subterranean environment, scarce network resources, and restricted communication coverage, WUSNs face significant challenges in supporting sustainable massive machine-type communications (mMTC), particularly in remote, disaster-stricken, and hard-to-reach areas. To complement this, we conceptualize in this study a novel space-air-ground-underground integrated network (SAGUIN) architecture that seamlessly incorporates satellite systems, aerial platforms, terrestrial networks, and underground communications. On this basis, we integrate LoRaWAN and wireless energy transfer (WET) technologies into SAGUIN to enable sustainable subterranean mMTC. We begin by reviewing the relevant technical background and presenting the architecture and implementation challenges of SAGUIN. Then, we employ simulations to model a remote underground pipeline monitoring scenario to evaluate the feasibility and performance of SAGUIN based on LoRaWAN and WET technologies, focusing on the effects of parameters such as underground conditions, time allocation, LoRaWAN spread factor (SF) configurations, reporting periods, and harvested energy levels. Our results evidence that the proposed SAGUIN system, when combined with the derived time allocation strategy and an appropriate SF, can effectively extend the operational lifetime of UDs, thereby facilitating sustainable subterranean mMTC. Finally, we pinpoint key challenges and future research directions for SAGUIN.

Paper number 100:
Title: Software System for Low-Cost, GUI-Based Microscopy Segmentation: Algorithmic Implementation
Authors: Surajit Das, Pavel Zun
Abstract: This article presents a novel microscopy image analysis framework designed for low-budget labs equipped with a standard CPU desktop. The Python-based program enables cytometric analysis of live, unstained cells in culture through an advanced computer vision and machine learning pipeline. Crucially, the framework operates on label-free data, requiring no manually annotated training data or training phase. It is accessible via a user-friendly, cross-platform GUI that requires no programming skills, while also providing a scripting interface for programmatic control and integration by developers. The end-to-end workflow performs semantic and instance segmentation, feature extraction, analysis, evaluation, and automated report generation. Its modular architecture supports easy maintenance and flexible integration while supporting both single-image and batch processing. Validated on several unstained cell types from the public dataset of livecells, the framework demonstrates superior accuracy and reproducibility compared to contemporary tools like Cellpose and StarDist. Its competitive segmentation speed on a CPU-based platform highlights its significant potential for basic research and clinical application-particularly in cell transplantation for personalised medicine and muscle regeneration therapies. The access to the application is available for reproducibility.

Paper number 101:
Title: Dual-Regularized Riccati Recursions for Interior-Point Optimal Control
Authors: João Sousa-Pinto, Dominique Orban
Abstract: We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.

Paper number 102:
Title: AudioGenie-Reasoner: A Training-Free Multi-Agent Framework for Coarse-to-Fine Audio Deep Reasoning
Authors: Yan Rong, Chenxing Li, Dong Yu, Li Liu
Abstract: Audio deep reasoning is a challenging task that requires expert-level perception, multi-step logical inference, and the integration of contextual knowledge. However, existing models suffer from a gap between audio perception and reasoning abilities due to the lack of training data with explicit reasoning chains and the absence of mechanisms for active exploration and iterative refinement. To address these challenges, we propose AudioGenie-Reasoner (AGR), the first unified training-free multi-agent system that coordinates perception and reasoning over an evolving chain of textual evidence. Our key idea is a paradigm shift that transforms audio deep reasoning into complex text understanding task from a new perspective, thereby unlocking the full potential of large language models. Specifically, the design of AGR mimics the human coarse-to-fine cognitive process. It first transforms the input audio into a coarse text-based document. Then, we design a novel proactive iterative document refinement loop, featuring tool-augmented routes and specialized agents, to continuously search for missing information and augment the evidence chain in a coarse-to-fine manner until sufficient question-related information is gathered for making final predictions. Experimental results show that AGR achieves state-of-the-art (SOTA) performance over existing open-source audio deep reasoning models across various benchmarks. The code will be available at this https URL.

Paper number 103:
Title: SAGE-Music: Low-Latency Symbolic Music Generation via Attribute-Specialized Key-Value Head Sharing
Authors: Jiaye Tan, Haonan Luo, Linfeng Song, Shuaiqi Chen, Yishan Lyu, Zian Zhong, Roujia Wang, Daniel Jiang, Haoran Zhang, Jiaming Bai, Haoran Cheng, Q. Vera Liao, Hao-Wen Dong
Abstract: Low-latency symbolic music generation is essential for real-time improvisation and human-AI co-creation. Existing transformer-based models, however, face a trade-off between inference speed and musical quality. Traditional acceleration techniques such as embedding pooling significantly degrade quality, while recently proposed Byte Pair Encoding (BPE) methods - though effective on single-track piano data - suffer large performance drops in multi-track settings, as revealed by our analysis. We propose Attribute-Specialized Key-Value Head Sharing (AS-KVHS), adapted to music's structured symbolic representation, achieving about 30% inference speedup with only a negligible (about 0.4%) quality drop in objective evaluations and slight improvements in subjective listening tests. Our main contributions are (1) the first systematic study of BPE's generalizability in multi-track symbolic music, and (2) the introduction of AS-KVHS for low-latency symbolic music generation. Beyond these, we also release SAGE-Music, an open-source benchmark that matches or surpasses state-of-the-art models in generation quality.

Paper number 104:
Title: Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances
Authors: Jaewoo Lee, Dongjae Lee, Jinwoo Lee, Hyungyu Lee, Yeonjoon Kim, H. Jin Kim
Abstract: This work presents a geometric backstepping controller for a variable-tilt omnidirectional multirotor that explicitly accounts for both servo and rotor dynamics. Considering actuator dynamics is essential for more effective and reliable operation, particularly during aggressive flight maneuvers or recovery from sudden disturbances. While prior studies have investigated actuator-aware control for conventional and fixed-tilt multirotors, these approaches rely on linear relationships between actuator input and wrench, which cannot capture the nonlinearities induced by variable tilt angles. In this work, we exploit the cascade structure between the rigid-body dynamics of the multirotor and its nonlinear actuator dynamics to design the proposed backstepping controller and establish exponential stability of the overall system. Furthermore, we reveal parametric uncertainty in the actuator model through experiments, and we demonstrate that the proposed controller remains robust against such uncertainty. The controller was compared against a baseline that does not account for actuator dynamics across three experimental scenarios: fast translational tracking, rapid rotational tracking, and recovery from sudden disturbance. The proposed method consistently achieved better tracking performance, and notably, while the baseline diverged and crashed during the fastest translational trajectory tracking and the recovery experiment, the proposed controller maintained stability and successfully completed the tasks, thereby demonstrating its effectiveness.

Paper number 105:
Title: MelCap: A Unified Single-Codebook Neural Codec for High-Fidelity Audio Compression
Authors: Jingyi Li, Zhiyuan Zhao, Yunfei Liu, Lijian Lin, Ye Zhu, Jiahao Wu, Qiuqiang Kong, Yu Li
Abstract: Neural audio codecs have recently emerged as powerful tools for high-quality and low-bitrate audio compression, leveraging deep generative models to learn latent representations of audio signals. However, existing approaches either rely on a single quantizer that only processes speech domain, or on multiple quantizers that are not well suited for downstream tasks. To address this issue, we propose MelCap, a unified "one-codebook-for-all" neural codec that effectively handles speech, music, and general sound. By decomposing audio reconstruction into two stages, our method preserves more acoustic details than previous single-codebook approaches, while achieving performance comparable to mainstream multi-codebook methods. In the first stage, audio is transformed into mel-spectrograms, which are compressed and quantized into compact single tokens using a 2D tokenizer. A perceptual loss is further applied to mitigate the over-smoothing artifacts observed in spectrogram reconstruction. In the second stage, a Vocoder recovers waveforms from the mel discrete tokens in a single forward pass, enabling real-time decoding. Both objective and subjective evaluations demonstrate that MelCap achieves quality on comparable to state-of-the-art multi-codebook codecs, while retaining the computational simplicity of a single-codebook design, thereby providing an effective representation for downstream tasks.

Paper number 106:
Title: Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network
Authors: Sara Strakosova, Petr Novak, Petr Kadera
Abstract: In a circular economy, products in their end-of-life phase should be either remanufactured or recycled. Both of these processes are crucial for sustainability and environmental conservation. However, manufacturers frequently do not support these processes enough in terms of not sharing relevant data about the products nor their (re-)manufacturing processes. This paper proposes to accompany each product with a digital twin technology, specifically the Product Digital Twin (PDT), which can carry information for facilitating and optimizing production and remanufacturing processes. This paper introduces a knowledge representation called Bi-Flow Product-Process-Resource Asset Network (Bi-PAN). Bi-PAN extends a well-proven Product-Process-Resource Asset Network (PAN) paradigm by integrating both assembly and disassembly workflows into a single information model. Such networks enable capturing relevant relationships across products, production resources, manufacturing processes, and specific production operations that have to be done in the manufacturing phase of a product. The proposed approach is demonstrated in a use-case of disassembling electric vehicle (EV) batteries. By utilizing PDTs with Bi-PAN knowledge models, challenges associated with disassembling of EV batteries can be solved flexibly and efficiently for various battery types, enhancing the sustainability of the EV battery life-cycle management.

Paper number 107:
Title: The Algorithmic Regulator
Authors: Giulio Ruffini
Abstract: The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\Delta > 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] making low $M(W{:}R)$ exponentially unlikely as $\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout.

Paper number 108:
Title: Hybrid Terrain-Aware Path Planning: Integrating VD-RRT* Exploration and VD-D* Lite Repair
Authors: Akshay Naik, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu
Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible paths while accounting for spatially varying soil strength and slope hazards in real time. We present a continuous state--cost metric that combines a Bekker pressure--sinkage model with elevation-derived slope and attitude penalties. The resulting terrain cost field is analytic, bounded, and monotonic in soil modulus and slope, ensuring well-posed discretization and stable updates under sensor noise. This metric is evaluated on a lattice with exact steering primitives: Dubins and Reeds--Shepp motions for differential drive and time-parameterized bicycle arcs for Ackermann steering. Global exploration is performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without heuristic smoothing. By separating the terrain--vehicle model from the planner, the framework provides a reusable basis for deterministic, sampling-based, or learning-driven planning in deformable terrain. Hardware trials on an off-road platform demonstrate real-time navigation across soft soil and slope transitions, supporting reliable autonomy in unstructured environments.

Paper number 109:
Title: The value of storage in electricity distribution: The role of markets
Authors: Dirk Lauinger, Deepjyoti Deka, Sungho Shin
Abstract: Electricity distribution companies deploy battery storage to defer grid upgrades by reducing peak demand. In deregulated jurisdictions, such storage often sits idle because regulatory constraints bar participation in electricity markets. Here, we develop an optimization framework that, to our knowledge, provides the first formal model of market participation constraints within storage investment and operation planning. Applying the framework to a Massachusetts case study, we find that market participation could deliver similar savings as peak demand reduction. Under current conditions, market participation does not increase storage investment, but at very low storage costs, could incentivize deployment beyond local distribution needs. This might run contrary to the separation of distribution from generation in deregulated markets. Our framework can identify investment levels appropriate for local distribution needs.
    