
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Comparative Analysis of Attention Mechanisms for Automatic Modulation Classification in Radio Frequency Signals
Authors: Ferhat Ozgur Catak, Murat Kuzlu, Umit Cali
Abstract: Automatic Modulation Classification (AMC) is a critical component in cognitive radio systems and spectrum management applications. This study presents a comprehensive comparative analysis of three attention mechanisms (i.e., baseline multi-head attention, causal attention, and sparse attention) integrated with Convolutional Neural Networks (CNNs) for radio frequency (RF) signal classification. It proposes a novel CNN-Transformer hybrid architecture that leverages different attention patterns to capture temporal dependencies in I/Q samples from the RML2016.10a dataset. The experimental results demonstrate that while baseline attention achieves the highest accuracy of 85.05\%, causal and sparse attention mechanisms offer significant computational advantages with inference times reduced by 83\% and 75\% respectively, while maintaining competitive classification performance above 84\%. The analysis reveals distinct attention pattern preferences across different modulation schemes, providing insights for designing efficient attention mechanisms for real-time radio signal processing applications.

Paper number 2:
Title: Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks
Authors: Nishan Rai, Sujan Khatri, Devendra Risal
Abstract: Early detection of lung cancer is critical to improving survival outcomes. We present a deep learning framework for automated lung cancer screening from chest computed tomography (CT) images with integrated explainability. Using the IQ-OTH/NCCD dataset (1,197 scans across Normal, Benign, and Malignant classes), we evaluate a custom convolutional neural network (CNN) and three fine-tuned transfer learning backbones: DenseNet121, ResNet152, and VGG19. Models are trained with cost-sensitive learning to mitigate class imbalance and evaluated via accuracy, precision, recall, F1-score, and ROC-AUC. While ResNet152 achieved the highest accuracy (97.3%), DenseNet121 provided the best overall balance in precision, recall, and F1 (up to 92%, 90%, 91%, respectively). We further apply Shapley Additive Explanations (SHAP) to visualize evidence contributing to predictions, improving clinical transparency. Results indicate that CNN-based approaches augmented with explainability can provide fast, accurate, and interpretable support for lung cancer screening, particularly in resource-limited settings.

Paper number 3:
Title: Data-Efficient Learning for Generalizable Surgical Video Understanding
Authors: Sahar Nasirihaghighi
Abstract: Advances in surgical video analysis are transforming operating rooms into intelligent, data-driven environments. Computer-assisted systems support full surgical workflow, from preoperative planning to intraoperative guidance and postoperative assessment. However, developing robust and generalizable models for surgical video understanding remains challenging due to (I) annotation scarcity, (II) spatiotemporal complexity, and (III) domain gap across procedures and institutions. This doctoral research aims to bridge the gap between deep learning-based surgical video analysis in research and its real-world clinical deployment. To address the core challenge of recognizing surgical phases, actions, and events, critical for analysis, I benchmarked state-of-the-art neural network architectures to identify the most effective designs for each task. I further improved performance by proposing novel architectures and integrating advanced modules. Given the high cost of expert annotations and the domain gap across surgical video sources, I focused on reducing reliance on labeled data. We developed semi-supervised frameworks that improve model performance across tasks by leveraging large amounts of unlabeled surgical video. We introduced novel semi-supervised frameworks, including DIST, SemiVT-Surge, and ENCORE, that achieved state-of-the-art results on challenging surgical datasets by leveraging minimal labeled data and enhancing model training through dynamic pseudo-labeling. To support reproducibility and advance the field, we released two multi-task datasets: GynSurg, the largest gynecologic laparoscopy dataset, and Cataract-1K, the largest cataract surgery video dataset. Together, this work contributes to robust, data-efficient, and clinically scalable solutions for surgical video analysis, laying the foundation for generalizable AI systems that can meaningfully impact surgical care and training.

Paper number 4:
Title: Information Retention in Iterative Random Projection of Convex Bodies to Lower Dimensions
Authors: Nazanin Mirhosseini
Abstract: In this paper, we consider a bounded convex body $K_0 \subset \mathbb{R}^{n}$ subjected to two successive random orthogonal projections onto $\mathbb{R}^{n-1}$ and $\mathbb{R}^{n-2}$, respectively. First, we project $K_0$ orthogonally onto $U_{1}^{\perp}$, the orthogonal complement of $\mbox{\boldmath $U$}_1$, where $\mbox{\boldmath $U$}_1$ is uniformly distributed on the unit sphere $S^{n-1}$. This yields a random convex body $K_1 = \mathrm{Proj}_{{U_1}^{\perp}}(K_0) \subset \mathbb{R}^{n-1}$. We then repeat the process, projecting $K_1$ orthogonally onto ${U}_{2}^{\perp}$, the orthogonal complement of $\mbox{\boldmath $U$}_2$ chosen uniformly from the unit sphere in $\mbox{\boldmath $U$}_{1}^{\perp}$ or $S^{n-2}$, resulting in a second random convex body $K_2 = \mathrm{Proj}_{{U_2}^{\perp}}(K_1) \subset \mathbb{R}^{n-2}$. To quantify information retention through these sequential dimension reductions, we derive an upper bound for the conditional mutual information $I(K_1;K_2 \mid K_0)$. Furthermore, we extend this process to $m$ iterations and generalize the upper bound on $I(K_1;K_2 \mid K_0)$ to establish an analogous upper bound for $I(K_1;K_m \mid K_0)$. Finally, we examine the influence of $K_0$'s symmetry on the achievability of this upper bound for $I(K_1;K_m \mid K_0)$.

Paper number 5:
Title: DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy
Authors: Soorena Salari, Catherine Spino, Laurie-Anne Pharand, Fabienne Lathuiliere, Hassan Rivaz, Silvain Beriault, Yiming Xiao
Abstract: Accurate tissue motion tracking is critical to ensure treatment outcome and safety in 2D-Cine MRI-guided radiotherapy. This is typically achieved by registration of sequential images, but existing methods often face challenges with large misalignments and lack of interpretability. In this paper, we introduce DINOMotion, a novel deep learning framework based on DINOv2 with Low-Rank Adaptation (LoRA) layers for robust, efficient, and interpretable motion tracking. DINOMotion automatically detects corresponding landmarks to derive optimal image registration, enhancing interpretability by providing explicit visual correspondences between sequential images. The integration of LoRA layers reduces trainable parameters, improving training efficiency, while DINOv2's powerful feature representations offer robustness against large misalignments. Unlike iterative optimization-based methods, DINOMotion directly computes image registration at test time. Our experiments on volunteer and patient datasets demonstrate its effectiveness in estimating both linear and nonlinear transformations, achieving Dice scores of 92.07% for the kidney, 90.90% for the liver, and 95.23% for the lung, with corresponding Hausdorff distances of 5.47 mm, 8.31 mm, and 6.72 mm, respectively. DINOMotion processes each scan in approximately 30ms and consistently outperforms state-of-the-art methods, particularly in handling large misalignments. These results highlight its potential as a robust and interpretable solution for real-time motion tracking in 2D-Cine MRI-guided radiotherapy.

Paper number 6:
Title: A Deep Learning based Signal Dimension Estimator with Single Snapshot Signal in Phased Array Radar Application
Authors: Yugang Ma, Yonghong Zeng, Sumei Sun, Gary Lee, Ernest Kurniawan, Francois Chin Po Shin
Abstract: Signal dimension, defined here as the number of copies with different delays or angular shifts, is a prerequisite for many high-resolution delay estimation and direction-finding algorithms in sensing and communication systems. Thus, correctly estimating signal dimension itself becomes crucial. In this paper, we present a deep learning-based signal dimension estimator (DLSDE) with single-snapshot observation in the example application of phased array radar. Unlike traditional model-based and existing deep learning-based signal dimension estimators relying on eigen-decomposition and information criterion, to which multiple data snapshots would be needed, the proposed DLSDE uses two-dimensional convolutional neural network (2D-CNN) to automatically develop features corresponding to the dimension of the received signal. Our study shows that DLSDE significantly outperforms traditional methods in terms of the successful detection rate and resolution. In a phased array radar with 32 antenna elements, DLSDE improves detection Signal to Noise Ratio (SNR) by >15dB and resolution by >1Â°. This makes the proposed method suitable for distinguishing multiple signals that are spatially correlated or have small angular separation. More importantly, our solution operates with a single snapshot signal, which is incompatible with other existing deep learning-based methods.

Paper number 7:
Title: Efficient Image Denoising Using Global and Local Circulant Representation
Authors: Zhaoming Kong, Jiahuan Zhang, Xiaowei Yang
Abstract: The advancement of imaging devices and countless image data generated everyday impose an increasingly high demand on efficient and effective image denoising. In this paper, we present a computationally simple denoising algorithm, termed Haar-tSVD, aiming to explore the nonlocal self-similarity prior and leverage the connection between principal component analysis (PCA) and the Haar transform under circulant representation. We show that global and local patch correlations can be effectively captured through a unified tensor-singular value decomposition (t-SVD) projection with the Haar transform. This results in a one-step, highly parallelizable filtering method that eliminates the need for learning local bases to represent image patches, striking a balance between denoising speed and performance. Furthermore, we introduce an adaptive noise estimation scheme based on a CNN estimator and eigenvalue analysis to enhance the robustness and adaptability of the proposed method. Experiments on different real-world denoising tasks validate the efficiency and effectiveness of Haar-tSVD for noise removal and detail preservation. Datasets, code and results are publicly available at this https URL.

Paper number 8:
Title: Cross-view Generalized Diffusion Model for Sparse-view CT Reconstruction
Authors: Jixiang Chen, Yiqun Lin, Yi Qin, Hualiang Wang, Xiaomeng Li
Abstract: Sparse-view computed tomography (CT) reduces radiation exposure by subsampling projection views, but conventional reconstruction methods produce severe streak artifacts with undersampled data. While deep-learning-based methods enable single-step artifact suppression, they often produce over-smoothed results under significant sparsity. Though diffusion models improve reconstruction via iterative refinement and generative priors, they require hundreds of sampling steps and struggle with stability in highly sparse regimes. To tackle these concerns, we present the Cross-view Generalized Diffusion Model (CvG-Diff), which reformulates sparse-view CT reconstruction as a generalized diffusion process. Unlike existing diffusion approaches that rely on stochastic Gaussian degradation, CvG-Diff explicitly models image-domain artifacts caused by angular subsampling as a deterministic degradation operator, leveraging correlations across sparse-view CT at different sample rates. To address the inherent artifact propagation and inefficiency of sequential sampling in generalized diffusion model, we introduce two innovations: Error-Propagating Composite Training (EPCT), which facilitates identifying error-prone regions and suppresses propagated artifacts, and Semantic-Prioritized Dual-Phase Sampling (SPDPS), an adaptive strategy that prioritizes semantic correctness before detail refinement. Together, these innovations enable CvG-Diff to achieve high-quality reconstructions with minimal iterations, achieving 38.34 dB PSNR and 0.9518 SSIM for 18-view CT using only \textbf{10} steps on AAPM-LDCT dataset. Extensive experiments demonstrate the superiority of CvG-Diff over state-of-the-art sparse-view CT reconstruction methods. The code is available at this https URL.

Paper number 9:
Title: Quantifying the Value of Seismic Structural Health Monitoring for post-earthquake recovery of electric power system in terms of resilience enhancement
Authors: Huangbin Liang, Beatriz Moya, Francisco Chinesta, Eleni Chatzi
Abstract: Post-earthquake recovery of electric power networks (EPNs) is critical to community resilience. Traditional recovery processes often rely on prolonged and imprecise manual inspections for damage diagnosis, leading to suboptimal repair prioritization and extended service disruptions. Seismic Structural Health Monitoring (SSHM) offers the potential to expedite recovery by enabling more accurate and timely damage assessment. However, SSHM deployment incurs costs, and its system-level resilience benefit remains underexplored. This study proposes a probabilistic simulation framework to quantify the value of SSHM for enhancing EPN resilience. The framework includes seismic damage modeling based on network configuration, hazard intensity, fragility functions, and damage-functionality mappings, combined with recovery simulations incorporating resource constraints, repair and transfer durations. System functionality is evaluated using graph-based island detection and optimal power flow analysis. Resilience is quantified via the Lack of Resilience (LoR) metric derived from the functionality restoration curve. SSHM is incorporated by altering the quality of damage information used in repair scheduling. Different monitoring scenarios (e.g., no-SSHM baseline, partial SSHM, full SSHM with various accuracies) are modeled using confusion matrices to simulate damage misclassification. Results show that improved damage awareness via SSHM significantly accelerates recovery and reduces LoR by up to 21%. This work supports evidence-based decisions for SSHM deployment in critical infrastructure.

Paper number 10:
Title: Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech
Authors: Abhijit Sinha, Harishankar Kumar, Mohit Joshi, Hemant Kumar Kathania, Shrikanth Narayanan, Sudarsana Reddy Kadiri
Abstract: Children's speech presents challenges for age and gender classification due to high variability in pitch, articulation, and developmental traits. While self-supervised learning (SSL) models perform well on adult speech tasks, their ability to encode speaker traits in children remains underexplored. This paper presents a detailed layer-wise analysis of four Wav2Vec2 variants using the PFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture speaker-specific cues more effectively than deeper layers, which increasingly focus on linguistic information. Applying PCA further improves classification, reducing redundancy and highlighting the most informative components. The Wav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU Kids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These results reveal how speaker traits are structured across SSL model depth and support more targeted, adaptive strategies for child-aware speech interfaces.

Paper number 11:
Title: Environment Reconstruction in Terahertz Monostatic Sensing: Joint Millimeter-level Geometry Mapping and Material Identification
Authors: Zitong Fang, Yejian Lyu, Ziming Yu, Chong Han
Abstract: Terahertz (THz) integrated sensing and communication (ISAC) offers high-speed communication alongside precise environmental sensing. This paper presents a computationally efficient framework for THz-based environment reconstruction by integrating connected component analysis (CCA)-assisted multipath component (MPC) estimation with a sliding-window refinement strategy. To start with, a monostatic sensing experiment is conducted in an indoor scenario using a vector network analyzer (VNA)-based sounder operating from 290 to 310 GHz. On one hand, as for geometry mapping, a CCA-based region search is employed to accelerate parameter extraction, significantly reducing the search space for space-alternating generalized expectation-maximization (SAGE)-based estimation and achieving an 8.4 times acceleration, while preserving resolution. Further analysis of the connected component structure enables the identification of indoor features such as flat walls and corners. A sliding-window refinement applied to the identified regions improves geometric mapping, achieving the mean distance error of 4.9 mm, which is one order of magnitude better than the literature. On the other hand, the deterministic and stochastic components of the monostatic channel are classified through reflection loss analysis. Then, material identification is performed by looking up the reflection loss in a THz time-domain spectroscopy (THz-TDS) database, which comprises over 200 materials across a 0-6 THz range. Experimental results validate millimeter-level accuracy in geometry mapping and reliable material classification, enhancing the environmental awareness capabilities of THz ISAC systems.

Paper number 12:
Title: Towards Frame-level Quality Predictions of Synthetic Speech
Authors: Michael Kuhlmann, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach
Abstract: While automatic subjective speech quality assessment has witnessed much progress, an open question is whether an automatic quality assessment at frame resolution is possible. This would be highly desirable, as it adds explainability to the assessment of speech synthesis systems. Here, we take first steps towards this goal by identifying issues of existing quality predictors that prevent sensible frame-level prediction. Further, we define criteria that a frame-level predictor should fulfill. We also suggest a chunk-based processing that avoids the impact of a localized distortion on the score of neighboring frames. Finally, we measure in experiments with localized artificial distortions the localization performance of a set of frame-level quality predictors and show that they can outperform detection performance of human annotations obtained from a crowd-sourced perception experiment.

Paper number 13:
Title: Interleaved Transceiver Design for a Continuous- Transmission MIMO-OFDM ISAC System
Authors: Yating Chen, Cai Wen, Yan Huang, Jinye Peng, Wei Hong, Timothy N. Davidson
Abstract: This paper proposes an interleaved transceiver design method for a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system utilizing orthogonal frequency division multiplexing (OFDM) waveforms. We consider a continuous transmission system and focus on the design of the transmission signal and a receiving filter in the time domain for an interleaved transmission architecture. For communication performance, constructive interference (CI) is integrated into the optimization problem. For radar sensing performance, the integrated mainlobe-to-sidelobe ratio (IMSR) of the beampattern is considered to ensure desirable directivity. Additionally, we tackle the challenges of inter-block interference and eliminate the spurious peaks, which are crucial for accurate target detection. Regarding the hardware implementation aspect, the power of each time sample is constrained to manage the peak-to-average power ratio (PAPR). The design problem is addressed using an alternating optimization (AO) framework, with the subproblem for transmitted waveform design being solved via the successive convex approximation (SCA) method. To further enhance computational efficiency, the alternate direction penalty method (ADPM) is employed to solve the subproblems within the SCA iterations. The convergence of ADPM is established, with convergence of the case of more than two auxiliary variables being established for the first time. Numerical simulations validate the effectiveness of our transceiver design in achieving desirable performance in both radar sensing and communication, with the fast algorithm achieving comparable performance with greater computational efficiency.

Paper number 14:
Title: A Structured Framework for Prioritizing Unsafe Control Actions in STPA: Case Study on eVTOL Operations
Authors: Halima El Badaoui
Abstract: Systems Theoretic Process Analysis (STPA) is a widely recommended method for analysing complex system safety. STPA can identify numerous Unsafe Control Actions (UCAs) and requirements depending on the level of granularity of the analysis and the complexity of the system being analysed. Managing numerous results is challenging, especially during a fast-paced development lifecycle. Extensive research has been done to optimize the efficiency of managing and prioritising the STPA results. However, maintaining the objectivity of prioritisation and communicating the prioritised results have become common challenges. In this paper, the authors present a complementary approach that incorporates inputs from both the safety analysts and domain experts to more objectively prioritise UCAs. This is done by evaluating the severity of each UCA, the impact factor of each controller or decision maker that issues the UCA, and the ranking provided by the subject matter experts who assess the UCA criticalities based on different factors. In addition, a Monte Carlo simulation is introduced to reduce subjectivity and relativity, thus enabling more objective prioritisation of the UCAs. As part of the approach to better communicate the prioritisation results and plan the next steps of system development, a dynamic-scaling prioritisation matrix was developed to capture different sets of prioritised UCAs. The approach was applied to a real project to improve the safe operations of Electric Vertical Take-off and Landing (eVTOL). The results highlighted critical UCAs that need to be prioritised for safer eVTOL operation. 318 UCAs were identified in total. Based on the application of the prioritisation methodology, 110 were recognized as high-priority UCAs to strengthen the system design.

Paper number 15:
Title: Exploring Cross-Utterance Speech Contexts for Conformer-Transducer Speech Recognition Systems
Authors: Mingyu Cui, Mengzhe Geng, Jiajun Deng, Chengxi Deng, Jiawen Kang, Shujie Hu, Guinan Li, Tianzi Wang, Zhaoqing Li, Xie Chen, Xunying Liu
Abstract: This paper investigates four types of cross-utterance speech contexts modeling approaches for streaming and non-streaming Conformer-Transformer (C-T) ASR systems: i) input audio feature concatenation; ii) cross-utterance Encoder embedding concatenation; iii) cross-utterance Encoder embedding pooling projection; or iv) a novel chunk-based approach applied to C-T models for the first time. An efficient batch-training scheme is proposed for contextual C-Ts that uses spliced speech utterances within each minibatch to minimize the synchronization overhead while preserving the sequential order of cross-utterance speech contexts. Experiments are conducted on four benchmark speech datasets across three languages: the English GigaSpeech and Mandarin Wenetspeech corpora used in contextual C-T models pre-training; and the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets used in domain fine-tuning. The best performing contextual C-T systems consistently outperform their respective baselines using no cross-utterance speech contexts in pre-training and fine-tuning stages with statistically significant average word error rate (WER) or character error rate (CER) reductions up to 0.9%, 1.1%, 0.51%, and 0.98% absolute (6.0%, 5.4%, 2.0%, and 3.4% relative) on the four tasks respectively. Their performance competitiveness against Wav2vec2.0-Conformer, XLSR-128, and Whisper models highlights the potential benefit of incorporating cross-utterance speech contexts into current speech foundation models.

Paper number 16:
Title: Second Order Channel Statistics: An Analysis for Optimal Single-user RIS Systems
Authors: Amy S. Inwood, Peter J. Smith, Philippa A. Martin, Graeme K. Woodward
Abstract: A key challenge facing reconfigurable intelligent surfaces (RISs) is channel state information acquisition. Passive RISs cannot generate pilot signals or process data, making rapid temporal changes in the channel problematic. Additionally, the impact of spatial changes in RIS channels has not been thoroughly investigated. Therefore, in this work, we use second order statistics to investigate the spatio-temporal behaviour of a single-user (SU) RIS system. Assuming a line-of-sight (LoS) RIS to base station (BS) link, we derive an exact expression for the level crossing rate (LCR) of the RIS link (user equipment (UE)-RIS-BS path) and propose a numerically stable approximation for the LCR of the global UE-BS channel. Each LCR expression attained is then utilised to find the corresponding average fade duration (AFD). The temporal signal-to-noise ratio (SNR) correlation is also derived assuming an LoS RIS-BS link. Assuming a Ricean RIS-BS link, expressions for the spatial correlation matrix of the global channel and the mean SNR loss due to channel ageing are derived. All of the analyses are verified by simulation, and the impact of key system parameters is investigated. We show that the use of an RIS does not significantly amplify changes in the channel.

Paper number 17:
Title: High SNR Probabilities of Continuous Fluid Antenna Systems in Ricean Environments
Authors: Amy S. Inwood, Peter J. Smith, Rajitha Senanayake, Michail Matthaiou
Abstract: We consider a single-user (SU) continuous fluid antenna system (CFAS) employing matched filtering (MF) operating over a Ricean fading channel. Focusing on the upper tail of the received signal-to-noise ratio (SNR) distribution (the high SNR probability (HSP)), we derive accurate approximations for the HSP in 1, 2, and 3 dimensions using the expected Euler characteristic (EEC), presenting the first analytical results for a CFAS in a Ricean environment. In the process, we provide the first closed-form expression for the Euler characteristic density of a non-central chi-squared random field. We then examine the impact of the Ricean K-factor on the CFAS performance, emphasizing the critical role of channel variations in achieving a strong HSP.

Paper number 18:
Title: Inverse Synthetic Aperture Radar, Radar Cross Section, and Iterative Smooth Reweighting $\ell_1$-minimization
Authors: Christer Larsson
Abstract: Radar Cross Section measurement data is often analyzed using Inverse Synthetic Aperture Radar images. This paper compares backprojection and iterative smooth reweighted $\ell_1$-minimization as methods to analyze radar cross section measurements and extract radar cross section for parts of the measured object. The main conclusion is that using backprojection images to extract RCS is robust and accurate but is more limited by the resolution than iterative smooth reweighted $\ell_1$-minimization. The latter method can be used for closely spaced scatterers but is limited in accuracy.

Paper number 19:
Title: Unsupervised Deep Equilibrium Model Learning for Large-Scale Channel Estimation with Performance Guarantees
Authors: Haotian Tian, Lixiang Lian
Abstract: Supervised deep learning methods have shown promise for large-scale channel estimation (LCE), but their reliance on ground-truth channel labels greatly limits their practicality in real-world systems. In this paper, we propose an unsupervised learning framework for LCE that does not require ground-truth channels. The proposed approach leverages Generalized Stein's Unbiased Risk Estimate (GSURE) as a principled unsupervised loss function, which provides an unbiased estimate of the projected mean-squared error (PMSE) from compressed noisy measurements. To ensure a guaranteed performance, we integrate a deep equilibrium (DEQ) model, which implicitly represents an infinite-depth network by directly learning the fixed point of a parameterized iterative process. We theoretically prove that, under mild conditions, the proposed GSURE-based unsupervised DEQ learning can achieve oracle-level supervised performance. In particular, we show that the DEQ architecture inherently enforces a compressible solution. We then demonstrate that DEQ-induced compressibility ensures that optimizing the projected error via GSURE suffices to guarantee a good MSE performance, enabling a rigorous performance guarantee. Extensive simulations validate the theoretical findings and demonstrate that the proposed framework significantly outperforms various baselines when ground-truth channel is unavailable.

Paper number 20:
Title: Compressive Spectral Imaging in View of Earth Observation Applications
Authors: ClÃ©ment Thomas, Laurent Jacques, Marc Georges
Abstract: Earth observation from space is an important scientific and industrial activity that has applications in many sectors. The instruments employed are often large, complex, and expensive. In addition, they generate large amounts of data, which is challenging for storage and transfer purposes. Compressive spectral imaging would be a cheaper, more efficient, and well-adapted technique to perform Earth observation. An interesting architecture is compressive spectral imaging with diffractive lenses, which is extremely compact. This work investigates the possibility of replacing the diffractive lens in this system with a classical refractive lens. Taking advantage of the chromatic aberration of a lens makes the use of expensive diffractive lenses unnecessary. Simulations are performed to test the feasibility of the method. Signal recovery is a basis pursuit solved using the Douglas-Rashford algorithm.

Paper number 21:
Title: Feedback stabilization of a nanoparticle at the intensity minimum of an optical double-well potential
Authors: VojtÄch MlynÃ¡Å (1), SalambÃ´ Dago (2), Jakob Rieser (2), Mario A. Ciampini (2), Markus Aspelmeyer (2 and 3), Nikolai Kiesel (2), Andreas Kugi (1 and 4), Andreas Deutschmann-Olek (1) ((1) Automation and Control Institute, TU Wien, Vienna, Austria, (2) University of Vienna, Faculty of Physics, Vienna Center for Quantum Science and Technology, Vienna, Austria, (3) Institute for Quantum Optics and Quantum Information Vienna, Austrian Academy of Sciences, Vienna, Austria, (4) AIT Austrian Institute of Technology, Vienna, Austria)
Abstract: In this work, we develop and analyze adaptive feedback control strategies to stabilize and confine a nanoparticle at the unstable intensity minimum of an optical double-well potential. The resulting stochastic optimal control problem for a noise-driven mechanical particle in a nonlinear optical potential must account for unavoidable experimental imperfections such as measurement nonlinearities and slow drifts of the optical setup. To address these issues, we simplify the model in the vicinity of the unstable equilibrium and employ indirect adaptive control techniques to dynamically follow changes in the potential landscape. Our approach leads to a simple and efficient Linear Quadratic Gaussian (LQG) controller that can be implemented on fast and cost-effective FPGAs, ensuring accessibility and reproducibility. We demonstrate that this strategy successfully tracks the intensity minimum and significantly reduces the nanoparticle's residual state variance, effectively lowering its center-of-mass temperature. While conventional optical traps rely on confining optical forces in the light field at the intensity maxima, trapping at intensity minima mitigates absorption heating, which is crucial for advanced quantum experiments. Since LQG control naturally extends into the quantum regime, our results provide a promising pathway for future experiments on quantum state preparation beyond the current absorption heating limitation, like matter-wave interference and tests of the quantum-gravity interface.

Paper number 22:
Title: DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality
Authors: Xinyi Wang, Angeliki Katsenou, David Bull
Abstract: The rapid growth of user-generated (video) content (UGC) has driven increased demand for research on no-reference (NR) perceptual video quality assessment (VQA). NR-VQA is a key component for large-scale video quality monitoring in social media and streaming applications where a pristine reference is not available. This paper proposes a novel NR-VQA model based on spatio-temporal fragmentation driven by inter-frame variations. By leveraging these inter-frame differences, the model progressively analyses quality-sensitive regions at multiple levels: frames, patches, and fragmented frames. It integrates frames, fragmented residuals, and fragmented frames aligned with residuals to effectively capture global and local information. The model extracts both 2D and 3D features in order to characterize these spatio-temporal variations. Experiments conducted on five UGC datasets and against state-of-the-art models ranked our proposed method among the top 2 in terms of average rank correlation (DIVA-VQA-L: 0.898 and DIVA-VQA-B: 0.886). The improved performance is offered at a low runtime complexity, with DIVA-VQA-B ranked top and DIVA-VQA-L third on average compared to the fastest existing NR-VQA method. Code and models are publicly available at: this https URL.

Paper number 23:
Title: A Robust Optimization Approach for Demand Response Participation of Fixed-Frequency Air Conditioners
Authors: Jinhua He, Tingzhe Pan, Chao Li, Xin Jin, Zijie Meng, Wei Zhou
Abstract: With the continuous increase in the penetration of renewable energy in the emerging power systems, the pressure on system peak regulation has been significantly intensified. Against this backdrop, demand side resources particularly air conditioning loads have garnered considerable attention for their substantial regulation potential and fast response capabilities, making them promising candidates for providing auxiliary peak shaving services. This study focuses on fixed frequency air conditioners (FFACs) and proposes an optimization model and solution method for their participation in demand response (DR) programs. First, a probabilistic response model for FFACs is developed based on the Markov assumption. Second, by sampling this probabilistic model, the aggregate power consumption of an FFAC cluster under decentralized control is obtained. Subsequently, a robust optimization model is formulated to maximize the profit of an aggregator managing the FFAC cluster during DR events, taking into account the aggregated response power. The model explicitly considers temperature uncertainty to ensure user comfort in a robust sense. Finally, leveraging the structure of the proposed model, it is reformulated as a mixed-integer linear programming (MILP) problem and solved using a commercial optimization solver. Simulation results validate the effectiveness of the proposed model and solution approach.

Paper number 24:
Title: Towards Hybrid Lunar PNT: Error Models, Lower Bounds and Algorithms
Authors: Robert PÃ¶hlmann, Emanuel Staudinger, Gonzalo Seco-Granados
Abstract: Accurate positioning, navigation and timing (PNT) are crucial for upcoming lunar surface missions. Lunar satellite navigation systems are being developed, but lack coverage during early deployment phases. Hybrid lunar PNT combining cooperative navigation, satellite systems, and an optional reference station offers improved accuracy and availability. This study develops realistic error models that incorporate temporal correlations often ignored in existing works. We derive a cooperative navigation error model considering fading and pseudorange bias from multipath propagation, and compare three error models for lunar satellite pseudorange and pseudorange rate signal-in-space error. These temporal error correlation models integrate easily into Kalman filters and provide realistic performance predictions essential for robust navigation engines. We perform case studies to demonstrate that hybrid navigation significantly improves accuracy, particularly with static users present. Most notably, hybrid navigation enables optimal performance when using a lunar reference station, achieving sub-meter accuracy with only two visible satellites.

Paper number 25:
Title: Probabilistic Forecasting Method for Offshore Wind Farm Cluster under Typhoon Conditions: a Score-Based Conditional Diffusion Model
Authors: Jinhua He, Zechun Hu
Abstract: Offshore wind power (OWP) exhibits significant fluctuations under typhoon conditions, posing substantial challenges to the secure operation of power systems. Accurate forecasting of OWP is therefore essential. However, the inherent scarcity of historical typhoon data and stochasticity of OWP render traditional point forecasting methods particularly difficult and inadequate. To address this challenge and provide grid operators with the comprehensive information necessary for decision-making, this study proposes a score-based conditional diffusion model (SCDM) for probabilistic forecasting of OWP during typhoon events. First, a knowledge graph algorithm is employed to embed historical typhoon paths as vectors. Then, a deterministic network is constructed to predict the wind power under typhoon conditions based on these vector embeddings. Finally, to better characterize prediction errors, a denoising network is developed. At the core of this approach is a mean-reverting stochastic differential equation (SDE), which transforms complex error distributions into a standard Gaussian, enabling the sampling of forecasting errors using a reverse-time SDE. The probabilistic forecasting results are reconstructed by combining deterministic forecasts with sampled errors. The proposed method is evaluated using real-world data from a cluster of 9 offshore wind farms. Results demonstrate that under typhoon conditions, our approach outperforms baseline models for both deterministic and probabilistic metrics, verifying the effectiveness of the approach.

Paper number 26:
Title: Multi-Functional Polarization-Based Coverage Control through Static Passive EMSs
Authors: Giacomo Oliveri, Francesco Zardi, Aaron Angel Salas Sanchez, Andrea Massa
Abstract: An innovative multi-functional static-passive electromagnetic skin (SP-EMS) solution is proposed to simultaneously support, in reflection, two independent wave-manipulation functionalities with a single meta-atoms arrangement on the EMS aperture when illuminated by two EM sources operating at the same frequency, but working in different polarization states. Towards this end, a simple reference meta-atom is designed first to enable an accurate and independent control of each polarization component of the local reflection tensor. Successively, the macro-scale synthesis of multi-polarization (MP) SP-EMSs (MP-SP-EMSs) is carried out by solving a global optimization problem where a cost function, which mathematically codes separate requirements for each polarization, is minimized with a customized version of the system-by-design (SbD) technique. Representative results from a set of numerical and experimental tests are reported to assess the feasibility of a multi-function EMS based on polarization diversity as well as the effectiveness and the robustness of the proposed method for the synthesis of MP-SP-EMSs.

Paper number 27:
Title: Affine Frequency Division Multiplexing with Subcarrier Power-Level Index Modulation for Integrated Sensing and Communications
Authors: Murat Temiz, Christos Masouros
Abstract: This study proposes an index modulation (IM) technique for affine frequency division multiplexing (AFDM) signals and examines its communication and sensing performance toward integrated sensing and communication (ISAC) systems. The power levels of subcarriers are utilized as modulation indices while also transmitting data symbols within each subcarrier. Thus, the proposed AFDM with subcarrier power-level index modulation (AFDM-PLIM) maintains all subcarriers active at all times to achieve a higher spectral efficiency compared to other AFDM-IM techniques, where some of the subcarriers are turned off for IM. A low complexity estimator and subcarrier grouping are also proposed to reduce the computational complexity of the maximum likelihood estimator. Furthermore, this study also examines the delay and Doppler ambiguity functions of the proposed AFDM-PLIM and evaluates its range estimation performance. The results show that its sensing performance is better than AFDM-IM waveforms due to keeping all subcarriers active at all times.

Paper number 28:
Title: When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images
Authors: M. Geshvadi, G. So, D.D. Chlorogiannis, C. Galvin, E. Torio, A. Azimi, Y. Tachie-Baffour, N. Haouchine, A. Golby, M. Vangel, W.M. Wells, Y. Epelboym, R. Du, F. Durupinar, S. Frisken
Abstract: We analyze the variability among segmentations of cranial blood vessels in 2D DSA performed by multiple annotators in order to characterize and quantify segmentation uncertainty. We use this analysis to quantify segmentation uncertainty and discuss ways it can be used to guide additional annotations and to develop uncertainty-aware automatic segmentation methods.

Paper number 29:
Title: Reduction of motion artifacts from photoplethysmography signals using learned convolutional sparse coding
Authors: Giulio Basso, Xi Long, Reinder Haakma, Rik Vullings
Abstract: Objective. Wearable devices with embedded photoplethysmography (PPG) enable continuous non-invasive monitoring of cardiac activity, offering a promising strategy to reduce the global burden of cardiovascular diseases. However, monitoring during daily life introduces motion artifacts that can compromise the signals. Traditional signal decomposition techniques often fail with severe artifacts. Deep learning denoisers are more effective but have poorer interpretability, which is critical for clinical acceptance. This study proposes a framework that combines the advantages of both signal decomposition and deep learning approaches. Approach. We leverage algorithm unfolding to integrate prior knowledge about the PPG structure into a deep neural network, improving its interpretability. A learned convolutional sparse coding model encodes the signal into a sparse representation using a learned dictionary of kernels that capture recurrent morphological patterns. The network is trained for denoising using the PulseDB dataset and a synthetic motion artifact model from the literature. Performance is benchmarked with PPG during daily activities using the PPG-DaLiA dataset and compared with two reference deep learning methods. Main results. On the synthetic dataset, the proposed method, on average, improved the signal-to-noise ratio (SNR) from -7.07 dB to 11.23 dB and reduced the heart rate mean absolute error (MAE) by 55%. On the PPG-DaLiA dataset, the MAE decreased by 23%. The proposed method obtained higher SNR and comparable MAE to the reference methods. Significance. Our method effectively enhances the quality of PPG signals from wearable devices and enables the extraction of meaningful waveform features, which may inspire innovative tools for monitoring cardiovascular diseases.

Paper number 30:
Title: Fluid Antenna Enabled Direction-of-Arrival Estimation Under Time-Constrained Mobility
Authors: He Xu, Tuo Wu, Ye Tian, Kangda Zhi, Wei Liu, Baiyang Liu, Hing Cheung So, Naofal Al-Dhahir, Kin-Fai Tong, Chan-Byoung Chae, Kai-Kit Wong
Abstract: Fluid antenna (FA) technology has emerged as a promising approach in wireless communications due to its capability of providing increased degrees of freedom (DoFs) and exceptional design flexibility. This paper addresses the challenge of direction-of-arrival (DOA) estimation for aligned received signals (ARS) and non-aligned received signals (NARS) by designing two specialized uniform FA structures under time-constrained mobility. For ARS scenarios, we propose a fully movable antenna configuration that maximizes the virtual array aperture, whereas for NARS scenarios, we design a structure incorporating a fixed reference antenna to reliably extract phase information from the signal covariance. To overcome the limitations of large virtual arrays and limited sample data inherent in time-varying channels (TVC), we introduce two novel DOA estimation methods: TMRLS-MUSIC for ARS, combining Toeplitz matrix reconstruction (TMR) with linear shrinkage (LS) estimation, and TMR-MUSIC for NARS, utilizing sub-covariance matrices to construct virtual array responses. Both methods employ Nystrom approximation to significantly reduce computational complexity while maintaining estimation accuracy. Theoretical analyses and extensive simulation results demonstrate that the proposed methods achieve underdetermined DOA estimation using minimal FA elements, outperform conventional methods in estimation accuracy, and substantially reduce computational complexity.

Paper number 31:
Title: The Future is Fluid: Revolutionizing DOA Estimation with Sparse Fluid Antennas
Authors: He Xu, Tuo Wu, Ye Tian, Ming Jin, Wei Liu, Qinghua Guo, Maged Elkashlan, Matthew C. Valenti, Chan-Byoung Chae, Kin-Fai Tong, Kai-Kit Wong
Abstract: This paper investigates a design framework for sparse fluid antenna systems (FAS) enabling high-performance direction-of-arrival (DOA) estimation, particularly in challenging millimeter-wave (mmWave) environments. By ingeniously harnessing the mobility of fluid antenna (FA) elements, the proposed architectures achieve an extended range of spatial degrees of freedom (DoF) compared to conventional fixed-position antenna (FPA) arrays. This innovation not only facilitates the seamless application of super-resolution DOA estimators but also enables robust DOA estimation, accurately localizing more sources than the number of physical antenna elements. We introduce two bespoke FA array structures and mobility strategies tailored to scenarios with aligned and misaligned received signals, respectively, demonstrating a hardware-driven approach to overcoming complexities typically addressed by intricate algorithms. A key contribution is a light-of-sight (LoS)-centric, closed-form DOA estimator, which first employs an eigenvalue-ratio test for precise LoS path number detection, followed by a polynomial root-finding procedure. This method distinctly showcases the unique advantages of FAS by simplifying the estimation process while enhancing accuracy. Numerical results compellingly verify that the proposed FA array designs and estimation techniques yield an extended DoF range, deliver superior DOA accuracy, and maintain robustness across diverse signal conditions.

Paper number 32:
Title: Scalable FAS: A New Paradigm for Array Signal Processing
Authors: Tuo Wu, Ye Tian, Jie Tang, Kangda Zhi, Maged Elkashlan, Kin-Fai Tong, Naofal Al-Dhahir, Chan-Byoung Chae, Matthew C. Valenti, George K. Karagiannidis, Kwai-Man Luk
Abstract: Most existing antenna array-based source localization methods rely on fixed-position arrays (FPAs) and strict assumptions about source field conditions (near-field or far-field), which limits their effectiveness in complex, dynamic real-world scenarios where high-precision localization is required. In contrast, this paper introduces a novel scalable fluid antenna system (SFAS) that can dynamically adjust its aperture configuration to optimize performance for different localization tasks. Within this framework, we develop a two-stage source localization strategy based on the exact spatial geometry (ESG) model: the first stage uses a compact aperture configuration for initial direction-of-arrival (DOA) estimation, while the second stage employs an expanded aperture for enhanced DOA and range estimation. The proposed approach eliminates the traditional need for signal separation or isolation to classify source types and enables a single SFAS array to achieve high localization accuracy without field-specific assumptions, model simplifications, or approximations, representing a new paradigm in array-based source localization. Extensive simulations demonstrate the superiority of the proposed method in terms of localization accuracy, computational efficiency, and robustness to different source types.

Paper number 33:
Title: Integrating Terrestrial and Non-Terrestrial Networks for Sustainable 6G Operations: A Latency-Aware Multi-Tier Cell-Switching Approach
Authors: Metin Ozturk, Maryam Salamatmoghadasi, Halim Yanikomeroglu
Abstract: Sustainability is paramount in modern cellular networks, which face significant energy consumption challenges from rising mobile traffic and advancements in wireless technology. Cell-switching, well-established in literature as an effective solution, encounters limitations such as inadequate capacity and limited coverage when implemented through terrestrial networks (TN). This study enhances cell-switching by integrating non-terrestrial networks (NTN), including satellites (used for cell-switching for the first time), high altitude platform stations (HAPS), and uncrewed aerial vehicles (UAVs) into TN. This integration significantly boosts energy savings by expanding capacity, enhancing coverage, and increasing operational flexibility. We introduce a multi-tier cell-switching approach that dynamically offloads users across network layers to manage energy effectively and minimize delays, accommodating diverse user demands with a context aware strategy. Additionally, we explore the role of artificial intelligence (AI), particularly generative AI, in optimizing network efficiency through data compression, handover optimization between different network layers, and enhancing device compatibility, further improving the adaptability and energy efficiency of cell-switching operations. A case study confirms substantial improvements in network power consumption and user satisfaction, demonstrating the potential of our approach for future networks.

Paper number 34:
Title: Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC
Authors: Bastian Heinlein, Kaikai Zhu, SÃ¼meyye Carkit-Yilmaz, Sebastian Lotter, Helene M. Loos, Andrea Buettner, Yansha Deng, Robert Schober, Vahid Jamali
Abstract: Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by existing sensor technologies such as metal-oxide semi-conductor (MOS) sensors. However, commercially available sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumptions about linear and perfectly molecule type-specific sensing often made in the MC literature. To address this gap, we propose a detector for molecule mixture communication with a general non-linear, cross-reactive receiver (RX) array that performs approximate maximum likelihood detection on the sensor outputs. Additionally, we introduce an algorithm for the design of mixture alphabets that accounts for the RX characteristics. We evaluate our detector and alphabet design algorithm through simulations that are based on measurements reported for two commercial MOS sensors. Our simulations demonstrate that the proposed detector achieves similar symbol error rates as data-driven methods without requiring large numbers of training samples and that the alphabet design algorithm outperforms methods that do not account for the RX characteristics. Since the proposed detector and alphabet design algorithm are also applicable to other chemical sensors, they pave the way for reliable air-based MC.

Paper number 35:
Title: Fuel Consumption in Platoons: A Literature Review
Authors: Oumaima Barhoumi, Ghazal Farhani, Taufiq Rahman, Mohamed H. Zaki, SofiÃ¨ne Tahar, Fadi Araji
Abstract: Platooning has emerged as a promising strategy for improving fuel efficiency in automated vehicle systems, with significant implications for reducing emissions and operational costs. While existing literature on vehicle platooning primarily focuses on individual aspects such as aerodynamic drag reduction or specific control strategies, this work takes a more comprehensive approach by bringing together a wide range of factors and components that contribute to fuel savings in platoons. In this literature review, we examine the impact of platooning on fuel consumption, highlighting the key components of platoon systems, the factors and actors influencing fuel savings, methods for estimating fuel use, and the effect of platoon instability on efficiency. Furthermore, we study the role of reduced aerodynamic drag, vehicle coordination, and the challenges posed by instability in real-world conditions. By compiling insights from recent studies, this work provides a comprehensive overview of the latest advancements in platooning technologies and highlights both the challenges and opportunities for future research to maximize fuel savings in real-world scenarios.

Paper number 36:
Title: Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression
Authors: Zheng Jie Wong, Bingquan Shen
Abstract: Currently, Automatic Speech Recognition (ASR) models are deployed in an extensive range of applications. However, recent studies have demonstrated the possibility of adversarial attack on these models which could potentially suppress or disrupt model output. We investigate and verify the robustness of these attacks and explore if it is possible to increase their imperceptibility. We additionally find that by relaxing the optimisation objective from complete suppression to partial suppression, we can further decrease the imperceptibility of the attack. We also explore possible defences against these attacks and show a low-pass filter defence could potentially serve as an effective defence.

Paper number 37:
Title: Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts
Authors: Hojun Jin, Eunsoo Hong, Ziwon Hyung, Sungjun Lim, Seungjin Lee, Keunseok Cho
Abstract: Hard-parameter sharing is a common strategy to train a single model jointly across diverse tasks. However, this often leads to task interference, impeding overall model performance. To address the issue, we propose a simple yet effective Supervised Mixture of Experts (S-MoE). Unlike traditional Mixture of Experts models, S-MoE eliminates the need for training gating functions by utilizing special guiding tokens to route each task to its designated expert. By assigning each task to a separate feedforward network, S-MoE overcomes the limitations of hard-parameter sharing. We further apply S-MoE to a speech-to-text model, enabling the model to process mixed-bandwidth input while jointly performing automatic speech recognition (ASR) and speech translation (ST). Experimental results demonstrate the effectiveness of the proposed S-MoE, achieving a 6.35% relative improvement in Word Error Rate (WER) when applied to both the encoder and decoder.

Paper number 38:
Title: Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems
Authors: Varsha Sen, Biswash Basnet
Abstract: False Data Injection Attacks (FDIAs) pose a significant threat to smart grid infrastructures, particularly Home Area Networks (HANs), where real-time monitoring and control are highly adopted. Owing to the comparatively less stringent security controls and widespread availability of HANs, attackers view them as an attractive entry point to manipulate aggregated demand patterns, which can ultimately propagate and disrupt broader grid operations. These attacks undermine the integrity of smart meter data, enabling malicious actors to manipulate consumption values without activating conventional alarms, thereby creating serious vulnerabilities across both residential and utility-scale infrastructures. This paper presents a machine learning-based framework for both the detection and classification of FDIAs using residential energy data. A real-time detection is provided by the lightweight Artificial Neural Network (ANN), which works by using the most vital features of energy consumption, cost, and time context. For the classification of different attack types, a Bidirectional LSTM is trained to recognize normal, trapezoidal, and sigmoid attack shapes through learning sequential dependencies in the data. A synthetic time-series dataset was generated to emulate realistic household behaviour. Experimental results demonstrate that the proposed models are effective in identifying and classifying FDIAs, offering a scalable solution for enhancing grid resilience at the edge. This work contributes toward building intelligent, data-driven defence mechanisms that strengthen smart grid cybersecurity from residential endpoints.

Paper number 39:
Title: Distributional Robustness in Output Feedback Regret-Optimal Control
Authors: Shuhao Yan, Carsten W. Scherer
Abstract: This paper studies distributionally robust regret-optimal (DRRO) control with purified output feedback for linear systems subject to additive disturbances and measurement noise. These uncertainties (including the initial system state) are assumed to be stochastic and distributed according to an unknown joint probability distribution within a Wasserstein ambiguity set. We design affine controllers to minimise the worst-case expected regret over all distributions in this set. The expected regret is defined as the difference between an expected cost incurred by an affine causal controller and the expected cost incurred by the optimal noncausal controller with perfect knowledge of the disturbance trajectory at the outset. Leveraging the duality theory in distributionally robust optimisation, we derive strong duality results for worst-case expectation problems involving general quadratic objective functions, enabling exact reformulations of the DRRO control problem as semidefinite programs (SDPs). Focusing on one such reformulation, we eliminate certain decision variables. This technique also permits a further equivalent reformulation of the SDP as a distributed optimisation problem, with potential to enhance scalability.

Paper number 40:
Title: MIMOSA: Multi-parametric Imaging using Multiple-echoes with Optimized Simultaneous Acquisition for highly-efficient quantitative MRI
Authors: Yuting Chen, Yohan Jun, Amir Heydari, Xingwang Yong, Jiye Kim, Jongho Lee, Huafeng Liu, Huihui Ye, Borjan Gagoski, Shohei Fujita, Berkin Bilgic
Abstract: Purpose: To develop a new sequence, MIMOSA, for highly-efficient T1, T2, T2*, proton density (PD), and source separation quantitative susceptibility mapping (QSM). Methods: MIMOSA was developed based on 3D-quantification using an interleaved Look-Locker acquisition sequence with T2 preparation pulse (3D-QALAS) by combining 3D turbo Fast Low Angle Shot (FLASH) and multi-echo gradient echo acquisition modules with a spiral-like Cartesian trajectory to facilitate highly-efficient acquisition. Simulations were performed to optimize the sequence. Multi-contrast/-slice zero-shot self-supervised learning algorithm was employed for reconstruction. The accuracy of quantitative mapping was assessed by comparing MIMOSA with 3D-QALAS and reference techniques in both ISMRM/NIST phantom and in-vivo experiments. MIMOSA's acceleration capability was assessed at R = 3.3, 6.5, and 11.8 in in-vivo experiments, with repeatability assessed through scan-rescan studies. Beyond the 3T experiments, mesoscale quantitative mapping was performed at 750 um isotropic resolution at 7T. Results: Simulations demonstrated that MIMOSA achieved improved parameter estimation accuracy compared to 3D-QALAS. Phantom experiments indicated that MIMOSA exhibited better agreement with the reference techniques than 3D-QALAS. In-vivo experiments demonstrated that an acceleration factor of up to R = 11.8-fold can be achieved while preserving parameter estimation accuracy, with intra-class correlation coefficients of 0.998 (T1), 0.973 (T2), 0.947 (T2*), 0.992 (QSM), 0.987 (paramagnetic susceptibility), and 0.977 (diamagnetic susceptibility) in scan-rescan studies. Whole-brain T1, T2, T2*, PD, source separation QSM were obtained with 1 mm isotropic resolution in 3 min at 3T and 750 um isotropic resolution in 13 min at 7T. Conclusion: MIMOSA demonstrated potential for highly-efficient multi-parametric mapping.

Paper number 41:
Title: Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets
Authors: Matthew D. Osburn, Cameron K. Peterson, John L. Salmon
Abstract: In this paper, we create optimal, collision-free, time-dependent trajectories through cluttered dynamic environments. The many spatial and temporal constraints make finding an initial guess for a numerical solver difficult. Graphs of Convex Sets (GCS) and the recently developed Space-Time Graphs of Convex Sets formulation (ST-GCS) enable us to generate optimal minimum distance collision-free trajectories without providing an initial guess to the solver. We also explore the derivation of general GCS-compatible constraints and document an intuitive strategy for adapting general constraints to the framework. We show that ST-GCS produces equivalent trajectories to the standard GCS formulation when the environment is static. We then show ST-GCS operating in dynamic environments to find minimum distance collision-free trajectories.

Paper number 42:
Title: Energy-Efficient Index and Code Index Modulations for Spread CPM Signals in Internet of Things
Authors: Long Yuan, Wenkun Wen, Junlin Liu, Peiran Wu, Minghua Xia
Abstract: The evolution of Internet of Things technologies is driven by four key demands: ultra-low power consumption, high spectral efficiency, reduced implementation cost, and support for massive connectivity. To address these challenges, this paper proposes two novel modulation schemes that integrate continuous phase modulation (CPM) with spread spectrum (SS) techniques. We begin by establishing the quasi-orthogonality properties of CPM-SS sequences. The first scheme, termed IM-CPM-SS, employs index modulation (IM) to select spreading sequences from the CPM-SS set, thereby improving spectral efficiency while maintaining the constant-envelope property. The second scheme, referred to as CIM-CPM-SS, introduces code index modulation (CIM), which partitions the input bits such that one subset is mapped to phase-shift keying symbols and the other to CPM-SS sequence indices. Both schemes are applied to downlink non-orthogonal multiple access (NOMA) systems. We analyze their performance in terms of bit error rate (BER), spectral and energy efficiency, computational complexity, and peak-to-average power ratio characteristics under nonlinear amplifier conditions. Simulation results demonstrate that both schemes outperform conventional approaches in BER while preserving the benefits of constant-envelope, continuous-phase signaling. Furthermore, they achieve higher spectral and energy efficiency and exhibit strong resilience to nonlinear distortions in downlink NOMA scenarios.

Paper number 43:
Title: SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning
Authors: Weijian Mai, Jiamin Wu, Yu Zhu, Zhouheng Yao, Dongzhan Zhou, Andrew F. Luo, Qihao Zheng, Wanli Ouyang, Chunfeng Song
Abstract: Deciphering how visual stimuli are transformed into cortical responses is a fundamental challenge in computational neuroscience. This visual-to-neural mapping is inherently a one-to-many relationship, as identical visual inputs reliably evoke variable hemodynamic responses across trials, contexts, and subjects. However, existing deterministic methods struggle to simultaneously model this biological variability while capturing the underlying functional consistency that encodes stimulus information. To address these limitations, we propose SynBrain, a generative framework that simulates the transformation from visual semantics to neural responses in a probabilistic and biologically interpretable manner. SynBrain introduces two key components: (i) BrainVAE models neural representations as continuous probability distributions via probabilistic learning while maintaining functional consistency through visual semantic constraints; (ii) A Semantic-to-Neural Mapper acts as a semantic transmission pathway, projecting visual semantics into the neural response manifold to facilitate high-fidelity fMRI synthesis. Experimental results demonstrate that SynBrain surpasses state-of-the-art methods in subject-specific visual-to-fMRI encoding performance. Furthermore, SynBrain adapts efficiently to new subjects with few-shot data and synthesizes high-quality fMRI signals that are effective in improving data-limited fMRI-to-image decoding performance. Beyond that, SynBrain reveals functional consistency across trials and subjects, with synthesized signals capturing interpretable patterns shaped by biological neural variability. The code will be made publicly available.

Paper number 44:
Title: Integrated Communication and Remote Sensing in LEO Satellite Systems: Protocol, Architecture and Prototype
Authors: Yichao Xu, Xiaoming Chen, Ming Ying, Zhaoyang Zhang
Abstract: In this paper, we explore the integration of communication and synthetic aperture radar (SAR)-based remote sensing in low Earth orbit (LEO) satellite systems to provide real-time SAR imaging and information transmission. Considering the high-mobility characteristics of satellite channels and limited processing capabilities of satellite payloads, we propose an integrated communication and remote sensing architecture based on an orthogonal delay-Doppler division multiplexing (ODDM) signal waveform. Both communication and SAR imaging functionalities are achieved with an integrated transceiver onboard the LEO satellite, utilizing the same waveform and radio frequency (RF) front-end. Based on such an architecture, we propose a transmission protocol compatible with the 5G NR standard using downlink pilots for joint channel estimation and SAR imaging. Furthermore, we design a unified signal processing framework for the integrated satellite receiver to simultaneously achieve high-performance channel sensing, low-complexity channel equalization and interference-free SAR imaging. Finally, the performance of the proposed integrated system is demonstrated through comprehensive analysis and extensive simulations in the sub-6 GHz band. Moreover, a software-defined radio (SDR) prototype is presented to validate its effectiveness for real-time SAR imaging and information transmission in satellite direct-connect user equipment (UE) scenarios within the millimeter-wave (mmWave) band.

Paper number 45:
Title: Quantum Wavefront Correction via Machine Learning for Satellite-to-Earth CV-QKD
Authors: Nathan K. Long, Ziqing Wang, Benjamin P. Dix-Matthews, Alex Frost, John Wallis, Kenneth J. Grant, Robert Malaney
Abstract: State-of-the-art free-space continuous-variable quantum key distribution (CV-QKD) protocols use phase reference pulses to modulate the wavefront of a real local oscillator at the receiver, thereby compensating for wavefront distortions caused by atmospheric turbulence. It is normally assumed that the wavefront distortion in these phase reference pulses is identical to the wavefront distortion in the quantum signals, which are multiplexed during transmission. However, in many real-world deployments, there can exist a relative wavefront error (WFE) between the reference pulses and quantum signals, which, among other deleterious effects, can severely limit secure key transfer in satellite-to-Earth CV-QKD. In this work, we introduce novel machine learning-based wavefront correction algorithms, which utilize multi-plane light conversion for decomposition of the reference pulses and quantum signals into the Hermite-Gaussian (HG) basis, then estimate the difference in HG mode phase measurements, effectively eliminating this problem. Through detailed simulations of the Earth-satellite channel, we demonstrate that our new algorithm can rapidly identify and compensate for any relative WFEs that may exist, whilst causing no harm when WFEs are similar across both the reference pulses and quantum signals. We quantify the gains available in our algorithm in terms of the CV-QKD secure key rate. We show channels where positive secure key rates are obtained using our algorithms, while information loss without wavefront correction would result in null key rates.

Paper number 46:
Title: A dataset and model for recognition of audiologically relevant environments for hearing aids: AHEAD-DS and YAMNet+
Authors: Henry Zhong, JÃ¶rg M. Buchholz, Julian Maclaren, Simon Carlile, Richard Lyon
Abstract: Scene recognition of audiologically relevant environments is important for hearing aids; however, it is challenging, in part because of the limitations of existing datasets. Datasets often lack public accessibility, completeness, or audiologically relevant labels, hindering systematic comparison of machine learning models. Deploying these models on resource-constrained edge devices presents another challenge. Our solution is two-fold: we leverage several open source datasets to create AHEAD-DS, a dataset designed for scene recognition of audiologically relevant environments, and introduce YAMNet+, a sound recognition model. AHEAD-DS aims to provide a standardised, publicly available dataset with consistent labels relevant to hearing aids, facilitating model comparison. YAMNet+ is designed for deployment on edge devices like smartphones connected to hearing devices, such as hearing aids and wireless earphones with hearing aid functionality; serving as a baseline model for sound-based scene recognition. YAMNet+ achieved a mean average precision of 0.83 and accuracy of 0.93 on the testing set of AHEAD-DS across fourteen categories of audiologically relevant environments. We found that applying transfer learning from the pretrained YAMNet model was essential. We demonstrated real-time sound-based scene recognition capabilities on edge devices by deploying YAMNet+ to an Android smartphone. Even with a Google Pixel 3 (a phone with modest specifications, released in 2018), the model processes audio with approximately 50ms of latency to load the model, and an approximate linear increase of 30ms per 1 second of audio. Our website and code this https URL .

Paper number 47:
Title: MCP2OSC: Parametric Control by Natural Language
Authors: Yuan-Yi Fan
Abstract: Text prompts enable intuitive content creation but may fall short in achieving high precision for intricate tasks; knob or slider controls offer precise adjustments at the cost of increased complexity. To address the gap between knobs and prompts, a new MCP (Model Context Protocol) server and a unique set of prompt design criteria are presented to enable exploring parametric OSC (OpenSoundControl) control by natural language prompts. Demonstrated by 14 practical QA examples with best practices and the generalized prompt templates, this study finds Claude integrated with the MCP2OSC server effective in generating OSC messages by natural language, interpreting, searching, and visualizing OSC messages, validating and debugging OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine collaboration by leveraging LLM (Large Language Model) to handle intricate OSC development tasks, and by empowering human creativity with an intuitive language interface featuring flexible precision controls: a prompt-based OSC tool. This study provides a novel perspective on the creative MCP application at the network protocol level by utilizing LLM's strength in directly processing and generating human-readable OSC messages. The results suggest its potential for a LLM-based universal control mechanism for multimedia devices.

Paper number 48:
Title: MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion
Authors: Qi Liu, Xiaopeng Zhang, Mingshan Tan, Shuaikang Ma, Jinliang Ding, Yanjie Li
Abstract: This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot's action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.

Paper number 49:
Title: Alternating Approach-Putt Models for Multi-Stage Speech Enhancement
Authors: Iksoon Jeong, Kyung-Joong Kim, Kang-Hun Ahn
Abstract: Speech enhancement using artificial neural networks aims to remove noise from noisy speech signals while preserving the speech content. However, speech enhancement networks often introduce distortions to the speech signal, referred to as artifacts, which can degrade audio quality. In this work, we propose a post-processing neural network designed to mitigate artifacts introduced by speech enhancement models. Inspired by the analogy of making a `Putt' after an `Approach' in golf, we name our model PuttNet. We demonstrate that alternating between a speech enhancement model and the proposed Putt model leads to improved speech quality, as measured by perceptual quality scores (PESQ), objective intelligibility (STOI), and background noise intrusiveness (CBAK) scores. Furthermore, we illustrate with graphical analysis why this alternating Approach outperforms repeated application of either model alone.

Paper number 50:
Title: Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules
Authors: Andrea Urgolo, Monika Stipsitz, Helios Sanchis-Alepuz
Abstract: Monitoring the degradation state of Insulated Gate Bipolar Transistor (IGBT) modules is essential for ensuring the reliability and longevity of power electronic systems, especially in safety-critical and high-performance applications. However, direct measurement of key degradation indicators - such as junction temperature, solder fatigue or delamination - remains challenging due to the physical inaccessibility of internal components and the harsh environment. In this context, machine learning-based virtual sensing offers a promising alternative by bridging the gap from feasible sensor placement to the relevant but inaccessible locations. This paper explores the feasibility of estimating the degradation state of solder layers, and the corresponding full temperature maps based on a limited number of physical sensors. Based on synthetic data of a specific degradation mode, we obtain a high accuracy in the estimation of the degraded solder area (1.17% mean absolute error), and are able to reproduce the surface temperature of the IGBT with a maximum relative error of 4.56% (corresponding to an average relative error of 0.37%).

Paper number 51:
Title: A 240 Elements Matrix Probe with Aberration Mask for 4D Carotid Artery Computational Ultrasound Imaging
Authors: Yuyang Hu, Michael Brown, Didem Dogan, MahÃ© Bulot, Maxime Cheppe, Guillaume Ferin, Geert Leus, Antonius F.W. van der Steen, Pieter Kruizinga, Johannes G. Bosch
Abstract: Three-dimensional (3D) ultrasound provides enhanced visualization of the carotid artery (CA) anatomy and volumetric flow, offering improved accuracy for cardiovascular diagnosis and monitoring. However, fully populated matrix transducers with large apertures are complex and costly to implement. Computational ultrasound imaging (cUSi) offers a promising alternative by enabling simplified hardware design through model-based reconstruction and spatial field encoding. In this work, we present a 3D cUSi system tailored for CA imaging, consisting of a 240-element matrix probe with a 40 x 24 mm$^2$ large aperture and a spatial encoding mask. We describe the system's design, characterization, and image reconstruction. Phantom experiments show that computational reconstruction using matched filtering (MF) significantly improves volumetric image quality over delay-and-sum (DAS), with spatial encoding enhancing lateral resolution at the cost of reduced contrast ratio. LSQR-based reconstruction was demonstrated to further improve resolution and suppress artifacts. Using both Hadamard and 16-angle plane wave transmission schemes, the system achieved high-resolution images with reasonable contrast, supporting the feasibility of 4D CA imaging applications.

Paper number 52:
Title: Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling
Authors: Andrea Gargano, Jasin Machkour, Mimma Nardelli, Enzo Pasquale Scilingo, Michael Muma
Abstract: In Affective Computing, a key challenge lies in reliably linking subjective emotional experiences with objective physiological markers. This preliminary study addresses the issue of reproducibility by identifying physiological features from cardiovascular and electrodermal signals that are associated with continuous self-reports of arousal levels. Using the Continuously Annotated Signal of Emotion dataset, we analyzed 164 features extracted from cardiac and electrodermal signals of 30 participants exposed to short emotion-evoking videos. Feature selection was performed using the Terminating-Random Experiments (T-Rex) method, which performs variable selection systematically controlling a user-defined target False Discovery Rate. Remarkably, among all candidate features, only two electrodermal-derived features exhibited reproducible and statistically significant associations with arousal, achieving a 100\% confirmation rate. These results highlight the necessity of rigorous reproducibility assessments in physiological features selection, an aspect often overlooked in Affective Computing. Our approach is particularly promising for applications in safety-critical environments requiring trustworthy and reliable white box models, such as mental disorder recognition and human-robot interaction systems.

Paper number 53:
Title: Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions
Authors: Birgit Nierula, Mustafa Tevfik Lafci, Anna Melnik, Mert AkgÃ¼l, Farelle Toumaleu Siewe, Sebastian Bosse
Abstract: Proxemics, the study of spatial behavior, is fundamental to social interaction and increasingly relevant for virtual reality (VR) applications. While previous research has established that users respond to personal space violations in VR similarly as in real-world settings, phase-specific physiological responses and the modulating effects of facial expressions remain understudied. We investigated physiological and subjective responses to personal space violations by virtual avatars, to understand how threatening facial expressions and interaction phases (approach vs. standing) influence these responses. Sixteen participants experienced a 2x2 factorial design manipulating Personal Space (intrusion vs. respect) and Facial Expression (neutral vs. angry) while we recorded skin conductance response (SCR), heart rate variability (HRV), and discomfort ratings. Personal space boundaries were individually calibrated using a stop-distance procedure. Results show that SCR responses are significantly higher during the standing phase compared to the approach phase when personal space was violated, indicating that prolonged proximity within personal space boundaries is more physiologically arousing than the approach itself. Angry facial expressions significantly reduced HRV, reflecting decreased parasympathetic activity, and increased discomfort ratings, but did not amplify SCR responses. These findings demonstrate that different physiological modalities capture distinct aspects of proxemic responses: SCR primarily reflects spatial boundary violations, while HRV responds to facial threat cues. Our results provide insights for developing comprehensive multi-modal assessments of social behavior in virtual environments and inform the design of more realistic avatar interactions.

Paper number 54:
Title: Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer
Authors: Xuanhao Mu, GÃ¶khan Demirel, Yuzhe Zhang, Jianlei Liu, Thorsten Schlachter, Veit Hagenmeyer
Abstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. The goal of time series generative models is to learn the distribution of the original data to generate high-resolution series with similar statistical characteristics. This is not entirely consistent with the definition of upsampling. Time series Super-Resolution models or imputation models can degrade the accuracy of upsampling because the input low-resolution time series are sparse and may have insufficient context. Moreover, such models usually rely on supervised learning paradigms. This presents a fundamental application paradox: their training requires the high-resolution time series that is intrinsically absent in upsampling application scenarios. To address the mentioned upsampling issue, this paper introduces a new method utilizing Generative Adversarial Transformers (GATs), which can be trained without access to any ground-truth high-resolution data. Compared with conventional interpolation methods, the introduced method can reduce the root mean square error (RMSE) of upsampling tasks by 9%, and the accuracy of a model predictive control (MPC) application scenario is improved by 13%.

Paper number 55:
Title: Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning
Authors: Davide Guidobene, Lorenzo Benedetti, Diego Arapovic
Abstract: Multi-Objective Reinforcement Learning (MORL) is a generalization of traditional Reinforcement Learning (RL) that aims to optimize multiple, often conflicting objectives simultaneously rather than focusing on a single reward. This approach is crucial in complex decision-making scenarios where agents must balance trade-offs between various goals, such as maximizing performance while minimizing costs. We consider the problem of MORL where the objectives are combined using a non-linear scalarization function. Just like in standard RL, policy gradient methods (PGMs) are amongst the most effective for handling large and continuous state-action spaces in MORL. However, existing PGMs for MORL suffer from high sample inefficiency, requiring large amounts of data to be effective. Previous attempts to solve this problem rely on overly strict assumptions, losing PGMs' benefits in scalability to large state-action spaces. In this work, we address the issue of sample efficiency by implementing variance-reduction techniques to reduce the sample complexity of policy gradients while maintaining general assumptions.

Paper number 56:
Title: FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction
Authors: Farid Tasharofi, Fuxin Fan, Melika Qahqaie, Mareike Thies, Andreas Maier
Abstract: Metal artifacts, caused by high-density metallic implants in computed tomography (CT) imaging, severely degrade image quality, complicating diagnosis and treatment planning. While existing deep learning algorithms have achieved notable success in Metal Artifact Reduction (MAR), they often struggle to suppress artifacts while preserving structural details. To address this challenge, we propose FIND-Net (Fourier-Integrated Network with Dictionary Kernels), a novel MAR framework that integrates frequency and spatial domain processing to achieve superior artifact suppression and structural preservation. FIND-Net incorporates Fast Fourier Convolution (FFC) layers and trainable Gaussian filtering, treating MAR as a hybrid task operating in both spatial and frequency domains. This approach enhances global contextual understanding and frequency selectivity, effectively reducing artifacts while maintaining anatomical structures. Experiments on synthetic datasets show that FIND-Net achieves statistically significant improvements over state-of-the-art MAR methods, with a 3.07% MAE reduction, 0.18% SSIM increase, and 0.90% PSNR improvement, confirming robustness across varying artifact complexities. Furthermore, evaluations on real-world clinical CT scans confirm FIND-Net's ability to minimize modifications to clean anatomical regions while effectively suppressing metal-induced distortions. These findings highlight FIND-Net's potential for advancing MAR performance, offering superior structural preservation and improved clinical applicability. Code is available at this https URL

Paper number 57:
Title: Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots
Authors: Mehdi Heydari Shahna, Jouni Mattila
Abstract: Deep neural networks (DNNs) can enable precise control while maintaining low computational costs by circumventing the need for dynamic modeling. However, the deployment of such black-box approaches remains challenging for heavy-duty wheeled mobile robots (WMRs), which are subject to strict international standards and prone to faults and disturbances. We designed a hierarchical control policy for heavy-duty WMRs, monitored by two safety layers with differing levels of authority. To this end, a DNN policy was trained and deployed as the primary control strategy, providing high-precision performance under nominal operating conditions. When external disturbances arise and reach a level of intensity such that the system performance falls below a predefined threshold, a low-level safety layer intervenes by deactivating the primary control policy and activating a model-free robust adaptive control (RAC) policy. This transition enables the system to continue operating while ensuring stability by effectively managing the inherent trade-off between system robustness and responsiveness. Regardless of the control policy in use, a high-level safety layer continuously monitors system performance during operation. It initiates a shutdown only when disturbances become sufficiently severe such that compensation is no longer viable and continued operation would jeopardize the system or its environment. The proposed synthesis of DNN and RAC policy guarantees uniform exponential stability of the entire WMR system while adhering to safety standards to some extent. The effectiveness of the proposed approach was further validated through real-time experiments using a 6,000 kg WMR.

Paper number 58:
Title: Two-Instrument Screening under Soft Budget Constraints
Authors: Xinli Guo
Abstract: We study soft budget constraints in multi-tier public finance when an upper-tier government uses two instruments: an ex-ante grant schedule and an ex-post rescue. Under convex rescue costs and standard primitives, the three-stage leader-follower problem collapses to one dimensional screening with a single allocation index: the cap on realized rescue. A hazard-based characterization delivers a unified rule that nests (i) no rescue, (ii) a threshold-cap with commitment, and (iii) a threshold--linear--cap without commitment. The knife-edge for eliminating bailouts compares the marginal cost at the origin to the supremum of a virtual weight, and the comparative statics show how greater curvature tightens caps while discretion shifts transfers toward front loading by lowering the effective grant weight. The framework provides a portable benchmark for mechanism design and yields testable implications for policy and empirical work on intergovernmental finance.

Paper number 59:
Title: Traffic Intersection Simulation Using Turning Movement Count Data in SUMO: A Case Study of Toronto Intersections
Authors: Harshit Maheshwari, Li Yang, Richard W Pazzi
Abstract: Urban traffic simulation is vital in planning, modeling, and analyzing road networks. However, the realism of a simulation depends extensively on the quality of input data. This paper presents an intersection traffic simulation tool that leverages real-world vehicle turning movement count (TMC) data from the City of Toronto to model traffic in an urban environment at an individual or multiple intersections using Simulation of Urban MObility (SUMO). The simulation performed in this research focuses specifically on intersection-level traffic generation without creating full vehicle routes through the network. This also helps keep the network's complexity to a minimum. The simulated traffic is evaluated against actual data to show that the simulation closely reproduces real intersection flows. This validates that the real data can drive practical simulations, and these scenarios can replace synthetic or random generated data, which is prominently used in developing new traffic-related methodologies. This is the first tool to integrate TMC data from Toronto into SUMO via an easy-to-use Graphical User Interface. This work contributes to the research and traffic planning community on data-driven traffic simulation. It provides transportation engineers with a framework to evaluate intersection design and traffic signal optimization strategies using readily available aggregate traffic data.

Paper number 60:
Title: Learning Task Execution Hierarchies for Redundant Robots
Authors: Alessandro Adami, Aris Synodinos, Matteo Iovino, Ruggero Carli, Pietro Falco
Abstract: Modern robotic systems, such as mobile manipulators, humanoids, and aerial robots with arms, often possess high redundancy, enabling them to perform multiple tasks simultaneously. Managing this redundancy is key to achieving reliable and flexible behavior. A widely used approach is the Stack of Tasks (SoT), which organizes control objectives by priority within a unified framework. However, traditional SoTs are manually designed by experts, limiting their adaptability and accessibility. This paper introduces a novel framework that automatically learns both the hierarchy and parameters of a SoT from user-defined objectives. By combining Reinforcement Learning and Genetic Programming, the system discovers task priorities and control strategies without manual intervention. A cost function based on intuitive metrics such as precision, safety, and execution time guides the learning process. We validate our method through simulations and experiments on the mobile-YuMi platform, a dual-arm mobile manipulator with high redundancy. Results show that the learned SoTs enable the robot to dynamically adapt to changing environments and inputs, balancing competing objectives while maintaining robust task execution. This approach provides a general and user-friendly solution for redundancy management in complex robots, advancing human-centered robot programming and reducing the need for expert design.

Paper number 61:
Title: Advances in Speech Separation: Techniques, Challenges, and Future Trends
Authors: Kai Li, Guo Chen, Wendi Sang, Yi Luo, Zhuo Chen, Shuai Wang, Shulin He, Zhong-Qiu Wang, Andong Li, Zhiyong Wu, Xiaolin Hu
Abstract: The field of speech separation, addressing the "cocktail party problem", has seen revolutionary advances with DNNs. Speech separation enhances clarity in complex acoustic environments and serves as crucial pre-processing for speech recognition and speaker recognition. However, current literature focuses narrowly on specific architectures or isolated approaches, creating fragmented understanding. This survey addresses this gap by providing systematic examination of DNN-based speech separation techniques. Our work differentiates itself through: (I) Comprehensive perspective: We systematically investigate learning paradigms, separation scenarios with known/unknown speakers, comparative analysis of supervised/self-supervised/unsupervised frameworks, and architectural components from encoders to estimation strategies. (II) Timeliness: Coverage of cutting-edge developments ensures access to current innovations and benchmarks. (III) Unique insights: Beyond summarization, we evaluate technological trajectories, identify emerging patterns, and highlight promising directions including domain-robust frameworks, efficient architectures, multimodal integration, and novel self-supervised paradigms. (IV) Fair evaluation: We provide quantitative evaluations on standard datasets, revealing true capabilities and limitations of different methods. This comprehensive survey serves as an accessible reference for experienced researchers and newcomers navigating speech separation's complex landscape.

Paper number 62:
Title: CVIRO: A Consistent and Tightly-Coupled Visual-Inertial-Ranging Odometry on Lie Groups
Authors: Yizhi Zhou, Ziwei Kang, Jiawei Xia, Xuan Wang
Abstract: Ultra Wideband (UWB) is widely used to mitigate drift in visual-inertial odometry (VIO) systems. Consistency is crucial for ensuring the estimation accuracy of a UWBaided VIO system. An inconsistent estimator can degrade localization performance, where the inconsistency primarily arises from two main factors: (1) the estimator fails to preserve the correct system observability, and (2) UWB anchor positions are assumed to be known, leading to improper neglect of calibration uncertainty. In this paper, we propose a consistent and tightly-coupled visual-inertial-ranging odometry (CVIRO) system based on the Lie group. Our method incorporates the UWB anchor state into the system state, explicitly accounting for UWB calibration uncertainty and enabling the joint and consistent estimation of both robot and anchor states. Furthermore, observability consistency is ensured by leveraging the invariant error properties of the Lie group. We analytically prove that the CVIRO algorithm naturally maintains the system's correct unobservable subspace, thereby preserving estimation consistency. Extensive simulations and experiments demonstrate that CVIRO achieves superior localization accuracy and consistency compared to existing methods.

Paper number 63:
Title: Finite Sample Performance Analysis of MIMO Systems Identification
Authors: Shuai Sun, Jiayun Li, Yilin Mo
Abstract: This paper is concerned with the finite sample identification performance of an n dimensional discrete-time Multiple-Input Multiple-Output (MIMO) Linear Time-Invariant system, with p inputs and m outputs. We prove that the widely-used Ho-Kalman algorithm and Multivariable Output Error State Space (MOESP) algorithm are ill-conditioned for MIMO systems when n/m or n/p is large. Moreover, by analyzing the Cramer-Rao bound, we derive a fundamental limit for identifying the real and stable (or marginally stable) poles of MIMO system and prove that the sample complexity for any unbiased pole estimation algorithm to reach a certain level of accuracy explodes superpolynomially with respect to n/(pm). Numerical results are provided to illustrate the ill-conditionedness of Ho-Kalman algorithm and MOESP algorithm as well as the fundamental limit on identification.

Paper number 64:
Title: Evaluation of Speech Foundation Models for ASR on Child-Adult Conversations in Autism Diagnostic Sessions
Authors: Aditya Ashvin, Rimita Lahiri, Aditya Kommineni, Somer Bishop, Catherine Lord, Sudarsana Reddy Kadiri, Shrikanth Narayanan
Abstract: Reliable transcription of child-adult conversations in clinical settings is crucial for diagnosing developmental disorders like Autism. Recent advances in deep learning and availability of large scale transcribed data has led to development of speech foundation models that have shown dramatic improvements in ASR performance. However, their performance on conversational child-adult interactions remains underexplored. In this work, we provide a comprehensive evaluation of ASR performance on a dataset containing child-adult interactions from autism diagnostic sessions, using Whisper, Wav2Vec2, HuBERT, and WavLM. We find that speech foundation models show a noticeable performance drop (15-20% absolute WER) for child speech compared to adult speech in the conversational setting. Then, we fine-tune the best-performing zero-shot model (Whisper-large) using LoRA in a low-resource setting, yielding 8% and 13% absolute WER improvements for child and adult speech, respectively.

Paper number 65:
Title: Unified Performance Control for Non-Square Nonlinear Systems with Relaxed Controllability
Authors: Bing Zhou, Kai Zhao, Yongduan Song, Zhen Chen
Abstract: In this paper, we investigate the problem of unified prescribed performance tracking for a class of non-square strict-feedback nonlinear systems under relaxed controllability conditions. By using a skillful matrix decomposition and introducing some feasible auxiliary matrices, a more generalized controllability condition than the current state of the art is constructed, which can be applied to both square and non-square nonlinear systems subject to actuator faults and unknown yet time-varying control gain. Incorporating the relaxed controllability conditions and the uniform performance specifications into the backstepping design procedure, a prescribed performance fault-tolerant controller is developed that can achieve different performance demands without modifying the controller structure, which is more flexible and this http URL addition, the destruction of the system stability by unknown controllability auxiliary matrices and unknown nonlinearities is circumvented by embedding the available core information of the state-dependent uncertainties into the design procedure. Both theoretical analysis and numerical simulation demonstrate the effectiveness and benefits of the proposed method.

Paper number 66:
Title: INSIGHT: Explainable Weakly-Supervised Medical Image Analysis
Authors: Wenbo Zhang, Junyu Chen, Christopher Kanan
Abstract: Due to their large sizes, volumetric scans and whole-slide pathology images (WSIs) are often processed by extracting embeddings from local regions and then an aggregator makes predictions from this set. However, current methods require post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize small yet clinically crucial details. To address these limitations, we introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap generation as an inductive bias. Starting from pre-trained feature maps, INSIGHT employs a detection module with small convolutional kernels to capture fine details and a context module with a broader receptive field to suppress local false positives. The resulting internal heatmap highlights diagnostically relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art classification results and high weakly-labeled semantic segmentation performance. Project website and code are available at: this https URL

Paper number 67:
Title: On Event-Triggered Resilient Consensus Using Auxiliary Layer
Authors: Pushkal Purohit, Anoop Jain
Abstract: Due to its design simplicity, auxiliary layer-based resilient control is widely discussed in the literature to mitigate the effects of False Data Injection (FDI) attacks. However, the increased communication burden due to additional communication links for connecting an extra layer is often overlooked in the literature. This paper bridges this gap by considering an event-triggered approach for inter-layer communication between the physical layer (containing actual agents) and the auxiliary layer (containing virtual agents) for the resilient state consensus in a multi-agent system. We provide state-based and dynamic event-triggering mechanisms, the former being the motivation for the latter. The exclusion of Zeno behavior is established by proving positive minimum inter-event time (MIET). Extensive simulation and experimental results are provided to illustrate the proposed methodology.

Paper number 68:
Title: Enhancing Fault Detection and Isolation in an All-Electric Auxiliary Power Unit (APU) Gas Generator by Utilizing Starter/Generator Signal
Authors: Haotian Mao, Khashayar Khorasani, Yingqing Guo
Abstract: This study proposes a novel paradigm for enhancing fault detection and isolation (FDI) of gas generators in all-electric auxiliary power unit (APU) by utilizing shaft power information from the starter/generator. First, we conduct a pioneering investigation into the challenges and opportunities for FDI brought about by APU electrification. Our analysis reveals that the electrification of APU opens up new possibilities for utilizing shaft power estimates from starter/generator to improve gas generator FDI. We then provide comprehensive theoretical and analytical evidence demonstrating why, how, and to what extent, the shaft power information from the starter/generator can fundamentally enhance the estimation accuracy of system states and health parameters of the gas generator, while also identifying the key factors influencing these improvements in FDI performance. The effectiveness of the proposed paradigm and its theoretical foundations are validated through extensive Monte Carlo simulations. Furthermore, through comprehensive comparative analysis with state-of-the-art gas generator fault diagnosis methods, our experimental results not only demonstrate the superior performance of the proposed approach but also validate that the diagnostic capabilities of existing advanced FDI techniques can be substantially enhanced by incorporating shaft power information. And the observed performance improvement patterns strongly align with our theoretical analysis, verifying both the effectiveness and guiding significance of our theoretical framework. These research findings provide a unique perspective in answering three fundamental questions: why joint fault diagnosis of the starter/generator and gas generator is essential, how it can be implemented, and what factors determine its effectiveness, thereby opening up promising new avenues for FDI technologies in all-electric APU systems.

Paper number 69:
Title: Incompressible Optimal Transport and Applications in Fluid Mixing
Authors: Max Emerick, Bassam Bamieh
Abstract: The problem of incompressible fluid mixing arises in numerous engineering applications and has been well-studied over the years, yet many open questions remain. This paper aims to address the question "what do efficient flow fields for mixing look like, and how do they behave?" We approach this question by developing a framework which is inspired by the dynamic and geometric approach to optimal mass transport. Specifically, we formulate the fluid mixing problem as an optimal control problem where the dynamics are given by the continuity equation together with an incompressibility constraint. We show that within this framework, the set of reachable fluid configurations can formally be endowed with the structure of an infinite-dimensional Riemannian manifold, with a metric which is induced by the control effort, and that flow fields which are maximally efficient at mixing correspond to geodesics in this Riemannian space.

Paper number 70:
Title: Ambiguity Function Analysis of Affine Frequency Division Multiplexing for Integrated Sensing and Communication
Authors: Ebrahim Bedeer
Abstract: Affine frequency division multiplexing (AFDM) is a chirp-based multicarrier waveform that was recently proposed for communication over doubly dispersive channels. Given its chirp nature, AFDM is expected to have superior sensing capabilities compared to orthogonal frequency division multiplexing (OFDM) and is thus a promising candidate for integrated sensing and communication (ISAC) applications. In this paper, we derive a closed-form expression for the ambiguity function of AFDM waveforms modulated with $M$-ary quadrature amplitude modulation (QAM) data symbols. We determine the condition on the chirp rate of the AFDM waveform that minimizes the sidelobes in the delay/range domain in the presence of random $M$-ary QAM symbols, thereby improving overall sensing performance. Additionally, we find an approximate statistical distribution for the magnitude of the derived ambiguity function. Simulation results are presented to evaluate the sensing performance of the AFDM waveform for various system parameters and to compare its peak-to-sidelobe ratio (PSLR) and integrated sidelobe ratio (ISLR) with those of OFDM.

Paper number 71:
Title: xApp Conflict Mitigation with Scheduler
Authors: Idris Cinemre, Toktam Mahmoodi, Amirmohammad Farzaneh
Abstract: Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven control but simultaneously introduces the challenge of coordinating pre-trained xApps that may produce conflicting actions. Although O-RAN specifications mandate offline training and validation to prevent the deployment of untrained or inadequately tested models, operational conflicts can still arise under dynamic and context-dependent this http URL work proposes a scheduler-based conflict mitigation framework to address these challenges without requiring training xApps together or further xApp re-training. By examining an indirect conflict involving power and resource block allocation xApps and employing an Advantage Actor-Critic (A2C) approach to train both xApps and the scheduler, we illustrate that a straightforward A2C-based scheduler improves performance relative to independently deployed xApps and conflicting cases. Notably, among all tested deployment scenarios (including individual xApp deployment, multiple conflicting xApps, and limited scheduler configurations), augmenting the system with baseline xApps and enabling the scheduler to select from a broader pool achieves the highest total transmission rate, thereby underscoring the importance of adaptive scheduling mechanisms. These findings highlight the context-dependent nature of conflicts in automated network management, as two xApps may conflict under certain conditions but coexist under others. Consequently, the ability to dynamically update and adapt the scheduler to accommodate diverse operational intents is vital for future network deployments. By offering dynamic scheduling without re-training xApps, this framework advances practical conflict resolution solutions while supporting real-world scalability.

Paper number 72:
Title: Navigating PESQ: Up-to-Date Versions and Open Implementations
Authors: Matteo Torcoli, Mhd Modar Halimeh, EmanuÃ«l A. P. Habets
Abstract: Perceptual Evaluation of Speech Quality (PESQ) is an objective quality measure that remains widely used despite its withdrawal by the International Telecommunication Union (ITU). PESQ has evolved over two decades, with multiple versions and publicly available implementations emerging during this time. Different versions and their updates can be overwhelming, especially for new PESQ users. This work provides practical guidance on the different versions and implementations of PESQ. We show that differences can be significant, especially between PESQ versions. We stress the importance of specifying the exact version and implementation that is used to compute PESQ, and possibly to detail how multi-channel signals are handled. These practices would facilitate the interpretation of results and allow comparisons of PESQ scores between different studies. We also provide a repository that implements the latest corrections to PESQ, i.e., Corrigendum 2, which is not implemented by any other openly available distribution: this https URL.

Paper number 73:
Title: EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement
Authors: Wenjie Cai, Qingguo Meng, Zhenyu Wang, Xingbo Dong, Zhe Jin
Abstract: Capturing high-quality visual content under low-light conditions remains a challenging problem due to severe noise and underexposure, which degrade the performance of downstream applications. Traditional frame-based low-light image enhancement methods often amplify noise or fail to preserve structural details. Event cameras, offering high dynamic range and microsecond temporal resolution by asynchronously capturing brightness changes, emerge as a promising complement for low-light imaging. However, existing fusion methods fail to fully exploit this synergy, either by forcing modalities into a shared representation too early or by losing vital low-level correlations through isolated processing. To address these challenges, we propose EvRWKV, a novel framework that enables continuous cross-modal interaction through dual-domain processing. Our approach incorporates a Cross-RWKV module, leveraging the Receptance Weighted Key Value (RWKV) architecture for fine-grained temporal and cross-modal fusion, and an Event Image Spectral Fusion Enhancer (EISFE) module, which jointly performs adaptive frequency-domain noise suppression and spatial-domain deformable convolution alignment. This continuous interaction maintains feature consistency from low-level textures to high-level semantics. Extensive qualitative and quantitative evaluations on real-world low-light datasets (SDE, SDSD, RELED) demonstrate that EvRWKV achieves state-of-the-art performance, effectively enhancing image quality by suppressing noise, restoring structural details, and improving visual clarity in challenging low-light conditions.

Paper number 74:
Title: LCS-CTC: Leveraging Soft Alignments to Enhance Phonetic Transcription Robustness
Authors: Zongli Ye, Jiachen Lian, Akshaj Gupta, Xuanru Zhou, Haodong Li, Krish Patel, Hwi Joo Park, Dingkun Zhou, Chenxu Guo, Shuhe Li, Sam Wang, Iris Zhou, Cheol Jun Cho, Zoe Ezzes, Jet M.J. Vonk, Brittany T. Morin, Rian Bogley, Lisa Wauters, Zachary A. Miller, Maria Luisa Gorno-Tempini, Gopala Anumanchipalli
Abstract: Phonetic speech transcription is crucial for fine-grained linguistic analysis and downstream speech applications. While Connectionist Temporal Classification (CTC) is a widely used approach for such tasks due to its efficiency, it often falls short in recognition performance, especially under unclear and nonfluent speech. In this work, we propose LCS-CTC, a two-stage framework for phoneme-level speech recognition that combines a similarity-aware local alignment algorithm with a constrained CTC training objective. By predicting fine-grained frame-phoneme cost matrices and applying a modified Longest Common Subsequence (LCS) algorithm, our method identifies high-confidence alignment zones which are used to constrain the CTC decoding path space, thereby reducing overfitting and improving generalization ability, which enables both robust recognition and text-free forced alignment. Experiments on both LibriSpeech and PPA demonstrate that LCS-CTC consistently outperforms vanilla CTC baselines, suggesting its potential to unify phoneme modeling across fluent and non-fluent speech.

Paper number 75:
Title: Speech Enhancement based on cascaded two flow
Authors: Seonggyu Lee, Sein Cheong, Sangwook Han, Kihyuk Kim, Jong Won Shin
Abstract: Speech enhancement (SE) based on diffusion probabilistic models has exhibited impressive performance, while requiring a relatively high number of function evaluations (NFE). Recently, SE based on flow matching has been proposed, which showed competitive performance with a small NFE. Early approaches adopted the noisy speech as the only conditioning variable. There have been other approaches which utilize speech enhanced with a predictive model as another conditioning variable and to sample an initial value, but they require a separate predictive model on top of the generative SE model. In this work, we propose to employ an identical model based on flow matching for both SE and generating enhanced speech used as an initial starting point and a conditioning variable. Experimental results showed that the proposed method required the same or fewer NFEs even with two cascaded generative methods while achieving equivalent or better performances to the previous baselines.

Paper number 76:
Title: RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach
Authors: Bile Peng, Karl-Ludwig Besser, Shanpu Shen, Finn Siegismund-Poschmann, Ramprasad Raghunath, Daniel M. Mittleman, Vahid Jamali, Eduard A. Jorswieck
Abstract: Non-orthogonal multiple access (NOMA) is a promising multiple access technique. Its performance depends strongly on the wireless channel property, which can be enhanced by reconfigurable intelligent surfaces (RISs). In this paper, we jointly optimize base station (BS) precoding and RIS configuration with unsupervised machine learning (ML), which looks for the optimal solution autonomously. In particular, we propose a dedicated neural network (NN) architecture RISnet inspired by domain knowledge in communication. Compared to state-of-the-art, the proposed approach combines analytical optimal BS precoding and ML-enabled RIS, has a high scalability to control more than 1000 RIS elements, has a low requirement for channel state information (CSI) in input, and addresses the mutual coupling between RIS elements. Beyond the considered problem, this work is an early contribution to domain knowledge enabled ML, which exploit the domain expertise of communication systems to design better approaches than general ML methods.

Paper number 77:
Title: Advancing Glitch Classification in Gravity Spy: Multi-view Fusion with Attention-based Machine Learning for Advanced LIGO's Fourth Observing Run
Authors: Yunan Wu, Michael Zevin, Christopher P. L. Berry, Kevin Crowston, Carsten Ãsterlund, Zoheyr Doctor, Sharan Banagiri, Corey B. Jackson, Vicky Kalogera, Aggelos K. Katsaggelos
Abstract: The first successful detection of gravitational waves by ground-based observatories, such as the Laser Interferometer Gravitational-Wave Observatory (LIGO), marked a breakthrough in our comprehension of the Universe. However, due to the unprecedented sensitivity required to make such observations, gravitational-wave detectors also capture disruptive noise sources called glitches, which can potentially be confused for or mask gravitational-wave signals. To address this problem, a community-science project, Gravity Spy, incorporates human insight and machine learning to classify glitches in LIGO data. The machine-learning classifier, integrated into the project since 2017, has evolved over time to accommodate increasing numbers of glitch classes. Despite its success, limitations have arisen in the ongoing LIGO fourth observing run (O4) due to the architecture's simplicity, which led to poor generalization and inability to handle multi-time window inputs effectively. We propose an advanced classifier for O4 glitches. Using data from previous observing runs, we evaluate different fusion strategies for multi-time window inputs, using label smoothing to counter noisy labels, and enhancing interpretability through attention module-generated weights. Our new O4 classifier shows improved performance, and will enhance glitch classification, aiding in the ongoing exploration of gravitational-wave phenomena.

Paper number 78:
Title: MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization
Authors: Bogdan Vlahov, Jason Gibson, Manan Gandhi, Evangelos A. Theodorou
Abstract: This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: this https URL .

Paper number 79:
Title: A Training-Free Approach for Music Style Transfer with Latent Diffusion Models
Authors: Heehwan Wang, Joonwoo Kwon, Sooyoung Kim, Shinjae Yoo, Yuewei Lin, Jiook Cha
Abstract: Music style transfer enables personalized music creation by combining the structure of one piece with the stylistic characteristics of another. While recent approaches have explored text-conditioned generation and diffusion-based synthesis, most require extensive training, paired datasets, or detailed textual annotations. In this work, we introduce Stylus, a novel training-free framework for music style transfer that directly manipulates the self-attention layers of a pre-trained Latent Diffusion Model (LDM). Operating in the mel-spectrogram domain, Stylus transfers musical style by replacing key and value representations from the content audio with those of the style reference, without any fine-tuning. To enhance stylization quality and controllability, we further incorporate query preservation, CFG-inspired guidance scaling, multi-style interpolation, and phase-preserving reconstruction. Our method significantly improves perceptual quality and structural preservation compared to prior work, while remaining lightweight and easy to deploy. This work highlights the potential of diffusion-based attention manipulation for efficient, high-fidelity, and interpretable music generation-without training. Codes will be released upon acceptance.

Paper number 80:
Title: Double reflections Assisted RIS Deployment and Energy-efficient Group Selection in mmWaves D2D Communication
Authors: Lakshmikanta Sau, Sasthi C. Ghosh
Abstract: Reconfigurable intelligent surfaces (RISs) offer a viable way to improve the performance of multi-hop device-to-device (D2D) communication. However, due to the substantial propagation and penetration losses of the millimeter waves (mmWaves), a direct line of sight (LoS) link and close proximity of a device pair are required for a high data rate. Static obstacles like trees and buildings can easily impede the direct LoS connectivity between a device pair. Hence, RIS placement plays a crucial role in establishing an indirect LoS link between them. Therefore, in this work, we propose a set cover-based RIS deployment strategy for both single and double RIS-assisted D2D communication. In particular, we have demonstrated that permitting reflections via two consecutive RISs can greatly lower the RIS density in the environment, preventing resource waste and enabling the service of more obstructed device pairs. After the RIS deployment, for information transfer, we also propose an energy-efficient group selection criteria. Moreover, we prove that sometimes double reflections are more beneficial than single reflection, which is counter-intuitive. Numerical results show that our approach outperforms a random and a recent deployment strategy.

Paper number 81:
Title: Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision
Authors: Haichao Wang, Xinyue Xi, Jiangtao Wen, Yuxing Han
Abstract: Existing computer vision processing pipeline acquires visual information using an image sensor that captures pixel information in the Bayer pattern. The raw sensor data are then processed using an image signal processor (ISP) that first converts Bayer pixel data to RGB on a pixel by pixel basis, followed by video convolutional network (VCN) processing on a frame by frame basis. Both ISP and VCN are computationally expensive with high power consumption and latency. In this paper, we propose a novel framework that eliminates the ISP and leverages motion estimation to accelerate video vision tasks directly in the Bayer domain. We introduce Motion Estimation-based Video Convolution (MEVC), which integrates sliding-window motion estimation into each convolutional layer, enabling prediction and residual-based refinement that reduces redundant computations across frames. This design bridges the structural gap between block-based motion estimation and spatial convolution, enabling accurate, low-cost processing. Our end-to-end pipeline supports raw Bayer input and achieves over 70\% reduction in FLOPs with minimal accuracy degradation across video semantic segmentation, depth estimation, and object detection benchmarks, using both synthetic Bayer-converted and real Bayer video datasets. This framework generalizes across convolution-based models and marks the first effective reuse of motion estimation for accelerating video computer vision directly from raw sensor data.

Paper number 82:
Title: TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion
Authors: Amr Mousa, Neil Karavis, Michele Caprio, Wei Pan, Richard Allmendinger
Abstract: Quadrupedal locomotion via Reinforcement Learning (RL) is commonly addressed using the teacher-student paradigm, where a privileged teacher guides a proprioceptive student policy. However, key challenges such as representation misalignment between privileged teacher and proprioceptive-only student, covariate shift due to behavioral cloning, and lack of deployable adaptation; lead to poor generalization in real-world scenarios. We propose Teacher-Aligned Representations via Contrastive Learning (TAR), a framework that leverages privileged information with self-supervised contrastive learning to bridge this gap. By aligning representations to a privileged teacher in simulation via contrastive objectives, our student policy learns structured latent spaces and exhibits robust generalization to Out-of-Distribution (OOD) scenarios, surpassing the fully privileged "Teacher". Results showed accelerated training by 2x compared to state-of-the-art baselines to achieve peak performance. OOD scenarios showed better generalization by 40% on average compared to existing methods. Moreover, TAR transitions seamlessly into learning during deployment without requiring privileged states, setting a new benchmark in sample-efficient, adaptive locomotion and enabling continual fine-tuning in real-world scenarios. Open-source code and videos are available at this https URL.

Paper number 83:
Title: Sequential QCQP for Bilevel Optimization with Line Search
Authors: Sina Sharifi, Erfan Yazdandoost Hamedani, Mahyar Fazlyab
Abstract: Bilevel optimization involves a hierarchical structure where one problem is nested within another, leading to complex interdependencies between levels. We propose a single-loop, tuning-free algorithm that guarantees anytime feasibility, i.e., approximate satisfaction of the lower-level optimality condition, while ensuring descent of the upper-level objective. At each iteration, a convex quadratically-constrained quadratic program (QCQP) with a closed-form solution yields the search direction, followed by a backtracking line search inspired by control barrier functions to ensure safe, uniformly positive step sizes. The resulting method is scalable, requires no hyperparameter tuning, and converges under mild local regularity assumptions. We establish an O(1/k) ergodic convergence rate in terms of a first-order stationary metric and demonstrate the algorithm's effectiveness on representative bilevel tasks.

Paper number 84:
Title: Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition
Authors: Leonora Vesterbacka, Faton Rekathati, Robin Kurtz, Justyna Sikora, Agnes ToftgÃ¥rd
Abstract: This work presents a suite of fine-tuned Whisper models for Swedish, trained on a dataset of unprecedented size and variability for this mid-resourced language. As languages of smaller sizes are often underrepresented in multilingual training datasets, substantial improvements in performance can be achieved by fine-tuning existing multilingual models, as shown in this work. This work reports an overall improvement across model sizes compared to OpenAI's Whisper evaluated on Swedish. Most notably, we report an average 47% reduction in WER comparing our best performing model to OpenAI's whisper-large-v3, in evaluations across FLEURS, Common Voice, and NST.

Paper number 85:
Title: Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits
Authors: Shan Shen, Shenglu Hua, Jiajun Zou, Jiawei Liu, Jianwang Zhai, Chuan Shi, Wenjian Yu
Abstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (BMSE) and balanced softmax cross-entropy (BSCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-score gain of $0.9\times \sim 2.1\times$ for node classification. Our code is available at this https URL.

Paper number 86:
Title: Curvature-adaptive gigapixel microscopy at submicron resolution and centimeter scale
Authors: Xi Yang, Haitao Chen, Lucas Kreiss, Clare B. Cook, Genevieve Kuczewski, Mark Harfouche, Martin O. Bohlen, Roarke Horstmeyer
Abstract: Large-area microscopy with submicron resolution is limited by tradeoffs between field of view (FOV), resolution, and imaging speed. Samples are rarely flat across centimeter-scale FOV, which often requires existing solutions to use mechanical scanning to ensure focused capture at reduced throughput. Here, we present PANORAMA, a single-shot, re-imaging microscope that achieves seamless, gigapixel imaging over a 16.3$\times$18.8 $\text{mm}^2$ FOV at 0.84 um resolution without mechanical scanning. By using a telecentric photolithography lens, a large-aperture tube lens, and a flat micro-camera array with adaptive per-camera focus control, PANORAMA maintains submicron focus across flat, curved or uneven samples that span centimeters. This approach improves imaging throughput and adaptability, enabling gigapixel multi-modal microscopy of large flat and non-flat samples in one shot, thus broadening its applications in biomedical and materials imaging.

Paper number 87:
Title: Marco-Voice Technical Report
Authors: Fengping Tian, Chenyang Lyu, Xuanfan Ni, Haoqin Sun, Qingjuan Li, Zhiqiang Qian, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang
Abstract: This paper presents a multifunctional speech synthesis system that integrates voice cloning and emotion control speech synthesis within a unified framework. The goal of this work is to address longstanding challenges in achieving highly expressive, controllable, and natural speech generation that faithfully preserves speaker identity across diverse linguistic and emotional contexts. Our approach introduces an effective speaker-emotion disentanglement mechanism with in-batch contrastive learning, enabling independent manipulation of speaker identity and eemotional style, as well as rotational emotional embedding integration method for smooth emotion control. To support comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality emotional speech dataset containing 10 hours of Mandarin speech from six professional speakers across seven emotional categories. Extensive experiments demonstrate that our system, Marco-Voice, achieves substantial improvements in both objective and subjective metrics. Comprehensive evaluations and analysis were conducted, results show that MarcoVoice delivers competitive performance in terms of speech clarity and emotional richness, representing a substantial advance in the field of expressive neural speech synthesis. Our code and dataset are publicly available at this https URL and this https URL respectively.

Paper number 88:
Title: Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning
Authors: Ruru Xu, Ilkay Oksuz
Abstract: Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of k-space sampling patterns to balance acquisition speed and image quality. While recent advances in deep learning have shown promise in optimizing Cartesian sampling, the potential of reinforcement learning (RL) for non-Cartesian trajectory optimization remains largely unexplored. In this work, we present a novel RL framework for optimizing radial sampling trajectories in cardiac MRI. Our approach features a dual-branch architecture that jointly processes k-space and image-domain information, incorporating a cross-attention fusion mechanism to facilitate effective information exchange between domains. The framework employs an anatomically-aware reward design and a golden-ratio sampling strategy to ensure uniform k-space coverage while preserving cardiac structural details. Experimental results demonstrate that our method effectively learns optimal radial sampling strategies across multiple acceleration factors, achieving improved reconstruction quality compared to conventional approaches. Code available: this https URL

Paper number 89:
Title: Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging
Authors: Shengling Shi, Jacob Sass, Jiaen Wu, Minsu Kim, Yingjie Ma, Sungho Shin, Richard D. Braatz
Abstract: Single-input fast optimal control problems, which aim to achieve the optimal objective as fast as possible, occur in various real-world applications. In the case of fast battery charging, the associated optimal control problem becomes computationally challenging when detailed battery models are used. A recent heuristic optimization-free algorithm can significantly reduce the computational cost and provide an approximate solution, consistent with many heuristic input profiles in practice. These heuristic solutions have several special properties: They follow a bang-ride pattern that always activates a constraint and applies the maximum feasible input. This work investigates when the above properties arise in the optimal input, and ultimately, when the heuristic input profiles satisfy necessary optimality conditions. By exploiting Pontryagin's maximum principle (PMP), we show that the optimal control is bang-ride under regularity conditions on constraint switching and local controllability of the system. Moreover, the special type of bang-ride behavior, i.e., applying the maximum feasible input, arises under the monotonicity of the system, objective function, and restricted sensitivity of the constraints. These results provide a theoretical justification for a class of charging heuristics and the fast optimization-free algorithm.
    