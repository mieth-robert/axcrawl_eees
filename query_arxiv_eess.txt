
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: In Planta Tattoo and Kirigami Sensors for Self-Powered Monitoring of Vapor Pressure Deficit and Growth Dynamics
Authors: Nafize Ishtiaque Hossain, Kundan Saha, Atul Sharma, Sameer Sonkusale
Abstract: We report a scalable, self-powered in planta sensor platform for continuous monitoring of plant hydration and growth. The system integrates two components a leaf mounted tattoo sensor for estimating vapor pressure deficit and a kirigami inspired strain sensor for tracking radial stem growth. Uniquely, the tattoo sensor serves a dual function measuring temperature and humidity beneath the leaf surface while simultaneously harvesting power from ambient moisture via a vanadium pentoxide nanosheet membrane. This moist-electric generator configuration enables energy-autonomous operation, delivering a power density of 0.1114 miroW per square cm. The V2O5 based sensor exhibits high sensitivity to humidity and temperature, enabling accurate VPD estimation for over 10 days until leaf senescence. The eutectogel based kirigami strain sensor, wrapped around the stem, offers a gauge factor of 1.5 and immunity to unrelated mechanical disturbances, allowing continuous growth tracking for more than 20 days. Both sensors are fabricated via cleanroom-free, roll to roll compatible methods, underscoring their potential for large-scale agricultural deployment to monitor abiotic stress and improve crop management.

Paper number 2:
Title: Artificial Intelligence-derived Cardiotocography Age as a Digital Biomarker for Predicting Future Adverse Pregnancy Outcomes
Authors: Jinshuai Gu, Zenghui Lin, Jingying Ma, Jingyu Wang, Linyan Zhang, Rui Bai, Zelin Tu, Youyou Jiang, Donglin Xie, Yuxi Zhou, Guoli Liu, Shenda Hong
Abstract: Cardiotocography (CTG) is a low-cost, non-invasive fetal health assessment technique used globally, especially in underdeveloped countries. However, it is currently mainly used to identify the fetus's current status (e.g., fetal acidosis or hypoxia), and the potential of CTG in predicting future adverse pregnancy outcomes has not been fully explored. We aim to develop an AI-based model that predicts biological age from CTG time series (named CTGage), then calculate the age gap between CTGage and actual age (named CTGage-gap), and use this gap as a new digital biomarker for future adverse pregnancy outcomes. The CTGage model is developed using 61,140 records from 11,385 pregnant women, collected at Peking University People's Hospital between 2018 and 2022. For model training, a structurally designed 1D convolutional neural network is used, incorporating distribution-aligned augmented regression technology. The CTGage-gap is categorized into five groups: < -21 days (underestimation group), -21 to -7 days, -7 to 7 days (normal group), 7 to 21 days, and > 21 days (overestimation group). We further defined the underestimation group and overestimation group together as the high-risk group. We then compare the incidence of adverse outcomes and maternal diseases across these groups. The average absolute error of the CTGage model is 10.91 days. When comparing the overestimation group with the normal group, premature infants incidence is 5.33% vs. 1.42% (p < 0.05) and gestational diabetes mellitus (GDM) incidence is 31.93% vs. 20.86% (p < 0.05). When comparing the underestimation group with the normal group, low birth weight incidence is 0.17% vs. 0.15% (p < 0.05) and anaemia incidence is 37.51% vs. 34.74% (p < 0.05). Artificial intelligence-derived CTGage can predict the future risk of adverse pregnancy outcomes and hold potential as a novel, non-invasive, and easily accessible digital biomarker.

Paper number 3:
Title: InWaveSR: Topography-Aware Super-Resolution Network for Internal Solitary Waves
Authors: Xinjie Wang, Zhongrui Li, Peng Han, Chunxin Yuan, Jiexin Xu, Zhiqiang Wei, Jie Nie
Abstract: The effective utilization of observational data is frequently hindered by insufficient resolution. To address this problem, we present a new spatio-temporal super-resolution (STSR) model, called InWaveSR. It is built on a deep learning framework with physical restrictions and can efficiently generate high-resolution data from low-resolution input, especially for data featuring internal solitary waves (ISWs). To increase generality and interpretation, the model InWaveSR uses the primitive Navier-Stokes equations as the constraint, ensuring that the output results are physically consistent. In addition, the proposed model incorporates an HF-ResBlock component that combines the attention mechanism and the Fast Fourier Transform (FFT) method to improve the performance of the model in capturing high-frequency characteristics. Simultaneously, in order to enhance the adaptability of the model to complicated bottom topography, an edge sampling and numerical pre-processing method are carried out to optimize the training process. On evaluations using the in-situ observational ISW data, the proposed InWaveSR achieved a peak signal-to-noise ratio (PSNR) score of 36.2, higher than those of the traditional interpolation method and the previous neural network. This highlights its significant superiority over traditional methods, demonstrating its excellent performance and reliability in high-resolution ISW reconstruction.

Paper number 4:
Title: SpeechOp: Inference-Time Task Composition for Generative Speech Processing
Authors: Justin Lovelace, Rithesh Kumar, Jiaqi Su, Ke Chen, Kilian Q Weinberger, Zeyu Jin
Abstract: While generative Text-to-Speech (TTS) systems leverage vast ``in-the-wild" data to achieve remarkable success, speech-to-speech processing tasks like enhancement face data limitations, which lead data-hungry generative approaches to distort speech content and speaker identity. To bridge this gap, we present SpeechOp, a multi-task latent diffusion model that transforms pre-trained TTS models into a universal speech processor capable of performing a wide range of speech tasks and composing them in novel ways at inference time. By adapting a pre-trained TTS model, SpeechOp inherits a rich understanding of natural speech, accelerating training and improving S2S task quality, while simultaneously enhancing core TTS performance. Finally, we introduce Implicit Task Composition (ITC), a novel pipeline where ASR-derived transcripts (e.g., from Whisper) guide SpeechOp's enhancement via our principled inference-time task composition. ITC achieves state-of-the-art content preservation by robustly combining web-scale speech understanding with SpeechOp's generative capabilities. Audio samples are available at this https URL

Paper number 5:
Title: D4PM: A Dual-branch Driven Denoising Diffusion Probabilistic Model with Joint Posterior Diffusion Sampling for EEG Artifacts Removal
Authors: Feixue Shao, Xueyu Liu, Yongfei Wu, Jianbo Lu, Guiying Yan, Weihua Yang
Abstract: Artifact removal is critical for accurate analysis and interpretation of Electroencephalogram (EEG) signals. Traditional methods perform poorly with strong artifact-EEG correlations or single-channel data. Recent advances in diffusion-based generative models have demonstrated strong potential for EEG denoising, notably improving fine-grained noise suppression and reducing over-smoothing. However, existing methods face two main limitations: lack of temporal modeling limits interpretability and the use of single-artifact training paradigms ignore inter-artifact differences. To address these issues, we propose D4PM, a dual-branch driven denoising diffusion probabilistic model that unifies multi-type artifact removal. We introduce a dual-branch conditional diffusion architecture to implicitly model the data distribution of clean EEG and artifacts. A joint posterior sampling strategy is further designed to collaboratively integrate complementary priors for high-fidelity EEG reconstruction. Extensive experiments on two public datasets show that D4PM delivers superior denoising. It achieves new state-of-the-art performance in EOG artifact removal, outperforming all publicly available baselines. The code is available at this https URL.

Paper number 6:
Title: Near-Real-Time Resource Slicing for QoS Optimization in 5G O-RAN using Deep Reinforcement Learning
Authors: Peihao Yan, Jie Lu, Huacheng Zeng, Y. Thomas Hou
Abstract: Open-Radio Access Network (O-RAN) has become an important paradigm for 5G and beyond radio access networks. This paper presents an xApp called xSlice for the Near-Real-Time (Near-RT) RAN Intelligent Controller (RIC) of 5G O-RANs. xSlice is an online learning algorithm that adaptively adjusts MAC-layer resource allocation in response to dynamic network states, including time-varying wireless channel conditions, user mobility, traffic fluctuations, and changes in user demand. To address these network dynamics, we first formulate the Quality-of-Service (QoS) optimization problem as a regret minimization problem by quantifying the QoS demands of all traffic sessions through weighting their throughput, latency, and reliability. We then develop a deep reinforcement learning (DRL) framework that utilizes an actor-critic model to combine the advantages of both value-based and policy-based updating methods. A graph convolutional network (GCN) is incorporated as a component of the DRL framework for graph embedding of RAN data, enabling xSlice to handle a dynamic number of traffic sessions. We have implemented xSlice on an O-RAN testbed with 10 smartphones and conducted extensive experiments to evaluate its performance in realistic scenarios. Experimental results show that xSlice can reduce performance regret by 67% compared to the state-of-the-art solutions. Source code is available on GitHub [1].

Paper number 7:
Title: On Finite- and Fixed-Time Stabilization of Abstract Nonlinear Systems with Well-Posedness Guarantees
Authors: Kamal Fenza, Moussa Labbadi, Mohamed Ouzahra
Abstract: This paper addresses the problem of stabilization for infinite-dimensional systems. In particular, we design nonlinear stabilizers for both linear and nonlinear abstract systems. We focus on two classes of systems: the first class comprises linear abstract systems subject to matched perturbations, while the second class encompasses fully nonlinear abstract systems. Our main objective is to synthesize state-feedback controllers that guarantee finite- or fixed-time stability of the closed-loop system, along with possible estimation of the settling time. For the first class, the presence of persistent perturbations introduces significant challenges in the well-posedness analysis, particularly due to the discontinuous nature of the control law. To address this, we employ maximal monotone operator theory to rigorously establish the existence and uniqueness of solutions, extending classical results from continuous abstract systems. For the second class, which includes nonlinearities, we further show that the proposed feedback law ensures fixed-time stability and well-posedness of the closed-loop system, again using maximal monotone theory. The results provide a unified framework for robust, finite /fixed-time stabilization in the presence of discontinuities and nonlinearities in infinite-dimensional settings.

Paper number 8:
Title: Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior
Authors: Yochai Yemini, Rami Ben-Ari, Sharon Gannot, Ethan Fetaya
Abstract: In this paper, we address the problem of single-microphone speech separation in the presence of ambient noise. We propose a generative unsupervised technique that directly models both clean speech and structured noise components, training exclusively on these individual signals rather than noisy mixtures. Our approach leverages an audio-visual score model that incorporates visual cues to serve as a strong generative speech prior. By explicitly modelling the noise distribution alongside the speech distribution, we enable effective decomposition through the inverse problem paradigm. We perform speech separation by sampling from the posterior distributions via a reverse diffusion process, which directly estimates and removes the modelled noise component to recover clean constituent signals. Experimental results demonstrate promising performance, highlighting the effectiveness of our direct noise modelling approach in challenging acoustic environments.

Paper number 9:
Title: UTOPY: Unrolling Algorithm Learning via Fidelity Homotopy for Inverse Problems
Authors: Roman Jacome, Romario Gualdrón-Hurtado, Leon Suarez-Rodriguez, Henry Arguello
Abstract: Imaging Inverse problems aim to reconstruct an underlying image from undersampled, coded, and noisy observations. Within the wide range of reconstruction frameworks, the unrolling algorithm is one of the most popular due to the synergistic integration of traditional model-based reconstruction methods and modern neural networks, providing an interpretable and highly accurate reconstruction. However, when the sensing operator is highly ill-posed, gradient steps on the data-fidelity term can hinder convergence and degrade reconstruction quality. To address this issue, we propose UTOPY, a homotopy continuation formulation for training the unrolling algorithm. Mainly, this method involves using a well-posed (synthetic) sensing matrix at the beginning of the unrolling network optimization. We define a continuation path strategy to transition smoothly from the synthetic fidelity to the desired ill-posed problem. This strategy enables the network to progressively transition from a simpler, well-posed inverse problem to the more challenging target scenario. We theoretically show that, for projected gradient descent-like unrolling models, the proposed continuation strategy generates a smooth path of unrolling solutions. Experiments on compressive sensing and image deblurring demonstrate that our method consistently surpasses conventional unrolled training, achieving up to 2.5 dB PSNR improvement in reconstruction performance. Source code at

Paper number 10:
Title: Conditional Nearest Level Modulation for Improved Switching Dynamics in Asymmetric Multilevel Converters
Authors: Jinshui Zhang, Angel V Peterchev, Stefan M Goetz
Abstract: Modular multilevel converters have promising applications in clean energy, electric vehicles, and biomedical instrumentation, but need many modules to achieve fine output granularity, particularly of the voltage. Asymmetric multilevel circuits introduce differences in module voltages so that the quantity of output levels grows exponentially with the number of modules. Nearest-level modulation (NLM) is preferred over carrier-based methods in asymmetric circuits for its simplicity. However, the large number of output levels can overwhelm NLM and cause excessive transistor switching on some modules and output voltage spikes. We propose a conditional nearest-level modulation (cNLM) by incorporating mathematical penalty models to regulate switching dynamics. This approach improves output quality and reduces switching rates. Additionally, we present cNLM variations tailored for specific functions, such as enforcing a minimum switching interval. Experimental validation on an asymmetric multilevel prototype demonstrates that cNLM reduces the total output distortion from 66.3% to 15.1% while cutting the switching rate to just 8% of the original NLM.

Paper number 11:
Title: Multi-Channel Differential ASR for Robust Wearer Speech Recognition on Smart Glasses
Authors: Yufeng Yang, Yiteng Huang, Yong Xu, Li Wan, Suwon Shon, Yang Liu, Yifeng Fan, Zhaojun Yang, Olivier Siohan, Yue Liu, Ming Sun, Florian Metze
Abstract: With the growing adoption of wearable devices such as smart glasses for AI assistants, wearer speech recognition (WSR) is becoming increasingly critical to next-generation human-computer interfaces. However, in real environments, interference from side-talk speech remains a significant challenge to WSR and may cause accumulated errors for downstream tasks such as natural language processing. In this work, we introduce a novel multi-channel differential automatic speech recognition (ASR) method for robust WSR on smart glasses. The proposed system takes differential inputs from different frontends that complement each other to improve the robustness of WSR, including a beamformer, microphone selection, and a lightweight side-talk detection model. Evaluations on both simulated and real datasets demonstrate that the proposed system outperforms the traditional approach, achieving up to an 18.0% relative reduction in word error rate.

Paper number 12:
Title: Indoor Airflow Imaging Using Physics-Informed Background-Oriented Schlieren Tomography
Authors: Arjun Teh, Wael H. Ali, Joshua Rapp, Hassan Mansour
Abstract: We develop a framework for non-invasive volumetric indoor airflow estimation from a single viewpoint using background-oriented schlieren (BOS) measurements and physics-informed reconstruction. Our framework utilizes a light projector that projects a pattern onto a target back-wall and a camera that observes small distortions in the light pattern. While the single-view BOS tomography problem is severely ill-posed, our proposed framework addresses this using: (1) improved ray tracing, (2) a physics-based light rendering approach and loss formulation, and (3) a physics-based regularization using a physics-informed neural network (PINN) to ensure that the reconstructed airflow is consistent with the governing equations for buoyancy-driven flows.

Paper number 13:
Title: Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces
Authors: Sriram V.C. Nallani, Gautham Ramachandran, Sahil S. Shah
Abstract: Brain-Computer Interfaces face challenges from neural signal instability and memory constraints for real-time implantable applications. We introduce an online SNN decoder using local three-factor learning rules with dual-timescale eligibility traces that avoid backpropagation through time while maintaining competitive performance. Our approach combines error-modulated Hebbian updates, fast/slow trace consolidation, and adaptive learning rate control, requiring only O(1) memory versus O(T) for BPTT methods. Evaluations on two primate datasets achieve comparable decoding accuracy (Pearson $R \geq 0.63$ Zenodo, $R \geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than BPTT-trained SNNs. Closed-loop simulations with synthetic neural populations demonstrate adaptation to neural disruptions and learning from scratch without offline calibration. This work enables memory-efficient, continuously adaptive neural decoding suitable for resource-constrained implantable BCI systems.

Paper number 14:
Title: Secure Blind Graph Signal Recovery and Adversary Detection Using Smoothness Maximization
Authors: Mahdi Shamsi, Hadi Zayyani, Hasan Abu Hilal, Mohammad Salman
Abstract: In this letter, we propose a secure blind Graph Signal Recovery (GSR) algorithm that can detect adversary nodes. Some unknown adversaries are assumed to be injecting false data at their respective nodes in the graph. The number and location of adversaries are not known in advance and the goal is to recover the graph signal in the presence of measurement noise and False Data Injection (FDI) caused by the adversaries. Consequently, the proposed algorithm would be a perfect candidate to solve this challenging problem. Moreover, due to the presence of malicious nodes, the proposed method serves as a secure GSR algorithm. For adversary detection, a statistical measure based on differential smoothness is used. Specifically, the difference between the current observed smoothness and the average smoothness excluding the corresponding node. This genuine statistical approach leads to an effective and low-complexity adversary detector. In addition, following malicious node detection, the GSR is performed using a variant of smoothness maximization, which is solved efficiently as a fractional optimization problem using a Dinkelbach's algorithm. Analysis of the detector, which determines the optimum threshold of the detector is also presented. Simulation results show a significant improvement of the proposed method in signal recovery compared to the median GSR algorithm and other competing methods.

Paper number 15:
Title: Age of Information Aided Intelligent Grant-Free Massive Access for Heterogeneous mMTC Traffic
Authors: Zhongwen Sun, Wei Chen, Yuxuan Sun, Bo Ai
Abstract: With the arrival of 6G, the Internet of Things (IoT) traffic is becoming more and more complex and diverse. To meet the diverse service requirements of IoT devices, massive machine-type communications (mMTC) becomes a typical scenario, and more recently, grant-free random access (GF-RA) presents a promising direction due to its low signaling overhead. However, existing GF-RA research primarily focuses on improving the accuracy of user detection and data recovery, without considering the heterogeneity of traffic. In this paper, we investigate a non-orthogonal GF-RA scenario where two distinct types of traffic coexist: event-triggered traffic with alarm devices (ADs), and status update traffic with monitor devices (MDs). The goal is to simultaneously achieve high detection success rates for ADs and high information timeliness for MDs. First, we analyze the age-based random access scheme and optimize the access parameters to minimize the average age of information (AoI) of MDs. Then, we design an age-based prior information aided autoencoder (A-PIAAE) to jointly detect active devices, together with learned pilots used in GF-RA to reduce interference between non-orthogonal pilots. In the decoder, an Age-based Learned Iterative Shrinkage Thresholding Algorithm (LISTA-AGE) utilizing the AoI of MDs as the prior information is proposed to enhance active user detection. Theoretical analysis is provided to demonstrate the proposed A-PIAAE has better convergence performance. Experiments demonstrate the advantage of the proposed method in reducing the average AoI of MDs and improving the successful detection rate of ADs.

Paper number 16:
Title: Geometry-Aware Decentralized Sinkhorn for Wasserstein Barycenters
Authors: Ali Baheri, David Millard, Alireza Vahid
Abstract: Distributed systems require fusing heterogeneous local probability distributions into a global summary over sparse and unreliable communication networks. Traditional consensus algorithms, which average distributions in Euclidean space, ignore their inherent geometric structure, leading to misleading results. Wasserstein barycenters offer a geometry-aware alternative by minimizing optimal transport costs, but their entropic approximations via the Sinkhorn algorithm typically require centralized coordination. This paper proposes a fully decentralized Sinkhorn algorithm that reformulates the centralized geometric mean as an arithmetic average in the log-domain, enabling approximation through local gossip protocols. Agents exchange log-messages with neighbors, interleaving consensus phases with local updates to mimic centralized iterations without a coordinator. To optimize bandwidth, we integrate event-triggered transmissions and b-bit quantization, providing tunable trade-offs between accuracy and communication while accommodating asynchrony and packet loss. Under mild assumptions, we prove convergence to a neighborhood of the centralized entropic barycenter, with bias linearly dependent on consensus tolerance, trigger threshold, and quantization error. Complexity scales near-linearly with network size. Simulations confirm near-centralized accuracy with significantly fewer messages, across various topologies and conditions.

Paper number 17:
Title: Radiolunadiff: Estimation of wireless network signal strength in lunar terrain
Authors: Paolo Torrado, Anders Pearson, Jason Klein, Alexander Moscibroda, Joshua Smith
Abstract: In this paper, we propose a novel physics-informed deep learning architecture for predicting radio maps over lunar terrain. Our approach integrates a physics-based lunar terrain generator, which produces realistic topography informed by publicly available NASA data, with a ray-tracing engine to create a high-fidelity dataset of radio propagation scenarios. Building on this dataset, we introduce a triplet-UNet architecture, consisting of two standard UNets and a diffusion network, to model complex propagation effects. Experimental results demonstrate that our method outperforms existing deep learning approaches on our terrain dataset across various metrics.

Paper number 18:
Title: Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation
Authors: Miseul Kim, Soo Jin Park, Kyungguen Byun, Hyeon-Kyeong Shin, Sunkuk Moon, Shuhua Zhang, Erik Visser
Abstract: Speaker diarization systems often struggle with high intrinsic intra-speaker variability, such as shifts in emotion, health, or content. This can cause segments from the same speaker to be misclassified as different individuals, for example, when one raises their voice or speaks faster during conversation. To address this, we propose a style-controllable speech generation model that augments speech across diverse styles while preserving the target speaker's identity. The proposed system starts with diarized segments from a conventional diarizer. For each diarized segment, it generates augmented speech samples enriched with phonetic and stylistic diversity. And then, speaker embeddings from both the original and generated audio are blended to enhance the system's robustness in grouping segments with high intrinsic intra-speaker variability. We validate our approach on a simulated emotional speech dataset and the truncated AMI dataset, demonstrating significant improvements, with error rate reductions of 49% and 35% on each dataset, respectively.

Paper number 19:
Title: Enhancing Situational Awareness in Wearable Audio Devices Using a Lightweight Sound Event Localization and Detection System
Authors: Jun-Wei Yeow, Ee-Leng Tan, Santi Peksi, Zhen-Ting Ong, Woon-Seng Gan
Abstract: Wearable audio devices with active noise control (ANC) enhance listening comfort but often at the expense of situational awareness. However, this auditory isolation may mask crucial environmental cues, posing significant safety risks. To address this, we propose an environmental intelligence framework that combines Acoustic Scene Classification (ASC) with Sound Event Localization and Detection (SELD). Our system first employs a lightweight ASC model to infer the current environment. The scene prediction then dynamically conditions a SELD network, tuning its sensitivity to detect and localize sounds that are most salient to the current context. On simulated headphone data, the proposed ASC-conditioned SELD system demonstrates improved spatial intelligence over a conventional baseline. This work represents a crucial step towards creating intelligent hearables that can deliver crucial environmental information, fostering a safer and more context-aware listening experience.

Paper number 20:
Title: Aligning Audio Captions with Human Preferences
Authors: Kartik Hegde, Rehana Mahfuz, Yinyi Guo, Erik Visser
Abstract: Current audio captioning systems rely heavily on supervised learning with paired audio-caption datasets, which are expensive to curate and may not reflect human preferences in real-world scenarios. To address this limitation, we propose a preference-aligned audio captioning framework based on Reinforcement Learning from Human Feedback (RLHF). To effectively capture nuanced human preferences, we train a Contrastive Language-Audio Pretraining (CLAP)-based reward model using human-labeled pairwise preference data. This reward model is integrated into a reinforcement learning framework to fine-tune any baseline captioning system without relying on ground-truth caption annotations. Extensive human evaluations across multiple datasets show that our method produces captions preferred over those from baseline models, particularly in cases where the baseline models fail to provide correct and natural captions. Furthermore, our framework achieves performance comparable to supervised approaches with ground-truth data, demonstrating its effectiveness in aligning audio captioning with human preferences and its scalability in real-world scenarios.

Paper number 21:
Title: Task-Oriented Learning for Automatic EEG Denoising
Authors: Tian-Yu Xiang, Zheng Lei, Xiao-Hu Zhou, Xiao-Liang Xie, Shi-Qi Liu, Mei-Jiang Gui, Hong-Yun Ou, Xin-Zheng Huang, Xin-Yi Fu, Zeng-Guang Hou
Abstract: Electroencephalography (EEG) denoising methods typically depend on manual intervention or clean reference signals. This work introduces a task-oriented learning framework for automatic EEG denoising that uses only task labels without clean reference signals. EEG recordings are first decomposed into components based on blind source separation (BSS) techniques. Then, a learning-based selector assigns a retention probability to each component, and the denoised signal is reconstructed as a probability-weighted combination. A downstream proxy-task model evaluates the reconstructed signal, with its task loss supervising the selector in a collaborative optimization scheme that relies solely on task labels, eliminating the need for clean EEG references. Experiments on three datasets spanning two paradigms and multiple noise conditions show consistent gains in both task performance (accuracy: $2.56\%\uparrow$) and standard signal-quality metrics (signal-to-noise-ratio: $0.82$\,dB\,$\uparrow$). Further analyses demonstrate that the task-oriented learning framework is algorithm-agnostic, as it accommodates diverse decomposition techniques and network backbones for both the selector and the proxy model. These promising results indicate that the proposed task-oriented learning framework is a practical EEG denoising solution with potential implications for neuroscience research and EEG-based interaction systems.

Paper number 22:
Title: SpeechMLC: Speech Multi-label Classification
Authors: Miseul Kim, Seyun Um, Hyeonjin Cha, Hong-goo Kang
Abstract: In this paper, we propose a multi-label classification framework to detect multiple speaking styles in a speech sample. Unlike previous studies that have primarily focused on identifying a single target style, our framework effectively captures various speaker characteristics within a unified structure, making it suitable for generalized human-computer interaction applications. The proposed framework integrates cross-attention mechanisms within a transformer decoder to extract salient features associated with each target label from the input speech. To mitigate the data imbalance inherent in multi-label speech datasets, we employ a data augmentation technique based on a speech generation model. We validate our model's effectiveness through multiple objective evaluations on seen and unseen corpora. In addition, we provide an analysis of the influence of human perception on classification accuracy by considering the impact of human labeling agreement on model performance.

Paper number 23:
Title: DAIEN-TTS: Disentangled Audio Infilling for Environment-Aware Text-to-Speech Synthesis
Authors: Ye-Xin Lu, Yu Gu, Kun Wei, Hui-Peng Du, Yang Ai, Zhen-Hua Ling
Abstract: This paper presents DAIEN-TTS, a zero-shot text-to-speech (TTS) framework that enables ENvironment-aware synthesis through Disentangled Audio Infilling. By leveraging separate speaker and environment prompts, DAIEN-TTS allows independent control over the timbre and the background environment of the synthesized speech. Built upon F5-TTS, the proposed DAIEN-TTS first incorporates a pretrained speech-environment separation (SES) module to disentangle the environmental speech into mel-spectrograms of clean speech and environment audio. Two random span masks of varying lengths are then applied to both mel-spectrograms, which, together with the text embedding, serve as conditions for infilling the masked environmental mel-spectrogram, enabling the simultaneous continuation of personalized speech and time-varying environmental audio. To further enhance controllability during inference, we adopt dual class-free guidance (DCFG) for the speech and environment components and introduce a signal-to-noise ratio (SNR) adaptation strategy to align the synthesized speech with the environment prompt. Experimental results demonstrate that DAIEN-TTS generates environmental personalized speech with high naturalness, strong speaker similarity, and high environmental fidelity.

Paper number 24:
Title: Secure Short-Packet Communications for RIS-Assisted AAV Networks
Authors: Huiling Liu, Junshan Luo, Shilian Wang, Fanggang Wang, Theodoros A. Tsiftsis, Symeon Chatzinotas
Abstract: Advancements toward 6G have intensified demands for ultra-reliable low-latency communication, positioning shortpacket communications as a critical technology for autonomous aerial vehicle (AAV) networks. However, the open broadcast nature introduces significant security vulnerabilities. Although physical-layer security offers a low-complexity solution by exploiting wireless channel randomness, the AAV communication performance severely degrades in weak-coverage or non-line-of sight scenarios. To overcome these limitations, this paper proposes a short-packet communications framework for AAV networks that leverages reconfigurable intelligent surfaces (RIS) with the aim of extending coverage and enhancing secrecy capabilities. Analytical frameworks are developed to evaluate the average secrecy throughput (AST) in finite blocklength constraints for both external and internal avesdropping scenarios, which incorporates non-orthogonal multiple access with imperfect successive interference cancellation. Asymptotic approximations of AST are derived as transmit power approaches infinity. Furthermore, we formulate a blocklength optimization problem to maximize the AST, effectively resolving the trade-offs among delay, reliability, and secrecy. Extensive simulations validate the analytical frameworks, which reveal that large-scale RIS deployment significantly boosts AST, and the power allocation coefficient exhibits dual effects in the internal eavesdropping scenario. These observations provide useful insights for designing reliable and secure lowlatency AAV communications systems.

Paper number 25:
Title: Mitigating the Impact of Location Uncertainty on Radio Map-Based Predictive Rate Selection via Noisy-Input Gaussian Process
Authors: Koya Sato
Abstract: This paper proposes a predictive rate-selection framework based on Gaussian process (GP)-based radio map construction that is robust to location uncertainty. Radio maps are a promising tool for improving communication efficiency in 6G networks. Although they enable the design of location-based maximum transmission rates by exploiting statistical channel information, existing discussions often assume perfect (i.e., noiseless) location information during channel sensing. Since such information must be obtained from positioning systems such as global navigation satellite systems, it inevitably involves positioning errors; this location uncertainty can degrade the reliability of radio map-based wireless systems. To mitigate this issue, we introduce the noisy-input GP (NIGP), which treats location noise as additional output noise by applying a Taylor approximation of the function of interest. Numerical results demonstrate that the proposed NIGP-based design achieves more reliable transmission-rate selection than pure GP and yields higher throughput than path loss-based rate selection.

Paper number 26:
Title: LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines
Authors: Ziwei Huang, Shiliang Lu, Lu Bai, Xuesong Cai, Xiang Cheng
Abstract: Based on Synesthesia of Machines (SoM), a large language model (LLM) is adapted for multipath generation (LLM4MG) for the first time. Considering a typical sixth-generation (6G) vehicle-to-infrastructure (V2I) scenario, a new multi-modal sensing-communication dataset is constructed, named SynthSoM-V2I, including channel multipath information, millimeter wave (mmWave) radar sensory data, RGB-D images, and light detection and ranging (LiDAR) point clouds. Based on the SynthSoM-V2I dataset, the proposed LLM4MG leverages Large Language Model Meta AI (LLaMA) 3.2 for multipath generation via multi-modal sensory data. The proposed LLM4MG aligns the multi-modal feature space with the LLaMA semantic space through feature extraction and fusion networks. To further achieve general knowledge transfer from the pre-trained LLaMA for multipath generation via multi-modal sensory data, the low-rank adaptation (LoRA) parameter-efficient fine-tuning and propagation-aware prompt engineering are exploited. Simulation results demonstrate that the proposed LLM4MG outperforms conventional deep learning-based methods in terms of line-of-sight (LoS)/non-LoS (NLoS) classification with accuracy of 92.76%, multipath power/delay generation precision with normalized mean square error (NMSE) of 0.099/0.032, and cross-vehicular traffic density (VTD), cross-band, and cross-scenario generalization. The utility of the proposed LLM4MG is validated by real-world generalization. The necessity of high-precision multipath generation for system design is also demonstrated by channel capacity comparison.

Paper number 27:
Title: Subjective Evaluation of Low Distortion Coded Light Fields with View Synthesis
Authors: Daniela Saraiva, Joao Prazeres, Manuela Pereira, Antonio M. G. Pinheiro
Abstract: Light field technology is a powerful imaging method that captures both the intensity and direction of light rays in a scene, enabling the reconstruction of 3D information and supporting a range of unique applications. However, light fields produce vast amounts of data, making efficient compression essential for their practical use. View synthesis plays a key role in light field technology by enabling the generation of new views, yet its interaction with compression has not been fully explored. In this work, a subjective analysis of the effect of view synthesis on light field compression is conducted. To achieve this, a sparsely sampled light field is created by dropping views from an original light field. Both light fields are then encoded using JPEG Pleno and VVC. View synthesis is then applied to the compressed sampled light field to reconstruct the same number of views as the original. The subjective evaluation follows the proposed JPEG AIC-3 test methodology designed to assess the quality of high-fidelity compressed images. This test consists of two test stimuli displayed side-by-side, each alternating between an original and a coded view, creating a flicker effect on both sides. The user must choose which side has the stronger flicker and, therefore, the lower quality. Using these subjective results, a selection of metrics is validated.

Paper number 28:
Title: Efficient Solutions for Mitigating Initialization Bias in Unsupervised Self-Adaptive Auditory Attention Decoding
Authors: Yuanyuan Yao, Simon Geirnaert, Tinne Tuytelaars, Alexander Bertrand
Abstract: Decoding the attended speaker in a multi-speaker environment from electroencephalography (EEG) has attracted growing interest in recent years, with neuro-steered hearing devices as a driver application. Current approaches typically rely on ground-truth labels of the attended speaker during training, necessitating calibration sessions for each user and each EEG set-up to achieve optimal performance. While unsupervised self-adaptive auditory attention decoding (AAD) for stimulus reconstruction has been developed to eliminate the need for labeled data, it suffers from an initialization bias that can compromise performance. Although an unbiased variant has been proposed to address this limitation, it introduces substantial computational complexity that scales with data size. This paper presents three computationally efficient alternatives that achieve comparable performance, but with a significantly lower and constant computational cost. The code for the proposed algorithms is available at this https URL.

Paper number 29:
Title: MELA-TTS: Joint transformer-diffusion model with representation alignment for speech synthesis
Authors: Keyu An, Zhiyu Zhang, Changfeng Gao, Yabin Li, Zhendong Peng, Haoxu Wang, Zhihao Du, Han Zhao, Zhifu Gao, Xiangang Li
Abstract: This work introduces MELA-TTS, a novel joint transformer-diffusion framework for end-to-end text-to-speech synthesis. By autoregressively generating continuous mel-spectrogram frames from linguistic and speaker conditions, our architecture eliminates the need for speech tokenization and multi-stage processing pipelines. To address the inherent difficulties of modeling continuous features, we propose a representation alignment module that aligns output representations of the transformer decoder with semantic embeddings from a pretrained ASR encoder during training. This mechanism not only speeds up training convergence, but also enhances cross-modal coherence between the textual and acoustic domains. Comprehensive experiments demonstrate that MELA-TTS achieves state-of-the-art performance across multiple evaluation metrics while maintaining robust zero-shot voice cloning capabilities, in both offline and streaming synthesis modes. Our results establish a new benchmark for continuous feature generation approaches in TTS, offering a compelling alternative to discrete-token-based paradigms.

Paper number 30:
Title: Acoustic Simulation Framework for Multi-channel Replay Speech Detection
Authors: Michael Neri, Tuomas Virtanen
Abstract: Replay speech attacks pose a significant threat to voice-controlled systems, especially in smart environments where voice assistants are widely deployed. While multi-channel audio offers spatial cues that can enhance replay detection robustness, existing datasets and methods predominantly rely on single-channel recordings. In this work, we introduce an acoustic simulation framework designed to simulate multi-channel replay speech configurations using publicly available resources. Our setup models both genuine and spoofed speech across varied environments, including realistic microphone and loudspeaker impulse responses, room acoustics, and noise conditions. The framework employs measured loudspeaker directionalities during the replay attack to improve the realism of the simulation. We define two spoofing settings, which simulate whether a reverberant or an anechoic speech is used in the replay scenario, and evaluate the impact of omnidirectional and diffuse noise on detection performance. Using the state-of-the-art M-ALRAD model for replay speech detection, we demonstrate that synthetic data can support the generalization capabilities of the detector across unseen enclosures.

Paper number 31:
Title: Comparative Performance Analysis of Different Hybrid NOMA Schemes
Authors: Ning Wang, Chenyu Zhang, Yanshi Sun, Minghui Min, Shiyin Li
Abstract: Hybrid non-orthogonal multiple access (H-NOMA), which combines the advantages of pure NOMA and conventional OMA organically, has emerged as a highly promising multiple access technology for future wireless networks. Recent studies have proposed various H-NOMA systems by employing different successive interference cancellation (SIC) methods for the NOMA transmission phase. However, existing analyses typically assume a fixed channel gain order between paired users, despite the fact that channel coefficients follow random distribution, leading to their magnitude relationships inherently stochastic and time varying. This paper analyzes the performance of three H-NOMA schemes under stochastic channel gain ordering: a) fixed order SIC (FSIC) aided H-NOMA scheme; b) hybrid SIC with non-power adaptation (HSIC-NPA) aided H-NOMA scheme; c) hybrid SIC with power adaptation (HSIC-PA) aided H-NOMA scheme. Theoretical analysis derives closed-form expressions for the probability that H-NOMA schemes underperform conventional OMA. Asymptotic results in the high signal-to-noise ratio (SNR) regime are also developed. Simulation results validate our analysis and demonstrate the performance of H-NOMA schemes across different SNR scenarios, providing a theoretical foundation for the deployment of H-NOMA in next-generation wireless systems.

Paper number 32:
Title: Sampling Method for Generalized Graph Signals with Pre-selected Vertices via DC Optimization
Authors: Keitaro Yamashita, Kazuki Naganuma, Shunsuke Ono
Abstract: This paper proposes a method for vertex-wise flexible sampling of a broad class of graph signals, designed to attain the best possible recovery based on the generalized sampling theory. This is achieved by designing a sampling operator by an optimization problem, which is inherently non-convex, as the best possible recovery imposes a rank constraint. An existing method for vertex-wise flexible sampling is able to control the number of active vertices but cannot incorporate prior knowledge of mandatory or forbidden vertices. To address these challenges, we formulate the operator design as a problem that handles a constraint of the number of active vertices and prior knowledge on specific vertices for sampling, mandatory inclusion or exclusion. We transformed this constrained problem into a difference-of-convex (DC) optimization problem by using the nuclear norm and a DC penalty for vertex selection. To solve this, we develop a convergent solver based on the general double-proximal gradient DC algorithm. The effectiveness of our method is demonstrated through experiments on various graph signal models, including real-world data, showing superior performance in the recovery accuracy by comparing to existing methods.

Paper number 33:
Title: AmbiDrop: Array-Agnostic Speech Enhancement Using Ambisonics Encoding and Dropout-Based Learning
Authors: Michael Tatarjitzky, Boaz Rafaely
Abstract: Multichannel speech enhancement leverages spatial cues to improve intelligibility and quality, but most learning-based methods rely on specific microphone array geometry, unable to account for geometry changes. To mitigate this limitation, current array-agnostic approaches employ large multi-geometry datasets but may still fail to generalize to unseen layouts. We propose AmbiDrop (Ambisonics with Dropouts), an Ambisonics-based framework that encodes arbitrary array recordings into the spherical harmonics domain using Ambisonics Signal Matching (ASM). A deep neural network is trained on simulated Ambisonics data, combined with channel dropout for robustness against array-dependent encoding errors, therefore omitting the need for a diverse microphone array database. Experiments show that while the baseline and proposed models perform similarly on the training arrays, the baseline degrades on unseen arrays. In contrast, AmbiDrop consistently improves SI-SDR, PESQ, and STOI, demonstrating strong generalization and practical potential for array-agnostic speech enhancement.

Paper number 34:
Title: Hint: hierarchical inter-frame correlation for one-shot point cloud sequence compression
Authors: Yuchen Gao, Qi Zhang
Abstract: Deep learning has demonstrated strong capability in compressing point clouds. Within this area, entropy modeling for lossless compression is widely investigated. However, most methods rely solely on parent orsibling contexts and level-wise autoregression, which suffers from decoding latency on the order of 10 to 100 seconds. We propose HINT, a method that integrates temporal and spatial correlation for sequential point cloud compression. Specifically, it first uses a two stage temporal feature extraction: (i) a parent-level existence map and (ii) a child-level neighborhood lookup in the previous frame. These cues are fused with the spatial features via elementwise addition and encoded with a group-wise strategy. Experimental results show that HINT achieves encoding and decoding time at 105 ms and 140 ms, respectively, equivalent to 49.6x and 21.6x acceleration in comparison with G-PCC, while achieving up to bit rate reduction of 43.6%, in addition, consistently outperforming over the strong spatial only baseline (RENO).

Paper number 35:
Title: Hybrid Table-Assisted and RL-Based Dynamic Routing for NGSO Satellite Networks
Authors: Flor Ortiz, Eva Lagunas
Abstract: This letter investigates dynamic routing in Next-Generation Satellite Orbit (NGSO) constellations and proposes a hybrid strategy that combines precomputed routing tables with a Deep Q-Learning (DQL) fallback mechanism. While fully RL-based schemes offer adaptability to topology dynamics, they often suffer from high complexity, long convergence times, and unstable performance under heavy traffic. In contrast, the proposed framework exploits deterministic table lookups under nominal conditions and selectively activates the DQL agent only when links become unavailable or congested. Simulation results in large-scale NGSO networks show that the hybrid approach consistently achieves higher packet delivery ratio, lower end-to-end delay, shorter average hop count, and improved throughput compared to a pure RL baseline. These findings highlight the effectiveness of hybrid routing as a scalable and resilient solution for delay-sensitive satellite broadband services

Paper number 36:
Title: Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance
Authors: Francisco Messina, Francesca Ronchini, Luca Comanducci, Paolo Bestagini, Fabio Antonacci
Abstract: A persistent challenge in generative audio models is data replication, where the model unintentionally generates parts of its training data during inference. In this work, we address this issue in text-to-audio diffusion models by exploring the use of anti-memorization strategies. We adopt Anti-Memorization Guidance (AMG), a technique that modifies the sampling process of pre-trained diffusion models to discourage memorization. Our study explores three types of guidance within AMG, each designed to reduce replication while preserving generation quality. We use Stable Audio Open as our backbone, leveraging its fully open-source architecture and training dataset. Our comprehensive experimental analysis suggests that AMG significantly mitigates memorization in diffusion-based text-to-audio generation without compromising audio fidelity or semantic alignment.

Paper number 37:
Title: SynParaSpeech: Automated Synthesis of Paralinguistic Datasets for Speech Generation and Understanding
Authors: Bingsong Bai, Qihang Lu, Wenbing Yang, Zihan Sun, YueRan Hou, Peilei Jia, Songbai Pu, Ruibo Fu, Yingming Gao, Ya Li, Jun Gao
Abstract: Paralinguistic sounds, like laughter and sighs, are crucial for synthesizing more realistic and engaging speech. However, existing methods typically depend on proprietary datasets, while publicly available resources often suffer from incomplete speech, inaccurate or missing timestamps, and limited real-world relevance. To address these problems, we propose an automated framework for generating large-scale paralinguistic data and apply it to construct the SynParaSpeech dataset. The dataset comprises 6 paralinguistic categories with 118.75 hours of data and precise timestamps, all derived from natural conversational speech. Our contributions lie in introducing the first automated method for constructing large-scale paralinguistic datasets and releasing the SynParaSpeech corpus, which advances speech generation through more natural paralinguistic synthesis and enhances speech understanding by improving paralinguistic event detection. The dataset and audio samples are available at this https URL.

Paper number 38:
Title: Discrete optimal transport is a strong audio adversarial attack
Authors: Anton Selitskiy, Akib Shahriyar, Jishnuraj Prakasan
Abstract: In this paper, we show that discrete optimal transport (DOT) is an effective black-box adversarial attack against modern audio anti-spoofing countermeasures (CMs). Our attack operates as a post-processing, distribution-alignment step: frame-level WavLM embeddings of generated speech are aligned to an unpaired bona fide pool via entropic OT and a top-$k$ barycentric projection, then decoded with a neural vocoder. Evaluated on ASVspoof2019 and ASVspoof5 with AASIST baselines, DOT yields consistently high equal error rate (EER) across datasets and remains competitive after CM fine-tuning, outperforming several conventional attacks in cross-dataset transfer. Ablation analysis highlights the practical impact of vocoder overlap. Results indicate that distribution-level alignment is a powerful and stable attack surface for deployed CMs.

Paper number 39:
Title: BabyHuBERT: Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings
Authors: Théo Charlot, Tarek Kunze, Maxime Poli, Alejandrina Cristia, Emmanuel Dupoux, Marvin Lavechin
Abstract: Child-centered long-form recordings are essential for studying early language development, but existing speech models trained on clean adult data perform poorly due to acoustic and linguistic differences. We introduce BabyHuBERT, the first self-supervised speech representation model trained on 13,000 hours of multilingual child-centered long-form recordings spanning over 40 languages. We evaluate BabyHuBERT on speaker segmentation, identifying when target children speak versus female adults, male adults, or other children -- a fundamental preprocessing step for analyzing naturalistic language experiences. BabyHuBERT achieves F1-scores from 52.1% to 74.4% across six diverse datasets, consistently outperforming W2V2-LL4300 (trained on English long-forms) and standard HuBERT (trained on clean adult speech). Notable improvements include 13.2 absolute F1 points over HuBERT on Vanuatu and 15.9 points on Solomon Islands corpora, demonstrating effectiveness on underrepresented languages. By sharing code and models, BabyHuBERT serves as a foundation model for child speech research, enabling fine-tuning on diverse downstream tasks.

Paper number 40:
Title: Transfer Learning for Paediatric Sleep Apnoea Detection Using Physiology-Guided Acoustic Models
Authors: Chaoyue Niu, Veronica Rowe, Guy J. Brown, Heather Elphick, Heather Kenyon, Lowri Thomas, Sam Johnson, Ning Ma
Abstract: Paediatric obstructive sleep apnoea (OSA) is clinically significant yet difficult to diagnose, as children poorly tolerate sensor-based polysomnography. Acoustic monitoring provides a non-invasive alternative for home-based OSA screening, but limited paediatric data hinders the development of robust deep learning approaches. This paper proposes a transfer learning framework that adapts acoustic models pretrained on adult sleep data to paediatric OSA detection, incorporating SpO2-based desaturation patterns to enhance model training. Using a large adult sleep dataset (157 nights) and a smaller paediatric dataset (15 nights), we systematically evaluate (i) single- versus multi-task learning, (ii) encoder freezing versus full fine-tuning, and (iii) the impact of delaying SpO2 labels to better align them with the acoustics and capture physiologically meaningful features. Results show that fine-tuning with SpO2 integration consistently improves paediatric OSA detection compared with baseline models without adaptation. These findings demonstrate the feasibility of transfer learning for home-based OSA screening in children and offer its potential clinical value for early diagnosis.

Paper number 41:
Title: Undersampled Phase Retrieval with Image Priors
Authors: Stanislas Ducotterd, Zhiyuan Hu, Michael Unser, Jonathan Dong
Abstract: Phase retrieval seeks to recover a complex signal from amplitude-only measurements, a challenging nonlinear inverse problem. Current theory and algorithms often ignore signal priors. By contrast, we evaluate here a variety of image priors in the context of severe undersampling with structured random Fourier measurements. Our results show that those priors significantly improve reconstruction, allowing accurate reconstruction even below the weak recovery threshold.

Paper number 42:
Title: On Uniformly Time-Varying Control Barrier Functions
Authors: Adrian Wiltz, Dimos V. Dimarogonas
Abstract: This paper investigates the design of a subclass of time-varying Control Barrier Functions (CBFs), specifically that of uniformly time-varying CBFs. Leveraging the fact that CBFs encode a system's dynamic capabilities relative to a state constraint, we decouple the design of uniformly time-varying CBFs into a time-invariant and a time-varying component. We characterize the subclass of time-invariant CBFs that yield a uniformly time-varying CBF when combined with a specific type of time-varying function. A detailed analysis of those conditions under which the time-varying function preserves the CBF property of the time-invariant component is provided. These conditions allow for selecting the time-varying function such that diverse variations in the state constraints can be captured while avoiding the redesign of the time-invariant component. From a technical point of view, the analysis requires the derivation of novel relations for comparison functions, not previously reported in the literature. We further relax the requirements on the time-varying function, showing that forward invariance can still be ensured even when the uniformly time-varying value function does not strictly constitute a CBF. Finally, we discuss how existing CBF construction methods can be applied to design suitable time-invariant CBFs, and demonstrate the effectiveness of the approach through detailed numerical examples.

Paper number 43:
Title: Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators
Authors: Deijany Rodriguez Linares, Oksana Moryakova, Håkan Johansson
Abstract: This letter presents a novel approach for \mbox{efficiently} computing time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$ using cascaded accumulators. Traditional direct computation requires $K{\times}N$ general multiplications, which become prohibitive for large $N$, while alternative strategies based on lookup tables or signal reversal require storing entire data blocks. By exploiting accumulator properties, the proposed method eliminates the need for such storage and reduces the multiplicative cost to only $K{+}1$ constant multiplications, enabling efficient real-time implementation. The approach is particularly useful when such sums need to be efficiently computed in sample-by-sample processing systems.

Paper number 44:
Title: A Nonlinear Scaling-based Design of Control Lyapunov-barrier Function for Relative Degree 2 Case and its Application to Safe Feedback Linearization
Authors: Haechan Pyon, Gyunghoon Park
Abstract: In this paper we address the problem of control Lyapunov-barrier function (CLBF)-based safe stabilization for a class of nonlinear control-affine systems. A difficulty may arise for the case when a constraint has the relative degree larger than 1, at which computing a proper CLBF is not straightforward. Instead of adding an (possibly non-existent) control barrier function (CBF) to a control Lyapunov function (CLF), our key idea is to simply scale the value of the CLF on the unsafe set, by utilizing a sigmoid function as a scaling factor. We provide a systematic design method for the CLBF, with a detailed condition for the parameters of the sigmoid function to satisfy. It is also seen that the proposed approach to the CLBF design can be applied to the problem of task-space control for a planar robot manipulator with guaranteed safety, for which a safe feedback linearization-based controller is presented.

Paper number 45:
Title: From Who Said What to Who They Are: Modular Training-free Identity-Aware LLM Refinement of Speaker Diarization
Authors: Yu-Wen Chen, William Ho, Maxim Topaz, Julia Hirschberg, Zoran Kostic
Abstract: Speaker diarization (SD) struggles in real-world scenarios due to dynamic environments and unknown speaker counts. SD is rarely used alone and is often paired with automatic speech recognition (ASR), but non-modular methods that jointly train on domain-specific data have limited flexibility. Moreover, many applications require true speaker identities rather than SD's pseudo labels. We propose a training-free modular pipeline combining off-the-shelf SD, ASR, and a large language model (LLM) to determine who spoke, what was said, and who they are. Using structured LLM prompting on reconciled SD and ASR outputs, our method leverages semantic continuity in conversational context to refine low-confidence speaker labels and assigns role identities while correcting split speakers. On a real-world patient-clinician dataset, our approach achieves a 29.7% relative error reduction over baseline reconciled SD and ASR. It enhances diarization performance without additional training and delivers a complete pipeline for SD, ASR, and speaker identity detection in practical applications.

Paper number 46:
Title: Real-Time Streaming Mel Vocoding with Generative Flow Matching
Authors: Simon Welker, Tal Peer, Timo Gerkmann
Abstract: The task of Mel vocoding, i.e., the inversion of a Mel magnitude spectrogram to an audio waveform, is still a key component in many text-to-speech (TTS) systems today. Based on generative flow matching, our prior work on generative STFT phase retrieval (DiffPhase), and the pseudoinverse operator of the Mel filterbank, we develop MelFlow, a streaming-capable generative Mel vocoder for speech sampled at 16 kHz with an algorithmic latency of only 32 ms and a total latency of 48 ms. We show real-time streaming capability at this latency not only in theory, but in practice on a consumer laptop GPU. Furthermore, we show that our model achieves substantially better PESQ and SI-SDR values compared to well-established not streaming-capable baselines for Mel vocoding including HiFi-GAN.

Paper number 47:
Title: Listening, Imagining \& Refining: A Heuristic Optimized ASR Correction Framework with LLMs
Authors: Yutong Liu, Ziyue Zhang, Yongbin Yu, Xiangxiang Wang, Yuqing Cai, Nyima Tashi
Abstract: Automatic Speech Recognition (ASR) systems remain prone to errors that affect downstream applications. In this paper, we propose LIR-ASR, a heuristic optimized iterative correction framework using LLMs, inspired by human auditory perception. LIR-ASR applies a "Listening-Imagining-Refining" strategy, generating phonetic variants and refining them in context. A heuristic optimization with finite state machine (FSM) is introduced to prevent the correction process from being trapped in local optima and rule-based constraints help maintain semantic fidelity. Experiments on both English and Chinese ASR outputs show that LIR-ASR achieves average reductions in CER/WER of up to 1.5 percentage points compared to baselines, demonstrating substantial accuracy gains in transcription.

Paper number 48:
Title: Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach
Authors: Taoyuan Yu, Kui Wang, Zongdian Li, Tao Yu, Kei Sakaguchi, Walid Saad
Abstract: Unsignalized intersections pose safety and efficiency challenges due to complex traffic flows and blind spots. In this paper, a digital twin (DT)-based cooperative driving system with roadside unit (RSU)-centric architecture is proposed for enhancing safety and efficiency at unsignalized intersections. The system leverages comprehensive bird-eye-view (BEV) perception to eliminate blind spots and employs a hybrid reinforcement learning (RL) framework combining offline pre-training with online fine-tuning. Specifically, driving policies are initially trained using conservative Q-learning (CQL) with behavior cloning (BC) on real datasets, then fine-tuned using multi-agent proximal policy optimization (MAPPO) with self-attention mechanisms to handle dynamic multi-agent coordination. The RSU implements real-time commands via vehicle-to-infrastructure (V2I) communications. Experimental results show that the proposed method yields failure rates below 0.03\% coordinating up to three connected autonomous vehicles (CAVs), significantly outperforming traditional methods. In addition, the system exhibits sub-linear computational scaling with inference times under 40 ms. Furthermore, it demonstrates robust generalization across diverse unsignalized intersection scenarios, indicating its practicality and readiness for real-world deployment.

Paper number 49:
Title: Learning Constraints from Stochastic Partially-Observed Closed-Loop Demonstrations
Authors: Chih-Yuan Chiu, Zhouyu Zhang, Glen Chou
Abstract: We present an algorithm for learning unknown parametric constraints from locally-optimal input-output trajectory data. We assume that the given data is generated by demonstrators with stochastic nonlinear dynamics who execute a state or output feedback law to robustly satisfy the constraints despite worst-case dynamics and output noise. We encode the Karush-Kuhn-Tucker (KKT) conditions of this robust optimal output feedback control problem within a feasibility problem to recover constraints consistent with the local optimality of the demonstrations. We prove that our constraint learning method (i) accurately recovers the demonstrator's state or output feedback policy, and (ii) conservatively estimates the set of all state or output feedback policies that ensure constraint satisfaction despite worst-case noise realizations. Moreover, we perform sensitivity analysis, proving that when demonstrations are corrupted by transmission error, the inaccuracy in the learned state or output feedback law scales linearly in the error magnitude. Our method accurately recovers unknown constraints from simulated noisy, closed-loop demonstrations generated using dynamics, both linear and nonlinear, (e.g., unicycle and quadrotor) and a range of state and output feedback mechanisms.

Paper number 50:
Title: Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model
Authors: Sanduni Pinnawala, Annabelle Hartanto, Ivor J. A. Simpson, Peter A. Wijeratne
Abstract: Modelling the underlying mechanisms of neurodegenerative diseases demands methods that capture heterogeneous and spatially varying dynamics from sparse, high-dimensional neuroimaging data. Integrating partial differential equation (PDE) based physics knowledge with machine learning provides enhanced interpretability and utility over classic numerical methods. However, current physics-integrated machine learning methods are limited to considering a single PDE, severely limiting their application to diseases where multiple mechanisms are responsible for different groups (i.e., subtypes) and aggravating problems with model misspecification and degeneracy. Here, we present a deep generative model for learning mixtures of latent dynamic models governed by physics-based PDEs, going beyond traditional approaches that assume a single PDE structure. Our method integrates reaction-diffusion PDEs within a variational autoencoder (VAE) mixture model framework, supporting inference of subtypes of interpretable latent variables (e.g. diffusivity and reaction rates) from neuroimaging data. We evaluate our method on synthetic benchmarks and demonstrate its potential for uncovering mechanistic subtypes of Alzheimer's disease progression from positron emission tomography (PET) data.

Paper number 51:
Title: Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition
Authors: Navid Hasanzadeh, Shahrokh Valaee
Abstract: With the IEEE 802.11bf Task Group introducing amendments to the WLAN standard for advanced sensing, interest in using Wi-Fi Channel State Information (CSI) for remote sensing has surged. Recent findings indicate that learning a unified three-dimensional motion representation through Doppler Radiance Fields (DoRFs) derived from CSI significantly improves the generalization capabilities of Wi-Fi-based human activity recognition (HAR). Despite this progress, CSI signals remain affected by asynchronous access point (AP) clocks and additive noise from environmental and hardware sources. Consequently, even with existing preprocessing techniques, both the CSI data and Doppler velocity projections used in DoRFs are still susceptible to noise and outliers, limiting HAR performance. To address this challenge, we propose a novel framework for multi-antenna APs to suppress noise and identify the most informative antennas based on DoRF fitting errors, which capture inconsistencies among Doppler velocity projections. Experimental results on a challenging small-scale hand gesture recognition dataset demonstrate that the proposed DoRF-guided Wi-Fi-based HAR approach significantly improves generalization capability, paving the way for robust real-world sensing deployments.

Paper number 52:
Title: Nonlinear Cooperative Salvo Guidance with Seeker-Limited Interceptors
Authors: Lohitvel Gopikannan, Shashi Ranjan Kumar, Abhinav Sinha
Abstract: This paper presents a cooperative guidance strategy for the simultaneous interception of a constant-velocity, non-maneuvering target, addressing the realistic scenario where only a subset of interceptors are equipped with onboard seekers. To overcome the resulting heterogeneity in target observability, a fixed-time distributed observer is employed, enabling seeker-less interceptors to estimate the target state using information from seeker-equipped agents and local neighbors over a directed communication topology. Departing from conventional strategies that approximate time-to-go via linearization or small-angle assumptions, the proposed approach leverages deviated pursuit guidance where the time-to-go expression is exact for such a target. Moreover, a higher-order sliding mode consensus protocol is utilized to establish time-to-go consensus within a finite time. The effectiveness of the proposed guidance and estimation architecture is demonstrated through simulations.

Paper number 53:
Title: A Unified Distributed Algorithm for Hybrid Near-Far Field Activity Detection in Cell-Free Massive MIMO
Authors: Jingreng Lei, Yang Li, Ziyue Wang, Qingfeng Lin, Ya-Feng Liu, Yik-Chung Wu
Abstract: A great amount of endeavor has recently been devoted to activity detection for massive machine-type communications in cell-free multiple-input multiple-output (MIMO) systems. However, as the number of antennas at the access points (APs) increases, the Rayleigh distance that separates the near-field and far-field regions also expands, rendering the conventional assumption of far-field propagation alone impractical. To address this challenge, this paper establishes a covariance-based formulation that can effectively capture the statistical property of hybrid near-far field channels. Based on this formulation, we theoretically reveal that increasing the proportion of near-field channels enhances the detection performance. Furthermore, we propose a distributed algorithm, where each AP performs local activity detection and only exchanges the detection results to the central processing unit, thus significantly reducing the computational complexity and the communication overhead. Not only with convergence guarantee, the proposed algorithm is unified in the sense that it can handle single-cell or cell-free systems with either near-field or far-field devices as special cases. Simulation results validate the theoretical analyses and demonstrate the superior performance of the proposed approach compared with existing methods.

Paper number 54:
Title: Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity
Authors: Qihang Chen
Abstract: Metro crew planning is a key component of smart city development as it directly impacts the operational efficiency and service reliability of public transportation. With the rapid expansion of metro networks, effective multi-line scheduling and emergency management have become essential for large-scale seamless operations. However, current research focuses primarily on individual metro lines,with insufficient attention on cross-line coordination and rapid replanning during disruptions. Here, a unified optimization framework is presented for multi-line metro crew planning and replanning with heterogeneous workforce. Specifically, a hierarchical time-space network model is proposed to represent the unified crew action space, and computationally efficient constraints and formulations are derived for the crew's heterogeneous qualifications and preferences. Solution algorithms based on column generation and shortest path adjustment are further developed, utilizing the proposed network model. Experiments with real data from Shanghai and Beijing Metro demonstrate that the proposed methods outperform benchmark heuristics in both cost reduction and task completion,and achieve notable efficiency gains by incorporating cross-line operations, particularly for urgent tasks during disruptions. This work highlights the role of global optimization and cross-line coordination in multi-line metro system operations, providing insights into the efficient and reliable functioning of public transportation in smart cities.

Paper number 55:
Title: Context-Enhanced Granular Edit Representation for Efficient and Accurate ASR Post-editing
Authors: Luan Vejsiu, Qianyu Zheng, Haoxuan Chen, Yizhou Han
Abstract: Despite ASR technology being full-scale adopted by industry and for large portions of the population, ASR systems often have errors that require editors to post-edit text quality. While LLMs are powerful post-editing tools, baseline full rewrite models have inference inefficiencies because they often generate the same redundant text over and over again. Compact edit representations have existed but often lack the efficacy and context required for optimal accuracy. This paper introduces CEGER (Context-Enhanced Granular Edit Representation), a compact edit representation that was generated for highly accurate, efficient ASR post-editing. CEGER allows LLMs to generate a sequence of structured, fine-grained, contextually rich commands to modify the original ASR output. A separate expansion module deterministically reconstructs the corrected text based on the commands. Extensive experiments on the LibriSpeech dataset that were conducted, CEGER achieves state-of-the-art accuracy, achieving the lowest word error rate (WER) versus full rewrite and prior compact representations.

Paper number 56:
Title: SpeechWeave: Diverse Multilingual Synthetic Text & Audio Data Generation Pipeline for Training Text to Speech Models
Authors: Karan Dua, Puneet Mittal, Ranjeet Gupta, Hitesh Laxmichand Patel
Abstract: High-quality Text-to-Speech (TTS) model training requires extensive and diverse text and speech data. It is challenging to procure such data from real sources due to issues of domain specificity, licensing, and scalability. Large language models (LLMs) can certainly generate textual data, but they create repetitive text with insufficient variation in the prompt during the generation process. Another important aspect in TTS training data is text normalization. Tools for normalization might occasionally introduce anomalies or overlook valuable patterns, and thus impact data quality. Furthermore, it is also impractical to rely on voice artists for large scale speech recording in commercial TTS systems with standardized voices. To address these challenges, we propose SpeechWeave, a synthetic speech data generation pipeline that is capable of automating the generation of multilingual, domain-specific datasets for training TTS models. Our experiments reveal that our pipeline generates data that is 10-48% more diverse than the baseline across various linguistic and phonetic metrics, along with speaker-standardized speech audio while generating approximately 97% correctly normalized text. Our approach enables scalable, high-quality data generation for TTS training, improving diversity, normalization, and voice consistency in the generated datasets.

Paper number 57:
Title: HQCNN: A Hybrid Quantum-Classical Neural Network for Medical Image Classification
Authors: Shahjalal, Jahid Karim Fahim, Pintu Chandra Paul, Md Robin Hossain, Md. Tofael Ahmed, Dulal Chakraborty
Abstract: Classification of medical images plays a vital role in medical image analysis; however, it remains challenging due to the limited availability of labeled data, class imbalances, and the complexity of medical patterns. To overcome these challenges, we propose a novel Hybrid Quantum-Classical Neural Network (HQCNN) for both binary and multi-class classification. The architecture of HQCNN integrates a five-layer classical convolutional backbone with a 4-qubit variational quantum circuit that incorporates quantum state encoding, superpositional entanglement, and a Fourier-inspired quantum attention mechanism. We evaluate the model on six MedMNIST v2 benchmark datasets. The HQCNN consistently outperforms classical and quantum baselines, achieving up to 99.91% accuracy and 100.00% AUC on PathMNIST (binary) and 99.95% accuracy on OrganAMNIST (multi-class) with strong robustness on noisy datasets like BreastMNIST (87.18% accuracy). The model demonstrates superior generalization capability and computational efficiency, accomplished with significantly fewer trainable parameters, making it suitable for data-scarce scenarios. Our findings provide strong empirical evidence that hybrid quantum-classical models can advance medical imaging tasks.

Paper number 58:
Title: QLook:Quantum-Driven Viewport Prediction for Virtual Reality
Authors: Niusha Sabri Kadijani, Yoga Suhas Kuruba Manjunath, Xiaodan Bi, Lian Zhao
Abstract: We propose QLook, a quantum-driven predictive framework to improve viewport prediction accuracy in immersive virtual reality (VR) environments. The framework utilizes quantum neural networks (QNNs) to model the user movement data, which has multiple interdependent dimensions and is collected in six-degree-of-freedom (6DoF) VR settings. QNN leverages superposition and entanglement to encode and process complex correlations among high-dimensional user positional data. The proposed solution features a cascaded hybrid architecture that integrates classical neural networks with variational quantum circuits (VQCs)-enhanced quantum long short-term memory (QLSTM) networks. We utilize identity block initialization to mitigate training challenges commonly associated with VQCs, particularly those encountered as barren plateaus. Empirical evaluation of QLook demonstrates a 37.4% reduction in mean squared error (MSE) compared to state-of-the-art (SoTA), showcasing superior viewport prediction.

Paper number 59:
Title: Deploying UDM Series in Real-Life Stuttered Speech Applications: A Clinical Evaluation Framework
Authors: Eric Zhang, Li Wei, Sarah Chen, Michael Wang (SSHealth Team, AI for Healthcare Laboratory)
Abstract: Stuttered and dysfluent speech detection systems have traditionally suffered from the trade-off between accuracy and clinical interpretability. While end-to-end deep learning models achieve high performance, their black-box nature limits clinical adoption. This paper looks at the Unconstrained Dysfluency Modeling (UDM) series-the current state-of-the-art framework developed by Berkeley that combines modular architecture, explicit phoneme alignment, and interpretable outputs for real-world clinical deployment. Through extensive experiments involving patients and certified speech-language pathologists (SLPs), we demonstrate that UDM achieves state-of-the-art performance (F1: 0.89+-0.04) while providing clinically meaningful interpretability scores (4.2/5.0). Our deployment study shows 87% clinician acceptance rate and 34% reduction in diagnostic time. The results provide strong evidence that UDM represents a practical pathway toward AI-assisted speech therapy in clinical environments.

Paper number 60:
Title: On the Complexity of the Secret Protection Problem for Discrete-Event Systems
Authors: Tomáš Masopust, Jakub Večeřa
Abstract: The secret protection problem (SPP) seeks to synthesize a minimum-cost policy ensuring that every execution from an initial state to a secret state includes a sufficient number of protected events. Previous work showed that the problem is solvable in polynomial time under the assumptions that transitions are uniquely labeled and that the clearance level for every event is uniformly set to one. When these assumptions are relaxed, the problem was shown to be weakly NP-hard, leaving the complexity of the uniform variant open. In this paper, we close this gap by proving that the uniform secret protection problem is NP-hard, even if all parameters are restricted to binary values. Moreover, we strengthen the existing results by showing that the general problem becomes NP-hard as soon as the uniqueness constraint on event labels is removed. We further propose a formulation of SPP as an Integer Linear Programming (ILP) problem. Our empirical evaluation demonstrates the scalability and effectiveness of the ILP-based approach on relatively large systems. Finally, we examine a variant of SPP in which only distinct protected events contribute to clearance and show that its decision version is $\Sigma_{2}^{P}$-complete.

Paper number 61:
Title: Online Learning of Deceptive Policies under Intermittent Observation
Authors: Gokul Puthumanaillam, Ram Padmanabhan, Jose Fuentes, Nicole Cruz, Paulo Padrao, Ruben Hernandez, Hao Jiang, William Schafer, Leonardo Bobadilla, Melkior Ornik
Abstract: In supervisory control settings, autonomous systems are not monitored continuously. Instead, monitoring often occurs at sporadic intervals within known bounds. We study the problem of deception, where an agent pursues a private objective while remaining plausibly compliant with a supervisor's reference policy when observations occur. Motivated by the behavior of real, human supervisors, we situate the problem within Theory of Mind: the representation of what an observer believes and expects to see. We show that Theory of Mind can be repurposed to steer online reinforcement learning (RL) toward such deceptive behavior. We model the supervisor's expectations and distill from them a single, calibrated scalar -- the expected evidence of deviation if an observation were to happen now. This scalar combines how unlike the reference and current action distributions appear, with the agent's belief that an observation is imminent. Injected as a state-dependent weight into a KL-regularized policy improvement step within an online RL loop, this scalar informs a closed-form update that smoothly trades off self-interest and compliance, thus sidestepping hand-crafted or heuristic policies. In real-world, real-time hardware experiments on marine (ASV) and aerial (UAV) navigation, our ToM-guided RL runs online, achieves high return and success with observed-trace evidence calibrated to the supervisor's expectations.

Paper number 62:
Title: Optimal Algorithms for Bandit Learning in Matching Markets
Authors: Tejas Pagare, Agniv Bandyopadhyay, Sandeep Juneja
Abstract: We study the problem of pure exploration in matching markets under uncertain preferences, where the goal is to identify a stable matching with confidence parameter $\delta$ and minimal sample complexity. Agents learn preferences via stochastic rewards, with expected values indicating preferences. This finds use in labor market platforms like Upwork, where firms and freelancers must be matched quickly despite noisy observations and no prior knowledge, in a stable manner that prevents dissatisfaction. We consider markets with unique stable matching and establish information-theoretic lower bounds on sample complexity for (1) one-sided learning, where one side of the market knows its true preferences, and (2) two-sided learning, where both sides are uncertain. We propose a computationally efficient algorithm and prove that it asymptotically ($\delta\to 0$) matches the lower bound to a constant for one-sided learning. Using the insights from the lower bound, we extend our algorithm to the two-sided learning setting and provide experimental results showing that it closely matches the lower bound on sample complexity. Finally, using a system of ODEs, we characterize the idealized fluid path that our algorithm chases.

Paper number 63:
Title: From Turn-Taking to Synchronous Dialogue: A Survey of Full-Duplex Spoken Language Models
Authors: Yuxuan Chen, Haoyuan Yu
Abstract: True Full-Duplex (TFD) voice communication--enabling simultaneous listening and speaking with natural turn-taking, overlapping speech, and interruptions--represents a critical milestone toward human-like AI interaction. This survey comprehensively reviews Full-Duplex Spoken Language Models (FD-SLMs) in the LLM era. We establish a taxonomy distinguishing Engineered Synchronization (modular architectures) from Learned Synchronization (end-to-end architectures), and unify fragmented evaluation approaches into a framework encompassing Temporal Dynamics, Behavioral Arbitration, Semantic Coherence, and Acoustic Performance. Through comparative analysis of mainstream FD-SLMs, we identify fundamental challenges: synchronous data scarcity, architectural divergence, and evaluation gaps, providing a roadmap for advancing human-AI communication.

Paper number 64:
Title: Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language
Authors: Hanlong Wan, Xing Lu, Yan Chen, Karthik Devaprasad, Laura Hinkle
Abstract: Dynamic energy systems and controls require advanced modeling frameworks to design and test supervisory and fault tolerant strategies. Modelica is a widely used equation based language, but developing control modules is labor intensive and requires specialized expertise. This paper examines the use of large language models (LLMs) to automate the generation of Control Description Language modules in the Building Modelica Library as a case study. We developed a structured workflow that combines standardized prompt scaffolds, library aware grounding, automated compilation with OpenModelica, and human in the loop evaluation. Experiments were carried out on four basic logic tasks (And, Or, Not, and Switch) and five control modules (chiller enable/disable, bypass valve control, cooling tower fan speed, plant requests, and relief damper control). The results showed that GPT 4o failed to produce executable Modelica code in zero shot mode, while Claude Sonnet 4 achieved up to full success for basic logic blocks with carefully engineered prompts. For control modules, success rates reached 83 percent, and failed outputs required medium level human repair (estimated one to eight hours). Retrieval augmented generation often produced mismatches in module selection (for example, And retrieved as Or), while a deterministic hard rule search strategy avoided these errors. Human evaluation also outperformed AI evaluation, since current LLMs cannot assess simulation results or validate behavioral correctness. Despite these limitations, the LLM assisted workflow reduced the average development time from 10 to 20 hours down to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings. These results highlight both the potential and current limitations of LLM assisted Modelica generation, and point to future research in pre simulation validation, stronger grounding, and closed loop evaluation.

Paper number 65:
Title: Chameleon: Integrated Sensing and Communication with Sub-Symbol Beam Switching in mmWave Networks
Authors: Zhihui Gao, Zhecun Liu, Tingjun Chen
Abstract: Next-generation cellular networks are envisioned to integrate sensing capabilities with communication, particularly in the millimeter-wave (mmWave) spectrum, where beamforming using large-scale antenna arrays enables directional signal transmissions for improved spatial multiplexing. In current 5G networks, however, beamforming is typically designed either for communication or sensing (e.g., beam training during link establishment). In this paper, we present Chameleon, a novel framework that augments and rapidly switches beamformers during each demodulation reference signal (DMRS) symbol to achieve integrated sensing and communication (ISAC) in 5G mmWave networks. Each beamformer introduces an additional sensing beam toward target angles while maintaining the communication beams toward multiple users. We implement Chameleon on a 28 GHz software-defined radio testbed supporting over-the-air 5G physical downlink shared channel (PDSCH) transmissions. Extensive experiments in open environments show that Chameleon achieves multi-user communication with a sum data rate of up to 0.80 Gbps across two users. Simultaneously, Chameleon employs a beamformer switching interval of only 0.24 {\mu}s, therefore producing a 31x31-point 2D imaging within just 0.875 ms. Leveraging machine learning, Chameleon further enables object localization with median errors of 0.14 m (distance) and 0.24° (angle), and material classification with 99.0% accuracy.

Paper number 66:
Title: How Does Instrumental Music Help SingFake Detection?
Authors: Xuanjun Chen, Chia-Yu Hu, I-Ming Lin, Yi-Cheng Lin, I-Hsiang Chiu, You Zhang, Sung-Feng Huang, Yi-Hsuan Yang, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang
Abstract: Although many models exist to detect singing voice deepfakes (SingFake), how these models operate, particularly with instrumental accompaniment, is unclear. We investigate how instrumental music affects SingFake detection from two perspectives. To investigate the behavioral effect, we test different backbones, unpaired instrumental tracks, and frequency subbands. To analyze the representational effect, we probe how fine-tuning alters encoders' speech and music capabilities. Our results show that instrumental accompaniment acts mainly as data augmentation rather than providing intrinsic cues (e.g., rhythm or harmony). Furthermore, fine-tuning increases reliance on shallow speaker features while reducing sensitivity to content, paralinguistic, and semantic information. These insights clarify how models exploit vocal versus instrumental cues and can inform the design of more interpretable and robust SingFake detection systems.

Paper number 67:
Title: Designing Latent Safety Filters using Pre-Trained Vision Models
Authors: Ihab Tabbara, Yuxuan Yang, Ahmad Hamzeh, Maxwell Astafyev, Hussein Sibai
Abstract: Ensuring safety of vision-based control systems remains a major challenge hindering their deployment in critical settings. Safety filters have gained increased interest as effective tools for ensuring the safety of classical control systems, but their applications in vision-based control settings have so far been limited. Pre-trained vision models (PVRs) have been shown to be effective perception backbones for control in various robotics domains. In this paper, we are interested in examining their effectiveness when used for designing vision-based safety filters. We use them as backbones for classifiers defining failure sets, for Hamilton-Jacobi (HJ) reachability-based safety filters, and for latent world models. We discuss the trade-offs between training from scratch, fine-tuning, and freezing the PVRs when training the models they are backbones for. We also evaluate whether one of the PVRs is superior across all tasks, evaluate whether learned world models or Q-functions are better for switching decisions to safe policies, and discuss practical considerations for deploying these PVRs on resource-constrained devices.

Paper number 68:
Title: Diffusion-Based Scenario Tree Generation for Multivariate Time Series Prediction and Multistage Stochastic Optimization
Authors: Stelios Zarifis, Ioannis Kordonis, Petros Maragos
Abstract: Stochastic forecasting is critical for efficient decision-making in uncertain systems, such as energy markets and finance, where estimating the full distribution of future scenarios is essential. We propose Diffusion Scenario Tree (DST), a general framework for constructing scenario trees for multivariate prediction tasks using diffusion-based probabilistic forecasting models. DST recursively samples future trajectories and organizes them into a tree via clustering, ensuring non-anticipativity (decisions depending only on observed history) at each stage. We evaluate the framework on the optimization task of energy arbitrage in New York State's day-ahead electricity market. Experimental results show that our approach consistently outperforms the same optimization algorithms that use scenario trees from more conventional models and Model-Free Reinforcement Learning baselines. Furthermore, using DST for stochastic optimization yields more efficient decision policies, achieving higher performance by better handling uncertainty than deterministic and stochastic MPC variants using the same diffusion-based forecaster.

Paper number 69:
Title: Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization
Authors: Houssem Sifaou, Osvaldo Simeone
Abstract: Optimizing a reinforcement learning (RL) policy typically requires extensive interactions with a high-fidelity simulator of the environment, which are often costly or impractical. Offline RL addresses this problem by allowing training from pre-collected data, but its effectiveness is strongly constrained by the size and quality of the dataset. Hybrid offline-online RL leverages both offline data and interactions with a single simulator of the environment. In many real-world scenarios, however, multiple simulators with varying levels of fidelity and computational cost are available. In this work, we study multi-fidelity hybrid RL for policy optimization under a fixed cost budget. We introduce multi-fidelity hybrid RL via information gain maximization (MF-HRL-IGM), a hybrid offline-online RL algorithm that implements fidelity selection based on information gain maximization through a bootstrapping approach. Theoretical analysis establishes the no-regret property of MF-HRL-IGM, while empirical evaluations demonstrate its superior performance compared to existing benchmarks.

Paper number 70:
Title: Graph-Aware Learning Rates for Decentralized Optimization
Authors: Aaron Fainman, Stefan Vlaski
Abstract: We propose an adaptive step-size rule for decentralized optimization. Choosing a step-size that balances convergence and stability is challenging. This is amplified in the decentralized setting as agents observe only local (possibly stochastic) gradients and global information (like smoothness) is unavailable. We derive a step-size rule from first principles. The resulting formulation reduces to the well-known Polyak's rule in the single-agent setting, and is suitable for use with stochastic gradients. The method is parameter free, apart from requiring the optimal objective value, which is readily available in many applications. Numerical simulations demonstrate that the performance is comparable to the optimally fine-tuned step-size.

Paper number 71:
Title: Learning Graph from Smooth Signals under Partial Observation: A Robustness Analysis
Authors: Hoang-Son Nguyen, Hoi-To Wai
Abstract: Learning the graph underlying a networked system from nodal signals is crucial to downstream tasks in graph signal processing and machine learning. The presence of hidden nodes whose signals are not observable might corrupt the estimated graph. While existing works proposed various robustifications of vanilla graph learning objectives by explicitly accounting for the presence of these hidden nodes, a robustness analysis of "naive", hidden-node agnostic approaches is still underexplored. This work demonstrates that vanilla graph topology learning methods are implicitly robust to partial observations of low-pass filtered graph signals. We achieve this theoretical result through extending the restricted isometry property (RIP) to the Dirichlet energy function used in graph learning objectives. We show that smoothness-based graph learning formulation (e.g., the GL-SigRep method) on partial observations can recover the ground truth graph topology corresponding to the observed nodes. Synthetic and real data experiments corroborate our findings.

Paper number 72:
Title: Temporally Heterogeneous Graph Contrastive Learning for Multimodal Acoustic event Classification
Authors: Yuanjian Chen, Yang Xiao, Jinjie Huang
Abstract: Multimodal acoustic event classification plays a key role in audio-visual systems. Although combining audio and visual signals improves recognition, it is still difficult to align them over time and to reduce the effect of noise across modalities. Existing methods often treat audio and visual streams separately, fusing features later with contrastive or mutual information objectives. Recent advances explore multimodal graph learning, but most fail to distinguish between intra- and inter-modal temporal dependencies. To address this, we propose Temporally Heterogeneous Graph-based Contrastive Learning (THGCL). Our framework constructs a temporal graph for each event, where audio and video segments form nodes and their temporal links form edges. We introduce Gaussian processes for intra-modal smoothness, Hawkes processes for inter-modal decay, and contrastive learning to capture fine-grained relationships. Experiments on AudioSet show that THGCL achieves state-of-the-art performance.

Paper number 73:
Title: Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space
Authors: Wenyan Ma, Lipeng Zhu, Rui Zhang
Abstract: In this paper, we present a new wireless sensing system utilizing a movable antenna (MA) that continuously moves and receives sensing signals to enhance sensing performance over the conventional fixed-position antenna (FPA) sensing. We show that the angle estimation performance is fundamentally determined by the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square error (MSE) for angle-of-arrival (AoA) estimation as a function of the trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna movement. For the 1D case, a globally optimal trajectory that minimizes the CRB is derived in closed form. Notably, the resulting CRB decreases cubically with sensing time in the time-constrained regime, whereas it decreases linearly with sensing time and quadratically with the movement line segment's length in the space-constrained regime. For the 2D case, we aim to achieve the minimum of maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the horizontal and vertical axes. To this end, we design an efficient alternating optimization algorithm that iteratively updates the MA's horizontal or vertical coordinates with the other being fixed, yielding a locally optimal trajectory. Numerical results show that the proposed 1D/2D MA-based sensing schemes significantly reduce both the CRB and actual AoA estimation MSE compared to conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as well as various benchmark MA trajectories. Moreover, it is revealed that the steering vectors of our designed 1D/2D MA trajectories have low correlation in the angular domain, thereby effectively increasing the angular resolution for achieving higher AoA estimation accuracy.

Paper number 74:
Title: Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening
Authors: Xiaolei Xu, Chaoyue Niu, Guy J. Brown, Hector Romero, Ning Ma
Abstract: Obstructive sleep apnoea (OSA) is a prevalent condition with significant health consequences, yet many patients remain undiagnosed due to the complexity and cost of over-night polysomnography. Acoustic-based screening provides a scalable alternative, yet performance is limited by environmental noise and the lack of physiological context. Respiratory effort is a key signal used in clinical scoring of OSA events, but current approaches require additional contact sensors that reduce scalability and patient comfort. This paper presents the first study to estimate respiratory effort directly from nocturnal audio, enabling physiological context to be recovered from sound alone. We propose a latent-space fusion framework that integrates the estimated effort embeddings with acoustic features for OSA detection. Using a dataset of 157 nights from 103 participants recorded in home environments, our respiratory effort estimator achieves a concordance correlation coefficient of 0.48, capturing meaningful respiratory dynamics. Fusing effort and audio improves sensitivity and AUC over audio-only baselines, especially at low apnoea-hypopnoea index thresholds. The proposed approach requires only smartphone audio at test time, which enables sensor-free, scalable, and longitudinal OSA monitoring.

Paper number 75:
Title: The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation
Authors: João Damião Almeida, Egidio Falotico, Cecilia Laschi, José Santos-Victor
Abstract: In-hand manipulation tasks, particularly in human-inspired robotic systems, must rely on distributed tactile sensing to achieve precise control across a wide variety of tasks. However, the optimal configuration of this network of sensors is a complex problem, and while the fingertips are a common choice for placing sensors, the contribution of tactile information from other regions of the hand is often overlooked. This work investigates the impact of tactile feedback from various regions of the fingers and palm in performing in-hand object reorientation tasks. We analyze how sensory feedback from different parts of the hand influences the robustness of deep reinforcement learning control policies and investigate the relationship between object characteristics and optimal sensor placement. We identify which tactile sensing configurations contribute to improving the efficiency and accuracy of manipulation. Our results provide valuable insights for the design and use of anthropomorphic end-effectors with enhanced manipulation capabilities.

Paper number 76:
Title: On the Late-Time Instability of MOT solution to the Time-Domain PMCHWT Equation
Authors: Van Chien Le, Viviana Giunzioni, Pierrick Cordel, Francesco P. Andriulli, Kristof Cools
Abstract: This paper investigates the late-time instability of marching-on-in-time solution to the time-domain PMCHWT equation. The stability analysis identifies the static solenoidal nullspace of the time-domain electric field integral operator as the primary cause of instability. Furthermore, it reveals that the instability mechanisms of the time-domain PMCHWT equation are fundamentally different from those of the time-domain electric field integral equation. In particular, the PMCHWT's instability is much more sensitive to numerical quadrature errors, and its spectral characteristics are strongly influenced by the topology and smoothness of the scatterer surface.

Paper number 77:
Title: Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting
Authors: Aarushi Mahajan, Wayne Burleson
Abstract: Radio frequency fingerprint identification (RFFI) distinguishes wireless devices by the small variations in their analog circuits, avoiding heavy cryptographic authentication. While deep learning on spectrograms improves accuracy, models remain vulnerable to copying, tampering, and evasion. We present a stronger RFFI system combining watermarking for ownership proof and anomaly detection for spotting suspicious inputs. Using a ResNet-34 on log-Mel spectrograms, we embed three watermarks: a simple trigger, an adversarially trained trigger robust to noise and filtering, and a hidden gradient/weight signature. A convolutional Variational Autoencoders (VAE) with Kullback-Leibler (KL) warm-up and free-bits flags off-distribution queries. On the LoRa dataset, our system achieves 94.6% accuracy, 98% watermark success, and 0.94 AUROC, offering verifiable, tamper-resistant authentication.

Paper number 78:
Title: Version Age of Information with Contact Mobility in Gossip Networks
Authors: Irtiza Hasan, Ahmed Arafa
Abstract: A gossip network is considered in which a source node updates its status while other nodes in the network aim at keeping track of it as it varies over time. Information gets disseminated by the source sending status updates to the nodes, and the nodes gossiping with each other. In addition, the nodes in the network are mobile, and can move to other nodes to get information, which we term contact mobility. The goal for the nodes is to remain as fresh as possible, i.e., to have the same information as the source's. To evaluate the freshness of information, we use the Version Age-of-Information (VAoI) metric, defined as the difference between the version of information available at a given node and that at the source. We analyze the effect of contact mobility on information dissemination in the gossip network using a Stochastic Hybrid System (SHS) framework for different topologies and mobility scalings with increasing number of nodes. It is shown that with the presence of contact mobility the freshness of the network improves in both ends of the network connectivity spectrum: disconnected and fully connected gossip networks. We mathematically analyze the average version age scalings and validate our theoretical results via simulations. Finally, we incorporate the cost of mobility for the network by formulating and solving an optimization problem that minimizes a weighted sum of version age and mobility cost. Our results show that contact mobility, with optimized mobility cost, improves the average version age in the network.

Paper number 79:
Title: Two Web Toolkits for Multimodal Piano Performance Dataset Acquisition and Fingering Annotation
Authors: Junhyung Park, Yonghyun Kim, Joonhyung Bae, Kirak Kim, Taegyun Kwon, Alexander Lerch, Juhan Nam
Abstract: Piano performance is a multimodal activity that intrinsically combines physical actions with the acoustic rendition. Despite growing research interest in analyzing the multimodal nature of piano performance, the laborious process of acquiring large-scale multimodal data remains a significant bottleneck, hindering further progress in this field. To overcome this barrier, we present an integrated web toolkit comprising two graphical user interfaces (GUIs): (i) PiaRec, which supports the synchronized acquisition of audio, video, MIDI, and performance metadata. (ii) ASDF, which enables the efficient annotation of performer fingering from the visual data. Collectively, this system can streamline the acquisition of multimodal piano performance datasets.

Paper number 80:
Title: Low-Complexity Memoryless Linearizer for Analog-to-Digital Interfaces
Authors: Deijany Rodriguez Linares, Håkan Johansson
Abstract: This paper introduces a low-complexity memoryless linearizer for suppression of distortion in analog-to-digital interfaces. It is inspired by neural networks, but has a substantially lower complexity than the neural-network schemes that have appeared earlier in the literature in this context. The paper demonstrates that the proposed linearizer can outperform the conventional parallel memoryless Hammerstein linearizer even when the nonlinearities have been generated through a memoryless polynomial model. Further, a design procedure is proposed in which the linearizer parameters are obtained through matrix inversion. Thereby, the costly and time consuming numerical optimization that is traditionally used when training neural networks is eliminated. Moreover, the design and evaluation incorporate a large set of multi-tone signals covering the first Nyquist band. Simulations show signal-to-noise-and-distortion ratio (SNDR) improvements of some 25 dB for multi-tone signals that correspond to the quadrature parts of OFDM signals with QPSK modulation.

Paper number 81:
Title: Order Estimation of Linear-Phase FIR Filters for DAC Equalization in Multiple Nyquist Bands
Authors: Deijany Rodriguez Linares, Håkan Johansson, Yinan Wang
Abstract: This letter considers the design of linear-phase finite-length impulse response (FIR) filters for equalization of the frequency responses of digital-to-analog converters (DACs). The letter derives estimates for the filter orders required, as functions of the bandwidth and equalization accuracy, for four DAC pulses that are used in DACs in multiple Nyquist bands. The estimates are derived through a large set of minimax-optimal equalizers and the use of symbolic regression followed by minimax-optimal curve fitting for further enhancement. Design examples included demonstrate the accuracy of the proposed estimates. In addition, the letter discusses the appropriateness of the four types of linear-phase FIR filters, for the different equalizer cases, as well as the corresponding properties of the equalized systems.

Paper number 82:
Title: Optimal Control of Markov Decision Processes for Efficiency with Linear Temporal Logic Tasks
Authors: Yu Chen, Xuanyuan Yin, Shaoyuan Li, Xiang Yin
Abstract: We investigate the problem of optimal control synthesis for Markov Decision Processes (MDPs), addressing both qualitative and quantitative objectives. Specifically, we require the system to satisfy a qualitative task specified by a Linear Temporal Logic (LTL) formula with probability one. Additionally, to quantify the system's performance, we introduce the concept of efficiency, defined as the ratio between rewards and costs. This measure is more general than the standard long-run average reward metric, as it seeks to maximize the reward obtained per unit cost. Our objective is to synthesize a control policy that not only ensures the LTL task is satisfied but also maximizes efficiency. We present an effective approach for synthesizing a stationary control policy that achieves $\epsilon$-optimality by integrating state classifications of MDPs with perturbation analysis in a novel manner. Our results extend existing work on efficiency-optimal control synthesis for MDPs by incorporating qualitative LTL tasks. Case studies in robot task planning are provided to illustrate the proposed algorithm.

Paper number 83:
Title: Object Tracking Incorporating Transfer Learning into Unscented and Cubature Kalman Filters
Authors: Omar Alotaibi, Brian L. Mark, Mohammad Reza Fasihi
Abstract: We present a novel filtering algorithm that employs Bayesian transfer learning to address the challenges posed by mismatched intensity of the noise in a pair of sensors, each of which tracks an object using a nonlinear dynamic system model. In this setting, the primary sensor experiences a higher noise intensity in tracking the object than the source sensor. To improve the estimation accuracy of the primary sensor, we propose a framework that integrates Bayesian transfer learning into an Unscented Kalman Filter (UKF) and a Cubature Kalman Filter (CKF). In this approach, the parameters of the predicted observations in the source sensor are transferred to the primary sensor and used as an additional prior in the filtering process. Our simulation results show that the transfer learning approach significantly outperforms the conventional isolated UKF and CKF. Comparisons to a form of measurement vector fusion are also presented.

Paper number 84:
Title: Compositional Design of Safety Controllers for Large-scale Stochastic Hybrid Systems
Authors: Mahdieh Zaker, Omid Akbarzadeh, Behrad Samari, Abolfazl Lavaei
Abstract: In this work, we propose a compositional scheme based on small-gain reasoning for the safety controller synthesis of interconnected stochastic hybrid systems with both continuous evolutions and instantaneous jumps. In our proposed setting, we first offer an augmented scheme to represent each stochastic hybrid subsystem with continuous and discrete evolutions in a unified framework, ensuring that the state trajectories match those of the original hybrid systems. We then introduce the concept of augmented control sub-barrier certificates (A-CSBC) for each subsystem, which allows the construction of augmented control barrier certificates (A-CBC) for interconnected systems and their safety controllers under small-gain compositional conditions. We eventually leverage the constructed A-CBC and quantify a guaranteed probabilistic bound across the safety of the interconnected system. While the computational complexity of designing a barrier certificate and its safety controller grows polynomially with network dimension using sum-of-squares (SOS) optimization program, our compositional approach significantly reduces it to a linear scale with respect to the number of subsystems. We verify the efficacy of our proposed approach over an interconnected stochastic hybrid system composed of 1000 nonlinear subsystems with two distinct interconnection topologies.

Paper number 85:
Title: Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation
Authors: Yujin Oh, Sangjoon Park, Xiang Li, Pengfei Jin, Yi Wang, Jonathan Paly, Jason Efstathiou, Annie Chan, Jun Won Kim, Hwa Kyung Byun, Ik Jae Lee, Jaeho Cho, Chan Woo Wee, Peng Shu, Peilong Wang, Nathan Yu, Jason Holmes, Jong Chul Ye, Quanzheng Li, Wei Liu, Woong Sub Koom, Jin Sung Kim, Kyungsang Kim
Abstract: Clinical decision-making reflects diverse strategies shaped by regional patient populations and institutional protocols. However, most existing medical artificial intelligence (AI) models are trained on highly prevalent data patterns, which reinforces biases and fails to capture the breadth of clinical expertise. Inspired by the recent advances in Mixture of Experts (MoE), we propose a Mixture of Multicenter Experts (MoME) framework to address AI bias in the medical domain without requiring data sharing across institutions. MoME integrates specialized expertise from diverse clinical strategies to enhance model generalizability and adaptability across medical centers. We validate this framework using a multimodal target volume delineation model for prostate cancer radiotherapy. With few-shot training that combines imaging and clinical notes from each center, the model outperformed baselines, particularly in settings with high inter-center variability or limited data availability. Furthermore, MoME enables model customization to local clinical preferences without cross-institutional data exchange, making it especially suitable for resource-constrained settings while promoting broadly generalizable medical AI.

Paper number 86:
Title: Traffic Co-Simulation Framework Empowered by Infrastructure Camera Sensing and Reinforcement Learning
Authors: Talha Azfar, Kaicong Huang, Andrew Tracy, Sandra Misiewicz, Chenxi Liu, Ruimin Ke
Abstract: Traffic simulations are commonly used to optimize urban traffic flow, with reinforcement learning (RL) showing promising potential for automated traffic signal control, particularly in intelligent transportation systems involving connected automated vehicles. Multi-agent reinforcement learning (MARL) is particularly effective for learning control strategies for traffic lights in a network using iterative simulations. However, existing methods often assume perfect vehicle detection, which overlooks real-world limitations related to infrastructure availability and sensor reliability. This study proposes a co-simulation framework integrating CARLA and SUMO, which combines high-fidelity 3D modeling with large-scale traffic flow simulation. Cameras mounted on traffic light poles within the CARLA environment use a YOLO-based computer vision system to detect and count vehicles, providing real-time traffic data as input for adaptive signal control in SUMO. MARL agents trained with four different reward structures leverage this visual feedback to optimize signal timings and improve network-wide traffic flow. Experiments in a multi-intersection test-bed demonstrate the effectiveness of the proposed MARL approach in enhancing traffic conditions using real-time camera based detection. The framework also evaluates the robustness of MARL under faulty or sparse sensing and compares the performance of YOLOv5 and YOLOv8 for vehicle detection. Results show that while better accuracy improves performance, MARL agents can still achieve significant improvements with imperfect detection, demonstrating scalability and adaptability for real-world scenarios.

Paper number 87:
Title: A Large-Scale Probing Analysis of Speaker-Specific Attributes in Self-Supervised Speech Representations
Authors: Aemon Yat Fei Chiu, Kei Ching Fung, Roger Tsz Yeung Li, Jingyu Li, Tan Lee
Abstract: Speech self-supervised learning (SSL) models are known to learn hierarchical representations, yet how they encode different speaker-specific attributes remains under-explored. This study investigates the layer-wise disentanglement of speaker information across multiple speech SSL model families and their variants. Drawing from phonetic frameworks, we conduct a large-scale probing analysis of attributes categorised into functional groups: Acoustic (Gender), Prosodic (Pitch, Tempo, Energy), and Paralinguistic (Emotion), which we use to deconstruct the model's representation of Speaker Identity. Our findings validate a consistent three-stage hierarchy: initial layers encode fundamental timbre and prosody; middle layers synthesise abstract traits; and final layers suppress speaker identity to abstract linguistic content. An ablation study shows that while specialised speaker embeddings excel at identifying speaker identity, the intermediate layers of speech SSL models better represent dynamic prosody. This work is the first large-scale study covering a wide range of speech SSL model families and variants with fine-grained speaker-specific attributes on how they hierarchically separate the dynamic style of speech from its intrinsic characteristics, offering practical implications for downstream tasks.

Paper number 88:
Title: MedFuncta: A Unified Framework for Learning Efficient Medical Neural Fields
Authors: Paul Friedrich, Florentin Bieder, Julian McGinnis, Julia Wolleb, Daniel Rueckert, Philippe C. Cattin
Abstract: Research in medical imaging primarily focuses on discrete data representations that poorly scale with grid resolution and fail to capture the often continuous nature of the underlying signal. Neural Fields (NFs) offer a powerful alternative by modeling data as continuous functions. While single-instance NFs have successfully been applied in medical contexts, extending them to large-scale medical datasets remains an open challenge. We therefore introduce MedFuncta, a unified framework for large-scale NF training on diverse medical signals. Building on Functa, our approach encodes data into a unified representation, namely a 1D latent vector, that modulates a shared, meta-learned NF, enabling generalization across a dataset. We revisit common design choices, introducing a non-constant frequency parameter $\omega$ in widely used SIREN activations, and establish a connection between this $\omega$-schedule and layer-wise learning rates, relating our findings to recent work in theoretical learning dynamics. We additionally introduce a scalable meta-learning strategy for shared network learning that employs sparse supervision during training, thereby reducing memory consumption and computational overhead while maintaining competitive performance. Finally, we evaluate MedFuncta across a diverse range of medical datasets and show how to solve relevant downstream tasks on our neural data representation. To promote further research in this direction, we release our code, model weights and the first large-scale dataset - MedNF - containing > 500 k latent vectors for multi-instance medical NFs.

Paper number 89:
Title: Digital Linearizer Based on 1-Bit Quantizations
Authors: Deijany Rodriguez Linares, Håkan Johansson
Abstract: This paper introduces a novel low-complexity memoryless linearizer for suppression of distortion in analog frontends. It is based on our recently introduced linearizer which is inspired by neural networks, but with orders-of-magnitude lower complexity than conventional neural-networks considered in this context, and it can also outperform the conventional parallel memoryless Hammerstein linearizer. Further, it can be designed through matrix inversion and thereby the costly and time consuming numerical optimization traditionally used when training neural networks is avoided. The linearizer proposed in this paper is different in that it uses 1-bit quantizations as nonlinear activation functions and different bias values. These features enable a look-up table implementation which eliminates all but one of the multiplications and additions required for the linearization. Extensive simulations and comparisons are included in the paper, for distorted multi-tone signals and bandpass filtered white noise, which demonstrate the efficacy of the proposed linearizer.

Paper number 90:
Title: Joint Sampling Frequency Offset Estimation and Compensation Based on the Farrow Structure
Authors: Deijany Rodriguez Linares, Oksana Moryakova, Håkan Johansson
Abstract: This paper introduces a sampling frequency offset (SFO) estimation method based on the Farrow structure, which is typically utilized for the SFO compensation and thereby enables a reduction of the implementation complexity of the SFO estimation. The proposed method is implemented in the time domain and works for arbitrary bandlimited signals, thus with no additional constraints on the waveform structure. Moreover, it can operate on only the real or imaginary part of a complex signal, which further reduces the estimation complexity. Furthermore, the proposed method can simultaneously estimate the SFO and additional sampling time offset (STO) and it is insensitive to other synchronization errors, like carrier frequency offset. Both the derivations of the proposed method and its implementation are presented, and through simulation examples, it is demonstrated that it can accurately estimate both SFO and STO for different types of bandlimited signals.

Paper number 91:
Title: HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement
Authors: Hantang Li, Qiang Zhu, Xiandong Meng, Lei Xiong, Shuyuan Zhu, Xiaopeng Fan
Abstract: In practical applications, low-light images are often compressed for efficient storage and transmission. Most existing methods disregard compression artifacts removal or hardly establish a unified framework for joint task enhancement of low-light images with varying compression qualities. To address this problem, we propose a hybrid priors-guided network (HPGN) that enhances compressed low-light images by integrating both compression and illumination priors. Our approach fully utilizes the JPEG quality factor (QF) and DCT quantization matrix to guide the design of efficient plug-and-play modules for joint tasks. Additionally, we employ a random QF generation strategy to guide model training, enabling a single model to enhance low-light images with different compression levels. Experimental results demonstrate the superiority of our proposed method..

Paper number 92:
Title: A Data-Driven Adaptive Impedance Matching Method Robust to Parasitic Effects
Authors: Wendong Cheng, Li Chen, Weidong Wang
Abstract: Adaptive impedance matching between antennas and radio frequency front-end (RFFE) power modules is essential for mobile communication systems. To address the matching performance degradation caused by parasitic effects in practical tunable matching networks (TMNs), this paper proposes a data-driven adaptive impedance matching method that avoids physical adjustment. First, we propose the residual enhanced circuit behavior modeling network (RECBM-Net), a deep learning model that maps TMN operating states to their scattering parameters (S-parameters). Then, we formulate the matching process based on the trained surrogate model as a mathematical optimization problem. We employ two classic numerical methods with different online computational overhead, namely simulated annealing particle swarm optimization (SAPSO) and adaptive moment estimation with automatic differentiation (AD-Adam), to search for the matching solution. To further reduce the online inference overhead caused by repeated forward propagation through RECBM-Net, we train an inverse mapping solver network (IMS-Net) to directly predict the optimal solution. Simulation results show that RECBM-Net accurately predicts S-parameters, achieving a mean absolute error of $6.98 \times 10^{-5}$. Across 9000 mismatched scenarios, the compliance rate after tuning increases from 0.97% with the analytical solution of the ideal L-network to 95.92% with SAPSO, 93.42% with AD-Adam, and 95% with IMS-Net. While AD-Adam significantly reduces computational overhead, lowering the average number of RECBM-Net inferences from 2097 with SAPSO to 285, it sacrifices some accuracy. IMS-Net requires only a single inference to obtain the matching solution, resulting in minimal online overhead while maintaining excellent matching accuracy.

Paper number 93:
Title: The Mean of Multi-Object Trajectories
Authors: Tran Thien Dat Nguyen, Ba Tuong Vo, Ba-Ngu Vo, Hoa Van Nguyen, Changbeom Shim
Abstract: This paper introduces the concept of a mean for trajectories and multi-object trajectories (defined as sets or multi-sets of trajectories) along with algorithms for computing them. Specifically, we use the Fréchet mean, and metrics based on the optimal sub-pattern assignment (OSPA) construct, to extend the notion of average from vectors to trajectories and multi-object trajectories. Further, we develop efficient algorithms to compute these means using greedy search and Gibbs sampling. Using distributed multi-object tracking as an application, we demonstrate that the Fréchet mean approach to multi-object trajectory consensus significantly outperforms state-of-the-art distributed multi-object tracking methods.

Paper number 94:
Title: Generating Sustainability-Targeting Attacks For Cyber-Physical Systems
Authors: Faysal Ahamed, Tanushree Roy
Abstract: Sustainability-targeting attacks (STA) are a growing threat to cyber-physical system (CPS)-based infrastructure, as sustainability goals become an integral part of CPS objectives. STA can be especially disruptive if it impacts the long-term sustainability cost of CPS, while its performance goals remain within acceptable parameters. Thus, in this work, we propose a general mathematical framework for modeling such stealthy STA and derive the feasibility conditions for generating a minimum-effort maximum-impact STA on a linear CPS using a max-min formulation. A gradient ascent descent algorithm is used to construct this attack policy with an added constraint on stealthiness. An illustrative example has been simulated to demonstrate the impact of the generated attack on the sustainability cost of the CPS.

Paper number 95:
Title: Quasi Steady-State Frequency
Authors: Joan Gutierrez-Florensa, Alvaro Ortega, Lukas Sigrist, Federico Milano
Abstract: Accurate frequency estimation is critical for the control, monitoring and protection of electrical power systems, in particular, of systems with a high penetration of power electronics. This paper introduces the novel concept of Quasi Steady-State (QSS) frequency as a quantity that fills the gap between stationary and instantaneous frequency. QSS frequency coincides with the fundamental frequency of an AC voltage in any stationary conditions, including unbalanced and non-sinusoidal, and is able to capture the time-varying fundamental frequency in transient conditions. The paper also proposes a metric borrowed from fluid dynamics, namely, the time derivative of the circulation, to define the scope of validity of the QSS frequency. Analytical examples as well as a case study based on a fully-fledged EMT model of the IEEE 39-bus system serve to illustrate, respectively, the properties of the QSS frequency and its behavior in transient conditions.

Paper number 96:
Title: A Multi-Scale Spatial Attention Network for Near-field MIMO Channel Estimation
Authors: Zhiming Zhu, Shu Xu, Jiexin Zhang, Chunguo Li, Yongming Huang, Luxi Yang
Abstract: The deployment of extremely large-scale array (ELAA) brings higher spectral efficiency and spatial degree of freedom, but triggers issues on near-field channel estimation. Existing near-field channel estimation schemes primarily exploit sparsity in the transform domain. However, these schemes are sensitive to the transform matrix selection and the stopping criteria. Inspired by the success of deep learning (DL) in far-field channel estimation, this paper proposes a novel spatial-attention-based method for reconstructing extremely large-scale MIMO (XL-MIMO) channel. Initially, the spatial antenna correlations of near-field channels are analyzed as an expectation over the angle-distance space, which demonstrate correlation range of an antenna element varies with its position. Due to the strong correlation between adjacent antenna elements, interactions of inter-subchannel are applied to describe inherent correlation of near-field channels instead of inter-element. Subsequently, a multi-scale spatial attention network (MsSAN) with the inter-subchannel correlation learning capabilities is proposed tailed to near-field MIMO channel estimation. We employ the multi-scale architecture to refine the subchannel size in MsSAN. Specially, we inventively introduce the sum of dot products as spatial attention (SA) instead of cross-covariance to weight subchannel features at different scales in the SA module. Simulation results are presented to validate the proposed MsSAN achieves remarkable the inter-subchannel correlation learning capabilities and outperforms others in terms of near-field channel reconstruction.

Paper number 97:
Title: Deep Reinforcement Learning-Based Control Strategy with Direct Gate Control for Buck Converters
Authors: Noboru Katayama
Abstract: This paper proposes a deep reinforcement learning (DRL)-based approach for directly controlling the gate signals of switching devices to achieve voltage regulation in a buck converter. Unlike conventional control methods, the proposed method directly generates gate signals using a neural network trained through DRL, with the objective of achieving high control speed and flexibility while maintaining stability. Simulation results demonstrate that the proposed direct gate control (DGC) method achieves a faster transient response and stable output voltage regulation, outperforming traditional PWM-based control schemes. The DGC method also exhibits strong robustness against parameter variations and sensor noise, indicating its suitability for practical power electronics applications. The effectiveness of the proposed approach is validated via simulation.

Paper number 98:
Title: A new dataset and comparison for multi-camera frame synthesis
Authors: Conall Daly, Anil Kokaram
Abstract: Many methods exist for frame synthesis in image sequences but can be broadly categorised into frame interpolation and view synthesis techniques. Fundamentally, both frame interpolation and view synthesis tackle the same task, interpolating a frame given surrounding frames in time or space. However, most frame interpolation datasets focus on temporal aspects with single cameras moving through time and space, while view synthesis datasets are typically biased toward stereoscopic depth estimation use cases. This makes direct comparison between view synthesis and frame interpolation methods challenging. In this paper, we develop a novel multi-camera dataset using a custom-built dense linear camera array to enable fair comparison between these approaches. We evaluate classical and deep learning frame interpolators against a view synthesis method (3D Gaussian Splatting) for the task of view in-betweening. Our results reveal that deep learning methods do not significantly outperform classical methods on real image data, with 3D Gaussian Splatting actually underperforming frame interpolators by as much as 3.5 dB PSNR. However, in synthetic scenes, the situation reverses -- 3D Gaussian Splatting outperforms frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level.

Paper number 99:
Title: Efficient motion-based metrics for video frame interpolation
Authors: Conall Daly, Darren Ramsook, Anil Kokaram
Abstract: Video frame interpolation (VFI) offers a way to generate intermediate frames between consecutive frames of a video sequence. Although the development of advanced frame interpolation algorithms has received increased attention in recent years, assessing the perceptual quality of interpolated content remains an ongoing area of research. In this paper, we investigate simple ways to process motion fields, with the purposes of using them as video quality metric for evaluating frame interpolation algorithms. We evaluate these quality metrics using the BVI-VFI dataset which contains perceptual scores measured for interpolated sequences. From our investigation we propose a motion metric based on measuring the divergence of motion fields. This metric correlates reasonably with these perceptual scores (PLCC=0.51) and is more computationally efficient (x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then use our new proposed metrics to evaluate a range of state of the art frame interpolation metrics and find our metrics tend to favour more perceptual pleasing interpolated frames that may not score highly in terms of PSNR or SSIM.

Paper number 100:
Title: Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025
Authors: Guillaume Balezo, Hana Feki, Raphaël Bourgade, Lily Monnier, Alice Blondel, Albert Pla Planas, Thomas Walter
Abstract: Atypical mitotic figures (AMFs) represent abnormal cell division associated with poor prognosis. Yet their detection remains difficult due to low prevalence, subtle morphology, and inter-observer variability. The MIDOG 2025 challenge introduces a benchmark for AMF classification across multiple domains. In this work, we fine-tuned the recently published DINOv3-H+ vision transformer, pretrained on natural images, using low-rank adaptation (LoRA), training only ~1.3M parameters in combination with extensive augmentation and a domain-weighted Focal Loss to handle domain heterogeneity. Despite the domain gap, our fine-tuned DINOv3 transfers effectively to histopathology, reaching second place on the preliminary test set. These results highlight the advantages of DINOv3 pretraining and underline the efficiency and robustness of our fine-tuning strategy, yielding state-of-the-art results for the atypical mitosis classification challenge in MIDOG 2025.

Paper number 101:
Title: Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification
Authors: Mieko Ochi, Bae Yuan
Abstract: Mitotic figures are classified into typical and atypical variants, with atypical counts correlating strongly with tumor aggressiveness. Accurate differentiation is therefore essential for patient prognostication and resource allocation, yet remains challenging even for expert pathologists. Here, we leveraged Pathology Foundation Models (PFMs) pre-trained on large histopathology datasets and applied parameter-efficient fine-tuning via low-rank adaptation. In addition, we incorporated ConvNeXt V2, a state-of-the-art convolutional neural network architecture, to complement PFMs. During training, we employed a fisheye transform to emphasize mitoses and Fourier Domain Adaptation using ImageNet target images. Finally, we ensembled multiple PFMs to integrate complementary morphological insights, achieving competitive balanced accuracy on the Preliminary Evaluation Phase dataset.

Paper number 102:
Title: FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes
Authors: Muraam Abdel-Ghani, Mahmoud Ali, Mohamed Ali, Fatmaelzahraa Ahmed, Muhammad Arsalan, Abdulaziz Al-Ali, Shidin Balakrishnan
Abstract: The growing popularity of robotic minimally invasive surgeries has made deep learning-based surgical training a key area of research. A thorough understanding of the surgical scene components is crucial, which semantic segmentation models can help achieve. However, most existing work focuses on surgical tools and overlooks anatomical objects. Additionally, current state-of-the-art (SOTA) models struggle to balance capturing high-level contextual features and low-level edge features. We propose a Feature-Adaptive Spatial Localization model (FASL-Seg), designed to capture features at multiple levels of detail through two distinct processing streams, namely a Low-Level Feature Projection (LLFP) and a High-Level Feature Projection (HLFP) stream, for varying feature resolutions - enabling precise segmentation of anatomy and surgical instruments. We evaluated FASL-Seg on surgical segmentation benchmark datasets EndoVis18 and EndoVis17 on three use cases. The FASL-Seg model achieves a mean Intersection over Union (mIoU) of 72.71% on parts and anatomy segmentation in EndoVis18, improving on SOTA by 5%. It further achieves a mIoU of 85.61% and 72.78% in EndoVis18 and EndoVis17 tool type segmentation, respectively, outperforming SOTA overall performance, with comparable per-class SOTA results in both datasets and consistent performance in various classes for anatomy and instruments, demonstrating the effectiveness of distinct processing streams for varying feature resolutions.

Paper number 103:
Title: Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems
Authors: Yi-Cheng Lin, Huang-Cheng Chou, Tzu-Chieh Wei, Kuan-Yu Chen, Hung-yi Lee
Abstract: Instruction-guided text-to-speech (ITTS) enables users to control speech generation through natural language prompts, offering a more intuitive interface than traditional TTS. However, the alignment between user style instructions and listener perception remains largely unexplored. This work first presents a perceptual analysis of ITTS controllability across two expressive dimensions (adverbs of degree and graded emotion intensity) and collects human ratings on speaker age and word-level emphasis attributes. To comprehensively reveal the instruction-perception gap, we provide a data collection with large-scale human evaluations, named Expressive VOice Control (E-VOC) corpus. Furthermore, we reveal that (1) gpt-4o-mini-tts is the most reliable ITTS model with great alignment between instruction and generated utterances across acoustic dimensions. (2) The 5 analyzed ITTS systems tend to generate Adult voices even when the instructions ask to use child or Elderly voices. (3) Fine-grained control remains a major challenge, indicating that most ITTS systems have substantial room for improvement in interpreting slightly different attribute instructions.

Paper number 104:
Title: Backward Reachability Analysis of Perturbed Continuous-Time Linear Systems Using Set Propagation
Authors: Mark Wetzlinger, Matthias Althoff
Abstract: Backward reachability analysis computes the set of states that reach a target set under the competing influence of control input and disturbances. Depending on their interplay, the backward reachable set either represents all states that can be steered into the target set or all states that cannot avoid entering it -- the corresponding solutions can be used for controller synthesis and safety verification, respectively. A popular technique for backward reachable set computation solves Hamilton-Jacobi-Isaacs equations, which scales exponentially with the state dimension due to gridding the state space. In this work, we instead use set propagation techniques to design backward reachability algorithms for linear time-invariant systems. Crucially, the proposed algorithms scale only polynomially with the state dimension. Our numerical examples demonstrate the tightness of the obtained backward reachable sets and show an overwhelming improvement of our proposed algorithms over state-of-the-art methods regarding scalability, as systems with well over a hundred states can now be analyzed.

Paper number 105:
Title: Sensing environmental physical interaction to traverse cluttered obstacles
Authors: Yaqing Wang, Ling Xu, Chen Li
Abstract: The long-standing, dominant approach to robotic obstacle negotiation relies on mapping environmental geometry to avoid obstacles. However, this approach does not allow for traversal of cluttered obstacles, hindering applications such as search and rescue operations through earthquake rubble and exploration across lunar and Martian rocks. To overcome this challenge, robots must further sense and utilize environmental physical interactions to control themselves to traverse obstacles. Recently, a physics-based approach has been established towards this vision. Self-propelled robots interacting with obstacles results in a potential energy landscape. On this landscape, to traverse obstacles, a robot must escape from certain landscape basins that attract it into failure modes, to reach other basins that lead to successful modes. Thus, sensing the potential energy landscape is crucial. Here, we developed new methods and performed systematic experiments to demonstrate that the potential energy landscape can be estimated by sensing environmental physical interaction. We developed a minimalistic robot capable of sensing obstacle contact forces and torques for systematic experiments over a wide range of parameter space. Surprisingly, although these forces and torques are not fully conservative, they match the potential energy landscape gradients that are conservative forces and torques, enabling an accurate estimation of the potential energy landscape. Additionally, a bio-inspired strategy further enhanced estimation accuracy. Our results provided a foundation for further refining these methods for use in free-locomoting robots. Our study is a key step in establishing a new physics-based approach for robots to traverse clustered obstacles to advance their mobility in complex, real-world environments.

Paper number 106:
Title: Domain Generalization for In-Orbit 6D Pose Estimation
Authors: Antoine Legrand, Renaud Detry, Christophe De Vleeschouwer
Abstract: We address the problem of estimating the relative 6D pose, i.e., position and orientation, of a target spacecraft, from a monocular image, a key capability for future autonomous Rendezvous and Proximity Operations. Due to the difficulty of acquiring large sets of real images, spacecraft pose estimation networks are exclusively trained on synthetic ones. However, because those images do not capture the illumination conditions encountered in orbit, pose estimation networks face a domain gap problem, i.e., they do not generalize to real images. Our work introduces a method that bridges this domain gap. It relies on a novel, end-to-end, neural-based architecture as well as a novel learning strategy. This strategy improves the domain generalization abilities of the network through multi-task learning and aggressive data augmentation policies, thereby enforcing the network to learn domain-invariant features. We demonstrate that our method effectively closes the domain gap, achieving state-of-the-art accuracy on the widespread SPEED+ dataset. Finally, ablation studies assess the impact of key components of our method on its generalization abilities.

Paper number 107:
Title: Silent Speech Sentence Recognition with Six-Axis Accelerometers using Conformer and CTC Algorithm
Authors: Yudong Xie, Zhifeng Han, Qinfan Xiao, Liwei Liang, Lu-Qi Tao, Tian-Ling Ren
Abstract: Silent speech interfaces (SSI) are being actively developed to assist individuals with communication impairments who have long suffered from daily hardships and a reduced quality of life. However, silent sentences are difficult to segment and recognize due to elision and linking. A novel silent speech sentence recognition method is proposed to convert the facial motion signals collected by six-axis accelerometers into transcribed words and sentences. A Conformer-based neural network with the Connectionist-Temporal-Classification algorithm is used to gain contextual understanding and translate the non-acoustic signals into words sequences, solely requesting the constituent words in the database. Test results show that the proposed method achieves a 97.17% accuracy in sentence recognition, surpassing the existing silent speech recognition methods with a typical accuracy of 85%-95%, and demonstrating the potential of accelerometers as an available SSI modality for high-accuracy silent speech sentence recognition.

Paper number 108:
Title: GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music
Authors: Xinran Liu, Xu Dong, Diptesh Kanojia, Wenwu Wang, Zhenhua Feng
Abstract: Generating high-quality full-body dance sequences from music is a challenging task as it requires strict adherence to genre-specific choreography. Moreover, the generated sequences must be both physically realistic and precisely synchronized with the beats and rhythm of the music. To overcome these challenges, we propose GCDance, a classifier-free diffusion framework for generating genre-specific dance motions conditioned on both music and textual prompts. Specifically, our approach extracts music features by combining high-level pre-trained music foundation model features with hand-crafted features for multi-granularity feature fusion. To achieve genre controllability, we leverage CLIP to efficiently embed genre-based textual prompt representations at each time step within our dance generation pipeline. Our GCDance framework can generate diverse dance styles from the same piece of music while ensuring coherence with the rhythm and melody of the music. Extensive experimental results obtained on the FineDance dataset demonstrate that GCDance significantly outperforms the existing state-of-the-art approaches, which also achieve competitive results on the AIST++ dataset. Our ablation and inference time analysis demonstrate that GCDance provides an effective solution for high-quality music-driven dance generation.

Paper number 109:
Title: Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection
Authors: Md Fahimuzzman Sohan, Raid Alzubi, Hadeel Alzoubi, Eid Albalawi, A. H. Abdul Hafez
Abstract: Cattle lameness is a prevalent health problem in livestock farming, often resulting from hoof injuries or infections, and severely impacts animal welfare and productivity. Early and accurate detection is critical for minimizing economic losses and ensuring proper treatment. This study proposes a spatiotemporal deep learning framework for automated cattle lameness detection using publicly available video data. We curate and publicly release a balanced set of 50 online video clips featuring 42 individual cattle, recorded from multiple viewpoints in both indoor and outdoor environments. The videos were categorized into lame and non-lame classes based on visual gait characteristics and metadata descriptions. After applying data augmentation techniques to enhance generalization, two deep learning architectures were trained and evaluated: 3D Convolutional Neural Networks (3D CNN) and Convolutional Long-Short-Term Memory (ConvLSTM2D). The 3D CNN achieved a video-level classification accuracy of 90%, with a precision, recall, and F1 score of 90.9% each, outperforming the ConvLSTM2D model, which achieved 85% accuracy. Unlike conventional approaches that rely on multistage pipelines involving object detection and pose estimation, this study demonstrates the effectiveness of a direct end-to-end video classification approach. Compared with the best end-to-end prior method (C3D-ConvLSTM, 90.3%), our model achieves comparable accuracy while eliminating pose estimation this http URL results indicate that deep learning models can successfully extract and learn spatio-temporal features from various video sources, enabling scalable and efficient cattle lameness detection in real-world farm settings.

Paper number 110:
Title: Learning Conservative Neural Control Barrier Functions from Offline Data
Authors: Ihab Tabbara, Hussein Sibai
Abstract: Safety filters, particularly those based on control barrier functions, have gained increased interest as effective tools for safe control of dynamical systems. Existing correct-by-construction synthesis algorithms for such filters, however, suffer from the curse-of-dimensionality. Deep learning approaches have been proposed in recent years to address this challenge. In this paper, we add to this set of approaches an algorithm for training neural control barrier functions from offline datasets. Such functions can be used to design constraints for quadratic programs that are then used as safety filters. Our algorithm trains these functions so that the system is not only prevented from reaching unsafe states but is also disincentivized from reaching out-of-distribution ones, at which they would be less reliable. It is inspired by Conservative Q-learning, an offline reinforcement learning algorithm. We call its outputs Conservative Control Barrier Functions (CCBFs). Our empirical results demonstrate that CCBFs outperform existing methods in maintaining safety while minimally affecting task performance. Source code is available at this https URL.

Paper number 111:
Title: MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation
Authors: Woohyun Cho, Youngmin Kim, Sunghyun Lee, Youngjae Yu
Abstract: Lyrics translation requires both accurate semantic transfer and preservation of musical rhythm, syllabic structure, and poetic style. In animated musicals, the challenge intensifies due to alignment with visual and auditory cues. We introduce Multilingual Audio-Video Lyrics Benchmark for Animated Song Translation (MAVL), the first multilingual, multimodal benchmark for singable lyrics translation. By integrating text, audio, and video, MAVL enables richer and more expressive translations than text-only approaches. Building on this, we propose Syllable-Constrained Audio-Video LLM with Chain-of-Thought SylAVL-CoT, which leverages audio-video cues and enforces syllabic constraints to produce natural-sounding lyrics. Experimental results demonstrate that SylAVL-CoT significantly outperforms text-based models in singability and contextual accuracy, emphasizing the value of multimodal, multilingual approaches for lyrics translation.

Paper number 112:
Title: A Test-Function Approach to Incremental Stability
Authors: Daniel Pfrommer, Max Simchowitz, Ali Jadbabaie
Abstract: This paper presents a novel framework for analyzing Incremental-Input-to-State Stability ($\delta$ISS) based on the idea of using rewards as "test functions." Whereas control theory traditionally deals with Lyapunov functions that satisfy a time-decrease condition, reinforcement learning (RL) value functions are constructed by exponentially decaying a Lipschitz reward function that may be non-smooth and unbounded on both sides. Thus, these RL-style value functions cannot be directly understood as Lyapunov certificates. We develop a new equivalence between a variant of incremental input-to-state stability of a closed-loop system under given a policy, and the regularity of RL-style value functions under adversarial selection of a Hölder-continuous reward function. This result highlights that the regularity of value functions, and their connection to incremental stability, can be understood in a way that is distinct from the traditional Lyapunov-based approach to certifying stability in control theory.

Paper number 113:
Title: Adaptive Linearly Constrained Minimum Variance Framework for Volumetric Active Noise Control
Authors: Manan Mittal, Ryan M. Corey, Andrew C. Singer
Abstract: Traditional volumetric noise control typically relies on multipoint error minimization to suppress sound energy across a region, but offers limited flexibility in shaping spatial responses. This paper introduces a time domain formulation for linearly constrained minimum variance active noise control (LCMV ANC) for spatial control filter design. We demonstrate how the LCMV ANC optimization framework allows system designers to prioritize noise reduction at specific spatial locations through strategically defined linear constraints, providing a more flexible alternative to uniformly weighted multi point error minimization. An adaptive algorithm based of filtered X least mean squares (FxLMS) is derived for online adaptation of filter coefficients. Simulation and experimental results validate the proposed method's noise reduction and constraint adherence, demonstrating effective, spatially selective and broadband noise control compared to multipoint volumetric noise control.

Paper number 114:
Title: FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation
Authors: Yuxuan Jiang, Zehua Chen, Zeqian Ju, Chang Li, Weibei Dou, Jun Zhu
Abstract: Text-to-audio (T2A) generation has achieved promising results with the recent advances in generative models. However, because of the limited quality and quantity of temporally-aligned audio-text pairs, existing T2A methods struggle to handle the complex text prompts that contain precise timing control, e.g., "owl hooted at 2.4s-5.2s". Recent works have explored data augmentation techniques or introduced timing conditions as model inputs to enable timing-conditioned 10-second T2A generation, while their synthesis quality is still limited. In this work, we propose a novel training-free timing-controlled T2A framework, FreeAudio, making the first attempt to enable timing-controlled long-form T2A generation, e.g., "owl hooted at 2.4s-5.2s and crickets chirping at 0s-24s". Specifically, we first employ an LLM to plan non-overlapping time windows and recaption each with a refined natural language description, based on the input text and timing prompts. Then we introduce: 1) Decoupling and Aggregating Attention Control for precise timing control; 2) Contextual Latent Composition for local smoothness and Reference Guidance for global consistency. Extensive experiments show that: 1) FreeAudio achieves state-of-the-art timing-conditioned T2A synthesis quality among training-free methods and is comparable to leading training-based methods; 2) FreeAudio demonstrates comparable long-form generation quality with training-based Stable Audio and paves the way for timing-controlled long-form T2A synthesis. Demo samples are available at: this https URL

Paper number 115:
Title: SALM: Spatial Audio Language Model with Structured Embeddings for Understanding and Editing
Authors: Jinbo Hu, Yin Cao, Ming Wu, Zhenbo Luo, Jun Yang
Abstract: Spatial audio understanding is essential for accurately perceiving and interpreting acoustic environments. However, existing audio-language models exhibit limitations in processing spatial audio and perceiving spatial acoustic scenes. To address this gap, we propose the Spatial Audio Language Model (SALM), a novel framework that bridges spatial audio and language through multi-modal contrastive learning. SALM integrates a text encoder with a dual-branch audio encoder that decomposes spatial sound into semantic and spatial components via structured audio embeddings. Key features of SALM include seamless alignment between spatial audio and natural language, both separate and joint extraction of spatial and semantic representations, zero-shot direction classification, and flexible support for spatial audio editing. Experimental results demonstrate that SALM effectively captures and aligns cross-modal representations, yielding well-structured audio embeddings. Furthermore, SALM enables advanced editing capabilities, such as modifying directional audio using text-based embeddings.

Paper number 116:
Title: AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting
Authors: Chen Zeng, Tiehang Xu, Qiao Wang
Abstract: Traditional neural networks struggle to capture the spectral structure of complex signals. Fourier neural networks (FNNs) attempt to address this by embedding Fourier series components, yet many real-world signals are almost-periodic with non-commensurate frequencies, posing additional challenges. Building on prior work showing that ARIMA outperforms large language models (LLMs) for forecasting, we extend the comparison to neural predictors and find ARIMA still superior. We therefore propose the Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network (AR-KAN), which integrates a pre-trained AR module for temporal memory with a KAN for nonlinear representation. The AR module preserves essential temporal features while reducing redundancy. Experiments demonstrate that AR-KAN matches ARIMA on almost-periodic functions and achieves the best results on $72\%$ of Rdatasets series, with a clear advantage on data with periodic structure. These results highlight AR-KAN as a robust and effective framework for time series forecasting.

Paper number 117:
Title: Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering
Authors: Jinghua Zhao, Hang Su, Lichun Fan, Zhenbo Luo, Hui Wang, Haoqin Sun, Yong Qin
Abstract: With the rapid progress of large audio-language models (LALMs), audio question answering (AQA) has emerged as a challenging task requiring both fine-grained audio understanding and complex reasoning. While current methods mainly rely on constructing new datasets via captioning or reasoning traces, existing high-quality AQA data remains underutilized. To address this, we propose Omni-CLST, an error-aware Curriculum Learning framework with guided Selective Chain-of-Thought. The framework efficiently leverages existing high-quality dataset through two key strategies: an error-aware curriculum that organizes samples by difficulty, and a guided thought dropout mechanism that focuses reasoning on challenging cases. Experiments show that Omni-CLST achieves 73.80% on MMAU-mini and a new state of the art of 64.30% on MMAR, demonstrating robust generalization in multimodal audio-language understanding.

Paper number 118:
Title: FunAudio-ASR Technical Report
Authors: Keyu An, Yanni Chen, Chong Deng, Changfeng Gao, Zhifu Gao, Bo Gong, Xiangang Li, Yabin Li, Xiang Lv, Yunjie Ji, Yiheng Jiang, Bin Ma, Haoneng Luo, Chongjia Ni, Zexu Pan, Yiping Peng, Zhendong Peng, Peiyao Wang, Hao Wang, Wen Wang, Wupeng Wang, Biao Tian, Zhentao Tan, Nan Yang, Bin Yuan, Jieping Ye, Jixing Yu, Qinglin Zhang, Kun Zou, Han Zhao, Shengkui Zhao, Jingren Zhou
Abstract: In recent years, automatic speech recognition (ASR) has witnessed transformative advancements driven by three complementary paradigms: data scaling, model size scaling, and deep integration with large language models (LLMs). However, LLMs are prone to hallucination, which can significantly degrade user experience in real-world ASR applications. In this paper, we present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically combines massive data, large model capacity, LLM integration, and reinforcement learning to achieve state-of-the-art performance across diverse and complex speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized for practical deployment, with enhancements in streaming capability, noise robustness, code-switching, hotword customization, and satisfying other real-world application requirements. Experimental results show that while most LLM-based ASR systems achieve strong performance on open-source benchmarks, they often underperform on real industry evaluation sets. Thanks to production-oriented optimizations, FunAudio-ASR achieves SOTA performance on real application datasets, demonstrating its effectiveness and robustness in practical settings.
    