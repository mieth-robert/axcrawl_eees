
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Estimating Control Barriers from Offline Data
Authors: Hongzhan Yu, Seth Farrell, Ryo Yoshimitsu, Zhizhen Qin, Henrik I. Christensen, Sicun Gao
Abstract: Learning-based methods for constructing control barrier functions (CBFs) are gaining popularity for ensuring safe robot control. A major limitation of existing methods is their reliance on extensive sampling over the state space or online system interaction in simulation. In this work we propose a novel framework for learning neural CBFs through a fixed, sparsely-labeled dataset collected prior to training. Our approach introduces new annotation techniques based on out-of-distribution analysis, enabling efficient knowledge propagation from the limited labeled data to the unlabeled data. We also eliminate the dependency on a high-performance expert controller, and allow multiple sub-optimal policies or even manual control during data collection. We evaluate the proposed method on real-world platforms. With limited amount of offline data, it achieves state-of-the-art performance for dynamic obstacle avoidance, demonstrating statistically safer and less conservative maneuvers compared to existing methods.

Paper number 2:
Title: Deep Learning-Based Automated Workflow for Accurate Segmentation and Measurement of Abdominal Organs in CT Scans
Authors: Praveen Shastry, Ashok Sharma, Kavya Mohan, Naveen Kumarasami, Anandakumar D, Mounigasri M, Keerthana R, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: Automated analysis of CT scans for abdominal organ measurement is crucial for improving diagnostic efficiency and reducing inter-observer variability. Manual segmentation and measurement of organs such as the kidneys, liver, spleen, and prostate are time-consuming and subject to inconsistency, underscoring the need for automated approaches. Purpose: The purpose of this study is to develop and validate an automated workflow for the segmentation and measurement of abdominal organs in CT scans using advanced deep learning models, in order to improve accuracy, reliability, and efficiency in clinical evaluations. Methods: The proposed workflow combines nnU-Net, U-Net++ for organ segmentation, followed by a 3D RCNN model for measuring organ volumes and dimensions. The models were trained and evaluated on CT datasets with metrics such as precision, recall, and Mean Squared Error (MSE) to assess performance. Segmentation quality was verified for its adaptability to variations in patient anatomy and scanner settings. Results: The developed workflow achieved high precision and recall values, exceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were low, indicating a high level of consistency between predicted and ground truth measurements. The segmentation and measurement pipeline demonstrated robust performance, providing accurate delineation and quantification of the kidneys, liver, spleen, and prostate. Conclusion: The proposed approach offers an automated, efficient, and reliable solution for abdominal organ measurement in CT scans. By significantly reducing manual intervention, this workflow enhances measurement accuracy and consistency, with potential for widespread clinical implementation. Future work will focus on expanding the approach to other organs and addressing complex pathological cases.

Paper number 3:
Title: EEG-Based Decoding of Sound Location: Comparing Free-Field to Headphone-Based Non-Individual HRTFs
Authors: Nils Marggraf-Turley, Martha Shiell, Niels Pontoppidan, Drew Cappotto, Lorenzo Picinali
Abstract: Sound source localization relies on spatial cues such as interaural time differences (ITD), interaural level differences (ILD), and monaural spectral cues. Individually measured Head-Related Transfer Functions (HRTFs) facilitate precise spatial hearing but are impractical to measure, necessitating non-individual HRTFs, which may compromise localization accuracy and externalization. To further investigate this phenomenon, the neurophysiological differences between free-field and non-individual HRTF listening are explored by decoding sound locations from EEG-derived Event-Related Potentials (ERPs). Twenty-two participants localized stimuli under both conditions with EEG responses recorded and logistic regression classifiers trained to distinguish sound source locations. Lower cortical response amplitudes were observed for KEMAR compared to free-field, especially in front-central and occipital-parietal regions. ANOVA identified significant main effects of auralization condition (F(1, 21) = 34.56, p < 0.0001) and location (F(3, 63) = 18.17, p < 0.0001) on decoding accuracy (DA), which was higher in free-field and interaural-cue-dominated locations. DA negatively correlated with front-back confusion rates (r = -0.57, p < 0.01), linking neural DA to perceptual confusion. These findings demonstrate that headphone-based non-individual HRTFs elicit lower amplitude cortical responses to static, azimuthally-varying locations than free-field conditions. The correlation between EEG-based DA and front-back confusion underscores neurophysiological markers' potential for assessing spatial auditory discrimination.

Paper number 4:
Title: Multipath Component Power Delay Profile Based Joint Range and Doppler Estimation for AFDM-ISAC Systems
Authors: Fangqing Xiao, Zunqi Li, Dirk Slock
Abstract: Integrated Sensing and Communication (ISAC) systems combine sensing and communication functionalities within a unified framework, enhancing spectral efficiency and reducing costs by utilizing shared hardware components. This paper investigates multipath component power delay profile (MPCPDP)-based joint range and Doppler estimation for Affine Frequency Division Multiplexing (AFDM)-ISAC systems. The path resolvability of the equivalent channel in the AFDM system allows the recognition of Line-of-Sight (LoS) and Non-Line-of-Sight (NLoS) paths within a single pilot symbol in fast time-varying channels. We develop a joint estimation model that leverages multipath Doppler shifts and delays information under the AFDM waveform. Utilizing the MPCPDP, we propose a novel ranging method that exploits the range-dependent magnitude of the MPCPDP across its delay spread by constructing a Nakagami-m statistical fading model for MPC channel fading and correlating the distribution parameters with propagation distance in AFDM systems. This method eliminates the need for additional time synchronization or extra hardware. We also transform the nonlinear Doppler estimation problem into a bilinear estimation problem using a First-order Taylor expansion. Moreover, we introduce the Expectation Maximization algorithm to estimate the hyperparameters and leverage the Expectation Consistent algorithm to cope with high-dimensional integration challenges. Extensive numerical simulations demonstrate the effectiveness of our MPCPDP-based joint range and Doppler estimation in ISAC systems.

Paper number 5:
Title: On Dynamic Mode Decomposition of Control-affine Systems
Authors: Moad Abudia, Joel A. Rosenfeld, Rushikesh Kamalapurkar
Abstract: This paper builds on the theoretical foundations for dynamic mode decomposition (DMD) of control-affine dynamical systems by leveraging the theory of vector-valued reproducing kernel Hilbert spaces (RKHSs). Specifically, control Liouville operators and control occupation kernels are used to separate the drift dynamics from the input dynamics. A provably convergent finite-rank estimation of a compact control Liouville operator is obtained, provided sufficiently rich data are available. A matrix representation of the finite-rank operator is used to construct a data-driven representation of its singular values, left singular functions, and right singular functions. The singular value decomposition is used to generate a data-driven model of the control-affine nonlinear system. The developed method generates a model that can be used to predict the trajectories of the system in response to any admissible control input. Numerical experiments are included to demonstrate the efficacy of the developed technique.

Paper number 6:
Title: Degradation-Aware Microgrid Optimal Planning: Integrating Dynamic Energy Efficiencies and Second-Life Battery Potential
Authors: Hassan Zahid Butt, Xingpeng Li
Abstract: Traditional microgrid planning often overlooks PV and BESS degradation or relies on complex, downscaled models, leading to unreliable, costly and suboptimal investment decisions. This paper presents a degradation-based investment optimization (DBIO) methodology for long-term microgrid planning. The model optimally sizes and schedules PV, BESS, and controllable distributed energy resources, while considering technical, financial, and degradation characteristics. We first developed a cumulative multi-year optimization model as a benchmark, excluding BESS efficiency fade and capacity degradation that would be captured in the next step, to ensure convergence. Subsequently, a yearly validation model was iteratively solved for each year in the planning horizon, updating energy efficiencies of PV and BESS, along with BESS capacity, based on annual degradation, ensuring the reliability of initial solution. An iterative refinement process further adjusts BESS capacity to eliminate load shedding while minimizing costs. Sensitivity analyses on PV efficiency degradation rates, second-life battery (SLB) capital cost, and grid tariffs further explore their economic implications. Results show that degradation significantly impacts resource allocation, with ignored degradation risking reliability, potential load shedding, and blackout costs, while SLBs provide cost-saving opportunities. The DBIO framework offers a computationally efficient and scalable solution for microgrid planning, with broader applications in grid-scale asset management.

Paper number 7:
Title: Decode and Forward Relaying for SC-FDE Systems with a Multi-Antenna Relay
Authors: Farshad Dizani, Ali Olfat
Abstract: In this paper, a cooperative relay network consisting of a single-antenna source, a multi-antenna relay, and a multi-antenna destination is considered. The relay operates in decode-and-forward (DF) mode under frequency-selective fading. To combat intersymbol interference (ISI), single-carrier frequency-domain equalization (SC-FDE) with or without decision feedback is deployed at the relay and the destination. The equalization coefficients are obtained using minimum mean squared error (MMSE) criterion. Both equal and optimum power allocations for a constant total transmit power at the relay are considered. While, the optimum power allocation is a non-convex problem, the solution is obtained using strong duality.

Paper number 8:
Title: A review on modelling, evaluation, and optimization of cyber-physical system reliability
Authors: Moslem Uddin, Huadong Mo, Daoyi Dong
Abstract: The aim of this study is to present an overview of current research on modelling, evaluation, and optimization methods for improving the reliability of Cyber-Physical System (CPS). Three major modelling approaches, namely analytical, simulation, and hybrid models, are discussed. Various evaluation techniques, including fault tree analysis, Markov models, and availability measures, are reviewed and compared. Optimization strategies for CPS reliability, including fault tolerance, dynamic reconfiguration, and resource allocation, are also reviewed and briefly discussed. Besides, emerging trends and research opportunities in this field are highlighted and explained. Finally, the possible challenges are outlined and then future research are directed for CPS. This study can provide a systematic and in-dept introduction to CPS for researchers, practitioners, and policymakers.

Paper number 9:
Title: Adaptive model predictive control for traffic signal timing with unknown demand and parameters
Authors: Zhexian Li, Ketan Savla
Abstract: This paper designs traffic signal control policies for a network of signalized intersections without knowing the demand and parameters. Within a model predictive control (MPC) framework, control policies consist of an algorithm that estimates parameters and a one-step MPC that computes control inputs using estimated parameters. The algorithm switches between different terminal sets of the MPC to explore different regions of the state space, where different parameters are identifiable. The one-step MPC minimizes a cost that approximates the sum of squares of all the queue lengths within a constant and does not require demand information. We show that the algorithm can estimate parameters exactly in finite time, and the one-step MPC renders maximum throughput in terms of input-to-state practical stability. Simulations indicate better transient performance regarding queue lengths under our proposed policies than existing ones.

Paper number 10:
Title: Safe Control of Second-Order Systems with Linear Constraints
Authors: Mohammed Alyaseen, Nikolay Atanasov, Jorge Cortes
Abstract: Control barrier functions (CBFs) offer a powerful tool for enforcing safety specifications in control synthesis. This paper deals with the problem of constructing valid CBFs. Given a second-order system and any desired safety set with linear boundaries in the position space, we construct a provably control-invariant subset of this desired safety set. The constructed subset does not sacrifice any positions allowed by the desired safety set, which can be nonconvex. We show how our construction can also meet safety specification on the velocity. We then demonstrate that if the system satisfies standard Euler-Lagrange systems properties then our construction can also handle constraints on the allowable control inputs. We finally show the efficacy of the proposed method in a numerical example of keeping a 2D robot arm safe from collision.

Paper number 11:
Title: A Weighted Predict-and-Optimize Framework for Power System Operation Considering Varying Impacts of Uncertainty
Authors: Yingrui Zhuang, Lin Cheng, Can Wan, Rui Xie, Ning Qi, Yue Chen
Abstract: Integrating prediction and optimization enhances decision-making quality by yielding near optimal solutions. Given that prediction errors associated with multiple uncertainties have varying impacts on downstream decision-making, improving the prediction accuracy of critical uncertainties with significant impacts on decision-making quality yields better optimization results. Inspired by this observation, this paper proposes a novel weighted predict-and-optimize (WPO) framework for decision-making under uncertainty. Specifically, we introduce an uncertainty-aware weighting mechanism into the predictive model to capture the relative importance of each uncertainty for specific optimization tasks, and introduce a problem-driven prediction loss (PDPL) to quantify the suboptimality of weighted predictions for downstream optimization as compared to perfect predictions. By optimizing the uncertainty weights to minimize the PDPL, WPO framework enables adaptive uncertainty impact assessment and integrated learning of prediction and optimization. Furthermore, to facilitate weight optimization, we construct a surrogate model to establish the mapping between weights and PDPL, where multi-task learning and enhanced graph convolutional networks are adopted for efficient surrogate model construction and training. Numerical experiments on modified IEEE 33-bus and 123-bus systems demonstrate that the proposed WPO framework outperforms traditional methods by achieving a much smaller PDPL within acceptable computational time.

Paper number 12:
Title: Approximate Reachable Sets using Singularly Perturbed Differential Games, with Application to Biological System Models
Authors: Dylan Hirsch, Sylvia Herbert
Abstract: Hamilton-Jacobi Reachability (HJR) is an exciting framework used for control of safety-critical systems with nonlinear and possibly uncertain dynamics. However, HJR suffers from the curse of dimensionality, with computation times growing exponentially in the dimension of the system state. Many autonomous and controlled systems involve dynamics that evolve on multiple timescales, and for these systems, singular perturbation methods can be used for model reduction. However, such methods are more challenging to apply in HJR due to the presence of an underlying differential game. In this work, we leverage prior work on singularly perturbed differential games to identify a class of systems which can be readily reduced, and we relate these results to the quantities of interest in HJR. We demonstrate the utility of our results on two examples involving biological systems, where dynamics fitting the identified class are frequently encountered.

Paper number 13:
Title: MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation
Authors: Sungwoo Cho, Jeongsoo Choi, Sungnyun Kim, Se-Young Yun
Abstract: Despite recent advances in text-to-speech (TTS) models, audio-visual to audio-visual (AV2AV) translation still faces a critical challenge: maintaining speaker consistency between the original and translated vocal and facial features. To address this issue, we propose a conditional flow matching (CFM) zero-shot audio-visual renderer that utilizes strong dual guidance from both audio and visual modalities. By leveraging multi-modal guidance with CFM, our model robustly preserves speaker-specific characteristics and significantly enhances zero-shot AV2AV translation abilities. For the audio modality, we enhance the CFM process by integrating robust speaker embeddings with x-vectors, which serve to bolster speaker consistency. Additionally, we convey emotional nuances to the face rendering module. The guidance provided by both audio and visual cues remains independent of semantic or linguistic content, allowing our renderer to effectively handle zero-shot translation tasks for monolingual speakers in different languages. We empirically demonstrate that the inclusion of high-quality mel-spectrograms conditioned on facial information not only enhances the quality of the synthesized speech but also positively influences facial generation, leading to overall performance improvements.

Paper number 14:
Title: Evaluation of the Impact of IBR on the Frequency Dynamics in the Brazilian Power System
Authors: Bruno Pinheiro, M. C. Llerena Velasquez, Giovane Faria, A. F. C. Aquino, Diego Issicaba, Daniel Dotta
Abstract: In this paper, the impact of inverter-based resources (IBRs) on the frequency dynamics of the Brazilian Interconnected Power System (BIPS) is evaluated. A measurement-based framework is proposed to assess the impact of IBR penetration on the system-wide and regional/local frequency dynamic. The analysis leverages data from a low-voltage wide area monitoring system (WAMS) and publicly available historical generation records from the Brazilian System Operator. A methodology is introduced to extract local frequency fluctuations across regions using a variational mode decomposition (VMD) approach. The findings reveal a continuous degradation in the system-wide frequency and local frequency variations, underscoring the need for enhanced regional monitoring and evaluation metrics to maintain frequency stability in large-scale interconnected systems.

Paper number 15:
Title: MobiVital: Self-supervised Time-series Quality Estimation for Contactless Respiration Monitoring Using UWB Radar
Authors: Ziqi Wang, Derek Hua, Wenjun Jiang, Tianwei Xing, Xun Chen, Mani Srivastava
Abstract: Respiration waveforms are increasingly recognized as important biomarkers, offering insights beyond simple respiration rates, such as detecting breathing irregularities for disease diagnosis or monitoring breath patterns to guide rehabilitation training. Previous works in wireless respiration monitoring have primarily focused on estimating respiration rate, where the breath waveforms are often generated as a by-product. As a result, issues such as waveform deformation and inversion have largely been overlooked, reducing the signal's utility for applications requiring breathing waveforms. To address this problem, we present a novel approach, MobiVital, that improves the quality of respiration waveforms obtained from ultra-wideband (UWB) radar data. MobiVital combines a self-supervised autoregressive model for breathing waveform extraction with a biology-informed algorithm to detect and correct waveform inversions. To encourage reproducible research efforts for developing wireless vital signal monitoring systems, we also release a 12-person, 24-hour UWB radar vital signal dataset, with time-synchronized ground truth obtained from wearable sensors. Our results show that the respiration waveforms produced by our system exhibit a 7-34% increase in fidelity to the ground truth compared to the baselines and can benefit downstream tasks such as respiration rate estimation.

Paper number 16:
Title: Inverter Control with Time-Varying and Nonconvex State and Input Constraints
Authors: Zixiao Ma, Baosen Zhang
Abstract: The growing integration of inverter-based resources (IBRs) into modern power systems poses significant challenges for maintaining reliable operation under dynamic and constrained conditions. This paper focuses on the power tracking problem for grid-connected IBRs, addressing the complexities introduced by voltage and power factor constraints. Voltage constraints, being time-varying and nonlinear input constraints, often conflict with power factor constraints, which are state constraints. These conflicts, coupled with stability requirements, add substantial complexity to control design. To overcome these challenges, we propose a computationally efficient static state-feedback controller that guarantees stability and satisfies operational constraints. The concept of achievability is introduced to evaluate whether power setpoints can be accurately tracked while adhering to all constraints. Using a parameterization framework and the S-lemma, we develop criteria to assess and maximize the continuous achievable region for IBR operation. This framework allows system operators to ensure safety and stability by precomputing a finite set of control gains, significantly reducing online computational requirements. The proposed approach is validated through simulations, demonstrating its effectiveness in handling time-varying grid disturbances and achieving reliable control performance.

Paper number 17:
Title: Deep Learning-based OTFS Channel Estimation and Symbol Detection with Plug and Play Framework
Authors: Xiaoqi Zhang, Zhitong Ni, Weijie Yuan, J. Andrew Zhang
Abstract: Orthogonal Time Frequency Space (OTFS) modulation has recently attracted significant interest due to its potential for enabling reliable communication in high-mobility environments. One of the challenges for OTFS receivers is the fractional Doppler that occurs in practical systems, resulting in decreased channel sparsity, and then inaccurate channel estimation and high-complexity equalization. In this paper, we propose a novel unsupervised deep learning (DL)-based OTFS channel estimation and symbol detection scheme, capable of handling different channel conditions, even in the presence of fractional Doppler. In particular, we design a unified plug-and-play (PnP) framework, which can jointly exploit the flexibility of optimization-based methods and utilize the powerful data-driven capability of DL. A lightweight Unet is integrated into the framework as a powerful implicit channel prior for channel estimation, leading to better exploitation of the channel sparsity and the characteristic of the noise simultaneously. Furthermore, to mitigate the channel estimation errors, we realize the PnP framework with a fully connected (FC) network for symbol detection at different noise levels, thereby enhancing robustness. Finally, numerical results demonstrate the effectiveness and robustness of the algorithm.

Paper number 18:
Title: Joint Optimization of Resource Allocation and Radar Receiver Selection in Integrated Communication-Radar Systems
Authors: Chen Zhong, Xufeng Zhou, Lan Tang, Mengting Lou
Abstract: In this paper, we investigate a distributed multi-input multi-output and orthogonal frequency division multiplexing (MIMO-OFDM) dual-function radar-communication (DFRC) system, which enables simultaneous communication and sensing in different subcarrier sets. To obtain the best tradeoff between communication and sensing performance, we first derive Cramer-Rao Bound (CRB) of targets in the detection area, and then maximize the transmission rate by jointly optimizing the power/subcarriers allocation and the selection of radar receivers under the constraints of detection performance and total transmit power. To tackle the non-convex mixed integer programming problem, we decompose the original problem into a semidefinite programming (SDP) problem and a convex quadratic integer problem and solve them iteratively. The numerical results demonstrate the effectiveness of our proposed algorithm, as well as the performance improvement brought by optimizing radar receivers selection.

Paper number 19:
Title: Flexible Intelligent Metasurface-Aided Wireless Communications: Architecture and Performance
Authors: Songjie Yang, Zihang Wan, Boyu Ning, Weidong Mei, Jiancheng An, Yonina C. Eldar, Chau Yuen
Abstract: Typical reconfigurable intelligent surface (RIS) implementations include metasurfaces with almost passive unit elements capable of reflecting their incident waves in controllable ways, enhancing wireless communications in a cost-effective manner. In this paper, we advance the concept of intelligent metasurfaces by introducing a flexible array geometry, termed flexible intelligent metasurface (FIM), which supports both element movement (EM) and passive beamforming (PBF). In particular, based on the single-input single-output (SISO) system setup, we first compare three modes of FIM, namely, EM-only, PBF-only, and EM-PBF, in terms of received signal power under different FIM and channel setups. The PBF-only mode, which only adjusts the reflect phase, is shown to be less effective than the EM-only mode in enhancing received signal strength. In a multi-element, multi-path scenario, the EM-only mode improves the received signal power by 125% compared to the PBF-only mode. The EM-PBF mode, which optimizes both element positions and phases, further enhances performance. Additionally, we investigate the channel estimation problem for FIM systems by designing a protocol that gathers EM and PBF measurements, enabling the formulation of a compressive sensing problem for joint cascaded and direct channel estimation. We then propose a sparse recovery algorithm called clustering mean-field variational sparse Bayesian learning, which enhances estimation performance while maintaining low complexity.

Paper number 20:
Title: Modeling and Optimization for Flexible Cylindrical Arrays-Enabled Wireless Communications
Authors: Songjie Yang, Jiahe Guo, Zilin He, Boyu Ning, Weidong Mei, Zhongpei Zhang, Chadi Assi, Chau Yuen
Abstract: Flexible-geometry arrays have garnered much attention in wireless communications, which dynamically adjust wireless channels to improve the system performance. In this paper, we propose a novel flexible-geometry array for a $360^\circ$ coverage, named flxible cylindrical array (FCLA), comprised of multiple flexible circular arrays (FCAs). The elements in each FCA can revolve around the circle track to change their horizontal positions, and the FCAs can move along the vertical axis to change the elements' heights. Considering that horizontal revolving can change the antenna orientation, we adopt both the omni-directional and the directional antenna patterns. Based on the regularized zero-forcing (RZF) precoding scheme, we formulate a particular compressive sensing (CS) problem incorporating joint precoding and antenna position optimization, and propose two effective methods, namely FCLA-J and FCLA-A, to solve it. Specifically, the first method involves jointly optimizing the element's revolving angle, height, and precoding coefficient within a single CS framework. The second method decouples the CS problem into two subproblems by utilizing an alternative sparse optimization approach for the revolving angle and height, thereby reducing time complexity. Simulation results reveal that, when utilizing directional radiation patterns, FCLA-J and FCLA-A achieve substantial performance improvements of 43.32\% and 25.42\%, respectively, compared to uniform cylindrical arrays (UCLAs) with RZF precoding.

Paper number 21:
Title: Beamforming for Movable and Rotatable Antenna Enabled Multi-User Communications
Authors: Ruojing Zhao, Yifei Xu, Songjie Yang, Hua Chen, Chadi Assi
Abstract: In the development of wireless communication technology, multiple-input multiple-output (MIMO) technology has emerged as a key enabler, significantly enhancing the capacity of communication systems. However, traditional MIMO systems, which rely on fixed-position antennas (FPAs) with spacing limitations, cannot fully exploit the channel variations in the continuous spatial domain, thus limiting the system's spatial multiplexing performance and diversity. To address these limitations, movable antennas (MAs) have been introduced, offering a breakthrough in signal processing and spatial multiplexing by overcoming the constraints of FPA-based systems. Furthermore, this paper extends the functionality of MAs by introducing movable rotatable antennas (MRAs), which enhance the system's ability to optimize performance in the spatial domain by adding rotational degrees of freedom. By incorporating a dynamic precoding framework based on both antenna position and rotation angle optimization, and employing the zero-forcing (ZF) precoding method, this paper proposes an efficient optimization approach aimed at improving signal quality, mitigating interference, and solving the non-linear, constrained optimization problem using the sequential quadratic programming (SQP) algorithm. This approach effectively enhances the communication system's performance.

Paper number 22:
Title: Deep Lossless Image Compression via Masked Sampling and Coarse-to-Fine Auto-Regression
Authors: Tiantian Li, Qunbing Xia, Yue Li, Ruixiao Guo, Gaobo Yang
Abstract: Learning-based lossless image compression employs pixel-based or subimage-based auto-regression for probability estimation, which achieves desirable performances. However, the existing works only consider context dependencies in one direction, namely, those symbols that appear before the current symbol in raster order. We believe that the dependencies between the current and future symbols should be further considered. In this work, we propose a deep lossless image compression via masked sampling and coarse-to-fine auto-regression. It combines lossy reconstruction and progressive residual compression, which fuses contexts from various directions and is more consistent with human perception. Specifically, the residuals are decomposed via $T$ iterative masked sampling, and each sampling consists of three steps: 1) probability estimation, 2) mask computation, and 3) arithmetic coding. The iterative process progressively refines our prediction and gradually presents a real image. Extensive experimental results show that compared with the existing traditional and learned lossless compression, our method achieves comparable compression performance on extensive datasets with competitive coding speed and more flexibility.

Paper number 23:
Title: AI and Deep Learning for Automated Segmentation and Quantitative Measurement of Spinal Structures in MRI
Authors: Praveen Shastry, Bhawana Sonawane, Kavya Mohan, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Kaviya SP, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: Accurate spinal structure measurement is crucial for assessing spine health and diagnosing conditions like spondylosis, disc herniation, and stenosis. Manual methods for measuring intervertebral disc height and spinal canal diameter are subjective and time-consuming. Automated solutions are needed to improve accuracy, efficiency, and reproducibility in clinical practice. Purpose: This study develops an autonomous AI system for segmenting and measuring key spinal structures in MRI scans, focusing on intervertebral disc height and spinal canal anteroposterior (AP) diameter in the cervical, lumbar, and thoracic regions. The goal is to reduce clinician workload, enhance diagnostic consistency, and improve assessments. Methods: The AI model leverages deep learning architectures, including UNet, nnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated against expert annotations. Performance was evaluated using Dice coefficients and segmentation accuracy. Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for cervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely measured spinal parameters like disc height and canal diameter, demonstrating robustness and clinical applicability. Conclusion: The AI system effectively automates MRI-based spinal measurements, improving accuracy and reducing clinician workload. Its consistent performance across spinal regions supports clinical decision-making, particularly in high-demand settings, enhancing spinal assessments and patient outcomes.

Paper number 24:
Title: Six-DoF Stewart Platform Motion Simulator Control using Switchable Model Predictive Control
Authors: Jiangwei Zhao, Zhengjia Xu, Dongsu Wu, Yingrui Cao, Jinpeng Xie
Abstract: Due to excellent mechanism characteristics of high rigidity, maneuverability and strength-to-weight ratio, 6 Degree-of-Freedom (DoF) Stewart structure is widely adopted to construct flight simulator platforms for replicating motion feelings during training pilots. Unlike conventional serial link manipulator based mechanisms, Upset Prevention and Recovery Training (UPRT) in complex flight status is often accompanied by large speed and violent rate of change in angular velocity of the simulator. However, Classical Washout Filter (CWF) based Motion Cueing Algorithm (MCA) shows limitations in providing rapid response to drive motors to satisfy high accuracy performance requirements. This paper aims at exploiting Model Predictive Control (MPC) based MCA which is proved to be efficient in Hexapod-based motion simulators through controlling over limited linear workspace. With respect to uncertainties and control solution errors from the extraction of Terminal Constraints (COTC), this paper proposes a Switchable Model Predictive Control (S-MPC) based MCA under model adaptive architecture to mitigate the solution uncertainties and inaccuracies. It is verified that high accurate tracking is achievable using the MPC-based MCA with COTC within the simulator operating envelope. The proposed method provides optimal tracking solutions by switching to MPC based MCA without COTC outside the operating envelope. By demonstrating the UPRT with horizontal stall conditions following Average Absolute Scale(AAS) evaluation criteria, the proposed S-MPC based MCA outperforms MPC based MCA and SWF based MCA by 42.34% and 65.30%, respectively.

Paper number 25:
Title: Lightweight Learning for Grant-Free Activity Detection in Cell-Free Massive MIMO Networks
Authors: Ali Elkeshawy, Haifa Fares, Amor Nafkha
Abstract: Grant-free random access (GF-RA) is a promising access technique for massive machine-type communications (mMTC) in future wireless networks, particularly in the context of 5G and beyond (6G) systems. Within the context of GF-RA, this study investigates the efficiency of employing supervised machine learning techniques to tackle the challenges on the device activity detection (AD). GF-RA addresses scalability by employing non-orthogonal pilot sequences, which provides an efficient alternative comparing to conventional grant-based random access (GB-RA) technique that are constrained by the scarcity of orthogonal preamble resources. In this paper, we propose a novel lightweight data-driven algorithmic framework specifically designed for activity detection in GF-RA for mMTC in cell-free massive multiple-input multiple-output (CF-mMIMO) networks. We propose two distinct framework deployment strategies, centralized and decentralized, both tailored to streamline the proposed approach implementation across network infrastructures. Moreover, we introduce optimized post-detection methodologies complemented by a clustering stage to enhance overall detection performances. Our 3GPP-compliant simulations have validated that the proposed algorithm achieves state-of-the-art model-based activity detection accuracy while significantly reducing complexity. Achieving 99% accuracy, it demonstrates real-world viability and effectiveness.

Paper number 26:
Title: A Data-Driven Exploration of Elevation Cues in HRTFs: An Explainable AI Perspective Across Multiple Datasets
Authors: Juan Antonio De Rus, Mario Montagud, Jesus Lopez-Ballester, Francesc J. Ferri, Maximo Cobos
Abstract: Precise elevation perception in binaural audio remains a challenge, despite extensive research on head-related transfer functions (HRTFs) and spectral cues. While prior studies have advanced our understanding of sound localization cues, the interplay between spectral features and elevation perception is still not fully understood. This paper presents a comprehensive analysis of over 600 subjects from 11 diverse public HRTF datasets, employing a convolutional neural network (CNN) model combined with explainable artificial intelligence (XAI) techniques to investigate elevation cues. In addition to testing various HRTF pre-processing methods, we focus on both within-dataset and inter-dataset generalization and explainability, assessing the model's robustness across different HRTF variations stemming from subjects and measurement setups. By leveraging class activation mapping (CAM) saliency maps, we identify key frequency bands that may contribute to elevation perception, providing deeper insights into the spectral features that drive elevation-specific classification. This study offers new perspectives on HRTF modeling and elevation perception by analyzing diverse datasets and pre-processing techniques, expanding our understanding of these cues across a wide range of conditions.

Paper number 27:
Title: Advancements in Real-Time Oncology Diagnosis: Harnessing AI and Image Fusion Techniques
Authors: Leila Bagheriye, Johan Kwisthout
Abstract: Real-time computer-aided diagnosis using artificial intelligence (AI), with images, can help oncologists diagnose cancer with high accuracy and in an early phase. We reviewed real-time AI-based analyzed images for decision-making in different cancer types. This paper provides insights into the present and future potential of real-time imaging and image fusion. It explores various real-time techniques, encompassing technical solutions, AI-based imaging, and image fusion diagnosis across multiple anatomical areas, and electromagnetic needle tracking. To provide a thorough overview, this paper discusses ultrasound image fusion, real-time in vivo cancer diagnosis with different spectroscopic techniques, different real-time optical imaging-based cancer diagnosis techniques, elastography-based cancer diagnosis, cervical cancer detection using neuromorphic architectures, different fluorescence image-based cancer diagnosis techniques, and hyperspectral imaging-based cancer diagnosis. We close by offering a more futuristic overview to solve existing problems in real-time image-based cancer diagnosis.

Paper number 28:
Title: FG-DFPN: Flow Guided Deformable Frame Prediction Network
Authors: M. Akın Yılmaz, Ahmet Bilican, A. Murat Tekalp
Abstract: Video frame prediction remains a fundamental challenge in computer vision with direct implications for autonomous systems, video compression, and media synthesis. We present FG-DFPN, a novel architecture that harnesses the synergy between optical flow estimation and deformable convolutions to model complex spatio-temporal dynamics. By guiding deformable sampling with motion cues, our approach addresses the limitations of fixed-kernel networks when handling diverse motion patterns. The multi-scale design enables FG-DFPN to simultaneously capture global scene transformations and local object movements with remarkable precision. Our experiments demonstrate that FG-DFPN achieves state-of-the-art performance on eight diverse MPEG test sequences, outperforming existing methods by 1dB PSNR while maintaining competitive inference speeds. The integration of motion cues with adaptive geometric transformations makes FG-DFPN a promising solution for next-generation video processing systems that require high-fidelity temporal predictions. The model and instructions to reproduce our results will be released at: this https URL Group/frame-prediction

Paper number 29:
Title: Enhanced Diagnostic Fidelity in Pathology Whole Slide Image Compression via Deep Learning
Authors: Maximilian Fischer, Peter Neher, Peter Schüffler, Shuhan Xiao, Silvia Dias Almeida, Constantin Ulrich, Alexander Muckenhuber, Rickmer Braren, Michael Götz, Jens Kleesiek, Marco Nolden, Klaus Maier-Hein
Abstract: Accurate diagnosis of disease often depends on the exhaustive examination of Whole Slide Images (WSI) at microscopic resolution. Efficient handling of these data-intensive images requires lossy compression techniques. This paper investigates the limitations of the widely-used JPEG algorithm, the current clinical standard, and reveals severe image artifacts impacting diagnostic fidelity. To overcome these challenges, we introduce a novel deep-learning (DL)-based compression method tailored for pathology images. By enforcing feature similarity of deep features between the original and compressed images, our approach achieves superior Peak Signal-to-Noise Ratio (PSNR), Multi-Scale Structural Similarity Index (MS-SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) scores compared to JPEG-XL, Webp, and other DL compression methods.

Paper number 30:
Title: Learning-Based MPC for Efficient Control of Autonomous Vehicles
Authors: Samuel Mallick, Gianpietro Battocletti, Qizhang Dong, Azita Dabiri, Bart De Schutter
Abstract: Co-optimization of both vehicle speed and gear position via model predictive control (MPC) has been shown to offer benefits for fuel-efficient autonomous driving. However, optimizing both the vehicle's continuous dynamics and discrete gear positions may be too computationally intensive for a real-time implementation. This work proposes a learning-based MPC scheme to address this issue. A policy is trained to select and fix the gear positions across the prediction horizon of the MPC controller, leaving a significantly simpler continuous optimization problem to be solved online. In simulation, the proposed approach is shown to have a significantly lower computation burden and a comparable performance, with respect to pure MPC-based co-optimization.

Paper number 31:
Title: Reinforcement Learning-Based Controlled Switching Approach for Inrush Current Minimization in Power Transformers
Authors: Jone Ugarte Valdivielso, Jose I. Aizpurua, Manex Barrenetxea, Brian G. Stewart
Abstract: Transformers are essential components for the reliable operation of power grids. The transformer core is constituted by a ferromagnetic material, and accordingly, depending on the magnetization state, the energization of the transformer can lead to high magnetizing inrush currents. Such high amplitudes shorten the life expectancy of a transformer and cause power quality issues in power grids. Various techniques have been proposed to minimize the inrush current; however, the application of Reinforcement Learning (RL) for this challenge has not been investigated. RL incorporates the ability to learn inrush minimization strategies adjusted to the dynamic transformer operation environment. This study proposes an inrush current minimization framework by combining controlled switching with RL. Depending on the opening angle of the circuit breaker and the remanent fluxes at disconnection, the proposed method learns the optimal closing instant of the circuit breaker. Two RL algorithms have been trained and tested through an equivalent duality-based model of a real 7.4 MVA power transformer. The evaluation of the RL algorithms is carried out with real measurement data and compared with real laboratory inrush currents. The results show that the inrush current is effectively minimized with the proposed framework.

Paper number 32:
Title: Feasibility of Randomized Detector Tuning for Attack Impact Mitigation
Authors: Sribalaji C. Anand, Kamil Hassan, Henrik Sandberg
Abstract: This paper considers the problem of detector tuning against false data injection attacks. In particular, we consider an adversary injecting false sensor data to maximize the state deviation of the plant, referred to as impact, whilst being stealthy. To minimize the impact of stealthy attacks, inspired by moving target defense, the operator randomly switches the detector thresholds. In this paper, we theoretically derive the sufficient (and in some cases necessary) conditions under which the impact of stealthy attacks can be made smaller with randomized switching of detector thresholds compared to static thresholds. We establish the conditions for the stateless ($\chi^2$) and the stateful (CUSUM) detectors. The results are illustrated through numerical examples.

Paper number 33:
Title: A Real-World Energy Management Dataset from a Smart Company Building for Optimization and Machine Learning
Authors: Jens Engel, Andrea Castellani, Patricia Wollstadt, Felix Lanfermann, Thomas Schmitt, Sebastian Schmitt, Lydia Fischer, Steffen Limmer, David Luttropp, Florian Jomrich, René Unger, Tobias Rodemann
Abstract: We present a large real-world dataset obtained from monitoring a smart company facility over the course of six years, from 2018 to 2023. The dataset includes energy consumption data from various facility areas and components, energy production data from a photovoltaic system and a combined heat and power plant, operational data from heating and cooling systems, and weather data from an on-site weather station. The measurement sensors installed throughout the facility are organized in a hierarchical metering structure with multiple sub-metering levels, which is reflected in the dataset. The dataset contains measurement data from 72 energy meters, 9 heat meters and a weather station. Both raw and processed data at different processing levels, including labeled issues, is available. In this paper, we describe the data acquisition and post-processing employed to create the dataset. The dataset enables the application of a wide range of methods in the domain of energy management, including optimization, modeling, and machine learning to optimize building operations and reduce costs and carbon emissions.

Paper number 34:
Title: Topological Dictionary Learning
Authors: Enrico Grimaldi, Claudio Battiloro, Paolo Di Lorenzo
Abstract: The aim of this paper is to introduce a novel dictionary learning algorithm for sparse representation of signals defined over combinatorial topological spaces, specifically, regular cell complexes. Leveraging Hodge theory, we embed topology into the dictionary structure via concatenated sub-dictionaries, each as a polynomial of Hodge Laplacians, yielding localized spectral topological filter frames. The learning problem is cast to jointly infer the underlying cell complex and optimize the dictionary coefficients and the sparse signal representation. We efficiently solve the problem via iterative alternating algorithms. Numerical results on both synthetic and real data show the effectiveness of the proposed procedure in jointly learning the sparse representations and the underlying relational structure of topological signals.

Paper number 35:
Title: Alzheimer's Disease Classification Using Retinal OCT: TransnetOCT and Swin Transformer Models
Authors: Siva Manohar Reddy Kesu, Neelam Sinha, Hariharan Ramasangu, Thomas Gregor Issac
Abstract: Retinal optical coherence tomography (OCT) images are the biomarkers for neurodegenerative diseases, which are rising in prevalence. Early detection of Alzheimer's disease using retinal OCT is a primary challenging task. This work utilizes advanced deep learning techniques to classify retinal OCT images of subjects with Alzheimer's disease (AD) and healthy controls (CO). The goal is to enhance diagnostic capabilities through efficient image analysis. In the proposed model, Raw OCT images have been preprocessed with ImageJ and given to various deep-learning models to evaluate the accuracy. The best classification architecture is TransNetOCT, which has an average accuracy of 98.18% for input OCT images and 98.91% for segmented OCT images for five-fold cross-validation compared to other models, and the Swin Transformer model has achieved an accuracy of 93.54%. The evaluation accuracy metric demonstrated TransNetOCT and Swin transformer models capability to classify AD and CO subjects reliably, contributing to the potential for improved diagnostic processes in clinical settings.

Paper number 36:
Title: Observation-only learning of neural mapping schemes for gappy satellite-derived ocean colour parameters
Authors: Clément Dorffer, Frédéric Jourdin, Thi Thuy Nga Nguyen, Rodolphe Devillers, David Mouillot, Ronan Fablet
Abstract: Monitoring optical properties of coastal and open ocean waters is crucial to assessing the health of marine ecosystems. Deep learning offers a promising approach to address these ecosystem dynamics, especially in scenarios where gap-free ground-truth data is lacking, which poses a challenge for designing effective training frameworks. Using an advanced neural variational data assimilation scheme (called 4DVarNet), we introduce a comprehensive training framework designed to effectively train directly on gappy data sets. Using the Mediterranean Sea as a case study, our experiments not only highlight the high performance of the chosen neural network in reconstructing gap-free images from gappy datasets but also demonstrate its superior performance over state-of-the-art algorithms such as DInEOF and Direct Inversion, whether using CNN or UNet architectures.

Paper number 37:
Title: Goal-oriented Spectrum Sharing: Trading Edge Inference Power for Data Streaming Performance
Authors: Mattia Merluzzi, Miltiadis C. Filippou
Abstract: We study the problem of spectrum sharing between goal-oriented (GO) and legacy data-oriented (DO) systems. For the former, data quality and representation is no longer optimized based on classical communication key performance indicators, but rather configured on the fly to achieve the goal of communication with the least resource overhead. This paradigm can be followed to flexibly adapt wireless and in-network artificial intelligence operations across different nodes (e.g., access points, users, sensors or actuators) to data traffic, channel conditions, energy availability and distributed computing capabilities. In this paper, we argue and demonstrate that computing and learning/inference operation performance strongly affect lower layers, calling for a real cross-layer optimization that encompasses physical and computation resource orchestration, up to the application level. Focusing on a communication channel shared among a GO and a DO user, we define a goal-effective achievable rate region (GEARR), to assess the maximum data rate attainable by the latter, subject to goal achievement guarantees for the former. Finally, we propose a cross-layer dynamic resource orchestration able to reach the boundaries of the GEARR, under different goaleffectiveness and compute resource consumption constraints.

Paper number 38:
Title: Fault-tolerant control of nonlinear systems: An inductive synthesis approach
Authors: Daniele Masti, Davide Grande, Andrea Peruffo, Filippo Fabiani
Abstract: Actuator faults heavily affect the performance and stability of control systems, an issue that is even more critical for systems required to operate autonomously under adverse environmental conditions, such as unmanned vehicles. To this end, passive fault-tolerant control (PFTC) systems can be employed, namely fixed-gain control laws that guarantee stability both in the nominal case and in the event of faults. In this paper, we propose a counterexample guided inductive synthesis (CEGIS)-based approach to design reliable PFTC policies for nonlinear control systems affected by partial, or total, actuator faults. Our approach enjoys finite-time convergence guarantees and extends available techniques by considering nonlinear dynamics with possible fault conditions. Extensive numerical simulations illustrate how the proposed method can be applied to realistic operational scenarios involving the velocity and heading control of autonomous underwater vehicles (AUVs). Our PFTC technique exhibits comparatively low synthesis time (i.e. minutes) and minimal computational requirements, which render it is suitable for embedded applications with limited availability of energy and onboard power resources.

Paper number 39:
Title: Image Reconstruction from an Elastically Distorted Scan
Authors: Adrian Lopez, L. Mahadevan
Abstract: We consider the problem of inverting the artifacts associated with scanning a page from an open book, i.e. "xeroxing." The process typically leads to a non-uniform combination of distortion, blurring and darkening owing to the fact that the page is bound to a stiff spine that causes the sheet of paper to be bent inhomogeneously. Complementing purely data-driven approaches, we use knowledge about the geometry and elasticity of the curved sheet to pose and solve a minimal physically consistent inverse problem to reconstruct the image. Our results rely on 3 dimensionless parameters, all of which can be measured for a scanner, and show that we can improve on the data-driven approaches. More broadly, our results might serve as a "textbook" example and a tutorial of how knowledge of generative mechanisms can speed up the solution of inverse problems.

Paper number 40:
Title: Generalization performance of neural mapping schemes for the space-time interpolation of satellite-derived ocean colour datasets
Authors: Thi Thuy Nga Nguyen, Clément Dorffer, Frédéric Jourdin, Ronan Fablet
Abstract: Neural mapping schemes have become appealing approaches to deliver gap-free satellite-derived products for sea surface tracers. The generalization performance of these learning-based approaches naturally arises as a key challenge. This is particularly true for satellite-derived ocean colour products given the variety of bio-optical variables of interest, as well as the diversity of processes and scales involved. Considering region-specific and parameter-specific neural mapping schemes will result in substantial training costs. This study addresses generalization performance of neural mapping schemes to deliver gap-free satellite-derived ocean colour products. We develop a comprehensive experimental framework using real multi-sensor ocean colour datasets for two regions (the Mediterranean Sea and the North Sea) and a representative set of bio-optical parameters (Chlorophyll-a concentration, suspended particulate matter concentration, particulate backscattering coefficient). We consider several neural mapping schemes, and we report excellent generalization performance across regions and bio-optical parameters without any fine-tuning using appropriate dataset-specific normalization procedures. We discuss further how these results provide new insights towards the large-scale deployment of neural schemes for the processing of satellite-derived ocean colour datasets beyond case-study-specific demonstrations.

Paper number 41:
Title: Pathology Image Compression with Pre-trained Autoencoders
Authors: Srikar Yellapragada, Alexandros Graikos, Kostas Triaridis, Zilinghan Li, Tarak Nath Nandi, Ravi K Madduri, Prateek Prasanna, Joel Saltz, Dimitris Samaras
Abstract: The growing volume of high-resolution Whole Slide Images in digital histopathology poses significant storage, transmission, and computational efficiency challenges. Standard compression methods, such as JPEG, reduce file sizes but often fail to preserve fine-grained phenotypic details critical for downstream tasks. In this work, we repurpose autoencoders (AEs) designed for Latent Diffusion Models as an efficient learned compression framework for pathology images. We systematically benchmark three AE models with varying compression levels and evaluate their reconstruction ability using pathology foundation models. We introduce a fine-tuning strategy to further enhance reconstruction fidelity that optimizes a pathology-specific learned perceptual metric. We validate our approach on downstream tasks, including segmentation, patch classification, and multiple instance learning, showing that replacing images with AE-compressed reconstructions leads to minimal performance degradation. Additionally, we propose a K-means clustering-based quantization method for AE latents, improving storage efficiency while maintaining reconstruction quality. We provide the weights of the fine-tuned autoencoders at this https URL.

Paper number 42:
Title: VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation
Authors: Brunó B. Englert, Gijs Dubbelman
Abstract: Unsupervised Domain Adaptation (UDA) has shown remarkably strong generalization from a labeled source domain to an unlabeled target domain while requiring relatively little data. At the same time, large-scale pretraining without labels of so-called Vision Foundation Models (VFMs), has also significantly improved downstream generalization. This motivates us to research how UDA can best utilize the benefits of VFMs. The earlier work of VFM-UDA showed that beyond state-of-the-art (SotA) results can be obtained by replacing non-VFM with VFM encoders in SotA UDA methods. In this work, we take it one step further and improve on the UDA architecture and data strategy themselves. We observe that VFM-UDA, the current SotA UDA method, does not use multi-scale inductive biases or feature distillation losses, while it is known that these can improve generalization. We address both limitations in VFM-UDA++ and obtain beyond SotA generalization on standard UDA benchmarks of up to +5.3 mIoU. Inspired by work on VFM fine-tuning, such as Rein, we also explore the benefits of adding more easy-to-generate synthetic source data with easy-to-obtain unlabeled target data and realize a +6.6 mIoU over the current SotA. The improvements of VFM-UDA++ are most significant for smaller models, however, we show that for larger models, the obtained generalization is only 2.8 mIoU from that of fully-supervised learning with all target labels. Based on these strong results, we provide essential insights to help researchers and practitioners advance UDA.

Paper number 43:
Title: MaskAttn-UNet: A Mask Attention-Driven Framework for Universal Low-Resolution Image Segmentation
Authors: Anzhe Cheng, Chenzhong Yin, Yu Chang, Heng Ping, Shixuan Li, Shahin Nazarian, Paul Bogdan
Abstract: Low-resolution image segmentation is crucial in real-world applications such as robotics, augmented reality, and large-scale scene understanding, where high-resolution data is often unavailable due to computational constraints. To address this challenge, we propose MaskAttn-UNet, a novel segmentation framework that enhances the traditional U-Net architecture via a mask attention mechanism. Our model selectively emphasizes important regions while suppressing irrelevant backgrounds, thereby improving segmentation accuracy in cluttered and complex scenes. Unlike conventional U-Net variants, MaskAttn-UNet effectively balances local feature extraction with broader contextual awareness, making it particularly well-suited for low-resolution inputs. We evaluate our approach on three benchmark datasets with input images rescaled to 128x128 and demonstrate competitive performance across semantic, instance, and panoptic segmentation tasks. Our results show that MaskAttn-UNet achieves accuracy comparable to state-of-the-art methods at significantly lower computational cost than transformer-based models, making it an efficient and scalable solution for low-resolution segmentation in resource-constrained scenarios.

Paper number 44:
Title: Knowledge Consultation for Semi-Supervised Semantic Segmentation
Authors: Thuan Than, Nhat-Anh Nguyen-Dang, Dung Nguyen, Salwa K. Al Khatib, Ahmed Elhagry, Hai Phan, Yihui He, Zhiqiang Shen, Marios Savvides, Dang Huynh
Abstract: Semi-Supervised Semantic Segmentation reduces reliance on extensive annotations by using unlabeled data and state-of-the-art models to improve overall performance. Despite the success of deep co-training methods, their underlying mechanisms remain underexplored. This work revisits Cross Pseudo Supervision with dual heterogeneous backbones and introduces Knowledge Consultation (SegKC) to further enhance segmentation performance. The proposed SegKC achieves significant improvements on Pascal and Cityscapes benchmarks, with mIoU scores of 87.1%, 89.2%, and 89.8% on Pascal VOC with the 1/4, 1/2, and full split partition, respectively, while maintaining a compact model architecture.

Paper number 45:
Title: Neighboring Autoregressive Modeling for Efficient Visual Generation
Authors: Yefei He, Yuanyu He, Shaoxuan He, Feng Chen, Hong Zhou, Kaipeng Zhang, Bohan Zhuang
Abstract: Visual autoregressive models typically adhere to a raster-order ``next-token prediction" paradigm, which overlooks the spatial and temporal locality inherent in visual content. Specifically, visual tokens exhibit significantly stronger correlations with their spatially or temporally adjacent tokens compared to those that are distant. In this paper, we propose Neighboring Autoregressive Modeling (NAR), a novel paradigm that formulates autoregressive visual generation as a progressive outpainting procedure, following a near-to-far ``next-neighbor prediction" mechanism. Starting from an initial token, the remaining tokens are decoded in ascending order of their Manhattan distance from the initial token in the spatial-temporal space, progressively expanding the boundary of the decoded region. To enable parallel prediction of multiple adjacent tokens in the spatial-temporal space, we introduce a set of dimension-oriented decoding heads, each predicting the next token along a mutually orthogonal dimension. During inference, all tokens adjacent to the decoded tokens are processed in parallel, substantially reducing the model forward steps for generation. Experiments on ImageNet$256\times 256$ and UCF101 demonstrate that NAR achieves 2.4$\times$ and 8.6$\times$ higher throughput respectively, while obtaining superior FID/FVD scores for both image and video generation tasks compared to the PAR-4X approach. When evaluating on text-to-image generation benchmark GenEval, NAR with 0.8B parameters outperforms Chameleon-7B while using merely 0.4 of the training data. Code is available at this https URL.

Paper number 46:
Title: Zero-Shot Subject-Centric Generation for Creative Application Using Entropy Fusion
Authors: Kaifeng Zou, Xiaoyi Feng, Peng Wang, Tao Huang, Zizhou Huang, Zhang Haihang, Yuntao Zou, Dagang Li
Abstract: Generative models are widely used in visual content creation. However, current text-to-image models often face challenges in practical applications-such as textile pattern design and meme generation-due to the presence of unwanted elements that are difficult to separate with existing methods. Meanwhile, subject-reference generation has emerged as a key research trend, highlighting the need for techniques that can produce clean, high-quality subject images while effectively removing extraneous components. To address this challenge, we introduce a framework for reliable subject-centric image generation. In this work, we propose an entropy-based feature-weighted fusion method to merge the informative cross-attention features obtained from each sampling step of the pretrained text-to-image model FLUX, enabling a precise mask prediction and subject-centric generation. Additionally, we have developed an agent framework based on Large Language Models (LLMs) that translates users' casual inputs into more descriptive prompts, leading to highly detailed image generation. Simultaneously, the agents extract primary elements of prompts to guide the entropy-based feature fusion, ensuring focused primary element generation without extraneous components. Experimental results and user studies demonstrate our methods generates high-quality subject-centric images, outperform existing methods or other possible pipelines, highlighting the effectiveness of our approach.

Paper number 47:
Title: Real-time Pollutant Identification through Optical PM Micro-Sensor
Authors: Elie Azeraf, Audrey Wagner, Emilie Bialic, Samia Mellah, Ludovic Lelandais
Abstract: Air pollution remains one of the most pressing environmental challenges of the modern era, significantly impacting human health, ecosystems, and climate. While traditional air quality monitoring systems provide critical data, their high costs and limited spatial coverage hinder effective real-time pollutant identification. Recent advancements in micro-sensor technology have improved data collection but still lack efficient methods for source identification. This paper explores the innovative application of machine learning (ML) models to classify pollutants in real-time using only data from optical micro-sensors. We propose a novel classification framework capable of distinguishing between four pollutant scenarios: Background Pollution, Ash, Sand, and Candle. Three Machine Learning (ML) approaches - XGBoost, Long Short-Term Memory networks, and Hidden Markov Chains - are evaluated for their effectiveness in sequence modeling and pollutant identification. Our results demonstrate the potential of leveraging micro-sensors and ML techniques to enhance air quality monitoring, offering actionable insights for urban planning and environmental protection.

Paper number 48:
Title: Prototype-Guided Cross-Modal Knowledge Enhancement for Adaptive Survival Prediction
Authors: Fengchun Liu, Linghan Cai, Zhikang Wang, Zhiyuan Fan, Jin-gang Yu, Hao Chen, Yongbing Zhang
Abstract: Histo-genomic multimodal survival prediction has garnered growing attention for its remarkable model performance and potential contributions to precision medicine. However, a significant challenge in clinical practice arises when only unimodal data is available, limiting the usability of these advanced multimodal methods. To address this issue, this study proposes a prototype-guided cross-modal knowledge enhancement (ProSurv) framework, which eliminates the dependency on paired data and enables robust learning and adaptive survival prediction. Specifically, we first introduce an intra-modal updating mechanism to construct modality-specific prototype banks that encapsulate the statistics of the whole training set and preserve the modality-specific risk-relevant features/prototypes across intervals. Subsequently, the proposed cross-modal translation module utilizes the learned prototypes to enhance knowledge representation for multimodal inputs and generate features for missing modalities, ensuring robust and adaptive survival prediction across diverse scenarios. Extensive experiments on four public datasets demonstrate the superiority of ProSurv over state-of-the-art methods using either unimodal or multimodal input, and the ablation study underscores its feasibility for broad applicability. Overall, this study addresses a critical practical challenge in computational pathology, offering substantial significance and potential impact in the field.

Paper number 49:
Title: TAU: Modeling Temporal Consistency Through Temporal Attentive U-Net for PPG Peak Detection
Authors: Chunsheng Zuo, Yu Zhao, Juntao Ye
Abstract: Photoplethysmography (PPG) sensors have been widely used in consumer wearable devices to monitor heart rates (HR) and heart rate variability (HRV). Despite the prevalence, PPG signals can be contaminated by motion artifacts induced from daily activities. Existing approaches mainly use the amplitude information to perform PPG peak detection. However, these approaches cannot accurately identify peaks, since motion artifacts may bring random and significant amplitude variations. To improve the performance of PPG peak detection, the time information can be used. Specifically, heart rates exhibit temporal consistency that consecutive heartbeat intervals in a normal person can have limited variations. To leverage the temporal consistency, we propose the Temporal Attentive U-Net, i.e., TAU, to accurately detect peaks from PPG signals. In TAU, we design a time module that encodes temporal consistency in temporal embeddings. We integrate the amplitude information with temporal embeddings using the attention mechanism to estimate peak labels. Our experimental results show that TAU outperforms eleven baselines on heart rate estimation by more than 22.4%. Our TAU model achieves the best performance across various Signal-to-Noise Ratio (SNR) levels. Moreover, we achieve Pearson correlation coefficients higher than 0.9 (p < 0.01) on estimating HRV features from low-noise-level PPG signals.

Paper number 50:
Title: Efficient Reachability Analysis for Convolutional Neural Networks Using Hybrid Zonotopes
Authors: Yuhao Zhang, Xiangru Xu
Abstract: Feedforward neural networks are widely used in autonomous systems, particularly for control and perception tasks within the system loop. However, their vulnerability to adversarial attacks necessitates formal verification before deployment in safety-critical applications. Existing set propagation-based reachability analysis methods for feedforward neural networks often struggle to achieve both scalability and accuracy. This work presents a novel set-based approach for computing the reachable sets of convolutional neural networks. The proposed method leverages a hybrid zonotope representation and an efficient neural network reduction technique, providing a flexible trade-off between computational complexity and approximation accuracy. Numerical examples are presented to demonstrate the effectiveness of the proposed approach.

Paper number 51:
Title: Rapidly Converging Time-Discounted Ergodicity on Graphs for Active Inspection of Confined Spaces
Authors: Benjamin Wong, Ryan H. Lee, Tyler M. Paine, Santosh Devasia, Ashis G. Banerjee
Abstract: Ergodic exploration has spawned a lot of interest in mobile robotics due to its ability to design time trajectories that match desired spatial coverage statistics. However, current ergodic approaches are for continuous spaces, which require detailed sensory information at each point and can lead to fractal-like trajectories that cannot be tracked easily. This paper presents a new ergodic approach for graph-based discretization of continuous spaces. It also introduces a new time-discounted ergodicity metric, wherein early visitations of information-rich nodes are weighted more than late visitations. A Markov chain synthesized using a convex program is shown to converge more rapidly to time-discounted ergodicity than the traditional fastest mixing Markov chain. The resultant ergodic traversal method is used within a hierarchical framework for active inspection of confined spaces with the goal of detecting anomalies robustly using SLAM-driven Bayesian hypothesis testing. Both simulation and physical experiments on a ground robot show the advantages of this framework over greedy and random exploration methods for left-behind foreign object debris detection in a ballast tank.

Paper number 52:
Title: Beyond Diagonal RIS Enhanced Cognitive Radio Enabled Multilayer Non-Terrestrial Networks
Authors: Wali Ullah Khan, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas
Abstract: Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) have emerged as a transformative technology for enhancing wireless communication by intelligently manipulating the propagation environment. Its interconnected elements offer enhanced control over signal redirection, making it a promising solution for integrated terrestrial and non-terrestrial networks (NTNs). This paper explores the potential of BD-RIS in improving cognitive radio enabled multilayer non-terrestrial networks. We formulate a joint optimization problem that maximizes the achievable spectral efficiency by optimizing BD-RIS phase shifts and secondary transmitter power allocation while controlling the interference temperature from the secondary network to the primary network. To solve this problem efficiently, we decouple the original problem and propose a novel solution based on an alternating optimization approach. Simulation results demonstrate the effectiveness of BD-RIS in cognitive radio enabled multilayer NTNs.

Paper number 53:
Title: Data-Driven Soft Robot Control via Adiabatic Spectral Submanifolds
Authors: Roshan S. Kaundinya, John Irvin Alora, Jonas G. Matt, Luis A. Pabon, Marco Pavone, George Haller
Abstract: The mechanical complexity of soft robots creates significant challenges for their model-based control. Specifically, linear data-driven models have struggled to control soft robots on complex, spatially extended paths that explore regions with significant nonlinear behavior. To account for these nonlinearities, we develop here a model-predictive control strategy based on the recent theory of adiabatic spectral submanifolds (aSSMs). This theory is applicable because the internal vibrations of heavily overdamped robots decay at a speed that is much faster than the desired speed of the robot along its intended path. In that case, low-dimensional attracting invariant manifolds (aSSMs) emanate from the path and carry the dominant dynamics of the robot. Aided by this recent theory, we devise an aSSM-based model-predictive control scheme purely from data. We demonstrate the effectiveness of this data-driven model on various dynamic trajectory tracking tasks on a high-fidelity and high-dimensional finite-element model of a soft trunk robot. Notably, we find that four- or five-dimensional aSSM-reduced models outperform the tracking performance of other data-driven modeling methods by a factor up to 10 across all closed-loop control tasks.

Paper number 54:
Title: From Abstraction to Reality: DARPA's Vision for Robust Sim-to-Real Autonomy
Authors: Erfaun Noorani, Zachary Serlin, Ben Price, Alvaro Velasquez
Abstract: The DARPA Transfer from Imprecise and Abstract Models to Autonomous Technologies (TIAMAT) program aims to address rapid and robust transfer of autonomy technologies across dynamic and complex environments, goals, and platforms. Existing methods for simulation-to-reality (sim-to-real) transfer often rely on high-fidelity simulations and struggle with broad adaptation, particularly in time-sensitive scenarios. Although many approaches have shown incredible performance at specific tasks, most techniques fall short when posed with unforeseen, complex, and dynamic real-world scenarios due to the inherent limitations of simulation. In contrast to current research that aims to bridge the gap between simulation environments and the real world through increasingly sophisticated simulations and a combination of methods typically assuming a small sim-to-real gap -- such as domain randomization, domain adaptation, imitation learning, meta-learning, policy distillation, and dynamic optimization -- TIAMAT takes a different approach by instead emphasizing transfer and adaptation of the autonomy stack directly to real-world environments by utilizing a breadth of low(er)-fidelity simulations to create broadly effective sim-to-real transfers. By abstractly learning from multiple simulation environments in reference to their shared semantics, TIAMAT's approaches aim to achieve abstract-to-real transfer for effective and rapid real-world adaptation. Furthermore, this program endeavors to improve the overall autonomy pipeline by addressing the inherent challenges in translating simulated behaviors into effective real-world performance.

Paper number 55:
Title: Low-cost Real-world Implementation of the Swing-up Pendulum for Deep Reinforcement Learning Experiments
Authors: Peter Böhm, Pauline Pounds, Archie C. Chapman
Abstract: Deep reinforcement learning (DRL) has had success in virtual and simulated domains, but due to key differences between simulated and real-world environments, DRL-trained policies have had limited success in real-world applications. To assist researchers to bridge the \textit{sim-to-real gap}, in this paper, we describe a low-cost physical inverted pendulum apparatus and software environment for exploring sim-to-real DRL methods. In particular, the design of our apparatus enables detailed examination of the delays that arise in physical systems when sensing, communicating, learning, inferring and actuating. Moreover, we wish to improve access to educational systems, so our apparatus uses readily available materials and parts to reduce cost and logistical barriers. Our design shows how commercial, off-the-shelf electronics and electromechanical and sensor systems, combined with common metal extrusions, dowel and 3D printed couplings provide a pathway for affordable physical DRL apparatus. The physical apparatus is complemented with a simulated environment implemented using a high-fidelity physics engine and OpenAI Gym interface.

Paper number 56:
Title: Joint Training And Decoding for Multilingual End-to-End Simultaneous Speech Translation
Authors: Wuwei Huang, Renren Jin, Wen Zhang, Jian Luan, Bin Wang, Deyi Xiong
Abstract: Recent studies on end-to-end speech translation(ST) have facilitated the exploration of multilingual end-to-end ST and end-to-end simultaneous ST. In this paper, we investigate end-to-end simultaneous speech translation in a one-to-many multilingual setting which is closer to applications in real scenarios. We explore a separate decoder architecture and a unified architecture for joint synchronous training in this scenario. To further explore knowledge transfer across languages, we propose an asynchronous training strategy on the proposed unified decoder architecture. A multi-way aligned multilingual end-to-end ST dataset was curated as a benchmark testbed to evaluate our methods. Experimental results demonstrate the effectiveness of our models on the collected dataset. Our codes and data are available at: this https URL.

Paper number 57:
Title: GP-enhanced Autonomous Drifting Framework using ADMM-based iLQR
Authors: Yangyang Xie, Cheng Hu, Nicolas Baumann, Edoardo Ghignone, Michele Magno, Lei Xie
Abstract: Autonomous drifting is a complex challenge due to the highly nonlinear dynamics and the need for precise real-time control, especially in uncertain environments. To address these limitations, this paper presents a hierarchical control framework for autonomous vehicles drifting along general paths, primarily focusing on addressing model inaccuracies and mitigating computational challenges in real-time control. The framework integrates Gaussian Process (GP) regression with an Alternating Direction Method of Multipliers (ADMM)-based iterative Linear Quadratic Regulator (iLQR). GP regression effectively compensates for model residuals, improving accuracy in dynamic conditions. ADMM-based iLQR not only combines the rapid trajectory optimization of iLQR but also utilizes ADMM's strength in decomposing the problem into simpler sub-problems. Simulation results demonstrate the effectiveness of the proposed framework, with significant improvements in both drift trajectory tracking and computational efficiency. Our approach resulted in a 38$\%$ reduction in RMSE lateral error and achieved an average computation time that is 75$\%$ lower than that of the Interior Point OPTimizer (IPOPT).

Paper number 58:
Title: Flow-Aware Navigation of Magnetic Micro-Robots in Complex Fluids via PINN-Based Prediction
Authors: Yongyi Jia, Shu Miao, Jiayu Wu, Ming Yang, Chengzhi Hu, Xiang Li
Abstract: While magnetic micro-robots have demonstrated significant potential across various applications, including drug delivery and microsurgery, the open issue of precise navigation and control in complex fluid environments is crucial for in vivo implementation. This paper introduces a novel flow-aware navigation and control strategy for magnetic micro-robots that explicitly accounts for the impact of fluid flow on their movement. First, the proposed method employs a Physics-Informed U-Net (PI-UNet) to refine the numerically predicted fluid velocity using local observations. Then, the predicted velocity is incorporated in a flow-aware A* path planning algorithm, ensuring efficient navigation while mitigating flow-induced disturbances. Finally, a control scheme is developed to compensate for the predicted fluid velocity, thereby optimizing the micro-robot's performance. A series of simulation studies and real-world experiments are conducted to validate the efficacy of the proposed approach. This method enhances both planning accuracy and control precision, expanding the potential applications of magnetic micro-robots in fluid-affected environments typical of many medical scenarios.

Paper number 59:
Title: SpaceSeg: A High-Precision Intelligent Perception Segmentation Method for Multi-Spacecraft On-Orbit Targets
Authors: Hao Liu, Pengyu Guo, Siyuan Yang, Zeqing Jiang, Qinglei Hu, Dongyu Li
Abstract: With the continuous advancement of human exploration into deep space, intelligent perception and high-precision segmentation technology for on-orbit multi-spacecraft targets have become critical factors for ensuring the success of modern space missions. However, the complex deep space environment, diverse imaging conditions, and high variability in spacecraft morphology pose significant challenges to traditional segmentation methods. This paper proposes SpaceSeg, an innovative vision foundation model-based segmentation framework with four core technical innovations: First, the Multi-Scale Hierarchical Attention Refinement Decoder (MSHARD) achieves high-precision feature decoding through cross-resolution feature fusion via hierarchical attention. Second, the Multi-spacecraft Connected Component Analysis (MS-CCA) effectively resolves topological structure confusion in dense targets. Third, the Spatial Domain Adaptation Transform framework (SDAT) eliminates cross-domain disparities and resist spatial sensor perturbations through composite enhancement strategies. Finally, a custom Multi-Spacecraft Segmentation Task Loss Function is created to significantly improve segmentation robustness in deep space scenarios. To support algorithm validation, we construct the first multi-scale on-orbit multi-spacecraft semantic segmentation dataset SpaceES, which covers four types of spatial backgrounds and 17 typical spacecraft targets. In testing, SpaceSeg achieves state-of-the-art performance with 89.87$\%$ mIoU and 99.98$\%$ mAcc, surpassing existing best methods by 5.71 percentage points. The dataset and code are open-sourced at this https URL to provide critical technical support for next-generation space situational awareness systems.

Paper number 60:
Title: Cross-Modal Learning for Music-to-Music-Video Description Generation
Authors: Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Zhi Zhong, Wei-Hsiang Liao, Hiromi Wakaki, Yuki Mitsufuji
Abstract: Music-to-music-video generation is a challenging task due to the intrinsic differences between the music and video modalities. The advent of powerful text-to-video diffusion models has opened a promising pathway for music-video (MV) generation by first addressing the music-to-MV description task and subsequently leveraging these models for video generation. In this study, we focus on the MV description generation task and propose a comprehensive pipeline encompassing training data construction and multimodal model fine-tuning. We fine-tune existing pre-trained multimodal models on our newly constructed music-to-MV description dataset based on the Music4All dataset, which integrates both musical and visual information. Our experimental results demonstrate that music representations can be effectively mapped to textual domains, enabling the generation of meaningful MV description directly from music inputs. We also identify key components in the dataset construction pipeline that critically impact the quality of MV description and highlight specific musical attributes that warrant greater focus for improved MV description generation.

Paper number 61:
Title: Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering
Authors: Gang Li, Jizhong Liu, Heinrich Dinkel, Yadong Niu, Junbo Zhang, Jian Luan
Abstract: Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks. However, the audio modality has largely been overlooked in these developments. Thus, we conduct a series of RL explorations in audio understanding and reasoning, specifically focusing on the audio question answering (AQA) task. We leverage the group relative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and our experiments demonstrated state-of-the-art performance on the MMAU Test-mini benchmark, achieving an accuracy rate of 64.5%. The main findings in this technical report are as follows: 1) The GRPO algorithm can be effectively applied to large audio language models (LALMs), even when the model has only 8.2B parameters; 2) With only 38k post-training samples, RL significantly outperforms supervised fine-tuning (SFT), indicating that RL-based approaches can be effective without large datasets; 3) The explicit reasoning process has not shown significant benefits for AQA tasks, and how to efficiently utilize deep thinking remains an open question for further research; 4) LALMs still lag far behind humans auditory-language reasoning, suggesting that the RL-based approaches warrant further exploration. Our project is available at this https URL and this https URL.

Paper number 62:
Title: Comparative Study of Spike Encoding Methods for Environmental Sound Classification
Authors: Andres Larroza, Javier Naranjo-Alcazar, Vicent Ortiz Castelló, Pedro Zuccarello
Abstract: Spiking Neural Networks (SNNs) offer a promising approach to reduce energy consumption and computational demands, making them particularly beneficial for embedded machine learning in edge applications. However, data from conventional digital sensors must first be converted into spike trains to be processed using neuromorphic computing technologies. The classification of environmental sounds presents unique challenges due to the high variability of frequencies, background noise, and overlapping acoustic events. Despite these challenges, most studies on spike-based audio encoding focus on speech processing, leaving non-speech environmental sounds underexplored. In this work, we conduct a comprehensive comparison of widely used spike encoding techniques, evaluating their effectiveness on the ESC-10 dataset. By understanding the impact of encoding choices on environmental sound processing, researchers and practitioners can select the most suitable approach for real-world applications such as smart surveillance, environmental monitoring, and industrial acoustic analysis. This study serves as a benchmark for spike encoding in environmental sound classification, providing a foundational reference for future research in neuromorphic audio processing.

Paper number 63:
Title: Simulating Dual-Pixel Images From Ray Tracing For Depth Estimation
Authors: Fengchen He, Dayang Zhao, Hao Xu, Tingwei Quan, Shaoqun Zeng
Abstract: Many studies utilize dual-pixel (DP) sensor phase characteristics for various applications, such as depth estimation and deblurring. However, since the DP image features are entirely determined by the camera hardware, DP-depth paired datasets are very scarce, especially when performing depth estimation on customized cameras. To overcome this, studies simulate DP images using ideal optical system models. However, these simulations often violate real optical propagation laws,leading to poor generalization to real DP data. To address this, we investigate the domain gap between simulated and real DP data, and propose solutions using the Simulating DP images from ray tracing (Sdirt) scheme. The Sdirt generates realistic DP images via ray tracing and integrates them into the depth estimation training pipeline. Experimental results show that models trained with Sdirt-simulated images generalize better to real DP data.

Paper number 64:
Title: Exploring the Potential of Large Multimodal Models as Effective Alternatives for Pronunciation Assessment
Authors: Ke Wang, Lei He, Kun Liu, Yan Deng, Wenning Wei, Sheng Zhao
Abstract: Large Multimodal Models (LMMs) have demonstrated exceptional performance across a wide range of domains. This paper explores their potential in pronunciation assessment tasks, with a particular focus on evaluating the capabilities of the Generative Pre-trained Transformer (GPT) model, specifically GPT-4o. Our study investigates its ability to process speech and audio for pronunciation assessment across multiple levels of granularity and dimensions, with an emphasis on feedback generation and scoring. For our experiments, we use the publicly available Speechocean762 dataset. The evaluation focuses on two key aspects: multi-level scoring and the practicality of the generated feedback. Scoring results are compared against the manual scores provided in the Speechocean762 dataset, while feedback quality is assessed using Large Language Models (LLMs). The findings highlight the effectiveness of integrating LMMs with traditional methods for pronunciation assessment, offering insights into the model's strengths and identifying areas for further improvement.

Paper number 65:
Title: Cost-effective Deep Learning Infrastructure with NVIDIA GPU
Authors: Aatiz Ghimire, Shahnawaz Alam, Siman Giri, Madhav Prasad Ghimire
Abstract: The growing demand for computational power is driven by advancements in deep learning, the increasing need for big data processing, and the requirements of scientific simulations for academic and research purposes. Developing countries like Nepal often struggle with the resources needed to invest in new and better hardware for these purposes. However, optimizing and building on existing technology can still meet these computing demands effectively. To address these needs, we built a cluster using four NVIDIA GeForce GTX 1650 GPUs. The cluster consists of four nodes: one master node that controls and manages the entire cluster, and three compute nodes dedicated to processing tasks. The master node is equipped with all necessary software for package management, resource scheduling, and deployment, such as Anaconda and Slurm. In addition, a Network File Storage (NFS) system was integrated to provide the additional storage required by the cluster. Given that the cluster is accessible via ssh by a public domain address, which poses significant cybersecurity risks, we implemented fail2ban to mitigate brute force attacks and enhance security. Despite the continuous challenges encountered during the design and implementation process, this project demonstrates how powerful computational clusters can be built to handle resource-intensive tasks in various demanding fields.

Paper number 66:
Title: Noise Synthesis for Low-Light Image Denoising with Diffusion Models
Authors: Liying Lu, Raphaël Achddou, Sabine Süsstrunk
Abstract: Low-light photography produces images with low signal-to-noise ratios due to limited photons. In such conditions, common approximations like the Gaussian noise model fall short, and many denoising techniques fail to remove noise effectively. Although deep-learning methods perform well, they require large datasets of paired images that are impractical to acquire. As a remedy, synthesizing realistic low-light noise has gained significant attention. In this paper, we investigate the ability of diffusion models to capture the complex distribution of low-light noise. We show that a naive application of conventional diffusion models is inadequate for this task and propose three key adaptations that enable high-precision noise generation without calibration or post-processing: a two-branch architecture to better model signal-dependent and signal-independent noise, the incorporation of positional information to capture fixed-pattern noise, and a tailored diffusion noise schedule. Consequently, our model enables the generation of large datasets for training low-light denoising networks, leading to state-of-the-art performance. Through comprehensive analysis, including statistical evaluation and noise decomposition, we provide deeper insights into the characteristics of the generated data.

Paper number 67:
Title: EmoAgent: Multi-Agent Collaboration of Plan, Edit, and Critic, for Affective Image Manipulation
Authors: Qi Mao, Haobo Hu, Yujie He, Difei Gao, Haokun Chen, Libiao Jin
Abstract: Affective Image Manipulation (AIM) aims to alter an image's emotional impact by adjusting multiple visual elements to evoke specific this http URL AIM is inherently complex, necessitating a collaborative approach that involves identifying semantic cues within source images, manipulating these elements to elicit desired emotional responses, and verifying that the combined adjustments successfully evoke the target this http URL address these challenges, we introduce EmoAgent, the first multi-agent collaboration framework for AIM. By emulating the cognitive behaviors of a human painter, EmoAgent incorporates three specialized agents responsible for planning, editing, and critical evaluation. Furthermore, we develop an emotion-factor knowledge retriever, a decision-making tree space, and a tool library to enhance EmoAgent's effectiveness in handling AIM. Experiments demonstrate that the proposed multi-agent framework outperforms existing methods, offering more reasonable and effective emotional expression.

Paper number 68:
Title: MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens
Authors: Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro
Abstract: Audio-Visual Speech Recognition (AVSR) achieves robust speech recognition in noisy environments by combining auditory and visual information. However, recent Large Language Model (LLM) based AVSR systems incur high computational costs due to the high temporal resolution of audio-visual speech processed by LLMs. In this work, we introduce an efficient multimodal speech LLM framework that minimizes token length while preserving essential linguistic content. Our approach employs an early av-fusion module for streamlined feature integration, an audio-visual speech Q-Former that dynamically allocates tokens based on input duration, and a refined query allocation strategy with a speech rate predictor to adjust token allocation according to speaking speed of each audio sample. Extensive experiments on the LRS3 dataset show that our method achieves state-of-the-art performance with a WER of 0.74% while using only 3.5 tokens per second. Moreover, our approach not only reduces token usage by 86% compared to the previous multimodal speech LLM framework, but also improves computational efficiency by reducing FLOPs by 35.7%.

Paper number 69:
Title: Leveraging Diffusion Knowledge for Generative Image Compression with Fractal Frequency-Aware Band Learning
Authors: Lingyu Zhu, Xiangrui Zeng, Bolin Chen, Peilin Chen, Yung-Hui Li, Shiqi Wang
Abstract: By optimizing the rate-distortion-realism trade-off, generative image compression approaches produce detailed, realistic images instead of the only sharp-looking reconstructions produced by rate-distortion-optimized models. In this paper, we propose a novel deep learning-based generative image compression method injected with diffusion knowledge, obtaining the capacity to recover more realistic textures in practical scenarios. Efforts are made from three perspectives to navigate the rate-distortion-realism trade-off in the generative image compression task. First, recognizing the strong connection between image texture and frequency-domain characteristics, we design a Fractal Frequency-Aware Band Image Compression (FFAB-IC) network to effectively capture the directional frequency components inherent in natural images. This network integrates commonly used fractal band feature operations within a neural non-linear mapping design, enhancing its ability to retain essential given information and filter out unnecessary details. Then, to improve the visual quality of image reconstruction under limited bandwidth, we integrate diffusion knowledge into the encoder and implement diffusion iterations into the decoder process, thus effectively recovering lost texture details. Finally, to fully leverage the spatial and frequency intensity information, we incorporate frequency- and content-aware regularization terms to regularize the training of the generative image compression network. Extensive experiments in quantitative and qualitative evaluations demonstrate the superiority of the proposed method, advancing the boundaries of achievable distortion-realism pairs, i.e., our method achieves better distortions at high realism and better realism at low distortion than ever before.

Paper number 70:
Title: Safe-VAR: Safe Visual Autoregressive Model for Text-to-Image Generative Watermarking
Authors: Ziyi Wang, Songbai Tan, Gang Xu, Xuerui Qiu, Hongbin Xu, Xin Meng, Ming Li, Fei Richard Yu
Abstract: With the success of autoregressive learning in large language models, it has become a dominant approach for text-to-image generation, offering high efficiency and visual quality. However, invisible watermarking for visual autoregressive (VAR) models remains underexplored, despite its importance in misuse prevention. Existing watermarking methods, designed for diffusion models, often struggle to adapt to the sequential nature of VAR models. To bridge this gap, we propose Safe-VAR, the first watermarking framework specifically designed for autoregressive text-to-image generation. Our study reveals that the timing of watermark injection significantly impacts generation quality, and watermarks of different complexities exhibit varying optimal injection times. Motivated by this observation, we propose an Adaptive Scale Interaction Module, which dynamically determines the optimal watermark embedding strategy based on the watermark information and the visual characteristics of the generated image. This ensures watermark robustness while minimizing its impact on image quality. Furthermore, we introduce a Cross-Scale Fusion mechanism, which integrates mixture of both heads and experts to effectively fuse multi-resolution features and handle complex interactions between image content and watermark patterns. Experimental results demonstrate that Safe-VAR achieves state-of-the-art performance, significantly surpassing existing counterparts regarding image quality, watermarking fidelity, and robustness against perturbations. Moreover, our method exhibits strong generalization to an out-of-domain watermark dataset QR Codes.

Paper number 71:
Title: Creating a Good Teacher for Knowledge Distillation in Acoustic Scene Classification
Authors: Tobias Morocutti, Florian Schmid, Khaled Koutini, Gerhard Widmer
Abstract: Knowledge Distillation (KD) is a widespread technique for compressing the knowledge of large models into more compact and efficient models. KD has proved to be highly effective in building well-performing low-complexity Acoustic Scene Classification (ASC) systems and was used in all the top-ranked submissions to this task of the annual DCASE challenge in the past three years. There is extensive research available on establishing the KD process, designing efficient student models, and forming well-performing teacher ensembles. However, less research has been conducted on investigating which teacher model attributes are beneficial for low-complexity students. In this work, we try to close this gap by studying the effects on the student's performance when using different teacher network architectures, varying the teacher model size, training them with different device generalization methods, and applying different ensembling strategies. The results show that teacher model sizes, device generalization methods, the ensembling strategy and the ensemble size are key factors for a well-performing student network.

Paper number 72:
Title: Exploring Performance-Complexity Trade-Offs in Sound Event Detection
Authors: Tobias Morocutti, Florian Schmid, Jonathan Greif, Francesco Foscarin, Gerhard Widmer
Abstract: We target the problem of developing new low-complexity networks for the sound event detection task. Our goal is to meticulously analyze the performance-complexity trade-off, aiming to be competitive with the large state-of-the-art models, at a fraction of the computational requirements. We find that low-complexity convolutional models previously proposed for audio tagging can be effectively adapted for event detection (which requires frame-wise prediction) by adjusting convolutional strides, removing the global pooling, and, importantly, adding a sequence model before the (now frame-wise) classification heads. Systematic experiments reveal that the best choice for the sequence model type depends on which complexity metric is most important for the given application. We also investigate the impact of enhanced training strategies such as knowledge distillation. In the end, we show that combined with an optimized training strategy, we can reach event detection performance comparable to state-of-the-art transformers while requiring only around 5% of the parameters. We release all our pre-trained models and the code for reproducing this work to support future research in low-complexity sound event detection at this https URL.

Paper number 73:
Title: Certified Inductive Synthesis for Online Mixed-Integer Optimization
Authors: Marco Zamponi, Emilio Incerto, Daniele Masti, Mirco Tribastone
Abstract: In fields such as autonomous and safety-critical systems, online optimization plays a crucial role in control and decision-making processes, often requiring the integration of continuous and discrete variables. These tasks are frequently modeled as mixed-integer programming (MIP) problems, where feedback data are incorporated as parameters. However, solving MIPs within strict time constraints is challenging due to their $\mathcal{NP}$-complete nature. A promising solution to this challenge involves leveraging the largely invariant structure of these problems to perform most computations offline, thus enabling efficient online solving even on platforms with limited hardware capabilities. In this paper we present a novel implementation of this strategy that uses counterexample-guided inductive synthesis to split the MIP solution process into two stages. In the offline phase, we construct a mapping that provides feasible assignments for binary variables based on parameter values within a specified range. In the online phase, we solve the remaining continuous part of the problem by fixing the binary variables to the values predicted by this mapping. Our numerical evaluation demonstrates the efficiency and solution quality of this approach compared to standard mixed-integer solvers, highlighting its potential for real-time applications in resource-constrained environments.

Paper number 74:
Title: Adaptive Torque Control of Exoskeletons under Spasticity Conditions via Reinforcement Learning
Authors: Andrés Chavarrías, David Rodriguez-Cianca, Pablo Lanillos
Abstract: Spasticity is a common movement disorder symptom in individuals with cerebral palsy, hereditary spastic paraplegia, spinal cord injury and stroke, being one of the most disabling features in the progression of these diseases. Despite the potential benefit of using wearable robots to treat spasticity, their use is not currently recommended to subjects with a level of spasticity above ${1^+}$ on the Modified Ashworth Scale. The varying dynamics of this velocity-dependent tonic stretch reflex make it difficult to deploy safe personalized controllers. Here, we describe a novel adaptive torque controller via deep reinforcement learning (RL) for a knee exoskeleton under joint spasticity conditions, which accounts for task performance and interaction forces reduction. To train the RL agent, we developed a digital twin, including a musculoskeletal-exoskeleton system with joint misalignment and a differentiable spastic reflexes model for the muscles activation. Results for a simulated knee extension movement showed that the agent learns to control the exoskeleton for individuals with different levels of spasticity. The proposed controller was able to reduce maximum torques applied to the human joint under spastic conditions by an average of 10.6\% and decreases the root mean square until the settling time by 8.9\% compared to a conventional compliant controller.

Paper number 75:
Title: ARCAS: Adaptive Runtime System for Chiplet-Aware Scheduling
Authors: Alessandro Fogli, Bo Zhao, Peter Pietzuch, Jana Giceva
Abstract: The growing disparity between CPU core counts and available memory bandwidth has intensified memory contention in servers. This particularly affects highly parallelizable applications, which must achieve efficient cache utilization to maintain performance as CPU core counts grow. Optimizing cache utilization, however, is complex for recent chiplet-based CPUs, whose partitioned L3 caches lead to varying latencies and bandwidths, even within a single NUMA domain. Classical NUMA optimizations and task scheduling approaches unfortunately fail to address the performance issues of chiplet-based CPUs. We describe Adaptive Runtime system for Chiplet-Aware Scheduling (ARCAS), a new runtime system designed for chiplet-based CPUs. ARCAS combines chiplet-aware task scheduling heuristics, hardware-aware memory allocation, and fine-grained performance monitoring to optimize workload execution. It implements a lightweight concurrency model that combines user-level thread features-such as individual stacks, per-task scheduling, and state management-with coroutine-like behavior, allowing tasks to suspend and resume execution at defined points while efficiently managing task migration across chiplets. Our evaluation across diverse scenarios shows ARCAS's effectiveness for optimizing the performance of memory-intensive parallel applications.

Paper number 76:
Title: In Shift and In Variance: Assessing the Robustness of HAR Deep Learning Models against Variability
Authors: Azhar Ali Khaked, Nobuyuki Oishi, Daniel Roggen, Paula Lago
Abstract: Human Activity Recognition (HAR) using wearable inertial measurement unit (IMU) sensors can revolutionize healthcare by enabling continual health monitoring, disease prediction, and routine recognition. Despite the high accuracy of Deep Learning (DL) HAR models, their robustness to real-world variabilities remains untested, as they have primarily been trained and tested on limited lab-confined data. In this study, we isolate subject, device, position, and orientation variability to determine their effect on DL HAR models and assess the robustness of these models in real-world conditions. We evaluated the DL HAR models using the HARVAR and REALDISP datasets, providing a comprehensive discussion on the impact of variability on data distribution shifts and changes in model performance. Our experiments measured shifts in data distribution using Maximum Mean Discrepancy (MMD) and observed DL model performance drops due to variability. We concur that studied variabilities affect DL HAR models differently, and there is an inverse relationship between data distribution shifts and model performance. The compounding effect of variability was analyzed, and the implications of variabilities in real-world scenarios were highlighted. MMD proved an effective metric for calculating data distribution shifts and explained the drop in performance due to variabilities in HARVAR and REALDISP datasets. Combining our understanding of variability with evaluating its effects will facilitate the development of more robust DL HAR models and optimal training techniques. Allowing Future models to not only be assessed based on their maximum F1 score but also on their ability to generalize effectively

Paper number 77:
Title: Vectorable Thrust Control for Multimodal Locomotion of Quadruped Robot SPIDAR
Authors: Moju Zhao
Abstract: In this paper, I present vectorable thrust control for different locomotion modes by a novel quadruped robot, SPIDAR, equipped with vectoring rotor in each link. First, the robot's unique mechanical design, the dynamics model, and the basic control framework for terrestrial/aerial locomotion are briefly introduced. Second, a vectorable thrust control method derived from the basic control framework for aerial locomotion is presented. A key feature of this extended flight control is its ability to avoid interrotor aerodynamics interference under specific joint configuration. Third, another extended thrust control method and a fundamental gait strategy is proposed for special terrestrial locomotion called crawling that requires all legs to be lifted at the same time. Finally, the experimental results of the flight with a complex joint motion and the repeatable crawling motion are explained, which demonstrate the feasibility of the proposed thrust control methods for different locomotion modes.

Paper number 78:
Title: Designing Neural Synthesizers for Low Latency Interaction
Authors: Franco Caspe, Jordie Shier, Mark Sandler, Charalampos Saitis, Andrew McPherson
Abstract: Neural Audio Synthesis (NAS) models offer interactive musical control over high-quality, expressive audio generators. While these models can operate in real-time, they often suffer from high latency, making them unsuitable for intimate musical interaction. The impact of architectural choices in deep learning models on audio latency remains largely unexplored in the NAS literature. In this work, we investigate the sources of latency and jitter typically found in interactive NAS models. We then apply this analysis to the task of timbre transfer using RAVE, a convolutional variational autoencoder for audio waveforms introduced by Caillon et al. in 2021. Finally, we present an iterative design approach for optimizing latency. This culminates with a model we call BRAVE (Bravely Realtime Audio Variational autoEncoder), which is low-latency and exhibits better pitch and loudness replication while showing timbre modification capabilities similar to RAVE. We implement it in a specialized inference framework for low-latency, real-time inference and present a proof-of-concept audio plugin compatible with audio signals from musical instruments. We expect the challenges and guidelines described in this document to support NAS researchers in designing models for low-latency inference from the ground up, enriching the landscape of possibilities for musicians.

Paper number 79:
Title: Experimental evaluation of xApp Conflict Mitigation Framework in O-RAN: Insights from Testbed deployment in OTIC
Authors: Abida Sultana, Cezary Adamczyk, Mayukh Roy Chowdhury, Adrian Kliks, Aloizio Da Silva
Abstract: Conflict Mitigation (CM) in Open Radio Access Network (O-RAN) is a topic that is gaining importance as commercial O-RAN deployments become more complex. Although research on CM is already covered in terms of simulated network scenarios, it lacks validation using real-world deployment and Over The Air (OTA) Radio Frequency (RF) transmission. Our objective is to conduct the first assessment of the Conflict Mitigation Framework (CMF) for O-RAN using a real-world testbed and OTA RF transmission. This paper presents results of an experiment using a dedicated testbed built in an O-RAN Open Test and Integration Center (OTIC) to confirm the validity of one of the Conflict Resolution (CR) schemes proposed by existing research. The results show that the implemented conflict detection and resolution mechanisms allow a significant improvement in network operation stability by reducing the variability of the measured Downlink (DL) throughput by 78%.

Paper number 80:
Title: Pushing DSP-Free Coherent Interconnect to the Last Inch by Optically Analog Signal Processing
Authors: Mingming Zhang, Haoze Du, Xuefeng Wang, Junda Chen, Weihao Li, Zihe Hu, Yizhao Chen, Can Zhao, Hao Wu, Jiajun Zhou, Siyang Liu, Siqi Yan, Ming Tang
Abstract: To support the boosting interconnect capacity of the AI-related data centers, novel techniques enabled high-speed and low-cost optics are continuously emerging. When the baud rate approaches 200 GBaud per lane, the bottle-neck of traditional intensity modulation direct detection (IM-DD) architectures becomes increasingly evident. The simplified coherent solutions are widely discussed and considered as one of the most promising candidates. In this paper, a novel coherent architecture based on self-homodyne coherent detection and optically analog signal processing (OASP) is demonstrated. Proved by experiment, the first DSP-free baud-rate sampled 64-GBaud QPSK/16-QAM receptions are achieved, with BERs of 1e-6 and 2e-2, respectively. Even with 1-km fiber link propagation, the BER for QPSK reception remains at 3.6e-6. When an ultra-simple 1-sps SISO filter is utilized, the performance degradation of the proposed scheme is less than 1 dB compared to legacy DSP-based coherent reception. The proposed results pave the way for the ultra-high-speed coherent optical interconnections, offering high power and cost efficiency.

Paper number 81:
Title: Are Deep Speech Denoising Models Robust to Adversarial Noise?
Authors: Will Schwarzer, Philip S. Thomas, Andrea Fanelli, Xiaoyu Liu
Abstract: Deep noise suppression (DNS) models enjoy widespread use throughout a variety of high-stakes speech applications. However, in this paper, we show that four recent DNS models can each be reduced to outputting unintelligible gibberish through the addition of imperceptible adversarial noise. Furthermore, our results show the near-term plausibility of targeted attacks, which could induce models to output arbitrary utterances, and over-the-air attacks. While the success of these attacks varies by model and setting, and attacks appear to be strongest when model-specific (i.e., white-box and non-transferable), our results highlight a pressing need for practical countermeasures in DNS systems.

Paper number 82:
Title: Output-feedback adaptive model predictive control for ramp metering: a set-membership approach
Authors: Zhexian Li, Ketan Savla
Abstract: Ramp metering, which regulates the flow entering the freeway, is one of the most effective freeway traffic control methods. This paper introduces an output-feedback adaptive approach to ramp metering that combines model predictive control (MPC) with set-membership parameter and state estimation. The set-membership estimator is based on a mixed-monotone embedding of underlying traffic dynamics. The embedding is also used as the modeling basis for MPC optimization. For a freeway stretch with unknown parameters and partial measurement on the freeway mainline, we provide sufficient conditions on the control horizon, cost functions, terminal sets of MPC, and inflow demand at the ramps such that the queue lengths in the closed-loop system remain bounded. The sufficient condition on the demand matches the necessary condition, thereby proving maximal throughput under the proposed controller. The result is strengthened to input-to-state stability when model parameters and demand are known. The stability analysis is conducted for the case of constant demand and unbounded on-ramps. The closed-loop trajectory data generated by the proposed controller is shown to facilitate finite time estimation of free-flow model parameters, i.e., free-flow speed and turning ratios. Simulation results illustrate stability of the closed-loop system under the proposed controller with time-varying demand and few mainline measurements, for which the system becomes unstable under a well-known approach from the literature. This indicates that the proposed controller renders higher throughput than the well-known approach, possibly using more computing resources.

Paper number 83:
Title: VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech
Authors: Chenpeng Du, Yiwei Guo, Hankun Wang, Yifan Yang, Zhikang Niu, Shuai Wang, Hui Zhang, Xie Chen, Kai Yu
Abstract: Recent TTS models with decoder-only Transformer architecture, such as SPEAR-TTS and VALL-E, achieve impressive naturalness and demonstrate the ability for zero-shot adaptation given a speech prompt. However, such decoder-only TTS models lack monotonic alignment constraints, sometimes leading to hallucination issues such as mispronunciation, word skipping and repeating. To address this limitation, we propose VALL-T, a generative Transducer model that introduces shifting relative position embeddings for input phoneme sequence, explicitly indicating the monotonic generation process while maintaining the architecture of decoder-only Transformer. Consequently, VALL-T retains the capability of prompt-based zero-shot adaptation and demonstrates better robustness against hallucinations with a relative reduction of 28.3% in the word error rate.

Paper number 84:
Title: Antifragile Perimeter Control: Anticipating and Gaining from Disruptions with Reinforcement Learning
Authors: Linghang Sun, Michail A. Makridis, Alexander Genser, Cristian Axenie, Margherita Grossi, Anastasios Kouvelas
Abstract: The optimal operation of transportation networks is often susceptible to unexpected disruptions, such as traffic incidents and social events. Many established control strategies rely on mathematical models that struggle to cope with real-world uncertainties, leading to a significant decline in effectiveness when faced with substantial disruptions. While previous research works have dedicated efforts to improving the robustness or resilience of transportation systems against disruptions, this paper applies the cutting-edge concept of antifragility to better design a traffic control strategy for urban road networks. Antifragility sets itself apart from robustness and resilience as it represents a system's ability to not only withstand stressors, shocks, and volatility but also thrive and enhance performance in the presence of such adversarial events. Hence, modern transportation systems call for solutions that are antifragile. In this work, we propose a model-free deep Reinforcement Learning (RL) scheme to control a two-region urban traffic perimeter network. The system exploits the learning capability of RL under disruptions to achieve antifragility. By monitoring the change rate and curvature of the traffic state with the RL framework, the proposed algorithm anticipates imminent disruptions. An additional term is also integrated into the RL algorithm as redundancy to improve the performance under disruption scenarios. When compared to a state-of-the-art model predictive control approach and a state-of-the-art RL algorithm, our proposed method demonstrates two antifragility-related properties: (a) gradual performance improvement under disruptions of constant magnitude; and (b) increasingly superior performance under growing disruptions.

Paper number 85:
Title: Enhanced Low-Dose CT Image Reconstruction by Domain and Task Shifting Gaussian Denoisers
Authors: Tim Selig, Thomas März, Martin Storath, Andreas Weinmann
Abstract: Computed tomography from a low radiation dose (LDCT) is challenging due to high noise in the projection data. Popular approaches for LDCT image reconstruction are two-stage methods, typically consisting of the filtered backprojection (FBP) algorithm followed by a neural network for LDCT image enhancement. Two-stage methods are attractive for their simplicity and potential for computational efficiency, typically requiring only a single FBP and a neural network forward pass for inference. However, the best reconstruction quality is currently achieved by unrolled iterative methods (Learned Primal-Dual and ItNet), which are more complex and thus have a higher computational cost for training and inference. We propose a method combining the simplicity and efficiency of two-stage methods with state-of-the-art reconstruction quality. Our strategy utilizes a neural network pretrained for Gaussian noise removal from natural grayscale images, fine-tuned for LDCT image enhancement. We call this method FBP-DTSGD (Domain and Task Shifted Gaussian Denoisers) as the fine-tuning is a task shift from Gaussian denoising to enhancing LDCT images and a domain shift from natural grayscale to LDCT images. An ablation study with three different pretrained Gaussian denoisers indicates that the performance of FBP-DTSGD does not depend on a specific denoising architecture, suggesting future advancements in Gaussian denoising could benefit the method. The study also shows that pretraining on natural images enhances LDCT reconstruction quality, especially with limited training data. Notably, pretraining involves no additional cost, as existing pretrained models are used. The proposed method currently holds the top mean position in the LoDoPaB-CT challenge.

Paper number 86:
Title: A study of why we need to reassess full reference image quality assessment with medical images
Authors: Anna Breger, Ander Biguri, Malena Sabaté Landman, Ian Selby, Nicole Amberg, Elisabeth Brunner, Janek Gröhl, Sepideh Hatamikia, Clemens Karner, Lipeng Ning, Sören Dittmer, Michael Roberts, AIX-COVNET Collaboration, Carola-Bibiane Schönlieb
Abstract: Image quality assessment (IQA) is indispensable in clinical practice to ensure high standards, as well as in the development stage of machine learning algorithms that operate on medical images. The popular full reference (FR) IQA measures PSNR and SSIM are known and tested for working successfully in many natural imaging tasks, but discrepancies in medical scenarios have been reported in the literature, highlighting the gap between development and actual clinical application. Such inconsistencies are not surprising, as medical images have very different properties than natural images, and PSNR and SSIM have neither been targeted nor properly tested for medical images. This may cause unforeseen problems in clinical applications due to wrong judgment of novel methods. This paper provides a structured and comprehensive overview of examples where PSNR and SSIM prove to be unsuitable for the assessment of novel algorithms using different kinds of medical images, including real-world MRI, CT, OCT, X-Ray, digital pathology and photoacoustic imaging data. Therefore, improvement is urgently needed in particular in this era of AI to increase reliability and explainability in machine learning for medical imaging and beyond. Lastly, we will provide ideas for future research as well as suggesting guidelines for the usage of FR-IQA measures applied to medical images.

Paper number 87:
Title: Improving the Robustness and Clinical Applicability of Automatic Respiratory Sound Classification Using Deep Learning-Based Audio Enhancement: Algorithm Development and Validation
Authors: Jing-Tong Tzeng, Jeng-Lin Li, Huan-Yu Chen, Chun-Hsiang Huang, Chi-Hsin Chen, Cheng-Yi Fan, Edward Pei-Chuan Huang, Chi-Chun Lee
Abstract: Deep learning techniques have shown promising results in the automatic classification of respiratory sounds. However, accurately distinguishing these sounds in real-world noisy conditions remains challenging for clinical deployment. In addition, predicting signals with only background noise may reduce user trust in the system. This study explores the feasibility and effectiveness of incorporating a deep learning-based audio enhancement step into automatic respiratory sound classification systems to improve robustness and clinical applicability. We conducted extensive experiments using various audio enhancement model architectures, including time-domain and time-frequency-domain approaches, combined with multiple classification models to evaluate the module's effectiveness. The classification performance was compared against the noise injection data augmentation method. These experiments were carried out on two datasets: the ICBHI respiratory sound dataset and the FABS dataset. Furthermore, a physician validation study assessed the system's clinical utility. Integrating the audio enhancement module resulted in a 21.9% increase in the ICBHI classification score and a 4.1% improvement on the FABS dataset in multi-class noisy scenarios. Quantitative analysis revealed efficiency gains, higher diagnostic confidence, and increased trust, with workflows using enhanced audio improving diagnostic sensitivity by 11.6% and enabling high-confidence diagnoses. Incorporating an audio enhancement algorithm boosts the robustness and clinical utility of automatic respiratory sound classification systems, enhancing performance in noisy environments and fostering greater trust among medical professionals.

Paper number 88:
Title: LightViz: Autonomous Light-field Surveying and Mapping for Distributed Light Pollution Monitoring
Authors: Sheng-En Huang, Kazi Farha Farzana Suhi, Md Jahidul Islam
Abstract: Existing technologies for distributed light-field mapping and light pollution monitoring (LPM) rely on either remote satellite imagery or manual light surveying with single-point sensors such as SQMs (sky quality meters). These modalities offer low-resolution data that are not informative for dense light-field mapping, pollutant factor identification, or sustainable policy implementation. In this work, we propose LightViz -- an interactive software interface to survey, simulate, and visualize light pollution maps in real-time. As opposed to manual error-prone methods, LightViz (i) automates the light-field data collection and mapping processes; (ii) provides a platform to simulate various light sources and intensity attenuation models; and (iii) facilitates effective policy identification for conservation. To validate the end-to-end computational pipeline, we design a distributed light-field sensor suit, collect data on Florida coasts, and visualize the distributed light-field maps. In particular, we perform a case study at St. Johns County in Florida, which has a two-decade conservation program for lighting ordinances. The experimental results demonstrate that LightViz can offer high-resolution light-field mapping and provide interactive features to simulate and formulate community policies for light pollution mitigation. We also propose a mathematical formulation for light footprint evaluation, which we integrated into LightViz for targeted LPM in vulnerable communities. A test-case of the LightViz software release is available at: this https URL.

Paper number 89:
Title: Optimizing RIS Impairments through Semantic Communication
Authors: Nour Hello, Mattia Merluzzi, Emilio Calvanese Strinati, Luca Sanguinetti
Abstract: This paper investigates how semantic communication can effectively influence and potentially redefine the limitations imposed by physical layer settings. Reconfigurable Intelligent Surfaces (RIS) enable the intelligent configuration of the physical layer of communication systems. However, its practical implementation is hampered by several limitations. The Semantic Communication (SemCom) paradigm introduces additional degrees of freedom that can be exploited to improve the robustness of communication against physical layer impairments. In essence, SemCom ensures that the data representation remains robust even under adverse physical conditions by emphasizing the transmission of meaningful information in a manner that is less susceptible to degradation. Through the use of SemCom, potential RIS gains are demonstrated in terms of RIS area size and the phase shift precision of its active elements.

Paper number 90:
Title: Optimal gait design for nonlinear soft robotic crawlers
Authors: Yenan Shen, Naomi Ehrich Leonard, Bassam Bamieh, Juncal Arbelaiz
Abstract: Soft robots offer a frontier in robotics with enormous potential for safe human-robot interaction and agility in uncertain environments. A stepping stone towards unlocking their potential is a control theory tailored to soft robotics, including a principled framework for gait design. We analyze the problem of optimal gait design for a soft crawling body - the crawler. The crawler is an elastic body with the control signal defined as actuation forces between segments of the body. We consider the simplest such crawler: a two-segmented body with a passive mechanical connection modeling the viscoelastic body dynamics and a symmetric control force modeling actuation between the two body segments. The model accounts for the nonlinear asymmetric friction with the ground, which together with the symmetric actuation forces enable the crawler's locomotion. Using a describing-function analysis, we show that when the body is forced sinusoidally, the optimal actuator contraction frequency corresponds to the body's natural frequency when operating with only passive dynamics. We then use the framework of Optimal Periodic Control (OPC) to design optimal force cycles of arbitrary waveform and the corresponding crawling gaits. We provide a hill-climbing algorithm to solve the OPC problem numerically. Our proposed methods and results inform the design of optimal forcing and gaits for more complex and multi-segmented crawling soft bodies.

Paper number 91:
Title: Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency
Authors: Robin Strässer, Julian Berberich, Frank Allgöwer
Abstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.

Paper number 92:
Title: Unauthorized Radio Sensing and Privacy Risks: A Sampling Error-Based Defense
Authors: Zexin Fang, Bin Han, Wenwen Chen, Hans D. Schotten
Abstract: Unauthorized sensing activities pose an increasing threat to individual privacy, yet effective countermeasures remain underdeveloped. This paper presents a novel methodology to characterize and counter such unauthorized surveillance. We model pedestrian trajectories as a random process and leverage the Cramer-Rao bound (CRB) to evaluate sensing performance, interpreting it as sampling error within this random process. Through simulation, we verify our method's accuracy in monitoring unauthorized sensing activities in urban environments and validate the effectiveness of our proposed mitigation strategies.

Paper number 93:
Title: Wearable intelligent throat enables natural speech in stroke patients with dysarthria
Authors: Chenyu Tang, Shuo Gao, Cong Li, Wentian Yi, Yuxuan Jin, Xiaoxue Zhai, Sixuan Lei, Hongbei Meng, Zibo Zhang, Muzi Xu, Shengbo Wang, Xuhang Chen, Chenxi Wang, Hongyun Yang, Ningli Wang, Wenyu Wang, Jin Cao, Xiaodong Feng, Peter Smielewski, Yu Pan, Wenhui Song, Martin Birchall, Luigi G. Occhipinti
Abstract: Wearable silent speech systems hold significant potential for restoring communication in patients with speech impairments. However, seamless, coherent speech remains elusive, and clinical efficacy is still unproven. Here, we present an AI-driven intelligent throat (IT) system that integrates throat muscle vibrations and carotid pulse signal sensors with large language model (LLM) processing to enable fluent, emotionally expressive communication. The system utilizes ultrasensitive textile strain sensors to capture high-quality signals from the neck area and supports token-level processing for real-time, continuous speech decoding, enabling seamless, delay-free communication. In tests with five stroke patients with dysarthria, IT's LLM agents intelligently corrected token errors and enriched sentence-level emotional and logical coherence, achieving low error rates (4.2% word error rate, 2.9% sentence error rate) and a 55% increase in user satisfaction. This work establishes a portable, intuitive communication platform for patients with dysarthria with the potential to be applied broadly across different neurological conditions and in multi-language support systems.

Paper number 94:
Title: Local Flaw Detection with Adaptive Pyramid Image Fusion Across Spatial Sampling Resolution for SWRs
Authors: Siyu You, Huayi Gou, Leilei Yang, Zhiliang Liu, Mingjian Zuo
Abstract: The inspection of local flaws (LFs) in Steel Wire Ropes (SWRs) is crucial for ensuring safety and reliability in various industries. Magnetic Flux Leakage (MFL) imaging is commonly used for non-destructive testing, but its effectiveness is often hindered by the combined effects of inspection speed and sampling rate. To address this issue, the impacts of inspection speed and sampling rate on image quality are studied, as variations in these factors can cause stripe noise, axial compression of defect features, and increased interference, complicating accurate detection. We define the relationship between inspection speed and sampling rate as spatial sampling resolution (SSR) and propose an adaptive SSR target-feature-oriented (AS-TFO) method. This method incorporates adaptive adjustment and pyramid image fusion techniques to enhance defect detection under different SSR scenarios. Experimental results show that under high SSR scenarios, the method achieves a precision of 94.73% and a recall of 96.77%. It remains robust under low SSR scenarios with a precision of 94.30% and recall of 97.32%. The overall results show that the proposed method outperforms conventional approaches, achieving state-of-the-art performance. This improvement in detection accuracy and robustness is particularly valuable for handling complex inspection conditions, where inspection speed and sampling rate can vary significantly, making detection more robust and reliable in industrial settings.

Paper number 95:
Title: COMMA: Coordinate-aware Modulated Mamba Network for 3D Dispersed Vessel Segmentation
Authors: Gen Shi, Hui Zhang, Jie Tian
Abstract: Accurate segmentation of 3D vascular structures is essential for various medical imaging applications. The dispersed nature of vascular structures leads to inherent spatial uncertainty and necessitates location awareness, yet most current 3D medical segmentation models rely on the patch-wise training strategy that usually loses this spatial context. In this study, we introduce the Coordinate-aware Modulated Mamba Network (COMMA) and contribute a manually labeled dataset of 570 cases, the largest publicly available 3D vessel dataset to date. COMMA leverages both entire and cropped patch data through global and local branches, ensuring robust and efficient spatial location awareness. Specifically, COMMA employs a channel-compressed Mamba (ccMamba) block to encode entire image data, capturing long-range dependencies while optimizing computational costs. Additionally, we propose a coordinate-aware modulated (CaM) block to enhance interactions between the global and local branches, allowing the local branch to better perceive spatial information. We evaluate COMMA on six datasets, covering two imaging modalities and five types of vascular tissues. The results demonstrate COMMA's superior performance compared to state-of-the-art methods with computational efficiency, especially in segmenting small vessels. Ablation studies further highlight the importance of our proposed modules and spatial information. The code and data will be open source at this https URL.

Paper number 96:
Title: Cost-Effective Design of Grid-tied Community Microgrid
Authors: Moslem Uddin, Huadong Mo, Daoyi Dong
Abstract: This study aims to develop a cost-effective microgrid design that optimally balances the economic feasibility, reliability, efficiency, and environmental impact in a grid-tied community microgrid. A multi-objective optimization framework is employed, integrating HOMER Pro for system sizing with deep reinforcement learning (DRL). Sensitivity analyses are conducted to evaluate the system performance under varying load demand and renewable energy fluctuations, while an economic sensitivity assessment examines the impact of electricity prices and capital costs on the Levelized Cost of Energy (LCOE). The proposed microgrid configuration achieves high reliability, satisfying 100% of the load, even under adverse weather conditions. The proposed framework attains an efficiency of 91.99% while maintaining a carbon footprint of 302,747 kg/year, which is approximately 95% lower than that of the grid system. The economic analysis indicates a net present cost (NPC) of $4.83M with a competitive LCOE of $0.208/kWh. In addition, the operation cost is $201,473 per year with a capital investment of $1.42M, rendering it a financially viable alternative to conventional grid-dependent this http URL work can be valuable in identifying effective solutions for supplying reliable and cost-effective power to regional and remote areas.

Paper number 97:
Title: A Bi-channel Aided Stitching of Atomic Force Microscopy Images
Authors: Huanhuan Zhao, Ruben Millan-Solsona, Marti Checa, Spenser R. Brown, Jennifer L. Morrell-Falvey, Liam Collins, Arpan Biswas
Abstract: Microscopy is an essential tool in scientific research, enabling the visualization of structures at micro- and nanoscale resolutions. However, the field of microscopy often encounters limitations in field-of-view (FOV), restricting the amount of sample that can be imaged in a single capture. To overcome this limitation, image stitching techniques have been developed to seamlessly merge multiple overlapping images into a single, high-resolution composite. The images collected from microscope need to be optimally stitched before accurate physical information can be extracted from post analysis. However, the existing stitching tools either struggle to stitch images together when the microscopy images are feature sparse or cannot address all the transformations of images. To address these issues, we propose a bi-channel aided feature-based image stitching method and demonstrate its use on AFM generated biofilm images. The topographical channel image of AFM data captures the morphological details of the sample, and a stitched topographical image is desired for researchers. We utilize the amplitude channel of AFM data to maximize the matching features and to estimate the position of the original topographical images and show that the proposed bi-channel aided stitching method outperforms the traditional stitching approach. Furthermore, we found that the differentiation of the topographical images along the x-axis provides similar feature information to the amplitude channel image, which generalizes our approach when the amplitude images are not available. Here we demonstrated the application on AFM, but similar approaches could be employed of optical microscopy with brightfield and fluorescence channels. We believe this proposed workflow will benefit the experimentalist to avoid erroneous analysis and discovery due to incorrect stitching.

Paper number 98:
Title: A Heterogeneous Multiscale Method for Efficient Simulation of Power Systems with Inverter-Based Resources
Authors: Kaiyang Huang, Min Xiong, Yang Liu, Kai Sun
Abstract: As inverter-based resources (IBRs) penetrate power systems, the dynamics become more complex, exhibiting multiple timescales, including electromagnetic transient (EMT) dynamics of power electronic controllers and electromechanical dynamics of synchronous generators. Consequently, the power system model becomes highly stiff, posing a challenge for efficient simulation using existing methods that focus on dynamics within a single timescale. This paper proposes a Heterogeneous Multiscale Method for highly efficient multi-timescale simulation of a power system represented by its EMT model. The new method alternates between the microscopic EMT model of the system and an automatically reduced macroscopic model, varying the step size accordingly to achieve significant acceleration while maintaining accuracy in both fast and slow dynamics of interests. It also incorporates a semi-analytical solution method to enable a more adaptive variable-step mechanism. The new simulation method is illustrated using a two-area system and is then tested on a detailed EMT model of the IEEE 39-bus system.

Paper number 99:
Title: An Ensemble-Based Two-Step Framework for Classification of Pap Smear Cell Images
Authors: Theo Di Piazza, Loic Boussel
Abstract: Early detection of cervical cancer is crucial for improving patient outcomes and reducing mortality by identifying precancerous lesions as soon as possible. As a result, the use of pap smear screening has significantly increased, leading to a growing demand for automated tools that can assist cytologists managing their rising workload. To address this, the Pap Smear Cell Classification Challenge (PS3C) has been organized in association with ISBI in 2025. This project aims to promote the development of automated tools for pap smear images classification. The analyzed images are grouped into four categories: healthy, unhealthy, both, and rubbish images which are considered as unsuitable for diagnosis. In this work, we propose a two-stage ensemble approach: first, a neural network determines whether an image is rubbish or not. If not, a second neural network classifies the image as containing a healthy cell, an unhealthy cell, or both.

Paper number 100:
Title: What Would Trojans Do? Exploiting Partial-Information Vulnerabilities in Autonomous Vehicle Sensing
Authors: R. Spencer Hallyburton, Qingzhao Zhang, Z. Morley Mao, Michael Reiter, Miroslav Pajic
Abstract: Safety-critical sensors in autonomous vehicles (AVs) form an essential part of the vehicle's trusted computing base (TCB), yet they are highly susceptible to attacks. Alarmingly, Tier 1 manufacturers have already exposed vulnerabilities to attacks introducing Trojans that can stealthily alter sensor outputs. We analyze the feasible capability and safety-critical outcomes of an attack on sensing at a cyber level. To further address these threats, we design realistic attacks in AV simulators and real-world datasets under two practical constraints: attackers (1) possess only partial information and (2) are constrained by data structures that maintain sensor this http URL the role of camera and LiDAR in multi-sensor AVs, we find that attacks targeting only the camera have minimal safety impact due to the sensor fusion system's strong reliance on 3D data from LiDAR. This reliance makes LiDAR-based attacks especially detrimental to safety. To mitigate the vulnerabilities, we introduce security-aware sensor fusion incorporating (1) a probabilistic data-asymmetry monitor and (2) a scalable track-to-track fusion of 3D LiDAR and monocular detections (T2T-3DLM). We demonstrate that these methods significantly diminish attack success rate.

Paper number 101:
Title: On the Impact of Uncertainty and Calibration on Likelihood-Ratio Membership Inference Attacks
Authors: Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone
Abstract: In a membership inference attack (MIA), an attacker exploits the overconfidence exhibited by typical machine learning models to determine whether a specific data point was used to train a target model. In this paper, we analyze the performance of the likelihood ratio attack (LiRA) within an information-theoretical framework that allows the investigation of the impact of the aleatoric uncertainty in the true data generation process, of the epistemic uncertainty caused by a limited training data set, and of the calibration level of the target model. We compare three different settings, in which the attacker receives decreasingly informative feedback from the target model: confidence vector (CV) disclosure, in which the output probability vector is released; true label confidence (TLC) disclosure, in which only the probability assigned to the true label is made available by the model; and decision set (DS) disclosure, in which an adaptive prediction set is produced as in conformal prediction. We derive bounds on the advantage of an MIA adversary with the aim of offering insights into the impact of uncertainty and calibration on the effectiveness of MIAs. Simulation results demonstrate that the derived analytical bounds predict well the effectiveness of MIAs.

Paper number 102:
Title: A Semi-Lagrangian Approach for Time and Energy Path Planning Optimization in Static Flow Fields
Authors: Víctor C. da S. Campos, Armando A. Neto, Douglas G. Macharet
Abstract: Efficient path planning for autonomous mobile robots is a critical problem across numerous domains, where optimizing both time and energy consumption is paramount. This paper introduces a novel methodology that considers the dynamic influence of an environmental flow field and considers geometric constraints, including obstacles and forbidden zones, enriching the complexity of the planning problem. We formulate it as a multi-objective optimal control problem, propose a novel transformation called Harmonic Transformation, and apply a semi-Lagrangian scheme to solve it. The set of Pareto efficient solutions is obtained considering two distinct approaches: a deterministic method and an evolutionary-based one, both of which are designed to make use of the proposed Harmonic Transformation. Through an extensive analysis of these approaches, we demonstrate their efficacy in finding optimized paths.

Paper number 103:
Title: EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion Recognition
Authors: Yi Ding, Chengxuan Tong, Shuailei Zhang, Muyun Jiang, Yong Li, Kevin Lim Jun Liang, Cuntai Guan
Abstract: Integrating prior knowledge of neurophysiology into neural network architecture enhances the performance of emotion decoding. While numerous techniques emphasize learning spatial and short-term temporal patterns, there has been limited emphasis on capturing the vital long-term contextual information associated with emotional cognitive processes. In order to address this discrepancy, we introduce a novel transformer model called emotion transformer (EmT). EmT is designed to excel in both generalized cross-subject EEG emotion classification and regression tasks. In EmT, EEG signals are transformed into a temporal graph format, creating a sequence of EEG feature graphs using a temporal graph construction module (TGC). A novel residual multi-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph representations for each EEG feature graph within the series, and the learned representations of each graph are fused into one token. Furthermore, we design a temporal contextual transformer module (TCT) with two types of token mixers to learn the temporal contextual information. Finally, the task-specific output module (TSO) generates the desired outputs. Experiments on four publicly available datasets show that EmT achieves higher results than the baseline methods for both EEG emotion classification and regression tasks. The code is available at this https URL.

Paper number 104:
Title: Subband Splitting: Simple, Efficient and Effective Technique for Solving Block Permutation Problem in Determined Blind Source Separation
Authors: Kazuki Matsumoto, Kohei Yatabe
Abstract: Solving the permutation problem is essential for determined blind source separation (BSS). Existing methods, such as independent vector analysis (IVA) and independent low-rank matrix analysis (ILRMA), tackle the permutation problem by modeling the co-occurrence of the frequency components of source signals. One of the remaining challenges in these methods is the block permutation problem, which may cause severe performance degradation. In this paper, we propose a simple and effective technique for solving the block permutation problem. The proposed technique splits the entire frequency bands into several overlapping subbands and sequentially applies BSS methods (e.g., IVA, ILRMA, or any other method) to each subband. Since the splitting reduces the size of the problem, the BSS methods can effectively work in each subband. Then, the permutations among the subbands are aligned by using the separation result in one subband as the initial values for the other subbands. Additionally, we propose SS-IVA and SS-ILRMA by combining subband splitting (SS) with IVA and ILRMA. Experimental results demonstrated that our technique remarkably improves the separation performance without increasing computational cost. In particular, our SS-ILRMA achieved the separation performance comparable to the oracle method (frequency-domain independent component analysis with the ideal permutation solver). Moreover, SS-ILRMA converged faster than conventional IVA and ILRMA.

Paper number 105:
Title: Content-based Wake-up for Energy-efficient and Timely Top-k IoT Sensing Data Retrieval
Authors: Junya Shiraishi, Anders E. Kalør, Israel Leyva-Mayorga, Federico Chiariotti, Petar Popovski, Hiroyuki Yomo
Abstract: Energy efficiency and information freshness are key requirements for sensor nodes serving Industrial Internet of Things (IIoT) applications, where a sink node collects informative and fresh data before a deadline, e.g., to control an external actuator. Content-based wake-up (CoWu) activates a subset of nodes that hold data relevant for the sink's goal, thereby offering an energy-efficient way to attain objectives related to information freshness. This paper focuses on a scenario where the sink collects fresh information on top-k values, defined as data from the nodes observing the k highest readings at the deadline. We introduce a new metric called top-k Query Age of Information (k-QAoI), which allows us to characterize the performance of CoWu by considering the characteristics of the physical process. Further, we show how to select the CoWu parameters, such as its timing and threshold, to attain both information freshness and energy efficiency. The numerical results reveal the effectiveness of the CoWu approach, which is able to collect top-k data with higher energy efficiency while reducing k-QAoI when compared to round-robin scheduling, especially when the number of nodes is large and the required size of k is small.

Paper number 106:
Title: Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature
Authors: Jan Vrba, Jakub Steinbach, Tomáš Jirsa, Laura Verde, Roberta De Fazio, Yuwen Zeng, Kei Ichiji, Lukáš Hájek, Zuzana Sedláková, Zuzana Urbániová, Martin Chovanec, Jan Mareš, Noriyasu Homma
Abstract: Purpose: We introduce a novel methodology for voice pathology detection using the publicly available Saarbrücken Voice Database (SVD) and a robust feature set combining commonly used acoustic handcrafted features with two novel ones: pitch difference (relative variation in fundamental frequency) and NaN feature (failed fundamental frequency estimation). Methods: We evaluate six machine learning (ML) algorithms -- support vector machine, k-nearest neighbors, naive Bayes, decision tree, random forest, and AdaBoost -- using grid search for feasible hyperparameters and 20480 different feature subsets. Top 1000 classification models -- feature subset combinations for each ML algorithm are validated with repeated stratified cross-validation. To address class imbalance, we apply K-Means SMOTE to augment the training data. Results: Our approach achieves 85.61%, 84.69% and 85.22% unweighted average recall (UAR) for females, males and combined results respectively. We intentionally omit accuracy as it is a highly biased metric for imbalanced data. Conclusion: Our study demonstrates that by following the proposed methodology and feature engineering, there is a potential in detection of various voice pathologies using ML models applied to the simplest vocal task, a sustained utterance of the vowel /a:/. To enable easier use of our methodology and to support our claims, we provide a publicly available GitHub repository with DOI https://doi.org/10.5281/zenodo.13771573. Finally, we provide a REFORMS checklist to enhance readability, reproducibility and justification of our approach

Paper number 107:
Title: Real-Time Decision-Making for Digital Twin in Additive Manufacturing with Model Predictive Control using Time-Series Deep Neural Networks
Authors: Yi-Ping Chen, Vispi Karkaria, Ying-Kuan Tsai, Faith Rolark, Daniel Quispe, Robert X. Gao, Jian Cao, Wei Chen
Abstract: Digital Twin -- a virtual replica of a physical system enabling real-time monitoring, model updating, prediction, and decision-making -- combined with recent advances in machine learning, offers new opportunities for proactive control strategies in autonomous manufacturing. However, achieving real-time decision-making with Digital Twins requires efficient optimization driven by accurate predictions of highly nonlinear manufacturing systems. This paper presents a simultaneous multi-step Model Predictive Control (MPC) framework for real-time decision-making, using a multivariate deep neural network, named Time-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional MPC models which only provide one-step ahead prediction, TiDE is capable of predicting future states within the prediction horizon in one shot (multi-step), significantly accelerating the MPC. Using Directed Energy Deposition (DED) additive manufacturing as a case study, we demonstrate the effectiveness of the proposed MPC in achieving melt pool temperature tracking to ensure part quality, while reducing porosity defects by regulating laser power to maintain melt pool depth constraints. In this work, we first show that TiDE is capable of accurately predicting melt pool temperature and depth. Second, we demonstrate that the proposed MPC achieves precise temperature tracking while satisfying melt pool depth constraints within a targeted dilution range (10\%-30\%), reducing potential porosity defects. Compared to PID controller, the MPC results in smoother and less fluctuating laser power profiles with competitive or superior melt pool temperature control performance. This demonstrates the MPC's proactive control capabilities, leveraging time-series prediction and real-time optimization, positioning it as a powerful tool for future Digital Twin applications and real-time process optimization in manufacturing.

Paper number 108:
Title: Generative Multi-Agent Q-Learning for Policy Optimization: Decentralized Wireless Networks
Authors: Talha Bozkus, Urbashi Mitra
Abstract: Q-learning is a widely used reinforcement learning (RL) algorithm for optimizing wireless networks, but faces challenges with large state-spaces. Recently proposed multi-environment mixed Q-learning (MEMQ) algorithm addresses these challenges by employing multiple Q-learning algorithms across multiple synthetically generated, distinct but structurally related environments, so-called digital cousins. In this paper, we propose a novel multi-agent MEMQ (M-MEMQ) for cooperative decentralized wireless networks with multiple networked transmitters (TXs) and base stations (BSs). TXs do not have access to global information (joint state and actions). The new concept of coordinated and uncoordinated states is introduced. In uncoordinated states, TXs act independently to minimize their individual costs and update local Q-functions. In coordinated states, TXs use a Bayesian approach to estimate the joint state and update the joint Q-functions. The cost of information-sharing scales linearly with the number of TXs and is independent of the joint state-action space size. Several theoretical guarantees, including deterministic and probabilistic convergence, bounds on estimation error variance, and the probability of misdetecting the joint states, are given. Numerical simulations show that M-MEMQ outperforms several decentralized and centralized training with decentralized execution (CTDE) multi-agent RL algorithms by achieving 55% lower average policy error (APE), 35% faster convergence, 50% reduced runtime complexity, and 45% less sample complexity. Furthermore, M-MEMQ achieves comparable APE with significantly lower complexity than centralized methods. Simulations validate the theoretical analyses.

Paper number 109:
Title: Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model
Authors: Ali Vosoughi, Dimitra Emmanouilidou, Hannes Gamper
Abstract: Integrating audio and visual data for training multimodal foundational models remains challenging. We present Audio-Video Vector Alignment (AVVA), which aligns audiovisual (AV) scene content beyond mere temporal synchronization via a Large Language Model (LLM)-based data curation pipeline. Specifically, AVVA scores and selects high-quality training clips using Whisper (speech-based audio foundation model) for audio and DINOv2 for video within a dual-encoder contrastive learning framework. Evaluations on AudioCaps, VALOR, and VGGSound demonstrate that this approach can achieve significant accuracy gains with substantially less curated data. For instance, AVVA yields a 7.6% improvement in top-1 accuracy for audio-to-video retrieval on VGGSound compared to ImageBind, despite training on only 192 hours of carefully filtered data (vs. 5800+ hours). Moreover, an ablation study highlights that trading data quantity for data quality improves performance, yielding respective top-3 accuracy increases of 47.8, 48.4, and 58.0 percentage points on AudioCaps, VALOR, and VGGSound over uncurated baselines. While these results underscore AVVA's data efficiency, we also discuss the overhead of LLM-driven curation and how it may be scaled or approximated in larger domains. Overall, AVVA provides a viable path toward more robust, text-free audiovisual learning with improved retrieval accuracy.
    