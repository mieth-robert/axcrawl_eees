
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Unconventional Array Design in the Autocorrelation Domain -- Isophoric 1D Thinning
Authors: Lorenzo Poli, Giacomo Oliveri, Nicola Anselmi, Arianna Benoni, Luca Tosi, Andrea Massa
Abstract: The synthesis of thinned isophoric arrays (TIAs) radiating mask-constrained patterns is addressed. By leveraging on the recently-introduced formulation of the design of antenna arrays in the autocorrelation-domain (AD), the TIA synthesis is recast as the matching of a target autocorrelation function derived from the user-defined guidelines and objectives. By exploiting the autocorrelation invariance of cyclic binary sequences, the AD solution space is significantly reduced and it is efficiently sampled by means of a discrete hybrid optimization approach. Two possible implementations of the AD-based TIA formulation are discussed and assessed in a set of representative numerical examples concerned with both ideal and real radiators, which are full-wave modeled to account for the mutual coupling effects. Comparisons with traditional pattern-domain (PD) synthesis methods are also considered to point out the features and the advantages of AD-based approaches.

Paper number 2:
Title: Open-source End-to-End Digital Beamforming System Modeling
Authors: Jose Guajardo, Ali Niknejad
Abstract: Digital beamforming forms the foundation for massive MIMO in 6G wireless communications. At their core, digital beamforming architectures provide key benefits such as faster beam search, interference nulling via zero-force beamforming, higher spectral capacity, and more increased flexibility. However, they generally tradeoff power consumption due to the large number of ADCs in such systems. This paper introduces an open-source MATLAB-based behavioral hardware model of a general digital beamforming system. More specifically, it models an end-to-end uplink between an arbitrary number of user elements (UEs) and an arbitrarily large base station (BS) with and without a strong interferer. This paper also presents and validates an equation-based model for the effects of interference on thermal and quantization noise. The behavioral model presented in this paper aims to deepen understanding of such digital beamforming systems to enable system designers to make optimizations. The results presented in this paper primarily center on implementations with low-resolution ADCs and, thus, focus on the effects of system parameters, including interferer strength, on quantization noise.

Paper number 3:
Title: The Ingenuity Mars Helicopter Specified and Analyzed with the Real-time Mode-aware Dataflow Model
Authors: Guillaume Roumage (LCYL), Selma Azaiez (CEA), Cyril Faure (LCYL), Stéphane Louise (LCYL)
Abstract: Ingenuity is an autonomous Cyber-Pysical System (CPS) that has successfully completed more than 70 flights over Mars between 2021 and 2024. Ensuring the safety of its mission is paramount, as any failure could result in catastrophic economic damage and significant financial losses. Dataflow Models of Computation and Communication (DF MoCCs) serve as a formal framework for specifying and analyzing the timing behavior of such CPSs. In particular, the Real-time Mode-aware Dataflow (RMDF) model is highly suitable to specify and analyze real-time and mode-dependent Cyber-Physical Systems (CPSs) like Ingenuity. This paper showcases the application of RMDF for the specification and analysis of Ingenuity. We propose a dataflow specification of Ingenuity, analyze its timing behavior, and provide a feasibility test. Finally, we proposed a plausible explanation of the timing anomaly that occurred during the sixth flight of Ingenuity.

Paper number 4:
Title: Signal Processing Challenges in Automotive Radar
Authors: Sandeep Rao, Rajan Narasimha, Shunqiao Sun
Abstract: As automotive radars continue to proliferate, there is a continuous need for improved performance and several critical problems that need to be solved. All of this is driving research across industry and academia. This paper is an overview of research areas that are centered around signal processing. We discuss opportunities in the area of modulation schemes, interference avoidance, spatial resolution enhancement and application of deep learning. A rich list of references is provided. This paper should serve as a useful starting point for signal processing practitioners looking to work in the area of automotive radars.

Paper number 5:
Title: Koopman Meets Limited Bandwidth: Effect of Quantization on Data-Driven Linear Prediction and Control of Nonlinear Systems
Authors: Shahab Ataei, Dipankar Maity, Debdipta Goswami
Abstract: Koopman-based lifted linear identification have been widely used for data-driven prediction and model predictive control (MPC) of nonlinear systems. It has found applications in flow-control, soft robotics, and unmanned aerial vehicles (UAV). For autonomous systems, this system identification method works by embedding the nonlinear system in a higher-dimensional linear space and computing a finite-dimensional approximation of the corresponding Koopman operator with the Extended Dynamic Mode Decomposition (EDMD) algorithm. EDMD is a data-driven algorithm that estimates an approximate linear system by lifting the state data-snapshots via nonlinear dictionary functions. For control systems, EDMD is further modified to utilize both state and control data-snapshots to estimate a lifted linear predictor with control input. This article investigates how the estimation process is affected when the data is quantized. Specifically, we examine the fundamental connection between estimates of the linear predictor matrices obtained from unquantized data and those from quantized data via modified EDMD. Furthermore, using the law of large numbers, we demonstrate that, under a large data regime, the quantized estimate can be considered a regularized version of the unquantized estimate. We also explore the relationship between the two estimates in the finite data regime. We further analyze the effect of nonlinear lifting functions on this regularization due to quantization. The theory is validated through repeated numerical experiments conducted on several control systems. The effect of quantization on the MPC performance is also demonstrated.

Paper number 6:
Title: Analyzing the Role of the DSO in Electricity Trading of VPPs via a Stackelberg Game Model
Authors: Peng Wang, Xi Zhang, Luis Badesa
Abstract: The increasing penetration of distributed energy resources (DER) has sparked interest in promoting their participation in the power market. Here we consider a setting in which different virtual power plants (VPPs) with certain flexible resources take part in electricity trading, either by direct participation in the wholesale power market, or interfaced by the Distribution System Operator (DSO). Our goal is to examine the role and influence of the DSO as a stakeholder, for which we formulate a Stackelberg game via a bilevel optimization model: the DSO maximizes profits at the upper level, while VPPs minimize operating costs at the lower level. To solve this problem, we use the Karush-Kuhn-Tucke optimality conditions of the convex lower-level problems to achieve a single-level mixed-integer nonlinear program. The results show that the role of the DSO as an intermediary agent leads to a decrease in operating costs for the VPPs, while guaranteeing a profit for the DSO.

Paper number 7:
Title: A Doubly-Dispersive MIMO Channel Model Parametrized with Stacked Intelligent Metasurfaces
Authors: Kuranage Roche Rayan Ranasinghe, Iván Alexander Morales Sandoval, Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, George C. Alexandropoulos
Abstract: Introduced with the advent of statistical wireless channel models for high mobility communications and having a profound role in communication-centric (CC) integrated sensing and communications (ISAC), the doubly-dispersive (DD) channel structure has long been heralded as a useful tool enabling the capture of the most important fading effects undergone by an arbitrary time-domain transmit signal propagating through some medium. However, the incorporation of this model into multiple-input multiple-output (MIMO) system setups, relying on the recent paradigm-shifting transceiver architecture based on stacked intelligent metasurfaces (SIM), in an environment with reconfigurable intelligent surfaces (RISs) remains an open problem due to the many intricate details that have to be accounted for. In this paper, we fill this gap by introducing a novel DD MIMO channel model that incorporates an arbitrary number of RISs in the ambient, as well as SIMs equipping both the transmitter and receiver. We then discuss how the proposed metasurfaces-parametrized DD (MPDD) channel model can be seamlessly applied to waveforms that are known to perform well in DD environments, namely, orthogonal frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine frequency division multiplexing (AFDM), with each having their own inherent advantages and disadvantages. An illustrative application of the programmable functionality of the proposed model is finally presented to showcase its potential for boosting the performance of the aforementioned waveforms. Our numerical results indicate that the design of waveforms suitable to mitigating the effects of DD channels is significantly impacted by the emerging SIM technology.

Paper number 8:
Title: The Reliability of Remotely Piloted Aircraft System Performance under Communication Loss and Latency Uncertainties
Authors: Yutian Pang, Andrew Paul Kendall, John-Paul Clarke
Abstract: Mission-critical use of highly maneuverable Remotely Piloted Aircraft Systems (RPAS) requires a thorough understanding of the reliability of their communication systems. Investigations into system-level performance under stochastic aviation communication conditions are critical for estimating mission success rates and assessing the risks associated with integrating RPAS into existing airspace, ensuring overall aviation safety. This study aims to quantify the impact of communication latency and complete signal loss on the mission completion performance of a highly maneuverable RPAS. The mission is defined as a static waypoint tracking task in three-dimensional airspace. We start with examining and deriving mathematical formulations of key reliability metrics of Required Communication Performance (RCP). These stochastic factors are then embedded into flight control simulations (i.e., communication availability and latency) to examine the system behavior. Lastly, we generate mission success rate and mission completion time envelopes through extensive multiprocessing Monte Carlo simulations through high-performance computing. We discover a drastic deterioration in flight performance while latency or availability erodes the stability margin. In addition, we propose a new reliability metric, namely \textit{communicability}, which integrates three key RCP metrics and helps understanding the maximum tolerable latency to flight control. The procedure and results obtained from this research inform engineers designing RPAS with better trade-off between communication capability and flight control performance. Future works includes exploring alternative flight simulators (i.e., nonlinear dynamic inversion) with other missions (i.e., dynamic waypoint following), or develop delay-compensated optimal controls. The analysis on stability margin is also desired for theoretical verification.

Paper number 9:
Title: Atomic Norm Soft Thresholding for Sparse Time-frequency Representation
Authors: Zongyue Yang, Baoqing Ding, Shibin Wang, Chuang Sun, Xuefeng Chen
Abstract: Time-frequency (TF) representation of non-stationary signals typically requires the effective concentration of energy distribution along the instantaneous frequency (IF) ridge, which exhibits intrinsic sparsity. Inspired by the sparse optimization over continuum via atomic norm, a novel atomic norm soft thresholding for sparse TF representation (AST-STF) method is proposed, which ensures accurate TF localization under the strong duality. Numerical experiments demonstrate that the performance of the proposed method surpasses that of conventional methods.

Paper number 10:
Title: Deep Learning Waveform Modeling for Wideband Optical Fiber Channel Transmission: Challenges and Potential Solutions
Authors: Minghui Shi, Hang Yang, Zekun Niu, Chuyan Zeng, Junzhe Xiao, Yunfan Zhang, Zhixiong Zheng, Weisheng Hu, Lilin Yi
Abstract: Fast and accurate optical fiber communication simulation system are crucial for optimizing optical networks, developing digital signal processing algorithms, and performing end-to-end (E2E) optimization. Deep learning (DL) has emerged as a valuable tool to reduce the complexity of traditional waveform simulation methods, such as split-step Fourier method (SSFM). DL-based schemes have achieved high accuracy and low complexity fiber channel waveform modeling as its strong nonlinear fitting ability and high efficiency in parallel computation. However, DL-based schemes are mainly utilized in single-channel and few-channel wavelength division multiplexing (WDM) systems. The applicability of DL-based schemes in wideband WDM systems remains uncertain due to the lack of comparison under consistent standards and scenarios. In this paper, we propose a DSP-assisted accuracy evaluation method to evaluate the performance for DL-based schemes, from the aspects of waveform and quality of transmission (QoT) errors. We compare the performance of five various DL-based schemes and valid the effectiveness of DSP-assisted method in WDM systems. Results suggest that feature decoupled distributed (FDD) achieves the better accuracy, especially in large-channel and high-rate scenarios. Furthermore, we find that the accuracy of FDD still exhibit significant degradation with the number of WDM channels and transmission rates exceeds 15 and 100 GBaud, indicating challenges for wideband applications. We further analyze the reasons of performance degradation from the perspective of increased linearity and nonlinearity and discuss potential solutions including further decoupling scheme designs and improvement in DL models. Despite DL-based schemes remain challenges in wideband WDM systems, they have strong potential for high-accuracy and low-complexity optical fiber channel waveform modeling.

Paper number 11:
Title: An Intra- and Cross-frame Topological Consistency Scheme for Semi-supervised Atherosclerotic Coronary Plaque Segmentation
Authors: Ziheng Zhang, Zihan Li, Dandan Shan, Yuehui Qiu, Qingqi Hong, Qingqiang Wu
Abstract: Enhancing the precision of segmenting coronary atherosclerotic plaques from CT Angiography (CTA) images is pivotal for advanced Coronary Atherosclerosis Analysis (CAA), which distinctively relies on the analysis of vessel cross-section images reconstructed via Curved Planar Reformation. This task presents significant challenges due to the indistinct boundaries and structures of plaques and blood vessels, leading to the inadequate performance of current deep learning models, compounded by the inherent difficulty in annotating such complex data. To address these issues, we propose a novel dual-consistency semi-supervised framework that integrates Intra-frame Topological Consistency (ITC) and Cross-frame Topological Consistency (CTC) to leverage labeled and unlabeled data. ITC employs a dual-task network for simultaneous segmentation mask and Skeleton-aware Distance Transform (SDT) prediction, achieving similar prediction of topology structure through consistency constraint without additional annotations. Meanwhile, CTC utilizes an unsupervised estimator for analyzing pixel flow between skeletons and boundaries of adjacent frames, ensuring spatial continuity. Experiments on two CTA datasets show that our method surpasses existing semi-supervised methods and approaches the performance of supervised methods on CAA. In addition, our method also performs better than other methods on the ACDC dataset, demonstrating its generalization.

Paper number 12:
Title: Target Detection in OFDM-ISAC Systems: A Multipath Exploitation Approach
Authors: Xiaohan Lv, Rang Liu, Ming Li, Qian liu
Abstract: This paper investigates the potential of multipath exploitation for enhancing target detection in orthogonal frequency division multiplexing (OFDM)-based integrated sensing and communication (ISAC) systems. The study aims to improve target detection performance by harnessing the diversity gain in the delay-Doppler domain. We propose a weighted generalized likelihood ratio test (GLRT) detector that effectively leverages the multipath propagation between the base station (BS) and the target. To further enhance detection accuracy, a joint optimization framework is developed for subcarrier power allocation at the transmitter and weight coefficients of the GLRT detector. The objective is to maximize the probability of target detection while satisfying constraints on total transmit power and the communication receiver's signal-to-noise ratio (SNR). An iterative algorithm based on the majorization-minimization (MM) method is employed to address the resulting non-convex optimization problem. Simulation results demonstrate the efficacy of the proposed algorithm and confirm the benefits of multipath exploitation for target detection in OFDM-ISAC systems under multipath-rich environments.

Paper number 13:
Title: Revisiting Split Covariance Intersection: Correlated Components and Optimality
Authors: Colin Cros (GIPSA-INFINITY, GIPSA-GAIA), Pierre-Olivier Amblard (GIPSA-GAIA), Christophe Prieur (GIPSA-INFINITY), Jean-François Da Rocha
Abstract: Linear fusion is a cornerstone of estimation theory. Implementing optimal linear fusion requires knowledge of the covariance of the vector of errors associated with all the estimators. In distributed or cooperative systems, the cross-covariance terms cannot be computed, and to avoid underestimating the estimation error, conservative fusions must be performed. A conservative fusion provides a fused estimator with a covariance bound that is guaranteed to be larger than the true, but computationally intractable, covariance of the error. Previous research by Reinhardt \textit{et al.} proved that, if no additional assumption is made about the errors of the estimators, the minimal bound for fusing two estimators is given by a fusion called Covariance Intersection (CI). In distributed systems, the estimation errors contain independent and correlated terms induced by the measurement noises and the process noise. In this case, CI is no longer the optimal method. Split Covariance Intersection (SCI) has been developed to take advantage of the uncorrelated components. This paper extends SCI to also take advantage of the correlated components. Then, it is proved that the new fusion provides the optimal conservative fusion bounds for two estimators, generalizing the optimality of CI to a wider class of fusion schemes. The benefits of this extension are demonstrated in simulations.

Paper number 14:
Title: Tensor Train Discrete Grid-Based Filters: Breaking the Curse of Dimensionality
Authors: J. Matoušek, M. Brandner, J. Duník, I. Punčochář
Abstract: This paper deals with the state estimation of stochastic systems and examines the possible employment of tensor decompositions in grid-based filtering routines, in particular, the tensor-train decomposition. The aim is to show that these techniques can lead to a massive reduction in both the computational and storage complexity of grid-based filtering algorithms without considerable tradeoffs in accuracy. This claim is supported by an algorithm descriptions and numerical illustrations.

Paper number 15:
Title: Early prediction of the transferability of bovine embryos from videomicroscopy
Authors: Yasmine Hachani (LACODAM), Patrick Bouthemy (SAIRPICO), Elisa Fromont (LACODAM), Sylvie Ruffini (UVSQ, INRAE), Ludivine Laffont (UVSQ, INRAE), Alline de Paula Reis (UVSQ, INRAE, ENVA)
Abstract: Videomicroscopy is a promising tool combined with machine learning for studying the early development of in vitro fertilized bovine embryos and assessing its transferability as soon as possible. We aim to predict the embryo transferability within four days at most, taking 2D time-lapse microscopy videos as input. We formulate this problem as a supervised binary classification problem for the classes transferable and not transferable. The challenges are three-fold: 1) poorly discriminating appearance and motion, 2) class ambiguity, 3) small amount of annotated data. We propose a 3D convolutional neural network involving three pathways, which makes it multi-scale in time and able to handle appearance and motion in different ways. For training, we retain the focal loss. Our model, named SFR, compares favorably to other methods. Experiments demonstrate its effectiveness and accuracy for our challenging biological task.

Paper number 16:
Title: Decentralized Learning with Approximate Finite-Time Consensus
Authors: Aaron Fainman, Stefan Vlaski
Abstract: The performance of algorithms for decentralized optimization is affected by both the optimization error and the consensus error, the latter of which arises from the variation between agents' local models. Classically, algorithms employ averaging and gradient-tracking mechanisms with constant combination matrices to drive the collection of agents to consensus. Recent works have demonstrated that using sequences of combination matrices that achieve finite-time consensus (FTC) can result in improved communication efficiency or iteration complexity for decentralized optimization. Notably, these studies apply to highly structured networks, where exact finite-time consensus sequences are known exactly and in closed form. In this work we investigate the impact of utilizing approximate FTC matrices in decentralized learning algorithms, and quantify the impact of the approximation error on convergence rate and steady-state performance. Approximate FTC matrices can be inferred for general graphs and do not rely on a particular graph structure or prior knowledge, making the proposed scheme applicable to a broad range of decentralized learning settings.

Paper number 17:
Title: Enhanced Sparse Bayesian Learning Methods with Application to Massive MIMO Channel Estimation
Authors: Arttu Arjas, Italo Atzeni
Abstract: We consider the problem of sparse channel estimation in massive multiple-input multiple-output systems. In this context, we propose an enhanced version of the sparse Bayesian learning (SBL) framework, referred to as enhanced SBL (E-SBL), which is based on a reparameterization of the original SBL model. Specifically, we introduce a scale vector that brings extra flexibility to the model, which is estimated along with the other unknowns. Moreover, we introduce a variant of E-SBL, referred to as modified E-SBL (M-E-SBL), which is based on a computationally more efficient parameter estimation. We compare the proposed E-SBL and M-E-SBL with the baseline SBL and with a method based on variational message passing (VMP) in terms of computational complexity and performance. Numerical results show that the proposed E-SBL and M-E-SBL outperform the baseline SBL and VMP in terms of mean squared error of the channel estimation in all the considered scenarios. Furthermore, we show that M-E-SBL produces results comparable with E-SBL with considerably cheaper computations.

Paper number 18:
Title: A resource management approach for concurrent operation of RF functionalities
Authors: Pascal Marquardt, Sebastian Durst, Kilian Barth, Tobias Müller
Abstract: Future multifunction RF systems will be able to not only perform various different radar, communication and electronic warfare functionalities but also to perform them simultaneously on the same aperture. This ability of concurrent operations requires new, cognitive approaches of resource management compared to classical methods. This paper presents such a new approach using a combination of quality of service based resource management and Monte Carlo tree search.

Paper number 19:
Title: Movable Antenna Enhanced DF and AF Relaying Systems: Performance Analysis and Optimization
Authors: Nianzu Li, Weidong Mei, Peiran Wu, Boyu Ning, Lipeng Zhu
Abstract: Movable antenna (MA) has been deemed as a promising technology to flexibly reconfigure wireless channels by adjusting the antenna positions in a given local region. In this paper, we investigate the application of the MA technology in both decode-and-forward (DF) and amplify-and-forward (AF) relaying systems, where a relay is equipped with multiple MAs to assist in the data transmission between two single-antenna nodes. For the DF relaying system, our objective is to maximize the achievable rate at the destination by jointly optimizing the positions of the MAs in two stages for receiving signals from the source and transmitting signals to the destination, respectively. To drive essential insights, we first derive a closed-form upper bound on the maximum achievable rate of the DF relaying system. Then, a low-complexity algorithm based on projected gradient ascent (PGA) and alternating optimization (AO) is proposed to solve the antenna position optimization problem. For the AF relaying system, our objective is to maximize the achievable rate by jointly optimizing the two-stage MA positions as well as the AF beamforming matrix at the relay, which results in a more challenging optimization problem due to the intricate coupling variables. To tackle this challenge, we first reveal the hidden separability among the antenna position optimization in the two stages and the beamforming optimization. Based on such separability, we derive a closed-form upper bound on the maximum achievable rate of the AF relaying system and propose a low-complexity algorithm to obtain a high-quality suboptimal solution to the considered problem. Simulation results validate the efficacy of our theoretical analysis and demonstrate the superiority of the MA-enhanced relaying systems to the conventional relaying systems with fixed-position antennas (FPAs) and other benchmark schemes.

Paper number 20:
Title: Decision Transformers for RIS-Assisted Systems with Diffusion Model-Based Channel Acquisition
Authors: Jie Zhang, Yiyang Ni, Jun Li, Guangji Chen, Zhe Wang, Long Shi, Shi Jin, Wen Chen, H. Vincent Poor
Abstract: Reconfigurable intelligent surfaces (RISs) have been recognized as a revolutionary technology for future wireless networks. However, RIS-assisted communications have to continuously tune phase-shifts relying on accurate channel state information (CSI) that is generally difficult to obtain due to the large number of RIS channels. The joint design of CSI acquisition and subsection RIS phase-shifts remains a significant challenge in dynamic environments. In this paper, we propose a diffusion-enhanced decision Transformer (DEDT) framework consisting of a diffusion model (DM) designed for efficient CSI acquisition and a decision Transformer (DT) utilized for phase-shift optimizations. Specifically, we first propose a novel DM mechanism, i.e., conditional imputation based on denoising diffusion probabilistic model, for rapidly acquiring real-time full CSI by exploiting the spatial correlations inherent in wireless channels. Then, we optimize beamforming schemes based on the DT architecture, which pre-trains on historical environments to establish a robust policy model. Next, we incorporate a fine-tuning mechanism to ensure rapid beamforming adaptation to new environments, eliminating the retraining process that is imperative in conventional reinforcement learning (RL) methods. Simulation results demonstrate that DEDT can enhance efficiency and adaptability of RIS-aided communications with fluctuating channel conditions compared to state-of-the-art RL methods.

Paper number 21:
Title: Tutorial: VAE as an inference paradigm for neuroimaging
Authors: C. Vázquez-García, F. J. Martínez-Murcia, F. Segovia Román, Juan M. Górriz Sáez
Abstract: In this tutorial, we explore Variational Autoencoders (VAEs), an essential framework for unsupervised learning, particularly suited for high-dimensional datasets such as neuroimaging. By integrating deep learning with Bayesian inference, VAEs enable the generation of interpretable latent representations. This tutorial outlines the theoretical foundations of VAEs, addresses practical challenges such as convergence issues and over-fitting, and discusses strategies like the reparameterization trick and hyperparameter optimization. We also highlight key applications of VAEs in neuroimaging, demonstrating their potential to uncover meaningful patterns, including those associated with neurodegenerative processes, and their broader implications for analyzing complex brain data.

Paper number 22:
Title: Analysis of Power Losses and the Efficacy of Power Minimization Strategies in Multichannel Electrical Stimulation Systems
Authors: Francesc Varkevisser, Wouter A. Serdijn, Tiago L. Costa
Abstract: Neuroprosthetic devices require multichannel stimulator systems with an increasing number of channels. However, there are inherent power losses in typical multichannel stimulation circuits caused by a mismatch between the power supply voltage and the voltage required at each electrode to successfully stimulate tissue. This imposes a bottleneck towards high-channel-count devices, which is particularly severe in wirelessly-powered devices. Hence, advances in the power efficiency of stimulation systems are critical. To support these advances, this paper presents a methodology to identify and quantify power losses associated with different power supply scaling strategies in multichannel stimulation systems. The proposed methodology utilizes distributions of stimulation amplitudes and electrode impedances to calculate power losses in multichannel systems. Experimental data from previously published studies spanning various stimulation applications were analyzed to evaluate the performance of fixed, global, and stepped supply scaling methods, focusing on their impact on power dissipation and efficiency. Variability in output conditions results in low power efficiency in multichannel stimulation systems across all applications. Stepped voltage scaling demonstrated substantial efficiency improvements, achieving an increase of 67 % to 146 %, particularly in high-channel-count applications with significant variability in tissue impedance. Global scaling, by contrast, was more advantageous for systems with fewer channels. The findings highlight the importance of tailoring power management strategies to specific applications to optimize efficiency while minimizing system complexity. The proposed methodology offers a framework for evaluating efficiency-complexity trade-offs, advancing the design of scalable neurostimulation systems.

Paper number 23:
Title: Orthogonal Delay-Doppler Division Multiplexing Modulation with Hierarchical Mode-Based Index Modulation
Authors: Kehan Huang, Min Qiu, Jinhong Yuan
Abstract: The orthogonal time frequency space with index modulation (OTFS-IM) offers flexible tradeoffs between spectral efficiency (SE) and bit error rate (BER) in doubly selective fading channels. While OTFS-IM schemes demonstrated such potential, a persistent challenge lies in the detection complexity. To address this problem, we propose the hierarchical mode-based index modulation (HMIM). HMIM introduces a novel approach to modulate information bits by IM patterns, significantly simplifying the complexity of maximum a posteriori (MAP) estimation with Gaussian noise. Further, we incorporate HMIM with the recently proposed orthogonal delay-Doppler division multiplexing (ODDM) modulation, namely ODDM-HMIM, to exploit the full diversity of the delay-Doppler (DD) channel. The BER performance of ODDM-HMIM is analyzed considering a maximum likelihood (ML) detector. Our numerical results reveal that, with the same SE, HMIM can outperform conventional IM in terms of both BER and computational complexity. In addition, we propose a successive interference cancellation-based minimum mean square error (SIC-MMSE) detector for ODDM-HMIM, which enables low-complexity detection with large frame sizes.

Paper number 24:
Title: Gen-A: Generalizing Ambisonics Neural Encoding to Unseen Microphone Arrays
Authors: Mikko Heikkinen, Archontis Politis, Konstantinos Drossos, Tuomas Virtanen
Abstract: Using deep neural networks (DNNs) for encoding of microphone array (MA) signals to the Ambisonics spatial audio format can surpass certain limitations of established conventional methods, but existing DNN-based methods need to be trained separately for each MA. This paper proposes a DNN-based method for Ambisonics encoding that can generalize to arbitrary MA geometries unseen during training. The method takes as inputs the MA geometry and MA signals and uses a multi-level encoder consisting of separate paths for geometry and signal data, where geometry features inform the signal encoder at each level. The method is validated in simulated anechoic and reverberant conditions with one and two sources. The results indicate improvement over conventional encoding across the whole frequency range for dry scenes, while for reverberant scenes the improvement is frequency-dependent.

Paper number 25:
Title: Optimizing Speech Multi-View Feature Fusion through Conditional Computation
Authors: Weiqiao Shan, Yuhao Zhang, Yuchen Han, Bei Li, Xiaofeng Zhao, Yuang Li, Min Zhang, Hao Yang, Tong Xiao, Jingbo Zhu
Abstract: Recent advancements have highlighted the efficacy of self-supervised learning (SSL) features in various speech-related tasks, providing lightweight and versatile multi-view speech representations. However, our study reveals that while SSL features expedite model convergence, they conflict with traditional spectral features like FBanks in terms of update directions. In response, we propose a novel generalized feature fusion framework grounded in conditional computation, featuring a gradient-sensitive gating network and a multi-stage dropout strategy. This framework mitigates feature conflicts and bolsters model robustness to multi-view input features. By integrating SSL and spectral features, our approach accelerates convergence and maintains performance on par with spectral models across multiple speech translation tasks on the MUSTC dataset.

Paper number 26:
Title: Range-Only Dynamic Output Feedback Controller for Safe and Secure Target Circumnavigation
Authors: Anand Singh, Anoop Jain
Abstract: The safety and security of robotic systems are paramount when navigating around a hostile target. This paper addresses the problem of circumnavigating an unknown target by a unicycle robot while ensuring it maintains a desired safe distance and remains within the sensing region around the target throughout its motion. The proposed control design methodology is based on the construction of a joint Lyapunov function that incorporates: (i) a quadratic potential function characterizing the desired target-circumnavigation objective, and (ii) a barrier Lyapunov function-based potential term to enforce safety and sensing constraints on the robot's motion. A notable feature of the proposed control design is its reliance exclusively on local range measurements between the robot and the target, realized using a dynamic output feedback controller that treats the range as the only observable output for feedback. Using the Lyapunov stability theory, we show that the desired equilibrium of the closed-loop system is asymptotically stable, and the prescribed safety and security constraints are met under the proposed controllers. We also obtain restrictive bounds on the post-design signals and provide both simulation and experimental results to validate the theoretical contributions.

Paper number 27:
Title: CellOMaps: A Compact Representation for Robust Classification of Lung Adenocarcinoma Growth Patterns
Authors: Arwa Al-Rubaian, Gozde N. Gunesli, Wajd A. Althakfi, Ayesha Azam, David Snead, Nasir M. Rajpoot, Shan E Ahmed Raza
Abstract: Lung adenocarcinoma (LUAD) is a morphologically heterogeneous disease, characterized by five primary histological growth patterns. The classification of such patterns is crucial due to their direct relation to prognosis but the high subjectivity and observer variability pose a major challenge. Although several studies have developed machine learning methods for growth pattern classification, they either only report the predominant pattern per slide or lack proper evaluation. We propose a generalizable machine learning pipeline capable of classifying lung tissue into one of the five patterns or as non-tumor. The proposed pipeline's strength lies in a novel compact Cell Organization Maps (cellOMaps) representation that captures the cellular spatial patterns from Hematoxylin and Eosin whole slide images (WSIs). The proposed pipeline provides state-of-the-art performance on LUAD growth pattern classification when evaluated on both internal unseen slides and external datasets, significantly outperforming the current approaches. In addition, our preliminary results show that the model's outputs can be used to predict patients Tumor Mutational Burden (TMB) levels.

Paper number 28:
Title: A Comparative Analysis of Transformer-less Inverter Topologies for Grid-Connected PV Systems: Minimizing Leakage Current and THD
Authors: Shashwot Shrestha, Rachana Subedi, Swodesh Sharma, Sushil Phuyal, Indraman Tamrakar
Abstract: The integration of distributed energy resources (DERs), particularly photovoltaic (PV) systems, into power grids has gained major attention due to their environmental and economic benefits. Although traditional transformer-based grid-connected PV inverters provide galvanic isolation for leakage current, they suffer from major drawbacks of high cost, lower efficiency, and increased size. Transformer-less grid-connected PV inverters (TLGI) have emerged as a prominent alternative, as they achieve higher efficiency, compact design, and lower cost. However, due to a lack of galvanic isolation, TLGIs are highly affected by leakage current caused by the fluctuation of common-mode voltage (CMV). This paper investigates three topologies H4, H5, and HERIC with comparisons between their CMV, differential-mode voltage (DMV), total harmonic distortion (THD), and leakage current. A simulation was conducted for each topology in MATLAB/Simulink R2023a, and the results demonstrate that the H5 topology achieves a balance between low leakage current, reduced THD, and optimal operational efficiency, making it suitable for practical application.

Paper number 29:
Title: Loudspeaker Beamforming to Enhance Speech Recognition Performance of Voice Driven Applications
Authors: Dimme de Groot, Baturalp Karslioglu, Odette Scharenborg, Jorge Martinez
Abstract: In this paper we propose a robust loudspeaker beamforming algorithm which is used to enhance the performance of voice driven applications in scenarios where the loudspeakers introduce the majority of the noise, e.g. when music is playing loudly. The loudspeaker beamformer modifies the loudspeaker playback signals to create a low-acoustic-energy region around the device that implements automatic speech recognition for a voice driven application (VDA). The algorithm utilises a distortion measure based on human auditory perception to limit the distortion perceived by human listeners. Simulations and real-world experiments show that the proposed loudspeaker beamformer improves the speech recognition performance in all tested scenarios. Moreover, the algorithm allows to further reduce the acoustic energy around the VDA device at the expense of reduced objective audio quality at the listener's location.

Paper number 30:
Title: Neural Speech Tracking in a Virtual Acoustic Environment: Audio-Visual Benefit for Unscripted Continuous Speech
Authors: Mareike Daeglau, Juergen Otten, Giso Grimm, Bojana Mirkovic, Volker Hohmann, Stefan Debener
Abstract: The audio visual benefit in speech perception, where congruent visual input enhances auditory processing, is well documented across age groups, particularly in challenging listening conditions and among individuals with varying hearing abilities. However, most studies rely on highly controlled laboratory environments with scripted stimuli. Here, we examine the audio visual benefit using unscripted, natural speech from untrained speakers within a virtual acoustic environment. Using electroencephalography (EEG) and cortical speech tracking, we assessed neural responses across audio visual, audio only, visual only, and masked lip conditions to isolate the role of lip movements. Additionally, we analysed individual differences in acoustic and visual features of the speakers, including pitch, jitter, and lip openness, to explore their influence on the audio visual speech tracking benefit. Results showed a significant audio visual enhancement in speech tracking with background noise, with the masked lip condition performing similarly to the audio-only condition, emphasizing the importance of lip movements in adverse listening situations. Our findings reveal the feasibility of cortical speech tracking with naturalistic stimuli and underscore the impact of individual speaker characteristics on audio-visual integration in real world listening contexts.

Paper number 31:
Title: Automatic Live Music Song Identification Using Multi-level Deep Sequence Similarity Learning
Authors: Aapo Hakala, Trevor Kincy, Tuomas Virtanen
Abstract: This paper studies the novel problem of automatic live music song identification, where the goal is, given a live recording of a song, to retrieve the corresponding studio version of the song from a music database. We propose a system based on similarity learning and a Siamese convolutional neural network-based model. The model uses cross-similarity matrices of multi-level deep sequences to measure musical similarity between different audio tracks. A manually collected custom live music dataset is used to test the performance of the system with live music. The results of the experiments show that the system is able to identify 87.4% of the given live music queries.

Paper number 32:
Title: EEG-ReMinD: Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics
Authors: Zirui Wang, Zhenxi Song, Yi Guo, Yuxin Liu, Guoyang Xu, Min Zhang, Zhiguo Zhang
Abstract: The development of EEG decoding algorithms confronts challenges such as data sparsity, subject variability, and the need for precise annotations, all of which are vital for advancing brain-computer interfaces and enhancing the diagnosis of diseases. To address these issues, we propose a novel two-stage approach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics (EEG-ReMinD) , which mitigates reliance on supervised learning and integrates inherent geometric features. This approach efficiently handles EEG data corruptions and reduces the dependency on labels. EEG-ReMinD utilizes self-supervised and geometric learning techniques, along with an attention mechanism, to analyze the temporal dynamics of EEG features within the framework of Riemannian geometry, referred to as Riemannian dynamics. Comparative analyses on both intact and corrupted datasets from two different neurodegenerative disorders underscore the enhanced performance of EEG-ReMinD.

Paper number 33:
Title: Mobility Management in Integrated Sensing and Communications Networks
Authors: Yuri S. Ribeiro, Behrooz Makki, Andre L. F. de Almeida, Gabor Fodor
Abstract: The performance of the integrated sensing and communication (ISAC) networks is considerably affected by the mobility of the transceiver nodes, user equipment devices (UEs) and the passive objects that are sensed. For instance, the sensing efficiency is considerably affected by the presence or absence of a line-of-sight connection between the sensing transceivers and the object; a condition that may change quickly due to mobility. Moreover, the mobility of the UEs and objects may result in dynamically varying communication-to-sensing and sensing-to communication interference, deteriorating the network performance. In such cases, there may be a need to handover the sensing process to neighbor nodes. In this article, we develop the concept of mobility management in ISAC networks. Here, depending on the mobility of objects and/or the transceiver nodes, the data traffic, the sensing or communication coverage area of the transceivers, and the network interference, the transmission and/or the reception of the sensing signals may be handed over to neighbor nodes. Also, the ISAC configuration and modality - that is, using monostatic or bistatic sensing - are updated accordingly, such that the sensed objects can be continuously sensed with low overhead. We show that mobility management reduces the sensing interruption and boosts the communication and sensing efficiency of ISAC networks.

Paper number 34:
Title: DM-Mamba: Dual-domain Multi-scale Mamba for MRI reconstruction
Authors: Yucong Meng, Zhiwei Yang, Zhijian Song, Yonghong Shi
Abstract: The accelerated MRI reconstruction poses a challenging ill-posed inverse problem due to the significant undersampling in k-space. Deep neural networks, such as CNNs and ViT, have shown substantial performance improvements for this task while encountering the dilemma between global receptive fields and efficient computation. To this end, this paper pioneers exploring Mamba, a new paradigm for long-range dependency modeling with linear complexity, for efficient and effective MRI reconstruction. However, directly applying Mamba to MRI reconstruction faces three significant issues: (1) Mamba's row-wise and column-wise scanning disrupts k-space's unique spectrum, leaving its potential in k-space learning unexplored. (2) Existing Mamba methods unfold feature maps with multiple lengthy scanning paths, leading to long-range forgetting and high computational burden. (3) Mamba struggles with spatially-varying contents, resulting in limited diversity of local representations. To address these, we propose a dual-domain multi-scale Mamba for MRI reconstruction from the following perspectives: (1) We pioneer vision Mamba in k-space learning. A circular scanning is customized for spectrum unfolding, benefiting the global modeling of k-space. (2) We propose a multi-scale Mamba with an efficient scanning strategy in both image and k-space domains. It mitigates long-range forgetting and achieves a better trade-off between efficiency and performance. (3) We develop a local diversity enhancement module to improve the spatially-varying representation of Mamba. Extensive experiments are conducted on three public datasets for MRI reconstruction under various undersampling patterns. Comprehensive results demonstrate that our method significantly outperforms state-of-the-art methods with lower computational cost. Implementation code will be available at this https URL.

Paper number 35:
Title: Economic Model Predictive Control for Periodic Operation: A Quadratic Programming Approach
Authors: Jose A. Borja-Conde, Juan M. Nadales, Filiberto Fele, Daniel Limon
Abstract: Periodic dynamical systems, distinguished by their repetitive behavior over time, are prevalent across various engineering disciplines. In numerous applications, particularly within industrial contexts, the implementation of model predictive control (MPC) schemes tailored to optimize specific economic criteria was shown to offer substantial advantages. However, the real-time implementation of these schemes is often infeasible due to limited computational resources. To tackle this problem, we propose a resource-efficient economic model predictive control scheme for periodic systems, leveraging existing single-layer MPC techniques. Our method relies on a single quadratic optimization problem, which ensures high computational efficiency for real-time control in dynamic settings. We prove feasibility, stability and convergence to optimum of the proposed approach, and validate the effectiveness through numerical experiments.

Paper number 36:
Title: Efficient and Accurate Full-Waveform Inversion with Total Variation Constraint
Authors: Yudai Inada, Shingo Takemoto, Shunsuke Ono
Abstract: This paper proposes a computationally efficient algorithm to address the Full-Waveform Inversion (FWI) problem with a Total Variation (TV) constraint, designed to accurately reconstruct subsurface properties from seismic data. FWI, as an ill-posed inverse problem, requires effective regularizations or constraints to ensure accurate and stable solutions. Among these, the TV constraint is widely known as a powerful prior for modeling the piecewise smooth structure of subsurface properties. However, solving the optimization problem is challenging because of the nonlinear observation process combined with the non-smoothness of the TV constraint. Conventional methods rely on inner loops and/or approximations, which lead to high computational cost and/or inappropriate solutions. To address these limitations, we develop a novel algorithm based on a primal-dual splitting method, achieving computational efficiency by eliminating inner loops and ensuring high accuracy by avoiding approximations. We also demonstrate the effectiveness of the proposed method through experiments using the SEG/EAGE Salt and Overthrust Models. The source code will be available at this https URL.

Paper number 37:
Title: A Novel Method for Detecting Dust Accumulation in Photovoltaic Systems: Evaluating Visible Sunlight Obstruction in Different Dust Levels and AI-based Bird Droppings Detection
Authors: Md Shahriar Kabir, Khalid Mahmud Niloy, S. M. Imrat Rahman, Md Imon Hossen, Sumaiya Afrose, Md. Ismail Hossain Mofazzol, Md Lion Ahmmed
Abstract: This paper presents an innovative method for automatically detecting dust accumulation on a PV system and notifying the user to clean it instantly. The accumulation of dust, bird, or insect droppings on the surface of photovoltaic (PV) panels creates a barrier between the solar energy and the panel's surface to receive sufficient energy to generate electricity. The study investigates the effects of dust on PV panel output and visible sunlight (VSL) block amounts to utilize the necessity of cleaning and detection. The amount of blocked visible sunlight while passing through glass due to dust determines the accumulated dust level. Visible sunlight can easily pass through the clean, transparent glass but reflects when something like dust obstructs it. Based on those concepts, a system is designed with a light sensor that is simple, effective, easy to install, hassle-free, and can spread the technology. The study also explores the effectiveness of the detection system developed by using image processing and machine learning algorithms to identify dust levels and bird or insect droppings accurately. The experimental setup in Gazipur, Bangladesh, found that excessive dust can block up to 55% of visible sunlight, wasting 55% of solar energy in the visible spectrum, and cleaning can recover 3% of power weekly. The data from the dust detection system is correlated with the 400W capacity solar panels' naturally lost efficiency data to validate the system. This research measured visible sunlight obstruction and loss due to dust. However, the addition of an infrared radiation sensor can draw the entire scenario of energy loss by doing more research.

Paper number 38:
Title: Safety Verification for Evasive Collision Avoidance in Autonomous Vehicles with Enhanced Resolutions
Authors: Aliasghar Arab, Milad Khaleghi, Alireza Partovi, Alireza Abbaspour, Chaitanya Shinde, Yashar Mousavi, Vahid Azimi, Ali Karimmoddini
Abstract: This paper presents a comprehensive hazard analysis, risk assessment, and loss evaluation for an Evasive Minimum Risk Maneuvering (EMRM) system designed for autonomous vehicles. The EMRM system is engineered to enhance collision avoidance and mitigate loss severity by drawing inspiration from professional drivers who perform aggressive maneuvers while maintaining stability for effective risk mitigation. Recent advancements in autonomous vehicle technology demonstrate a growing capability for high-performance maneuvers. This paper discusses a comprehensive safety verification process and establishes a clear safety goal to enhance testing validation. The study systematically identifies potential hazards and assesses their risks to overall safety and the protection of vulnerable road users. A novel loss evaluation approach is introduced, focusing on the impact of mitigation maneuvers on loss severity. Additionally, the proposed mitigation integrity level can be used to verify the minimum-risk maneuver feature. This paper applies a verification method to evasive maneuvering, contributing to the development of more reliable active safety features in autonomous driving systems.

Paper number 39:
Title: Ultrafast pulsed laser evaluation of Single Event Transients in opto-couplers
Authors: Kavin Dave, Aditya Mukherjee, Hari Shanker Gupta, Deepak Jain, Shalabh Gupta
Abstract: We build a 1064 nm fiber laser system-based testing facility for emulating SETs in different electronics components and ICs. Using these facilities, we tested the 4N35 optocoupler to observe SETs for the first time.

Paper number 40:
Title: LUCAS: A Low-Power Ultra-Low Jitter Compact ASIC for SiPM Targetting ToF-CT
Authors: Seyed Arash Katourani
Abstract: We present LUCAS (Low power Ultra-low jitter Compact ASIC for SiPM), an analog front-end for Silicon Photomultipliers (SiPM) targeting fast timing detectors in Time-of-Flight Computed Tomography (ToF-CT). LUCAS features a very low input impedance preamplifier followed by a voltage comparator. It is designed in TSMC 65 nm low-power CMOS technology with a power supply of 1.2 V. Our first 8-channel prototype has been sent to fabrication and will be received in August 2023. Post-layout simulations predict less than 40 ps FWHM SPTR jitter and an approximate power consumption of 3.2 mW per channel. The front end is suitable for applications with rigorous jitter requirements and high event rates, thanks to its 3.9 GHz unity-gain bandwidth. The front-end compact form factor will facilitate its incorporation into systems demanding high channel densities.

Paper number 41:
Title: Real-Time Decision-Making for Digital Twin in Additive Manufacturing with Model Predictive Control using Time-Series Deep Neural Networks
Authors: Yi-Ping Chen, Vispi Karkaria, Ying-Kuan Tsai, Faith Rolark, Daniel Quispe, Robert X. Gao, Jian Cao, Wei Chen
Abstract: Digital Twin-a virtual replica of a physical system enabling real-time monitoring, model updating, prediction, and decision-making-combined with recent advances in machine learning (ML), offers new opportunities for proactive control strategies in autonomous manufacturing. However, achieving real-time decision-making with Digital Twins requires efficient optimization driven by accurate predictions of highly nonlinear manufacturing systems. This paper presents a simultaneous multi-step Model Predictive Control (MPC) framework for real-time decision-making, using a multi-variate deep neural network (DNN), named Time-Series Dense Encoder (TiDE), as the surrogate model. Different from the models in conventional MPC which only provide one-step ahead prediction, TiDE is capable of predicting future states within the prediction horizon in one shot (multi-step), significantly accelerating MPC. Using Directed Energy Deposition additive manufacturing as a case study, we demonstrate the effectiveness of the proposed MPC in achieving melt pool temperature tracking to ensure part quality, while reducing porosity defects by regulating laser power to maintain melt pool depth constraints. In this work, we first show that TiDE is capable of accurately predicting melt pool temperature and depth. Second, we demonstrate that the proposed MPC achieves precise temperature tracking while satisfying melt pool depth constraints within a targeted dilution range (10%-30%), reducing potential porosity defects. Compared to the PID controller, MPC results in smoother and less fluctuating laser power profiles with competitive or superior melt pool temperature control performance. This demonstrates MPC's proactive control capabilities, leveraging time-series prediction and real-time optimization, positioning it as a powerful tool for future Digital Twin applications and real-time process optimization in manufacturing.

Paper number 42:
Title: Finite Sample Identification of Partially Observed Bilinear Dynamical Systems
Authors: Yahya Sattar, Yassir Jedra, Maryam Fazel, Sarah Dean
Abstract: We consider the problem of learning a realization of a partially observed bilinear dynamical system (BLDS) from noisy input-output data. Given a single trajectory of input-output samples, we provide a finite time analysis for learning the system's Markov-like parameters, from which a balanced realization of the bilinear system can be obtained. Our bilinear system identification algorithm learns the system's Markov-like parameters by regressing the outputs to highly correlated, nonlinear, and heavy-tailed covariates. Moreover, the stability of BLDS depends on the sequence of inputs used to excite the system. These properties, unique to partially observed bilinear dynamical systems, pose significant challenges to the analysis of our algorithm for learning the unknown dynamics. We address these challenges and provide high probability error bounds on our identification algorithm under a uniform stability assumption. Our analysis provides insights into system theoretic quantities that affect learning accuracy and sample complexity. Lastly, we perform numerical experiments with synthetic data to reinforce these insights.

Paper number 43:
Title: Real-Time Outlier Connections Detection in Databases Network Traffic
Authors: Leonid Rodniansky, Tania Butovsky, Mikhail Shpak
Abstract: The article describes a practical method for detecting outlier database connections in real-time. Outlier connections are detected with a specified level of confidence. The method is based on generalized security rules and a simple but effective real-time machine learning mechanism. The described method is non-intrusive to the database and does not depend on the type of database. The method is used to proactively control access even before database connection is established, minimize false positives, and maintain the required response speed to detected database connection outliers. The capabilities of the system are demonstrated with several examples of outliers in real-world scenarios.

Paper number 44:
Title: Universal Training of Neural Networks to Achieve Bayes Optimal Classification Accuracy
Authors: Mohammadreza Tavasoli Naeini, Ali Bereyhi, Morteza Noshad, Ben Liang, Alfred O. Hero III
Abstract: This work invokes the notion of $f$-divergence to introduce a novel upper bound on the Bayes error rate of a general classification task. We show that the proposed bound can be computed by sampling from the output of a parameterized model. Using this practical interpretation, we introduce the Bayes optimal learning threshold (BOLT) loss whose minimization enforces a classification model to achieve the Bayes error rate. We validate the proposed loss for image and text classification tasks, considering MNIST, Fashion-MNIST, CIFAR-10, and IMDb datasets. Numerical experiments demonstrate that models trained with BOLT achieve performance on par with or exceeding that of cross-entropy, particularly on challenging datasets. This highlights the potential of BOLT in improving generalization.

Paper number 45:
Title: Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors
Authors: Saad Masrur, Jung-Fu (Thomas)Cheng, Atieh R. Khamesi, Ismail Guvenc
Abstract: Indoor localization in challenging non-line-of-sight (NLOS) environments often leads to mediocre accuracy with traditional approaches. Deep learning (DL) has been applied to tackle these challenges; however, many DL approaches overlook computational complexity, especially for floating-point operations (FLOPs), making them unsuitable for resource-limited devices. Transformer-based models have achieved remarkable success in natural language processing (NLP) and computer vision (CV) tasks, motivating their use in wireless applications. However, their use in indoor localization remains nascent, and directly applying Transformers for indoor localization can be both computationally intensive and exhibit limitations in accuracy. To address these challenges, in this work, we introduce a novel tokenization approach, referred to as Sensor Snapshot Tokenization (SST), which preserves variable-specific representations of power delay profile (PDP) and enhances attention mechanisms by effectively capturing multi-variate correlation. Complementing this, we propose a lightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer) model, designed to reduce computational complexity without compromising localization accuracy. Together, these contributions mitigate the computational burden and dependency on large datasets, making Transformer models more efficient and suitable for resource-constrained scenarios. The proposed tokenization method enables the Vanilla Transformer to achieve a 90th percentile positioning error of 0.388 m in a highly NLOS indoor factory, surpassing conventional tokenization methods. The L-SwiGLU ViT further reduces the error to 0.355 m, achieving an 8.51% improvement. Additionally, the proposed model outperforms a 14.1 times larger model with a 46.13% improvement, underscoring its computational efficiency.

Paper number 46:
Title: A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition
Authors: Mingke Xiao, Yue Su, Liang Yu, Guanglong Qu, Yutong Jia, Yukuan Chang, Xu Zhang
Abstract: The deployment of neural networks in vehicle platforms and wearable Artificial Intelligence-of-Things (AIOT) scenarios has become a research area that has attracted much attention. With the continuous evolution of deep learning technology, many image classification models are committed to improving recognition accuracy, but this is often accompanied by problems such as large model resource usage, complex structure, and high power consumption, which makes it challenging to deploy on resource-constrained platforms. Herein, we propose an ultra-lightweight binary neural network (BNN) model designed for hardware deployment, and conduct image classification research based on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also verify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS) datasets. The proposed model shows excellent recognition performance with an accuracy of up to 97.64%, making it one of the best performing BNN models in the GTSRB dataset. Compared with the full-precision model, the accuracy loss is controlled within 1%, and the parameter storage overhead of the model is only 10% of that of the full-precision model. More importantly, our network model only relies on logical operations and low-bit width fixed-point addition and subtraction operations during the inference phase, which greatly simplifies the design complexity of the processing element (PE). Our research shows the great potential of BNN in the hardware deployment of computer vision models, especially in the field of computer vision tasks related to autonomous driving.

Paper number 47:
Title: Prediction Interval Construction Method for Electricity Prices
Authors: Xin Lu
Abstract: Accurate prediction of electricity prices plays an essential role in the electricity market. To reflect the uncertainty of electricity prices, price intervals are predicted. This paper proposes a novel prediction interval construction method. A conditional generative adversarial network is first presented to generate electricity price scenarios, with which the prediction intervals can be constructed. Then, different generated scenarios are stacked to obtain the probability densities, which can be applied to accurately reflect the uncertainty of electricity prices. Furthermore, a reinforced prediction mechanism based on the volatility level of weather factors is introduced to address the spikes or volatile prices. A case study is conducted to verify the effectiveness of the proposed novel prediction interval construction method. The method can also provide the probability density of each price scenario within the prediction interval and has the superiority to address the volatile prices and price spikes with a reinforced prediction mechanism.

Paper number 48:
Title: RCD-IoT: Enabling Industrial Monitoring and Control with Resource-Constrained Devices UnderHigh Packet Transmission Rates
Authors: Ayesha Abid, Muhammad Jazib, Muhammad Riaz
Abstract: This paper highlights the significance of resource-constrained Internet of Things (RCD-IoT) systems in addressing the challenges faced by industries with limited resources. This paper presents an energy-efficient solution for industries to monitor and control their utilities remotely. Integrating intelligent sensors and IoT technologies, the proposed RCD-IoT system aims to revolutionize industrial monitoring and control processes, enabling efficient utilization of this http URL proposed system utilized the IEEE 802.15.4 WiFi Protocol for seamless data exchange between Sensor Nodes. This seamless exchange of information was analyzed through Packet Tracer. The system was equipped with a prototyped, depicting analytical chemical process to analyze the significant performance metrics. System achieved average Round trip time (RTT) of just 12ms outperforming the already existing solutions presented even with higher Quality of Service (QoS) under the transmission of 1500 packets/seconds under different line of sight (LOS) and Non line of sight (NLOS) fadings.

Paper number 49:
Title: Bridge-SR: Schr\"odinger Bridge for Efficient SR
Authors: Chang Li, Zehua Chen, Fan Bao, Jun Zhu
Abstract: Speech super-resolution (SR), which generates a waveform at a higher sampling rate from its low-resolution version, is a long-standing critical task in speech restoration. Previous works have explored speech SR in different data spaces, but these methods either require additional compression networks or exhibit limited synthesis quality and inference speed. Motivated by recent advances in probabilistic generative models, we present Bridge-SR, a novel and efficient any-to-48kHz SR system in the speech waveform domain. Using tractable Schrödinger Bridge models, we leverage the observed low-resolution waveform as a prior, which is intrinsically informative for the high-resolution target. By optimizing a lightweight network to learn the score functions from the prior to the target, we achieve efficient waveform SR through a data-to-data generation process that fully exploits the instructive content contained in the low-resolution observation. Furthermore, we identify the importance of the noise schedule, data scaling, and auxiliary loss functions, which further improve the SR quality of bridge-based systems. The experiments conducted on the benchmark dataset VCTK demonstrate the efficiency of our system: (1) in terms of sample quality, Bridge-SR outperforms several strong baseline methods under different SR settings, using a lightweight network backbone (1.7M); (2) in terms of inference speed, our 4-step synthesis achieves better performance than the 8-step conditional diffusion counterpart (LSD: 0.911 vs 0.927). Demo at this https URL.

Paper number 50:
Title: Cloud Removal With PolSAR-Optical Data Fusion Using A Two-Flow Residual Network
Authors: Yuxi Wang, Wenjuan Zhang, Bing Zhang
Abstract: Optical remote sensing images play a crucial role in the observation of the Earth's surface. However, obtaining complete optical remote sensing images is challenging due to cloud cover. Reconstructing cloud-free optical images has become a major task in recent years. This paper presents a two-flow Polarimetric Synthetic Aperture Radar (PolSAR)-Optical data fusion cloud removal algorithm (PODF-CR), which achieves the reconstruction of missing optical images. PODF-CR consists of an encoding module and a decoding module. The encoding module includes two parallel branches that extract PolSAR image features and optical image features. To address speckle noise in PolSAR images, we introduce dynamic filters in the PolSAR branch for image denoising. To better facilitate the fusion between multimodal optical images and PolSAR images, we propose fusion blocks based on cross-skip connections to enable interaction of multimodal data information. The obtained fusion features are refined through an attention mechanism to provide better conditions for the subsequent decoding of the fused images. In the decoding module, multi-scale convolution is introduced to obtain multi-scale information. Additionally, to better utilize comprehensive scattering information and polarization characteristics to assist in the restoration of optical images, we use a dataset for cloud restoration called OPT-BCFSAR-PFSAR, which includes backscatter coefficient feature images and polarization feature images obtained from PoLSAR data and optical images. Experimental results demonstrate that this method outperforms existing methods in both qualitative and quantitative evaluations.

Paper number 51:
Title: Synchronization of Kuramoto oscillators via HEOL, and a discussion on AI
Authors: Emmanuel Delaleau, Cédric Join, Michel Fliess
Abstract: Artificial neural networks and their applications in deep learning have recently made an incursion into the field of control. Deep learning techniques in control are often related to optimal control, which relies on Pontryagin maximum principle or the Hamilton-Jacobi-Bellman equation. They imply control schemes that are tedious to implement. We show here that the new HEOL setting, resulting from the fusion of the two established approaches, namely differential flatness and model-free control, provides a solution to control problems that is more sober in terms of computational resources. This communication is devoted to the synchronization of the popular Kuramoto's coupled oscillators, which was already considered via artificial neural networks (Böttcher et al., Nature Communications 2022), where, contrarily to this communication, only the single control variable is examined. One establishes the flatness of Kuramoto's coupled oscillator model with multiplicative control and develops the resulting HEOL control. Unlike many exemples, this system reveals singularities that are avoided by a clever generation of phase angle trajectories. The results obtained, verified in simulation, show that it is not only possible to synchronize these oscillators in finite time, and even to follow angular frequency profiles, but also to exhibit robustness concerning model mismatches. To the best of our knowledge this has never been done before. Concluding remarks advocate a viewpoint, which might be traced back to Wiener's cybernetics: control theory belongs to AI.

Paper number 52:
Title: Spiking Neural Network Accelerator Architecture for Differential-Time Representation using Learned Encoding
Authors: Daniel Windhager, Lothar Ratschbacher, Bernhard A. Moser, Michael Lunglmayr
Abstract: Spiking Neural Networks (SNNs) have garnered attention over recent years due to their increased energy efficiency and advantages in terms of operational complexity compared to traditional Artificial Neural Networks (ANNs). Two important questions when implementing SNNs are how to best encode existing data into spike trains and how to efficiently process these spike trains in hardware. This paper addresses both of these problems by incorporating the encoding into the learning process, thus allowing the network to learn the spike encoding alongside the weights. Furthermore, this paper proposes a hardware architecture based on a recently introduced differential-time representation for spike trains allowing decoupling of spike time and processing time. Together these contributions lead to a feedforward SNN using only Leaky-Integrate and Fire (LIF) neurons that surpasses 99% accuracy on the MNIST dataset while still being implementable on medium-sized FPGAs with inference times of less than 295us.

Paper number 53:
Title: Robust Hyperspectral Image Panshapring via Sparse Spatial-Spectral Representation
Authors: Chia-Ming Lee, Yu-Fan Lin, Li-Wei Kang, Chih-Chung Hsu
Abstract: High-resolution hyperspectral imaging plays a crucial role in various remote sensing applications, yet its acquisition often faces fundamental limitations due to hardware constraints. This paper introduces S$^{3}$RNet, a novel framework for hyperspectral image pansharpening that effectively combines low-resolution hyperspectral images (LRHSI) with high-resolution multispectral images (HRMSI) through sparse spatial-spectral representation. The core of S$^{3}$RNet is the Multi-Branch Fusion Network (MBFN), which employs parallel branches to capture complementary features at different spatial and spectral scales. Unlike traditional approaches that treat all features equally, our Spatial-Spectral Attention Weight Block (SSAWB) dynamically adjusts feature weights to maintain sparse representation while suppressing noise and redundancy. To enhance feature propagation, we incorporate the Dense Feature Aggregation Block (DFAB), which efficiently aggregates inputted features through dense connectivity patterns. This integrated design enables S$^{3}$RNet to selectively emphasize the most informative features from differnt scale while maintaining computational efficiency. Comprehensive experiments demonstrate that S$^{3}$RNet achieves state-of-the-art performance across multiple evaluation metrics, showing particular strength in maintaining high reconstruction quality even under challenging noise conditions. The code will be made publicly available.

Paper number 54:
Title: An Open Source Validation System for Continuous Arterial Blood Pressure Measuring Sensors
Authors: Attila Répai (1), Sándor Földi (2), Péter Sótonyi (3), György Cserey (2) ((1) Jedlik Innovation Ltd., Budapest, Hungary, (2) Faculty of Information Technology and Bionics, Pázmány Péter Catholic University, Budapest, Hungary, (3) Faculty of Medicine, Department of Vascular and Endovascular Surgery, Semmelweis University, Budapest, Hungary)
Abstract: Measuring the blood pressure waveform is becoming a more frequently studied area. The development of sensor technologies opens many new ways to be able to measure high-quality signals. The development of such an aim-specific sensor can be time-consuming, expensive, and difficult to test or validate with known and consistent waveforms. In this paper, we present an open source blood pressure waveform simulator with an open source Python validation package to reduce development costs for early-stage sensor development and research. The simulator mainly consists of 3D printed parts which technology has become a widely available and cheap solution. The core part of the simulator is a 3D printed cam that can be generated based on real blood pressure waveforms. The validation framework can create a detailed comparison between the signal waveform used to design the cam and the measured time series from the sensor being validated. The presented simulator proved to be robust and accurate in short- and long-term use, as it produced the signal waveform consistently and accurately. To validate this solution, a 3D force sensor was used, which was proven earlier to be able to measure high-quality blood pressure waveforms on the radial artery at the wrist. The results showed high similarity between the measured and the nominal waveforms, meaning that comparing the normalized signals, the RMSE value ranged from $0.0276 \pm 0.0047$ to $0.0212 \pm 0.0023$, and the Pearson correlation ranged from $0.9933 \pm 0.0027$ to $0.9978 \pm 0.0005$. Our validation framework is available at this https URL. Our hardware framework, which allows reproduction of the presented solution, is available at this https URL. The entire design is an open source project and was developed using free software.

Paper number 55:
Title: Combining imaging and shape features for prediction tasks of Alzheimer's disease classification and brain age regression
Authors: Nairouz Shehata, Carolina Piçarra, Ben Glocker
Abstract: We investigate combining imaging and shape features extracted from MRI for the clinically relevant tasks of brain age prediction and Alzheimer's disease classification. Our proposed model fuses ResNet-extracted image embeddings with shape embeddings from a bespoke graph neural network. The shape embeddings are derived from surface meshes of 15 brain structures, capturing detailed geometric information. Combined with the appearance features from T1-weighted images, we observe improvements in the prediction performance on both tasks, with substantial gains for classification. We evaluate the model using public datasets, including CamCAN, IXI, and OASIS3, demonstrating the effectiveness of fusing imaging and shape features for brain analysis.

Paper number 56:
Title: MMAPs to model complex multi-state systems with vacation policies in the repair facility
Authors: Juan Eloy Ruiz-Castro, Christian Acal
Abstract: Two complex multi-state systems subject to multiple events are built in an algorithmic and computational way by considering phase-type distributions and Markovian arrival processes with marked arrivals. The internal performance of the system is composed of different degradation levels and internal repairable and non-repairable failures can occur. Also, the system is subject to external shocks that may provoke repairable or non-repairable failure. A multiple vacation policy is introduced in the system for the repairperson. Preventive maintenance is included in the system to improve the behaviour. Two types of task may be performed by the repairperson; corrective repair and preventive maintenance. The systems are modelled, the transient and stationary distributions are built and different performance measures are calculated in a matrix-algorithmic form. Cost and rewards are included in the model in a vector matrix way. Several economic measures are worked out and the net reward per unit of time is used to optimize the system. A numerical example shows that the system can be optimized according to the existence of preventive maintenance and the distribution of vacation time. The results have been implemented computationally with Matlab and R (packages: expm, optim).

Paper number 57:
Title: DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them
Authors: Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen
Abstract: Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code will be made publicly available

Paper number 58:
Title: Evaluating Human Perception of Novel View Synthesis: Subjective Quality Assessment of Gaussian Splatting and NeRF in Dynamic Scenes
Authors: Yuhang Zhang, Joshua Maraval, Zhengyu Zhang, Nicolas Ramin, Shishun Tian, Lu Zhang
Abstract: Gaussian Splatting (GS) and Neural Radiance Fields (NeRF) are two groundbreaking technologies that have revolutionized the field of Novel View Synthesis (NVS), enabling immersive photorealistic rendering and user experiences by synthesizing multiple viewpoints from a set of images of sparse views. The potential applications of NVS, such as high-quality virtual and augmented reality, detailed 3D modeling, and realistic medical organ imaging, underscore the importance of quality assessment of NVS methods from the perspective of human perception. Although some previous studies have explored subjective quality assessments for NVS technology, they still face several challenges, especially in NVS methods selection, scenario coverage, and evaluation methodology. To address these challenges, we conducted two subjective experiments for the quality assessment of NVS technologies containing both GS-based and NeRF-based methods, focusing on dynamic and real-world scenes. This study covers 360°, front-facing, and single-viewpoint videos while providing a richer and greater number of real scenes. Meanwhile, it's the first time to explore the impact of NVS methods in dynamic scenes with moving objects. The two types of subjective experiments help to fully comprehend the influences of different viewing paths from a human perception perspective and pave the way for future development of full-reference and no-reference quality metrics. In addition, we established a comprehensive benchmark of various state-of-the-art objective metrics on the proposed database, highlighting that existing methods still struggle to accurately capture subjective quality. The results give us some insights into the limitations of existing NVS methods and may promote the development of new NVS methods.

Paper number 59:
Title: Audio-visual Deepfake Detection With Local Temporal Inconsistencies
Authors: Marcella Astrid, Enjie Ghorbel, Djamila Aouada
Abstract: This paper proposes an audio-visual deepfake detection approach that aims to capture fine-grained temporal inconsistencies between audio and visual modalities. To achieve this, both architectural and data synthesis strategies are introduced. From an architectural perspective, a temporal distance map, coupled with an attention mechanism, is designed to capture these inconsistencies while minimizing the impact of irrelevant temporal subsequences. Moreover, we explore novel pseudo-fake generation techniques to synthesize local inconsistencies. Our approach is evaluated against state-of-the-art methods using the DFDC and FakeAVCeleb datasets, demonstrating its effectiveness in detecting audio-visual deepfakes.

Paper number 60:
Title: Nonlinear Cruise Controllers with Bidirectional Sensing for a String of Vehicles
Authors: Iasson Karafyllis, Dionysios Theodosis, Markos Papageorgiou
Abstract: We introduce a nonlinear cruise controller that is fully decentralized (by vehicle) and uses spacing and speed measurements from the preceding and following vehicles to decide on the appropriate control action (acceleration) for each vehicle. The proposed cruise controller is studied on both a ring-road and an open road and guarantees that there are no collisions between vehicles, while their speeds are always positive and never exceed the road speed limits. For both cases of the open road and the ring-road, we rigorously prove that the set of equilibrium points is globally asymptotically stable and provide KL estimates that guarantee uniform convergence to the said set. Moreover, we show that for the ring-road, and under certain conditions, there is a single equilibrium point which is exponentially attractive.

Paper number 61:
Title: CodecFake-Omni: A Large-Scale Codec-based Deepfake Speech Dataset
Authors: Jiawei Du, Xuanjun Chen, Haibin Wu, Lin Zhang, I-Ming Lin, I-Hsiang Chiu, Wenze Ren, Yuan Tseng, Yu Tsao, Jyh-Shing Roger Jang, Hung-yi Lee
Abstract: With the rapid advancement of codec-based speech generation (CoSG) systems, creating fake speech that mimics an individual's identity and spreads misinformation has become remarkably easy. Addressing the risks posed by such deepfake speech has attracted significant attention. However, most existing studies focus on detecting fake data generated by traditional speech generation models. Research on detecting fake speech generated by CoSG systems remains limited and largely unexplored. In this paper, we introduce CodecFake-Omni, a large-scale dataset specifically designed to advance the study of neural codec-based deepfake speech (CodecFake) detection and promote progress within the anti-spoofing community. To the best of our knowledge, CodecFake-Omni is the largest dataset of its kind till writing this paper, encompassing the most diverse range of codec architectures. The training set is generated through re-synthesis using nearly all publicly available open-source 31 neural audio codec models across 21 different codec families (one codec family with different configurations will result in multiple different codec models). The evaluation set includes web-sourced data collected from websites generated by 17 advanced CoSG models with eight codec families. Using this large-scale dataset, we reaffirm our previous findings that anti-spoofing models trained on traditional spoofing datasets generated by vocoders struggle to detect synthesized speech from current CoSG systems. Additionally, we propose a comprehensive neural audio codec taxonomy, categorizing neural audio codecs by their root components: vector quantizer, auxiliary objectives, and decoder types, with detailed explanations and representative examples for each. Using this comprehensive taxonomy, we conduct stratified analysis to provide valuable insights for future CodecFake detection research.

Paper number 62:
Title: AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring
Authors: Sanjida Afrin Mou (1), Tasfia Noor Chowdhury (2), Adib Ibn Mannan (3), Sadia Nourin Mim (4), Lubana Tarannum (5), Tasrin Noman (6), Jamal Uddin Ahamed ((1) Department of Mechatronics &amp; Industrial Engineering, Chittagong University of Engineering &amp; Technology (CUET), Chattogram, Bangladesh (2) Department of Mechanical Engineering, Chittagong University of Engineering &amp; Technology (CUET), Chattogram, Bangladesh)
Abstract: Flooding is a major natural hazard causing significant fatalities and economic losses annually, with increasing frequency due to climate change. Rapid and accurate flood detection and monitoring are crucial for mitigating these impacts. This study compares the performance of three deep learning models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in flood detection, utilizing images from drones, in field observations, and social media. This study involves creating a new dataset that augments wellknown benchmark datasets with flood-specific images, enhancing the robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are tested to determine their effectiveness in various environmental conditions and geographical locations, and the strengths and limitations of each model are also discussed here, providing insights into their applicability in different scenarios by predicting image segmentation masks. This fully automated approach allows these models to isolate flooded areas in images, significantly reducing processing time compared to traditional semi-automated methods. The outcome of this study is to predict segmented masks for each image effected by a flood disaster and the validation accuracy of these models. This methodology facilitates timely and continuous flood monitoring, providing vital data for emergency response teams to reduce loss of life and economic damages. It offers a significant reduction in the time required to generate flood maps, cutting down the manual processing time. Additionally, we present avenues for future research, including the integration of multimodal data sources and the development of robust deep learning architectures tailored specifically for flood detection tasks. Overall, our work contributes to the advancement of flood management strategies through innovative use of deep learning technologies.

Paper number 63:
Title: Path Loss Prediction Using Machine Learning with Extended Features
Authors: Jonathan Ethier, Mathieu Chateauvert, Ryan G. Dempsey, Alexis Bose
Abstract: Wireless communications rely on path loss modeling, which is most effective when it includes the physical details of the propagation environment. Acquiring this data has historically been challenging, but geographic information system data is becoming increasingly available with higher resolution and accuracy. Access to such details enables propagation models to more accurately predict coverage and minimize interference in wireless deployments. Machine learning-based modeling can significantly support this effort, with feature-based approaches allowing for accurate, efficient, and scalable propagation modeling. Building on previous work, we introduce an extended set of features that improves prediction accuracy while, most importantly, maintaining model generalization across a broad range of environments.

Paper number 64:
Title: XVertNet: Unsupervised Contrast Enhancement of Vertebral Structures with Dynamic Self-Tuning Guidance and Multi-Stage Analysis
Authors: Ella Eidlin, Assaf Hoogi, Hila Rozen, Mohammad Badarne, Nathan S. Netanyahu
Abstract: Chest X-rays remain the primary diagnostic tool in emergency medicine, yet their limited ability to capture fine anatomical details can result in missed or delayed diagnoses. To address this, we introduce XVertNet, a novel deep-learning framework designed to enhance vertebral structure visualization in X-ray images significantly. Our framework introduces two key innovations: (1) An unsupervised learning architecture that eliminates reliance on manually labeled training data a persistent bottleneck in medical imaging, and (2) a dynamic self-tuned internal guidance mechanism featuring an adaptive feedback loop for real-time image optimization. Extensive validation across four major public datasets revealed that XVertNet outperforms state-of-the-art enhancement methods, as demonstrated by improvements in entropy scores, Tenengrad criterion values, the local phase coherence sharpness index (LPC-SI), and thetone mapped image quality index (TMQI). Furthermore, clinical validation conducted with two board-certified radiologists confirmed that the enhanced images enabled more sensitive detection of subtle vertebral fractures and degenerative changes. The unsupervised nature of XVertNet facilitates immediate clinical deployment without requiring additional training overhead. This innovation represents a transformative advancement in emergency radiology, providing a scalable and time-efficient solution to enhance diagnostic accuracy in high-pressure clinical environments.

Paper number 65:
Title: Enforcing contraction via data
Authors: Zhongjie Hu, Claudio De Persis, Pietro Tesi
Abstract: We present data-based conditions for enforcing contractivity via feedback control and obtain desired asymptotic properties of the closed-loop system. We focus on unknown nonlinear control systems whose vector fields are expressible via a dictionary of functions and derive data-dependent semidefinite programs whose solution returns the controller that guarantees contractivity. When data are perturbed by disturbances that are linear combinations of sinusoids of known frequencies (but unknown amplitude and phase) and constants, we remarkably obtain conditions for contractivity that do not depend on the magnitude of the disturbances, with imaginable positive consequences for the synthesis of the controller. Finally, we show how to design from data an integral controller for nonlinear systems that achieves constant reference tracking and constant disturbance rejection.

Paper number 66:
Title: Design and Implementation of Low-Cost Electric Vehicles (Evs) Supercharger: A Comprehensive Review
Authors: Md Khaledur Rahman, Faysal Amin Tanvir, Md Saiful Islam, Md Shameem Ahsan, Manam Ahmed
Abstract: This article presents a probabilistic modeling method utilizing smart meter data and an innovative agent-based simulator for electric vehicles (EVs). The aim is to assess the effects of different cost-driven EV charging strategies on the power distribution network (PDN). We investigate the effects of a 40% EV adoption on three parts of Frederiksberg's low voltage distribution network (LVDN), a densely urbanized municipality in Denmark. Our findings indicate that cable and transformer overloading especially pose a challenge. However, the impact of EVs varies significantly between each LVDN area and charging scenario. Across scenarios and LVDNs, the share of cables facing congestion ranges between 5% and 60%. It is also revealed that time-of-use (ToU)-based and single-day cost-minimized charging could be beneficial for LVDNs with moderate EV adoption rates. In contrast, multiple-day optimization will likely lead to severe congestion, as such strategies concentrate demand on a single day that would otherwise be distributed over several days, thus raising concerns about how to prevent it. The broader implications of our research suggest that, despite initial worries primarily centered on congestion due to unregulated charging during peak hours, a transition to cost-based smart charging, propelled by an increasing awareness of time-dependent electricity prices, may lead to a significant rise in charging synchronization, bringing about undesirable consequences for the power distribution network (PDN).

Paper number 67:
Title: High-Precision Positioning with Continuous Delay and Doppler Shift using AFT-MC Waveforms
Authors: Cong Yi, Haoran Yin, Xianjie Lu, Yanqun Tang
Abstract: This paper explores a novel integrated localization and communication (ILAC) system using the affine Fourier transform multicarrier (AFT-MC) waveform. Specifically, we consider a multiple-input multiple-output (MIMO) AFT-MC system with ILAC and derive a continuous delay and Doppler shift channel matrix model. Based on the derived signal model, we develop a two-step algorithm with low complexity for estimating channel parameters. Furthermore, we derive the Cramér-Rao lower bound (CRLB) of location estimation as the fundamental limit of localization. Finally, we provide some insights about the AFT-MC parameters by explaining the impact of the parameters on localization performance. Simulation results demonstrate that the AFT-MC waveform is able to provide significant localization performance improvement compared to orthogonal frequency division multiplexing (OFDM) while achieving the CRLB of location estimation.

Paper number 68:
Title: Regression Equilibrium in Electricity Markets
Authors: Vladimir Dvorkin
Abstract: In two-stage electricity markets, renewable power producers enter the day-ahead market with a forecast of future power generation and then reconcile any forecast deviation in the real-time market at a penalty. The choice of the forecast model is thus an important strategy decision for renewable power producers as it affects financial performance. In electricity markets with large shares of renewable generation, the choice of the forecast model impacts not only individual performance but also outcomes for other producers. In this paper, we argue for the existence of a competitive regression equilibrium in two-stage electricity markets in terms of the parameters of private forecast models informing the participation strategies of renewable power producers. In our model, renewables optimize the forecast against the day-ahead and real-time prices, thereby maximizing the average profits across the day-ahead and real-time markets. By doing so, they also implicitly enhance the temporal cost coordination of day-ahead and real-time markets. We base the equilibrium analysis on the theory of variational inequalities, providing results on the existence and uniqueness of regression equilibrium in energy-only markets. We also devise two methods to compute regression equilibrium: centralized optimization and a decentralized ADMM-based algorithm.

Paper number 69:
Title: VBIM-Net: Variational Born Iterative Network for Inverse Scattering Problems
Authors: Ziqing Xing, Zhaoyang Zhang, Zirui Chen, Yusong Wang, Haoran Ma, Zhun Wei
Abstract: Recently, studies have shown the potential of integrating field-type iterative methods with deep learning (DL) techniques in solving inverse scattering problems (ISPs). In this article, we propose a novel Variational Born Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with significantly improved structural rationality and inversion quality. The proposed VBIM-Net emulates the alternating updates of the total electric field and the contrast in the variational Born iterative method (VBIM) by multiple layers of subnetworks. We embed the analytical calculation of the contrast variation into each subnetwork, converting the scattered field residual into an approximate contrast variation and then enhancing it by a U-Net, thus avoiding the requirement of matched measurement dimension and grid resolution as in existing approaches. The total field and contrast of each layer's output is supervised in the loss function of VBIM-Net, imposing soft physical constraints on the variables in the subnetworks, which benefits the model's this http URL addition, we design a training scheme with extra noise to enhance the model's stability. Extensive numerical results on synthetic and experimental data both verify the inversion quality, generalization ability, and robustness of the proposed VBIM-Net. This work may provide some new inspiration for the design of efficient field-type DL schemes.

Paper number 70:
Title: Joint Beam Search Integrating CTC, Attention, and Transducer Decoders
Authors: Yui Sudo, Muhammad Shakeel, Yosuke Fukumoto, Brian Yan, Jiatong Shi, Yifan Peng, Shinji Watanabe
Abstract: End-to-end automatic speech recognition (E2E-ASR) can be classified by its decoder architectures, such as connectionist temporal classification (CTC), recurrent neural network transducer (RNN-T), attention-based encoder-decoder, and Mask-CTC models. Each decoder architecture has advantages and disadvantages, leading practitioners to switch between these different models depending on application requirements. Instead of building separate models, we propose a joint modeling scheme where four decoders (CTC, RNN-T, attention, and Mask-CTC) share the same encoder -- we refer to this as 4D modeling. The 4D model is trained jointly, which will bring model regularization and maximize the model robustness thanks to their complementary properties. To efficiently train the 4D model, we introduce a two-stage training strategy that stabilizes the joint training. In addition, we propose three novel joint beam search algorithms by combining three decoders (CTC, RNN-T, and attention) to further improve performance. These three beam search algorithms differ in which decoder is used as the primary decoder. We carefully evaluate the performance and computational tradeoffs associated with each algorithm. Experimental results demonstrate that the jointly trained 4D model outperforms the E2E-ASR models trained with only one individual decoder. Furthermore, we demonstrate that the proposed joint beam search algorithm outperforms the previously proposed CTC/attention decoding.

Paper number 71:
Title: Data-driven Bayesian State Estimation with Compressed Measurement of Model-free Process using Semi-supervised Learning
Authors: Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee
Abstract: The research topic is: data-driven Bayesian state estimation with compressed measurement (BSCM) of model-free process, say for a (causal) tracking application. The dimension of the temporal measurement vector is lower than the dimension of the temporal state vector to be estimated. Hence the state estimation problem is an underdetermined inverse problem. The underlying dynamical model of the states is assumed to be unknown and hence, we use the terminology 'model-free process'. In absence of the dynamical model, we can not employ traditional model-driven methods like Kalman Filter (KF) and Particle Filter (PF), and instead require data-driven methods. We first experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem for model-free process; they are - data-driven nonlinear state estimation (DANSE) method and deep Markov model (DMM) method. The unsupervised learning uses unlabelled data comprised of only noisy, linear measurements. While DANSE provides a good predictive / forecasting performance to model the temporal measurement data as time-series, its unsupervised learning lacks a regularization for state estimation. We then investigate the use of a semi-supervised learning approach, and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a limited amount of labelled data along-with a large amount of unlabelled data, and that helps to bring the desired regularization for addressing the BSCM problem. The labelled data means pairwise measurement-and-state data. Using three chaotic dynamical systems (or processes) with nonlinear dynamical models as benchmark, we show that the data-driven SemiDANSE provides competitive performance for BSCM against a hybrid method called KalmanNet and two model-driven methods -- an extended KF (EKF) and an unscented KF (UKF).

Paper number 72:
Title: Enhanced Masked Image Modeling to Avoid Model Collapse on Multi-modal MRI Datasets
Authors: Linxuan Han, Sa Xiao, Zimeng Li, Haidong Li, Xiuchao Zhao, Yeqing Han, Fumin Guo, Xin Zhou
Abstract: Multi-modal magnetic resonance imaging (MRI) provides information of lesions for computer-aided diagnosis from different views. Deep learning algorithms are suitable for identifying specific anatomical structures, segmenting lesions, and classifying diseases. Manual labels are limited due to the high expense, which hinders further improvement of accuracy. Self-supervised learning, particularly masked image modeling (MIM), has shown promise in utilizing unlabeled data. However, we spot model collapse when applying MIM to multi-modal MRI datasets. The performance of downstream tasks does not see any improvement following the collapsed model. To solve model collapse, we analyze and address it in two types: complete collapse and dimensional collapse. We find complete collapse occurs because the collapsed loss value in multi-modal MRI datasets falls below the normally converged loss value. Based on this, the hybrid mask pattern (HMP) masking strategy is introduced to elevate the collapsed loss above the normally converged loss value and avoid complete collapse. Additionally, we reveal that dimensional collapse stems from insufficient feature uniformity in MIM. We mitigate dimensional collapse by introducing the pyramid barlow twins (PBT) module as an explicit regularization method. Overall, we construct the enhanced MIM (E-MIM) with HMP and PBT module to avoid model collapse multi-modal MRI. Experiments are conducted on three multi-modal MRI datasets to validate the effectiveness of our approach in preventing both types of model collapse. By preventing model collapse, the training of the model becomes more stable, resulting in a decent improvement in performance for segmentation and classification tasks. The code is available at this https URL.

Paper number 73:
Title: Zero-shot 3D Segmentation of Abdominal Organs in CT Scans Using Segment Anything Model 2: Adapting Video Tracking Capabilities for 3D Medical Imaging
Authors: Yosuke Yamagishi, Shouhei Hanaoka, Tomohiro Kikuchi, Takahiro Nakao, Yuta Nakamura, Yukihiro Nomura, Soichiro Miki, Takeharu Yoshikawa, Osamu Abe
Abstract: Objectives: To evaluate the zero-shot performance of Segment Anything Model 2 (SAM 2) in 3D segmentation of abdominal organs in CT scans, and to investigate the effects of prompt settings on segmentation results. Materials and Methods: In this retrospective study, we used a subset of the TotalSegmentator CT dataset from eight institutions to assess SAM 2's ability to segment eight abdominal organs. Segmentation was initiated from three different z-coordinate levels (caudal, mid, and cranial levels) of each organ. Performance was measured using the Dice similarity coefficient (DSC). We also analyzed the impact of "negative prompts," which explicitly exclude certain regions from the segmentation process, on accuracy. Results: 123 patients (mean age, 60.7 \pm 15.5 years; 63 men, 60 women) were evaluated. As a zero-shot approach, larger organs with clear boundaries demonstrated high segmentation performance, with mean DSCs as follows: liver 0.821 \pm 0.192, right kidney 0.862 \pm 0.212, left kidney 0.870 \pm 0.154, and spleen 0.891 \pm 0.131. Smaller organs showed lower performance: gallbladder 0.531 \pm 0.291, pancreas 0.361 \pm 0.197, and adrenal glands, right 0.203 \pm 0.222, left 0.308 \pm 0.234. The initial slice for segmentation and the use of negative prompts significantly influenced the results. By removing negative prompts from the input, the DSCs significantly decreased for six organs. Conclusion: SAM 2 demonstrated promising zero-shot performance in segmenting certain abdominal organs in CT scans, particularly larger organs. Performance was significantly influenced by input negative prompts and initial slice selection, highlighting the importance of optimizing these factors.

Paper number 74:
Title: Diffraction Aided Wireless Positioning
Authors: Gaurav Duggal, R. Michael Buehrer, Harpreet S. Dhillon, Jeffrey H. Reed
Abstract: Wireless positioning in Non-Line-of-Sight (NLoS) scenarios presents significant challenges due to multipath effects that lead to biased measurements and reduced positioning accuracy. This paper revisits electromagnetic field theory related to diffraction and in the context of wireless positioning and proposes a novel positioning technique that greatly improves accuracy in NLoS environments dominated by diffraction. The method is applied to a critical public safety use case: precisely locating at-risk individuals within buildings, with a particular focus on improving 3D positioning and z-axis accuracy. By leveraging the Geometrical Theory of Diffraction (GTD), the approach introduces an innovative NLoS path length model and a new NLOS positioning technique. Using Fisher information analysis, we establish the conditions required for 3D positioning and derive lower bounds on positioning performance for both 3D and z-axis estimates for the proposed NLOS positioning technique. Additionally, we propose an algorithmic implementation of the proposed NLoS positioning method using non-linear least squares estimation, which we term D-NLS. The positioning performance of our proposed NLOs positioning technique is validated using an extensive ray-tracing simulation. The numerical results highlight the superiority of our approach in outdoor-to-indoor environments, which directly estimates NLoS path lengths and delivers significant performance enhancements over existing methods for both 3D and z-axis positioning scenarios.

Paper number 75:
Title: Leveraging Joint Spectral and Spatial Learning with MAMBA for Multichannel Speech Enhancement
Authors: Wenze Ren, Haibin Wu, Yi-Cheng Lin, Xuanjun Chen, Rong Chao, Kuo-Hsuan Hung, You-Jin Li, Wen-Yuan Ting, Hsin-Min Wang, Yu Tsao
Abstract: In multichannel speech enhancement, effectively capturing spatial and spectral information across different microphones is crucial for noise reduction. Traditional methods, such as CNN or LSTM, attempt to model the temporal dynamics of full-band and sub-band spectral and spatial features. However, these approaches face limitations in fully modeling complex temporal dependencies, especially in dynamic acoustic environments. To overcome these challenges, we modify the current advanced model McNet by introducing an improved version of Mamba, a state-space model, and further propose MCMamba. MCMamba has been completely reengineered to integrate full-band and narrow-band spatial information with sub-band and full-band spectral features, providing a more comprehensive approach to modeling spatial and spectral information. Our experimental results demonstrate that MCMamba significantly improves the modeling of spatial and spectral features in multichannel speech enhancement, outperforming McNet and achieving state-of-the-art performance on the CHiME-3 dataset. Additionally, we find that Mamba performs exceptionally well in modeling spectral information.

Paper number 76:
Title: A Physical Layer Security Framework for IRS-Assisted Integrated Sensing and Semantic Communication Systems
Authors: Hamid Amiriara, Mahtab Mirmohseni, Ahmed Elzanaty, Yi Ma, Rahim Tafazolli
Abstract: In this paper, we propose a physical layer security (PLS) framework for an intelligent reflecting surface (IRS)-assisted integrated sensing and semantic communication (ISASC) system, where a multi-antenna dual-functional semantic base station (BS) serves multiple semantic communication users (SCUs) and monitors a potentially malicious sensing target (MST) in the presence of an eavesdropper (EVE). Both MST and EVE attempt to wiretap information from the signals transmitted to the SCUs. The deployment of the IRS not only enhances PLS by directing a strong beam towards the SCUs, but also improves the localization information for the target without disclosing information about the SCUs. To further strengthen PLS, we employ joint artificial noise (AN) and dedicated sensing signal (DSS), in addition to wiretap coding. To evaluate sensing accuracy, we derive the Cramer-Rao bound (CRB) for estimating the direction of arrival (DoA), and to assess the PLS level of the ISASC system, we determine a closed-form expression for the semantic secrecy rate (SSR). To achieve an optimal trade-off between these two competing objectives, we formulate a multi-objective optimization problem (MOOP) for the joint design of the BS's beamforming (BF) vectors and the IRS's phase shift vector. To tackle this MOOP problem, the $\epsilon$-constraint method is employed, followed by an alternating optimization (AO)-based algorithm that leverages the classical successive convex approximation (SCA) and semidefinite relaxation (SDR) techniques. Simulation results demonstrate that the proposed scheme outperforms the baseline schemes, achieving a superior trade-off between SSR and CRB. Specifically, our proposed approach improves the sensing accuracy by 5 dB compared to the commonly adopted maximal ratio transmission (MRT) approach.

Paper number 77:
Title: Generative Semantic Communications with Foundation Models: Perception-Error Analysis and Semantic-Aware Power Allocation
Authors: Chunmei Xu, Mahdi Boloursaz Mashhadi, Yi Ma, Rahim Tafazolli, Jiangzhou Wang
Abstract: Generative foundation models can revolutionize the design of semantic communication (SemCom) systems allowing high fidelity exchange of semantic information at ultra low rates. In this work, a generative SemCom framework with pretrained foundation models is proposed, where both uncoded forward-with-error and coded discard-with-error schemes are developed for the semantic decoder. To characterize the impact of transmission reliability on the perceptual quality of the regenerated signal, their mathematical relationship is analyzed from a rate-distortion-perception perspective, which is proved to be non-decreasing. The semantic values are defined to measure the semantic information of multimodal semantic features accordingly. We also investigate semantic-aware power allocation problems aiming at power consumption minimization for ultra low rate and high fidelity SemComs. To solve these problems, two semantic-aware power allocation methods are proposed by leveraging the non-decreasing property of the perception-error relationship. Numerically, perception-error functions and semantic values of semantic data streams under both schemes for image tasks are obtained based on the Kodak dataset. Simulation results show that our proposed semanticaware method significantly outperforms conventional approaches, particularly in the channel-coded case (up to 90% power saving).

Paper number 78:
Title: Data-Augmented Numerical Integration in State Prediction: Rule Selection
Authors: Jindrich Dunik, Ladislav Kral, Jakub Matousek, Ondrej Straka, Marek Brandner
Abstract: This paper deals with the state prediction of nonlinear stochastic dynamic systems. The emphasis is laid on a solution to the integral Chapman-Kolmogorov equation by a deterministic-integration-rule-based point-mass method. A novel concept of reliable data-augmented, i.e., mathematics- and data-informed, integration rule is developed to enhance the point-mass state predictor, where the trained neural network (representing data contribution) is used for the selection of the best integration rule from a set of available rules (representing mathematics contribution). The proposed approach combining the best properties of the standard mathematics-informed and novel data-informed rules is thoroughly discussed.

Paper number 79:
Title: Stochastic Integration Based Estimator: Robust Design and Stone Soup Implementation
Authors: Jindrich Dunik, Jakub Matousek, Ondrej Straka, Erik Blasch, John Hiles, Ruixin Niu
Abstract: This paper deals with state estimation of nonlinear stochastic dynamic models. In particular, the stochastic integration rule, which provides asymptotically unbiased estimates of the moments of nonlinearly transformed Gaussian random variables, is reviewed together with the recently introduced stochastic integration filter (SIF). Using SIF, the respective multi-step prediction and smoothing algorithms are developed in full and efficient square-root form. The stochastic-integration-rule-based algorithms are implemented in Python (within the Stone Soup framework) and in MATLAB and are numerically evaluated and compared with the well-known unscented and extended Kalman filters using the Stone Soup defined tracking scenario.

Paper number 80:
Title: Data-Driven Assessment of Vehicle-to-Grid Capabilities in Supporting Grid During Emergencies: Case Study of Travis County, TX
Authors: Kelsey Nelson, Javad Mohammadi
Abstract: As extreme weather events become more common and threaten power grids, the continuing adoption of electric vehicles (EVs) introduces a growing opportunity for their use as a distributed energy storage resource. This energy storage can be used as backup generation through the use of vehicle-to-grid (V2G) technology, where electricity is sent back from EV batteries to the grid. With enough participation from EV owners, V2G can mitigate outages during grid emergencies. In order to investigate a practical application of V2G, this study leverages a vast array of real-world data, such as survey results on V2G participation willingness, historical outage data within ERCOT, current EV registrations, and demographic data. This data informs realistic emergency grid scenarios with V2G support using a synthetic transmission grid for Travis County. The results find that as EV ownership rises in the coming years, the simultaneous facilitation of bidirectional charging availability would allow for V2G to play a substantial role in preventing involuntary load shed as a result of emergencies like winter storms.

Paper number 81:
Title: A Cascaded Dilated Convolution Approach for Mpox Lesion Classification
Authors: Ayush Deshmukh
Abstract: The global outbreak of the Mpox virus, classified as a Public Health Emergency of International Concern (PHEIC) by the World Health Organization, presents significant diagnostic challenges due to its visual similarity to other skin lesion diseases. Traditional diagnostic methods for Mpox, which rely on clinical symptoms and laboratory tests, are slow and labor intensive. Deep learning-based approaches for skin lesion classification offer a promising alternative. However, developing a model that balances efficiency with accuracy is crucial to ensure reliable and timely diagnosis without compromising performance. This study introduces the Cascaded Atrous Group Attention (CAGA) framework to address these challenges, combining the Cascaded Atrous Attention module and the Cascaded Group Attention mechanism. The Cascaded Atrous Attention module utilizes dilated convolutions and cascades the outputs to enhance multi-scale representation. This is integrated into the Cascaded Group Attention mechanism, which reduces redundancy in Multi-Head Self-Attention. By integrating the Cascaded Atrous Group Attention module with EfficientViT-L1 as the backbone architecture, this approach achieves state-of-the-art performance, reaching an accuracy of 98% on the Mpox Close Skin Image (MCSI) dataset while reducing model parameters by 37.5% compared to the original EfficientViT-L1. The model's robustness is demonstrated through extensive validation on two additional benchmark datasets, where it consistently outperforms existing approaches.

Paper number 82:
Title: A Measurement-Based Spatially Consistent Channel Model for Distributed MIMO in Industrial Environments
Authors: Christian Nelson, Sara Willhammar, Fredrik Tufvesson
Abstract: Future wireless communication systems are envisioned to support ultra-reliable and low-latency communication (URLLC), which will enable new applications such as compute offloading, wireless real-time control, and reliable monitoring. Distributed multiple-input multiple-output (D-MIMO) is one of the most promising technologies for delivering URLLC. This paper classifies obstruction and derives a channel model from a D-MIMO measurement campaign carried out at a carrier frequency of 3.75 GHz with a bandwidth of 35 MHz using twelve distributed fully coherent dipole antennas in an industrial environment. Channel characteristics are investigated, including statistical measures such as small-scale fading, large-scale fading, delay spread, and transition rates between line-of-sight and obstructed line-of-sight conditions for the different antenna elements, laying the foundations for an accurate channel model for D-MIMO systems in industrial environments. Furthermore, correlations of large-scale fading between antennas, spatial correlation, and tail distributions are included to enable proper evaluations of reliability and rare events. Based on the results, a channel model for D-MIMO in industrial environments is presented together with a recipe for its implementation.

Paper number 83:
Title: Towards a Generalizable Speech Marker for Parkinson's Disease Diagnosis
Authors: Maksim Siniukov, Ellie Xing, Sanaz Attaripour Isfahani, Mohammad Soleymani
Abstract: Parkinson's Disease (PD) is a neurodegenerative disorder characterized by motor symptoms, including altered voice production in the early stages. Early diagnosis is crucial not only to improve PD patients' quality of life but also to enhance the efficacy of potential disease-modifying therapies during early neurodegeneration, a window often missed by current diagnostic tools. In this paper, we propose a more generalizable approach to PD recognition through domain adaptation and self-supervised learning. We demonstrate the generalization capabilities of the proposed approach across diverse datasets in different languages. Our approach leverages HuBERT, a large deep neural network originally trained for speech recognition and further trains it on unlabeled speech data from a population that is similar to the target group, i.e., the elderly, in a self-supervised manner. The model is then fine-tuned and adapted for use across different datasets in multiple languages, including English, Italian, and Spanish. Evaluations on four publicly available PD datasets demonstrate the model's efficacy, achieving an average specificity of 92.1% and an average sensitivity of 91.2%. This method offers objective and consistent evaluations across large populations, addressing the variability inherent in human assessments and providing a non-invasive, cost-effective and accessible diagnostic option.

Paper number 84:
Title: HyFusion: Enhanced Reception Field Transformer for Hyperspectral Image Fusion
Authors: Chia-Ming Lee, Yu-Fan Lin, Yu-Hao Ho, Li-Wei Kang, Chih-Chung Hsu
Abstract: Hyperspectral image (HSI) fusion addresses the challenge of reconstructing High-Resolution HSIs (HR-HSIs) from High-Resolution Multispectral images (HR-MSIs) and Low-Resolution HSIs (LR-HSIs), a critical task given the high costs and hardware limitations associated with acquiring high-quality HSIs. While existing methods leverage spatial and spectral relationships, they often suffer from limited receptive fields and insufficient feature utilization, leading to suboptimal performance. Furthermore, the scarcity of high-quality HSI data highlights the importance of efficient data utilization to maximize reconstruction quality. To address these issues, we propose HyFusion, a novel Dual-Coupled Network (DCN) framework designed to enhance cross-domain feature extraction and enable effective feature map reusing. The framework first processes HR-MSI and LR-HSI inputs through specialized subnetworks that mutually enhance each other during feature extraction, preserving complementary spatial and spectral details. At its core, HyFusion utilizes an Enhanced Reception Field Block (ERFB), which combines shifting-window attention and dense connections to expand the receptive field, effectively capturing long-range dependencies while minimizing information loss. Extensive experiments demonstrate that HyFusion achieves state-of-the-art performance in HR-MSI/LR-HSI fusion, significantly improving reconstruction quality while maintaining a compact model size and computational efficiency. By integrating enhanced receptive fields and feature map reusing into a coupled network architecture, HyFusion provides a practical and effective solution for HSI fusion in resource-constrained scenarios, setting a new benchmark in hyperspectral imaging. Our code will be publicly available.

Paper number 85:
Title: Meta-learning-based percussion transcription and $t\bar{a}la$ identification from low-resource audio
Authors: Rahul Bapusaheb Kodag, Vipul Arora
Abstract: This study introduces a meta-learning-based approach for low-resource Tabla Stroke Transcription (TST) and $t\bar{a}la$ identification in Hindustani classical music. Using Model-Agnostic Meta-Learning (MAML), we address the challenge of limited annotated datasets, enabling rapid adaptation to new tasks with minimal data. The method is validated across various datasets, including tabla solo and concert recordings, demonstrating robustness in polyphonic audio scenarios. We propose two novel $t\bar{a}la$ identification techniques based on stroke sequences and rhythmic patterns. Additionally, the approach proves effective for Automatic Drum Transcription (ADT), showcasing its flexibility for Indian and Western percussion music. Experimental results show that the proposed method outperforms existing techniques in low-resource settings, significantly contributing to music transcription and studying musical traditions through computational tools.

Paper number 86:
Title: Promoting Shared Energy Storage Aggregation among High Price-Tolerance Prosumer: An Incentive Deposit and Withdrawal Service
Authors: Xin Lu, Jing Qiu, Cuo Zhang, Gang Lei, Jianguo Zhu
Abstract: Many residential prosumers exhibit a high price-tolerance for household electricity bills and a low response to price incentives. This is because the household electricity bills are not inherently high, and the potential for saving on electricity bills through participation in conventional Shared Energy Storage (SES) is limited, which diminishes their motivation to actively engage in SES. Additionally, existing SES models often require prosumers to take additional actions, such as optimizing rental capacity and bidding prices, which happen to be capabilities that typical household prosumers do not possess. To incentivize these high price-tolerance residential prosumers to participate in SES, a novel SES aggregation framework is proposed, which does not require prosumers to take additional actions and allows them to maintain existing energy storage patterns. Compared to conventional long-term operation of SES, the proposed framework introduces an additional short-term construction step during which the energy service provider (ESP) acquires control of the energy storage systems (ESS) and offers electricity deposit and withdrawal services (DWS) with dynamic coefficients, enabling prosumers to withdraw more electricity than they deposit without additional actions. Additionally, a matching mechanism is proposed to align prosumers' electricity consumption behaviors with ESP's optimization strategies. Finally, the dynamic coefficients in DWS and trading strategies are optimized by an improved deep reinforcement learning (DRL) algorithm. Case studies are conducted to verify the effectiveness of the proposed SES aggregation framework with DWS and the matching mechanism.

Paper number 87:
Title: Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale Super-Resolution
Authors: Du Chen, Liyi Chen, Zhengqiang Zhang, Lei Zhang
Abstract: Equipped with the continuous representation capability of Multi-Layer Perceptron (MLP), Implicit Neural Representation (INR) has been successfully employed for Arbitrary-scale Super-Resolution (ASR). However, the limited receptive field of the linear layers in MLP restricts the representation capability of INR, while it is computationally expensive to query the MLP numerous times to render each pixel. Recently, Gaussian Splatting (GS) has shown its advantages over INR in both visual quality and rendering speed in 3D tasks, which motivates us to explore whether GS can be employed for the ASR task. However, directly applying GS to ASR is exceptionally challenging because the original GS is an optimization-based method through overfitting each single scene, while in ASR we aim to learn a single model that can generalize to different images and scaling factors. We overcome these challenges by developing two novel techniques. Firstly, to generalize GS for ASR, we elaborately design an architecture to predict the corresponding image-conditioned Gaussians of the input low-resolution image in a feed-forward manner. Secondly, we implement an efficient differentiable 2D GPU/CUDA-based scale-aware rasterization to render super-resolved images by sampling discrete RGB values from the predicted contiguous Gaussians. Via end-to-end training, our optimized network, namely GSASR, can perform ASR for any image and unseen scaling factors. Extensive experiments validate the effectiveness of our proposed method. The project page can be found at \url{this https URL}.

Paper number 88:
Title: A systematic review of the use of Deep Learning in Satellite Imagery for Agriculture
Authors: Brandon Victor, Zhen He, Aiden Nibali
Abstract: Agricultural research is essential for increasing food production to meet the requirements of an increasing population in the coming decades. Recently, satellite technology has been improving rapidly and deep learning has seen much success in generic computer vision tasks and many application areas which presents an important opportunity to improve analysis of agricultural land. Here we present a systematic review of 150 studies to find the current uses of deep learning on satellite imagery for agricultural research. Although we identify 5 categories of agricultural monitoring tasks, the majority of the research interest is in crop segmentation and yield prediction. We found that, when used, modern deep learning methods consistently outperformed traditional machine learning across most tasks; the only exception was that Long Short-Term Memory (LSTM) Recurrent Neural Networks did not consistently outperform Random Forests (RF) for yield prediction. The reviewed studies have largely adopted methodologies from generic computer vision, except for one major omission: benchmark datasets are not utilised to evaluate models across studies, making it difficult to compare results. Additionally, some studies have specifically utilised the extra spectral resolution available in satellite imagery, but other divergent properties of satellite images - such as the hugely different scales of spatial patterns - are not being taken advantage of in the reviewed studies.

Paper number 89:
Title: WINE: Wavelet-Guided GAN Inversion and Editing for High-Fidelity Refinement
Authors: Chaewon Kim, Seung-Jun Moon, Gyeong-Moon Park
Abstract: Recent advanced GAN inversion models aim to convey high-fidelity information from original images to generators through methods using generator tuning or high-dimensional feature learning. Despite these efforts, accurately reconstructing image-specific details remains as a challenge due to the inherent limitations both in terms of training and structural aspects, leading to a bias towards low-frequency information. In this paper, we look into the widely used pixel loss in GAN inversion, revealing its predominant focus on the reconstruction of low-frequency features. We then propose WINE, a Wavelet-guided GAN Inversion aNd Editing model, which transfers the high-frequency information through wavelet coefficients via newly proposed wavelet loss and wavelet fusion scheme. Notably, WINE is the first attempt to interpret GAN inversion in the frequency domain. Our experimental results showcase the precision of WINE in preserving high-frequency details and enhancing image quality. Even in editing scenarios, WINE outperforms existing state-of-the-art GAN inversion models with a fine balance between editability and reconstruction quality.

Paper number 90:
Title: CoVRage: Millimeter-Wave Beamforming for Mobile Interactive Virtual Reality
Authors: Jakob Struye, Filip Lemic, Jeroen Famaey
Abstract: Contemporary Virtual Reality (VR) setups often include an external source delivering content to a Head-Mounted Display (HMD). "Cutting the wire" in such setups and going truly wireless will require a wireless network capable of delivering enormous amounts of video data at an extremely low latency. The massive bandwidth of higher frequencies, such as the millimeter-wave (mmWave) band, can meet these requirements. Due to high attenuation and path loss in the mmWave frequencies, beamforming is essential. In wireless VR, where the antenna is integrated into the HMD, any head rotation also changes the antenna's orientation. As such, beamforming must adapt, in real-time, to the user's head rotations. An HMD's built-in sensors providing accurate orientation estimates may facilitate such rapid beamforming. In this work, we present coVRage, a receive-side beamforming solution tailored for VR HMDs. Using built-in orientation prediction present on modern HMDs, the algorithm estimates how the Angle of Arrival (AoA) at the HMD will change in the near future, and covers this AoA trajectory with a dynamically shaped oblong beam, synthesized using sub-arrays. We show that this solution can cover these trajectories with consistently high gain, even in light of temporally or spatially inaccurate orientational data.

Paper number 91:
Title: Tactile-based Exploration, Mapping and Navigation with Collision-Resilient Aerial Vehicles
Authors: Karishma Patnaik, Aravind Adhith Pandian Saravanakumaran, Wenlong Zhang
Abstract: This article introduces XPLORER, a passive deformable UAV with a spring-augmented chassis and proprioceptive state awareness, designed to endure collisions and maintain smooth contact. We develop a fast-converging external force estimation algorithm for XPLORER that leverages onboard sensors and proprioceptive data for contact and collision detection. Using this force information, we propose four motion primitives, including three novel tactile-based primitives: tactile-traversal, tactile-turning, and ricocheting-to aid XPLORER in navigating unknown environments. These primitives are synthesized autonomously in real-time to enable efficient exploration and navigation by leveraging collisions and contacts. Experimental results demonstrate the effectiveness of our approach, highlighting the potential of passive deformable UAVs for contact-rich real-world tasks such as non-destructive inspection, surveillance and mapping, and pursuit/evasion.

Paper number 92:
Title: Invariance Proximity: Closed-Form Error Bounds for Finite-Dimensional Koopman-Based Models
Authors: Masih Haseli, Jorge Cortés
Abstract: A popular way to approximate the Koopman operator's action on a finite-dimensional subspace of functions is via orthogonal projections. The quality of the projected model directly depends on the selected subspace, specifically on how close it is to being invariant under the Koopman operator. The notion of invariance proximity provides a tight upper bound on the worst-case relative prediction error of the finite-dimensional model. However, its direct calculation is computationally challenging. This paper leverages the geometric structure behind the definition of invariance proximity to provide a closed-form expression in terms of Jordan principal angles on general inner product spaces. Unveiling this connection allows us to exploit specific isomorphisms to circumvent the computational challenges associated with spaces of functions and enables the use of existing efficient numerical routines to compute invariance proximity.

Paper number 93:
Title: Joint Beamforming Optimization and Mode Selection for RDARS-Aided MIMO Systems
Authors: Jintao Wang, Chengzhi Ma, Shiqi Gong, Xi Yang, Shaodan Ma
Abstract: Reconfigurable intelligent surface (RIS) has emerged as a cost-effective solution for green communications in 6G. However, its further extensive use has been greatly limited due to its fully passive characteristics. Considering the appealing distribution gains of distributed antenna systems (DAS), a flexible reconfigurable architecture called reconfigurable distributed antenna and reflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as two special cases and maintains the advantages of distributed antennas while reducing the hardware cost by replacing some active antennas with low-cost passive reflecting surfaces. In this paper, we present a RDARS-aided uplink multi-user communication system and investigate the system transmission reliability with the newly proposed architecture. Specifically, in addition to the distribution gain and the reflection gain provided by the connection and reflection modes, respectively, we also consider the dynamic mode switching of each element which introduces an additional degree of freedom (DoF) and thus results in a selection gain. As such, we aim to minimize the total sum mean-square-error (MSE) of all data streams by jointly optimizing the receive beamforming matrix, the reflection phase shifts and the channel-aware placement of elements in the connection mode. Numerical results demonstrate the superiority of the proposed architecture compared to the conventional fully passive RIS or DAS. Furthermore, some insights about the practical implementation of RDARS are provided.

Paper number 94:
Title: United We Fall: On the Nash Equilibria of Multiplex and Multilayer Network Games
Authors: Raman Ebrahimi, Parinaz Naghizadeh
Abstract: Network games provide a framework to study strategic decision making processes that are governed by structured interdependencies among agents. However, existing models do not account for environments in which agents simultaneously interact over multiple networks, or when agents operate over multiple action dimensions. In this paper, we propose new models of multiplex network games to capture the different modalities of interactions among strategic agents, and multilayer network games to capture their interactions over multiple action dimensions. We explore how the properties of the constituent networks of a multiplex/multilayer network can undermine or support the existence, uniqueness, and stability of the game's Nash equilibria. Notably, we highlight that both the largest and smallest eigenvalues of the constituent networks (reflecting their connectivity and two-sidedness, respectively) are instrumental in determining the uniqueness of the multiplex/multilayer network game's equilibrium. Together, our findings shed light on the reasons for the fragility of equilibria when agents interact over networks of networks, and point out potential interventions to alleviate them.

Paper number 95:
Title: Maximum Channel Coding Rate of Finite Block Length MIMO Faster-Than-Nyquist Signaling
Authors: Zichao Zhang, Melda Yuksel, Halim Yanikomeroglu, Benjamin K. Ng, Chan-Tong Lam
Abstract: The pursuit of higher data rates and efficient spectrum utilization in modern communication technologies necessitates novel solutions. In order to provide insights into improving spectral efficiency and reducing latency, this study investigates the maximum channel coding rate (MCCR) of finite block length (FBL) multiple-input multiple-output (MIMO) faster-than-Nyquist (FTN) channels. By optimizing power allocation, we derive the system's MCCR expression. Simulation results are compared with the existing literature to reveal the benefits of FTN in FBL transmission.

Paper number 96:
Title: Information Rates of Successive Interference Cancellation for Optical Fiber
Authors: Alex Jäger, Gerhard Kramer
Abstract: Joint detection and decoding (JDD) achieves rates based on information theory but is too complex to implement for many channels with memory or nonlinearities. Successive interference cancellation (SIC) at the receiver, combined with multistage encoding at the transmitter, is a method that lets one use coded modulation for memoryless channels to approach JDD rates. A SIC-based receiver is presented to compensate for inter-channel interference in long-haul optical fiber links. Simulations for 1000 km of standard single-mode fiber with ideal distributed Raman amplification, single-polarization transmission, and circularly symmetric complex Gaussian (CSCG) modulation show that SIC attains the achievable information rates (AIRs) of JDD using surrogate channel models with correlated phase and additive noise (CPAN). Moreover, the AIRs of ring constellations are compared to those of CSCG modulation. Simulations show that 32 rings, 16 SIC-stages, and Gaussian message passing on the factor graph of the CPAN surrogate model achieve the JDD rates of CSCG modulation. The computational complexity scales in proportion to the number of SIC-stages, where one stage has complexity similar to separate detection and decoding.

Paper number 97:
Title: Deep Learning-Based Residual Useful Lifetime Prediction for Assets with Uncertain Failure Modes
Authors: Yuqi Su, Xiaolei Fang
Abstract: Industrial prognostics focuses on utilizing degradation signals to forecast and continually update the residual useful life of complex engineering systems. However, existing prognostic models for systems with multiple failure modes face several challenges in real-world applications, including overlapping degradation signals from multiple components, the presence of unlabeled historical data, and the similarity of signals across different failure modes. To tackle these issues, this research introduces two prognostic models that integrate the mixture (log)-location-scale distribution with deep learning. This integration facilitates the modeling of overlapping degradation signals, eliminates the need for explicit failure mode identification, and utilizes deep learning to capture complex nonlinear relationships between degradation signals and residual useful lifetimes. Numerical studies validate the superior performance of these proposed models compared to existing methods.

Paper number 98:
Title: Multi-Gigabit Interactive Extended Reality over Millimeter-Wave: An End-to-End System Approach
Authors: Jakob Struye, Filip Lemic, Jeroen Famaey
Abstract: Achieving high-quality wireless interactive Extended Reality (XR) will require multi-gigabit throughput at extremely low latency. The Millimeter-Wave (mmWave) frequency bands, between 24 and 300GHz, can achieve such extreme performance. However, maintaining a consistently high Quality of Experience with highly mobile users is challenging, as mmWave communications are inherently directional. In this work, we present and evaluate an end-to-end approach to such a mmWave-based mobile XR system. We perform a highly realistic simulation of the system, incorporating accurate XR data traffic, detailed mmWave propagation models and actual user motion. We evaluate the impact of the beamforming strategy and frequency on the overall performance. In addition, we provide the first system-level evaluation of the CoVRage algorithm, a proactive and spatially aware user-side beamforming approach designed specifically for highly mobile XR environments.

Paper number 99:
Title: GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model
Authors: Zhehua Zhou, Xuan Xie, Jiayang Song, Zhan Shu, Lei Ma
Abstract: Safe Reinforcement Learning (SRL) aims to realize a safe learning process for Deep Reinforcement Learning (DRL) algorithms by incorporating safety constraints. However, the efficacy of SRL approaches often relies on accurate function approximations, which are notably challenging to achieve in the early learning stages due to data insufficiency. To address this issue, we introduce in this work a novel Generalizable Safety enhancer (GenSafe) that is able to overcome the challenge of data insufficiency and enhance the performance of SRL approaches. Leveraging model order reduction techniques, we first propose an innovative method to construct a Reduced Order Markov Decision Process (ROMDP) as a low-dimensional approximator of the original safety constraints. Then, by solving the reformulated ROMDP-based constraints, GenSafe refines the actions of the agent to increase the possibility of constraint satisfaction. Essentially, GenSafe acts as an additional safety layer for SRL algorithms. We evaluate GenSafe on multiple SRL approaches and benchmark problems. The results demonstrate its capability to improve safety performance, especially in the early learning phases, while maintaining satisfactory task performance. Our proposed GenSafe not only offers a novel measure to augment existing SRL methods but also shows broad compatibility with various SRL algorithms, making it applicable to a wide range of systems and SRL problems.

Paper number 100:
Title: Enhancing Robustness and Security in ISAC Network Design: Leveraging Transmissive Reconfigurable Intelligent Surface with RSMA
Authors: Ziwei Liu, Wen Chen, Qingqing Wu, Zhendong Li, Xusheng Zhu, Qiong Wu, Nan Cheng
Abstract: In this paper, we propose a novel transmissive reconfigurable intelligent surface transceiver-enhanced robust and secure integrated sensing and communication network. A time-division sensing communication mechanism is designed for the scenario, which enables communication and sensing to share wireless resources. To address the interference management problem and hinder eavesdropping, we implement rate-splitting multiple access (RSMA), where the common stream is designed as a useful signal and an artificial noise, while taking into account the imperfect channel state information and modeling the channel for the illegal users in a fine-grained manner as well as giving an upper bound on the error. We introduce the secrecy outage probability and construct an optimization problem with secrecy sum-rate as the objective functions to optimize the common stream beamforming matrix, the private stream beamforming matrix and the timeslot duration variable. Due to the coupling of the optimization variables and the infinity of the error set, the proposed problem is a nonconvex optimization problem that cannot be solved directly. In order to address the above challenges, the block coordinate descent-based second-order cone programming algorithm is used to decouple the optimization variables and solving the problem. Specifically, the problem is decoupled into two subproblems concerning the common stream beamforming matrix, the private stream beamforming matrix, and the timeslot duration variable, which are solved by alternating optimization until convergence is reached. To solve the problem, S-procedure, Bernstein's inequality and successive convex approximation are employed to deal with the objective function and non-convex constraints. Numerical simulation results verify the superiority of the proposed scheme in improving the secrecy energy efficiency and the Cramér-Rao boundary.

Paper number 101:
Title: Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey
Authors: Hamza Kheddar
Abstract: With significant advancements in Transformers LLMs, NLP has extended its reach into many research fields due to its enhanced capabilities in text generation and user interaction. One field benefiting greatly from these advancements is cybersecurity. In cybersecurity, many parameters that need to be protected and exchanged between senders and receivers are in the form of text and tabular data, making NLP a valuable tool in enhancing the security measures of communication protocols. This survey paper provides a comprehensive analysis of the utilization of Transformers and LLMs in cyber-threat detection systems. The methodology of paper selection and bibliometric analysis is outlined to establish a rigorous framework for evaluating existing research. The fundamentals of Transformers are discussed, including background information on various cyber-attacks and datasets commonly used in this field. The survey explores the application of Transformers in IDSs, focusing on different architectures such as Attention-based models, LLMs like BERT and GPT, CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others. Furthermore, it explores the diverse environments and applications where Transformers and LLMs-based IDS have been implemented, including computer networks, IoT devices, critical infrastructure protection, cloud computing, SDN, as well as in autonomous vehicles. The paper also addresses research challenges and future directions in this area, identifying key issues such as interpretability, scalability, and adaptability to evolving threats, and more. Finally, the conclusion summarizes the findings and highlights the significance of Transformers and LLMs in enhancing cyber-threat detection capabilities, while also outlining potential avenues for further research and development.

Paper number 102:
Title: Audio-Agent: Leveraging LLMs For Audio Generation, Editing and Composition
Authors: Zixuan Wang, Chi-Keung Tang, Yu-Wing Tai
Abstract: We introduce Audio-Agent, a multimodal framework for audio generation, editing and composition based on text or video inputs. Conventional approaches for text-to-audio (TTA) tasks often make single-pass inferences from text descriptions. While straightforward, this design struggles to produce high-quality audio when given complex text conditions. In our method, we utilize a pre-trained TTA diffusion network as the audio generation agent to work in tandem with GPT-4, which decomposes the text condition into atomic, specific instructions and calls the agent for audio generation. In doing so, Audio-Agent can generate high-quality audio that is closely aligned with the provided text or video exhibiting complex and multiple events, while supporting variable-length and variable-volume generation. For video-to-audio (VTA) tasks, most existing methods require training a timestamp detector to synchronize video events with the generated audio, a process that can be tedious and time-consuming. Instead, we propose a simpler approach by fine-tuning a pre-trained Large Language Model (LLM), e.g., Gemma2-2B-it, to obtain both semantic and temporal conditions that bridge the video and audio modality. Consequently, our framework contributes a comprehensive solution for both TTA and VTA tasks without substantial computational overhead in training.

Paper number 103:
Title: Biodenoising: Animal Vocalization Denoising without Access to Clean Data
Authors: Marius Miron, Sara Keen, Jen-Yu Liu, Benjamin Hoffman, Masato Hagiwara, Olivier Pietquin, Felix Effenberger, Maddie Cusimano
Abstract: Animal vocalization denoising is a task similar to human speech enhancement, which is relatively well-studied. In contrast to the latter, it comprises a higher diversity of sound production mechanisms and recording environments, and this higher diversity is a challenge for existing models. Adding to the challenge and in contrast to speech, we lack large and diverse datasets comprising clean vocalizations. As a solution we use as training data pseudo-clean targets, i.e. pre-denoised vocalizations, and segments of background noise without a vocalization. We propose a train set derived from bioacoustics datasets and repositories representing diverse species, acoustic environments, geographic regions. Additionally, we introduce a non-overlapping benchmark set comprising clean vocalizations from different taxa and noise samples. We show that that denoising models (demucs, CleanUNet) trained on pseudo-clean targets obtained with speech enhancement models achieve competitive results on the benchmarking set. We publish data, code, libraries, and demos at this https URL.

Paper number 104:
Title: Layer-Adaptive State Pruning for Deep State Space Models
Authors: Minseon Gwak, Seongrok Moon, Joohwan Ko, PooGyeon Park
Abstract: Due to the lack of state dimension optimization methods, deep state space models (SSMs) have sacrificed model capacity, training search space, or stability to alleviate computational costs caused by high state dimensions. In this work, we provide a structured pruning method for SSMs, Layer-Adaptive STate pruning (LAST), which reduces the state dimension of each layer in minimizing model-level output energy loss by extending modal truncation for a single system. LAST scores are evaluated using the $\mathcal{H}_{\infty}$ norms of subsystems and layer-wise energy normalization. The scores serve as global pruning criteria, enabling cross-layer comparison of states and layer-adaptive pruning. Across various sequence benchmarks, LAST optimizes previous SSMs, revealing the redundancy and compressibility of their state spaces. Notably, we demonstrate that, on average, pruning 33% of states still maintains performance with 0.52% accuracy loss in multi-input multi-output SSMs without retraining. Code is available at this https URL.

Paper number 105:
Title: Mode-conditioned music learning and composition: a spiking neural network inspired by neuroscience and psychology
Authors: Qian Liang, Yi Zeng, Menghaoran Tang
Abstract: Musical mode is one of the most critical element that establishes the framework of pitch organization and determines the harmonic relationships. Previous works often use the simplistic and rigid alignment method, and overlook the diversity of modes. However, in contrast to AI models, humans possess cognitive mechanisms for perceiving the various modes and keys. In this paper, we propose a spiking neural network inspired by brain mechanisms and psychological theories to represent musical modes and keys, ultimately generating musical pieces that incorporate tonality features. Specifically, the contributions are detailed as follows: 1) The model is designed with multiple collaborated subsystems inspired by the structures and functions of corresponding brain regions; 2)We incorporate mechanisms for neural circuit evolutionary learning that enable the network to learn and generate mode-related features in music, reflecting the cognitive processes involved in human music perception. 3)The results demonstrate that the proposed model shows a connection framework closely similar to the Krumhansl-Schmuckler model, which is one of the most significant key perception models in the music psychology domain. 4) Experiments show that the model can generate music pieces with characteristics of the given modes and keys. Additionally, the quantitative assessments of generated pieces reveals that the generating music pieces have both tonality characteristics and the melodic adaptability needed to generate diverse and musical content. By combining insights from neuroscience, psychology, and music theory with advanced neural network architectures, our research aims to create a system that not only learns and generates music but also bridges the gap between human cognition and artificial intelligence.

Paper number 106:
Title: AdaptVC: High Quality Voice Conversion with Adaptive Learning
Authors: Jaehun Kim, Ji-Hoon Kim, Yeunju Choi, Tan Dat Nguyen, Seongkyu Mun, Joon Son Chung
Abstract: The goal of voice conversion is to transform the speech of a source speaker to sound like that of a reference speaker while preserving the original content. A key challenge is to extract disentangled linguistic content from the source and voice style from the reference. While existing approaches leverage various methods to isolate the two, a generalization still requires further attention, especially for robustness in zero-shot scenarios. In this paper, we achieve successful disentanglement of content and speaker features by tuning self-supervised speech features with adapters. The adapters are trained to dynamically encode nuanced features from rich self-supervised features, and the decoder fuses them to produce speech that accurately resembles the reference with minimal loss of content. Moreover, we leverage a conditional flow matching decoder with cross-attention speaker conditioning to further boost the synthesis quality and efficiency. Subjective and objective evaluations in a zero-shot scenario demonstrate that the proposed method outperforms existing models in speech quality and similarity to the reference speech.

Paper number 107:
Title: Radar Signal Recognition through Self-Supervised Learning and Domain Adaptation
Authors: Zi Huang, Simon Denman, Akila Pemasiri, Clinton Fookes, Terrence Martin
Abstract: Automatic radar signal recognition (RSR) plays a pivotal role in electronic warfare (EW), as accurately classifying radar signals is critical for informing decision-making processes. Recent advances in deep learning have shown significant potential in improving RSR performance in domains with ample annotated data. However, these methods fall short in EW scenarios where annotated RF data are scarce or impractical to obtain. To address these challenges, we introduce a self-supervised learning (SSL) method which utilises masked signal modelling and RF domain adaption to enhance RSR performance in environments with limited RF samples and labels. Specifically, we investigate pre-training masked autoencoders (MAE) on baseband in-phase and quadrature (I/Q) signals from various RF domains and subsequently transfer the learned representation to the radar domain, where annotated data are limited. Empirical results show that our lightweight self-supervised ResNet model with domain adaptation achieves up to a 17.5% improvement in 1-shot classification accuracy when pre-trained on in-domain signals (i.e., radar signals) and up to a 16.31% improvement when pre-trained on out-of-domain signals (i.e., comm signals), compared to its baseline without SSL. We also provide reference results for several MAE designs and pre-training strategies, establishing a new benchmark for few-shot radar signal classification.

Paper number 108:
Title: Multiple testing in multi-stream sequential change detection
Authors: Sanjit Dandapanthula, Aaditya Ramdas
Abstract: Multi-stream sequential change detection involves simultaneously monitoring many streams of data and trying to detect when their distributions change, if at all. Here, we theoretically study multiple testing issues that arise from detecting changes in many streams. We point out that any algorithm with finite average run length (ARL) must have a trivial worst-case false detection rate (FDR), family-wise error rate (FWER), and per-family error rate (PFER); thus, any attempt to control these Type I error metrics is fundamentally in conflict with the desire for a finite ARL (which is typically necessary in order to have a small detection delay). One of our contributions is to define a new class of metrics which can be controlled, called error over patience (EOP). We propose algorithms that combine the recent e-detector framework (which generalizes the Shiryaev-Roberts and CUSUM methods) with the recent e-Benjamini-Hochberg procedure and e-Bonferroni procedures. We prove that these algorithms control the EOP at any desired level under very general dependence structures on the data within and across the streams. In fact, we prove a more general error control that holds uniformly over all stopping times and provides a smooth trade-off between the conflicting metrics. Additionally, if finiteness of the ARL is forfeited, we show that our algorithms control the Type I error.

Paper number 109:
Title: ExPO: Explainable Phonetic Trait-Oriented Network for Speaker Verification
Authors: Yi Ma, Shuai Wang, Tianchi Liu, Haizhou Li
Abstract: In speaker verification, we use computational method to verify if an utterance matches the identity of an enrolled speaker. This task is similar to the manual task of forensic voice comparison, where linguistic analysis is combined with auditory measurements to compare and evaluate voice samples. Despite much success, we have yet to develop a speaker verification system that offers explainable results comparable to those from manual forensic voice comparison. A novel approach, Explainable Phonetic Trait-Oriented (ExPO) network, is proposed in this paper to introduce the speaker's phonetic trait which describes the speaker's characteristics at the phonetic level, resembling what forensic comparison does. ExPO not only generates utterance-level speaker embeddings but also allows for fine-grained analysis and visualization of phonetic traits, offering an explainable speaker verification process. Furthermore, we investigate phonetic traits from within-speaker and between-speaker variation perspectives to determine which trait is most effective for speaker verification, marking an important step towards explainable speaker verification. Our code is available at this https URL.

Paper number 110:
Title: The improvement in transmission resilience metrics from reduced outages or faster restoration can be calculated by rerunning historical outage data
Authors: Arslan Ahmad, Ian Dobson, Svetlana Ekisheva, Christopher Claypool, Mark Lauby
Abstract: Transmission utilities routinely collect detailed outage data, including resilience events in which outages bunch up due to weather. The resilience events and their resilience metrics can readily be extracted from this historical outage data. Improvements such as grid hardening or investments in restoration lead to reduced outages or faster restoration. We show how to rerun this history with the effects of the reduced outages or faster restoration included to find the resulting improvement in resilience metrics, thus quantifying the benefits of these investments. This is demonstrated with case studies for specific events (a derecho and a hurricane), and all large events or large thunderstorms in the Midwest USA. Instead of predicting future extreme events with models, which is very challenging, the historical rerun readily quantifies the benefits that a resilience investment would have had if it had been made in the past. The historical rerun is particularly vivid in making the case for resilience investments to stakeholders because it quantifies the benefits for events actually experienced by those stakeholders, rather than for future events predicted with uncertainty.

Paper number 111:
Title: Cooperative Aerial Robot Inspection Challenge: A Benchmark for Heterogeneous Multi-UAV Planning and Lessons Learned
Authors: Muqing Cao, Thien-Minh Nguyen, Shenghai Yuan, Andreas Anastasiou, Angelos Zacharia, Savvas Papaioannou, Panayiotis Kolios, Christos G. Panayiotou, Marios M. Polycarpou, Xinhang Xu, Mingjie Zhang, Fei Gao, Boyu Zhou, Ben M. Chen, Lihua Xie
Abstract: We propose the Cooperative Aerial Robot Inspection Challenge (CARIC), a simulation-based benchmark for motion planning algorithms in heterogeneous multi-UAV systems. CARIC features UAV teams with complementary sensors, realistic constraints, and evaluation metrics prioritizing inspection quality and efficiency. It offers a ready-to-use perception-control software stack and diverse scenarios to support the development and evaluation of task allocation and motion planning algorithms. Competitions using CARIC were held at IEEE CDC 2023 and the IROS 2024 Workshop on Multi-Robot Perception and Navigation, attracting innovative solutions from research teams worldwide. This paper examines the top three teams from CDC 2023, analyzing their exploration, inspection, and task allocation strategies while drawing insights into their performance across scenarios. The results highlight the task's complexity and suggest promising directions for future research in cooperative multi-UAV systems.

Paper number 112:
Title: Cost-Effective Robotic Handwriting System with AI Integration
Authors: Tianyi Huang, Richard Xiong
Abstract: This paper introduces a cost-effective robotic handwriting system designed to replicate human-like handwriting with high precision. Combining a Raspberry Pi Pico microcontroller, 3D-printed components, and a machine learning-based handwriting generation model implemented via TensorFlow, the system converts user-supplied text into realistic stroke trajectories. By leveraging lightweight 3D-printed materials and efficient mechanical designs, the system achieves a total hardware cost of approximately \$56, significantly undercutting commercial alternatives. Experimental evaluations demonstrate handwriting precision within $\pm$0.3 millimeters and a writing speed of approximately 200 mm/min, positioning the system as a viable solution for educational, research, and assistive applications. This study seeks to lower the barriers to personalized handwriting technologies, making them accessible to a broader audience.

Paper number 113:
Title: Movable Antenna Enhanced Integrated Sensing and Communication Via Antenna Position Optimization
Authors: Wenyan Ma, Lipeng Zhu, Rui Zhang
Abstract: In this paper, we propose an integrated sensing and communication (ISAC) system aided by the movable-antenna (MA) array, which can improve the communication and sensing performance via flexible antenna movement over conventional fixed-position antenna (FPA) array. First, we consider the downlink multiuser communication, where each user is randomly distributed within a given three-dimensional zone with local movement. To reduce the overhead of frequent antenna movement, the antenna position vector (APV) is designed based on users' statistical channel state information (CSI), so that the antennas only need to be moved in a large timescale. Then, for target sensing, the Cramer-Rao bounds (CRBs) of the estimation mean square error for different spatial angles of arrival (AoAs) are derived as functions of MAs' positions. Based on the above, we formulate an optimization problem to maximize the expected minimum achievable rate among all communication users, with given constraints on the maximum acceptable CRB thresholds for target sensing. An alternating optimization algorithm is proposed to iteratively optimize one of the horizontal and vertical APVs of the MA array with the other being fixed. Numerical results demonstrate that our proposed MA arrays can significantly enlarge the trade-off region between communication and sensing performance compared to conventional FPA arrays with different inter-antenna spacing. It is also revealed that the steering vectors of the designed MA arrays exhibit low correlation in the angular domain, thus effectively reducing channel correlation among communication users to enhance their achievable rates, while alleviating ambiguity in target angle estimation to achieve improved sensing accuracy.
    