
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Biaxialformer: Leveraging Channel Independence and Inter-Channel Correlations in EEG Signal Decoding for Predicting Neurological Outcomes
Authors: Naimahmed Nesaragi, Hemin Ali Qadir, Per Steiner Halvorsen, Ilangko Balasingham
Abstract: Accurate decoding of EEG signals requires comprehensive modeling of both temporal dynamics within individual channels and spatial dependencies across channels. While Transformer-based models utilizing channel-independence (CI) strategies have demonstrated strong performance in various time series tasks, they often overlook the inter-channel correlations that are critical in multivariate EEG signals. This omission can lead to information degradation and reduced prediction accuracy, particularly in complex tasks such as neurological outcome prediction. To address these challenges, we propose Biaxialformer, characterized by a meticulously engineered two-stage attention-based framework. This model independently captures both sequence-specific (temporal) and channel-specific (spatial) EEG information, promoting synergy and mutual reinforcement across channels without sacrificing CI. By employing joint learning of positional encodings, Biaxialformer preserves both temporal and spatial relationships in EEG data, mitigating the interchannel correlation forgetting problem common in traditional CI models. Additionally, a tokenization module with variable receptive fields balance the extraction of fine-grained, localized features and broader temporal dependencies. To enhance spatial feature extraction, we leverage bipolar EEG signals, which capture inter-hemispheric brain interactions, a critical but often overlooked aspect in EEG analysis. Our study broadens the use of Transformer-based models by addressing the challenge of predicting neurological outcomes in comatose patients. Using the multicenter I-CARE data from five hospitals, we validate the robustness and generalizability of Biaxialformer with an average AUC 0.7688, AUPRC 0.8643, and F1 0.6518 in a cross-hospital scenario.

Paper number 2:
Title: Control Synthesis in Partially Observable Environments for Complex Perception-Related Objectives
Authors: Zetong Xuan, Yu Wang
Abstract: Perception-related tasks often arise in autonomous systems operating under partial observability. This work studies the problem of synthesizing optimal policies for complex perception-related objectives in environments modeled by partially observable Markov decision processes. To formally specify such objectives, we introduce \emph{co-safe linear inequality temporal logic} (sc-iLTL), which can define complex tasks that are formed by the logical concatenation of atomic propositions as linear inequalities on the belief space of the POMDPs. Our solution to the control synthesis problem is to transform the \mbox{sc-iLTL} objectives into reachability objectives by constructing the product of the belief MDP and a deterministic finite automaton built from the sc-iLTL objective. To overcome the scalability challenge due to the product, we introduce a Monte Carlo Tree Search (MCTS) method that converges in probability to the optimal policy. Finally, a drone-probing case study demonstrates the applicability of our method.

Paper number 3:
Title: Global Optimization of Multi-Flyby Trajectories for Multi-Orbital-Plane Constellations Inspection
Authors: An-Yi Huang, Hong-Xin Shen, Zhao Li, Cong Sun, Chao Sheng, Zheng-Zhong Kuai
Abstract: The rapid expansion of mega-constellations in low Earth orbits has posed significant challenges to space traffic management, necessitating periodic inspections of satellites to ensure the sustainability of the space environment when economically feasible. This study addresses the orbital design challenge associated with inspecting numerous satellites distributed across multiple orbital planes through flybys by proposing an innovative orbital-plane-based inspection strategy. The proposed methodology reformulates the multi-satellite flyby problem into a multi-rendezvous trajectory planning problem by proposing an analytical approach to determine a maneuver-free inspection orbit that enables flyby of all satellites within a specific orbital plane. Additionally, a three-layer global optimization framework is developed to tackle this problem. The first layer establishes an approximate cost evaluation model for orbital plane visitation sequences, utilizing a genetic algorithm to identify the optimal sequence from a vast array of candidate planes, thereby maximizing inspection targets while minimizing fuel consumption. The second layer constructs a mixed-integer programming model to locally refine the rendezvous epochs and orbital parameters of each inspection orbit to reduce the total velocity increment. The third layer accurately computes the optimal impulsive maneuvers and trajectories between inspection orbits. In contrast to traditional low-Earth orbit rendezvous optimization frameworks, the proposed framework fully leverages the adjustable freedom in inclination and right ascension of the ascending node (RAAN) of inspection orbits, significantly reducing the total velocity increment. Simulation results demonstrate that the proposed method can effectively address the trajectory optimization problem associated with constellation inspection for tens of thousands of satellites.

Paper number 4:
Title: Determination of Bandwidth of Q-filter in Disturbance Observers to Guarantee Transient and Steady State Performance under Measurement Noise
Authors: Gaeun Kim, Hyungbo Shim
Abstract: Q-filter-based disturbance observer (DOB) is one of the most widely used robust controller due to its design simplicity. Such simplicity arises from that reducing the time constant of low pass filters, not only ensures robust stability but also enhances nominal performance recovery -- ability to recover the trajectory of nominal closed-loop system. However, in contrast to noise-free environment, excessively small time constant can rather damage the nominal performance recovery under measurement noise. That is, minimizing time constant is no longer immediately guaranteeing nominal performance recovery. Motivated by this observation, this paper concentrates on determination of time constant to ensure transient and steady state performance. This analysis uses Lyapunov method based on the coordinate change inspired by the singular perturbation theory. As a result, we present an affordable noise level and open interval for the time constant that guarantees both the required performances. The analysis can also lead to theoretical demonstration on that excessively reducing time constant is assured to achieve target performance only for noise-free case.

Paper number 5:
Title: Game-Theoretic Modeling of Vehicle Unprotected Left Turns Considering Drivers' Bounded Rationality
Authors: Yuansheng Lian, Ke Zhang, Meng Li, Shen Li
Abstract: Modeling the decision-making behavior of vehicles presents unique challenges, particularly during unprotected left turns at intersections, where the uncertainty of human drivers is especially pronounced. In this context, connected autonomous vehicle (CAV) technology emerges as a promising avenue for effectively managing such interactions while ensuring safety and efficiency. Traditional approaches, often grounded in game theory assumptions of perfect rationality, may inadequately capture the complexities of real-world scenarios and drivers' decision-making errors. To fill this gap, we propose a novel decision-making model for vehicle unprotected left-turn scenarios, integrating game theory with considerations for drivers' bounded rationality. Our model, formulated as a two-player normal-form game solved by a quantal response equilibrium (QRE), offers a more nuanced depiction of driver decision-making processes compared to Nash equilibrium (NE) models. Leveraging an Expectation-Maximization (EM) algorithm coupled with a subtle neural network trained on precise microscopic vehicle trajectory data, we optimize model parameters to accurately reflect drivers' interaction-aware bounded rationality and driving styles. Through comprehensive simulation experiments, we demonstrate the efficacy of our proposed model in capturing the interaction-aware bounded rationality and decision tendencies between players. The proposed model proves to be more realistic and efficient than NE models in unprotected left-turn scenarios. Our findings contribute valuable insights into the vehicle decision-making behaviors with bounded rationality, thereby informing the development of more robust and realistic autonomous driving systems.

Paper number 6:
Title: Outcome prediction and individualized treatment effect estimation in patients with large vessel occlusion stroke
Authors: Lisa Herzog, Pascal BÃ¼hler, Ezequiel de la Rosa, Beate Sick, Susanne Wegener
Abstract: Mechanical thrombectomy has become the standard of care in patients with stroke due to large vessel occlusion (LVO). However, only 50% of successfully treated patients show a favorable outcome. We developed and evaluated interpretable deep learning models to predict functional outcomes in terms of the modified Rankin Scale score alongside individualized treatment effects (ITEs) using data of 449 LVO stroke patients from a randomized clinical trial. Besides clinical variables, we considered non-contrast CT (NCCT) and angiography (CTA) scans which were integrated using novel foundation models to make use of advanced imaging information. Clinical variables had a good predictive power for binary functional outcome prediction (AUC of 0.719 [0.666, 0.774]) which could slightly be improved when adding CTA imaging (AUC of 0.737 [0.687, 0.795]). Adding NCCT scans or a combination of NCCT and CTA scans to clinical features yielded no improvement. The most important clinical predictor for functional outcome was pre-stroke disability. While estimated ITEs were well calibrated to the average treatment effect, discriminatory ability was limited indicated by a C-for-Benefit statistic of around 0.55 in all models. In summary, the models allowed us to jointly integrate CT imaging and clinical features while achieving state-of-the-art prediction performance and ITE estimates. Yet, further research is needed to particularly improve ITE estimation.

Paper number 7:
Title: Control Synthesis Along Uncertain Trajectories Using Integral Quadratic Constraints
Authors: Felix BiertÃ¼mpfel, Peter Seiler, Harald Pfifer
Abstract: The paper presents a novel approach to synthesize robust controllers for nonlinear systems along perturbed trajectories. The approach linearizes the system with respect to a reference trajectory. In contrast to existing methods rooted in robust linear time-varying synthesis, the approach accurately includes perturbations that drive the system away from the reference trajectory. Hence, the controller obtained in the linear framework provides a significantly more robust nonlinear performance. The calculation of the controller is derived from robust synthesis approaches rooted in the integral quadratic constraints framework. The feasibility of the approach is demonstrated on a pitch tracker design for a space launcher.

Paper number 8:
Title: Cross-Comparison of Neural Architectures and Data Sets for Digital Self-Interference Modeling
Authors: Gerald Enzner, Niklas Knaepper, Aleksej Chinaev
Abstract: Inband full-duplex communication requires accurate modeling and cancellation of self-interference, specifically in the digital domain. Neural networks are presently candidate models for capturing nonlinearity of the self-interference path. This work utilizes synthetic and real data from different sources to evaluate and cross-compare performances of previously proposed neural self-interference models from different sources. The relevance of the analysis consists in the mutual assessment of methods on data they were not specifically designed for. We find that our previously proposed Hammerstein model represents the range of data sets well, while being significantly smaller in terms of the number of parameters. A new Wiener-Hammerstein model further enhances the generalization performance.

Paper number 9:
Title: Neural Substitute Solver for Efficient Edge Inference of Power Electronic Hybrid Dynamics
Authors: Jialin Zheng, Haoyu Wang, Yangbin Zeng, Han Xu, Di Mou, Hong Li, Sergio Vazquez, Leopoldo G. Franquelo
Abstract: Advancing the dynamics inference of power electronic systems (PES) to the real-time edge-side holds transform-ative potential for testing, control, and monitoring. How-ever, efficiently inferring the inherent hybrid continu-ous-discrete dynamics on resource-constrained edge hardware remains a significant challenge. This letter pro-poses a neural substitute solver (NSS) approach, which is a neural-network-based framework aimed at rapid accurate inference with significantly reduced computational costs. Specifically, NSS leverages lightweight neural networks to substitute time-consuming matrix operation and high-order numerical integration steps in traditional solvers, which transforms sequential bottlenecks into highly parallel operation suitable for edge hardware. Experimental vali-dation on a multi-stage DC-DC converter demonstrates that NSS achieves 23x speedup and 60% hardware resource reduction compared to traditional solvers, paving the way for deploying edge inference of high-fidelity PES dynamics.

Paper number 10:
Title: On the Relationship between Accent Strength and Articulatory Features
Authors: Kevin Huang, Sean Foley, Jihwan Lee, Yoonjeong Lee, Dani Byrd, Shrikanth Narayanan
Abstract: This paper explores the relationship between accent strength and articulatory features inferred from acoustic speech. To quantify accent strength, we compare phonetic transcriptions with transcriptions based on dictionary-based references, computing phoneme-level difference as a measure of accent strength. The proposed framework leverages recent self-supervised learning articulatory inversion techniques to estimate articulatory features. Analyzing a corpus of read speech from American and British English speakers, this study examines correlations between derived articulatory parameters and accent strength proxies, associating systematic articulatory differences with indexed accent strength. Results indicate that tongue positioning patterns distinguish the two dialects, with notable differences inter-dialects in rhotic and low back vowels. These findings contribute to automated accent analysis and articulatory modeling for speech processing applications.

Paper number 11:
Title: First Contact: Data-driven Friction-Stir Process Control
Authors: James Koch, Ethan King, WoongJo Choi, Megan Ebers, David Garcia, Ken Ross, Keerti Kappagantula
Abstract: This study validates the use of Neural Lumped Parameter Differential Equations for open-loop setpoint control of the plunge sequence in Friction Stir Processing (FSP). The approach integrates a data-driven framework with classical heat transfer techniques to predict tool temperatures, informing control strategies. By utilizing a trained Neural Lumped Parameter Differential Equation model, we translate theoretical predictions into practical set-point control, facilitating rapid attainment of desired tool temperatures and ensuring consistent thermomechanical states during FSP. This study covers the design, implementation, and experimental validation of our control approach, establishing a foundation for efficient, adaptive FSP operations.

Paper number 12:
Title: EvRWKV: A RWKV Framework for Effective Event-guided Low-Light Image Enhancement
Authors: WenJie Cai, Qingguo Meng, Zhenyu Wang, Xingbo Dong, Zhe Jin
Abstract: Capturing high-quality visual content under low-light conditions remains a challenging problem due to severe noise, motion blur, and underexposure, which degrade the performance of downstream applications. Traditional frame-based low-light enhancement methods often amplify noise or fail to preserve structural details, especially in real-world scenarios. Event cameras, offering high dynamic range and microsecond temporal resolution by asynchronously capturing brightness changes, emerge as promising alternatives for low-light imaging. However, existing event-image fusion methods suffer from simplistic fusion strategies and inadequate handling of spatial-temporal misalignment and noise. To address these challenges, we propose EvRWKV, a novel framework that enables continuous cross-modal interaction through dual-domain processing. Our approach incorporates a Cross-RWKV module, leveraging the Receptance Weighted Key Value (RWKV) architecture for fine-grained temporal and cross-modal fusion, and an Event Image Spectral Fusion Enhancer (EISFE) module, which jointly performs adaptive frequency-domain noise suppression and spatial-domain deformable convolution alignment. Extensive qualitative and quantitative evaluations on real-world low-light datasets(SDE, SDSD, RELED) demonstrate that EvRWKV achieves state-of-the-art performance, effectively enhancing image quality by suppressing noise, restoring structural details, and improving visual clarity in challenging low-light conditions.

Paper number 13:
Title: A Hybrid Mean Field Framework for Aggregators Participating in Wholesale Electricity Markets
Authors: Jun He, Andrew L. Liu
Abstract: The rapid growth of distributed energy resources (DERs), including rooftop solar and energy storage, is transforming the grid edge, where distributed technologies and customer-side systems increasingly interact with the broader power grid. DER aggregators, entities that coordinate and optimize the actions of many small-scale DERs, play a key role in this transformation. This paper presents a hybrid Mean-Field Control (MFC) and Mean-Field Game (MFG) framework for integrating DER aggregators into wholesale electricity markets. Unlike traditional approaches that treat market prices as exogenous, our model captures the feedback between aggregators' strategies and locational marginal prices (LMPs) of electricity. The MFC component optimizes DER operations within each aggregator, while the MFG models strategic interactions among multiple aggregators. To account for various uncertainties, we incorporate reinforcement learning (RL), which allows aggregators to learn optimal bidding strategies in dynamic market conditions. We prove the existence and uniqueness of a mean-field equilibrium and validate the framework through a case study of the Oahu Island power system. Results show that our approach reduces price volatility and improves market efficiency, offering a scalable and decentralized solution for DER integration in wholesale markets.

Paper number 14:
Title: Enhancing Satellite Quantum Key Distribution with Dual Band Reconfigurable Intelligent Surfaces
Authors: Muhammad Khalil, Ke Wang, Jinho Choi
Abstract: This paper presents a novel system architecture for hybrid satellite communications, integrating quantum key distribution (QKD) and classical radio frequency (RF) data transmission using a dual-band reconfigurable intelligent surface (RIS). The motivation is to address the growing need for global, secure, and reliable communications by leveraging the security of quantum optical links and the robustness of classical RF channels within a unified framework. By employing a frequency-selective RIS, the system independently optimizes both quantum (850 nm) and classical (S-band) channels in real time, dynamically adapting to environmental fluctuations such as atmospheric turbulence and rain attenuation. The joint optimization of the quantum bit error rate (QBER) and the classical signal-to noise ratio (SNR) is formulated as a quadratic unconstrained binary optimization (QUBO) problem, enabling efficient adaptive phase control utilizing both quantum and classical computational methods. Comprehensive theoretical modeling and simulations, benchmarked against experimental data from the Micius satellite, demonstrate substantial performance gains. Notably, the RIS assisted system reduces QBER from approximately 2.5% to 0.7%, increases the secure key rate (SKR) to over 30,000 bits per second, and enhances classical RF SNR by about 3 dB at high elevation angles. These results illustrate the practical potential of hybrid RIS-assisted satellite links to deliver robust, efficient, and secure global communications.

Paper number 15:
Title: Event2Audio: Event-Based Optical Vibration Sensing
Authors: Mingxuan Cai, Dekel Galor, Amit Pal Singh Kohli, Jacob L. Yates, Laura Waller
Abstract: Small vibrations observed in video can unveil information beyond what is visual, such as sound and material properties. It is possible to passively record these vibrations when they are visually perceptible, or actively amplify their visual contribution with a laser beam when they are not perceptible. In this paper, we improve upon the active sensing approach by leveraging event-based cameras, which are designed to efficiently capture fast motion. We demonstrate our method experimentally by recovering audio from vibrations, even for multiple simultaneous sources, and in the presence of environmental distortions. Our approach matches the state-of-the-art reconstruction quality at much faster speeds, approaching real-time processing.

Paper number 16:
Title: An Adaptive Port Technique for Synthesising Rotational Components in Component Modal Synthesis Approaches
Authors: Xiang Zhao, My Ha Dao
Abstract: Component Modal Synthesis (CMS) is a reduced order modelling method widely used for large-scale complex systems. It can effectively approximate system-level models through component synthesis, in which the repetitive geometrical components are modelled once and synthesised together. However, the conventional CMS only applies to systems with stationary components connected by strictly compatible ports, limiting it from modelling systems with moving components. This paper presents an adaptive port (AP) technique to extend CMS approaches for modelling parametric systems with rotational parts. To demonstrate the capability of the AP technique, we apply it to the Static Condensation Reduced Basis Element (SCRBE), one widely used variant of CMS approaches. The AP-based SCRBE (AP-SCRBE) can enforce the synthesis of rotational-stationary components over a shared adaptive port when the connecting surfaces of two components are discretisation-wise incompatible, which happens when one component moves relative to the others. Numerical experiments on the NREL 5MW wind turbine show that, in the context of rotational-stationary component synthesis, the AP-SCRBE can accurately and efficiently model the rotating rotor with pitch rotation of blades. It can produce almost identical results to a high-fidelity finite element model at two to three orders faster speeds.

Paper number 17:
Title: Towards Interpretable PolSAR Image Classification: Polarimetric Scattering Mechanism Informed Concept Bottleneck and Kolmogorov-Arnold Network
Authors: Jinqi Zhang, Fangzhou Han, Di Zhuang, Lamei Zhang, Bin Zou, Li Yuan
Abstract: In recent years, Deep Learning (DL) based methods have received extensive and sufficient attention in the field of PolSAR image classification, which show excellent performance. However, due to the ``black-box" nature of DL methods, the interpretation of the high-dimensional features extracted and the backtracking of the decision-making process based on the features are still unresolved problems. In this study, we first highlight this issue and attempt to achieve the interpretability analysis of DL-based PolSAR image classification technology with the help of Polarimetric Target Decomposition (PTD), a feature extraction method related to the scattering mechanism unique to the PolSAR image processing field. In our work, by constructing the polarimetric conceptual labels and a novel structure named Parallel Concept Bottleneck Networks (PaCBM), the uninterpretable high-dimensional features are transformed into human-comprehensible concepts based on physically verifiable polarimetric scattering mechanisms. Then, the Kolmogorov-Arnold Network (KAN) is used to replace Multi-Layer Perceptron (MLP) for achieving a more concise and understandable mapping process between layers and further enhanced non-linear modeling ability. The experimental results on several PolSAR datasets show that the features could be conceptualization under the premise of achieving satisfactory accuracy through the proposed pipeline, and the analytical function for predicting category labels from conceptual labels can be obtained by combining spline functions, thus promoting the research on the interpretability of the DL-based PolSAR image classification model.

Paper number 18:
Title: Cancer cytoplasm segmentation in hyperspectral cell image with data augmentation
Authors: Rebeka Sultana, Hibiki Horibe, Tomoaki Murakami, Ikuko Shimizu
Abstract: Hematoxylin and Eosin (H&E)-stained images are commonly used to detect nuclear or cancerous regions in cells from images captured by a microscope. Identifying cancer cytoplasm is crucial for determining the type of cancer; hence, obtaining accurate cancer cytoplasm regions in cell images is important. While CMOS images often lack detailed information necessary for diagnosis, hyperspectral images provide more comprehensive cell information. Using a deep learning model, we propose a method for detecting cancer cell cytoplasm in hyperspectral images. Deep learning models require large datasets for learning; however, capturing a large number of hyperspectral images is difficult. Additionally, hyperspectral images frequently contain instrumental noise, depending on the characteristics of the imaging devices. We propose a data augmentation method to account for instrumental noise. CMOS images were used for data augmentation owing to their visual clarity, which facilitates manual annotation compared to original hyperspectral images. Experimental results demonstrate the effectiveness of the proposed data augmentation method both quantitatively and qualitatively.

Paper number 19:
Title: UltraDfeGAN: Detail-Enhancing Generative Adversarial Networks for High-Fidelity Functional Ultrasound Synthesis
Authors: Zhuo Li, Xuhang Chen, Shuqiang Wang
Abstract: Functional ultrasound (fUS) is a neuroimaging technique known for its high spatiotemporal resolution, enabling non-invasive observation of brain activity through neurovascular coupling. Despite its potential in clinical applications such as neonatal monitoring and intraoperative guidance, the development of fUS faces challenges related to data scarcity and limitations in generating realistic fUS images. This paper explores the use of a generative adversarial network (GAN) framework tailored for fUS image synthesis. The proposed method incorporates architectural enhancements, including feature enhancement modules and normalization techniques, aiming to improve the fidelity and physiological plausibility of generated images. The study evaluates the performance of the framework against existing generative models, demonstrating its capability to produce high-quality fUS images under various experimental conditions. Additionally, the synthesized images are assessed for their utility in downstream tasks, showing improvements in classification accuracy when used for data augmentation. Experimental results are based on publicly available fUS datasets, highlighting the framework's effectiveness in addressing data limitations.

Paper number 20:
Title: Specific Absorption Rate-Aware Multiuser MIMO Assisted by Fluid Antenna System
Authors: Yuqi Ye, Li You, Hao Xu, Ahmed Elzanaty, Kai-Kit Wong, Xiqi Gao
Abstract: With the development of the upcoming sixth-generation (6G) wireless networks, there is a pressing need for innovative technologies capable of satisfying heightened performance indicators. Fluid antenna system (FAS) is proposed recently as a promising technique to achieve higher data rates and more diversity gains by dynamically changing the positions of the antennas to form a more desirable channel. However, worries regarding the possibly harmful effects of electromagnetic (EM) radiation emitted by devices have arisen as a result of the rapid evolution of advanced techniques in wireless communication systems. Specific absorption rate (SAR) is a widely adopted metric to quantify EM radiation worldwide. In this paper, we investigate the SAR-aware multiuser multiple-input multiple-output (MIMO) communications assisted by FAS. In particular, a two-layer iterative algorithm is proposed to minimize the SAR value under signal-to-interference-plus-noise ratio (SINR) and FAS constraints. Moreover, the minimum weighted SINR maximization problem under SAR and FAS constraints is studied by finding its relationship with the SAR minimization problem. Simulation results verify that the proposed SAR-aware FAS design outperforms the adaptive backoff and fixed-position antenna designs.

Paper number 21:
Title: Adaptive Gate-Aware Mamba Networks for Magnetic Resonance Fingerprinting
Authors: Tianyi Ding, Hongli Chen, Yang Gao, Zhuang Xiong, Feng Liu, Martijn A. Cloos, Hongfu Sun
Abstract: Magnetic Resonance Fingerprinting (MRF) enables fast quantitative imaging by matching signal evolutions to a predefined dictionary. However, conventional dictionary matching suffers from exponential growth in computational cost and memory usage as the number of parameters increases, limiting its scalability to multi-parametric mapping. To address this, recent work has explored deep learning-based approaches as alternatives to DM. We propose GAST-Mamba, an end-to-end framework that combines a dual Mamba-based encoder with a Gate-Aware Spatial-Temporal (GAST) processor. Built on structured state-space models, our architecture efficiently captures long-range spatial dependencies with linear complexity. On 5 times accelerated simulated MRF data (200 frames), GAST-Mamba achieved a T1 PSNR of 33.12~dB, outperforming SCQ (31.69~dB). For T2 mapping, it reached a PSNR of 30.62~dB and SSIM of 0.9124. In vivo experiments further demonstrated improved anatomical detail and reduced artifacts. Ablation studies confirmed that each component contributes to performance, with the GAST module being particularly important under strong undersampling. These results demonstrate the effectiveness of GAST-Mamba for accurate and robust reconstruction from highly undersampled MRF acquisitions, offering a scalable alternative to traditional DM-based methods.

Paper number 22:
Title: Hybrid-View Attention for csPCa Classification in TRUS
Authors: Zetian Feng, Juan Fu, Xuebin Zou, Hongsheng Ye, Hong Wu, Jianhua Zhou, Yi Wang
Abstract: Prostate cancer (PCa) is a leading cause of cancer-related mortality in men, and accurate identification of clinically significant PCa (csPCa) is critical for timely intervention. Transrectal ultrasound (TRUS) is widely used for prostate biopsy; however, its low contrast and anisotropic spatial resolution pose diagnostic challenges. To address these limitations, we propose a novel hybrid-view attention (HVA) network for csPCa classification in 3D TRUS that leverages complementary information from transverse and sagittal views. Our approach integrates a CNN-transformer hybrid architecture, where convolutional layers extract fine-grained local features and transformer-based HVA models global dependencies. Specifically, the HVA comprises intra-view attention to refine features within a single view and cross-view attention to incorporate complementary information across views. Furthermore, a hybrid-view adaptive fusion module dynamically aggregates features along both channel and spatial dimensions, enhancing the overall representation. Experiments are conducted on an in-house dataset containing 590 subjects who underwent prostate biopsy. Comparative and ablation results prove the efficacy of our method. The code is available at this https URL.

Paper number 23:
Title: Airspeed estimation for UAVs using only propeller feedback
Authors: Evangelos Ntouros, Pavel Kelley, Ewoud Smeur
Abstract: This work introduces a novel analytical model for estimating the airspeed of fixed-wing Unmanned Aerial Vehicles (UAVs) using solely propeller power and rotational speed measurements. The model can be used to replace Pitot-tube-based airspeed sensors, or contribute to redundancy in airspeed estimation. It does not require knowledge of the vehicle's dynamic model and is computationally lightweight. It leverages power and rotational speed feedback, which is readily available from modern Electronic Speed Controllers (ESCs), thereby enabling seamless integration with existing systems and off-the-shelf components. A systematic approach is followed to derive the model structure based on least squares optimization and regularization techniques on Blade Element Momentum (BEM) simulation, wind tunnel, and flight test datasets. The final model generalizes well achieving a normalized Root Mean Square Error (nRMSE) of 5% on unseen flight data. The model parameters can be identified either offline, using flight logs with airspeed measurements, or in-flight, using a lightweight identification method based only on Global Positioning System (GPS) velocity data. The resulting system provides a robust and computationally efficient solution for real-time airspeed estimation across diverse fixed-wing UAV platforms.

Paper number 24:
Title: PhotIQA: A photoacoustic image data set with image quality ratings
Authors: Anna Breger, Janek GrÃ¶hl, Clemens Karner, Thomas R Else, Ian Selby, Jonathan Weir-McCall, Carola-Bibiane SchÃ¶nlieb
Abstract: Image quality assessment (IQA) is crucial in the evaluation stage of novel algorithms operating on images, including traditional and machine learning based methods. Due to the lack of available quality-rated medical images, most commonly used IQA methods employing reference images (i.e. full-reference IQA) have been developed and tested for natural images. Reported application inconsistencies arising when employing such measures for medical images are not surprising, as they rely on different properties than natural images. In photoacoustic imaging (PAI), especially, standard benchmarking approaches for assessing the quality of image reconstructions are lacking. PAI is a multi-physics imaging modality, in which two inverse problems have to be solved, which makes the application of IQA measures uniquely challenging due to both, acoustic and optical, artifacts. To support the development and testing of full- and no-reference IQA measures we assembled PhotIQA, a data set consisting of 1134 reconstructed photoacoustic (PA) images that were rated by 2 experts across five quality properties (overall quality, edge visibility, homogeneity, inclusion and background intensity), where the detailed rating enables usage beyond PAI. To allow full-reference assessment, highly characterised imaging test objects were used, providing a ground truth. Our baseline experiments show that HaarPSI$_{med}$ significantly outperforms SSIM in correlating with the quality ratings (SRCC: 0.83 vs. 0.62). The dataset is publicly available at this https URL.

Paper number 25:
Title: UWB TDoA Error Correction using Transformers: Patching and Positional Encoding Strategies
Authors: Dieter Coppens, Adnan Shahid, Eli De Poorter
Abstract: Despite their high accuracy, UWB-based localization systems suffer inaccuracies when deployed in industrial locations with many obstacles due to multipath effects and non-line-of-sight (NLOS) conditions. In such environments, current error mitigation approaches for time difference of arrival (TDoA) localization typically exclude NLOS links. However, this exclusion approach leads to geometric dilution of precision problems and this approach is infeasible when the majority of links are NLOS. To address these limitations, we propose a transformer-based TDoA position correction method that uses raw channel impulse responses (CIRs) from all available anchor nodes to compute position corrections. We introduce different CIR ordering, patching and positional encoding strategies for the transformer, and analyze each proposed technique's scalability and performance gains. Based on experiments on real-world UWB measurements, our approach can provide accuracies of up to 0.39 m in a complex environment consisting of (almost) only NLOS signals, which is an improvement of 73.6 % compared to the TDoA baseline.

Paper number 26:
Title: Optimization-Based Comparative System Evaluation of Single and Dual Traction Inverters with Focus on Partial Load Efficiency and Chip Area
Authors: Christoph Sachs, Fabian Stamer, Jan Allgeier, Duleepa Thrimawithana, Martin Neuburger
Abstract: The transition to electric transportation demands efficient and cost-effective powertrains. Optimizing energy use is crucial for extending range and reducing expenses. However, comparing inverter and motor efficiency based on inverter topologies is challenging due to biased methodologies that favor certain designs over others. This document introduces a novel optimization-based approach for enhancing partial load efficiency and minimizing chip area of single and dual traction inverters, indicating potential energy savings and cost reduction. Recent publications of both industry and academia underscore the importance of these design goals achieved by either novel inverter topologies or enhanced control methods. Two promising topologies with the inherent capability of partial load optimization are evaluated regarding chip area and system efficiency to find the most suitable concept for future electric vehicle power trains.

Paper number 27:
Title: On Decision-Dependent Uncertainties in Power Systems with High-Share Renewables
Authors: Yunfan Zhang, Yifan Su, Feng Liu
Abstract: The continuously increasing renewable energy sources (RES) and demand response (DR) are becoming important sources of system flexibility. As a consequence, decision-dependent uncertainties (DDUs), interchangeably referred to as endogenous uncertainties, impose new characteristics to power system dispatch. The DDUs faced by system operators originate from uncertain dispatchable resources such as RES units or DR, while reserve providers encounter DDUs arising from the uncertain reserve deployment. This paper presents a systematic framework for addressing robust dispatch problems with DDUs. The main contributions include i) the robust characterization of DDUs with a dependency decomposition structure; ii) a generic DDU coping mechanism, manifested as the bilateral matching between uncertainty and flexibility; iii) analyses of the influence of DDU incorporation on the convexity/non-convexity of robust dispatch problems; and iv) generic solution algorithms adaptive for DDUs. Under this framework, the inherent distinctions and correlations between DDUs and DIUs are revealed, providing a fundamental theoretical basis for the economic and reliable operation of RES-dominated power systems. Applications in the source and demand sides illustrate the importance of considering DDUs and verify the effectiveness of proposed algorithms for robust dispatch with DDUs.

Paper number 28:
Title: Implicit Neural Representation of Beamforming for Continuous Aperture Array (CAPA) System
Authors: Shiyong Chen, Jia Guo, Shengqian Han
Abstract: In this paper, a learning-based approach for optimizing downlink beamforming in continuous aperture array (CAPA) systems is proposed, where a MIMO scenario that both the base station (BS) and the user are equipped with CAPA is considered. As the beamforming in the CAPA system is a function that maps a coordinate on the aperture to the beamforming weight at the coordinate, a DNN called BeaINR is proposed to parameterize this function, which is called implicit neural representation (INR). We further find that the optimal beamforming function lies in the subspace of channel function, i.e., it can be expressed as a weighted integral of channel function. Based on this finding, we propose another DNN called CoefINR to learn the weighting coefficient with INR, which has lower complexity than learning the beamforming function with BeaINR. Simulation results show that the proposed INR-based methods outperform numerical baselines in both spectral efficiency (SE) and inference time, with CoefINR offering additional training efficiency.

Paper number 29:
Title: Benchmarking Spiking Neurons for Linear Quadratic Regulator Control of Multi-linked Pole on a Cart: from Single Neuron to Ensemble
Authors: Shreyan Banerjee, Luna Gava, Aasifa Rounak, Vikram Pakrashi
Abstract: The emerging field of neuromorphic computing for edge control applications poses the need to quantitatively estimate and limit the number of spiking neurons, to reduce network complexity and optimize the number of neurons per core and hence, the chip size, in an application-specific neuromorphic hardware. While rate-encoding for spiking neurons provides a robust way to encode signals with the same number of neurons as an ANN, it often lacks precision. To achieve the desired accuracy, a population of neurons is often needed to encode the complete range of input signals. However, using population encoding immensely increases the total number of neurons required for a particular application, thus increasing the power consumption and on-board resource utilization. A transition from two neurons to a population of neurons for the LQR control of a cartpole is shown in this work. The near-linear behavior of a Leaky-Integrate-and-Fire neuron can be exploited to achieve the Linear Quadratic Regulator (LQR) control of a cartpole system. This has been shown in simulation, followed by a demonstration on a single-neuron hardware, known as Lu.i. The improvement in control performance is then demonstrated by using a population of varying numbers of neurons for similar control in the Nengo Neural Engineering Framework, on CPU and on Intel's Loihi neuromorphic chip. Finally, linear control is demonstrated for four multi-linked pendula on cart systems, using a population of neurons in Nengo, followed by an implementation of the same on Loihi. This study compares LQR control in the NEF using $7$ control and $7$ neuromorphic performance metrics, followed by a comparison with other conventional spiking and non-spiking controllers.

Paper number 30:
Title: On the Limits of Robust Control Under Adversarial Disturbances
Authors: Paul Trodden, JosÃ© M. Maestre, Hideaki Ishii
Abstract: This paper addresses a fundamental and important question in control: under what conditions does there fail to exist a robust control policy that keeps the state of a constrained linear system within a target set, despite bounded disturbances? This question has practical implications for actuator and sensor specification, feasibility analysis for reference tracking, and the design of adversarial attacks in cyber-physical systems. While prior research has predominantly focused on using optimization to compute control-invariant sets to ensure feasible operation, our work complements these approaches by characterizing explicit sufficient conditions under which robust control is fundamentally infeasible. Specifically, we derive novel closed-form, algebraic expressions that relate the size of a disturbance set -- modelled as a scaled version of a basic shape -- to the system's spectral properties and the geometry of the constraint sets.

Paper number 31:
Title: Dual-Alignment Knowledge Retention for Continual Medical Image Segmentation
Authors: Yuxin Ye, Yan Liu, Shujian Yu
Abstract: Continual learning in medical image segmentation involves sequential data acquisition across diverse domains (e.g., clinical sites), where task interference between past and current domains often leads to catastrophic forgetting. Existing continual learning methods fail to capture the complex dependencies between tasks. We introduce a novel framework that mitigates forgetting by establishing and enhancing complex dependencies between historical data and the network in the present task. Our framework features a dual-alignment strategy, the cross-network alignment (CNA) module aligns the features extracted from the bottleneck layers of the current and previous networks, respectively, while the cross-representation alignment (CRA) module aligns the features learned by the current network from historical buffered data and current input data, respectively. Implementing both types of alignment is a non-trivial task. To address this, we further analyze the linear and nonlinear forms of the well-established Hilbert-Schmidt Independence Criterion (HSIC) and deliberately design feature mapping and feature pairing blocks within the CRA module. Experiments on medical image segmentation task demonstrate our framework's effectiveness in mitigating catastrophic forgetting under domain shifts.

Paper number 32:
Title: Multipath-Enhanced Measurement of Antenna Patterns: Theory
Authors: Daniel D. Stancil
Abstract: Traditional antenna pattern measurements involve minimizing the impact of multipath propagation in the measurement environment. In contrast, this work introduces a measurement approach that uses rather than mitigates multipath propagation. This is referred to as the Multipath-Enhanced Antenna Pattern (MEAP) Measurement technique. In this respect the approach has some kinship with Multiple-Input Multiple-Output (MIMO) systems. The advantage in the case of MIMO systems is increased capacity; in the MEAP approach the advantage is elimination of the need for creating an anechoic environment. The approach uses measurements with reference antennas to calibrate the multipath channel matrix, and vector spherical harmonics for efficient pattern representation. After presenting the mathematical details of the method, numerical calculations illustrating the approach are presented. Experimental results are described in a companion paper.

Paper number 33:
Title: Multipath-Enhanced Measurement of Antenna Patterns: Experiment
Authors: Daniel D. Stancil, Alexander R. Allen
Abstract: In a companion paper we presented the theory for an antenna pattern measuring technique that uses (rather than mitigates) the properties of a multipath environment. Here we use measurements in a typical home garage to experimentally demonstrate the feasibility of the technique. A half-wavelength electric dipole with different orientations was used as both the calibration and test antennas. For simplicity, we limited the modeling of the antenna pattern to using only the three $l=1$ vector spherical harmonics. Three methods were used to analyze the measurements: a matrix inversion method using only 3 sense antennas, a least-square-error technique, and a least-square-error technique with a constant power constraint imposed. The two least-square-error techniques used the measurements from 10 sense antennas. The constrained least-square-error technique was found to give the best results.

Paper number 34:
Title: Towards Long-Range, Battery-less Water Leak Detection: A LoRa-Based Approach
Authors: Roshan Nepal, Roozbeh Abbasi, Brandon Brown, Adunni Oginni, Norman Zhou, George Shaker
Abstract: This paper presents a battery-less, self-powered water leak detection system that utilizes LoRa communication for long-range, real-time monitoring. The system harvests hydroelectric energy through a layered stack of conductive nanomaterials and metals, achieving a peak short-circuit current of over 500 mA and 1.65 V open-circuit voltage upon exposure to water. To address LoRa's higher power demands, an energy management subsystem -- comprising a DC-DC boost converter and a 100 mF supercapacitor -- ensures stable power delivery for the LLCC68 LoRa module. Experimental results demonstrate the system's ability to detect leaks as shallow as 0.5 mm, activate within 50 seconds across varying water depths, and transmit data reliably over LoRaWAN. This solution eliminates battery dependency, offering a scalable, maintenance-free approach for industrial, commercial, and residential applications, while advancing sustainable IoT infrastructure.

Paper number 35:
Title: Segmentation of separated Lumens in 3D CTA images of Aortic Dissection
Authors: Christophe Lohou, Bruno Miguel
Abstract: Aortic dissection is a serious pathology and requires an emergency management. It is characterized by one or more tears of the intimal wall of the normal blood duct of the aorta (true lumen); the blood under pressure then creates a second blood lumen (false lumen) in the media tissue. The two lumens are separated by an intimal wall, called flap. From the segmentation of connected lumens (more precisely, blood inside lumens) of an aortic dissection 3D Computed Tomography Angiography (CTA) image, our previous studies allow us to retrieve the intimal flap by using Mathematical Morphology operators, and characterize intimal tears by 3d thin surfaces that fill them, these surfaces are obtained by operating the Aktouf et al. closing algorithm proposed in the framework of Digital Topology. Indeed, intimal tears are 3D holes in the intimal flap; although it is impossible to directly segment such non-concrete data, it is nevertheless possible to "materialize" them with these 3D filling surfaces that may be quantified or make easier the visualization of these holes. In this paper, we use these surfaces that fill tears to cut connections between lumens in order to separate them. This is the first time that surfaces filling tears are used as an image processing operator (to disconnect several parts of a 3D object). This lumen separation allows us to provide one of the first cartographies of an aortic dissection, that may better visually assist physicians during their diagnosis. Our method is able to disconnect lumens, that may also lead to enhance several current investigations (registration, segmentation, hemodynamics).

Paper number 36:
Title: Performance Analysis of Data Detection in the THz-Band under Channel-Correlated Noise
Authors: Almutasem Bellah Enad, Hadi Sarieddeen, Jihad Fahs, Hakim Jemaa, Tareq Y. Al-Naffouri
Abstract: We present a comprehensive symbol error rate (SER) analysis framework for link-level terahertz (THz)-band communication systems under linear zero-forcing (ZF) data detection. First, we derive the mismatched SER for indoor THz systems under independent channel and noise assumptions, calculating the probability density function of the ratio of Gaussian noise to $\alpha$-$\mu$ channels resulting from ZF filtering. Next, we derive the precise SER under correlated channel and noise conditions, modeling dependencies using the copula method. Finally, we evaluate the SER for THz channels with correlated distortion noise from hardware impairments. Simulations demonstrate that the proposed framework corrects for multi-dB SERs resulting from the channel-noise independence assumption.

Paper number 37:
Title: Improving SAGIN Resilience to Jamming with Reconfigurable Intelligent Surfaces
Authors: Leila Marandi, Khaled Humadi, Gunes Karabulut Kurt, Wessam Ajib, Wei-Ping Zhu
Abstract: This study investigates the anti-jamming space-air-ground integrated network (SAGIN) scenario wherein a reconfigurable intelligent surface (RIS) is deployed on a fixed Unmanned Aerial Vehicle (UAV) to counteract malevolent jamming attacks. In contrast to existing research, in this paper, we consider that a Low Earth Orbit (LEO) satellite is sending the signal to the user on the ground in the presence of jamming from a Geostationary Equatorial Orbit (GEO) satellite side. We aim to maximize the signal-to-jamming plus noise ratio (SJNR) by optimizing the RIS beamforming and transmit power of the LEO satellite. Assuming the availability of global channel state information (CSI) at the RIS, we propose alternating optimization (AO) and semidefinite relaxation (SDR) techniques to address the complexity. Simulation results show that the optimization schemes lead to considerable performance improvements. The results also indicate that, given the high jamming power and the relatively small number of RIS elements, deploying the RIS on UAVs near the user is more effective in mitigating the impact of jamming interferers.

Paper number 38:
Title: Inverse Synthetic Aperture Fourier Ptychography
Authors: Matthew A. Chan, Casey J. Pellizzari, Christopher A. Metzler
Abstract: Fourier ptychography (FP) is a powerful light-based synthetic aperture imaging technique that allows one to reconstruct a high-resolution, wide field-of-view image by computationally integrating a diverse collection of low-resolution, far-field measurements. Typically, FP measurement diversity is introduced by changing the angle of the illumination or the position of the camera; either approach results in sampling different portions of the target's spatial frequency content, but both approaches introduce substantial costs and complexity to the acquisition process. In this work, we introduce Inverse Synthetic Aperture Fourier Ptychography, a novel approach to FP that foregoes changing the illumination angle or camera position and instead generates measurement diversity through target motion. Critically, we also introduce a novel learning-based method for estimating k-space coordinates from dual plane intensity measurements, thereby enabling synthetic aperture imaging without knowing the rotation of the target. We experimentally validate our method in simulation and on a tabletop optical system.

Paper number 39:
Title: Efficient streaming dynamic mode decomposition
Authors: Aditya Kale, Marcos Netto, Xinyang Zhou
Abstract: We propose a reformulation of the streaming dynamic mode decomposition method that requires maintaining a single orthonormal basis, thereby reducing computational redundancy. The proposed efficient streaming dynamic mode decomposition method results in a constant-factor reduction in computational complexity and memory storage requirements. Numerical experiments on representative canonical dynamical systems show that the enhanced computational efficiency does not compromise the accuracy of the proposed method.

Paper number 40:
Title: SHAP-AAD: DeepSHAP-Guided Channel Reduction for EEG Auditory Attention Detection
Authors: Rayan Salmi, Guorui Lu, Qinyu Chen
Abstract: Electroencephalography (EEG)-based auditory attention detection (AAD) offers a non-invasive way to enhance hearing aids, but conventional methods rely on too many electrodes, limiting wearability and comfort. This paper presents SHAP-AAD, a two-stage framework that combines DeepSHAP-based channel selection with a lightweight temporal convolutional network (TCN) for efficient AAD using fewer this http URL, an explainable AI technique, is applied to a Convolutional Neural Network (CNN) trained on topographic alpha-power maps to rank channel importance, and the top-k EEG channels are used to train a compact TCN. Experiments on the DTU dataset show that using 32 channels yields comparable accuracy to the full 64-channel setup (79.21% vs. 81.06%) on average. In some cases, even 8 channels can deliver satisfactory accuracy. These results demonstrate the effectiveness of SHAP-AAD in reducing complexity while preserving high detection performance.

Paper number 41:
Title: Robust Node Localization for Rough and Extreme Deployment Environments
Authors: Abiy Tasissa, Waltenegus Dargie
Abstract: Many applications have been identified which require the deployment of large-scale low-power wireless sensor networks. Some of the deployment environments, however, impose harsh operation conditions due to intense cross-technology interference, extreme weather conditions (heavy rainfall, excessive heat, etc.), or rough motion, thereby affecting the quality and predictability of the wireless links the nodes establish. In localization tasks, these conditions often lead to significant errors in estimating the position of target nodes. Motivated by the practical deployments of sensors on the surface of different water bodies, we address the problem of identifying susceptible nodes and robustly estimating their positions. We formulate these tasks as a compressive sensing problem and propose algorithms for both node identification and robust estimation. Additionally, we design an optimal anchor configuration to maximize the robustness of the position estimation task. Our numerical results and comparisons with competitive methods demonstrate that the proposed algorithms achieve both objectives with a modest number of anchors. Since our method relies only on target-to-anchor distances, it is broadly applicable and yields resilient, robust localization.

Paper number 42:
Title: A Variational Bayesian Detector for Affine Frequency Division Multiplexing
Authors: Can Zheng, Chung G. Kang
Abstract: This paper proposes a variational Bayesian (VB) detector for affine frequency division multiplexing (AFDM) systems. The proposed method estimates the symbol probability distribution by minimizing the Kullback-Leibler (KL) divergence between the true posterior and an approximate distribution, thereby enabling low-complexity soft-decision detection. Compared to conventional approaches such as zero-forcing (ZF), Linear minimum mean square rrror (LMMSE), and the message passing algorithm (MPA), the proposed detector demonstrates lower bit error rates (BER), faster convergence, and improved robustness under complex multipath channels. Simulation results confirm its dual advantages in computational efficiency and detection performance.

Paper number 43:
Title: Modeling and control of a low-cost multirotor hybrid aerial underwater vehicle
Authors: RenKai Wang, ZhiGang Shang
Abstract: This paper presents a comprehensive modeling and control framework for a low-cost multirotor hybrid aerial-aquatic vehicle (MHAUV) capable of seamless air-water transitions. A hybrid dynamics model is proposed to account for the distinct hydrodynamic and aerodynamic forces across three operational zones: aerial, aquatic, and transitional hybrid regions. The model incorporates variable buoyancy, added mass effects, and fluid resistance, with thrust characteristics of submerged propellers analyzed through computational fluid dynamics (CFD) simulations. A hierarchical control strategy is developed, combining twisting sliding mode control (TWSMC) for robust attitude stabilization during medium transitions with cascade PID controllers for precise motion tracking in homogeneous media. Experimental validation using a modified FPV quadrotor prototype demonstrates the effectiveness of the approach, achieving steady-state height errors below 0.1 m and attitude fluctuations under 5Â° during repeated water-crossing maneuvers. The results highlight the system's adaptability to fluid medium variations while maintaining cost-effectiveness and operational simplicity.

Paper number 44:
Title: PLUS: Plug-and-Play Enhanced Liver Lesion Diagnosis Model on Non-Contrast CT Scans
Authors: Jiacheng Hao, Xiaoming Zhang, Wei Liu, Xiaoli Yin, Yuan Gao, Chunli Li, Ling Zhang, Le Lu, Yu Shi, Xu Han, Ke Yan
Abstract: Focal liver lesions (FLL) are common clinical findings during physical examination. Early diagnosis and intervention of liver malignancies are crucial to improving patient survival. Although the current 3D segmentation paradigm can accurately detect lesions, it faces limitations in distinguishing between malignant and benign liver lesions, primarily due to its inability to differentiate subtle variations between different lesions. Furthermore, existing methods predominantly rely on specialized imaging modalities such as multi-phase contrast-enhanced CT and magnetic resonance imaging, whereas non-contrast CT (NCCT) is more prevalent in routine abdominal imaging. To address these limitations, we propose PLUS, a plug-and-play framework that enhances FLL analysis on NCCT images for arbitrary 3D segmentation models. In extensive experiments involving 8,651 patients, PLUS demonstrated a significant improvement with existing methods, improving the lesion-level F1 score by 5.66%, the malignant patient-level F1 score by 6.26%, and the benign patient-level F1 score by 4.03%. Our results demonstrate the potential of PLUS to improve malignant FLL screening using widely available NCCT imaging substantially.

Paper number 45:
Title: Traceable TTS: Toward Watermark-Free TTS with Strong Traceability
Authors: Yuxiang Zhao, Yunchong Xiao, Yushen Chen, Zhikang Niu, Shuai Wang, Kai Yu, Xie Chen
Abstract: Recent advances in Text-To-Speech (TTS) technology have enabled synthetic speech to mimic human voices with remarkable realism, raising significant security concerns. This underscores the need for traceable TTS models-systems capable of tracing their synthesized speech without compromising quality or security. However, existing methods predominantly rely on explicit watermarking on speech or on vocoder, which degrades speech quality and is vulnerable to spoofing. To address these limitations, we propose a novel framework for model attribution. Instead of embedding watermarks, we train the TTS model and discriminator using a joint training method that significantly improves traceability generalization while preserving-and even slightly improving-audio quality. This is the first work toward watermark-free TTS with strong traceability. To promote progress in related fields, we will release the code upon acceptance of the paper.

Paper number 46:
Title: Prosody Labeling with Phoneme-BERT and Speech Foundation Models
Authors: Tomoki Koriyama
Abstract: This paper proposes a model for automatic prosodic label annotation, where the predicted labels can be used for training a prosody-controllable text-to-speech model. The proposed model utilizes not only rich acoustic features extracted by a self-supervised-learning (SSL)-based model or a Whisper encoder, but also linguistic features obtained from phoneme-input pretrained linguistic foundation models such as PnG BERT and PL-BERT. The concatenation of acoustic and linguistic features is used to predict phoneme-level prosodic labels. In the experimental evaluation on Japanese prosodic labels, including pitch accents and phrase break indices, it was observed that the combination of both speech and linguistic foundation models enhanced the prediction accuracy compared to using either a speech or linguistic input alone. Specifically, we achieved 89.8% prediction accuracy in accent labels, 93.2% in high-low pitch accents, and 94.3% in break indices.

Paper number 47:
Title: EdgeSRIE: A hybrid deep learning framework for real-time speckle reduction and image enhancement on portable ultrasound systems
Authors: Hyunwoo Cho, Jongsoo Lee, Jinbum Kang, Yangmo Yoo
Abstract: Speckle patterns in ultrasound images often obscure anatomical details, leading to diagnostic uncertainty. Recently, various deep learning (DL)-based techniques have been introduced to effectively suppress speckle; however, their high computational costs pose challenges for low-resource devices, such as portable ultrasound systems. To address this issue, EdgeSRIE, which is a lightweight hybrid DL framework for real-time speckle reduction and image enhancement in portable ultrasound imaging, is introduced. The proposed framework consists of two main branches: an unsupervised despeckling branch, which is trained by minimizing a loss function between speckled images, and a deblurring branch, which restores blurred images to sharp images. For hardware implementation, the trained network is quantized to 8-bit integer precision and deployed on a low-resource system-on-chip (SoC) with limited power consumption. In the performance evaluation with phantom and in vivo analyses, EdgeSRIE achieved the highest contrast-to-noise ratio (CNR) and average gradient magnitude (AGM) compared with the other baselines (different 2-rule-based methods and other 4-DL-based methods). Furthermore, EdgeSRIE enabled real-time inference at over 60 frames per second while satisfying computational requirements (< 20K parameters) on actual portable ultrasound hardware. These results demonstrated the feasibility of EdgeSRIE for real-time, high-quality ultrasound imaging in resource-limited environments.

Paper number 48:
Title: Structure from Noise: Confirmation Bias in Particle Picking in Structural Biology
Authors: Amnon Balanov, Alon Zabatani, Tamir Bendory
Abstract: Confirmation bias is a fundamental challenge in cryo-electron microscopy (cryo-EM) and cryo-electron tomography (cryo-ET), where prior expectations can lead to systematic errors in data interpretation. This bias may emerge at multiple stages of the reconstruction pipeline, and in particular in the critical particle picking stage, where 2D particles (in cryo-EM) or 3D subtomograms (in cryo-ET) are extracted from highly noisy micrographs or tomograms. Focusing on two widely used methodologies, template matching and deep neural networks, we combine theoretical analysis with controlled experiments to demonstrate that both methods, when applied to pure noise, can produce persistent molecular structures, a phenomenon we term structure from noise. This artifact highlights a critical vulnerability in current workflows: the potential for particle-picking algorithms to inject strong prior-driven bias into downstream analyses. We then propose practical mitigation strategies to reduce the impact of such biases. Together, our findings deepen the theoretical understanding of confirmation bias in cryo-EM and cryo-ET and call for cautious interpretation of reconstructions, primarily when relying on template-driven particle picking.

Paper number 49:
Title: SAFERad: A Framework to Enable Radar Data for Safety-Relevant Perception Tasks
Authors: Tim BrÃ¼hl, Jenny GlÃ¶nkler, Robin Schwager, Tin Stribor Sohn, Tim Dieter Eberhardt, SÃ¶ren Hohmann
Abstract: Radar sensors play a crucial role for perception systems in automated driving but suffer from a high level of noise. In the past, this could be solved by strict filters, which remove most false positives at the expense of undetected objects. Future highly automated functions are much more demanding with respect to error rate. Hence, if the radar sensor serves as a component of perception systems for such functions, a simple filter strategy cannot be applied. In this paper, we present a modified filtering approach which is characterized by the idea to vary the filtering depending on the potential of harmful collision with the object which is potentially represented by the radar point. We propose an algorithm which determines a criticality score for each point based on the planned or presumable trajectory of the automated vehicle. Points identified as very critical can trigger manifold actions to confirm or deny object presence. Our pipeline introduces criticality regions. The filter threshold in these criticality regions is omitted. Commonly known radar data sets do not or barely feature critical scenes. Thus, we present an approach to evaluate our framework by adapting the planned trajectory towards vulnerable road users, which serve as ground truth critical points. Evaluation of the criticality metric prove high recall rates. Besides, our post-processing algorithm lowers the rate of non-clustered critical points by 74.8 % in an exemplary setup compared to a moderate, generic filter.

Paper number 50:
Title: MMOC: Self-Supervised EEG Emotion Recognition Framework with Multi-Model Online Collaboration
Authors: Hanqi Wang, Yang Liu, Peng Ye, Liang Song
Abstract: Electroencephalography (EEG) emotion recognition plays a crucial role in human-computer interaction, particularly in healthcare and neuroscience. While supervised learning has been widely used, its reliance on manual annotations introduces high costs and potential bias. Self-supervised learning (SSL) offers a promising alternative by generating labels through pretext tasks. However, high inter-subject variability in EEG signals leads to significant data drift, limiting self-supervised models' generalization across unseen subjects. Traditional domain adaptation (DA) methods require access to target-domain data during training. Although domain generalization (DG) avoids this constraint, it often falls short in handling complex data drift due to limited coverage of possible target distributions. To tackle these challenges, we propose MMOC, a self-supervised framework with multi-model online collaboration (MMOC), to achieve online adaptation to unseen data. MMOC trains multiple base models using diverse strategies rooted in reconstruction and contrastive learning, enabling each model to develop distinct generalization capabilities. During inference, MMOC dynamically activates the most suitable model for each test sample via a loss-based routing mechanism that evaluates both contrastive and reconstruction losses. This dual consideration allows for a comprehensive measurement of data drift at both structural and semantic levels. Experimental results on the SEED and Dreamer datasets show that MMOC achieves state-of-the-art performance: 85.39% on SEED, and 68.77% and 69.37% on Dreamer arousal and valence dimensions, respectively. MMOC effectively mitigates inter-subject data drift, offering a practical solution for real-world EEG emotion recognition.

Paper number 51:
Title: An Efficient Detector for Faulty GNSS Measurements Detection With Non-Gaussian Noises
Authors: Penggao Yan, Baoshan Song, Xiao Xia, Weisong Wen, Li-Ta Hsu
Abstract: Fault detection is crucial to ensure the reliability of navigation systems. However, mainstream fault detection methods are developed based on Gaussian assumptions on nominal errors, while current attempts at non-Gaussian fault detection are either heuristic or lack rigorous statistical properties. The performance and reliability of these methods are challenged in real-world applications. This paper proposes the jackknife detector, a fault detection method tailored for linearized pseudorange-based positioning systems under non-Gaussian nominal errors. Specifically, by leveraging the jackknife technique, a test statistic is derived as a linear combination of measurement errors, eliminating the need for restrictive distributional assumptions while maintaining computational efficiency. A hypothesis test with the Bonferroni correction is then constructed to detect potential faults in measurements. Theoretical analysis proves the equivalence between the jackknife detector and the solution separation (SS) detector, while revealing the former's superior computational efficiency. Through a worldwide simulation and a real-world satellite clock anomaly detection experiment--both involving non-Gaussian nominal errors--the proposed jackknife detector demonstrates equivalent detection performance to the SS detector but achieves a fourfold improvement in computational efficiency. These results highlight the jackknife detector's substantial potential for real-time applications requiring robust and efficient fault detection in non-Gaussian noise environments.

Paper number 52:
Title: PASC-Net:Plug-and-play Shape Self-learning Convolutions Network with Hierarchical Topology Constraints for Vessel Segmentation
Authors: Xiao Zhang, Zhuo Jin, Shaoxuan Wu, Fengyu Wang, Guansheng Peng, Xiang Zhang, Ying Huang, JingKun Chen, Jun Feng
Abstract: Accurate vessel segmentation is crucial to assist in clinical diagnosis by medical experts. However, the intricate tree-like tubular structure of blood vessels poses significant challenges for existing segmentation algorithms. Small vascular branches are often overlooked due to their low contrast compared to surrounding tissues, leading to incomplete vessel segmentation. Furthermore, the complex vascular topology prevents the model from accurately capturing and reconstructing vascular structure, resulting in incorrect topology, such as breakpoints at the bifurcation of the vascular tree. To overcome these challenges, we propose a novel vessel segmentation framework called PASC Net. It includes two key modules: a plug-and-play shape self-learning convolutional (SSL) module that optimizes convolution kernel design, and a hierarchical topological constraint (HTC) module that ensures vascular connectivity through topological constraints. Specifically, the SSL module enhances adaptability to vascular structures by optimizing conventional convolutions into learnable strip convolutions, which improves the network's ability to perceive fine-grained features of tubular anatomies. Furthermore, to better preserve the coherence and integrity of vascular topology, the HTC module incorporates hierarchical topological constraints-spanning linear, planar, and volumetric levels-which serve to regularize the network's representation of vascular continuity and structural consistency. We replaced the standard convolutional layers in U-Net, FCN, U-Mamba, and nnUNet with SSL convolutions, leading to consistent performance improvements across all architectures. Furthermore, when integrated into the nnUNet framework, our method outperformed other methods on multiple metrics, achieving state-of-the-art vascular segmentation performance.

Paper number 53:
Title: Differentiable High-Performance Ray Tracing-Based Simulation of Radio Propagation with Point Clouds
Authors: Niklas Vaara, Pekka Sangi, Miguel Bordallo LÃ³pez, Janne HeikkilÃ¤
Abstract: Ray tracing is a widely used deterministic method for radio propagation simulations, capable of producing physically accurate multipath components. The accuracy depends on the quality of the environment model and its electromagnetic properties. Recent advances in computer vision and machine learning have made it possible to reconstruct detailed environment models augmented with semantic segmentation labels. In this letter, we propose a differentiable ray tracing-based radio propagation simulator that operates directly on point clouds. We showcase the efficiency of our method by simulating multi-bounce propagation paths with up to five interactions with specular reflections and diffuse scattering in two indoor scenarios, each completing in less than 90 ms. Lastly, we demonstrate how the differentiability of electromagnetic computations can be combined with segmentation labels to learn the electromagnetic properties of the environment.

Paper number 54:
Title: CSI-Free Symbol Detection for Atomic MIMO Receivers via In-Context Learning
Authors: Zihang Song, Qihao Peng, Pei Xiao, Bipin Rajendran, Osvaldo Simeone
Abstract: Atomic receivers based on Rydberg vapor cells as sensors of electromagnetic fields offer a promising alternative to conventional radio frequency front-ends. In multi-antenna configurations, the magnitude-only, phase-insensitive measurements produced by atomic receivers pose challenges for traditional detection methods. Existing solutions rely on two-step iterative optimization processes, which suffer from cascaded channel estimation errors and high computational complexity. We propose a channel state information (CSI)-free symbol detection method based on in-context learning (ICL), which directly maps pilot-response pairs to data symbol predictions without explicit channel estimation. Simulation results show that ICL achieves competitive accuracy with {higher computational efficiency} compared to existing solutions.

Paper number 55:
Title: MMMOS: Multi-domain Multi-axis Audio Quality Assessment
Authors: Yi-Cheng Lin, Jia-Hung Chen, Hung-yi Lee
Abstract: Accurate audio quality estimation is essential for developing and evaluating audio generation, retrieval, and enhancement systems. Existing non-intrusive assessment models predict a single Mean Opinion Score (MOS) for speech, merging diverse perceptual factors and failing to generalize beyond speech. We propose MMMOS, a no-reference, multi-domain audio quality assessment system that estimates four orthogonal axes: Production Quality, Production Complexity, Content Enjoyment, and Content Usefulness across speech, music, and environmental sounds. MMMOS fuses frame-level embeddings from three pretrained encoders (WavLM, MuQ, and M2D) and evaluates three aggregation strategies with four loss functions. By ensembling the top eight models, MMMOS shows a 20-30% reduction in mean squared error and a 4-5% increase in Kendall's {\tau} versus baseline, gains first place in six of eight Production Complexity metrics, and ranks among the top three on 17 of 32 challenge metrics.

Paper number 56:
Title: Ambisonics Encoder for Wearable Array with Improved Binaural Reproduction
Authors: Yhonatan Gayer, Vladimir Tourbabin, Zamir Ben-Hur, David Alon, Boaz Rafaely
Abstract: Ambisonics Signal Matching (ASM) is a recently proposed signal-independent approach to encoding Ambisonic signal from wearable microphone arrays, enabling efficient and standardized spatial sound reproduction. However, reproduction accuracy is currently limited due to the non-ideal layout of the microphones. This research introduces an enhanced ASM encoder that reformulates the loss function by integrating a Binaural Signal Matching (BSM) term into the optimization framework. The aim of this reformulation is to improve the accuracy of binaural reproduction when integrating the Ambisonic signal with Head-Related Transfer Functions (HRTFs), making the encoded Ambisonic signal better suited for binaural reproduction. This paper first presents the mathematical formulation developed to align the ASM and BSM objectives in a single loss function, followed by a simulation study with a simulated microphone array mounted on a rigid sphere representing a head-mounted wearable array. The analysis shows that improved binaural reproduction with the encoded Ambisonic signal can be achieved using this joint ASM-BSM optimization, thereby enabling higher-quality binaural playback for virtual and augmented reality applications based on Ambisonics.

Paper number 57:
Title: Experimental Demonstration of Computational AoA Detection Using Conformal Frequency Diverse Metasurface Antennas
Authors: Idban Alamzadeh, Michael Inman, Mohammadreza F. Imani
Abstract: Devices that detect angle-of-arrival (AoA) over a wide field of view are crucial for various applications such as wireless communication and navigation. They are often installed on platforms with challenging mechanical and stealth constraints like vehicles, drones, and helmets, where traditional methods -- mechanically rotating antennas or conformal arrays -- tend to be bulky, heavy, and costly. A recent work has proposed a conformal frequency diverse antenna that is designed to produce angularly diverse patterns that encode angular information into frequency sweeps. This capability allows AoA to be determined across the entire horizon using only two receiving units. This paper experimentally validates this concept, detailing the prototyping process and practical design considerations. The AoA detection capabilities of the proposed device are confirmed through experimental demonstrations. The proposed conformal metasurfaces offer an alternative hardware solution for sensing over large fields of view, with potential applications in radar sensing, situational awareness, and navigation.

Paper number 58:
Title: The Frequency Response of Networks as Open Systems
Authors: Amirhossein Nazerian, Malbor Asllani, Melvyn Tyloo, Wai Lim Ku, Francesco Sorrentino
Abstract: Many biological, technological, and social systems are effectively networks of interacting individual systems. Typically, these networks are not isolated objects, but interact with their environment through both signals and information that is received by specific nodes with an input function or released to the environment by other nodes with an output function. An important question is whether the structure of different networks, together with the particular selection of input and output nodes, is such that it favors the passing or blocking of such signals. For a given network and a given choice of the input and output nodes, the H2-norm provides a natural and general quantification of the extent to which input signals-whether deterministic or stochastic, periodic or arbitrary-are amplified. We analyze a diverse set of empirical networks and conjecture that many naturally occurring systems-such as food webs, signaling pathways, and gene regulatory circuits-are structurally organized to enhance the passing of signals, facilitating the efficient flow of biomass, information, or regulatory activity. This passing behavior culminates in directed acyclic graphs (DAGs), for which we analytically show that amplification depends on the number and length of input-output pathways, which is consistent with the well-known tendency of naturally emerging networks to approximate DAG structures. In contrast, the structure of engineered systems like power grids appears to be intentionally designed to suppress signal propagation, as the transmitted quantity-voltage phase differences-requires tight control to maintain synchronized operation.

Paper number 59:
Title: On the Dynamics of Control
Authors: Rachit Mehra, M Parimi, S.R. Wagh, Navdeep M Singh
Abstract: We present a dynamical system approach for the control of a nonlinear dynamical system by defining the control problem in a Fiber bundle framework. The constructive procedure derived results in the generation of a NHIM/NAIM which facilitates the use of tools and ideas from dynamical system theory to analyze and understand the properties associated with the controlled system. The time scale separation, decoupling of system dynamics, and their role in the system behavior are analyzed. An overview of the benefits of the above approach is demonstrated by briefly discussing three main application areas.

Paper number 60:
Title: Adaptive Resource Management in Cognitive Radar via Deep Deterministic Policy Gradient
Authors: Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney
Abstract: In this paper, scanning for target detection, and multi-target tracking in a cognitive radar system are considered, and adaptive radar resource management is investigated. In particular, time management for radar scanning and tracking of multiple maneuvering targets subject to budget constraints is studied with the goal to jointly maximize the tracking and scanning performances of a cognitive radar. We tackle the constrained optimization problem of allocating the dwell time to track individual targets by employing a deep deterministic policy gradient (DDPG) based reinforcement learning approach. We propose a constrained deep reinforcement learning (CDRL) algorithm that updates the DDPG neural networks and dual variables simultaneously. Numerical results show that the radar can autonomously allocate time appropriately so as to maximize the reward function without exceeding the time constraint.

Paper number 61:
Title: Grid-Reg: Grid-Based SAR and Optical Image Registration Across Platforms
Authors: Xiaochen Wei, Weiwei Guo, Zenghui Zhang, Wenxian Yu
Abstract: Registering airborne SAR with spaceborne optical images is crucial for SAR image interpretation and geo-localization. It is challenging for this cross-platform heterogeneous image registration due to significant geometric and radiation differences, which current methods fail to handle. To tackle these challenges, we propose a novel grid-based multimodal registration framework (Grid-Reg) across airborne and space-born platforms, including a new domain-robust descriptor extraction network, Hybrid Siamese Correlation Metric Learning Network (HSCMLNet) and a grid-based solver (Grid-solver) for transformation parameters estimation. Our Grid-Reg is based on detector-free and global matching loss rather than accurate keypoint correspondences. These accurate correspondences are inherently difficult in heterogeneous images with large geometric deformation. By Grid-Solver, our Grid-Reg estimates transformation parameters by optimizing robust global matching loss-based patch correspondences of whole images in a coarse-to-fine strategy. To robustly calculate the similarity between patches, specifically that have noise and change objects, we propose HSCMLNet, including a hybrid Siamese module to extract high-level features of multimodal images and a correlation learning module (CMLModule) based equiangular unit basis vectors (EUBVs). Moreover, we propose a manifold loss EUBVsLoss to constrain the normalized correlation between local embeddings of patches and EUBVs. Furthermore, we curate a new challenging benchmark dataset of SAR-to-optical registration using real-world UAV MiniSAR data and optical images from Google Earth. We extensively analyze factors affecting registration accuracy and compare our method with state-of-the-art techniques on this dataset, showing superior performance.

Paper number 62:
Title: Deep-Learning-Assisted Highly-Accurate COVID-19 Diagnosis on Lung Computed Tomography Images
Authors: Yinuo Wang, Juhyun Bae, Ka Ho Chow, Shenyang Chen, Shreyash Gupta
Abstract: COVID-19 is a severe and acute viral disease that can cause symptoms consistent with pneumonia in which inflammation is caused in the alveolous regions of the lungs leading to a build-up of fluid and breathing difficulties. Thus, the diagnosis of COVID using CT scans has been effective in assisting with RT-PCR diagnosis and severity classifications. In this paper, we proposed a new data quality control pipeline to refine the quality of CT images based on GAN and sliding windows. Also, we use class-sensitive cost functions including Label Distribution Aware Loss(LDAM Loss) and Class-balanced(CB) Loss to solve the long-tail problem existing in datasets. Our model reaches more than 0.983 MCC in the benchmark test dataset.

Paper number 63:
Title: The Overview of Segmental Durations Modification Algorithms on Speech Signal Characteristics
Authors: Kyeomeun Jang, Jiaying Li, Yinuo Wang
Abstract: This paper deeply evaluates and analyzes several mainstream algorithms that can arbitrarily modify the duration of any portion of a given speech signal without changing the essential properties (e.g., pitch contour, power spectrum, etc.) of the original signal. Arbitrary modification in this context means that the duration of any region of the signal can be changed by specifying the starting and ending time for modification or the target duration of the specified interval, which can be either a fixed value of duration in the time domain or a scaling factor of the original duration. In addition, arbitrary modification also indicates any number of intervals can be modified at the same time.

Paper number 64:
Title: High-Availability Integrity Monitoring for Multi-Constellation GNSS Navigation with Non-Gaussian Errors
Authors: Penggao Yan, Ronghe Jin, Junyi Zhang, Cheng-Wei Wang, Li-Ta Hsu
Abstract: Global navigation satellite systems (GNSS) are essential for aviation, requiring strict integrity monitoring to alert users to hazardously misleading information. Conventional receiver autonomous integrity monitoring (RAIM) and advanced RAIM (ARAIM) rely heavily on Gaussian models in bounding nominal errors, which can be overly conservative with real-world non-Gaussian errors with heavy tails, such as the satellite clock and orbit errors. This paper proposes an extended jackknife detector capable of detecting multiple simultaneous faults with non-Gaussian nominal errors. Furthermore, an integrity monitoring algorithm, jackknife ARAIM, is developed by systematically exploiting the properties of the jackknife detector in the range domain. A tight bound of the integrity risk is derived by quantifying the impacts of hypothetical fault vectors on the position solution. The proposed method is examined in worldwide simulations, with the nominal measurement error simulated based on authentic experimental data, which reveals different findings in existing research. In a setting of a single Global Positioning System (GPS) constellation, the proposed method reduces the 99.5 percentile vertical protection level (VPL) 45m, where the VPL of the baseline ARAIM is larger than 50m in most user locations. For dual-constellation (GPS-Galileo) settings, baseline ARAIM suffers VPL inflation over 60m due to the over-conservatism induced by the heavy-tailed Galileo signal-in-space range errors, whereas the proposed jackknife ARAIM retains VPL below 40m, achieving over 92% normal operations for a 35m Vertical Alert Limit. These improvements have promising potential to support localizer performance with vertical guidance (LPV) with a decision height of 200 ft, enhancing integrity and availability for multi-constellation GNSS applications.

Paper number 65:
Title: Near-Field ISAC for THz Wireless Systems
Authors: Fan Zhang, Tianqi Mao, Mingkun Li, Meng Hua, Jinshu Chen, Christos Masouros, Zhaocheng Wang
Abstract: Sixth-generation (6G) wireless networks are expected not only to provide high-speed connectivity but also to support reliable sensing capabilities, giving rise to the integrated sensing and communication (ISAC) paradigm. To enable higher data rates and more accurate sensing, terahertz (THz) systems empowered by extremely large multiple-input-multiple-output (XL-MIMO) technology are envisioned as key enablers for future ISAC systems. Owing to the substantial increase in both effective array aperture and carrier frequency, a considerable portion of future ISAC applications is anticipated to fall within the near-field coverage region, instead of the conventional far-field. However, most existing ISAC techniques are designed under the far-field planar wave assumption, struggling to accommodate the unique characteristics of THz near-field propagation. To motivate future research into near-field ISAC research, we systematically investigate the characteristics of THz near-field propagation and explore its potential to facilitate ISAC systems. Specifically, we analyze three fundamental characteristics of THz near-field propagation and review state-of-the-art techniques that exploit these features to boost both communication and sensing performance. To further harness the angular-range coupling effect, we zoom into a particularly interesting approach to near-field sensing based on wavenumber domain. Besides, to exploit the beam squint effect, an ISAC resource allocation framework is introduced to support integrated multi-angle sensing and multi-user communication. Finally, we outline promising directions for future research in this emerging area.

Paper number 66:
Title: Surg-SegFormer: A Dual Transformer-Based Model for Holistic Surgical Scene Segmentation
Authors: Fatimaelzahraa Ahmed, Muraam Abdel-Ghani, Muhammad Arsalan, Mahmoud Ali, Abdulaziz Al-Ali, Shidin Balakrishnan
Abstract: Holistic surgical scene segmentation in robot-assisted surgery (RAS) enables surgical residents to identify various anatomical tissues, articulated tools, and critical structures, such as veins and vessels. Given the firm intraoperative time constraints, it is challenging for surgeons to provide detailed real-time explanations of the operative field for trainees. This challenge is compounded by the scarcity of expert surgeons relative to trainees, making the unambiguous delineation of go- and no-go zones inconvenient. Therefore, high-performance semantic segmentation models offer a solution by providing clear postoperative analyses of surgical procedures. However, recent advanced segmentation models rely on user-generated prompts, rendering them impractical for lengthy surgical videos that commonly exceed an hour. To address this challenge, we introduce Surg-SegFormer, a novel prompt-free model that outperforms current state-of-the-art techniques. Surg-SegFormer attained a mean Intersection over Union (mIoU) of 0.80 on the EndoVis2018 dataset and 0.54 on the EndoVis2017 dataset. By providing robust and automated surgical scene comprehension, this model significantly reduces the tutoring burden on expert surgeons, empowering residents to independently and effectively understand complex surgical environments.

Paper number 67:
Title: CLIP-RL: Surgical Scene Segmentation Using Contrastive Language-Vision Pretraining & Reinforcement Learning
Authors: Fatmaelzahraa Ali Ahmed, Muhammad Arsalan, Abdulaziz Al-Ali, Khalid Al-Jalham, Shidin Balakrishnan
Abstract: Understanding surgical scenes can provide better healthcare quality for patients, especially with the vast amount of video data that is generated during MIS. Processing these videos generates valuable assets for training sophisticated models. In this paper, we introduce CLIP-RL, a novel contrastive language-image pre-training model tailored for semantic segmentation for surgical scenes. CLIP-RL presents a new segmentation approach which involves reinforcement learning and curriculum learning, enabling continuous refinement of the segmentation masks during the full training pipeline. Our model has shown robust performance in different optical settings, such as occlusions, texture variations, and dynamic lighting, presenting significant challenges. CLIP model serves as a powerful feature extractor, capturing rich semantic context that enhances the distinction between instruments and tissues. The RL module plays a pivotal role in dynamically refining predictions through iterative action-space adjustments. We evaluated CLIP-RL on the EndoVis 2018 and EndoVis 2017 datasets. CLIP-RL achieved a mean IoU of 81%, outperforming state-of-the-art models, and a mean IoU of 74.12% on EndoVis 2017. This superior performance was achieved due to the combination of contrastive learning with reinforcement learning and curriculum learning.

Paper number 68:
Title: Optimal Sizing and Control of a Grid-Connected Battery in a Stacked Revenue Model Including an Energy Community
Authors: Tudor Octavian Pocola, Valentin Robu, Jip Rietveld, Sonam Norbu, Benoit Couraud, Merlinda Andoni, David Flynn, H. Vincent Poor
Abstract: Recent years have seen rapid increases in intermittent renewable generation, requiring novel battery energy storage systems (BESS) solutions. One recent trend is the emergence of large grid-connected batteries, that can be controlled to provide multiple storage and flexibility services, using a stacked revenue model. Another emerging development is renewable energy communities (REC), in which prosumers invest in their own renewable generation capacity, but also requiring battery storage for flexibility. In this paper, we study settings in which energy communities rent battery capacity from a battery operator through a battery-as-a-service (BaaS) model. We present a methodology for determining the sizing and pricing of battery capacity that can be rented, such that it provides economic benefits to both the community and the battery operator that participates in the energy market. We examine how sizes and prices vary across a number of different scenarios for different types of tariffs (flat, dynamic) and competing energy market uses. Second, we conduct a systematic study of linear optimization models for battery control when deployed to provide flexibility to energy communities. We show that existing approaches for battery control with daily time windows have a number of important limitations in practical deployments, and we propose a number of regularization functions in the optimization to address them. Finally, we investigate the proposed method using real generation, demand, tariffs, and battery data, based on a practical case study from a large battery operator in the Netherlands. For the settings in our case study, we find that a community of 200 houses with a 330 kW wind turbine can save up to 12,874 euros per year by renting just 280 kWh of battery capacity (after subtracting battery rental costs), with the methodology applicable to a wide variety of settings and tariff types.

Paper number 69:
Title: Improving Action Smoothness for a Cascaded Online Learning Flight Control System
Authors: Yifei Li, Erik-jan van Kampen
Abstract: This paper aims to improve the action smoothness of a cascaded online learning flight control system. Although the cascaded structure is widely used in flight control design, its stability can be compromised by oscillatory control actions, which poses challenges for practical engineering applications. To address this issue, we introduce an online temporal smoothness technique and a low-pass filter to reduce the amplitude and frequency of the control actions. Fast Fourier Transform (FFT) is used to analyze policy performance in the frequency domain. Simulation results demonstrate the improvements achieved by the two proposed techniques.

Paper number 70:
Title: Long-Context Modeling Networks for Monaural Speech Enhancement: A Comparative Study
Authors: Qiquan Zhang, Moran Chen, Zeyang Song, Hexin Liu, Xiangyu Zhang, Haizhou Li
Abstract: Advanced long-context modeling backbone networks, such as Transformer, Conformer, and Mamba, have demonstrated state-of-the-art performance in speech enhancement. However, a systematic and comprehensive comparative study of these backbones within a unified speech enhancement framework remains lacking. In addition, xLSTM, a more recent and efficient variant of LSTM, has shown promising results in language modeling and as a general-purpose vision backbone. In this paper, we investigate the capability of xLSTM in speech enhancement, and conduct a comprehensive comparison and analysis of the Transformer, Conformer, Mamba, and xLSTM backbones within a unified framework, considering both causal and noncausal configurations. Overall, xLSTM and Mamba achieve better performance than Transformer and Conformer. Mamba demonstrates significantly superior training and inference efficiency, particularly for long speech inputs, whereas xLSTM suffers from the slowest processing speed.

Paper number 71:
Title: ViTaL: A Multimodality Dataset and Benchmark for Multi-pathological Ovarian Tumor Recognition
Authors: You Zhou, Lijiang Chen, Guangxia Cui, Wenpei Bai, Yu Guo, Shuchang Lyu, Guangliang Cheng, Qi Zhao
Abstract: Ovarian tumor, as a common gynecological disease, can rapidly deteriorate into serious health crises when undetected early, thus posing significant threats to the health of women. Deep neural networks have the potential to identify ovarian tumors, thereby reducing mortality rates, but limited public datasets hinder its progress. To address this gap, we introduce a vital ovarian tumor pathological recognition dataset called \textbf{ViTaL} that contains \textbf{V}isual, \textbf{T}abular and \textbf{L}inguistic modality data of 496 patients across six pathological categories. The ViTaL dataset comprises three subsets corresponding to different patient data modalities: visual data from 2216 two-dimensional ultrasound images, tabular data from medical examinations of 496 patients, and linguistic data from ultrasound reports of 496 patients. It is insufficient to merely distinguish between benign and malignant ovarian tumors in clinical practice. To enable multi-pathology classification of ovarian tumor, we propose a ViTaL-Net based on the Triplet Hierarchical Offset Attention Mechanism (THOAM) to minimize the loss incurred during feature fusion of multi-modal data. This mechanism could effectively enhance the relevance and complementarity between information from different modalities. ViTaL-Net serves as a benchmark for the task of multi-pathology, multi-modality classification of ovarian tumors. In our comprehensive experiments, the proposed method exhibited satisfactory performance, achieving accuracies exceeding 90\% on the two most common pathological types of ovarian tumor and an overall performance of 85\%. Our dataset and code are available at this https URL.

Paper number 72:
Title: Context-Aware Deep Learning for Robust Channel Extrapolation in Fluid Antenna Systems
Authors: Yanliang Jin, Runze Yu, Yuan Gao, Shengli Liu, Xiaoli Chu, Kai-Kit Wong, Chan-Byoung Chae
Abstract: Fluid antenna systems (FAS) offer remarkable spatial flexibility but face significant challenges in acquiring high-resolution channel state information (CSI), leading to considerable overhead. To address this issue, we propose CANet, a robust deep learning model for channel extrapolation in FAS. CANet combines context-adaptive modeling with a cross-scale attention mechanism and is built on a ConvNeXt v2 backbone to improve extrapolation accuracy for unobserved antenna ports. To further enhance robustness, we introduce a novel spatial amplitude perturbation strategy, inspired by frequency-domain augmentation techniques in image processing. This motivates the incorporation of a Fourier-domain loss function, capturing frequency-domain consistency, alongside a spectral structure consistency loss that reinforces learning stability under perturbations. Our simulation results demonstrate that CANet outperforms benchmark models across a wide range of signal-to-noise ratio (SNR) levels.

Paper number 73:
Title: Dynamic Frequency Feature Fusion Network for Multi-Source Remote Sensing Data Classification
Authors: Yikang Zhao, Feng Gao, Xuepeng Jin, Junyu Dong, Qian Du
Abstract: Multi-source data classification is a critical yet challenging task for remote sensing image interpretation. Existing methods lack adaptability to diverse land cover types when modeling frequency domain features. To this end, we propose a Dynamic Frequency Feature Fusion Network (DFFNet) for hyperspectral image (HSI) and Synthetic Aperture Radar (SAR) / Light Detection and Ranging (LiDAR) data joint classification. Specifically, we design a dynamic filter block to dynamically learn the filter kernels in the frequency domain by aggregating the input features. The frequency contextual knowledge is injected into frequency filter kernels. Additionally, we propose spectral-spatial adaptive fusion block for cross-modal feature fusion. It enhances the spectral and spatial attention weight interactions via channel shuffle operation, thereby providing comprehensive cross-modal feature fusion. Experiments on two benchmark datasets show that our DFFNet outperforms state-of-the-art methods in multi-source data classification. The codes will be made publicly available at this https URL.

Paper number 74:
Title: FB-Diff: Fourier Basis-guided Diffusion for Temporal Interpolation of 4D Medical Imaging
Authors: Xin You, Runze Yang, Chuyan Zhang, Zhongliang Jiang, Jie Yang, Nassir Navab
Abstract: The temporal interpolation task for 4D medical imaging, plays a crucial role in clinical practice of respiratory motion modeling. Following the simplified linear-motion hypothesis, existing approaches adopt optical flow-based models to interpolate intermediate frames. However, realistic respiratory motions should be nonlinear and quasi-periodic with specific frequencies. Intuited by this property, we resolve the temporal interpolation task from the frequency perspective, and propose a Fourier basis-guided Diffusion model, termed FB-Diff. Specifically, due to the regular motion discipline of respiration, physiological motion priors are introduced to describe general characteristics of temporal data distributions. Then a Fourier motion operator is elaborately devised to extract Fourier bases by incorporating physiological motion priors and case-specific spectral information in the feature space of Variational Autoencoder. Well-learned Fourier bases can better simulate respiratory motions with motion patterns of specific frequencies. Conditioned on starting and ending frames, the diffusion model further leverages well-learned Fourier bases via the basis interaction operator, which promotes the temporal interpolation task in a generative manner. Extensive results demonstrate that FB-Diff achieves state-of-the-art (SOTA) perceptual performance with better temporal consistency while maintaining promising reconstruction metrics. Codes are available.

Paper number 75:
Title: Comprehensive Modeling of Camera Spectral and Color Behavior
Authors: Sanush K Abeysekera, Ye Chow Kuang, Melanie Po-Leen Ooi
Abstract: The spectral response of a digital camera defines the mapping between scene radiance and pixel intensity. Despite its critical importance, there is currently no comprehensive model that considers the end-to-end interaction between light input and pixel intensity output. This paper introduces a novel technique to model the spectral response of an RGB digital camera, addressing this gap. Such models are indispensable for applications requiring accurate color and spectral data interpretation. The proposed model is tested across diverse imaging scenarios by varying illumination conditions and is validated against experimental data. Results demonstrate its effectiveness in improving color fidelity and spectral accuracy, with significant implications for applications in machine vision, remote sensing, and spectral imaging. This approach offers a powerful tool for optimizing camera systems in scientific, industrial, and creative domains where spectral precision is paramount.

Paper number 76:
Title: A Deep Unfolding Framework for Diffractive Snapshot Spectral Imaging
Authors: Zhengyue Zhuge, Jiahui Xu, Shiqi Chen, Hao Xu, Yueting Chen, Zhihai Xu, Huajun Feng
Abstract: Snapshot hyperspectral imaging systems acquire spectral data cubes through compressed sensing. Recently, diffractive snapshot spectral imaging (DSSI) methods have attracted significant attention. While various optical designs and improvements continue to emerge, research on reconstruction algorithms remains limited. Although numerous networks and deep unfolding methods have been applied on similar tasks, they are not fully compatible with DSSI systems because of their distinct optical encoding mechanism. In this paper, we propose an efficient deep unfolding framework for diffractive systems, termed diffractive deep unfolding (DDU). Specifically, we derive an analytical solution for the data fidelity term in DSSI, ensuring both the efficiency and the effectiveness during the iterative reconstruction process. Given the severely ill-posed nature of the problem, we employ a network-based initialization strategy rather than non-learning-based methods or linear layers, leading to enhanced stability and performance. Our framework demonstrates strong compatibility with existing state-of-the-art (SOTA) models, which effectively address the initialization and prior subproblem. Extensive experiments validate the superiority of the proposed DDU framework, showcasing improved performance while maintaining comparable parameter counts and computational complexity. These results suggest that DDU provides a solid foundation for future unfolding-based methods in DSSI.

Paper number 77:
Title: Risk-Aware Trajectory Optimization and Control for an Underwater Suspended Robotic System
Authors: Yuki Origane, Nicolas Hoischen, Tzu-Yuan Huang, Daisuke Kurabayashi, Stefan Sosnowski, Sandra Hirche
Abstract: This paper focuses on the trajectory optimization of an underwater suspended robotic system comprising an uncrewed surface vessel (USV) and an uncrewed underwater vehicle (UUV) for autonomous litter collection. The key challenge lies in the significant uncertainty in drag and weight parameters introduced by the collected litter. We propose a dynamical model for the coupled UUV-USV system in the primary plane of motion and a risk-aware optimization approach incorporating parameter uncertainty and noise to ensure safe interactions with the environment. A stochastic optimization problem is solved using a conditional value-at-risk framework. Simulations demonstrate that our approach reduces collision risks and energy consumption, highlighting its reliability compared to existing control methods.

Paper number 78:
Title: Feature-Based Belief Aggregation for Partially Observable Markov Decision Problems
Authors: Yuchao Li, Kim Hammar, Dimitri Bertsekas
Abstract: We consider a finite-state partially observable Markov decision problem (POMDP) with an infinite horizon and a discounted cost, and we propose a new method for computing a cost function approximation that is based on features and aggregation. In particular, using the classical belief-space formulation, we construct a related Markov decision problem (MDP) by first aggregating the unobservable states into feature states, and then introducing representative beliefs over these feature states. This two-stage aggregation approach facilitates the use of dynamic programming methods for solving the aggregate problem and provides additional design flexibility. The optimal cost function of the aggregate problem can in turn be used within an on-line approximation in value space scheme for the original POMDP. We derive a new bound on the approximation error of our scheme. In addition, we establish conditions under which the cost function approximation provides a lower bound for the optimal cost. Finally, we present a biased aggregation approach, which leverages an optimal cost function estimate to improve the quality of the approximation error of the aggregate problem.

Paper number 79:
Title: Enhancing Data Processing Efficiency in Blockchain Enabled Metaverse over Wireless Communications
Authors: Liangxin Qian, Jun Zhao
Abstract: In the rapidly evolving landscape of the Metaverse, enhanced by blockchain technology, the efficient processing of data has emerged as a critical challenge, especially in wireless communication systems. Addressing this challenge, our paper introduces the innovative concept of data processing efficiency (DPE), aiming to maximize processed bits per unit of resource consumption in blockchain-empowered Metaverse environments. To achieve this, we propose the DPE-Aware User Association and Resource Allocation (DAUR) algorithm, a tailored optimization framework for blockchain-enabled Metaverse wireless communication systems characterized by joint computing and communication resource constraints. The DAUR algorithm transforms the nonconvex problem of maximizing the sum of DPE ratios into a solvable convex optimization problem. It alternates the optimization of key variables, including user association, work offloading ratios, task-specific computing resource distribution, bandwidth allocation, user power usage ratios, and server computing resource allocation ratios. Our extensive numerical results demonstrate the DAUR algorithm's effectiveness in DPE.

Paper number 80:
Title: CP-Dilatation: A Copy-and-Paste Augmentation Method for Preserving the Boundary Context Information of Histopathology Images
Authors: Sungrae Hong, Sol Lee, Mun Yong Yi
Abstract: Medical AI diagnosis including histopathology segmentation has derived benefits from the recent development of deep learning technology. However, deep learning itself requires a large amount of training data and the medical image segmentation masking, in particular, requires an extremely high cost due to the shortage of medical specialists. To mitigate this issue, we propose a new data augmentation method built upon the conventional Copy and Paste (CP) augmentation technique, called CP-Dilatation, and apply it to histopathology image segmentation. To the well-known traditional CP technique, the proposed method adds a dilation operation that can preserve the boundary context information of the malignancy, which is important in histopathological image diagnosis, as the boundary between the malignancy and its margin is mostly unclear and a significant context exists in the margin. In our experiments using histopathology benchmark datasets, the proposed method was found superior to the other state-of-the-art baselines chosen for comparison.

Paper number 81:
Title: Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR
Authors: Tao Du, Jie Yang, Fan Liu, Jiaxiang Guo, Shuqiang Xia, Chao-Kai Wen, Shi Jin
Abstract: Millimeter-wave (mmWave) 5G New Radio (NR) communication systems, with their high-resolution antenna arrays and extensive bandwidth, offer a transformative opportunity for high-throughput data transmission and advanced environmental sensing. Although passive sensing-based SLAM techniques can estimate user locations and environmental reflections simultaneously, their effectiveness is often constrained by assumptions of specular reflections and oversimplified map representations. To overcome these limitations, this work employs a mmWave 5G NR system for active sensing, enabling it to function similarly to a laser scanner for point cloud generation. Specifically, point clouds are extracted from the power delay profile estimated from each beam direction using a binary search approach. To ensure accuracy, hardware delays are calibrated with multiple predefined target points. Pose variations of the terminal are then estimated from point cloud data gathered along continuous trajectory viewpoints using point cloud registration algorithms. Loop closure detection and pose graph optimization are subsequently applied to refine the sensing results, achieving precise terminal localization and detailed radio map reconstruction. The system is implemented and validated through both simulations and experiments, confirming the effectiveness of the proposed approach.

Paper number 82:
Title: SPIDER: Structure-Preferential Implicit Deep Network for Biplanar X-ray Reconstruction
Authors: Tianqi Yu, Xuanyu Tian, Jiawen Yang, Dongming He, Jingyi Yu, Xudong Wang, Yuyao Zhang
Abstract: Biplanar X-ray imaging is widely used in health screening, postoperative rehabilitation evaluation of orthopedic diseases, and injury surgery due to its rapid acquisition, low radiation dose, and straightforward setup. However, 3D volume reconstruction from only two orthogonal projections represents a profoundly ill-posed inverse problem, owing to the intrinsic lack of depth information and irreducible ambiguities in soft-tissue visualization. Some existing methods can reconstruct skeletal structures and Computed Tomography (CT) volumes, they often yield incomplete bone geometry, imprecise tissue boundaries, and a lack of anatomical realism, thereby limiting their clinical utility in scenarios such as surgical planning and postoperative assessment. In this study, we introduce SPIDER, a novel supervised framework designed to reconstruct CT volumes from biplanar X-ray images. SPIDER incorporates tissue structure as prior (e.g., anatomical segmentation) into an implicit neural representation decoder in the form of joint supervision through a unified encoder-decoder architecture. This design enables the model to jointly learn image intensities and anatomical structures in a pixel-aligned fashion. To address the challenges posed by sparse input and structural ambiguity, SPIDER directly embeds anatomical constraints into the reconstruction process, thereby enhancing structural continuity and reducing soft-tissue artifacts. We conduct comprehensive experiments on clinical head CT datasets and show that SPIDER generates anatomically accurate reconstructions from only two projections. Furthermore, our approach demonstrates strong potential in downstream segmentation tasks, underscoring its utility in personalized treatment planning and image-guided surgical navigation.

Paper number 83:
Title: Higher-Order Harmonics Reduction in Reset-Based Control Systems: Application to Precision Positioning Systems
Authors: S. Ali Hosseini, Nima Karbasizadeh, S. Hassan HosseiniNia
Abstract: To address the limitations imposed by Bode's gain-phase relationship in linear controllers, a reset-based filter called the Constant in gain- Lead in phase (CgLp) filter has been introduced. This filter consists of a reset element and a linear lead filter. However, the sequencing of these two components has been a topic of debate. Positioning the lead filter before the reset element in the loop leads to noise amplification in the reset signal, whereas placing the lead filter after the reset element results in the magnification of higher-order harmonics. This study introduces a tunable lead CgLp structure in which the lead filter is divided into two segments, enabling a balance between noise reduction and higher-order harmonics mitigation. Additionally, a filtering technique is proposed, employing a target-frequency-based approach to mitigate nonlinearity in reset control systems in the presence of noise. The effectiveness of the proposed methods in reducing nonlinearity is demonstrated through both frequency domain and time-domain analyses using a simulated precision positioning system as a case study.

Paper number 84:
Title: Multi-Objective Nonlinear Power Split Control For BESS With Real-Time Simulation Feedback
Authors: Vivek Teja Tanjavooru, Prashant Pant, Thomas Hamacher, Holger Hesse
Abstract: This paper presents a mixed-integer, nonlinear, multi-objective optimization strategy for optimal power allocation among parallel strings in Battery Energy Storage Systems (BESS). High-fidelity control is achieved by co-simulating the optimizer with a BESS electro-thermal simulation that models spatial thermal dynamics of the battery, providing real-time State of Charge (SOC) and temperature feedback. The optimizer prioritizes reliability by enforcing power availability as a hard constraint and penalizing battery thermal derating. Within these bounds, the controller performs a Pareto sweep on the relative weights of inverter and battery losses to balance the trade-off between inverter efficiency and battery efficiency. The inverter loss model is based on an empirical lookup table (LUT) derived from a commercial inverter system, while the battery thermal loss model uses SOC and temperature-dependent internal resistance, with electric current computed from the battery Equivalent Circuit Model (ECM). When the optimization was applied to a two-string BESS, the competing effects of inverter and battery losses on system availability and thermal derating were observed. The balanced operation yielded improvements of 1% in battery efficiency, 1.5% in inverter efficiency, and 2% in derating efficiency, while maintaining higher availability. Additionally, a 5 degrees C reduction in BESS peak temperature also suggests reduced thermal stress without compromising availability.

Paper number 85:
Title: UAV-Assisted Integrated Communication and Over-the-Air Computation with Interference Awareness
Authors: Xunqiang Lan, Xiao Tang, Ruonan Zhang, Bin Li, Yichen Wang, Dusit Niyato, Zhu Han
Abstract: Over the air computation (AirComp) is a promising technique that addresses big data collection and fast wireless data aggregation. However, in a network where wireless communication and AirComp coexist, mutual interference becomes a critical challenge. In this paper, we propose to employ an unmanned aerial vehicle (UAV) to enable integrated communication and AirComp, where we capitalize on UAV mobility with alleviated interference for performance enhancement. Particularly, we aim to maximize the sum of user transmission rate with the guaranteed AirComp accuracy requirement, where we jointly optimize the transmission strategy, signal normalizing factor, scheduling strategy, and UAV trajectory. We decouple the formulated problem into two layers where the outer layer is for UAV trajectory and scheduling, and the inner layer is for transmission and computation. Then, we solve the inner layer problem through alternating optimization, and the outer layer is solved through soft actor critic based deep reinforcement learning. Simulation results show the convergence of the proposed learning process and also demonstrate the performance superiority of our proposal as compared with the baselines in various situations.

Paper number 86:
Title: Accounting for Subsystem Aging Variability in Battery Energy Storage System Optimization
Authors: Melina Grane, Martin Cornejo, Holger Hesse, Andreas Jossen
Abstract: This paper presents a degradation-cost-aware optimization framework for multi-string battery energy storage systems, emphasizing the impact of inhomogeneous subsystem-level aging in operational decision-making. We evaluate four scenarios for an energy arbitrage scenario, that vary in model precision and treatment of aging costs. Key performance metrics include operational revenue, power schedule mismatch, missed revenues, capacity losses, and revenue generated per unit of capacity loss. Our analysis reveals that ignoring heterogeneity of subunits may lead to infeasible dispatch plans and reduced revenues. In contrast, combining accurate representation of degraded subsystems and the consideration of aging costs in the objective function improves operational accuracy and economic efficiency of BESS with heterogeneous aged subunits. The fully informed scenario, which combines aging-cost-aware optimization with precise string-level modeling, achieves 21% higher revenue per unit of SOH loss compared to the baseline scenario. These findings highlight that modeling aging heterogeneity is not just a technical refinement but may become a crucial enabler for maximizing both short-term profitability and long-term asset value in particular for long BESS usage scenarios.

Paper number 87:
Title: Force-IMU Fusion-Based Sensing Acupuncture Needle and Quantitative Analysis System for Acupuncture Manipulations
Authors: Peng Tian, Kang Yu, Tianyun Jiang, Yuqi Wang, Haiying Zhang, Hao Yang, Yunfeng Wang, Jun Zhang, Shuo Gao, Junhong Gao
Abstract: Acupuncture, one of the key therapeutic methods in Traditional Chinese Medicine (TCM), has been widely adopted in various clinical fields. Quantitative research on acupuncture manipulation parameters is critical to achieve standardized techniques. However, quantitative mechanical detection of acupuncture parameters remains limited. This study establishes a kinematic and dynamic model of acupuncture, identifying key parameters such as lifting-thrusting force, acceleration, velocity, displacement, as well as twirling-rotating angular velocity and angle. To measure these critical parameters, we propose a quantitative system comprising a sensing needle equipped with a force sensor and an inertial measurement unit (IMU), as well as an external camera module to capture image information. By fusing visual and IMU data, we accurately identify the stationary or motion states of the needle, enabling segmented computation of lifting-thrusting velocity and displacement. The experimental results demonstrate that the sensing needle achieves comprehensive detection with high precision, featuring a nonlinearity error of 0.45% in force measurement and an RMSE of 1.2 mm in displacement. The extracted parameters provide an objective description of the operational characteristics and motion patterns of the four basic acupuncture manipulations. These findings provide valuable tools and methods for research in acupuncture standardization.

Paper number 88:
Title: Spatial and Semantic Embedding Integration for Stereo Sound Event Localization and Detection in Regular Videos
Authors: Davide Berghi, Philip J. B. Jackson
Abstract: This report presents our systems submitted to the audio-only and audio-visual tracks of the DCASE2025 Task 3 Challenge: Stereo Sound Event Localization and Detection (SELD) in Regular Video Content. SELD is a complex task that combines temporal event classification with spatial localization, requiring reasoning across spatial, temporal, and semantic dimensions. The last is arguably the most challenging to model. Traditional SELD architectures rely on multichannel input, which limits their ability to leverage large-scale pre-training due to data constraints. To address this, we enhance standard SELD architectures with semantic information by integrating pre-trained, contrastive language-aligned models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are incorporated into a modified Conformer module tailored for multimodal fusion, which we refer to as the Cross-Modal Conformer. Additionally, we incorporate autocorrelation-based acoustic features to improve distance estimation. We pre-train our models on curated synthetic audio and audio-visual datasets and apply a left-right channel swapping augmentation to further increase the training data. Both our audio-only and audio-visual systems substantially outperform the challenge baselines on the development set, demonstrating the effectiveness of our strategy. Performance is further improved through model ensembling and a visual post-processing step based on human keypoints. Future work will investigate the contribution of each modality and explore architectural variants to further enhance results.

Paper number 89:
Title: Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation
Authors: Thomas Wallace, Ik Siong Heng, Senad Subasic, Chris Messenger
Abstract: Synthetic images are an option for augmenting limited medical imaging datasets to improve the performance of various machine learning models. A common metric for evaluating synthetic image quality is the FrÃ©chet Inception Distance (FID) which measures the similarity of two image datasets. In this study we evaluate the relationship between this metric and the improvement which synthetic images, generated by a Progressively Growing Generative Adversarial Network (PGGAN), grant when augmenting Diabetes-related Macular Edema (DME) intraretinal fluid segmentation performed by a U-Net model with limited amounts of training data. We find that the behaviour of augmenting with standard and synthetic images agrees with previously conducted experiments. Additionally, we show that dissimilar (high FID) datasets do not improve segmentation significantly. As FID between the training and augmenting datasets decreases, the augmentation datasets are shown to contribute to significant and robust improvements in image segmentation. Finally, we find that there is significant evidence to suggest that synthetic and standard augmentations follow separate log-normal trends between FID and improvements in model performance, with synthetic data proving more effective than standard augmentation techniques. Our findings show that more similar datasets (lower FID) will be more effective at improving U-Net performance, however, the results also suggest that this improvement may only occur when images are sufficiently dissimilar.

Paper number 90:
Title: Adaptive Slimming for Scalable and Efficient Speech Enhancement
Authors: Riccardo Miccini, Minje Kim, ClÃ©ment Laroche, Luca Pezzarossa, Paris Smaragdis
Abstract: Speech enhancement (SE) enables robust speech recognition, real-time communication, hearing aids, and other applications where speech quality is crucial. However, deploying such systems on resource-constrained devices involves choosing a static trade-off between performance and computational efficiency. In this paper, we introduce dynamic slimming to DEMUCS, a popular SE architecture, making it scalable and input-adaptive. Slimming lets the model operate at different utilization factors (UF), each corresponding to a different performance/efficiency trade-off, effectively mimicking multiple model sizes without the extra storage costs. In addition, a router subnet, trained end-to-end with the backbone, determines the optimal UF for the current input. Thus, the system saves resources by adaptively selecting smaller UFs when additional complexity is unnecessary. We show that our solution is Pareto-optimal against individual UFs, confirming the benefits of dynamic routing. When training the proposed dynamically-slimmable model to use 10% of its capacity on average, we obtain the same or better speech quality as the equivalent static 25% utilization while reducing MACs by 29%.

Paper number 91:
Title: Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven Methods
Authors: Carmen Jimenez-Mesa, Yizhou Wan, Guilio Sansone, Francisco J. Martinez-Murcia, Javier Ramirez, Pietro Lio, Juan M. Gorriz, Stephen J. Price, John Suckling, Michail Mamalakis
Abstract: Brain tumor resection is a complex procedure with significant implications for patient survival and quality of life. Predictions of patient outcomes provide clinicians and patients the opportunity to select the most suitable onco-functional balance. In this study, global features derived from structural magnetic resonance imaging in a clinical dataset of 49 pre- and post-surgery patients identified potential biomarkers associated with survival outcomes. We propose a framework that integrates Explainable AI (XAI) with neuroimaging-based feature engineering for survival assessment, offering guidance for surgical decision-making. In this study, we introduce a global explanation optimizer that refines survival-related feature attribution in deep learning models, enhancing interpretability and reliability. Our findings suggest that survival is influenced by alterations in regions associated with cognitive and sensory functions, indicating the importance of preserving areas involved in decision-making and emotional regulation during surgery to improve outcomes. The global explanation optimizer improves both fidelity and comprehensibility of explanations compared to state-of-the-art XAI methods. It effectively identifies survival-related variability, underscoring its relevance in precision medicine for brain tumor treatment.

Paper number 92:
Title: MurreNet: Modeling Holistic Multimodal Interactions Between Histopathology and Genomic Profiles for Survival Prediction
Authors: Mingxin Liu, Chengfei Cai, Jun Li, Pengbo Xu, Jinze Li, Jiquan Ma, Jun Xu
Abstract: Cancer survival prediction requires integrating pathological Whole Slide Images (WSIs) and genomic profiles, a challenging task due to the inherent heterogeneity and the complexity of modeling both inter- and intra-modality interactions. Current methods often employ straightforward fusion strategies for multimodal feature integration, failing to comprehensively capture modality-specific and modality-common interactions, resulting in a limited understanding of multimodal correlations and suboptimal predictive performance. To mitigate these limitations, this paper presents a Multimodal Representation Decoupling Network (MurreNet) to advance cancer survival analysis. Specifically, we first propose a Multimodal Representation Decomposition (MRD) module to explicitly decompose paired input data into modality-specific and modality-shared representations, thereby reducing redundancy between modalities. Furthermore, the disentangled representations are further refined then updated through a novel training regularization strategy that imposes constraints on distributional similarity, difference, and representativeness of modality features. Finally, the augmented multimodal features are integrated into a joint representation via proposed Deep Holistic Orthogonal Fusion (DHOF) strategy. Extensive experiments conducted on six TCGA cancer cohorts demonstrate that our MurreNet achieves state-of-the-art (SOTA) performance in survival prediction.

Paper number 93:
Title: Exploring O-RAN Compression Techniques in Decentralized Distributed MIMO Systems: Reducing Fronthaul Load
Authors: Mostafa Rahmani, Junbo Zhao, Vida Ranjbar, Ahmed Al-Tahmeesschi, Hamed Ahmadi, Sofie Pollin, Alister G. Burr
Abstract: This paper explores the application of uplink fronthaul compression techniques within Open RAN (O-RAN) to mitigate fronthaul load in decentralized distributed MIMO (DD-MIMO) systems. With the ever-increasing demand for high data rates and system scalability, the fronthaul load becomes a critical bottleneck. Our method uses O-RAN compression techniques to efficiently compress the fronthaul signals. The goal is to greatly lower the fronthaul load while having little effect on the overall system performance, as shown by Block Error Rate (BLER) curves. Through rigorous link-level simulations, we compare our quantization strategies against a benchmark scenario with no quantization, providing insights into the trade-offs between fronthaul data rate reduction and link performance integrity. The results demonstrate that our proposed quantization techniques not only lower the fronthaul load but also maintain a competitive link quality, making them a viable solution for enhancing the efficiency of next-generation wireless networks. This study underscores the potential of quantization in O-RAN contexts to achieve optimal balance between system capacity and performance, paving the way for more scalable and robust DD-MIMO deployments.

Paper number 94:
Title: The Extended SONICOM HRTF Dataset and Spatial Audio Metrics Toolbox
Authors: Katarina C. Poole, Julie Meyer, Vincent Martin, Rapolas Daugintis, Nils Marggraf-Turley, Jack Webb, Ludovic Pirard, Nicola La Magna, Oliver Turvey, Lorenzo Picinali
Abstract: Headphone-based spatial audio uses head-related transfer functions (HRTFs) to simulate real-world acoustic environments. HRTFs are unique to everyone, due to personal morphology, shaping how sound waves interact with the body before reaching the eardrums. Here we present the extended SONICOM HRTF dataset which expands on the previous version released in 2023. The total number of measured subjects has now been increased to 300, with demographic information for a subset of the participants, providing context for the dataset's population and relevance. The dataset incorporates synthesised HRTFs for 200 of the 300 subjects, generated using Mesh2HRTF, alongside pre-processed 3D scans of the head and ears, optimised for HRTF synthesis. This rich dataset facilitates rapid and iterative optimisation of HRTF synthesis algorithms, allowing the automatic generation of large data. The optimised scans enable seamless morphological modifications, providing insights into how anatomical changes impact HRTFs, and the larger sample size enhances the effectiveness of machine learning approaches. To support analysis, we also introduce the Spatial Audio Metrics (SAM) Toolbox, a Python package designed for efficient analysis and visualisation of HRTF data, offering customisable tools for advanced research. Together, the extended dataset and toolbox offer a comprehensive resource for advancing personalised spatial audio research and development.

Paper number 95:
Title: A Corrective Frequency-Constrained Unit Commitment with Data-driven Estimation of Optimal UFLS in Island Power Systems
Authors: Miad Sarvarizadeh, Lukas Sigrist, Almudena Rouco, Mohammad Rajabdorri, Enrique Lobato
Abstract: This paper presents a novel corrective \gls{fcuc} formulation for island power systems by implementing data-driven constraint learning to estimate the optimal \gls{ufls}. The Tobit model is presented to estimate the optimal amount of \gls{ufls} using the initial rate of change of frequency. The proposed formulation enables co-optimizing operation costs and \gls{ufls}. The aim is to account for optimal \gls{ufls} occurrences during operation planning, without increasing them. This would potentially reduce system operation costs by relaxing the reserve requirement constraint. The performance of the proposed formulation has been analyzed for a Spanish island power system through various simulations. Different daily demand profiles are analyzed to demonstrate the effectiveness of the proposed formulation. Additionally, a sensitivity analysis is conducted to demonstrate the effects of changing the cost associated with \gls{ufls}. The corrective \gls{fcuc} is shown to be capable of reducing system operation costs without jeopardizing the quality of the frequency response in terms of \gls{ufls} occurrence.

Paper number 96:
Title: Deep Learning Based Antenna Selection Technique for RIS-Empowered RQSM System
Authors: Burak Ahmet Ozden, Fatih Cogen, Erdogan Aydin
Abstract: Reconfigurable intelligent surface (RIS) technology has attracted considerable interest due to its ability to control wireless propagation with minimal power usage. Receive quadrature spatial modulation (RQSM) scheme transmits data bits in both in-phase ($I$) and quadrature ($Q$) channels, doubling the number of active receive antenna indices and improving spectral efficiency compared to the traditional receive spatial modulation (RSM) technique. Also, capacity-optimized antenna selection (COAS) improves error performance by selecting antennas with the best channel conditions. This paper proposes a new deep neural network (DNN)-based antenna selection method, supported by the COAS technique, to improve the error performance of the RIS-RQSM system. Monte Carlo simulations of the proposed DNN-COAS-RIS-RQSM system using the quadrature amplitude modulation (QAM) technique for Rayleigh fading channels are performed and compared with the COAS-RIS-RQSM system. Also, a comparative analysis of the computational complexities of the DNN and COAS techniques is conducted to evaluate the trade-offs between error performance and complexity.

Paper number 97:
Title: Sequential Attention-based Sampling for Histopathological Analysis
Authors: Tarun G, Naman Malpani, Gugan Thoppe, Sridharan Devarajan
Abstract: Deep neural networks are increasingly applied for automated histopathology. Yet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering it computationally infeasible to analyze them entirely at high resolution. Diagnostic labels are largely available only at the slide-level, because expert annotation of images at a finer (patch) level is both laborious and expensive. Moreover, regions with diagnostic information typically occupy only a small fraction of the WSI, making it inefficient to examine the entire slide at full resolution. Here, we propose SASHA -- {\it S}equential {\it A}ttention-based {\it S}ampling for {\it H}istopathological {\it A}nalysis -- a deep reinforcement learning approach for efficient analysis of histopathological images. First, SASHA learns informative features with a lightweight hierarchical, attention-based multiple instance learning (MIL) model. Second, SASHA samples intelligently and zooms selectively into a small fraction (10-20\%) of high-resolution patches, to achieve reliable diagnosis. We show that SASHA matches state-of-the-art methods that analyze the WSI fully at high-resolution, albeit at a fraction of their computational and memory costs. In addition, it significantly outperforms competing, sparse sampling methods. We propose SASHA as an intelligent sampling model for medical imaging challenges that involve automated diagnosis with exceptionally large images containing sparsely informative features.

Paper number 98:
Title: A Comparative Study on Frequency-Constrained Unit Commitment Approaches in Island Power Systems
Authors: Miad Sarvarizadeh, Mohammad Rajabdorri, Enrique Lobato, Lukas Sigrist
Abstract: The increasing penetration of renewable energy sources reduces rotating inertia and even frequency control capacity, affecting frequency stability. This challenge is significant in \gls{ips} that already suffer from low inertia and frequency control capacity. This paper presents a comparative study on different \gls{fcuc} formulations applied to \gls{ips}. Then, by considering under-frequency load shedding as a significant measure of frequency stability in \gls{ips}, two indices are presented to fully compare the formulations from system benefits and computational burden perspectives. Simulations conducted on a real Spanish island show that the data-driven corrective \gls{fcuc} formulation has the most advantages among other formulations.

Paper number 99:
Title: Real-Time Graph-based Point Cloud Networks on FPGAs via Stall-Free Deep Pipelining
Authors: Marc Neu, Isabel Haide, Timo Justinger, Till RÃ¤dler, Valdrin Dajaku, Torben Ferber, JÃ¼rgen Becker
Abstract: Graph-based Point Cloud Networks (PCNs) are powerful tools for processing sparse sensor data with irregular geometries, as found in high-energy physics detectors. However, deploying models in such environments remains challenging due to stringent real-time requirements for both latency, and throughput. In this work, we present a deeply pipelined dataflow architecture for executing graph-based PCNs on FPGAs. Our method supports efficient processing of dynamic, sparse point clouds while meeting hard real-time constraints. We introduce specialized processing elements for core graph operations, such as GraVNet convolution and condensation point clustering, and demonstrate our design on the AMD Versal VCK190. Compared to a GPU baseline, our FPGA implementation achieves up to 5.25x speedup in throughput while maintaining latencies below 10 {\mu}s, satisfying the demands of real-time trigger systems in particle physics experiments. An open-source reference implementation is provided.

Paper number 100:
Title: A Federated Learning-based Lightweight Network with Zero Trust for UAV Authentication
Authors: Hao Zhang, Fuhui Zhou, Wei Wang, Qihui Wu, Chau Yuen
Abstract: Unmanned aerial vehicles (UAVs) are increasingly being integrated into next-generation networks to enhance communication coverage and network capacity. However, the dynamic and mobile nature of UAVs poses significant security challenges, including jamming, eavesdropping, and cyber-attacks. To address these security challenges, this paper proposes a federated learning-based lightweight network with zero trust for enhancing the security of UAV networks. A novel lightweight spectrogram network is proposed for UAV authentication and rejection, which can effectively authenticate and reject UAVs based on spectrograms. Experiments highlight LSNet's superior performance in identifying both known and unknown UAV classes, demonstrating significant improvements over existing benchmarks in terms of accuracy, model compactness, and storage requirements. Notably, LSNet achieves an accuracy of over $80\%$ for known UAV types and an Area Under the Receiver Operating Characteristic (AUROC) of $0.7$ for unknown types when trained with all five clients. Further analyses explore the impact of varying the number of clients and the presence of unknown UAVs, reinforcing the practical applicability and effectiveness of our proposed framework in real-world FL scenarios.

Paper number 101:
Title: SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model
Authors: Chun Xie, Yuichi Yoshii, Itaru Kitahara
Abstract: X-ray imaging is a rapid and cost-effective tool for visualizing internal human anatomy. While multi-view X-ray imaging provides complementary information that enhances diagnosis, intervention, and education, acquiring images from multiple angles increases radiation exposure and complicates clinical workflows. To address these challenges, we propose a novel view-conditioned diffusion model for synthesizing multi-view X-ray images from a single view. Unlike prior methods, which are limited in angular range, resolution, and image quality, our approach leverages the Diffusion Transformer to preserve fine details and employs a weak-to-strong training strategy for stable high-resolution image generation. Experimental results demonstrate that our method generates higher-resolution outputs with improved control over viewing angles. This capability has significant implications not only for clinical applications but also for medical education and data extension, enabling the creation of diverse, high-quality datasets for training and analysis. Our code is available at GitHub.

Paper number 102:
Title: Latent Motion Profiling for Annotation-free Cardiac Phase Detection in Adult and Fetal Echocardiography Videos
Authors: Yingyu Yang, Qianye Yang, Kangning Cui, Can Peng, Elena D'Alberti, Netzahualcoyotl Hernandez-Cruz, Olga Patey, Aris T. Papageorghiou, J. Alison Noble
Abstract: The identification of cardiac phase is an essential step for analysis and diagnosis of cardiac function. Automatic methods, especially data-driven methods for cardiac phase detection, typically require extensive annotations, which is time-consuming and labor-intensive. In this paper, we present an unsupervised framework for end-diastole (ED) and end-systole (ES) detection through self-supervised learning of latent cardiac motion trajectories from 4-chamber-view echocardiography videos. Our method eliminates the need for manual annotations, including ED and ES indices, segmentation, or volumetric measurements, by training a reconstruction model to encode interpretable spatiotemporal motion patterns. Evaluated on the EchoNet-Dynamic benchmark, the approach achieves mean absolute error (MAE) of 3 frames (58.3 ms) for ED and 2 frames (38.8 ms) for ES detection, matching state-of-the-art supervised methods. Extended to fetal echocardiography, the model demonstrates robust performance with MAE 1.46 frames (20.7 ms) for ED and 1.74 frames (25.3 ms) for ES, despite the fact that the fetal heart model is built using non-standardized heart views due to fetal heart positioning variability. Our results demonstrate the potential of the proposed latent motion trajectory strategy for cardiac phase detection in adult and fetal echocardiography. This work advances unsupervised cardiac motion analysis, offering a scalable solution for clinical populations lacking annotated data. Code will be released at this https URL.

Paper number 103:
Title: RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis
Authors: Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima, Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi
Abstract: Rheumatoid arthritis (RA) is a common autoimmune disease that has been the focus of research in computer-aided diagnosis (CAD) and disease monitoring. In clinical settings, conventional radiography (CR) is widely used for the screening and evaluation of RA due to its low cost and accessibility. The wrist is a critical region for the diagnosis of RA. However, CAD research in this area remains limited, primarily due to the challenges in acquiring high-quality instance-level annotations. (i) The wrist comprises numerous small bones with narrow joint spaces, complex structures, and frequent overlaps, requiring detailed anatomical knowledge for accurate annotation. (ii) Disease progression in RA often leads to osteophyte, bone erosion (BE), and even bony ankylosis, which alter bone morphology and increase annotation difficulty, necessitating expertise in rheumatology. This work presents a multi-task dataset for wrist bone in CR, including two tasks: (i) wrist bone instance segmentation and (ii) Sharp/van der Heijde (SvdH) BE scoring, which is the first public resource for wrist bone instance segmentation. This dataset comprises 621 wrist conventional radiographs of 227 patients from four medical centers, with pixel-level instance segmentation annotations for 443 images and SvdH BE scores for 548 images. This dataset can potentially support a wide range of research tasks related to RA, including joint space narrowing (JSN) progression quantification, BE detection, bone deformity evaluation, and osteophyte detection. It may also be applied to other wrist-related tasks, such as carpal bone fracture localization. We hope this dataset will significantly lower the barrier to research on wrist RA and accelerate progress in CAD research within the RA-related domain.

Paper number 104:
Title: Regulation Compliant AI for Fusion: Real-Time Image Analysis-Based Control of Divertor Detachment in Tokamaks
Authors: Nathaniel Chen, Cheolsik Byun, Azarakash Jalalvand, Sangkyeun Kim, Andrew Rothstein, Filippo Scotti, Steve Allen, David Eldon, Keith Erickson, Egemen Kolemen
Abstract: While artificial intelligence (AI) has been promising for fusion control, its inherent black-box nature will make compliant implementation in regulatory environments a challenge. This study implements and validates a real-time AI enabled linear and interpretable control system for successful divertor detachment control with the DIII-D lower divertor camera. Using D2 gas, we demonstrate feedback divertor detachment control with a mean absolute difference of 2% from the target for both detachment and reattachment. This automatic training and linear processing framework can be extended to any image based diagnostic for regulatory compliant controller necessary for future fusion reactors.

Paper number 105:
Title: DiceHuBERT: Distilling HuBERT with a Self-Supervised Learning Objective
Authors: Hyung Gun Chi, Zakaria Aldeneh, Tatiana Likhomanenko, Oggi Rudovic, Takuya Higuchi, Li-Wei Chen, Shinji Watanabe, Ahmed Hussen Abdelaziz
Abstract: We introduce DiceHuBERT, a knowledge distillation framework for compressing HuBERT, a widely used self-supervised learning (SSL)-based speech foundation model. Unlike existing distillation methods that rely on layer-wise and feature-wise mapping between teacher and student models, DiceHuBERT leverages HuBERT's iterative self-distillation mechanism by directly replacing the original model with a student model. This replacement allows the student to be trained using the same SSL objective used when pre-training HuBERT, eliminating the need for additional modules or architectural constraints. Experimental results on SUPERB show that DiceHuBERT consistently outperforms existing distillation methods, improving phoneme recognition performance by over 21% and ASR performance by more than 14%. Furthermore, DiceHuBERT demonstrates competitive performance across multiple tasks, highlighting its clear advantage.

Paper number 106:
Title: Audio-JEPA: Joint-Embedding Predictive Architecture for Audio Representation Learning
Authors: Ludovic Tuncay (IRIT-SAMoVA), Etienne LabbÃ© (IRIT-SAMoVA), Emmanouil Benetos (QMUL), Thomas Pellegrini (IRIT-SAMoVA)
Abstract: Building on the Joint-Embedding Predictive Architecture (JEPA) paradigm, a recent self-supervised learning framework that predicts latent representations of masked regions in high-level feature spaces, we propose Audio-JEPA (Audio Joint-Embedding Predictive Architecture), tailored specifically for audio data. Audio-JEPA uses a simple Vision Transformer backbone to predict latent representations of masked spectrogram patches rather than reconstructing raw audio. We pre-train on unlabeled AudioSet clips (10s, 32kHz) with random patch masking on mel-spectrograms. We evaluate on the X-ARES suite covering speech, music, and environmental sound tasks. Although our implementation is a straightforward translation of the original model to audio, the results still show comparable performance to wav2vec 2.0 and data2vec while using less than one-fifth of their training data and with no hyper-parameter tuning. All code and pretrained checkpoints will be released on GitHub.

Paper number 107:
Title: A Unified Speech LLM for Diarization and Speech Recognition in Multilingual Conversations
Authors: Phurich Saengthong, Boonnithi Jiaramaneepinit, Sheng Li, Manabu Okumura, Takahiro Shinozaki
Abstract: Speech Large Language Models (Speech LLMs) have emerged as a crucial paradigm in recent years, extending the capabilities of traditional LLMs to speech tasks such as automatic speech recognition (ASR) and spoken dialogue modeling. However, their effectiveness in real-world multilingual conversations remains limited by the scarcity of data that captures natural conversational phenomena. To address this, the MLC-SLM Challenge provides a multilingual conversational dataset and evaluates models on two tasks: ASR with oracle segmentation (Task I) and joint diarization and recognition without oracle information (Task II). In this paper, we focus on Task II and propose a unified speech LLM that jointly performs diarization and ASR in an end-to-end manner. By reformulating the training data format and modifying the inference procedure, our model addresses the ambiguity inherent in pre-segmented audio and achieves a 54.87\% relative improvement in tcpWER/tcpCER over the baseline, ranking 8th overall, despite using a smaller LLM backbone. We also report results from Task I using a fine-tuned speech LLM.

Paper number 108:
Title: Predictive Maintenance Optimization for Smart Vending Machines Using IoT and Machine Learning
Authors: Md. Nisharul Hasan (Department of Industrial Engineering, Lamar University, Beaumont, Texas, USA)
Abstract: The increasing proliferation of vending machines in public and commercial environments has placed a growing emphasis on operational efficiency and customer satisfaction. Traditional maintenance approaches either reactive or time-based preventive are limited in their ability to preempt machine failures, leading to unplanned downtimes and elevated service costs. This research presents a novel predictive maintenance framework tailored for vending machines by leveraging Internet of Things (IoT) sensors and machine learning (ML) algorithms. The proposed system continuously monitors machine components and operating conditions in real time and applies predictive models to forecast failures before they occur. This enables timely maintenance scheduling, minimizing downtime and extending machine lifespan. The framework was validated through simulated fault data and performance evaluation using classification algorithms. Results show a significant improvement in early fault detection and a reduction in redundant service interventions. The findings indicate that predictive maintenance systems, when integrated into vending infrastructure, can transform operational efficiency and service reliability.

Paper number 109:
Title: Closed-Form Robustness Bounds for Second-Order Pruning of Neural Controller Policies
Authors: Maksym Shamrai
Abstract: Deep neural policies have unlocked agile flight for quadcopters, adaptive grasping for manipulators, and reliable navigation for ground robots, yet their millions of weights conflict with the tight memory and real-time constraints of embedded microcontrollers. Second-order pruning methods, such as Optimal Brain Damage (OBD) and its variants, including Optimal Brain Surgeon (OBS) and the recent SparseGPT, compress networks in a single pass by leveraging the local Hessian, achieving far higher sparsity than magnitude thresholding. Despite their success in vision and language, the consequences of such weight removal on closed-loop stability, tracking accuracy, and safety have remained unclear. We present the first mathematically rigorous robustness analysis of second-order pruning in nonlinear discrete-time control. The system evolves under a continuous transition map, while the controller is an $L$-layer multilayer perceptron with ReLU-type activations that are globally 1-Lipschitz. Pruning the weight matrix of layer $k$ replaces $W_k$ with $W_k+\delta W_k$, producing the perturbed parameter vector $\widehat{\Theta}=\Theta+\delta\Theta$ and the pruned policy $\pi(\cdot;\widehat{\Theta})$. For every input state $s\in X$ we derive the closed-form inequality $ \|\pi(s;\Theta)-\pi(s;\widehat{\Theta})\|_2 \le C_k(s)\,\|\delta W_k\|_2, $ where the constant $C_k(s)$ depends only on unpruned spectral norms and biases, and can be evaluated in closed form from a single forward pass. The derived bounds specify, prior to field deployment, the maximal admissible pruning magnitude compatible with a prescribed control-error threshold. By linking second-order network compression with closed-loop performance guarantees, our work narrows a crucial gap between modern deep-learning tooling and the robustness demands of safety-critical autonomous systems.

Paper number 110:
Title: VR-YOLO: Enhancing PCB Defect Detection with Viewpoint Robustness Based on YOLO
Authors: Hengyi Zhu, Linye Wei, He Li
Abstract: The integration of large-scale circuits and systems emphasizes the importance of automated defect detection of electronic components. The YOLO image detection model has been used to detect PCB defects and it has become a typical AI-assisted case of traditional industrial production. However, conventional detection algorithms have stringent requirements for the angle, orientation, and clarity of target images. In this paper, we propose an enhanced PCB defect detection algorithm, named VR-YOLO, based on the YOLOv8 model. This algorithm aims to improve the model's generalization performance and enhance viewpoint robustness in practical application scenarios. We first propose a diversified scene enhancement (DSE) method by expanding the PCB defect dataset by incorporating diverse scenarios and segmenting samples to improve target diversity. A novel key object focus (KOF) scheme is then presented by considering angular loss and introducing an additional attention mechanism to enhance fine-grained learning of small target features. Experimental results demonstrate that our improved PCB defect detection approach achieves a mean average precision (mAP) of 98.9% for the original test images, and 94.7% for the test images with viewpoint shifts (horizontal and vertical shear coefficients of $\pm 0.06$ and rotation angle of $\pm 10$ degrees), showing significant improvements compared to the baseline YOLO model with negligible additional computational cost.

Paper number 111:
Title: Enabling Robust, Real-Time Verification of Vision-Based Navigation through View Synthesis
Authors: Marius Neuhalfen, Jonathan Grzymisch, Manuel Sanchez-Gestido
Abstract: This work introduces VISY-REVE: a novel pipeline to validate image processing algorithms for Vision-Based Navigation. Traditional validation methods such as synthetic rendering or robotic testbed acquisition suffer from difficult setup and slow runtime. Instead, we propose augmenting image datasets in real-time with synthesized views at novel poses. This approach creates continuous trajectories from sparse, pre-existing datasets in open or closed-loop. In addition, we introduce a new distance metric between camera poses, the Boresight Deviation Distance, which is better suited for view synthesis than existing metrics. Using it, a method for increasing the density of image datasets is developed.

Paper number 112:
Title: A Novel Hybrid Grey Wolf Differential Evolution Algorithm
Authors: Ioannis D. Bougas, Pavlos Doanis, Maria S. Papadopoulou, Achilles D. Boursianis, Sotirios P. Sotiroudis, Zaharias D. Zaharis, George Koudouridis, Panagiotis Sarigiannidis, Mohammad Abdul Matint, George Karagiannidis, Sotirios K. Goudos
Abstract: Grey wolf optimizer (GWO) is a nature-inspired stochastic meta-heuristic of the swarm intelligence field that mimics the hunting behavior of grey wolves. Differential evolution (DE) is a popular stochastic algorithm of the evolutionary computation field that is well suited for global optimization. In this part, we introduce a new algorithm based on the hybridization of GWO and two DE variants, namely the GWO-DE algorithm. We evaluate the new algorithm by applying various numerical benchmark functions. The numerical results of the comparative study are quite satisfactory in terms of performance and solution quality.

Paper number 113:
Title: K-Function: Joint Pronunciation Transcription and Feedback for Evaluating Kids Language Function
Authors: Shuhe Li, Chenxu Guo, Jiachen Lian, Cheol Jun Cho, Wenshuo Zhao, Xuanru Zhou, Dingkun Zhou, Sam Wang, Grace Wang, Jingze Yang, Jingyi Xu, Ruohan Bao, Elise Brenner, Brandon In, Francesca Pei, Maria Luisa Gorno-Tempini, Gopala Anumanchipalli
Abstract: Early evaluation of children's language is frustrated by the high pitch, long phones, and sparse data that derail automatic speech recognisers. We introduce K-Function, a unified framework that combines accurate sub-word transcription, objective scoring, and actionable feedback. Its core, Kids-WFST, merges a Wav2Vec2 phoneme encoder with a phoneme-similarity Dysfluent-WFST to capture child-specific errors while remaining fully interpretable. Kids-WFST attains 1.39% phoneme error on MyST and 8.61% on Multitudes--absolute gains of 10.47 and 7.06 points over a greedy-search decoder. These high-fidelity transcripts power an LLM that grades verbal skills, milestones, reading, and comprehension, aligning with human proctors and supplying tongue-and-lip visualizations plus targeted advice. The results show that precise phoneme recognition cements a complete diagnostic-feedback loop, paving the way for scalable, clinician-ready language assessment.

Paper number 114:
Title: Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention
Authors: HyeYoung Lee, Muhammad Nadeem
Abstract: Speech Emotion Recognition (SER) traditionally relies on auditory data analysis for emotion classification. Several studies have adopted different methods for SER. However, existing SER methods often struggle to capture subtle emotional variations and generalize across diverse datasets. In this article, we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to bridge the gap between computational emotion processing and human auditory perception. To further improve robustness and feature diversity, we propose a novel 1D-CNN-based SER framework that integrates data augmentation techniques. MFCC features extracted from the augmented data are processed using a 1D Convolutional Neural Network (CNN) architecture enhanced with channel and spatial attention mechanisms. These attention modules allow the model to highlight key emotional patterns, enhancing its ability to capture subtle variations in speech signals. The proposed method delivers cutting-edge performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS, 89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO. Experimental results show new benchmarks in SER, demonstrating the effectiveness of our approach in recognizing emotional expressions with high precision. Our evaluation demonstrates that the integration of advanced Deep Learning (DL) methods substantially enhances generalization across diverse datasets, underscoring their potential to advance SER for real-world deployment in assistive technologies and human-computer interaction.

Paper number 115:
Title: LTLCrit: A Temporal Logic-based LLM Critic for Safe and Efficient Embodied Agents
Authors: Anand Gokhale, Vaibhav Srivastava, Francesco Bullo
Abstract: Large language models (LLMs) have demonstrated promise in reasoning tasks and general decision-making in static environments. In long-term planning tasks, however, errors tend to accumulate, often leading to unsafe or inefficient behavior, limiting their use in general-purpose settings. We propose a modular actor-critic architecture in which an LLM actor is guided by LTLCrit, a trajectory-level LLM critic that communicates via linear temporal logic (LTL). Our setup combines the reasoning strengths of language models with the guarantees of formal logic. The actor selects high-level actions from natural language observations, while the critic analyzes full trajectories and proposes new LTL constraints that shield the actor from future unsafe or inefficient behavior. The architecture supports both fixed, hand-specified safety constraints and adaptive, learned soft constraints that promote long-term efficiency. Our architecture is model-agnostic: any LLM-based planner can serve as the actor, and LTLCrit serves as a logic-generating wrapper. We formalize planning as graph traversal under symbolic constraints, allowing LTLCrit to analyze failed or suboptimal trajectories and generate new temporal logic rules that improve future behavior. We evaluate our system on the Minecraft diamond-mining benchmark, achieving 100% completion rates and improving efficiency compared to baseline LLM planners. Our results suggest that enabling LLMs to supervise each other through logic is a powerful and flexible paradigm for safe, generalizable decision making.

Paper number 116:
Title: SHNU Multilingual Conversational Speech Recognition System for INTERSPEECH 2025 MLC-SLM Challenge
Authors: Yuxiang Mei, Yuang Zheng, Dongxing Xu, Yanhua Long
Abstract: This paper describes SHNU multilingual conversational speech recognition system (SHNU-mASR, team name-"maybe"), submitted to Track 1 of the INTERSPEECH 2025 MLC-SLM Challenge. Our system integrates a parallel-speech-encoder architecture with a large language model (LLM) to form a unified multilingual ASR framework. The parallel-speech-encoder consists of two pre-trained encoders, the Whisper-large-v3 encoder and mHuBERT-147 encoder. Their output embeddings are concatenated and fed into the LLM, enabling the model to leverage complementary acoustic and linguistic knowledge and achieve competitive performance. Moreover, we adopt a tri-stage training strategy to jointly update the low-rank adaptation modules and projector parameters of both the speech encoders and the LLM. In addition, we incorporate an additional language-aware prompt at the LLM input to enhance language-specific text generation. The SHNU-mASR system achieves an overall character/word error rate (CER/WER) of 11.76% on the blind evaluation set of the challenge, outperforming the official MLC-SLM baseline by 8.41 absolute CER/WER, without increasing the baseline training data.

Paper number 117:
Title: Eigenvoice Synthesis based on Model Editing for Speaker Generation
Authors: Masato Murata, Koichi Miyazaki, Tomoki Koriyama, Tomoki Toda
Abstract: Speaker generation task aims to create unseen speaker voice without reference speech. The key to the task is defining a speaker space that represents diverse speakers to determine the generated speaker trait. However, the effective way to define this speaker space remains unclear. Eigenvoice synthesis is one of the promising approaches in the traditional parametric synthesis framework, such as HMM-based methods, which define a low-dimensional speaker space using pre-stored speaker features. This study proposes a novel DNN-based eigenvoice synthesis method via model editing. Unlike prior methods, our method defines a speaker space in the DNN model parameter space. By directly sampling new DNN model parameters in this space, we can create diverse speaker voices. Experimental results showed the capability of our method to generate diverse speakers' speech. Moreover, we discovered a gender-dominant axis in the created speaker space, indicating the potential to control speaker attributes.

Paper number 118:
Title: Evaluation of an Uncertainty-Aware Late Fusion Algorithm for Multi-Source Bird's Eye View Detections Under Controlled Noise
Authors: Maryem Fadili (VeDeCom, IRSEEM), Louis Lecrosnier (IRSEEM), Steve Pechberti (VeDeCom), Redouane Khemmar (IRSEEM)
Abstract: Reliable multi-source fusion is crucial for robust perception in autonomous systems. However, evaluating fusion performance independently of detection errors remains challenging. This work introduces a systematic evaluation framework that injects controlled noise into ground-truth bounding boxes to isolate the fusion process. We then propose Unified Kalman Fusion (UniKF), a late-fusion algorithm based on Kalman filtering to merge Bird's Eye View (BEV) detections while handling synchronization issues. Experiments show that UniKF outperforms baseline methods across various noise levels, achieving up to 3x lower object's positioning and orientation errors and 2x lower dimension estimation errors, while maintaining nearperfect precision and recall between 99.5% and 100%.

Paper number 119:
Title: Speaker-agnostic Emotion Vector for Cross-speaker Emotion Intensity Control
Authors: Masato Murata, Koichi Miyazaki, Tomoki Koriyama
Abstract: Cross-speaker emotion intensity control aims to generate emotional speech of a target speaker with desired emotion intensities using only their neutral speech. A recently proposed method, emotion arithmetic, achieves emotion intensity control using a single-speaker emotion vector. Although this prior method has shown promising results in the same-speaker setting, it lost speaker consistency in the cross-speaker setting due to mismatches between the emotion vector of the source and target speakers. To overcome this limitation, we propose a speaker-agnostic emotion vector designed to capture shared emotional expressions across multiple speakers. This speaker-agnostic emotion vector is applicable to arbitrary speakers. Experimental results demonstrate that the proposed method succeeds in cross-speaker emotion intensity control while maintaining speaker consistency, speech quality, and controllability, even in the unseen speaker case.

Paper number 120:
Title: MaskBeat: Loopable Drum Beat Generation
Authors: Luca A. LanzendÃ¶rfer, Florian GrÃ¶tschla, Karim Galal, Roger Wattenhofer
Abstract: We present MaskBeat, a transformer-based approach for loopable drum pattern generation. Rather than predicting drum hits sequentially, our method uses bidirectional attention with iterative refinement, allowing instruments to be generated in parallel while maintaining musical coherence. Additionally, we introduce custom loss functions that capture drum-specific musical relationships. Our experiments show that MaskBeat generates higher quality and more musically coherent drum patterns than baseline approaches.

Paper number 121:
Title: AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network
Authors: Hanjian Liu, Jinsong Gui
Abstract: This paper designs a post-disaster powered communication intelligent network (PDPCIN) to address communication disruptions caused by ground base station (GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial vehicles (UAVs) to provide wireless data collection (WDC) and wireless energy transmission (WET) for affected areas and leverages low earth orbit satellites (LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic post-disaster communication while co-optimizing age of information (AoI), energy efficiency, and spectrum efficiency, intelligent synchronization-UAV (IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and Dynamic multi-LEO access (DMLA) strategy are proposed. However, three key challenges remain: time-varying task-resource imbalances, complex topology caused by multi-device scheduling, and nonlinear coupling in multidimensional metric optimization, making system optimization NP-hard. Therefore, this paper proposes a hierarchical heterogeneous graph neural networks (HHGNN) framework. It models heterogeneous device nodes and their communication relations as a hierarchical heterogeneous graph structure, integrating our defined graph sensing, exchange, and mask layer to handle the network's input, feature propagation, and output. To search appropriate number of single-LEO SATs, we propose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we compare the proposed scheme with state-of-the-art benchmarks to validate its superior collaborative optimization of AoI, energy efficiency, and spectrum efficiency. Based on this, we derive the expressions for the expected values of AoI and stagnant AoI proportion.

Paper number 122:
Title: A Hybrid Game-Theory and Deep Learning Framework for Predicting Tourist Arrivals via Big Data Analytics and Opinion Leader Detection
Authors: Ali Nikseresht
Abstract: In the era of Industry 5.0, data-driven decision-making has become indispensable for optimizing systems across Industrial Engineering. This paper addresses the value of big data analytics by proposing a novel non-linear hybrid approach for forecasting international tourist arrivals in two different contexts: (i) arrivals to Hong Kong from five major source nations (pre-COVID-19), and (ii) arrivals to Sanya in Hainan province, China (post-COVID-19). The method integrates multiple sources of Internet big data and employs an innovative game theory-based algorithm to identify opinion leaders on social media platforms. Subsequently, nonstationary attributes in tourism demand data are managed through Empirical Wavelet Transform (EWT), ensuring refined time-frequency analysis. Finally, a memory-aware Stacked Bi-directional Long Short-Term Memory (Stacked BiLSTM) network is used to generate accurate demand forecasts. Experimental results demonstrate that this approach outperforms existing state-of-the-art techniques and remains robust under dynamic and volatile conditions, highlighting its applicability to broader Industrial Engineering domains, such as logistics, supply chain management, and production planning, where forecasting and resource allocation are key challenges. By merging advanced Deep Learning (DL), time-frequency analysis, and social media insights, the proposed framework showcases how large-scale data can elevate the quality and efficiency of decision-making processes.

Paper number 123:
Title: Statistical-Spatial Model for Motor Potentials Evoked Through Transcranial Magnetic Stimulation for the Development of Closed-Loop Procedures
Authors: Maryam Farahmandrad, Stefan Goetz
Abstract: The primary motor cortex appears to be in the center of transcranial magnetic stimulation (TMS). It is one of few locations that provide directly observable responses, and its physiology serves as model or reference for almost all other TMS targets, e.g., through the motor threshold and spatial targeting relative to its position. It furthermore sets the safety limits for the entire brain. Its easily detectable responses have led to closed-loop methods for a range of aspects, e.g., for automated thresholding, amplitude tracking, and targeting. The high variability of brain stimulation methods would substantially benefit from fast unbiased closed-loop methods. However, the development of more potent methods would early on in the design phase require proper models that allowed tuning and testing with sufficient without a high number of experiments, which are time-consuming and expensive or even impossible at the needed scale. On the one hand, theoretical researchers without access to experiments miss realistic spatial response models of brain stimulation to develop better methods. On the other hand, subjects should potentially not be exposed to early closed-loop-methods without sufficient prior testing as not yet well tuned feed-back as needed for closed-loop operation is known to erratic behavior. To bridge this gap, we developed a digital-twin-style population model that generates motor evoked potentials in response to virtual stimuli and includes statistical information on spatial (coil position and orientation) as well as recruitment in the population to represent inter- and intra-individual variability. The model allows users to simulate different subjects and millions of runs for software-in-the loop testing. The model includes all code to stimulate further development.

Paper number 124:
Title: Movable-Antenna-Enhanced Physical-Layer Service Integration: Performance Analysis and Optimization
Authors: Xuanlin Shen, Xin Wei, Weidong Mei, Zhi Chen, Jun Fang, Boyu Ning
Abstract: Movable antennas (MAs) have drawn increasing attention in wireless communications due to their capability to create favorable channel conditions via local movement within a confined region. In this letter, we investigate its application in physical-layer service integration (PHY-SI), where a multi-MA base station (BS) simultaneously transmits both confidential and multicast messages to two users. The multicast message is intended for both users, while the confidential message is intended only for one user and must remain perfectly secure from the other. Our goal is to jointly optimize the secrecy and multicast beamforming, as well as the MAs' positions at the BS to maximize the secrecy rate for one user while satisfying the multicast rate requirement for both users. To gain insights, we first conduct performance analysis of this MA-enhanced PHY-SI system in two special cases, revealing its unique characteristics compared to conventional PHY-SI with fixed-position antennas (FPAs). To address the secrecy rate maximization problem, we propose a two-layer optimization framework that integrates the semidefinite relaxation (SDR) technique and a discrete sampling algorithm. Numerical results demonstrate that MAs can greatly enhance the achievable secrecy rate region for PHY-SI compared to FPAs.

Paper number 125:
Title: Learning Variable Node Selection for Improved Multi-Round Belief Propagation Decoding
Authors: Ahmad Ismail, RaphaÃ«l Le Bidan, Elsa Dupraz, Charbel Abdel Nour
Abstract: Error correction at short blocklengths remains a challenge for low-density parity-check (LDPC) codes, as belief propagation (BP) decoding is suboptimal compared to maximum-likelihood decoding (MLD). While BP rarely makes errors, it often fails to converge due to a small number of problematic, erroneous variable nodes (VNs). Multi-round BP (MRBP) decoding improves performance by identifying and perturbing these VNs, enabling BP to succeed in subsequent decoding attempts. However, existing heuristic approaches for VN identification may require a large number of decoding rounds to approach ML performance. In this work, we draw a connection between identifying candidate VNs to perturb in MRBP and estimating channel output errors, a problem previously addressed by syndrome-based neural decoders (SBND). Leveraging this insight, we propose an SBND-inspired neural network architecture that learns to predict which VNs MRBP needs to focus on. Experimental results demonstrate that the proposed learning approach outperforms expert rules from the literature, requiring fewer MRBP decoding attempts to reach near-MLD performance. This makes it a promising lead for improving the decoding of short LDPC codes.

Paper number 126:
Title: Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength
Authors: Mahdi Ali Pour, Utku Gunay Acer
Abstract: Sound-tracking refers to the process of determining the direction from which a sound originates, making it a fundamental component of sound source localization. This capability is essential in a variety of applications, including security systems, acoustic monitoring, and speaker tracking, where accurately identifying the direction of a sound source enables real-time responses, efficient resource allocation, and improved situational awareness. While sound-tracking is closely related to localization, it specifically focuses on identifying the direction of the sound source rather than estimating its exact position in space. Despite its utility, sound-tracking systems face several challenges, such as maintaining directional accuracy and precision, along with the need for sophisticated hardware configurations and complex signal processing algorithms. This paper presents a sound-tracking method using three electret microphones. We estimate the direction of a sound source using a lightweight method that analyzes signals from three strategically placed microphones. By comparing the average power of the received signals, the system infers the most probable direction of the sound. The results indicate that the power level from each microphone effectively determines the sound source direction. Our system employs a straightforward and cost-effective hardware design, ensuring simplicity and affordability in implementation. It achieves a localization error of less than 6 degrees and a precision of 98%. Additionally, its effortless integration with various systems makes it versatile and adaptable. Consequently, this technique presents a robust and reliable solution for sound-tracking and localization, with potential applications spanning diverse domains such as security systems, smart homes, and acoustic monitoring.

Paper number 127:
Title: Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation
Authors: Hieu-Thi Luong, Inbal Rimons, Haim Permuter, Kong Aik Lee, Eng Siong Chng
Abstract: Partial audio deepfake localization pose unique challenges and remain underexplored compared to full-utterance spoofing detection. While recent methods report strong in-domain performance, their real-world utility remains unclear. In this analysis, we critically examine the limitations of current evaluation practices, particularly the widespread use of Equal Error Rate (EER), which often obscures generalization and deployment readiness. We propose reframing the localization task as a sequential anomaly detection problem and advocate for the use of threshold-dependent metrics such as accuracy, precision, recall, and F1-score, which better reflect real-world behavior. Specifically, we analyze the performance of the open-source Coarse-to-Fine Proposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on the in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the LlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our reproduced version of the same model performs worse on in-domain data (9.84%) but better on the out-of-domain sets (41.72% and 14.98%, respectively). This highlights the risks of over-optimizing for in-domain EER, which can lead to models that perform poorly in real-world scenarios. It also suggests that while deep learning models can be effective on in-domain data, they generalize poorly to out-of-domain scenarios, failing to detect novel synthetic samples and misclassifying unfamiliar bona fide audio. Finally, we observe that adding more bona fide or fully synthetic utterances to the training data often degrades performance, whereas adding partially fake utterances improves it.

Paper number 128:
Title: OMAR-RQ: Open Music Audio Representation Model Trained with Multi-Feature Masked Token Prediction
Authors: Pablo Alonso-JimÃ©nez, Pedro Ramoneda, R. Oguz Araz, Andrea Poltronieri, Dmitry Bogdanov
Abstract: Developing open-source foundation models is essential for advancing research in music audio understanding and ensuring access to powerful, multipurpose representations for music information retrieval. We present OMAR-RQ, a model trained with self-supervision via masked token classification methodologies using a large-scale dataset with over 330,000 hours of music audio. We experiment with different input features and quantization options, and achieve state-of-the-art performance in music tagging, pitch estimation, chord recognition, beat tracking, segmentation, and difficulty estimation among open self-supervised models. We open-source our training and evaluation pipelines and model weights, available at this https URL.

Paper number 129:
Title: Near-Field Codebook-Based 3D Spherical Channel Estimation for UCA XL-MIMO Systems
Authors: Chenliang Yang, Guangchi Zhang, Miao Cui, Qingqing Wu, Yong Zeng
Abstract: Extremely large-scale multiple input multiple output (XL-MIMO), a key technology for 6G communications, faces challenges in near-field channel estimation due to spherical wavefronts and the need for three-dimensional (3D) spatial characterization, particularly with uniform circular arrays (UCAs). This letter proposes a spherical-domain simultaneous orthogonal matching pursuit (S-SOMP) based scheme tailored for near-field 3D channel estimation in UCA-equipped XL-MIMO systems. We establish a sparse channel representation based on the near-field spherical wave model. Then, a novel spherical-domain transform matrix codebook is designed via joint discrete sampling of distance, azimuth, and elevation parameters, leveraging analytical approximations to ensure low correlation between steering vectors. This structured codebook enables accurate sparse signal recovery using the S-SOMP algorithm for efficient joint estimation of channel path gains, spatial angles, and distances. Simulation results demonstrate significant channel estimation accuracy improvements compared to existing benchmarks.

Paper number 130:
Title: Multi-robot Aerial Soft Manipulator For Floating Litter Collection
Authors: Antonio GonzÃ¡lez-Morgado, Sander Smits, Guillermo Heredia, Anibal Ollero, Alexandre Krupa, FranÃ§ois Chaumette, Fabien Spindler, Antonio Franchi, Chiara Gabellieri
Abstract: Removing floating litter from water bodies is crucial to preserving aquatic ecosystems and preventing environmental pollution. In this work, we present a multi-robot aerial soft manipulator for floating litter collection, leveraging the capabilities of aerial robots. The proposed system consists of two aerial robots connected by a flexible rope manipulator, which collects floating litter using a hook-based tool. Compared to single-aerial-robot solutions, the use of two aerial robots increases payload capacity and flight endurance while reducing the downwash effect at the manipulation point, located at the midpoint of the rope. Additionally, we employ an optimization-based rope-shape planner to compute the desired rope shape. The planner incorporates an adaptive behavior that maximizes grasping capabilities near the litter while minimizing rope tension when farther away. The computed rope shape trajectory is controlled by a shape visual servoing controller, which approximates the rope as a parabola. The complete system is validated in outdoor experiments, demonstrating successful grasping operations. An ablation study highlights how the planner's adaptive mechanism improves the success rate of the operation. Furthermore, real-world tests in a water channel confirm the effectiveness of our system in floating litter collection. These results demonstrate the potential of aerial robots for autonomous litter removal in aquatic environments.

Paper number 131:
Title: Limits of Safe AI Deployment: Differentiating Oversight and Control
Authors: David Manheim, Aidan Homewood
Abstract: Oversight and control (collectively, supervision) are often invoked as key levers for ensuring that AI systems are accountable, reliable, and able to fulfill governance and management requirements. However, the concepts are frequently conflated or insufficiently distinguished in academic and policy discourse, undermining efforts to design or evaluate systems that should remain under meaningful human supervision. This paper undertakes a targeted critical review of literature on supervision outside of AI, along with a brief summary of past work on the topic related to AI. We then differentiate control as being ex-ante or real-time, and operational rather than policy or governance. In contrast, oversight is either a policy and governance function, or is ex-post. We suggest that control aims to prevent failures. In contrast, oversight often focuses on detection, remediation, or incentives for future prevention; all preventative oversight strategies nonetheless necessitate control. Building on this foundation, we make three contributions. First, we propose a theoretically-informed yet policy-grounded framework that articulates the conditions under which each mechanism is possible, where they fall short, and what is required to make them meaningful in practice. Second, we outline how supervision methods should be documented and integrated into risk management, and drawing on the Microsoft Responsible AI Maturity Model, we outline a maturity model for AI supervision. Third, we explicitly highlight some boundaries of these mechanisms, including where they apply, where they fail, and where it is clear that no existing methods suffice. This foregrounds the question of whether meaningful supervision is possible in a given deployment context, and can support regulators, auditors, and practitioners in identifying both present limitations and the need for new conceptual and technical advances.

Paper number 132:
Title: Predicting Asphalt Pavement Friction Using Texture-Based Image Indicator
Authors: Bingjie Lu, Zhengyang Lu, Yijiashun Qi, Hanzhe Guo, Tianyao Sun, Zunduo Zhao
Abstract: Pavement skid resistance is of vital importance for road safety. The objective of this study is to propose and validate a texture-based image indicator to predict pavement friction. This index enables pavement friction to be measured easily and inexpensively using digital images. Three different types of asphalt surfaces (dense-graded asphalt mix, open-grade friction course, and chip seal) were evaluated subject to various tire polishing cycles. Images were taken with corresponding friction measured using Dynamic Friction Tester (DFT) in the laboratory. The aggregate protrusion area is proposed as the indicator. Statistical models are established for each asphalt surface type to correlate the proposed indicator with friction coefficients. The results show that the adjusted R-square values of all relationships are above 0.90. Compared to other image-based indicators in the literature, the proposed image indicator more accurately reflects the changes in pavement friction with the number of polishing cycles, proving its cost-effective use for considering pavement friction in mix design stage.

Paper number 133:
Title: You May Use the Same Channel Knowledge Map for Environment-Aware NLoS Sensing and Communication
Authors: Di Wu, Zhuoyin Dai, Yong Zeng
Abstract: As one of the key usage scenarios for the sixth generation (6G) wireless networks, integrated sensing and communication (ISAC) provides an efficient framework to achieve simultaneous wireless sensing and communication. However, traditional wireless sensing techniques mainly rely on the line-of-sight (LoS) assumptions, i.e., the sensing targets are directly visible to both the sensing transmitter and receiver. This hinders ISAC systems to be applied in complex environments such as the urban low-altitude airspace, which usually suffers from signal blockage and non-line-of-sight (NLoS) multi-path propagation. To address this challenge, in this paper, we propose a novel approach to enable environment-aware NLoS ISAC by leveraging the new technique called channel knowledge map (CKM), which was originally proposed for environment-aware wireless communications. One major novelty of our proposed method is that the same CKM built for wireless communication can be directly used to enable NLoS wireless sensing, thus enjoying the benefits of ``killing two birds with one stone''. To this end, the sensing targets are treated as virtual user equipment (UE), and the wireless communication channel priors are transformed into the sensing channel priors, allowing one single CKM to serve dual purposes. We illustrate our proposed framework by a specific CKM called \emph{channel angle-delay map} (CADM). Specifically, the proposed framework utilizes CADM to derive angle-delay priors of the sensing channel by exploiting the relationship between communication and sensing angle-delay distributions, enabling sensing target localization in the challenging NLoS environment. Extensive simulation results demonstrate significant performance improvements over classic geometry-based sensing methods, which is further validated by CramÃ©r-Rao Lower Bound (CRLB) analysis.

Paper number 134:
Title: RECA-PD: A Robust Explainable Cross-Attention Method for Speech-based Parkinson's Disease Classification
Authors: Terry Yi Zhong, Cristian Tejedor-Garcia, Martha Larson, Bastiaan R. Bloem
Abstract: Parkinson's Disease (PD) affects over 10 million people globally, with speech impairments often preceding motor symptoms by years, making speech a valuable modality for early, non-invasive detection. While recent deep-learning models achieve high accuracy, they typically lack the explainability required for clinical use. To address this, we propose RECA-PD, a novel, robust, and explainable cross-attention architecture that combines interpretable speech features with self-supervised representations. RECA-PD matches state-of-the-art performance in Speech-based PD detection while providing explanations that are more consistent and more clinically meaningful. Additionally, we demonstrate that performance degradation in certain speech tasks (e.g., monologue) can be mitigated by segmenting long recordings. Our findings indicate that performance and explainability are not necessarily mutually exclusive. Future work will enhance the usability of explanations for non-experts and explore severity estimation to increase the real-world clinical relevance.

Paper number 135:
Title: MusGO: A Community-Driven Framework For Assessing Openness in Music-Generative AI
Authors: Roser Batlle-Roca, Laura IbÃ¡Ã±ez-MartÃ­nez, Xavier Serra, Emilia GÃ³mez, MartÃ­n Rocamora
Abstract: Since 2023, generative AI has rapidly advanced in the music domain. Despite significant technological advancements, music-generative models raise critical ethical challenges, including a lack of transparency and accountability, along with risks such as the replication of artists' works, which highlights the importance of fostering openness. With upcoming regulations such as the EU AI Act encouraging open models, many generative models are being released labelled as 'open'. However, the definition of an open model remains widely debated. In this article, we adapt a recently proposed evidence-based framework for assessing openness in LLMs to the music domain. Using feedback from a survey of 110 participants from the Music Information Retrieval (MIR) community, we refine the framework into MusGO (Music-Generative Open AI), which comprises 13 openness categories: 8 essential and 5 desirable. We evaluate 16 state-of-the-art generative models and provide an openness leaderboard that is fully open to public scrutiny and community contributions. Through this work, we aim to clarify the concept of openness in music-generative AI and promote its transparent and responsible development.

Paper number 136:
Title: Subpixel correction of diffraction pattern shifts in ptychography via automatic differentiation
Authors: Zhengkang Xu, Yanqi Chen, Hao Xu, Qingxin Wang, Jin Niu, Lei Huang, Jiyue Tang, Yongjun Ma, Yutong Wang, Yishi Shi, Changjun Ke, Jie Li, Zhongwei Fan
Abstract: Ptychography, a coherent diffraction imaging technique, has become an indispensable tool in materials characterization, biological imaging, and nanostructure analysis due to its capability for high-resolution, lensless reconstruction of complex-valued images. In typical workflows, raw diffraction patterns are commonly cropped to isolate the valid central region before reconstruction. However, if the crop is misaligned from the diffraction pattern's zero-order, reconstruction may suffer from slower convergence, phase wrapping, and reduced image fidelity. These issues are further exacerbated in experimental configurations involving reflective geometries or broadband illumination, where incorrect cropping introduces systematic preprocessing errors that compromise the entire ptychographic inversion. To address this challenge, we present an approach based on automatic differentiation (AD), where the cropping shift is treated as an optimizable parameter within the reconstruction framework. By integrating shift correction into the backpropagation loop, our method simultaneously refines the object, probe, and shift positions without requiring manual tuning. Simulation results demonstrate that, even with initial offsets ranging up to 5 pixels, the proposed method achieves subpixel correction, with an average deviation below 0.5 pixels. Experiments in the extreme ultraviolet (EUV) regime further validate the method's robustness and effectiveness. This AD-based strategy enhances the automation and robustness of ptychographic reconstructions, and is adaptable to diverse experimental conditions.

Paper number 137:
Title: Improving Low-Resource Dialect Classification Using Retrieval-based Voice Conversion
Authors: Lea Fischbach, Akbar Karimi, Caroline Kleen, Alfred Lameli, Lucie Flek
Abstract: Deep learning models for dialect identification are often limited by the scarcity of dialectal data. To address this challenge, we propose to use Retrieval-based Voice Conversion (RVC) as an effective data augmentation method for a low-resource German dialect classification task. By converting audio samples to a uniform target speaker, RVC minimizes speaker-related variability, enabling models to focus on dialect-specific linguistic and phonetic features. Our experiments demonstrate that RVC enhances classification performance when utilized as a standalone augmentation method. Furthermore, combining RVC with other augmentation methods such as frequency masking and segment removal leads to additional performance gains, highlighting its potential for improving dialect classification in low-resource scenarios.

Paper number 138:
Title: StreamDiT: Real-Time Streaming Text-to-Video Generation
Authors: Akio Kodaira, Tingbo Hou, Ji Hou, Masayoshi Tomizuka, Yue Zhao
Abstract: Recently, great progress has been achieved in text-to-video (T2V) generation by scaling transformer-based diffusion models to billions of parameters, which can generate high-quality videos. However, existing models typically produce only short clips offline, restricting their use cases in interactive and real-time applications. This paper addresses these challenges by proposing StreamDiT, a streaming video generation model. StreamDiT training is based on flow matching by adding a moving buffer. We design mixed training with different partitioning schemes of buffered frames to boost both content consistency and visual quality. StreamDiT modeling is based on adaLN DiT with varying time embedding and window attention. To practice the proposed method, we train a StreamDiT model with 4B parameters. In addition, we propose a multistep distillation method tailored for StreamDiT. Sampling distillation is performed in each segment of a chosen partitioning scheme. After distillation, the total number of function evaluations (NFEs) is reduced to the number of chunks in a buffer. Finally, our distilled model reaches real-time performance at 16 FPS on one GPU, which can generate video streams at 512p resolution. We evaluate our method through both quantitative metrics and human evaluation. Our model enables real-time applications, e.g. streaming generation, interactive generation, and video-to-video. We provide video results and more examples in our project website: <a href="this https URL https URL.</a>

Paper number 139:
Title: Assessing the Viability of Wave Field Synthesis in VR-Based Cognitive Research
Authors: Benjamin Kahl
Abstract: This paper investigates the viability of Wave Field Synthesis (WFS) for enhancing auditory immersion in VR-based cognitive research. While Virtual Reality (VR) offers significant advantages for studying human perception and behavior, auditory cues are often underutilized. WFS, an advanced audio rendering technique, can create highly realistic and spatially accurate soundscapes, potentially increasing ecological validity. This study evaluates WFS by implementing a sample experiment where participants localize static and moving sound sources in both a WFS-rendered environment and a conventional stereo headphone setup. The research explores the impact of virtual environments, sound types, and durations on localization accuracy and search behavior. Findings indicate that while stereo setups can achieve higher accuracy, WFS provides a more natural and intuitive auditory experience, particularly for directional cues. The study also highlights limitations of current WFS systems, such as the lack of height localization, occlusion simulation, and user-dependent optimization, which affect performance, especially for centrally located sound sources. Despite these challenges, WFS shows promise for specialized auditory perception research, particularly for complex soundscapes where directional information is paramount.

Paper number 140:
Title: On the Distribution of Age of Information in Time-varying Updating Systems
Authors: Jin Xu, Weiqi Wang, Natarajan Gautam
Abstract: Age of Information (AoI) is a crucial metric for quantifying information freshness in real-time systems where the sampling rate of data packets is time-varying. Evaluating AoI under such conditions is challenging, as system states become temporally correlated and traditional stationary analysis is inapplicable. We investigate an $M_{t}/G/1/1$ queueing system with a time-varying sampling rate and probabilistic preemption, proposing a novel analytical framework based on multi-dimensional partial differential equations (PDEs) to capture the time evolution of the system's status distribution. To solve the PDEs, we develop a decomposition technique that breaks the high-dimensional PDE into lower-dimensional subsystems. Solving these subsystems allows us to derive the Aol distribution at arbitrary time instances. We show AoI does not exhibit a memoryless property, even with negligible processing times, due to its dependence on the historical sampling process. Our framework extends to the stationary setting, where we derive a closed-form expression for the Laplace-Stieltjes Transform (LST) of the steady-state AoI. Numerical experiments reveal AoI exhibits a non-trivial lag in response to sampling rate changes. Our results also show that no single preemption probability or processing time distribution can minimize Aol violation probability across all thresholds in either time-varying or stationary scenarios. Finally, we formulate an optimization problem and propose a heuristic method to find sampling rates that reduce costs while satisfying AoI constraints.

Paper number 141:
Title: Study of AP Association and Users and Power Allocation for Cell-Free Massive MIMO Systems
Authors: S. Mohammadzadeh, S. Mashdour, R. C. de Lamare, K. Cumanan, C. Li
Abstract: This paper introduces an access point-user (AP-UE) association strategy combined with pilot power allocation to mitigate multiuser interference and enhance spectral efficiency (SE) in clustered cell-free massive MIMO (CCF-mMIMO) networks. We propose a dynamic channel-based clustering method that groups APs according to their channel correlation, ensuring users are associated with APs exhibiting similar channel characteristics. The proposed approach exploits hierarchical clustering, enabling flexible cluster sizing to improve interference management and overall SE. Moreover, we present a power control (PC) technique that is based on a weighted sum-rate maximization (WSRM) algorithm to ensure consistent service quality across users. Numerical results demonstrate that the proposed method achieves superior SE and robust performance in high-density multi-user environments as compared to competing approaches.

Paper number 142:
Title: Latent FxLMS: Accelerating Active Noise Control with Neural Adaptive Filters
Authors: Kanad Sarkar, Austin Lu, Manan Mittal, Yongjie Zhuang, Ryan Corey, Andrew Singer
Abstract: Filtered-X LMS (FxLMS) is commonly used for active noise control (ANC), wherein the soundfield is minimized at a desired location. Given prior knowledge of the spatial region of the noise or control sources, we could improve FxLMS by adapting along the low-dimensional manifold of possible adaptive filter weights. We train an auto-encoder on the filter coefficients of the steady-state adaptive filter for each primary source location sampled from a given spatial region and constrain the weights of the adaptive filter to be the output of the decoder for a given state of latent variables. Then, we perform updates in the latent space and use the decoder to generate the cancellation filter. We evaluate how various neural network constraints and normalization techniques impact the convergence speed and steady-state mean squared error. Under certain conditions, our Latent FxLMS model converges in fewer steps with comparable steady-state error to the standard FxLMS.

Paper number 143:
Title: RateCount: Learning-Free Device Counting by Wi-Fi Probe Listening
Authors: Tianlang He, Zhangyu Chang, S.-H. Gary Chan
Abstract: A Wi-Fi-enabled device, or simply Wi-Fi device, sporadically broadcasts probe request frames (PRFs) to discover nearby access points (APs), whether connected to an AP or not. To protect user privacy, unconnected devices often randomize their MAC addresses in the PRFs, known as MAC address randomization. While prior works have achieved accurate device counting under MAC address randomization, they typically rely on machine learning, resulting in inefficient deployment due to the time-consuming processes of data cleaning, model training, and hyperparameter tuning. To enhance deployment efficiency, we propose RateCount, an accurate, lightweight, and learning-free counting approach based on the rate at which APs receive PRFs within a window. RateCount employs a provably unbiased closed-form expression to estimate the device count time-averaged over the window and an error model to compute the lower bound of the estimation variance. We also demonstrate how to extend RateCount to people counting by incorporating a device-to-person calibration scheme. Through extensive real-world experiments conducted at multiple sites spanning a wide range of counts, we show that RateCount, without any deployment costs for machine learning, achieves comparable counting accuracy with the state-of-the-art learning-based device counting and improves previous people counting schemes by a large margin.

Paper number 144:
Title: Resource Allocation for Multi-waveguide Pinching Antenna-assisted Broadcast Networks
Authors: Ruotong Zhao, Shaokang Hu, Deepak Mishra, Derrick Wing Kwan Ng
Abstract: In this paper, we investigate the resource allocation for multi-dielectric waveguide-assisted broadcast systems, where each waveguide employs multiple pinching antennas (PAs), aiming to maximize the minimum achievable rate among multiple users. To capture realistic propagation effects, we propose a novel generalized frequency-dependent power attenuation model for dielectric waveguides PA system. We jointly optimize waveguide beamforming, PA power allocation, and antenna positions via a block coordinate descent scheme that capitalizes on majorization minimization and penalty methods, circumventing the inherent non-convexity of the formulated optimization problem and obtaining a computationally efficient sub-optimal solution. Simulation results demonstrate that our proposed framework substantially outperforms both conventional antenna systems and single-PA-per-waveguide configurations, clearly illustrating the intricate trade-offs between waveguide propagation loss, path loss, and resource allocation among multiple PAs.

Paper number 145:
Title: FollowSpot: Enhancing Wireless Communications via Movable Ceiling-Mounted Metasurfaces
Authors: Wenhai Lai, Kaiming Shen, Rui Zhang
Abstract: This paper studies the optimal placement of ceiling-mounted metasurfaces (MTSs) to help focus the wireless signal beam onto the target receiver, as inspired by the theatre spotlight. We assume that a total of $M$ MTSs are deployed, and that there are $L$ possible positions for each MTS. The resulting signal-to-noise (SNR) maximization problem is difficult to tackle directly because of the coupling between the placement decisions of the different MTSs. Mathematically, we are faced with a nonlinear discrete optimization problem with $L^M$ possible solutions. A remarkable result shown in this paper is that the above challenging problem can be efficiently solved within $O(ML^2\log(ML))$ time. There are two key steps in developing the proposed algorithm. First, we successfully decouple the placement variables of different MTSs by introducing a continuous auxiliary variable $\mu$; the discrete primal variables are now easy to optimize when $\mu$ is held fixed, but the optimization problem of $\mu$ is nonconvex. Second, we show that the optimization of continuous $\mu$ can be recast into a discrete optimization problem with only $LM$ possible solutions, so the optimal $\mu$ can now be readily obtained. Numerical results show that the proposed algorithm can not only guarantee a global optimum but also reach the optimal solution efficiently.

Paper number 146:
Title: Optimizing Age of Trust and Throughput in Multi-Hop UAV-Aided IoT Networks
Authors: Yizhou Luo, Kwan-Wu Chin, Ruyi Guan, Xi Xiao, Caimeng Wang, Jingyin Feng, Tengjiao He
Abstract: Devices operating in Internet of Things (IoT) networks may be deployed across vast geographical areas and interconnected via multi-hop communications. Further, they may be unguarded. This makes them vulnerable to attacks and motivates operators to check on devices frequently. To this end, we propose and study an Unmanned Aerial Vehicle (UAV)-aided attestation framework for use in IoT networks with a charging station powered by solar. A key challenge is optimizing the trajectory of the UAV to ensure it attests as many devices as possible. A trade-off here is that devices being checked by the UAV are offline, which affects the amount of data delivered to a gateway. Another challenge is that the charging station experiences time-varying energy arrivals, which in turn affect the flight duration and charging schedule of the UAV. To address these challenges, we employ a Deep Reinforcement Learning (DRL) solution to optimize the UAV's charging schedule and the selection of devices to be attested during each flight. The simulation results show that our solution reduces the average age of trust by 88% and throughput loss due to attestation by 30%.

Paper number 147:
Title: Scalable Learning of High-Dimensional Demonstrations with Composition of Linear Parameter Varying Dynamical Systems
Authors: Shreenabh Agrawal, Hugo T. M. Kussaba, Lingyun Chen, Allen Emmanuel Binny, Abdalla Swikir, Pushpak Jagtap, Sami Haddadin
Abstract: Learning from Demonstration (LfD) techniques enable robots to learn and generalize tasks from user demonstrations, eliminating the need for coding expertise among end-users. One established technique to implement LfD in robots is to encode demonstrations in a stable Dynamical System (DS). However, finding a stable dynamical system entails solving an optimization problem with bilinear matrix inequality (BMI) constraints, a non-convex problem which, depending on the number of scalar constraints and variables, demands significant computational resources and is susceptible to numerical issues such as floating-point errors. To address these challenges, we propose a novel compositional approach that enhances the applicability and scalability of learning stable DSs with BMIs.

Paper number 148:
Title: NRSeg: Noise-Resilient Learning for BEV Semantic Segmentation via Driving World Models
Authors: Siyu Li, Fei Teng, Yihong Cao, Kailun Yang, Zhiyong Li, Yaonan Wang
Abstract: Birds' Eye View (BEV) semantic segmentation is an indispensable perception task in end-to-end autonomous driving systems. Unsupervised and semi-supervised learning for BEV tasks, as pivotal for real-world applications, underperform due to the homogeneous distribution of the labeled data. In this work, we explore the potential of synthetic data from driving world models to enhance the diversity of labeled data for robustifying BEV segmentation. Yet, our preliminary findings reveal that generation noise in synthetic data compromises efficient BEV model learning. To fully harness the potential of synthetic data from world models, this paper proposes NRSeg, a noise-resilient learning framework for BEV semantic segmentation. Specifically, a Perspective-Geometry Consistency Metric (PGCM) is proposed to quantitatively evaluate the guidance capability of generated data for model learning. This metric originates from the alignment measure between the perspective road mask of generated data and the mask projected from the BEV labels. Moreover, a Bi-Distribution Parallel Prediction (BiDPP) is designed to enhance the inherent robustness of the model, where the learning process is constrained through parallel prediction of multinomial and Dirichlet distributions. The former efficiently predicts semantic probabilities, whereas the latter adopts evidential deep learning to realize uncertainty quantification. Furthermore, a Hierarchical Local Semantic Exclusion (HLSE) module is designed to address the non-mutual exclusivity inherent in BEV semantic segmentation tasks. Experimental results demonstrate that NRSeg achieves state-of-the-art performance, yielding the highest improvements in mIoU of 13.8% and 11.4% in unsupervised and semi-supervised BEV segmentation tasks, respectively. The source code will be made publicly available at this https URL.

Paper number 149:
Title: CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning
Authors: Jiacheng Shi, Yanfu Zhang, Ye Gao
Abstract: Speech Emotion Recognition (SER) is fundamental to affective computing and human-computer interaction, yet existing models struggle to generalize across diverse acoustic conditions. While Contrastive Language-Audio Pretraining (CLAP) provides strong multimodal alignment, it lacks dedicated mechanisms for capturing emotional cues, making it suboptimal for SER. To address this, we propose CLEP-DG, a framework that enhances CLAP's robustness in emotion recognition. First, we fine-tune CLAP to obtain CLEP, adapting it on large-scale emotional speech datasets to better encode emotion-relevant features. Then, we introduce Acoustic Context Prompt Tuning (ACPT), a text-driven augmentation strategy that optimizes learnable prompt vectors to model diverse acoustic environments without additional labeled audio. Finally, leveraging cross-modal transferability, we train a classifier on text-derived embeddings and apply it to the audio encoder during inference, mitigating domain shifts between textual supervision and audio-based emotion recognition. Experiments across five benchmark datasets show that CLEP-DG outperforms prior CLAP-based approaches, achieving state-of-the-art performance in both supervised and domain generalization settings.

Paper number 150:
Title: Hierarchical Testing with Rabbit Optimization for Industrial Cyber-Physical Systems
Authors: Jinwei Hu, Zezhi Tang, Xin Jin, Benyuan Zhang, Yi Dong, Xiaowei Huang
Abstract: This paper presents HERO (Hierarchical Testing with Rabbit Optimization), a novel black-box adversarial testing framework for evaluating the robustness of deep learning-based Prognostics and Health Management systems in Industrial Cyber-Physical Systems. Leveraging Artificial Rabbit Optimization, HERO generates physically constrained adversarial examples that align with real-world data distributions via global and local perspective. Its generalizability ensures applicability across diverse ICPS scenarios. This study specifically focuses on the Proton Exchange Membrane Fuel Cell system, chosen for its highly dynamic operational conditions, complex degradation mechanisms, and increasing integration into ICPS as a sustainable and efficient energy solution. Experimental results highlight HERO's ability to uncover vulnerabilities in even state-of-the-art PHM models, underscoring the critical need for enhanced robustness in real-world applications. By addressing these challenges, HERO demonstrates its potential to advance more resilient PHM systems across a wide range of ICPS domains.

Paper number 151:
Title: Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning
Authors: Ho Jae Lee, Se Hwan Jeon, Sangbae Kim
Abstract: Humans naturally swing their arms during locomotion to regulate whole-body dynamics, reduce angular momentum, and help maintain balance. Inspired by this principle, we present a limb-level multi-agent reinforcement learning (RL) framework that enables coordinated whole-body control of humanoid robots through emergent arm motion. Our approach employs separate actor-critic structures for the arms and legs, trained with centralized critics but decentralized actors that share only base states and centroidal angular momentum (CAM) observations, allowing each agent to specialize in task-relevant behaviors through modular reward design. The arm agent guided by CAM tracking and damping rewards promotes arm motions that reduce overall angular momentum and vertical ground reaction moments, contributing to improved balance during locomotion or under external perturbations. Comparative studies with single-agent and alternative multi-agent baselines further validate the effectiveness of our approach. Finally, we deploy the learned policy on a humanoid platform, achieving robust performance across diverse locomotion tasks, including flat-ground walking, rough terrain traversal, and stair climbing.

Paper number 152:
Title: Navigating Speech Recording Collections with AI-Generated Illustrations
Authors: Sirina HÃ¥land, Trond Karlsen StrÃ¸m, Petra GaluÅ¡ÄÃ¡kovÃ¡
Abstract: Although the amount of available spoken content is steadily increasing, extracting information and knowledge from speech recordings remains challenging. Beyond enhancing traditional information retrieval methods such as speech search and keyword spotting, novel approaches for navigating and searching spoken content need to be explored and developed. In this paper, we propose a novel navigational method for speech archives that leverages recent advances in language and multimodal generative models. We demonstrate our approach with a Web application that organizes data into a structured format using interactive mind maps and image generation tools. The system is implemented using the TED-LIUM~3 dataset, which comprises over 2,000 speech transcripts and audio files of TED Talks. Initial user tests using a System Usability Scale (SUS) questionnaire indicate the application's potential to simplify the exploration of large speech collections.

Paper number 153:
Title: Gramians for a New Class of Nonlinear Control Systems Using Koopman and a Novel Generalized SVD
Authors: Brian Brown, Michael King
Abstract: Model reduction with error bounds in nonlinear systems with non-affine control inputs remains an active field of research. In this work we present a construction for Controllability and Observability Gramians in a class of non-affine control input systems satisfying certain induced norm properties. We do so using a combination of representational forms, including a novel function decomposition that resembles linear Singular Value Decomposition (SVD), in tandem with an additional unconventional decomposition of the dynamics, and Koopman operator theory. The resulting representation allows one to place error bounds on the $H_{\infty}$ norm on a reduced-order representation of the system computed using finite-dimensional nonlinear Controllability and Observability Gramians.

Paper number 154:
Title: Towards Spatially-Varying Gain and Binning
Authors: Anqi Yang, Eunhee Kang, Wei Chen, Hyong-Euk Lee, Aswin C. Sankaranarayanan
Abstract: Pixels in image sensors have progressively become smaller, driven by the goal of producing higher-resolution imagery. However, ceteris paribus, a smaller pixel accumulates less light, making image quality worse. This interplay of resolution, noise, and the dynamic range of the sensor and their impact on the eventual quality of acquired imagery is a fundamental concept in photography. In this paper, we propose spatially-varying gain and binning to enhance the noise performance and dynamic range of image sensors. First, we show that by varying gain spatially to local scene brightness, the read noise can be made negligible, and the dynamic range of a sensor is expanded by an order of magnitude. Second, we propose a simple analysis to find a binning size that best balances resolution and noise for a given light level; this analysis predicts a spatially-varying binning strategy, again based on local scene brightness, to effectively increase the overall signal-to-noise ratio. % without sacrificing resolution. We discuss analog and digital binning modes and, perhaps surprisingly, show that digital binning outperforms its analog counterparts when a larger gain is allowed. Finally, we demonstrate that combining spatially-varying gain and binning in various applications, including high dynamic range imaging, vignetting, and lens distortion.

Paper number 155:
Title: Mutual Information Bounds for Lossy Common Information
Authors: Anderson de Andrade
Abstract: We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and GÃ¡cs-KÃ¶rner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).

Paper number 156:
Title: Normalized Iterative Hard Thresholding for Tensor Recovery
Authors: Li Li, Yuneng Liang, Kaijie Zheng, Jian Lu
Abstract: Low-rank recovery builds upon ideas from the theory of compressive sensing, which predicts that sparse signals can be accurately reconstructed from incomplete measurements. Iterative thresholding-type algorithms-particularly the normalized iterative hard thresholding (NIHT) method-have been widely used in compressed sensing (CS) and applied to matrix recovery tasks. In this paper, we propose a tensor extension of NIHT, referred to as TNIHT, for the recovery of low-rank tensors under two widely used tensor decomposition models. This extension enables the effective reconstruction of high-order low-rank tensors from a limited number of linear measurements by leveraging the inherent low-dimensional structure of multi-way data. Specifically, we consider both the CANDECOMP/PARAFAC (CP) rank and the Tucker rank to characterize tensor low-rankness within the TNIHT framework. At the same time, we establish a convergence theorem for the proposed TNIHT method under the tensor restricted isometry property (TRIP), providing theoretical support for its recovery guarantees. Finally, we evaluate the performance of TNIHT through numerical experiments on synthetic, image, and video data, and compare it with several state-of-the-art algorithms.

Paper number 157:
Title: Efficient Learning of A Unified Policy For Whole-body Manipulation and Locomotion Skills
Authors: Dianyong Hou, Chengrui Zhu, Zhen Zhang, Zhibin Li, Chuang Guo, Yong Liu
Abstract: Equipping quadruped robots with manipulators provides unique loco-manipulation capabilities, enabling diverse practical applications. This integration creates a more complex system that has increased difficulties in modeling and control. Reinforcement learning (RL) offers a promising solution to address these challenges by learning optimal control policies through interaction. Nevertheless, RL methods often struggle with local optima when exploring large solution spaces for motion and manipulation tasks. To overcome these limitations, we propose a novel approach that integrates an explicit kinematic model of the manipulator into the RL framework. This integration provides feedback on the mapping of the body postures to the manipulator's workspace, guiding the RL exploration process and effectively mitigating the local optima issue. Our algorithm has been successfully deployed on a DeepRobotics X20 quadruped robot equipped with a Unitree Z1 manipulator, and extensive experimental results demonstrate the superior performance of this approach.

Paper number 158:
Title: High-Resolution Sustain Pedal Depth Estimation from Piano Audio Across Room Acoustics
Authors: Kun Fang, Hanwen Zhang, Ziyu Wang, Ichiro Fujinaga
Abstract: Piano sustain pedal detection has previously been approached as a binary on/off classification task, limiting its application in real-world piano performance scenarios where pedal depth significantly influences musical expression. This paper presents a novel approach for high-resolution estimation that predicts continuous pedal depth values. We introduce a Transformer-based architecture that not only matches state-of-the-art performance on the traditional binary classification task but also achieves high accuracy in continuous pedal depth estimation. Furthermore, by estimating continuous values, our model provides musically meaningful predictions for sustain pedal usage, whereas baseline models struggle to capture such nuanced expressions with their binary detection approach. Additionally, this paper investigates the influence of room acoustics on sustain pedal estimation using a synthetic dataset that includes varied acoustic conditions. We train our model with different combinations of room settings and test it in an unseen new environment using a "leave-one-out" approach. Our findings show that the two baseline models and ours are not robust to unseen room conditions. Statistical analysis further confirms that reverberation influences model predictions and introduces an overestimation bias.

Paper number 159:
Title: Domain Adaptation of Drag Reduction Policy to Partial Measurements
Authors: Anton Plaksin, Georgios Rigas
Abstract: Feedback control of fluid-based systems poses significant challenges due to their high-dimensional, nonlinear, and multiscale dynamics, which demand real-time, three-dimensional, multi-component measurements for sensing. While such measurements are feasible in digital simulations, they are often only partially accessible in the real world. In this paper, we propose a method to adapt feedback control policies obtained from full-state measurements to setups with only partial measurements. Our approach is demonstrated in a simulated environment by minimising the aerodynamic drag of a simplified road vehicle. Reinforcement learning algorithms can optimally solve this control task when trained on full-state measurements by placing sensors in the wake. However, in real-world applications, sensors are limited and typically only on the vehicle, providing only partial measurements. To address this, we propose to train a Domain Specific Feature Transfer (DSFT) map reconstructing the full measurements from the history of the partial measurements. By applying this map, we derive optimal policies based solely on partial data. Additionally, our method enables determination of the optimal history length and offers insights into the architecture of optimal control policies, facilitating their implementation in real-world environments with limited sensor information.

Paper number 160:
Title: Implicit Dual-Control for Visibility-Aware Navigation in Unstructured Environments
Authors: Benjamin Johnson, Qilun Zhu, Robert Prucka, Morgan Barron, Miriam Figueroa-Santos, Matthew Castanier
Abstract: Navigating complex, cluttered, and unstructured environments that are a priori unknown presents significant challenges for autonomous ground vehicles, particularly when operating with a limited field of view(FOV) resulting in frequent occlusion and unobserved space. This paper introduces a novel visibility-aware model predictive path integral framework(VA-MPPI). Formulated as a dual control problem where perceptual uncertainties and control decisions are intertwined, it reasons over perception uncertainty evolution within a unified planning and control pipeline. Unlike traditional methods that rely on explicit uncertainty objectives, the VA-MPPI controller implicitly balances exploration and exploitation, reducing uncertainty only when system performance would be increased. The VA-MPPI framework is evaluated in simulation against deterministic and prescient controllers across multiple scenarios, including a cluttered urban alleyway and an occluded off-road environment. The results demonstrate that VA-MPPI significantly improves safety by reducing collision with unseen obstacles while maintaining competitive performance. For example, in the off-road scenario with 400 control samples, the VA-MPPI controller achieved a success rate of 84%, compared to only 8% for the deterministic controller, with all VA-MPPI failures arising from unmet stopping criteria rather than collisions. Furthermore, the controller implicitly avoids unobserved space, improving safety without explicit directives. The proposed framework highlights the potential for robust, visibility-aware navigation in unstructured and occluded environments, paving the way for future advancements in autonomous ground vehicle systems.

Paper number 161:
Title: Rapid and Safe Trajectory Planning over Diverse Scenes through Diffusion Composition
Authors: Wule Mao, Zhouheng Li, Yunhao Luo, Yilun Du, Lei Xie
Abstract: Safe trajectory planning remains a significant challenge in complex environments, where traditional methods often trade off computational efficiency for safety. Comprehensive obstacle modeling improves safety but is computationally expensive, while approximate methods are more efficient but may compromise safety. To address this issue, this paper introduces a rapid and safe trajectory planning framework based on state-based diffusion models. Leveraging only low-dimensional vehicle states, the diffusion models achieve notable inference efficiency while ensuring sufficient collision-free characteristics. By composing diffusion models, the proposed framework can safely generalize across diverse scenarios, planning collision-free trajectories even in unseen scenes. To further ensure the safety of the generated trajectories, an efficient, rule-based safety filter is proposed, which selects optimal trajectories that satisfy both sufficient safety and control feasibility from among candidate trajectories. Both in seen and unseen scenarios, the proposed method achieves efficient inference time while maintaining high safety and stability. Evaluations on the F1TENTH vehicle further demonstrate that the proposed method is practical in real-world applications. The project page is at: this https URL.

Paper number 162:
Title: Inverse Reinforcement Learning using Revealed Preferences and Passive Stochastic Optimization
Authors: Vikram Krishnamurthy
Abstract: This monograph, spanning three chapters, explores Inverse Reinforcement Learning (IRL). The first two chapters view inverse reinforcement learning (IRL) through the lens of revealed preferences from microeconomics while the third chapter studies adaptive IRL via Langevin dynamics stochastic gradient algorithms. Chapter uses classical revealed preference theory (Afriat's theorem and extensions) to identify constrained utility maximizers based on observed agent actions. This allows for the reconstruction of set-valued estimates of an agent's utility. We illustrate this procedure by identifying the presence of a cognitive radar and reconstructing its utility function. The chapter also addresses the construction of a statistical detector for utility maximization behavior when agent actions are corrupted by noise. Chapter 2 studies Bayesian IRL. It investigates how an analyst can determine if an observed agent is a rationally inattentive Bayesian utility maximizer (i.e., simultaneously optimizing its utility and observation likelihood). The chapter discusses inverse stopping-time problems, focusing on reconstructing the continuation and stopping costs of a Bayesian agent operating over a random horizon. We then apply this IRL methodology to identify the presence of a Bayes-optimal sequential detector. Additionally, Chapter 2 provides a concise overview of discrete choice models, inverse Bayesian filtering, and inverse stochastic gradient algorithms for adaptive IRL. Finally, Chapter 3 introduces an adaptive IRL approach utilizing passive Langevin dynamics. This method aims to track time-varying utility functions given noisy and misspecified gradients. In essence, the adaptive IRL algorithms presented in Chapter 3 can be conceptualized as inverse stochastic gradient algorithms, as they learn the utility function in real-time while a stochastic gradient algorithm is in operation.

Paper number 163:
Title: Machine Learning in Acoustics: A Review and Open-Source Repository
Authors: Ryan A. McCarthy, You Zhang, Samuel A. Verburg, William F. Jenkins, Peter Gerstoft
Abstract: Acoustic data provide scientific and engineering insights in fields ranging from bioacoustics and communications to ocean and earth sciences. In this review, we survey recent advances and the transformative potential of machine learning (ML) in acoustics, including deep learning (DL). Using the Python high-level programming language, we demonstrate a broad collection of ML techniques to detect and find patterns for classification, regression, and generation in acoustics data automatically. We have ML examples including acoustic data classification, generative modeling for spatial audio, and physics-informed neural networks. This work includes AcousticsML, a set of practical Jupyter notebook examples on GitHub demonstrating ML benefits and encouraging researchers and practitioners to apply reproducible data-driven approaches to acoustic challenges.

Paper number 164:
Title: TeleSim: A Network-Aware Testbed and Benchmark Dataset for Telerobotic Applications
Authors: Zexin Deng (University of Warwick, UK), Zhenhui Yuan (University of Warwick, UK), Longhao Zou (Pengcheng Laboratory, China)
Abstract: Telerobotic technologies are becoming increasingly essential in fields such as remote surgery, nuclear decommissioning, and space exploration. Reliable datasets and testbeds are essential for evaluating telerobotic system performance prior to real-world deployment. However, there is a notable lack of datasets that capture the impact of network delays, as well as testbeds that realistically model the communication link between the operator and the robot. This paper introduces TeleSim, a network-aware teleoperation dataset and testbed designed to assess the performance of telerobotic applications under diverse network conditions. TeleSim systematically collects performance data from fine manipulation tasks executed under three predefined network quality tiers: High, Medium, and Low. Each tier is characterized through controlled settings of bandwidth, latency, jitter, and packet loss. Using OMNeT++ for precise network simulation, we record a wide range of metrics, including completion time, success rates, video quality indicators (Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM)), and quality of service (QoS) parameters. TeleSim comprises 300 experimental trials, providing a robust benchmark for evaluating teleoperation systems across heterogeneous network scenarios. In the worst network condition, completion time increases by 221.8% and success rate drops by 64%. Our findings reveal that network degradation leads to compounding negative impacts, notably reduced video quality and prolonged task execution, highlighting the need for adaptive, resilient teleoperation protocols. The full dataset and testbed software are publicly available on our GitHub repository: this https URL and YouTube channel: this https URL.

Paper number 165:
Title: A Quadratic Programming Algorithm with $O(n^3)$ Time Complexity
Authors: Liang Wu, Richard D. Braatz
Abstract: Solving linear systems and quadratic programming (QP) problems are both ubiquitous tasks in the engineering and computing fields. Direct methods for solving systems, such as Cholesky, LU, and QR factorizations, exhibit data-independent time complexity of $O(n^3)$. This raises a natural question: could there exist algorithms for solving QPs that also achieve \textit{data-independent} time complexity of $O(n^3)$? This raises a natural question: could there exist algorithms for solving QPs that also achieve data-independent time complexity of $O(n^3)$? This is critical for offering an execution time certificate for real-time optimization-based applications such as model predictive control. This article first demonstrates that solving real-time strictly convex QPs, Lasso problems, and support vector machine problems can be turned into solving box-constrained QPs (Box-QPs), which support a cost-free initialization strategy for feasible interior-point methods (IPMs). Next, focusing on solving Box-QPs, this article replaces the exact Newton step with an approximated Newton step (substituting the matrix-inversion operation with multiple rank-1 updates) within feasible IPMs. For the first time, this article proposes an implementable feasible IPM algorithm with $O(n^3)$ time complexity, by proving the number of iterations is exact $O(\sqrt{n})$ and the number of rank-1 updates is bounded by $O(n)$. Numerical validations/applications and codes are provided.

Paper number 166:
Title: Self-supervised learning of speech representations with Dutch archival data
Authors: Nik Vaessen, David A. van Leeuwen, Roeland Ordelman
Abstract: This paper explores the use of Dutch archival television broadcast data for self-supervised learning of speech foundation models, specifically wav2vec 2.0. We first study data quality assumptions for pre-training, and show how music, noise and speaker overlap affect SSL convergence and downstream fine-tuning performance. Secondly, we explore effectively pre-processing strategies to convert the noisy broadcast dataset into a qualitative dataset for pre-training, by using Whisper and WhisperX., Thirdly, we compare mono-lingual and multi-lingual pre-training with equivalent amounts of data, and show that mono-lingual pre-training is more robust to out-of-domain data. Lastly, we achieve a state-of-the-art LARGE wav2vec 2.0 model for the Dutch language, by a continuation of pre-training a wav2vec 2.0 XLS-R model checkpoint with our 55k hour archival dataset.

Paper number 167:
Title: The Difference between the Left and Right Invariant Extended Kalman Filter
Authors: Yixiao Ge, Giulio Delama, Martin Scheiber, Alessandro Fornasier, Pieter van Goor, Stephan Weiss, Robert Mahony
Abstract: The extended Kalman filter (EKF) has been the industry standard for state estimation problems over the past sixty years. The Invariant Extended Kalman Filter (IEKF) is a recent development of the EKF for the class of group-affine systems on Lie groups that has shown superior performance for inertial navigation problems. The IEKF comes in two versions, left- and right- handed respectively, and there is a perception in the robotics community that these filters are different and one should choose the handedness of the IEKF to match handedness of the measurement model for a given filtering problem. In this paper, we revisit these algorithms and demonstrate that the left- and right- IEKF algorithms (with reset step) are identical, that is, the choice of the handedness does not affect the IEKF's performance when the reset step is properly implemented. The reset step was not originally proposed as part of the IEKF, however, we provide simulations to show that the reset step improves asymptotic performance of all versions of the the filter, and should be included in all high performance algorithms. The GNSS-aided inertial navigation system (INS) is used as a motivating example to demonstrate the equivalence of the two filters.

Paper number 168:
Title: On-Demand Multimedia Delivery in 6G: An Optimal-Cost Steiner Tree Approach
Authors: Zien Wang, Xiucheng Wang, Nan Cheng, Wenchao Xu, Wei Quan, Ruijin Sun, Conghao Zhou
Abstract: The exponential growth of multimedia data traffic in 6G networks poses unprecedented challenges for immersive communication, where ultra-high-definition, multi-quality streaming must be delivered on demand while minimizing network operational costs. Traditional routing approaches, such as shortest-path algorithms, fail to optimize flow multiplexing across multiple destinations, while conventional Steiner tree methods cannot accommodate heterogeneous quality-of-service (QoS) requirements-a critical need for 6G's personalized services. In this paper, we address a fundamental but unsolved challenge: the minimum flow problem (MFP) with multi-destination, heterogeneous outflow demands, which is pivotal for efficient multimedia distribution such as adaptive-resolution video streaming. To overcome the limitations of existing methods, we propose a two-stage dynamic programming-enhanced On-demand Steiner Tree (OST) algorithm, the first approach that jointly optimizes flow aggregation and QoS-aware path selection for arbitrary outflow requirements. We rigorously prove the optimality of OST using mathematical induction, demonstrating that it guarantees the minimum-cost multicast flow under differentiated service constraints. Extensive experiments in 6G-like multimedia transmission scenarios show that OST reduces total network flow by over 10% compared to state-of-the-art methods while ensuring on-demand QoS fulfillment. The complete code is available at this https URL.

Paper number 169:
Title: Emerging Frameworks for Objective Task-based Evaluation of Quantitative Medical Imaging Methods
Authors: Yan Liu, Huitian Xia, Nancy A. Obuchowski, Richard Laforest, Arman Rahmim, Barry A. Siegel, Abhinav K. Jha
Abstract: Quantitative imaging (QI) is demonstrating strong promise across multiple clinical applications. For clinical translation of QI methods, objective evaluation on clinically relevant tasks is essential. To address this need, multiple evaluation strategies are being developed. In this paper, based on previous literature, we outline four emerging frameworks to perform evaluation studies of QI methods. We first discuss the use of virtual imaging trials (VITs) to evaluate QI methods. Next, we outline a no-gold-standard evaluation framework to clinically evaluate QI methods without ground truth. Third, a framework to evaluate QI methods for joint detection and quantification tasks is outlined. Finally, we outline a framework to evaluate QI methods that output multi-dimensional parameters, such as radiomic features. We review these frameworks, discussing their utilities and limitations. Further, we examine future research areas in evaluation of QI methods. Given the recent advancements in PET, including long axial field-of-view scanners and the development of artificial-intelligence algorithms, we present these frameworks in the context of PET.

Paper number 170:
Title: Exploring Core and Periphery Precepts in Biological and Artificial Intelligence: An Outcome-Based Perspective
Authors: Niloofar Shadab, Tyler Cody, Alejandro Salado, Taylan G. Topcu, Mohammad Shadab, Peter Beling
Abstract: Engineering methodologies predominantly revolve around established principles of decomposition and recomposition. These principles involve partitioning inputs and outputs at the component level, ensuring that the properties of individual components are preserved upon composition. However, this view does not transfer well to intelligent systems, particularly when addressing the scaling of intelligence as a system property. Our prior research contends that the engineering of general intelligence necessitates a fresh set of overarching systems principles. As a result, we introduced the "core and periphery" principles, a novel conceptual framework rooted in abstract systems theory and the Law of Requisite Variety. In this paper, we assert that these abstract concepts hold practical significance. Through empirical evidence, we illustrate their applicability to both biological and artificial intelligence systems, bridging abstract theory with real-world implementations. Then, we expand on our previous theoretical framework by mathematically defining core-dominant vs periphery-dominant systems.

Paper number 171:
Title: Multi-Step Prediction and Control of Hierarchical Emotion Distribution in Text-to-Speech Synthesis
Authors: Sho Inoue, Kun Zhou, Shuai Wang, Haizhou Li
Abstract: We investigate hierarchical emotion distribution (ED) for achieving multi-level quantitative control of emotion rendering in text-to-speech synthesis (TTS). We introduce a novel multi-step hierarchical ED prediction module that quantifies emotion variance at the utterance, word, and phoneme levels. By predicting emotion variance in a multi-step manner, we leverage global emotional context to refine local emotional variations, thereby capturing the intrinsic hierarchical structure of speech emotion. Our approach is validated through its integration into a variance adaptor and an external module design compatible with various TTS systems. Both objective and subjective evaluations demonstrate that the proposed framework significantly enhances emotional expressiveness and enables precise control of emotion rendering across multiple speech granularities.

Paper number 172:
Title: Mutual Information Optimal Control of Discrete-Time Linear Systems
Authors: Shoju Enami, Kenji Kashima
Abstract: In this paper, we formulate a mutual information optimal control problem (MIOCP) for discrete-time linear systems. This problem can be regarded as an extension of a maximum entropy optimal control problem (MEOCP). Differently from the MEOCP where the prior is fixed to the uniform distribution, the MIOCP optimizes the policy and prior simultaneously. As analytical results, under the policy and prior classes consisting of Gaussian distributions, we derive the optimal policy and prior of the MIOCP with the prior and policy fixed, respectively. Using the results, we propose an alternating minimization algorithm for the MIOCP. Through numerical experiments, we discuss how our proposed algorithm works.

Paper number 173:
Title: Improving BERT for Symbolic Music Understanding Using Token Denoising and Pianoroll Prediction
Authors: Jun-You Wang, Li Su
Abstract: We propose a pre-trained BERT-like model for symbolic music understanding that achieves competitive performance across a wide range of downstream tasks. To achieve this target, we design two novel pre-training objectives, namely token correction and pianoroll prediction. First, we sample a portion of note tokens and corrupt them with a limited amount of noise, and then train the model to denoise the corrupted tokens; second, we also train the model to predict bar-level and local pianoroll-derived representations from the corrupted note tokens. We argue that these objectives guide the model to better learn specific musical knowledge such as pitch intervals. For evaluation, we propose a benchmark that incorporates 12 downstream tasks ranging from chord estimation to symbolic genre classification. Results confirm the effectiveness of the proposed pre-training objectives on downstream tasks.

Paper number 174:
Title: UDF-GMA: Uncertainty Disentanglement and Fusion for General Movement Assessment
Authors: Zeqi Luo, Ali Gooya, Edmond S. L. Ho
Abstract: General movement assessment (GMA) is a non-invasive tool for the early detection of brain dysfunction through the qualitative assessment of general movements, and the development of automated methods can broaden its application. However, mainstream pose-based automated GMA methods are prone to uncertainty due to limited high-quality data and noisy pose estimation, hindering clinical reliability without reliable uncertainty measures. In this work, we introduce UDF-GMA which explicitly models epistemic uncertainty in model parameters and aleatoric uncertainty from data noise for pose-based automated GMA. UDF-GMA effectively disentangles uncertainties by directly modelling aleatoric uncertainty and estimating epistemic uncertainty through Bayesian approximation. We further propose fusing these uncertainties with the embedded motion representation to enhance class separation. Extensive experiments on the Pmi-GMA benchmark dataset demonstrate the effectiveness and generalisability of the proposed approach in predicting poor repertoire.

Paper number 175:
Title: Fast-VGAN: Lightweight Voice Conversion with Explicit Control of F0 and Duration Parameters
Authors: Mathilde Abrassart, Nicolas Obin, Axel Roebel
Abstract: Precise control over speech characteristics, such as pitch, duration, and speech rate, remains a significant challenge in the field of voice conversion. The ability to manipulate parameters like pitch and syllable rate is an important element for effective identity conversion, but can also be used independently for voice transformation, achieving goals that were historically addressed by vocoder-based methods. In this work, we explore a convolutional neural network-based approach that aims to provide means for modifying fundamental frequency (F0), phoneme sequences, intensity, and speaker identity. Rather than relying on disentanglement techniques, our model is explicitly conditioned on these factors to generate mel spectrograms, which are then converted into waveforms using a universal neural vocoder. Accordingly, during inference, F0 contours, phoneme sequences, and speaker embeddings can be freely adjusted, allowing for intuitively controlled voice transformations. We evaluate our approach on speaker conversion and expressive speech tasks using both perceptual and objective metrics. The results suggest that the proposed method offers substantial flexibility, while maintaining high intelligibility and speaker similarity.

Paper number 176:
Title: Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu
Authors: AntÃ³nio SÃ¡ Pinto
Abstract: We explore transfer learning strategies for musical onset detection in the Afro-Brazilian Maracatu tradition, which features complex rhythmic patterns that challenge conventional models. We adapt two Temporal Convolutional Network architectures: one pre-trained for onset detection (intra-task) and another for beat tracking (inter-task). Using only 5-second annotated snippets per instrument, we fine-tune these models through layer-wise retraining strategies for five traditional percussion instruments. Our results demonstrate significant improvements over baseline performance, with F1 scores reaching up to 0.998 in the intra-task setting and improvements of over 50 percentage points in best-case scenarios. The cross-task adaptation proves particularly effective for time-keeping instruments, where onsets naturally align with beat positions. The optimal fine-tuning configuration varies by instrument, highlighting the importance of instrument-specific adaptation strategies. This approach addresses the challenges of underrepresented musical traditions, offering an efficient human-in-the-loop methodology that minimizes annotation effort while maximizing performance. Our findings contribute to more inclusive music information retrieval tools applicable beyond Western musical contexts.

Paper number 177:
Title: Music Boomerang: Reusing Diffusion Models for Data Augmentation and Audio Manipulation
Authors: Alexander Fichtinger, Jan SchlÃ¼ter, Gerhard Widmer
Abstract: Generative models of music audio are typically used to generate output based solely on a text prompt or melody. Boomerang sampling, recently proposed for the image domain, allows generating output close to an existing example, using any pretrained diffusion model. In this work, we explore its application in the audio domain as a tool for data augmentation or content manipulation. Specifically, implementing Boomerang sampling for Stable Audio Open, we augment training data for a state-of-the-art beat tracker, and attempt to replace musical instruments in recordings. Our results show that the rhythmic structure of existing examples is mostly preserved, that it improves performance of the beat tracker, but only in scenarios of limited training data, and that it can accomplish text-based instrument replacement on monophonic inputs. We publish our implementation to invite experiments on data augmentation in other tasks and explore further applications.

Paper number 178:
Title: EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation
Authors: Fathinah Izzati, Xinyue Li, Gus Xia
Abstract: We propose Expotion (Facial Expression and Motion Control for Multimodal Music Generation), a generative model leveraging multimodal visual controls - specifically, human facial expressions and upper-body motion - as well as text prompts to produce expressive and temporally accurate music. We adopt parameter-efficient fine-tuning (PEFT) on the pretrained text-to-music generation model, enabling fine-grained adaptation to the multimodal controls using a small dataset. To ensure precise synchronization between video and music, we introduce a temporal smoothing strategy to align multiple modalities. Experiments demonstrate that integrating visual features alongside textual descriptions enhances the overall quality of generated music in terms of musicality, creativity, beat-tempo consistency, temporal alignment with the video, and text adherence, surpassing both proposed baselines and existing state-of-the-art video-to-music generation models. Additionally, we introduce a novel dataset consisting of 7 hours of synchronized video recordings capturing expressive facial and upper-body gestures aligned with corresponding music, providing significant potential for future research in multimodal and interactive music generation.

Paper number 179:
Title: Hear-Your-Click: Interactive Video-to-Audio Generation via Object-aware Contrastive Audio-Visual Fine-tuning
Authors: Yingshan Liang, Keyu Fan, Zhicheng Du, Yiran Wang, Qingyang Shi, Xinyu Zhang, Jiasheng Lu, Peiwu Qin
Abstract: Video-to-audio (V2A) generation shows great potential in fields such as film production. Despite significant advances, current V2A methods, which rely on global video information, struggle with complex scenes and often fail to generate audio tailored to specific objects or regions in the videos. To address these limitations, we introduce Hear-Your-Click, an interactive V2A framework that enables users to generate sounds for specific objects in the videos by simply clicking on the frame. To achieve this, we propose Object-aware Contrastive Audio-Visual Fine-tuning (OCAV) with a Mask-guided Visual Encoder (MVE) to obtain object-level visual features aligned with corresponding audio segments. Furthermore, we tailor two data augmentation strategies: Random Video Stitching (RVS) and Mask-guided Loudness Modulation (MLM), aimed at enhancing the model's sensitivity to the segmented objects. To effectively measure the audio-visual correspondence, we design a new evaluation metric, the CAV score, for evaluation. Extensive experiments demonstrate that our framework offers more precise control and improved generation performance across various metrics. Project Page: this https URL

Paper number 180:
Title: Modeling the Difficulty of Saxophone Music
Authors: Å imon LibÅickÃ½, Jan HajiÄ jr
Abstract: In learning music, difficulty is an important factor in choice of repertoire, choice of tempo, and structure of practice. These choices are typically done with the guidance of a teacher; however, not all learners have access to one. While piano and strings have had some attention devoted to automated difficulty estimation, wind instruments have so far been under-served. In this paper, we propose a method for estimating the difficulty of pieces for winds and implement it for the tenor saxophone. We take the cost-of-traversal approach, modelling the part as a sequence of transitions -- note pairs. We estimate transition costs from newly collected recordings of trill speeds, comparing representations of saxophone fingerings at various levels of expert input. We then compute and visualise the cost of the optimal path through the part, at a given tempo. While we present this model for the tenor saxophone, the same pipeline can be applied to other woodwinds, and our experiments show that with appropriate feature design, only a small proportion of possible trills is needed to estimate the costs well. Thus, we present a practical way of diversifying the capabilities of MIR in music education to the wind family of instruments.

Paper number 181:
Title: LAPS-Diff: A Diffusion-Based Framework for Singing Voice Synthesis With Language Aware Prosody-Style Guided Learning
Authors: Sandipan Dhar, Mayank Gupta, Preeti Rao
Abstract: The field of Singing Voice Synthesis (SVS) has seen significant advancements in recent years due to the rapid progress of diffusion-based approaches. However, capturing vocal style, genre-specific pitch inflections, and language-dependent characteristics remains challenging, particularly in low-resource scenarios. To address this, we propose LAPS-Diff, a diffusion model integrated with language-aware embeddings and a vocal-style guided learning mechanism, specifically designed for Bollywood Hindi singing style. We curate a Hindi SVS dataset and leverage pre-trained language models to extract word and phone-level embeddings for an enriched lyrics representation. Additionally, we incorporated a style encoder and a pitch extraction model to compute style and pitch losses, capturing features essential to the naturalness and expressiveness of the synthesized singing, particularly in terms of vocal style and pitch variations. Furthermore, we utilize MERT and IndicWav2Vec models to extract musical and contextual embeddings, serving as conditional priors to refine the acoustic feature generation process further. Based on objective and subjective evaluations, we demonstrate that LAPS-Diff significantly improves the quality of the generated samples compared to the considered state-of-the-art (SOTA) model for our constrained dataset that is typical of the low resource scenario.

Paper number 182:
Title: OpenS2S: Advancing Open-Source End-to-End Empathetic Large Speech Language Model
Authors: Chen Wang, Tianyu Peng, Wen Yang, Yinan Bai, Guangfu Wang, Jun Lin, Lanpeng Jia, Lingxiang Wu, Jinqiao Wang, Chengqing Zong, Jiajun Zhang
Abstract: Empathetic interaction is a cornerstone of human-machine communication, due to the need for understanding speech enriched with paralinguistic cues and generating emotional and expressive responses. However, the most powerful empathetic LSLMs are increasingly closed off, leaving the crucial details about the architecture, data and development opaque to researchers. Given the critical need for transparent research into the LSLMs and empathetic behavior, we present OpenS2S, a fully open-source, transparent and end-to-end LSLM designed to enable empathetic speech interactions. Based on our empathetic speech-to-text model BLSP-Emo, OpenS2S further employs a streaming interleaved decoding architecture to achieve low-latency speech generation. To facilitate end-to-end training, OpenS2S incorporates an automated data construction pipeline that synthesizes diverse, high-quality empathetic speech dialogues at low cost. By leveraging large language models to generate empathetic content and controllable text-to-speech systems to introduce speaker and emotional variation, we construct a scalable training corpus with rich paralinguistic diversity and minimal human supervision. We release the fully open-source OpenS2S model, including the dataset, model weights, pre-training and fine-tuning codes, to empower the broader research community and accelerate innovation in empathetic speech systems. The project webpage can be accessed at this https URL

Paper number 183:
Title: NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving
Authors: Qucheng Peng, Chen Bai, Guoxiang Zhang, Bo Xu, Xiaotong Liu, Xiaoyin Zheng, Chen Chen, Cheng Lu
Abstract: Autonomous driving systems have made significant advances in Q&A, perception, prediction, and planning based on local visual information, yet they struggle to incorporate broader navigational context that human drivers routinely utilize. We address this critical gap between local sensor data and global navigation information by proposing NavigScene, an auxiliary navigation-guided natural language dataset that simulates a human-like driving environment within autonomous driving systems. Moreover, we develop three complementary paradigms to leverage NavigScene: (1) Navigation-guided Reasoning, which enhances vision-language models by incorporating navigation context into the prompting approach; (2) Navigation-guided Preference Optimization, a reinforcement learning method that extends Direct Preference Optimization to improve vision-language model responses by establishing preferences for navigation-relevant summarized information; and (3) Navigation-guided Vision-Language-Action model, which integrates navigation guidance and vision-language models with conventional driving models through feature fusion. Extensive experiments demonstrate that our approaches significantly improve performance across perception, prediction, planning, and question-answering tasks by enabling reasoning capabilities beyond visual range and improving generalization to diverse driving scenarios. This work represents a significant step toward more comprehensive autonomous driving systems capable of navigating complex, unfamiliar environments with greater reliability and safety.

Paper number 184:
Title: Coherent Track Before Detect: Detection via simultaneous trajectory estimation and long time integration
Authors: Kimin Kim, Murat Uney, Bernard Mulgrew
Abstract: In this work, we consider the detection of manoeuvring small objects with radars. Such objects induce low signal to noise ratio (SNR) reflections in the received signal. We consider both co-located and separated transmitter/receiver pairs, i.e., mono-static and bi-static configurations, respectively, as well as multi-static settings involving both types. We propose coherent track before detect: A detection approach which is capable of coherently integrating these reflections within a coherent processing interval (CPI) in all these configurations and continuing integration for an arbitrarily long time across consecutive CPIs. {We estimate the complex value of the reflection coefficients for integration while simultaneously estimating the object trajectory. Compounded with these computations is the estimation of the unknown time reference shift of the separated transmitters necessary for coherent processing.} Detection is made by using the resulting integration value in a Neyman-Pearson test against a constant false alarm rate threshold. We demonstrate the efficacy of our approach in a simulation example with a very low SNR object which cannot be detected with conventional techniques.

Paper number 185:
Title: HRVGAN: High Resolution Video Generation using Spatio-Temporal GAN
Authors: Abhinav Sagar
Abstract: High-resolution video generation has emerged as a crucial task in computer vision, with wide-ranging applications in entertainment, simulation, and data augmentation. However, generating temporally coherent and visually realistic videos remains a significant challenge due to the high dimensionality and complex dynamics of video data. In this paper, we propose a novel deep generative network architecture designed specifically for high-resolution video synthesis. Our approach integrates key concepts from Wasserstein Generative Adversarial Networks (WGANs), enforcing a k-Lipschitz continuity constraint on the discriminator to stabilize training and enhance convergence. We further leverage Conditional GAN (cGAN) techniques by incorporating class labels during both training and inference, enabling class-specific video generation with improved semantic consistency. We provide a detailed layer-wise description of the Generator and Discriminator networks, highlighting architectural design choices promoting temporal coherence and spatial detail. The overall combined architecture, training algorithm, and optimization strategy are thoroughly presented. Our training objective combines a pixel-wise mean squared error loss with an adversarial loss to balance frame-level accuracy and video realism. We validate our approach on benchmark datasets including UCF101, Golf, and Aeroplane, encompassing diverse motion patterns and scene contexts. Quantitative evaluations using Inception Score (IS) and FrÃ©chet Inception Distance (FID) demonstrate that our model significantly outperforms previous state-of-the-art unsupervised video generation methods in terms of both quality and diversity.

Paper number 186:
Title: Steering Control of an Autonomous Unicycle
Authors: MÃ¡tÃ© BenjÃ¡min Vizi, GÃ¡bor Orosz, DÃ©nes TakÃ¡cs, GÃ¡bor StÃ©pÃ¡n
Abstract: The steering control of an autonomous unicycle is considered. The underlying dynamical model of a single rolling wheel is discussed regarding the steady state motions and their stability. The unicycle model is introduced as the simplest possible extension of the rolling wheel where the location of the center of gravity is controlled. With the help of the Appellian approach, a state space representation of the controlled nonholonomic system is built in a way that the most compact nonlinear equations of motions are constructed. Based on controllability analysis, feedback controllers are designed which successfully carry out lane changing and turning maneuvers. The behavior of the closed-loop system is demonstrated by numerical simulations.

Paper number 187:
Title: 3D SA-UNet: 3D Spatial Attention UNet with 3D Atrous Spatial Pyramid Pooling for White Matter Hyperintensities Segmentation
Authors: Changlu Guo
Abstract: White Matter Hyperintensity (WMH) is an imaging feature related to various diseases such as dementia and stroke. Accurately segmenting WMH using computer technology is crucial for early disease diagnosis. However, this task remains challenging due to the small lesions with low contrast and high discontinuity in the images, which contain limited contextual and spatial information. To address this challenge, we propose a deep learning model called 3D Spatial Attention U-Net (3D SA-UNet) for automatic WMH segmentation using only Fluid Attenuation Inversion Recovery (FLAIR) scans. The 3D SA-UNet introduces a 3D Spatial Attention Module that highlights important lesion features, such as WMH, while suppressing unimportant regions. Additionally, to capture features at different scales, we extend the Atrous Spatial Pyramid Pooling (ASPP) module to a 3D version, enhancing the segmentation performance of the network. We evaluate our method on publicly available dataset and demonstrate the effectiveness of 3D spatial attention module and 3D ASPP in WMH segmentation. Through experimental results, it has been demonstrated that our proposed 3D SA-UNet model achieves higher accuracy compared to other state-of-the-art 3D convolutional neural networks.

Paper number 188:
Title: Barrier States Theory for Safety-Critical Multi-Objective Control
Authors: Hassan Almubarak, Nader Sadegh, Evangelos A. Theodorou
Abstract: Multi-objective safety-critical control entails a diligent design to avoid possibly conflicting scenarios and ensure safety. This paper addresses multi-objective safety-critical control through a novel approach utilizing barrier states (BaS) to integrate safety into control design. It introduces the concept of safety embedded systems, where the safety condition is integrated with barrier functions to characterize a dynamical subsystem that is incorporated into the original model for control design. This approach reformulates the control problem to focus on designing a control law for an unconstrained system, ensuring that the barrier state remains bounded while achieving other performance objectives. The paper demonstrates that designing a stabilizing controller for the safety embedded system guarantees the safe stabilization of the original safety-critical system, effectively mitigating conflicts between performance and safety constraints. This approach enables the use of various legacy control methods from the literature to develop safe control laws. Moreover, it explores how this method can be applied to enforce input constraints and extend traditional control techniques to incorporate safety considerations. Additionally, the paper introduces input-to-state safety (ISSf) through barrier states for analyzing robust safety under bounded input disturbances and develops the notion of input-to-state safe stability IS3 for analyzing and designing robustly safe stabilizing feedback controls. The proposed techniques and concepts are used in various examples including the design of proportional-integral-derivative-barrier (PIDB) control for adaptive cruise control.

Paper number 189:
Title: Fast and Scalable Beamforming for RIS-Assisted Downlink Multi-group Multicasting
Authors: Mohammad Ebrahimi, Min Dong, Mitra Hekmat
Abstract: This paper considers downlink multi-group multicasting via beamforming facilitated by a reconfigurable intelligent surface (RIS). We develop a fast and scalable algorithm for the joint base station (BS) and RIS beamforming optimization to minimize the transmit power while meeting user quality-of-service (QoS) targets. By analyzing the structure of the QoS constraints, we reformulate the problem and show that the joint beamforming optimization inherently consists of a multicast beamforming QoS problem for the BS and a passive multicast beamforming max-min-fair (MMF) problem for the RIS. We propose a fast alternating multicast beamforming (AMBF) algorithm to effectively solve the two subproblems alternatingly. For the BS multicast subproblem, we utilize the optimal multicast beamforming structure to efficiently determine the BS beamformers. For the RIS multicast subproblem, we reformulate the MMF problem and apply a first-order projected subgradient algorithm (PSA), which yields simple closed-form updates. The computational complexity of the AMBF algorithm grows linearly with the number of RIS elements and BS antennas. We further consider joint BS and RIS beamforming for the weighted MMF design objective, subject to the BS transmit power budget. We propose an alternating PSA (APSA) fast algorithm to compute the beamforming solutions for the BS and RIS. APSA consists of only closed-form updates per iteration, yielding linear computational complexity in the number of RIS elements and BS antennas. Simulation results show the efficacy of our proposed algorithms in terms of performance and computational cost compared to alternative methods.

Paper number 190:
Title: Robust Semantic Communications for Speech Transmission
Authors: Zhenzi Weng, Zhijin Qin, Geoffrey Ye Li
Abstract: In this paper, we propose a robust semantic communication system for speech transmission, named Ross-S2T, by delivering the essential semantic information. Specifically, we consider the speech-to-text translation (S2TT) as the transmission goal. First, a new deep semantic encoder is developed to convert speech in the source language to textual features associated with the target language, facilitating the end-to-end semantic exchange to perform the S2TT task and reducing the transmission data without performance degradation. To mitigate semantic impairments inherent in the corrupted speech, a novel generative adversarial network (GAN)-enabled deep semantic compensator is established to estimate the lost semantic information within the speech and extract deep semantic features simultaneously, which enables robust semantic transmission for corrupted speech. Furthermore, a semantic probe-aided compensator is devised to enhance the semantic fidelity of recovered semantic features and improve the understandability of the target text. According to simulation results, the proposed Ross-S2T exhibits superior S2TT performance compared to conventional approaches and high robustness against semantic impairments.

Paper number 191:
Title: Differentially Private Dual Gradient Tracking for Distributed Resource Allocation
Authors: Wei Huo, Xiaomeng Chen, Lingying Huang, Karl Henrik Johansson, Ling Shi
Abstract: This paper investigates privacy issues in distributed resource allocation over directed networks, where each agent holds a private cost function and optimizes its decision subject to a global coupling constraint through local interaction with other agents. Conventional methods for resource allocation over directed networks require all agents to transmit their original data to neighbors, which poses the risk of disclosing sensitive and private information. To address this issue, we propose an algorithm called differentially private dual gradient tracking (DP-DGT) for distributed resource allocation, which obfuscates the exchanged messages using independent Laplacian noise. Our algorithm ensures that the agents' decisions converge to a neighborhood of the optimal solution almost surely. Furthermore, without the assumption of bounded gradients, we prove that the cumulative differential privacy loss under the proposed algorithm is finite even when the number of iterations goes to infinity. To the best of our knowledge, we are the first to simultaneously achieve these two goals in distributed resource allocation problems over directed networks. Finally, numerical simulations on economic dispatch problems within the IEEE 14-bus system illustrate the effectiveness of our proposed algorithm.

Paper number 192:
Title: Spatio-Spectral Structure Tensor Total Variation for Hyperspectral Image Denoising and Destriping
Authors: Shingo Takemoto, Kazuki Naganuma, Shunsuke Ono
Abstract: This paper proposes a novel regularization method, named Spatio-Spectral Structure Tensor Total Variation (S3TTV), for denoising and destriping of hyperspectral (HS) images. HS images are inevitably contaminated by various types of noise, during acquisition process, due to the measurement equipment and the environment. For HS image denoising and destriping tasks, Spatio-Spectral Total Variation (SSTV) is widely known as a powerful regularization approach that models the spatio-spectral piecewise smoothness. However, since SSTV refers only to the local differences of pixels/bands, edges and textures that extend beyond adjacent pixels are not preserved during denoising process. To address this problem, we newly introduce S3TTV, which is designed to preserve two essential physical characteristics of HS images: semi-local spatial structures and spectral correlation across all bands. Specifically, we define S3TTV as the sum of the nuclear norms of spatio-spectral structure tensors, which are matrices formed by arranging second-order spatio-spectral difference vectors within semi-local areas. Furthermore, we formulate the HS image denoising and destriping problem as a constrained convex optimization problem involving S3TTV and develop an algorithm based on a preconditioned primal-dual splitting method to solve this problem efficiently. Finally, we demonstrate the effectiveness of S3TTV by comparing it with existing methods, including state-of-the-art ones through denoising and destriping experiments.

Paper number 193:
Title: MarsQE: Semantic-Informed Quality Enhancement for Compressed Martian Image
Authors: Chengfeng Liu, Mai Xu, Qunliang Xing, Xin Zou
Abstract: Lossy image compression is essential for Mars exploration missions, due to the limited bandwidth between Earth and Mars. However, the compression may introduce visual artifacts that complicate the geological analysis of the Martian surface. Existing quality enhancement approaches, primarily designed for Earth images, fall short for Martian images due to a lack of consideration for the unique Martian semantics. In response to this challenge, we conduct an in-depth analysis of Martian images, yielding two key insights based on semantics: the presence of texture similarities and the compact nature of texture representations in Martian images. Inspired by these findings, we introduce MarsQE, an innovative, semantic-informed, two-phase quality enhancement approach specifically designed for Martian images. The first phase involves the semantic-based matching of texture-similar reference images, and the second phase enhances image quality by transferring texture patterns from these reference images to the compressed image. We also develop a post-enhancement network to further reduce compression artifacts and achieve superior compression quality. Our extensive experiments demonstrate that MarsQE significantly outperforms existing approaches for Earth images, establishing a new benchmark for the quality enhancement on Martian images.

Paper number 194:
Title: A hybrid systems framework for data-based adaptive control of linear time-varying systems
Authors: Andrea Iannelli, Romain Postoyan
Abstract: We consider the data-driven stabilization of discrete-time linear time-varying systems. The controller is defined as a linear state-feedback law whose gain is adapted to the plant changes through a data-based event-triggering rule. To do so, we monitor the evolution of a data-based Lyapunov function along the solution. When this Lyapunov function does not satisfy a designed desirable condition, an episode is triggered to update the controller gain and the corresponding Lyapunov function using the last collected data. The resulting closed-loop dynamics hence exhibits both physical jumps, due to the system dynamics, and episodic jumps, which naturally leads to a hybrid discrete-time system. We leverage the inherent robustness of the controller and provide general conditions under which various stability notions can be established for the system. Two notable cases where these conditions are satisfied are treated, and numerical results illustrating the relevance of the approach are discussed.

Paper number 195:
Title: Fairness Evolution in Continual Learning for Medical Imaging
Authors: Marina Ceccon, Davide Dalle Pezze, Alessandro Fabris, Gian Antonio Susto
Abstract: Deep Learning has advanced significantly in medical applications, aiding disease diagnosis in Chest X-ray images. However, expanding model capabilities with new data remains a challenge, which Continual Learning (CL) aims to address. Previous studies have evaluated CL strategies based on classification performance; however, in sensitive domains such as healthcare, it is crucial to assess performance across socially salient groups to detect potential biases. This study examines how bias evolves across tasks using domain-specific fairness metrics and how different CL strategies impact this evolution. Our results show that Learning without Forgetting and Pseudo-Label achieve optimal classification performance, but Pseudo-Label is less biased.

Paper number 196:
Title: QoE Maximization for Multiple-UAV-Assisted Multi-Access Edge Computing via an Online Joint Optimization Approach
Authors: Long He, Geng Sun, Zemin Sun, Qingqing Wu, Jiawen Kang, Dusit Niyato, Zhu Han, Victor C. M. Leung
Abstract: In disaster scenarios, conventional terrestrial multi-access edge computing (MEC) paradigms, which rely on ground infrastructure, may become unavailable due to infrastructure damage. With high-probability line-of-sight (LoS) communication, flexible mobility, and low cost, uncrewed aerial vehicle (UAV)-assisted MEC is emerging as a promising paradigm to provide edge computing services for ground user devices (UDs) in disaster-stricken areas. However, the limited battery capacity, computing resources, and spectrum resources also pose serious challenges for UAV-assisted MEC, which can potentially shorten the service time of UAVs and degrade the quality of experience (QoE) of UDs without an effective control approach. To this end, in this work, we first present a hierarchical architecture of multiple-UAV-assisted MEC networks that enables the coordinated provision of edge computing services by multiple UAVs. Then, we formulate a joint task offloading, resource allocation, and UAV trajectory control optimization problem (JTRTOP) to maximize the QoE of UDs while considering the energy and resource constraints of UAVs. Since the problem is proven to be a future-dependent and NP-hard problem, we propose a novel online joint task offloading, resource allocation, and UAV trajectory control approach (OJTRTA) to solve the problem. Specifically, the JTRTOP is first transformed into a per-slot real-time optimization problem (PROP) using the Lyapunov optimization framework. Then, a two-stage optimization method based on game theory and convex optimization is proposed to solve the PROP. Simulation results show that the proposed OJTRTA outperforms various benchmark approaches and achieves at least a 10% improvement in the QoE of UDs compared to deep reinforcement learning (DRL)-based algorithms, thereby validating the superiority of the proposed approach.

Paper number 197:
Title: AI-Driven Mobility Management for High-Speed Railway Communications: Compressed Measurements and Proactive Handover
Authors: Wen Li, Wei Chen, Shiyue Wang, Yuanyuan Zhang, Michail Matthaiou, Bo Ai
Abstract: High-speed railway (HSR) communications are pivotal for ensuring rail safety, operations, maintenance, and delivering passenger information services. The high speed of trains creates rapidly time-varying wireless channels, increases the signaling overhead, and reduces the system throughput, making it difficult to meet the growing and stringent needs of HSR applications. In this article, we explore artificial intelligence (AI)-based beam-level and cell-level mobility management suitable for HSR communications. Particularly, we propose a compressed spatial multi-beam measurements scheme via compressive sensing for beam-level mobility management in HSR communications. In comparison to traditional down-sampling spatial beam measurements, this method leads to improved spatial-temporal beam prediction accuracy with the same measurement overhead. Moreover, we propose a novel AI-based proactive handover scheme to predict handover events and reduce radio link failure (RLF) rates in HSR communications. Compared with the traditional event A3-based handover mechanism, the proposed approach significantly reduces the RLF rates which saves 50% beam measurement overhead.

Paper number 198:
Title: Deception in Nash Equilibrium Seeking
Authors: Michael Tang, Umar Javed, Xudong Chen, Miroslav Krstic, Jorge I. Poveda
Abstract: In socio-technical multi-agent systems, deception exploits privileged information to induce false beliefs in "victims," keeping them oblivious and leading to outcomes detrimental to them or advantageous to the deceiver. We consider model-free Nash-equilibrium-seeking for non-cooperative games with asymmetric information and introduce model-free deceptive algorithms with stability guarantees. In the simplest algorithm, the deceiver includes in his action policy the victim's exploration signal, with an amplitude tuned by an integrator of the regulation error between the deceiver's actual and desired payoff. The integral feedback drives the deceiver's payoff to the payoff's reference value, while the victim is led to adopt a suboptimal action, at which the pseudogradient of the deceiver's payoff is zero. The deceiver's and victim's actions turn out to constitute a "deceptive" Nash equilibrium of a different game, whose structure is managed - in real time - by the deceiver. We examine quadratic, aggregative, and more general games and provide conditions for a successful deception, mutual and benevolent deception, and immunity to deception. Stability results are established using techniques based on averaging and singular perturbations. Among the examples in the paper is a microeconomic duopoly in which the deceiver induces in the victim a belief that the buyers disfavor the deceiver more than they actually do, leading the victim to increase the price above the Nash price, and resulting in an increased profit for the deceiver and a decreased profit for the victim. A study of the deceiver's integral feedback for the desired profit reveals that, in duopolies with equal marginal costs, a deceiver that is greedy for very high profit can attain any such profit, and pursue this with arbitrarily high integral gain (impatiently), irrespective of the market preference for the victim.

Paper number 199:
Title: Large-Language-Model Enabled Semantic Communication Systems
Authors: Zhenyi Wang, Li Zou, Shengyun Wei, Kai Li, Feifan Liao, Haibo Mi, Rongxuan Lai
Abstract: Large language models (LLMs) have recently demonstrated state-of-the-art performance across various natural language processing (NLP) tasks, achieving near-human levels in multiple language understanding challenges and aligning closely with the core principles of semantic communication. Inspired by LLMs' advancements in semantic processing, we propose an innovative LLM-enabled semantic communication system framework, named LLM-SC, that applies LLMs directly to the physical layer coding and decoding for the first time. By analyzing the relationship between the training process of LLMs and the optimization objectives of semantic communication, we propose training a semantic encoder through LLMs' tokenizer training and establishing a semantic knowledge base via the LLMs' unsupervised pre-training process. This knowledge base aids in constructing the optimal decoder by providing the prior probability of the transmitted language sequence. Based on this foundation, we derive the optimal decoding criterion for the receiver and introduce the beam search algorithm to further reduce the complexity. Furthermore, we assert that existing LLMs can be employed directly for LLM-SC without additional re-training or fine-tuning. Simulation results demonstrate that LLM-SC outperforms classical DeepSC at signal-to-noise ratios (SNR) exceeding 3 dB, enabling error-free transmission of semantic information under high SNR, which is unattainable by DeepSC. In addition to semantic-level performance, LLM-SC demonstrates compatibility with technical-level performance, achieving approximately 8 dB coding gain for a bit error ratio (BER) of $10^{-3}$ without any channel coding while maintaining the same joint source-channel coding rate as traditional communication systems.

Paper number 200:
Title: Distilling High Diagnostic Value Patches for Whole Slide Image Classification Using Attention Mechanism
Authors: Tianhang Nan, Hao Quan, Yong Ding, Xingyu Li, Kai Yang, Xiaoyu Cui
Abstract: Multiple Instance Learning (MIL) has garnered widespread attention in the field of Whole Slide Image (WSI) classification as it replaces pixel-level manual annotation with diagnostic reports as labels, significantly reducing labor costs. Recent research has shown that bag-level MIL methods often yield better results because they can consider all patches of the WSI as a whole. However, a drawback of such methods is the incorporation of more redundant patches, leading to interference. To extract patches with high diagnostic value while excluding interfering patches to address this issue, we developed an attention-based feature distillation multi-instance learning (AFD-MIL) approach. This approach proposed the exclusion of redundant patches as a preprocessing operation in weakly supervised learning, directly mitigating interference from extensive noise. It also pioneers the use of attention mechanisms to distill features with high diagnostic value, as opposed to the traditional practice of indiscriminately and forcibly integrating all patches. Additionally, we introduced global loss optimization to finely control the feature distillation module. AFD-MIL is orthogonal to many existing MIL methods, leading to consistent performance improvements. This approach has surpassed the current state-of-the-art method, achieving 91.47% ACC (accuracy) and 94.29% AUC (area under the curve) on the Camelyon16 (Camelyon Challenge 2016, breast cancer), while 93.33% ACC and 98.17% AUC on the TCGA-NSCLC (The Cancer Genome Atlas Program: non-small cell lung cancer). Different feature distillation methods were used for the two datasets, tailored to the specific diseases, thereby improving performance and interpretability.

Paper number 201:
Title: ISLES'24: Final Infarct Prediction with Multimodal Imaging and Clinical Data. Where Do We Stand?
Authors: Ezequiel de la Rosa, Ruisheng Su, Mauricio Reyes, Evamaria O. Riedel, Hakim Baazaoui, Roland Wiest, Florian Kofler, Kaiyuan Yang, David Robben, Mahsa Mojtahedi, Laura van Poppel, Lucas de Vries, Anthony Winder, Kimberly Amador, Nils D. Forkert, Gyeongyeon Hwang, Jiwoo Song, Dohyun Kim, Eneko UruÃ±uela, Annabella Bregazzi, Matthias Wilms, Hyun Yang, Jin Tae Kwak, Sumin Jung, Luan Matheus Trindade Dalmazo, Kumaradevan Punithakumar, Moona Mazher, Abdul Qayyum, Steven Niederer, Jacob Idoko, Mariana Bento, Gouri Ginde, Tianyi Ren, Juampablo Heras Rivera, Mehmet Kurt, Carole Frindel, Susanne Wegener, Jan S. Kirschke, Benedikt Wiestler, Bjoern Menze
Abstract: Accurate estimation of brain infarction (i.e., irreversibly damaged tissue) is critical for guiding treatment decisions in acute ischemic stroke. Reliable infarct prediction informs key clinical interventions, including the need for patient transfer to comprehensive stroke centers, the potential benefit of additional reperfusion attempts during mechanical thrombectomy, decisions regarding secondary neuroprotective treatments, and ultimately, prognosis of clinical outcomes. This work introduces the Ischemic Stroke Lesion Segmentation (ISLES) 2024 challenge, which focuses on the prediction of final infarct volumes from pre-interventional acute stroke imaging and clinical data. ISLES24 provides a comprehensive, multimodal setting where participants can leverage all clinically and practically available data, including full acute CT imaging, sub-acute follow-up MRI, and structured clinical information, across a train set of 150 cases. On the hidden test set of 98 cases, the top-performing model, a multimodal nnU-Net-based architecture, achieved a Dice score of 0.285 (+/- 0.213) and an absolute volume difference of 21.2 (+/- 37.2) mL, underlining the significant challenges posed by this task and the need for further advances in multimodal learning. This work makes two primary contributions: first, we establish a standardized, clinically realistic benchmark for post-treatment infarct prediction, enabling systematic evaluation of multimodal algorithmic strategies on a longitudinal stroke dataset; second, we analyze current methodological limitations and outline key research directions to guide the development of next-generation infarct prediction models.

Paper number 202:
Title: Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets: A Hybrid Mean Field Approach
Authors: Jun He, Andrew L. Liu
Abstract: The integration of distributed energy resources (DERs) into wholesale energy markets can greatly enhance grid flexibility, improve market efficiency, and contribute to a more sustainable energy future. As DERs -- such as solar PV panels and energy storage -- proliferate, effective mechanisms are needed to ensure that small prosumers can participate meaningfully in these markets. We study a wholesale market model featuring multiple DER aggregators, each controlling a portfolio of DER resources and bidding into the market on behalf of the DER asset owners. The key of our approach lies in recognizing the repeated nature of market interactions the ability of participants to learn and adapt over time. Specifically, Aggregators repeatedly interact with each other and with other suppliers in the wholesale market, collectively shaping wholesale electricity prices (aka the locational marginal prices (LMPs)). We model this multi-agent interaction using a mean-field game (MFG), which uses market information -- reflecting the average behavior of market participants -- to enable each aggregator to predict long-term LMP trends and make informed decisions. For each aggregator, because they control the DERs within their portfolio under certain contract structures, we employ a mean-field control (MFC) approach (as opposed to a MFG) to learn an optimal policy that maximizes the total rewards of the DERs under their management. We also propose a reinforcement learning (RL)-based method to help each agent learn optimal strategies within the MFG framework, enhancing their ability to adapt to market conditions and uncertainties. Numerical simulations show that LMPs quickly reach a steady state in the hybrid mean-field approach. Furthermore, our results demonstrate that the combination of energy storage and mean-field learning significantly reduces price volatility compared to scenarios without storage.

Paper number 203:
Title: Mind the Context: Attention-Guided Weak-to-Strong Consistency for Enhanced Semi-Supervised Medical Image Segmentation
Authors: Yuxuan Cheng, Chenxi Shao, Jie Ma, Yunfei Xie, Guoliang Li
Abstract: Medical image segmentation is a pivotal step in diagnostic and therapeutic processes, relying on high-quality annotated data that is often challenging and costly to obtain. Semi-supervised learning offers a promising approach to enhance model performance by leveraging unlabeled data. Although weak-to-strong consistency is a prevalent method in semi-supervised image segmentation, there is a scarcity of research on perturbation strategies specifically tailored for semi-supervised medical image segmentation tasks. To address this challenge, this paper introduces a simple yet efficient semi-supervised learning framework named Attention-Guided weak-to-strong Consistency Match (AIGCMatch). The AIGCMatch framework incorporates attention-guided perturbation strategies at both the image and feature levels to achieve weak-to-strong consistency regularization. This method not only preserves the structural information of medical images but also enhances the model's ability to process complex semantic information. Extensive experiments conducted on the ACDC and ISIC-2017 datasets have validated the effectiveness of AIGCMatch. Our method achieved a 90.4\% Dice score in the 7-case scenario on the ACDC dataset, surpassing the state-of-the-art methods and demonstrating its potential and efficacy in clinical settings.

Paper number 204:
Title: Distributionally Robust Adaptive Beamforming
Authors: Shixiong Wang, Wei Dai, Geoffrey Ye Li
Abstract: As a fundamental technique in array signal processing, beamforming plays a crucial role in amplifying signals of interest (SoI) while mitigating interference plus noise (IPN). When uncertainties exist in the signal model or the data size of snapshots is limited, the performance of beamformers significantly degrades. In this article, we comprehensively study the conceptual system, theoretical analysis, and algorithmic design for robust beamforming against uncertainties in the assumed snapshot or IPN covariances. Since such robustness is specific to the probabilistic uncertainties of snapshots or IPN signals, it is referred to as distributional robustness. Particularly, four technical approaches for distributionally robust beamforming are proposed, including locally distributionally robust beamforming, globally distributionally robust beamforming, regularized beamforming, and Bayesian-nonparametric beamforming. In addition, we investigate the equivalence among the four technical approaches and suggest a unified distributionally robust beamforming framework. Moreover, we show that the resolution of power spectra estimation using distributionally robust beamforming can be greatly refined by incorporating the characteristics of subspace methods, and hence, the accuracy of IPN covariance reconstruction can be improved, especially when the interferers are close to the SoI. As a result, the robustness of beamformers based on IPN covariance estimation can be further enhanced.

Paper number 205:
Title: A Novel Automatic Real-time Motion Tracking Method in MRI-guided Radiotherapy Using Enhanced Tracking-Learning-Detection Framework with Automatic Segmentation
Authors: Shengqi Chen, Zilin Wang, Jianrong Dai, Shirui Qin, Ying Cao, Ruiao Zhao, Jiayun Chen, Guohua Wu, Yuan Tang
Abstract: Background and Purpose: Accurate motion tracking in MRI-guided Radiotherapy (MRIgRT) is essential for effective treatment delivery. This study aimed to enhance motion tracking precision in MRIgRT through an automatic real-time markerless tracking method using an enhanced Tracking-Learning-Detection (ETLD) framework with automatic segmentation. Materials and Methods: We developed a novel MRIgRT motion tracking and segmentation method by integrating the ETLD framework with an improved Chan-Vese model (ICV), named ETLD+ICV. The ETLD framework was upgraded for real-time cine MRI, including advanced image preprocessing, no-reference image quality assessment, an enhanced median-flow tracker, and a refined detector with dynamic search region adjustments. ICV was used for precise target volume coverage, refining the segmented region frame by frame using tracking results, with key parameters optimized. The method was tested on 3.5D MRI scans from 10 patients with liver metastases. Results: Evaluation of 106,000 frames across 77 treatment fractions showed sub-millimeter tracking errors of less than 0.8mm, with over 99% precision and 98% recall for all subjects in the Beam Eye View(BEV)/Beam Path View(BPV) orientation. The ETLD+ICV method achieved a dice global score of more than 82% for all subjects, demonstrating the method's extensibility and precise target volume coverage. Conclusion: This study successfully developed an automatic real-time markerless motion tracking method for MRIgRT that significantly outperforms current methods. The novel method not only delivers exceptional precision in tracking and segmentation but also shows enhanced adaptability to clinical demands, making it an indispensable asset in improving the efficacy of radiotherapy treatments.

Paper number 206:
Title: CT-Mamba: A Hybrid Convolutional State Space Model for Low-Dose CT Denoising
Authors: Linxuan Li, Wenjia Wei, Luyao Yang, Wenwen Zhang, Jiashu Dong, Yahua Liu, Hongshi Huang, Wei Zhao
Abstract: Low-dose CT (LDCT) significantly reduces the radiation dose received by patients, however, dose reduction introduces additional noise and artifacts. Currently, denoising methods based on convolutional neural networks (CNNs) face limitations in long-range modeling capabilities, while Transformer-based denoising methods, although capable of powerful long-range modeling, suffer from high computational complexity. Furthermore, the denoised images predicted by deep learning-based techniques inevitably exhibit differences in noise distribution compared to normal-dose CT (NDCT) images, which can also impact the final image quality and diagnostic outcomes. This paper proposes CT-Mamba, a hybrid convolutional State Space Model for LDCT image denoising. The model combines the local feature extraction advantages of CNNs with Mamba's strength in capturing long-range dependencies, enabling it to capture both local details and global context. Additionally, we introduce an innovative spatially coherent Z-shaped scanning scheme to ensure spatial continuity between adjacent pixels in the image. We design a Mamba-driven deep noise power spectrum (NPS) loss function to guide model training, ensuring that the noise texture of the denoised LDCT images closely resembles that of NDCT images, thereby enhancing overall image quality and diagnostic value. Experimental results have demonstrated that CT-Mamba performs excellently in reducing noise in LDCT images, enhancing detail preservation, and optimizing noise texture distribution, and exhibits higher statistical similarity with the radiomics features of NDCT images. The proposed CT-Mamba demonstrates outstanding performance in LDCT denoising and holds promise as a representative approach for applying the Mamba framework to LDCT denoising tasks.

Paper number 207:
Title: Experimental Study of Underwater Acoustic Reconfigurable Intelligent Surfaces with Synthetic Reflection
Authors: Yu Luo, Lina Pu, Aijun Song
Abstract: This paper presents an underwater acoustic reconfigurable intelligent surfaces (UA-RIS) designed for long-range, high-speed, and environmentally friendly communication in oceanic environments. The proposed UA-RIS comprises multiple pairs of acoustic reflectors that utilize a synthetic reflection scheme to flexibly control the amplitude and phase of reflected waves. This capability enables precise beam steering to enhance or attenuate sound levels in specific directions. A prototype UA-RIS with 4*6 acoustic reflection units is constructed and tested in both tank and lake environments to evaluate performance. Experimental results using a continuous wave (CW) as the source signal demonstrate that the prototype is capable of effectively pointing reflected waves to targeted directions while minimizing side lobes through synthetic reflection. Field tests reveal that deploying the UA-RIS on the sender side considerably extends communication ranges by 28% in deep water and 46% in shallow waters. Furthermore, with a fixed communication distance, positioning the UA-RIS at the transmitter side substantially boosts data rates, with an average increase of 63.8% and peaks up to 96%. When positioned on the receiver side, the UA-RIS can expand the communication range in shallow and deep water environments by 40.6% and 66%, respectively. Moreover, placing the UA-RIS close to the receiver enhances data rates by an average of 80.3%, reaching up to 163% under certain circumstances.

Paper number 208:
Title: Image Generation with Supervised Selection Based on Multimodal Features for Semantic Communications
Authors: Chengyang Liang, Dong Li
Abstract: Semantic communication (SemCom) has emerged as a promising technique for the next-generation communication systems, in which the generation at the receiver side is allowed with semantic features' recovery. However, the majority of existing research predominantly utilizes a singular type of semantic information, such as text, images, or speech, to supervise and choose the generated source signals, which may not sufficiently encapsulate the comprehensive and accurate semantic information, and thus creating a performance bottleneck. In order to bridge this gap, in this paper, we propose and investigate a SemCom framework using multimodal information to supervise the generated image. To be specific, in this framework, we first extract semantic features at both the image and text levels utilizing the Convolutional Neural Network (CNN) architecture and the Contrastive Language-Image Pre-Training (CLIP) model before transmission. Then, we employ a generative diffusion model at the receiver to generate multiple images. In order to ensure the accurate extraction and facilitate high-fidelity image reconstruction, we select the "best" image with the minimum reconstruction errors by taking both the aided image and text semantic features into account. We further extend multimodal semantic communication (MMSemCom) system to the multiuser scenario for orthogonal transmission. Experimental results demonstrate that the proposed framework can not only achieve the enhanced fidelity and robustness in image transmission compared with existing communication systems but also sustain a high performance in the low signal-to-noise ratio (SNR) conditions.

Paper number 209:
Title: AlignFormer: Modality Matching Can Achieve Better Zero-shot Instruction-Following Speech-LLM
Authors: Ruchao Fan, Bo Ren, Yuxuan Hu, Rui Zhao, Shujie Liu, Jinyu Li
Abstract: Integrating speech into LLM (speech-LLM) has gaining increased attention recently. The mainstream solution is to connect a well-trained speech encoder and LLM with a neural adapter. However, the length mismatch between the speech and text sequences are not well handled, leading to imperfect modality matching between the speech and text. In this work, we propose a novel neural adapter, AlignFormer, to reduce the length gap between the two modalities. AlignFormer consists of CTC and dynamic-window QFormer layers, where the CTC alignment provides the dynamic window information for QFormer. The LLM backbone is frozen in training to preserve its text capability, especially the instruction following capability. When training with ASR data only, the proposed AlignFormer unlocks the instruction following capability for speech-LLM and the model can perform zero-shot speech translation (ST) and speech question answering (SQA) tasks. In fact, speech-LLM with AlignFormer can theoretically perform any tasks that the LLM backbone can deal with in the speech version. To evaluate the effectiveness of the instruction-following speech-LLM, we propose to use instruction following rate (IFR) and offer a systematic perspective for the IFR evaluation. In addition, we find that the audio position in training would affect the instruction following capability of speech-LLM and conduct an in-depth study on it. Our findings show that audio-first training achieves higher IFR than instruction-first training. The AlignFormer can achieve a near 100% IFR with audio-first training and game-changing improvements from zero to non-zero IFR on some evaluation data with instruction-first training. We believe that this study is a big step towards the perfect speech and text modality matching in the LLM embedding space.

Paper number 210:
Title: QCResUNet: Joint Subject-level and Voxel-level Segmentation Quality Prediction
Authors: Peijie Qiu, Satrajit Chakrabarty, Phuc Nguyen, Soumyendu Sekhar Ghosh, Aristeidis Sotiras
Abstract: Deep learning has made significant strides in automated brain tumor segmentation from magnetic resonance imaging (MRI) scans in recent years. However, the reliability of these tools is hampered by the presence of poor-quality segmentation outliers, particularly in out-of-distribution samples, making their implementation in clinical practice difficult. Therefore, there is a need for quality control (QC) to screen the quality of the segmentation results. Although numerous automatic QC methods have been developed for segmentation quality screening, most were designed for cardiac MRI segmentation, which involves a single modality and a single tissue type. Furthermore, most prior works only provided subject-level predictions of segmentation quality and did not identify erroneous parts segmentation that may require refinement. To address these limitations, we proposed a novel multi-task deep learning architecture, termed QCResUNet, which produces subject-level segmentation-quality measures as well as voxel-level segmentation error maps for each available tissue class. To validate the effectiveness of the proposed method, we conducted experiments on assessing its performance on evaluating the quality of two distinct segmentation tasks. First, we aimed to assess the quality of brain tumor segmentation results. For this task, we performed experiments on one internal and two external datasets. Second, we aimed to evaluate the segmentation quality of cardiac Magnetic Resonance Imaging (MRI) data from the Automated Cardiac Diagnosis Challenge. The proposed method achieved high performance in predicting subject-level segmentation-quality metrics and accurately identifying segmentation errors on a voxel basis. This has the potential to be used to guide human-in-the-loop feedback to improve segmentations in clinical settings.

Paper number 211:
Title: BS-LDM: Effective Bone Suppression in High-Resolution Chest X-Ray Images with Conditional Latent Diffusion Models
Authors: Yifei Sun, Zhanghao Chen, Hao Zheng, Wenming Deng, Jin Liu, Wenwen Min, Ahmed Elazab, Xiang Wan, Changmiao Wang, Ruiquan Ge
Abstract: Lung diseases represent a significant global health challenge, with Chest X-Ray (CXR) being a key diagnostic tool due to its accessibility and affordability. Nonetheless, the detection of pulmonary lesions is often hindered by overlapping bone structures in CXR images, leading to potential misdiagnoses. To address this issue, we develop an end-to-end framework called BS-LDM, designed to effectively suppress bone in high-resolution CXR images. This framework is based on conditional latent diffusion models and incorporates a multi-level hybrid loss-constrained vector-quantized generative adversarial network which is crafted for perceptual compression, ensuring the preservation of details. To further enhance the framework's performance, we utilize offset noise in the forward process, and a temporal adaptive thresholding strategy in the reverse process. These additions help minimize discrepancies in generating low-frequency information of soft tissue images. Additionally, we have compiled a high-quality bone suppression dataset named SZCH-X-Rays. This dataset includes 818 pairs of high-resolution CXR and soft tissue images collected from our partner hospital. Moreover, we processed 241 data pairs from the JSRT dataset into negative images, which are more commonly used in clinical practice. Our comprehensive experiments and downstream evaluations reveal that BS-LDM excels in bone suppression, underscoring its clinical value. Our code is available at this https URL.

Paper number 212:
Title: Bayesian Model Parameter Learning in Linear Inverse Problems: Application in EEG Focal Source Imaging
Authors: Alexandra Koulouri, Ville Rimpilainen
Abstract: Inverse problems can be described as limited-data problems in which the signal of interest cannot be observed directly. A physics-based forward model that relates the signal with the observations is typically needed. Unfortunately, unknown model parameters and imperfect forward models can undermine the signal recovery. Even though supervised machine learning offers promising avenues to improve the robustness of the solutions, we have to rely on model-based learning when there is no access to ground truth for the training. Here, we studied a linear inverse problem that included an unknown non-linear model parameter and utilized a Bayesian model-based learning approach that allowed signal recovery and subsequently estimation of the model parameter. This approach, called Bayesian Approximation Error approach, employed a simplified model of the physics of the problem augmented with an approximation error term that compensated for the simplification. An error subspace was spanned with the help of the eigenvectors of the approximation error covariance matrix which allowed, alongside the primary signal, simultaneous estimation of the induced error. The estimated error and signal were then used to determine the unknown model parameter. For the model parameter estimation, we tested different approaches: a conditional Gaussian regression, an iterative (model-based) optimization, and a Gaussian process that was modeled with the help of physics-informed learning. In addition, alternating optimization was used as a reference method. As an example application, we focused on the problem of reconstructing brain activity from EEG recordings under the condition that the electrical conductivity of the patient's skull was unknown in the model. Our results demonstrated clear improvements in EEG source localization accuracy and provided feasible estimates for the unknown model parameter, skull conductivity.

Paper number 213:
Title: Identifying Large-Scale Linear Parameter Varying Systems with Dynamic Mode Decomposition Methods
Authors: Jean Panaioti Jordanou, Eduardo Camponogara, Eduardo Gildin
Abstract: Linear Parameter Varying (LPV) Systems are a well-established class of nonlinear systems with a rich theory for stability analysis, control, and analytical response finding, among other aspects. Although there are works on data-driven identification of such systems, the literature is quite scarce in terms of works that tackle the identification of LPV models for large-scale systems. Since large-scale systems are ubiquitous in practice, this work develops a methodology for the local and global identification of large-scale LPV systems based on nonintrusive reduced-order modeling. The developed method is coined as DMD-LPV for being inspired in the Dynamic Mode Decomposition (DMD). To validate the proposed identification method, we identify a system described by a discretized linear diffusion equation, with the diffusion gain defined by a polynomial over a parameter. The experiments show that the proposed method can easily identify a reduced-order LPV model of a given large-scale system without the need to perform identification in the full-order dimension, and with almost no performance decay over performing a reduction, given that the model structure is well-established.

Paper number 214:
Title: AFDM-Enabled Integrated Sensing and Communication: Theoretical Framework and Pilot Design
Authors: Fan Zhang, Zhaocheng Wang, Tianqi Mao, Tianyu Jiao, Yinxiao Zhuo, Miaowen Wen, Wei Xiang, Sheng Chen, George K. Karagiannidis
Abstract: The integrated sensing and communication (ISAC) has been envisioned as one representative usage scenario of sixth-generation (6G) network. However, the unprecedented characteristics of 6G, especially the doubly dispersive channel, make classical ISAC waveforms rather challenging to guarantee a desirable performance level. The recently proposed affine frequency division multiplexing (AFDM) can attain full diversity even under doubly dispersive effects, thus becoming a competitive candidate for next-generation ISAC waveforms. Relevant investigations are still at an early stage, which involve only straightforward design lacking explicit theoretical analysis. This paper provides an in-depth investigation on AFDM waveform design for ISAC applications. Specifically, the closed-form CrÃ¡mer-Rao bounds of target detection for AFDM are derived, followed by a demonstration on its merits over existing counterparts. Furthermore, we formulate the ambiguity function of the pilot-assisted AFDM waveform for the first time, revealing conditions for stable sensing performance. To further enhance both the communication and sensing performance of the AFDM waveform, we propose a novel pilot design by exploiting the characteristics of AFDM signals. The proposed design is analytically validated to be capable of optimizing the ambiguity function property and channel estimation accuracy simultaneously as well as overcoming the sensing and channel estimation range limitation originated from the pilot spacing. Numerical results have verified the superiority of the proposed pilot design in terms of dual-functional performance.

Paper number 215:
Title: On Performance of LoRa Fluid Antenna Systems
Authors: Gaoze Mu, Yanzhao Hou, Kai-Kit Wong, Mingjie Chen, Qimei Cui, Xiaofeng Tao, Ping Zhang
Abstract: This paper advocates a fluid antenna system (FAS)-assisted long-range communication (LoRa-FAS) for Internet-of-Things (IoT) applications. \textcolor{blue}{In the proposed system, FAS provides spatial diversity gains for LoRa, eliminating the necessity for integrating multiple-input multiple-output (MIMO) technologies into the system. It consists of a traditional LoRa transmitter with a fixed-position antenna and a LoRa receiver employing the FAS (Rx-FAS). The pilot sequence overhead and placement for FAS are also considered. Specifically, we consider embedding pilot sequences within symbols to reduce the impact of pilot overhead on system throughput and the physical layer (PHY) frame structure, leveraging the fact that the pilot sequences do not convey source information and correlation detection at the LoRa receiver needs not be performed across the entire symbol. The achievable performance of LoRa-FAS is thoroughly analyzed under both coherent and non-coherent detection schemes.} We obtain new closed-form approximations for the probability density function (PDF) and cumulative distribution function (CDF) of the FAS channel under the block-correlation model. Furthermore, the approximate SER, equivalently the bit error rate (BER), of the proposed LoRa-FAS is also derived in closed form. Simulation results indicate that substantial SER gains can be achieved by FAS within the LoRa framework, even with a limited size of FAS. In addition, our analytical results align well with Clarke's exact spatial correlation model. Finally, when utilizing the block-correlation model, we suggest that the correlation factor should be selected as the proportion of the eigenvalues of the exact correlation matrix greater than 1 for higher accuracy.

Paper number 216:
Title: Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces
Authors: Jiyuan Wang, Weishan Ye, Jialin He, Li Zhang, Gan Huang, Zhuliang Yu, Zhen Liang
Abstract: With the rapid advancement of deep learning, attention mechanisms have become indispensable in electroencephalography (EEG) signal analysis, significantly enhancing Brain-Computer Interface (BCI) applications. This paper presents a comprehensive review of traditional and Transformer-based attention mechanisms, their embedding strategies, and their applications in EEG-based BCI, with a particular emphasis on multimodal data fusion. By capturing EEG variations across time, frequency, and spatial channels, attention mechanisms improve feature extraction, representation learning, and model robustness. These methods can be broadly categorized into traditional attention mechanisms, which typically integrate with convolutional and recurrent networks, and Transformer-based multi-head self-attention, which excels in capturing long-range dependencies. Beyond single-modality analysis, attention mechanisms also enhance multimodal EEG applications, facilitating effective fusion between EEG and other physiological or sensory data. Finally, we discuss existing challenges and emerging trends in attention-based EEG modeling, highlighting future directions for advancing BCI technology. This review aims to provide valuable insights for researchers seeking to leverage attention mechanisms for improved EEG interpretation and application.

Paper number 217:
Title: Modeling Driver Behavior in Speed Advisory Systems: Koopman-based Approach with Online Update
Authors: Mehmet Fatih Ozkan, Jeff Chrstos, Marcello Canova, Stephanie Stockar
Abstract: Accurate driver behavior modeling is essential for improving the interaction and cooperation of the human driver with the driver assistance system. This paper presents a novel approach for modeling the response of human drivers to visual cues provided by a speed advisory system using a Koopman-based method with online updates. The proposed method utilizes the Koopman operator to transform the nonlinear dynamics of driver-speed advisory system interactions into a linear framework, allowing for efficient real-time prediction. An online update mechanism based on Recursive Least Squares (RLS) is integrated into the Koopman-based model to ensure continuous adaptation to changes in driver behavior over time. The model is validated using data collected from a human-in-the-loop driving simulator, capturing diverse driver-specific trajectories. The results demonstrate that the offline learned Koopman-based model can closely predict driver behavior and its accuracy is further enhanced through an online update mechanism with the RLS method.

Paper number 218:
Title: Neuroverse3D: Developing In-Context Learning Universal Model for Neuroimaging in 3D
Authors: Jiesi Hu, Chenfei Ye, Yanwu Yang, Xutao Guo, Yang Shang, Pengcheng Shi, Hanyang Peng, Ting Ma
Abstract: In-context learning (ICL), a type of universal model, demonstrates exceptional generalization across a wide range of tasks without retraining by leveraging task-specific guidance from context, making it particularly effective for the intricate demands of neuroimaging. However, current ICL models, limited to 2D inputs and thus exhibiting suboptimal performance, struggle to extend to 3D inputs due to the high memory demands of ICL. In this regard, we introduce Neuroverse3D, an ICL model capable of performing multiple neuroimaging tasks in 3D (e.g., segmentation, denoising, inpainting). Neuroverse3D overcomes the large memory consumption associated with 3D inputs through adaptive parallel-sequential context processing and a U-shaped fusion strategy, allowing it to handle an unlimited number of context images. Additionally, we propose an optimized loss function to balance multi-task training and enhance focus on anatomical boundaries. Our study incorporates 43,674 3D multi-modal scans from 19 neuroimaging datasets and evaluates Neuroverse3D on 14 diverse tasks using held-out test sets. The results demonstrate that Neuroverse3D significantly outperforms existing ICL models and closely matches task-specific models, enabling flexible adaptation to medical center variations without retraining. The code and model weights are publicly available at this https URL.

Paper number 219:
Title: GlaGAN: A Generative Unsupervised Model for High-Precision Segmentation of Retinal Main Vessels toward Early Detection of Glaucoma
Authors: Cheng Huang, Weizheng Xie, Tsengdar J. Lee, Jui-Kai Wang, Karanjit Kooner, Ning Zhang, Jia Zhang
Abstract: Structural changes in the main retinal blood vessels are critical biomarkers for glaucoma onset and progression. Identifying these vessels is essential for vascular modeling yet highly challenging. This paper introduces GlaGAN, an unsupervised generative AI model for segmenting main blood vessels in Optical Coherence Tomography Angiography (OCTA) images. The process begins with the Space Colonization Algorithm (SCA) to rapidly generate vessel skeletons, including radius estimations. By synergistically integrating generative adversarial networks (GANs) with biostatistical modeling of vessel radii, GlaGAN efficiently reconstructs 2D and 3D representations, achieving nearly 100\% segmentation accuracy without requiring labeled data or high-performance computing resources. To address data scarcity, we also present GSS-RetVein, a high-definition mixed 2D/3D glaucoma retinal dataset featuring clear capillary structures. Designed for robustness testing, GSS-RetVein incorporates controlled noise while maintaining sharp capillary boundaries in 2D and enhancing 3D vascular reconstruction for blood flow prediction and glaucoma progression simulations. Experimental results demonstrate GSS-RetVein outperforms existing datasets in evaluating main vessel segmentation. Code and dataset are available: this https URL.

Paper number 220:
Title: Liquid Lens-Based Imaging Receiver for MIMO VLC Systems
Authors: Kapila W. S. Palitharathna, Christodoulos Skouroumounis, Ioannis Krikidis
Abstract: In this paper, we consider a tunable liquid convex lens-assisted imaging receiver for indoor multiple-input multiple-output (MIMO) visible light communication (VLC) systems. In contrast to existing MIMO VLC receivers that rely on fixed optical lenses, the proposed receiver leverages the additional degrees of freedom offered by liquid lenses via adjusting both focal length and orientation angles of the lens. This capability facilitates the mitigation of spatial correlation between the channel gains, thereby enhancing the overall signal quality and leading to improved bit-error rate (BER) performance. We present an accurate channel model for the liquid lens-assisted VLC system by using three-dimensional geometry and geometric optics. To achieve optimal performance under practical conditions such as random receiver orientation and user mobility, optimization of both focal length and orientation angles of the lens are required. To this end, driven by the fact that channel models are mathematically complex, we present two optimization schemes including a blockwise machine learning (ML) architecture that includes convolution layers to extract spatial features from the received signal, long-short term memory layers to predict the user position and orientation, and fully connected layers to estimate the optimal lens parameters. Numerical results are presented to compare the performance of each scheme with conventional receivers. Results show that a significant BER improvement is achieved when liquid lenses and presented ML-based optimization approaches are used. Specifically, the BER can be improved from $6\times 10^{-2}$ to $1.4\times 10^{-3}$ at an average signal-to-noise ratio of $30$ dB.

Paper number 221:
Title: Inference and Learning of Nonlinear LFR State-Space Models
Authors: Merijn Floren, Jean-Philippe NoÃ«l, Jan Swevers
Abstract: Estimating the parameters of nonlinear block-oriented state-space models from input-output data typically involves solving a highly non-convex optimization problem, which is prone to poor local minima and slow convergence. This paper presents a computationally efficient initialization method for nonlinear linear fractional representation (NL-LFR) models using periodic data. By first inferring the latent signals and subsequently estimating the model parameters, the approach generates initial estimates for use in a later nonlinear optimization step. The proposed method shows robustness against poor local minima, and achieves a twofold error reduction compared to the state-of-the-art on a challenging benchmark dataset.

Paper number 222:
Title: Reinforcement learning for robust dynamic metabolic control
Authors: SebastiÃ¡n Espinel-RÃ­os, River Walser, Dongda Zhang
Abstract: Dynamic metabolic control enables key metabolic fluxes to be modulated in real time, enhancing bioprocess flexibility and expanding the available optimization degrees of freedom. This can be achieved, e.g., via targeted modulation of metabolic enzyme expression. However, identifying optimal dynamic control policies in metabolic engineering is challenging due to the generally high-dimensional solution space, and the need to manage potential metabolic burden and cytotoxic effects, arising from inducible enzyme expression. This task is further complicated by the presence of stochastic dynamics, which reduce the reproducibility of bioprocesses. Here, we propose a reinforcement learning framework to derive optimal dynamic metabolic control policies by allowing an agent (i.e., the controller) to interact with a surrogate dynamic model $\textit{in silico}$. To promote robustness in the metabolic control policies, we apply domain randomization, enabling the controller to generalize across system uncertainties. Our framework provides an alternative to conventional model-based control such as model predictive control, which requires model differentiation with respect to decision variables; an often impractical task when dealing with complex stochastic, nonlinear, stiff, and piecewise-defined dynamics. In contrast, our approach only requires forward integration, making the task much simpler. We demonstrate our framework in two $\textit{Escherichia coli}$ bioprocesses, one involving the dynamic control of acetyl-CoA carboxylase in the synthesis of fatty acids, and another one dealing with the dynamic control of adenosine triphosphatase in the synthesis of lactate.

Paper number 223:
Title: GAMBAS: Generalised-Hilbert Mamba for Super-resolution of Paediatric Ultra-Low-Field MRI
Authors: Levente Baljer, Ula Briski, Robert Leech, Niall J. Bourke, Kirsten A. Donald, Layla E. Bradford, Simone R. Williams, Sadia Parkar, Sidra Kaleem, Salman Osmani, Sean C. L. Deoni, Steven C. R. Williams, Rosalyn J. Moran, Emma C. Robinson, Frantisek Vasa
Abstract: Magnetic resonance imaging (MRI) is critical for neurodevelopmental research, however access to high-field (HF) systems in low- and middle-income countries is severely hindered by their cost. Ultra-low-field (ULF) systems mitigate such issues of access inequality, however their diminished signal-to-noise ratio limits their applicability for research and clinical use. Deep-learning approaches can enhance the quality of scans acquired at lower field strengths at no additional cost. For example, Convolutional neural networks (CNNs) fused with transformer modules have demonstrated a remarkable ability to capture both local information and long-range context. Unfortunately, the quadratic complexity of transformers leads to an undesirable trade-off between long-range sensitivity and local precision. We propose a hybrid CNN and state-space model (SSM) architecture featuring a novel 3D to 1D serialisation (GAMBAS), which learns long-range context without sacrificing spatial precision. We exhibit improved performance compared to other state-of-the-art medical image-to-image translation models.

Paper number 224:
Title: Examining Joint Demosaicing and Denoising for Single-, Quad-, and Nona-Bayer Patterns
Authors: SaiKiran Tedla, Abhijith Punnappurath, Luxi Zhao, Michael S. Brown
Abstract: Camera sensors have color filters arranged in a mosaic layout, traditionally following the Bayer pattern. Demosaicing is a critical step camera hardware applies to obtain a full-channel RGB image. Many smartphones now have multiple sensors with different patterns, such as Quad-Bayer or Nona-Bayer. Most modern deep network-based models perform joint demosaicing and denoising with the strategy of training a separate network per pattern. Relying on individual models per pattern requires additional memory overhead and makes it challenging to switch quickly between cameras. In this work, we are interested in analyzing strategies for joint demosaicing and denoising for the three main mosaic layouts (1x1 Single-Bayer, 2x2 Quad-Bayer, and 3x3 Nona-Bayer). We found concatenating a three-channel mosaic embedding to the input image and training a unified demosaicing architecture yields results that outperform existing Quad-Bayer and Nona-Bayer models and are comparable to Single-Bayer models. Additionally, we describe a maskout strategy that enhances the model performance and facilitates dead pixel correction -- a step often overlooked by existing AI-based demosaicing models. As part of this effort, we captured a new demosaicing dataset of 638 RAW images that contain challenging scenes with patches annotated for training, validation, and testing. Code and data is available at this https URL.

Paper number 225:
Title: Simultaneous Input and State Estimation under Output Quantization: A Gaussian Mixture approach
Authors: Rodrigo A. GonzÃ¡lez, Angel L. CedeÃ±o
Abstract: Simultaneous Input and State Estimation (SISE) enables the reconstruction of unknown inputs and internal states in dynamical systems, with applications in fault detection, robotics, and control. While various methods exist for linear systems, extensions to systems with output quantization are scarce, and no formal connections to limit Kalman filters are known in this context. This work addresses these gaps by proposing a novel SISE algorithm for linear systems with quantized output measurements. The proposed algorithm introduces a Gaussian mixture model formulation of the observation model, which leads to closed-form recursive equations in the form of a Gaussian sum filter. In the absence of input prior knowledge, the recursions are shown to converge to a limit-case SISE algorithm, implementable as a bank of linear SISE filters running in parallel. A simulation example is presented to illustrate the effectiveness of the proposed approach.

Paper number 226:
Title: Learned enclosure method for experimental EIT data
Authors: Sara Sippola, Siiri Rautio, Andreas Hauptmann, Takanori Ide, Samuli Siltanen
Abstract: Electrical impedance tomography (EIT) is a non-invasive imaging method with diverse applications, including medical imaging and non-destructive testing. The inverse problem of reconstructing internal electrical conductivity from boundary measurements is nonlinear and highly ill-posed, making it difficult to solve accurately. In recent years, there has been growing interest in combining analytical methods with machine learning to solve inverse problems. In this paper, we propose a method for estimating the convex hull of inclusions from boundary measurements by combining the enclosure method proposed by Ikehata with neural networks. We demonstrate its performance using experimental data. Compared to the classical enclosure method with least squares fitting, the learned convex hull achieves superior performance on both simulated and experimental data.

Paper number 227:
Title: A Data-centric Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections
Authors: Bo Zhou, Kaijie Xu, Yinghui Quan, Mengdao Xing
Abstract: In practical scenarios, processes such as sensor design, manufacturing, and installation will introduce certain errors. Furthermore, mutual interference occurs when the sensors receive signals. These defects in array systems are referred to as array imperfections, which can significantly degrade the performance of Direction of Arrival (DOA) estimation. In this study, we propose a deep-learning based transfer learning approach, which effectively mitigates the degradation of deep-learning based DOA estimation performance caused by array imperfections. In the proposed approach, we highlight three major contributions. First, we propose a Vision Transformer (ViT) based method for DOA estimation, which achieves excellent performance in scenarios with low signal-to-noise ratios (SNR) and limited snapshots. Second, we introduce a transfer learning framework that extends deep learning models from ideal simulation scenarios to complex real-world scenarios with array imperfections. By leveraging prior knowledge from ideal simulation data, the proposed transfer learning framework significantly improves deep learning-based DOA estimation performance in the presence of array imperfections, without the need for extensive real-world data. Finally, we incorporate visualization and evaluation metrics to assess the performance of DOA estimation algorithms, which allow for a more thorough evaluation of algorithms and further validate the proposed method. Our code can be accessed at this https URL.

Paper number 228:
Title: A Statistical Approach for Synthetic EEG Data Generation
Authors: Gideon Vos, Maryam Ebrahimpour, Liza van Eijk, Zoltan Sarnyai, Mostafa Rahimi Azghadi
Abstract: Electroencephalogram (EEG) data is crucial for diagnosing mental health conditions but is costly and time-consuming to collect at scale. Synthetic data generation offers a promising solution to augment datasets for machine learning applications. However, generating high-quality synthetic EEG that preserves emotional and mental health signals remains challenging. This study proposes a method combining correlation analysis and random sampling to generate realistic synthetic EEG data. We first analyze interdependencies between EEG frequency bands using correlation analysis. Guided by this structure, we generate synthetic samples via random sampling. Samples with high correlation to real data are retained and evaluated through distribution analysis and classification tasks. A Random Forest model trained to distinguish synthetic from real EEG performs at chance level, indicating high fidelity. The generated synthetic data closely match the statistical and structural properties of the original EEG, with similar correlation coefficients and no significant differences in PERMANOVA tests. This method provides a scalable, privacy-preserving approach for augmenting EEG datasets, enabling more efficient model training in mental health research.

Paper number 229:
Title: Toward a Harmonized Approach -- Requirement-based Structuring of a Safety Assurance Argumentation for Automated Vehicles
Authors: Marvin Loba, Nayel Fabian Salem, Marcus Nolte, Andreas Dotzler, Dieter Ludwig, Markus Maurer
Abstract: Despite the increasing testing operations of automated vehicles on public roads, media reports on incidents show that safety issues caused by automated driving systems persist to this day. Manufacturers face high development uncertainty when aiming to deploy these systems in an open context. In particular, one challenge is establishing a valid argument at design time that the vehicles will exhibit reasonable residual risk when operating in its intended operational design domain. While there is extensive literature on assurance cases for safety-critical systems in general, the domain of automated driving lacks explicit requirements regarding the creation of safety assurance argumentations for automated vehicles. In this paper, we aim to narrow this gap by elaborating a requirement-based approach. We identify structural requirements for an argumentation based on published literature and supplement these with structural requirements derived from stakeholder concerns. We apply these requirements to obtain a proposal for a generic argumentation structure. The resulting "safety arguments" address the developed product (product argument), the underlying process (process argument) including its conformance/compliance to standards/laws (conformance/compliance argument), as well as an argumentation's context (context argument) and soundness (soundness argument). Finally, we outline argumentation principles in accordance with domain-specific needs and concepts.

Paper number 230:
Title: StereoINR: Cross-View Geometry Consistent Stereo Super Resolution with Implicit Neural Representation
Authors: Yi Liu, Xinyi Liu, Yi Wan, Panwang Xia, Qiong Wu, Yongjun Zhang
Abstract: Stereo image super-resolution (SSR) aims to enhance high-resolution details by leveraging information from stereo image pairs. However, existing stereo super-resolution (SSR) upsampling methods (e.g., pixel shuffle) often overlook cross-view geometric consistency and are limited to fixed-scale upsampling. The key issue is that previous upsampling methods use convolution to independently process deep features of different views, lacking cross-view and non-local information perception, making it difficult to select beneficial information from multi-view scenes adaptively. In this work, we propose Stereo Implicit Neural Representation (StereoINR), which innovatively models stereo image pairs as continuous implicit representations. This continuous representation breaks through the scale limitations, providing a unified solution for arbitrary-scale stereo super-resolution reconstruction of left-right views. Furthermore, by incorporating spatial warping and cross-attention mechanisms, StereoINR enables effective cross-view information fusion and achieves significant improvements in pixel-level geometric consistency. Extensive experiments across multiple datasets show that StereoINR outperforms out-of-training-distribution scale upsampling and matches state-of-the-art SSR methods within training-distribution scales.

Paper number 231:
Title: BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression
Authors: Wei Jiang, Junru Li, Kai Zhang, Li Zhang
Abstract: Recent forward prediction-based learned video compression (LVC) methods have achieved impressive results, even surpassing VVC reference software VTM under the Low Delay B (LDB) configuration. In contrast, learned bidirectional video compression (BVC) remains underexplored and still lags behind its forward-only counterparts. This performance gap is mainly due to the limited ability to extract diverse and accurate contexts: most existing BVCs primarily exploit temporal motion while neglecting non-local correlations across frames. Moreover, they lack the adaptability to dynamically suppress harmful contexts arising from fast motion or occlusion. To tackle these challenges, we propose BiECVC, a BVC framework that incorporates diversified local and non-local context modeling along with adaptive context gating. For local context enhancement, BiECVC reuses high-quality features from lower layers and aligns them using decoded motion vectors without introducing extra motion overhead. To model non-local dependencies efficiently, we adopt a linear attention mechanism that balances performance and complexity. To further mitigate the impact of inaccurate context prediction, we introduce Bidirectional Context Gating, inspired by data-dependent decay in recent autoregressive language models, to dynamically filter contextual information based on conditional coding results. Extensive experiments demonstrate that BiECVC achieves state-of-the-art performance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2 under the Random Access (RA) configuration with intra periods of 32 and 64, respectively. To our knowledge, BiECVC is the first learned video codec to surpass VTM 13.2 RA across all standard test datasets. Code will be available at this https URL.

Paper number 232:
Title: Lifelong reinforcement learning for health-aware fast charging of lithium-ion batteries
Authors: Meng Yuan, Changfu Zou
Abstract: Fast charging of lithium-ion batteries remains a critical bottleneck for widespread adoption of electric vehicles and stationary energy storage systems, as improperly designed fast charging can accelerate battery degradation and shorten lifespan. In this work, we address this challenge by proposing a health-aware fast charging strategy that explicitly balances charging speed and battery longevity across the entire service life. The key innovation lies in establishing a mapping between anode overpotential and the state of health (SoH) of battery, which is then used to constrain the terminal charging voltage in a twin delayed deep deterministic policy gradient (TD3) framework. By incorporating this SoH-dependent voltage constraint, our designed deep learning method mitigates side reactions and effectively extends battery life. To validate the proposed approach, a high-fidelity single particle model with electrolyte is implemented in the widely adopted PyBaMM simulation platform, capturing degradation phenomena at realistic scales. Comparative life-cycle simulations against conventional CC-CV, its variants, and constant current-constant overpotential methods show that the TD3-based controller reduces overall degradation while maintaining competitively fast charge times. These results demonstrate the practical viability of deep reinforcement learning for advanced battery management systems and pave the way for future explorations of health-aware, performance-optimized charging strategies.

Paper number 233:
Title: Incremental Firmware Update Over-the-Air for Low-Power IoT Devices over LoRaWAN
Authors: Andrea De Simone, Giovanna Turvani, Fabrizio Riente
Abstract: Efficiently supporting remote firmware updates in Internet of Things (IoT) devices remains a significant challenge due to the limitations of many IoT communication protocols, which often make it impractical to transmit full firmware images. Techniques such as firmware partitioning have been introduced to mitigate this issue, but they frequently fall short, especially in battery-powered systems where time and energy constraints are critical. As a result, physical maintenance interventions are still commonly required, which is costly and inconvenient in large-scale deployments. In this work, we present a lightweight and innovative method that addresses this challenge by generating highly compact delta patches, enabling firmware reconstruction directly on the device. Our algorithm is specifically optimized for low-power devices, minimizing both memory usage and computational overhead. Compared to existing solutions, our approach significantly reduces the data volume needed for updates while maintaining performance comparable to more complex alternatives. Experimental evaluations confirm that our method yields substantial time and energy savings, making it particularly well-suited for battery-powered IoT nodes. Although our implementation targets the LoRaWAN protocol, the approach is flexible and can be adapted to other IoT communication technologies.

Paper number 234:
Title: A Distributed Local Energy Market Clearing Framework Using a Two-Loop ADMM Method
Authors: Milad Kabirifar, Biswarup Mukherjee, S. Gokul Krishnan, Charalambos Konstantinou, Subhash Lakshminarayana
Abstract: The diversity of prosumers' resources in energy communities can provide significant technical and economic benefits to both prosumers and the distribution system operator (DSO). To maximize these benefits, a coordination framework is required to address all techno-economic constraints as well as the objectives of all agents. This paper presents a fully distributed market-clearing scheme to coordinate the strategies of agents within a local energy community. In the proposed framework, prosumers, the DSO, and the local market operator (LMO) are the participating agents. The framework addresses the preferences and techno-economic constraints of all actors while preserving their privacy. The proposed model is based on a modified alternating direction method of multipliers (ADMM) method with two outer and inner loops; the outer loop models the interactions between the LMO and prosumers, while the inner loop addresses the interactions between the LMO and the DSO. The model is demonstrated on IEEE-69bus test network, showcasing its effectiveness from various perspectives.

Paper number 235:
Title: UltraBoneUDF: Self-supervised Bone Surface Reconstruction from Ultrasound Based on Neural Unsigned Distance Functions
Authors: Luohong Wu, Matthias Seibold, Nicola A. Cavalcanti, Giuseppe Loggia, Lisa Reissner, Bastian Sigrist, Jonas Hein, Lilian Calvet, Arnd ViehÃ¶fer, Philipp FÃ¼rnstahl
Abstract: Background: Bone surface reconstruction plays a critical role in computer-assisted orthopedic surgery. Compared to traditional imaging modalities such as CT and MRI, ultrasound offers a radiation-free, cost-effective, and portable alternative. Continuous bone surface reconstruction can be employed for many clinical applications. However, due to the inherent limitations of ultrasound imaging, B-mode ultrasound typically capture only partial bone surfaces. Existing reconstruction methods struggle with such incomplete data, leading to artifacts and increased reconstruction errors. Effective techniques for accurately reconstructing thin and open bone surfaces from real-world 3D ultrasound volumes remain lacking. Methods: We propose UltraBoneUDF, a self-supervised framework designed for reconstructing open bone surfaces from ultrasound using neural Unsigned Distance Functions. To enhance reconstruction quality, we introduce a novel global feature extractor that effectively fuses ultrasound-specific image characteristics. Additionally, we present a novel loss function based on local tangent plane optimization that substantially improves surface reconstruction quality. UltraBoneUDF and baseline models are extensively evaluated on four open-source datasets. Results: Qualitative results highlight the limitations of the state-of-the-art methods for open bone surface reconstruction and demonstrate the effectiveness of UltraBoneUDF. Quantitatively, UltraBoneUDF significantly outperforms competing methods across all evaluated datasets for both open and closed bone surface reconstruction in terms of mean Chamfer distance error: 1.10 mm on the UltraBones100k dataset (39.6\% improvement compared to the SOTA), 0.23 mm on the OpenBoneCT dataset (69.3\% improvement), 0.18 mm on the ClosedBoneCT dataset (70.2\% improvement), and 0.05 mm on the Prostate dataset (55.3\% improvement).

Paper number 236:
Title: Frequency and Bandwidth Design of FR3-Band Lithium Niobate Acoustic Filter
Authors: Taran Anusorn, Omar Barrera, Jack Kramer, Ian Anderson, Ziqian Yao, Vakhtang Chulukhadze, Ruochen Lu
Abstract: This article presents an approach to control the operating frequency and fractional bandwidth (FBW) of miniature acoustic filters in thin-film lithium niobate (TFLN). More specifically, we used first-order antisymmetric (A1) mode lateral-field-excited bulk acoustic wave resonators (XBARs) to achieve efficient operation at 20.5 GHz. Our technique leverages the thickness-dependent resonance frequency of A1 XBARs, combined with the in-plane anisotropic properties of 128$^\circ$ Y-cut TFLN, to customize filter characteristics. The implemented three-element ladder filter prototype achieves an insertion loss (IL) of only 1.79 dB and a controlled 3-dB FBW of 8.58% at 20.5 GHz, with an out-of-band (OoB) rejection greater than 14.9 dB across the entire FR3 band, while featuring a compact footprint of 0.90 $\times$ 0.74 mm$^2$. Moreover, an eight-element filter prototype shows an IL of 3.80 dB, an FBW of 6.12% at 22.0 GHz, and a high OoB rejection of 22.97 dB, demonstrating the potential for expanding to higher-order filters. As frequency allocation requirements become more stringent in future FR3 bands, our technique showcases promising capability in enabling compact and monolithic filter banks toward next-generation acoustic filters for 6G and beyond.

Paper number 237:
Title: Decoupling Periodic Systems: An Algebraic Approach
Authors: VladimÃ­r KuÄera
Abstract: This paper addresses the problem of row-by-row (or diagonal) decoupling of discrete-time linear multi-input multi-output systems with periodic time-varying coefficients using periodic state feedback. Previous solutions have tackled row-by-row decoupling using dynamic compensation for square systems and block-decoupling through regular state feedback for nonsquare systems with more outputs than inputs. While it appears likely that a row-by-row state feedback solution for square systems can be deduced from these findings, a direct argument seems more appropriate here as it presents a natural extension for decoupling nonsquare systems with more inputs than outputs. This extension, which necessitates nonregular state feedback, has yet to be explored for periodic systems. Our approach is purely algebraic, based on a time-invariant representation of the periodic system.

Paper number 238:
Title: UNSURF: Uncertainty Quantification for Cortical Surface Reconstruction of Clinical Brain MRIs
Authors: Raghav Mehta, Karthik Gopinath, Ben Glocker, Juan Eugenio Iglesias
Abstract: We propose UNSURF, a novel uncertainty measure for cortical surface reconstruction of clinical brain MRI scans of any orientation, resolution, and contrast. It relies on the discrepancy between predicted voxel-wise signed distance functions (SDFs) and the actual SDFs of the fitted surfaces. Our experiments on real clinical scans show that traditional uncertainty measures, such as voxel-wise Monte Carlo variance, are not suitable for modeling the uncertainty of surface placement. Our results demonstrate that UNSURF estimates correlate well with the ground truth errors and: \textit{(i)}~enable effective automated quality control of surface reconstructions at the subject-, parcel-, mesh node-level; and \textit{(ii)}~improve performance on a downstream Alzheimer's disease classification task.

Paper number 239:
Title: Prediction of the Conditional Probability Densities of Time Interval Extrema with Application to Risk-Sensitive Scheduling
Authors: Buyi Yu, Wenyuan Tang
Abstract: Planning and scheduling activities in the electrical power system, such as the commitment of reserve generation, often involve the statistical characterization of peak demand. Due to the stationarity assumption of classical extreme value analysis (EVA), existing approaches in the industry apply EVA on simulated annual peaks created by weather-dependent surrogate models using Monte-Carlo simulations on a per-scenario basis. In day-ahead scheduling, the daily peak demand changes upon various factors besides temperature, Monte-Carlo experiments become intractable, and state-of-the-art generalized additive model for location, scale and shape (GAMLSS)-based nonstationary EVA is often impractical due to convergence issues on high-dimensional covariates. This article explores uncharted territories and proposes a novel nonstationary EVA estimator that predicts the probable peaks of high-resolution time intervals and their corresponding conditional probability densities based on calendar information and weather conditions where historical peaks are observed. Compared to GAMLSS, our method automatically discovers and robustly models complex relationships between the covariate and the peak demand density. We present a case study on the determination of day-ahead scheduling capacity and demonstrate that compared to the industry approach, our approach results in a 38% reduction in the yearly total committed capacity while maintaining the given risk requirement.

Paper number 240:
Title: Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction
Authors: Ambrose Emmett-Iwaniw, Nathan Kirk
Abstract: Autoregressive models are often employed to learn distributions of image data by decomposing the $D$-dimensional density function into a product of one-dimensional conditional distributions. Each conditional depends on preceding variables (pixels, in the case of image data), making the order in which variables are processed fundamental to the model performance. In this paper, we study the problem of observing a small subset of image pixels (referred to as a pixel patch) to predict the unobserved parts of the image. As our prediction mechanism, we propose a generalized version of the convolutional neural autoregressive distribution estimation (ConvNADE) model adapted for real-valued and color images. Moreover, we investigate the quality of image reconstruction when observing both random pixel patches and low-discrepancy pixel patches inspired by quasi-Monte Carlo theory. Experiments on benchmark datasets demonstrate that, where design permits, pixels sampled or stored to preserve uniform coverage improves reconstruction fidelity and test performance.

Paper number 241:
Title: Direct Integration of Recursive Gaussian Process Regression Into Extended Kalman Filters With Application to Vapor Compression Cycle Control
Authors: Ricus Husmann, Sven Weishaupt, Harald Aschemann
Abstract: This paper presents a real-time capable algorithm for the learning of Gaussian Processes (GP) for submodels. It extends an existing recursive Gaussian Process (RGP) algorithm which requires a measurable output. In many applications, however, an envisaged GP output is not directly measurable. Therefore, we present the integration of an RGP into an Extended Kalman Filter (EKF) for the combined state estimation and GP learning. The algorithm is successfully tested in simulation studies and outperforms two alternative implementations -- especially if high measurement noise is present. We conclude the paper with an experimental validation within the control structure of a Vapor Compression Cycle typically used in refrigeration and heat pumps. In this application, the algorithm is used to learn a GP model for the heat-transfer values in dependency of several process parameters. The GP model significantly improves the tracking performance of a previously published model-based controller.

Paper number 242:
Title: Message Passing for Track-Before-Detect
Authors: Mingchao Liang, Florian Meyer
Abstract: Accurately tracking an unknown and time-varying number of objects in complex environments is a significant challenge but a fundamental capability in a variety of applications, including applied ocean sciences, surveillance, autonomous driving, and wireless communications. Conventional Bayesian multiobject tracking (MOT) methods typically employ a detect-then-track (DTT) approach, where a frontend detector preprocesses raw sensor data to extract measurements for MOT. The irreversible nature of this preprocessing step can discard valuable object-related information, particularly impairing the ability to resolve weak or closely spaced objects. The track-before-detect (TBD) paradigm offers an alternative by operating directly on sensor data. However, existing TBD approaches introduce simplifications to facilitate the development of inference methods, such as assuming known signal amplitudes or conditional independence between sensor measurements given object states. These assumptions can lead to suboptimal performance and limit the applicability of the resulting TBD methods in realistic scenarios. This paper introduces a novel TBD method that is based on a comprehensive signal model for sensor data. The new model accounts for sensor data correlations and amplitude fluctuations, enabling the accurate representation of the physics of the data-generating process in TBD. The proposed model is suitable for a wide range of problems in active and passive radar, active and passive sonar, as well as integrated sensing and communication systems. Based on a factor graph representation of the new measurement model, a scalable belief propagation (BP) method is developed to perform efficient Bayesian inference. Experimental results, performed with both synthetic and real data, demonstrate that the proposed method outperforms state-of-the-art conventional MOT methods.

Paper number 243:
Title: Multimodal Visual Image Based User Association and Beamforming Using Graph Neural Networks
Authors: Yinghan Li, Yiming Liu, Wei Yu
Abstract: This paper proposes an approach that leverages multimodal data by integrating visual images with radio frequency (RF) pilots to optimize user association and beamforming in a downlink wireless cellular network under a max-min fairness criterion. Traditional methods typically optimize wireless system parameters based on channel state information (CSI). However, obtaining accurate CSI requires extensive pilot transmissions, which lead to increased overhead and latency. Moreover, the optimization of user association and beamforming is a discrete and non-convex optimization problem, which is challenging to solve analytically. In this paper, we propose to incorporate visual camera data in addition to the RF pilots to perform the joint optimization of user association and beamforming. The visual image data helps enhance channel awareness, thereby reducing the dependency on extensive pilot transmissions for system optimization. We employ a learning-based approach based on using first a detection neural network that estimates user locations from images, and subsequently two graph neural networks (GNNs) that extract features for system optimization based on the location information and the received pilots, respectively. Then, a multimodal GNN is constructed to integrate the features for the joint optimization user association and beamforming. Simulation results demonstrate that the proposed method achieves superior performance, while having low computational complexity and being interpretable and generalizable, making it an effective solution as compared to traditional methods based only on RF pilots.

Paper number 244:
Title: Low-Complexity Frequency Domain Equalization of Zak-OTFS in Doubly-Spread Channels
Authors: Saif Khan Mohammed, Sandesh Rao Mattu, Nishant Mehrotra, Venkatesh Khammammetti, Robert Calderbank
Abstract: We communicate over wireless channels by first estimating and then equalizing the effective channel. In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform is a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic localized function with specific periods along delay and Doppler. When the channel delay spread is less than the delay period, and the channel Doppler spread is less than the Doppler period, the response to a single Zak-OTFS carrier provides an image of the scattering environment and can be used to predict the effective channel at all other carriers. This makes DD domain channel estimation straightforward, and there is no loss in spectral efficiency since it is possible to design data and pilot signals that are mutually unbiased. However, equalization in the DD domain has high complexity ${\mathcal O}(M^3N^3)$ where $M$, $N$ are respectively the number of delay and Doppler bins in an OTFS frame, and $MN$ is the number of information symbols. We demonstrate that equalization in the frequency domain (FD) reduces complexity to only ${\mathcal O}(M^2 N^2)$ by taking advantage of the banded structure of the effective FD channel. We also derive a low-complexity method to reconstruct the effective FD channel from the estimated DD domain effective channel.

Paper number 245:
Title: CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation
Authors: Xinlei Yu, Changmiao Wang, Hui Jin, Ahmed Elazab, Gangyong Jia, Xiang Wan, Changqing Zou, Ruiquan Ge
Abstract: Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: this https URL.

Paper number 246:
Title: ANN-Based Grid Impedance Estimation for Adaptive Gain Scheduling in VSG Under Dynamic Grid Conditions
Authors: Quang-Manh Hoang, Van Nam Nguyen, Taehyung Kim, Guilherme Vieira Hollweg, Wencong Su, Van-Hai Bui
Abstract: In contrast to grid-following inverters, Virtual Synchronous Generators (VSGs) perform well under weak grid conditions but may become unstable when the grid is strong. Grid strength depends on grid impedance, which unfortunately varies over time. In this paper, we propose a novel adaptive gain-scheduling control scheme for VSGs. First, an Artificial Neural Network (ANN) estimates the fundamental-frequency grid impedance; then these estimates are fed into an adaptive gain-scheduling function to recalculate controller parameters under varying grid conditions. The proposed method is validated in Simulink and compared with a conventional VSG employing fixed controller gains. The results demonstrate that settling times and overshoot percentages remain consistent across different grid conditions. Additionally, previously unseen grid impedance values are estimated with high accuracy and minimal time delay, making the approach well suited for real-time gain-scheduling control.

Paper number 247:
Title: AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm
Authors: Xinyue Li, Zhangkai Ni, Wenhan Yang
Abstract: Existing learning-based methods effectively reconstruct HDR images from multi-exposure LDR inputs with extended dynamic range and improved detail, but they rely more on empirical design rather than theoretical foundation, which can impact their reliability. To address these limitations, we propose the cross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR reconstruction is systematically decoupled into two interleaved subtasks -- alignment and fusion -- optimized through alternating refinement, achieving synergy between the two subtasks to enhance the overall performance. Our method formulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP) estimation perspective, explicitly incorporating spatial correspondence priors across LDR images and naturally bridging the alignment and fusion subproblems through joint constraints. Building on the mathematical foundation, we reimagine traditional iterative optimization through unfolding -- transforming the conventional solution process into an end-to-end trainable AFUNet with carefully designed modules that work progressively. Specifically, each iteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that alternates between a Spatial Alignment Module (SAM) for alignment and a Channel Fusion Module (CFM) for adaptive feature fusion, progressively bridging misaligned content and exposure discrepancies. Extensive qualitative and quantitative evaluations demonstrate AFUNet's superior performance, consistently surpassing state-of-the-art methods. Our code is available at: this https URL

Paper number 248:
Title: Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning
Authors: Siyang Tang, Wen-Hua Chen, Cunjia Liu
Abstract: This paper presents an auto-optimization control framework for wave energy converters (WECs) to maximize energy generation under unknown and changing ocean conditions. The proposed control framework consists of two levels. The high-level controller operating at a longer time scale aims to maximize the average energy generation over several wave periods. The generated Power Take-Off (PTO) profile as the reference for the low-level physical system to follow. The new auto-optimization process leverages the parameterization of the non-stationary operation condition in WECs, establishing the relationship between the average energy generation and the key design parameters of the PTO force subject to the unknown wave parameters. The high-level controller is designed based on the concept of Dual Control for Exploration and Exploitation (DCEE) to quickly learn the unknown wave parameters by actively probing the ocean condition, while generating the optimal PTO profile. During this process, the uncertainty of the estimated wave condition is quantified and embedded in the optimization cost function to enable active learning. Simulation results under unknown regular and irregular waves demonstrate the effectiveness and robustness of this novel auto-optimization WEC systems with active learning, outperforming model predictive control, extremum seeking and classic Bang-Bang control approaches.

Paper number 249:
Title: Unsupervised Cardiac Video Translation Via Motion Feature Guided Diffusion Model
Authors: Swakshar Deb, Nian Wu, Frederick H. Epstein, Miaomiao Zhang
Abstract: This paper presents a novel motion feature guided diffusion model for unpaired video-to-video translation (MFD-V2V), designed to synthesize dynamic, high-contrast cine cardiac magnetic resonance (CMR) from lower-contrast, artifact-prone displacement encoding with stimulated echoes (DENSE) CMR sequences. To achieve this, we first introduce a Latent Temporal Multi-Attention (LTMA) registration network that effectively learns more accurate and consistent cardiac motions from cine CMR image videos. A multi-level motion feature guided diffusion model, equipped with a specialized Spatio-Temporal Motion Encoder (STME) to extract fine-grained motion conditioning, is then developed to improve synthesis quality and fidelity. We evaluate our method, MFD-V2V, on a comprehensive cardiac dataset, demonstrating superior performance over the state-of-the-art in both quantitative metrics and qualitative assessments. Furthermore, we show the benefits of our synthesized cine CMRs improving downstream clinical and analytical tasks, underscoring the broader impact of our approach. Our code is publicly available at this https URL.

Paper number 250:
Title: Pronunciation Editing for Finnish Speech using Phonetic Posteriorgrams
Authors: Zirui Li, Lauri Juvela, Mikko Kurimo
Abstract: Synthesizing second-language (L2) speech is potentially highly valued for L2 language learning experience and feedback. However, due to the lack of L2 speech synthesis datasets, it is difficult to synthesize L2 speech for low-resourced languages. In this paper, we provide a practical solution for editing native speech to approximate L2 speech and present PPG2Speech, a diffusion-based multispeaker Phonetic-Posteriorgrams-to-Speech model that is capable of editing a single phoneme without text alignment. We use Matcha-TTS's flow-matching decoder as the backbone, transforming Phonetic Posteriorgrams (PPGs) to mel-spectrograms conditioned on external speaker embeddings and pitch. PPG2Speech strengthens the Matcha-TTS's flow-matching decoder with Classifier-free Guidance (CFG) and Sway Sampling. We also propose a new task-specific objective evaluation metric, the Phonetic Aligned Consistency (PAC), between the edited PPGs and the PPGs extracted from the synthetic speech for editing effects. We validate the effectiveness of our method on Finnish, a low-resourced, nearly phonetic language, using approximately 60 hours of data. We conduct objective and subjective evaluations of our approach to compare its naturalness, speaker similarity, and editing effectiveness with TTS-based editing. Our source code is published at this https URL.

Paper number 251:
Title: Pinching-Antenna-Assisted Index Modulation: Channel Modeling, Transceiver Design, and Performance Analysis
Authors: Shuaixin Yang, Yijia Li, Yue Xiao, Yong Liang Guan, Xianfu Lei, Zhiguo Ding
Abstract: In this paper, a novel pinching-antenna assisted index modulation (PA-IM) scheme is proposed for improving the spectral efficiency without increasing the hardware complexity, where the information bits are conveyed not only by the conventional M-ary quadrature amplitude modulation (QAM) symbols but also by the indices of pinching antenna (PA) position patterns. To realize the full potential of this scheme, this paper focuses on the comprehensive transceiver design, addressing key challenges in signal detection at the receiver and performance optimization at thetransmitter. First, a comprehensive channel model is formulated for this architecture, which sophisticatedly integrates the deterministic in-waveguide propagation effects with the stochastic nature of wireless channels, including both largescale path loss and small-scale fading. Next, to overcome the prohibitive complexity of optimal maximum likelihood (ML) detection, a low-complexity box-optimized sphere decoding (BOSD) algorithm is designed, which adaptively prunes the search space whilst preserving optimal ML performance. Furthermore, an analytical upper bound on the bit error rate (BER) is derived and validated by the simulations. Moreover, a new transmit precoding method is designed using manifold optimization, which minimizes the BER by jointly optimizing the complex-valued precoding coefficients across the waveguides for the sake of maximizing the minimum Euclidean distance of all received signal points. Finally, the simulation results demonstrate that the proposed PA-IM scheme attains a significant performance gain over its conventional counterparts and that the overall BER of the pinching-antenna system is substantially improved by the proposed precoding design.

Paper number 252:
Title: Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance
Authors: Jakob Kienegger, Alina Mannanova, Huajian Fang, Timo Gerkmann
Abstract: Recent works on deep non-linear spatially selective filters demonstrate exceptional enhancement performance with computationally lightweight architectures for stationary speakers of known directions. However, to maintain this performance in dynamic scenarios, resource-intensive data-driven tracking algorithms become necessary to provide precise spatial guidance conditioned on the initial direction of a target speaker. As this additional computational overhead hinders application in resource-constrained scenarios such as real-time speech enhancement, we present a novel strategy utilizing a low-complexity tracking algorithm in the form of a particle filter instead. Assuming a causal, sequential processing style, we introduce temporal feedback to leverage the enhanced speech signal of the spatially selective filter to compensate for the limited modeling capabilities of the particle filter. Evaluation on a synthetic dataset illustrates how the autoregressive interplay between both algorithms drastically improves tracking accuracy and leads to strong enhancement performance. A listening test with real-world recordings complements these findings by indicating a clear trend towards our proposed self-steering pipeline as preferred choice over comparable methods.

Paper number 253:
Title: DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift
Authors: Po-Heng Chou, Ching-Wen Chen, Wan-Jen Huang, Walid Saad, Yu Tsao, Ronald Y. Chang
Abstract: In this paper, the precoding design is investigated for maximizing the throughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO) systems with obstructed direct communication paths. In particular, a reconfigurable intelligent surface (RIS) is employed to enhance MIMO transmissions, considering mmWave characteristics related to line-of-sight (LoS) and multipath effects. The traditional exhaustive search (ES) for optimal codewords in the continuous phase shift is computationally intensive and time-consuming. To reduce computational complexity, permuted discrete Fourier transform (DFT) vectors are used for finding codebook design, incorporating amplitude responses for practical or ideal RIS systems. However, even if the discrete phase shift is adopted in the ES, it results in significant computation and is time-consuming. Instead, the trained deep neural network (DNN) is developed to facilitate faster codeword selection. Simulation results show that the DNN maintains sub-optimal spectral efficiency even as the distance between the end-user and the RIS has variations in the testing phase. These results highlight the potential of DNN in advancing RIS-aided systems.

Paper number 254:
Title: AASeg: Attention Aware Network for Real Time Semantic Segmentation
Authors: Abhinav Sagar
Abstract: Semantic segmentation is a fundamental task in computer vision that involves dense pixel-wise classification for scene understanding. Despite significant progress, achieving high accuracy while maintaining real-time performance remains a challenging trade-off, particularly for deployment in resource-constrained or latency-sensitive applications. In this paper, we propose AASeg, a novel Attention-Aware Network for real-time semantic segmentation. AASeg effectively captures both spatial and channel-wise dependencies through lightweight Spatial Attention (SA) and Channel Attention (CA) modules, enabling enhanced feature discrimination without incurring significant computational overhead. To enrich contextual representation, we introduce a Multi-Scale Context (MSC) module that aggregates dense local features across multiple receptive fields. The outputs from attention and context modules are adaptively fused to produce high-resolution segmentation maps. Extensive experiments on Cityscapes, ADE20K, and CamVid demonstrate that AASeg achieves a compelling trade-off between accuracy and efficiency, outperforming prior real-time methods.

Paper number 255:
Title: Iterative Linear Quadratic Optimization for Nonlinear Control: Differentiable Programming Algorithmic Templates
Authors: Vincent Roulet, Siddhartha Srinivasa, Maryam Fazel, Zaid Harchaoui
Abstract: Iterative optimization algorithms depend on access to information about the objective function. In a differentiable programming framework, this information, such as gradients, can be automatically derived from the computational graph. We explore how nonlinear control algorithms, often employing linear and/or quadratic approximations, can be effectively cast within this framework. Our approach illuminates shared components and differences between gradient descent, Gauss-Newton, Newton, and differential dynamic programming methods in the context of discrete time nonlinear control. Furthermore, we present line-search strategies and regularized variants of these algorithms, along with a comprehensive analysis of their computational complexities. We study the performance of the aforementioned algorithms on various nonlinear control benchmarks, including autonomous car racing simulations using a simplified car model. All implementations are publicly available in a package coded in a differentiable programming language.

Paper number 256:
Title: QuTE: decentralized multiple testing on sensor networks with false discovery rate control
Authors: Aaditya Ramdas, Jianbo Chen, Martin J. Wainwright, Michael I. Jordan
Abstract: This paper designs methods for decentralized multiple hypothesis testing on graphs that are equipped with provable guarantees on the false discovery rate (FDR). We consider the setting where distinct agents reside on the nodes of an undirected graph, and each agent possesses p-values corresponding to one or more hypotheses local to its node. Each agent must individually decide whether to reject one or more of its local hypotheses by only communicating with its neighbors, with the joint aim that the global FDR over the entire graph must be controlled at a predefined level. We propose a simple decentralized family of Query-Test-Exchange (QuTE) algorithms and prove that they can control FDR under independence or positive dependence of the p-values. Our algorithm reduces to the Benjamini-Hochberg (BH) algorithm when after graph-diameter rounds of communication, and to the Bonferroni procedure when no communication has occurred or the graph is empty. To avoid communicating real-valued p-values, we develop a quantized BH procedure, and extend it to a quantized QuTE procedure. QuTE works seamlessly in streaming data settings, where anytime-valid p-values may be continually updated at each node. Last, QuTE is robust to arbitrary dropping of packets, or a graph that changes at every step, making it particularly suitable to mobile sensor networks involving drones or other multi-agent systems. We study the power of our procedure using a simulation suite of different levels of connectivity and communication on a variety of graph structures, and also provide an illustrative real-world example.

Paper number 257:
Title: Uncertainty in Real-Time Semantic Segmentation on Embedded Systems
Authors: Ethan Goan, Clinton Fookes
Abstract: Application for semantic segmentation models in areas such as autonomous vehicles and human computer interaction require real-time predictive capabilities. The challenges of addressing real-time application is amplified by the need to operate on resource constrained hardware. Whilst development of real-time methods for these platforms has increased, these models are unable to sufficiently reason about uncertainty present when applied on embedded real-time systems. This paper addresses this by combining deep feature extraction from pre-trained models with Bayesian regression and moment propagation for uncertainty aware predictions. We demonstrate how the proposed method can yield meaningful epistemic uncertainty on embedded hardware in real-time whilst maintaining predictive performance.

Paper number 258:
Title: AVTENet: A Human-Cognition-Inspired Audio-Visual Transformer-Based Ensemble Network for Video Deepfake Detection
Authors: Ammarah Hashmi, Sahibzada Adil Shahzad, Chia-Wen Lin, Yu Tsao, Hsin-Min Wang
Abstract: The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous studies on detecting artificial intelligence-generated fake videos only utilize visual modality or audio modality. While some methods exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multimodal datasets of deepfake videos involving acoustic and visual manipulations, and are mostly based on convolutional neural networks with low detection accuracy. Considering that human cognition instinctively integrates multisensory information including audio and visual cues to perceive and interpret content and the success of transformer in various fields, this study introduces the audio-visual transformer-based ensemble network (AVTENet). This innovative framework tackles the complexities of deepfake technology by integrating both acoustic and visual manipulations to enhance the accuracy of video forgery detection. Specifically, the proposed model integrates several purely transformer-based variants that capture video, audio, and audio-visual salient cues to reach a consensus in prediction. For evaluation, we use the recently released benchmark multimodal audio-video FakeAVCeleb dataset. For a detailed analysis, we evaluate AVTENet, its variants, and several existing methods on multiple test sets of the FakeAVCeleb dataset. Experimental results show that the proposed model outperforms all existing methods and achieves state-of-the-art performance on Testset-I and Testset-II of the FakeAVCeleb dataset. We also compare AVTENet against humans in detecting video forgery. The results show that AVTENet significantly outperforms humans.

Paper number 259:
Title: PIP-Net: Pedestrian Intention Prediction in the Wild
Authors: Mohsen Azarmi, Mahdi Rezaei, He Wang
Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to an enhancement in the model's contextual perception. Depending on the traffic scenario and road environment, the model excels in predicting pedestrian crossing intentions up to 4 seconds in advance, which is a breakthrough in current research studies in pedestrian intention prediction. Finally, for the first time, we present the Urban-PIP dataset, a customised pedestrian intention prediction dataset, with multi-camera annotations in real-world automated driving scenarios.

Paper number 260:
Title: VGMShield: Mitigating Misuse of Video Generative Models
Authors: Yan Pang, Baicheng Chen, Yang Zhang, Tianhao Wang
Abstract: With the rapid advancement in video generation, people can conveniently use video generation models to create videos tailored to their specific desires. As a result, there are also growing concerns about the potential misuse of video generation for spreading illegal content and misinformation. In this work, we introduce VGMShield: a set of straightforward but effective mitigations through the lifecycle of fake video generation. We start from fake video detection, trying to understand whether there is uniqueness in generated videos and whether we can differentiate them from real videos; then, we investigate the fake video source tracing problem, which maps a fake video back to the model that generated it. Towards these, we propose to leverage pre-trained models that focus on spatial-temporal dynamics as the backbone to identify inconsistencies in videos. In detail, we analyze fake videos from the perspective of the generation process. Based on the observation of attention shifts, motion variations, and frequency fluctuations, we identify common patterns in the generated video. These patterns serve as the foundation for our experiments on fake video detection and source tracing. Through experiments on seven state-of-the-art open-source models, we demonstrate that current models still cannot reliably reproduce spatial-temporal relationships, and thus, we can accomplish detection and source tracing with over 90% accuracy. Furthermore, anticipating future generative model improvements, we propose a prevention method that adds invisible perturbations to the query images to make the generated videos look unreal. Together with detection and tracing, our multi-faceted set of solutions can effectively mitigate misuse of video generative models.

Paper number 261:
Title: Stabilization of infinite-dimensional systems under quantization and packet loss
Authors: Masashi Wakaiki
Abstract: We study the problem of stabilizing infinite-dimensional systems with input and output quantization. The closed-loop system we consider is subject to packet loss, whose average duration is assumed to be bounded. Given a bound on the initial state, we propose a design method for dynamic quantizers with zoom parameters. We show that the closed-loop state starting in a given region exponentially converges to zero if bounds on quantization errors and packet-loss intervals satisfy suitable conditions. Since the norms of the operators representing the system dynamics are used in the proposed quantizer design, we also present methods for approximately computing the operator norms.

Paper number 262:
Title: SEE-2-SOUND: Zero-Shot Spatial Environment-to-Spatial Sound
Authors: Rishit Dagli, Shivesh Prakash, Robert Wu, Houman Khosravani
Abstract: Generating combined visual and auditory sensory experiences is critical for the consumption of immersive content. Recent advances in neural generative models have enabled the creation of high-resolution content across multiple modalities such as images, text, speech, and videos. Despite these successes, there remains a significant gap in the generation of high-quality spatial audio that complements generated visual content. Furthermore, current audio generation models excel in either generating natural audio or speech or music but fall short in integrating spatial audio cues necessary for immersive experiences. In this work, we introduce SEE-2-SOUND, a zero-shot approach that decomposes the task into (1) identifying visual regions of interest; (2) locating these elements in 3D space; (3) generating mono-audio for each; and (4) integrating them into spatial audio. Using our framework, we demonstrate compelling results for generating spatial audio for high-quality videos, images, and dynamic images from the internet, as well as media generated by learned approaches.

Paper number 263:
Title: Deep Transformer Network for Monocular Pose Estimation of Shipborne Unmanned Aerial Vehicle
Authors: Maneesha Wickramasuriya, Taeyoung Lee, Murray Snyder
Abstract: This paper introduces a deep transformer network for estimating the relative 6D pose of a Unmanned Aerial Vehicle (UAV) with respect to a ship using monocular images. A synthetic dataset of ship images is created and annotated with 2D keypoints of multiple ship parts. A Transformer Neural Network model is trained to detect these keypoints and estimate the 6D pose of each part. The estimates are integrated using Bayesian fusion. The model is tested on synthetic data and in-situ flight experiments, demonstrating robustness and accuracy in various lighting conditions. The position estimation error is approximately 0.8\% and 1.0\% of the distance to the ship for the synthetic data and the flight experiments, respectively. The method has potential applications for ship-based autonomous UAV landing and navigation.

Paper number 264:
Title: ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in Robotic Surgical Skill Assessment
Authors: Julien Quarez, Marc Modat, Sebastien Ourselin, Jonathan Shapey, Alejandro Granados
Abstract: In surgical skill assessment, the Objective Structured Assessments of Technical Skills (OSATS) and Global Rating Scale (GRS) are well-established tools for evaluating surgeons during training. These metrics, along with performance feedback, help surgeons improve and reach practice standards. Recent research on the open-source JIGSAWS dataset, which includes both GRS and OSATS labels, has focused on regressing GRS scores from kinematic data, video, or their combination. However, we argue that regressing GRS alone is limiting, as it aggregates OSATS scores and overlooks clinically meaningful variations during a surgical trial. To address this, we developed a weakly-supervised recurrent transformer model that tracks a surgeon's performance throughout a session by mapping hidden states to six OSATS, derived from kinematic data. These OSATS scores are averaged to predict GRS, allowing us to compare our model's performance against state-of-the-art (SOTA) methods. We report Spearman's Correlation Coefficients (SCC) demonstrating that our model outperforms SOTA using kinematic data (SCC 0.83-0.88), and matches performance with video-based models. Our model also surpasses SOTA in most tasks for average OSATS predictions (SCC 0.46-0.70) and specific OSATS (SCC 0.56-0.95). The generation of pseudo-labels at the segment level translates quantitative predictions into qualitative feedback, vital for automated surgical skill assessment pipelines. A senior surgeon validated our model's outputs, agreeing with 77\% of the weakly-supervised predictions \(p=0.006\).

Paper number 265:
Title: A Framework for Synthetic Audio Conversations Generation using Large Language Models
Authors: Kaung Myat Kyaw, Jonathan Hoyin Chan
Abstract: In this paper, we introduce ConversaSynth, a framework designed to generate synthetic conversation audio using large language models (LLMs) with multiple persona settings. The framework first creates diverse and coherent text-based dialogues across various topics, which are then converted into audio using text-to-speech (TTS) systems. Our experiments demonstrate that ConversaSynth effectively generates highquality synthetic audio datasets, which can significantly enhance the training and evaluation of models for audio tagging, audio classification, and multi-speaker speech recognition. The results indicate that the synthetic datasets generated by ConversaSynth exhibit substantial diversity and realism, making them suitable for developing robust, adaptable audio-based AI systems.

Paper number 266:
Title: AADNet: An End-to-End Deep Learning Model for Auditory Attention Decoding
Authors: Nhan Duc Thanh Nguyen, Huy Phan, Simon Geirnaert, Kaare Mikkelsen, Preben Kidmose
Abstract: Auditory attention decoding (AAD) is the process of identifying the attended speech in a multi-talker environment using brain signals, typically recorded through electroencephalography (EEG). Over the past decade, AAD has undergone continuous development, driven by its promising application in neuro-steered hearing devices. Most AAD algorithms are relying on the increase in neural entrainment to the envelope of attended speech, as compared to unattended speech, typically using a two-step approach. First, the algorithm predicts representations of the attended speech signal envelopes; second, it identifies the attended speech by finding the highest correlation between the predictions and the representations of the actual speech signals. In this study, we proposed a novel end-to-end neural network architecture, named AADNet, which combines these two stages into a direct approach to address the AAD problem. We compare the proposed network against the traditional approaches, including linear stimulus reconstruction, canonical correlation analysis, and an alternative non-linear stimulus reconstruction using two different datasets. AADNet shows a significant performance improvement for both subject-specific and subject-independent models. Notably, the average subject-independent classification accuracies from 56.1 % to 82.7 % with analysis window lengths ranging from 1 to 40 seconds, respectively, show a significantly improved ability to generalize to data from unseen subjects. These results highlight the potential of deep learning models for advancing AAD, with promising implications for future hearing aids, assistive devices, and clinical assessments.

Paper number 267:
Title: Music102: An $D_{12}$-equivariant transformer for chord progression accompaniment
Authors: Weiliang Luo
Abstract: We present Music102, an advanced model aimed at enhancing chord progression accompaniment through a $D_{12}$-equivariant transformer. Inspired by group theory and symbolic music structures, Music102 leverages musical symmetry--such as transposition and reflection operations--integrating these properties into the transformer architecture. By encoding prior music knowledge, the model maintains equivariance across both melody and chord sequences. The POP909 dataset was employed to train and evaluate Music102, revealing significant improvements over the non-equivariant Music101 prototype Music101 in both weighted loss and exact accuracy metrics, despite using fewer parameters. This work showcases the adaptability of self-attention mechanisms and layer normalization to the discrete musical domain, addressing challenges in computational music analysis. With its stable and flexible neural framework, Music102 sets the stage for further exploration in equivariant music generation and computational composition tools, bridging mathematical theory with practical music performance.

Paper number 268:
Title: Learning Maximal Safe Sets Using Hypernetworks for MPC-based Local Trajectory Planning in Unknown Environments
Authors: Bojan DerajiÄ, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Wolfgang HÃ¶nig
Abstract: This paper presents a novel learning-based approach for online estimation of maximal safe sets for local trajectory planning in unknown static environments. The neural representation of a set is used as the terminal set constraint for a model predictive control (MPC) local planner, resulting in improved recursive feasibility and safety. To achieve real-time performance and desired generalization properties, we employ the idea of hypernetworks. We use the Hamilton-Jacobi (HJ) reachability analysis as the source of supervision during the training process, allowing us to consider general nonlinear dynamics and arbitrary constraints. The proposed method is extensively evaluated against relevant baselines in simulations for different environments and robot dynamics. The results show an increase in success rate of up to 52% compared to the best baseline while maintaining comparable execution speed. Additionally, we deploy our proposed method, NTC-MPC, on a physical robot and demonstrate its ability to safely avoid obstacles in scenarios where the baselines fail.

Paper number 269:
Title: Sensor-fusion based Prognostics for Deep-space Habitats Exhibiting Multiple Unlabeled Failure Modes
Authors: Benjamin Peters, Ayush Mohanty, Xiaolei Fang, Stephen K. Robinson, Nagi Gebraeel
Abstract: Deep-space habitats are complex systems that must operate autonomously over extended durations without ground-based maintenance. These systems are vulnerable to multiple, often unknown, failure modes that affect different subsystems and sensors in mode-specific ways. Developing accurate remaining useful life (RUL) prognostics is challenging, especially when failure labels are unavailable and sensor relevance varies by failure mode. In this paper, we propose an unsupervised prognostics framework that jointly identifies latent failure modes and selects informative sensors using only unlabeled training data. The methodology consists of two phases. In the offline phase, we model system failure times using a mixture of Gaussian regressions and apply a novel Expectation-Maximization algorithm to cluster degradation trajectories and select mode-specific sensors. In the online phase, we extract low-dimensional features from the selected sensors to diagnose the active failure mode and predict RUL using a weighted regression model. We demonstrate the effectiveness of our approach on a simulated dataset that reflects deep-space telemetry characteristics and on a real-world engine degradation dataset, showing improved accuracy and interpretability over existing methods.

Paper number 270:
Title: A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs
Authors: Ehsan Kabir, Austin R.J. Downey, Jason D. Bakos, David Andrews, Miaoqing Huang
Abstract: Transformer neural networks (TNN) excel in natural language processing (NLP), machine translation, and computer vision (CV) without relying on recurrent or convolutional layers. However, they have high computational and memory demands, particularly on resource-constrained devices like FPGAs. Moreover, transformer models vary in processing time across applications, requiring custom models with specific parameters. Designing custom accelerators for each model is complex and time-intensive. Some custom accelerators exist with no runtime adaptability, and they often rely on sparse matrices to reduce latency. However, hardware designs become more challenging due to the need for application-specific sparsity patterns. This paper introduces ADAPTOR, a runtime-adaptive accelerator for dense matrix computations in transformer encoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing elements and on-chip memory, enhancing parallelism and reducing latency. It incorporates efficient matrix tiling to distribute resources across FPGA platforms and is fully quantized for computational efficiency and portability. Evaluations on Xilinx Alveo U55C data center cards and embedded platforms like VC707 and ZCU102 show that our design is 1.2$\times$ and 2.87$\times$ more power efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively. Additionally, it achieves a speedup of 1.7 to 2.25$\times$ compared to some state-of-the-art FPGA-based accelerators.

Paper number 271:
Title: Event-based Photometric Bundle Adjustment
Authors: Shuang Guo, Guillermo Gallego
Abstract: We tackle the problem of bundle adjustment (i.e., simultaneous refinement of camera poses and scene map) for a purely rotating event camera. Starting from first principles, we formulate the problem as a classical non-linear least squares optimization. The photometric error is defined using the event generation model directly in the camera rotations and the semi-dense scene brightness that triggers the events. We leverage the sparsity of event data to design a tractable Levenberg-Marquardt solver that handles the very large number of variables involved. To the best of our knowledge, our method, which we call Event-based Photometric Bundle Adjustment (EPBA), is the first event-only photometric bundle adjustment method that works on the brightness map directly and exploits the space-time characteristics of event data, without having to convert events into image-like representations. Comprehensive experiments on both synthetic and real-world datasets demonstrate EPBA's effectiveness in decreasing the photometric error (by up to 90%), yielding results of unparalleled quality. The refined maps reveal details that were hidden using prior state-of-the-art rotation-only estimation methods. The experiments on modern high-resolution event cameras show the applicability of EPBA to panoramic imaging in various scenarios (without map initialization, at multiple resolutions, and in combination with other methods, such as IMU dead reckoning or previous event-based rotation estimation methods). We make the source code publicly available. this https URL

Paper number 272:
Title: AVE Speech: A Comprehensive Multi-Modal Dataset for Speech Recognition Integrating Audio, Visual, and Electromyographic Signals
Authors: Dongliang Zhou, Yakun Zhang, Jinghan Wu, Xingyu Zhang, Liang Xie, Erwei Yin
Abstract: The global aging population faces considerable challenges, particularly in communication, due to the prevalence of hearing and speech impairments. To address these, we introduce the AVE speech, a comprehensive multi-modal dataset for speech recognition tasks. The dataset includes a 100-sentence Mandarin corpus with audio signals, lip-region video recordings, and six-channel electromyography (EMG) data, collected from 100 participants. Each subject read the entire corpus ten times, with each sentence averaging approximately two seconds in duration, resulting in over 55 hours of multi-modal speech data per modality. Experiments demonstrate that combining these modalities significantly improves recognition performance, particularly in cross-subject and high-noise environments. To our knowledge, this is the first publicly available sentence-level dataset integrating these three modalities for large-scale Mandarin speech recognition. We expect this dataset to drive advancements in both acoustic and non-acoustic speech recognition research, enhancing cross-modal learning and human-machine interaction.

Paper number 273:
Title: UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation
Authors: Lei Zhao, Linfeng Feng, Dongxu Ge, Rujin Chen, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li
Abstract: With the rise of diffusion models, audio-video generation has been revolutionized. However, most existing methods rely on separate modules for each modality, with limited exploration of unified generative architectures. In addition, many are confined to a single task and small-scale datasets. To overcome these limitations, we introduce UniForm, a unified multi-task diffusion transformer that generates both audio and visual modalities in a shared latent space. By using a unified denoising network, UniForm captures the inherent correlations between sound and vision. Additionally, we propose task-specific noise schemes and task tokens, enabling the model to support multiple tasks with a single set of parameters, including video-to-audio, audio-to-video and text-to-audio-video generation. Furthermore, by leveraging large language models and a large-scale text-audio-video combined dataset, UniForm achieves greater generative diversity than prior approaches. Experiments show that UniForm achieves performance close to the state-of-the-art single-task models across three generation tasks, with generated content that is not only highly aligned with real-world data distributions but also enables more diverse and fine-grained generation.

Paper number 274:
Title: A Concise Lyapunov Analysis of Nesterov's Accelerated Gradient Method
Authors: Jun Liu
Abstract: Convergence analysis of Nesterov's accelerated gradient method has attracted significant attention over the past decades. While extensive work has explored its theoretical properties and elucidated the intuition behind its acceleration, a simple and direct proof of its convergence rates is still lacking. We provide a concise Lyapunov analysis of the convergence rates of Nesterov's accelerated gradient method for both general convex and strongly convex functions.

Paper number 275:
Title: Occlusion-Aware Consistent Model Predictive Control for Robot Navigation in Occluded Obstacle-Dense Environments
Authors: Minzhe Zheng, Lei Zheng, Jun Ma
Abstract: Ensuring safety and motion consistency for robot navigation in occluded, obstacle-dense environments is a critical challenge. In this context, this study presents an occlusion-aware Consistent Model Predictive Control (CMPC) strategy. To account for the occluded obstacles, it incorporates adjustable risk regions that represent their potential future locations. Subsequently, dynamic risk boundary constraints are developed online to ensure safety. The CMPC then constructs multiple locally optimal trajectory branches (each tailored to different risk regions) to balance between exploitation and exploration. A shared consensus trunk is generated to ensure smooth transitions between branches without significant velocity fluctuations, further preserving motion consistency. To facilitate high computational efficiency and ensure coordination across local trajectories, we use the alternating direction method of multipliers (ADMM) to decompose the CMPC into manageable sub-problems for parallel solving. The proposed strategy is validated through simulation and real-world experiments on an Ackermann-steering robot platform. The results demonstrate the effectiveness of the proposed CMPC strategy through comparisons with baseline approaches in occluded, obstacle-dense environments.

Paper number 276:
Title: Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds
Authors: Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi
Abstract: The adoption of Millimeter-Wave (mmWave) radar devices for human sensing, particularly gait recognition, has recently gathered significant attention due to their efficiency, resilience to environmental conditions, and privacy-preserving nature. In this work, we tackle the challenging problem of Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike most existing research, which assumes a closed-set scenario, our work considers the more realistic open-set case, where unknown subjects might be present at inference time, and should be correctly recognized by the system. Point clouds are well-suited for edge computing applications with resource constraints, but are more significantly affected by noise and random fluctuations than other representations, like the more common micro-Doppler signature. This is the first work addressing open-set gait recognition with sparse point cloud data. To do so, we propose a novel neural network architecture that combines supervised classification with unsupervised reconstruction of the point clouds, creating a robust, rich, and highly regularized latent space of gait features. To detect unknown subjects at inference time, we introduce a probabilistic novelty detection algorithm that leverages the structured latent space and offers a tunable trade-off between inference speed and prediction accuracy. Along with this paper, we release mmGait10, an original human gait dataset featuring over five hours of measurements from ten subjects, under varied walking modalities. Extensive experimental results show that our solution attains F1-Score improvements by 24% over state-of-the-art methods adapted for point clouds, on average, and across multiple openness levels.

Paper number 277:
Title: Mirror Online Conformal Prediction with Intermittent Feedback
Authors: Bowen Wang, Matteo Zecchin, Osvaldo Simeone
Abstract: Online conformal prediction enables the runtime calibration of a pre-trained artificial intelligence model using feedback on its performance. Calibration is achieved through set predictions that are updated via online rules so as to ensure long-term coverage guarantees. While recent research has demonstrated the benefits of incorporating prior knowledge into the calibration process, this has come at the cost of replacing coverage guarantees with less tangible regret guarantees based on the quantile loss. This work introduces intermittent mirror online conformal prediction (IM-OCP), a novel runtime calibration framework that integrates prior knowledge, operates under potentially intermittent feedback, and features minimal memory complexity. IM-OCP guarantees long-term coverage and sub-linear regret, both of which hold deterministically for any given data sequence and in expectation with respect to the intermittent feedback.

Paper number 278:
Title: Dark Noise Diffusion: Noise Synthesis for Low-Light Image Denoising
Authors: Liying Lu, RaphaÃ«l Achddou, Sabine SÃ¼sstrunk
Abstract: Low-light photography produces images with low signal-to-noise ratios due to limited photons. In such conditions, common approximations like the Gaussian noise model fall short, and many denoising techniques fail to remove noise effectively. Although deep-learning methods perform well, they require large datasets of paired images that are impractical to acquire. As a remedy, synthesizing realistic low-light noise has gained significant attention. In this paper, we investigate the ability of diffusion models to capture the complex distribution of low-light noise. We show that a naive application of conventional diffusion models is inadequate for this task and propose three key adaptations that enable high-precision noise generation: a two-branch architecture to better model signal-dependent and signal-independent noise, the incorporation of positional information to capture fixed-pattern noise, and a tailored diffusion noise schedule. Consequently, our model enables the generation of large datasets for training low-light denoising networks, leading to state-of-the-art performance. Through comprehensive analysis, including statistical evaluation and noise decomposition, we provide deeper insights into the characteristics of the generated data.

Paper number 279:
Title: D4orm: Multi-Robot Trajectories with Dynamics-aware Diffusion Denoised Deformations
Authors: Yuhao Zhang, Keisuke Okumura, Heedo Woo, Ajay Shankar, Amanda Prorok
Abstract: This work presents an optimization method for generating kinodynamically feasible and collision-free multi-robot trajectories that exploits an incremental denoising scheme in diffusion models. Our key insight is that high-quality trajectories can be discovered merely by denoising noisy trajectories sampled from a distribution. This approach has no learning component, relying instead on only two ingredients: a dynamical model of the robots to obtain feasible trajectories via rollout, and a fitness function to guide denoising with Monte Carlo gradient approximation. The proposed framework iteratively optimizes a deformation for the previous trajectory with the current denoising process, allows anytime refinement as time permits, supports different dynamics, and benefits from GPU acceleration. Our evaluations for differential-drive and holonomic teams with up to 16 robots in 2D and 3D worlds show its ability to discover high-quality solutions faster than other black-box optimization methods such as MPPI. In a 2D holonomic case with 16 robots, it is almost twice as fast. As evidence for feasibility, we demonstrate zero-shot deployment of the planned trajectories on eight multirotors.

Paper number 280:
Title: Serenade: A Singing Style Conversion Framework Based On Audio Infilling
Authors: Lester Phillip Violeta, Wen-Chin Huang, Tomoki Toda
Abstract: We propose Serenade, a novel framework for the singing style conversion (SSC) task. Although singer identity conversion has made great strides in the previous years, converting the singing style of a singer has been an unexplored research area. We find three main challenges in SSC: modeling the target style, disentangling source style, and retaining the source melody. To model the target singing style, we use an audio infilling task by predicting a masked segment of the target mel-spectrogram with a flow-matching model using the complement of the masked target mel-spectrogram along with disentangled acoustic features. On the other hand, to disentangle the source singing style, we use a cyclic training approach, where we use synthetic converted samples as source inputs and reconstruct the original source mel-spectrogram as a target. Finally, to retain the source melody better, we investigate a post-processing module using a source-filter-based vocoder and resynthesize the converted waveforms using the original F0 patterns. Our results showed that the Serenade framework can handle generalized SSC tasks with the best overall similarity score, especially in modeling breathy and mixed singing styles. We also found that resynthesizing with the original F0 patterns alleviated out-of-tune singing and improved naturalness, but found a slight tradeoff in similarity due to not changing the F0 patterns into the target style.

Paper number 281:
Title: Decision Feedback In-Context Learning for Wireless Symbol Detection
Authors: Li Fan, Wei Shen, Jing Yang, Cong Shen
Abstract: Pre-trained Transformers, through in-context learning (ICL), have demonstrated exceptional capabilities to adapt to new tasks using example prompts without model update. Transformer-based wireless receivers, where prompts consist of the pilot data in the form of transmitted and received signal pairs, have shown high detection accuracy when pilot data are abundant. However, pilot information is often costly and limited in practice. In this work, we propose DEcision Feedback IN-ContExt Detection (DEFINED) as a new wireless receiver design, which bypasses channel estimation and directly performs symbol detection using the (sometimes extremely) limited pilot data. The key innovation in DEFINED is the proposed decision feedback mechanism in ICL, where we sequentially incorporate the detected symbols into the prompts as pseudo-labels to improve the detection for subsequent symbols. We further establish an error lower bound and provide theoretical insights into the model's generalization under channel distribution mismatch. Extensive experiments across a broad range of wireless settings demonstrate that a small Transformer trained with DEFINED achieves significant performance improvements over conventional methods, in some cases only needing a single pilot pair to achieve similar performance to the latter with more than 4 pilot pairs.

Paper number 282:
Title: Low-Complexity Detection of Permutational Index Modulation for Noncoherent Communications
Authors: Marc VilÃ -Insa, Aniol MartÃ­, Meritxell Lamarca, Jaume Riba
Abstract: This work presents a massive SIMO scheme for wireless communications with one-shot noncoherent detection. It is based on permutational index modulation over OFDM. Its core principle is to convey information on the ordering in which a fixed collection of values is mapped onto a set of OFDM subcarriers. A spherical code is obtained which provides improved robustness against channel impairments. A simple detector based on the sorting of quadratic metrics of data is proposed. By exploiting statistical channel state information and hardening, it reaches near-ML error performance with a low-complexity implementation.

Paper number 283:
Title: Satellite-Assisted Low-Altitude Economy Networking: Concepts, Applications, and Opportunities
Authors: Shizhao He, Jiacheng Wang, Ying-Chang Liang, Geng Sun, Dusit Niyato
Abstract: The low-altitude economy (LAE) is a new economic paradigm that leverages low-altitude vehicles (LAVs) to perform diverse missions across diverse areas. To support the operations of LAE, it is essential to establish LAE networks that enable LAV management and this http URL studies mainly reuse terrestrial networks to construct LAE networks. However, the limited coverage of terrestrial networks poses challenges for serving LAVs in remote areas. Besides, efficient LAV operations also require support such as localization and navigation, which terrestrial networks designed for communications cannot fully provide. Due to ubiquitous coverage and diverse functions, satellites are a promising technology to support LAVs. Therefore, this article investigates satellite-assisted LAE networking. First, we introduce an overview of LAE and satellites, discussing their features, applications, and architectures. Next, we investigate opportunities for satellites to assist LAE from aspects of communication, control, and computation. As all assistance depends on reliable satellite-LAV communications, we propose a satellite-assisted LAE framework to tackle issues caused by the severe path loss and high dynamics in satellite-assisted LAE this http URL case study demonstrates that the distributed MIMO architecture efficiently reduces the required transmission power and extends service duration, while the two-timescale optimization scheme balances the performance and control signaling overheads. Specifically, the proposed framework comprises distributed satellite MIMO, distributed LAV MIMO, and a two-timescale optimization scheme.

Paper number 284:
Title: Joint Source-Channel Noise Adding with Adaptive Denoising for Diffusion-Based Semantic Communications
Authors: Chengyang Liang, Dong Li
Abstract: Semantic communication (SemCom) aims to convey the intended meaning of messages rather than merely transmitting bits, thereby offering greater efficiency and robustness, particularly in resource-constrained or noisy environments. In this paper, we propose a novel framework which is referred to as joint source-channel noise adding with adaptive denoising (JSCNA-AD) for SemCom based on a diffusion model (DM). Unlike conventional encoder-decoder designs, our approach intentionally incorporates the channel noise during transmission, effectively transforming the harmful channel noise into a constructive component of the diffusion-based semantic reconstruction process. Besides, we introduce an attention-based adaptive denoising mechanism, in which transmitted images are divided into multiple regions, and the number of denoising steps is dynamically allocated based on the semantic importance of each region. This design effectively balances the reception quality and the inference latency by prioritizing the critical semantic information. Extensive experiments demonstrate that our method significantly outperforms existing SemCom schemes under various noise conditions, underscoring the potential of diffusion-based models in next-generation communication systems.

Paper number 285:
Title: ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs
Authors: Pooneh Mousavi, Yingzhi Wang, Mirco Ravanelli, Cem Subakan
Abstract: Large Language Models (LLMs) are increasingly used in Spoken Language Understanding (SLU), where effective multimodal learning depends on the alignment between audio and text. Despite various fusion methods, no standard metric exists to assess this alignment. This work introduces ALAS (Automatic Latent Alignment Score), a metric that evaluates alignment by measuring correlations between audio and text representations across transformer layers. Experiments on Spoken Question Answering and Emotion Recognition show that ALAS captures meaningful patterns across tasks and layers.

Paper number 286:
Title: Physical Reduced Stochastic Equations for Continuously Monitored Non-Markovian Quantum Systems with a Markovian Embedding
Authors: Hendra I. Nurdin
Abstract: An effective approach to modeling non-Markovian quantum systems is to embed a principal (quantum) system of interest into a larger quantum system. A widely employed embedding is one that uses another quantum system, referred to as the auxiliary system, which is coupled to the principal system, and both the principal and auxiliary can be coupled to quantum white noise processes. The principal and auxiliary together form a quantum Markov system and the quantum white noises act as a bath (environment) for this system. Recently it was shown that the conditional evolution of the principal system in this embedding under continuous monitoring by a travelling quantum probe can be expressed as a system of coupled stochastic differential equations (SDEs) that involve only operators of the principal system. The reduced conditional state of the principal only (conditioned on the measurement outcomes) is determined by the ``diagonal" blocks of this coupled systems of SDEs. It is shown here that the ``off-diagonal" blocks can be exactly eliminated up to their initial conditions, leaving a reduced closed system of SDEs for the diagonal blocks only. Under additional conditions the off-diagonal initial conditions can be made to vanish. This new closed system of equations, which includes an integration term involving a two-time stochastic kernel, represents the non-Markovian stochastic dynamics of the principal system under continuous-measurement. The system of equations determine the reduced conditional state of the principal only and may be viewed as a stochastic Nakajima-Zwanzig type of equation for continuously monitored non-Markovian quantum systems.

Paper number 287:
Title: SwitchCodec: A High-Fidelity Nerual Audio Codec With Sparse Quantization
Authors: Jin Wang, Wenbin Jiang, Xiangbo Wang
Abstract: Neural audio compression has emerged as a promising technology for efficiently representing speech, music, and general audio. However, existing methods suffer from significant performance degradation at limited bitrates, where the available embedding space is sharply constrained. To address this, we propose a universal high-fidelity neural audio compression algorithm featuring Residual Experts Vector Quantization (REVQ), which substantially expands the embedding space with minimal impact on bandwidth. A gentle load-balancing strategy is introduced to ensure the full utilization of this expanded space. Furthermore, we develop a novel multi-tiered discriminator that periodically stratifies STFT spectra, guiding the generator to focus on critical spectral regions. To support multiple bitrates without quality loss at the lower end, we adopt an efficient post-training strategy. Our proposed model achieves impressive performance, with PESQ and ViSQOL scores of 2.87 and 4.27, respectively, at 2.67 kbps bandwidth. The approach effectively reduces spectral blur, decreasing the distance to the original mel-spectrogram by 13%. Notably, our post-training strategy achieves performance comparable to dedicated fixed-bitrate models while reducing the required training time by half. Extensive ablation studies confirm the superiority of our method over baselines.

Paper number 288:
Title: UltrasonicSpheres: Localized, Multi-Channel Sound Spheres Using Off-the-Shelf Speakers and Earables
Authors: Michael KÃ¼ttner, Valeria Zitz, Kathrin Gerling, Michael Beigl, Tobias RÃ¶ddiger
Abstract: We present a demo of UltrasonicSpheres, a novel system for location-specific audio delivery using wearable earphones that decode ultrasonic signals into audible sound. Unlike conventional beamforming setups, UltrasonicSpheres relies on single ultrasonic speakers to broadcast localized audio with multiple channels, each encoded on a distinct ultrasonic carrier frequency. Users wearing our acoustically transparent earphones can demodulate their selected stream, such as exhibit narrations in a chosen language, while remaining fully aware of ambient environmental sounds. The experience preserves spatial audio perception, giving the impression that the sound originates directly from the physical location of the source. This enables personalized, localized audio without requiring pairing, tracking, or additional infrastructure. Importantly, visitors not equipped with the earphones are unaffected, as the ultrasonic signals are inaudible to the human ear. Our demo invites participants to explore multiple co-located audio zones and experience how UltrasonicSpheres supports unobtrusive delivery of personalized sound in public spaces.

Paper number 289:
Title: CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model
Authors: Yuxuan Chen, Haipeng Xie
Abstract: The denoising diffusion probabilistic model has become a mainstream generative model, achieving significant success in various computer vision tasks. Recently, there has been initial exploration of applying diffusion models to time series tasks. However, existing studies still face challenges in multi-scale feature alignment and generative capabilities across different entities and long-time scales. In this paper, we propose CHIME, a conditional hallucination and integrated multi-scale enhancement framework for time series diffusion models. By employing multi-scale decomposition and integration, CHIME captures the decomposed features of time series, achieving in-domain distribution alignment between generated and original samples. In addition, we introduce a feature hallucination module in the conditional denoising process, enabling the temporal features transfer across long-time scales. Experimental results on publicly available real-world datasets demonstrate that CHIME achieves state-of-the-art performance and exhibits excellent generative generalization capabilities in few-shot scenarios.

Paper number 290:
Title: An introduction to pitch strength in contemporary popular music analysis and production
Authors: Emmanuel Deruty
Abstract: Music information retrieval distinguishes between low- and high-level descriptions of music. Current generative AI models rely on text descriptions that are higher level than the controls familiar to studio musicians. Pitch strength, a low-level perceptual parameter of contemporary popular music, may be one feature that could make such AI models more suited to music production. Signal and perceptual analyses suggest that pitch strength (1) varies significantly across and inside songs; (2) contributes to both small- and large-scale structure; (3) contributes to the handling of polyphonic dissonance; and (4) may be a feature of upper harmonics made audible in a perspective of perceptual richness.

Paper number 291:
Title: NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025
Authors: Yizhou Peng, Bin Wang, Yi-Wen Chao, Ziyang Ma, Haoyang Zhang, Hexin Liu, Xie Chen, Eng Siong Chng
Abstract: This report details the NTU Speechlab system developed for the Interspeech 2025 Multilingual Conversational Speech and Language Model (MLC-SLM) Challenge (Task I), where we achieved 5th place. We present comprehensive analyses of our multilingual automatic speech recognition system, highlighting key advancements in model architecture, data selection, and training strategies. In particular, language-specific prompts and model averaging techniques were instrumental in boosting system performance across diverse languages. Compared to the initial baseline system, our final model reduced the average Mix Error Rate from 20.2% to 10.6%, representing an absolute improvement of 9.6% (a relative improvement of 48%) on the evaluation set. Our results demonstrate the effectiveness of our approach and offer practical insights for future Speech Large Language Models.

Paper number 292:
Title: Bi-directional Context-Enhanced Speech Large Language Models for Multilingual Conversational ASR
Authors: Yizhou Peng, Hexin Liu, Eng Siong Chng
Abstract: This paper introduces the integration of language-specific bi-directional context into a speech large language model (SLLM) to improve multilingual continuous conversational automatic speech recognition (ASR). We propose a character-level contextual masking strategy during training, which randomly removes portions of the context to enhance robustness and better emulate the flawed transcriptions that may occur during inference. For decoding, a two-stage pipeline is utilized: initial isolated segment decoding followed by context-aware re-decoding using neighboring hypotheses. Evaluated on the 1500-hour Multilingual Conversational Speech and Language Model (MLC-SLM) corpus covering eleven languages, our method achieves an 18% relative improvement compared to a strong baseline, outperforming even the model trained on 6000 hours of data for the MLC-SLM competition. These results underscore the significant benefit of incorporating contextual information in multilingual continuous conversational ASR.

Paper number 293:
Title: Qwen vs. Gemma Integration with Whisper: A Comparative Study in Multilingual SpeechLLM Systems
Authors: Tuan Nguyen, Long-Vu Hoang, Huy-Dat Tran
Abstract: This paper presents our system for the MLC-SLM Challenge 2025, focusing on multilingual speech recognition and language modeling with large language models (LLMs). Our approach combines a fine-tuned Whisper-large-v3 encoder with efficient projector architectures and various decoder configurations. We employ a three-stage training methodology that progressively optimizes the encoder, projector, and LLM components. Our system achieves competitive performance with a private test average WER/CER result of 16.63% using the Gemma3-12B and 18.6% using the Qwen2.5-7B as decoder-only language model.

Paper number 294:
Title: RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models
Authors: Jacky Kwok, Christopher Agia, Rohan Sinha, Matt Foutter, Shulu Li, Ion Stoica, Azalia Mirhoseini, Marco Pavone
Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in visuomotor control, yet ensuring their robustness in unstructured real-world environments remains a persistent challenge. In this paper, we investigate test-time scaling through the lens of sampling and verification as means to enhance the robustness and generalization of VLAs. We first demonstrate that the relationship between action error and the number of generated samples follows an exponentiated power law across a range of VLAs, indicating the existence of inference-time scaling laws. Building on these insights, we introduce RoboMonkey, a test-time scaling framework for VLAs. At deployment, RoboMonkey samples a small set of actions from a VLA, applies Gaussian perturbation and majority voting to construct an action proposal distribution, and then uses a Vision Language Model (VLM)-based verifier to select the optimal action. We propose a synthetic data generation pipeline for training such VLM-based action verifiers, and demonstrate that scaling the synthetic dataset consistently improves verification and downstream accuracy. Through extensive simulated and hardware experiments, we show that pairing existing VLAs with RoboMonkey yields significant performance gains, achieving a 25% absolute improvement on out-of-distribution tasks and 9% on in-distribution tasks. Additionally, when adapting to new robot setups, we show that fine-tuning both VLAs and action verifiers yields a 7% performance increase compared to fine-tuning VLAs alone.

Paper number 295:
Title: Bayesian Multiobject Tracking With Neural-Enhanced Motion and Measurement Models
Authors: Shaoxiu Wei, Mingchao Liang, Florian Meyer
Abstract: Multiobject tracking (MOT) is an important task in applications including autonomous driving, ocean sciences, and aerospace surveillance. Traditional MOT methods are model-based and combine sequential Bayesian estimation with data association and an object birth model. More recent methods are fully data-driven and rely on the training of neural networks. Both approaches offer distinct advantages in specific settings. In particular, model-based methods are generally applicable across a wide range of scenarios, whereas data-driven MOT achieves superior performance in scenarios where abundant labeled data for training is available. A natural thought is whether a general framework can integrate the two approaches. This paper introduces a hybrid method that utilizes neural networks to enhance specific aspects of the statistical model in Bayesian MOT that have been identified as overly simplistic. By doing so, the performance of the prediction and update steps of Bayesian MOT is improved. To ensure tractable computation, our framework uses belief propagation to avoid high-dimensional operations combined with sequential Monte Carlo methods to perform low-dimensional operations efficiently. The resulting method combines the flexibility and robustness of model-based approaches with the capability to learn complex information from data of neural networks. We evaluate the performance of the proposed method based on the nuScenes autonomous driving dataset and demonstrate that it has state-of-the-art performance

Paper number 296:
Title: Towards Universal Shared Control in Teleoperation Without Haptic Feedback
Authors: Max Grobbel, Tristan Schneider, SÃ¶ren Hohmann
Abstract: Teleoperation with non-haptic VR controllers deprives human operators of critical motion feedback. We address this by embedding a multi-objective optimization problem that converts user input into collision-free UR5e joint trajectories while actively suppressing liquid slosh in a glass. The controller maintains 13 ms average planning latency, confirming real-time performance and motivating the augmentation of this teleoperation approach to further objectives.

Paper number 297:
Title: Approximate Solution Methods for the Average Reward Criterion in Optimal Tracking Control of Linear Systems
Authors: Duc Cuong Nguyen
Abstract: This paper studies optimal control under the average-reward/cost criterion for deterministic linear systems. We derive the value function and optimal policy, and propose an approximate solution using Model Predictive Control to enable practical implementation.

Paper number 298:
Title: Online Convex Optimization for Coordinated Long-Term and Short-Term Isolated Microgrid Dispatch
Authors: Ning Qi, Yousuf Baker, Bolun Xu
Abstract: This paper proposes a novel non-anticipatory long-short-term coordinated dispatch framework for isolated microgrid with hybrid short-long-duration energy storages (LDES). We introduce a convex hull approximation model for nonconvex LDES electrochemical dynamics, facilitating computational tractability and accuracy. To address temporal coupling in SoC dynamics and long-term contracts, we generate hindsight-optimal state-of-charge (SoC) trajectories of LDES and netloads for offline training. In the online stage, we employ kernel regression to dynamically update the SoC reference and propose an adaptive online convex optimization (OCO) algorithm with SoC reference tracking and expert tracking to mitigate myopia and enable adaptive step-size optimization. We rigorously prove that both long-term and short-term policies achieve sublinear regret bounds over time, which improves with more regression scenarios, stronger tracking penalties, and finer convex approximations. Simulation results show that the proposed method outperforms state-of-the-art methods, reducing costs by 73.4%, eliminating load loss via reference tracking, and achieving an additional 2.4% cost saving via the OCO algorithm. These benefits scale up with longer LDES durations, and the method demonstrates resilience to poor forecasts and unexpected system faults.
    