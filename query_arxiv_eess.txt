
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Computing Longitudinal Dynamic Derivatives of a VTOL Aircraft Using CFD Simulations and Forced-Oscillation Model
Authors: Ali Khosravani Nezhad, AmirReza Kosari, Rasoul Askari
Abstract: This study presents a comprehensive evaluation of dynamic aerodynamic derivatives during aircraft transition phases using advanced CFD simulations and forced oscillation testing. Two case studies are examined: a three dimensional fighter aircraft (Standard Dynamic Model, SDM) and a UT24 eVTOL model. The transition phase from vertical hover to forward cruise is analyzed with harmonic oscillation techniques to capture unsteady aerodynamic forces and moments. Grid sensitivity studies and multi zone meshing strategies ensure simulation accuracy, while ANSYS Fluent finite volume solver and coupled pressure velocity algorithms provide high fidelity results. Dynamic derivatives are derived from variations in angle of attack, flight path, and rotational movements, with experimental and numerical data validating the approach. The findings offer valuable insights for robust control design and stability analysis, supporting future advancements in urban air mobility and aerospace engineering. Overall, this approach demonstrates substantial promise for optimizing aircraft performance during critical transition phases. These results pave the way for future innovations

Paper number 2:
Title: Reinforcement learning in pursuit-evasion differential game: safety, stability and robustness
Authors: Xinyang Wang, Hongwei Zhang, Jun Xu, Shimin Wang, Martin Guay
Abstract: Safety and stability are two critical concerns in pursuit-evasion (PE) problems in an obstacle-rich environment. Most existing works combine control barrier functions (CBFs) and reinforcement learning (RL) to provide an efficient and safe solution. However, they do not consider the presence of disturbances, such as wind gust and actuator fault, which may exist in many practical applications. This paper integrates CBFs and a sliding mode control (SMC) term into RL to simultaneously address safety, stability, and robustness to disturbances. However, this integration is significantly challenging due to the strong coupling between the CBF and SMC terms. Inspired by Stackelberg game, we handle the coupling issue by proposing a hierarchical design scheme where SMC and safe control terms interact with each other in a leader-follower manner. Specifically, the CBF controller, acting as the leader, enforces safety independently of the SMC design; while the SMC term, as the follower, is designed based on the CBF controller. We then formulate the PE problem as a zero-sum game and propose a safe robust RL framework to learn the min-max strategy online. A sufficient condition is provided under which the proposed algorithm remains effective even when constraints are conflicting. Simulation results demonstrate the effectiveness of the proposed safe robust RL framework.

Paper number 3:
Title: A safety governor for learning explicit MPC controllers from data
Authors: Anjie Mao, Zheming Wang, Hao Gu, Bo Chen, Li Yu
Abstract: We tackle neural networks (NNs) to approximate model predictive control (MPC) laws. We propose a novel learning-based explicit MPC structure, which is reformulated into a dual-mode scheme over maximal constrained feasible set. The scheme ensuring the learning-based explicit MPC reduces to linear feedback control while entering the neighborhood of origin. We construct a safety governor to ensure that learning-based explicit MPC satisfies all the state and input constraints. Compare to the existing approach, our approach is computationally easier to implement even in high-dimensional system. The proof of recursive feasibility for the safety governor is given. Our approach is demonstrated on numerical examples.

Paper number 4:
Title: Whale Optimization Algorithms based fractional order fuzzy PID controller for Depth of Anesthesia
Authors: Amin Behboudifar, Chen Jing
Abstract: One of the most important surgical factors is Depth of Anesthesia (DOA) control in patients. The main problem is to overcome the uncertainty and nonlinearity of the system, due to different physiological parameters of the patient's body and maintain DOA of patients in desired range during surgery. This study demonstrates a fractional order fuzzy PID controller (FOFPID) and fractional order PID controller (FOPID) to the problem. The Whale Optimization Algorithms (WOA) is used to optimized the parameters of proposed controllers. The orders of derivative and integral fractional controller is achieved by WOA. The results indicate that FOFPID has a better performance than FOPID. To check the performance of the controllers in presence of uncertainty, physiological logical model of 8 patients has been investigated. The modeling is based on Pharmacodynamic and Pharmacokinetic model. The results show the performance of the proposed method.

Paper number 5:
Title: Comparing Behavioural Cloning and Reinforcement Learning for Spacecraft Guidance and Control Networks
Authors: Harry Holt, Sebastien Origer, Dario Izzo
Abstract: Guidance & control networks (G&CNETs) provide a promising alternative to on-board guidance and control (G&C) architectures for spacecraft, offering a differentiable, end-to-end representation of the guidance and control architecture. When training G&CNETs, two predominant paradigms emerge: behavioural cloning (BC), which mimics optimal trajectories, and reinforcement learning (RL), which learns optimal behaviour through trials and errors. Although both approaches have been adopted in G&CNET related literature, direct comparisons are notably absent. To address this, we conduct a systematic evaluation of BC and RL specifically for training G&CNETs on continuous-thrust spacecraft trajectory optimisation tasks. We introduce a novel RL training framework tailored to G&CNETs, incorporating decoupled action and control frequencies alongside reward redistribution strategies to stabilise training and to provide a fair comparison. Our results show that BC-trained G&CNETs excel at closely replicating expert policy behaviour, and thus the optimal control structure of a deterministic environment, but can be negatively constrained by the quality and coverage of the training dataset. In contrast RL-trained G&CNETs, beyond demonstrating a superior adaptability to stochastic conditions, can also discover solutions that improve upon suboptimal expert demonstrations, sometimes revealing globally optimal strategies that eluded the generation of training samples.

Paper number 6:
Title: Biogeography-Based Optimization of Fuzzy Controllers for Improved Quarter Car Suspension Performance
Authors: Lida Shahbandari, Mohammad Mansouri
Abstract: This study proposes optimized Type-I and Type-II fuzzy controllers for automotive suspension systems to enhance ride comfort and stability under road disturbances (step/sine inputs), addressing the lack of systematic performance comparisons in existing literature. We integrate Biogeography-Based Optimization (BBO), Particle Swarm Optimization (PSO), and Genetic Algorithms (GA) to tune controller parameters for a quarter car model, with emphasis on BBO's underexplored efficacy. MATLAB Simulink simulations demonstrate that BBO-optimized Type-II fuzzy control reduces body displacement by 22% and acceleration by 18% versus baseline methods under step disturbances, while maintaining computational efficiency. The framework provides practical, high-performance solutions for modern vehicles, particularly electric and autonomous platforms where vibration attenuation and energy efficiency are critical.

Paper number 7:
Title: Simulation of Emergency Evacuation in Large Scale Metropolitan Railway Systems for Urban Resilience
Authors: Hangli Ge, Xiaojie Yang, Zipei Fan, Francesco Flammini, Noboru Koshizuka
Abstract: This paper presents a simulation for traffic evacuation during railway disruptions to enhance urban resilience. The research focuses on large-scale railway networks and provides flexible simulation settings to accommodate multiple node or line failures. The evacuation optimization model is mathematically formulated using matrix computation and nonlinear programming. The simulation integrates railway lines operated by various companies, along with external geographical features of the network. Furthermore, to address computational complexity in large-scale graph networks, a subgraph partitioning solution is employed for computation acceleration. The model is evaluated using the extensive railway network of Greater Tokyo. Data collection included both railway network structure and real-world GPS footfall data to estimate the number of station-area visitors for simulation input and evaluation purposes. Several evacuation scenarios were simulated for major stations including Tokyo, Shinjuku, Shibuya and so on. The results demonstrate that both evacuation passenger flow (EPF) and average travel time (ATT) during emergencies were successfully optimized, while remaining within the capacity constraints of neighboring stations and the targeted disruption recovery times.

Paper number 8:
Title: Multipath Interference Suppression in Indirect Time-of-Flight Imaging via a Novel Compressed Sensing Framework
Authors: Yansong Du, Yutong Deng, Yuting Zhou, Feiyu Jiao, Bangyao Wang, Zhancong Xu, Zhaoxiang Jiang, Xun Guan
Abstract: We propose a novel compressed sensing method to improve the depth reconstruction accuracy and multi-target separation capability of indirect Time-of-Flight (iToF) systems. Unlike traditional approaches that rely on hardware modifications, complex modulation, or cumbersome data-driven reconstruction, our method operates with a single modulation frequency and constructs the sensing matrix using multiple phase shifts and narrow-duty-cycle continuous waves. During matrix construction, we further account for pixel-wise range variation caused by lens distortion, making the sensing matrix better aligned with actual modulation response characteristics. To enhance sparse recovery, we apply K-Means clustering to the distance response dictionary and constrain atom selection within each cluster during the OMP process, which effectively reduces the search space and improves solution stability. Experimental results demonstrate that the proposed method outperforms traditional approaches in both reconstruction accuracy and robustness, without requiring any additional hardware changes.

Paper number 9:
Title: Controller Design of an Airship
Authors: Manuel Schimmer
Abstract: Airships offer unique operational advantages due to their ability to generate lift via buoyancy, enabling low-speed flight and stationary hovering. These capabilities make them ideal for missions requiring endurance and precision positioning. However, they also present significant control challenges: their large, lightweight structures are highly sensitive to environmental disturbances, and conventional aerodynamic control surfaces lose effectiveness during low-speed or hover flight. The objective of this thesis is to develop a robust control strategy tailored to a vectored-thrust airship equipped with tiltable propellers. The proposed approach is based on an Extended Incremental Nonlinear Dynamic Inversion inner loop in combination with a high level outer loop, controlling the attitude and velocity of the airship. The proposed method is able to effectively control the airship over the whole envelope, including hover and high speed flight. For this, effective use of available actuators is key. This includes especially the tilt rotors, for which a control allocation method is presented. The controller's performance is validated through a series of simulation-based test scenarios, including aggressive maneuvering, gust rejection, atmospheric turbulence, and significant parameter mismatches. The controller is compared against an alternative controller developed at the institute, offering insight into the trade-offs between direct inversion and incremental control approaches. Results demonstrate that the proposed E-INDI controller achieves very good tracking performance and high high robustness against parameter uncertainties.

Paper number 10:
Title: SLENet: A Novel Multiscale CNN-Based Network for Detecting the Rats Estrous Cycle
Authors: Qinyang Wang, Hoileong Lee, Xiaodi Pu, Yuanming Lai, Yiming Ma
Abstract: In clinical medicine, rats are commonly used as experimental subjects. However, their estrous cycle significantly impacts their biological responses, leading to differences in experimental results. Therefore, accurately determining the estrous cycle is crucial for minimizing interference. Manually identifying the estrous cycle in rats presents several challenges, including high costs, long training periods, and subjectivity. To address these issues, this paper proposes a classification network-Spatial Long-distance EfficientNet (SLENet). This network is designed based on EfficientNet, specifically modifying the Mobile Inverted Bottleneck Convolution (MBConv) module by introducing a novel Spatial Efficient Channel Attention (SECA) mechanism to replace the original Squeeze Excitation (SE) module. Additionally, a Non-local attention mechanism is incorporated after the last convolutional layer to enhance the network's ability to capture long-range dependencies. The dataset used 2,655 microscopic images of rat vaginal epithelial cells, with 531 images in the test set. Experimental results indicate that SLENet achieved an accuracy of 96.31%, outperforming baseline EfficientNet model (94.2%). This finding provide practical value for optimizing experimental design in rat-based studies such as reproductive and pharmacological research, but this study is limited to microscopy image data, without considering other factors like temporal patterns, thus, incorporating multi-modal input is necessary for future application.

Paper number 11:
Title: Diversity and Interaction Quality of a Heterogeneous Multi-Agent System Applied to a Synchronization Problem
Authors: Xin Mao, Dan Wang, Wei Chen, Li Qiu
Abstract: In this paper, scalable controller design to achieve output synchronization for a heterogeneous discrete-time nonlinear multi-agent system is considered. The agents are assumed to exhibit potentially nonlinear dynamics but share linear common oscillatory modes. In a distributed control architecture, scalability is ensured by designing a small number of distinguished controllers, significantly fewer than the number of agents, even when agent diversity is high. Our findings indicate that the number of controllers required can be effectively determined by the number of strongly connected components of the underlying graph. The study in this paper builds on the recently developed phase theory of matrices and systems. First, we employ the concept of matrix phase, specifically the phase alignability of a collection of matrices, to quantify agent diversity. Next, we use matrix phase, particularly the essential phase of the graph Laplacian, to evaluate the interaction quality among the agents. Based on these insights, we derive a sufficient condition for the solvability of the synchronization problem, framed as a trade-off between the agent diversity and the interaction quality. In the process, a controller design procedure based on Lyapunov analysis is provided, which produces low gain, component-wise synchronizing controllers when the solvability condition is satisfied. Numerical examples are given to illustrate the effectiveness of the proposed design procedure. Furthermore, we consider cases where the component-wise controller design problem is unsolvable. We propose alternative strategies involving the design of a small inventory of controllers, which can still achieve synchronization effectively by employing certain clustering methods to manage heterogeneity.

Paper number 12:
Title: Multisession Longitudinal Dynamic MRI Incorporating Patient-Specific Prior Image Information Across Time
Authors: Jingjia Chen, Hersh Chandarana, Daniel K. Sodickson, Li Feng
Abstract: Serial Magnetic Resonance Imaging (MRI) exams are often performed in clinical practice, offering shared anatomical and motion information across imaging sessions. However, existing reconstruction methods process each session independently without leveraging this valuable longitudinal information. In this work, we propose a novel concept of longitudinal dynamic MRI, which incorporates patient-specific prior images to exploit temporal correlations across sessions. This framework enables progressive acceleration of data acquisition and reduction of scan time as more imaging sessions become available. The concept is demonstrated using the 4D Golden-angle RAdial Sparse Parallel (GRASP) MRI, a state-of-the-art dynamic imaging technique. Longitudinal reconstruction is performed by concatenating multi-session time-resolved 4D GRASP datasets into an extended dynamic series, followed by a low-rank subspace-based reconstruction algorithm. A series of experiments were conducted to evaluate the feasibility and performance of the proposed method. Results show that longitudinal 4D GRASP reconstruction consistently outperforms standard single-session reconstruction in image quality, while preserving inter-session variations. The approach demonstrated robustness to changes in anatomy, imaging intervals, and body contour, highlighting its potential for improving imaging efficiency and consistency in longitudinal MRI applications. More generally, this work suggests a new context-aware imaging paradigm in which the more we see a patient, the faster we can image.

Paper number 13:
Title: Wardropian Cycles make traffic assignment both optimal and fair by eliminating price-of-anarchy with Cyclical User Equilibrium for compliant connected autonomous vehicles
Authors: Michał Hoffmann, Michał Bujak, Grzegorz Jamróz, Rafał Kucharski
Abstract: Connected and Autonomous Vehicles (CAVs) open the possibility for centralised routing with full compliance, making System Optimal traffic assignment attainable. However, as System Optimum makes some drivers better off than others, voluntary acceptance seems dubious. To overcome this issue, we propose a new concept of Wardropian cycles, which, in contrast to previous utopian visions, makes the assignment fair on top of being optimal, which amounts to satisfaction of both Wardrop's principles. Such cycles, represented as sequences of permutations to the daily assignment matrices, always exist and equalise, after a limited number of days, average travel times among travellers (like in User Equilibrium) while preserving everyday optimality of path flows (like in System Optimum). We propose exact methods to compute such cycles and reduce their length and within-cycle inconvenience to the users. As identification of optimal cycles turns out to be NP-hard in many aspects, we introduce a greedy heuristic efficiently approximating the optimal solution. Finally, we introduce and discuss a new paradigm of Cyclical User Equilibrium, which ensures stability of optimal Wardropian Cycles under unilateral deviations. We complement our theoretical study with large-scale simulations. In Barcelona, 670 vehicle-hours of Price-of-Anarchy are eliminated using cycles with a median length of 11 days-though 5% of cycles exceed 90 days. However, in Berlin, just five days of applying the greedy assignment rule significantly reduces initial inequity. In Barcelona, Anaheim, and Sioux Falls, less than 7% of the initial inequity remains after 10 days, demonstrating the effectiveness of this approach in improving traffic performance with more ubiquitous social acceptability.

Paper number 14:
Title: CDA-SimBoost: A Unified Framework Bridging Real Data and Simulation for Infrastructure-Based CDA Systems
Authors: Zhaoliang Zheng, Xu Han, Yuxin Bao, Yun Zhang, Johnson Liu, Zonglin Meng, Xin Xia, Jiaqi Ma
Abstract: Cooperative Driving Automation (CDA) has garnered increasing research attention, yet the role of intelligent infrastructure remains insufficiently explored. Existing solutions offer limited support for addressing long-tail challenges, real-synthetic data fusion, and heterogeneous sensor management. This paper introduces CDA-SimBoost, a unified framework that constructs infrastructure-centric simulation environments from real-world data. CDA-SimBoost consists of three main components: a Digital Twin Builder for generating high-fidelity simulator assets based on sensor and HD map data, OFDataPip for processing both online and offline data streams, and OpenCDA-InfraX, a high-fidelity platform for infrastructure-focused simulation. The system supports realistic scenario construction, rare event synthesis, and scalable evaluation for CDA research. With its modular architecture and standardized benchmarking capabilities, CDA-SimBoost bridges real-world dynamics and virtual environments, facilitating reproducible and extensible infrastructure-driven CDA studies. All resources are publicly available at this https URL

Paper number 15:
Title: A Metabolic-Imaging Integrated Model for Prognostic Prediction in Colorectal Liver Metastases
Authors: Qinlong Li, Pu Sun, Guanlin Zhu, Tianjiao Liang, Honggang QI
Abstract: Prognostic evaluation in patients with colorectal liver metastases (CRLM) remains challenging due to suboptimal accuracy of conventional clinical models. This study developed and validated a robust machine learning model for predicting postoperative recurrence risk. Preliminary ensemble models achieved exceptionally high performance (AUC $>$ 0.98) but incorporated postoperative features, introducing data leakage risks. To enhance clinical applicability, we restricted input variables to preoperative baseline clinical parameters and radiomic features from contrast-enhanced CT imaging, specifically targeting recurrence prediction at 3, 6, and 12 months postoperatively. The 3-month recurrence prediction model demonstrated optimal performance with an AUC of 0.723 in cross-validation. Decision curve analysis revealed that across threshold probabilities of 0.55-0.95, the model consistently provided greater net benefit than "treat-all" or "treat-none" strategies, supporting its utility in postoperative surveillance and therapeutic decision-making. This study successfully developed a robust predictive model for early CRLM recurrence with confirmed clinical utility. Importantly, it highlights the critical risk of data leakage in clinical prognostic modeling and proposes a rigorous framework to mitigate this issue, enhancing model reliability and translational value in real-world settings.

Paper number 16:
Title: Coverage Probability and Average Rate Analysis of Hybrid Cellular and Cell-free Network
Authors: Zhuoyin Dai, Jingran Xu, Xiaoli Xu, Ruoguang Li, Yong Zeng, Jiangbin Lyu
Abstract: Cell-free wireless networks deploy distributed access points (APs) to simultaneously serve user equipments (UEs) across the service region and are regarded as one of the most promising network architectural paradigms. Despite recent advances in the performance analysis and optimization of cellfree wireless networks, it remains an open question whether large-scale deployment of APs in existing wireless networks can cost-effectively achieve communication capacity growth. Besides, the realization of a cell-free network is considered to be a gradual long-term evolutionary process in which cell-free APs will be incrementally introduced into existing cellular networks, and form a hybrid communication network with the existing cellular base stations (BSs). Such a collaboration will bridge the gap between the established cellular network and the innovative cellfree network. Therefore, hybrid cellular and cell-free networks (HCCNs) emerge as a practical and feasible solution for advancing cell-free network development, and it is worthwhile to further explore its performance limits. This paper presents a stochastic geometry-based hybrid cellular and cell-free network model to analyze the distributions of signal and interference and reveal their mutual coupling. Specifically, in order to benefit the UEs from both the cellular BSs and the cell-free APs, a conjugate beamforming design is employed, and the aggregated signal is analyzed using moment matching. Then, the coverage probability of the hybrid network is characterized by deriving the Laplace transforms and their higher-order derivatives of interference components. Furthermore, the average achievable rate of the hybrid network over channel fading is derived based on the interference coupling analysis.

Paper number 17:
Title: SpecBPP: A Self-Supervised Learning Approach for Hyperspectral Representation and Soil Organic Carbon Estimation
Authors: Daniel La'ah Ayuba, Jean-Yves Guillemaut, Belen Marti-Cardona, Oscar Mendez Maldonado
Abstract: Self-supervised learning has revolutionized representation learning in vision and language, but remains underexplored for hyperspectral imagery (HSI), where the sequential structure of spectral bands offers unique opportunities. In this work, we propose Spectral Band Permutation Prediction (SpecBPP), a novel self-supervised learning framework that leverages the inherent spectral continuity in HSI. Instead of reconstructing masked bands, SpecBPP challenges a model to recover the correct order of shuffled spectral segments, encouraging global spectral understanding. We implement a curriculum-based training strategy that progressively increases permutation difficulty to manage the factorial complexity of the permutation space. Applied to Soil Organic Carbon (SOC) estimation using EnMAP satellite data, our method achieves state-of-the-art results, outperforming both masked autoencoder (MAE) and joint-embedding predictive (JEPA) baselines. Fine-tuned on limited labeled samples, our model yields an $R^2$ of 0.9456, RMSE of 1.1053%, and RPD of 4.19, significantly surpassing traditional and self-supervised benchmarks. Our results demonstrate that spectral order prediction is a powerful pretext task for hyperspectral understanding, opening new avenues for scientific representation learning in remote sensing and beyond.

Paper number 18:
Title: Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification
Authors: Gevindu Ganganath, Pasindu Sankalpa, Samal Punsara, Demitha Pasindu, Chamira U. S. Edussooriya, Ranga Rodrigo, Udaya S. K. P. Miriya Thanthrige
Abstract: The use of drones in a wide range of applications is steadily increasing. However, this has also raised critical security concerns such as unauthorized drone intrusions into restricted zones. Therefore, robust and accurate drone detection and classification mechanisms are required despite significant challenges due to small size of drones, low-altitude flight, and environmental noise. In this letter, we propose a multi-modal approach combining radar and acoustic sensing for detecting and classifying drones. We employ radar due to its long-range capabilities, and robustness to different weather conditions. We utilize raw acoustic signals without converting them to other domains such as spectrograms or Mel-frequency cepstral coefficients. This enables us to use fewer number of parameters compared to the stateof-the-art approaches. Furthermore, we explore the effectiveness of the transformer encoder architecture in fusing these sensors. Experimental results obtained in outdoor settings verify the superior performance of the proposed approach compared to the state-of-the-art methods.

Paper number 19:
Title: Channel Estimation in Massive MIMO Systems with Orthogonal Delay-Doppler Division Multiplexing
Authors: Dezhi Wang, Chongwen Huang, Xiaojun Yuan, Sami Muhaidat, Lei Liu, Xiaoming Chen, Zhaoyang Zhang, Chau Yuen, Mérouane Debbah
Abstract: Orthogonal delay-Doppler division multiplexing~(ODDM) modulation has recently been regarded as a promising technology to provide reliable communications in high-mobility situations. Accurate and low-complexity channel estimation is one of the most critical challenges for massive multiple input multiple output~(MIMO) ODDM systems, mainly due to the extremely large antenna arrays and high-mobility environments. To overcome these challenges, this paper addresses the issue of channel estimation in downlink massive MIMO-ODDM systems and proposes a low-complexity algorithm based on memory approximate message passing~(MAMP) to estimate the channel state information~(CSI). Specifically, we first establish the effective channel model of the massive MIMO-ODDM systems, where the magnitudes of the elements in the equivalent channel vector follow a Bernoulli-Gaussian distribution. Further, as the number of antennas grows, the elements in the equivalent coefficient matrix tend to become completely random. Leveraging these characteristics, we utilize the MAMP method to determine the gains, delays, and Doppler effects of the multi-path channel, while the channel angles are estimated through the discrete Fourier transform method. Finally, numerical results show that the proposed channel estimation algorithm approaches the Bayesian optimal results when the number of antennas tends to infinity and improves the channel estimation accuracy by about 30% compared with the existing algorithms in terms of the normalized mean square error.

Paper number 20:
Title: Feature Engineering for Wireless Communications and Networking: Concepts, Methodologies, and Applications
Authors: Jiacheng Wang, Changyuan Zhao, Zehui Xiong, Tao Xiang, Dusit Niyato, Xianbin Wang, Shiwen Mao, Dong In Kim
Abstract: AI-enabled wireless communications have attracted tremendous research interest in recent years, particularly with the rise of novel paradigms such as low-altitude integrated sensing and communication (ISAC) networks. Within these systems, feature engineering plays a pivotal role by transforming raw wireless data into structured representations suitable for AI models. Hence, this paper offers a comprehensive investigation of feature engineering techniques in AI-driven wireless communications. Specifically, we begin with a detailed analysis of fundamental principles and methodologies of feature engineering. Next, we present its applications in wireless communication systems, with special emphasis on ISAC networks. Finally, we introduce a generative AI-based framework, which can reconstruct signal feature spectrum under malicious attacks in low-altitude ISAC networks. The case study shows that it can effectively reconstruct the signal spectrum, achieving an average structural similarity index improvement of 4%, thereby supporting downstream sensing and communication applications.

Paper number 21:
Title: Star Tracker Misalignment Compensation in Deep Space Navigation Through Model-Based Estimation
Authors: Ridma Ganganath, Simone Servadio, David Lee
Abstract: This work presents a novel adaptive framework for simultaneously estimating spacecraft attitude and sensor misalignment. Uncorrected star tracker misalignment can introduce significant pointing errors that compromise mission objectives in GPS-denied environments. To address this challenge, the proposed architecture integrates a Bayesian Multiple-Model Adaptive Estimation (MMAE) framework operating over an N x N x N 3D hypothesis grid. Each hypothesis employs a 9-state Multiplicative Extended Kalman Filter (MEKF) to estimate attitude, angular velocity, and gyroscope bias using TRIAD-based vector measurements. A key contribution is the development of a robust grid refinement strategy that uses hypothesis diversity and weighted-mean grid centering to prevent the premature convergence commonly encountered in classical, dominant model-based refinement triggers. Extensive Monte Carlo simulations demonstrate that the proposed method reduces the final misalignment RMSE relative to classical approaches, achieving arcsecond-level accuracy. The resulting framework offers a computationally tractable and statistically robust solution for in-flight calibration, enhancing the navigational autonomy of resource-constrained spacecraft.

Paper number 22:
Title: Hybrid Deep Learning and Handcrafted Feature Fusion for Mammographic Breast Cancer Classification
Authors: Maximilian Tschuchnig, Michael Gadermayr, Khalifa Djemal
Abstract: Automated breast cancer classification from mammography remains a significant challenge due to subtle distinctions between benign and malignant tissue. In this work, we present a hybrid framework combining deep convolutional features from a ResNet-50 backbone with handcrafted descriptors and transformer-based embeddings. Using the CBIS-DDSM dataset, we benchmark our ResNet-50 baseline (AUC: 78.1%) and demonstrate that fusing handcrafted features with deep ResNet-50 and DINOv2 features improves AUC to 79.6% (setup d1), with a peak recall of 80.5% (setup d1) and highest F1 score of 67.4% (setup d1). Our experiments show that handcrafted features not only complement deep representations but also enhance performance beyond transformer-based embeddings. This hybrid fusion approach achieves results comparable to state-of-the-art methods while maintaining architectural simplicity and computational efficiency, making it a practical and effective solution for clinical decision support.

Paper number 23:
Title: Taming Domain Shift in Multi-source CT-Scan Classification via Input-Space Standardization
Authors: Chia-Ming Lee, Bo-Cheng Qiu, Ting-Yao Chen, Ming-Han Sun, Fang-Ying Lin, Jung-Tse Tsai, I-An Tsai, Yu-Fan Lin, Chih-Chung Hsu
Abstract: Multi-source CT-scan classification suffers from domain shifts that impair cross-source generalization. While preprocessing pipelines combining Spatial-Slice Feature Learning (SSFL++) and Kernel-Density-based Slice Sampling (KDS) have shown empirical success, the mechanisms underlying their domain robustness remain underexplored. This study analyzes how this input-space standardization manages the trade-off between local discriminability and cross-source generalization. The SSFL++ and KDS pipeline performs spatial and temporal standardization to reduce inter-source variance, effectively mapping disparate inputs into a consistent target space. This preemptive alignment mitigates domain shift and simplifies the learning task for network optimization. Experimental validation demonstrates consistent improvements across architectures, proving the benefits stem from the preprocessing itself. The approach's effectiveness was validated by securing first place in a competitive challenge, supporting input-space standardization as a robust and practical solution for multi-institutional medical imaging.

Paper number 24:
Title: Toward Dual-Functional LAWN: Control-Aware System Design for Aerodynamics-Aided UAV Formations
Authors: Jun Wu, Weijie Yuan, Qingqing Cheng, Haijia Jin
Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal technology for advancing low-altitude wireless networks (LAWNs), serving as a critical enabler for next-generation communication systems. This paper investigates the system design for energy-saving unmanned aerial vehicle (UAV) formations in dual-functional LAWNs, where a ground base station (GBS) simultaneously wirelessly controls multiple UAV formations and performs sensing tasks. To enhance flight endurance, we exploit the aerodynamic upwash effects and propose a distributed energy-saving formation framework based on the adapt-then-combine (ATC) diffusion least mean square (LMS) algorithm. Specifically, each UAV updates the local position estimate by invoking the LMS algorithm, followed by refining it through cooperative information exchange with neighbors. This enables an optimized aerodynamic structure that minimizes the formation's overall energy consumption. To ensure control stability and fairness, we formulate a maximum linear quadratic regulator (LQR) minimization problem, which is subject to both the available power budget and the required sensing beam pattern gain. To address this non-convex problem, we develop a two-step approach by first deriving a closed-form expression of LQR as a function of arbitrary beamformers. Subsequently, an efficient iterative algorithm that integrates successive convex approximation (SCA) and semidefinite relaxation (SDR) techniques is proposed to obtain a sub-optimal dual-functional beamforming solution. Extensive simulation results confirm that the 'V'-shaped formation is the most energy-efficient configuration and demonstrate the superiority of our proposed design over benchmark schemes in improving control performance.

Paper number 25:
Title: The Phantom of Davis-Wielandt Shell: A Unified Framework for Graphical Stability Analysis of MIMO LTI Systems
Authors: Ding Zhang, Xiaokan Yang, Axel Ringh, Li Qiu
Abstract: This paper presents a unified framework based on Davis-Wielandt (DW) shell for graphical stability analysis of multi-input and multi-output linear time-invariant feedback systems. Connections between DW shells and various graphical descriptions, as well as gain and phase measures, are established through an intuitive geometric perspective. Within this framework, we examine the relationships and relative conservatism among various separation conditions. A rotated Scaled Relative Graph (SRG) concept is proposed as a mixed gain-phase representation, from which a closed-loop stability criterion is derived and shown to be the least conservative among the existing 2-D graphical conditions for bi-component feedback loops. We also propose a reliable algorithm for visualizing the rotated SRGs and include an example to demonstrate the non-conservatism of the proposed condition.

Paper number 26:
Title: Periodic orbit tracking in cislunar space: A finite-horizon approach
Authors: Mohammed Atallah, Simone Servadio
Abstract: This paper presents a Nonlinear Model Predictive Control (NMPC) scheme for maintaining a spacecraft within a specified family of periodic orbits near the libration points in cislunar space. Unlike traditional approaches that track a predefined reference orbit, the proposed method designs an optimal trajectory that keeps the spacecraft within the orbit family, regardless of the initial reference. The Circular Restricted Three-Body Problem (CR3BP) is used to model the system dynamics. First, the Pseudo-Arclength Continuation (PAC) method is employed to compute the members of each orbit family. Then, the state of each member is parameterized by two variables: one defining the orbit and the other specifying the location along it. These computed states are then fit to a Multivariate Polynomial Regression (MPR) model. An NMPC framework is developed to generate the optimal reference trajectory and compute the corresponding velocity impulses for trajectory tracking. The control system is integrated with a Extended Kalman Filter (EKF) observer that estimates the spacecraft's relative state. Numerical simulations are conducted for Lyapunov, halo, and near-rectilinear halo orbits near L1 and L2. The results demonstrate a significant reduction in fuel consumption compared to conventional tracking methods.

Paper number 27:
Title: Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems
Authors: Zhongnian Li, Chao Zheng, Jian Xiao, Ji Wang, Gongpu Wang, Ming Zeng, Octavia A. Dobre
Abstract: This paper investigates joint channel estimation and positioning in near-field sparse extra-large multiple-input multiple-output (XL-MIMO) orthogonal frequency division multiplexing (OFDM) systems. To achieve cooperative gains between channel estimation and positioning, we propose a deep learning-based two-stage framework comprising positioning and channel estimation. In the positioning stage, the user's coordinates are predicted and utilized in the channel estimation stage, thereby enhancing the accuracy of channel estimation. Within this framework, we propose a U-shaped Mamba architecture for channel estimation and positioning, termed as CP-Mamba. This network integrates the strengths of the Mamba model with the structural advantages of U-shaped convolutional networks, enabling effective capture of local spatial features and long-range temporal dependencies of the channel. Numerical simulation results demonstrate that the proposed two-stage approach with CP-Mamba architecture outperforms existing baseline methods. Moreover, sparse arrays (SA) exhibit significantly superior performance in both channel estimation and positioning accuracy compared to conventional compact arrays.

Paper number 28:
Title: SkinDualGen: Prompt-Driven Diffusion for Simultaneous Image-Mask Generation in Skin Lesions
Authors: Zhaobin Xu
Abstract: Medical image analysis plays a pivotal role in the early diagnosis of diseases such as skin lesions. However, the scarcity of data and the class imbalance significantly hinder the performance of deep learning models. We propose a novel method that leverages the pretrained Stable Diffusion-2.0 model to generate high-quality synthetic skin lesion images and corresponding segmentation masks. This approach augments training datasets for classification and segmentation tasks. We adapt Stable Diffusion-2.0 through domain-specific Low-Rank Adaptation (LoRA) fine-tuning and joint optimization of multi-objective loss functions, enabling the model to simultaneously generate clinically relevant images and segmentation masks conditioned on textual descriptions in a single step. Experimental results show that the generated images, validated by FID scores, closely resemble real images in quality. A hybrid dataset combining real and synthetic data markedly enhances the performance of classification and segmentation models, achieving substantial improvements in accuracy and F1-score of 8% to 15%, with additional positive gains in other key metrics such as the Dice coefficient and IoU. Our approach offers a scalable solution to address the challenges of medical imaging data, contributing to improved accuracy and reliability in diagnosing rare diseases.

Paper number 29:
Title: Dependability Theory-based Statistical QoS Provisioning of Fluid Antenna Systems
Authors: Irfan Muhammad, Priyadarshi Mukherjee, Wee Kiat New, Hirley Alves, Ioannis Krikidis, Kai-Kit Wong
Abstract: Fluid antenna systems (FAS) have recently emerged as a promising technology for next-generation wireless networks, offering real-time spatial reconfiguration to enhance reliability, throughput, and energy efficiency. Nevertheless, existing studies often overlook the temporal dynamics of channel fading and their implications for mission-critical operations. In this paper, we propose a dependability-theoretic framework for statistical quality-of-service (QoS) provisioning of FAS under finite blocklength (FBL) constraints. Specifically, we derive new closed-form expressions for the level-crossing rate (LCR) and average fade duration (AFD) of an $N$-port FAS over Nakagami-$m$ fading channels. Leveraging these second-order statistics, we define two key dependability metrics such as mission reliability and mean time-to-first-failure (MTTFF), to quantify the probability of uninterrupted operation over a defined mission duration. We further extend the classical effective capacity (EC) concept to incorporate mission reliability in the FBL regime, yielding a mission EC (mEC). To capture energy efficiency under bursty traffic and latency constraints, we also develop the mission effective energy efficiency (mEEE) metric and formulate its maximization as a non-convex fractional optimization problem. This problem is then solved via a modified Dinkelbach's method with an embedded line search. Extensive simulations uncover critical trade-offs among port count, QoS exponent, signal-to-noise ratio, and mission duration, offering insights for the design of ultra-reliable, low-latency, and energy-efficient industrial internet-of-things (IIoT) systems.

Paper number 30:
Title: DOA Estimation via Optimal Weighted Low-Rank Matrix Completion
Authors: Saeed Razavikia, Mohammad Bokaei, Arash Amini, Stefano Rini, Carlo Fischione
Abstract: This paper presents a novel method for estimating the direction of arrival (DOA) for a non-uniform and sparse linear sensor array using the weighted lifted structure low-rank matrix completion. The proposed method uses a single snapshot sample in which a single array of data is observed. The method is rooted in a weighted lifted-structured low-rank matrix recovery framework. The method involves four key steps: (i) lifting the antenna samples to form a low-rank stature, then (ii) designing left and right weight matrices to reflect the sample informativeness, (iii) estimating a noise-free uniform array output through completion of the weighted lifted samples, and (iv) obtaining the DOAs from the restored uniform linear array samples. We study the complexity of steps (i) to (iii) above, where we analyze the required sample for the array interpolation of step (iii) for DOA estimation. We demonstrate that the proposed choice of weight matrices achieves a near-optimal sample complexity. This complexity aligns with the problem's degree of freedom, equivalent to the number of DOAs adjusted for logarithmic factors. Numerical evaluations show the proposed method's superiority against the non-weighted counterpart and atomic norm minimization-based methods. Notably, our proposed method significantly improves, with approximately a 10 dB reduction in normalized mean-squared error over the non-weighted method at low-noise conditions.

Paper number 31:
Title: Binaural Speech Enhancement Using Complex Convolutional Recurrent Networks
Authors: Vikas Tokala, Eric Grinstein, Mike Brookes, Simon Doclo, Jesper Jensen, Patrick A. Naylor
Abstract: From hearing aids to augmented and virtual reality devices, binaural speech enhancement algorithms have been established as state-of-the-art techniques to improve speech intelligibility and listening comfort. In this paper, we present an end-to-end binaural speech enhancement method using a complex recurrent convolutional network with an encoder-decoder architecture and a complex LSTM recurrent block placed between the encoder and decoder. A loss function that focuses on the preservation of spatial information in addition to speech intelligibility improvement and noise reduction is introduced. The network estimates individual complex ratio masks for the left and right-ear channels of a binaural hearing device in the time-frequency domain. We show that, compared to other baseline algorithms, the proposed method significantly improves the estimated speech intelligibility and reduces the noise while preserving the spatial information of the binaural signals in acoustic situations with a single target speaker and isotropic noise of various types.

Paper number 32:
Title: Binaural Localization Model for Speech in Noise
Authors: Vikas Tokala, Eric Grinstein, Rory Brooks, Mike Brookes, Simon Doclo, Jesper Jensen, Patrick A. Naylor
Abstract: Binaural acoustic source localization is important to human listeners for spatial awareness, communication and safety. In this paper, an end-to-end binaural localization model for speech in noise is presented. A lightweight convolutional recurrent network that localizes sound in the frontal azimuthal plane for noisy reverberant binaural signals is introduced. The model incorporates additive internal ear noise to represent the frequency-dependent hearing threshold of a typical listener. The localization performance of the model is compared with the steered response power algorithm, and the use of the model as a measure of interaural cue preservation for binaural speech enhancement methods is studied. A listening test was performed to compare the performance of the model with human localization of speech in noisy conditions.

Paper number 33:
Title: A Unified Finite-Time Sliding Mode Quaternion-based Tracking Control for Quadrotor UAVs without Time Scale Separation
Authors: Ali M. Ali, Hashim A. Hashim, Awantha Jayasiri
Abstract: This paper presents a novel design for finite-time position control of quadrotor Unmanned Aerial Vehicles (UAVs). A robust, finite-time, nonlinear feedback controller is introduced to reject bounded disturbances in tracking tasks. The proposed control framework differs conceptually from conventional controllers that utilize Euler angle parameterization for attitude and adhere to the traditional hierarchical inner-outer loop design. In standard approaches, the translational controller and the corresponding desired attitude are computed first, followed by the design of the attitude controller based on time-scale separation between fast attitude and slow translational dynamics. In contrast, the proposed control scheme is quaternion-based and utilizes a transit feed-forward term in the attitude dynamics that anticipates the slower translational subsystem. Robustness is achieved through the use of continuously differentiable sliding manifolds. The proposed approach guarantees semi-global finite-time stability, without requiring time-scale separation. Finally, numerical simulation results are provided to demonstrate the effectiveness of the proposed controller.

Paper number 34:
Title: Comparative Analysis of Data-Driven Predictive Control Strategies
Authors: Sohrab Rezaei, Ali Khaki-Sedigh
Abstract: This paper compares data-driven predictive control strategies by examining their theoretical foundations, assumptions, and applications. The three most widely recognized and consequential methods, Data Enabled Predictive Control, Willems-Koopman Predictive Control, Model-Free Adaptive Predictive Control are employed. Each of these strategies is systematically reviewed, and the primary theories supporting it are outlined. Following analysis, a discussion is provided regarding their fundamental assumptions, emphasizing their influence on control effectiveness. A numerical example is presented as a benchmark for comparison to enable a rigorous performance evaluation.

Paper number 35:
Title: On Uncertainty Prediction for Deep-Learning-based Particle Image Velocimetry
Authors: Wei Wang, Jeremiah Hu, Jia Ai, Yong Lee
Abstract: Particle Image Velocimetry (PIV) is a widely used technique for flow measurement that traditionally relies on cross-correlation to track the displacement. Recent advances in deep learning-based methods have significantly improved the accuracy and efficiency of PIV measurements. However, despite its importance, reliable uncertainty quantification for deep learning-based PIV remains a critical and largely overlooked challenge. This paper explores three methods for quantifying uncertainty in deep learning-based PIV: the Uncertainty neural network (UNN), Multiple models (MM), and Multiple transforms (MT). We evaluate the three methods across multiple datasets. The results show that all three methods perform well under mild perturbations. Among the three evaluation metrics, the UNN method consistently achieves the best performance, providing accurate uncertainty estimates and demonstrating strong potential for uncertainty quantification in deep learning-based PIV. This study provides a comprehensive framework for uncertainty quantification in PIV, offering insights for future research and practical implementation.

Paper number 36:
Title: NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis
Authors: Chengkai Wang, Di Wu, Yunsheng Liao, Wenyao Zheng, Ziyi Zeng, Xurong Gao, Hemmings Wu, Zhoule Zhu, Jie Yang, Lihua Zhong, Weiwei Cheng, Yun-Hsuan Chen, Mohamad Sawan
Abstract: Methamphetamine dependence poses a significant global health challenge, yet its assessment and the evaluation of treatments like repetitive transcranial magnetic stimulation (rTMS) frequently depend on subjective self-reports, which may introduce uncertainties. While objective neuroimaging modalities such as electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) offer alternatives, their individual limitations and the reliance on conventional, often hand-crafted, feature extraction can compromise the reliability of derived biomarkers. To overcome these limitations, we propose NeuroCLIP, a novel deep learning framework integrating simultaneously recorded EEG and fNIRS data through a progressive learning strategy. This approach offers a robust and trustworthy biomarker for methamphetamine addiction. Validation experiments show that NeuroCLIP significantly improves discriminative capabilities among the methamphetamine-dependent individuals and healthy controls compared to models using either EEG or only fNIRS alone. Furthermore, the proposed framework facilitates objective, brain-based evaluation of rTMS treatment efficacy, demonstrating measurable shifts in neural patterns towards healthy control profiles after treatment. Critically, we establish the trustworthiness of the multimodal data-driven biomarker by showing its strong correlation with psychometrically validated craving scores. These findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP offers enhanced robustness and reliability over single-modality approaches, providing a valuable tool for addiction neuroscience research and potentially improving clinical assessments.

Paper number 37:
Title: On Certificates for Almost Sure Reachability in Stochastic Systems
Authors: Arash Bahari Kordabad, Rupak Majumdar, Harshit Jitendra Motwani, Sadegh Soudjani
Abstract: Almost sure reachability refers to the property of a stochastic system whereby, from any initial condition, the system state reaches a given target set with probability one. In this paper, we study the problem of certifying almost sure reachability in discrete-time stochastic systems using drift and variant conditions. While these conditions are both necessary and sufficient in theory, computational approaches often rely on restricting the search to fixed templates, such as polynomial or quadratic functions. We show that this restriction compromises completeness: there exists a polynomial system for which a given target set is almost surely reachable but admits no polynomial certificate, and a linear system for which a neighborhood of the origin is almost surely reachable but admits no quadratic certificate. We then provide a complete characterization of reachability certificates for linear systems with additive noise. Our analysis yields conditions on the system matrices under which valid certificates exist, and shows how the structure and dimension of the system determine the need for non-quadratic templates. Our results generalize the classical random walk behavior to a broader class of stochastic dynamical systems.

Paper number 38:
Title: A Truthful Mechanism Design for Distributed Optimisation Algorithms in Networks with Self-interested Agents
Authors: Tianyi Zhong, David Angeli
Abstract: Enhancing resilience in multi-agent systems in the face of selfish agents is an important problem that requires further characterisation. This work develops a truthful mechanism that avoids self-interested and strategic agents maliciously manipulating the algorithm. We prove theoretically that the proposed mechanism incentivises self-interested agents to participate and follow the provided algorithm faithfully. Additionally, the mechanism is compatible with any distributed optimisation algorithm that can calculate at least one subgradient at a given point. Finally, we present an illustrative example that shows the effectiveness of the mechanism.

Paper number 39:
Title: Relaxing Probabilistic Latent Variable Models' Specification via Infinite-Horizon Optimal Control
Authors: Zhichao Chen, Hao Wang, Licheng Pan, Yiran Ma, Yunfei Teng, Jiaze Ma, Le Yao, Zhiqiang Ge, Zhihuan Song
Abstract: In this paper, we address the issue of model specification in probabilistic latent variable models (PLVMs) using an infinite-horizon optimal control approach. Traditional PLVMs rely on joint distributions to model complex data, but introducing latent variables results in an ill-posed parameter learning problem. To address this issue, regularization terms are typically introduced, leading to the development of the expectation-maximization (EM) algorithm, where the latent variable distribution is restricted to a predefined normalized distribution family to facilitate the expectation step. To overcome this limitation, we propose representing the latent variable distribution as a finite set of instances perturbed via an ordinary differential equation with a control policy. This approach ensures that the instances asymptotically converge to the true latent variable distribution as time approaches infinity. By doing so, we reformulate the distribution inference problem as an optimal control policy determination problem, relaxing the model specification to an infinite-horizon path space. Building on this formulation, we derive the corresponding optimal control policy using the Pontryagin's maximum principle and provide a closed-form expression for its implementation using the reproducing kernel Hilbert space. After that, we develop a novel, convergence-guaranteed EM algorithm for PLVMs based on this infinite-horizon-optimal-control-based inference strategy. Finally, extensive experiments are conducted to validate the effectiveness and superiority of the proposed approach.

Paper number 40:
Title: Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation
Authors: Haotian Tian, Lixiang Lian, Jiaqi Cao, Sijie Ji
Abstract: Deep learning has emerged as a promising so- lution for efficient channel state information (CSI) feedback in frequency division duplex (FDD) massive MIMO systems. Conventional deep learning-based methods typically rely on a deep autoencoder to compress the CSI, which leads to irre- versible information loss and degrades reconstruction accuracy. This paper introduces InvCSINet, an information-preserving CSI feedback framework based on invertible neural networks (INNs). By leveraging the bijective nature of INNs, the model ensures information-preserving compression and reconstruction with shared model parameters. To address practical challenges such as quantization and channel-induced errors, we endoge- nously integrate an adaptive quantization module, a differentiable bit-channel distortion module and an information compensation module into the INN architecture. This design enables the network to learn and compensate the information loss during CSI compression, quantization, and noisy transmission, thereby preserving the CSI integrity throughout the feedback process. Simulation results validate the effectiveness of the proposed scheme, demonstrating superior CSI recovery performance and robustness to practical impairments with a lightweight architec- ture.

Paper number 41:
Title: Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design
Authors: Donggu Lee, Sung Joon Maeng, Ozgur Ozdemir, Mani Bharathi Pandian, Ismail Guvenc
Abstract: Command and control of uncrewed aerial vehicles (UAVs) is often realized through air-to-ground (A2G) remote control (RC) links that operate in ISM bands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC links, ISM-based long-term evolution (LTE) and fifth-generation (5G) technologies have also been recently considered for the same purpose. A major problem for UAV RC links in the ISM bands is that other types of interference sources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link quality. Such interference problems are a higher concern for the UAV in the air than the RC unit on the ground due to the UAV being in line-of-sight (LoS) with a larger number of interference sources. To obtain empirical evidence of the asymmetric interference conditions in downlink (DL) and uplink (UL), we first conducted a measurement campaign using a helikite platform in urban and rural areas at NC State University. The results from this measurement campaign show that the aggregate interference can be up to 16.66 dB at higher altitudes up to 170 m, compared with the interference observed at a ground receiver. As a result of this asymmetric UL interference, lost hybrid automatic repeat request (HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To investigate this, we study various HARQ mechanisms, including HARQ Type-I with no combining, HARQ Type-I with chase combining, HARQ Type-III with incremental redundancy, and burst transmission with chase combining. To evaluate the impact of asymmetric UL interference on throughput performance, we consider three steps of evaluation process: 1) standalone physical DL shared channel (PDSCH) throughput evaluation with perfect ACK/NACK assumption; 2) standalone physical UL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL throughput evaluation with asymmetric UL ACK/NACK transmission.

Paper number 42:
Title: ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories
Authors: Rajat Bhattacharjya, Arnab Sarkar, Ish Kool, Sabur Baidya, Nikil Dutt
Abstract: Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting goods in 5G network-enabled smart factories, with the compute-intensive localization module presenting a significant opportunity for optimization. We propose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I) localization framework that leverages existing 5G infrastructure in smart factory environments. By opportunistically accessing the periodically broadcast 5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates the need for dedicated Roadside Units (RSUs) or additional onboard sensors to achieve energy efficiency as well as cost reduction. We implement an Angle-of-Arrival (AoA)-based estimation method using the Multiple Signal Classification (MUSIC) algorithm, optimized for resource-constrained ADV platforms through an adaptive communication-computation strategy that dynamically balances energy consumption with localization accuracy based on environmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle velocity. Experimental results demonstrate that ACCESS-AV achieves an average energy reduction of 43.09% compared to non-adaptive systems employing AoA algorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30 cm localization accuracy while also delivering substantial reductions in infrastructure and operational costs, establishing its viability for sustainable smart factory environments.

Paper number 43:
Title: A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification
Authors: Samiul Based Shuvo, Taufiq Hasan
Abstract: Automated analysis of lung sound auscultation is essential for monitoring respiratory health, especially in regions facing a shortage of skilled healthcare workers. While respiratory sound classification has been widely studied in adults, its ap plication in pediatric populations, particularly in children aged <6 years, remains an underexplored area. The developmental changes in pediatric lungs considerably alter the acoustic proper ties of respiratory sounds, necessitating specialized classification approaches tailored to this age group. To address this, we propose a multistage hybrid CNN-Transformer framework that combines CNN-extracted features with an attention-based architecture to classify pediatric respiratory diseases using scalogram images from both full recordings and individual breath events. Our model achieved an overall score of 0.9039 in binary event classifi cation and 0.8448 in multiclass event classification by employing class-wise focal loss to address data imbalance. At the recording level, the model attained scores of 0.720 for ternary and 0.571 for multiclass classification. These scores outperform the previous best models by 3.81% and 5.94%, respectively. This approach offers a promising solution for scalable pediatric respiratory disease diagnosis, especially in resource-limited settings.

Paper number 44:
Title: Energy-Efficient Secure Communications via Joint Optimization of UAV Trajectory and Movable-Antenna Array Beamforming
Authors: Sanghyeok Kim, Jinu Gong, Joonhyuk Kang
Abstract: This paper investigates the potential of unmanned aerial vehicles (UAVs) equipped with movable-antenna (MA) arrays to strengthen security in wireless communication systems. We propose a novel framework that jointly optimizes the UAV trajectory and the reconfigurable beamforming of the MA array to maximize secrecy energy efficiency, while ensuring reliable communication with legitimate users. By exploiting the spatial degrees of freedom enabled by the MA array, the system can form highly directional beams and deep nulls, thereby significantly improving physical layer security. Numerical results demonstrate that the proposed approach achieves superior secrecy energy efficiency, attributed to the enhanced spatial flexibility provided by the movable antenna architecture.

Paper number 45:
Title: Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots
Authors: Gyeong-Tae Lee, Hyeonuk Nam, Yong-Hwa Park
Abstract: This paper introduces Binaural Sound Event Localization and Detection (BiSELD), a task that aims to jointly detect and localize multiple sound events using binaural audio, inspired by the spatial hearing mechanism of humans. To support this task, we present a synthetic benchmark dataset, called the Binaural Set, which simulates realistic auditory scenes using measured head-related transfer functions (HRTFs) and diverse sound events. To effectively address the BiSELD task, we propose a new input feature representation called the Binaural Time-Frequency Feature (BTFF), which encodes interaural time difference (ITD), interaural level difference (ILD), and high-frequency spectral cues (SC) from binaural signals. BTFF is composed of eight channels, including left and right mel-spectrograms, velocity-maps, SC-maps, and ITD-/ILD-maps, designed to cover different spatial cues across frequency bands and spatial axes. A CRNN-based model, BiSELDnet, is then developed to learn both spectro-temporal patterns and HRTF-based localization cues from BTFF. Experiments on the Binaural Set show that each BTFF sub-feature enhances task performance: V-map improves detection, ITD-/ILD-maps enable accurate horizontal localization, and SC-map captures vertical spatial cues. The final system achieves a SELD error of 0.110 with 87.1% F-score and 4.4° localization error, demonstrating the effectiveness of the proposed framework in mimicking human-like auditory perception.

Paper number 46:
Title: HJB-based online safety-embedded critic learning for uncertain systems with self-triggered mechanism
Authors: Zhanglin Shangguan, Bo Yang, Qi Li, Wei Xiao, Xingping Guan
Abstract: This paper presents a learning-based optimal control framework for safety-critical systems with parametric uncertainties, addressing both time-triggered and self-triggered controller implementations. First, we develop a robust control barrier function (RCBF) incorporating Lyapunov-based compensation terms to rigorously guarantee safety despite parametric uncertainties. Building on this safety guarantee, we formulate the constrained optimal control problem as the minimization of a novel safety-embedded value function, where the RCBF is involved via a Lagrange multiplier that adaptively balances safety constraints against optimal stabilization objectives. To enhance computational efficiency, we propose a self-triggered implementation mechanism that reduces control updates while maintaining dual stability-safety guarantees. The resulting self-triggered constrained Hamilton-Jacobi-Bellman (HJB) equation is solved through an online safety-embedded critic learning framework, with the Lagrange multiplier computed in real time to ensure safety. Numerical simulations demonstrate the effectiveness of the proposed approach in achieving both safety and control performance.

Paper number 47:
Title: Implicit Spatiotemporal Bandwidth Enhancement Filter by Sine-activated Deep Learning Model for Fast 3D Photoacoustic Tomography
Authors: I Gede Eka Sulistyawan, Takuro Ishii, Riku Suzuki, Yoshifumi Saijo
Abstract: 3D photoacoustic tomography (3D-PAT) using high-frequency hemispherical transducers offers near-omnidirectional reception and enhanced sensitivity to the finer structural details encoded in the high-frequency components of the broadband photoacoustic (PA) signal. However, practical constraints such as limited number of channels with bandlimited sampling rate often result in sparse and bandlimited sensors that degrade image quality. To address this, we revisit the 2D deep learning (DL) approach applied directly to sensor-wise PA radio-frequency (PARF) data. Specifically, we introduce sine activation into the DL model to restore the broadband nature of PARF signals given the observed band-limited and high-frequency PARF data. Given the scarcity of 3D training data, we employ simplified training strategies by simulating random spherical absorbers. This combination of sine-activated model and randomized training is designed to emphasize bandwidth learning over dataset memorization. Our model was evaluated on a leaf skeleton phantom, a micro-CT-verified 3D spiral phantom and in-vivo human palm vasculature. The results showed that the proposed training mechanism on sine-activated model was well-generalized across the different tests by effectively increasing the sensor density and recovering the spatiotemporal bandwidth. Qualitatively, the sine-activated model uniquely enhanced high-frequency content that produces clearer vascular structure with fewer artefacts. Quantitatively, the sine-activated model exhibits full bandwidth at -12 dB spectrum and significantly higher contrast-to-noise ratio with minimal loss of structural similarity index. Lastly, we optimized our approach to enable fast enhanced 3D-PAT at 2 volumes-per-second for better practical imaging of a free-moving targets.

Paper number 48:
Title: A Modified Adaptive Data-Enabled Policy Optimization Control to Resolve State Perturbations
Authors: Mojtaba Kaheni, Niklas Persson, Vittorio De Iuliis, Costanzo Manes, Alessandro V. Papadopoulos
Abstract: This paper proposes modifications to the data-enabled policy optimization (DeePO) algorithm to mitigate state perturbations. DeePO is an adaptive, data-driven approach designed to iteratively compute a feedback gain equivalent to the certainty-equivalence LQR gain. Like other data-driven approaches based on Willems' fundamental lemma, DeePO requires persistently exciting input signals. However, linear state-feedback gains from LQR designs cannot inherently produce such inputs. To address this, probing noise is conventionally added to the control signal to ensure persistent excitation. However, the added noise may induce undesirable state perturbations. We first identify two key issues that jeopardize the desired performance of DeePO when probing noise is not added: the convergence of states to the equilibrium point, and the convergence of the controller to its optimal value. To address these challenges without relying on probing noise, we propose Perturbation-Free DeePO (PFDeePO) built on two fundamental principles. First, the algorithm pauses the control gain updating in DeePO process when system states are near the equilibrium point. Second, it applies a multiplicative noise, scaled by a mean value of $1$ as a gain for the control signal, when the controller converges. This approach minimizes the impact of noise as the system approaches equilibrium while preserving stability. We demonstrate the effectiveness of PFDeePO through simulations, showcasing its ability to eliminate state perturbations while maintaining system performance and stability.

Paper number 49:
Title: Real-Time Distributed Optical Fiber Vibration Recognition via Extreme Lightweight Model and Cross-Domain Distillation
Authors: Zhongyao Luo, Hao Wu, Zhao Ge, Ming Tang
Abstract: Distributed optical fiber vibration sensing (DVS) systems offer a promising solution for large-scale monitoring and intrusion event recognition. However, their practical deployment remains hindered by two major challenges: degradation of recognition accuracy in dynamic conditions, and the computational bottleneck of real-time processing for mass sensing data. This paper presents a new solution to these challenges, through a FPGA-accelerated extreme lightweight model along with a newly proposed knowledge distillation framework. The proposed three-layer depthwise separable convolution network contains only 4141 parameters, which is the most compact architecture in this field to date, and achieves a maximum processing speed of 0.019 ms for each sample covering a 12.5 m fiber length over 0.256 s. This performance corresponds to real-time processing capabilities for sensing fibers extending up to 168.68 km. To improve generalizability under changing environments, the proposed cross-domain distillation framework guided by physical priors is used here to embed frequency-domain insights into the time-domain model. This allows for time-frequency representation learning without increasing complexity and boosts recognition accuracy from 51.93% to 95.72% under unseen environmental conditions. The proposed methodology provides key advancements including a framework combining interpretable signal processing technique with deep learning and a reference architecture for real-time processing and edge-computing in DVS systems, and more general distributed optical fiber sensing (DOFS) area. It mitigates the trade-off between sensing range and real-time capability, bridging the gap between theoretical capabilities and practical deployment requirements. Furthermore, this work reveals a new direction for building more efficient, robust and explainable artificial intelligence systems for DOFS technologies.

Paper number 50:
Title: Sequential Operation of Residential Energy Hubs
Authors: Darío Slaifstein (1), Gautham Ram Chandra Mouli (1), Laura Ramirez-Elizondo (1), Pavol Bauer (1) ((1) Delft University of Technology)
Abstract: The operation of residential energy hubs with multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to different carrier dynamics, hybrid storage coordination and high-dimensional action-spaces. Energy management systems oversee their operation, deciding the set points of the primary control layer. This paper presents a novel 2-stage economic model predictive controller for electrified buildings including physics-based models of the battery degradation and thermal systems. The hierarchical control operates in the Dutch sequential energy markets. In particular common assumptions regarding intra-day markets (auction and continuous-time) are discussed as well as the coupling of the different storage systems. The best control policy is to co-optimize day-ahead and intra-day auctions in the first stage, to later follow intra-day auctions. If no intra-day prices are known at the time of the day-ahead auction, its best to follow continuous time intra-day in the summer and the intra-day auction in the winter. Additionally, this sequential operation increases battery degradation. Finally, under our controller the realized short-term flexibility of the thermal energy storage is marginal compared to the flexibility delivered by static battery pack and electric vehicles with bidirectional charging.

Paper number 51:
Title: Convergent Weight and Activation Dynamics in Memristor Neural Networks
Authors: Mauro Di Marco, Mauro Forti, Luca Pancioni, Giacomo Innocenti, Alberto Tesi
Abstract: Convergence of dynamic feedback neural networks (NNs), as the Cohen-Grossberg, Hopfield and cellular NNs, has been for a long time a workhorse of NN theory. Indeed, convergence in the presence of multiple stable equilibrium points (EPs) is crucial to implement content addressable memories and solve several other signal processing tasks in real time. There are two typical ways to use a convergent NN, i.e.: a) let the activations evolve while maintaining fixed weights and inputs (activation dynamics) or b) adapt the weights while maintaining fixed activations (weight dynamics). As remarked in a seminal paper by Hirsch, there is another interesting possibility, i.e., let the neuron interconnection weights evolve while simultaneously running the activation dynamics (weight-activation dynamics). The weight-activation dynamics is of importance also because it is more plausible than the other two types for modeling neural systems. The paper breaks new ground by analyzing for the first time in a systematic way the convergence properties of the weight-activation dynamics for a class of memristor feedback dynamic NNs. The main result is that, under suitable assumptions on the structure of the memristor interconnections, the solutions (weights and activations) converge to an EP, except at most for a set of initial conditions with zero measure. The result includes the most important case where the NN has multiple stable EPs.

Paper number 52:
Title: RFI and Jamming Detection in Antenna Arrays with an LSTM Autoencoder
Authors: Christos Ntemkas, Antonios Argyriou
Abstract: Radio frequency interference (RFI) and malicious jammers are a significant problem in our wireless world. De- tecting RFI or jamming is typically performed with model-based statistical detection or AI-empowered algorithms that use an input baseband data or time-frequency representations like spectrograms. In this work we depart from the previous approaches and we leverage data in antenna array systems. We use Fourier imaging to localize spatially the sources and then deploy a deep LSTM autoencoder that detects RFI and jamming as anomalies. Our results for different power levels of the RFI/jamming sources, and the signal of interest, reveal that our detector offers high performance without needing any pre-existing knowledge regarding the RFI or jamming signal.

Paper number 53:
Title: Angle-distance decomposition based on deep learning for active sonar detection
Authors: Jichao Zhang, Xiao-Lei Zhang, Kunde Yang
Abstract: Underwater target detection using active sonar constitutes a critical research area in marine sciences and engineering. However, traditional signal processing methods face significant challenges in complex underwater environments due to noise, reverberation, and interference. To address these issues, this paper presents a deep learning-based active sonar target detection method that decomposes the detection process into separate angle and distance estimation tasks. Active sonar target detection employs deep learning models to predict target distance and angle, with the final target position determined by integrating these estimates. Limited underwater acoustic data hinders effective model training, but transfer learning and simulation offer practical solutions to this challenge. Experimental results verify that the method achieves effective and robust performance under challenging conditions.

Paper number 54:
Title: The micro-Doppler Attack Against AI-based Human Activity Classification from Wireless Signals
Authors: Margarita Loupa, Antonios Argyriou, Yanwei Liu
Abstract: A subset of Human Activity Classification (HAC) systems are based on AI algorithms that use passively collected wireless signals. This paper presents the micro-Doppler attack targeting HAC from wireless orthogonal frequency division multiplexing (OFDM) signals. The attack is executed by inserting artificial variations in a transmitted OFDM waveform to alter its micro-Doppler signature when it reflects off a human target. We investigate two variants of our scheme that manipulate the waveform at different time scales resulting in altered receiver spectrograms. HAC accuracy with a deep convolutional neural network (CNN) can be reduced to less than 10%.

Paper number 55:
Title: A Nonlinear Spectral Approach for Radar-Based Heartbeat Estimation via Autocorrelation of Higher Harmonics
Authors: Kohei Shimomura, Chi-Hsuan Lee, Takuya Sakamoto
Abstract: This study presents a nonlinear signal processing method for accurate radar-based heartbeat interval estimation by exploiting the periodicity of higher-order harmonics inherent in heartbeat signals. Unlike conventional approaches that employ selective frequency filtering or track individual harmonics, the proposed method enhances the global periodic structure of the spectrum via nonlinear correlation processing. Specifically, smoothing and second-derivative operations are first applied to the radar displacement signal to suppress noise and accentuate higher-order heartbeat harmonics. Rather than isolating specific frequency components, we compute localized autocorrelations of the Fourier spectrum around the harmonic frequencies. The incoherent summation of these autocorrelations yields a pseudo-spectrum in which the fundamental heartbeat periodicity is distinctly emphasized. This nonlinear approach mitigates the effects of respiratory harmonics and noise, enabling robust interbeat interval estimation. Experiments with radar measurements from five participants demonstrate that the proposed method reduces root-mean-square error by 20% and improves the correlation coefficient by 0.20 relative to conventional techniques.

Paper number 56:
Title: MIMII-Agent: Leveraging LLMs with Function Calling for Relative Evaluation of Anomalous Sound Detection
Authors: Harsh Purohit, Tomoya Nishida, Kota Dohi, Takashi Endo, Yohei Kawaguchi
Abstract: This paper proposes a method for generating machine-type-specific anomalies to evaluate the relative performance of unsupervised anomalous sound detection (UASD) systems across different machine types, even in the absence of real anomaly sound data. Conventional keyword-based data augmentation methods often produce unrealistic sounds due to their reliance on manually defined labels, limiting scalability as machine types and anomaly patterns diversify. Advanced audio generative models, such as MIMII-Gen, show promise but typically depend on anomalous training data, making them less effective when diverse anomalous examples are unavailable. To address these limitations, we propose a novel synthesis approach leveraging large language models (LLMs) to interpret textual descriptions of faults and automatically select audio transformation functions, converting normal machine sounds into diverse and plausible anomalous sounds. We validate this approach by evaluating a UASD system trained only on normal sounds from five machine types, using both real and synthetic anomaly data. Experimental results reveal consistent trends in relative detection difficulty across machine types between synthetic and real anomalies. This finding supports our hypothesis and highlights the effectiveness of the proposed LLM-based synthesis approach for relative evaluation of UASD systems.

Paper number 57:
Title: SNR Optimization for Common Emitter Amplifier
Authors: Orhan Gazi
Abstract: In this paper we investigate the effects of the thermal noise of the base resistance of common emitter amplifier (CEA) on the output SNR, and we show that a first order Butterworth filter at the output of the CEA significantly improves output SNR significantly and supress the performances of higher order Butterworth, Chebyshev I, II and elliptic filters. We propose a formula for the selection of cut-off frequency of analog filters for given orders to achieve significant SNR improvement at CEA output. Considering the filter complexity and output SNR improvement, we can conclude that the first order Butterworth filter outperforms Chebyshev I, II and elliptic filters.

Paper number 58:
Title: What's Really Different with AI? -- A Behavior-based Perspective on System Safety for Automated Driving Systems
Authors: Marcus Nolte, Nayel Fabian Salem, Olaf Franke, Jan Heckmann, Christoph Höhmann, Georg Stettinger, Markus Maurer
Abstract: Assuring safety for ``AI-based'' systems is one of the current challenges in safety engineering. For automated driving systems, in particular, further assurance challenges result from the open context that the systems need to operate in after deployment. The current standardization and regulation landscape for ``AI-based'' systems is becoming ever more complex, as standards and regulations are being released at high frequencies. This position paper seeks to provide guidance for making qualified arguments which standards should meaningfully be applied to (``AI-based'') automated driving systems. Furthermore, we argue for clearly differentiating sources of risk between AI-specific and general uncertainties related to the open context. In our view, a clear conceptual separation can help to exploit commonalities that can close the gap between system-level and AI-specific safety analyses, while ensuring the required rigor for engineering safe ``AI-based'' systems.

Paper number 59:
Title: Efficient Adjoint Petrov-Galerkin Reduced Order Models for fluid flows governed by the incompressible Navier-Stokes equations
Authors: Kamil David Sommer, Lucas Mieg, Siddharth Sharma, Romuald Skoda, Martin Mönnigmann
Abstract: This research paper investigates the Adjoint Petrov-Galerkin (APG) method for reduced order models (ROM) and fluid dynamics governed by the incompressible Navier-Stokes equations. The Adjoint Petrov-Galerkin ROM, derived using the Mori-Zwanzig formalism, demonstrates superior accuracy and stability compared to standard Galerkin ROMs. However, challenges arise due to the time invariance of the test basis vectors, resulting in high computational requirements. To address this, we introduce a new efficient Adjoint Petrov-Galerkin (eAPG) ROM formulation, extending its application to the incompressible Navier-Stokes equations by exploiting the polynomial structure inherent in these equations. The offline and online phases partition eliminates the need for repeated test basis vector evaluations. This improves computational efficiency in comparison to the general Adjoint Petrov-Galerkin ROM formulation. A novel approach to augmenting the memory length, a critical factor influencing the stability and accuracy of the APG-ROM, is introduced, employing a data-driven optimization. Numerical results for the 3D turbulent flow around a circular cylinder demonstrate the efficacy of the proposed approach. Error measures and computational cost evaluations, considering metrics such as floating point operations and simulation time, provide a comprehensive analysis.

Paper number 60:
Title: Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network
Authors: Davide Piccinini, Diego Valsesia, Enrico Magli
Abstract: Hyperspectral imagers on satellites obtain the fine spectral signatures essential for distinguishing one material from another at the expense of limited spatial resolution. Enhancing the latter is thus a desirable preprocessing step in order to further improve the detection capabilities offered by hyperspectral images on downstream tasks. At the same time, there is a growing interest towards deploying inference methods directly onboard of satellites, which calls for lightweight image super-resolution methods that can be run on the payload in real time. In this paper, we present a novel neural network design, called Deep Pushbroom Super-Resolution (DPSR) that matches the pushbroom acquisition of hyperspectral sensors by processing an image line by line in the along-track direction with a causal memory mechanism to exploit previously acquired lines. This design greatly limits memory requirements and computational complexity, achieving onboard real-time performance, i.e., the ability to super-resolve a line in the time it takes to acquire the next one, on low-power hardware. Experiments show that the quality of the super-resolved images is competitive or even outperforms state-of-the-art methods that are significantly more complex.

Paper number 61:
Title: Beyond Line-of-Sight: Cooperative Localization Using Vision and V2X Communication
Authors: Annika Wong, Zhiqi Tang, Frank J. Jiang, Karl H. Johansson, Jonas Mårtensson
Abstract: Accurate and robust localization is critical for the safe operation of Connected and Automated Vehicles (CAVs), especially in complex urban environments where Global Navigation Satellite System (GNSS) signals are unreliable. This paper presents a novel vision-based cooperative localization algorithm that leverages onboard cameras and Vehicle-to-Everything (V2X) communication to enable CAVs to estimate their poses, even in occlusion-heavy scenarios such as busy intersections. In particular, we propose a novel decentralized observer for a group of connected agents that includes landmark agents (static or moving) in the environment with known positions and vehicle agents that need to estimate their poses (both positions and orientations). Assuming that (i) there are at least three landmark agents in the environment, (ii) each vehicle agent can measure its own angular and translational velocities as well as relative bearings to at least three neighboring landmarks or vehicles, and (iii) neighboring vehicles can communicate their pose estimates, each vehicle can estimate its own pose using the proposed decentralized observer. We prove that the origin of the estimation error is locally exponentially stable under the proposed observer, provided that the minimal observability conditions are satisfied. Moreover, we evaluate the proposed approach through experiments with real 1/10th-scale connected vehicles and large-scale simulations, demonstrating its scalability and validating the theoretical guarantees in practical scenarios.

Paper number 62:
Title: DT-Aided Resource Management in Spectrum Sharing Integrated Satellite-Terrestrial Networks
Authors: Hung Nguyen-Kha, Vu Nguyen Ha, Ti Ti Nguyen, Eva Lagunas, Symeon Chatzinotas, Joel Grotz
Abstract: The integrated satellite-terrestrial networks (ISTNs) through spectrum sharing have emerged as a promising solution to improve spectral efficiency and meet increasing wireless demand. However, this coexistence introduces significant challenges, including inter-system interference (ISI) and the low Earth orbit satellite (LSat) movements. To capture the actual environment for resource management, we propose a time-varying digital twin (DT)-aided framework for ISTNs incorporating 3D map that enables joint optimization of bandwidth (BW) allocation, traffic steering, and resource allocation, and aims to minimize congestion. The problem is formulated as a mixed-integer nonlinear programming (MINLP), addressed through a two-phase algorithm based on successive convex approximation (SCA) and compressed sensing approaches. Numerical results demonstrate the proposed method's superior performance in queue length minimization compared to benchmarks.

Paper number 63:
Title: UAV-Borne Digital Radar System for Coherent Multistatic SAR Imaging
Authors: Julian Kanz, Christian Gesell, Christina Bonfert, David Werbunat, Alexander Grathwohl, Julian Aguilar, Martin Vossiek, Christian Waldschmidt
Abstract: Advancements in analog-to-digital converter (ADC) technology have enabled higher sampling rates, making it feasible to adopt digital radar architectures that directly sample the radio-frequency (RF) signal, eliminating the need for analog downconversion. This digital approach supports greater flexibility in waveform design and signal processing, particularly through digital modulation schemes like orthogonal frequency division multiplexing (OFDM). This paper presents a digital radar system mounted on an uncrewed aerial vehicle (UAV), which employs OFDM waveforms for coherent multistatic synthetic aperture radar (SAR) imaging in the L-band. The radar setup features a primary UAV node responsible for signal transmission and monostatic data acquisition, alongside secondary nodes that operate in a receive-only mode. These secondary nodes capture the radar signal reflected from the scene as well as a direct sidelink signal. RF signals from both the radar and sidelink paths are sampled and processed offline. To manage data storage efficiently, a trigger mechanism is employed to record only the relevant portions of the radar signal. The system maintains coherency in both fast-time and slow-time domains, which is essential for multistatic SAR imaging. Because the secondary nodes are passive, the system can be easily scaled to accommodate a larger swarm of UAVs. The paper details the full signal processing workflow for both monostatic and multistatic SAR image formation, including an analysis and correction of synchronization errors that arise from the uncoupled operation of the nodes. The proposed coherent processing method is validated through static radar measurements, demonstrating coherency achieved by the concept. Additionally, a UAV-based bistatic SAR experiment demonstrates the system's performance by producing high-resolution monostatic, bistatic, and combined multistatic SAR images.

Paper number 64:
Title: Chirp-Permuted AFDM: A New Degree of Freedom for Next-Generation Versatile Waveform Design
Authors: Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu
Abstract: We present a novel multicarrier waveform, termed chirp-permuted affine frequency division multiplexing (CP-AFDM), which introduces a unique chirp-permutation domain on top of the chirp subcarriers of the conventional AFDM. Rigorous analysis of the signal model and waveform properties, supported by numerical simulations, demonstrates that the proposed CP-AFDM preserves all core characteristics of affine frequency division multiplexing (AFDM) - including robustness to doubly-dispersive channels, peak-to-average power ratio (PAPR), and full delay-Doppler representation - while further enhancing ambiguity function resolution and peak-to-sidelobe ratio (PSLR) in the Doppler domain. These improvements establish CP-AFDM as a highly attractive candidate for emerging sixth generation (6G) use cases demanding both reliability and sensing-awareness. Moreover, by exploiting the vast degree of freedom in the chirp-permutation domain, two exemplary multifunctional applications are introduced: an index modulation (IM) technique over the permutation domain which achieves significant spectral efficiency gains, and a physical-layer security scheme that ensures practically perfect security through permutation-based keying, without requiring additional transmit energy or signaling overhead.

Paper number 65:
Title: Minimum Attention Control (MAC) in a Receding Horizon Framework with Applications
Authors: T. Ganesh Teja, Santhosh Kumar Varanasi, Phanindra Jampana
Abstract: Minimum Attention Control (MAC) is a control technique that provides minimal input changes to meet the control objective. Mathematically, the zero norm of the input changes is used as a constraint for the given control objective and minimized with respect to the process dynamics. In this paper, along with the zero norm constraint, stage costs are also considered for reference tracking in a receding horizon framework. For this purpose, the optimal inputs of the previous horizons are also considered in the optimization problem of the current horizon. An alternating minimization algorithm is applied to solve the optimization problem (Minimum Attention Model Predictive Control (MAMPC)). The outer step of the optimization is a quadratic program, while the inner step, which solves for sparsity, has an analytical solution. The proposed algorithm is implemented on two case studies: a four-tank system with slow dynamics and a fuel cell stack with fast dynamics. A detailed comparative study of the proposed algorithm with standard MPC indicates sparse control actions with a tradeoff in the tracking error.

Paper number 66:
Title: dq Modeling for Series-Parallel Compensated Wireless Power Transfer Systems
Authors: Zixuan Jiang
Abstract: Series-parallel (SP) compensated wireless power transfer (WPT) systems are widely used in some specific scenarios, such as bioelectronics and portable electronics. However, most studies are based on the phasor method and focused on the steady-state analysis, which may overlook the transient process of systems. Accordingly, inspired by the notion of coordinate transformation in the field of motor drive, this work develops a dq modeling method for SP compensated WPT systems. The proposed model effectively characterizes first-order system dynamics, facilitating enhanced measurement precision and control system development. One measurement application, dq model-based mutual inductance identification, is presented to reflect the value of the dq model. Simulation results are shown to validate the model's effectiveness, indicating that the developed model can be a good tool for the design of SP compensated WPT systems.

Paper number 67:
Title: End-to-End DOA-Guided Speech Extraction in Noisy Multi-Talker Scenarios
Authors: Kangqi Jing, Wenbin Zhang, Yu Gao
Abstract: Target Speaker Extraction (TSE) plays a critical role in enhancing speech signals in noisy and multi-speaker environments. This paper presents an end-to-end TSE model that incorporates Direction of Arrival (DOA) and beamwidth embeddings to extract speech from a specified spatial region centered around the DOA. Our approach efficiently captures spatial and temporal features, enabling robust performance in highly complex scenarios with multiple simultaneous speakers. Experimental results demonstrate that the proposed model not only significantly enhances the target speech within the defined beamwidth but also effectively suppresses interference from other directions, producing a clear and isolated target voice. Furthermore, the model achieves remarkable improvements in downstream Automatic Speech Recognition (ASR) tasks, making it particularly suitable for real-world applications.

Paper number 68:
Title: Interference Analysis and Successive Interference Cancellation for Multistatic OFDM-based ISAC Systems
Authors: Taewon Jeong, Lucas Giroto, Umut Utku Erdem, Christian Karle, Jiyeon Choi, Thomas Zwick, Benjamin Nuss
Abstract: Multistatic integrated sensing and communications (ISAC) systems, which use distributed transmitters and receivers, offer enhanced spatial coverage and sensing accuracy compared to stand-alone ISAC configurations. However, these systems face challenges due to interference between co-existing ISAC nodes, especially during simultaneous operation. In this paper, we analyze the impact of this mutual interference arising from the co-existence in a multistatic ISAC scenario, where a mono- and a bistatic ISAC system share the same spectral resources. We first classify differenct types of interference in the power domain. Then, we discuss how the interference can affect both sensing and communications in terms of bit error rate (BER), error vector magnitude (EVM), and radar image under varied transmit power and RCS configurations through simulations. Along with interfernce analysis, we propose a low-complexity successive interference cancellation method that adaptively cancels either the monostatic reflection or the bistatic line-of-sight signal based on a monostatic radar image signal-to-interference-plus-noise ratio (SINR). The proposed framework is evaluated with both simulations and proof-of-concept measurements using an ISAC testbed with a radar echo generator for object emulation. The results have shown that the proposed method reduces BER and improves EVM as well as radar image SINR across a wide range of SINR conditions. These results demonstrate that accurate component-wise cancellation can be achieved with low computational overhead, making the method suitable for practical applications.

Paper number 69:
Title: Analytical Modeling of Batteryless IoT Sensors Powered by Ambient Energy Harvesting
Authors: Jimmy Fernandez Landivar, Andrea Zanella, Ihsane Gryech, Sofie Pollin, Hazem Sallouha
Abstract: This paper presents a comprehensive mathematical model to characterize the energy dynamics of batteryless IoT sensor nodes powered entirely by ambient energy harvesting. The model captures both the energy harvesting and consumption phases, explicitly incorporating power management tasks to enable precise estimation of device behavior across diverse environmental conditions. The proposed model is applicable to a wide range of IoT devices and supports intelligent power management units designed to maximize harvested energy under fluctuating environmental conditions. We validated our model against a prototype batteryless IoT node, conducting experiments under three distinct illumination scenarios. Results show a strong correlation between analytical and measured supercapacitor voltage profiles, confirming the proposed model's accuracy.

Paper number 70:
Title: A lightweight numerical model for predictive control of borehole thermal energy storages
Authors: Johannes van Randenborgh, Steffen Daniel, Moritz Schulze Darup
Abstract: Borehole thermal energy storage (BTES) can reduce the operation of fossil fuel-based heating, ventilation, and air conditioning systems for buildings. With BTES, thermal energy is stored via a borehole heat exchanger in the ground. Model predictive control (MPC) may maximize the use of BTES by achieving a dynamic interaction between the building and BTES. However, modeling BTES for MPC is challenging, and a trade-off between model accuracy and an easy-to-solve optimal control problem (OCP) must be found. This manuscript presents an accurate numerical model yielding an easy-to-solve linear-quadratic OCP.

Paper number 71:
Title: From Bench to Bedside: A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice
Authors: Yaowei Bai, Ruiheng Zhang, Yu Lei, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Xuhua Duan, Xinggang Wang, Tao Sun, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du
Abstract: A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT06874647). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating robust detection of eight clinically critical radiographic findings (area under the curve, AUC > 0.8). Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores (4.37 vs. 4.11, P < 0.001), reduced interpretation time by 18.5% (P < 0.001), and was preferred by a majority of experts (3 out of 5) in 52.7% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.

Paper number 72:
Title: Joint Feature and Output Distillation for Low-complexity Acoustic Scene Classification
Authors: Haowen Li, Ziyi Yang, Mou Wang, Ee-Leng Tan, Junwei Yeow, Santi Peksi, Woon-Seng Gan
Abstract: This report presents a dual-level knowledge distillation framework with multi-teacher guidance for low-complexity acoustic scene classification (ASC) in DCASE2025 Task 1. We propose a distillation strategy that jointly transfers both soft logits and intermediate feature representations. Specifically, we pre-trained PaSST and CP-ResNet models as teacher models. Logits from teachers are averaged to generate soft targets, while one CP-ResNet is selected for feature-level distillation. This enables the compact student model (CP-Mobile) to capture both semantic distribution and structural information from teacher guidance. Experiments on the TAU Urban Acoustic Scenes 2022 Mobile dataset (development set) demonstrate that our submitted systems achieve up to 59.30\% accuracy.

Paper number 73:
Title: DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference
Authors: Jiawen Qi, Chang Gao, Zhaochun Ren, Qinyu Chen
Abstract: Deploying Large Language Models (LLMs) on edge devices remains challenging due to their quadratically increasing computations with the sequence length. Existing studies for dynamic attention pruning are designed for hardware with massively parallel computation capabilities, such as GPUs or TPUs, and aim at long context lengths (e.g., 64K), making them unsuitable for edge scenarios. We present DeltaLLM, a training-free framework that exploits temporal sparsity in attention patterns to enable efficient LLM inference across both the prefilling and decoding stages, on resource-constrained edge devices. DeltaLLM introduces an accuracy- and memory-aware delta matrix construction strategy that introduces temporal sparsity, and a context-aware hybrid attention mechanism that combines full attention in a local context window with delta approximation outside it to increase accuracy. We evaluate our framework on the edge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model across diverse language tasks. The results show that on BitNet, our framework increases the attention sparsity from 0% to 60% during the prefilling stage with slight accuracy improvement on the WG task, and 0% to 57% across both the prefilling and decoding stages, with even higher F1 score from 29.63 to 30.97 on SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity during the prefilling stage and around 57% across both stages with negligible accuracy drop. These results demonstrate that DeltaLLM offers a promising solution for efficient edge deployment, requiring no fine-tuning and seamlessly integrating with existing inference pipelines.

Paper number 74:
Title: Long-Duration Station-Keeping Strategy for Cislunar Spacecraft Formations
Authors: Ethan Foss, Yuji Takubo, Simone D'Amico
Abstract: This paper demonstrates a novel guidance and control strategy for cislunar near-rectilinear halo orbit formation-keeping applied to high-fidelity dynamics. Bounded relative motion is constructed about long-duration ephemeris trajectories with osculating invariant circles to form quasi-periodic relative orbits. State-of-the-art absolute control strategies are paired with a simple and effective relative control feedback law. Finally, a control barrier function is implemented to ensure recursively passively-safe bounded relative motion under feedback in the presence of possible missed maneuver events for the duration of the formation flight. The strategy is verified in high-fidelity simulation environments through Monte Carlo trials.

Paper number 75:
Title: Reward-Augmented Reinforcement Learning for Continuous Control in Precision Autonomous Parking via Policy Optimization Methods
Authors: Ahmad Suleman, Misha Urooj Khan, Zeeshan Kaleem, Ali H. Alenezi, Iqra Shabbir Sinem Coleri, Chau Yuen
Abstract: Autonomous parking (AP) represents a critical yet complex subset of intelligent vehicle automation, characterized by tight spatial constraints, frequent close-range obstacle interactions, and stringent safety margins. However, conventional rule-based and model-predictive methods often lack the adaptability and generalization needed to handle the nonlinear and environment-dependent complexities of AP. To address these limitations, we propose a reward-augmented learning framework for AP (RARLAP), that mitigates the inherent complexities of continuous-domain control by leveraging structured reward design to induce smooth and adaptable policy behavior, trained entirely within a high-fidelity Unity-based custom 3D simulation environment. We systematically design and assess three structured reward strategies: goal-only reward (GOR), dense proximity reward (DPR), and milestone-augmented reward (MAR), each integrated with both on-policy and off-policy optimization paradigms. Empirical evaluations demonstrate that the on-policy MAR achieves a 91\% success rate, yielding smoother trajectories and more robust behavior, while GOR and DPR fail to guide effective learning. Convergence and trajectory analyses demonstrate that the proposed framework enhances policy adaptability, accelerates training, and improves safety in continuous control. Overall, RARLAP establishes that reward augmentation effectively addresses complex autonomous parking challenges, enabling scalable and efficient policy optimization with both on- and off-policy methods. To support reproducibility, the code accompanying this paper is publicly available.

Paper number 76:
Title: RAKOMO: Reachability-Aware K-Order Markov Path Optimization for Quadrupedal Loco-Manipulation
Authors: Mattia Risiglione, Abdelrahman Abdalla, Victor Barasuol, Kim Tien Ly, Ioannis Havoutis, Claudio Semini
Abstract: Legged manipulators, such as quadrupeds equipped with robotic arms, require motion planning techniques that account for their complex kinematic constraints in order to perform manipulation tasks both safely and effectively. However, trajectory optimization methods often face challenges due to the hybrid dynamics introduced by contact discontinuities, and tend to neglect leg limitations during planning for computational reasons. In this work, we propose RAKOMO, a path optimization technique that integrates the strengths of K-Order Markov Optimization (KOMO) with a kinematically-aware criterion based on the reachable region defined as reachability margin. We leverage a neural-network to predict the margin and optimize it by incorporating it in the standard KOMO formulation. This approach enables rapid convergence of gradient-based motion planning -- commonly tailored for continuous systems -- while adapting it effectively to legged manipulators, successfully executing loco-manipulation tasks. We benchmark RAKOMO against a baseline KOMO approach through a set of simulations for pick-and-place tasks with the HyQReal quadruped robot equipped with a Kinova Gen3 robotic arm.

Paper number 77:
Title: LowKeyEMG: Electromyographic typing with a reduced keyset
Authors: Johannes Y. Lee, Derek Xiao, Shreyas Kaasyap, Nima R. Hadidi, John L. Zhou, Jacob Cunningham, Rakshith R. Gore, Deniz O. Eren, Jonathan C. Kao
Abstract: We introduce LowKeyEMG, a real-time human-computer interface that enables efficient text entry using only 7 gesture classes decoded from surface electromyography (sEMG). Prior work has attempted full-alphabet decoding from sEMG, but decoding large character sets remains unreliable, especially for individuals with motor impairments. Instead, LowKeyEMG reduces the English alphabet to 4 gesture keys, with 3 more for space and system interaction, to reliably translate simple one-handed gestures into text, leveraging the recurrent transformer-based language model RWKV for efficient computation. In real-time experiments, participants achieved average one-handed keyboardless typing speeds of 23.3 words per minute with LowKeyEMG, and improved gesture efficiency by 17% (relative to typed phrase length). When typing with only 7 keys, LowKeyEMG can achieve 98.2% top-3 word accuracy, demonstrating that this low-key typing paradigm can maintain practical communication rates. Our results have implications for assistive technologies and any interface where input bandwidth is constrained.

Paper number 78:
Title: DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning
Authors: Yanbin Li, Canran Xiao, Hongyang He, Shenghai Yuan, Zong Ke, Jiajie Yu, Zixiong Qin, Zhiguo Zhang, Wenzheng Chi, Wei Zhang
Abstract: Particle filter-based 2D-SLAM is widely used in indoor localization tasks due to its efficiency. However, indoor environments such as long straight corridors can cause severe degeneracy problems in SLAM. In this paper, we use Proximal Policy Optimization (PPO) to train an adaptive degeneracy optimization agent (DOA) to address degeneracy problem. We propose a systematic methodology to address three critical challenges in traditional supervised learning frameworks: (1) data acquisition bottlenecks in degenerate dataset, (2) inherent quality deterioration of training samples, and (3) ambiguity in annotation protocol design. We design a specialized reward function to guide the agent in developing perception capabilities for degenerate environments. Using the output degeneracy factor as a reference weight, the agent can dynamically adjust the contribution of different sensors to pose optimization. Specifically, the observation distribution is shifted towards the motion model distribution, with the step size determined by a linear interpolation formula related to the degeneracy factor. In addition, we employ a transfer learning module to endow the agent with generalization capabilities across different environments and address the inefficiency of training in degenerate environments. Finally, we conduct ablation studies to demonstrate the rationality of our model design and the role of transfer learning. We also compare the proposed DOA with SOTA methods to prove its superior degeneracy detection and optimization capabilities across various environments.

Paper number 79:
Title: Debunking Optimization Myths in Federated Learning for Medical Image Classification
Authors: Youngjoon Lee, Hyukjoon Lee, Jinu Gong, Yang Cao, Joonhyuk Kang
Abstract: Federated Learning (FL) is a collaborative learning method that enables decentralized model training while preserving data privacy. Despite its promise in medical imaging, recent FL methods are often sensitive to local factors such as optimizers and learning rates, limiting their robustness in practical deployments. In this work, we revisit vanilla FL to clarify the impact of edge device configurations, benchmarking recent FL methods on colorectal pathology and blood cell classification task. We numerically show that the choice of local optimizer and learning rate has a greater effect on performance than the specific FL method. Moreover, we find that increasing local training epochs can either enhance or impair convergence, depending on the FL method. These findings indicate that appropriate edge-specific configuration is more crucial than algorithmic complexity for achieving effective FL.

Paper number 80:
Title: Feeling the Force: A Nuanced Physics-based Traversability Sensor for Navigation in Unstructured Vegetation
Authors: Zaar Khizar, Johann Laconte, Roland Lenain, Romuald Aufrere
Abstract: In many applications, robots are increasingly deployed in unstructured and natural environments where they encounter various types of vegetation. Vegetation presents unique challenges as a traversable obstacle, where the mechanical properties of the plants can influence whether a robot can safely collide with and overcome the obstacle. A more nuanced approach is required to assess the safety and traversability of these obstacles, as collisions can sometimes be safe and necessary for navigating through dense or unavoidable vegetation. This paper introduces a novel sensor designed to directly measure the applied forces exerted by vegetation on a robot: by directly capturing the push-back forces, our sensor provides a detailed understanding of the interactions between the robot and its surroundings. We demonstrate the sensor's effectiveness through experimental validations, showcasing its ability to measure subtle force variations. This force-based approach provides a quantifiable metric that can inform navigation decisions and serve as a foundation for developing future learning algorithms.

Paper number 81:
Title: VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets
Authors: Biswarup Mukherjee, Li Zhou, S. Gokul Krishnan, Milad Kabirifar, Subhash Lakshminarayana, Charalambos Konstantinou
Abstract: This paper introduces a model for coordinating prosumers with heterogeneous distributed energy resources (DERs), participating in the local energy market (LEM) that interacts with the market-clearing entity. The proposed LEM scheme utilizes a data-driven, model-free reinforcement learning approach based on the multi-agent deep deterministic policy gradient (MADDPG) framework, enabling prosumers to make real-time decisions on whether to buy, sell, or refrain from any action while facilitating efficient coordination for optimal energy trading in a dynamic market. In addition, we investigate a price manipulation strategy using a variational auto encoder-generative adversarial network (VAE-GAN) model, which allows utilities to adjust price signals in a way that induces financial losses for the prosumers. Our results show that under adversarial pricing, heterogeneous prosumer groups, particularly those lacking generation capabilities, incur financial losses. The same outcome holds across LEMs of different sizes. As the market size increases, trading stabilizes and fairness improves through emergent cooperation among agents.

Paper number 82:
Title: Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control
Authors: Haoze Dong, Meng Guo, Chengyi He, Zhongkui Li
Abstract: Multi-agent trajectory planning requires ensuring both safety and efficiency, yet deadlocks remain a significant challenge, especially in obstacle-dense environments. Such deadlocks frequently occur when multiple agents attempt to traverse the same long and narrow corridor simultaneously. To address this, we propose a novel distributed trajectory planning framework that bridges the gap between global path and local trajectory cooperation. At the global level, a homotopy-aware optimal path planning algorithm is proposed, which fully leverages the topological structure of the environment. A reference path is chosen from distinct homotopy classes by considering both its spatial and temporal properties, leading to improved coordination among agents globally. At the local level, a model predictive control-based trajectory optimization method is used to generate dynamically feasible and collision-free trajectories. Additionally, an online replanning strategy ensures its adaptability to dynamic environments. Simulations and experiments validate the effectiveness of our approach in mitigating deadlocks. Ablation studies demonstrate that by incorporating time-aware homotopic properties into the underlying global paths, our method can significantly reduce deadlocks and improve the average success rate from 4%-13% to over 90% in randomly generated dense scenarios.

Paper number 83:
Title: Adaptive Learned Belief Propagation for Decoding Error-Correcting Codes
Authors: Alireza Tasdighi, Mansoor Yousefi
Abstract: Weighted belief propagation (WBP) for the decoding of linear block codes is considered. In WBP, the Tanner graph of the code is unrolled with respect to the iterations of the belief propagation decoder. Then, weights are assigned to the edges of the resulting recurrent network and optimized offline using a training dataset. The main contribution of this paper is an adaptive WBP where the weights of the decoder are determined for each received word. Two variants of this decoder are investigated. In the parallel WBP decoders, the weights take values in a discrete set. A number of WBP decoders are run in parallel to search for the best sequence- of weights in real time. In the two-stage decoder, a small neural network is used to dynamically determine the weights of the WBP decoder for each received word. The proposed adaptive decoders demonstrate significant improvements over the static counterparts in two applications. In the first application, Bose--Chaudhuri--Hocquenghem, polar and quasi-cyclic low-density parity-check (QC-LDPC) codes are used over an additive white Gaussian noise channel. The results indicate that the adaptive WBP achieves bit error rates (BERs) up to an order of magnitude less than the BERs of the static WBP at about the same decoding complexity, depending on the code, its rate, and the signal-to-noise ratio. The second application is a concatenated code designed for a long-haul nonlinear optical fiber channel where the inner code is a QC-LDPC code and the outer code is a spatially coupled LDPC code. In this case, the inner code is decoded using an adaptive WBP, while the outer code is decoded using the sliding window decoder and static belief propagation. The results show that the adaptive WBP provides a coding gain of 0.8 dB compared to the neural normalized min-sum decoder, with about the same computational complexity and decoding latency.

Paper number 84:
Title: Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations
Authors: Supawich Sitdhipol, Waritwong Sukprasongdee, Ekapol Chuangsuwanich, Rina Tse
Abstract: Fusing information from human observations can help robots overcome sensing limitations in collaborative tasks. However, an uncertainty-aware fusion framework requires a grounded likelihood representing the uncertainty of human inputs. This paper presents a Feature Pyramid Likelihood Grounding Network (FP-LGN) that grounds spatial language by learning relevant map image features and their relationships with spatial relation semantics. The model is trained as a probability estimator to capture aleatoric uncertainty in human language using three-stage curriculum learning. Results showed that FP-LGN matched expert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated greater robustness with lower standard deviation. Collaborative sensing results demonstrated that the grounded likelihood successfully enabled uncertainty-aware fusion of heterogeneous human language observations and robot sensor measurements, achieving significant improvements in human-robot collaborative task performance.

Paper number 85:
Title: Towards Next Generation Immersive Applications in 5G Environments
Authors: Rohail Asim, Ankit Bhardwaj, Lakshmi Suramanian, Yasir Zaki
Abstract: The Multi-user Immersive Reality (MIR) landscape is evolving rapidly, with applications spanning virtual collaboration, entertainment, and training. However, wireless network limitations create a critical bottleneck, struggling to meet the high-bandwidth and ultra-low latency demands essential for next-generation MIR experiences. This paper presents Hera, a modular framework for next-generation immersive applications, comprising a high-level streaming and synchronization layer for AR/VR systems and a low-level delay-based QoE-aware rate control protocol optimized for dynamic wireless environments. The Hera framework integrates application-aware streaming logic with a QoE-centric rate control core, enabling adaptive video quality, multi-user fairness, and low-latency communication across challenging 5G network conditions. We demonstrate that Hera outperforms existing state-of-the-art rate control algorithms by maintaining up to 66% lower latencies with comparable throughput performance, higher visual quality with 50% average bitrate improvements in our analysis, and improved fairness. By bridging the gap between application-level responsiveness and network-level adaptability, Hera lays the foundation for more scalable, robust, and high-fidelity multi-user immersive experiences.

Paper number 86:
Title: ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models
Authors: Kaizhi Qian, Xulin Fan, Junrui Ni, Slava Shechtman, Mark Hasegawa-Johnson, Chuang Gan, Yang Zhang
Abstract: Speech language models refer to language models with speech processing and understanding capabilities. One key desirable capability for speech language models is the ability to capture the intricate interdependency between content and prosody. The existing mainstream paradigm of training speech language models, which converts speech into discrete tokens before feeding them into LLMs, is sub-optimal in learning prosody information -- we find that the resulting LLMs do not exhibit obvious emerging prosody processing capabilities via pre-training alone. To overcome this, we propose ProsodyLM, which introduces a simple tokenization scheme amenable to learning prosody. Each speech utterance is first transcribed into text, followed by a sequence of word-level prosody tokens. Compared with conventional speech tokenization schemes, the proposed tokenization scheme retains more complete prosody information, and is more understandable to text-based LLMs. We find that ProsodyLM can learn surprisingly diverse emerging prosody processing capabilities through pre-training alone, ranging from harnessing the prosody nuances in generated speech, such as contrastive focus, understanding emotion and stress in an utterance, to maintaining prosody consistency in long contexts.

Paper number 87:
Title: Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech
Authors: Taesoo Kim, Jinju Kim, Dongchan Kim, Jong Hwan Ko, Gyeong-Moon Park
Abstract: The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has enabled high-fidelity voice synthesis from minimal audio cues, raising significant privacy and ethical concerns. Despite the threats to voice privacy, research to selectively remove the knowledge to replicate unwanted individual voices from pre-trained model parameters has not been explored. In this paper, we address the new challenge of speaker identity unlearning for ZS-TTS systems. To meet this goal, we propose the first machine unlearning frameworks for ZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the model forgets designated speaker identities while retaining its ability to generate accurate speech for other speakers. Our proposed methods incorporate randomness to prevent consistent replication of forget speakers' voices, assuring unlearned identities remain untraceable. Additionally, we propose a new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses the model's ability to disregard prompts associated with forgotten speakers, effectively neutralizing its knowledge of these voices. The experiments conducted on the state-of-the-art model demonstrate that TGU prevents the model from replicating forget speakers' voices while maintaining high quality for other speakers. The demo is available at this https URL

Paper number 88:
Title: Self-Improvement for Audio Large Language Model using Unlabeled Speech
Authors: Shaowen Wang, Xinyuan Chen, Yao Xu
Abstract: Recent audio LLMs have emerged rapidly, demonstrating strong generalization across various speech tasks. However, given the inherent complexity of speech signals, these models inevitably suffer from performance degradation in specific target domains. To address this, we focus on enhancing audio LLMs in target domains without any labeled data. We propose a self-improvement method called SI-SDA, leveraging the information embedded in large-model decoding to evaluate the quality of generated pseudo labels and then perform domain adaptation based on reinforcement learning optimization. Experimental results show that our method consistently and significantly improves audio LLM performance, outperforming existing baselines in WER and BLEU across multiple public datasets of automatic speech recognition (ASR), spoken question-answering (SQA), and speech-to-text translation (S2TT). Furthermore, our approach exhibits high data efficiency, underscoring its potential for real-world deployment.

Paper number 89:
Title: SAMwave: Wavelet-Driven Feature Enrichment for Effective Adaptation of Segment Anything Model
Authors: Saurabh Yadav, Avi Gupta, Koteswar Rao Jerripothula
Abstract: The emergence of large foundation models has propelled significant advances in various domains. The Segment Anything Model (SAM), a leading model for image segmentation, exemplifies these advances, outperforming traditional methods. However, such foundation models often suffer from performance degradation when applied to complex tasks for which they are not trained. Existing methods typically employ adapter-based fine-tuning strategies to adapt SAM for tasks and leverage high-frequency features extracted from the Fourier domain. However, Our analysis reveals that these approaches offer limited benefits due to constraints in their feature extraction techniques. To overcome this, we propose \textbf{\textit{SAMwave}}, a novel and interpretable approach that utilizes the wavelet transform to extract richer, multi-scale high-frequency features from input data. Extending this, we introduce complex-valued adapters capable of capturing complex-valued spatial-frequency information via complex wavelet transforms. By adaptively integrating these wavelet coefficients, SAMwave enables SAM's encoder to capture information more relevant for dense prediction. Empirical evaluations on four challenging low-level vision tasks demonstrate that SAMwave significantly outperforms existing adaptation methods. This superior performance is consistent across both the SAM and SAM2 backbones and holds for both real and complex-valued adapter variants, highlighting the efficiency, flexibility, and interpretability of our proposed method for adapting segment anything models.

Paper number 90:
Title: Data-Efficient Prediction-Powered Calibration via Cross-Validation
Authors: Seonghoon Yoo, Houssem Sifaou, Sangwoo Park, Joonhyuk Kang, Osvaldo Simeone
Abstract: Calibration data are necessary to formally quantify the uncertainty of the decisions produced by an existing artificial intelligence (AI) model. To overcome the common issue of scarce calibration data, a promising approach is to employ synthetic labels produced by a (generally different) predictive model. However, fine-tuning the label-generating predictor on the inference task of interest, as well as estimating the residual bias of the synthetic labels, demand additional data, potentially exacerbating the calibration data scarcity problem. This paper introduces a novel approach that efficiently utilizes limited calibration data to simultaneously fine-tune a predictor and estimate the bias of the synthetic labels. The proposed method yields prediction sets with rigorous coverage guarantees for AI-generated decisions. Experimental results on an indoor localization problem validate the effectiveness and performance gains of our solution.

Paper number 91:
Title: Two Views, One Truth: Spectral and Self-Supervised Features Fusion for Robust Speech Deepfake Detection
Authors: Yassine El Kheir, Arnab Das, Enes Erdem Erdogan, Fabian Ritter-Guttierez, Tim Polzehl, Sebastian Möller
Abstract: Recent advances in synthetic speech have made audio deepfakes increasingly realistic, posing significant security risks. Existing detection methods that rely on a single modality, either raw waveform embeddings or spectral based features, are vulnerable to non spoof disturbances and often overfit to known forgery algorithms, resulting in poor generalization to unseen attacks. To address these shortcomings, we investigate hybrid fusion frameworks that integrate self supervised learning (SSL) based representations with handcrafted spectral descriptors (MFCC , LFCC, CQCC). By aligning and combining complementary information across modalities, these fusion approaches capture subtle artifacts that single feature approaches typically overlook. We explore several fusion strategies, including simple concatenation, cross attention, mutual cross attention, and a learnable gating mechanism, to optimally blend SSL features with fine grained spectral cues. We evaluate our approach on four challenging public benchmarks and report generalization performance. All fusion variants consistently outperform an SSL only baseline, with the cross attention strategy achieving the best generalization with a 38% relative reduction in equal error rate (EER). These results confirm that joint modeling of waveform and spectral views produces robust, domain agnostic representations for audio deepfake detection.

Paper number 92:
Title: ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings
Authors: Samiul Based Shuvo, Tasnia Binte Mamun, U Rajendra Acharya
Abstract: DNA-binding proteins (DBPs) are integral to gene regulation and cellular processes, making their accurate identification essential for understanding biological functions and disease mechanisms. Experimental methods for DBP identification are time-consuming and costly, driving the need for efficient computational prediction techniques. In this study, we propose a novel deep learning framework, ResCap-DBP, that combines a residual learning-based encoder with a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly from raw protein sequences. Our architecture incorporates dilated convolutions within residual blocks to mitigate vanishing gradient issues and extract rich sequence features, while capsule layers with dynamic routing capture hierarchical and spatial relationships within the learned feature space. We conducted comprehensive ablation studies comparing global and local embeddings from ProteinBERT and conventional one-hot encoding. Results show that ProteinBERT embeddings substantially outperform other representations on large datasets. Although one-hot encoding showed marginal advantages on smaller datasets, such as PDB186, it struggled to scale effectively. Extensive evaluations on four pairs of publicly available benchmark datasets demonstrate that our model consistently outperforms current state-of-the-art methods. It achieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On independent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2% and 83.3%, while maintaining competitive performance on larger datasets such as PDB20000. Notably, the model maintains a well balanced sensitivity and specificity across datasets. These results demonstrate the efficacy and generalizability of integrating global protein representations with advanced deep learning architectures for reliable and scalable DBP prediction in diverse genomic contexts.

Paper number 93:
Title: Rethinking Multi-User Communication in Semantic Domain: Enhanced OMDMA by Shuffle-Based Orthogonalization and Diffusion Denoising
Authors: Maojun Zhang, Guangxu Zhu, Xiaoming Chen, Kaibin Huang, Zhaoyang Zhang
Abstract: Inter-user interference remains a critical bottleneck in wireless communication systems, particularly in the emerging paradigm of semantic communication (SemCom). Compared to traditional systems, inter-user interference in SemCom severely degrades key semantic information, often causing worse performance than Gaussian noise under the same power level. To address this challenge, inspired by the recently proposed concept of Orthogonal Model Division Multiple Access (OMDMA) that leverages semantic orthogonality rooted in the personalized joint source and channel (JSCC) models to distinguish users, we propose a novel, scalable framework that eliminates the need for user-specific JSCC models as did in original OMDMA. Our key innovation lies in shuffle-based orthogonalization, where randomly permuting the positions of JSCC feature vectors transforms inter-user interference into Gaussian-like noise. By assigning each user a unique shuffling pattern, the interference is treated as channel noise, enabling effective mitigation using diffusion models (DMs). This approach not only simplifies system design by requiring a single universal JSCC model but also enhances privacy, as shuffling patterns act as implicit private keys. Additionally, we extend the framework to scenarios involving semantically correlated data. By grouping users based on semantic similarity, a cooperative beamforming strategy is introduced to exploit redundancy in correlated data, further improving system performance. Extensive simulations demonstrate that the proposed method outperforms state-of-the-art multi-user SemCom frameworks, achieving superior semantic fidelity, robustness to interference, and scalability-all without requiring additional training overhead.

Paper number 94:
Title: Sound Safeguarding for Acoustic Measurement Using Any Sounds: Tools and Applications
Authors: Hideki Kawahara, Kohei Yatabe, Ken-Ichi Sakakibara
Abstract: We demonstrate tools and applications developed based on the method of "sound safeguarding," which enables any sound to be used for acoustic measurements. We developed tools for preparation, interactive and real-time measurement, and report generation. We extended and modified the method during its development based on its application in various practical situations. We have open-sourced these tools and encourage prospective users to use them to improve their acoustic environments.

Paper number 95:
Title: Investigating the Effect of Spatial Context on Multi-Task Sea Ice Segmentation
Authors: Behzad Vahedi, Rafael Pires de Lima, Sepideh Jalayer, Walter N. Meier, Andrew P. Barrett, Morteza Karimzadeh
Abstract: Capturing spatial context at multiple scales is crucial for deep learning-based sea ice segmentation. However, the optimal specification of spatial context based on observation resolution and task characteristics remains underexplored. This study investigates the impact of spatial context on the segmentation of sea ice concentration, stage of development, and floe size using a multi-task segmentation model. We implement Atrous Spatial Pyramid Pooling with varying atrous rates to systematically control the receptive field size of convolutional operations, and to capture multi-scale contextual information. We explore the interactions between spatial context and feature resolution for different sea ice properties and examine how spatial context influences segmentation performance across different input feature combinations from Sentinel-1 SAR and Advanced Microwave Radiometer-2 (AMSR2) for multi-task mapping. Using Gradient-weighted Class Activation Mapping, we visualize how atrous rates influence model decisions. Our findings indicate that smaller receptive fields excel for high-resolution Sentinel-1 data, while medium receptive fields yield better performances for stage of development segmentation and larger receptive fields often lead to diminished performances. The fusion of SAR and AMSR2 enhances segmentation across all tasks. We highlight the value of lower-resolution 18.7 and 36.5 GHz AMSR2 channels in sea ice mapping. These findings highlight the importance of selecting appropriate spatial context based on observation resolution and target properties in sea ice mapping. By systematically analyzing receptive field effects in a multi-task setting, our study provides insights for optimizing deep learning models in geospatial applications.

Paper number 96:
Title: LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models
Authors: Zhongchao Zhou, Yuxi Lu, Yaonan Zhu, Yifan Zhao, Bin He, Liang He, Wenwen Yu, Yusuke Iwasawa
Abstract: With rapid advances in code generation, reasoning, and problem-solving, Large Language Models (LLMs) are increasingly applied in robotics. Most existing work focuses on high-level tasks such as task decomposition. A few studies have explored the use of LLMs in feedback controller design; however, these efforts are restricted to overly simplified systems, fixed-structure gain tuning, and lack real-world validation. To further investigate LLMs in automatic control, this work targets a key subfield: adaptive control. Inspired by the framework of model reference adaptive control (MRAC), we propose an LLM-guided adaptive compensator framework that avoids designing controllers from scratch. Instead, the LLMs are prompted using the discrepancies between an unknown system and a reference system to design a compensator that aligns the response of the unknown system with that of the reference, thereby achieving adaptivity. Experiments evaluate five methods: LLM-guided adaptive compensator, LLM-guided adaptive controller, indirect adaptive control, learning-based adaptive control, and MRAC, on soft and humanoid robots in both simulated and real-world environments. Results show that the LLM-guided adaptive compensator outperforms traditional adaptive controllers and significantly reduces reasoning complexity compared to the LLM-guided adaptive controller. The Lyapunov-based analysis and reasoning-path inspection demonstrate that the LLM-guided adaptive compensator enables a more structured design process by transforming mathematical derivation into a reasoning task, while exhibiting strong generalizability, adaptability, and robustness. This study opens a new direction for applying LLMs in the field of automatic control, offering greater deployability and practicality compared to vision-language models.

Paper number 97:
Title: Symplectic Elimination
Authors: Ayan Mahalanobis
Abstract: We develop the symplectic elimnation algorithm. This algorithm using simple row operations reduce a symplectic matrix to a diagonal matrix. This algorithm gives rise to a decomposition of an arbitrary matrix into a product of a symplectic matrix and a reduced matrix. This decomposition is similar to the SR decomposition studied for a long time, which is analogous to the QR decomposition.

Paper number 98:
Title: Controllable Video-to-Music Generation with Multiple Time-Varying Conditions
Authors: Junxian Wu, Weitao You, Heda Zuo, Dengming Zhang, Pei Chen, Lingyun Sun
Abstract: Music enhances video narratives and emotions, driving demand for automatic video-to-music (V2M) generation. However, existing V2M methods relying solely on visual features or supplementary textual inputs generate music in a black-box manner, often failing to meet user expectations. To address this challenge, we propose a novel multi-condition guided V2M generation framework that incorporates multiple time-varying conditions for enhanced control over music generation. Our method uses a two-stage training strategy that enables learning of V2M fundamentals and audiovisual temporal synchronization while meeting users' needs for multi-condition control. In the first stage, we introduce a fine-grained feature selection module and a progressive temporal alignment attention mechanism to ensure flexible feature alignment. For the second stage, we develop a dynamic conditional fusion module and a control-guided decoder module to integrate multiple conditions and accurately guide the music composition process. Extensive experiments demonstrate that our method outperforms existing V2M pipelines in both subjective and objective evaluations, significantly enhancing control and alignment with user expectations.

Paper number 99:
Title: Fundamental diagram constrained dynamic optimal transport via proximal splitting methods
Authors: Anqi Dong, Karl Henrik Johansson, Johan Karlsson
Abstract: Optimal transport has recently been brought forward as a tool for modeling and efficiently solving a variety of flow problems, such as origin-destination problems and multi-commodity flow problems. Although the framework has shown to be effective for many large scale flow problems, the formulations typically lack dynamic properties used in common traffic models, such as the Lighthill-Whitham-Richards model. In this work, we propose an optimal transport framework that includes dynamic constraints specified by the fundamental diagram for modeling macroscopic traffic flow. The problem is cast as a convex variant of dynamic optimal transport, with additional nonlinear temporal-spatial inequality constraints of momentum, modeled after the fundamental diagram from traffic theory. This constraint imposes a density-dependent upper bound on the admissible flux, capturing flow saturation and congestion effects, and thus leaves space for kinetic optimization. The formulation follows the Benamou-Brenier transportation rationale, whereby kinetic energy over density and momentum fields is optimized subject to the mass conservation law. We develop proximal splitting methods, namely the Douglas-Rachford and Chambolle-Pock algorithms, which exploit the separable structure of the constraint set and require only simple proximal operations, and can accommodate additional (time-varying) spatial restrictions or obstacles. Numerical experiments illustrate the impact of the constraint on transport behavior, including congestion-aware spreading, rerouting, and convergence. The framework establishes a connection between optimal transport and macroscopic traffic flow theory and provides a scalable, variational tool for modeling congestion-constricted (or saturation-aware) Wasserstein gradient flow.

Paper number 100:
Title: Precision spectral estimation at sub-Hz frequencies: closed-form posteriors and Bayesian noise projection
Authors: Lorenzo Sala, Stefano Vitale
Abstract: We present a Bayesian method for estimating spectral quantities in multivariate Gaussian time series. The approach, based on periodograms and Wishart statistics, yields closed-form expressions at any given frequency for the marginal posterior distributions of the individual power spectral densities, the pairwise coherence, and the multiple coherence, as well as for the joint posterior distribution of the full cross-spectral density matrix. In the context of noise projection - where one series is modeled as a linear combination of filtered versions of the others, plus a background component - the method also provides closed-form posteriors for both the susceptibilities, i.e., the filter transfer functions, and the power spectral density of the background. Originally developed for the analysis of the data from the European Space Agency's LISA Pathfinder mission, the method is particularly well-suited to very-low-frequency data, where long observation times preclude averaging over large sets of periodograms, which would otherwise allow these to be treated as approximately normally distributed.

Paper number 101:
Title: The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?
Authors: Dinh Nam Pham, Eleftherios Avramidis
Abstract: Non-manual facial features play a crucial role in sign language communication, yet their importance in automatic sign language recognition (ASLR) remains underexplored. While prior studies have shown that incorporating facial features can improve recognition, related work often relies on hand-crafted feature extraction and fails to go beyond the comparison of manual features versus the combination of manual and facial features. In this work, we systematically investigate the contribution of distinct facial regionseyes, mouth, and full faceusing two different deep learning models (a CNN-based model and a transformer-based model) trained on an SLR dataset of isolated signs with randomly selected classes. Through quantitative performance and qualitative saliency map evaluation, we reveal that the mouth is the most important non-manual facial feature, significantly improving accuracy. Our findings highlight the necessity of incorporating facial features in ASLR.

Paper number 102:
Title: Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL
Authors: Hussein A. Ammar, Raviraj Adve, Shahram Shahbazpanahi, Gary Boudreau, Israfil Bahceci
Abstract: In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user mobility necessitates updating the set of serving access points to maintain the user-centric clustering. Such updates are typically performed through handoff (HO) operations; however, frequent HOs lead to overheads associated with the allocation and release of resources. This paper presents a deep reinforcement learning (DRL)-based solution to predict and manage these connections for mobile users. Our solution employs the Soft Actor-Critic algorithm, with continuous action space representation, to train a deep neural network to serve as the HO policy. We present a novel proposition for a reward function that integrates a HO penalty in order to balance the attainable rate and the associated overhead related to HOs. We develop two variants of our system; the first one uses mobility direction-assisted (DA) observations that are based on the user movement pattern, while the second one uses history-assisted (HA) observations that are based on the history of the large-scale fading (LSF). Simulation results show that our DRL-based continuous action space approach is more scalable than discrete space counterpart, and that our derived HO policy automatically learns to gather HOs in specific time slots to minimize the overhead of initiating HOs. Our solution can also operate in real time with a response time less than 0.4 ms.

Paper number 103:
Title: VArsity: Can Large Language Models Keep Power Engineering Students in Phase?
Authors: Samuel Talkington, Daniel K. Molzahn
Abstract: This paper provides an educational case study regarding our experience in deploying ChatGPT Large Language Models (LLMs) in the Spring 2025 and Fall 2023 offerings of ECE 4320: Power System Analysis and Control at Georgia Tech. As part of course assessments, students were tasked with identifying, explaining, and correcting errors in the ChatGPT outputs corresponding to power factor correction problems. While most students successfully identified the errors in the outputs from the GPT-4 version of ChatGPT used in Fall 2023, students found the errors from the ChatGPT o1 version much more difficult to identify in Spring 2025. As shown in this case study, the role of LLMs in pedagogy, assessment, and learning in power engineering classrooms is an important topic deserving further investigation.

Paper number 104:
Title: On Using the Shapley Value for Anomaly Localization: A Statistical Investigation
Authors: Rick S. Blum, Franziska Freytag
Abstract: Recent publications have suggested using the Shapley value for anomaly localization for sensor data systems. Using a reasonable mathematical anomaly model for full control, experiments indicate that using a single fixed term in the Shapley value calculation achieves a lower complexity anomaly localization test, with the same probability of error, as a test using the Shapley value for all cases tested. A proof demonstrates these conclusions must be true for all independent observation cases. For dependent observation cases, no proof is available.

Paper number 105:
Title: Deep Koopman Learning of Nonlinear Time-Varying Systems
Authors: Wenjian Hao, Bowen Huang, Wei Pan, Di Wu, Shaoshuai Mou
Abstract: This paper presents a data-driven approach to approximate the dynamics of a nonlinear time-varying system (NTVS) by a linear time-varying system (LTVS), which is resulted from the Koopman operator and deep neural networks. Analysis of the approximation error between states of the NTVS and the resulting LTVS is presented. Simulations on a representative NTVS show that the proposed method achieves small approximation errors, even when the system changes rapidly. Furthermore, simulations in an example of quadcopters demonstrate the computational efficiency of the proposed approach.

Paper number 106:
Title: AutoLungDx: A Hybrid Deep Learning Approach for Early Lung Cancer Diagnosis Using 3D Res-U-Net, YOLOv5, and Vision Transformers
Authors: Samiul Based Shuvo, Tasnia Binte Mamun
Abstract: Lung cancer is a leading cause of cancer-related deaths worldwide, and early detection is crucial for improving patient outcomes. Nevertheless, early diagnosis of cancer is a major challenge, particularly in low-resource settings where access to medical resources and trained radiologists is limited. The objective of this study is to propose an automated end-to-end deep learning-based framework for the early detection and classification of lung nodules, specifically for low-resource settings. The proposed framework consists of three stages: lung segmentation using a modified 3D U-Net named 3D Res-U-Net, nodule detection using YOLO-v5, and classification with a Vision Transformer-based architecture. We evaluated the proposed framework on a publicly available dataset, LUNA16. The proposed framework's performance was measured using the respective domain's evaluation matrices. The proposed framework achieved a 98.82% lung segmentation dice score while detecting the lung nodule with 0.76 mAP@50 from the segmented lung, at a low false-positive rate. The performance of both networks of the proposed framework was compared with other studies and found to outperform them regarding segmentation and detection accuracy. Additionally, our proposed Vision transformer network obtained an accuracy of 93.57%, which is 1.21% higher than the state-of-the-art networks. Our proposed end-to-end deep learning-based framework can effectively segment lungs, and detect and classify lung nodules, specifically in low-resource settings with limited access to radiologists. The proposed framework outperforms existing studies regarding all the respective evaluation metrics. The proposed framework can potentially improve the accuracy and efficiency of lung cancer screening in low-resource settings, ultimately leading to better patient outcomes.

Paper number 107:
Title: Performance-Based Optimization of 2D Reinforced Concrete Moment Frames through Pushover Analysis and ABC Optimization Algorithm
Authors: Saba Faghirnejad
Abstract: Conducting nonlinear pushover analysis typically demands intricate and resource-intensive computational attempts, and involves a process that is highly iterative and necessary for satisfying design-defined and also requirements of codes in performance-based design. A computer-based technique is presented for reinforced concrete (RC) buildings in this study, incorporating optimization numerical approaches, techniques of optimality criteria and pushover analysis to seismic design automatically the pushover drift performance. The optimal design based on the performance of concrete beams, columns and shear walls in concrete moment frames is presented using the artificial bee colony optimization algorithm. The design is applied to three frames such as a 4-story, an 8-story and a 12-story. These structures are designed to minimize the overall weight while satisfying the levels of performance include Life Safety (L-S), Collapse Prevention (C-P), and Immediate Occupancy (I-O). To achieve this goal, three main steps are performed. In the first step, optimization codes are implemented in MATLAB software, and the OpenSees software is used for nonlinear static analysis of the structure. By solving the optimization problem, several top designs are obtained for each frame and shear wall. Pushover analysis is performed considering the constraints of relative displacement and plastic hinge rotation based on the nonlinear provisions of FEMA356 code to achieve each levels of performance. Following this, convergence, pushover, and drift history curves are plotted for each frame, and selecting the best design for each frame ultimately occurs. The results demonstrate the algorithm's performance is desirable for the structure to achieve selecting the best design and lower weight.

Paper number 108:
Title: Quantifying the Aggregate Flexibility of Electric Vehicles Charging Stations for Dependable Congestion Management Products - A Dutch Case Study
Authors: Nanda Kishor Panda, Simon H. Tindemans
Abstract: Electric vehicles (EVs) play a crucial role in the transition towards sustainable modes of transportation and thus are critical to the energy transition. As their number grows, managing the aggregate power of EV charging is crucial to maintain grid stability and mitigate congestion. This study analyses more than 500 thousand real charging transactions in the Netherlands to explore the challenge and opportunity for the energy system presented by increased charging needs and smart charging flexibility. Specifically, it quantifies the collective ability to provide dependable congestion management services according to the specifications of those services in the Netherlands. In this study, a data-driven model of charging behaviour is created to explore the implications of delivering dependable congestion management services at various aggregation levels and types of service. The probabilistic ability to offer different flexibility products, namely, redispatch and capacity limitation, for congestion management, is assessed for different categories of charging stations (CS) and dispatch strategies. These probabilities can help EV aggregators, such as charging point operators, make informed decisions about offering congestion mitigation products per relevant regulations and distribution system operators to assess their potential. Further, it is shown how machine learning models can be incorporated to predict the day-ahead consumption, followed by operationally predicting redispatch flexibility. The findings demonstrate that the timing of EV arrivals, departures, and connections plays a crucial role in determining the feasibility of product offerings, and dependable services can generally be delivered using a sufficiently large number of CSs.

Paper number 109:
Title: Safe and Stable Formation Control with Autonomous Multi-Agents Using Adaptive Control (Extended Version)
Authors: Jose A. Solano-Castellanos, Peter A. Fisher, Anuradha Annaswamy
Abstract: This manuscript considers the problem of ensuring stability and safety during formation control with distributed multi-agent systems in the presence of parametric uncertainty in the dynamics and limited communication. We propose an integrative approach that combines Adaptive Control, Control Barrier Functions (CBFs), and connected graphs. The main elements employed in the integrative approach are an adaptive control design that ensures stability, a CBF-based safety filter that generates safe commands based on a reference model dynamics, and a reference model that ensures formation control with multi-agent systems when no uncertainties are present. The overall control design is shown to lead to a closed-loop adaptive system that is stable, avoids unsafe regions, and converges to a desired formation of the multi-agents. Numerical examples are provided to support the theoretical derivations.

Paper number 110:
Title: Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment
Authors: Tien-Hong Lo, Meng-Ting Tsai, Yao-Ting Sung, Berlin Chen
Abstract: Second language (L2) learners can improve their pronunciation by imitating golden speech, especially when the speech that aligns with their respective speech characteristics. This study explores the hypothesis that learner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS) techniques can be harnessed as an effective metric for measuring the pronunciation proficiency of L2 learners. Building on this exploration, the contributions of this study are at least two-fold: 1) design and development of a systematic framework for assessing the ability of a synthesis model to generate golden speech, and 2) in-depth investigations of the effectiveness of using golden speech in automatic pronunciation assessment (APA). Comprehensive experiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets suggest that our proposed modeling can yield significant performance improvements with respect to various assessment metrics in relation to some prior arts. To our knowledge, this study is the first to explore the role of golden speech in both ZS-TTS and APA, offering a promising regime for computer-assisted pronunciation training (CAPT).

Paper number 111:
Title: RF Challenge: The Data-Driven Radio Frequency Signal Separation Challenge
Authors: Alejandro Lancho, Amir Weiss, Gary C.F. Lee, Tejas Jayashankar, Binoy Kurien, Yury Polyanskiy, Gregory W. Wornell
Abstract: We address the critical problem of interference rejection in radio-frequency (RF) signals using a data-driven approach that leverages deep-learning methods. A primary contribution of this paper is the introduction of the RF Challenge, which is a publicly available, diverse RF signal dataset for data-driven analyses of RF signal problems. Specifically, we adopt a simplified signal model for developing and analyzing interference rejection algorithms. For this signal model, we introduce a set of carefully chosen deep learning architectures, incorporating key domain-informed modifications alongside traditional benchmark solutions to establish baseline performance metrics for this intricate, ubiquitous problem. Through extensive simulations involving eight different signal mixture types, we demonstrate the superior performance (in some cases, by two orders of magnitude) of architectures such as UNet and WaveNet over traditional methods like matched filtering and linear minimum mean square error estimation. Our findings suggest that the data-driven approach can yield scalable solutions, in the sense that the same architectures may be similarly trained and deployed for different types of signals. Moreover, these findings further corroborate the promising potential of deep learning algorithms for enhancing communication systems, particularly via interference mitigation. This work also includes results from an open competition based on the RF Challenge, hosted at the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP'24).

Paper number 112:
Title: Reinforcement Leaning for Infinite-Dimensional Systems
Authors: Wei Zhang, Jr-Shin Li
Abstract: Interest in reinforcement learning (RL) for massive-scale systems consisting of large populations of intelligent agents interacting with heterogeneous environments has witnessed a significant surge in recent years across diverse scientific domains. However, the large-scale nature of these systems often results in high computational costs or compromised performance for most state-of-the-art RL techniques. To address these challenges, we propose a novel RL architecture along with the derivation of effective algorithms to learn optimal policies for arbitrarily large systems of agents. In our formulation, we model such a system as a parameterized control system defined on an infinite-dimensional function space. We then develop a moment kernel transform to map the parameterized system and the value function into a reproducing kernel Hilbert space. This transformation generates a sequence of finite-dimensional moment representations for the RL problem, which are organized into a filtrated structure. Leveraging this RL filtration, we develop a hierarchical algorithm for learning optimal policies for the infinite-dimensional parameterized system. We further enhance the efficiency of the algorithm by exploiting early stopping at each hierarchy, which demonstrates the fast convergence property of the algorithm through the construction of a convergent spectral sequence. The performance and efficiency of the proposed algorithm are validated using practical examples.

Paper number 113:
Title: Synomaly Noise and Multi-Stage Diffusion: A Novel Approach for Unsupervised Anomaly Detection in Medical Images
Authors: Yuan Bi, Lucie Huang, Ricarda Clarenbach, Reza Ghotbi, Angelos Karlas, Nassir Navab, Zhongliang Jiang
Abstract: Anomaly detection in medical imaging plays a crucial role in identifying pathological regions across various imaging modalities, such as brain MRI, liver CT, and carotid ultrasound (US). However, training fully supervised segmentation models is often hindered by the scarcity of expert annotations and the complexity of diverse anatomical structures. To address these issues, we propose a novel unsupervised anomaly detection framework based on a diffusion model that incorporates a synthetic anomaly (Synomaly) noise function and a multi-stage diffusion process. Synomaly noise introduces synthetic anomalies into healthy images during training, allowing the model to effectively learn anomaly removal. The multi-stage diffusion process is introduced to progressively denoise images, preserving fine details while improving the quality of anomaly-free reconstructions. The generated high-fidelity counterfactual healthy images can further enhance the interpretability of the segmentation models, as well as provide a reliable baseline for evaluating the extent of anomalies and supporting clinical decision-making. Notably, the unsupervised anomaly detection model is trained purely on healthy images, eliminating the need for anomalous training samples and pixel-level annotations. We validate the proposed approach on brain MRI, liver CT datasets, and carotid US. The experimental results demonstrate that the proposed framework outperforms existing state-of-the-art unsupervised anomaly detection methods, achieving performance comparable to fully supervised segmentation models in the US dataset. Ablation studies further highlight the contributions of Synomaly noise and the multi-stage diffusion process in improving anomaly segmentation. These findings underscore the potential of our approach as a robust and annotation-efficient alternative for medical anomaly detection.

Paper number 114:
Title: The networked input-output economic problem
Authors: Minh Hoang Trinh, Nhat-Minh Le-Phan, Hyo-Sung Ahn
Abstract: In this chapter, an input-output economic model with multiple interactive economic systems is considered. The model captures the multi-dimensional nature of the economic sectors or industries in each economic system, the interdependencies among industries within an economic system and across different economic systems, and the influence of demand. To determine the equilibrium price structure of the model, a matrix-weighted updating algorithm is proposed. The equilibrium price structure is proved to be globally asymptotically achieved when certain joint conditions on the matrix-weighted graph and the input-output matrices are satisfied. The theoretical results are then supported by numerical simulations.

Paper number 115:
Title: GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution
Authors: Qiwei Zhu, Kai Li, Guojing Zhang, Xiaoying Wang, Jianqiang Huang, Xilai Li
Abstract: In recent years, deep neural networks, including Convolutional Neural Networks, Transformers, and State Space Models, have achieved significant progress in Remote Sensing Image (RSI) Super-Resolution (SR). However, existing SR methods typically overlook the complementary relationship between global and local dependencies. These methods either focus on capturing local information or prioritize global information, which results in models that are unable to effectively capture both global and local features simultaneously. Moreover, their computational cost becomes prohibitive when applied to large-scale RSIs. To address these challenges, we introduce the novel application of Receptance Weighted Key Value (RWKV) to RSI-SR, which captures long-range dependencies with linear complexity. To simultaneously model global and local features, we propose the Global-Detail dual-branch structure, GDSR, which performs SR by paralleling RWKV and convolutional operations to handle large-scale RSIs. Furthermore, we introduce the Global-Detail Reconstruction Module (GDRM) as an intermediary between the two branches to bridge their complementary roles. In addition, we propose the Dual-Group Multi-Scale Wavelet Loss, a wavelet-domain constraint mechanism via dual-group subband strategy and cross-resolution frequency alignment for enhanced reconstruction fidelity in RSI-SR. Extensive experiments under two degradation methods on several benchmarks, including AID, UCMerced, and RSSRD-QH, demonstrate that GSDR outperforms the state-of-the-art Transformer-based method HAT by an average of 0.09 dB in PSNR, while using only 63% of its parameters and 51% of its FLOPs, achieving an inference speed 3.2 times faster.

Paper number 116:
Title: Compressed Image Generation with Denoising Diffusion Codebook Models
Authors: Guy Ohayon, Hila Manor, Tomer Michaeli, Michael Elad
Abstract: We present a novel generative approach based on Denoising Diffusion Models (DDMs), which produces high-quality image samples along with their losslessly compressed bit-stream representations. This is obtained by replacing the standard Gaussian noise sampling in the reverse diffusion with a selection of noise samples from pre-defined codebooks of fixed iid Gaussian vectors. Surprisingly, we find that our method, termed Denoising Diffusion Codebook Model (DDCM), retains sample quality and diversity of standard DDMs, even for extremely small codebooks. We leverage DDCM and pick the noises from the codebooks that best match a given image, converting our generative model into a highly effective lossy image codec achieving state-of-the-art perceptual image compression results. More generally, by setting other noise selections rules, we extend our compression method to any conditional image generation task (e.g., image restoration), where the generated images are produced jointly with their condensed bit-stream representations. Our work is accompanied by a mathematical interpretation of the proposed compressed conditional generation schemes, establishing a connection with score-based approximations of posterior samplers for the tasks considered.

Paper number 117:
Title: Stretching Rubber, Not Budgets: Accurate Parking Utilization on a Shoestring
Authors: Christopher K. Allsup
Abstract: Effective parking management is essential for ensuring safety and convenience in master-planned communities, particularly in active adult neighborhoods experiencing rapid growth. Accurately assessing parking utilization is a crucial first step in planning for future demand, but data collection methods can be costly and labor-intensive. This paper presents a low-cost yet highly accurate methodology for measuring parking utilization using pneumatic road tubes connected to portable traffic counters from JAMAR Technologies, Inc. By integrating results from JAMAR's analysis tool with custom Python scripting, the methodology enables precise parking lot counts through automated parameter optimization and error correction. The system's efficiency allows for scalable deployment without significant manual observation, reducing both costs and disruptions to daily operations. Using Tellico Village as a case study, this effort demonstrates that community planners can obtain actionable parking insights on a limited budget, empowering them to make informed decisions about capacity expansion and facility scheduling.

Paper number 118:
Title: Generative AI-enabled Wireless Communications for Robust Low-Altitude Economy Networking
Authors: Changyuan Zhao, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Geng Sun, Hongyang Du, Dong In Kim, Abbas Jamalipour
Abstract: Low-Altitude Economy Networks (LAENets) have emerged as significant enablers of social activities, offering low-altitude services such as the transportation of packages, groceries, and medical supplies. Owing to their control mechanisms and ever-changing operational factors, LAENets are inherently more complex and vulnerable to security threats than traditional terrestrial networks. As applications of LAENet continue to expand, the robustness of these systems becomes crucial. In this paper, we propose a generative artificial intelligence (GenAI) optimization framework that tackles robustness challenges in LAENets. We conduct a systematic analysis of robustness requirements for LAENets, complemented by a comprehensive review of robust Quality of Service (QoS) metrics from the wireless physical layer perspective. We then investigate existing GenAI-enabled approaches for robustness enhancement. This leads to our proposal of a novel diffusion-based optimization framework with a Mixture of Experts (MoE)-transformer actor network. In the robust beamforming case study, the proposed framework demonstrates its effectiveness by optimizing beamforming under uncertainties, achieving a more than 15% increase over four learning baselines in the worst-case achievable secrecy rate. These findings highlight the significant potential of GenAI in strengthening LAENet robustness.

Paper number 119:
Title: RIS-Assisted Joint Sensing and Communications via Fractionally Constrained Fractional Programming
Authors: Yiming Liu, Kareem M. Attiah, Wei Yu
Abstract: This paper studies an uplink dual-functional sensing and communication system aided by a reconfigurable intelligent surface (RIS), whose reflection pattern is optimally configured to trade-off sensing and communication functionalities. Specifically, the Bayesian Cramér-Rao lower bound (BCRLB) for estimating the azimuth angle of a sensing user is minimized while ensuring the signal-to-interference-plus-noise ratio constraints for communication users. We show that this problem can be formulated as a novel fractionally constrained fractional programming (FCFP) problem. To deal with this highly nontrivial problem, we extend a quadratic transform technique, originally proposed to handle optimization problems containing fractional structures only in objectives, to the scenario where the constraints also include ratios. First, we consider the case where the fading coefficient is known. Using the quadratic transform, the FCFP problem can be turned into a sequence of subproblems that are convex except for the constant-modulus constraints which can be tackled using a penalty-based approach. To further reduce the computational complexity, we leverage the constant-modulus conditions and propose a novel linear transform. This new transform enables the FCFP problem to be turned into a sequence of linear programming (LP) subproblems, which can be solved with linear complexity in the dimension of reflecting elements. Then, we consider the case where the fading coefficient is unknown. A modified BCRLB is used to make the problem more tractable, and the proposed quadratic transform based algorithm is used to solve the problem. Numerical results unveil nontrivial and effective reflection patterns that can be synthesized by the RIS to facilitate both communication and sensing functionalities.

Paper number 120:
Title: Restoring Feasibility in Power Grid Optimization: A Counterfactual ML Approach
Authors: Mostafa Mohammadian, Anna Van Boven, Kyri Baker
Abstract: Electric power grids are essential components of modern life, delivering reliable power to end-users while adhering to a multitude of engineering constraints and requirements. In grid operations, the Optimal Power Flow problem plays a key role in determining cost-effective generator dispatch that satisfies load demands and operational limits. However, due to stressed operating conditions, volatile demand profiles, and increased generation from intermittent energy sources, this optimization problem may become infeasible, posing risks such as voltage instability and line overloads. This study proposes a learning framework that combines machine learning with counterfactual explanations to automatically diagnose and restore feasibility in the OPF problem. Our method provides transparent and actionable insights by methodically identifying infeasible conditions and suggesting minimal demand response actions. We evaluate the proposed approach on IEEE 30-bus and 300-bus systems, demonstrating its capability to recover feasibility with high success rates and generating diverse corrective options, appropriate for real-time decision-making. These preliminary findings illustrate the potential of combining classical optimization with explainable AI techniques to enhance grid reliability and resilience.

Paper number 121:
Title: Filtering through a topological lens: homology for point processes on the time-frequency plane
Authors: Juan Manuel Miramont, Kin Aun Tan, Soumendu Sundar Mukherjee, Rémi Bardenet, Subhroshekhar Ghosh
Abstract: We introduce a very general approach to the analysis of signals from their noisy measurements from the perspective of Topological Data Analysis (TDA). While TDA has emerged as a powerful analytical tool for data with pronounced topological structures, here we demonstrate its applicability for general problems of signal processing, without any a-priori geometric feature. Our methods are well-suited to a wide array of time-dependent signals in different scientific domains, with acoustic signals being a particularly important application. We invoke time-frequency representations of such signals, focusing on their zeros which are gaining salience as a signal processing tool in view of their stability properties. Leveraging state-of-the-art topological concepts, such as stable and minimal volumes, we develop a complete suite of TDA-based methods to explore the delicate stochastic geometry of these zeros, capturing signals based on the disruption they cause to this rigid, hyperuniform spatial structure. Unlike classical spatial data tools, TDA is able to capture the full spectrum of the stochastic geometry of the zeros, thereby leading to powerful inferential outcomes that are underpinned by a principled statistical foundation. This is reflected in the power and versatility of our applications, which include competitive performance in processing. a wide variety of audio signals (esp. in low SNR regimes), effective detection and reconstruction of gravitational wave signals (a reputed signal processing challenge with non-Gaussian noise), and medical time series data from EEGs, indicating a wide horizon for the approach and methods introduced in this paper.

Paper number 122:
Title: Incorporating a Deep Neural Network into Moving Horizon Estimation for Embedded Thermal Torque Derating of an Electric Machine
Authors: Alexander Winkler, Pranav Shah, Katrin Baumgärtner, Vasu Sharma, David Gordon, Jakob Andert
Abstract: This study presents a novel state estimation approach integrating Deep Neural Networks (DNNs) into Moving Horizon Estimation (MHE). This is a shift from using traditional physics-based models within MHE towards data-driven techniques. Specifically, a Long Short-Term Memory (LSTM)-based DNN is trained using synthetic data derived from a high-fidelity thermal model of a Permanent Magnet Synchronous Machine (PMSM), applied within a thermal derating torque control strategy for battery electric vehicles. The trained DNN is directly embedded within an MHE formulation, forming a discrete-time nonlinear optimal control problem (OCP) solved via the acados optimization framework. Model-in-the-Loop simulations demonstrate accurate temperature estimation even under noisy sensor conditions and simulated sensor failures. Real-time implementation on embedded hardware confirms practical feasibility, achieving computational performance exceeding real-time requirements threefold. By integrating the learned LSTM-based dynamics directly into MHE, this work achieves state estimation accuracy, robustness, and adaptability while reducing modeling efforts and complexity. Overall, the results highlight the effectiveness of combining model-based and data-driven methods in safety-critical automotive control systems.

Paper number 123:
Title: RADE: A Neural Codec for Transmitting Speech over HF Radio Channels
Authors: David Rowe, Jean-Marc Valin
Abstract: Speech compression is commonly used to send voice over radio channels in applications such as mobile telephony and two-way push-to-talk (PTT) radio. In classical systems, the speech codec is combined with forward error correction, modulation and radio hardware. In this paper we describe an autoencoder that replaces many of the traditional signal processing elements with a neural network. The encoder takes a vocoder feature set (short term spectrum, pitch, voicing), and produces discrete time, but continuously valued quadrature amplitude modulation (QAM) symbols. We use orthogonal frequency domain multiplexing (OFDM) to send and receive these symbols over high frequency (HF) radio channels. The decoder converts received QAM symbols to vocoder features suitable for synthesis. The autoencoder has been trained to be robust to additive Gaussian noise and multipath channel impairments while simultaneously maintaining a Peak To Average Power Ratio (PAPR) of less than 1 dB. Over simulated and real world HF radio channels we have achieved output speech intelligibility that clearly surpasses existing analog and digital radio systems over a range of SNRs.

Paper number 124:
Title: Neural Spectral Band Generation for Audio Coding
Authors: Woongjib Choi, Byeong Hyeon Kim, Hyungseob Lim, Inseon Jang, Hong-Goo Kang
Abstract: Spectral band replication (SBR) enables bit-efficient coding by generating high-frequency bands from the low-frequency ones. However, it only utilizes coarse spectral features upon a subband-wise signal replication, limiting adaptability to diverse acoustic signals. In this paper, we explore the efficacy of a deep neural network (DNN)-based generative approach for coding the high-frequency bands, which we call neural spectral band generation (n-SBG). Specifically, we propose a DNN-based encoder-decoder structure to extract and quantize the side information related to the high-frequency components and generate the components given both the side information and the decoded core-band signals. The whole coding pipeline is optimized with generative adversarial criteria to enable the generation of perceptually plausible sound. From experiments using AAC as the core codec, we show that the proposed method achieves a better perceptual quality than HE-AAC-v1 with much less side information.

Paper number 125:
Title: Text-guided multi-stage cross-perception network for medical image segmentation
Authors: Gaoyu Chen, Haixia Pan
Abstract: Medical image segmentation plays a crucial role in clinical medicine, serving as a tool for auxiliary diagnosis, treatment planning, and disease monitoring, thus facilitating physicians in the study and treatment of diseases. However, existing medical image segmentation methods are limited by the weak semantic expression of the target segmentation regions, which is caused by the low contrast between the target and non-target segmentation regions. To address this limitation, text prompt information has greast potential to capture the lesion location. However, existing text-guided methods suffer from insufficient cross-modal interaction and inadequate cross-modal feature expression. To resolve these issues, we propose the Text-guided Multi-stage Cross-perception network (TMC). In TMC, we introduce a multistage cross-attention module to enhance the model's understanding of semantic details and a multi-stage alignment loss to improve the consistency of cross-modal semantics. The results of the experiments demonstrate that our TMC achieves a superior performance with Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19, MosMedData and Breast), outperforming UNet based networks and text-guided methods.

Paper number 126:
Title: ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator
Authors: Wenlong Hou, Guangqian Yang, Ye Du, Yeung Lau, Lihao Liu, Junjun He, Ling Long, Shujun Wang
Abstract: Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disease. Early and precise diagnosis of AD is crucial for timely intervention and treatment planning to alleviate the progressive neurodegeneration. However, most existing methods rely on single-modality data, which contrasts with the multifaceted approach used by medical experts. While some deep learning approaches process multi-modal data, they are limited to specific tasks with a small set of input modalities and cannot handle arbitrary combinations. This highlights the need for a system that can address diverse AD-related tasks, process multi-modal or missing input, and integrate multiple advanced methods for improved performance. In this paper, we propose ADAgent, the first specialized AI agent for AD analysis, built on a large language model (LLM) to address user queries and support decision-making. ADAgent integrates a reasoning engine, specialized medical tools, and a collaborative outcome coordinator to facilitate multi-modal diagnosis and prognosis tasks in AD. Extensive experiments demonstrate that ADAgent outperforms SOTA methods, achieving significant improvements in accuracy, including a 2.7% increase in multi-modal diagnosis, a 0.7% improvement in multi-modal prognosis, and enhancements in MRI and PET diagnosis tasks.

Paper number 127:
Title: Conformal Safety Shielding for Imperfect-Perception Agents
Authors: William Scarbro, Calum Imrie, Sinem Getir Yaman, Kavan Fatehi, Corina S. Pasareanu, Radu Calinescu, Ravi Mangal
Abstract: We consider the problem of safe control in discrete autonomous agents that use learned components for imperfect perception (or more generally, state estimation) from high-dimensional observations. We propose a shield construction that provides run-time safety guarantees under perception errors by restricting the actions available to an agent, modeled as a Markov decision process, as a function of the state estimates. Our construction uses conformal prediction for the perception component, which guarantees that for each observation, the predicted set of estimates includes the actual state with a user-specified probability. The shield allows an action only if it is allowed for all the estimates in the predicted set, resulting in local safety. We also articulate and prove a global safety property of existing shield constructions for perfect-perception agents bounding the probability of reaching unsafe states if the agent always chooses actions prescribed by the shield. We illustrate our approach with a case-study of an experimental autonomous system that guides airplanes on taxiways using high-dimensional perception DNNs.

Paper number 128:
Title: AI-Driven Radio Propagation Prediction in Automated Warehouses using Variational Autoencoders
Authors: Rahul Gulia, Amlan Ganguly, Andres Kwasinski, Michael E. Kuhl, Ehsan Rashedi, Clark Hochgraf
Abstract: The next decade will usher in a profound transformation of wireless communication, driven by the ever-increasing demand for data-intensive applications and the rapid adoption of emerging technologies. To fully unlock the potential of 5G and beyond, substantial advancements are required in signal processing techniques, innovative network architectures, and efficient spectrum utilization strategies. These advancements facilitate seamless integration of emerging technologies, driving industrial digital transformation and connectivity. This paper introduces a novel Variational Autoencoder (VAE)-based framework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA), designed for accurate indoor radio propagation modeling in automated Industry 4.0 environments such as warehouses and factory floors operating within 5G wireless bands. The research delves into the meticulous creation of training data tensors, capturing complex electromagnetic (EM) wave behaviors influenced by diverse obstacles, and outlines the architecture and training methodology of the proposed VAE model. The model's robustness and adaptability are showcased through its ability to predict signal-to-interference-plus-noise ratio (SINR) heatmaps across various scenarios, including denoising tasks, validation datasets, extrapolation to unseen configurations, and previously unencountered warehouse layouts. Compelling reconstruction error heatmaps are presented, highlighting the superior accuracy of WISVA compared to traditional autoencoder models. The paper also analyzes the model's performance in handling complex smart warehouse environments, demonstrating its potential as a key enabler for optimizing wireless infrastructure in Industry 4.0.

Paper number 129:
Title: Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses
Authors: He-Yang Xu, Hongxiang Gao, Yuwen Li, Xiu-Shen Wei, Chengyu Liu
Abstract: The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance.

Paper number 130:
Title: A Hybrid Mean Field Framework for Aggregators Participating in Wholesale Electricity Markets
Authors: Jun He, Andrew L. Liu
Abstract: The rapid growth of distributed energy resources (DERs), including rooftop solar and energy storage, is transforming the grid edge, where distributed technologies and customer-side systems increasingly interact with the broader power grid. DER aggregators, entities that coordinate and optimize the actions of many small-scale DERs, play a key role in this transformation. This paper presents a hybrid Mean-Field Control (MFC) and Mean-Field Game (MFG) framework for integrating DER aggregators into wholesale electricity markets. Unlike traditional approaches that treat market prices as exogenous, our model captures the feedback between aggregators' strategies and locational marginal prices (LMPs) of electricity. The MFC component optimizes DER operations within each aggregator, while the MFG models strategic interactions among multiple aggregators. To account for various uncertainties, we incorporate reinforcement learning (RL), which allows aggregators to learn optimal bidding strategies in dynamic market conditions. We prove the existence and uniqueness of a mean-field equilibrium and validate the framework through a case study of the Oahu Island power system. Results show that our approach reduces price volatility and improves market efficiency, offering a scalable and decentralized solution for DER integration in wholesale markets.

Paper number 131:
Title: Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation
Authors: Thomas Wallace, Ik Siong Heng, Senad Subasic, Chris Messenger
Abstract: Synthetic images are an option for augmenting limited medical imaging datasets to improve the performance of various machine learning models. A common metric for evaluating synthetic image quality is the Fréchet Inception Distance (FID) which measures the similarity of two image datasets. In this study we evaluate the relationship between this metric and the improvement which synthetic images, generated by a Progressively Growing Generative Adversarial Network (PGGAN), grant when augmenting Diabetes-related Macular Edema (DME) intraretinal fluid segmentation performed by a U-Net model with limited amounts of training data. We find that the behaviour of augmenting with standard and synthetic images agrees with previously conducted experiments. Additionally, we show that dissimilar (high FID) datasets do not improve segmentation significantly. As FID between the training and augmenting datasets decreases, the augmentation datasets are shown to contribute to significant and robust improvements in image segmentation. Finally, we find that there is significant evidence to suggest that synthetic and standard augmentations follow separate log-normal trends between FID and improvements in model performance, with synthetic data proving more effective than standard augmentation techniques. Our findings show that more similar datasets (lower FID) will be more effective at improving U-Net performance, however, the results also suggest that this improvement may only occur when images are sufficiently dissimilar.

Paper number 132:
Title: Beyond Manual Annotation: A Human-AI Collaborative Framework for Medical Image Segmentation Using Only "Better or Worse" Expert Feedback
Authors: Yizhe Zhang
Abstract: Manual annotation of medical images is a labor-intensive and time-consuming process, posing a significant bottleneck in the development and deployment of robust medical imaging AI systems. This paper introduces a novel hands-free Human-AI collaborative framework for medical image segmentation that substantially reduces the annotation burden by eliminating the need for explicit manual pixel-level labeling. The core innovation lies in a preference learning paradigm, where human experts provide minimal, intuitive feedback -- simply indicating whether an AI-generated segmentation is better or worse than a previous version. The framework comprises four key components: (1) an adaptable foundation model (FM) for feature extraction, (2) label propagation based on feature similarity, (3) a clicking agent that learns from human better-or-worse feedback to decide where to click and with which label, and (4) a multi-round segmentation learning procedure that trains a state-of-the-art segmentation network using pseudo-labels generated by the clicking agent and FM-based label propagation. Experiments on three public datasets demonstrate that the proposed approach achieves competitive segmentation performance using only binary preference feedback, without requiring experts to directly manually annotate the images.

Paper number 133:
Title: A Differential Evolution Algorithm with Neighbor-hood Mutation for DOA Estimation
Authors: Bo Zhou, Kaijie Xu, Yinghui Quan, Mengdao Xing
Abstract: Two-dimensional (2D) Multiple Signal Classification algorithm is a powerful technique for high-resolution direction-of-arrival (DOA) estimation in array signal processing. However, the exhaustive search over the 2D an-gular domain leads to high computa-tional cost, limiting its applicability in real-time scenarios. In this work, we reformulate the peak-finding process as a multimodal optimization prob-lem, and propose a Differential Evolu-tion algorithm with Neighborhood Mutation (DE-NM) to efficiently lo-cate multiple spectral peaks without requiring dense grid sampling. Simu-lation results demonstrate that the proposed method achieves comparable estimation accuracy to the traditional grid search, while significantly reduc-ing computation time. This strategy presents a promising solution for real-time, high-resolution DOA estimation in practical applications. The imple-mentation code is available at this https URL.

Paper number 134:
Title: Learning Koopman Models From Data Under General Noise Conditions
Authors: Lucian Cristian Iacob, Máté Szécsi, Gerben Izaak Beintema, Maarten Schoukens, Roland Tóth
Abstract: This paper presents a novel identification approach of Koopman models of nonlinear systems with inputs under rather general noise conditions. The method uses deep state-space encoders based on the concept of state reconstructability and an efficient multiple-shooting formulation of the squared loss of the prediction error to estimate the dynamics and the lifted state from input-output data. Furthermore, the Koopman model structure includes an innovation noise term that is used to handle process and measurement noise. It is shown that the proposed approach is statistically consistent and computationally efficient due to the multiple-shooting formulation where, on subsections of the data, multi-step prediction errors can be calculated in parallel. The latter allows for efficient batch optimization of the network parameters and, at the same time, excellent long-term prediction capabilities of the obtained models. The performance of the approach is illustrated by nonlinear benchmark examples.

Paper number 135:
Title: IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution
Authors: Sejin Park, Sangmin Lee, Kyong Hwan Jin, Seung-Won Jung
Abstract: Super-resolution (SR) has been a pivotal task in image processing, aimed at enhancing image resolution across various applications. Recently, look-up table (LUT)-based approaches have attracted interest due to their efficiency and performance. However, these methods are typically designed for fixed scale factors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing ASISR techniques often employ implicit neural representations, which come with considerable computational cost and memory demands. To address these limitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework that operates ASISR by learning to blend multiple interpolation functions to maximize their representational capacity. Specifically, we introduce IM-Net, a network trained to predict mixing weights for interpolation functions based on local image patterns and the target scale factor. To enhance efficiency of interpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are employed to replace computationally expensive operations, enabling lightweight and fast inference on CPUs while preserving reconstruction quality. Experimental results on several benchmark datasets demonstrate that IM-LUT consistently achieves a superior balance between image quality and efficiency compared to existing methods, highlighting its potential as a promising solution for resource-constrained applications.

Paper number 136:
Title: OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models
Authors: Ningyong Wu, Jinzhi Wang, Wenhong Zhao, Chenzhan Yu, Zhigang Xiu, Duwei Dai
Abstract: The growing volume of medical imaging data has increased the need for automated diagnostic tools, especially for musculoskeletal injuries like rib fractures, commonly detected via CT scans. Manual interpretation is time-consuming and error-prone. We propose OrthoInsight, a multi-modal deep learning framework for rib fracture diagnosis and report generation. It integrates a YOLOv9 model for fracture detection, a medical knowledge graph for retrieving clinical context, and a fine-tuned LLaVA language model for generating diagnostic reports. OrthoInsight combines visual features from CT images with expert textual data to deliver clinically useful outputs. Evaluated on 28,675 annotated CT images and expert reports, it achieves high performance across Diagnostic Accuracy, Content Completeness, Logical Coherence, and Clinical Guidance Value, with an average score of 4.28, outperforming models like GPT-4 and Claude-3. This study demonstrates the potential of multi-modal learning in transforming medical image analysis and providing effective support for radiologists.

Paper number 137:
Title: Recursive KalmanNet: Analyse des capacités de généralisation d'un réseau de neurones récurrent guidé par un filtre de Kalman
Authors: Cyril Falcon, Hassan Mortada, Mathéo Clavaud, Jean-Philippe Michel
Abstract: The Recursive KalmanNet, recently introduced by the authors, is a recurrent neural network guided by a Kalman filter, capable of estimating the state variables and error covariance of stochastic dynamic systems from noisy measurements, without prior knowledge of the noise characteristics. This paper explores its generalization capabilities in out-of-distribution scenarios, where the temporal dynamics of the test measurements differ from those encountered during training. Le Recursive KalmanNet, récemment introduit par les auteurs, est un réseau de neurones récurrent guidé par un filtre de Kalman, capable d'estimer les variables d'état et la covariance des erreurs des systèmes dynamiques stochastiques à partir de mesures bruitées, sans connaissance préalable des caractéristiques des bruits. Cet article explore ses capacités de généralisation dans des scénarios hors distribution, où les dynamiques temporelles des mesures de test diffèrent de celles rencontrées à l'entraînement.

Paper number 138:
Title: An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems
Authors: Mahyar Mahinzaeim, Kamyar Mehran
Abstract: This is an expository paper which discusses an approach to the LQG/LTR design problem for finite-dimensional SISO control systems. The approach is based on the utilisation of weighting augmentation for incorporating design specifications into the framework of the LTR technique for LQG compensator design. The LQG compensator is to simultaneously meet given analytical low- and high-frequency design specifications expressed in terms of desirable sensitivity and controller noise sensitivity functions. The paper is aimed at nonspecialists and, in particular, practitioners in finite-dimensional LQG theory interested in the design of feedback compensators for closed-loop performance and robustness shaping of SISO control systems in realistic situations. The proposed approach is illustrated by a detailed numerical example: the torque control of a current-controlled DC motor with an elastically mounted rotor.

Paper number 139:
Title: SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding
Authors: Linye Wei, Shuzhang Zhong, Songqiang Xu, Runsheng Wang, Ru Huang, Meng Li
Abstract: Large language model (LLM)-based automatic speech recognition (ASR) has recently attracted a lot of attention due to its high recognition accuracy and enhanced multi-dialect support. However, the high decoding latency of LLMs challenges the real-time ASR requirements. Although speculative decoding has been explored for better decoding efficiency, they usually ignore the key characteristics of the ASR task and achieve limited speedup. To further reduce the real-time ASR latency, in this paper, we propose a novel speculative decoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed based on our core observation that ASR decoding is audio-conditioned, which results in high output alignment between small and large ASR models, even given output mismatches in intermediate decoding steps. Therefore, SpecASR features an adaptive draft sequence generation process that dynamically modifies the draft sequence length to maximize the token acceptance length. SpecASR further proposes a draft sequence recycling strategy that reuses the previously generated draft sequence to reduce the draft ASR model latency. Moreover, a two-pass sparse token tree generation algorithm is also proposed to balance the latency of draft and target ASR models. With extensive experimental results, we demonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the baseline autoregressive decoding and speculative decoding, respectively, without any loss in recognition accuracy.

Paper number 140:
Title: Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?
Authors: Simon Malan, Benjamin van Niekerk, Herman Kamper
Abstract: We investigate the problem of segmenting unlabeled speech into word-like units and clustering these to create a lexicon. Prior work can be categorized into two frameworks. Bottom-up methods first determine boundaries and then cluster the fixed segmented words into a lexicon. In contrast, top-down methods incorporate information from the clustered words to inform boundary selection. However, it is unclear whether top-down information is necessary to improve segmentation. To explore this, we look at two similar approaches that differ in whether top-down clustering informs boundary selection. Our simple bottom-up strategy predicts word boundaries using the dissimilarity between adjacent self-supervised features, then clusters the resulting segments to construct a lexicon. Our top-down system is an updated version of the ES-KMeans dynamic programming method that iteratively uses K-means to update its boundaries. On the five-language ZeroSpeech benchmarks, both approaches achieve comparable state-of-the-art results, with the bottom-up system being nearly five times faster. Through detailed analyses, we show that the top-down influence of ES-KMeans can be beneficial (depending on factors like the candidate boundaries), but in many cases the simple bottom-up method performs just as well. For both methods, we show that the clustering step is a limiting factor. Therefore, we recommend that future work focus on improved clustering techniques and learning more discriminative word-like representations. Project code repository: this https URL.

Paper number 141:
Title: A multi-dynamic low-rank deep image prior (ML-DIP) for real-time 3D cardiovascular MRI
Authors: Chong Chen, Marc Vornehm, Preethi Chandrasekaran, Muhammad A. Sultan, Syed M. Arshad, Yingmin Liu, Yuchi Han, Rizwan Ahmad
Abstract: Purpose: To develop a reconstruction framework for 3D real-time cine cardiovascular magnetic resonance (CMR) from highly undersampled data without requiring fully sampled training data. Methods: We developed a multi-dynamic low-rank deep image prior (ML-DIP) framework that models spatial image content and temporal deformation fields using separate neural networks. These networks are optimized per scan to reconstruct the dynamic image series directly from undersampled k-space data. ML-DIP was evaluated on (i) a 3D cine digital phantom with simulated premature ventricular contractions (PVCs), (ii) ten healthy subjects (including two scanned during both rest and exercise), and (iii) five patients with PVCs. Phantom results were assessed using peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM). In vivo performance was evaluated by comparing left-ventricular function quantification (against 2D real-time cine) and image quality (against 2D real-time cine and binning-based 5D-Cine). Results: In the phantom study, ML-DIP achieved PSNR > 29 dB and SSIM > 0.90 for scan times as short as two minutes, while recovering cardiac motion, respiratory motion, and PVC events. In healthy subjects, ML-DIP yielded functional measurements comparable to 2D cine and higher image quality than 5D-Cine, including during exercise with high heart rates and bulk motion. In PVC patients, ML-DIP preserved beat-to-beat variability and reconstructed irregular beats, whereas 5D-Cine showed motion artifacts and information loss due to binning. Conclusion: ML-DIP enables high-quality 3D real-time CMR with acceleration factors exceeding 1,000 by learning low-rank spatial and temporal representations from undersampled data, without relying on external fully sampled training datasets.

Paper number 142:
Title: A Validation Approach to Over-parameterized Matrix and Image Recovery
Authors: Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu
Abstract: This paper studies the problem of recovering a low-rank matrix from several noisy random linear measurements. We consider the setting where the rank of the ground-truth matrix is unknown a priori and use an objective function built from a rank-overspecified factored representation of the matrix variable, where the global optimal solutions overfit and do not correspond to the underlying ground truth. We then solve the associated nonconvex problem using gradient descent with small random initialization. We show that as long as the measurement operators satisfy the restricted isometry property (RIP) with its rank parameter scaling with the rank of the ground-truth matrix rather than scaling with the overspecified matrix rank, gradient descent iterations are on a particular trajectory towards the ground-truth matrix and achieve nearly information-theoretically optimal recovery when it is stopped appropriately. We then propose an efficient stopping strategy based on the common hold-out method and show that it detects a nearly optimal estimator provably. Moreover, experiments show that the proposed validation approach can also be efficiently used for image restoration with deep image prior, which over-parameterizes an image with a deep network.

Paper number 143:
Title: On data-driven Wasserstein distributionally robust Nash equilibrium problems with heterogeneous uncertainty
Authors: Georgios Pantazis, Barbara Franci, Sergio Grammatico
Abstract: We study stochastic Nash equilibrium problems subject to heterogeneous uncertainty on the expected valued cost functions of the individual agents, where we assume no prior knowledge of the underlying probability distributions of the uncertain variables. To account for this lack of knowledge, we consider an ambiguity set around the empirical probability distribution under the Wasserstein metric. We then show that, under mild assumptions, finite-sample guarantees on the probability that any resulting distributionally robust Nash equilibrium is also robust with respect to the true probability distributions with high confidence can be obtained. Furthermore, by recasting the game as a distributionally robust variational inequality, we establish asymptotic consistency of the set of data-driven distributionally robust equilibria to the solution set of the original game. Finally, we recast the distributionally robust Nash game as a finite-dimensional Nash equilibrium problem. We illustrate the proposed distributionally robust reformulation via numerical experiments of stochastic peer-to-peer electricity markets and Nash-Cournot games.

Paper number 144:
Title: DRL-AdaPart: DRL-Driven Adaptive STAR-RIS Partitioning for Fair and Frugal Resource Utilization
Authors: Ashok S. Kumar, Nancy Nayak, Sheetal Kalyani, Himal A. Suraweera
Abstract: In this work, we propose a method for efficient resource utilization of simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) elements to ensure fair and high data rates. We introduce a subsurface assignment variable that determines the number of STAR-RIS elements allocated to each user and maximizes the sum of the data rates by jointly optimizing the phase shifts of the STAR-RIS and the subsurface assignment variables using an appropriately tailored deep reinforcement learning (DRL) algorithm. The proposed DRL method is also compared with a Dinkelbach algorithm and the designed hybrid DRL approach. A penalty term is incorporated into the DRL model to enhance resource utilization by intelligently deactivating STAR-RIS elements when not required. The proposed DRL method can achieve fair and high data rates for static and mobile users while ensuring efficient resource utilization through extensive simulations. Using the proposed DRL method, up to 27% and 21% of STAR-RIS elements can be deactivated in static and mobile scenarios, respectively, without affecting performance.

Paper number 145:
Title: Computer Audition: From Task-Specific Machine Learning to Foundation Models
Authors: Andreas Triantafyllopoulos, Iosif Tsangko, Alexander Gebhard, Annamaria Mesaros, Tuomas Virtanen, Björn Schuller
Abstract: Foundation models (FMs) are increasingly spearheading recent advances on a variety of tasks that fall under the purview of computer audition -- the use of machines to understand sounds. They feature several advantages over traditional pipelines: among others, the ability to consolidate multiple tasks in a single model, the option to leverage knowledge from other modalities, and the readily-available interaction with human users. Naturally, these promises have created substantial excitement in the audio community, and have led to a wave of early attempts to build new, general-purpose foundation models for audio. In the present contribution, we give an overview of computational audio analysis as it transitions from traditional pipelines towards auditory foundation models. Our work highlights the key operating principles that underpin those models, and showcases how they can accommodate multiple tasks that the audio community previously tackled separately.

Paper number 146:
Title: The Impact of LoRA Adapters on LLMs for Clinical Text Classification Under Computational and Data Constraints
Authors: Thanh-Dung Le, Ti Ti Nguyen, Vu Nguyen Ha, Symeon Chatzinotas, Philippe Jouvet, Rita Noumeir
Abstract: Fine-tuning Large Language Models (LLMs) for clinical Natural Language Processing (NLP) poses significant challenges due to domain gap, limited data, and stringent hardware constraints. In this study, we evaluate four adapter techniques-Adapter, Lightweight, TinyAttention, and Gated Residual Network (GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note classification under real-world, resource-constrained conditions. All experiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512 CUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to <8 sequences and maximum sequence length to 256 tokens. Our clinical corpus comprises only 580 000 tokens, several orders of magnitude smaller than standard LLM pre-training datasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio, AliBERT, DrBERT) and two lightweight Transformer models trained from scratch. Results show that 1) adapter structures provide no consistent gains when fine-tuning biomedical LLMs under these constraints, and 2) simpler Transformers, with minimal parameter counts and training times under six hours, outperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among adapters, GRN achieved the best metrics (accuracy, precision, recall, F1 = 0.88). These findings demonstrate that, in low-resource clinical settings with limited data and compute, lightweight Transformers trained from scratch offer a more practical and efficient solution than large LLMs, while GRN remains a viable adapter choice when minimal adaptation is needed.

Paper number 147:
Title: Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty
Authors: Sara Pohland, Claire Tomlin
Abstract: Perception-based navigation systems are useful for unmanned ground vehicle (UGV) navigation in complex terrains, where traditional depth-based navigation schemes are insufficient. However, these data-driven methods are highly dependent on their training data and can fail in surprising and dramatic ways with little warning. To ensure the safety of the vehicle and the surrounding environment, it is imperative that the navigation system is able to recognize the predictive uncertainty of the perception model and respond safely and effectively in the face of uncertainty. In an effort to enable safe navigation under perception uncertainty, we develop a probabilistic and reconstruction-based competency estimation (PaRCE) method to estimate the model's level of familiarity with an input image as a whole and with specific regions in the image. We find that the overall competency score can correctly predict correctly classified, misclassified, and out-of-distribution (OOD) samples. We also confirm that the regional competency maps can accurately distinguish between familiar and unfamiliar regions across images. We then use this competency information to develop a planning and control scheme that enables effective navigation while maintaining a low probability of error. We find that the competency-aware scheme greatly reduces the number of collisions with unfamiliar obstacles, compared to a baseline controller with no competency awareness. Furthermore, the regional competency information is very valuable in enabling efficient navigation.

Paper number 148:
Title: Safe and Real-Time Consistent Planning for Autonomous Vehicles in Partially Observed Environments via Parallel Consensus Optimization
Authors: Lei Zheng, Rui Yang, Minzhe Zheng, Michael Yu Wang, Jun Ma
Abstract: Ensuring safety and driving consistency is a significant challenge for autonomous vehicles operating in partially observed environments. This work introduces a consistent parallel trajectory optimization (CPTO) approach to enable safe and consistent driving in dense obstacle environments with perception uncertainties. Utilizing discrete-time barrier function theory, we develop a consensus safety barrier module that ensures reliable safety coverage within the spatiotemporal trajectory space across potential obstacle configurations. Following this, a bi-convex parallel trajectory optimization problem is derived that facilitates decomposition into a series of low-dimensional quadratic programming problems to accelerate computation. By leveraging the consensus alternating direction method of multipliers (ADMM) for parallel optimization, each generated candidate trajectory corresponds to a possible environment configuration while sharing a common consensus trajectory segment. This ensures driving safety and consistency when executing the consensus trajectory segment for the ego vehicle in real time. We validate our CPTO framework through extensive comparisons with state-of-the-art baselines across multiple driving tasks in partially observable environments. Our results demonstrate improved safety and consistency using both synthetic and real-world traffic datasets.

Paper number 149:
Title: Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models
Authors: Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu
Abstract: Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked audio dialogue capabilities, enabling direct spoken exchanges with humans. The potential of LALMs broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these advancements, a comprehensive benchmark to evaluate the performance of LALMs in the open-ended audio dialogue understanding remains absent currently. To address this gap, we propose an Audio Dialogue Understanding Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9 multilingual languages, and 4 categories of ambiguity handling. Notably, we firstly propose the evaluation of ambiguity handling in audio dialogues that expresses different intentions beyond the same literal meaning of sentences, e.g., "Really!?" with different intonations. In summary, ADU-Bench includes over 20,000 open-ended audio dialogues for the assessment of LALMs. Through extensive experiments on 16 LALMs, our analysis reveals that existing LALMs struggle with mathematical symbols and formulas, understanding human behavior such as roleplay, comprehending multiple languages, and handling audio dialogue ambiguities from different phonetic elements, such as intonations, pause positions, and homophones. The benchmark is available at this https URL.

Paper number 150:
Title: A Combined Channel Approach for Decoding Intracranial EEG Signals: Enhancing Accuracy through Spatial Information Integration
Authors: Maryam Ostadsharif Memar, Navid Ziaei, Behzad Nazari
Abstract: Intracranial EEG (iEEG) recording, characterized by high spatial and temporal resolution and superior signal-to-noise ratio (SNR), enables the development of precise brain-computer interface (BCI) systems for neural decoding. However, the invasive nature of the procedure significantly limits the availability of iEEG datasets in terms of both the number of participants and the duration of recorded sessions. To address this limitation, we propose a single-participant machine learning model optimized for decoding iEEG signals. The model employs 18 key features and operates in two modes: best channel and combined channel. The combined channel mode integrates spatial information from multiple brain regions, leading to superior classification performance. Evaluations across three datasets -- Music Reconstruction, Audio Visual, and AJILE12 -- demonstrate that the combined channel mode consistently outperforms the best channel mode across all classifiers. In the best-performing cases, Random Forest achieved an F1 score of 0.81 +/- 0.05 in the Music Reconstruction dataset and 0.82 +/- 0.10 in the Audio Visual dataset, while XGBoost achieved an F1 score of 0.84 +/- 0.08 in the AJILE12 dataset. Furthermore, the analysis of brain region contributions in the combined channel mode revealed that the model identifies relevant brain regions aligned with physiological expectations for each task and effectively combines data from electrodes in these regions to achieve high performance. These findings highlight the potential of integrating spatial information across brain regions to improve task decoding, offering new avenues for advancing BCI systems and neurotechnological applications.

Paper number 151:
Title: From DeepSense to Open RAN: AI/ML Advancements in Dynamic Spectrum Sensing and Their Applications
Authors: Ryan Barker
Abstract: The integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communication systems has become a cornerstone for advancing intelligent, adaptive, and scalable networks. This reading report examines key innovations in dynamic spectrum sensing (DSS), beginning with the foundational DeepSense framework, which uses convolutional neural networks (CNNs) and spectrogram-based analysis for real-time wideband spectrum monitoring. Building on this groundwork, it highlights advancements such as DeepSweep and Wideband Signal Stitching, which address the challenges of scalability, latency, and dataset diversity through parallel processing, semantic segmentation, and robust data augmentation strategies. The report then explores Open Radio Access Networks (ORAN), focusing on AI/ML-driven enhancements for UAV experimentation, digital twin-based optimization, network slicing, and self-healing xApp development. By bridging AI-based DSS methodologies with ORAN's open, vendor-neutral architecture, these studies underscore the potential of software-defined, intelligent infrastructures in enabling efficient, resilient, and self-optimizing networks for 5G/6G ecosystems. Through this synthesis, the report highlights AI's transformative role in shaping the future of wireless communication and autonomous systems.

Paper number 152:
Title: TAIL: Text-Audio Incremental Learning
Authors: Yingfei Sun, Xu Gu, Wei Ji, Hanbin Zhao, Yifang Yin, Roger Zimmermann
Abstract: Many studies combine text and audio to capture multi-modal information but they overlook the model's generalization ability on new datasets. Introducing new datasets may affect the feature space of the original dataset, leading to catastrophic forgetting. Meanwhile, large model parameters can significantly impact training performance. To address these limitations, we introduce a novel task called Text-Audio Incremental Learning (TAIL) task for text-audio retrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text incremental learning. This method utilizes prompt tuning to optimize the model parameters while incorporating an audio-text similarity and feature distillation module to effectively mitigate catastrophic forgetting. We benchmark our method and previous incremental learning methods on AudioCaps, Clotho, BBC Sound Effects and Audioset datasets, and our method outperforms previous methods significantly, particularly demonstrating stronger resistance to forgetting on older datasets. Compared to the full-parameters Finetune (Sequential) method, our model only requires 2.42\% of its parameters, achieving 4.46\% higher performance.

Paper number 153:
Title: The Pitfalls of Imitation Learning when Actions are Continuous
Authors: Max Simchowitz, Daniel Pfrommer, Ali Jadbabaie
Abstract: We study the problem of imitating an expert demonstrator in a discrete-time, continuous state-and-action control system. We show that, even if the dynamics satisfy a control-theoretic property called exponential stability (i.e. the effects of perturbations decay exponentially quickly), and the expert is smooth and deterministic, any smooth, deterministic imitator policy necessarily suffers error on execution that is exponentially larger, as a function of problem horizon, than the error under the distribution of expert training data. Our negative result applies to any algorithm which learns solely from expert data, including both behavior cloning and offline-RL algorithms, unless the algorithm produces highly "improper" imitator policies--those which are non-smooth, non-Markovian, or which exhibit highly state-dependent stochasticity--or unless the expert trajectory distribution is sufficiently "spread." We provide experimental evidence of the benefits of these more complex policy parameterizations, explicating the benefits of today's popular policy parameterizations in robot learning (e.g. action-chunking and diffusion policies). We also establish a host of complementary negative and positive results for imitation in control systems.

Paper number 154:
Title: Ordering and refining path-complete Lyapunov functions through composition lifts
Authors: Wouter Jongeneel, Raphaël M. Jungers
Abstract: A fruitful approach to study stability of switched systems is to look for multiple Lyapunov functions. However, in general, we do not yet understand the interplay between the desired stability certificate, the template of the Lyapunov functions and their mutual relationships to accommodate switching. In this work we elaborate on path-complete Lyapunov functions: a graphical framework that aims to elucidate this interplay. In particular, previously, several preorders were introduced to compare multiple Lyapunov functions. These preorders are initially algorithmically intractable due to the algebraic nature of Lyapunov inequalities, yet, lifting techniques were proposed to turn some preorders purely combinatorial and thereby eventually tractable. In this note we show that a conjecture in this area regarding the so-called composition lift, that was believed to be true, is false. This refutal, however, points us to a beneficial structural feature of the composition lift that we exploit to iteratively refine path-complete graphs, plus, it points us to a favourable adaptation of the composition lift.

Paper number 155:
Title: Scaling Analysis of Interleaved Speech-Text Language Models
Authors: Gallil Maimon, Michael Hassid, Amit Roth, Yossi Adi
Abstract: Existing Speech Language Model (SLM) scaling analysis paints a bleak picture. It predicts that SLMs require much more compute and data compared to text, leading some to question the feasibility of training high-quality SLMs. However, modern SLMs are often initialised from pre-trained TextLMs using speech-text interleaving to allow knowledge transfer. This raises the question - "Do interleaved SLMs scale more efficiently than textless-SLMs?" In this paper we answer a resounding yes! We conduct scaling analysis of interleaved SLMs by training several dozen and analysing the scaling trends. We see that under this setup SLMs scale more efficiently with compute. Additionally, our results indicate that the scaling dynamics significantly differ from textless-SLMs, suggesting one should allocate notably more of the compute budget to increasing model size over training tokens. We also study the role of synthetic data and TextLM model families in unlocking this potential. Results suggest that our scaled up model achieves comparable semantic speech performance to leading models, while using less compute and data. We open source models, samples, and data - this https URL .

Paper number 156:
Title: FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation
Authors: Yutong Liu, Ziyue Zhang, Ban Ma-bao, Yuqing Cai, Yongbin Yu, Renzeng Duojie, Xiangxiang Wang, Fan Gao, Cheng Huang, Nyima Tashi
Abstract: Tibetan is a low-resource language with minimal parallel speech corpora spanning its three major dialects-Ü-Tsang, Amdo, and Kham-limiting progress in speech modeling. To address this issue, we propose FMSD-TTS, a few-shot, multi-speaker, multi-dialect text-to-speech framework that synthesizes parallel dialectal speech from limited reference audio and explicit dialect labels. Our method features a novel speaker-dialect fusion module and a Dialect-Specialized Dynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and linguistic variations across dialects while preserving speaker identity. Extensive objective and subjective evaluations demonstrate that FMSD-TTS significantly outperforms baselines in both dialectal expressiveness and speaker similarity. We further validate the quality and utility of the synthesized speech through a challenging speech-to-speech dialect conversion task. Our contributions include: (1) a novel few-shot TTS system tailored for Tibetan multi-dialect speech synthesis, (2) the public release of a large-scale synthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source evaluation toolkit for standardized assessment of speaker similarity, dialect consistency, and audio quality.

Paper number 157:
Title: Predicting Neoadjuvant Chemotherapy Response in Triple-Negative Breast Cancer Using Pre-Treatment Histopathologic Images
Authors: Hikmat Khan, Ziyu Su, Huina Zhang, Yihong Wang, Bohan Ning, Shi Wei, Hua Guo, Zaibo Li, Muhammad Khalid Khan Niazi
Abstract: Triple-negative breast cancer (TNBC) remains a major clinical challenge due to its aggressive behavior and lack of targeted therapies. Accurate early prediction of response to neoadjuvant chemotherapy (NACT) is essential for guiding personalized treatment strategies and improving patient outcomes. In this study, we present an attention-based multiple instance learning (MIL) framework designed to predict pathologic complete response (pCR) directly from pre-treatment hematoxylin and eosin (H&E)-stained biopsy slides. The model was trained on a retrospective in-house cohort of 174 TNBC patients and externally validated on an independent cohort (n = 30). It achieved a mean area under the curve (AUC) of 0.85 during five-fold cross-validation and 0.78 on external testing, demonstrating robust predictive performance and generalizability. To enhance model interpretability, attention maps were spatially co-registered with multiplex immuno-histochemistry (mIHC) data stained for PD-L1, CD8+ T cells, and CD163+ macrophages. The attention regions exhibited moderate spatial overlap with immune-enriched areas, with mean Intersection over Union (IoU) scores of 0.47 for PD-L1, 0.45 for CD8+ T cells, and 0.46 for CD163+ macrophages. The presence of these biomarkers in high-attention regions supports their biological relevance to NACT response in TNBC. This not only improves model interpretability but may also inform future efforts to identify clinically actionable histological biomarkers directly from H&E-stained biopsy slides, further supporting the utility of this approach for accurate NACT response prediction and advancing precision oncology in TNBC.

Paper number 158:
Title: CP-LLM: Context and Pixel Aware Large Language Model for Video Quality Assessment
Authors: Wen Wen, Yaohong Wu, Yue Sheng, Neil Birkbeck, Balu Adsumilli, Yilin Wang
Abstract: Video quality assessment (VQA) is a challenging research topic with broad applications. Effective VQA necessitates sensitivity to pixel-level distortions and a comprehensive understanding of video context to accurately determine the perceptual impact of distortions. Traditional hand-crafted and learning-based VQA models mainly focus on pixel-level distortions and lack contextual understanding, while recent LLM-based models struggle with sensitivity to small distortions or handle quality scoring and description as separate tasks. To address these shortcomings, we introduce CP-LLM: a Context and Pixel aware Large Language Model. CP-LLM is a novel multimodal LLM architecture featuring dual vision encoders designed to independently analyze perceptual quality at both high-level (video context) and low-level (pixel distortion) granularity, along with a language decoder subsequently reasons about the interplay between these aspects. This design enables CP-LLM to simultaneously produce robust quality scores and interpretable quality descriptions, with enhanced sensitivity to pixel distortions (e.g. compression artifacts). The model is trained via a multi-task pipeline optimizing for score prediction, description generation, and pairwise comparisons. Experiment results demonstrate that CP-LLM achieves state-of-the-art cross-dataset performance on established VQA benchmarks and superior robustness to pixel distortions, confirming its efficacy for comprehensive and practical video quality assessment in real-world scenarios.

Paper number 159:
Title: Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory
Authors: Sota Yoshihara (1), Ryosuke Yamamoto (2), Hiroyuki Kusumoto (1), Masanari Shimura (1) ((1) Graduate School of Mathematics, Nagoya University, (2) AISIN SOFTWARE Co., Ltd.)
Abstract: This paper proposes a novel theoretical framework for guaranteeing and evaluating the resilience of long short-term memory (LSTM) networks in control systems. We introduce "recovery time" as a new metric of resilience in order to quantify the time required for an LSTM to return to its normal state after anomalous inputs. By mathematically refining incremental input-to-state stability ($\delta$ISS) theory for LSTM, we derive a practical data-independent upper bound on recovery time. This upper bound gives us resilience-aware training. Experimental validation on simple models demonstrates the effectiveness of our resilience estimation and control methods, enhancing a foundation for rigorous quality assurance in safety-critical AI applications.

Paper number 160:
Title: Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation
Authors: Yihong Cao, Jiaming Zhang, Xu Zheng, Hao Shi, Kunyu Peng, Hang Liu, Kailun Yang, Hui Zhang
Abstract: Panoramic image processing is essential for omni-context perception, yet faces constraints like distortions, perspective occlusions, and limited annotations. Previous unsupervised domain adaptation methods transfer knowledge from labeled pinhole data to unlabeled panoramic images, but they require access to source pinhole data. To address these, we introduce a more practical task, i.e., Source-Free Occlusion-Aware Seamless Segmentation (SFOASS), and propose its first solution, called UNconstrained Learning Omni-Context Knowledge (UNLOCK). Specifically, UNLOCK includes two key modules: Omni Pseudo-Labeling Learning and Amodal-Driven Context Learning. While adapting without relying on source data or target labels, this framework enhances models to achieve segmentation with 360° viewpoint coverage and occlusion-aware reasoning. Furthermore, we benchmark the proposed SFOASS task through both real-to-real and synthetic-to-real adaptation settings. Experimental results show that our source-free method achieves performance comparable to source-dependent methods, yielding state-of-the-art scores of 10.9 in mAAP and 11.6 in mAP, along with an absolute improvement of +4.3 in mAPQ over the source-only method. All data and code will be made publicly available at this https URL.

Paper number 161:
Title: ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech
Authors: Gautam Siddharth Kashyap, Mohammad Anas Azeez, Rafiq Ali, Zohaib Hasan Siddiqui, Jiechao Gao, Usman Naseem
Abstract: Hate speech targeting children on social media is a serious and growing problem, yet current NLP systems struggle to detect it effectively. This gap exists mainly because existing datasets focus on adults, lack age specific labels, miss nuanced linguistic cues, and are often too small for robust modeling. To address this, we introduce ChildGuard, the first large scale English dataset dedicated to hate speech aimed at children. It contains 351,877 annotated examples from X (formerly Twitter), Reddit, and YouTube, labeled by three age groups: younger children (under 11), pre teens (11--12), and teens (13--17). The dataset is split into two subsets for fine grained analysis: a contextual subset (157K) focusing on discourse level features, and a lexical subset (194K) emphasizing word-level sentiment and vocabulary. Benchmarking state of the art hate speech models on ChildGuard reveals notable drops in performance, highlighting the challenges of detecting child directed hate speech.

Paper number 162:
Title: A Novel Hybrid Grey Wolf Differential Evolution Algorithm
Authors: Ioannis D. Bougas, Pavlos Doanis, Maria S. Papadopoulou, Achilles D. Boursianis, Sotirios P. Sotiroudis, Zaharias D. Zaharis, George Koudouridis, Panagiotis Sarigiannidis, Mohammad Abdul Matint, George Karagiannidis, Sotirios K. Goudos
Abstract: Grey wolf optimizer (GWO) is a nature-inspired stochastic meta-heuristic of the swarm intelligence field that mimics the hunting behavior of grey wolves. Differential evolution (DE) is a popular stochastic algorithm of the evolutionary computation field that is well suited for global optimization. In this part, we introduce a new algorithm based on the hybridization of GWO and two DE variants, namely the GWO-DE algorithm. We evaluate the new algorithm by applying various numerical benchmark functions. The numerical results of the comparative study are quite satisfactory in terms of performance and solution quality.

Paper number 163:
Title: From General to Specialized: The Need for Foundational Models in Agriculture
Authors: Vishal Nedungadi, Xingguo Xiong, Aike Potze, Ron Van Bree, Tao Lin, Marc Rußwurm, Ioannis N. Athanasiadis
Abstract: Food security remains a global concern as population grows and climate change intensifies, demanding innovative solutions for sustainable agricultural productivity. Recent advances in foundation models have demonstrated remarkable performance in remote sensing and climate sciences, and therefore offer new opportunities for agricultural monitoring. However, their application in challenges related to agriculture-such as crop type mapping, crop phenology estimation, and crop yield estimation-remains under-explored. In this work, we quantitatively evaluate existing foundational models to assess their effectivity for a representative set of agricultural tasks. From an agricultural domain perspective, we describe a requirements framework for an ideal agricultural foundation model (CropFM). We then survey and compare existing general-purpose foundational models in this framework and empirically evaluate two exemplary of them in three representative agriculture specific tasks. Finally, we highlight the need for a dedicated foundational model tailored specifically to agriculture.

Paper number 164:
Title: BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning
Authors: Ruohong Liu, Jack Umenberger, Yize Chen
Abstract: Recent years have seen significant advancements in designing reinforcement learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.

Paper number 165:
Title: Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases
Authors: Mihails Milehins, Dan Marghitu
Abstract: In the article titled "The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies" and published in the Journal of Computational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted, demonstrating that the models can accurately capture the nature of a variety of collision phenomena. In this article, the aforementioned models are augmented by modeling the effects of external forces as time-dependent inputs that belong to a certain function space. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces.

Paper number 166:
Title: Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction
Authors: Thomas T. Zhang, Daniel Pfrommer, Nikolai Matni, Max Simchowitz
Abstract: We study the problem of imitating an expert demonstrator in a continuous state-and-action dynamical system. While imitation learning in discrete settings such as autoregressive language modeling has seen immense success and popularity in recent years, imitation in physical settings such as autonomous driving and robot learning has proven comparably more complex due to the compounding errors problem, often requiring elaborate set-ups to perform stably. Recent work has demonstrated that even in benign settings, exponential compounding errors are unavoidable when learning solely from expert-controlled trajectories, suggesting the need for more advanced policy parameterizations or data augmentation. To this end, we present minimal interventions that provably mitigate compounding errors in continuous state-and-action imitation learning. When the system is open-loop stable, we prescribe "action chunking," i.e., predicting and playing sequences of actions in open-loop; when the system is possibly unstable, we prescribe "noise injection," i.e., adding noise during expert demonstrations. These interventions align with popular choices in modern robot learning, though the benefits we derive are distinct from the effects they were designed to target. Our results draw insights and tools from both control theory and reinforcement learning; however, our analysis reveals novel considerations that do not naturally arise when either literature is considered in isolation.

Paper number 167:
Title: BENYO-S2ST-Corpus-1: A Bilingual English-to-Yoruba Direct Speech-to-Speech Translation Corpus
Authors: Emmanuel Adetiba, Abdultaofeek Abayomi, Raymond J. Kala, Ayodele H. Ifijeh, Oluwatobi E. Dare, Olabode Idowu-Bismark, Gabriel O. Sobola, Joy N. Adetiba, Monsurat Adepeju Lateef, Heather Cole-Lewis
Abstract: There is a major shortage of Speech-to-Speech Translation (S2ST) datasets for high resource-to-low resource language pairs such as English-to-Yoruba. Thus, in this study, we curated the Bilingual English-to-Yoruba Speech-to-Speech Translation Corpus Version 1 (BENYO-S2ST-Corpus-1). The corpus is based on a hybrid architecture we developed for large-scale direct S2ST corpus creation at reduced cost. To achieve this, we leveraged non speech-to-speech Standard Yoruba (SY) real-time audios and transcripts in the YORULECT Corpus as well as the corresponding Standard English (SE) transcripts. YORULECT Corpus is small scale(1,504) samples, and it does not have paired English audios. Therefore, we generated the SE audios using pre-trained AI models (i.e. Facebook MMS). We also developed an audio augmentation algorithm named AcoustAug based on three latent acoustic features to generate augmented audios from the raw audios of the two languages. BENYO-S2ST-Corpus-1 has 12,032 audio samples per language, which gives a total of 24,064 sample size. The total audio duration for the two languages is 41.20 hours. This size is quite significant. Beyond building S2ST models, BENYO-S2ST-Corpus-1 can be used to build pretrained models or improve existing ones. The created corpus and Coqui framework were used to build a pretrained Yoruba TTS model (named YoruTTS-0.5) as a proof of concept. The YoruTTS-0.5 gave a F0 RMSE value of 63.54 after 1,000 epochs, which indicates moderate fundamental pitch similarity with the reference real-time audio. Ultimately, the corpus architecture in this study can be leveraged by researchers and developers to curate datasets for multilingual high-resource-to-low-resource African languages. This will bridge the huge digital divides in translations among high and low-resource language pairs. BENYO-S2ST-Corpus-1 and YoruTTS-0.5 are publicly available at (this https URL).

Paper number 168:
Title: Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data
Authors: Mohammad Alikhani, Reza Kazemi
Abstract: In the era of the Fourth Industrial Revolution, cybersecurity and intrusion detection systems are vital for the secure and reliable operation of IoT and IIoT environments. A key challenge in this domain is the scarcity of labeled cyberattack data, as most industrial systems operate under normal conditions. This data imbalance, combined with the high cost of annotation, hinders the effective training of machine learning models. Moreover, the rapid detection of attacks is essential, especially in critical infrastructure, to prevent large-scale disruptions. To address these challenges, we propose a real-time intrusion detection system based on a semi-supervised contrastive learning framework using the Kolmogorov-Arnold Network (KAN). Our method leverages abundant unlabeled data to effectively distinguish between normal and attack behaviors. We validate our approach on three benchmark datasets, UNSW-NB15, BoT-IoT, and Gas Pipeline, using only 2.20\%, 1.28\%, and 8\% of labeled samples, respectively, to simulate real-world conditions. Experimental results show that our method outperforms existing contrastive learning-based approaches. We further compare KAN with a traditional multilayer perceptron (MLP), demonstrating KAN's superior performance in both detection accuracy and robustness under limited supervision. KAN's ability to model complex relationships, along with its learnable activation functions, is also explored and visualized, offering interpretability and the potential for rule extraction. The method supports multi-class classification and proves effective in safety, critical environments where reliability is paramount.

Paper number 169:
Title: Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice
Authors: Shanbo Cheng, Yu Bao, Zhichao Huang, Yu Lu, Ningxin Peng, Lu Xu, Runsheng Yu, Rong Cao, Yujiao Du, Ting Han, Yuxiang Hu, Zeyang Li, Sitong Liu, Shengtao Ma, Shiguang Pan, Jiongchen Xiao, Nuo Xu, Meng Yang, Rong Ye, Yiming Yu, Jun Zhang, Ruofei Zhang, Wanyi Zhang, Wenhao Zhu, Liehao Zou, Lu Lu, Yuxuan Wang, Yonghui Wu
Abstract: Simultaneous Interpretation (SI) represents one of the most daunting frontiers in the translation industry, with product-level automatic systems long plagued by intractable challenges: subpar transcription and translation quality, lack of real-time speech generation, multi-speaker confusion, and translated speech inflation, especially in long-form discourses. In this study, we introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers high-fidelity, ultra-low-latency speech-to-speech generation with voice cloning capabilities. As a fully operational product-level solution, Seed-LiveInterpret 2.0 tackles these challenges head-on through our novel duplex speech-to-speech understanding-generating framework. Experimental results demonstrate that through large-scale pretraining and reinforcement learning, the model achieves a significantly better balance between translation accuracy and latency, validated by human interpreters to exceed 70% correctness in complex scenarios. Notably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by significant margins in translation quality, while slashing the average latency of cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is around a near 70% reduction that drastically enhances practical usability.

Paper number 170:
Title: A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation
Authors: Dennis Benders, Laura Ferranti, Johannes Köhler
Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot to safely navigate through an obstacle-filled environment is a complicated yet essential task in robotics. In this technical report, safety refers to ensuring that the robot respects state and input constraints while avoiding collisions with obstacles despite the presence of disturbances and measurement noise. This report offers a step-by-step approach to implementing Nonlinear Model Predictive Control (NMPC) schemes addressing these safety requirements. Numerous books and survey papers provide comprehensive overviews of linear MPC (LMPC), NMPC, and their applications in various domains, including robotics. This report does not aim to replicate those exhaustive reviews. Instead, it focuses specifically on NMPC as a foundation for safe mobile robot navigation. The goal is to provide a practical and accessible path from theoretical concepts to mathematical proofs and implementation, emphasizing safety and performance guarantees. It is intended for researchers, robotics engineers, and practitioners seeking to bridge the gap between theoretical NMPC formulations and real-world robotic applications. This report is not necessarily meant to remain fixed over time. If someone finds an error in the presented theory, please reach out via the given email addresses. We are happy to update the document if necessary.

Paper number 171:
Title: Part Segmentation of Human Meshes via Multi-View Human Parsing
Authors: James Dickens, Kamyar Hamad
Abstract: Recent advances in point cloud deep learning have led to models that achieve high per-part labeling accuracy on large-scale point clouds, using only the raw geometry of unordered point sets. In parallel, the field of human parsing focuses on predicting body part and clothing/accessory labels from images. This work aims to bridge these two domains by enabling per-vertex semantic segmentation of large-scale human meshes. To achieve this, a pseudo-ground truth labeling pipeline is developed for the Thuman2.1 dataset: meshes are first aligned to a canonical pose, segmented from multiple viewpoints, and the resulting point-level labels are then backprojected onto the original mesh to produce per-point pseudo ground truth annotations. Subsequently, a novel, memory-efficient sampling strategy is introduced, a windowed iterative farthest point sampling (FPS) with space-filling curve-based serialization to effectively downsample the point clouds. This is followed by a purely geometric segmentation using PointTransformer, enabling semantic parsing of human meshes without relying on texture information. Experimental results confirm the effectiveness and accuracy of the proposed approach.
    