
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Exploring Patient Data Requirements in Training Effective AI Models for MRI-based Breast Cancer Classification
Authors: Solha Kang, Wesley De Neve, Francois Rameau, Utku Ozbulak
Abstract: The past decade has witnessed a substantial increase in the number of startups and companies offering AI-based solutions for clinical decision support in medical institutions. However, the critical nature of medical decision-making raises several concerns about relying on external software. Key issues include potential variations in image modalities and the medical devices used to obtain these images, potential legal issues, and adversarial attacks. Fortunately, the open-source nature of machine learning research has made foundation models publicly available and straightforward to use for medical applications. This accessibility allows medical institutions to train their own AI-based models, thereby mitigating the aforementioned concerns. Given this context, an important question arises: how much data do medical institutions need to train effective AI models? In this study, we explore this question in relation to breast cancer detection, a particularly contested area due to the prevalence of this disease, which affects approximately 1 in every 8 women. Through large-scale experiments on various patient sizes in the training set, we show that medical institutions do not need a decade's worth of MRI images to train an AI model that performs competitively with the state-of-the-art, provided the model leverages foundation models. Furthermore, we observe that for patient counts greater than 50, the number of patients in the training set has a negligible impact on the performance of models and that simple ensembles further improve the results without additional complexity.

Paper number 2:
Title: Gradient entropy (GradEn): The two dimensional version of slope entropy for image analysis
Authors: Runze Jiang, Pengjian Shang
Abstract: Information theory and Shannon entropy are essential for quantifying irregularity in complex systems or signals. Recently, two-dimensional entropy methods, such as two-dimensional sample entropy, distribution entropy, and permutation entropy, have been proposed for analyzing 2D texture or image data. This paper introduces Gradient entropy (GradEn), an extension of slope entropy to 2D, which considers both symbolic patterns and amplitude information, enabling better feature extraction from image data. We evaluate GradEn with simulated data, including 2D colored noise, 2D mixed processes, and the logistic map. Results show the ability of GradEn to distinguish images with various characteristics while maintaining low computational cost. Real-world datasets, consist of texture, fault gear, and railway corrugation signals, demonstrate the superior performance of GradEn in classification tasks compared to other 2D entropy methods. In conclusion, GradEn is an effective tool for image characterization, offering a novel approach for image processing and recognition.

Paper number 3:
Title: FreeTumor: Large-Scale Generative Tumor Synthesis in Computed Tomography Images for Improving Tumor Recognition
Authors: Linshan Wu, Jiaxin Zhuang, Yanning Zhou, Sunan He, Jiabo Ma, Luyang Luo, Xi Wang, Xuefeng Ni, Xiaoling Zhong, Mingxiang Wu, Yinghua Zhao, Xiaohui Duan, Varut Vardhanabhuti, Pranav Rajpurkar, Hao Chen
Abstract: Tumor is a leading cause of death worldwide, with an estimated 10 million deaths attributed to tumor-related diseases every year. AI-driven tumor recognition unlocks new possibilities for more precise and intelligent tumor screening and diagnosis. However, the progress is heavily hampered by the scarcity of annotated datasets, which demands extensive annotation efforts by radiologists. To tackle this challenge, we introduce FreeTumor, an innovative Generative AI (GAI) framework to enable large-scale tumor synthesis for mitigating data scarcity. Specifically, FreeTumor effectively leverages a combination of limited labeled data and large-scale unlabeled data for tumor synthesis training. Unleashing the power of large-scale data, FreeTumor is capable of synthesizing a large number of realistic tumors on images for augmenting training datasets. To this end, we create the largest training dataset for tumor synthesis and recognition by curating 161,310 publicly available Computed Tomography (CT) volumes from 33 sources, with only 2.3% containing annotated tumors. To validate the fidelity of synthetic tumors, we engaged 13 board-certified radiologists in a Visual Turing Test to discern between synthetic and real tumors. Rigorous clinician evaluation validates the high quality of our synthetic tumors, as they achieved only 51.1% sensitivity and 60.8% accuracy in distinguishing our synthetic tumors from real ones. Through high-quality tumor synthesis, FreeTumor scales up the recognition training datasets by over 40 times, showcasing a notable superiority over state-of-the-art AI methods including various synthesis methods and foundation models. These findings indicate promising prospects of FreeTumor in clinical applications, potentially advancing tumor treatments and improving the survival rates of patients.

Paper number 4:
Title: Rewards-based image analysis in microscopy
Authors: Kamyar Barakati, Yu Liu, Utkarsh Pratiush, Boris N. Slautin, Sergei V. Kalinin
Abstract: Analyzing imaging and hyperspectral data is crucial across scientific fields, including biology, medicine, chemistry, and physics. The primary goal is to transform high-resolution or high-dimensional data into an interpretable format to generate actionable insights, aiding decision-making and advancing knowledge. Currently, this task relies on complex, human-designed workflows comprising iterative steps such as denoising, spatial sampling, keypoint detection, feature generation, clustering, dimensionality reduction, and physics-based deconvolutions. The introduction of machine learning over the past decade has accelerated tasks like image segmentation and object detection via supervised learning, and dimensionality reduction via unsupervised methods. However, both classical and NN-based approaches still require human input, whether for hyperparameter tuning, data labeling, or both. The growing use of automated imaging tools, from atomically resolved imaging to biological applications, demands unsupervised methods that optimize data representation for human decision-making or autonomous experimentation. Here, we discuss advances in reward-based workflows, which adopt expert decision-making principles and demonstrate strong transfer learning across diverse tasks. We represent image analysis as a decision-making process over possible operations and identify desiderata and their mappings to classical decision-making frameworks. Reward-driven workflows enable a shift from supervised, black-box models sensitive to distribution shifts to explainable, unsupervised, and robust optimization in image analysis. They can function as wrappers over classical and DCNN-based methods, making them applicable to both unsupervised and supervised workflows (e.g., classification, regression for structure-property mapping) across imaging and hyperspectral data.

Paper number 5:
Title: End-to-End Deep Learning for Structural Brain Imaging: A Unified Framework
Authors: Yao Su, Keqi Han, Mingjie Zeng, Lichao Sun, Liang Zhan, Carl Yang, Lifang He, Xiangnan Kong
Abstract: Brain imaging analysis is fundamental in neuroscience, providing valuable insights into brain structure and function. Traditional workflows follow a sequential pipeline-brain extraction, registration, segmentation, parcellation, network generation, and classification-treating each step as an independent task. These methods rely heavily on task-specific training data and expert intervention to correct intermediate errors, making them particularly burdensome for high-dimensional neuroimaging data, where annotations and quality control are costly and time-consuming. We introduce UniBrain, a unified end-to-end framework that integrates all processing steps into a single optimization process, allowing tasks to interact and refine each other. Unlike traditional approaches that require extensive task-specific annotations, UniBrain operates with minimal supervision, leveraging only low-cost labels (i.e., classification and extraction) and a single labeled atlas. By jointly optimizing extraction, registration, segmentation, parcellation, network generation, and classification, UniBrain enhances both accuracy and computational efficiency while significantly reducing annotation effort. Experimental results demonstrate its superiority over existing methods across multiple tasks, offering a more scalable and reliable solution for neuroimaging analysis. Our code and data can be found at this https URL

Paper number 6:
Title: A Comparative Review of the Histogram-based Image Segmentation Methods
Authors: ZhenZhou Wang
Abstract: The histogram of an image is the accurate graphical representation of the numerical grayscale distribution and it is also an estimate of the probability distribution of image pixels. Therefore, histogram has been widely adopted to calculate the clustering means and partitioning thresholds for image segmentation. There have been many classical histogram-based image segmentation methods proposed and played important roles in both academics and industry. In this article, the histories and recent advances of the histogram-based image segmentation techniques are first reviewed and then they are divided into four categories: (1), the means-based method; (2), the Gaussian-mixture-model-based method; (3), the entropy-based method and (4) the feature-points-based method. The principles of the classical histogram-based image segmentation methods are described at first and then their performances are compared objectively. In addition, the histogram-based image segmentation methods are compared with the general-purpose deep learning methods in segmenting objects with uniform or simple backgrounds. The histogram-based image segmentation methods are more accurate than the universal deep-learning methods without special training in segmenting many types of images.

Paper number 7:
Title: Understanding Untrained Deep Models for Inverse Problems: Algorithms and Theory
Authors: Ismail Alkhouri, Evan Bell, Avrajit Ghosh, Shijun Liang, Rongrong Wang, Saiprasad Ravishankar
Abstract: In recent years, deep learning methods have been extensively developed for inverse imaging problems (IIPs), encompassing supervised, self-supervised, and generative approaches. Most of these methods require large amounts of labeled or unlabeled training data to learn effective models. However, in many practical applications, such as medical image reconstruction, extensive training datasets are often unavailable or limited. A significant milestone in addressing this challenge came in 2018 with the work of Ulyanov et al., which introduced the Deep Image Prior (DIP)--the first training-data-free neural network method for IIPs. Unlike conventional deep learning approaches, DIP requires only a convolutional neural network, the noisy measurements, and a forward operator. By leveraging the implicit regularization of deep networks initialized with random noise, DIP can learn and restore image structures without relying on external datasets. However, a well-known limitation of DIP is its susceptibility to overfitting, primarily due to the over-parameterization of the network. In this tutorial paper, we provide a comprehensive review of DIP, including a theoretical analysis of its training dynamics. We also categorize and discuss recent advancements in DIP-based methods aimed at mitigating overfitting, including techniques such as regularization, network re-parameterization, and early stopping. Furthermore, we discuss approaches that combine DIP with pre-trained neural networks, present empirical comparison results against data-centric methods, and highlight open research questions and future directions.

Paper number 8:
Title: Transfer Learning Assisted Fast Design Migration Over Technology Nodes: A Study on Transformer Matching Network
Authors: Chenhao Chu, Yuhao Mao, Hua Wang
Abstract: In this study, we introduce an innovative methodology for the design of mm-Wave passive networks that leverages knowledge transfer from a pre-trained synthesis neural network (NN) model in one technology node and achieves swift and reliable design adaptation across different integrated circuit (IC) technologies, operating frequencies, and metal options. We prove this concept through simulation-based demonstrations focusing on the training and comparison of the coefficient of determination (R2) of synthesis NNs for 1:1 on-chip transformers in GlobalFoundries(GF) 22nm FDX+ (target domain), with and without transfer learning from a model trained in GF 45nm SOI (source domain). In the experiments, we explore varying target data densities of 0.5%, 1%, 5%, and 100% with a complete dataset of 0.33 million in GF 22FDX+, and for comparative analysis, apply source data densities of 25%, 50%, 75%, and 100% with a complete dataset of 2.5 million in GF 45SOI. With the source data only at 30GHz, the experiments span target data from two metal options in GF 22FDX+ at frequencies of 30 and 39 GHz. The results prove that the transfer learning with the source domain knowledge (GF 45SOI) can both accelerate the training process in the target domain (GF 22FDX+) and improve the R2 values compared to models without knowledge transfer. Furthermore, it is observed that a model trained with just 5% of target data and augmented by transfer learning achieves R2 values superior to a model trained with 20% of the data without transfer, validating the advantage seen from 1% to 5% data density. This demonstrates a notable reduction of 4X in the necessary dataset size highlighting the efficacy of utilizing transfer learning to mm-Wave passive network design. The PyTorch learning and testing code is publicly available at this https URL.

Paper number 9:
Title: Identification and Characterization for Disruptions in the U.S. National Airspace System (NAS)
Authors: Jing Xu, Mark Hansen, Megan Ryerson
Abstract: Disruptions in the National Airspace System (NAS) lead to significant losses to air traffic system participants and raise public concerns. We apply two methods, cluster analysis and anomaly detection models, to identify operational disruptions with geographical patterns in the NAS since 2010. We identify four types and twelve categories of days of operations, distinguished according to air traffic system operational performance and geographical patterns of disruptions. Two clusters--NAS Disruption and East Super Disruption, accounting for 0.8% and 1.2% of the days respectively, represent the most disrupted days of operations in U.S. air traffic system. Another 16.5% of days feature less severe but still significant disruptions focused on certain regions of the NAS, while on the remaining 81.5% of days the NAS operates relatively smoothly. Anomaly detection results show good agreement with cluster results and further distinguish days in the same cluster by severity of disruptions. Results show an increasing trend in frequency of disruptions especially post-COVID. Additionally, disruptions happen most frequently in the summer and winter.

Paper number 10:
Title: Interpretable Data-Driven Ship Dynamics Model: Enhancing Physics-Based Motion Prediction with Parameter Optimization
Authors: Papandreou Christos, Mathioudakis Michail, Stouraitis Theodoros, Iatropoulos Petros, Nikitakis Antonios, Stavros Paschalakis, Konstantinos Kyriakopoulos
Abstract: The deployment of autonomous navigation systems on ships necessitates accurate motion prediction models tailored to individual vessels. Traditional physics-based models, while grounded in hydrodynamic principles, often fail to account for ship-specific behaviors under real-world conditions. Conversely, purely data-driven models offer specificity but lack interpretability and robustness in edge cases. This study proposes a data-driven physics-based model that integrates physics-based equations with data-driven parameter optimization, leveraging the strengths of both approaches to ensure interpretability and adaptability. The model incorporates physics-based components such as 3-DoF dynamics, rudder, and propeller forces, while parameters such as resistance curve and rudder coefficients are optimized using synthetic data. By embedding domain knowledge into the parameter optimization process, the fitted model maintains physical consistency. Validation of the approach is realized with two container ships by comparing, both qualitatively and quantitatively, predictions against ground-truth trajectories. The results demonstrate significant improvements, in predictive accuracy and reliability, of the data-driven physics-based models over baseline physics-based models tuned with traditional marine engineering practices. The fitted models capture ship-specific behaviors in diverse conditions with their predictions being, 51.6% (ship A) and 57.8% (ship B) more accurate, 72.36% (ship A) and 89.67% (ship B) more consistent.

Paper number 11:
Title: TerraTrace: Temporal Signature Land Use Mapping System
Authors: Angela Busheska, Vikram Iyer, Bruno Silva, Peder Olsen, Ranveer Chandra, Vaishnavi Ranganathan
Abstract: Understanding land use over time is critical to tracking events related to climate change, like deforestation. However, satellite-based remote sensing tools which are used for monitoring struggle to differentiate vegetation types in farms and orchards from forests. We observe that metrics such as the Normalized Difference Vegetation Index (NDVI), based on plant photosynthesis, have unique temporal signatures that reflect agricultural practices and seasonal cycles. We analyze yearly NDVI changes on 20 farms for 10 unique crops. Initial results show that NDVI curves are coherent with agricultural practices, are unique to each crop, consistent globally, and can differentiate farms from forests. We develop a novel longitudinal NDVI dataset for the state of California from 2020-2023 with 500~m resolution and over 70 million points. We use this to develop the TerraTrace platform, an end-to-end analytic tool that classifies land use using NDVI signatures and allows users to query the system through an LLM chatbot and graphical interface.

Paper number 12:
Title: DRL-Based Secure Spectrum-Reuse D2D Communications with RIS Assistance
Authors: Maryam Asadi Ahmadabadi, Farimehr Zohari, S. Mohammad Razavizadeh
Abstract: This study examines the secrecy performance of an uplink device-to-device (D2D) communication system enhanced by reconfigurable intelligent surfaces (RIS) while considering the presence of multiple eavesdroppers. RIS technology is employed to improve wireless communication environment by intelligently reflecting signals, thereby improving both capacity and security. We employ deep reinforcement learning (DRL) to optimize resource allocation dynamically, addressing challenges in D2D pairs and optimizing RIS positioning and phase shifts in a changing wireless environment. Our simulations demonstrate that the developed DRL-based framework significantly maximizes the sum secrecy capacity of both D2D and cellular communications, achieving higher transmission secrecy rates compared to existing benchmarks. The results highlight the effectiveness of integrating RIS with D2D communications for improved security performance.

Paper number 13:
Title: MTCA: Multi-Task Channel Analysis for Wireless Communication
Authors: Jun Jiang, Wenjun Yu, Yuan Gao, Shugong Xu
Abstract: In modern wireless communication systems, the effective processing of Channel State Information (CSI) is crucial for enhancing communication quality and reliability. However, current methods often handle different tasks in isolation, thereby neglecting the synergies among various tasks and leading to extract CSI features inadequately for subsequent analysis. To address these limitations, this paper introduces a novel Multi-Task Channel Analysis framework named MTCA, aimed at improving the performance of wireless communication even sensing. MTCA is designed to handle four critical tasks, including channel prediction, antenna-domain channel extrapolation, channel identification, and scenario classification. Experiments conducted on a multi-scenario, multi-antenna dataset tailored for UAV-based communications demonstrate that the proposed MTCA exhibits superior comprehension of CSI, achieving enhanced performance across all evaluated tasks. Notably, MTCA reached 100% prediction accuracy in channel identification and scenario classification. Compared to the previous state-of-the-art methods, MTCA improved channel prediction performance by 20.1% and antenna-domain extrapolation performance by 54.5%.

Paper number 14:
Title: Ptychographic Image Reconstruction from Limited Data via Score-Based Diffusion Models with Physics-Guidance
Authors: Refik Mert Cam, Junjing Deng, Rajkumar Kettimuthu, Mathew J. Cherukara, Tekin Bicer
Abstract: Ptychography is a computational imaging technique that achieves high spatial resolution over large fields of view. It involves scanning a coherent beam across overlapping regions and recording diffraction patterns. Conventional reconstruction algorithms require substantial overlap, increasing data volume and experimental time. We propose a reconstruction method employing a physics-guided score-based diffusion model. Our approach trains a diffusion model on representative object images to learn an object distribution prior. During reconstruction, we modify the reverse diffusion process to enforce data consistency, guiding reverse diffusion toward a physically plausible solution. This method requires a single pretraining phase, allowing it to generalize across varying scan overlap ratios and positions. Our results demonstrate that the proposed method achieves high-fidelity reconstructions with only a 20% overlap, while the widely employed rPIE method requires a 62% overlap to achieve similar accuracy. This represents a significant reduction in data requirements, offering an alternative to conventional techniques.

Paper number 15:
Title: Subclass Classification of Gliomas Using MRI Fusion Technique
Authors: Kiranmayee Janardhan, Christy Bobby Thomas
Abstract: Glioma, the prevalent primary brain tumor, exhibits diverse aggressiveness levels and prognoses. Precise classification of glioma is paramount for treatment planning and predicting prognosis. This study aims to develop an algorithm to fuse the MRI images from T1, T2, T1ce, and fluid-attenuated inversion recovery (FLAIR) sequences to enhance the efficacy of glioma subclass classification as no tumor, necrotic core, peritumoral edema, and enhancing tumor. The MRI images from BraTS datasets were used in this work. The images were pre-processed using max-min normalization to ensure consistency in pixel intensity values across different images. The segmentation of the necrotic core, peritumoral edema, and enhancing tumor was performed on 2D and 3D images separately using UNET architecture. Further, the segmented regions from multimodal MRI images were fused using the weighted averaging technique. Integrating 2D and 3D segmented outputs enhances classification accuracy by capturing detailed features like tumor shape, boundaries, and intensity distribution in slices, while also providing a comprehensive view of spatial extent, shape, texture, and localization within the brain volume. The fused images were used as input to the pre-trained ResNet50 model for glioma subclass classification. The network is trained on 80% and validated on 20% of the data. The proposed method achieved a classification of accuracy of 99.25%, precision of 99.30%, recall of 99.10, F1 score of 99.19%, Intersection Over Union of 84.49%, and specificity of 99.76, which showed a significantly higher performance than existing techniques. These findings emphasize the significance of glioma segmentation and classification in aiding accurate diagnosis.

Paper number 16:
Title: Hyperspectral image reconstruction by deep learning with super-Rayleigh speckles
Authors: Ziyan Chen, Zhentao Liu, Jianrong Wu, Shensheng Han
Abstract: Ghost imaging via sparsity constraints (GISC) spectral camera modulates the three-dimensional (3D) hyperspectral image into a two-dimensional (2D) compressive image with speckles in a single shot. It obtains a 3D hyperspectral image (HSI) by reconstruction algorithms. The rapid development of deep learning has provided a new method for 3D HSI reconstruction. Moreover, the imaging performance of the GISC spectral camera can be improved by optimizing the speckle modulation. In this paper, we propose an end-to-end GISCnet with super-Rayleigh speckle modulation to improve the imaging quality of the GISC spectral camera. The structure of GISCnet is very simple but effective, and we can easily adjust the network structure parameters to improve the image reconstruction quality. Relative to Rayleigh speckles, our super-Rayleigh speckles modulation exhibits a wealth of detail in reconstructing 3D HSIs. After evaluating 648 3D HSIs, it was found that the average peak signal-to-noise ratio increased from 27 dB to 31 dB. Overall, the proposed GISCnet with super-Rayleigh speckle modulation can effectively improve the imaging quality of the GISC spectral camera by taking advantage of both optimized super-Rayleigh modulation and deep-learning image reconstruction, inspiring joint optimization of light-field modulation and image reconstruction to improve ghost imaging performance.

Paper number 17:
Title: Towards ISAC RIS-Enabled Passive Radar Target Localization
Authors: Ahmad Bazzi, Marwa Chafii
Abstract: Incorporating integrated sensing and communication capabilities into forthcoming 6G wireless networks is crucial for achieving seamless synchronization between the digital and physical worlds. The following paper focuses on a scenario where a passive radar (PR) is subject to weak line-of-sight signals of opportunity, emanating from an access point and subsequently reflecting off targets, ultimately reaching the PR. Furthermore, a normalized least mean squares method is presented for jointly detecting the number of targets and estimating target angles of arrival (AoAs). The algorithm iteratively adjusts the steering vector estimates to minimize a suitable error cost function, while the target AoAs are identified via a peak-finding search conducted on the resulted power spectrum. Simulation results show the capabilities of the proposed localization method, as well as a 14 dB dynamic range reduction that can be achieved at the PR.

Paper number 18:
Title: Music Therapy based Stress Prediction using Homological Feature Analysis on EEG Signals
Authors: Srikireddy Dhanunjay Reddy, Tharun Kumar Reddy Bollu
Abstract: Stress became a common factor in the busy daily routines of all academic and corporate working environments. Everyone checks for efficient stress-buster alternatives to calm down from work pressure. Instead of investing time in unnecessary efforts, this work shows the stress relief scenario of subjects by listening to Raag Darbari music notes as a simple add-on to their schedule. An innovative approach has been implemented on the MUSEI-EEG dataset using Topological Data Analysis (TDA) to analyze this stress relief study. This study reveals that persistent homological features can be robust biomarkers for classifying closely distributed subject data. The proposed TDA approach framework revealed homological features like birth-death rate and entropy efficacy in stress prediction using Electroencephalogram (EEG) signals with 86% average accuracy and 0.2 standard deviation.

Paper number 19:
Title: DFT-based Near-field Beam Alignment: Model-based and Data-Driven Hybrid Approach
Authors: Hongjun Heo, Wan Choi
Abstract: Accurate beam alignment is a critical challenge in XL-MIMO systems, especially in the near-field regime, where conventional far-field assumptions no longer hold. Although 2D grid-based codebooks in the polar domain are widely accepted for capturing near-field effects, they often suffer from high complexity and inefficiency in both time and computational resources. To address this issue, we propose a novel line-of-sight (LoS) near-field beam alignment scheme that leverages the discrete Fourier transform (DFT) matrix, which is commonly used in far-field environments. This approach ensures backward compatibility with the legacy DFT codebook for far-field signals by allowing its reuse. By introducing a new method to analyze the energy spread effect, we define the concept of an $\epsilon$-approximated signal subspace, spanned by DFT vectors that exhibit significant correlation with the near-field channel vector. Building on this analysis, the proposed hybrid scheme integrates model-based principles with data-driven techniques. Specifically, it utilizes the properties of the DFT matrix for efficient coarse alignment while employing a deep neural network (DNN)-aided fine alignment process. The fine alignment operates within the reduced search space defined by the coarse alignment stage, significantly enhancing accuracy while reducing complexity. Simulation results demonstrate that the proposed scheme achieves superior alignment performance while reducing both computational and model complexity compared to existing methods.

Paper number 20:
Title: Multivariable Generalized Super-Twisting Algorithm Robust Control of Linear Time-Invariant Systems
Authors: J. C. Geromel, E. V. L. Nunes, L. Hsu
Abstract: This paper presents a novel procedure for robust control design of linear time-invariant systems using a Multivariable Generalized Super-Twisting Algorithm (MGSTA). The proposed approach addresses robust stability and performance conditions, considering convex bounded parameter uncertainty in all matrices of the plant state-space realization and Lipschitz exogenous disturbances. The primary characteristic of the closed-loop system, sliding mode finite-time convergence, is thoroughly examined and evaluated. The design conditions, obtained through the proposal of a novel max-type non-differentiable piecewise-continuous Lyapunov function are formulated as Linear Matrix Inequalities (LMIs), which can be efficiently solved using existing computational tools. A fault-tolerant MGSTA control is designed for a mechanical system with three degrees of freedom, illustrating the efficacy of the proposed LMI approach.

Paper number 21:
Title: Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis
Authors: Ziyue Jiang, Yi Ren, Ruiqi Li, Shengpeng Ji, Zhenhui Ye, Chen Zhang, Bai Jionghao, Xiaoda Yang, Jialong Zuo, Yu Zhang, Rui Liu, Xiang Yin, Zhou Zhao
Abstract: While recent zero-shot text-to-speech (TTS) models have significantly improved speech quality and expressiveness, mainstream systems still suffer from issues related to speech-text alignment modeling: 1) models without explicit speech-text alignment modeling exhibit less robustness, especially for hard sentences in practical applications; 2) predefined alignment-based models suffer from naturalness constraints of forced alignments. This paper introduces \textit{S-DiT}, a TTS system featuring an innovative sparse alignment algorithm that guides the latent diffusion transformer (DiT). Specifically, we provide sparse alignment boundaries to S-DiT to reduce the difficulty of alignment learning without limiting the search space, thereby achieving high naturalness. Moreover, we employ a multi-condition classifier-free guidance strategy for accent intensity adjustment and adopt the piecewise rectified flow technique to accelerate the generation process. Experiments demonstrate that S-DiT achieves state-of-the-art zero-shot TTS speech quality and supports highly flexible control over accent intensity. Notably, our system can generate high-quality one-minute speech with only 8 sampling steps. Audio samples are available at this https URL.

Paper number 22:
Title: A Novel Topology Recovery Method for Low Voltage Distribution Networks
Authors: Sina Mohammadi, Van-Hai Bui, Wencong Su
Abstract: Low voltage distribution networks (LVDNs) suffer from limited visibility due to sparse or nonexistent measurement systems, leaving distribution network service providers with incomplete data. Maintenance activities, such as transformer upgrades and power line replacements, sometimes go undocumented, leading to unmonitored topology changes. This lack of oversight hinders network optimization, fault detection, and outage management, as utilities cannot fully monitor or control the system. With the rise of electric vehicles, having an accurate understanding of LVDN topology is crucial to avoid infrastructure damage from potential overloads. This paper introduces a method to reconstruct LVDN topology using incremental voltage and current changes from smart meters at customer endpoints. The approach identifies and maps network topologies with high accuracy, overcoming limitations of prior methods by discarding unrealistic assumptions. Specifically, it addresses grids with fewer than three pole connections and employs an AC power flow model over simplified DC approximations. Simulations across diverse configurations validate the method's effectiveness in accurately reconstructing LVDN topologies, enhancing real-world applicability.

Paper number 23:
Title: Sparse Spectrahedral Shadows for State Estimation and Reachability Analysis: Set Operations, Validations and Order Reductions
Authors: Chengrui Wang, Haohao Qiu, Sibo Yao, James Lam
Abstract: Set representations are the foundation of various set-based approaches in state estimation, reachability analysis and fault diagnosis. In this paper, we investigate spectrahedral shadows, a class of nonlinear geometric objects previously studied in semidefinite programming and real algebraic geometry. We demonstrate spectrahedral shadows generalize traditional and emerging set representations like ellipsoids, zonotopes, constrained zonotopes and ellipsotopes. Analytical forms of set operations are provided including linear map, linear inverse map, Minkowski sum, intersection, Cartesian product, Minkowski-Firey Lp sum, convex hull, conic hull and polytopic map, all of which are implemented without approximation in polynomial time. In addition, we develop set validation and order reduction techniques for spectrahedral shadows, thereby establishing spectrahedral shadows as a set representation applicable to a range of set-based tasks.

Paper number 24:
Title: Polarization Angle Scanning for Wide-band Millimeter-wave Direct Detection
Authors: Heyao Wang, Ziran Zhao, Lingbo Qiao, Dalu Guo
Abstract: Millimeter-wave (MMW) technology has been widely utilized in human security screening applications due to its superior penetration capabilities through clothing and safety for human exposure. However, existing methods largely rely on fixed polarization modes, neglecting the potential insights from variations in target echoes with respect to incident polarization. This study provides a theoretical analysis of the cross-polarization echo power as a function of the incident polarization angle under linear polarization conditions. Additionally, based on the transmission characteristics of multi-layer medium, we extended the depth spectrum model employed in direct detection to accommodate scenarios involving multi-layered structures. Building on this foundation, by obtaining multiple depth spectrums through polarization angle scanning, we propose the Polarization Angle-Depth Matrix to characterize target across both the polarization angle and depth dimensions in direct detection. Simulations and experimental validations confirm its accuracy and practical value in detecting concealed weapons in human security screening scenarios.

Paper number 25:
Title: KAN-powered large-target detection for automotive radar
Authors: Vinay Kulkarni, V. V. Reddy, Neha Maheshwari
Abstract: This paper presents a novel radar signal detection pipeline focused on detecting large targets such as cars and SUVs. Traditional methods, such as Ordered-Statistic Constant False Alarm Rate (OS-CFAR), commonly used in automotive radar, are designed for point or isotropic target models. These may not adequately capture the Range-Doppler (RD) scattering patterns of larger targets, especially in high-resolution radar systems. Additional modules such as association and tracking are necessary to refine and consolidate the detections over multiple dwells. To address these limitations, we propose a detection technique based on the probability density function (pdf) of RD segments, leveraging the Kolmogorov-Arnold neural network (KAN) to learn the data and generate interpretable symbolic expressions for binary hypotheses. Beside the Monte-Carlo study showing better performance for the proposed KAN expression over OS-CFAR, it is shown to exhibit a probability of detection (PD) of 96% when transfer learned with field data. The false alarm rate (PFA) is comparable with OS-CFAR designed with PFA = $10^{-6}$. Additionally, the study also examines impact of the number of pdf bins representing RD segment on performance of the KAN-based detection.

Paper number 26:
Title: Robust Over-the-Air Computation with Type-Based Multiple Access
Authors: Marc Martinez-Gost, Ana Pérez-Neira, Miguel Ángel Lagunas
Abstract: This paper utilizes the properties of type-based multiple access (TBMA) to investigate its effectiveness as a robust approach for over-the-air computation (AirComp) in the presence of Byzantine attacks, this is, adversarial strategies where malicious nodes intentionally distort their transmissions to corrupt the aggregated result. Unlike classical direct aggregation (DA) AirComp, which aggregates data in the amplitude of the signals and are highly vulnerable to attacks, TBMA distributes data over multiple radio resources, enabling the receiver to construct a histogram representation of the transmitted data. This structure allows the integration of classical robust estimators and supports the computation of diverse functions beyond the arithmetic mean, which is not feasible with DA. Through extensive simulations, we demonstrate that robust TBMA significantly outperforms DA, maintaining high accuracy even under adversarial conditions, and showcases its applicability in federated learning (FEEL) scenarios. Additionally, TBMA reduces channel state information (CSI) requirements, lowers energy consumption, and enhances resiliency by leveraging the diversity of the transmitted data. These results establish TBMA as a scalable and robust solution for AirComp, paving the way for secure and efficient aggregation in next-generation networks.

Paper number 27:
Title: InternVQA: Advancing Compressed Video QualityAssessment with Distilling Large Foundation Model
Authors: Fengbin Guan, Zihao Yu, Yiting Lu, Xin Li, Zhibo Chen
Abstract: Video quality assessment tasks rely heavily on the rich features required for video understanding, such as semantic information, texture, and temporal motion. The existing video foundational model, InternVideo2, has demonstrated strong potential in video understanding tasks due to its large parameter size and large-scale multimodal data pertaining. Building on this, we explored the transferability of InternVideo2 to video quality assessment under compression scenarios. To design a lightweight model suitable for this task, we proposed a distillation method to equip the smaller model with rich compression quality priors. Additionally, we examined the performance of different backbones during the distillation process. The results showed that, compared to other methods, our lightweight model distilled from InternVideo2 achieved excellent performance in compression video quality assessment.

Paper number 28:
Title: PolypFlow: Reinforcing Polyp Segmentation with Flow-Driven Dynamics
Authors: Pu Wang, Huaizhi Ma, Zhihua Zhang, Zhuoran Zheng
Abstract: Accurate polyp segmentation remains challenging due to irregular lesion morphologies, ambiguous boundaries, and heterogeneous imaging conditions. While U-Net variants excel at local feature fusion, they often lack explicit mechanisms to model the dynamic evolution of segmentation confidence under uncertainty. Inspired by the interpretable nature of flow-based models, we present \textbf{PolypFLow}, a flow-matching enhanced architecture that injects physics-inspired optimization dynamics into segmentation refinement. Unlike conventional cascaded networks, our framework solves an ordinary differential equation (ODE) to progressively align coarse initial predictions with ground truth masks through learned velocity fields. This trajectory-based refinement offers two key advantages: 1) Interpretable Optimization: Intermediate flow steps visualize how the model corrects under-segmented regions and sharpens boundaries at each ODE-solver iteration, demystifying the ``black-box" refinement process; 2) Boundary-Aware Robustness: The flow dynamics explicitly model gradient directions along polyp edges, enhancing resilience to low-contrast regions and motion artifacts. Numerous experimental results show that PolypFLow achieves a state-of-the-art while maintaining consistent performance in different lighting scenarios.

Paper number 29:
Title: Max360IQ: Blind Omnidirectional Image Quality Assessment with Multi-axis Attention
Authors: Jiebin Yan, Ziwen Tan, Yuming Fang, Jiale Rao, Yifan Zuo
Abstract: Omnidirectional image, also called 360-degree image, is able to capture the entire 360-degree scene, thereby providing more realistic immersive feelings for users than general 2D image and stereoscopic image. Meanwhile, this feature brings great challenges to measuring the perceptual quality of omnidirectional images, which is closely related to users' quality of experience, especially when the omnidirectional images suffer from non-uniform distortion. In this paper, we propose a novel and effective blind omnidirectional image quality assessment (BOIQA) model with multi-axis attention (Max360IQ), which can proficiently measure not only the quality of uniformly distorted omnidirectional images but also the quality of non-uniformly distorted omnidirectional images. Specifically, the proposed Max360IQ is mainly composed of a backbone with stacked multi-axis attention modules for capturing both global and local spatial interactions of extracted viewports, a multi-scale feature integration (MSFI) module to fuse multi-scale features and a quality regression module with deep semantic guidance for predicting the quality of omnidirectional images. Experimental results demonstrate that the proposed Max360IQ outperforms the state-of-the-art Assessor360 by 3.6\% in terms of SRCC on the JUFE database with non-uniform distortion, and gains improvement of 0.4\% and 0.8\% in terms of SRCC on the OIQA and CVIQ databases, respectively. The source code is available at this https URL.

Paper number 30:
Title: Circulant ADMM-Net for Fast High-resolution DoA Estimation
Authors: Youval Klioui
Abstract: This paper introduces CADMM-Net and CHADMM-Net, two deep neural networks for direction of arrival estimation within the least-absolute shrinkage and selection operator (LASSO) framework. These two networks are based on a structured deep unfolding of the alternating direction method of multipliers (ADMM) algorithm through the use of circulant as well as Hermitian-circulant matrices. Along with a computational complexity of $\mathcal{O}(N\log(N))$ per layer for the inference, where $N$ is the length of the dictionary $\mathbf{A}$, they additionally exhibit a memory footprint of $N$ and approximately half of $N$ for CADMMNet and CHADMM-Net, respectively, compared with $N^{2}$ for ADMM-Net. Furthermore, these structured networks exhibit a competitive performance against ADMM-Net, LISTA, TLISTA, and THLISTA with respect to the detection rate, the angular root-mean square error, and the normalized mean squared error.

Paper number 31:
Title: Naked Eye Three-dimensional Display System Based on Time-multiplexed Technology
Authors: Ziyang Liu, Zekai Chen, Changxiong Zheng, Phil Surman, Xiao Wei Sun
Abstract: Our group is developing a multi-user eye-tracked 3D display, an evolution of the single-user eye-tracked 3D display that we have already successfully developed. This display utilizes a slanted lenticular setup, where multiple perspective views are shown across the viewing field. Due to the constraints of the lenticular lens parameters, identical views are repeated across the field, limiting eye tracking to a single user. However, this limitation can be addressed using spatio-temporal multiplexing, where view zone groups are presented sequentially with a high frame rate liquid crystal display (LCD) and driver, in combination with a synchronized directional light emitting diode (LED) array. In this paper, we describe the operation and results of the backlight drive electronics, where a prototype using a white LED illumination matrix, a simplified LCD panel, and a linear Fresnel lens array serves as a test bed.

Paper number 32:
Title: From Traditional to Deep Learning Approaches in Whole Slide Image Registration: A Methodological Review
Authors: Behnaz Elhaminia, Abdullah Alsalemi, Esha Nasir, Mostafa Jahanifar, Ruqayya Awan, Lawrence S. Young, Nasir M. Rajpoot, Fayyaz Minhas, Shan E Ahmed Raza
Abstract: Whole slide image (WSI) registration is an essential task for analysing the tumour microenvironment (TME) in histopathology. It involves the alignment of spatial information between WSIs of the same section or serial sections of a tissue sample. The tissue sections are usually stained with single or multiple biomarkers before imaging, and the goal is to identify neighbouring nuclei along the Z-axis for creating a 3D image or identifying subclasses of cells in the TME. This task is considerably more challenging compared to radiology image registration, such as magnetic resonance imaging or computed tomography, due to various factors. These include gigapixel size of images, variations in appearance between differently stained tissues, changes in structure and morphology between non-consecutive sections, and the presence of artefacts, tears, and deformations. Currently, there is a noticeable gap in the literature regarding a review of the current approaches and their limitations, as well as the challenges and opportunities they present. We aim to provide a comprehensive understanding of the available approaches and their application for various purposes. Furthermore, we investigate current deep learning methods used for WSI registration, emphasising their diverse methodologies. We examine the available datasets and explore tools and software employed in the field. Finally, we identify open challenges and potential future trends in this area of research.

Paper number 33:
Title: RetinaRegen: A Hybrid Model for Readability and Detail Restoration in Fundus Images
Authors: Yuhan Tang, Yudian Wang, Weizhen Li, Ye Yue, Chengchang Pan, Honggang Qi
Abstract: Fundus image quality is crucial for diagnosing eye diseases, but real-world conditions often result in blurred or unreadable images, increasing diagnostic uncertainty. To address these challenges, this study proposes RetinaRegen, a hybrid model for retinal image restoration that integrates a readability classifi-cation model, a Diffusion Model, and a Variational Autoencoder (VAE). Ex-periments on the SynFundus-1M dataset show that the proposed method achieves a PSNR of 27.4521, an SSIM of 0.9556, and an LPIPS of 0.1911 for the readability labels of the optic disc (RO) region. These results demonstrate superior performance in restoring key regions, offering an effective solution to enhance fundus image quality and support clinical diagnosis.

Paper number 34:
Title: Beamforming and Waveform Optimization for RF Wireless Power Transfer with Beyond Diagonal Reconfigurable Intelligent Surfaces
Authors: Amirhossein Azarbahram, Onel L. A. Lopez, Bruno Clerckx, Marco Di Renzo, Matti Latva-Aho
Abstract: Radio frequency (RF) wireless power transfer (WPT) is a promising technology to seamlessly charge low-power devices, but its low end-to-end power transfer efficiency remains a critical challenge. To address the latter, low-cost transmit/radiating architectures, e.g., based on reconfigurable intelligent surfaces (RISs), have shown great potential. Beyond diagonal (BD) RIS is a novel branch of RIS offering enhanced performance over traditional diagonal RIS (D-RIS) in wireless communications, but its potential gains in RF-WPT remain unexplored. Motivated by this, we analyze a BD-RIS-assisted single-antenna RF-WPT system to charge a single rectifier, and formulate a joint beamforming and multi-carrier waveform optimization problem aiming to maximize the harvested power. We propose two solutions relying on semi-definite programming for fully connected BD-RIS and an efficient low-complexity iterative method relying on successive convex approximation. Numerical results show that the proposed algorithms converge to a local optimum and that adding transmit sub-carriers or RIS elements improves the harvesting performance. We show that the transmit power budget impacts the relative power allocation among different sub-carriers depending on the rectifier's operating regime, while BD-RIS shapes the cascade channel differently for frequency-selective and flat scenarios. Finally, we verify by simulation that BD-RIS and D-RIS achieve the same performance under pure far-field line-of-sight conditions (in the absence of mutual coupling). Meanwhile, BD-RIS outperforms D-RIS as the non-line-of-sight components of the channel become dominant.

Paper number 35:
Title: Multi-level Attention-guided Graph Neural Network for Image Restoration
Authors: Jiatao Jiang, Zhen Cui, Chunyan Xu, Jian Yang
Abstract: In recent years, deep learning has achieved remarkable success in the field of image restoration. However, most convolutional neural network-based methods typically focus on a single scale, neglecting the incorporation of multi-scale information. In image restoration tasks, local features of an image are often insufficient, necessitating the integration of global features to complement them. Although recent neural network algorithms have made significant strides in feature extraction, many models do not explicitly model global features or consider the relationship between global and local features. This paper proposes multi-level attention-guided graph neural network. The proposed network explicitly constructs element block graphs and element graphs within feature maps using multi-attention mechanisms to extract both local structural features and global representation information of the image. Since the network struggles to effectively extract global information during image degradation, the structural information of local feature blocks can be used to correct and supplement the global information. Similarly, when element block information in the feature map is missing, it can be refined using global element representation information. The graph within the network learns real-time dynamic connections through the multi-attention mechanism, and information is propagated and aggregated via graph convolution algorithms. By combining local element block information and global element representation information from the feature map, the algorithm can more effectively restore missing information in the image. Experimental results on several classic image restoration tasks demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance.

Paper number 36:
Title: Few Shot Alternating GD and Minimization for Generalizable Real-Time MRI
Authors: Silpa Babu, Sajan Goud Lingala, Namrata Vaswani
Abstract: This work introduces a novel near real-time (real-time after an initial short delay) MRI solution that handles motion well and is generalizable. Here, real-time means the algorithm works well on a highly accelerated scan, is zero-latency (reconstructs a new frame as soon as MRI data for it arrives), and is fast enough, i.e., the time taken to process a frame is comparable to the scan time per frame or lesser. We demonstrate its generalizability through experiments on 6 prospective datasets and 17 retrospective datasets that span multiple different applications -- speech larynx imaging, brain, ungated cardiac perfusion, cardiac cine, cardiac OCMR, abdomen; sampling schemes -- Cartesian, pseudo-radial, radial, spiral; and sampling rates -- ranging from 6x to 4 radial lines per frame. Comparisons with a large number of existing real-time and batch methods, including unsupervised and supervised deep learning methods, show the power and speed of our approach.

Paper number 37:
Title: Modelling Regional Solar Photovoltaic Capacity in Great Britain
Authors: Hussah Alghanem, Alastair Buckley
Abstract: Great Britain aims to meet growing electricity demand and achieve a fully decarbonised grid by 2035, targeting 70 GW of solar photovoltaic (PV) capacity. However, grid constraints and connection delays hinder solar integration. To address these integration challenges, various connection reform processes and policies are being developed [1]. This study supports the connection reforms with a model that estimates regional PV capacity at the NUTS 3 level, explaining 89% of the variation in capacity, with a mean absolute error of 20 MW and a national mean absolute percentage error of 5.4%. Artificial surfaces and agricultural areas are identified as key factors in deployment. The model has three primary applications: disaggregating national PV capacity into regional capacity, benchmarking regional PV deployment between different regions, and forecasting future PV capacity distribution. These applications support grid operators in generation monitoring and strategic grid planning by identifying regions where capacity is likely to be concentrated. This can address grid connection delays, plan network expansions, and resolve land-use conflicts.

Paper number 38:
Title: Deep learning and classical computer vision techniques in medical image analysis: Case studies on brain MRI tissue segmentation, lung CT COPD registration, and skin lesion classification
Authors: Anyimadu Daniel Tweneboah, Suleiman Taofik Ahmed, Hossain Mohammad Imran
Abstract: Medical imaging spans diverse tasks and modalities which play a pivotal role in disease diagnosis, treatment planning, and monitoring. This study presents a novel exploration, being the first to systematically evaluate segmentation, registration, and classification tasks across multiple imaging modalities. Integrating both classical and deep learning (DL) approaches in addressing brain MRI tissue segmentation, lung CT image registration, and skin lesion classification from dermoscopic images, we demonstrate the complementary strengths of these methodologies in diverse applications. For brain tissue segmentation, 3D DL models outperformed 2D and patch-based models, specifically nnU-Net achieving Dice of 0.9397, with 3D U-Net models on ResNet34 backbone, offering competitive results with Dice 0.8946. Multi-Atlas methods provided robust alternatives for cases where DL methods are not feasible, achieving average Dice of 0.7267. In lung CT registration, classical Elastix-based methods outperformed DL models, achieving a minimum Target Registration Error (TRE) of 6.68 mm, highlighting the effectiveness of parameter tuning. HighResNet performed best among DL models with a TRE of 7.40 mm. For skin lesion classification, ensembles of DL models like InceptionResNetV2 and ResNet50 excelled, achieving up to 90.44%, and 93.62% accuracies for binary and multiclass classification respectively. Also, adopting One-vs-All method, DL attained accuracies of 94.64% (mel vs. others), 95.35% (bcc vs. others), and 96.93% (scc vs. others), while ML models specifically Multi-Layer Perceptron (MLP) on handcrafted features offered interpretable alternatives with 85.04% accuracy using SMOTE for class imbalance correction on the multi-class task and 83.27% on the binary-class task. Links to source code are available on request.

Paper number 39:
Title: Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces
Authors: Jiyuan Wang, Weishan Ye, Jialin He, Li Zhang, Gan Huang, Zhuliang Yu, Zhen Liang
Abstract: With the rapid advancement of deep learning, attention mechanisms have become indispensable in electroencephalography (EEG) signal analysis, significantly enhancing Brain-Computer Interface (BCI) applications. This paper presents a comprehensive review of traditional and Transformer-based attention mechanisms, their embedding strategies, and their applications in EEG-based BCI, with a particular emphasis on multimodal data fusion. By capturing EEG variations across time, frequency, and spatial channels, attention mechanisms improve feature extraction, representation learning, and model robustness. These methods can be broadly categorized into traditional attention mechanisms, which typically integrate with convolutional and recurrent networks, and Transformer-based multi-head self-attention, which excels in capturing long-range dependencies. Beyond single-modality analysis, attention mechanisms also enhance multimodal EEG applications, facilitating effective fusion between EEG and other physiological or sensory data. Finally, we discuss existing challenges and emerging trends in attention-based EEG modeling, highlighting future directions for advancing BCI technology. This review aims to provide valuable insights for researchers seeking to leverage attention mechanisms for improved EEG interpretation and application.

Paper number 40:
Title: Pilot and Data Power Control for Uplink Cell-free massive MIMO
Authors: Saeed Mohammadzadeh, Mostafa Rahmani, Kanapathippillai Cumanan, Alister Burr, Pei Xiao
Abstract: This paper introduces a novel iterative algorithm for optimizing pilot and data power control (PC) in cell-free massive multiple-input multiple-output (CF-mMIMO) systems, aiming to enhance system performance under real-time channel conditions. The approach begins by deriving the signal-to-interference-plus-noise ratio (SINR) using a matched filtering receiver and formulating a min-max optimization problem to minimize the normalized mean square error (NMSE). Utilizing McCormick relaxation, the algorithm adjusts pilot power dynamically, ensuring efficient channel estimation. A subsequent max-min optimization problem allocates data power, balancing fairness and efficiency. The iterative process refines pilot and data power allocations based on updated channel state information (CSI) and NMSE results, optimizing spectral efficiency. By leveraging geometric programming (GP) for data power allocation, the proposed method achieves a robust trade-off between simplicity and performance, significantly improving system capacity and fairness. The simulation results demonstrate that dynamic adjustment of both pilot and data PC substantially enhances overall spectral efficiency and fairness, outperforming the existing schemes in the literature.

Paper number 41:
Title: A Direct State-Space Realization of Discrete-Time Linear Parameter-Varying Input-Output Models
Authors: Johan Kon, Roland Tóth, Jeroen van de Wijdeven, Marcel Heertjes, Tom Oomen
Abstract: A minimal state-space (SS) realization of an identified linear parameter-varying (LPV) input-output (IO) model usually introduces dynamic and nonlinear dependency of the state-space coefficient functions, complicating stability analysis and controller synthesis. The aim of this paper is to introduce and analyze a direct SS realization of this IO model that avoids this nonlinear and dynamic dependency, at the cost of introducing a nonminimal state. It is shown that this direct SS realization 1) is reachable under a coprimeness condition on the coefficient functions of the IO model and a well-posedness condition on the model order, and 2) is never observable but that the unobservable directions converge to zero in a finite amount of steps, i.e., that the realization is reconstructible. The derived results are illustrated through numerical examples in both the LPV and LTI case.

Paper number 42:
Title: Deep Learning-Based Transfer Learning for Classification of Cassava Disease
Authors: Ademir G. Costa Junior, Fábio S. da Silva, Ricardo Rios
Abstract: This paper presents a performance comparison among four Convolutional Neural Network architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) for classifying cassava disease images. The images were sourced from an imbalanced dataset from a competition. Appropriate metrics were employed to address class imbalance. The results indicate that EfficientNet-B3 achieved on this task accuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of 87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool to support Digital Agriculture.

Paper number 43:
Title: Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis
Authors: Minjoo Lim, Bogyeong Kang, Tae-Eui Kam
Abstract: Multi-modal magnetic resonance imaging (MRI) is essential for providing complementary information about brain anatomy and pathology, leading to more accurate diagnoses. However, obtaining high-quality multi-modal MRI in a clinical setting is difficult due to factors such as time constraints, high costs, and patient movement artifacts. To overcome this difficulty, there is increasing interest in developing generative models that can synthesize missing target modality images from the available source ones. Therefore, we design a generative model for missing MRI that integrates multi-modal contrastive learning with a focus on critical tumor regions. Specifically, we integrate multi-modal contrastive learning, tailored for multiple source modalities, and enhance its effectiveness by selecting features based on entropy during the contrastive learning process. Additionally, our network not only generates the missing target modality images but also predicts segmentation outputs, simultaneously. This approach improves the generator's capability to precisely generate tumor regions, ultimately improving performance in downstream segmentation tasks. By leveraging a combination of contrastive, segmentation, and additional self-representation losses, our model effectively reflects target-specific information and generate high-quality target images. Consequently, our results in the Brain MR Image Synthesis challenge demonstrate that the proposed model excelled in generating the missing modality.

Paper number 44:
Title: Convolutional neural networks for mineral prospecting through alteration mapping with remote sensing data
Authors: Ehsan Farahbakhsh, Dakshi Goel, Dhiraj Pimparkar, R. Dietmar Muller, Rohitash Chandra
Abstract: Traditional geological mapping, based on field observations and rock sample analysis, is inefficient for continuous spatial mapping of features like alteration zones. Deep learning models, such as convolutional neural networks (CNNs), have revolutionised remote sensing data analysis by automatically extracting features for classification and regression tasks. CNNs can detect specific mineralogical changes linked to mineralisation by identifying subtle features in remote sensing data. This study uses CNNs with Landsat 8, Landsat 9, and ASTER data to map alteration zones north of Broken Hill, New South Wales, Australia. The model is trained using ground truth data and an automated approach with selective principal component analysis (PCA). We compare CNNs with traditional machine learning models, including k-nearest neighbours, support vector machines, and multilayer perceptron. Results show that ground truth-based training yields more reliable maps, with CNNs slightly outperforming conventional models in capturing spatial patterns. Landsat 9 outperforms Landsat 8 in mapping iron oxide areas using ground truth-trained CNNs, while ASTER data provides the most accurate argillic and propylitic alteration maps. This highlights CNNs' effectiveness in improving geological mapping precision, especially for identifying subtle mineralisation-related alterations.

Paper number 45:
Title: Multigrid methods for total variation
Authors: Felipe Guerra, Tuomo Valkonen
Abstract: Based on a nonsmooth coherence condition, we construct and prove the convergence of a forward-backward splitting method that alternates between steps on a fine and a coarse grid. Our focus is a total variation regularised inverse imaging problems, specifically, their dual problems, for which we develop in detail the relevant coarse-grid problems. We demonstrate the performance of our method on total variation denoising and magnetic resonance imaging.

Paper number 46:
Title: Enhancing Subject-Independent Accuracy in fNIRS-based Brain-Computer Interfaces with Optimized Channel Selection
Authors: Yuxin Li, Hao Fang, Wen Liu, Chuantong Cheng, Hongda Chen
Abstract: Achieving high subject-independent accuracy in functional near-infrared spectroscopy (fNIRS)-based brain-computer interfaces (BCIs) remains a challenge, particularly when minimizing the number of channels. This study proposes a novel feature extraction scheme and a Pearson correlation-based channel selection algorithm to enhance classification accuracy while reducing hardware complexity. Using an open-access fNIRS dataset, our method improved average accuracy by 28.09% compared to existing approaches, achieving a peak subject-independent accuracy of 95.98% with only two channels. These results demonstrate the potential of our optimized feature extraction and channel selection methods for developing efficient, subject-independent fNIRS-based BCI systems.

Paper number 47:
Title: Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking
Authors: Shaheer Mohamed, Tharindu Fernando, Sridha Sridharan, Peyman Moghadam, Clinton Fookes
Abstract: Hyperspectral object tracking using snapshot mosaic cameras is emerging as it provides enhanced spectral information alongside spatial data, contributing to a more comprehensive understanding of material properties. Using transformers, which have consistently outperformed convolutional neural networks (CNNs) in learning better feature representations, would be expected to be effective for Hyperspectral object tracking. However, training large transformers necessitates extensive datasets and prolonged training periods. This is particularly critical for complex tasks like object tracking, and the scarcity of large datasets in the hyperspectral domain acts as a bottleneck in achieving the full potential of powerful transformer models. This paper proposes an effective methodology that adapts large pretrained transformer-based foundation models for hyperspectral object tracking. We propose an adaptive, learnable spatial-spectral token fusion module that can be extended to any transformer-based backbone for learning inherent spatial-spectral features in hyperspectral data. Furthermore, our model incorporates a cross-modality training pipeline that facilitates effective learning across hyperspectral datasets collected with different sensor modalities. This enables the extraction of complementary knowledge from additional modalities, whether or not they are present during testing. Our proposed model also achieves superior performance with minimal training iterations.

Paper number 48:
Title: O-RIS-ing: Evaluating RIS-Assisted NextG Open RAN
Authors: Maria Tsampazi, Michele Polese, Falko Dressler, Tommaso Melodia
Abstract: Reconfigurable Intelligent Surfaces (RISs) pose as a transformative technology to revolutionize the cellular architecture of Next Generation (NextG) Radio Access Networks (RANs). Previous studies have demonstrated the capabilities of RISs in optimizing wireless propagation, achieving high spectral efficiency, and improving resource utilization. At the same time, the transition to softwarized, disaggregated, and virtualized architectures, such as those being standardized by the O-RAN ALLIANCE, enables the vision of a reconfigurable Open RAN. In this work, we aim to integrate these technologies by studying how different resource allocation policies enhance the performance of RIS-assisted Open RANs. We perform a comparative analysis among various network configurations and show how proper network optimization can enhance the performance across the Enhanced Mobile Broadband (eMBB) and Ultra Reliable and Low Latency Communications (URLLC) network slices, achieving up to ~34% throughput improvement. Furthermore, leveraging the capabilities of OpenRAN Gym, we deploy an xApp on Colosseum, the world's largest wireless system emulator with hardware-in-the-loop, to control the Base Station (BS)'s scheduling policy. Experimental results demonstrate that RIS-assisted topologies achieve high resource efficiency and low latency, regardless of the BS's scheduling policy.

Paper number 49:
Title: Stabilization of singularly perturbed networked control systems over a single channel
Authors: Weixuan Wang, Alejandro I. Maass, Dragan Nešić, Ying Tan, Romain Postoyan, W.P.M.H. Heemels
Abstract: This paper studies the emulation-based stabilization of nonlinear networked control systems with two time scales. We address the challenge of using a single communication channel for transmitting both fast and slow variables between the plant and the controller. A novel dual clock mechanism is proposed to schedule transmissions for this purpose. The system is modeled as a hybrid singularly perturbed dynamical system, and singular perturbation analysis is employed to determine individual maximum allowable transmission intervals for both fast and slow variables, ensuring semi-global practical asymptotic stability. Enhanced stability guarantees are also provided under stronger assumptions. The efficacy of the proposed method is illustrated through a numerical example.

Paper number 50:
Title: Damping Tuning Considering Random Disturbances Adopting Distributionally Robust Optimization
Authors: Yuhong Wang, Xinyao Wang, Chen Shen, Jianquan Liao, Qianni Cao, Yufei Teng, Huabo Shi, Gang Chen
Abstract: In scenarios where high penetration of renewable energy sources (RES) is connected to the grid over long distances, the output of RES exhibits significant fluctuations, making it difficult to accurately characterize. The intermittency and uncertainty of these fluctuations pose challenges to the stability of the power system. This paper proposes a distributionally robust damping optimization control framework (DRDOC) to address the uncertainty in the true distribution of random disturbances caused by RES. First, the installation location of damping controllers and key control parameters are determined through Sobol sensitivity indices and participation factors. Next, a nonlinear relationship between damping and random disturbances is established with Polynomial Chaos Expansion (PCE). The uncertainty in the distribution of disturbances is captured by ambiguity sets. The DRDOC is formulated as a convex optimization problem, which is further simplified for efficient computation. Finally, the optimal control parameters are derived through convex optimization techniques. Simulation results demonstrate the effectiveness and distribution robustness of the proposed DRDOC.

Paper number 51:
Title: RL-OGM-Parking: Lidar OGM-Based Hybrid Reinforcement Learning Planner for Autonomous Parking
Authors: Zhitao Wang, Zhe Chen, Mingyang Jiang, Tong Qin, Ming Yang
Abstract: Autonomous parking has become a critical application in automatic driving research and development. Parking operations often suffer from limited space and complex environments, requiring accurate perception and precise maneuvering. Traditional rule-based parking algorithms struggle to adapt to diverse and unpredictable conditions, while learning-based algorithms lack consistent and stable performance in various scenarios. Therefore, a hybrid approach is necessary that combines the stability of rule-based methods and the generalizability of learning-based methods. Recently, reinforcement learning (RL) based policy has shown robust capability in planning tasks. However, the simulation-to-reality (sim-to-real) transfer gap seriously blocks the real-world deployment. To address these problems, we employ a hybrid policy, consisting of a rule-based Reeds-Shepp (RS) planner and a learning-based reinforcement learning (RL) planner. A real-time LiDAR-based Occupancy Grid Map (OGM) representation is adopted to bridge the sim-to-real gap, leading the hybrid policy can be applied to real-world systems seamlessly. We conducted extensive experiments both in the simulation environment and real-world scenarios, and the result demonstrates that the proposed method outperforms pure rule-based and learning-based methods. The real-world experiment further validates the feasibility and efficiency of the proposed method.

Paper number 52:
Title: Clip-TTS: Contrastive Text-content and Mel-spectrogram, A High-Huality Text-to-Speech Method based on Contextual Semantic Understanding
Authors: Tianyun Liu
Abstract: Traditional text-to-speech (TTS) methods primarily focus on establishing a mapping between phonemes and mel-spectrograms. However, during the phoneme encoding stage, there is often a lack of real mel-spectrogram auxiliary information, which results in the encoding process lacking true semantic understanding. At the same time, traditional TTS systems often struggle to balance the inference speed of the model with the quality of the synthesized speech. Methods that generate high-quality synthesized speech tend to have slower inference speeds, while faster inference methods often sacrifice speech quality. In this paper, I propose Clip-TTS, a TTS method based on the Clip architecture. This method uses the Clip framework to establish a connection between text content and real mel-spectrograms during the text encoding stage, enabling the text encoder to directly learn the true semantics of the global context, thereby ensuring the quality of the synthesized speech. In terms of model architecture, I adopt the basic structure of Transformer, which allows Clip-TTS to achieve fast inference speeds. Experimental results show that on the LJSpeech and Baker datasets, the speech generated by Clip-TTS achieves state-of-the-art MOS scores, and it also performs excellently on multi-emotion this http URL samples are available at: this https URL.

Paper number 53:
Title: CS-Dialogue: A 104-Hour Dataset of Spontaneous Mandarin-English Code-Switching Dialogues for Speech Recognition
Authors: Jiaming Zhou, Yujie Guo, Shiwan Zhao, Haoqin Sun, Hui Wang, Jiabei He, Aobo Kong, Shiyao Wang, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin
Abstract: Code-switching (CS), the alternation between two or more languages within a single conversation, presents significant challenges for automatic speech recognition (ASR) systems. Existing Mandarin-English code-switching datasets often suffer from limitations in size, spontaneity, and the lack of full-length dialogue recordings with transcriptions, hindering the development of robust ASR models for real-world conversational scenarios. This paper introduces CS-Dialogue, a novel large-scale Mandarin-English code-switching speech dataset comprising 104 hours of spontaneous conversations from 200 speakers. Unlike previous datasets, CS-Dialogue provides full-length dialogue recordings with complete transcriptions, capturing naturalistic code-switching patterns in continuous speech. We describe the data collection and annotation processes, present detailed statistics of the dataset, and establish benchmark ASR performance using state-of-the-art models. Our experiments, using Transformer, Conformer, and Branchformer, demonstrate the challenges of code-switching ASR, and show that existing pre-trained models such as Whisper still have the space to improve. The CS-Dialogue dataset will be made freely available for all academic purposes.

Paper number 54:
Title: Brain-inspired analogical mixture prototypes for few-shot class-incremental learning
Authors: Wanyi Li, Wei Wei, Yongkang Luo, Peng Wang
Abstract: Few-shot class-incremental learning (FSCIL) poses significant challenges for artificial neural networks due to the need to efficiently learn from limited data while retaining knowledge of previously learned tasks. Inspired by the brain's mechanisms for categorization and analogical learning, we propose a novel approach called Brain-inspired Analogical Mixture Prototypes (BAMP). BAMP has three components: mixed prototypical feature learning, statistical analogy, and soft voting. Starting from a pre-trained Vision Transformer (ViT), mixed prototypical feature learning represents each class using a mixture of prototypes and fine-tunes these representations during the base session. The statistical analogy calibrates the mean and covariance matrix of prototypes for new classes according to similarity to the base classes, and computes classification score with Mahalanobis distance. Soft voting combines both merits of statistical analogy and an off-shelf FSCIL method. Our experiments on benchmark datasets demonstrate that BAMP outperforms state-of-the-art on both traditional big start FSCIL setting and challenging small start FSCIL setting. The study suggests that brain-inspired analogical mixture prototypes can alleviate catastrophic forgetting and over-fitting problems in FSCIL.

Paper number 55:
Title: Switching multiplicative watermark design against covert attacks
Authors: Alexander J. Gallo, Sribalaji C. Anand, André M. H. Teixeira, Riccardo M. G. Ferrari
Abstract: Active techniques have been introduced to give better detectability performance for cyber-attack diagnosis in cyber-physical systems (CPS). In this paper, switching multiplicative watermarking is considered, whereby we propose an optimal design strategy to define switching filter parameters. Optimality is evaluated exploiting the so-called output-to-output gain of the closed loop system, including some supposed attack dynamics. A worst-case scenario of a matched covert attack is assumed, presuming that an attacker with full knowledge of the closed-loop system injects a stealthy attack of bounded energy. Our algorithm, given watermark filter parameters at some time instant, provides optimal next-step parameters. Analysis of the algorithm is given, demonstrating its features, and demonstrating that through initialization of certain parameters outside of the algorithm, the parameters of the multiplicative watermarking can be randomized. Simulation shows how, by adopting our method for parameter design, the attacker's impact on performance diminishes.

Paper number 56:
Title: DualSpec: Text-to-spatial-audio Generation via Dual-Spectrogram Guided Diffusion Model
Authors: Lei Zhao, Sizhou Chen, Linfeng Feng, Xiao-Lei Zhang, Xuelong Li
Abstract: Text-to-audio (TTA), which generates audio signals from textual descriptions, has received huge attention in recent years. However, recent works focused on text to monaural audio only. As we know, spatial audio provides more immersive auditory experience than monaural audio, e.g. in virtual reality. To address this issue, we propose a text-to-spatial-audio (TTSA) generation framework named this http URL, it first trains variational autoencoders (VAEs) for extracting the latent acoustic representations from sound event audio. Then, given text that describes sound events and event directions, the proposed method uses the encoder of a pretrained large language model to transform the text into text features. Finally, it trains a diffusion model from the latent acoustic representations and text features for the spatial audio generation. In the inference stage, only the text description is needed to generate spatial audio. Particularly, to improve the synthesis quality and azimuth accuracy of the spatial sound events simultaneously, we propose to use two kinds of acoustic features. One is the Mel spectrograms which is good for improving the synthesis quality, and the other is the short-time Fourier transform spectrograms which is good at improving the azimuth accuracy. We provide a pipeline of constructing spatial audio dataset with text prompts, for the training of the VAEs and diffusion model. We also introduce new spatial-aware evaluation metrics to quantify the azimuth errors of the generated spatial audio recordings. Experimental results demonstrate that the proposed method can generate spatial audio with high directional and event consistency.

Paper number 57:
Title: Handover-Aware Trajectory Optimization for Cellular-Connected UAV
Authors: Xiangming Du, Shuowen Zhang, Francis C.-M. Lau
Abstract: In this letter, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to complete a mission of flying between two pre-determined locations while maintaining satisfactory communication quality with the ground base stations (GBSs). Due to the potentially long distance of the UAV's flight, frequent handovers may be incurred among different GBSs, which leads to various practical issues such as large delay and synchronization overhead. To address this problem, we investigate the trajectory optimization of the UAV to minimize the number of GBS handovers during the flight, subject to a communication quality constraint and a maximum mission completion time constraint. Although this problem is non-convex and difficult to solve, we derive useful structures of the optimal solution, based on which we propose an efficient algorithm based on graph theory and Lagrangian relaxation for finding a high-quality suboptimal solution in polynomial time. Numerical results validate the effectiveness of our proposed trajectory design.

Paper number 58:
Title: Software demodulation of weak radio signals using convolutional neural network
Authors: Mykola Kozlenko, Ihor Lazarovych, Valerii Tkachuk, Vira Vialkova
Abstract: In this paper we proposed the use of JT65A radio communication protocol for data exchange in wide-area monitoring systems in electric power systems. We investigated the software demodulation of the multiple frequency shift keying weak signals transmitted with JT65A communication protocol using deep convolutional neural network. We presented the demodulation performance in form of symbol and bit error rates. We focused on the interference immunity of the protocol over an additive white Gaussian noise with average signal-to-noise ratios in the range from -30 dB to 0 dB, which was obtained for the first time. We proved that the interference immunity is about 1.5 dB less than the theoretical limit of non-coherent demodulation of orthogonal MFSK signals.

Paper number 59:
Title: Design of Cavity Backed Slotted Antenna using Machine Learning Regression Model
Authors: Vijay Kumar Sutrakar, Anjana PK, Rohit Bisariya, Soumya KK, Gopal Chawan M
Abstract: In this paper, a regression-based machine learning model is used for the design of cavity backed slotted antenna. This type of antenna is commonly used in military and aviation communication systems. Initial reflection coefficient data of cavity backed slotted antenna is generated using electromagnetic solver. These reflection coefficient data is then used as input for training regression-based machine learning model. The model is trained to predict the dimensions of cavity backed slotted antenna based on the input reflection coefficient for a wide frequency band varying from 1 GHz to 8 GHz. This approach allows for rapid prediction of optimal antenna configurations, reducing the need for repeated physical testing and manual adjustments, may lead to significant amount of design and development cost saving. The proposed model also demonstrates its versatility in predicting multi frequency resonance across 1 GHz to 8 GHz. Also, the proposed approach demonstrates the potential for leveraging machine learning in advanced antenna design, enhancing efficiency and accuracy in practical applications such as radar, military identification systems and secure communication networks.

Paper number 60:
Title: Generalizable deep learning for photoplethysmography-based blood pressure estimation -- A Benchmarking Study
Authors: Mohammad Moulaeifard, Peter H. Charlton, Nils Strodthoff
Abstract: Photoplethysmography (PPG)-based blood pressure (BP) estimation represents a promising alternative to cuff-based BP measurements. Recently, an increasing number of deep learning models have been proposed to infer BP from the raw PPG waveform. However, these models have been predominantly evaluated on in-distribution test sets, which immediately raises the question of the generalizability of these models to external datasets. To investigate this question, we trained five deep learning models on the recently released PulseDB dataset, provided in-distribution benchmarking results on this dataset, and then assessed out-of-distribution performance on several external datasets. The best model (XResNet1d101) achieved in-distribution MAEs of 9.4 and 6.0 mmHg for systolic and diastolic BP respectively on PulseDB (with subject-specific calibration), and 14.0 and 8.5 mmHg respectively without calibration. Equivalent MAEs on external test datasets without calibration ranged from 15.0 to 25.1 mmHg (SBP) and 7.0 to 10.4 mmHg (DBP). Our results indicate that the performance is strongly influenced by the differences in BP distributions between datasets. We investigated a simple way of improving performance through sample-based domain adaptation and put forward recommendations for training models with good generalization properties. With this work, we hope to educate more researchers for the importance and challenges of out-of-distribution generalization.

Paper number 61:
Title: Self-supervised conformal prediction for uncertainty quantification in Poisson imaging problems
Authors: Bernardin Tamo Amougou, Marcelo Pereyra, Barbara Pascal
Abstract: Image restoration problems are often ill-posed, leading to significant uncertainty in reconstructed images. Accurately quantifying this uncertainty is essential for the reliable interpretation of reconstructed images. However, image restoration methods often lack uncertainty quantification capabilities. Conformal prediction offers a rigorous framework to augment image restoration methods with accurate uncertainty quantification estimates, but it typically requires abundant ground truth data for calibration. This paper presents a self-supervised conformal prediction method for Poisson imaging problems which leverages Poisson Unbiased Risk Estimator to eliminate the need for ground truth data. The resulting self-calibrating conformal prediction approach is applicable to any Poisson linear imaging problem that is ill-conditioned, and is particularly effective when combined with modern self-supervised image restoration techniques trained directly on measurement data. The proposed method is demonstrated through numerical experiments on image denoising and deblurring; its performance are comparable to supervised conformal prediction methods relying on ground truth data.

Paper number 62:
Title: CPG-Based Manipulation with Multi-Module Origami Robot Surface
Authors: Yuhao Jiang, Serge El Asmar, Ziqiao Wang, Serhat Demirtas, Jamie Paik
Abstract: Robotic manipulators often face challenges in handling objects of different sizes and materials, limiting their effectiveness in practical applications. This issue is particularly pronounced when manipulating meter-scale objects or those with varying stiffness, as traditional gripping techniques and strategies frequently prove inadequate. In this letter, we introduce a novel surface-based multi-module robotic manipulation framework that utilizes a Central Pattern Generator (CPG)-based motion generator, combined with a simulation-based optimization method to determine the optimal manipulation parameters for a multi-module origami robotic surface (Ori-Pixel). This approach allows for the manipulation of objects ranging from centimeters to meters in size, with varying stiffness and shape. The optimized CPG parameters are tested through both dynamic simulations and a series of prototype experiments involving a wide range of objects differing in size, weight, shape, and material, demonstrating robust manipulation capabilities.

Paper number 63:
Title: Arbitrary Volumetric Refocusing of Dense and Sparse Light Fields
Authors: Tharindu Samarakoon, Kalana Abeywardena, Chamira U. S. Edussooriya
Abstract: A four-dimensional light field (LF) captures both textural and geometrical information of a scene in contrast to a two-dimensional image that captures only the textural information of a scene. Post-capture refocusing is an exciting application of LFs enabled by the geometric information captured. Previously proposed LF refocusing methods are mostly limited to the refocusing of single planar or volumetric region of a scene corresponding to a depth range and cannot simultaneously generate in-focus and out-of-focus regions having the same depth range. In this paper, we propose an end-to-end pipeline to simultaneously refocus multiple arbitrary planar or volumetric regions of a dense or a sparse LF. We employ pixel-dependent shifts with the typical shift-and-sum method to refocus an LF. The pixel-dependent shifts enables to refocus each pixel of an LF independently. For sparse LFs, the shift-and-sum method introduces ghosting artifacts due to the spatial undersampling. We employ a deep learning model based on U-Net architecture to almost completely eliminate the ghosting artifacts. The experimental results obtained with several LF datasets confirm the effectiveness of the proposed method. In particular, sparse LFs refocused with the proposed method archive structural similarity index higher than 0.9 despite having only 20% of data compared to dense LFs.

Paper number 64:
Title: Epitaxial high-K AlBN barrier GaN HEMTs
Authors: Chandrashekhar Savant, Thai-Son Nguyen, Kazuki Nomoto, Saurabh Vishwakarma, Siyuan Ma, Akshey Dhar, Yu-Hsin Chen, Joseph Casamento, David J. Smith, Huili Grace Xing, Debdeep Jena
Abstract: We report a polarization-induced 2D electron gas (2DEG) at an epitaxial AlBN/GaN heterojunction grown on a SiC substrate. Using this 2DEG in a long conducting channel, we realize ultra-thin barrier AlBN/GaN high electron mobility transistors that exhibit current densities of more than 0.25 A/mm, clean current saturation, a low pinch-off voltage of -0.43 V, and a peak transconductance of 0.14 S/mm. Transistor performance in this preliminary realization is limited by the contact resistance. Capacitance-voltage measurements reveal that introducing 7 % B in the epitaxial AlBN barrier on GaN boosts the relative dielectric constant of AlBN to 16, higher than the AlN dielectric constant of 9. Epitaxial high-K barrier AlBN/GaN HEMTs can thus extend performance beyond the capabilities of current GaN transistors.

Paper number 65:
Title: Unveiling Wireless Users' Locations via Modulation Classification-based Passive Attack
Authors: Ali Hanif, Abdulrahman Katranji, Nour Kouzayha, Muhammad Mahboob Ur Rahman, Tareq Y. Al-Naffouri
Abstract: The broadcast nature of the wireless medium and openness of wireless standards, e.g., 3GPP releases 16-20, invite adversaries to launch various active and passive attacks on cellular and other wireless networks. This work identifies one such loose end of wireless standards and presents a novel passive attack method enabling an eavesdropper (Eve) to localize a line of sight wireless user (Bob) who is communicating with a base station or WiFi access point (Alice). The proposed attack involves two phases. In the first phase, Eve performs modulation classification by intercepting the downlink channel between Alice and Bob. This enables Eve to utilize the publicly available modulation and coding scheme (MCS) tables to do pesudo-ranging, i.e., the Eve determines the ring within which Bob is located, which drastically reduces the search space. In the second phase, Eve sniffs the uplink channel, and employs multiple strategies to further refine Bob's location within the ring. Towards the end, we present our thoughts on how this attack can be extended to non-line-of-sight scenarios, and how this attack could act as a scaffolding to construct a malicious digital twin map.

Paper number 66:
Title: Two-Stage Weighted Projection for Reliable Low-Complexity Cooperative and Non-Cooperative Localization
Authors: Harish K. Dureppagari, R. Michael Buehrer, Harpreet S. Dhillon
Abstract: In this paper, we propose a two-stage weighted projection method (TS-WPM) for time-difference-of-arrival (TDOA)-based localization, providing provable improvements in positioning accuracy, particularly under high geometric dilution of precision (GDOP) and low signal-to-noise ratio (SNR) conditions. TS-WPM employs a two-stage iterative refinement approach that dynamically updates both range and position estimates, effectively mitigating residual errors while maintaining computational efficiency. Additionally, we extend TS-WPM to support cooperative localization by leveraging two-way time-of-arrival (TW-TOA) measurements, which enhances positioning accuracy in scenarios with limited anchor availability. To analyze TS-WPM, we derive its error covariance matrix and mean squared error (MSE), establishing conditions for its optimality and robustness. To facilitate rigorous evaluation, we develop a 3rd Generation Partnership Project (3GPP)-compliant analytical framework, incorporating 5G New Radio (NR) physical layer aspects as well as large-scale and small-scale fading. As part of this, we derive a generalized Cram{é}r-Rao lower bound (CRLB) for multipath propagation and introduce a novel non-line-of-sight (NLOS) bias model that accounts for propagation conditions and SNR variations. Our evaluations demonstrate that TS-WPM achieves near-CRLB performance and consistently outperforms state-of-the-art weighted nonlinear least squares (WNLS) in high GDOP and low SNR scenarios. Moreover, cooperative localization with TS-WPM significantly enhances accuracy, especially when an insufficient number of anchors (such as 2) are visible. Finally, we analyze the computational complexity of TS-WPM, showing its balanced trade-off between accuracy and efficiency, making it a scalable solution for real-time localization in next-generation networks.

Paper number 67:
Title: Recurrent Auto-Encoders for Enhanced Deep Reinforcement Learning in Wilderness Search and Rescue Planning
Authors: Jan-Hendrik Ewers, David Anderson, Douglas Thomson
Abstract: Wilderness search and rescue operations are often carried out over vast landscapes. The search efforts, however, must be undertaken in minimum time to maximize the chance of survival of the victim. Whilst the advent of cheap multicopters in recent years has changed the way search operations are handled, it has not solved the challenges of the massive areas at hand. The problem therefore is not one of complete coverage, but one of maximizing the information gathered in the limited time available. In this work we propose that a combination of a recurrent autoencoder and deep reinforcement learning is a more efficient solution to the search problem than previous pure deep reinforcement learning or optimisation approaches. The autoencoder training paradigm efficiently maximizes the information throughput of the encoder into its latent space representation which deep reinforcement learning is primed to leverage. Without the overhead of independently solving the problem that the recurrent autoencoder is designed for, it is more efficient in learning the control task. We further implement three additional architectures for a comprehensive comparison of the main proposed architecture. Similarly, we apply both soft actor-critic and proximal policy optimisation to provide an insight into the performance of both in a highly non-linear and complex application with a large observation Results show that the proposed architecture is vastly superior to the benchmarks, with soft actor-critic achieving the best performance. This model further outperformed work from the literature whilst having below a fifth of the total learnable parameters and training in a quarter of the time.

Paper number 68:
Title: Surface-Based Manipulation
Authors: Ziqiao Wang, Serhat Demirtas, Fabio Zuliani, Jamie Paik
Abstract: Intelligence lies not only in the brain but in the body. The shape of our bodies can influence how we think and interact with the physical world. In robotics research, interacting with the physical world is crucial as it allows robots to manipulate objects in various real-life scenarios. Conventional robotic manipulation strategies mainly rely on finger-shaped end effectors. However, achieving stable grasps on fragile, deformable, irregularly shaped, or slippery objects is challenging due to difficulties in establishing stable force or geometric constraints. Here, we present surface-based manipulation strategies that diverge from classical grasping approaches, using with flat surfaces as minimalist end-effectors. By changing the position and orientation of these surfaces, objects can be translated, rotated and even flipped across the surface using closed-loop control strategies. Since this method does not rely on stable grasp, it can adapt to objects of various shapes, sizes, and stiffness levels, even enabling the manipulation the shape of deformable objects. Our results provide a new perspective for solving complex manipulation problems.

Paper number 69:
Title: A variational and symplectic framework for model-free control: preliminary results
Authors: Loïc Michel
Abstract: The model-free control approach is an advanced control law that requires few information about the process to control. Since its introduction in 2008, numerous applications have been successfully considered, highlighting attractive robustness properties towards tracking efficiency and disturbance rejection. In this work, a variational approach of the model-free control is proposed in order to extend its robustness capabilities. An adaptive formulation of the controller is proposed using the calculus of variations within a symplectic framework, that aims to consider the control law as an optimization problem toward the auto-tuning of its main key parameter. The proposed formulation provides a coupling between the model-free control law and a variational integrator to improve the robustness of the tracking towards process changes and emphasize closed-loop stabilization. Some illustrative examples are discussed to highlight the rightness of the proposed approach.

Paper number 70:
Title: Combining TF-GridNet and Mixture Encoder for Continuous Speech Separation for Meeting Transcription
Authors: Peter Vieting, Simon Berger, Thilo von Neumann, Christoph Boeddeker, Ralf Schlüter, Reinhold Haeb-Umbach
Abstract: Many real-life applications of automatic speech recognition (ASR) require processing of overlapped speech. A common method involves first separating the speech into overlap-free streams on which ASR is performed. Recently, TF-GridNet has shown impressive performance in speech separation in real reverberant conditions. Furthermore, a mixture encoder was proposed that leverages the mixed speech to mitigate the effect of separation artifacts. In this work, we extended the mixture encoder from a static two-speaker scenario to a natural meeting context featuring an arbitrary number of speakers and varying degrees of overlap. We further demonstrate its limits by the integration with separators of varying strength including TF-GridNet. Our experiments result in a new state-of-the-art performance on LibriCSS using a single microphone. They show that TF-GridNet largely closes the gap between previous methods and oracle separation independent of mixture encoding. We further investigate the remaining potential for improvement.

Paper number 71:
Title: Neural Radiance Fields in Medical Imaging: A Survey
Authors: Xin Wang, Yineng Chen, Shu Hu, Heng Fan, Hongtu Zhu, Xin Li
Abstract: Neural Radiance Fields (NeRF), as a pioneering technique in computer vision, offer great potential to revolutionize medical imaging by synthesizing three-dimensional representations from the projected two-dimensional image data. However, they face unique challenges when applied to medical applications. This paper presents a comprehensive examination of applications of NeRFs in medical imaging, highlighting four imminent challenges, including fundamental imaging principles, inner structure requirement, object boundary definition, and color density significance. We discuss current methods on different organs and discuss related limitations. We also review several datasets and evaluation metrics and propose several promising directions for future research.

Paper number 72:
Title: NeuroVoz: a Castillian Spanish corpus of parkinsonian speech
Authors: Janaína Mendes-Laureano, Jorge A. Gómez-García, Alejandro Guerrero-López, Elisa Luque-Buzo, Julián D. Arias-Londoño, Francisco J. Grandas-Pérez, Juan I. Godino-Llorente
Abstract: The screening of Parkinson's Disease (PD) through speech is hindered by a notable lack of publicly available datasets in different languages. This fact limits the reproducibility and further exploration of existing research. To address this gap, this manuscript presents the NeuroVoz corpus consisting of 112 native Castilian-Spanish speakers, including 58 healthy controls and 54 individuals with PD, all recorded in ON state. The corpus showcases a diverse array of speech tasks: sustained vowels; diadochokinetic tests; 16 Listen-and-Repeat utterances; and spontaneous monologues. The dataset is also complemented with subjective assessments of voice quality performed by an expert according to the GRBAS scale (Grade/Roughness/Breathiness/Asthenia/Strain), as well as annotations with a thorough examination of phonation quality, intensity, speed, resonance, intelligibility, and prosody. The corpus offers a substantial resource for the exploration of the impact of PD on speech. This data set has already supported several studies, achieving a benchmark accuracy of 89% for the screening of PD. Despite these advances, the broader challenge of conducting a language-agnostic, cross-corpora analysis of Parkinsonian speech patterns remains open.

Paper number 73:
Title: Distributed Stochastic Optimization of a Neural Representation Network for Time-Space Tomography Reconstruction
Authors: K. Aditya Mohan, Massimiliano Ferrucci, Chuck Divin, Garrett A. Stevenson, Hyojin Kim
Abstract: 4D time-space reconstruction of dynamic events or deforming objects using X-ray computed tomography (CT) is an important inverse problem in non-destructive evaluation. Conventional back-projection based reconstruction methods assume that the object remains static for the duration of several tens or hundreds of X-ray projection measurement images (reconstruction of consecutive limited-angle CT scans). However, this is an unrealistic assumption for many in-situ experiments that causes spurious artifacts and inaccurate morphological reconstructions of the object. To solve this problem, we propose to perform a 4D time-space reconstruction using a distributed implicit neural representation (DINR) network that is trained using a novel distributed stochastic training algorithm. Our DINR network learns to reconstruct the object at its output by iterative optimization of its network parameters such that the measured projection images best match the output of the CT forward measurement model. We use a forward measurement model that is a function of the DINR outputs at a sparsely sampled set of continuous valued 4D object coordinates. Unlike previous neural representation architectures that forward and back propagate through dense voxel grids that sample the object's entire time-space coordinates, we only propagate through the DINR at a small subset of object coordinates in each iteration resulting in an order-of-magnitude reduction in memory and compute for training. DINR leverages distributed computation across several compute nodes and GPUs to produce high-fidelity 4D time-space reconstructions. We use both simulated parallel-beam and experimental cone-beam X-ray CT datasets to demonstrate the superior performance of our approach.

Paper number 74:
Title: TotalSegmentator MRI: Robust Sequence-independent Segmentation of Multiple Anatomic Structures in MRI
Authors: Tugba Akinci D'Antonoli, Lucas K. Berger, Ashraya K. Indrakanti, Nathan Vishwanathan, Jakob Weiß, Matthias Jung, Zeynep Berkarda, Alexander Rau, Marco Reisert, Thomas Küstner, Alexandra Walter, Elmar M. Merkle, Daniel Boll, Hanns-Christian Breit, Andrew Phillip Nicoli, Martin Segeroth, Joshy Cyriac, Shan Yang, Jakob Wasserthal
Abstract: Since the introduction of TotalSegmentator CT, there is demand for a similar robust automated MRI segmentation tool that can be applied across all MRI sequences and anatomic structures. In this retrospective study, a nnU-Net model (TotalSegmentator) was trained on MRI and CT examinations to segment 80 anatomic structures relevant for use cases such as organ volumetry, disease characterization, surgical planning and opportunistic screening. Examinations were randomly sampled from routine clinical studies to represent real-world examples. Dice scores were calculated between the predicted segmentations and expert radiologist reference standard segmentations to evaluate model performance on an internal test set, two external test sets and against two publicly available models, and TotalSegmentator CT. The model was applied to an internal dataset containing abdominal MRIs to investigate age-dependent volume changes. A total of 1143 examinations (616 MRIs, 527 CTs) (median age 61 years, IQR 50-72) were split into training (n=1088, CT and MRI) and an internal test set (n=55; only MRI), two external test sets (AMOS, n=20; CHAOS, n=20; only MRI), and an internal aging-study dataset of 8672 abdominal MRIs (median age 59 years, IQR 45-70) were included. The model showed a Dice Score of 0.839 on the internal test set and outperformed two other models (Dice Score, 0.862 versus 0.759; and 0.838 versus 0.560; p<.001 for both). The proposed open-source, easy-to-use model allows for automatic, robust segmentation of 80 structures, extending the capabilities of TotalSegmentator to MRIs of any sequence. The ready-to-use online tool is available at this https URL, the model at this https URL, and the dataset at this https URL.

Paper number 75:
Title: Robust Pareto Transistor Sizing of GaN HEMTs for Millimeter-Wave Applications
Authors: Rafael Perez Martinez, Stephen Boyd, Srabanti Chowdhury
Abstract: This paper introduces a robust Pareto design approach for transistor sizing of Gallium Nitride (GaN) High Electron Mobility Transistors (HEMTs), particularly for power amplifier (PA) and low-noise amplifier (LNA) designs in 5G applications. We consider five key design variables and two settings (PAs and LNAs) where we have multiple objectives. We assess designs based on three critical objectives, evaluating each by its worst-case performance across a range of Gate-Source Voltages ($V_{\text{GS}}$). We conduct simulations across a range of $V_{\text{GS}}$ values to ensure a thorough and robust analysis. For PAs, the optimization goals are to maximize the worst-case modulated average output power ($P_{\text{out,avg}}$) and power-added efficiency ($\text{PAE}_{\text{avg}}$) while minimizing the worst-case average junction temperature ($T_{\text{j,avg}}$) under a modulated 64-QAM signal stimulus. In contrast, for LNAs, the focus is on maximizing the worst-case maximum oscillation frequency ($f_{\text{max}}$) and Gain, and minimizing the worst-case minimum noise figure ($\text{NF}_{\text{min}}$). We utilize a derivative-free optimization method to effectively identify robust Pareto optimal device designs. This approach enhances our comprehension of the trade-off space, facilitating more informed decision-making. Furthermore, this method is general across different applications. Although it does not guarantee a globally optimal design, we demonstrate its effectiveness in GaN transistor sizing. The primary advantage of this method is that it enables the attainment of near-optimal or even optimal designs with just a fraction of the simulations required for an exhaustive full-grid search.

Paper number 76:
Title: Position and Time Determination without Prior State Knowledge via Onboard Optical Observations of Delta Scuti Variable Stars
Authors: Linyi Hou, Ishaan Bansal, Clark Davis, Siegfried Eggl
Abstract: We present a navigation concept for solving the lost in space and time problem using optical observations of $\delta$ Scuti variable stars. Only a small number of techniques exist that allow a spacecraft to recover from being lost in both space and time, which can be caused by a failure of the onboard clock and navigation systems. Optical observations of $\delta$ Scuti stars, which can be collected onboard from star trackers or navigation cameras, may enable autonomous position and time determination without requiring additional equipment or external communication. Our results indicate that less than one day of observation by the OSIRIS-APEX PolyCam may enable position and time determination accuracy within 0.03 au (3$\sigma$) and 3 seconds (3$\sigma$).

Paper number 77:
Title: Analysis of a platooned car-following model with different inter-platoon communication levels
Authors: Shouwei Hui, Michael Zhang
Abstract: Despite growing interest in vehicle platooning research, the effect of communication capability between platoons is not investigated to a depth of depth. In this paper, we extend a single-platoon car-following (CF) model to multi-platoon CF models for connected and autonomous vehicles (CAVs) with different inter-platoon communication capabilities. Specifically, we consider forward and backward connection availabilities with delays between platoons. Using linear stability analysis, we discovered that for identical platoons, stability increases with platoon size and connection availabilities and decreases exponentially with large delay. With maximum acceleration and emergency braking constraints integrated into the models, we performed simulations for various cases of CAV platoons and mixed autonomy with human-driven vehicles (HDVs). The simulation results for CAV platoons are consistent with theoretical analysis. The mixed autonomy experiments demonstrate that in the ring road scenario, CAV platoons can stabilize HDVs without adaptions, and the effect of distribution is marginal. Overall, this paper provides valuable insights for designing vehicle-to-vehicle (V2V) communications and managing mixed traffic scenarios.

Paper number 78:
Title: Advancing Hybrid Quantum Neural Network for Alternative Current Optimal Power Flow
Authors: Ze Hu, Ziqing Zhu, Linghua Zh, Xiang Wei, Siqi Bu, Ka Wing Chan
Abstract: Alternative Current Optimal Power Flow (AC-OPF) is essential for efficient planning and real-time operation in power systems but is NP-hard and non-convex, leading to significant computational challenges. Neural networks (NNs) offer computational speedups in solving OPF but face issues like dependency on large datasets, scalability limitations, and inability to enforce physical constraints, compromising solution reliability. To overcome these limitations, this paper proposes hybrid Quantum Neural Networks (QNNs) that integrate quantum computing principles into neural network architectures. Leveraging quantum mechanics properties such as superposition and entanglement, QNNs can capture complex input-output relationships more effectively and learn from small or noisy this http URL further improve the performance of QNNs and investigate the interplay between classical and quantum components in hybrid architectures, we incorporate advanced techniques, including residual learning and physics-informed machine learning, into the hybrid QNN designs. These enhancements aim to boost convergence efficiency, lower errors, superior generalization, and robustness to quantum noise. Simulation results demonstrate that these enhanced hybrid QNNs outperform typical hybrid QNNs in solving OPF problems. This work provides valuable insights into the design and optimization of hybrid QNNs, highlighting the potential of quantum computation for broader applications in power systems.

Paper number 79:
Title: Disturbance Observer-Parameterized Control Barrier Function with Adaptive Safety Bounds
Authors: Ziqi Yang, Lihua Xie
Abstract: This letter presents a nonlinear disturbance observer-parameterized control barrier function (DOp-CBF) designed for a robust safety control system under external disturbances. This framework emphasizes that the safety bounds are relevant to the disturbances, acknowledging the critical impact of disturbances on system safety. This work incorporates a disturbance observer (DO) as an adaptive mechanism of the safety bounds design. Instead of considering the worst-case scenario, the safety bounds are dynamically adjusted using DO. The forward invariance of the proposed method regardless of the observer error is ensured, and the corresponding optimal control formulation is presented. The performance of the proposed method is demonstrated through simulations of a cruise control problem under varying road grades. The influence of road grade on the safe distance between vehicles is analyzed and managed using a DO. The results demonstrate the advantages of this approach in maintaining safety and improving system performance under disturbances.

Paper number 80:
Title: Synesthesia of Machine (SoM)-Driven Analog Precoder Optimization for Enhanced ISAC Performance in Sub-THz Systems
Authors: Zonghui Yang, Shijian Gao, Xiang Cheng
Abstract: The potential benefits of integrated sensing and communication (ISAC) are anticipated to play a significant role in future sub-terahertz (sub-THz) mobile information networks. However, the beam squint effect is pronounced in sub-THz systems, expanding coverage areas while severely degrading the communication performance. Existing analog precoder designs struggle to balance both functionalities in the presence of beam squint, limiting the performance gain achievable through ISAC. To address this challenge, we propose two squint-aware analog precoding schemes for sub-THz systems that proactively regulate the correlation between communication and sensing channels, leveraging the inherent degrees of freedom in the hardware architecture to enhance ISAC performance. We first introduce a squint-aware optimization-based analog precoder design approach (SA-Opt). Inspired by the synesthesia of machine (SoM), we further develop an unsupervised learning-assisted complex-valued squint-aware network (CSP-Net) to reduce complexity based on both communication and sensing channel data, tailoring its architecture to the specific data and task characteristics. The effectiveness of the proposed schemes is demonstrated through simulations.

Paper number 81:
Title: Secure Beamforming for Continuous Aperture Array (CAPA) Systems
Authors: Mingjun Sun, Chongjun Ouyang, Zhaolin Wang, Shaochuan Wu, Yuanwei Liu
Abstract: Continuous aperture array (CAPA) is considered a promising technology for 6G networks, offering the potential to fully exploit spatial DoFs and achieve the theoretical limits of channel capacity. This paper investigates the performance gain of a CAPA-based downlink secure transmission system, where multiple legitimate user terminals (LUTs) coexist with multiple eavesdroppers (Eves). The system's secrecy performance is evaluated using a weighted secrecy sum-rate (WSSR) under a power constraint. We then propose two solutions for the secure current pattern design. The first solution is a block coordinate descent (BCD) optimization method based on fractional programming, which introduces a continuous-function inversion theory corresponding to matrix inversion in the discrete domain. This approach derives a closed-form expression for the optimal source current pattern. Based on this, it can be found that the optimal current pattern is essentially a linear combination of the channel spatial responses, thus eliminating the need for complex integration operations during the algorithm's optimization process. The second solution is a heuristic algorithm based on Zero-Forcing (ZF), which constructs a zero-leakage current pattern using the channel correlation matrix. It further employs a water-filling approach to design an optimal power allocation scheme that maximizes the WSSR. In high SNR regions, this solution gradually approaches the first solution, ensuring zero leakage while offering lower computational complexity. Simulation results demonstrate that: 1) CAPA-based systems achieve better WSSR compared to discrete multiple-input multiple-output systems. 2) The proposed methods, whether optimization-based or heuristic, provide significant performance improvements over existing state-of-the-art Fourier-based discretization methods, while considerably reducing computational complexity.

Paper number 82:
Title: Vision Foundation Models for Computed Tomography
Authors: Suraj Pai, Ibrahim Hadzic, Dennis Bontempi, Keno Bressem, Benjamin H. Kann, Andriy Fedorov, Raymond H. Mak, Hugo J. W. L. Aerts
Abstract: Foundation models (FMs) have shown transformative potential in radiology by performing diverse, complex tasks across imaging modalities. Here, we developed CT-FM, a large-scale 3D image-based pre-trained model designed explicitly for various radiological tasks. CT-FM was pre-trained using 148,000 computed tomography (CT) scans from the Imaging Data Commons through label-agnostic contrastive learning. We evaluated CT-FM across four categories of tasks, namely, whole-body and tumor segmentation, head CT triage, medical image retrieval, and semantic understanding, showing superior performance against state-of-the-art models. Beyond quantitative success, CT-FM demonstrated the ability to cluster regions anatomically and identify similar anatomical and structural concepts across scans. Furthermore, it remained robust across test-retest settings and indicated reasonable salient regions attached to its embeddings. This study demonstrates the value of large-scale medical imaging foundation models and by open-sourcing the model weights, code, and data, aims to support more adaptable, reliable, and interpretable AI solutions in radiology.

Paper number 83:
Title: 3D ReX: Causal Explanations in 3D Neuroimaging Classification
Authors: Melane Navaratnarajah, Sophie A. Martin, David A. Kelly, Nathan Blake, Hana Chockler
Abstract: Explainability remains a significant problem for AI models in medical imaging, making it challenging for clinicians to trust AI-driven predictions. We introduce 3D ReX, the first causality-based post-hoc explainability tool for 3D models. 3D ReX uses the theory of actual causality to generate responsibility maps which highlight the regions most crucial to the model's decision. We test 3D ReX on a stroke detection model, providing insight into the spatial distribution of features relevant to stroke.

Paper number 84:
Title: PixleepFlow: A Pixel-Based Lifelog Framework for Predicting Sleep Quality and Stress Level
Authors: Younghoon Na, Seunghun Oh, Seongji Ko, Hyunkyung Lee
Abstract: The analysis of lifelogs can yield valuable insights into an individual's daily life, particularly with regard to their health and well-being. The accurate assessment of quality of life is necessitated by the use of diverse sensors and precise synchronization. To rectify this issue, this study proposes the image-based sleep quality and stress level estimation flow (PixleepFlow). PixleepFlow employs a conversion methodology into composite image data to examine sleep patterns and their impact on overall health. Experiments were conducted using lifelog datasets to ascertain the optimal combination of data formats. In addition, we identified which sensor information has the greatest influence on the quality of life through Explainable Artificial Intelligence(XAI). As a result, PixleepFlow produced more significant results than various data formats. This study was part of a written-based competition, and the additional findings from the lifelog dataset are detailed in Section Section IV. More information about PixleepFlow can be found at this https URL.

Paper number 85:
Title: MC2SleepNet: Multi-modal Cross-masking with Contrastive Learning for Sleep Stage Classification
Authors: Younghoon Na
Abstract: Sleep profoundly affects our health, and sleep deficiency or disorders can cause physical and mental problems. % Despite significant findings from previous studies, challenges persist in optimizing deep learning models, especially in multi-modal learning for high-accuracy sleep stage classification. Our research introduces MC2SleepNet (Multi-modal Cross-masking with Contrastive learning for Sleep stage classification Network). It aims to facilitate the effective collaboration between Convolutional Neural Networks (CNNs) and Transformer architectures for multi-modal training with the help of contrastive learning and cross-masking. % Raw single channel EEG signals and corresponding spectrogram data provide differently characterized modalities for multi-modal learning. Our MC2SleepNet has achieved state-of-the-art performance with an accuracy of both 84.6% on the SleepEDF-78 and 88.6% accuracy on the Sleep Heart Health Study (SHHS). These results demonstrate the effective generalization of our proposed network across both small and large datasets.

Paper number 86:
Title: ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis
Authors: Xu Wang, Jiaju Kang, Puyu Han
Abstract: We present ECG-Expert-QA, a comprehensive multimodal dataset designed for evaluating diagnostic capabilities in ECG interpretation, integrating real clinical data with systematically generated synthetic cases. The dataset encompasses six fundamental diagnostic tasks, comprising 47,211 meticulously curated question-answer pairs that span a spectrum of clinical scenarios, from basic rhythm analysis to complex case interpretation. By simulating challenging clinical cases through a rigorous medical knowledge-guided process, ECG-Expert-QA not only enhances the availability of annotated diagnostic data but also significantly increases the complexity and diversity of clinical presentations, including rare cardiac conditions and temporal progression patterns. This design enables comprehensive evaluation of medical language models across multiple dimensions, including diagnostic accuracy, clinical reasoning, and knowledge integration. To facilitate global research collaboration, ECG-Expert-QA is available in both Chinese and English versions, with rigorous quality control ensuring linguistic and clinical consistency. The dataset's challenging diagnostic tasks, which include interpretation of complex arrhythmias, identification of subtle ischemic changes, and integration of clinical context, establish it as an effective benchmark for advancing AI-assisted ECG interpretation and pushing the boundaries of current diagnostic models. Our dataset is open-source and available at this https URL

Paper number 87:
Title: Underwater Motions Analysis and Control of a Coupling-Tiltable Unmanned Aerial-Aquatic Vehicle
Authors: Dongyue Huang, Minghao Dou, Xuchen Liu, Tao Sun, Jianguo Zhang, Ning Ding, Xinlei Chen, Ben M. Chen
Abstract: Coupling-Tiltable Unmanned Aerial-Aquatic Vehicles (UAAVs) have gained increasing importance, yet lack comprehensive analysis and suitable controllers. This paper analyzes the underwater motion characteristics of a self-designed UAAV, Mirs-Alioth, and designs a controller for it. The effectiveness of the controller is validated through experiments. The singularities of Mirs-Alioth are derived as Singular Thrust Tilt Angle (STTA), which serve as an essential tool for an analysis of its underwater motion characteristics. The analysis reveals several key factors for designing the controller. These include the need for logic switching, using a Nussbaum function to compensate control direction uncertainty in the auxiliary channel, and employing an auxiliary controller to mitigate coupling effects. Based on these key points, a control scheme is designed. It consists of a controller that regulates the thrust tilt angle to the singular value, an auxiliary controller incorporating a Saturated Nussbaum function, and a logic switch. Eventually, two sets of experiments are conducted to validate the effectiveness of the controller and demonstrate the necessity of the Nussbaum function.

Paper number 88:
Title: Breaking Down Power Barriers in On-Device Streaming ASR: Insights and Solutions
Authors: Yang Li, Yuan Shangguan, Yuhao Wang, Liangzhen Lai, Ernie Chang, Changsheng Zhao, Yangyang Shi, Vikas Chandra
Abstract: Power consumption plays a crucial role in on-device streaming speech recognition, significantly influencing the user experience. This study explores how the configuration of weight parameters in speech recognition models affects their overall energy efficiency. We found that the influence of these parameters on power consumption varies depending on factors such as invocation frequency and memory allocation. Leveraging these insights, we propose design principles that enhance on-device speech recognition models by reducing power consumption with minimal impact on accuracy. Our approach, which adjusts model components based on their specific energy sensitivities, achieves up to 47% lower energy usage while preserving comparable model accuracy and improving real-time performance compared to leading methods.

Paper number 89:
Title: Efficient Sensors Selection for Traffic Flow Monitoring: An Overview of Model-Based Techniques leveraging Network Observability
Authors: Marco Fabris, Riccardo Ceccato, Andrea Zanella
Abstract: The emergence of 6G-enabled Internet of Vehicles (IoV) promises to revolutionize mobility and connectivity, integrating vehicles into a mobile Internet of Things (IoT)-oriented wireless sensor network (WSN). Meanwhile, 5G technologies and mobile edge computing further support this vision by facilitating real-time connectivity and empowering massive access to the Internet. Within this context, IoT-oriented WSNs play a crucial role in intelligent transportation systems, offering affordable alternatives for traffic monitoring and management. Efficient sensor selection thus represents a critical concern while deploying WSNs on urban networks. In this paper, we provide an overview of such a notably hard problem. The contribution is twofold: (i) surveying state-of-the-art model-based techniques for efficient sensor selection in traffic flow monitoring, emphasizing challenges of sensor placement, and (ii) advocating for {the development of} data-driven methodologies to enhance sensor deployment efficacy and traffic modeling accuracy. Further considerations underscore the importance of data-driven approaches for adaptive transportation systems aligned with the IoV paradigm.

Paper number 90:
Title: Graph Neural Network based Active and Passive Beamforming for Distributed STAR-RIS-Assisted Multi-User MISO Systems
Authors: Ha An Le, Trinh Van Chien, Wan Choi
Abstract: This paper investigates a joint active and passive beamforming design for distributed simultaneous transmitting and reflecting (STAR) reconfigurable intelligent surface (RIS) assisted multi-user (MU)- mutiple input single output (MISO) systems, where the energy splitting (ES) mode is considered for the STAR-RIS. We aim to design the active beamforming vectors at the base station (BS) and the passive beamforming at the STAR-RIS to maximize the user sum rate under transmitting power constraints. The formulated problem is non-convex and nontrivial to obtain the global optimum due to the coupling between active beamforming vectors and STAR-RIS phase shifts. To efficiently solve the problem, we propose a novel graph neural network (GNN)-based framework. Specifically, we first model the interactions among users and network entities are using a heterogeneous graph representation. A heterogeneous graph neural network (HGNN) implementation is then introduced to directly optimizes beamforming vectors and STAR-RIS coefficients with the system objective. Numerical results show that the proposed approach yields efficient performance compared to the previous benchmarks. Furthermore, the proposed GNN is scalable with various system configurations.

Paper number 91:
Title: Robots Have Been Seen and Not Heard: Effects of Consequential Sounds on Human-Perception of Robots
Authors: Aimee Allen (1), Tom Drummond (2), Dana Kulić (1) ((1) Monash University - Australia, (2) University of Melbourne - Australia)
Abstract: Robots make compulsory machine sounds, known as `consequential sounds', as they move and operate. As robots become more prevalent in workplaces, homes and public spaces, understanding how sounds produced by robots affect human-perceptions of these robots is becoming increasingly important to creating positive human robot interactions (HRI). This paper presents the results from 182 participants (858 trials) investigating how human-perception of robots is changed by consequential sounds. In a between-participants study, participants in the sound condition were shown 5 videos of different robots and asked their opinions on the robots and the sounds they made. This was compared to participants in the control condition who viewed silent videos. Consequential sounds correlated with significantly more negative perceptions of robots, including increased negative `associated affects', feeling more distracted, and being less willing to colocate in a shared environment with robots.

Paper number 92:
Title: Optimizing Multi-Stuttered Speech Classification: Leveraging Whisper's Encoder for Efficient Parameter Reduction in Automated Assessment
Authors: Huma Ameer, Seemab Latif, Mehwish Fatima
Abstract: The automated classification of stuttered speech has significant implications for timely assessments providing assistance to speech language pathologists. Despite notable advancements in the field, the cases in which multiple disfluencies occur in speech require attention. We have taken a progressive approach to fill this gap by classifying multi-stuttered speech more efficiently. The problem has been addressed by firstly curating a dataset of multi-stuttered disfluencies from open source dataset SEP-28k audio clips. Secondly, employing Whisper, a state-of-the-art speech recognition model has been leveraged by using its encoder and taking the problem as multi label classification. Thirdly, using a 6 encoder layer Whisper and experimenting with various layer freezing strategies, a computationally efficient configuration of the model was identified. The proposed configuration achieved micro, macro, and weighted F1-scores of 0.88, 0.85, and 0.87, correspondingly on an external test dataset i.e. Fluency-Bank. In addition, through layer freezing strategies, we were able to achieve the aforementioned results by fine-tuning a single encoder layer, consequently, reducing the model's trainable parameters from 20.27 million to 3.29 million. This research study unveils the contribution of the last encoder layer in the identification of disfluencies in stuttered speech. Consequently, it has led to a computationally efficient approach, 83.7% less parameters to train, making the proposed approach more adaptable for various dialects and languages.

Paper number 93:
Title: A Digital Twin Framework for Physical-Virtual Integration in V2X-Enabled Connected Vehicle Corridors
Authors: Keshu Wu, Pei Li, Yang Cheng, Steven T. Parker, Bin Ran, David A. Noyce, Xinyue Ye
Abstract: Transportation Cyber-Physical Systems (T-CPS) enhance safety and mobility by integrating cyber and physical transportation systems. A key component of T-CPS is the Digital Twin (DT), a virtual representation that enables simulation, analysis, and optimization through real-time data exchange and communication. Although existing studies have explored DTs for vehicles, communications, pedestrians, and traffic, real-world validations and implementations of DTs that encompass infrastructure, vehicles, signals, communications, and more remain limited due to several challenges. These include accessing real-world connected infrastructure, integrating heterogeneous, multi-sourced data, ensuring real-time data processing, and synchronizing the digital and physical systems. To address these challenges, this study develops a traffic DT based on a real-world connected vehicle corridor. Leveraging the Cellular Vehicle-to-Everything (C-V2X) infrastructure in the corridor, along with communication, computing, and simulation technologies, the proposed DT accurately replicates physical vehicle behaviors, signal timing, communications, and traffic patterns within the virtual environment. Building upon the previous data pipeline, the digital system ensures robust synchronization with the physical environment. Moreover, the DT's scalable and redundant architecture enhances data integrity, making it capable of supporting future large-scale C-V2X deployments. Furthermore, its ability to provide feedback to the physical system is demonstrated through applications such as signal timing adjustments, vehicle advisory messages, and incident notifications. The proposed DT is a vital tool in T-CPS, enabling real-time traffic monitoring, prediction, and optimization to enhance the reliability and safety of transportation systems.

Paper number 94:
Title: SONIQUE: Video Background Music Generation Using Unpaired Audio-Visual Data
Authors: Liqian Zhang, Magdalena Fuentes
Abstract: We present SONIQUE, a model for generating background music tailored to video content. Unlike traditional video-to-music generation approaches, which rely heavily on paired audio-visual datasets, SONIQUE leverages unpaired data, combining royalty-free music and independent video sources. By utilizing large language models (LLMs) for video understanding and converting visual descriptions into musical tags, alongside a U-Net-based conditional diffusion model, SONIQUE enables customizable music generation. Users can control specific aspects of the music, such as instruments, genres, tempo, and melodies, ensuring the generated output fits their creative vision. SONIQUE is open-source, with a demo available online.

Paper number 95:
Title: Movie Gen: A Cast of Media Foundation Models
Authors: Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu Ma, Ishan Misra, Ji Hou, Jialiang Wang, Kiran Jagadeesh, Kunpeng Li, Luxin Zhang, Mannat Singh, Mary Williamson, Matt Le, Matthew Yu, Mitesh Kumar Singh, Peizhao Zhang, Peter Vajda, Quentin Duval, Rohit Girdhar, Roshan Sumbaly, Sai Saketh Rambhatla, Sam Tsai, Samaneh Azadi, Samyak Datta, Sanyuan Chen, Sean Bell, Sharadh Ramaswamy, Shelly Sheynin, Siddharth Bhattacharya, Simran Motwani, Tao Xu, Tianhe Li, Tingbo Hou, Wei-Ning Hsu, Xi Yin, Xiaoliang Dai, Yaniv Taigman, Yaqiao Luo, Yen-Cheng Liu, Yi-Chiao Wu, Yue Zhao, Yuval Kirstain, Zecheng He, Zijian He, Albert Pumarola, Ali Thabet, Artsiom Sanakoyeu, Arun Mallya, Baishan Guo, Boris Araya, Breena Kerr, Carleigh Wood, Ce Liu, Cen Peng, Dimitry Vengertsev, Edgar Schonfeld, Elliot Blanchard, Felix Juefei-Xu, Fraylie Nord, Jeff Liang, John Hoffman, Jonas Kohler, Kaolin Fire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Georgopoulos, Rashel Moritz, Sara K. Sampson, Shikai Li, Simone Parmeggiani, Steve Fine, Tara Fowler, Vladan Petrovic, Yuming Du
Abstract: We present Movie Gen, a cast of foundation models that generates high-quality, 1080p HD videos with different aspect ratios and synchronized audio. We also show additional capabilities such as precise instruction-based video editing and generation of personalized videos based on a user's image. Our models set a new state-of-the-art on multiple tasks: text-to-video synthesis, video personalization, video editing, video-to-audio generation, and text-to-audio generation. Our largest video generation model is a 30B parameter transformer trained with a maximum context length of 73K video tokens, corresponding to a generated video of 16 seconds at 16 frames-per-second. We show multiple technical innovations and simplifications on the architecture, latent spaces, training objectives and recipes, data curation, evaluation protocols, parallelization techniques, and inference optimizations that allow us to reap the benefits of scaling pre-training data, model size, and training compute for training large scale media generation models. We hope this paper helps the research community to accelerate progress and innovation in media generation models. All videos from this paper are available at this https URL.

Paper number 96:
Title: Modeling and Optimization for Rotatable Antenna Enabled Wireless Communication
Authors: Qingjie Wu, Beixiong Zheng, Tiantian Ma, Rui Zhang
Abstract: Fluid antenna system (FAS)/movable antenna (MA) has emerged as a promising technology to fully exploit the spatial degrees of freedom (DoFs). In this paper, we propose a new rotatable antenna (RA) model, as a simplified implementation of six-dimensional movable antenna (6DMA), to improve the performance of wireless communication systems. Different from conventional fixed-position antenna (FPA), the proposed RA system can independently and flexibly change the three-dimensional (3D) orientation/boresight of each antenna by adjusting its deflection angles to achieve desired channel realizations. Specifically, we study an RA-enabled uplink communication system, where the receive beamforming and the deflection angles of all RAs are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal deflection angles are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the base station (BS). In the general multi-user and multi-path setup, we propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the deflection angles in an iterative manner. Simulation results are provided to demonstrate that the proposed RA-enabled system can significantly outperform other benchmark schemes.

Paper number 97:
Title: Multiclass Post-Earthquake Building Assessment Integrating Optical and SAR Satellite Imagery, Ground Motion, and Soil Data with Transformers
Authors: Deepank Singh, Vedhus Hoskere, Pietro Milillo
Abstract: Timely and accurate assessments of building damage are crucial for effective response and recovery in the aftermath of earthquakes. Conventional preliminary damage assessments (PDA) often rely on manual door-to-door inspections, which are not only time-consuming but also pose significant safety risks. To safely expedite the PDA process, researchers have studied the applicability of satellite imagery processed with heuristic and machine learning approaches. These approaches output binary or, more recently, multiclass damage states at the scale of a block or a single building. However, the current performance of such approaches limits practical applicability. To address this limitation, we introduce a metadata-enriched, transformer based framework that combines high-resolution post-earthquake satellite imagery with building-specific metadata relevant to the seismic performance of the structure. Our model achieves state-of-the-art performance in multiclass post-earthquake damage identification for buildings from the Turkey-Syria earthquake on February 6, 2023. Specifically, we demonstrate that incorporating metadata, such as seismic intensity indicators, soil properties, and SAR damage proxy maps not only enhances the model's accuracy and ability to distinguish between damage classes, but also improves its generalizability across various regions. Furthermore, we conducted a detailed, class-wise analysis of feature importance to understand the model's decision-making across different levels of building damage. This analysis reveals how individual metadata features uniquely contribute to predictions for each damage class. By leveraging both satellite imagery and metadata, our proposed framework enables faster and more accurate damage assessments for precise, multiclass, building-level evaluations that can improve disaster response and accelerate recovery efforts for affected communities.

Paper number 98:
Title: Harvesting energy from turbulent winds with Reinforcement Learning
Authors: Lorenzo Basile, Maria Grazia Berni, Antonio Celani
Abstract: Airborne Wind Energy (AWE) is an emerging technology designed to harness the power of high-altitude winds, offering a solution to several limitations of conventional wind turbines. AWE is based on flying devices (usually gliders or kites) that, tethered to a ground station and driven by the wind, convert its mechanical energy into electrical energy by means of a generator. Such systems are usually controlled by manoeuvering the kite so as to follow a predefined path prescribed by optimal control techniques, such as model-predictive control. These methods are strongly dependent on the specific model at use and difficult to generalize, especially in unpredictable conditions such as the turbulent atmospheric boundary layer. Our aim is to explore the possibility of replacing these techniques with an approach based on Reinforcement Learning (RL). Unlike traditional methods, RL does not require a predefined model, making it robust to variability and uncertainty. Our experimental results in complex simulated environments demonstrate that AWE agents trained with RL can effectively extract energy from turbulent flows, relying on minimal local information about the kite orientation and speed relative to the wind.

Paper number 99:
Title: Rotatable Antenna Enabled Wireless Communication: Modeling and Optimization
Authors: Beixiong Zheng, Qingjie Wu, Rui Zhang
Abstract: Fluid antenna system (FAS) and movable antenna (MA) have recently emerged as promising technologies to exploit new spatial degrees of freedom (DoFs), which have attracted growing attention in wireless communication. In this paper, we propose a new rotatable antenna (RA) model to improve the performance of wireless communication systems. Different from conventional fixed antennas, the proposed RA system can flexibly alter the three-dimensional (3D) boresight direction of each antenna independently by adjusting its deflection angles to achieve a desired array directional gain pattern. Specifically, we investigate an RA-enabled uplink communication system, where the receive beamforming and the deflection angles of all RAs at the base station (BS) are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal deflection angles of RAs are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the BS. Moreover, we analyze the asymptotic performance with an infinite number of antennas based on this solution, which theoretically proves that the RA system can achieve a higher array gain as compared to the fixed-antenna system. In the general multi-user and multi-path channel setup, we first propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the deflection angles of RAs in an iterative manner. Then, a two-stage algorithm that solves the formulated problem without the need for iteration is further proposed to reduce computational complexity. Simulation results are provided to validate our analytical results and demonstrate that the proposed RA system can significantly outperform other benchmark schemes.

Paper number 100:
Title: Orbit-Aware Split Learning: Optimizing LEO Satellite Networks for Distributed Online Learning
Authors: Marc Martinez-Gost, Ana Pérez-Neira
Abstract: This paper proposes a novel split learning architecture designed to exploit the cyclical movement of Low Earth Orbit (LEO) satellites in non-terrestrial networks (NTNs). Although existing research focuses on offloading tasks to the NTN infrastructure, these approaches overlook the dynamic movement patterns of LEO satellites that can be used to efficiently distribute the learning task. In this work, we analyze how LEO satellites, from the perspective of ground terminals, can participate in a time-window-based model training. By splitting the model between a LEO and a ground terminal, the computational burden on the satellite segment is reduced, while each LEO satellite offloads the partially trained model to the next satellite in the constellation. This cyclical training process allows larger and more energy-intensive models to be deployed and trained across multiple LEO satellites, despite their limited energy resources. We formulate an optimization problem that manages radio and processing resources, ensuring the entire data is processed during each satellite pass while minimizing the energy consumption. Our results demonstrate that this approach offers a more scalable and energy-efficient way to train complex models, enhancing the capabilities of LEO satellite constellations in the context of Artificial Intelligence-driven applications.

Paper number 101:
Title: High-Fidelity Simultaneous Speech-To-Speech Translation
Authors: Tom Labiausse, Laurent Mazaré, Edouard Grave, Patrick Pérez, Alexandre Défossez, Neil Zeghidour
Abstract: We introduce Hibiki, a decoder-only model for simultaneous speech translation. Hibiki leverages a multistream language model to synchronously process source and target speech, and jointly produces text and audio tokens to perform speech-to-text and speech-to-speech translation. We furthermore address the fundamental challenge of simultaneous interpretation, which unlike its consecutive counterpart, where one waits for the end of the source utterance to start translating, adapts its flow to accumulate just enough context to produce a correct translation in real-time, chunk by chunk. To do so, we introduce a weakly-supervised method that leverages the perplexity of an off-the-shelf text translation system to identify optimal delays on a per-word basis and create aligned synthetic data. After supervised training, Hibiki performs adaptive, simultaneous speech translation with vanilla temperature sampling. On a French-English simultaneous speech translation task, Hibiki demonstrates state-of-the-art performance in translation quality, speaker fidelity and naturalness. Moreover, the simplicity of its inference process makes it compatible with batched translation and even real-time on-device deployment. We provide examples as well as models and inference code.

Paper number 102:
Title: TALKPLAY: Multimodal Music Recommendation with Large Language Models
Authors: Seungheon Doh, Keunwoo Choi, Juhan Nam
Abstract: We present TalkPlay, a multimodal music recommendation system that reformulates the recommendation task as large language model token generation. TalkPlay represents music through an expanded token vocabulary that encodes multiple modalities - audio, lyrics, metadata, semantic tags, and playlist co-occurrence. Using these rich representations, the model learns to generate recommendations through next-token prediction on music recommendation conversations, that requires learning the associations natural language query and response, as well as music items. In other words, the formulation transforms music recommendation into a natural language understanding task, where the model's ability to predict conversation tokens directly optimizes query-item relevance. Our approach eliminates traditional recommendation-dialogue pipeline complexity, enabling end-to-end learning of query-aware music recommendations. In the experiment, TalkPlay is successfully trained and outperforms baseline methods in various aspects, demonstrating strong context understanding as a conversational music recommender.

Paper number 103:
Title: No Minima, No Collisions: Combining Modulation and Control Barrier Function Strategies for Feasible Dynamical Collision Avoidance
Authors: Yifan Xue, Nadia Figueroa
Abstract: As prominent real-time safety-critical reactive control techniques, Control Barrier Function Quadratic Programs (CBF-QPs) work for control affine systems in general but result in local minima in the generated trajectories and consequently cannot ensure convergence to the goals. Contrarily, Modulation of Dynamical Systems (Mod-DSs), including normal, reference, and on-manifold Mod-DS, achieve obstacle avoidance with few and even no local minima but have trouble optimally minimizing the difference between the constrained and the unconstrained controller outputs, and its applications are limited to fully-actuated systems. We dive into the theoretical foundations of CBF-QP and Mod-DS, proving that despite their distinct origins, normal Mod-DS is a special case of CBF-QP, and reference Mod-DS's solutions are mathematically connected to that of the CBF-QP through one equation. Building on top of the unveiled theoretical connections between CBF-QP and Mod-DS, reference Mod-based CBF-QP and on-manifold Mod-based CBF-QP controllers are proposed to combine the strength of CBF-QP and Mod-DS approaches and realize local-minimum-free reactive obstacle avoidance for control affine systems in general. We validate our methods in both simulated hospital environments and real-world experiments using Ridgeback for fully-actuated systems and Fetch robots for underactuated systems. Mod-based CBF-QPs outperform CBF-QPs as well as the optimally constrained-enforcing Mod-DS approaches we proposed in all experiments.

Paper number 104:
Title: Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation
Authors: Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng
Abstract: Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation. Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages. While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility. To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead. LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility. Experimental results across a range of languages demonstrate that LoRS-Merging reduces the word error rate by 10% and improves BLEU scores by 4% compared to conventional multi-lingual multi-task training baselines. Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications.

Paper number 105:
Title: CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement
Authors: Lei Cheng, Lihao Guo, Tianya Zhang, Tam Bang, Austin Harris, Mustafa Hajij, Mina Sartipi, Siyang Cao
Abstract: Accurate multi-sensor calibration is essential for deploying robust perception systems in applications such as autonomous driving, robotics, and intelligent transportation. Existing LiDAR-camera calibration methods often rely on manually placed targets, preliminary parameter estimates, or intensive data preprocessing, limiting their scalability and adaptability in real-world settings. In this work, we propose a fully automatic, targetless, and online calibration framework, CalibRefine, which directly processes raw LiDAR point clouds and camera images. Our approach is divided into four stages: (1) a Common Feature Discriminator that trains on automatically detected objects--using relative positions, appearance embeddings, and semantic classes--to generate reliable LiDAR-camera correspondences, (2) a coarse homography-based calibration, (3) an iterative refinement to incrementally improve alignment as additional data frames become available, and (4) an attention-based refinement that addresses non-planar distortions by leveraging a Vision Transformer and cross-attention mechanisms. Through extensive experiments on two urban traffic datasets, we show that CalibRefine delivers high-precision calibration results with minimal human involvement, outperforming state-of-the-art targetless methods and remaining competitive with, or surpassing, manually tuned baselines. Our findings highlight how robust object-level feature matching, together with iterative and self-supervised attention-based adjustments, enables consistent sensor fusion in complex, real-world conditions without requiring ground-truth calibration matrices or elaborate data preprocessing.

Paper number 106:
Title: GPUArmor: A Hardware-Software Co-design for Efficient and Scalable Memory Safety on GPUs
Authors: Mohamed Tarek Ibn Ziad, Sana Damani, Mark Stephenson, Stephen W. Keckler, Aamer Jaleel
Abstract: Memory safety errors continue to pose a significant threat to current computing systems, and graphics processing units (GPUs) are no exception. A prominent class of memory safety algorithms is allocation-based solutions. The key idea is to maintain each allocation's metadata (base address and size) in a disjoint table and retrieve it at runtime to verify memory accesses. While several previous solutions have adopted allocation-based algorithms (e.g., cuCatch and GPUShield), they typically suffer from high memory overheads or scalability problems. In this work, we examine the key characteristics of real-world GPU workloads and observe several differences between GPU and CPU applications regarding memory access patterns, memory footprint, number of live allocations, and active allocation working set. Our observations motivate GPUArmor, a hardware-software co-design framework for memory safety on GPUs. We show that a simple compiler analysis combined with lightweight hardware support using a small Memory Lookaside Buffer (MLB) can help prevent spatial and temporal memory violations on modern GPU workloads with 2.3% average run time overheads. More importantly, GPUArmor achieves speed-of-light performance with negligible storage requirements. This result benefits both base and bounds solutions and memory tagging techniques, which we showcase with GPUArmor-HWOnly, a variation of GPUArmor that does not require recompilation, and achieves 2.2% slowdowns while significantly reducing storage overheads beyond traditional memory tagging approaches.

Paper number 107:
Title: NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms
Authors: Yashan Wang, Shangda Wu, Jianhuai Hu, Xingjian Du, Yueqi Peng, Yongxin Huang, Shuai Fan, Xiaobing Li, Feng Yu, Maosong Sun
Abstract: We introduce NotaGen, a symbolic music generation model aiming to explore the potential of producing high-quality classical sheet music. Inspired by the success of Large Language Models (LLMs), NotaGen adopts pre-training, fine-tuning, and reinforcement learning paradigms (henceforth referred to as the LLM training paradigms). It is pre-trained on 1.6M pieces of music, and then fine-tuned on approximately 9K high-quality classical compositions conditioned on "period-composer-instrumentation" prompts. For reinforcement learning, we propose the CLaMP-DPO method, which further enhances generation quality and controllability without requiring human annotations or predefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in symbolic music generation models with different architectures and encoding schemes. Furthermore, subjective A/B tests show that NotaGen outperforms baseline models against human compositions, greatly advancing musical aesthetics in symbolic music generation. The project homepage is this https URL.
    