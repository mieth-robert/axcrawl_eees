
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: LiCAR: pseudo-RGB LiDAR image for CAR segmentation
Authors: Ignacio de Loyola Páez-Ubieta, Edison P. Velasco-Sánchez, Santiago T. Puente
Abstract: With the advancement of computing resources, an increasing number of Neural Networks (NNs) are appearing for image detection and segmentation appear. However, these methods usually accept as input a RGB 2D image. On the other side, Light Detection And Ranging (LiDAR) sensors with many layers provide images that are similar to those obtained from a traditional low resolution RGB camera. Following this principle, a new dataset for segmenting cars in pseudo-RGB images has been generated. This dataset combines the information given by the LiDAR sensor into a Spherical Range Image (SRI), concretely the reflectivity, near infrared and signal intensity 2D images. These images are then fed into instance segmentation NNs. These NNs segment the cars that appear in these images, having as result a Bounding Box (BB) and mask precision of 88% and 81.5% respectively with You Only Look Once (YOLO)-v8 large. By using this segmentation NN, some trackers have been applied so as to follow each car segmented instance along a video feed, having great performance in real world experiments.

Paper number 2:
Title: Patch-Based and Non-Patch-Based inputs Comparison into Deep Neural Models: Application for the Segmentation of Retinal Diseases on Optical Coherence Tomography Volumes
Authors: Khaled Al-Saih, Fares Al-Shargie, Mohammed Isam Al-hiyali, Reham Alhejaili
Abstract: Worldwide, sight loss is commonly occurred by retinal diseases, with age-related macular degeneration (AMD) being a notable facet that affects elderly patients. Approaching 170 million persons wide-ranging have been spotted with AMD, a figure anticipated to rise to 288 million by 2040. For visualizing retinal layers, optical coherence tomography (OCT) dispenses the most compelling non-invasive method. Frequent patient visits have increased the demand for automated analysis of retinal diseases, and deep learning networks have shown promising results in both image and pixel-level 2D scan classification. However, when relying solely on 2D data, accuracy may be impaired, especially when localizing fluid volume diseases. The goal of automatic techniques is to outperform humans in manually recognizing illnesses in medical data. In order to further understand the benefit of deep learning models, we studied the effects of the input size. The dice similarity coefficient (DSC) metric showed a human performance score of 0.71 for segmenting various retinal diseases. Yet, the deep models surpassed human performance to establish a new era of advancement of segmenting the diseases on medical images. However, to further improve the performance of the models, overlapping patches enhanced the performance of the deep models compared to feeding the full image. The highest score for a patch-based model in the DSC metric was 0.88 in comparison to the score of 0.71 for the same model in non-patch-based for SRF fluid segmentation. The objective of this article is to show a fair comparison between deep learning models in relation to the input (Patch-Based vs. NonPatch-Based).

Paper number 3:
Title: Synthetic CT image generation from CBCT: A Systematic Review
Authors: Alzahra Altalib, Scott McGregor, Chunhui Li, Alessandro Perelli
Abstract: The generation of synthetic CT (sCT) images from cone-beam CT (CBCT) data using deep learning methodologies represents a significant advancement in radiation oncology. This systematic review, following PRISMA guidelines and using the PICO model, comprehensively evaluates the literature from 2014 to 2024 on the generation of sCT images for radiation therapy planning in oncology. A total of 35 relevant studies were identified and analyzed, revealing the prevalence of deep learning approaches in the generation of sCT. This review comprehensively covers synthetic CT generation based on CBCT and proton-based studies. Some of the commonly employed architectures explored are convolutional neural networks (CNNs), generative adversarial networks (GANs), transformers, and diffusion models. Evaluation metrics including mean absolute error (MAE), root mean square error (RMSE), peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) consistently demonstrate the comparability of sCT images with gold-standard planning CTs (pCT), indicating their potential to improve treatment precision and patient outcomes. Challenges such as field-of-view (FOV) disparities and integration into clinical workflows are discussed, along with recommendations for future research and standardization efforts. In general, the findings underscore the promising role of sCT-based approaches in personalized treatment planning and adaptive radiation therapy, with potential implications for improved oncology treatment delivery and patient care.

Paper number 4:
Title: Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation
Authors: Xinya Wang, Tejas Sudharshan Mathai, Boah Kim, Ronald M. Summers
Abstract: Multiphase CT studies are routinely obtained in clinical practice for diagnosis and management of various diseases, such as cancer. However, the CT studies can be acquired with low radiation doses, different scanners, and are frequently affected by motion and metal artifacts. Prior approaches have targeted the quality improvement of one specific CT phase (e.g., non-contrast CT). In this work, we hypothesized that leveraging multiple CT phases for the quality enhancement of one phase may prove advantageous for downstream tasks, such as segmentation. A 3D progressive fusion and non-local (PFNL) network was developed. It was trained with three degraded (low-quality) phases (non-contrast, arterial, and portal venous) to enhance the quality of the portal venous phase. Then, the effect of scan quality enhancement was evaluated using a proxy task of pancreas segmentation, which is useful for tracking pancreatic cancer. The proposed approach improved the pancreas segmentation by 3% over the corresponding low-quality CT scan. To the best of our knowledge, we are the first to harness multiphase CT for scan quality enhancement and improved pancreas segmentation.

Paper number 5:
Title: A Synchrophasor Estimator Characterized by Attenuated Self-Interference and Robustness Against DC Offsets: the DCSOGI Interpolated DFT
Authors: César García-Veloso, Mario Paolone, José María Maza-Ortega
Abstract: The second-order generalized integrator (SOGI), which can be used to attenuate the self-interference of the fundamental tone, is unable to reject DC offsets on the input signal. Consequently, the performance of any SOGI based synchrophasor estimation (SE) technique might be compromised in the presence of such DC components. The current work presents a SE algorithm which adopts and enhanced SOGI formulation, robust against DC, combined with a three-point IpDFT and a Hanning window. Two alternative formulations relying respectively on the use of two and three nominal fundamental period observation windows are proposed and assessed for simultaneous compliance with both phasor measurement unit (PMU) P and M performance classes. This is done by means of a simulated environment where all the operating conditions defined by the IEC/IEEE Std. 60255-118-1-2018 are evaluated simultaneously combined with a $10\%$ static DC and under two different noise levels. Furthermore, both formulations adopt a dedicated mechanism for the detection and correction of low amplitude $2^{nd}$ harmonic tones to ensure their compliance with the standard can be maintained in the presence of such disturbances even under off-nominal frequency conditions. Finally the resilience of both methods against multiple simultaneous harmonic interferences is also analyzed.

Paper number 6:
Title: Efficient 2D CT Foundation Model for Contrast Phase Classification
Authors: Benjamin Hou, Tejas Sudharshan Mathai, Pritam Mukherjee, Xinya Wang, Ronald M. Summers, Zhiyong Lub
Abstract: Purpose: The purpose of this study is to harness the efficiency of a 2D foundation model to develop a robust phase classifier that is resilient to domain shifts. Materials and Methods: This retrospective study utilized three public datasets from separate institutions. A 2D foundation model was trained on the DeepLesion dataset (mean age: 51.2, s.d.: 17.6; 2398 males) to generate embeddings from 2D CT slices for downstream contrast phase classification. The classifier was trained on the VinDr Multiphase dataset and externally validated on the WAW-TACE dataset. The 2D model was also compared to three 3D supervised models. Results: On the VinDr dataset (146 male, 63 female, 56 unidentified), the model achieved near-perfect AUROC scores and F1 scores of 99.2%, 94.2%, and 93.1% for non-contrast, arterial, and venous phases, respectively. The `Other' category scored lower (F1: 73.4%) due to combining multiple contrast phases into one class. On the WAW-TACE dataset (mean age: 66.1, s.d.: 10.0; 185 males), the model showed strong performance with AUROCs of 91.0% and 85.6%, and F1 scores of 87.3% and 74.1% for non-contrast and arterial phases. Venous phase performance was lower, with AUROC and F1 scores of 81.7% and 70.2% respectively, due to label mismatches. Compared to 3D supervised models, the approach trained faster, performed as well or better, and showed greater robustness to domain shifts. Conclusion: The robustness of the 2D Foundation model may be potentially useful for automation of hanging protocols and data orchestration for clinical deployment of AI algorithms.

Paper number 7:
Title: Passivity-Based Robust Shape Control of a Cable-Driven Solar Sail Boom for the CABLESSail Concept
Authors: Soojeong Lee, Ryan J. Caverly
Abstract: Solar sails provide a means of propulsion using solar radiation pressure, which offers the possibility of exciting new spacecraft capabilities. However, solar sails have attitude control challenges because of the significant disturbance torques that they encounter due to imperfections in the sail and its supporting structure, as well as limited actuation capabilities. The Cable-Actuated Bio-inspired Lightweight Elastic Solar Sail (CABLESSail) concept was previously proposed to overcome these challenges by controlling the shape of the sail through cable actuation. The structural flexibility of CABLESSail introduces control challenges, which necessitate the design of a robust feedback controller for this system. The purpose of the proposed research here is to design a robust controller to ensure precise and reliable control of CABLESSail's boom. Taking into account the system dynamics and the dynamic properties of the CABLESSail concept, a passivity-based proportional-derivative (PD) controller for a single boom on the CABLESSail system is designed. To reach the nonzero desired setpoints, a feedforward input is additionally applied to the control law and a time-varying feedforward input is used instead of the constant one to effectively track a time-varying desired boom tip deflection. This control law is assessed by numerical simulations and by tests using a smaller-scale prototype of Solar Cruiser. Both the simulation and the test results show that this PD control with the time-varying feedforward input robustly controls the flexible cable-actuated solar sail.

Paper number 8:
Title: Domain-Factored Untrained Deep Prior for Spectrum Cartography
Authors: Subash Timilsina, Sagar Shrestha, Lei Cheng, Xiao Fu
Abstract: Spectrum cartography (SC) focuses on estimating the radio power propagation map of multiple emitters across space and frequency using limited sensor measurements. Recent advances in SC have shown that leveraging learned deep generative models (DGMs) as structural constraints yields state-of-the-art performance. By harnessing the expressive power of neural networks, these structural "priors" capture intricate patterns in radio maps. However, training DGMs requires substantial data, which is not always available, and distribution shifts between training and testing data can further degrade performance. To address these challenges, this work proposes using untrained neural networks (UNNs) for SC. UNNs, commonly applied in vision tasks to represent complex data without training, encode structural information of data in neural architectures. In our approach, a custom-designed UNN represents radio maps under a spatio-spectral domain factorization model, leveraging physical characteristics to reduce sample complexity of SC. Experiments show that the method achieves performance comparable to learned DGM-based SC, without requiring training data.

Paper number 9:
Title: A Root Extension to the Propagator Algorithm for Direction of Arrival Estimation
Authors: Pradeep Dheerendra, Zoltan Derzsi
Abstract: In this paper, we propose an extension to the Propagator algorithm for source bearing estimation by performing root decomposition which eliminates the need for spectral search over angles. Further the propagator spatial spectrum is reused after performing the polynomial rooting to alleviate the observed drawback of an increase in RMSE at lower SNRs for estimating the directions-of-arrival of signals impinging on a linear array of sensors. Our proposed algorithm achieves a 98% reduction in computational complexity compared to Propagator alongside an improved angular resolution suitable for real time DOA estimation for wireless communications.

Paper number 10:
Title: WaveMax: Radar Waveform Design via Convex Maximization of FrFT Phase Retrieval
Authors: Samuel Pinilla, Kumar Vijay Mishra, Brian M. Sadler
Abstract: The ambiguity function (AF) is a critical tool in radar waveform design, representing the two-dimensional correlation between a transmitted signal and its time-delayed, frequency-shifted version. Obtaining a radar signal to match a specified AF magnitude is a bi-variate variant of the well-known phase retrieval problem. Prior approaches to this problem were either limited to a few classes of waveforms or lacked a computable procedure to estimate the signal. Our recent work provided a framework for solving this problem for both band- and time-limited signals using non-convex optimization. In this paper, we introduce a novel approach WaveMax that formulates waveform recovery as a convex optimization problem by relying on the fractional Fourier transform (FrFT)-based AF. We exploit the fact that AF of the FrFT of the original signal is equivalent to a rotation of the original AF. In particular, we reconstruct the radar signal by solving a low-rank minimization problem, which approximates the waveform using the leading eigenvector of a matrix derived from the AF. Our theoretical analysis shows that unique waveform reconstruction is achievable with a sample size no more than three times the signal frequencies or time samples. Numerical experiments validate the efficacy of WaveMax in recovering signals from noiseless and noisy AF, including scenarios with randomly and uniformly sampled sparse data.

Paper number 11:
Title: Fully Guided Neural Schr\"odinger bridge for Brain MR image synthesis
Authors: Hanyeol Yang, Sunggyu Kim, Yongseon Yoo, Jong-min Lee
Abstract: Multi-modal brain MRI provides essential complementary information for clinical diagnosis. However, acquiring all modalities is often challenging due to time and cost constraints. To address this, various methods have been proposed to generate missing modalities from available ones. Traditional approaches can be broadly categorized into two main types: paired and unpaired methods. While paired methods offer superior performance, obtaining large-scale paired datasets is challenging in real-world scenarios. Conversely, unpaired methods facilitate large-scale data collection but struggle to preserve critical image features, such as tumors. In this paper, we propose Fully Guided Schrödinger Bridges (FGSB), a novel framework based on Neural Schrödinger Bridges, to overcome these limitations. FGSB achieves stable, high-quality generation of missing modalities using minimal paired data. Furthermore, when provided with ground truth or a segmentation network for specific regions, FGSB can generate missing modalities while preserving these critical areas with reduced data requirements. Our proposed model consists of two consecutive phases. 1) Generation Phase: Fuses a generated image, a paired reference image, and Gaussian noise, employing iterative refinement to mitigate issues such as mode collapse and improve generation quality 2) Training Phase: Learns the mapping from the generated image to the target modality. Experiments demonstrate that FGSB achieves comparable generation performance to methods trained on large datasets, while using data from only two subjects. Moreover, the utilization of lesion information with FGSB significantly enhances its ability to preserve crucial lesion features.

Paper number 12:
Title: Fabrication of Soft and Comfortable Pressure-Sensing Shoe Sole for Intuitive Monitoring of Human Quality Gaits
Authors: Muhammad Adeel, Hasnain Ali, Afaque Manzoor Soomro, Muhammad Waqas
Abstract: The study discusses the design and fabrication of flexible pressure sensors using Ecoflex/Graphene composites. The fabricated sensor is used for the application of intuitive monitoring of human quality gaits and implementation of the soft and comfortable shoe sole for rehabilitation of the patients with foot disorder is also taken into consideration. The sensor is fabricated using molding and casting technique by sandwiching the thin film Ecoflex/Graphene composites between the copper (Cu) electrodes with the dimension of 15 x 15 mm2 with high sensitivity. There are five pressure sensors integrated in the shoe sole, a sensor at the forefoot, three sensors at the midfoot and one sensor at the lower foot (heel). The behavior of the sensor is negative piezoresistive in which the resistance decreases as the pressure increases. The sensors are embedded in a soft and comfortable shoe sole and then integrated with a laptop or mobile application to monitor and analyze human gait in real-time. Furthermore, a dedicated Graphical User Interface (GUI) is designed to read the data. The pressure sensors are integrated with ESP32 microcontroller which wirelessly transmit data to the GUI and smart phones which could be further used in the intuitive monitoring, rehabilitation of the patients with foot disorder or neuromotor diseases.

Paper number 13:
Title: Sparse Mixture-of-Experts for Non-Uniform Noise Reduction in MRI Images
Authors: Zeyun Deng, Joseph Campbell
Abstract: Magnetic Resonance Imaging (MRI) is an essential diagnostic tool in clinical settings, but its utility is often hindered by noise artifacts introduced during the imaging this http URL denoising is critical for enhancing image quality while preserving anatomical structures. However, traditional denoising methods, which often assume uniform noise distributions, struggle to handle the non-uniform noise commonly present in MRI images. In this paper, we introduce a novel approach leveraging a sparse mixture-of-experts framework for MRI image denoising. Each expert is a specialized denoising convolutional neural network fine-tuned to target specific noise characteristics associated with different image regions. Our method demonstrates superior performance over state-of-the-art denoising techniques on both synthetic and real-world brain MRI datasets. Furthermore, we show that it generalizes effectively to unseen datasets, highlighting its robustness and adaptability.

Paper number 14:
Title: Learning-Augmented Online Control for Decarbonizing Water Infrastructures
Authors: Jianyi Yang, Pengfei Li, Tongxin Li, Adam Wierman, Shaolei Ren
Abstract: Water infrastructures are essential for drinking water supply, irrigation, fire protection, and other critical applications. However, water pumping systems, which are key to transporting water to the point of use, consume significant amounts of energy and emit millions of tons of greenhouse gases annually. With the wide deployment of digital water meters and sensors in these infrastructures, Machine Learning (ML) has the potential to optimize water supply control and reduce greenhouse gas emissions. Nevertheless, the inherent vulnerability of ML methods in terms of worst-case performance raises safety concerns when deployed in critical water infrastructures. To address this challenge, we propose a learning-augmented online control algorithm, termed LAOC, designed to dynamically schedule the activation and/or speed of water pumps. To ensure safety, we introduce a novel design of safe action sets for online control problems. By leveraging these safe action sets, LAOC can provably guarantee safety constraints while utilizing ML predictions to reduce energy and environmental costs. Our analysis reveals the tradeoff between safety requirements and average energy/environmental cost performance. Additionally, we conduct an experimental study on a building water supply system to demonstrate the empirical performance of LAOC. The results indicate that LAOC can effectively reduce environmental and energy costs while guaranteeing safety constraints.

Paper number 15:
Title: STAR-RIS-Enabled Multi-Path Beam Routing with Passive Beam Splitting
Authors: Bonan An, Weidong Mei, Yuanwei Liu, Zhi Chen
Abstract: Reconfigurable intelligent surfaces (RISs) can be densely deployed in the environment to create multi-reflection line-of-sight (LoS) links for signal coverage enhancement. However, conventional reflection-only RISs can only achieve half-space reflection, which limits the LoS path diversity. In contrast, simultaneously transmitting and reflecting RISs (STAR-RISs) can achieve full-space reflection and transmission, thereby creating more LoS paths. Hence, in this paper, we study a new multi-STAR-RIS-aided communication system, where a multi-antenna base station (BS) transmits to multiple single-antenna users by exploiting the signal beam routing over a set of cascaded LoS paths each formed by multiple STAR-RISs. To reveal essential insights, we first consider a simplified single-user case, aiming to maximize its received signal power by jointly optimizing the active beamforming at the BS, the BS's power allocation over different paths, the number of selected beam-routing paths, the selected STAR-RISs for each path, as well as their amplitude and phase shifts for transmission/reflection. However, this problem is difficult to be optimally solved as different paths may be intricately coupled at their shared STAR-RISs. To tackle this difficulty, we first derive the optimal solution to this problem in closed-form for a given set of paths. The clique-based approach in graph theory is then applied to solve the remaining multi-path selection problem efficiently. Next, we extend the proposed clique-based method to the multi-user case to maximize the minimum received signal power among all users, subject to additional constraints on the disjointness of the selected paths for different users. Simulation results show that our proposed STAR-RIS-enabled beam routing outperforms the conventional beam routing with reflection-only RISs in both single- and multi-user cases.

Paper number 16:
Title: Generalizable Audio Deepfake Detection via Latent Space Refinement and Augmentation
Authors: Wen Huang, Yanmei Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian
Abstract: Advances in speech synthesis technologies, like text-to-speech (TTS) and voice conversion (VC), have made detecting deepfake speech increasingly challenging. Spoofing countermeasures often struggle to generalize effectively, particularly when faced with unseen attacks. To address this, we propose a novel strategy that integrates Latent Space Refinement (LSR) and Latent Space Augmentation (LSA) to improve the generalization of deepfake detection systems. LSR introduces multiple learnable prototypes for the spoof class, refining the latent space to better capture the intricate variations within spoofed data. LSA further diversifies spoofed data representations by applying augmentation techniques directly in the latent space, enabling the model to learn a broader range of spoofing patterns. We evaluated our approach on four representative datasets, i.e. ASVspoof 2019 LA, ASVspoof 2021 LA and DF, and In-The-Wild. The results show that LSR and LSA perform well individually, and their integration achieves competitive results, matching or surpassing current state-of-the-art methods.

Paper number 17:
Title: Adaptive Progressive Attention Graph Neural Network for EEG Emotion Recognition
Authors: Tianzhi Feng, Chennan Wu, Yi Niu, Fu Li, Boxun Fu, Zhifu Zhao, Xiaotian Wang, Guangming Shi
Abstract: In recent years, numerous neuroscientific studies have shown that human emotions are closely linked to specific brain regions, with these regions exhibiting variability across individuals and emotional states. To fully leverage these neural patterns, we propose an Adaptive Progressive Attention Graph Neural Network (APAGNN), which dynamically captures the spatial relationships among brain regions during emotional processing. The APAGNN employs three specialized experts that progressively analyze brain topology. The first expert captures global brain patterns, the second focuses on region-specific features, and the third examines emotion-related channels. This hierarchical approach enables increasingly refined analysis of neural activity. Additionally, a weight generator integrates the outputs of all three experts, balancing their contributions to produce the final predictive label. Extensive experiments on three publicly available datasets (SEED, SEED-IV and MPED) demonstrate that the proposed method enhances EEG emotion recognition performance, achieving superior results compared to baseline methods.

Paper number 18:
Title: Optimal Investment under Mutual Strategy Influence among Agents
Authors: Huisheng Wang, H. Vicky Zhao
Abstract: In financial markets, agents often mutually influence each other's investment strategies and adjust their strategies to align with others. However, there is limited quantitative study of agents' investment strategies in such scenarios. In this work, we formulate the optimal investment differential game problem to study the mutual influence among agents. We derive the analytical solutions for agents' optimal strategies and propose a fast algorithm to find approximate solutions with low computational complexity. We theoretically analyze the impact of mutual influence on agents' optimal strategies and terminal wealth. When the mutual influence is strong and approaches infinity, we show that agents' optimal strategies converge to the asymptotic strategy. Furthermore, in general cases, we prove that agents' optimal strategies are linear combinations of the asymptotic strategy and their rational strategies without others' influence. We validate the performance of the fast algorithm and verify the correctness of our analysis using numerical experiments. This work is crucial to comprehend mutual influence among agents and design effective mechanisms to guide their strategies in financial markets.

Paper number 19:
Title: CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image
Authors: Xiaojun Tang, Jingru Wang, Guangwei Huang, Guannan Chen, Rui Zheng, Lian Huai, Yuyu Liu, Xingqun Jiang
Abstract: Recent advancements in Blind Image Restoration (BIR) methods, based on Generative Adversarial Networks and Diffusion Models, have significantly improved visual quality. However, they present significant challenges for Image Quality Assessment (IQA), as the existing Full-Reference IQA methods often rate images with high perceptual quality poorly. In this paper, we reassess the Solution Non-Uniqueness and Degradation Indeterminacy issues of BIR, and propose constructing a specific BIR IQA system. In stead of directly comparing a restored image with a reference image, the BIR IQA evaluates fidelity by calculating the Consistency with Degraded Image (CDI). Specifically, we propose a wavelet domain Reference Guided CDI algorithm, which can acquire the consistency with a degraded image for various types without requiring knowledge of degradation parameters. The supported degradation types include down sampling, blur, noise, JPEG and complex combined degradations etc. In addition, we propose a Reference Agnostic CDI, enabling BIR fidelity evaluation without reference images. Finally, in order to validate the rationality of CDI, we create a new Degraded Images Switch Display Comparison Dataset (DISDCD) for subjective evaluation of BIR fidelity. Experiments conducted on DISDCD verify that CDI is markedly superior to common Full Reference IQA methods for BIR fidelity evaluation. The source code and the DISDCD dataset will be publicly available shortly.

Paper number 20:
Title: Characteristic-Specific Partial Fine-Tuning for Efficient Emotion and Speaker Adaptation in Codec Language Text-to-Speech Models
Authors: Tianrui Wang, Meng Ge, Cheng Gong, Chunyu Qiang, Haoyu Wang, Zikang Huang, Yu Jiang, Xiaobao Wang, Xie Chen, Longbiao Wang, Jianwu Dang
Abstract: Recently, emotional speech generation and speaker cloning have garnered significant interest in text-to-speech (TTS). With the open-sourcing of codec language TTS models trained on massive datasets with large-scale parameters, adapting these general pre-trained TTS models to generate speech with specific emotional expressions and target speaker characteristics has become a topic of great attention. Common approaches, such as full and adapter-based fine-tuning, often overlook the specific contributions of model parameters to emotion and speaker control. Treating all parameters uniformly during fine-tuning, especially when the target data has limited content diversity compared to the pre-training corpus, results in slow training speed and an increased risk of catastrophic forgetting. To address these challenges, we propose a characteristic-specific partial fine-tuning strategy, short as CSP-FT. First, we use a weighted-sum approach to analyze the contributions of different Transformer layers in a pre-trained codec language TTS model for emotion and speaker control in the generated speech. We then selectively fine-tune the layers with the highest and lowest characteristic-specific contributions to generate speech with target emotional expression and speaker identity. Experimental results demonstrate that our method achieves performance comparable to, or even surpassing, full fine-tuning in generating speech with specific emotional expressions and speaker identities. Additionally, CSP-FT delivers approximately 2x faster training speeds, fine-tunes only around 8% of parameters, and significantly reduces catastrophic forgetting. Furthermore, we show that codec language TTS models perform competitively with self-supervised models in speaker identification and emotion classification tasks, offering valuable insights for developing universal speech processing models.

Paper number 21:
Title: Deep Learning-Powered Classification of Thoracic Diseases in Chest X-Rays
Authors: Yiming Lei, Michael Nguyen, Tzu Chia Liu, Hyounkyun Oh
Abstract: Chest X-rays play a pivotal role in diagnosing respiratory diseases such as pneumonia, tuberculosis, and COVID-19, which are prevalent and present unique diagnostic challenges due to overlapping visual features and variability in image quality. Severe class imbalance and the complexity of medical images hinder automated analysis. This study leverages deep learning techniques, including transfer learning on pre-trained models (AlexNet, ResNet, and InceptionNet), to enhance disease detection and classification. By fine-tuning these models and incorporating focal loss to address class imbalance, significant performance improvements were achieved. Grad-CAM visualizations further enhance model interpretability, providing insights into clinically relevant regions influencing predictions. The InceptionV3 model, for instance, achieved a 28% improvement in AUC and a 15% increase in F1-Score. These findings highlight the potential of deep learning to improve diagnostic workflows and support clinical decision-making.

Paper number 22:
Title: Higher-Order Meta Distribution Analysis of Wireless Systems with Application to the Reliability of UWB THz Networks
Authors: Mehdi Monemi, Mehdi Rasti, S. Ali Mousavi, Matti Latva-aho, Martin Haenggi
Abstract: Communication reliability, as defined by 3GPP, refers to the probability of providing a desired quality of service (QoS). This metric is typically quantified for wireless networks by averaging the QoS success indicator over spatial and temporal random variables. Recently, the meta distribution (MD) has emerged as a two-level performance analysis tool for wireless networks, offering a detailed examination of the outer level (i.e., system-level) reliability assessment versus the inner level (i.e., link-level) reliability thresholds. Most existing studies focus on first-order spatiotemporal MD reliability analyses, and the benefits of leveraging MD reliability for applications beyond this structure remain unexplored, a gap addressed in this paper. We present wireless application examples that can benefit the higher-order MD reliability analysis. Specifically, we provide the analysis and numerical results for a second-order spatial-spectral-temporal MD reliability of ultra-wideband THz communication. The results demonstrate the value of the hierarchical representation of MD reliability across three domains and the impact of the inner-layer target reliability on the overall MD reliability measure.

Paper number 23:
Title: Automatic detection and prediction of nAMD activity change in retinal OCT using Siamese networks and Wasserstein Distance for ordinality
Authors: Taha Emre, Teresa Araújo, Marzieh Oghbaie, Dmitrii Lachinov, Guilherme Aresta, Hrvoje Bogunović
Abstract: Neovascular age-related macular degeneration (nAMD) is a leading cause of vision loss among older adults, where disease activity detection and progression prediction are critical for nAMD management in terms of timely drug administration and improving patient outcomes. Recent advancements in deep learning offer a promising solution for predicting changes in AMD from optical coherence tomography (OCT) retinal volumes. In this work, we proposed deep learning models for the two tasks of the public MARIO Challenge at MICCAI 2024, designed to detect and forecast changes in nAMD severity with longitudinal retinal OCT. For the first task, we employ a Vision Transformer (ViT) based Siamese Network to detect changes in AMD severity by comparing scan embeddings of a patient from different time points. To train a model to forecast the change after 3 months, we exploit, for the first time, an Earth Mover (Wasserstein) Distance-based loss to harness the ordinal relation within the severity change classes. Both models ranked high on the preliminary leaderboard, demonstrating that their predictive capabilities could facilitate nAMD treatment management.

Paper number 24:
Title: Joint Infrastructure Planning and Order Assignment for On-Demand Food-Delivery Services with Coordinated Drones and Human Couriers
Authors: Yang Liu, Yitong Shang, Sen Li
Abstract: This paper investigates the optimal infrastructure planning and order assignment problem of an on-demand food-delivery platform with a mixed fleet of drones and human couriers. The platform has two delivery modes: (a) ground delivery and (b) drone-assisted delivery (i.e., air delivery). In ground delivery, couriers directly collect and transport orders from restaurants to destinations. For air delivery, the delivery process involves three legs: initially, a human courier picks up the order from the restaurant and transports it to a nearby launchpad, where personnel load the orders onto drones and replace batteries as needed. The loaded drone then transports the order from the launchpad to a kiosk, where another courier retrieves the order from the kiosk for final delivery. The platform must determine the optimal locations for launchpads and kiosks within a transportation network, and devise an order assignment strategy that allocates food-delivery orders between ground and air delivery considering the bundling probabilities of ground deliveries and the waiting times at launchpads and kiosks. We formulate the platform's problem as a mixed-integer nonlinear program and develop a novel neural network-assisted optimization method to obtain high-quality solutions. A case study in Hong Kong validates our model and algorithm, revealing that drone delivery reduces operational costs, minimizes courier fleet size, and increases order bundling opportunities. We also find that the expansion of air delivery services may entail larger delivery times due to the trade-off between the travel time savings induced by the faster air delivery and the associated detours incurred by intermodal transfer and extra waiting times at launchpads and kiosks, which crucially depends on the distance of the orders and the sequence of activating long-distance air delivery routes versus short-distance ones.

Paper number 25:
Title: FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration
Authors: Kai-Tuo Xu, Feng-Long Xie, Xu Tang, Yao Hu
Abstract: We present FireRedASR, a family of large-scale automatic speech recognition (ASR) models for Mandarin, designed to meet diverse requirements in superior performance and optimal efficiency across various applications. FireRedASR comprises two variants: FireRedASR-LLM: Designed to achieve state-of-the-art (SOTA) performance and to enable seamless end-to-end speech interaction. It adopts an Encoder-Adapter-LLM framework leveraging large language model (LLM) capabilities. On public Mandarin benchmarks, FireRedASR-LLM (8.3B parameters) achieves an average Character Error Rate (CER) of 3.05%, surpassing the latest SOTA of 3.33% with an 8.4% relative CER reduction (CERR). It demonstrates superior generalization capability over industrial-grade baselines, achieving 24%-40% CERR in multi-source Mandarin ASR scenarios such as video, live, and intelligent assistant. FireRedASR-AED: Designed to balance high performance and computational efficiency and to serve as an effective speech representation module in LLM-based speech models. It utilizes an Attention-based Encoder-Decoder (AED) architecture. On public Mandarin benchmarks, FireRedASR-AED (1.1B parameters) achieves an average CER of 3.18%, slightly worse than FireRedASR-LLM but still outperforming the latest SOTA model with over 12B parameters. It offers a more compact size, making it suitable for resource-constrained applications. Moreover, both models exhibit competitive results on Chinese dialects and English speech benchmarks and excel in singing lyrics recognition. To advance research in speech processing, we release our models and inference code at this https URL.

Paper number 26:
Title: CSI-Free Low-Complexity Remote State Estimation over Wireless MIMO Fading Channels using Semantic Analog Aggregation
Authors: Minjie Tang, Photios A. Stavrou, Marios Kountouris
Abstract: In this work, we investigate low-complexity remote system state estimation over wireless multiple-input-multiple-output (MIMO) channels without requiring prior knowledge of channel state information (CSI). We start by reviewing the conventional Kalman filtering-based state estimation algorithm, which typically relies on perfect CSI and incurs considerable computational complexity. To overcome the need for CSI, we introduce a novel semantic aggregation method, in which sensors transmit semantic measurement discrepancies to the remote state estimator through analog aggregation. To further reduce computational complexity, we introduce a constant-gain-based filtering algorithm that can be optimized offline using the constrained stochastic successive convex approximation (CSSCA) method. We derive a closed-form sufficient condition for the estimation stability of our proposed scheme via Lyapunov drift analysis. Numerical results showcase significant performance gains using the proposed scheme compared to several widely used methods.

Paper number 27:
Title: ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer
Authors: Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G.E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings
Abstract: The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor for patients with (triple-negative) breast cancer (BC). Computational TIL assessment (CTA) has the potential to assist pathologists in this labour-intensive task, but current CTA models rely heavily on many detailed annotations. We propose and validate a fundamentally simpler deep learning based CTA that can be trained in only ten minutes on hundredfold fewer pathologist annotations. We collected whole slide images (WSIs) with TILs scores and clinical data of 2,340 patients with BC from six cohorts including three randomised clinical trials. Morphological features were extracted from whole slide images (WSIs) using a pathology foundation model. Our label-efficient Computational stromal TIL assessment model (ECTIL) directly regresses the TILs score from these features. ECTIL trained on only a few hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all slides of five cohorts (ECTIL-combined) improved results on a held-out test set (r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that every 10% increase of ECTIL scores was associated with improved overall survival independent of clinicopathological variables (HR 0.86, p<0.01), similar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL is highly concordant with an expert pathologist and obtains a similar hazard ratio. ECTIL has a fundamentally simpler design than existing methods and can be trained on orders of magnitude fewer annotations. Such a CTA may be used to pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a tool to assist clinicians in the diagnostic work-up of patients with BC. Our model is available under an open source licence (this https URL).

Paper number 28:
Title: Human Activity Recognition with a 6.5 GHz Reconfigurable Intelligent Surface for Wi-Fi 6E
Authors: Nuno Paulino, Mariana Oliveira, Francisco Ribeiro, Luís Outeiro, Pedro A. Lopes, Francisco Vilarinho, Sofia Inácio, Luís M. Pessoa
Abstract: Human Activity Recognition (HAR) is the identification and classification of static and dynamic human activities, which find applicability in domains like healthcare, entertainment, security, and cyber-physical systems. Traditional HAR approaches rely on wearable sensors, vision-based systems, or ambient sensing, each with inherent limitations such as privacy concerns or restricted sensing conditions. Recently, Radio Frequency (RF)-based HAR has emerged, relying on the interaction of RF signals with people to infer activities. Reconfigurable Intelligent Surfaces (RISs) offers significant potential in this domain by enabling dynamic control over the wireless environment, thus enhancing the information extracted from RF signals. We present an Hand Gesture Recognition (HGR) approach that employs our own 6.5 GHz RIS design to manipulate the RF medium in an area of interest. We validate the capability of our RIS to control the medium by characterizing its steering response, and further we gather and publish a dataset for HGR classification for three different hand gestures. By employing two Convolutional Neural Networks (CNNs) models trained on data gathered under random and optimized RIS configuration sequences, we achieved classification accuracies exceeding 90%.

Paper number 29:
Title: Enhancing Intelligibility for Generative Target Speech Extraction via Joint Optimization with Target Speaker ASR
Authors: Hao Ma, Rujin Chen, Ruihao Jing, Xiao-Lei Zhang, Ju Liu, Xuelong Li
Abstract: Target speech extraction (TSE) isolates the speech of a specific speaker from a multi-talker overlapped speech mixture. Most existing TSE models rely on discriminative methods, typically predicting a time-frequency spectrogram mask for the target speech. However, imperfections in these masks often result in over-/under-suppression of target/non-target speech, degrading perceptual quality. Generative methods, by contrast, re-synthesize target speech based on the mixture and target speaker cues, achieving superior perceptual quality. Nevertheless, these methods often overlook speech intelligibility, leading to alterations or loss of semantic content in the re-synthesized speech. Inspired by the Whisper model's success in target speaker ASR, we propose a generative TSE framework based on the pre-trained Whisper model to address the above issues. This framework integrates semantic modeling with flow-based acoustic modeling to achieve both high intelligibility and perceptual quality. Results from multiple benchmarks demonstrate that the proposed method outperforms existing generative and discriminative baselines. We present speech samples on our demo page.

Paper number 30:
Title: Registration of Longitudinal Liver Examinations for Tumor Progress Assessment
Authors: Walid Yassine, Martin Charachon, Céline Hudelot, Roberto Ardon
Abstract: Assessing cancer progression in liver CT scans is a clinical challenge, requiring a comparison of scans at different times for the same patient. Practitioners must identify existing tumors, compare them with prior exams, identify new tumors, and evaluate overall disease evolution. This process is particularly complex in liver examinations due to misalignment between exams caused by several factors. Indeed, longitudinal liver examinations can undergo different non-pathological and pathological changes due to non-rigid deformations, the appearance or disappearance of pathologies, and other variations. In such cases, existing registration approaches, mainly based on intrinsic features may distort tumor regions, biasing the tumor progress evaluation step and the corresponding diagnosis. This work proposes a registration method based only on geometrical and anatomical information from liver segmentation, aimed at aligning longitudinal liver images for aided diagnosis. The proposed method is trained and tested on longitudinal liver CT scans, with 317 patients for training and 53 for testing. Our experimental results support our claims by showing that our method is better than other registration techniques by providing a smoother deformation while preserving the tumor burden (total volume of tissues considered as tumor) within the volume. Qualitative results emphasize the importance of smooth deformations in preserving tumor appearance.

Paper number 31:
Title: Scene Understanding Enabled Semantic Communication with Open Channel Coding
Authors: Zhe Xiang, Fei Yu, Quan Deng, Yuandi Li, Zhiguo Wan
Abstract: As communication systems transition from symbol transmission to conveying meaningful information, sixth-generation (6G) networks emphasize semantic communication. This approach prioritizes high-level semantic information, improving robustness and reducing redundancy across modalities like text, speech, and images. However, traditional semantic communication faces limitations, including static coding strategies, poor generalization, and reliance on task-specific knowledge bases that hinder adaptability. To overcome these challenges, we propose a novel system combining scene understanding, Large Language Models (LLMs), and open channel coding, named \textbf{OpenSC}. Traditional systems rely on fixed domain-specific knowledge bases, limiting their ability to generalize. Our open channel coding approach leverages shared, publicly available knowledge, enabling flexible, adaptive encoding. This dynamic system reduces reliance on static task-specific data, enhancing adaptability across diverse tasks and environments. Additionally, we use scene graphs for structured semantic encoding, capturing object relationships and context to improve tasks like Visual Question Answering (VQA). Our approach selectively encodes key semantic elements, minimizing redundancy and improving transmission efficiency. Experimental results show significant improvements in both semantic understanding and efficiency, advancing the potential of adaptive, generalizable semantic communication in 6G networks.

Paper number 32:
Title: Wearable slot antenna at 2.45 GHz for off-body radiation: analysis of efficiency, frequency shift and body absorption
Authors: Marta Fernandez, Hugo G. Espinosa, David V. Thiel, Amaia Arrinda
Abstract: The interaction of body worn antennas with the human body causes a significant decrease in the antenna efficiency and a shift in the resonant frequency. A resonant slot in a small conductive box placed on the body has been shown to reduce these effects. The specific absorption rate (SAR) is less than international health standards for most wearable antennas due to the small transmitter power. This paper reports the linear relationship between the power absorbed by biological tissues at different locations on the body, and the radiation efficiency based on numerical modeling (r = 0.99). While the -10 dB bandwidth of the antenna remains constant and equal to 12.5%, the maximum frequency shift occurs when the antenna is close to the elbow (6.61%) and on the thigh (5.86%). The smallest change was found on the torso (4.21%). Participants with body-mass index (BMI) between 17 and 29 kg/m2 took part in experimental measurements, where the maximum frequency shift was 2.51%. Measurements show better agreement with simulations on the upper arm. These experimental results demonstrate that the BMI for each individual has little effect on the performance of the antenna.

Paper number 33:
Title: Calibrating Wireless AI via Meta-Learned Context-Dependent Conformal Prediction
Authors: Seonghoon Yoo, Sangwoo Park, Joonhyuk Kang, Petar Popovski, Osvaldo Simeone
Abstract: Modern software-defined networks, such as Open Radio Access Network (O-RAN) systems, rely on artificial intelligence (AI)-powered applications running on controllers interfaced with the radio access network. To ensure that these AI applications operate reliably at runtime, they must be properly calibrated before deployment. A promising and theoretically grounded approach to calibration is conformal prediction (CP), which enhances any AI model by transforming it into a provably reliable set predictor that provides error bars for estimates and decisions. CP requires calibration data that matches the distribution of the environment encountered during runtime. However, in practical scenarios, network controllers often have access only to data collected under different contexts -- such as varying traffic patterns and network conditions -- leading to a mismatch between the calibration and runtime distributions. This paper introduces a novel methodology to address this calibration-test distribution shift. The approach leverages meta-learning to develop a zero-shot estimator of distribution shifts, relying solely on contextual information. The proposed method, called meta-learned context-dependent weighted conformal prediction (ML-WCP), enables effective calibration of AI applications without requiring data from the current context. Additionally, it can incorporate data from multiple contexts to further enhance calibration reliability.

Paper number 34:
Title: A Transferable Physics-Informed Framework for Battery Degradation Diagnosis, Knee-Onset Detection and Knee Prediction
Authors: Huang Zhang, Xixi Liu, Faisal Altaf, Torsten Wik
Abstract: The techno-economic and safety concerns of battery capacity knee occurrence call for developing online knee detection and prediction methods as an advanced battery management system (BMS) function. To address this, a transferable physics-informed framework that consists of a histogram-based feature engineering method, a hybrid physics-informed model, and a fine-tuning strategy, is proposed for online battery degradation diagnosis and knee-onset detection. The hybrid model is first developed and evaluated using a scenario-aware pipeline in protocol cycling scenarios and then fine-tuned to create a local model deployed in a dynamic cycling scenario. A 2D histogram-based feature set is found to be the best choice in both source and target scenarios. The fine-tuning strategy is proven to be effective in improving battery degradation mode estimation and degradation phase detection performance in the target scenario. Again, a strong linear correlation was found between the identified knee-onset and knee points. As a result, advanced BMS functions, such as online degradation diagnosis and prognosis, online knee-onset detection and knee prediction, aging-aware battery classification, and second-life repurposing, can be enabled through a battery performance digital twin in the cloud.

Paper number 35:
Title: Harmonization of Noise Measurement Methods: Measurements of radio impulsive noise from a specific source
Authors: Marta Fernandez, Iratxe Landa, Amaia Arrinda, Ruben Torre, Manuel Velez
Abstract: This article describes a procedure for measuring and evaluating radio impulsive noise (IN) from a specific source. A good knowledge of the noise caused by different sources is essential to plan radio services and to ensure good quality of service. Moreover, it is necessary to harmonize noise measurement methods to achieve results that can be mutually compared. This article not only provides steps that should be followed to make proper measurements, but also specifies appropriate parameters to characterize the IN when it is generated by a principal source. A detailed description of parameter calculation is presented, based on the recommendations of the International Telecommunication Union (ITU). This answers the request made in an ITU-R 214-4/3 question, which suggests determining the appropriate parameters to describe the noise when it has an impulsive characteristic.

Paper number 36:
Title: A sub-structuring approach for model reduction of frictionally clamped thin-walled structures
Authors: Patrick Hippold, Johann Gross, Malte Krack
Abstract: Thin-walled structures clamped by friction joints, such as aircraft skin panels are exposed to bending-stretching coupling and frictional contact. We propose an original sub-structuring approach, where the system is divided into thin-walled and support regions, so that geometrically nonlinear behavior is relevant only in the former, and nonlinear contact behavior only in the latter. This permits to derive reduced component models, in principle, with available techniques. The Hurty-/Craig-Bampton method, combined with an interface reduction relying on an orthogonal polynomial series, is used to construct the reduction basis for each component. To model geometrically nonlinear behavior, implicit condensation is used, where an original, engineering-oriented proposition is made for the delicate scaling of the static load cases required to estimate the coefficients of the nonlinear terms. The proposed method is validated and its computational performance is assessed for the example of a plate with frictional clamping, using finite element analysis as reference. The numerical results shed light into an interesting mutual interaction: The extent of geometric hardening is limited by the reduced boundary stiffness when more sliding occurs in the clamping. On the other hand, the frictional dissipation is increased by the tangential loading induced by membrane stretching.

Paper number 37:
Title: Improved Vessel Segmentation with Symmetric Rotation-Equivariant U-Net
Authors: Jiazhen Zhang, Yuexi Du, Nicha C. Dvornek, John A. Onofrey
Abstract: Automated segmentation plays a pivotal role in medical image analysis and computer-assisted interventions. Despite the promising performance of existing methods based on convolutional neural networks (CNNs), they neglect useful equivariant properties for images, such as rotational and reflection equivariance. This limitation can decrease performance and lead to inconsistent predictions, especially in applications like vessel segmentation where explicit orientation is absent. While existing equivariant learning approaches attempt to mitigate these issues, they substantially increase learning cost, model size, or both. To overcome these challenges, we propose a novel application of an efficient symmetric rotation-equivariant (SRE) convolutional (SRE-Conv) kernel implementation to the U-Net architecture, to learn rotation and reflection-equivariant features, while also reducing the model size dramatically. We validate the effectiveness of our method through improved segmentation performance on retina vessel fundus imaging. Our proposed SRE U-Net not only significantly surpasses standard U-Net in handling rotated images, but also outperforms existing equivariant learning methods and does so with a reduced number of trainable parameters and smaller memory cost. The code is available at this https URL.

Paper number 38:
Title: Characterisation of exposure to non-ionising electromagnetic fields in the Spanish INMA birth cohort: Study protocol
Authors: M. Gallastegi, M. Guxens, A. Jimenez-Zabala, I. Calvente, M. Fernandez, L. Birks, B. Struchen, M. Vrijheid, M. Estarlich, M.F. Fernandez, M. Torrent, F. Ballester, J.J. Aurrekoetxea, J. Ibarluzea, D. Guerra, J. Gonzalez, M. Roosli, L. Santa-Marina
Abstract: Analysis of the association between exposure to electromagnetic fields of non-ionising radiation (EMF-NIR) and health in children and adolescents is hindered by the limited availability of data, mainly due to the difficulties on the exposure assessment. This study protocol describes the methodologies used for characterising exposure of children to EMF-NIR in the INMA (INfancia y Medio Ambiente- Environment and Childhood) Project, a prospective cohort study. Indirect (proximity to emission sources, questionnaires on sources use and geospatial propagation models) and direct methods (spot and fixed longer-term measurements and personal measurements) were conducted in order to assess exposure levels of study participants aged between 7 and 18 years old. The methodology used varies depending on the frequency of the EMF-NIR and the environment (homes, schools and parks). Questionnaires assessed the use of sources contributing both to Extremely Low Frequency (ELF) and Radiofrequency (RF) exposure levels. Geospatial propagation models (NISMap) are implemented and validated for environmental outdoor sources of RFs using spot measurements. Spot and fixed longer-term ELF and RF measurements were done in the environments where children spend most of the time. Moreover, personal measurements were taken in order to assess individual exposure to RF. The exposure data are used to explore their relationships with proximity and/or use of EMF-NIR sources.

Paper number 39:
Title: Joint Precoder and Reflector Design for RIS-assisted Multi-user OAM Communication Systems
Authors: Xiaoyan Ma, Yufei Zhao, Haixia Zhang, Yong Liang Guan, Chau Yuen
Abstract: Orbital angular momentum (OAM) can enhance the spectral efficiency by multiplying a set of orthogonal modes on the same frequency channel. To maintain the orthogonal among different OAM modes, perfect alignments between transmitters and receivers are strictly required. However, in multi-user OAM communications, the perfect alignments between the transmitter and all the receivers are impossible. The phase turbulence, caused by misaligned transmitters and receivers, leads to serious inter-mode interference, which greatly degrades the capacity of OAM transmissions. To eliminate the negative effects of phase turbulence and further enhance the transmission capacity, we introduce RIS into the system, and propose a joint precoder and reflector design for reconfigurable intelligent surface (RIS)-assisted multi-user OAM communication systems. Specifically, we propose a three-layer design at the transmitter side, which includes inter-user OAM mode interference cancellation, inter-mode self-interference elimination and the power allocation among different users. By analyzing the characteristics of the overall channels, we are able to give the specific expressions of the precoder designs, which significantly reduce the optimization complexity. We further leverage RIS to guarantee the line-ofsight (LoS) transmissions between the transmitter and users for better sum rate performance. To verify the superiority of the proposed multi-user OAM transmission system, we compare it with traditional MIMO transmission schemes, numerical results have shown that our proposed design can achieve better sum rate performance due to the well-designed orthogonality among different users and OAM modes.

Paper number 40:
Title: Predictive Position Estimation for Remote Surgery under Packet Loss Using the Informer Framework
Authors: Muhammad Hanif Lashari, Shakil Ahmed, Wafa Batayneh, Ashfaq Khokhar
Abstract: Accurate and real-time position estimation of the robotic arm on the patient's side is crucial for the success of remote robotic surgery in Tactile Internet environments. This paper proposes a predictive approach using the computationally efficient Transformer-based Informer model for position estimation, combined with a Four-State Hidden Markov Model (4-State HMM) to simulate realistic packet loss scenarios. The method effectively addresses network-induced delays, jitter, and packet loss, ensuring reliable performance in remote robotic surgery. The study evaluates the Informer model on the JIGSAWS dataset, demonstrating its capability to handle sequential data challenges caused by network uncertainties. Key features, including ProbSparse attention and a generative-style decoder, enhance prediction accuracy, computational speed, and memory efficiency. Results indicate that the proposed method achieves over 90 percent accuracy across varying network conditions. Furthermore, the Informer framework outperforms traditional models such as TCN, RNN, and LSTM, highlighting its suitability for real-time remote surgery applications.

Paper number 41:
Title: Gaussian-Process-based Adaptive Tracking Control with Dynamic Active Learning for Autonomous Ground Vehicles
Authors: Kristóf Floch, Tamás Péni, Roland Tóth
Abstract: This article proposes an active-learning-based adaptive trajectory tracking control method for autonomous ground vehicles to compensate for modeling errors and unmodeled dynamics. The nominal vehicle model is decoupled into lateral and longitudinal subsystems, which are augmented with online Gaussian Processes (GPs), using measurement data. The estimated mean functions of the GPs are used to construct a feedback compensator, which, together with an LPV state feedback controller designed for the nominal system, gives the adaptive control structure. To assist exploration of the dynamics, the paper proposes a new, dynamic active learning method to collect the most informative samples to accelerate the training process. To analyze the performance of the overall learning tool-chain provided controller, a novel iterative, counterexample-based algorithm is proposed for calculating the induced L2 gain between the reference trajectory and the tracking error. The analysis can be executed for a set of possible realizations of the to-be-controlled system, giving robust performance certificate of the learning method under variation of the vehicle dynamics. The efficiency of the proposed control approach is shown on a high-fidelity physics simulator and in real experiments using a 1/10 scale F1TENTH electric car.

Paper number 42:
Title: Channel-Aware Constellation Design for Digital OTA Computation
Authors: Zeyang Li, Chen Chen, Carlo Fischione
Abstract: Over-the-air (OTA) computation has emerged as a promising technique for efficiently aggregating data from massive numbers of wireless devices. OTA computations can be performed by analog or digital communications. Analog OTA systems are often constrained by limited function adaptability and their reliance on analog amplitude modulation. On the other hand, digital OTA systems may face limitations such as high computational complexity and limited adaptability to varying network configurations. To address these challenges, this paper proposes a novel digital OTA computation system with a channel-aware constellation design for demodulation mappers. The proposed system dynamically adjusts the constellation based on the channel conditions of participating nodes, enabling reliable computation of various functions. By incorporating channel randomness into the constellation design, the system prevent overlap of constellation points, reduces computational complexity, and mitigates excessive transmit power consumption under poor channel conditions. Numerical results demonstrate that the system achieves reliable NMSE performance across a range of scenarios, offering valuable insights into the choice of signal processing methods and weighting strategies under varying computation point configurations, node counts, and quantization levels. This work advances the state of digital OTA computation by addressing critical challenges in scalability, transmit power consumption, and function adaptability.

Paper number 43:
Title: Diffusion based Text-to-Music Generationwith Global and Local Text based Conditioning
Authors: Jisi Zhang, Pablo Peso Parada, Md Asif Jalal, Karthikeyan Saravanan
Abstract: Diffusion based Text-To-Music (TTM) models generate music corresponding to text descriptions. Typically UNet based diffusion models condition on text embeddings generated from a pre-trained large language model or from a cross-modality audio-language representation model. This work proposes a diffusion based TTM, in which the UNet is conditioned on both (i) a uni-modal language model (e.g., T5) via cross-attention and (ii) a cross-modal audio-language representation model (e.g., CLAP) via Feature-wise Linear Modulation (FiLM). The diffusion model is trained to exploit both a local text representation from the T5 and a global representation from the CLAP. Furthermore, we propose modifications that extract both global and local representations from the T5 through pooling mechanisms that we call mean pooling and self-attention pooling. This approach mitigates the need for an additional encoder (e.g., CLAP) to extract a global representation, thereby reducing the number of model parameters. Our results show that incorporating the CLAP global embeddings to the T5 local embeddings enhances text adherence (KL=1.47) compared to a baseline model solely relying on the T5 local embeddings (KL=1.54). Alternatively, extracting global text embeddings directly from the T5 local embeddings through the proposed mean pooling approach yields superior generation quality (FAD=1.89) while exhibiting marginally inferior text adherence (KL=1.51) against the model conditioned on both CLAP and T5 text embeddings (FAD=1.94 and KL=1.47). Our proposed solution is not only efficient but also compact in terms of the number of parameters required.

Paper number 44:
Title: Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST
Authors: Fuping Wu, Bartlomiej W. Papiez
Abstract: Foundation models are widely employed in medical image analysis, due to their high adaptability and generalizability for downstream tasks. With the increasing number of foundation models being released, model selection has become an important issue. In this work, we study the capabilities of foundation models in medical image classification tasks by conducting a benchmark study on the MedMNIST dataset. Specifically, we adopt various foundation models ranging from convolutional to Transformer-based models and implement both end-to-end training and linear probing for all classification tasks. The results demonstrate the significant potential of these pre-trained models when transferred for medical image classification. We further conduct experiments with different image sizes and various sizes of training data. By analyzing all the results, we provide preliminary, yet useful insights and conclusions on this topic.

Paper number 45:
Title: Decision-Focused Learning for Complex System Identification: HVAC Management System Application
Authors: Pietro Favaro, Jean-François Toubeau, François Vallée, Yury Dvorkin
Abstract: As opposed to conventional training methods tailored to minimize a given statistical metric or task-agnostic loss (e.g., mean squared error), Decision-Focused Learning (DFL) trains machine learning models for optimal performance in downstream decision-making tools. We argue that DFL can be leveraged to learn the parameters of system dynamics, expressed as constraint of the convex optimization control policy, while the system control signal is being optimized, thus creating an end-to-end learning framework. This is particularly relevant for systems in which behavior changes once the control policy is applied, hence rendering historical data less applicable. The proposed approach can perform system identification - i.e., determine appropriate parameters for the system analytical model - and control simultaneously to ensure that the model's accuracy is focused on areas most relevant to control. Furthermore, because black-box systems are non-differentiable, we design a loss function that requires solely to measure the system response. We propose pre-training on historical data and constraint relaxation to stabilize the DFL and deal with potential infeasibilities in learning. We demonstrate the usefulness of the method on a building Heating, Ventilation, and Air Conditioning day-ahead management system for a realistic 15-zone building located in Denver, US. The results show that the conventional RC building model, with the parameters obtained from historical data using supervised learning, underestimates HVAC electrical power consumption. For our case study, the ex-post cost is on average six times higher than the expected one. Meanwhile, the same RC model with parameters obtained via DFL underestimates the ex-post cost only by 3%.

Paper number 46:
Title: Gland Segmentation Using SAM With Cancer Grade as a Prompt
Authors: Yijie Zhu, Shan E Ahmed Raza
Abstract: Cancer grade is a critical clinical criterion that can be used to determine the degree of cancer malignancy. Revealing the condition of the glands, a precise gland segmentation can assist in a more effective cancer grade classification. In machine learning, binary classification information about glands (i.e., benign and malignant) can be utilized as a prompt for gland segmentation and cancer grade classification. By incorporating prior knowledge of the benign or malignant classification of the gland, the model can anticipate the likely appearance of the target, leading to better segmentation performance. We utilize Segment Anything Model to solve the segmentation task, by taking advantage of its prompt function and applying appropriate modifications to the model structure and training strategies. We improve the results from fine-tuned Segment Anything Model and produce SOTA results using this approach.

Paper number 47:
Title: Communication-Based Distributed Control of Large-Scale District Heating Networks
Authors: Audrey Blizard, Stephanie Stockar
Abstract: This paper presents a non-cooperative distributed model predictive controller for the control of large-scale District Heating Networks. To enable the design of this controller a novel information passing scheme and feasibility restoration method are created, allowing the local controllers to achieve a global consensus while minimizing a local cost function. The effectiveness of this controller is demonstrated on an 18-user District Heating Network decomposed into six subsystems. The results show that the developed control scheme effectively uses flexibility to manage the buildings' heat demands reducing the total losses by 14% and the return temperature by 37%.

Paper number 48:
Title: Estimation-theoretic analysis of lensless imaging
Authors: Leyla A. Kabuli, Nalini M. Singh, Laura Waller
Abstract: We analyze lensless imaging systems with estimation-theoretic techniques based on Fisher information. Our analysis evaluates multiple optical encoder designs on objects with varying sparsity, in the context of both Gaussian and Poisson noise models. Our simulations verify that lensless imaging system performance is object-dependent and highlight tradeoffs between encoder multiplexing and object sparsity, showing quantitatively that sparse objects tolerate higher levels of multiplexing than dense objects. Insights from our analysis promise to inform and improve optical encoder designs for lensless imaging.

Paper number 49:
Title: Adaptive Cyber-Attack Detection in IIoT Using Attention-Based LSTM-CNN Models
Authors: Afrah Gueriani, Hamza Kheddar, Ahmed Cherif Mazari
Abstract: The rapid expansion of the industrial Internet of things (IIoT) has introduced new challenges in securing critical infrastructures against sophisticated cyberthreats. This study presents the development and evaluation of an advanced Intrusion detection (IDS) based on a hybrid LSTM-convolution neural network (CNN)-Attention architecture, specifically designed to detect and classify cyberattacks in IIoT environments. The research focuses on two key classification tasks: binary and multi-class classification. The proposed models was rigorously tested using the Edge-IIoTset dataset. To mitigate the class imbalance in the dataset, the synthetic minority over-sampling technique (SMOTE) was employed to generate synthetic samples for the underrepresented classes. This ensured that the model could learn effectively from all classes, thereby improving the overall classification performance. Through systematic experimentation, various deep learning (DL) models were compared, ultimately demonstrating that the LSTM-CNN-Attention model consistently outperformed others across key performance metrics. In binary classification, the model achieved near-perfect accuracy, while in multi-class classification, it maintained a high accuracy level (99.04%), effectively categorizing different attack types with a loss value of 0.0220%.

Paper number 50:
Title: Triplet Synthesis For Enhancing Composed Image Retrieval via Counterfactual Image Generation
Authors: Kenta Uesugi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama
Abstract: Composed Image Retrieval (CIR) provides an effective way to manage and access large-scale visual data. Construction of the CIR model utilizes triplets that consist of a reference image, modification text describing desired changes, and a target image that reflects these changes. For effectively training CIR models, extensive manual annotation to construct high-quality training datasets, which can be time-consuming and labor-intensive, is required. To deal with this problem, this paper proposes a novel triplet synthesis method by leveraging counterfactual image generation. By controlling visual feature modifications via counterfactual image generation, our approach automatically generates diverse training triplets without any manual intervention. This approach facilitates the creation of larger and more expressive datasets, leading to the improvement of CIR model's performance.

Paper number 51:
Title: GS-LiDAR: Generating Realistic LiDAR Point Clouds with Panoramic Gaussian Splatting
Authors: Junzhe Jiang, Chun Gu, Yurui Chen, Li Zhang
Abstract: LiDAR novel view synthesis (NVS) has emerged as a novel task within LiDAR simulation, offering valuable simulated point cloud data from novel viewpoints to aid in autonomous driving systems. However, existing LiDAR NVS methods typically rely on neural radiance fields (NeRF) as their 3D representation, which incurs significant computational costs in both training and rendering. Moreover, NeRF and its variants are designed for symmetrical scenes, making them ill-suited for driving scenarios. To address these challenges, we propose GS-LiDAR, a novel framework for generating realistic LiDAR point clouds with panoramic Gaussian splatting. Our approach employs 2D Gaussian primitives with periodic vibration properties, allowing for precise geometric reconstruction of both static and dynamic elements in driving scenarios. We further introduce a novel panoramic rendering technique with explicit ray-splat intersection, guided by panoramic LiDAR supervision. By incorporating intensity and ray-drop spherical harmonic (SH) coefficients into the Gaussian primitives, we enhance the realism of the rendered point clouds. Extensive experiments on KITTI-360 and nuScenes demonstrate the superiority of our method in terms of quantitative metrics, visual quality, as well as training and rendering efficiency.

Paper number 52:
Title: Enhanced PEC-YOLO for Detecting Improper Safety Gear Wearing Among Power Line Workers
Authors: Chen Zuguo, Kuang Aowei, Huang Yi, Jin Jie
Abstract: To address the high risks associated with improper use of safety gear in complex power line environments, where target occlusion and large variance are prevalent, this paper proposes an enhanced PEC-YOLO object detection algorithm. The method integrates deep perception with multi-scale feature fusion, utilizing PConv and EMA attention mechanisms to enhance feature extraction efficiency and minimize model complexity. The CPCA attention mechanism is incorporated into the SPPF module, improving the model's ability to focus on critical information and enhance detection accuracy, particularly in challenging conditions. Furthermore, the introduction of the BiFPN neck architecture optimizes the utilization of low-level and high-level features, enhancing feature representation through adaptive fusion and context-aware mechanism. Experimental results demonstrate that the proposed PEC-YOLO achieves a 2.7% improvement in detection accuracy compared to YOLOv8s, while reducing model parameters by 42.58%. Under identical conditions, PEC-YOLO outperforms other models in detection speed, meeting the stringent accuracy requirements for safety gear detection in construction sites. This study contributes to the development of efficient and accurate intelligent monitoring systems for ensuring worker safety in hazardous environments.

Paper number 53:
Title: Scalable and Explainable Verification of Image-based Neural Network Controllers for Autonomous Vehicles
Authors: Aditya Parameshwaran, Yue Wang
Abstract: Existing formal verification methods for image-based neural network controllers in autonomous vehicles often struggle with high-dimensional inputs, computational inefficiency, and a lack of explainability. These challenges make it difficult to ensure safety and reliability, as processing high-dimensional image data is computationally intensive and neural networks are typically treated as black boxes. To address these issues, we propose \textbf{SEVIN} (Scalable and Explainable Verification of Image-Based Neural Network Controllers), a framework that leverages a Variational Autoencoders (VAE) to encode high-dimensional images into a lower-dimensional, explainable latent space. By annotating latent variables with corresponding control actions, we generate convex polytopes that serve as structured input spaces for verification, significantly reducing computational complexity and enhancing scalability. Integrating the VAE's decoder with the neural network controller allows for formal and robustness verification using these explainable polytopes. Our approach also incorporates robustness verification under real-world perturbations by augmenting the dataset and retraining the VAE to capture environmental variations. Experimental results demonstrate that SEVIN achieves efficient and scalable verification while providing explainable insights into controller behavior, bridging the gap between formal verification techniques and practical applications in safety-critical systems.

Paper number 54:
Title: INDIGO+: A Unified INN-Guided Probabilistic Diffusion Algorithm for Blind and Non-Blind Image Restoration
Authors: Di You, Pier Luigi Dragotti
Abstract: Generative diffusion models are becoming one of the most popular prior in image restoration (IR) tasks due to their remarkable ability to generate realistic natural images. Despite achieving satisfactory results, IR methods based on diffusion models present several limitations. First of all, most non-blind approaches require an analytical expression of the degradation model to guide the sampling process. Secondly, most existing blind approaches rely on families of pre-defined degradation models for training their deep networks. The above issues limit the flexibility of these approaches and so their ability to handle real-world degradation tasks. In this paper, we propose a novel INN-guided probabilistic diffusion algorithm for non-blind and blind image restoration, namely INDIGO and BlindINDIGO, which combines the merits of the perfect reconstruction property of invertible neural networks (INN) with the strong generative capabilities of pre-trained diffusion models. Specifically, we train the forward process of the INN to simulate an arbitrary degradation process and use the inverse to obtain an intermediate image that we use to guide the reverse diffusion sampling process through a gradient step. We also introduce an initialization strategy, to further improve the performance and inference speed of our algorithm. Experiments demonstrate that our algorithm obtains competitive results compared with recently leading methods both quantitatively and visually on synthetic and real-world low-quality images.

Paper number 55:
Title: Some Applications envisaged for the new generation of communications networks 6G
Authors: Sofiane Latreche, Hocine Bellahsene, Abdelmalik Taleb-Ahmed
Abstract: Future applications such as intelligent vehicles, the Internet of Things and holographic telepresence are already highlighting the limits of existing fifth-generation (5G) mobile networks. These limitations relate to data throughput, latency, reliability, availability, processing, connection density and global coverage, whether terrestrial, submarine or space-based. To remedy this, research institutes have begun to look beyond IMT2020, and as a result, 6G should provide effective solutions to 5G shortcomings. 6G will offer high quality of service and energy efficiency to meet the demands of future applications that are unimaginable to most people. In this article, we present the future applications and services promised by 6G.

Paper number 56:
Title: Development of a Validation and Inspection Tool for Armband-based Lifelog Data (VITAL) to Facilitate the Clinical Use of Wearable Data: A Prototype and Usability Evaluation
Authors: Im Eunyoung, Kang Sunghoon, Kim Hyeoneui
Abstract: Background: The rise of mobile technology and health apps has increased the use of person-generated health data (PGHD). PGHD holds significant potential for clinical decision-making but remains challenging to manage. Objective: This study aimed to enhance the clinical utilization of wearable health data by developing the Validation and Inspection Tool for Armband-Based Lifelog Data (VITAL), a pipeline for data integration, visualization, and quality management, and evaluating its usability. Methods: The study followed a structured process of requirement gathering, tool implementation, and usability evaluation. Requirements were identified through input from four clinicians. Wearable health data from Samsung, Apple, Fitbit, and Xiaomi devices were integrated into a standardized dataframe at 10-minute intervals, focusing on biometrics, activity, and sleep. Features of VITAL support data integration, visualization, and quality management. Usability evaluation involved seven clinicians performing tasks, completing the Unified Theory of Acceptance and Use of Technology (UTAUT) survey, and participating in interviews to identify usability issues. Results: VITAL successfully integrated wearable data, thus enabling all participants to complete tasks with minimal errors without prior participant training. UTAUT survey results were positive, with average scores of 4.2 for performance expectancy, 3.96 for effort expectancy, and 4.14 for intention to use, indicating high user satisfaction and intent to adopt the tool. Conclusions: By enhancing wearable data integration, visualization, and quality management, the VITAL prototype shows significant potential for clinical application. Positive feedback highlights its promise, while emphasizing the need for further studies to confirm its real-world effectiveness.

Paper number 57:
Title: Constrained Fuel and Time Optimal 6DOF Powered Descent Guidance Using Indirect Optimization
Authors: Nicholas P. Nurre, Ehsan Taheri
Abstract: Powered descent guidance (PDG) problems subject to six-degrees-of-freedom (6DOF) dynamics allow for enforcement of practical attitude constraints. However, numerical solutions to 6DOF PDG problems are challenging due to fast rotational dynamics coupled with translational dynamics, and the presence of highly nonlinear state/control path inequality constraints. In this work, constrained fuel- and time-optimal 6DOF PDG problems are solved leveraging a regularized indirect method, subject to inequality constraints on the thrust magnitude, thruster gimbal angle, rocket tilt angle, glideslope angle, and angular velocity magnitude. To overcome the challenges associated with solving the resulting multipoint boundary-value problems (MPBVPs), the state-only path inequality constraints (SOPICs) are enforced through an interior penalty function method, which embeds the resulting MPBVPs into a multi-parameter smooth neighboring families of two-point BVPs. Extremal solutions are obtained using an indirect multiple-shooting solution method with numerical continuation. Moreover, an empirical relation is derived for the directly-adjoined Lagrange multipliers associated with SOPICs. The fuel- and time-optimal trajectories are compared against solutions of DIDO -- a capable pseudospectral-based software for solving practical constrained optimal control problems.

Paper number 58:
Title: Correlation-Based Band Selection for Hyperspectral Image Classification
Authors: Dibyabha Deb, Ujjwal Verma
Abstract: Hyperspectral images offer extensive spectral information about ground objects across multiple spectral bands. However, the large volume of data can pose challenges during processing. Typically, adjacent bands in hyperspectral data are highly correlated, leading to the use of only a few selected bands for various applications. In this work, we present a correlation-based band selection approach for hyperspectral image classification. Our approach calculates the average correlation between bands using correlation coefficients to identify the relationships among different bands. Afterward, we select a subset of bands by analyzing the average correlation and applying a threshold-based method. This allows us to isolate and retain bands that exhibit lower inter-band dependencies, ensuring that the selected bands provide diverse and non-redundant information. We evaluate our proposed approach on two standard benchmark datasets: Pavia University (PA) and Salinas Valley (SA), focusing on image classification tasks. The experimental results demonstrate that our method performs competitively with other standard band selection approaches.

Paper number 59:
Title: Joint System Latency and Data Freshness Optimization for Cache-enabled Mobile Crowdsensing Networks
Authors: Kexin Shi, Yaru Fu, Yongna Guo, Fu Lee Wang, Yan Zhang
Abstract: Mobile crowdsensing (MCS) networks enable large-scale data collection by leveraging the ubiquity of mobile devices. However, frequent sensing and data transmission can lead to significant resource consumption. To mitigate this issue, edge caching has been proposed as a solution for storing recently collected data. Nonetheless, this approach may compromise data freshness. In this paper, we investigate the trade-off between re-using cached task results and re-sensing tasks in cache-enabled MCS networks, aiming to minimize system latency while maintaining information freshness. To this end, we formulate a weighted delay and age of information (AoI) minimization problem, jointly optimizing sensing decisions, user selection, channel selection, task allocation, and caching strategies. The problem is a mixed-integer non-convex programming problem which is intractable. Therefore, we decompose the long-term problem into sequential one-shot sub-problems and design a framework that optimizes system latency, task sensing decision, and caching strategy subproblems. When one task is re-sensing, the one-shot problem simplifies to the system latency minimization problem, which can be solved optimally. The task sensing decision is then made by comparing the system latency and AoI. Additionally, a Bayesian update strategy is developed to manage the cached task results. Building upon this framework, we propose a lightweight and time-efficient algorithm that makes real-time decisions for the long-term optimization problem. Extensive simulation results validate the effectiveness of our approach.

Paper number 60:
Title: New scenarios and trends in non-traditional laboratories from 2000 to 2020
Authors: Ricardo M. Fernandez, Felix Garcia-Loro, Gustavo Alves, Africa Lopez-Rey, Russ Meier, Manuel Castro
Abstract: For educational institutions in STEM areas, the provision of practical learning scenarios is, traditionally, a major concern. In the 21st century, the explosion of ICTs, as well as the universalization of low-cost hardware, have allowed the proliferation of technical solutions for any field; in the case of experimentation, encouraging the emergence and proliferation of non-traditional experimentation platforms. This movement has resulted in enriched practical environments, with wider adaptability for both students and teachers. In this paper, the evolution of scholar production has been analyzed at the global level from 2000 to 2020. Current and emerging experimentation scenarios have been identified, specifying the scope and boundaries between them.

Paper number 61:
Title: On the Rate-Exponent Region of Integrated Sensing and Communications With Variable-Length Coding
Authors: Ioannis Papoutsidakis, George C. Alexandropoulos
Abstract: This paper considers the achievable rate-exponent region of integrated sensing and communication systems in the presence of variable-length coding with feedback. This scheme is fundamentally different from earlier studies, as the coding methods that utilize feedback impose different constraints on the codewords. The focus herein is specifically on the Gaussian channel, where three achievable regions are analytically derived and numerically evaluated. In contrast to a setting without feedback, we show that a trade-off exists between the operations of sensing and communications.

Paper number 62:
Title: Robustified Time-optimal Point-to-point Motion Planning and Control under Uncertainty
Authors: Shuhao Zhang, Jan Swevers
Abstract: This paper proposes a novel approach to formulate time-optimal point-to-point motion planning and control under uncertainty. The approach defines a robustified two-stage Optimal Control Problem (OCP), in which stage 1, with a fixed time grid, is seamlessly stitched with stage 2, which features a variable time grid. Stage 1 optimizes not only the nominal trajectory, but also feedback gains and corresponding state covariances, which robustify constraints in both stages. The outcome is a minimized uncertainty in stage 1 and a minimized total motion time for stage 2, both contributing to the time optimality and safety of the total motion. A timely replanning strategy is employed to handle changes in constraints and maintain feasibility, while a tailored iterative algorithm is proposed for efficient, real-time OCP execution.

Paper number 63:
Title: Next-Generation Wireless: Tracking the Evolutionary Path of 6G Mobile Communication
Authors: Ekram Hossain, Angelo Vera-Rivera
Abstract: The mobile communications industry is lighting-fast machinery, and discussions about 6G technologies have already begun. In this article, we intend to take the readers on a journey to discover 6G and its evolutionary stages. The journey starts with an overview of the technical constraints of 5G prompting the need for a new generation of mobile systems. The initial discussion is followed by an examination of the 6G vision, use cases, technical requirements, technology enablers, and potential network architecture. We conclude the discussion by reviewing the transformative opportunities of this technology in society, businesses and industries, along with the anticipated technological limitations of the network that will drive the development of further mobile generations. Our goal is to deliver a friendly, informative, precise, and engaging narrative that could give readers a panoramic overview of this important topic.

Paper number 64:
Title: Dynamic Operation and Control of a Multi-Stack Alkaline Water Electrolysis System with Shared Gas Separators and Lye Circulation: A Model-Based Study
Authors: Yiwei Qiu (1), Jiatong Li (1), Yangjun Zeng (1), Yi Zhou (1), Shi Chen (1), Xiaoyan Qiu (1), Buxiang Zhou (1), Ge He,  (2), Xu Ji,  (2), Wenying Li (3),  ((1) College of Electrical Engineering, Sichuan University, (2) School of Chemical Engineering, Sichuan University, (3) Sichuan Tsinghua Energy Internet Research Institute)
Abstract: An emerging approach for large-scale hydrogen production using renewable energy is to integrate multiple alkaline water electrolysis (AWE) stacks into a single balance of plant (BoP) system, sharing components such as gas-lye separation and lye circulation. This configuration, termed the $N$-in-1 AWE system, packs $N$ stacks into a modular system, reducing land requirements, the complexity of plant topology, and overall capital costs. However, the coupling of these stacks through the shared BoP introduces challenges in dynamic operation under varying energy inputs, making their performance unclear compared to traditional 1-in-1 systems. To address this, we develop a state-space model of the $N$-in-1 AWE system, capturing the dynamic behaviors of lye circulation, temperature, and HTO impurity, and their impact on energy conversion efficiency. We then propose a nonlinear model predictive controller (NMPC) to coordinately optimize inter-stack electrolytic current distribution, lye flow, and cooling, enabling the system to dynamically track varying load commands while maximizing efficiency, stabilizing temperature, and limiting HTO impurity accumulation. Simulation studies on a 4,000 Nm$^3$/h-rated 4-in-1 system verify the proposed controller under dynamic operation. Comparison with 4 independent 1-in-1 systems reveals that, with proper control, the $N$-in-1 configuration offers comparable flexibility in accommodating real-world wind power inputs. The average differences in the root-mean-square errors (RMSEs) for load-tracking and stack temperature stabilization, and specific energy consumption are below 0.014 MW, 2.356 K, and 0.003 kWh/Nm$^3$.

Paper number 65:
Title: Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes
Authors: Feyisayo Olalere, Kiki van der Heijden, Christiaan H. Stronks, Jeroen Briaire, Johan HM Frijns, Marcel van Gerven
Abstract: Speech separation approaches for single-channel, dry speech mixtures have significantly improved. However, real-world spatial and reverberant acoustic environments remain challenging, limiting the effectiveness of these approaches for assistive hearing devices like cochlear implants (CIs). To address this, we quantify the impact of real-world acoustic scenes on speech separation and explore how spatial cues can enhance separation quality efficiently. We analyze performance based on implicit spatial cues (inherent in the acoustic input and learned by the model) and explicit spatial cues (manually calculated spatial features added as auxiliary inputs). Our findings show that spatial cues (both implicit and explicit) improve separation for mixtures with spatially separated and nearby talkers. Furthermore, spatial cues enhance separation when spectral cues are ambiguous, such as when voices are similar. Explicit spatial cues are particularly beneficial when implicit spatial cues are weak. For instance, single CI microphone recordings provide weaker implicit spatial cues than bilateral CIs, but even single CIs benefit from explicit cues. These results emphasize the importance of training models on real-world data to improve generalizability in everyday listening scenarios. Additionally, our statistical analyses offer insights into how data properties influence model performance, supporting the development of efficient speech separation approaches for CIs and other assistive devices in real-world settings.

Paper number 66:
Title: Channel Independent Precoder for OFDM-based Systems over Fading Channels
Authors: Jorge Ortin, Paloma Garcia, Fernando Gutierrez, Antonio Valdovinos
Abstract: In this paper we propose an independent channel precoder for orthogonal frequency division multiplexing (OFDM) systems over fading channels. The design of the precoder is based on the information redistribution of the input modulated symbols amongst the output precoded symbols. The proposed precoder decreases the variance of the instantaneous noise power at the receiver produced by the channel variability. The employment of an interleaver together with a precoding matrix whose size does not depend on the number of data carriers in an OFDM symbol allows different configurations of time-frequency diversity which can be easily adapted to the channel conditions. The precoder is evaluated with a modified Zero Forcing (ZF) equalizer whose maximum gain is constrained by means of a clipping factor. Thus, the clipping factor limits the noise power transfer in the receiver deprecoding block in low SNR conditions.

Paper number 67:
Title: Predictor-Feedback Stabilization of Globally Lipschitz Nonlinear Systems with State and Input Quantization
Authors: Florent Koudohode, Nikolaos Bekiaris-Liberis
Abstract: We develop a switched nonlinear predictor-feedback control law to achieve global asymptotic stabilization for nonlinear systems with arbitrarily long input delay, under state quantization. The proposed design generalizes the nonlinear predictor-feedback framework by incorporating quantized measurements of both the plant and actuator states into the predictor state formulation. Due to the mismatch between the (inapplicable) exact predictor state and the predictor state constructed in the presence of state quantization, a global stabilization result is possible under a global Lipschitzness assumption on the vector field, as well as under the assumption of existence of a globally Lipschitz, nominal feedback law that achieves global exponential stability of the delay and quantization-free system. To address the constraints imposed by quantization, a dynamic switching strategy is constructed, adjusting the quantizer's tunable parameter in a piecewise constant manner-initially increasing the quantization range, to capture potentially large system states and subsequently refining the precision to reduce quantization error. The global asymptotic stability of the closed-loop system is established through solutions estimates derived using backstepping transformations, combined with small-gain and input-to-state stability arguments. We also extend our approach to the case of input quantization.

Paper number 68:
Title: Enhanced Confocal Laser Scanning Microscopy with Adaptive Physics Informed Deep Autoencoders
Authors: Zaheer Ahmad, Junaid Shabeer, Usman Saleem, Tahir Qadeer, Abdul Sami, Zahira El Khalidi, Saad Mehmood
Abstract: We present a physics-informed deep learning framework to address common limitations in Confocal Laser Scanning Microscopy (CLSM), such as diffraction limited resolution, noise, and undersampling due to low laser power conditions. The optical system's point spread function (PSF) and common CLSM image degradation mechanisms namely photon shot noise, dark current noise, motion blur, speckle noise, and undersampling were modeled and were directly included into model architecture. The model reconstructs high fidelity images from heavily noisy inputs by using convolutional and transposed convolutional layers. Following the advances in compressed sensing, our approach significantly reduces data acquisition requirements without compromising image resolution. The proposed method was extensively evaluated on simulated CLSM images of diverse structures, including lipid droplets, neuronal networks, and fibrillar systems. Comparisons with traditional deconvolution algorithms such as Richardson-Lucy (RL), non-negative least squares (NNLS), and other methods like Total Variation (TV) regularization, Wiener filtering, and Wavelet denoising demonstrate the superiority of the network in restoring fine structural details with high fidelity. Assessment metrics like Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR), underlines that the AdaptivePhysicsAutoencoder achieved robust image enhancement across diverse CLSM conditions, helping faster acquisition, reduced photodamage, and reliable performance in low light and sparse sampling scenarios holding promise for applications in live cell imaging, dynamic biological studies, and high throughput material characterization.

Paper number 69:
Title: Design and Implementation of an Efficient Onboard Computer System for CanSat Atmosphere Monitoring
Authors: Abhijit Gadekar
Abstract: With advancements in technology, the smaller versions of satellites have gained momentum in the space industry for earth monitoring and communication-based applications. The rise of CanSat technology has significantly impacted the space industry by providing a cost-effective solution for space exploration. CanSat is a simulation model of a real satellite and plays a crucial role in collecting and transmitting atmospheric data. This paper discusses the design of an Onboard Computer System forCanSat, used to study various environmental parameters by monitoring the concentrations of gases in the atmosphere. The Onboard Computer System uses GPS, accelerometer, altitude, temperature, pressure, gyroscope, magnetometer, UV radiation, and air quality sensors for atmospheric sensing. A highly efficient and low-power ESP32 microcontroller and a transceiver module are used to acquire data, facilitate seamless communication and transmit the collected data to the ground station.

Paper number 70:
Title: Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of Function Slices Approach
Authors: Guoming Li, Jian Yang, Shangsong Liang, Dongsheng Luo
Abstract: Spectral graph neural networks are proposed to harness spectral information inherent in graph-structured data through the application of polynomial-defined graph filters, recently achieving notable success in graph-based web applications. Existing studies reveal that various polynomial choices greatly impact spectral GNN performance, underscoring the importance of polynomial selection. However, this selection process remains a critical and unresolved challenge. Although prior work suggests a connection between the approximation capabilities of polynomials and the efficacy of spectral GNNs, there is a lack of theoretical insights into this relationship, rendering polynomial selection a largely heuristic process. To address the issue, this paper examines polynomial selection from an error-sum of function slices perspective. Inspired by the conventional signal decomposition, we represent graph filters as a sum of disjoint function slices. Building on this, we then bridge the polynomial capability and spectral GNN efficacy by proving that the construction error of graph convolution layer is bounded by the sum of polynomial approximation errors on function slices. This result leads us to develop an advanced filter based on trigonometric polynomials, a widely adopted option for approximating narrow signal slices. The proposed filter remains provable parameter efficiency, with a novel Taylor-based parameter decomposition that achieves streamlined, effective implementation. With this foundation, we propose TFGNN, a scalable spectral GNN operating in a decoupled paradigm. We validate the efficacy of TFGNN via benchmark node classification tasks, along with an example graph anomaly detection application to show its practical utility.

Paper number 71:
Title: Quasiperiodic Disturbance Observer for Wideband Harmonic Suppression
Authors: Hisayoshi Muramatsu
Abstract: Periodic disturbances composed of harmonics typically occur during periodic operations, impairing performance of mechanical and electrical systems. To improve the performance, control of periodic-disturbance suppression has been studied, such as repetitive control and periodic-disturbance observers. However, actual periodic disturbances are typically quasiperiodic owing to perturbations in each cycle, identification errors of the period, variations in the period, and/or aperiodic disturbances. For robustness against quasiperiodicity, although wideband harmonic suppression is expected, conventional methods have trade-offs among harmonic suppression bandwidth, amplification of aperiodic disturbances, and deviation of harmonic suppression frequencies. This paper proposes a quasiperiodic disturbance observer to compensate for quasiperiodic disturbances while simultaneously achieving the wideband harmonic suppression, non-amplification of aperiodic disturbances, and proper harmonic suppression frequencies. A quasiperiodic disturbance is defined as comprising harmonics and surrounding signals. On the basis of this definition, the quasiperiodic disturbance observer is designed using a periodic-pass filter of a first-order periodic/aperiodic separation filter for its Q-filter, time delay integrated with a zero-phase low-pass filter, and an inverse plant model with a first-order low-pass filter. The periodic-pass filter achieves the wideband harmonic suppression while the zero-phase and first-order low-pass filters prevent the amplification of aperiodic disturbances and deviation of harmonic suppression frequencies. For the implementation, the Q-filter is discretized by an exact mapping of the s-plane to the z-plane, and the inverse plant model is discretized by the backward Euler method. The experiments validated the frequency response and position-control precision of the proposed method.

Paper number 72:
Title: Desynchronization Index: a New Approach for Exploring Complex Epileptogenic Networks in Stereoelectroencephalography
Authors: Federico Mason, Lorenzo Ferri, Lidia Di Vito, Lara Alvisi, Luca Zanuttini, Matteo Martinoni, Roberto Mai, Francesco Cardinale, Paolo Tinuper, Roberto Michelucci, Elena Pasini, Francesca Bisulli
Abstract: Objective. In this work, we propose a new computational framework to assist neurophysiologists in Stereoelectroencephalography (SEEG) analysis, with the final aim of improving the definition of the Epileptogenic Zone (EZ) in patients with drug-resistant epilepsy. Method. We consider the Phase Transfer Entropy (PTE) model to estimate the effective connectivity between SEEG channels. Hence, we design an algorithm, named the Desynchronization Index (DI), that classifies as epileptogenic the channels that show independent behavior with respect to the rest of the network during the seconds preceding the seizure propagation. Results. We test the proposed DI algorithm against Epileptogenic Index (EI) on a clinical dataset of 11 patients, considering the neurophysiological evaluation of the EZ as the clinical ground truth. Our results denote that DI overcomes EI in terms of area under the ROC curve (AUC=0.80 vs AUC=0.74), while combining the two algorithms as a unique tool leads to the best performance (AUC=0.87). Conclusions. The DI algorithm underscores connectivity dynamics that can hardly be identified with a pure visual analysis, increasing the accuracy in the EZ definition compared to traditional methods. Significance. The integration of connectivity- and energy-based metrics, as the one we propose, can lead to the definition of a new effective biomarker of the EZ, reducing the burden required by the SEEG review in the case of extensive implants and improving our understanding of the dynamics leading to the generation of seizures.

Paper number 73:
Title: Language-Queried Target Sound Extraction Without Parallel Training Data
Authors: Hao Ma, Zhiyuan Peng, Xu Li, Yukai Li, Mingjie Shao, Qiuqiang Kong, Ju Liu
Abstract: Language-queried target sound extraction (TSE) aims to extract specific sounds from mixtures based on language queries. Traditional fully-supervised training schemes require extensively annotated parallel audio-text data, which are labor-intensive. We introduce a parallel-data-free training scheme, requiring only unlabelled audio clips for TSE model training by utilizing the contrastive language-audio pre-trained model (CLAP). In a vanilla parallel-data-free training stage, target audio is encoded using the pre-trained CLAP audio encoder to form a condition embedding, while during testing, user language queries are encoded by CLAP text encoder as the condition embedding. This vanilla approach assumes perfect alignment between text and audio embeddings, which is unrealistic. Two major challenges arise from training-testing mismatch: the persistent modality gap between text and audio and the risk of overfitting due to the exposure of rich acoustic details in target audio embedding during training. To address this, we propose a retrieval-augmented strategy. Specifically, we create an embedding cache using audio captions generated by a large language model (LLM). During training, target audio embeddings retrieve text embeddings from this cache to use as condition embeddings, ensuring consistent modalities between training and testing and eliminating information leakage. Extensive experiment results show that our retrieval-augmented approach achieves consistent and notable performance improvements over existing state-of-the-art with better generalizability.

Paper number 74:
Title: ElectricityEmissions.jl: A Framework for the Comparison of Carbon Intensity Signals
Authors: Joe Gorka, Noah Rhodes, Line Roald
Abstract: An increasing number of individuals, companies and organizations are interested in computing and minimizing the carbon emissions associated with their real-time electricity consumption. To achieve this, they require a carbon signal, i.e. a metric that defines the real-time carbon intensity of their electricity supply. Unfortunately, in a grid with multiple generation sources and multiple consumers, the physics of the system do not provide an unambiguous way to trace electricity from source to sink. As a result, there are a multitude of proposed carbon signals, each of which has a distinct set of properties and method of calculation. It remains unclear which signal best quantifies the carbon footprint of electricity. This paper seeks to inform the discussion about which carbon signal is better or more suitable for two important use cases, namely carbon-informed load shifting and carbon accounting. We do this by developing a new software package ElectricityEmissions$.$jl, that computes several established and newly proposed carbon emission metrics for standard electric grid test cases. We also demonstrate how the package can be used to investigate the effects of using these metrics to guide load shifting. Our results affirm previous research, which showed that the choice of carbon emission metric has significant impact on shifting results and associated carbon emission reductions. In addition, we demonstrate the impact of load shifting on both the consumers that perform the shifting and consumers that do not. Disconcertingly, we observe that shifting according to common metrics such as average carbon emissions can reduce the amount of emissions allocated to the consumer doing the shifting, while increasing the total emissions of the power system.

Paper number 75:
Title: Understanding the Impact of Evaluation Metrics in Kinetic Models for Consensus-based Segmentation
Authors: Raffaella Fiamma Cabini, Horacio Tettamanti, Mattia Zanella
Abstract: In this article we extend a recently introduced kinetic model for consensus-based segmentation of images. In particular, we will interpret the set of pixels of a 2D image as an interacting particle system which evolves in time in view of a consensus-type process obtained by interactions between pixels and external noise. Thanks to a kinetic formulation of the introduced model we derive the large time solution of the model. We will show that the choice of parameters defining the segmentation task can be chosen from a plurality of loss functions characterising the evaluation metrics.

Paper number 76:
Title: Localization Accuracy Improvement in Multistatic ISAC with LoS/NLoS Condition using 5G NR Signals
Authors: Keivan Khosroshahi, Philippe Sehier, Sami Mekki, Michael Suppa
Abstract: Integrated sensing and communication (ISAC) is anticipated to play a crucial role in sixth-generation (6G) mobile communication networks. A significant challenge in ISAC systems is the degradation of localization accuracy due to poor propagation conditions, such as multipath effects and non-line-of-sight (NLoS) scenarios. These conditions result in outlier measurements that can severely impact localization performance. This paper investigates the enhancement of target localization accuracy in multistatic ISAC systems under both line-of-sight (LoS) and NLoS conditions. We leverage positioning reference signal (PRS), which is currently employed in fifth-generation (5G) new radio (NR) for user equipment (UE) positioning, as the sensing signal. We introduce a novel algorithm to improve localization accuracy by mitigating the impact of outliers in range measurements, while also accounting for errors due to PRS range resolution. Eventually, through simulation results, we demonstrate the superiority of the proposed method over previous approaches. Indeed, we achieve up to 28% and 20% improvements in average localization error over least squares (LS) and iteratively reweighted least squares (IRLS) methods, respectively. Additionally, we observe up to 16% and 13% enhancements in the 90th percentile of localization error compared to LS and IRLS, respectively. Our simulation is based on 3rd Generation Partnership Project (3GPP) standards, ensuring the applicability of our results across diverse environments, including urban and indoor areas.

Paper number 77:
Title: Deep Learning Based Segmentation of Blood Vessels from H&E Stained Oesophageal Adenocarcinoma Whole-Slide Images
Authors: Jiaqi Lv, Stefan S Antonowicz, Shan E Ahmed Raza
Abstract: Blood vessels (BVs) play a critical role in the Tumor Micro-Environment (TME), potentially influencing cancer progression and treatment response. However, manually quantifying BVs in Hematoxylin and Eosin (H&E) stained images is challenging and labor-intensive due to their heterogeneous appearances. We propose a novel approach of constructing guiding maps to improve the performance of state-of-the-art segmentation models for BV segmentation, the guiding maps encourage the models to learn representative features of BVs. This is particularly beneficial for computational pathology, where labeled training data is often limited and large models are prone to overfitting. We have quantitative and qualitative results to demonstrate the efficacy of our approach in improving segmentation accuracy. In future, we plan to validate this method to segment BVs across various tissue types and investigate the role of cellular structures in relation to BVs in the TME.

Paper number 78:
Title: Joint Beamforming and Position Optimization for Fluid RIS-aided ISAC Systems
Authors: Junjie Ye, Peichang Zhang, Xiao-Peng Li, Lei Huang, Yuanwei Liu
Abstract: A fluid reconfigurable intelligent surface (fRIS)-aided integrated sensing and communications (ISAC) system is proposed to enhance multi-target sensing and multi-user communication. Unlike the conventional RIS, the fRIS incorporates movable elements whose positions can be flexibly adjusted to provide extra spatial degrees of freedom. In this system, a joint optimization problem is formulated to minimize sensing beampattern mismatch and communication symbol estimation error by optimizing the symbol estimator, transmit beamformer, fRIS phase shifts, and element positions. To solve this problem, an algorithm based on alternating minimization is devised, where subproblems are solved leveraging augmented Lagrangian method, quadratic programming, semidefinite-relaxation, and majorization-minimization techniques. A key challenge exists that the fRIS element positions affect both the incident and reflective channels, leading to the high-order composite functions regarding the positions. As a remedy, it is proved that the high-order terms can be transformed to linear and linear-difference forms using the characteristics of fRIS and structural channels, which facilitates the position optimization. Numerical results validate the effectiveness of the proposed scheme as compared to the conventional RIS-aided ISAC systems and other benchmarks.

Paper number 79:
Title: Skip-WaveNet: A Wavelet based Multi-scale Architecture to Trace Snow Layers in Radar Echograms
Authors: Debvrat Varshney, Masoud Yari, Oluwanisola Ibikunle, Jilu Li, John Paden, Aryya Gangopadhyay, Maryam Rahnemoonfar
Abstract: Airborne radar sensors capture the profile of snow layers present on top of an ice sheet. Accurate tracking of these layers is essential to calculate their thicknesses, which are required to investigate the contribution of polar ice cap melt to sea-level rise. However, automatically processing the radar echograms to detect the underlying snow layers is a challenging problem. In our work, we develop wavelet-based multi-scale deep learning architectures for these radar echograms to improve snow layer detection. These architectures estimate the layer depths with a mean absolute error of 3.31 pixels and 94.3% average precision, achieving higher generalizability as compared to state-of-the-art snow layer detection networks. These depth estimates also agree well with physically drilled stake measurements. Such robust architectures can be used on echograms from future missions to efficiently trace snow layers, estimate their individual thicknesses and thus support sea-level rise projection models.

Paper number 80:
Title: Exposure Bracketing Is All You Need For A High-Quality Image
Authors: Zhilu Zhang, Shuohao Zhang, Renlong Wu, Zifei Yan, Wangmeng Zuo
Abstract: It is highly desired but challenging to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus on specific restoration or enhancement problems, and do not fully explore the potential of utilizing multiple images. Motivated by the fact that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize exposure bracketing photography to get a high-quality image by combining these tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. Code and datasets are available at this https URL.

Paper number 81:
Title: Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering Tasks
Authors: Zihao Wang, Zhe Wu
Abstract: Computational efficiency and robustness are essential in process modeling, optimization, and control for real-world engineering applications. While neural network-based approaches have gained significant attention in recent years, conventional neural networks often fail to address these two critical aspects simultaneously or even independently. Inspired by natural physical systems and established literature, input convex architectures are known to enhance computational efficiency in optimization tasks, whereas Lipschitz-constrained architectures improve robustness. However, combining these properties within a single model requires careful review, as inappropriate methods for enforcing one property can undermine the other. To overcome this, we introduce a novel network architecture, termed Input Convex Lipschitz Recurrent Neural Networks (ICLRNNs). This architecture seamlessly integrates the benefits of convexity and Lipschitz continuity, enabling fast and robust neural network-based modeling and optimization. The ICLRNN outperforms existing recurrent units in both computational efficiency and robustness. Additionally, it has been successfully applied to practical engineering scenarios, such as modeling and control of chemical process and the modeling and real-world solar irradiance prediction for solar PV system planning at LHT Holdings in Singapore. Source code is available at this https URL.

Paper number 82:
Title: Hidden Markov Models and the Bayes Filter in Categorical Probability
Authors: Tobias Fritz, Andreas Klingler, Drew McNeely, Areeb Shah-Mohammed, Yuwen Wang
Abstract: We use Markov categories to generalize the basic theory of Markov chains and hidden Markov models to an abstract setting. This comprises characterizations of hidden Markov models in terms of conditional independences and algorithms for Bayesian filtering and smoothing applicable in all Markov categories with conditionals. When instantiated in appropriate Markov categories, these algorithms specialize to existing ones such as the Kalman filter, forward-backward algorithm, and the Rauch-Tung-Striebel smoother. We also prove that the sequence of outputs of our abstract Bayes filter is itself a Markov chain with a concrete formula for its transition maps. There are two main features of this categorical framework. The first is its abstract generality, as manifested in our unified account of hidden Markov models and algorithms for filtering and smoothing in discrete probability, Gaussian probability, measure-theoretic probability, possibilistic nondeterminism and others at the same time. The second feature is the intuitive visual representation of information flow in terms of string diagrams.

Paper number 83:
Title: Destructive and constructive RIS beamforming in an ISAC-multi-user MIMO network
Authors: Steven Rivetti, Ozlem Tugfe Demir, Emil Bjornson, Mikael Skoglund
Abstract: Integrated sensing and communication (ISAC) has already established itself as a promising solution to the spectrum scarcity problem, even more so when paired with a reconfigurable intelligent surface (RIS), as RISs can shape the propagation environment by adjusting their phase-shift coefficients. Albeit the potential performance gain, a RIS is also a potential security threat to the system. In this paper, we explore both the positive and negative sides of having a RIS in a multi-user multiple-input multiple-output (MIMO) ISAC network. We first develop an alternating optimization algorithm, obtaining the active and passive beamforming vectors that maximize the sensing signal-to-noise ratio (SNR) under minimum signal-to-interference-plus-noise ratio (SINR) constraints for the communication users and finite power budget. We also investigate the destructive potential of the RIS by devising a RIS phase-shift optimization algorithm that minimizes the sensing SNR while preserving the same minimum communication SINR previously guaranteed by the system. We further investigate the impact of the RIS's individual element failures on the system performance. The simulation results show that the RIS performance-boosting potential is as good as its destructive one and that both of our optimization strategies are hindered by the investigated impairments.

Paper number 84:
Title: SMRU: Split-and-Merge Recurrent-based UNet for Acoustic Echo Cancellation and Noise Suppression
Authors: Zhihang Sun, Andong Li, Rilin Chen, Hao Zhang, Meng Yu, Yi Zhou, Dong Yu
Abstract: The proliferation of deep neural networks has spawned the rapid development of acoustic echo cancellation and noise suppression, and plenty of prior arts have been proposed, which yield promising performance. Nevertheless, they rarely consider the deployment generality in different processing scenarios, such as edge devices, and cloud processing. To this end, this paper proposes a general model, termed SMRU, to cover different application scenarios. The novelty lies in two-fold. First, a multi-scale band split layer and band merge layer are proposed to effectively fuse local frequency bands for lower complexity modeling. Besides, by simulating the multi-resolution feature modeling characteristic of the classical UNet structure, a novel recurrent-dominated UNet is devised. It consists of multiple variable frame rate blocks, each of which involves the causal time down-/up-sampling layer with varying compression ratios and the dual-path structure for inter- and intra-band modeling. The model is configured from 50 M/s to 6.8 G/s in terms of MACs, and the experimental results show that the proposed approach yields competitive or even better performance over existing baselines, and has the full potential to adapt to more general scenarios with varying complexity requirements.

Paper number 85:
Title: Goal-Oriented Status Updating for Real-time Remote Inference over Networks with Two-Way Delay
Authors: Cagri Ari, Md Kamran Chowdhury Shisher, Yin Sun, Elif Uysal
Abstract: We study a setting where an intelligent model (e.g., a pre-trained neural network) predicts the real-time value of a target signal using data samples transmitted from a remote source according to a scheduling policy. The scheduler decides on i) the age of the samples to be sent, ii) when to send them, and iii) the length of each packet (i.e., the number of samples contained in each packet). The dependence of inference quality on the Age of Information (AoI) for a given packet length is modeled by a general relationship. Previous work assumed i.i.d. transmission delays with immediate feedback or were restricted to the case where inference performance degrades as the input data ages. Our formulation, in addition to capturing non-monotone age dependence, also covers Markovian delay on both forward and feedback links. We model this as an infinite-horizon average-cost Semi-Markov Decision Process. We obtain a closed-form solution that decides on (i) and (ii) for any constant packet length. The solution for when to send is an index-based threshold policy, where the index function is expressed in terms of the delay state and AoI at the receiver. The age of the packet selected is a function of the delay state. We separately optimize the value of the constant length. We also develop an index-based threshold policy for the variable length case, which allows a complexity reduction. In simulation results, we observe that our goal-oriented scheduler drops inference error down to one sixth with respect to age-based scheduling of unit-length packets.

Paper number 86:
Title: GraFPrint: A GNN-Based Approach for Audio Identification
Authors: Aditya Bhattacharjee, Shubhr Singh, Emmanouil Benetos
Abstract: This paper introduces GraFPrint, an audio identification framework that leverages the structural learning capabilities of Graph Neural Networks (GNNs) to create robust audio fingerprints. Our method constructs a k-nearest neighbor (k-NN) graph from time-frequency representations and applies max-relative graph convolutions to encode local and global information. The network is trained using a self-supervised contrastive approach, which enhances resilience to ambient distortions by optimizing feature representation. GraFPrint demonstrates superior performance on large-scale datasets at various levels of granularity, proving to be both lightweight and scalable, making it suitable for real-world applications with extensive reference databases.

Paper number 87:
Title: Enhanced Encoder-Decoder Architecture for Accurate Monocular Depth Estimation
Authors: Dabbrata Das, Argho Deb Das, Farhan Sadaf
Abstract: Estimating depth from a single 2D image is a challenging task due to the lack of stereo or multi-view data, which are typically required for depth perception. In state-of-the-art architectures, the main challenge is to efficiently capture complex objects and fine-grained details, which are often difficult to predict. This paper introduces a novel deep learning-based approach using an enhanced encoder-decoder architecture, where the Inception-ResNet-v2 model serves as the encoder. This is the first instance of utilizing Inception-ResNet-v2 as an encoder for monocular depth estimation, demonstrating improved performance over previous models. It incorporates multi-scale feature extraction to enhance depth prediction accuracy across various object sizes and distances. We propose a composite loss function comprising depth loss, gradient edge loss, and Structural Similarity Index Measure (SSIM) loss, with fine-tuned weights to optimize the weighted sum, ensuring a balance across different aspects of depth estimation. Experimental results on the KITTI dataset show that our model achieves a significantly faster inference time of 0.019 seconds, outperforming vision transformers in efficiency while maintaining good accuracy. On the NYU Depth V2 dataset, the model establishes state-of-the-art performance, with an Absolute Relative Error (ARE) of 0.064, a Root Mean Square Error (RMSE) of 0.228, and an accuracy of 89.3% for $\delta$ < 1.25. These metrics demonstrate that our model can accurately and efficiently predict depth even in challenging scenarios, providing a practical solution for real-time applications.

Paper number 88:
Title: CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models
Authors: Shangda Wu, Yashan Wang, Ruibin Yuan, Zhancheng Guo, Xu Tan, Ge Zhang, Monan Zhou, Jing Chen, Xuefeng Mu, Yuejie Gao, Yuanliang Dong, Jiafeng Liu, Xiaobing Li, Feng Yu, Maosong Sun
Abstract: Challenges in managing linguistic diversity and integrating various musical modalities are faced by current music information retrieval systems. These limitations reduce their effectiveness in a global, multimodal music environment. To address these issues, we introduce CLaMP 2, a system compatible with 101 languages that supports both ABC notation (a text-based musical notation format) and MIDI (Musical Instrument Digital Interface) for music information retrieval. CLaMP 2, pre-trained on 1.5 million ABC-MIDI-text triplets, includes a multilingual text encoder and a multimodal music encoder aligned via contrastive learning. By leveraging large language models, we obtain refined and consistent multilingual descriptions at scale, significantly reducing textual noise and balancing language distribution. Our experiments show that CLaMP 2 achieves state-of-the-art results in both multilingual semantic search and music classification across modalities, thus establishing a new standard for inclusive and global music information retrieval.

Paper number 89:
Title: Ternary Stochastic Neuron -- Implemented with a Single Strained Magnetostrictive Nanomagnet
Authors: Rahnuma Rahman, Supriyo Bandyopadhyay
Abstract: Stochastic neurons are extremely efficient hardware for solving a large class of problems and usually come in two varieties -- "binary" where the neuronal statevaries randomly between two values of -1, +1 and "analog" where the neuronal state can randomly assume any value between -1 and +1. Both have their uses in neuromorphic computing and both can be implemented with low- or zero-energy-barrier nanomagnets whose random magnetization orientations in the presence of thermal noise encode the binary or analog state variables. In between these two classes is n-ary stochastic neurons, mainly ternary stochastic neurons (TSN) whose state randomly assumes one of three values (-1, 0, +1), which have proved to be efficient in pattern classification tasks such as recognizing handwritten digits from the MNIST data set or patterns from the CIFAR-10 data set. Here, we show how to implement a TSN with a zero-energy-barrier (shape isotropic) magnetostrictive nanomagnet subjected to uniaxial strain.

Paper number 90:
Title: LoFi: Vision-Aided Label Generator for Wi-Fi Localization and Tracking
Authors: Zijian Zhao, Tingwei Chen, Fanyi Meng, Zhijie Cai, Hang Li, Xiaoyang Li, Guangxu Zhu
Abstract: Data-driven Wi-Fi localization and tracking have shown great promise due to their lower reliance on specialized hardware compared to model-based methods. However, most existing data collection techniques provide only coarse-grained ground truth or a limited number of labeled points, significantly hindering the advancement of data-driven approaches. While systems like lidar can deliver precise ground truth, their high costs make them inaccessible to many users. To address these challenges, we propose LoFi, a vision-aided label generator for Wi-Fi localization and tracking. LoFi can generate ground truth position coordinates solely from 2D images, offering high precision, low cost, and ease of use. Utilizing our method, we have compiled a Wi-Fi tracking and localization dataset using the ESP32-S3 and a webcam, which will be open-sourced along with the code upon publication.
    