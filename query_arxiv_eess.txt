
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: FM-RME: Foundation Model Empowered Radio Map Estimation
Authors: Dong Yang, Yue Wang, Songyang Zhang, Yingshu Li, Zhipeng Cai, Zhi Tian
Abstract: Traditional radio map estimation (RME) techniques fail to capture multi-dimensional and dynamic characteristics of complex spectrum environments. Recent data-driven methods achieve accurate RME in spatial domain, but ignore physical prior knowledge of radio propagation, limiting data efficiency especially in multi-dimensional scenarios. To overcome such limitations, we propose a new foundation model, characterized by self-supervised pre-training on diverse data for zero-shot generalization, enabling multi-dimensional radio map estimation (FM-RME). Specifically, FM-RME builds an effective synergy of two core components: a geometry-aware feature extraction module that encodes physical propagation symmetries, i.e., translation and rotation invariance, as inductive bias, and an attention-based neural network that learns long-range correlations across the spatial-temporal-spectral domains. A masked self-supervised multi-dimensional pre-training strategy is further developed to learn generalizable spectrum representations across diverse wireless environments. Once pre-trained, FM-RME supports zero-shot inference for multi-dimensional RME, including spatial, temporal, and spectral estimation, without scenario-specific retraining. Simulation results verify that FM-RME exhibits desired learning performance across diverse datasets and zero-shot generalization capabilities beyond existing RME methods.

Paper number 2:
Title: Deep Accurate Solver for the Geodesic Problem
Authors: Saar Huberman, Amit Bracha, Ron Kimmel
Abstract: A common approach to compute distances on continuous surfaces is by considering a discretized polygonal mesh approximating the surface and estimating distances on the polygon. We show that exact geodesic distances restricted to the polygon are at most second-order accurate with respect to the distances on the corresponding continuous surface. By order of accuracy we refer to the convergence rate as a function of the average distance between sampled points. Next, a higher-order accurate deep learning method for computing geodesic distances on surfaces is introduced. Traditionally, one considers two main components when computing distances on surfaces: a numerical solver that locally approximates the distance function, and an efficient causal ordering scheme by which surface points are updated. Classical minimal path methods often exploit a dynamic programming principle with quasi-linear computational complexity in the number of sampled points. The quality of the distance approximation is determined by the local solver that is revisited in this paper. To improve state of the art accuracy, we consider a neural network-based local solver which implicitly approximates the structure of the continuous surface. We supply numerical evidence that the proposed learned update scheme provides better accuracy compared to the best possible polyhedral approximations and previous learning-based methods. The result is a third-order accurate solver with a bootstrapping-recipe for further improvement.

Paper number 3:
Title: Learning to reconstruct from saturated data: audio declipping and high-dynamic range imaging
Authors: Victor Sechaud, Laurent Jacques, Patrice Abry, Julián Tachella
Abstract: Learning based methods are now ubiquitous for solving inverse problems, but their deployment in real-world applications is often hindered by the lack of ground truth references for training. Recent self-supervised learning strategies offer a promising alternative, avoiding the need for ground truth. However, most existing methods are limited to linear inverse problems. This work extends self-supervised learning to the non-linear problem of recovering audio and images from clipped measurements, by assuming that the signal distribution is approximately invariant to changes in amplitude. We provide sufficient conditions for learning to reconstruct from saturated signals alone and a self-supervised loss that can be used to train reconstruction networks. Experiments on both audio and image data show that the proposed approach is almost as effective as fully supervised approaches, despite relying solely on clipped measurements for training.

Paper number 4:
Title: Full Waveform Inversion using the Wasserstein metric for ultrasound transducer array based NDT
Authors: Daniel Rossato, Thiago Alberto Rigo Passarin, Gustavo Pinto Pires, Daniel Rodrigues Pipa
Abstract: Ultrasonic imaging methods often assume linear direct models, while in reality, many nonlinear phenomena are present, e.g. multiple reflections. A family of imaging methods called Full Waveform Inversion (FWI), which has been developed in the field of seismic imaging, uses full acoustic wave simulations as direct models, taking into account virtually all nonlinearities, which can ultimately enhance the accuracy of ultrasonic imaging. However, the problem of cycle skipping -- the existence of many local minima of the Least Squares (L2) misfit function due to the oscillatory nature of the signals -- is worsened when FWI is applied to ultrasound data because of a lack of low-frequency components. In this paper, we explore the use of the squared Wasserstein (W2) Optimal Transport Distance as the metric for the misfit between the acquired and the synthetic data, applying the method to Nondestructive Evaluation with ultrasonic phased arrays. An analytical continuous time-domain derivation of the adjoint acoustic field related to the W2 misfit is presented and used for the computation of the gradients. To cope with the computational burden of FWI, we apply a low-memory strategy that allows for the computation of the gradients without the storage of the full simulated fields. The GPU implementation of the method (in CUDA language) is detailed, and the source code is made available. Six prototypical cases are presented, and the corresponding sound speed maps are reconstructed with FWI using both the L2 and the W2 misfit functionals. In five of the six cases, the pixel-wise sum of squared errors obtained with W2 was at least one order of magnitude lower than that obtained with W2, with an increase in the gradient computation time not exceeding 2\%. The results highlight both the adequacy of the W2 misfit for ultrasonic FWI with phased arrays and its computational feasibility.

Paper number 5:
Title: A Mission Engineering Framework for Uncrewed Aerial Vehicle Design in GNSS-Denied Environments for Intelligence, Surveillance, and Reconnaissance Mission Sets
Authors: Alfonso Sciacchitano, Douglas L. Van Bossuyt
Abstract: Small, low-size, weight, power, and cost (SWaP-C) uncrewed aerial vehicles (UAVs) are increasingly used for intelligence, surveillance, and reconnaissance (ISR) missions due to their affordability, attritability, and suitability for distributed operations. However, their design poses challenges including limited endurance, constrained payload capacity, and reliance on simple sensing modalities such as fixed-field-of-view, bearing-only cameras. Traditional platform-centric methods cannot capture the coupled performance, cost, and coordination trade-offs that emerge at the system-of-systems level. This paper presents a mission engineering framework for early-phase design of low-SWaP-C UAV ISR architectures. The framework integrates design of experiments, multi-objective optimization, and high-fidelity simulation into a closed-loop process linking design variables to estimator-informed performance and mission cost. Candidate architectures are explored via Latin hypercube sampling and refined using a genetic algorithm, with performance evaluated through Monte Carlo trials of a federated Kalman filter benchmarked against the posterior Cramer-Rao lower bound. Validation follows the Validation Square methodology, combining theoretical, empirical, and structural assessments. A case study on man-overboard localization in a GNSS-denied maritime environment shows that localization accuracy saturates at sub-meter levels, while higher-cost configurations primarily add redundancy and resilience. The framework thus quantifies mission trade-offs between performance, affordability, and robustness, providing a scalable decision-support tool for contested, resource-constrained ISR missions.

Paper number 6:
Title: Moving Speaker Separation via Parallel Spectral-Spatial Processing
Authors: Yuzhu Wang, Archontis Politis, Konstantinos Drossos, Tuomas Virtanen
Abstract: Multi-channel speech separation in dynamic environments is challenging as time-varying spatial and spectral features evolve at different temporal scales. Existing methods typically employ sequential architectures, forcing a single network stream to simultaneously model both feature types, creating an inherent modeling conflict. In this paper, we propose a dual-branch parallel spectral-spatial (PS2) architecture that separately processes spectral and spatial features through parallel streams. The spectral branch uses a bi-directional long short-term memory (BLSTM)-based frequency module, a Mamba-based temporal module, and a self-attention module to model spectral features. The spatial branch employs bi-directional gated recurrent unit (BGRU) networks to process spatial features that encode the evolving geometric relationships between sources and microphones. Features from both branches are integrated through a cross-attention fusion mechanism that adaptively weights their contributions. Experimental results demonstrate that the PS2 outperforms existing state-of-the-art (SOTA) methods by 1.6-2.2 dB in scale-invariant signal-to-distortion ratio (SI-SDR) for moving speaker scenarios, with robust separation quality under different reverberation times (RT60), noise levels, and source movement speeds. Even with fast source movements, the proposed model maintains SI-SDR improvements of over 13 dB. These improvements are consistently observed across multiple datasets, including WHAMR! and our generated WSJ0-Demand-6ch-Move dataset.

Paper number 7:
Title: Small HVAC Control Demonstrations in Larger Buildings Often Overestimate Savings
Authors: Arash J. Khabbazi, Kevin J. Kircher
Abstract: How much energy, money, and emissions can advanced control of heating and cooling equipment save in real buildings? To address this question, researchers sometimes control a small number of thermal zones within a larger multi-zone building, then report savings for the controlled zones only. That approach can overestimate savings by neglecting heat transfer between controlled zones and adjacent zones. This paper mathematically characterizes the overestimation error when the dynamics are linear and the objectives are linear in the thermal load, as usually holds when optimizing energy efficiency, energy costs, or emissions. Overestimation errors can be large even in seemingly innocuous situations. For example, when controlling only interior zones that have no direct thermal contact with the outdoors, all perceived savings are fictitious. This paper provides an alternative estimation method based on the controlled and adjacent zones' temperature measurements. The new method does not require estimating how much energy the building would have used under baseline operations, so it removes the additional measurement and verification challenge of accurate baseline estimation.

Paper number 8:
Title: HARU-Net: Hybrid Attention Residual U-Net for Edge-Preserving Denoising in Cone-Beam Computed Tomography
Authors: Khuram Naveed, Ruben Pauwels
Abstract: Cone-beam computed tomography (CBCT) is widely used in dental and maxillofacial imaging, but low-dose acquisition introduces strong, spatially varying noise that degrades soft-tissue visibility and obscures fine anatomical structures. Classical denoising methods struggle to suppress noise in CBCT while preserving edges. Although deep learning-based approaches offer high-fidelity restoration, their use in CBCT denoising is limited by the scarcity of high-resolution CBCT data for supervised training. To address this research gap, we propose a novel Hybrid Attention Residual U-Net (HARU-Net) for high-quality denoising of CBCT data, trained on a cadaver dataset of human hemimandibles acquired using a high-resolution protocol of the 3D Accuitomo 170 (J. Morita, Kyoto, Japan) CBCT system. The novel contribution of this approach is the integration of three complementary architectural components: (i) a hybrid attention transformer block (HAB) embedded within each skip connection to selectively emphasize salient anatomical features, (ii) a residual hybrid attention transformer group (RHAG) at the bottleneck to strengthen global contextual modeling and long-range feature interactions, and (iii) residual learning convolutional blocks to facilitate deeper, more stable feature extraction throughout the network. HARU-Net consistently outperforms state-of-the-art (SOTA) methods including SwinIR and Uformer, achieving the highest PSNR (37.52 dB), highest SSIM (0.9557), and lowest GMSD (0.1084). This effective and clinically reliable CBCT denoising is achieved at a computational cost significantly lower than that of the SOTA methods, offering a practical advancement toward improving diagnostic quality in low-dose CBCT imaging.

Paper number 9:
Title: HyperKKL: Enabling Non-Autonomous State Estimation through Dynamic Weight Conditioning
Authors: Yahia Salaheldin Shaaban, Salem Lahlou, Abdelrahman Sayed Sayed
Abstract: This paper proposes HyperKKL, a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for non-autonomous nonlinear systems. While KKL observers offer a rigorous theoretical framework by immersing nonlinear dynamics into a stable linear latent space, its practical realization relies on solving Partial Differential Equations (PDE) that are analytically intractable. Current existing learning-based approximations of the KKL observer are mostly designed for autonomous systems, failing to generalize to driven dynamics without expensive retraining or online gradient updates. HyperKKL addresses this by employing a hypernetwork architecture that encodes the exogenous input signal to instantaneously generate the parameters of the KKL observer, effectively learning a family of immersion maps parameterized by the external drive. We rigorously evaluate this approach against a curriculum learning strategy that attempts to generalize from autonomous regimes via training heuristics alone. The novel approach is illustrated on four numerical simulations in benchmark examples including the Duffing, Van der Pol, Lorenz, and Rössler systems.

Paper number 10:
Title: Deepfake Word Detection by Next-token Prediction using Fine-tuned Whisper
Authors: Hoan My Tran, Xin Wang, Wanying Ge, Xuechen Liu, Junichi Yamagishi
Abstract: Deepfake speech utterances can be forged by replacing one or more words in a bona fide utterance with semantically different words synthesized by speech generative models. While a dedicated synthetic word detector could be developed, we investigate a cost-effective method that fine-tunes a pre-trained Whisper model to detect synthetic words while transcribing the input utterance via next-token prediction. We further investigate using partially vocoded utterances as the fine-tuning data, thereby reducing the cost of data collection. Our experiments demonstrate that, on in-domain test data, the fine-tuned Whisper yields low synthetic-word detection error rates and transcription error rates. On out-of-domain test data with synthetic words produced by unseen speech generative models, the fine-tuned Whisper remains on par with a dedicated ResNet-based detection model; however, the overall performance degradation calls for strategies to improve its generalization capability.

Paper number 11:
Title: Toward Wireless Human-Machine Collaboration in the 6G Era
Authors: Gaoyang Pang, Wanchun Liu, Chentao Yue, Daniel E. Quevedo, Karl H. Johansson, Branka Vucetic, Yonghui Li
Abstract: The next industrial revolution, Industry 5.0, will be driven by advanced technologies that foster human-machine collaboration (HMC). It will leverage human creativity, judgment, and dexterity with the machine's strength, precision, and speed to improve productivity, quality of life, and sustainability. Wireless communications, empowered by the emerging capabilities of sixth-generation (6G) wireless networks, will play a central role in enabling flexible, scalable, and low-cost deployment of geographically distributed HMC systems. In this article, we first introduce the generic architecture and key components of wireless HMC (WHMC). We then present the network topologies of WHMC and highlight impactful applications across various industry sectors. Driven by the prospective applications, we elaborate on new performance metrics that researchers and practitioners may consider during the exploration and implementation of WHMC and discuss new design methodologies. We then summarize the communication requirements and review promising state-of-the-art technologies that can support WHMC. Finally, we present a proof-of-concept case study and identify several open challenges.

Paper number 12:
Title: U-Net-Based Generative Joint Source-Channel Coding for Wireless Image Transmission
Authors: Ming Ye, Kui Cai, Cunhua Pan, Zhen Mei, Wanting Yang, Chunguo Li
Abstract: Deep learning (DL)-based joint source-channel coding (JSCC) methods have achieved remarkable success in wireless image transmission. However, these methods either focus on conventional distortion metrics that do not necessarily yield high perceptual quality or incur high computational complexity. In this paper, we propose two DL-based JSCC (DeepJSCC) methods that leverage deep generative architectures for wireless image transmission. Specifically, we propose G-UNet-JSCC, a scheme comprising an encoder and a U-Net-based generator serving as the decoder. Its skip connections enable multi-scale feature fusion to improve both pixel-level fidelity and perceptual quality of reconstructed images by integrating low- and high-level features. To further enhance pixel-level fidelity, the encoder and the U-Net-based decoder are jointly optimized using a weighted sum of structural similarity and mean-squared error (MSE) losses. Building upon G-UNet-JSCC, we further develop a DeepJSCC method called cGAN-JSCC, where the decoder is enhanced through adversarial training. In this scheme, we retain the encoder of G-UNet-JSCC and adversarially train the decoder's generator against a patch-based discriminator. cGAN-JSCC employs a two-stage training procedure. The outer stage trains the encoder and the decoder end-to-end using an MSE loss, while the inner stage adversarially trains the decoder's generator and the discriminator by minimizing a joint loss combining adversarial and distortion losses. Simulation results demonstrate that the proposed methods achieve superior pixel-level fidelity and perceptual quality on both high- and low-resolution images. For low-resolution images, cGAN-JSCC achieves better reconstruction performance and greater robustness to channel variations than G-UNet-JSCC.

Paper number 13:
Title: Opacity in Discrete Event Systems: A Perspective and Overview
Authors: Xiang Yin
Abstract: Opacity has emerged as a central confidentiality notion for information-flow security in discrete event systems (DES), capturing the requirement that an external observer (intruder) should never be able to determine with certainty whether the system is, was, or will be in a secret state. This article provides a concise, newcomer-friendly overview of opacity in DES, emphasizing core definitions and the unifying estimation viewpoint behind major opacity notions,. We summarize representative verification techniques and highlight how different observation models reshape both the problem formulation and algorithmic structure. We then review principal enforcement paradigms, ranging from opacity-enforcing supervisory control to sensor activation/information release optimization and obfuscation/editing mechanisms. Beyond finite automata, we outline how opacity has been studied in richer models such as stochastic systems, timed systems, Petri nets, and continuous/hybrid dynamics, and we briefly survey applications in robotics, location privacy, and information services. Finally, we discuss selected open challenges, including solvability under incomparable information, scalable methods beyond worst-case complexity, and opacity under intelligent or data-driven adversaries.

Paper number 14:
Title: CSI-RFF: Leveraging Micro-Signals on CSI for RF Fingerprinting of Commodity WiFi
Authors: Ruiqi Kong, He Chen
Abstract: This paper introduces CSI-RFF, a new framework that leverages micro-signals embedded within Channel State Information (CSI) curves to realize Radio-Frequency Fingerprinting of commodity off-the-shelf (COTS) WiFi devices for open-set authentication. The micro-signals that serve as RF fingerprints are termed ``micro-CSI''. Through experimentation, we have found that the presence of micro-CSI can primarily be attributed to imperfections in the RF circuitry. Furthermore, this characteristic signal is detectable in WiFi 4/5/6 network interface cards (NICs). We have conducted further experiments to determine the most effective CSI collection configurations to stabilize micro-CSI. Yet, extracting micro-CSI for authentication purposes poses a significant challenge. This complexity arises from the fact that CSI measurements inherently include both micro-CSI and the distortions introduced by wireless channels. These two elements are intricately intertwined, making their separation non-trivial. To tackle this challenge, we have developed a signal space-based extraction technique for line-of-sight (LoS) scenarios, which can effectively separate the distortions caused by wireless channels and micro-CSI. Over the course of our comprehensive CSI data collection period extending beyond one year, we found that the extracted micro-CSI displays unique characteristics specific to each WiFi device and remains invariant over time. This establishes micro-CSI as a suitable candidate for device fingerprinting. Finally, we conduct a case study focusing on area access control for mobile robots. Our experimental results demonstrate that the micro-CSI-based authentication algorithm can achieve an average attack detection rate close to 99% with a false alarm rate of 0% in both static and mobile conditions when using 20 CSI measurements to construct one fingerprint.

Paper number 15:
Title: Constructing Knowledge Map for MIMO-OFDM Clustered Channel Estimation
Authors: Heling Zhang, Xiujun Zhang, Xiaofeng Zhong, Shidong Zhou
Abstract: Channel knowledge map (CKM) exploits environ-ment information to assist channel estimation during communi-cation. For clustered channels, which represent a typical type ofwireless propagation environment, there has been no researchdevoted to designing an appropriate CKM to enhance theirestimation. To exploit environment information for clusteredchannel, improve channel estimation accuracy and reduce pilotoverhead, we propose ClusterCKM, a CKM providing the rangeof clustered multipath parameters for any pair of transmitter-receiver links in the region of interest. Firstly, we construct Clus-terCKM through estimating the spatial range of scatterer clustersfrom historical channel information. From these spatial range ofscatterer clusters, ClusterCKM infers the range of multipathparameters for the target link. Furthermore, a ClusterCKM-based channel estimation algorithm is developed to utilize theparameter range provided by ClusterCKM. Simulation resultsshow that, more accurate channel estimation can be achievedand pilot overhead can also be reduced by ClusterCKM and theClusterCKM-based estimation algorithm.

Paper number 16:
Title: Transformer Actor-Critic for Efficient Freshness-Aware Resource Allocation
Authors: Maryam Ansarifard, Mohit K. Sharma, Kishor C. Joshi, George Exarchakos
Abstract: Emerging applications such as autonomous driving and industrial automation demand ultra-reliable and low-latency communication (URLLC), where maintaining fresh and timely information is critical. A key performance metric in such systems is the age of information (AoI). This paper addresses AoI minimization in a multi-user uplink wireless network using non-orthogonal multiple access (NOMA), where users offload tasks to a base station. The system must handle user heterogeneity in task sizes, AoI thresholds, and penalty sensitivities, while adhering to NOMA constraints on user scheduling. We propose a deep reinforcement learning (DRL) framework based on proximal policy optimization (PPO), enhanced with a Transformer encoder. The attention mechanism allows the agent to focus on critical user states and capture inter-user dependencies, improving policy performance and scalability. Extensive simulations show that our method reduces average AoI compared to baselines. We also analyze the evolution of attention weights during training and observe that the model progressively learns to prioritize high-importance users. Attention maps reveal meaningful structure: early-stage policies exhibit uniform attention, while later stages show focused patterns aligned with user priority and NOMA constraints. These results highlight the promise of attention-driven DRL for intelligent, priority-aware resource allocation in next-generation wireless systems.

Paper number 17:
Title: Steady State Covariance Steering via Sparse Intervention
Authors: Yosuke Inoue, Masaki Inoue
Abstract: This paper addresses the steady state covariance steering for linear dynamical systems via structural intervention on the system matrix. We formulate the covariance steering problem as the minimization of the Kullback-Leibler (KL) divergence between the steady state and target Gaussian distributions. To solve the problem, we develop a solution method, hereafter referred to as the proximal gradient-based algorithm, of promoting sparsity in the structural intervention by integrating the objective into a proximal gradient framework with L1 regularization. The main contribution of this paper lies in the analytical expression of the KL divergence gradient with respect to the intervention matrix: the gradient is characterized by the solutions to two Lyapunov equations related to the state covariance equation and its adjoint. Numerical simulations demonstrate that the proximal gradient-based algorithm effectively identifies sparse, structurally-constrained interventions to achieve precise covariance steering.

Paper number 18:
Title: A guided residual search for nonlinear state-space identification
Authors: Merijn Floren, Jan Swevers
Abstract: Parameter estimation of nonlinear state-space models from input-output data typically requires solving a highly non-convex optimization problem prone to slow convergence and suboptimal solutions. This work improves the reliability and efficiency of the estimation process by decomposing the overall optimization problem into a sequence of tractable subproblems. Based on an initial linear model, nonlinear residual dynamics are first estimated via a guided residual search and subsequently refined using multiple-shooting optimization. Experimental results on two benchmarks demonstrate competitive performance relative to state-of-the-art black-box methods and improved convergence compared to naive initialization.

Paper number 19:
Title: Digital Twin-Based Beamforming for Interference Mitigation in AF Relay MIMO Systems
Authors: Alexander Bonora, Anna V. Guglielmi, Davide Scazzoli, Marco Giordani, Maurizio Magarini, Vineeth Teeda, Stefano Tomasin
Abstract: Beamforming in multiple-input multiple-output (MIMO) systems should take interference mitigation into account. However, for beamform design, accurate channel state information (CSI) is needed, which is often difficult to obtain due to channel variability, feedback overhead, or hardware constraints. For example, amplify-and-forward (AF) relays passively forward signals without measurement, precluding full CSI acquisition to and from the relay. To address these issues, this paper introduces a novel prediction-assisted optimization (PAO) framework for beamform design in AF relay-assisted multiuser MIMO systems. The proposed solution in the AF relay aims at maximizing the signal-plus-interference-to-noise ratio (SINR). Unlike other methods, PAO relies solely on received power measurements, making it suitable for scenarios where CSI is unreliable or unavailable. PAO consists of two stages: a supervised-learning-based neural network (NN) that predicts the positions of transmitters using signal observations, and an optimization algorithm, guided by a digital twin (DT), that iteratively refines the beam direction of the relay in a simulated radio environment. As a key contribution, we validate the proposed framework using realistic measurements collected on a custom-built experimental millimeter wave (mmWave) platform, which enables training of the NN model under practical wireless conditions. The estimated information is then used to update the digital twin with knowledge of the surrounding environment, enabling online optimization. Numerical results show the trade-off between localization accuracy and beamforming performance and confirm that PAO maintains robustness even in the presence of localization errors while reducing the need for real-world measurements.

Paper number 20:
Title: Scattering Transform for Auditory Attention Decoding
Authors: René Pallenberg, Fabrice Katzberg, Alfred Mertins, Marco Maass
Abstract: The use of hearing aids will increase in the coming years due to demographic change. One open problem that remains to be solved by a new generation of hearing aids is the cocktail party problem. A possible solution is electroencephalography-based auditory attention decoding. This has been the subject of several studies in recent years, which have in common that they use the same preprocessing methods in most cases. In this work, in order to achieve an advantage, the use of a scattering transform is proposed as an alternative to these preprocessing methods. The two-layer scattering transform is compared with a regular filterbank, the synchrosqueezing short-time Fourier transform and the common preprocessing. To demonstrate the performance, the known and the proposed preprocessing methods are compared for different classification tasks on two widely used datasets, provided by the KU Leuven (KUL) and the Technical University of Denmark (DTU). Both established and new neural-network-based models, CNNs, LSTMs, and recent Transformer/graph-based models are used for classification. Various evaluation strategies were compared, with a focus on the task of classifying speakers who are unknown from the training. We show that the two-layer scattering transform can significantly improve the performance for subject-related conditions, especially on the KUL dataset. However, on the DTU dataset, this only applies to some of the models, or when larger amounts of training data are provided, as in 10-fold cross-validation. This suggests that the scattering transform is capable of extracting additional relevant information.

Paper number 21:
Title: Integrated Flight and Propulsion Control for Fixed-Wing UAVs via Thrust and Disturbance Compensation
Authors: Chong-Yi Sun, Heling Yuan, Xu Fang, Yan He, Xi-Ming Sun
Abstract: This paper investigates the position-tracking control problem for fixed-wing unmanned aerial vehicles (UAVs) equipped with a turbojet engine via an integrated flight and propulsion control scheme. To this end, a hierarchical control framework with thrust and disturbance compensation is proposed. In particular, we first propose a perturbed fixed-wing UAV model with turbojet engine dynamics, accounting for both unmodeled dynamics and external disturbances. Second, a versatile extended observer is designed to handle both unmeasurable thrust dynamics and external disturbances. Third, a hierarchical control framework is implemented using three observer-based controllers to guarantee position-tracking performance. With the proposed control strategy, we prove that the closed-loop system asymptotically converges to the desired trajectory. Finally, a comparative simulation is performed to illustrate the proposed control strategy.

Paper number 22:
Title: A Directional-Derivative-Constrained Method for Continuously Steerable Differential Beamformers with Uniform Circular Arrays
Authors: Tiantian Xiong, Yongyi Deng, Kunlong Zhao, Jilu Jin, Xueqin Luo, Gongping Huang, Jingdong Chen, Jacob Benesty
Abstract: Differential microphone arrays offer a promising solution for far-field acoustic signal acquisition due to their high spatial directivity and compact array structure. A key challenge lies in designing differential beamformers that are continuously steerable and capable of enhancing target signals arriving from arbitrary directions. This paper studies the design of differential beamformers for circular arrays and proposes a novel framework that incorporates directional derivative constraints. By constraining the first-order derivatives of the beampattern at the desired steering direction to zero and assigning suitable values to higher-order derivatives, the beamformer is ensured to achieve its maximum response in the target direction and provide sufficient beam steering. This approach not only improves steering flexibility but also enables a more intuitive and robust beampattern design. Simulation results demonstrate that the proposed method produces continuously steerable beampatterns.

Paper number 23:
Title: Align-Consistency: Improving Non-autoregressive and Semi-supervised ASR with Consistency Regularization
Authors: Wanting Huang, Weiran Wang
Abstract: Consistency regularization (CR) improves the robustness and accuracy of Connectionist Temporal Classification (CTC) by ensuring predictions remain stable across input perturbations. In this work, we propose Align-Consistency, an extension of CR designed for Align-Refine -- a non-autoregressive (non-AR) model that performs iterative refinement of frame-level hypotheses. This method leverages the speed of parallel inference while significantly boosting recognition performance. The effectiveness of Align-Consistency is demonstrated in two settings. First, in the fully supervised setting, our results indicate that applying CR to both the base CTC model and the subsequent refinement steps is critical, and the accuracy improvements from non-AR decoding and CR are mutually additive. Second, for semi-supervised ASR, we employ fast non-AR decoding to generate online pseudo-labels on unlabeled data, which are used to further refine the supervised model and lead to substantial gains.

Paper number 24:
Title: A Scaling Law for Bandwidth Under Quantization
Authors: Maximilian Kalcher, Tena Dubcek
Abstract: We derive a scaling law relating ADC bit depth to effective bandwidth for signals with $1/f^\alpha$ power spectra. Quantization introduces a flat noise floor whose intersection with the declining signal spectrum defines an effective cutoff frequency $f_c$. We show that each additional bit extends this cutoff by a factor of $2^{2/\alpha}$, approximately doubling bandwidth per bit for $\alpha = 2$. The law requires that quantization noise be approximately white, a condition whose minimum bit depth $N_{\min}$ we show to be $\alpha$-dependent. Validation on synthetic $1/f^\alpha$ signals for $\alpha \in \{1.5, 2.0, 2.5\}$ yields prediction errors below 3\% using the theoretical noise floor $\Delta^2/(6f_s)$, and approximately 14\% when the noise floor is estimated empirically from the quantized signal's spectrum. We illustrate practical implications on real EEG data.

Paper number 25:
Title: Analog Time Multiplexing for Digital-to-Analog Conversion
Authors: Juana M. Martínez-Heredia, Alfredo P. Vega-Leal
Abstract: The signal bandwidth of Digital to Analog Converters based on Sigma Delta Modulation is limited by speed constrains. Time-Interleaving allows coping with complexity vs. speed by replacing the original architecture by M parallel paths. These path are clocked at a frequency M times smaller and their digital outputs time multiplexed. This is then converted to analog by means of a Digital to Analog Converter clocked at the high rate. This preprint proposes that time multiplexing be performed in the analog domain. As a result robustness against dynamic effects is achieved.

Paper number 26:
Title: Signal Temporal Logic Verification and Synthesis Using Deep Reachability Analysis and Layered Control Architecture
Authors: Joonwon Choi, Kartik Anand Pant, Youngim Nam, Henry Hellmann, Karthik Nune, Inseok Hwang
Abstract: We propose a signal temporal logic (STL)-based framework that rigorously verifies the feasibility of a mission described in STL and synthesizes control to safely execute it. The proposed framework ensures safe and reliable operation through two phases. First, the proposed framework assesses the feasibility of STL by computing a backward reachable tube (BRT), which captures all states that can satisfy the given STL, regardless of the initial state. The proposed framework accommodates the multiple reach-avoid (MRA) problem to address more general STL specifications and leverages a deep neural network to alleviate the computation burden for reachability analysis, reducing the computation time by about 1000 times compared to a baseline method. We further propose a layered planning and control architecture that combines mixed-integer linear programming (MILP) for global planning with model predictive control (MPC) as a local controller for the verified STL. Consequently, the proposed framework can robustly handle unexpected behavior of obstacles that are not described in the environment information or STL, thereby providing reliable mission performance. Our numerical simulations demonstrate that the proposed framework can successfully compute BRT for a given STL and perform the mission.

Paper number 27:
Title: CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons
Authors: Kyle D. Massingill, Tyler M. Karasinski, Sean Bryan, Michael Baricuatro, Daniel Bliss, Delondrae Carter, Walter Goodwin, Jonathan Greenfield, Christopher Groppi, Jae Joiner, Philip Mauskopf, Philip Rybak, Scott Smas, Roshni Suresh, Joesph Tinlin, Bianca Wullen, Peter Wullen
Abstract: Microwave sounding is the leading driver of global numerical weather forecasting, but is limited by the scalability of such instruments. With modern machining and commercial microwave components, it is now possible to design low size, weight, power, and cost (SWaP-C) microwave spectrometers while maintaining wide bandwidth performance. Here we report on the status of CubeSounder, a spectrometer tailored for water vapor radiometry that utilizes passive wave guide filter banks. After developing a prototype and high altitude balloon payload, we demonstrated CubeSounder on commercial stratospheric balloon flights. We report on our design process, especially the simulation and fabrication of the custom millimeter-wave filter banks. We also report the initial results of the data collected from the balloon flights.

Paper number 28:
Title: Millimeter-Wave RIS: Hardware Design and System-Level Considerations
Authors: Ruiqi Wang, Pinjun Zheng, Yiming Yang, Xiarui Su, Mohammad Vaseem, Anas Chaaban, Md. Jahangir Hossain, Tareq Y. Al-Naffouri, Atif Shamim
Abstract: Reconfigurable intelligent surfaces have emerged as a promising hardware platform for shaping wireless propagation environments at millimeter-wave (mm-Wave) frequencies and beyond. While many existing studies emphasize channel modeling and signal processing, practical RIS deployment is fundamentally governed by hardware design choices and their system-level implications. This paper presents a hardware-centric overview of recent mm-Wave RIS developments, covering wideband realizations, high-resolution phase-quantized designs, fully printed low-cost implementations, optically transparent surfaces, RIS-on-chip solutions, and emerging three-dimensional architectures. Key challenges including mutual coupling, calibration, multi-RIS interaction, and frequency-dependent phase control are discussed to bridge hardware realization with system-level optimization. This overview provides practical design insights and aims to guide future RIS research toward scalable, efficient, and practically deployable intelligent surface architectures.

Paper number 29:
Title: Unsupervised Denoising of Diffusion-Weighted Images with Bias and Variance Corrected Noise Modeling
Authors: Jine Xie, Zhicheng Zhang, Yunwei Chen, Yanqiu Feng, Xinyuan Zhang
Abstract: Diffusion magnetic resonance imaging (dMRI) plays a vital role in both clinical diagnostics and neuroscience research. However, its inherently low signal-to-noise ratio (SNR), especially under high diffusion weighting, significantly degrades image quality and impairs downstream analysis. Recent self-supervised and unsupervised denoising methods offer a practical solution by enhancing image quality without requiring clean references. However, most of these methods do not explicitly account for the non-Gaussian noise characteristics commonly present in dMRI magnitude data during the supervised learning process, potentially leading to systematic bias and heteroscedastic variance, particularly under low-SNR conditions. To overcome this limitation, we introduce noise-corrected training objectives that explicitly model Rician statistics. Specifically, we propose two alternative loss functions: one derived from the first-order moment to remove mean bias, and another from the second-order moment to correct squared-signal bias. Both losses include adaptive weighting to account for variance heterogeneity and can be used without changing the network architecture. These objectives are instantiated in an image-specific, unsupervised Deep Image Prior (DIP) framework. Comprehensive experiments on simulated and in-vivo dMRI show that the proposed losses effectively reduce Rician bias and suppress noise fluctuations, yielding higher image quality and more reliable diffusion metrics than state-of-the-art denoising baselines. These results underscore the importance of bias- and variance-aware noise modeling for robust dMRI analysis under low-SNR conditions.

Paper number 30:
Title: Machine Learning on Heterogeneous, Edge, and Quantum Hardware for Particle Physics (ML-HEQUPP)
Authors: Julia Gonski, Jenni Ott, Shiva Abbaszadeh, Sagar Addepalli, Matteo Cremonesi, Jennet Dickinson, Giuseppe Di Guglielmo, Erdem Yigit Ertorer, Lindsey Gray, Ryan Herbst, Christian Herwig, Tae Min Hong, Benedikt Maier, Maryam Bayat Makou, David Miller, Mark S. Neubauer, Cristián Peña, Dylan Rankin, Seon-Hee (Sunny)Seo, Giordon Stark, Alexander Tapper, Audrey Corbeil Therrien, Ioannis Xiotidis, Keisuke Yoshihara, G Abarajithan, Sagar Addepalli, Nural Akchurin, Carlos Argüelles, Saptaparna Bhattacharya, Lorenzo Borella, Christian Boutan, Tom Braine, James Brau, Martin Breidenbach, Antonio Chahine, Talal Ahmed Chowdhury, Yuan-Tang Chou, Seokju Chung, Alberto Coppi, Mariarosaria D'Alfonso, Abhilasha Dave, Chance Desmet, Angela Di Fulvio, Karri DiPetrillo, Javier Duarte, Auralee Edelen, Jan Eysermans, Yongbin Feng, Emmett Forrestel, Dolores Garcia, Loredana Gastaldo, Julián García Pardiñas, Lino Gerlach, Loukas Gouskos, Katya Govorkova, Carl Grace, Christopher Grant, Philip Harris, Ciaran Hasnip, Timon Heim, Abraham Holtermann, Tae Min Hong, Gian Michele Innocenti, Koji Ishidoshiro, Miaochen Jin, Jyothisraj Johnson, Stephen Jones, Andreas Jung, Georgia Karagiorgi, Ryan Kastner, Nicholas Kamp, Doojin Kim, Kyoungchul Kong, Katie Kudela, Jelena Lalic, Bo-Cheng Lai, Yun-Tsung Lai, Tommy Lam, Jeffrey Lazar, Aobo Li, Zepeng Li, Haoyun Liu, Vladimir Lončar, Luca Macchiarulo, Christopher Madrid, Benedikt Maier, Zhenghua Ma, Prashansa Mukim, Mark S. Neubauer, Victoria Nguyen, Sungbin Oh, Isobel Ojalvo, Hideyoshi Ozaki, Simone Pagan Griso, Myeonghun Park, Christoph Paus, Santosh Parajuli, Benjamin Parpillon, Sara Pozzi, Ema Puljak
Abstract: The next generation of particle physics experiments will face a new era of challenges in data acquisition, due to unprecedented data rates and volumes along with extreme environments and operational constraints. Harnessing this data for scientific discovery demands real-time inference and decision-making, intelligent data reduction, and efficient processing architectures beyond current capabilities. Crucial to the success of this experimental paradigm are several emerging technologies, such as artificial intelligence and machine learning (AI/ML) and silicon microelectronics, and the advent of quantum algorithms and processing. Their intersection includes areas of research such as low-power and low-latency devices for edge computing, heterogeneous accelerator systems, reconfigurable hardware, novel codesign and synthesis strategies, readout for cryogenic or high-radiation environments, and analog computing. This white paper presents a community-driven vision to identify and prioritize research and development opportunities in hardware-based ML systems and corresponding physics applications, contributing towards a successful transition to the new data frontier of fundamental science.

Paper number 31:
Title: Improving Spatial Allocation for Energy System Coupling with Graph Neural Networks
Authors: Xuanhao Mu, Jakob Geiges, Nan Liu, Thorsten Schlachter, Veit Hagenmeyer
Abstract: In energy system analysis, coupling models with mismatched spatial resolutions is a significant challenge. A common solution is assigning weights to high-resolution geographic units for aggregation, but traditional models are limited by using only a single geospatial attribute. This paper presents an innovative method employing a self-supervised Heterogeneous Graph Neural Network to address this issue. This method models high-resolution geographic units as graph nodes, integrating various geographical features to generate physically meaningful weights for each grid point. These weights enhance the conventional Voronoi-based allocation method, allowing it to go beyond simply geographic proximity by incorporating essential geographic this http URL addition, the self-supervised learning paradigm overcomes the lack of accurate ground-truth data. Experimental results demonstrate that applying weights generated by this method to cluster-based Voronoi Diagrams significantly enhances scalability, accuracy, and physical plausibility, while increasing precision compared to traditional methods.

Paper number 32:
Title: CryoNet.Refine: A One-step Diffusion Model for Rapid Refinement of Structural Models with Cryo-EM Density Map Restraints
Authors: Fuyao Huang, Xiaozhu Yu, Kui Xu, Qiangfeng Cliff Zhang
Abstract: High-resolution structure determination by cryo-electron microscopy (cryo-EM) requires the accurate fitting of an atomic model into an experimental density map. Traditional refinement pipelines such as Phenix.real_space_refine and Rosetta are computationally expensive, demand extensive manual tuning, and present a significant bottleneck for researchers. We present this http URL, an end-to-end deep learning framework that automates and accelerates molecular structure refinement. Our approach utilizes a one-step diffusion model that integrates a density-aware loss function with robust stereochemical restraints, enabling rapid optimization of a structure against experimental data. this http URL provides a unified and versatile solution capable of refining protein complexes as well as DNA/RNA-protein complexes. In benchmarks against Phenix.real_space_refine, this http URL consistently achieves substantial improvements in both model-map correlation and overall geometric quality metrics. By offering a scalable, automated, and powerful alternative, this http URL aims to serve as an essential tool for next-generation cryo-EM structure refinement. Web server: this https URL Source code: this https URL.

Paper number 33:
Title: X-REFINE: XAI-based RElevance input-Filtering and archItecture fiNe-tuning for channel Estimation
Authors: Abdul Karim Gizzini, Yahia Medjahdi
Abstract: AI-native architectures are vital for 6G wireless communications. The black-box nature and high complexity of deep learning models employed in critical applications, such as channel estimation, limit their practical deployment. While perturbation-based XAI solutions offer input filtering, they often neglect internal structural optimization. We propose X-REFINE, an XAI-based framework for joint input-filtering and architecture fine-tuning. By utilizing a decomposition-based, sign-stabilized LRP epsilon rule, X-REFINE backpropagates predictions to derive high-resolution relevance scores for both subcarriers and hidden neurons. This enables a holistic optimization that identifies the most faithful model components. Simulation results demonstrate that X-REFINE achieves a superior interpretability-performance-complexity trade-off, significantly reducing computational complexity while maintaining robust bit error rate (BER) performance across different scenarios.

Paper number 34:
Title: AdapTBF: Decentralized Bandwidth Control via Adaptive Token Borrowing for HPC Storage
Authors: Md Hasanur Rashid, Dong Dai
Abstract: Modern high-performance computing (HPC) applications run on compute resources but share global storage systems. This design can cause problems when applications consume a disproportionate amount of storage bandwidth relative to their allocated compute resources. For example, an application running on a single compute node can issue many small, random writes and consume excessive I/O bandwidth from a storage server. This can hinder larger jobs that write to the same storage server and are allocated many compute nodes, resulting in significant resource waste. A straightforward solution is to limit each application's I/O bandwidth on storage servers in proportion to its allocated compute resources. This approach has been implemented in parallel file systems using Token Bucket Filter (TBF). However, strict proportional limits often reduce overall I/O efficiency because HPC applications generate short, bursty I/O. Limiting bandwidth can waste server capacity when applications are idle or prevent applications from temporarily using higher bandwidth during bursty phases. We argue that I/O control should maximize per-application performance and overall storage efficiency while ensuring fairness (e.g., preventing small jobs from blocking large-scale ones). We propose AdapTBF, which builds on TBF in modern parallel file systems (e.g., Lustre) and introduces a decentralized bandwidth control approach using adaptive borrowing and lending. We detail the algorithm, implement AdapTBF in Lustre, and evaluate it using synthetic workloads modeled after real-world scenarios. Results show that AdapTBF manages I/O bandwidth effectively while maintaining high storage utilization, even under extreme conditions.

Paper number 35:
Title: Absorbing Discrete Diffusion for Speech Enhancement
Authors: Philippe Gonzalez
Abstract: Inspired by recent developments in neural speech coding and diffusion-based language modeling, we tackle speech enhancement by modeling the conditional distribution of clean speech codes given noisy speech codes using absorbing discrete diffusion. The proposed approach, which we call ADDSE, leverages both the expressive latent space of neural audio codecs and the non-autoregressive sampling procedure of diffusion models. To efficiently model the hierarchical structure of residual vector quantization codes, we propose RQDiT, which combines techniques from RQ-Transformer and diffusion Transformers for non-autoregressive modeling. Results show competitive performance in terms of non-intrusive objective metrics on two datasets, especially at low signal-to-noise ratios and with few sampling steps. Code and audio examples are available online.

Paper number 36:
Title: Differentially Private Data-Driven Markov Chain Modeling
Authors: Alexander Benvenuti, Brandon Fallin, Calvin Hawkins, Brendan Bialy, Miriam Dennis, Warren Dixon, Matthew Hale
Abstract: Markov chains model a wide range of user behaviors. However, generating accurate Markov chain models requires substantial user data, and sharing these models without privacy protections may reveal sensitive information about the underlying user data. We introduce a method for protecting user data used to formulate a Markov chain model. First, we develop a method for privatizing database queries whose outputs are elements of the unit simplex, and we prove that this method is differentially private. We quantify its accuracy by bounding the expected KL divergence between private and non-private queries. We extend this method to privatize stochastic matrices whose rows are each a simplex-valued query of a database, which includes data-driven Markov chain models. To assess their accuracy, we analytically bound the change in the stationary distribution and the change in the convergence rate between a non-private Markov chain model and its private form. Simulations show that under a typical privacy implementation, our method yields less than 2% error in the stationary distribution, indicating that our approach to private modeling faithfully captures the behavior of the systems we study.

Paper number 37:
Title: Hierarchical Trajectory Planning of Floating-Base Multi-Link Robot for Maneuvering in Confined Environments
Authors: Yicheng Chen, Jinjie Li, Haokun Liu, Zicheng Luo, Kotaro Kaneko, Moju Zhao
Abstract: Floating-base multi-link robots can change their shape during flight, making them well-suited for applications in confined environments such as autonomous inspection and search and rescue. However, trajectory planning for such systems remains an open challenge because the problem lies in a high-dimensional, constraint-rich space where collision avoidance must be addressed together with kinematic limits and dynamic feasibility. This work introduces a hierarchical trajectory planning framework that integrates global guidance with configuration-aware local optimization. First, we exploit the dual nature of these robots - the root link as a rigid body for guidance and the articulated joints for flexibility - to generate global anchor states that decompose the planning problem into tractable segments. Second, we design a local trajectory planner that optimizes each segment in parallel with differentiable objectives and constraints, systematically enforcing kinematic feasibility and maintaining dynamic feasibility by avoiding control singularities. Third, we implement a complete system that directly processes point-cloud data, eliminating the need for handcrafted obstacle models. Extensive simulations and real-world experiments confirm that this framework enables an articulated aerial robot to exploit its morphology for maneuvering that rigid robots cannot achieve. To the best of our knowledge, this is the first planning framework for floating-base multi-link robots that has been demonstrated on a real robot to generate continuous, collision-free, and dynamically feasible trajectories directly from raw point-cloud inputs, without relying on handcrafted obstacle models.

Paper number 38:
Title: SignVLA: A Gloss-Free Vision-Language-Action Framework for Real-Time Sign Language-Guided Robotic Manipulation
Authors: Xinyu Tan, Ningwei Bai, Harry Gardener, Zhengyang Zhong, Luoyu Zhang, Liuhaichen Yang, Zhekai Duan, Monkgogi Galeitsiwe, Zezhi Tang
Abstract: We present, to our knowledge, the first sign language-driven Vision-Language-Action (VLA) framework for intuitive and inclusive human-robot interaction. Unlike conventional approaches that rely on gloss annotations as intermediate supervision, the proposed system adopts a gloss-free paradigm and directly maps visual sign gestures to semantic instructions. This design reduces annotation cost and avoids the information loss introduced by gloss representations, enabling more natural and scalable multimodal interaction. In this work, we focus on a real-time alphabet-level finger-spelling interface that provides a robust and low-latency communication channel for robotic control. Compared with large-scale continuous sign language recognition, alphabet-level interaction offers improved reliability, interpretability, and deployment feasibility in safety-critical embodied environments. The proposed pipeline transforms continuous gesture streams into coherent language commands through geometric normalization, temporal smoothing, and lexical refinement, ensuring stable and consistent interaction. Furthermore, the framework is designed to support future integration of transformer-based gloss-free sign language models, enabling scalable word-level and sentence-level semantic understanding. Experimental results demonstrate the effectiveness of the proposed system in grounding sign-derived instructions into precise robotic actions under diverse interaction scenarios. These results highlight the potential of the framework to advance accessible, scalable, and multimodal embodied intelligence.

Paper number 39:
Title: Efficient Dialect-Aware Modeling and Conditioning for Low-Resource Taiwanese Hakka Speech Processing
Authors: An-Ci Peng, Kuan-Tang Huang, Tien-Hong Lo, Hung-Shin Lee, Hsin-Min Wang, Berlin Chen
Abstract: Taiwanese Hakka is a low-resource, endangered language that poses significant challenges for automatic speech recognition (ASR), including high dialectal variability and the presence of two distinct writing systems (Hanzi and Pinyin). Traditional ASR models often encounter difficulties in this context, as they tend to conflate essential linguistic content with dialect-specific variations across both phonological and lexical dimensions. To address these challenges, we propose a unified framework grounded in the Recurrent Neural Network Transducers (RNN-T). Central to our approach is the introduction of dialect-aware modeling strategies designed to disentangle dialectal "style" from linguistic "content", which enhances the model's capacity to learn robust and generalized representations. Additionally, the framework employs parameter-efficient prediction networks to concurrently model ASR (Hanzi and Pinyin). We demonstrate that these tasks create a powerful synergy, wherein the cross-script objective serves as a mutual regularizer to improve the primary ASR tasks. Experiments conducted on the HAT corpus reveal that our model achieves 57.00% and 40.41% relative error rate reduction on Hanzi and Pinyin ASR, respectively. To our knowledge, this is the first systematic investigation into the impact of Hakka dialectal variations on ASR and the first single model capable of jointly addressing these tasks.

Paper number 40:
Title: Agentic AI for Intent-driven Optimization in Cell-free O-RAN
Authors: Mohammad Hossein Shokouhi, Vincent W.S. Wong
Abstract: Agentic artificial intelligence (AI) is emerging as a key enabler for autonomous radio access networks (RANs), where multiple large language model (LLM)-based agents reason and collaborate to achieve operator-defined intents. The open RAN (O-RAN) architecture enables the deployment and coordination of such agents. However, most existing works consider simple intents handled by independent agents, while complex intents that require coordination among agents remain unexplored. In this paper, we propose an agentic AI framework for intent translation and optimization in cell-free O-RAN. A supervisor agent translates the operator intents into an optimization objective and minimum rate requirements. Based on this information, a user weighting agent retrieves relevant prior experience from a memory module to determine the user priority weights for precoding. If the intent includes an energy-saving objective, then an open radio unit (O-RU) management agent will also be activated to determine the set of active O-RUs by using a deep reinforcement learning (DRL) algorithm. A monitoring agent measures and monitors the user data rates and coordinates with other agents to guarantee the minimum rate requirements are satisfied. To enhance scalability, we adopt a parameter-efficient fine-tuning (PEFT) method that enables the same underlying LLM to be used for different agents. Simulation results show that the proposed agentic AI framework reduces the number of active O-RUs by 41.93% when compared with three baseline schemes in energy-saving mode. Using the PEFT method, the proposed framework reduces the memory usage by 92% when compared with deploying separate LLM agents.

Paper number 41:
Title: Gradient Dominance in the Linear Quadratic Regulator: A Unified Analysis for Continuous-Time and Discrete-Time Systems
Authors: Yuto Watanabe, Yang Zheng
Abstract: Despite its nonconvexity, policy optimization for the Linear Quadratic Regulator (LQR) admits a favorable structural property known as gradient dominance, which facilitates linear convergence of policy gradient methods to the globally optimal gain. While gradient dominance has been extensively studied, continuous-time and discrete-time LQRs have largely been analyzed separately, relying on slightly different assumptions, proof strategies, and resulting guarantees. In this paper, we present a unified gradient dominance property for both continuous-time and discrete-time LQRs under mild stabilizability and detectability assumptions. Our analysis is based on a convex reformulation derived from a common Lyapunov inequality representation and a unified change-of-variables procedure. This convex-lifting perspective yields a single proof framework applicable to both time models. The unified treatment clarifies how differences between continuous-time and discrete-time dynamics influence theoretical guarantees and reveals a deeper structural symmetry between the two formulations. Numerical examples illustrate and support the theoretical findings.

Paper number 42:
Title: Relating the Neural Representations of Vocalized, Mimed, and Imagined Speech
Authors: Maryam Maghsoudi, Rupesh Chillale, Shihab A. Shamma
Abstract: We investigated the relationship among neural representations of vocalized, mimed, and imagined speech recorded using publicly available stereotactic EEG recordings. Most prior studies have focused on decoding speech responses within each condition separately. Here, instead, we explore how responses across conditions relate by training linear spectrogram reconstruction models for each condition and evaluate their generalization across conditions. We demonstrate that linear decoders trained on one condition generally transfer successfully to others, implying shared speech representations. This commonality was assessed with stimulus-level discriminability by performing a rank-based analysis demonstrating preservation of stimulus-specific structure in both within- and across-conditions. Finally, we compared linear reconstructions to those from a nonlinear neural network. While both exhibited cross-condition transfer, linear models achieve superior stimulus-level discriminability.

Paper number 43:
Title: Robust Helicopter Ship Deck Landing With Guaranteed Timing Using Shrinking-Horizon Model Predictive Control
Authors: Philipp Schitz, Paolo Mercorelli, Johann C. Dauer
Abstract: We present a runtime efficient algorithm for autonomous helicopter landings on moving ship decks based on Shrinking-Horizon Model Predictive Control (SHMPC). First, a suitable planning model capturing the relevant aspects of the full nonlinear helicopter dynamics is derived. Next, we use the SHMPC together with a touchdown controller stage to ensure a pre-specified maneuver time and an associated landing time window despite the presence of disturbances. A high disturbance rejection performance is achieved by designing an ancillary controller with disturbance feedback. Thus, given a target position and time, a safe landing with suitable terminal conditions is be guaranteed if the initial optimization problem is feasible. The efficacy of our approach is shown in simulation where all maneuvers achieve a high landing precision in strong winds while satisfying timing and operational constraints with maximum computation times in the millisecond range.

Paper number 44:
Title: Molecule Mixture Detection and Design for MC Systems with Non-linear, Cross-reactive Receiver Arrays
Authors: Bastian Heinlein, Kaikai Zhu, Sümeyye Carkit-Yilmaz, Sebastian Lotter, Helene M. Loos, Andrea Buettner, Yansha Deng, Robert Schober, Vahid Jamali
Abstract: Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by commercially available sensors. However, these sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumption of linear and perfectly molecule type-specific sensing often made in the MC literature. To address this mismatch, we propose several detectors and transmission schemes for a molecule mixture communication system where the receiver (RX) employs non-linear, cross-reactive sensors. All proposed schemes are based on the first- and second-order moments of the symbol likelihoods that are fed through the non-linear RX using the Unscented Transform. In particular, we propose an approximate maximum likelihood (AML) symbol-by-symbol detector for inter-symbol-interference (ISI)-free transmission scenarios and a complementary mixture alphabet design algorithm which accounts for the RX characteristics. When significant ISI is present at high data rates, the AML detector can be adapted to exploit statistical ISI knowledge. Additionally, we propose a sequence detector which combines information from multiple symbol intervals. For settings where sequence detection is not possible due to extremely limited computational power at the RX, we propose an adaptive transmission scheme which can be combined with symbol-by-symbol detection. Using computer simulations, we validate all proposed detectors and algorithms based on the responses of commercially available sensors as well as artificially generated sensor data incorporating the characteristics of metal-oxide semiconductor sensors. By employing a general system model that accounts for transmitter noise, ISI, and general non-linear, cross-reactive RX arrays, this work enables reliable communication for a large class of MC systems.

Paper number 45:
Title: Reflectance Multispectral Imaging for Soil Composition Estimation and USDA Texture Classification
Authors: G.A.S.L Ranasinghe, J.A.S.T. Jayakody, M.C.L. De Silva, G. Thilakarathne, G.M.R.I. Godaliyadda, H.M.V.R. Herath, M.P.B. Ekanayake, S.K. Navaratnarajah
Abstract: Soil texture is a foundational attribute that governs water availability and erosion in agriculture, as well as load bearing capacity, deformation response, and shrink-swell risk in geotechnical engineering. Yet texture is still typically determined by slow and labour intensive laboratory particle size tests, while many sensing alternatives are either costly or too coarse to support routine field scale deployment. This paper proposes a robust and field deployable multispectral imaging (MSI) system and machine learning framework for predicting soil composition and the United States Department of Agriculture (USDA) texture classes. The proposed system uses a cost effective in-house MSI device operating from 365 nm to 940 nm to capture thirteen spectral bands, which effectively capture the spectral properties of soil texture. Regression models use the captured spectral properties to estimate clay, silt, and sand percentages, while a direct classifier predicts one of the twelve USDA textural classes. Indirect classification is obtained by mapping the regressed compositions to texture classes via the USDA soil texture triangle. The framework is evaluated on mixture data by mixing clay, silt, and sand in varying proportions, using the USDA classification triangle as a basis. Experimental results show that the proposed approach achieves a coefficient of determination R^2 up to 0.99 for composition prediction and over 99% accuracy for texture classification. These findings indicate that MSI combined with data-driven modeling can provide accurate, non-destructive, and field deployable soil texture characterization suitable for geotechnical screening and precision agriculture.

Paper number 46:
Title: Continuous Blood Monitoring with Particle-based Integrated Sensing and Communication (ISAC)
Authors: Fatih E. Bilgen, Ozgur B. Akan
Abstract: Although the circulatory system functions as a continuous source of physiological data, contemporary diagnostics remain bound to intermittent, time-delayed assessments. To resolve this, we present a framework for ubiquitous hematological profiling driven by Integrated Sensing and Communication (ISAC). We demonstrate how electromagnetic signals can be exploited to monitor blood in real-time, effectively converting them into diagnostic tools. We analyze the biological foundations of blood, review existing Complete Blood Count (CBC) and sensing technologies, and detail a novel pipeline for continuous blood monitoring. Furthermore, we discuss the potential applications of deploying these devices to enable real-time CBC and biomarker detection, ultimately revolutionizing how we predict, detect, and manage individual and public health.

Paper number 47:
Title: Effective sample size approximations as entropy measures
Authors: L. Martino, V. Elvira
Abstract: In this work, we analyze alternative effective sample size (ESS) metrics for importance sampling algorithms, and discuss a possible extended range of applications. We show the relationship between the ESS expressions used in the literature and two entropy families, the Rényi and Tsallis entropy. The Rényi entropy is connected to the Huggins-Roy's ESS family introduced in \cite{Huggins15}. We prove that that all the ESS functions included in the Huggins-Roy's family fulfill all the desirable theoretical conditions. We analyzed and remark the connections with several other fields, such as the Hill numbers introduced in ecology, the Gini inequality coefficient employed in economics, and the Gini impurity index used mainly in machine learning, to name a few. Finally, by numerical simulations, we study the performance of different ESS expressions contained in the previous ESS families in terms of approximation of the theoretical ESS definition, and show the application of ESS formulas in a variable selection problem.

Paper number 48:
Title: A note on the area under the likelihood and the fake evidence for model selection
Authors: L. Martino, F. Llorente
Abstract: Improper priors are not allowed for the computation of the Bayesian evidence $Z=p({\bf y})$ (a.k.a., marginal likelihood), since in this case $Z$ is not completely specified due to an arbitrary constant involved in the computation. However, in this work, we remark that they can be employed in a specific type of model selection problem: when we have several (possibly infinite) models belonging to the same parametric family (i.e., for tuning parameters of a parametric model). However, the quantities involved in this type of selection cannot be considered as Bayesian evidences: we suggest to use the name ``fake evidences'' (or ``areas under the likelihood'' in the case of uniform improper priors). We also show that, in this model selection scenario, using a diffuse prior and increasing its scale parameter asymptotically to infinity, we cannot recover the value of the area under the likelihood, obtained with a uniform improper prior. We first discuss it from a general point of view. Then we provide, as an applicative example, all the details for Bayesian regression models with nonlinear bases, considering two cases: the use of a uniform improper prior and the use of a Gaussian prior, respectively. A numerical experiment is also provided confirming and checking all the previous statements.

Paper number 49:
Title: An automatic counting algorithm for the quantification and uncertainty analysis of the number of microglial cells trainable in small and heterogeneous datasets
Authors: L. Martino, M. M. Garcia, P. S. Paradas, E. Curbelo
Abstract: Counting immunopositive cells on biological tissues generally requires either manual annotation or (when available) automatic rough systems, for scanning signal surface and intensity in whole slide imaging. In this work, we tackle the problem of counting microglial cells in lumbar spinal cord cross-sections of rats by omitting cell detection and focusing only on the counting task. Manual cell counting is, however, a time-consuming task and additionally entails extensive personnel training. The classic automatic color-based methods roughly inform about the total labeled area and intensity (protein quantification) but do not specifically provide information on cell number. Since the images to be analyzed have a high resolution but a huge amount of pixels contain just noise or artifacts, we first perform a pre-processing generating several filtered images {(providing a tailored, efficient feature extraction)}. Then, we design an automatic kernel counter that is a non-parametric and non-linear method. The proposed scheme can be easily trained in small datasets since, in its basic version, it relies only on one hyper-parameter. However, being non-parametric and non-linear, the proposed algorithm is flexible enough to express all the information contained in rich and heterogeneous datasets as well (providing the maximum overfit if required). Furthermore, the proposed kernel counter also provides uncertainty estimation of the given prediction, and can directly tackle the case of receiving several expert opinions over the same image. Different numerical experiments with artificial and real datasets show very promising results. Related Matlab code is also provided.

Paper number 50:
Title: Learning-based Multi-agent Race Strategies in Formula 1
Authors: Giona Fieni, Joschua Wüthrich, Marc-Philippe Neumann, Christopher H. Onder
Abstract: In Formula 1, race strategies are adapted according to evolving race conditions and competitors' actions. This paper proposes a reinforcement learning approach for multi-agent race strategy optimization. Agents learn to balance energy management, tire degradation, aerodynamic interaction, and pit-stop decisions. Building on a pre-trained single-agent policy, we introduce an interaction module that accounts for the behavior of competitors. The combination of the interaction module and a self-play training scheme generates competitive policies, and agents are ranked based on their relative performance. Results show that the agents adapt pit timing, tire selection, and energy allocation in response to opponents, achieving robust and consistent race performance. Because the framework relies only on information available during real races, it can support race strategists' decisions before and during races.

Paper number 51:
Title: Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization via Extreme Augmentation and Perfect Alignment
Authors: Sanjid Hasan, Risalat Labib, A H M Fuad, Bayazid Hasan
Abstract: Although Automatic Speech Recognition (ASR) in Bengali has seen significant progress, processing long-duration audio and performing robust speaker diarization remain critical research gaps. To address the severe scarcity of joint ASR and diarization resources for this language, we introduce Lipi-Ghor-882, a comprehensive 882-hour multi-speaker Bengali dataset. In this paper, detailing our submission to the DL Sprint 4.0 competition, we systematically evaluate various architectures and approaches for long-form Bengali speech. For ASR, we demonstrate that raw data scaling is ineffective; instead, targeted fine-tuning utilizing perfectly aligned annotations paired with synthetic acoustic degradation (noise and reverberation) emerges as the singular most effective approach. Conversely, for speaker diarization, we observed that global open-source state-of-the-art models (such as Diarizen) performed surprisingly poorly on this complex dataset. Extensive model retraining yielded negligible improvements; instead, strategic, heuristic post-processing of baseline model outputs proved to be the primary driver for increasing accuracy. Ultimately, this work outlines a highly optimized dual pipeline achieving a $\sim$0.019 Real-Time Factor (RTF), establishing a practical, empirically backed benchmark for low-resource, long-form speech processing.

Paper number 52:
Title: Plug-and-Play Diffusion Meets ADMM: Dual-Variable Coupling for Robust Medical Image Reconstruction
Authors: Chenhe Du, Xuanyu Tian, Qing Wu, Muyu Liu, Jingyi Yu, Hongjiang Wei, Yuyao Zhang
Abstract: Plug-and-Play diffusion prior (PnPDP) frameworks have emerged as a powerful paradigm for solving imaging inverse problems by treating pretrained generative models as modular priors. However, we identify a critical flaw in prevailing PnP solvers (e.g., based on HQS or Proximal Gradient): they function as memoryless operators, updating estimates solely based on instantaneous gradients. This lack of historical tracking inevitably leads to non-vanishing steady-state bias, where the reconstruction fails to strictly satisfy physical measurements under heavy corruption. To resolve this, we propose Dual-Coupled PnP Diffusion, which restores the classical dual variable to provide integral feedback, theoretically guaranteeing asymptotic convergence to the exact data manifold. However, this rigorous geometric coupling introduces a secondary challenge: the accumulated dual residuals exhibit spectrally colored, structured artifacts that violate the Additive White Gaussian Noise (AWGN) assumption of diffusion priors, causing severe hallucinations. To bridge this gap, we introduce Spectral Homogenization (SH), a frequency-domain adaptation mechanism that modulates these structured residuals into statistically compliant pseudo-AWGN inputs. This effectively aligns the solver's rigorous optimization trajectory with the denoiser's valid statistical manifold. Extensive experiments on CT and MRI reconstruction demonstrate that our approach resolves the bias-hallucination trade-off, achieving state-of-the-art fidelity with significantly accelerated convergence.

Paper number 53:
Title: A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations
Authors: Soumya Dutta, Smruthi Balaji, Sriram Ganapathy
Abstract: Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.

Paper number 54:
Title: Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction
Authors: Rafael R. Baptista, André de Lima Salgado, Ricardo V. Godoy, Marcelo Becker, Thiago Boaventura, Gustavo J. G. Lahr
Abstract: Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.

Paper number 55:
Title: Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning
Authors: Manh Luong, Khai Nguyen, Dinh Phung, Gholamreza Haffari, Lizhen Qu
Abstract: Audio captioning systems face a fundamental challenge: teacher-forcing training creates exposure bias that leads to caption degeneration during inference. While contrastive methods have been proposed as solutions, they typically fail to capture the crucial temporal relationships between acoustic and linguistic modalities. We address this limitation by introducing the unbiased sliced Wasserstein RBF (USW-RBF) kernel with rotary positional embedding, specifically designed to preserve temporal information across modalities. Our approach offers a practical advantage: the kernel enables efficient stochastic gradient optimization, making it computationally feasible for real-world applications. Building on this foundation, we develop a complete audio captioning framework that integrates stochastic decoding to further mitigate caption degeneration. Extensive experiments on AudioCaps and Clotho datasets demonstrate that our method significantly improves caption quality, lexical diversity, and text-to-audio retrieval accuracy. Furthermore, we demonstrate the generalizability of our USW-RBF kernel by applying it to audio reasoning tasks, where it enhances the reasoning capabilities of large audio language models on the CompA-R in terms of correctness and quality. Our kernel also improves the reasoning accuracy of the MMAU-test-mini benchmarks by $4\%$. These results establish our approach as a powerful and generalizable solution for cross-modal alignment challenges in audio-language tasks.

Paper number 56:
Title: Stealthy Sensor Attacks Against Direct Data-Driven Controllers
Authors: Sribalaji C. Anand
Abstract: This paper investigates the vulnerability of discrete-time linear time-invariant systems to stealthy sensor attacks during the learning phase. In particular, we demonstrate that a {data-driven} adversary, without access to the system model, can inject attacks that mislead the operator into learning an {unstable} state-feedback controller. We further analyze attacks that degrade the performance of data-driven ${H}_2$ controllers, while ensuring that the operator can always compute a feasible controller. Potential mitigation strategies are also discussed. Numerical examples illustrate the effectiveness of the proposed attacks and underscore the importance of accounting for adversarial manipulations in data-driven controller design.

Paper number 57:
Title: A spherical amplitude-phase formulation for 3-D adaptive line-of-sight (ALOS) guidance with USGES stability guarantees
Authors: Erlend M. Coates, Thor I. Fossen
Abstract: A recently proposed 3-D adaptive line-of-sight (ALOS) path-following algorithm addressed coupled motion dynamics of marine craft, aircraft and uncrewed vehicles under environmental disturbances such as wind, waves and ocean currents. Stability analysis established uniform semi-global exponential stability (USGES) using a body-velocity-based amplitude-phase representation of the North-East-Down kinematic differential equations. However, the analysis is limited to straight-line paths, and restrictive assumptions are needed to ensure convergence of the vertical crab angle estimation error to zero. In this paper, we revisit the ALOS framework and introduce a novel spherical amplitude-phase design model that uses an alternative definition of the vertical crab angle. Our proposed formulation enables a significantly simplified stability proof, while retaining the USGES property for straight-line paths, removing restrictive assumptions on constant altitude/depth or zero horizontal crab angle, and remaining valid for general 3-D motion with nonzero roll, pitch and flight-path angles. We also show that the USGES result extends to a class of curved 3-D paths.

Paper number 58:
Title: LinGuinE: Longitudinal Guidance Estimation for Volumetric Tumour Segmentation
Authors: Nadine Garibli, Mayank Patwari, Bence Csiba, Yi Wei, Kostantinos Sidiropoulos
Abstract: Longitudinal volumetric tumour segmentation is critical for radiotherapy planning and response assessment, yet this problem is underexplored and most methods produce single-timepoint semantic masks, lack lesion correspondence, and offer limited radiologist control. We introduce LinGuinE (Longitudinal Guidance Estimation), a PyTorch framework that combines image registration and guided segmentation to deliver lesion-level tracking and volumetric masks across all scans in a longitudinal study from a single radiologist prompt. LinGuinE is temporally direction agnostic, requires no training on longitudinal data, and allows any registration and semi-automatic segmentation algorithm to be repurposed for the task. We evaluate various combinations of registration and segmentation algorithms within the framework. LinGuinE achieves state-of-the-art segmentation and tracking performance across four datasets with a total of 456 longitudinal studies. Tumour segmentation performance shows minimal degradation with increasing temporal separation. We conduct ablation studies to determine the impact of autoregression, pathology specific finetuning, and the use of real radiologist prompts. We release our code and substantial public benchmarking for longitudinal segmentation, facilitating future research.

Paper number 59:
Title: Adiabatic Capacitive Neuron: An Energy-Efficient Functional Unit for Artificial Neural Networks
Authors: Sachin Maheshwari, Mike Smart, Himadri Singh Raghav, Themis Prodromakis, Alexander Serb
Abstract: This paper introduces a new, highly energy-efficient, Adiabatic Capacitive Neuron (ACN) hardware implementation of an Artificial Neuron (AN) with improved functionality, accuracy, robustness and scalability over previous work. The paper describes the implementation of a \mbox{12-bit} single neuron, with positive and negative weight support, in an $\mathbf{0.18\mu m}$ CMOS technology. The paper also presents a new Threshold Logic (TL) design for a binary AN activation function that generates a low symmetrical offset across three process corners and five temperatures between $-55^o$C and $125^o$C. Post-layout simulations demonstrate a maximum rising and falling offset voltage of 9$mV$ compared to conventional TL, which has rising and falling offset voltages of 27$mV$ and 5$mV$ respectively, across temperature and process. Moreover, the proposed TL design shows a decrease in average energy of 1.5$\%$ at the SS corner and 2.3$\%$ at FF corner compared to the conventional TL design. The total synapse energy saving for the proposed ACN was above 90$\%$ (over 12x improvement) when compared to a non-adiabatic CMOS Capacitive Neuron (CCN) benchmark for a frequency ranging from 500$kHz$ to 100$MHz$. A 1000-sample Monte Carlo simulation including process variation and mismatch confirms the worst-case energy savings of $\>$90$\%$ compared to CCN in the synapse energy profile. Finally, the impact of supply voltage scaling shows consistent energy savings of above 90$\%$ (except all zero inputs) without loss of functionality.

Paper number 60:
Title: Spectrotemporal Feature Extraction in EHG Signals and Tocograms for Enhanced Preterm Birth Prediction
Authors: Senith Jayakody, Kalana Jayasooriya, Sashini Liyanage, Roshan Godaliyadda, Parakrama Ekanayake, Chathura Rathnayake
Abstract: Preterm birth (PTB), defined as delivery before 37 weeks of gestation, is a leading cause of neonatal mortality and long term health complications. Early detection is essential for enabling timely medical interventions. Electrohysterography (EHG) and tocography (TOCO) are promising non invasive tools for PTB prediction, but prior studies often suffer from class imbalance, improper oversampling, and reliance on features with limited physiological relevance. This work presents a machine learning (ML) pipeline incorporating robust preprocessing, physiologically grounded feature extraction, and rigorous evaluation. Features were extracted from EHG (and TOCO) signals using Mel frequency cepstral coefficients, statistical descriptors of wavelet coefficients, and peaks of the normalized power spectrum. Signal quality was enhanced via Karhunen Loeve Transform (KLT) denoising through eigenvalue based subspace decomposition. Multiple classifiers, including Logistic Regression, Support Vector Machines, Random Forest, Gradient Boosting, Multilayer Perceptron, and CatBoost, were evaluated on the TPEHGT dataset. The CatBoost classifier with KLT denoising achieved the highest performance on fixed interval segments of the TPEHGT dataset, reaching 97.28% accuracy and an AUC of 0.9988. Ablation studies confirmed the critical role of both KLT denoising and physiologically informed features. Comparative analysis showed that including TOCO signals did not substantially improve prediction over EHG alone, highlighting the sufficiency of EHG for PTB detection. These results demonstrate that combining denoising with domain-relevant features can yield highly accurate, robust, and clinically interpretable models, supporting the development of cost-effective and accessible PTB prediction tools, particularly in low-resource healthcare settings.

Paper number 61:
Title: Efficient CNN Inference on Ultra-Low-Power MCUs via Saturation-Aware Convolution
Authors: Shiming Li, Luca Mottola, Yuan Yao, Stefanos Kaxiras
Abstract: Quantized CNN inference on ultra-low-power MCUs incurs unnecessary computations in neurons that produce saturated output values. These values are too extreme and are eventually clamped to the boundaries allowed by the neuron. Often times, the neuron can save time by only producing a value that is extreme enough to lead to the clamped result, instead of completing the computation, yet without introducing any error. Based on this, we present saturation-aware convolution: an inference technique whereby we alter the order of computations in convolution kernels to induce earlier saturation, and value checks are inserted to omit unnecessary computations when the intermediate result is sufficiently extreme. Our experimental results display up to 24% inference time saving on a Cortex-M0+ MCU, with zero impact on accuracy.

Paper number 62:
Title: Gain-Scheduling Data-Enabled Predictive Control for Nonlinear Systems with Linearized Operating Regions
Authors: Sebastian Zieglmeier, Mathias Hudoba de Badyn, Narada D. Warakagoda, Thomas R. Krogstad, Paal Engelstad
Abstract: This paper presents a Gain-Scheduled Data-Enabled Predictive Control (GS-DeePC) framework for nonlinear systems based on multiple locally linear data representations. Instead of relying on a single global Hankel matrix, the operating range of a measurable scheduling variable is partitioned into regions, and regional Hankel matrices are constructed from persistently exciting data. To ensure smooth transitions between linearization regions and suppress region-induced chattering, composite regions are introduced, merging neighboring data sets and enabling a robust switching mechanism. The proposed method maintains the original DeePC problem structure and can achieve reduced computational complexity by requiring only short, locally informative data sequences. Extensive experiments on a nonlinear DC-motor with an unbalanced disc demonstrate the significantly improved control performance compared to standard DeePC.

Paper number 63:
Title: Log-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3)
Authors: Micah K. Condie, Abigaile E. Woodbury, Li-Yu Lin, Kartik A. Pant, Michael Walker, James Goppert
Abstract: We demonstrate that the error dynamics of a thrusting spacecraft are nearly group affine on the $SE_2(3)$ Lie group, and the nonlinearity can be bounded, or removed with the application of a dynamic inversion control law. A numerical example validates the results by showing agreement between the error predicted by the log-dynamics and the error obtained from classical integration of trajectories using Newtonian dynamics. The result clarifies how thrusting spacecraft dynamics fit within the invariant systems framework.

Paper number 64:
Title: BenchLink: An SoC-Based Benchmark for Resilient Communication Links in GPS-Denied Environments
Authors: Sidharth Santhi Nivas, Prem Sagar Pattanshetty Vasanth Kumar, Zhaoxi Zhang, Chenzhi Zhao, Maxwell McManus, Nicholas Mastronarde, Elizabeth Serena Bentley, George Sklivanitis, Dimitris A. Pados, Zhangyu Guan
Abstract: Accurate timing and synchronization, typically enabled by GPS, are essential for modern wireless communication systems. However, many emerging applications must operate in GPS-denied environments where signals are unreliable or disrupted, resulting in oscillator drift and carrier frequency impairments. To address these challenges, we present BenchLink, a System-on-Chip (SoC)-based benchmark for resilient communication links that functions without GPS and supports adaptive pilot density and modulation. Unlike traditional General Purpose Processor (GPP)-based software-defined radios (e.g. USRPs), the SoC-based design allows for more precise latency control. We implement and evaluate BenchLink on Zynq UltraScale+ MPSoCs, and demonstrate its effectiveness in both ground and aerial environments. A comprehensive dataset has also been collected under various conditions. We will make both the SoC-based link design and dataset available to the wireless community. BenchLink is expected to facilitate future research on data-driven link adaptation, resilient synchronization in GPS-denied scenarios, and emerging applications that require precise latency control, such as integrated radar sensing and communication.

Paper number 65:
Title: Linear viscoelastic rheological FrBD models
Authors: Luigi Romano, Ole Morten Aamo, Jan Åslund, Erik Frisk
Abstract: In [1], a new modeling paradigm for developing rate-and-state-dependent, control-oriented friction models was introduced. The framework, termed Friction with Bristle Dynamics (FrBD), combines nonlinear analytical expressions for the friction coefficient with constitutive equations for bristle-like elements. Within the FrBD framework, this letter introduces two novel formulations based on the two most general linear viscoelastic models for solids: the Generalized Maxwell (GM) and Generalized Kelvin-Voigt (GKV) elements. Both are analyzed in terms of boundedness and passivity, revealing that these properties are satisfied for any physically meaningful parametrization. An application of passivity for control design is also illustrated, considering an example from robotics. The findings of this letter systematically integrate rate-and-state dynamic friction models with linear viscoelasticity.

Paper number 66:
Title: Passive Beam Shaping via Binary-Coded Apertures
Authors: Mohammed E Eltayeb
Abstract: This paper presents a coded-aperture reflector for indoor mmWave coverage enhancement in obstructed or blocked LoS settings. We model the reflecting aperture using an equivalent array-factor formulation, where each passive reflecting cell contributes a reradiated field with phase set by the incident and departure directions. Building on this model, we develop two fabrication-friendly passive synthesis methods: (i) binary (1-bit) spatial coding that enables deterministic non-specular beam formation and multibeam patterns by selecting cell participation on a dense {\lambda}/2 lattice via an ON/OFF metallization mask, and (ii) diffraction-order (periodic) steering that exploits aperture periodicity to place selected diffraction orders at prescribed angles. We analytically characterize the proposed cosine-threshold quantization rule, including its asymptotic activation ratio and a distribution-free lower bound on non-specular gain relative to ideal continuous-phase control. To validate the proposed designs, we fabricate and metallize low-cost prototypes in-house using a copper-backed 3D-printed "inkwell" substrate with stencil-guided conductive ink deposition. 60 GHz over-the-air measurements show non-specular power enhancements on the order of +14-20 dB relative to passive, non-engineered (all-ON) reflector baselines. Results also demonstrate that fully passive, binary-coded apertures can deliver beam control with rapid in-lab manufacturability and offer a practical alternative to power-consuming reconfigurable surfaces for static indoor mmWave links.

Paper number 67:
Title: Visible Light Positioning With Lamé Curve LEDs: A Generic Approach for Camera Pose Estimation
Authors: Wenxuan Pan, Yang Yang, Dong Wei, Zhiyu Zhu, Jintao Wang, Huan Wu, Yao Nie
Abstract: Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lamé curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lamé curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lamé curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-n-points (FreePnP) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm.

Paper number 68:
Title: Automated Disentangling Analysis of Skin Colour for Lesion Images
Authors: Wenbo Yang, Eman Rezk, Walaa M. Moursi, Zhou Wang
Abstract: Machine-learning models applied to skin images often have degraded performance when the skin colour captured in images (SCCI) differs between training and deployment. These discrepancies arise from a combination of entangled environmental factors (e.g., illumination, camera settings) and intrinsic factors (e.g., skin tone) that cannot be accurately described by a single "skin tone" scalar -- a simplification commonly adopted by prior work. To mitigate such colour mismatches, we propose a skin-colour disentangling framework that adapts disentanglement-by-compression to learn a structured, manipulable latent space for SCCI from unlabelled dermatology images. To prevent information leakage that hinders proper learning of dark colour features, we introduce a randomized, mostly monotonic decolourization mapping. To suppress unintended colour shifts of localized patterns (e.g., ink marks, scars) during colour manipulation, we further propose a geometry-aligned post-processing step. Together, these components enable faithful counterfactual editing and answering an essential question: "What would this skin condition look like under a different SCCI?", as well as direct colour transfer between images and controlled traversal along physically meaningful directions (e.g., blood perfusion, camera white balance), enabling educational visualization of skin conditions under varying SCCI. We demonstrate that dataset-level augmentation and colour normalization based on our framework achieve competitive lesion classification performance. Ultimately, our work promotes equitable diagnosis through creating diverse training datasets that include different skin tones and image-capturing conditions.

Paper number 69:
Title: Informativity and Identifiability for Identification of Networks of Dynamical Systems
Authors: Anders Hansson, João Victor Galvão da Mata, Martin S. Andersen
Abstract: In this paper, we show how informativity and identifiability for networks of dynamical systems can be investigated using Gröbner bases. We provide a sufficient condition for informativity in terms of positive definiteness of the spectrum of external signals and full generic rank of the transfer function relating the external signals to the inputs of the predictor. Moreover, we show how generic local network identifiability can be investigated by computing the dimension of the fiber associated with the closed loop transfer function from external measurable signals to the measured outputs.

Paper number 70:
Title: TokEye: Fast Signal Extraction for Fluctuating Time Series via Offline Self-Supervised Learning From Fusion Diagnostics to Bioacoustics
Authors: Nathaniel Chen, Kouroche Bouchiat, Peter Steiner, Andrew Rothstein, David Smith, Max Austin, Mike van Zeeland, Azarakhsh Jalalvand, Egemen Kolemen
Abstract: Next-generation fusion facilities like ITER face a "data deluge," generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a "signals-first" self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data across a variety of sensors. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in this https URL.

Paper number 71:
Title: Preference Analysis Using Random Spanning Trees: A Stochastic Sampling Approach to Inconsistent Pairwise Comparisons
Authors: Salvatore Greco, Sajid Siraj, Michele Lundy
Abstract: Eliciting preferences from human judgements is inherently imprecise, yet most decision analysis methods force a single priority vector from pairwise comparisons, discarding the information embedded in inconsistencies. We instead leverage inconsistency to characterise preference uncertainty by examining all priority vectors consistent with the decision maker's judgements. Spanning tree analysis enumerates combinations of evaluation and weighting vectors from pairwise comparison subsets, each yielding a distinct preference vector and collectively defining a distribution over possible preference orderings. Since exponential growth renders complete enumeration prohibitive, we propose a stochastic random walk sampling approach with sample sizes formally established via statistical sampling theory. This enables two key metrics: Pairwise Winning Indices (PWIs), the probability one alternative is preferred to another, and Rank Acceptability Indices (RAIs), the probability an alternative attains a given rank. A notable advantage is applicability to incomplete pairwise comparisons, common in large-scale problems. We validate the methodology against complete enumeration on a didactic example, then demonstrate scalability on a telecommunications backbone infrastructure selection case study involving billions of spanning tree combinations. The approach yields probabilistic insights into preference robustness and ranking uncertainty, supporting informed decisions without the burden of exact enumeration.

Paper number 72:
Title: Harmony and Duality: An introduction to Music Theory
Authors: Maksim Lipyanskiy
Abstract: We develop aspects of music theory related to harmony, such as scales, chord formation and improvisation from a combinatorial perspective. The goal is to provide a foundation for this subject by deriving the basic structure from a few assumptions, rather than writing down long lists of chords/scales to memorize without an underlying principle. Our approach involves introducing constraints that limit the possible scales we can consider. For example, we may impose the constraint that two voices cannot be only a semitone apart as this is too dissonant. We can then study scales that do not contain notes that are a semitone apart. A more refined constraint avoids three voices colliding by studying scales that do not have three notes separated only by semitones. Additionally, we require that our scales are complete, which roughly means that they are the maximal sets of tones that satisfy these constraints. As it turns out, completeness as applied to these simple two/three voice constraints characterizes the types of scales that are commonly used in music composition. Surprisingly, there is a correspondence between scales subject to the two-voice constraint and those subject to the three-voice constraint. We formulate this correspondence as a duality statement that provides a way to understand scales subject to one type of constraint in terms of scales subject to the other. Finally, we combine these constraint ideas to provide a classification of chords.

Paper number 73:
Title: DreamWaQ++: Obstacle-Aware Quadrupedal Locomotion With Resilient Multi-Modal Reinforcement Learning
Authors: I Made Aswin Nahrendra, Byeongho Yu, Minho Oh, Dongkyu Lee, Seunghyun Lee, Hyeonwoo Lee, Hyungtae Lim, Hyun Myung
Abstract: Quadrupedal robots hold promising potential for applications in navigating cluttered environments with resilience akin to their animal counterparts. However, their floating base configuration makes them vulnerable to real-world uncertainties, yielding substantial challenges in their locomotion control. Deep reinforcement learning has become one of the plausible alternatives for realizing a robust locomotion controller. However, the approaches that rely solely on proprioception sacrifice collision-free locomotion because they require front-feet contact to detect the presence of stairs to adapt the locomotion gait. Meanwhile, incorporating exteroception necessitates a precisely modeled map observed by exteroceptive sensors over a period of time. Therefore, this work proposes a novel method to fuse proprioception and exteroception featuring a resilient multi-modal reinforcement learning. The proposed method yields a controller that showcases agile locomotion performance on a quadrupedal robot over a myriad of real-world courses, including rough terrains, steep slopes, and high-rise stairs, while retaining its robustness against out-of-distribution situations.

Paper number 74:
Title: A Framework for Robust Lossy Compression of Heavy-Tailed Sources
Authors: Karim Ezzeddine, Jihad Fahs, Ibrahim Abou-Faycal
Abstract: We study the rate-distortion problem for both scalar and vector memoryless heavy-tailed $\alpha$-stable sources ($0 < \alpha < 2$). Using a recently defined notion of ``strength" as a power measure, we derive the rate-distortion function for $\alpha$-stable sources subject to a constraint on the strength of the error and show it to be logarithmic in the strength-to-distortion ratio. We show how our framework paves the way for finding optimal quantizers for $\alpha$-stable sources and other general heavy-tailed ones. In addition, we study high-rate scalar quantizers and show that uniform ones are asymptotically optimal under the error-strength distortion measure. We compare uniform Gaussian and Cauchy quantizers and show that more representation points for the Cauchy source are required to guarantee the same quantization quality. Our findings generalize the well-known results of rate-distortion and quantization of Gaussian sources ($\alpha = 2$) under a quadratic distortion measure.

Paper number 75:
Title: Optimization with Multi-sourced Information and Unknown Reliability: A Distributionally Robust Approach
Authors: Yanru Guo, Ruiwei Jiang, Siqian Shen
Abstract: In problems that involve input parameter information gathered from multiple data sources with varying reliability, incorporating decision makers' trust on different sources in optimization models can potentially improve solution performance. In this work, we propose a novel multi-reference distributionally robust optimization (MR-DRO) framework, where the model inputs are uncertain and their probability distributions can be statistically inferred from multiple information sources. Via nonparametric data fusion, we construct a Wasserstein ambiguity set to minimize the worst-case expected cost of a stochastic objective function, accounting for both uncertainty and unknown reliability of several given information sources. We reformulate the MR-DRO model as a linear program given linear objective and constraints in the original problem. We also incorporate a dynamic trust update mechanism that adjusts the trust for each source based on its performance over time. In addition, we introduce the concept of probability dominance to identify sources with dominant trust. Via computational studies using resource allocation and portfolio optimization instances, we demonstrate the effectiveness of the MR-DRO approach compared to traditional optimization frameworks relying on a single data source. Our results highlight the significance of integrating (dynamic) decision maker's trust in optimization under uncertainty, particularly when given diverse and potentially conflicting input data.

Paper number 76:
Title: Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning
Authors: Nicola Cibin, Bas Mulder, Herman Carstens, Peter Palensky, Alexandru Ştefanov
Abstract: The digital transformation of power systems is accelerating the adoption of IEC 61850 standard. However, its communication protocols, including Sampled Values (SV), lack built-in security features such as authentication and encryption, making them vulnerable to malicious packet injection. Such cyber attacks can delay fault clearance or trigger unintended circuit breaker operations. While most existing research focuses on detecting cyber attacks in digital substations, intrusion prevention systems have been disregarded because of the risk of potential communication network disruptions. This paper proposes a novel method using hybrid statistical-deep learning for the detection, prevention, and source localization of IEC 61850 SV injection attacks. The method uses exponentially modified Gaussian distributions to model communication network latency and long short-term memory and Elman recurrent neural network to detect anomalous variations in the estimated probability distributions. It effectively discards malicious SV frames with minimal processing overhead and latency, maintains robustness against communication network latency variation and time-synchronization issues, and guarantees a near-zero false positive rate in non-attack scenarios. Comprehensive validation is conducted on three testbeds involving industrial-grade devices, hardware-in-the-loop simulations, virtualized intelligent electronic devices and merging units, and high-fidelity emulated communication networks. Results demonstrate the method's suitability for practical deployment in IEC 61850-compliant digital substations.

Paper number 77:
Title: Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation
Authors: Jaechul Roh, Zachary Novack, Yuefeng Peng, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Amir Houmansadr
Abstract: Generative AI systems for music and video commonly use text-based filters to prevent regurgitation of copyrighted material. We expose a significant vulnerability in this approach by introducing Adversarial PhoneTic Prompting (APT), a novel attack that bypasses these safeguards by exploiting phonetic memorization--the tendency of models to bind sub-lexical acoustic patterns (phonemes, rhyme, stress, cadence) to memorized copyrighted content. APT replaces iconic lyrics with homophonic but semantically unrelated alternatives (e.g., "mom's spaghetti" becomes "Bob's confetti"), preserving phonetic structure while evading lexical filters. We evaluate APT on leading lyrics-to-song models (Suno, YuE) across English and Korean songs spanning rap, pop, and K-pop. APT achieves 91% average similarity to copyrighted originals, versus 13.7% for random lyrics and 42.2% for semantic paraphrases. Embedding analysis confirms the mechanism: YuE's text encoder treats APT-modified lyrics as near-identical to originals (cosine similarity 0.90) while Sentence-BERT semantic similarity drops to 0.71, showing the model encodes phonetic structure over meaning. This vulnerability extends cross-modally--Veo 3 reconstructs visual scenes from original music videos when prompted with APT lyrics alone, despite no visual cues in the prompt. We further show that phonetic-semantic defense signatures fail, as APT prompts exhibit higher semantic similarity than benign paraphrases. Our findings reveal that sub-lexical acoustic structure acts as a cross-modal retrieval key, rendering current copyright filters systematically vulnerable. Demo examples are available at this https URL.

Paper number 78:
Title: RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer
Authors: Fangyu Du, Taiqing Li, Qian Qiao, Tan Yu, Ziwei Zhang, Dingcheng Zhen, Xu Jia, Yang Yang, Shunshun Yin, Siyuan Liu
Abstract: Audio-driven portrait animation aims to synthesize realistic and natural talking head videos from an input audio signal and a single reference image. While existing methods achieve high-quality results by leveraging high-dimensional intermediate representations and explicitly modeling motion dynamics, their computational complexity renders them unsuitable for real-time deployment. Real-time inference imposes stringent latency and memory constraints, often necessitating the use of highly compressed latent representations. However, operating in such compact spaces hinders the preservation of fine-grained spatiotemporal details, thereby complicating audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a unified framework for generating high-quality talking portraits under real-time constraints. Specifically, RAP introduces a hybrid attention mechanism for fine-grained audio control, and a static-dynamic training-inference paradigm that avoids explicit motion supervision. Through these techniques, RAP achieves precise audio-driven control, mitigates long-term temporal drift, and maintains high visual fidelity. Extensive experiments demonstrate that RAP achieves state-of-the-art performance while operating under real-time constraints.

Paper number 79:
Title: LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control
Authors: Junki Ohmura, Yuki Ito, Emiru Tsunoo, Toshiyuki Sekiya, Toshiyuki Kumakura
Abstract: Fine-grained control over voice impressions (e.g., making a voice brighter or calmer) is a key frontier for creating more controllable text-to-speech. However, this nascent field faces two key challenges. The first is the problem of impression leakage, where the synthesized voice is undesirably influenced by the speaker's reference audio, rather than the separately specified target impression, and the second is the lack of a public, annotated corpus. To mitigate impression leakage, we propose two methods: 1) a training strategy that separately uses an utterance for speaker identity and another utterance of the same speaker for target impression, and 2) a novel reference-free model that generates a speaker embedding solely from the target impression, achieving the benefits of improved robustness against the leakage and the convenience of reference-free generation. Objective and subjective evaluations demonstrate a significant improvement in controllability. Our best method reduced the mean squared error of 11-dimensional voice impression vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high fidelity. To foster reproducible research, we introduce LibriTTS-VI, the first public voice impression dataset released with clear annotation standards, built upon the LibriTTS-R corpus.

Paper number 80:
Title: Optimum Spectrum Extension for PAPR Reduction of DFT-s-OFDM
Authors: Renaud-Alexandre Pitaval, Fredrik Berggren, Branislav M. Popovic
Abstract: Uplink coverage in cellular networks is constrained by the maximum UE transmit power, making peak-to-average power ratio (PAPR) reduction essential. While DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves significantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains too high for higher-rate transmission. Spectrum extension (SE) combined with FDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper considers FDSS-SE with parametrized FDSS windows spanning a range of possible power ripples, as well as arbitrary circular shifts of the subcarrier coefficients. We optimize both the frequency shift and the SE size, and show that there exists an optimal SE size for reducing the PAPR and another one for increasing the rate. Analysis and simulations reveal that both optima largely depend on the window attenuation but are nearly invariant in proportion to the bandwidth. While the PAPR-optimal SE size is nearly invariant to the constellation order of regular QAM, the rate-optimal SE size depends also on the SNR. These insights provide practical guidelines for beyond-5G uplink coverage enhancement, highlighting that SE size should be individually configured according to the user's FDSS window and link quality.

Paper number 81:
Title: Atlas-free Brain Network Transformer
Authors: Shuai Huang, Xuan Kan, James J. Lah, Deqiang Qiu
Abstract: Current atlas-based approaches to brain network analysis rely heavily on standardized anatomical or connectivity-driven brain atlases. However, these fixed atlases often introduce significant limitations, such as spatial misalignment across individuals, functional heterogeneity within predefined regions, and atlas-selection biases, collectively undermining the reliability and interpretability of the derived brain networks. To address these challenges, we propose a novel atlas-free brain network transformer (atlas-free BNT) that leverages individualized brain parcellations derived directly from subject-specific resting-state fMRI data. Our approach computes ROI-to-voxel connectivity features in a standardized voxel-based feature space, which are subsequently processed using the BNT architecture to produce comparable subject-level embeddings. Experimental evaluations on sex classification and brain-connectome age prediction tasks demonstrate that our atlas-free BNT consistently outperforms state-of-the-art atlas-based methods, including elastic net, BrainGNN, Graphormer and the original BNT. Our atlas-free approach significantly improves the precision, robustness, and generalizability of brain network analyses. This advancement holds great potential to enhance neuroimaging biomarkers and clinical diagnostic tools for personalized precision medicine. Reproducible code is available at this https URL

Paper number 82:
Title: Performance Analysis of Cell-Free Massive MIMO under Imperfect LoS Phase Tracking
Authors: Noor Ul Ain, Lorenzo Miretti, Renato L. G. Cavalcante, Slawomir Stanczak
Abstract: We study the impact of imperfect line-of-sight (LoS) phase tracking on the uplink performance of cell-free massive MIMO networks. Unlike prior works that assume perfectly known or completely unknown phases, we consider a realistic regime where LoS phases are estimated with residual uncertainty due to hardware impairments, mobility, and synchronization errors. To this end, we propose a Rician fading model where LoS components are rotated by imperfect phase estimates and attenuated by a deterministic \textit{phase-error penalty factor}. We derive a linear MMSE channel estimator that accounts for statistical phase errors and unifies prior results, reducing to the Bayesian MMSE estimator when phase is perfectly known and to a zero-mean model when no phase information is available. To address the non-Gaussian setting, we introduce a virtual uplink model that preserves second-order statistics of channel estimation, enabling the derivation of tractable virtual centralized and distributed MMSE beamformers. To ensure fair assessment of network performance, we apply these virtual beamformers to the operational uplink model that reflects the actual physical channel and compute the spectral efficiency bounds available in the literature. Numerical results show that our framework bridges idealized assumptions and practical tracking limitations, providing rigorous performance benchmarks and design insights for 6G cell-free networks.
    