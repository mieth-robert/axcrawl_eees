
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Flight of Dynamic Targeting on the CogniSAT-6 Spacecraft
Authors: Steve Chien, Itai Zilberstein, Alberto Candela, David Rijlaarsdam, Tom Hendrix, Aubrey Dunne, Aragon Oriol, Miquel Juan Puig
Abstract: Dynamic targeting (DT) is a spacecraft autonomy concept in which sensor data is acquired and rapidly analyzed and used to drive subsequent observation. We describe the low Earth orbit application of this approach in which lookahead imagery is analyzed to detect clouds, thermal anomalies, or land use cases to drive higher quality near nadir imaging. Use cases for such a capability include: cloud avoidance, storm hunting, search for planetary boundary layer events, plume study, and beyond. The DT concept requires a lookahead sensor or agility to use a primary sensor in such a mode, edge computing to analyze images rapidly onboard, and a primary followup sensor. Additionally, an inter-satellite or low latency communications link can be leveraged for cross platform tasking. We describe implementation in progress to fly DT in early 2025 on the CogniSAT-6 (Ubotica/Open Cosmos) spacecraft that launched in March 2024 on the SpaceX Transporter-10 launch.

Paper number 2:
Title: A Synthetic-to-Real Dehazing Method based on Domain Unification
Authors: Zhiqiang Yuan, Jinchao Zhang, Jie Zhou
Abstract: Due to distribution shift, the performance of deep learning-based method for image dehazing is adversely affected when applied to real-world hazy images. In this paper, we find that such deviation in dehazing task between real and synthetic domains may come from the imperfect collection of clean data. Owing to the complexity of the scene and the effect of depth, the collected clean data cannot strictly meet the ideal conditions, which makes the atmospheric physics model in the real domain inconsistent with that in the synthetic domain. For this reason, we come up with a synthetic-to-real dehazing method based on domain unification, which attempts to unify the relationship between the real and synthetic domain, thus to let the dehazing model more in line with the actual situation. Extensive experiments qualitatively and quantitatively demonstrate that the proposed dehazing method significantly outperforms state-of-the-art methods on real-world images.

Paper number 3:
Title: Graph Connectionist Temporal Classification for Phoneme Recognition
Authors: Henry Graf√©, Hugo Van hamme
Abstract: Automatic Phoneme Recognition (APR) systems are often trained using pseudo phoneme-level annotations generated from text through Grapheme-to-Phoneme (G2P) systems. These G2P systems frequently output multiple possible pronunciations per word, but the standard Connectionist Temporal Classification (CTC) loss cannot account for such ambiguity during training. In this work, we adapt Graph Temporal Classification (GTC) to the APR setting. GTC enables training from a graph of alternative phoneme sequences, allowing the model to consider multiple pronunciations per word as valid supervision. Our experiments on English and Dutch data sets show that incorporating multiple pronunciations per word into the training loss consistently improves phoneme error rates compared to a baseline trained with CTC. These results suggest that integrating pronunciation variation into the loss function is a promising strategy for training APR systems from noisy G2P-based supervision.

Paper number 4:
Title: A Fully Analog Implementation of Model Predictive Control with Application to Buck Converters
Authors: Simone Pirrera, Lorenzo Calogero, Francesco Gabriele, Diego Regruto, Alessandro Rizzo, Gianluca Setti
Abstract: This paper proposes a novel approach to design analog electronic circuits that implement Model Predictive Control (MPC) policies for plants described by affine models. The combination of state-of-the-art approaches to define reduced-complexity Explicit MPC (EMPC) is employed to realize an analog circuit characterized by a limited amount of low-latency and commercially available components. The practical feasibility and effectiveness of the proposed approach are demonstrated through its application in the design of an advanced controller for DC-DC Buck converters. We formally analyze the stability of the obtained system and conduct extensive numerical simulations to demonstrate that it is capable of achieving outstanding load disturbance rejection performance, outclassing standard approaches.

Paper number 5:
Title: Developing a Framework to Simulate Quantitative Ultrasound Flow and Tissue Motion for Ultrafast Doppler Ultrasound
Authors: Qiang Fu, Changhui Li
Abstract: Ultrafast power Doppler imaging (uPDI) has made significant progress and become an important imaging method for both research and clinical implementations. While, it lacks simulation tools that can perform three-dimensional (3D) quantitative flow with tissue motion close to realistic conditions. In this study, we explore to construct an open-source framework, named 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling of 3D vascular flow with tissue motion and uPDI imaging. The framework integrates a L-system-based vascular generator with SimVascular CFD for hemodynamics, a tissue motion simulator supporting user-defined or clinical-data-driven condition, an optimized PFILED ultrasound simulator, a precomputed-matrix-based reconstructor, and a quantitative analyzer (MSE/PSNR/SSIM). Results demonstrate distinct influences of four motion patterns on SVD decomposition; successful 3D imaging of rabbit kidney (SSIM = 0.951), generated vasculature (SSIM = 0.902), and clinical pulmonary arteries (SSIM = 0.850); and GPU acceleration permitting 1-million-scatterer simulation in 4,117 seconds with 18.8* speedup for 100-frame 3D-uPDI generation. 3D-FQFlow establishes the first open-source framework for quantitative validation of uPDI under realistic vascular and motion conditions, creating a reproducible standard for microvascular imaging research (this https URL).

Paper number 6:
Title: State Estimation for Linear Systems with Non-Gaussian Measurement Noise via Dynamic Programming
Authors: Mohammad Hussein Yoosefian Nooshabadi, Laurent Lessard
Abstract: We propose a new recursive estimator for linear dynamical systems under Gaussian process noise and non-Gaussian measurement noise. Specifically, we develop an approximate maximum a posteriori (MAP) estimator using dynamic programming and tools from convex analysis. Our approach does not rely on restrictive noise assumptions and employs a Bellman-like update instead of a Bayesian update. Our proposed estimator is computationally efficient, with only modest overhead compared to a standard Kalman filter. Simulations demonstrate that our estimator achieves lower root mean squared error (RMSE) than the Kalman filter and has comparable performance to state-of-the-art estimators, while requiring significantly less computational power.

Paper number 7:
Title: Time-Modulated Intelligent Reflecting Surfaces for Integrated Sensing, Communication and Security: A Generative AI Design Framework
Authors: Zhihao Tao, Athina Petropulu, H. Vincent Poor
Abstract: We propose a novel approach to achieve physical layer security for integrated sensing and communication (ISAC) systems operating in the presence of targets that may be eavesdroppers. The system is aided by a time-modulated intelligent reflecting surface (TM-IRS), which is configured to preserve the integrity of the transmitted data at one or more legitimate communication users (CUs) while making them appear scrambled in all other directions. The TM-IRS design leverages a generative flow network (GFlowNet) framework to learn a stochastic policy that samples high-performing TM-IRS configurations from a vast discrete parameter space. Specifically, we begin by formulating the achievable sum rate for the legitimate CUs and the beampattern gain toward the target direction, based on which we construct reward functions for GFlowNets that jointly capture both communication and sensing performance. The TM-IRS design is modeled as a deterministic Markov decision process (MDP), where each terminal state corresponds to a complete configuration of TM-IRS parameters. GFlowNets, parametrized by deep neural networks are employed to learn a stochastic policy that samples TM-IRS parameter sets with probability proportional to their associated reward. Experimental results demonstrate the effectiveness of the proposed GFlowNet-based method in integrating sensing, communication and security simultaneously, and also exhibit significant sampling efficiency as compared to the exhaustive combinatorial search and enhanced robustness against the rule-based TM-IRS design method.

Paper number 8:
Title: On the Contribution of Lexical Features to Speech Emotion Recognition
Authors: David Combei
Abstract: Although paralinguistic cues are often considered the primary drivers of speech emotion recognition (SER), we investigate the role of lexical content extracted from speech and show that it can achieve competitive and in some cases higher performance compared to acoustic models. On the MELD dataset, our lexical-based approach obtains a weighted F1-score (WF1) of 51.5%, compared to 49.3% for an acoustic-only pipeline with a larger parameter count. Furthermore, we analyze different self-supervised (SSL) speech and text representations, conduct a layer-wise study of transformer-based encoders, and evaluate the effect of audio denoising.

Paper number 9:
Title: Power-Measurement-Based Channel Estimation for Beyond Diagonal RIS
Authors: Yijie Liu, Weidong Mei, He Sun, Dong Wang, Peilan Wang
Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS), with its enhanced degrees of freedom compared to conventional RIS, has demonstrated notable potential for enhancing wireless communication performance. However, a key challenge in employing BD-RIS lies in accurately acquiring its channel state information (CSI) with both the base station (BS) and users. Existing BD-RIS channel estimation methods rely mainly on dedicated pilot signals, which increase system overhead and may be incompatible with current communication protocols. To overcome these limitations, this letter proposes a new single-layer neural network (NN)-enabled channel estimation method utilizing only the easily accessible received power measurements at user terminals. In particular, we show that the received signal power can be expressed in a form similar to a single-layer NN, where the weights represent the BD-RIS's CSI. This structure enables the recovery of CSI using the backward propagation, based on power measurements collected under varying training reflection coefficients. Numerical results show that our proposed method can achieve a small normalized mean square error (NMSE), particularly when the number of training reflections is large.

Paper number 10:
Title: Full-Angle Ray Antenna Array and Omnicell Wireless Communication System
Authors: Xuancheng Zhu, Zhiwen Zhou, Yong Zeng
Abstract: Ray antenna array (RAA) was recently proposed as a novel multi-antenna architecture that arranges multiple massive cheap antenna elements into simple uniform linear arrays (sULAs) with different orientations. Compared with traditional architectures like hybrid analog/digital beamforming with uniform linear array (ULA) and uniform circular array (UCA), RAA has several promising advantages such as significantly reduced hardware cost, higher beamforming gains and the ability of providing uniform angular resolution for all directions. In this paper, we propose a full-angle RAA architecture and an innovative omnicell wireless communication paradigm enabled by full-angle RAA. The proposed full-angle RAA expands RAA's orientation angle to the full angle domain, such that the RAA's advantages can be exploited to all directions. This further enables the new concept of omnicell wireless communication system, with the base station equipped by full-angle RAA and deployed at the center of each cell. Compared to the conventional cell sectoring wireless communication system, the proposed omnicell system is expected to not only significantly reduce the inter-user interference, but also improve the cost efficiency. Extensive analytical and numerical results are provided to compare those key performance indicators such as the spatial resolution and the communication rate of the proposed full-angle RAA based omnicell wireless communication system against the conventional ULA/UCA-based cell sectoring systems.

Paper number 11:
Title: Affine Filter Bank Modulation (AFBM): A Novel 6G ISAC Waveform with Low PAPR and OOBE
Authors: Kuranage Roche Rayan Ranasinghe, Henrique L. Senger, Gustavo P. Gon√ßalves, Hyeon Seok Rou, Bruno S. Chang, Giuseppe Thadeu Freitas de Abreu, Didier Le Ruyet
Abstract: We propose the affine filter bank modulation (AFBM) waveform for enhanced integrated sensing and communications (ISAC) in sixth generation (6G), designed by drawing on concepts from classical filter bank multicarrier modulation (FBMC) theory and recent advances in chirp-domain waveforms, particularly affine frequency division multiplexing (AFDM). Specifically, AFBM exhibits several desirable properties, with emphasis on its remarkably low peak-to-average power ratio (PAPR) and reduced out-of-band emission (OOBE) when benchmarked against the conventional AFDM waveform under doubly-dispersive (DD) channel conditions. In the communications setting, reliable symbol detection is achieved using a tailored low-complexity Gaussian belief propagation (GaBP)-based algorithm, while in the sensing setting, a range and velocity estimation approach is developed that integrates an expectation maximization (EM)-assisted probabilistic data association (PDA) framework to accurately identify surrounding targets. The highlighted performance and benefits of AFBM are validated through analytical and numerical evaluations, including conventional metrics such as ambiguity function (AF), bit error rate (BER), and root mean square error (RMSE), consolidating its position as a promising waveform for next-generation wireless systems.

Paper number 12:
Title: Resource Allocation and Beamforming in FIM-Assisted BS and STAR-BD-RIS-Aided NOMA: A Meta-Learning Approach
Authors: Armin Farhadi, Maryam Cheraghy, Qingqing Wu, Eduard Jorswieck
Abstract: This study explores a flexible intelligent metasurface (FIM)-based wireless communication system that integrates simultaneously transmitting and reflecting beyond diagonal reconfigurable intelligent surfaces (STAR-BD-RIS) with non-orthogonal multiple access (NOMA). The system features a multi-antenna FIM-assisted base station (BS) aided by dual-sector BD-RIS. The FIM consists of cost-effective radiating elements that can independently emit signals and dynamically adjust their vertical positions ("morphing"). The goal is to maximize energy efficiency by jointly optimizing BS beamforming, the STAR-BD-RIS matrix, NOMA constraints, and the FIM surface shape under power limits. Due to the problem's non-convexity, a meta-soft actor-critic (Meta-SAC) algorithm is proposed for adaptive optimization. Simulation results show that Meta-SAC outperforms the Meta-DDPG algorithm, and FIM-assisted designs yield substantial energy efficiency gains over benchmark schemes.

Paper number 13:
Title: Time-domain sound field estimation using kernel ridge regression
Authors: Jesper Brunnstr√∂m, Martin Bo M√∏ller, Jan √òstergaard, Shoichi Koyama, Toon van Waterschoot, Marc Moonen
Abstract: Sound field estimation methods based on kernel ridge regression have proven effective, allowing for strict enforcement of physical properties, in addition to the inclusion of prior knowledge such as directionality of the sound field. These methods have been formulated for single-frequency sound fields, restricting the types of data and prior knowledge that can be used. In this paper, the kernel ridge regression approach is generalized to consider discrete-time sound fields. The proposed method provides time-domain sound field estimates that can be computed in closed form, are guaranteed to be physically realizable, and for which time-domain properties of the sound fields can be exploited to improve estimation performance. Exploiting prior information on the time-domain behaviour of room impulse responses, the estimation performance of the proposed method is shown to be improved using a time-domain data weighting, demonstrating the usefulness of the proposed approach. It is further shown using both simulated and real data that the time-domain data weighting can be combined with a directional weighting, exploiting prior knowledge of both spatial and temporal properties of the room impulse responses. The theoretical framework of the proposed method enables solving a broader class of sound field estimation problems using kernel ridge regression where it would be required to consider the time-domain response rather than the frequency-domain response of each frequency separately.

Paper number 14:
Title: Stabilizing RED using the Koopman Operator
Authors: Shraddha Chavan, Kunal N. Chaudhury
Abstract: The widely used RED (Regularization-by-Denoising) framework uses pretrained denoisers as implicit regularizers for model-based reconstruction. Although RED generally yields high-fidelity reconstructions, the use of black-box denoisers can sometimes lead to instability. In this letter, we propose a data-driven mechanism to stabilize RED using the Koopman operator, a classical tool for analyzing dynamical systems. Specifically, we use the operator to capture the local dynamics of RED in a low-dimensional feature space, and its spectral radius is used to detect instability and formulate an adaptive step-size rule that is model-agnostic, has modest overhead, and requires no retraining. We test this with several pretrained denoisers to demonstrate the effectiveness of the proposed Koopman stabilization.

Paper number 15:
Title: CardiacFlow: 3D+t Four-Chamber Cardiac Shape Completion and Generation via Flow Matching
Authors: Qiang Ma, Qingjie Meng, Mengyun Qiao, Paul M. Matthews, Declan P. O'Regan, Wenjia Bai
Abstract: Learning 3D+t shape completion and generation from multi-view cardiac magnetic resonance (CMR) images requires a large amount of high-resolution 3D whole-heart segmentations (WHS) to capture shape priors. In this work, we leverage flow matching techniques to learn deep generative flows for augmentation, completion, and generation of 3D+t shapes of four cardiac chambers represented implicitly by segmentations. Firstly, we introduce a latent rectified flow to generate 3D cardiac shapes for data augmentation, learnt from a limited number of 3D WHS data. Then, a label completion network is trained on both real and synthetic data to reconstruct 3D+t shapes from sparse multi-view CMR segmentations. Lastly, we propose CardiacFlow, a novel one-step generative flow model for efficient 3D+t four-chamber cardiac shape generation, conditioned on the periodic Gaussian kernel encoding of time frames. The experiments on the WHS datasets demonstrate that flow-based data augmentation reduces geometric errors by 16% in 3D shape completion. The evaluation on the UK Biobank dataset validates that CardiacFlow achieves superior generation quality and periodic consistency compared to existing baselines.

Paper number 16:
Title: Hierarchical Decision-Making in Population Games
Authors: Yu-Wen Chen, Nuno C. Martins, Murat Arcak
Abstract: This paper introduces a hierarchical framework for population games, where individuals delegate decision-making to proxies that act within their own strategic interests. This framework extends classical population games, where individuals are assumed to make decisions directly, to capture various real-world scenarios involving multiple decision layers. We establish equilibrium properties and provide convergence results for the proposed hierarchical structure. Additionally, based on these results, we develop a systematic approach to analyze population games with general convex constraints, without requiring individuals to have full knowledge of the constraints as in existing methods. We present a navigation application with capacity constraints as a case study.

Paper number 17:
Title: Brain Tumor Detection Through Diverse CNN Architectures in IoT Healthcare Industries: Fast R-CNN, U-Net, Transfer Learning-Based CNN, and Fully Connected CNN
Authors: Mohsen Asghari Ilani, Yaser M. Banad
Abstract: Artificial intelligence (AI)-powered deep learning has advanced brain tumor diagnosis in Internet of Things (IoT)-healthcare systems, achieving high accuracy with large datasets. Brain health is critical to human life, and accurate diagnosis is essential for effective treatment. Magnetic Resonance Imaging (MRI) provides key data for brain tumor detection, serving as a major source of big data for AI-driven image classification. In this study, we classified glioma, meningioma, and pituitary tumors from MRI images using Region-based Convolutional Neural Network (R-CNN) and UNet architectures. We also applied Convolutional Neural Networks (CNN) and CNN-based transfer learning models such as Inception-V3, EfficientNetB4, and VGG19. Model performance was assessed using F-score, recall, precision, and accuracy. The Fast R-CNN achieved the best results with 99% accuracy, 98.5% F-score, 99.5% Area Under the Curve (AUC), 99.4% recall, and 98.5% precision. Combining R-CNN, UNet, and transfer learning enables earlier diagnosis and more effective treatment in IoT-healthcare systems, improving patient outcomes. IoT devices such as wearable monitors and smart imaging systems continuously collect real-time data, which AI algorithms analyze to provide immediate insights for timely interventions and personalized care. For external cohort cross-dataset validation, EfficientNetB2 achieved the strongest performance among fine-tuned EfficientNet models, with 92.11% precision, 92.11% recall/sensitivity, 95.96% specificity, 92.02% F1-score, and 92.23% accuracy. These findings underscore the robustness and reliability of AI models in handling diverse datasets, reinforcing their potential to enhance brain tumor classification and patient care in IoT healthcare environments.

Paper number 18:
Title: From perception to production: how acoustic invariance facilitates articulatory learning in a self-supervised vocal imitation model
Authors: Marvin Lavechin, Thomas Hueber
Abstract: Human infants face a formidable challenge in speech acquisition: mapping extremely variable acoustic inputs into appropriate articulatory movements without explicit instruction. We present a computational model that addresses the acoustic-to-articulatory mapping problem through self-supervised learning. Our model comprises a feature extractor that transforms speech into latent representations, an inverse model that maps these representations to articulatory parameters, and a synthesizer that generates speech outputs. Experiments conducted in both single- and multi-speaker settings reveal that intermediate layers of a pre-trained wav2vec 2.0 model provide optimal representations for articulatory learning, significantly outperforming MFCC features. These representations enable our model to learn articulatory trajectories that correlate with human patterns, discriminate between places of articulation, and produce intelligible speech. Critical to successful articulatory learning are representations that balance phonetic discriminability with speaker invariance -- precisely the characteristics of self-supervised representation learning models. Our findings provide computational evidence consistent with developmental theories proposing that perceptual learning of phonetic categories guides articulatory development, offering insights into how infants might acquire speech production capabilities despite the complex mapping problem they face.

Paper number 19:
Title: Real-Time Single-Iteration Model Predictive Control for Wave Energy Converters
Authors: Simone Pirrera, Nicolas Faedo, Sophie M. Fosson, Diego Regruto
Abstract: This paper proposes a novel real-time algorithm for controlling wave energy converters (WECs). We begin with the economic model predictive control (MPC) problem formulation and apply a novel, first-order optimization algorithm inspired by recently developed control-based algorithms for constrained optimization to define the controller dynamics according to the single-iteration MPC approach. We theoretically analyse the convergence of the employed algorithm and the computational complexity of the obtained controller. Results from simulations using a benchmark WEC system indicate that the proposed approach significantly outperforms standard MPC, thanks to the inherent ability to handle faster sampling rates.

Paper number 20:
Title: Optimal Anchor Deployment and Topology Design for Large-Scale AUV Navigation
Authors: Wei Huang, Junpeng Lu, Tianhe Xu, Jianxu Shu, Hao Zhang, Kaitao Meng, Yanan Wu
Abstract: Seafloor acoustic anchors are an important component of AUV navigation, providing absolute updates that correct inertial dead-reckoning. Unlike terrestrial positioning systems, the deployment of underwater anchor nodes is usually sparse due to the uneven distribution of underwater users, as well as the high economic cost and difficult maintenance of underwater equipment. These anchor nodes lack satellite coverage and cannot form ubiquitous backhaul as terrestrial nodes do. In this paper, we investigate the optimal anchor deployment topology to provide high-quality AUV navigation and positioning services. We first analyze the possible deployment mode in large-scale underwater navigation system, and formulate a topology optimization for underwater anchor node deployment. Then, we derive a scaling law about the influence of anchors in each cluster on the navigation performance within a given area and demonstrate a service area coverage condition with a high probability of reaching the destination. Finally, the optimization performance is evaluated through experimental results.

Paper number 21:
Title: A Dynamic Programming Framework for Vehicular Task Offloading with Successive Action Improvement
Authors: Qianren Li, Yuncong Hong, Bojie Lv, Rui Wang
Abstract: In this paper, task offloading from vehicles with random velocities is optimized via a novel dynamic programming framework. Particularly, in a vehicular network with multiple vehicles and base stations (BSs), computing tasks of vehicles are offloaded via BSs to an edge server. Due to the random velocities, the exact locations of vehicles versus time, namely trajectories, cannot be determined in advance. Hence, instead of deterministic optimization, the cell association, uplink time, and throughput allocation of multiple vehicles during a period of task offloading are formulated as a finite-horizon Markov decision process. In order to derive a low-complexity solution algorithm, a two-time-scale framework is proposed. The scheduling period is divided into super slots, each super slot is further divided into a number of time slots. At the beginning of each super slot, we first obtain a reference scheduling scheme of cell association, uplink time and throughput allocation via deterministic optimization, yielding an approximation of the optimal value function. Within the super slot, the actual scheduling action of each time slot is determined by making improvement to the approximate value function according to the system state. Due to the successive improvement framework, a non-trivial average cost upper bound could be derived. In the simulation, the random trajectories of vehicles are generated from a high-fidelity traffic simulator. It is shown that the performance gain of the proposed scheduling framework over the baselines is significant.

Paper number 22:
Title: Application Space and the Rate-Distortion-Complexity Analysis of Neural Video CODECs
Authors: Ricardo L. de Queiroz, Diogo C. Garcia, Yi-Hsin Chen, Ruhan Concei√ß√£o, Wen-Hsiao Peng, Luciano V. Agostini
Abstract: We study the decision-making process for choosing video compression systems through a rate-distortion-complexity (RDC) analysis. We discuss the 2D Bjontegaard delta (BD) metric and formulate generalizations in an attempt to extend its notions to the 3D RDC volume. We follow that discussion with another one on the computation of metrics in the RDC volume, and on how to define and measure the cost of a coder-decoder (codec) pair, where the codec is characterized by a cloud of points in the RDC space. We use a Lagrangian cost $D+\lambda R + \gamma C$, such that choosing the best video codec among a number of candidates for an application demands selecting appropriate $(\lambda, \gamma)$ values. Thus, we argue that an application may be associated with a $(\lambda, \gamma)$ point in the application space. An example streaming application was given as a case study to set a particular point in the $(\lambda, \gamma)$ plane. The result is that we can compare Lagrangian costs in an RDC volume for different codecs for a given application. Furthermore, we can span the plane and compare codecs for the entire application space filled with different $(\lambda, \gamma)$ choices. We then compared several state-of-the-art neural video codecs using the proposed metrics. Results are informative and surprising. We found that, within our RDC computation constraints, only four neural video codecs came out as the best suited for any application, depending on where its desirable $(\lambda, \gamma)$ lies.

Paper number 23:
Title: Certifying the Nonexistence of Feasible Path Between Power System Operating Points
Authors: Mohammad Rasoul Narimani, Katherine R. Davis, Daniel K. Molzahn
Abstract: By providing the optimal operating point that satisfies both the power flow equations and engineering limits, the optimal power flow (OPF) problem is central to the operation of electric power systems. While extensive research efforts have focused on reliably computing high-quality OPF solutions, assessing the feasibility of transitioning between operating points remains challenging since the feasible spaces of OPF problems may consist of multiple disconnected components. It is not possible to transition between operating points in different disconnected components without violating OPF constraints. To identify such situations, this paper introduces an algorithm for certifying the infeasibility of transitioning between two operating points within an OPF feasible space. As an indication of potential disconnectedness, the algorithm first seeks an infeasible point on the line connecting a pair of feasible points. The algorithm then certifies disconnectedness by using convex relaxation and bound tightening techniques to show that all points on the plane that is normal to this line are infeasible. Using this algorithm, we provide the first certifications of disconnected feasible spaces for a variety of OPF test cases.

Paper number 24:
Title: Active noise cancellation in ultra-low field MRI: distinct strategies for different channels
Authors: Jiali He, Sheng Shen, Jiamin Wu, Xiaohan Kong, Yamei Dai, Liang Tan, Zheng Xu
Abstract: Ultra-low field magnetic resonance imaging(ULF-MRI) systems operating in open environments are highly susceptible to composite electromagnetic interference(EMI). Different imaging channels respond non-uniformly to EMI owing to their distinct coupling characteristics. Here, we investigate channel-specific interference pathways in a permanent-magnet-based low-field MRI system and show that saddle coils are intrinsically more vulnerable to transverse EMI components than solenoidal coils. To mitigate these heterogeneous coupling effects, we propose a dual-stage suppression strategy that combines front-end spatial-domain inverse field reconstruction with back-end channel-adaptive active noise cancellation. Experiments demonstrate that this approach suppresses EMI by more than 80%, substantially improves inter-channel signal-to-noise ratio(SNR) consistency, and enhances the fused-image SNR by 24%. These findings elucidate the channel-dependent nature of EMI coupling and establish targeted mitigation strategies, providing both a theoretical basis and practical guidance for noise suppression in future array-coil ULF-MRI systems.

Paper number 25:
Title: The Case for a DNANF 1Pb/s Trans-Atlantic Submarine Cable
Authors: Pierluigi Poggiolini, Francesco Poletti
Abstract: The recent progress in low-loss hollow-core fibers allows to speculate on the possibility of building a transatlantic submarine cable that can achieve the goal of 1 Pb/s per direction, leveraging bidirectional transmission, and at the same time drastically increase span length, theoretically to 200km.

Paper number 26:
Title: DeepStream: Prototyping Deep Joint Source-Channel Coding for Real-Time Multimedia Transmissions
Authors: Kaiyi Chi, Yinghui He, Qianqian Yang, Zhiping Jiang, Yuanchao Shu, Zhiqin Wang, Jun Luo, Jiming Chen
Abstract: Deep learning-based joint source-channel coding (DeepJSCC) has emerged as a promising technique in 6G for enhancing the efficiency and reliability of data transmission across diverse modalities, particularly in low signal-to-noise ratio (SNR) environments. This advantage is realized by leveraging powerful neural networks to learn an optimal end-to-end mapping from the source data directly to the transmit symbol sequence, eliminating the need for separate source coding, channel coding, and modulation. Although numerous efforts have been made towards efficient DeepJSCC, they have largely stayed at numerical simulations that can be far from practice, leaving the real-world viability of DeepJSCC largely unverified. To this end, we prototype DeepStream upon orthogonal frequency division multiplexing (OFDM) technology to offer efficient and robust DeepJSCC for multimedia transmission. In conforming to OFDM, we develop both a feature-to-symbol mapping method and a cross-subcarrier precoding method to improve the subcarrier independence and reduce peak-to-average power ratio. To reduce system complexity and enable flexibility in accommodating varying quality of service requirements, we further propose a progressive coding strategy that adjusts the compression ratio based on latency with minimal performance loss. We implement DeepStream for real-time image transmission and video streaming using software-defined radio. Extensive evaluations verify that DeepStream outperforms both the standard scheme and the direct deployment scheme. Particularly, at an SNR of 10 dB, DeepStream achieves a PSNR of 35 dB for image transmission and an MS-SSIM of 20 dB for video streaming, whereas the standard scheme fails to recover meaningful information.

Paper number 27:
Title: 3D-Image Reconstruction using MIMO-SAR FMCW Radar
Authors: Ayush Jha, Dhanireddy Chandrika, Chandra Sekhar Seelamantula, Chetan Singh Thakur
Abstract: With the advancement of millimeter-wave radar technology, Synthetic Aperture Radar (SAR) imaging at millimeter-wave frequencies has gained significant attention in both academic research and industrial applications. However, traditional SAR imaging algorithms primarily focus on extracting two-dimensional information from detected targets, which limits their potential for 3D scene reconstruction. In this work, we demonstrated a fast time-domain reconstruction algorithm for achieving high-resolution 3D radar imaging at millimeter-wave (mmWave) frequencies. This approach leverages a combination of virtual Multiple Input Multiple Output (MIMO) Frequency Modulated Continuous Wave (FMCW) radar with the precision of Synthetic Aperture Radar (SAR) technique, setting the stage for a new era of advanced radar imaging applications.

Paper number 28:
Title: Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance
Authors: Mohamed Mohamed, Brennan Nichyporuk, Douglas L. Arnold, Tal Arbel
Abstract: Vision-language models have demonstrated impressive capabilities in generating 2D images under various conditions; however the impressive performance of these models in 2D is largely enabled by extensive, readily available pretrained foundation models. Critically, comparable pretrained foundation models do not exist for 3D, significantly limiting progress in this domain. As a result, the potential of vision-language models to produce high-resolution 3D counterfactual medical images conditioned solely on natural language descriptions remains completely unexplored. Addressing this gap would enable powerful clinical and research applications, such as personalized counterfactual explanations, simulation of disease progression scenarios, and enhanced medical training by visualizing hypothetical medical conditions in realistic detail. Our work takes a meaningful step toward addressing this challenge by introducing a framework capable of generating high-resolution 3D counterfactual medical images of synthesized patients guided by free-form language prompts. We adapt state-of-the-art 3D diffusion models with enhancements from Simple Diffusion and incorporate augmented conditioning to improve text alignment and image quality. To our knowledge, this represents the first demonstration of a language-guided native-3D diffusion model applied specifically to neurological imaging data, where faithful three-dimensional modeling is essential to represent the brain's three-dimensional structure. Through results on two distinct neurological MRI datasets, our framework successfully simulates varying counterfactual lesion loads in Multiple Sclerosis (MS), and cognitive states in Alzheimer's disease, generating high-quality images while preserving subject fidelity in synthetically generated medical images. Our results lay the groundwork for prompt-driven disease progression analysis within 3D medical imaging.

Paper number 29:
Title: Quantum Radar for ISAC: Sum-Rate Optimization
Authors: Abdulmohsen Alsaui, Neel Kanth Kundu, Hyundong Shin, Octavia A. Dobre
Abstract: Integrated sensing and communication (ISAC) is emerging as a key enabler for spectrum-efficient and hardware-converged wireless networks. However, classical radar systems within ISAC architectures face fundamental limitations under low signal power and high-noise conditions. This paper proposes a novel framework that embeds quantum illumination radar into a base station to simultaneously support full-duplex classical communication and quantum-enhanced target detection. The resulting integrated quantum sensing and classical communication (IQSCC) system is optimized via a sum-rate maximization formulation subject to radar sensing constraints. The non-convex joint optimization of transmit power and beamforming vectors is tackled using the successive convex approximation technique. Furthermore, we derive performance bounds for classical and quantum radar protocols under the statistical detection theory, highlighting the quantum advantage in low signal-to-interference-plus-noise ratio regimes. Simulation results demonstrate that the proposed IQSCC system achieves a higher communication throughput than the conventional ISAC baseline while satisfying the sensing requirement.

Paper number 30:
Title: Mutual Support by Sensor-Attacker Team for a Passive Target
Authors: Prajakta Surve, Shaunak D. Bopardikar, Alexander Von Moll, Isaac Weintraub, David W. Casbeer
Abstract: We introduce a pursuit game played between a team of a sensor and an attacker and a mobile target in the unbounded Euclidean plane. The target is faster than the sensor, but slower than the attacker. The sensor's objective is to keep the target within a sensing radius so that the attacker can capture the target, whereas the target seeks to escape by reaching beyond the sensing radius from the sensor without getting captured by the attacker. We assume that as long as the target is within the sensing radius from the sensor, the sensor-attacker team is able to measure the target's instantaneous position and velocity. We pose and solve this problem as a \emph{game of kind} in which the target uses an open-loop strategy (passive target). Aside from the novel formulation, our contributions are four-fold. First, we present optimal strategies for both the sensor and the attacker, according to their respective objectives. Specifically, we design a sensor strategy that maximizes the duration for which the target remains within its sensing range, while the attacker uses proportional navigation to capture the target. Second, we characterize the \emph{sensable region} -- the region in the plane in which the target remains within the sensing radius of the sensor during the game -- and show that capture is guaranteed {if and only if} the Apollonius circle between the attacker and the target is fully contained within this region. Third, we {derive a lower bound} on the target's speed below which capture is guaranteed, and an upper bound on the target speed above which there exists an escape strategy for the target, from an arbitrary initial orientation between the agents. Fourth, for a given initial orientation between the agents, we present a sharper upper bound on the target speed above which there exists an escape strategy for the target.

Paper number 31:
Title: FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes
Authors: Muraam Abdel-Ghani, Mahmoud Ali, Mohamed Ali, Fatmaelzahraa Ahmed, Mohamed Arsalan, Abdulaziz Al-Ali, Shidin Balakrishnan
Abstract: The growing popularity of robotic minimally invasive surgeries has made deep learning-based surgical training a key area of research. A thorough understanding of the surgical scene components is crucial, which semantic segmentation models can help achieve. However, most existing work focuses on surgical tools and overlooks anatomical objects. Additionally, current state-of-the-art (SOTA) models struggle to balance capturing high-level contextual features and low-level edge features. We propose a Feature-Adaptive Spatial Localization model (FASL-Seg), designed to capture features at multiple levels of detail through two distinct processing streams, namely a Low-Level Feature Projection (LLFP) and a High-Level Feature Projection (HLFP) stream, for varying feature resolutions - enabling precise segmentation of anatomy and surgical instruments. We evaluated FASL-Seg on surgical segmentation benchmark datasets EndoVis18 and EndoVis17 on three use cases. The FASL-Seg model achieves a mean Intersection over Union (mIoU) of 72.71% on parts and anatomy segmentation in EndoVis18, improving on SOTA by 5%. It further achieves a mIoU of 85.61% and 72.78% in EndoVis18 and EndoVis17 tool type segmentation, respectively, outperforming SOTA overall performance, with comparable per-class SOTA results in both datasets and consistent performance in various classes for anatomy and instruments, demonstrating the effectiveness of distinct processing streams for varying feature resolutions.

Paper number 32:
Title: Pinching Antenna System (PASS) Enhanced Covert Communications: Against Warden via Sensing
Authors: Hao Jiang, Zhaolin Wang, Yuanwei Liu, Arumugam Nallanathan, Zhiguo Ding
Abstract: A sensing-aided covert communication network empowered by pinching antenna systems (PASS) is proposed in this work. Unlike conventional fixed-position MIMO arrays, PASS dynamically reconfigures its pinching antennas (PAs) closer to the legitimate user, substantially enhancing covertness. To further secure the adversary's channel state information (CSI), a sensing function is leveraged to track the malicious warden's movements. In particular, this paper first proposes an extended Kalman filter (EKF) based approach to fulfilling the tracking function. Building on this, a covert communication problem is formulated with a joint design of beamforming, artificial noise (AN) signals, and the position of PAs. Then, the beamforming and AN design subproblems are resolved jointly with a subspace approach, while the PA position optimization subproblem is handled by a deep reinforcement learning (DRL) approach by treating the evolution of the warden's mobility status as a temporally corrected process. Numerical results are presented and demonstrate that: i) the EKF approach can accurately track the warden's CSI with low complexity, ii) the effectiveness of the proposed solution is verified by its outperformance over the greedy and searching-based benchmarks, and iii) with new design degrees of freedom (DoFs), the performance of PASS is superior to the conventional fully-digital MIMO systems.

Paper number 33:
Title: Beamforming-LLM: What, Where and When Did I Miss?
Authors: Vishal Choudhari
Abstract: We present Beamforming-LLM, a system that enables users to semantically recall conversations they may have missed in multi-speaker environments. The system combines spatial audio capture using a microphone array with retrieval-augmented generation (RAG) to support natural language queries such as, "What did I miss when I was following the conversation on dogs?" Directional audio streams are separated using beamforming, transcribed with Whisper, and embedded into a vector database using sentence encoders. Upon receiving a user query, semantically relevant segments are retrieved, temporally aligned with non-attended segments, and summarized using a lightweight large language model (GPT-4o-mini). The result is a user-friendly interface that provides contrastive summaries, spatial context, and timestamped audio playback. This work lays the foundation for intelligent auditory memory systems and has broad applications in assistive technology, meeting summarization, and context-aware personal spatial computing.

Paper number 34:
Title: Human Body Weight Estimation Through Music-Induced Bed Vibrations
Authors: Yuyan Wu, Jiale Zhang, Moon Lee, Cherrelle Smith, Xinyi Li, Ankur Senapati, Pei Zhang, Hae Young Noh
Abstract: Rapid and accurate body weight estimation is critical in emergency medical care, as it directly influences treatment decisions, such as drug dosing, defibrillation energy selection, and fluid resuscitation. Traditional methods such as stand-on scales, length-based tapes, or transfer-based weighing scales are often impractical for immobilized patients, inaccurate, or labor-intensive and time-consuming. This paper introduces MelodyBedScale, a non-intrusive and rapid on-bed weight estimation system that leverages bed vibration induced by music. The core insight is that body weight affects the vibration transfer function of the bed-body system, which is captured using vibration sensors placed on opposite sides of the bed. First, we identify weight-sensitive frequency bands and compose clinically acceptable soft, natural music with high signal energy in these frequency bands. This music is then played through a speaker mounted on the bed to induce bed vibrations. Additionally, to efficiently capture the complex weight-vibration relationship with limited data and enhance generalizability to unseen individuals and weights, we theoretically analyze the weight-vibration relationship and integrate the results into the activation functions of the neural network for physics-informed weight regression. We evaluated MelodyBedScale on both wooden and steel beds across 11 participants, achieving a mean absolute error of up to 1.55 kg.

Paper number 35:
Title: DNN-based Digital Twin Framework of a DC-DC Buck Converter using Spider Monkey Optimization Algorithm
Authors: Tahmin Mahmud, Euzeli Cipriano Dos Santos Jr
Abstract: Component ageing is a critical concern in power electronic converter systems (PECSs). It directly impacts the reliability, performance, and operational lifespan of converters used across diverse applications, including electric vehicles (EVs), renewable energy systems (RESs) and industrial automation. Therefore, understanding and monitoring component ageing is crucial for developing robust converters and achieving long-term system reliability. This paper proposes a data-driven digital twin (DT) framework for DC-DC buck converters, integrating deep neural network (DNN) with the spider monkey optimization (SMO) algorithm to monitor and predict component degradation. Utilizing a low-power prototype testbed along with empirical and synthetic datasets, the SMO+DNN approach achieves the global optimum in 95% of trials, requires 33% fewer iterations, and results in 80% fewer parameter constraint violations compared to traditional methods. The DNN model achieves $R^2$ scores above 0.998 for all key degradation parameters and accurately forecasts time to failure ($t_{failure}$). In addition, SMO-tuned degradation profile improves the converter's performance by reducing voltage ripple by 20-25% and inductor current ripple by 15-20%.

Paper number 36:
Title: Enhancing Low-Altitude Airspace Security: MLLM-Enabled UAV Intent Recognition
Authors: Guangyu Lei, Tianhao Liang, Yuqi Ping, Xinglin Chen, Longyu Zhou, Junwei Wu, Xiyuan Zhang, Huahao Ding, Xingjian Zhang, Weijie Yuan, Tingting Zhang, Qinyu Zhang
Abstract: The rapid development of the low-altitude economy emphasizes the critical need for effective perception and intent recognition of non-cooperative unmanned aerial vehicles (UAVs). The advanced generative reasoning capabilities of multimodal large language models (MLLMs) present a promising approach in such tasks. In this paper, we focus on the combination of UAV intent recognition and the MLLMs. Specifically, we first present an MLLM-enabled UAV intent recognition architecture, where the multimodal perception system is utilized to obtain real-time payload and motion information of UAVs, generating structured input information, and MLLM outputs intent recognition results by incorporating environmental information, prior knowledge, and tactical preferences. Subsequently, we review the related work and demonstrate their progress within the proposed architecture. Then, a use case for low-altitude confrontation is conducted to demonstrate the feasibility of our architecture and offer valuable insights for practical system design. Finally, the future challenges are discussed, followed by corresponding strategic recommendations for further applications.

Paper number 37:
Title: Speaker Privacy and Security in the Big Data Era: Protection and Defense against Deepfake
Authors: Liping Chen, Kong Aik Lee, Zhen-Hua Ling, Xin Wang, Rohan Kumar Das, Tomoki Toda, Haizhou Li
Abstract: In the era of big data, remarkable advancements have been achieved in personalized speech generation techniques that utilize speaker attributes, including voice and speaking style, to generate deepfake speech. This has also amplified global security risks from deepfake speech misuse, resulting in considerable societal costs worldwide. To address the security threats posed by deepfake speech, techniques have been developed focusing on both the protection of voice attributes and the defense against deepfake speech. Among them, the voice anonymization technique has been developed to protect voice attributes from extraction for deepfake generation, while deepfake detection and watermarking have been utilized to defend against the misuse of deepfake speech. This paper provides a short and concise overview of the three techniques, describing the methodologies, advancements, and challenges. A comprehensive version, offering additional discussions, will be published in the near future.

Paper number 38:
Title: First-Principle Modeling Framework of Boost Converter Dynamics for Precise Energy Conversions in Space
Authors: Yifan Wang, Wenhua Li, Zhenlong Wang, Xinrui Zhang, Jianfeng Sun, Qianfu Xia, Zhongtao Gou, Jiangang Rong, Tao Ye
Abstract: Boost converters are essential for modern electrification and intelligent technologies. However, conventional Boost converter models relying on steady-state assumptions fail to accurately predict transient behaviors during input voltage and load fluctuations, which cause significant output voltage overshoots and instability, resulting in failures of electrical systems, thereby restricting their use in space. This study introduces a first-principle modeling framework that derives precise dynamic equations for Boost converters by incorporating non-ideal component coupling. As compared to the most accurate existing Boost converter model, the proposed models reduce steady-state and dynamic-state errors between experimental and simulated output voltages by factors of 11.0 (from 20.9% to 1.9%) and 15.4 (from 77.1% to 5.0%) under input voltage variations, and by factors of 10.2 (from 15.3% to 1.5%) and 35.1 (from 42.1% to 1.2%) under load changes, respectively. Consequently, a reliable Boost converter is accordingly designed and on-orbit deployed for precise energy conversions.

Paper number 39:
Title: Unified Graph-Theoretic Modeling of Multi-Energy Flows in Distribution Systems
Authors: Marwan Mostafa, Daniel Wenser, Payam Teimourzadeh Baboli, Christian Becker
Abstract: The increasing complexity of energy systems due to sector coupling and decarbonization calls for unified modeling frameworks that capture the physical and structural interactions between electricity, gas, and heat networks. This paper presents a graph-based modeling approach for multi-energy systems, where each domain is represented as a layer in a multi-layer graph, and coupling technologies are modeled as inter-layer edges via a dedicated coupling layer. A steady-state solver based on a block-structured Newton-Raphson method is developed to jointly compute flows and state variables across all carriers. The proposed model is tested and validated on a realistic case study based on data from a German distribution network. The results demonstrate convergence, numerical accuracy, and consistent domain interaction, and demonstrate the method's applicability for system-wide analysis and its potential as a foundation for future optimizations in integrated energy systems.

Paper number 40:
Title: Optimal Distortion-Aware Multi-User Power Allocation for Massive MIMO Networks
Authors: Siddarth Marwaha, Pawel Kryszkiewicz, Eduard Jorswieck
Abstract: Real-world wireless transmitter front-ends exhibit certain nonlinear behavior, e.g., signal clipping by a Power Amplifier (PA). Although many resource allocation solutions do not consider this for simplicity, it leads to inaccurate results or a reduced number of degrees of freedom, not achieving the global performance. In this work, we propose an optimal PA distortion-aware power allocation strategy in a downlink orthogonal frequency division multiplex (OFDM) based massive multiple-input multiple-output (M-MIMO) system. Assuming a soft-limiter PA model, where the transmission occurs under small-scale independent and identically distributed (i.i.d) Rayleigh fading channel, we derive the wideband signal-to-noise-and-distortion ratio (SNDR) and formulate the power allocation problem. Most interestingly, the distortion introduced by the PA leads to an SNDR-efficient operating point without explicit transmit power constraints. While the optimization problem is non-convex, we decouple it into a non-convex total power allocation problem and a convex power distribution problem among the users (UEs). We propose an alternating optimization algorithm to find the optimum solution. Our simulation results show significant sum-rate gains over existing distortion-neglecting solutions, e.g., a median 4 times increase and a median 50\% increase for a 64-antenna and 512-antenna base station serving 60 users, respectively.

Paper number 41:
Title: Leveraging Information Divergence for Robust Semi-Supervised Fetal Ultrasound Image Segmentation
Authors: Fangyijie Wang, Gu√©nol√© Silvestre, Kathleen M. Curran
Abstract: Maternal-fetal Ultrasound is the primary modality for monitoring fetal development, yet automated segmentation remains challenging due to the scarcity of high-quality annotations. To address this limitation, we propose a semi-supervised learning framework that leverages information divergence for robust fetal ultrasound segmentation. Our method employs a lightweight convolutional network (1.47M parameters) and a Transformer-based network, trained jointly with labelled data through standard supervision and with unlabelled data via cross-supervision. To encourage consistent and confident predictions, we introduce an information divergence loss that combines per-pixel Kullback-Leibler divergence and Mutual Information Gap, effectively reducing prediction disagreement between the two models. In addition, we apply mixup on unlabelled samples to further enhance robustness. Experiments on two fetal ultrasound datasets demonstrate that our approach consistently outperforms seven state-of-the-art semi-supervised methods. When only 5% of training data is labelled, our framework improves the Dice score by 2.39%, reduces the 95% Hausdorff distance by 14.90, and decreases the Average Surface Distance by 4.18. These results highlight the effectiveness of leveraging information divergence for annotation-efficient and robust medical image segmentation. Our code is publicly available on GitHub.

Paper number 42:
Title: Synesthesia of Machines (SoM)-Aided LiDAR Point Cloud Transmission for Collaborative Perception
Authors: Ensong Liu, Rongqing Zhang, Xiang Cheng, Jian Tang
Abstract: Collaborative perception enables more accurate and comprehensive scene understanding by learning how to share information between agents, with LiDAR point clouds providing essential precise spatial data. Due to the substantial data volume generated by LiDAR sensors, efficient point cloud transmission is essential for low-latency multi-agent collaboration. In this work, we propose an efficient, robust and applicable LiDAR point cloud transmission system via the Synesthesia of Machines (SoM), termed LiDAR Point Cloud Feature Transmission (LPC-FT), to support collaborative perception among multiple agents. Specifically, we employ a density-preserving deep point cloud compression method that encodes the complete point cloud into a downsampled efficient representation. To mitigate the effects of the wireless channel, we design a channel encoder module based on self-attention to enhance LiDAR point cloud features and a feature fusion module based on cross-attention to integrate features from transceivers. Furthermore, we utilize the nonlinear activation layer and transfer learning to improve the training of deep neural networks in the presence the digital channel noise. Experimental results demonstrate that the proposed LPC-FT is more robust and effective than traditional octree-based compression followed by channel coding, and outperforms state-of-the-art deep learning-based compression techniques and existing semantic communication methods, reducing the Chamfer Distance by 30% and improving the PSNR by 1.9 dB on average. Owing to its superior reconstruction performance and robustness against channel variations, LPC-FT is expected to support collaborative perception tasks.

Paper number 43:
Title: Parameter Robustness in Data-Driven Estimation of Dynamical Systems
Authors: Ayush Pandey
Abstract: We study the robustness of system estimation to parametric perturbations in system dynamics and initial conditions. We define the problem of sensitivity-based parametric uncertainty quantification in dynamical system estimation. The main contribution of this paper is the development of a novel robustness metric for estimation of parametrized linear dynamical systems with and without control actions. For the computation of this metric, we delineate the uncertainty contributions arising from control actions, system dynamics, and initial conditions. Furthermore, to validate our theoretical findings, we establish connections between these new results and the existing literature on the robustness of model reduction. This work provides guidance for selecting estimation methods based on tolerable levels of parametric uncertainty and paves the way for new cost functions in data-driven estimation that reward sensitivity to a desired subset of parameters while penalizing others.

Paper number 44:
Title: Wireless Low-Latency Synchronization for Body-Worn Multi-Node Systems in Sports
Authors: Nico Krull, Lukas Schulthess, Michele Magno, Luca Benini, Christoph Leitner
Abstract: Biomechanical data acquisition in sports demands sub-millisecond synchronization across distributed body-worn sensor nodes. This study evaluates and characterizes the Enhanced ShockBurst (ESB) protocol from Nordic Semiconductor under controlled laboratory conditions for wireless, low-latency command broadcasting, enabling fast event updates in multi-node systems. Through systematic profiling of protocol parameters, including cyclic-redundancy-check modes, bitrate, transmission modes, and payload handling, we achieve a mean Device-to-Device (D2D) latency of 504.99 +- 96.89 us and a network-to-network core latency of 311.78 +- 96.90 us using a one-byte payload with retransmission optimization. This performance significantly outperforms Bluetooth Low Energy (BLE), which is constrained by a 7.5 ms connection interval, by providing deterministic, sub-millisecond synchronization suitable for high-frequency (500 Hz to 1000 Hz) biosignals. These results position ESB as a viable solution for time-critical, multi-node wearable systems in sports, enabling precise event alignment and reliable high-speed data fusion for advanced athlete monitoring and feedback applications.

Paper number 45:
Title: Impact of Labeling Inaccuracy and Image Noise on Tooth Segmentation in Panoramic Radiographs using Federated, Centralized and Local Learning
Authors: Johan Andreas Balle Rubak, Khuram Naveed, Sanyam Jain, Lukas Esterle, Alexandros Iosifidis, Ruben Pauwels
Abstract: Objectives: Federated learning (FL) may mitigate privacy constraints, heterogeneous data quality, and inconsistent labeling in dental diagnostic AI. We compared FL with centralized (CL) and local learning (LL) for tooth segmentation in panoramic radiographs across multiple data corruption scenarios. Methods: An Attention U-Net was trained on 2066 radiographs from six institutions across four settings: baseline (unaltered data); label manipulation (dilated/missing annotations); image-quality manipulation (additive Gaussian noise); and exclusion of a faulty client with corrupted data. FL was implemented via the Flower AI framework. Per-client training- and validation-loss trajectories were monitored for anomaly detection and a set of metrics (Dice, IoU, HD, HD95 and ASSD) was evaluated on a hold-out test set. From these metrics significance results were reported through Wilcoxon signed-rank test. CL and LL served as comparators. Results: Baseline: FL achieved a median Dice of 0.94889 (ASSD: 1.33229), slightly better than CL at 0.94706 (ASSD: 1.37074) and LL at 0.93557-0.94026 (ASSD: 1.51910-1.69777). Label manipulation: FL maintained the best median Dice score at 0.94884 (ASSD: 1.46487) versus CL's 0.94183 (ASSD: 1.75738) and LL's 0.93003-0.94026 (ASSD: 1.51910-2.11462). Image noise: FL led with Dice at 0.94853 (ASSD: 1.31088); CL scored 0.94787 (ASSD: 1.36131); LL ranged from 0.93179-0.94026 (ASSD: 1.51910-1.77350). Faulty-client exclusion: FL reached Dice at 0.94790 (ASSD: 1.33113) better than CL's 0.94550 (ASSD: 1.39318). Loss-curve monitoring reliably flagged the corrupted site. Conclusions: FL matches or exceeds CL and outperforms LL across corruption scenarios while preserving privacy. Per-client loss trajectories provide an effective anomaly-detection mechanism and support FL as a practical, privacy-preserving approach for scalable clinical AI deployment.

Paper number 46:
Title: Robustness and accuracy of mean opinion scores with hard and soft outlier detection
Authors: Dietmar Saupe, Tim Bleile
Abstract: In subjective assessment of image and video quality, observers rate or compare selected stimuli. Before calculating the mean opinion scores (MOS) for these stimuli from the ratings, it is recommended to identify and deal with outliers that may have given unreliable ratings. Several methods are available for this purpose, some of which have been standardized. These methods are typically based on statistics and sometimes tested by introducing synthetic ratings from artificial outliers, such as random clickers. However, a reliable and comprehensive approach is lacking for comparative performance analysis of outlier detection methods. To fill this gap, this work proposes and applies an empirical worst-case analysis as a general solution. Our method involves evolutionary optimization of an adversarial black-box attack on outlier detection algorithms, where the adversary maximizes the distortion of scale values with respect to ground truth. We apply our analysis to several hard and soft outlier detection methods for absolute category ratings and show their differing performance in this stress test. In addition, we propose two new outlier detection methods with low complexity and excellent worst-case performance. Software for adversarial attacks and data analysis is available.

Paper number 47:
Title: Integrated Detection and Tracking Based on Radar Range-Doppler Feature
Authors: Chenyu Zhang, Yuanhang Wu, Xiaoxi Ma, Wei Yi
Abstract: Detection and tracking are the basic tasks of radar systems. Current joint detection tracking methods, which focus on dynamically adjusting detection thresholds from tracking results, still present challenges in fully utilizing the potential of radar signals. These are mainly reflected in the limited capacity of the constant false-alarm rate model to accurately represent information, the insufficient depiction of complex scenes, and the limited information acquired by the tracker. We introduce the Integrated Detection and Tracking based on radar feature (InDT) method, which comprises a network architecture for radar signal detection and a tracker that leverages detection assistance. The InDT detector extracts feature information from each Range-Doppler (RD) matrix and then returns the target position through the feature enhancement module and the detection head. The InDT tracker adaptively updates the measurement noise covariance of the Kalman filter based on detection confidence. The similarity of target RD features is measured by cosine distance, which enhances the data association process by combining location and feature information. Finally, the efficacy of the proposed method was validated through testing on both simulated data and publicly available datasets.

Paper number 48:
Title: Distributed Automatic Generation Control subject to Ramp-Rate-Limits: Anytime Feasibility and Uniform Network-Connectivity
Authors: Mohammadreza Doostmohammadian, Hamid R. Rabiee
Abstract: This paper considers automatic generation control over an information-sharing network of communicating generators as a multi-agent system. The optimization solution is distributed among the agents based on information consensus algorithms, while addressing the generators' ramp-rate-limits (RRL). This is typically ignored in the existing linear/nonlinear optimization solutions but they exist in real-time power generation scenarios. Without addressing the RRL, the generators cannot follow the assigned rate of generating power by the optimization algorithm; therefore, the existing solutions may not necessarily converge to the exact optimal cost or may lose feasibility in practice. The proposed solution in this work addresses the ramp-rate-limit constraint along with the box constraint (limits on the generated powers) and the coupling-constraint (generation-demand balance) at all iteration times of the algorithm. The latter is referred to as the anytime feasibility and implies that at every termination point of the algorithm, the balance between the demand and generated power holds. To improve the convergence rate of the algorithm we further consider internal signum-based nonlinearity. We also show that our solution can tolerate communication link removal. This follows from the uniform-connectivity assumption on the communication network.

Paper number 49:
Title: Contrastive Anatomy-Contrast Disentanglement: A Domain-General MRI Harmonization Method
Authors: Daniel Scholz, Ayhan Can Erdur, Robbie Holland, Viktoria Ehm, Jan C. Peeken, Benedikt Wiestler, Daniel Rueckert
Abstract: Magnetic resonance imaging (MRI) is an invaluable tool for clinical and research applications. Yet, variations in scanners and acquisition parameters cause inconsistencies in image contrast, hindering data comparability and reproducibility across datasets and clinical studies. Existing scanner harmonization methods, designed to address this challenge, face limitations, such as requiring traveling subjects or struggling to generalize to unseen domains. We propose a novel approach using a conditioned diffusion autoencoder with a contrastive loss and domain-agnostic contrast augmentation to harmonize MR images across scanners while preserving subject-specific anatomy. Our method enables brain MRI synthesis from a single reference image. It outperforms baseline techniques, achieving a +7% PSNR improvement on a traveling subjects dataset and +18% improvement on age regression in unseen. Our model provides robust, effective harmonization of brain MRIs to target scanners without requiring fine-tuning. This advancement promises to enhance comparability, reproducibility, and generalizability in multi-site and longitudinal clinical studies, ultimately contributing to improved healthcare outcomes.

Paper number 50:
Title: Integrating Spatial and Semantic Embeddings for Stereo Sound Event Localization in Videos
Authors: Davide Berghi, Philip J. B. Jackson
Abstract: In this study, we address the multimodal task of stereo sound event localization and detection with source distance estimation (3D SELD) in regular video content. 3D SELD is a complex task that combines temporal event classification with spatial localization, requiring reasoning across spatial, temporal, and semantic dimensions. The last is arguably the most challenging to model. Traditional SELD approaches typically rely on multichannel input, limiting their capacity to benefit from large-scale pre-training due to data constraints. To overcome this, we enhance a standard SELD architecture with semantic information by integrating pre-trained, contrastive language-aligned models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are incorporated into a modified Conformer module tailored for multimodal fusion, which we refer to as the Cross-Modal Conformer. We perform an ablation study on the development set of the DCASE2025 Task3 Stereo SELD Dataset to assess the individual contributions of the language-aligned models and benchmark against the DCASE Task 3 baseline systems. Additionally, we detail the curation process of large synthetic audio and audio-visual datasets used for model pre-training. These datasets were further expanded through left-right channel swapping augmentation. Our approach, combining extensive pre-training, model ensembling, and visual post-processing, achieved second rank in the DCASE 2025 Challenge Task 3 (Track B), underscoring the effectiveness of our method. Future work will explore the modality-specific contributions and architectural refinements.

Paper number 51:
Title: Towards In-Air Ultrasonic QR Codes: Deep Learning for Classification of Passive Reflector Constellations
Authors: Wouter Jansen, Jan Steckel
Abstract: In environments where visual sensors falter, in-air sonar provides a reliable alternative for autonomous systems. While previous research has successfully classified individual acoustic landmarks, this paper takes a step towards increasing information capacity by introducing reflector constellations as encoded tags. Our primary contribution is a multi-label Convolutional Neural Network (CNN) designed to simultaneously identify multiple, closely spaced reflectors from a single in-air 3D sonar measurement. Our initial findings on a small dataset confirm the feasibility of this approach, validating the ability to decode these complex acoustic patterns. Secondly, we investigated using adaptive beamforming with null-steering to isolate individual reflectors for single-label classification. Finally, we discuss the experimental results and limitations, offering key insights and future directions for developing acoustic landmark systems with significantly increased information entropy and their accurate and robust detection and classification.

Paper number 52:
Title: MM-DINOv2: Adapting Foundation Models for Multi-Modal Medical Image Analysis
Authors: Daniel Scholz, Ayhan Can Erdur, Viktoria Ehm, Anke Meyer-Baese, Jan C. Peeken, Daniel Rueckert, Benedikt Wiestler
Abstract: Vision foundation models like DINOv2 demonstrate remarkable potential in medical imaging despite their origin in natural image domains. However, their design inherently works best for uni-modal image analysis, limiting their effectiveness for multi-modal imaging tasks that are common in many medical fields, such as neurology and oncology. While supervised models perform well in this setting, they fail to leverage unlabeled datasets and struggle with missing modalities, a frequent challenge in clinical settings. To bridge these gaps, we introduce MM-DINOv2, a novel and efficient framework that adapts the pre-trained vision foundation model DINOv2 for multi-modal medical imaging. Our approach incorporates multi-modal patch embeddings, enabling vision foundation models to effectively process multi-modal imaging data. To address missing modalities, we employ full-modality masking, which encourages the model to learn robust cross-modality relationships. Furthermore, we leverage semi-supervised learning to harness large unlabeled datasets, enhancing both the accuracy and reliability of medical predictions. Applied to glioma subtype classification from multi-sequence brain MRI, our method achieves a Matthews Correlation Coefficient (MCC) of 0.6 on an external test set, surpassing state-of-the-art supervised approaches by +11.1%. Our work establishes a scalable and robust solution for multi-modal medical imaging tasks, leveraging powerful vision foundation models pre-trained on natural images while addressing real-world clinical challenges such as missing data and limited annotations.

Paper number 53:
Title: Near-Threshold Voltage Massive MIMO Computing
Authors: Mikael Rinkinen, Mehdi Safarpour, Shahriar Shahabuddin, Olli Silven, Lauri Koskinen
Abstract: Massive MIMO systems have the potential to significantly enhance spectral efficiency, yet their widespread integration is hindered by the high power consumption of the underlying computations. This paper explores the applicability and effectiveness of Algorithm-Based Fault Tolerance (ABFT) for massive MIMO signal processing to tackle the reliability challenge of Near Threshold Computing (NTC). We propose modifying matrix arithmetic Newton iteration MIMO algorithm to seamlessly integrate ABFT to detect any computational errors by inspecting the final result. The overhead from ABFT depends largely on the matrix dimensions, which in this context are dictated by the number of user equipments involved in the computation. NTC is a promising strategy for reducing the energy consumption in digital circuits by operating transistors at extremely reduced voltages. However, NTC is highly susceptible to variations in Process, Voltage, and Temperature (PVT) which can lead to increased error rates in computations. Traditional techniques for enabling NTC, such as dynamic voltage and frequency scaling guided by circuit level timing error detection methods, introduce considerable hardware complexity and are difficult to implement at high clock frequencies. In this context ABFT has emerged as a lightweight error detection method tailored for matrix operations without requiring any modifications on circuit-level and can be implemented purely in software.A MIMO accelerator was implemented on a reconfigurable hardware platform. Experimental results demonstrate that for sufficiently large problem sizes, the proposed method achieves a 36% power saving compared to baseline, with only an average of 3% computational overhead, at default clock frequency. These results indicate that combining ABFT with near-threshold operation provides a viable path toward energy-efficient and robust massive MIMO processors.

Paper number 54:
Title: Human-Hardware-in-the-Loop simulations for systemic resilience assessment in cyber-socio-technical systems
Authors: Francesco Simone, Marco Bortolini, Giovanni Mazzuto, Giulio di Gravio, Riccardo Patriarca
Abstract: Modern industrial systems require updated approaches to safety management, as the tight interplay between cyber-physical, human, and organizational factors has driven their processes toward increasing complexity. In addition to dealing with known risks, managing system resilience acquires great value to address complex behaviors pragmatically. This manuscript starts from the System-Theoretic Accident Model and Processes (STAMP) as a modelling initiative for such complexity. The STAMP can be natively integrated with simulation-based approaches, which however fail to realistically represent human behaviors and their influence on the system performance. To overcome this limitation, this paper proposes a Human-Hardware-in-the-Loop (HHIL) modeling and simulation framework aimed at supporting a more realistic and comprehensive assessments of systemic resilience. The approach is tested on an experimental oil and gas plant experiencing cyber-attacks, where two personas of operators (experts and novices) work. This research provides a mean to quantitatively assess how variations in operator behavior impact the overall system performance, offering insights into how resilience should be understood and implemented in complex socio-technical systems at large.

Paper number 55:
Title: SE and EE Tradeoff in Active STAR-RIS Assisted Systems With Hardware Impairments
Authors: Ao Huang, Xidong Mu, Li Guo, Guangyu Zhu
Abstract: This paper investigates the problem of resource efficiency maximization in an active simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted communication system under practical transceiver hardware impairments (HWIs). We aim to obtain an optimal tradeoff between system spectral efficiency (SE) and energy efficiency (EE), by jointly optimizing the base station (BS) transmit beamforming and the active STAR-RIS beamforming. To tackle the challenges in the fractional objective function, we begin by applying the quadratic transformation method to simplify it into a manageable form. An alternating optimization-based algorithm is then developed to iteratively update the BS and STAR-RIS beamforming coefficients. Simulation results demonstrate that the proposed scheme performs better than other baseline schemes in the presence of HWIs. Moreover, the variation of the achievable SE-EE region with different transmit power budgets is analyzed.

Paper number 56:
Title: ISAC Imaging by Channel State Information using Ray Tracing for Next Generation 6G
Authors: Ahmad Bazzi, Mingjun Ying, Ojas Kanhere, Theodore S. Rappaport, Marwa Chafii
Abstract: Integrated sensing and communications (ISAC) is emerging as a cornerstone technology for sixth generation (6G) wireless systems, unifying connectivity and environmental mapping through shared hardware, spectrum, and waveforms. The following paper presents an ISAC imaging framework utilizing channel state information (CSI) per-path components, transmitter (TX) positions, and receiver (RX) positions obtained from the calibrated NYURay ray tracer at 6.75 GHz in the upper mid-band. Our work shows how each resolvable multipath component can be extracted from CSI estimation and cast into an equivalent three-dimensional reflection point by fusing its angle and delay information, which is useful and challenging for multi-bounce reflections. The primary contribution of the paper is the two-segment reflection point optimization algorithm, which independently estimates the path lengths from the TX position and RX position to an equivalent reflection point (ERP) on the object surface, thus enabling precise geometric reconstruction. Subsequently, we aggregate the ERPs derived from multiple pairs of TX and RX positions, generating dense three dimensional point clouds representing the objects in the channel. Experimental results validate that the proposed ISAC imaging framework accurately reconstructs object surfaces, edges, and curved features. To the best of our knowledge, this paper provides the first demonstration of multi bounce ISAC imaging using wireless ray tracing at 6.75 GHz.

Paper number 57:
Title: Edge Server Monitoring for Job Assignment
Authors: Samuel Chamoun, Sirin Chakraborty, Eric Graves, Kevin Chan, Yin Sun
Abstract: In this paper, we study a goal-oriented communication problem for edge server monitoring, where compute jobs arrive intermittently at dispatchers and must be immediately assigned to distributed edge servers. Due to competing workloads and the dynamic nature of the edge environment, server availability fluctuates over time. To maintain accurate estimates of server availability states, each dispatcher updates its belief using two mechanisms: (i) active queries over shared communication channels and (ii) feedback from past job executions. We formulate a query scheduling problem that maximizes the job success rate under limited communication resources for queries. This problem is modeled as a Restless Multi-Armed Bandit (RMAB) with multiple actions and addressed using a Net-Gain Maximization (NGM) scheduling algorithm, which selects servers to query based on their expected improvement in execution performance. Simulation results show that the proposed NGM Policy significantly outperforms baseline strategies, achieving up to a 30% gain over the Round-Robin Policy and up to a 107% gain over the Never-Query Policy.

Paper number 58:
Title: RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator
Authors: Weicheng Gao
Abstract: Radar-based human activity recognition (HAR) is a pivotal research area for applications requiring non-invasive monitoring. However, the acquisition of diverse and high-fidelity radar datasets for robust algorithm development remains a significant challenge. To overcome this bottleneck, a model-based frequency-modulated continuous wave (FMCW) radar HAR simulator is developed. The simulator integrates an anthropometrically scaled $13$-scatterer kinematic model to simulate $12$ distinct activities. The FMCW radar echo model is employed, which incorporates dynamic radar cross-section (RCS), free-space or through-the-wall propagation, and a calibrated noise floor to ensure signal fidelity. The simulated raw data is then processed through a complete pipeline, including moving target indication (MTI), bulk Doppler compensation, and Savitzky-Golay denoising, culminating in the generation of high-resolution range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel neural network method is proposed to validate the effectiveness of the radar HAR. Numerical experiments demonstrate that the simulator successfully generates high-fidelity and distinct micro-Doppler signature, which provides a valuable tool for radar HAR algorithm design and validation. The installer of this simulator is released at: \href{this https URL}{Github/JoeyBGOfficial/RadHARSimulatorV1}.

Paper number 59:
Title: Steering Opinion through Dynamic Stackelberg Optimization
Authors: Hossein Rastgoftar
Abstract: This paper employs the Friedkin-Johnsen (FJ) model to describe the dynamics of opinion evolution within a social network. Under the FJ framework, the society is divided into two subgroups that include stubborn agents and regular agents. The opinions of stubborn agents are not influenced by regular agents, whereas the opinions of regular agents evolve based on the opinions of their neighboring agents. By defining the origin as the desired collective opinion of the society, the objective of the paper is to minimize deviations from this desired opinion. To achieve this, a Stackelberg game is established between the stubborn and regular subgroups, where the opinion adjustments of the stubborn agents and the openness variables of regular agents serve as the decision variables. The proposed solution approach integrates quadratic programming and dynamic programming to optimize these decision variables at each discrete time step using forward and backward propagation.

Paper number 60:
Title: Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks
Authors: Po-Heng Chou, Pin-Qi Fu, Walid Saad, Li-Chun Wang
Abstract: This paper presents an agentic artificial intelligence (AI)-driven double deep Q-network (DDQN) scheduling framework for licensed and unlicensed band allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi, posing significant challenges for coexistence. Unlike prior rule-based or threshold-based methods, the proposed agentic scheduler autonomously perceives queueing dynamics, channel conditions, and coexistence states, and adapts its policy to maintain quality-of-service (QoS). Simulation results show that our framework reduces the blocking rate by up to 87.5% compared to threshold-based scheduling under limited licensed bandwidth. These findings demonstrate the potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling for future NR SL systems.

Paper number 61:
Title: Green Learning for STAR-RIS mmWave Systems with Implicit CSI
Authors: Yu-Hsiang Huang, Po-Heng Chou, Wan-Jen Huang, Walid Saad, C.-C. Jay Kuo
Abstract: In this paper, a green learning (GL)-based precoding framework is proposed for simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems. Motivated by the growing emphasis on environmental sustainability in future 6G networks, this work adopts a broadcasting transmission architecture for scenarios where multiple users share identical information, improving spectral efficiency and reducing redundant transmissions and power consumption. Different from conventional optimization methods, such as block coordinate descent (BCD) that require perfect channel state information (CSI) and iterative computation, the proposed GL framework operates directly on received uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL) approaches that require CSI-based labels for training, the proposed GL approach also avoids deep neural networks and backpropagation, leading to a more lightweight design. Although the proposed GL framework is trained with supervision generated by BCD under full CSI, inference is performed in a fully CSI-free manner. The proposed GL integrates subspace approximation with adjusted bias (Saab), relevant feature test (RFT)-based supervised feature selection, and eXtreme gradient boosting (XGBoost)-based decision learning to jointly predict the STAR-RIS coefficients and transmit precoder. Simulation results show that the proposed GL approach achieves competitive spectral efficiency compared to BCD and DL-based models, while reducing floating-point operations (FLOPs) by over four orders of magnitude. These advantages make the proposed GL approach highly suitable for real-time deployment in energy- and hardware-constrained broadcasting scenarios.

Paper number 62:
Title: Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor
Authors: Juan D. Gil, Ehecatl Antonio Del Rio Chanona, Jos√© L. Guzm√°n, Manuel Berenguel
Abstract: The inherent complexity of living cells as production units creates major challenges for maintaining stable and optimal bioprocess conditions, especially in open Photobioreactors (PBRs) exposed to fluctuating environments. To address this, we propose a Reinforcement Learning (RL) control approach, combined with Behavior Cloning (BC), for pH regulation in open PBR systems. This represents, to the best of our knowledge, the first application of an RL-based control strategy to such a nonlinear and disturbance-prone bioprocess. Our method begins with an offline training stage in which the RL agent learns from trajectories generated by a nominal Proportional-Integral-Derivative (PID) controller, without direct interaction with the real system. This is followed by a daily online fine-tuning phase, enabling adaptation to evolving process dynamics and stronger rejection of fast, transient disturbances. This hybrid offline-online strategy allows deployment of an adaptive control policy capable of handling the inherent nonlinearities and external perturbations in open PBRs. Simulation studies highlight the advantages of our method: the Integral of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5% relative to standard off-policy RL. Moreover, control effort decreased substantially-by 54% compared to PID and 7% compared to standard RL-an important factor for minimizing operational costs. Finally, an 8-day experimental validation under varying environmental conditions confirmed the robustness and reliability of the proposed approach. Overall, this work demonstrates the potential of RL-based methods for bioprocess control and paves the way for their broader application to other nonlinear, disturbance-prone systems.

Paper number 63:
Title: LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba
Authors: Yinuo Wang, Gavin Tao
Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on selective state-space models, specifically leveraging Mamba, that achieves near-linear-time sequence modeling, effectively captures long-range dependencies, and enables efficient training with longer sequences. First, we embed proprioceptive states with a multilayer perceptron and patchify depth images with a lightweight convolutional neural network, producing compact tokens that improve state representation. Second, stacked Mamba layers fuse these tokens via near-linear-time selective scanning, reducing latency and memory footprint, remaining robust to token length and image resolution, and providing an inductive bias that mitigates overfitting. Third, we train the policy end-to-end with Proximal Policy Optimization under terrain and appearance randomization and an obstacle-density curriculum, using a compact state-centric reward that balances progress, smoothness, and safety. We evaluate our method in challenging simulated environments with static and moving obstacles as well as uneven terrain. Compared with state-of-the-art baselines, our method achieves higher returns and success rates with fewer collisions, exhibits stronger generalization to unseen terrains and obstacle densities, and improves training efficiency by converging in fewer updates under the same compute budget.

Paper number 64:
Title: An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training
Authors: Yanis Labrak, Richard Dufour, Micka√´l Rouvier
Abstract: This paper investigates discrete unit representations in Speech Language Models (SLMs), focusing on optimizing speech modeling during continual pre-training. In this paper, we systematically examine how model architecture, data representation, and training robustness influence the pre-training stage in which we adapt existing pre-trained language models to the speech modality. Our experiments highlight the role of speech encoders and clustering granularity across different model scales, showing how optimal discretization strategies vary with model capacity. By examining cluster distribution and phonemic alignments, we investigate the effective use of discrete vocabulary, uncovering both linguistic and paralinguistic patterns. Additionally, we explore the impact of clustering data selection on model robustness, highlighting the importance of domain matching between discretization training and target applications.

Paper number 65:
Title: Distributed Link Sparsification for Scalable Scheduling Using Graph Neural Networks (Journal Version)
Authors: Zhongyuan Zhao, Gunjan Verma, Ananthram Swami, Santiago Segarra
Abstract: In wireless networks characterized by dense connectivity, the significant signaling overhead generated by distributed link scheduling algorithms can exacerbate issues like congestion, energy consumption, and radio footprint expansion. To mitigate these challenges, we propose a distributed link sparsification scheme employing graph neural networks (GNNs) to reduce scheduling overhead for delay-tolerant traffic while maintaining network capacity. A GNN module is trained to adjust contention thresholds for individual links based on traffic statistics and network topology, enabling links to withdraw from scheduling contention when they are unlikely to succeed. Our approach is facilitated by a novel offline constrained {unsupervised} learning algorithm capable of balancing two competing objectives: minimizing scheduling overhead while ensuring that total utility meets the required level. In simulated wireless multi-hop networks with up to 500 links, our link sparsification technique effectively alleviates network congestion and reduces radio footprints across four distinct distributed link scheduling protocols.

Paper number 66:
Title: Hybrid-illumination multiplexed Fourier ptychographic microscopy with robust aberration correction
Authors: Shi Zhao, Haowen Zhou, Changhuei Yang
Abstract: Fourier ptychographic microscopy (FPM) is a powerful computational imaging modality that achieves high space-bandwidth product imaging for biomedical samples. However, its adoption is limited by slow data acquisition due to the need for sequential measurements. Multiplexed FPM strategies have been proposed to accelerate imaging by activating multiple LEDs simultaneously, but they typically require careful parameter tuning, and their lack of effective aberration correction makes them prone to image degradation. To address these limitations, we introduce hybrid-illumination multiplexed Fourier ptychographic microscopy (HMFPM), which integrates analytic aberration extraction capability with the efficiency of multiplexed illumination. Specifically, HMFPM employs a hybrid illumination strategy and a customized reconstruction algorithm with analytic and optimization methods. This hybrid strategy substantially reduces the number of required measurements while ensuring robust aberration correction and stable convergence. We demonstrate that HMFPM achieves 1.08 micrometers resolution, representing a 4-fold enhancement over the system's coherent diffraction limit, across a 1.77x1.77 millimeter square field of view using 20 measurements. HMFPM remains robust under diverse aberrations, providing up to 84 micrometers digital refocusing capability, and effectively corrects both field-dependent and scanning-induced aberrations in whole-slide pathology imaging. These results establish HMFPM as a practical, high-throughput, and aberration-free solution for biological and biomedical imaging.

Paper number 67:
Title: Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids
Authors: Arturo Flores Alvarez, Fatemeh Zargarbashi, Havel Liu, Shiqi Wang, Liam Edwards, Jessica Anz, Alex Xu, Fan Shi, Stelian Coros, Dennis W. Hong
Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a custom-built humanoid robot designed for entertainment applications. Unlike traditional humanoids, entertainment robots present unique challenges due to aesthetic-driven design choices. Cosmo embodies these with a disproportionately large head (16% of total mass), limited sensing, and protective shells that considerably restrict movement. To address these challenges, we apply Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking movements while maintaining physical stability. We develop tailored domain randomization techniques and specialized reward structures to ensure safe sim-to-real, protecting valuable hardware components during deployment. Our experiments demonstrate that AMP generates stable standing and walking behaviors despite Cosmo's extreme mass distribution and movement constraints. These results establish a promising direction for robots that balance aesthetic appeal with functional performance, suggesting that learning-based methods can effectively adapt to aesthetic-driven design constraints.

Paper number 68:
Title: Effectively obtaining acoustic, visual and textual data from videos
Authors: Jorge E. Le√≥n, Miguel Carrasco
Abstract: The increasing use of machine learning models has amplified the demand for high-quality, large-scale multimodal datasets. However, the availability of such datasets, especially those combining acoustic, visual and textual data, remains limited. This paper addresses this gap by proposing a method to extract related audio-image-text observations from videos. We detail the process of selecting suitable videos, extracting relevant data pairs, and generating descriptive texts using image-to-text models. Our approach ensures a robust semantic connection between modalities, enhancing the utility of the created datasets for various applications. We also discuss the challenges encountered and propose solutions to improve data quality. The resulting datasets, publicly available, aim to support and advance research in multimodal data analysis and machine learning.

Paper number 69:
Title: Yours or Mine? Overwriting Attacks against Neural Audio Watermarking
Authors: Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Phone Lin, Tomoaki Ohtsuki, Miao Pan
Abstract: As generative audio models are rapidly evolving, AI-generated audios increasingly raise concerns about copyright infringement and misinformation spread. Audio watermarking, as a proactive defense, can embed secret messages into audio for copyright protection and source verification. However, current neural audio watermarking methods focus primarily on the imperceptibility and robustness of watermarking, while ignoring its vulnerability to security attacks. In this paper, we develop a simple yet powerful attack: the overwriting attack that overwrites the legitimate audio watermark with a forged one and makes the original legitimate watermark undetectable. Based on the audio watermarking information that the adversary has, we propose three categories of overwriting attacks, i.e., white-box, gray-box, and black-box attacks. We also thoroughly evaluate the proposed attacks on state-of-the-art neural audio watermarking methods. Experimental results demonstrate that the proposed overwriting attacks can effectively compromise existing watermarking schemes across various settings and achieve a nearly 100% attack success rate. The practicality and effectiveness of the proposed overwriting attacks expose security flaws in existing neural audio watermarking systems, underscoring the need to enhance security in future audio watermarking designs.

Paper number 70:
Title: Genesis: A Spiking Neuromorphic Accelerator With On-chip Continual Learning
Authors: Vedant Karia, Abdullah Zyarah, Dhireesha Kudithipudi
Abstract: Continual learning, the ability to acquire and transfer knowledge through a models lifetime, is critical for artificial agents that interact in real-world environments. Biological brains inherently demonstrate these capabilities while operating within limited energy and resource budgets. Achieving continual learning capability in artificial systems considerably increases memory and computational demands, and even more so when deploying on platforms with limited resources. In this work, Genesis, a spiking continual learning accelerator, is proposed to address this gap. The architecture supports neurally inspired mechanisms, such as activity-dependent metaplasticity, to alleviate catastrophic forgetting. It integrates low-precision continual learning parametersand employs a custom data movement strategy to accommodate the sparsely distributed spikes. Furthermore, the architecture features a memory mapping technique that places metaplasticity parameters and synaptic weights in a single address location for faster memory access. Results show that the mean classification accuracy for Genesis is 74.6% on a task-agnostic split-MNIST benchmark with power consumption of 17.08mW in a 65nm technology node.

Paper number 71:
Title: Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data
Authors: Caleb Gates, Patrick Moorhead, Jayden Ferguson, Omar Darwish, Conner Stallman, Pablo Rivas, Paapa Quansah
Abstract: Dust storms harm health and reduce visibility; quick detection from satellites is needed. We present a near real-time system that flags dust at the pixel level using multi-band images from NASA's Terra and Aqua (MODIS). A 3D convolutional network learns patterns across all 36 bands, plus split thermal bands, to separate dust from clouds and surface features. Simple normalization and local filling handle missing data. An improved version raises training speed by 21x and supports fast processing of full scenes. On 17 independent MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error of 0.014. Maps show strong agreement in plume cores, with most misses along edges. These results show that joint band-and-space learning can provide timely dust alerts at global scale; using wider input windows or attention-based models may further sharpen edges.

Paper number 72:
Title: Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling
Authors: Yue Gu, Zhihao Du, Ying Shi, Shiliang Zhang, Qian Chen, Jiqing Han
Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR) models have made notable advancements in recognizing personalized biasing phrases. However, the effectiveness of cross-attention is affected by variations in biasing information volume, especially when the length of the biasing list increases significantly. We find that, regardless of the length of the biasing list, only a limited amount of biasing information is most relevant to a specific ASR intermediate representation. Therefore, by identifying and integrating the most relevant biasing information rather than the entire biasing list, we can alleviate the effects of variations in biasing information volume for contextual ASR. To this end, we propose a purified semantic correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and calculate three semantic correlations between the ASR intermediate representations and biasing information from coarse to fine: list-level, phrase-level, and token-level. Then, the three correlations are jointly modeled to produce their intersection, so that the most relevant biasing information across various granularities is highlighted and integrated for contextual recognition. In addition, to reduce the computational cost introduced by the joint modeling of three semantic correlations, we also propose a purification mechanism based on a grouped-and-competitive strategy to filter out irrelevant biasing phrases. Compared with baselines, our PSC-Joint approach achieves average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46% on KeSpeech, across biasing lists of varying lengths.

Paper number 73:
Title: Smoothed Online Optimization for Target Tracking: Robust and Learning-Augmented Algorithms
Authors: Ali Zeynali, Mahsa Sahebdel, Qingsong Liu, Mohammad Hajiesmaili, Ramesh K. Sitaraman
Abstract: We introduce the Smoothed Online Optimization for Target Tracking (SOOTT) problem, a new framework that integrates three key objectives in online decision-making under uncertainty: (1) tracking cost for following a dynamically moving target, (2) adversarial perturbation cost for withstanding unpredictable disturbances, and (3) switching cost for penalizing abrupt changes in decisions. This formulation captures real-world scenarios such as elastic and inelastic workload scheduling in AI clusters, where operators must balance long-term service-level agreements (e.g., LLM training) against sudden demand spikes (e.g., real-time inference). We first present BEST, a robust algorithm with provable competitive guarantees for SOOTT. To enhance practical performance, we introduce CoRT, a learning-augmented variant that incorporates untrusted black-box predictions (e.g., from ML models) into its decision process. Our theoretical analysis shows that CoRT strictly improves over BEST when predictions are accurate, while maintaining robustness under arbitrary prediction errors. We validate our approach through a case study on workload scheduling, demonstrating that both algorithms effectively balance trajectory tracking, decision smoothness, and resilience to external disturbances.

Paper number 74:
Title: TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition
Authors: Minh N. H. Nguyen, Anh Nguyen Tran, Dung Truong Dinh, Nam Van Vo
Abstract: Code-switching (CS) presents a significant challenge for general Auto-Speech Recognition (ASR) systems. Existing methods often fail to capture the subtle phonological shifts inherent in CS scenarios. The challenge is particularly difficult for language pairs like Vietnamese and English, where both distinct phonological features and the ambiguity arising from similar sound recognition are present. In this paper, we propose a novel architecture for Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC employs a phoneme-centric approach, built upon an extended Vietnamese phoneme set as an intermediate representation to facilitate mixed-lingual modeling. Experimental results demonstrate that TSPC consistently outperforms existing baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a significantly lower word error rate of 20.8\% with reduced training resources. Furthermore, the phonetic-based two-stage architecture enables phoneme adaptation and language conversion to enhance ASR performance in complex CS Vietnamese-English ASR scenarios.

Paper number 75:
Title: Xi+: Uncertainty Supervision for Robust Speaker Embedding
Authors: Junjie Li, Kong Aik Lee, Duc-Tuan Truong, Tianchi Liu, Man-Wai Mak
Abstract: There are various factors that can influence the performance of speaker recognition systems, such as emotion, language and other speaker-related or context-related variations. Since individual speech frames do not contribute equally to the utterance-level representation, it is essential to estimate the importance or reliability of each frame. The xi-vector model addresses this by assigning different weights to frames based on uncertainty estimation. However, its uncertainty estimation model is implicitly trained through classification loss alone and does not consider the temporal relationships between frames, which may lead to suboptimal supervision. In this paper, we propose an improved architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention module to capture frame-level uncertainty in a context-aware manner. In addition, we introduce a novel loss function, Stochastic Variance Loss, which explicitly supervises the learning of uncertainty. Results demonstrate consistent performance improvements of about 10\% on the VoxCeleb1-O set and 11\% on the NIST SRE 2024 evaluation set.

Paper number 76:
Title: DreamAudio: Customized Text-to-Audio Generation with Diffusion Models
Authors: Yi Yuan, Xubo Liu, Haohe Liu, Xiyuan Kang, Zhuo Chen, Yuxuan Wang, Mark D. Plumbley, Wenwu Wang
Abstract: With the development of large-scale diffusion-based and language-modeling-based generative models, impressive progress has been achieved in text-to-audio generation. Despite producing high-quality outputs, existing text-to-audio models mainly aim to generate semantically aligned sound and fall short on precisely controlling fine-grained acoustic characteristics of specific sounds. As a result, users that need specific sound content may find it challenging to generate the desired audio clips. In this paper, we present DreamAudio for customized text-to-audio generation (CTTA). Specifically, we introduce a new framework that is designed to enable the model to identify auditory information from user-provided reference concepts for audio generation. Given a few reference audio samples containing personalized audio events, our system can generate new audio samples that include these specific events. In addition, two types of datasets are developed for training and testing the customized systems. The experiments show that the proposed model, DreamAudio, generates audio samples that are highly consistent with the customized audio features and aligned well with the input text prompts. Furthermore, DreamAudio offers comparable performance in general text-to-audio tasks. We also provide a human-involved dataset containing audio events from real-world CTTA cases as the benchmark for customized generation tasks.

Paper number 77:
Title: Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots
Authors: Runjiao Bao, Lin Zhang, Tianwei Niu, Haoyu Yuan, Shoukun Wang
Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a rich set of motion modes, such as Ackermann steering, lateral steering, and parallel movement, offering superior maneuverability in constrained environments. However, existing path planning methods generally assume a single kinematic model and thus fail to fully exploit the multi-modal capabilities of 4WIS platforms. To address this limitation, we propose an extended Hybrid A* framework that operates in a four-dimensional state space incorporating both spatial states and motion modes. Within this framework, we design multi-modal Reeds-Shepp curves tailored to the distinct kinematic constraints of each motion mode, develop an enhanced heuristic function that accounts for mode-switching costs, and introduce a terminal connection strategy with intelligent mode selection to ensure smooth transitions between different steering patterns. The proposed planner enables seamless integration of multiple motion modalities within a single path, significantly improving flexibility and adaptability in complex environments. Results demonstrate significantly improved planning performance for 4WIS robots in complex environments.

Paper number 78:
Title: A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications
Authors: Shiqi Xu, Lihao Zhang, Yuyang Du, Qun Yang, Soung Chang Liew
Abstract: Recent progress in robotics has underscored the demand for real-time control in applications such as manufacturing, healthcare, and autonomous systems, where the timely delivery of mission-critical commands under heterogeneous robotic traffic is paramount for operational efficacy and safety. In these scenarios, mission-critical traffic follows a strict deadline-constrained communication pattern: commands must arrive within defined QoS deadlines, otherwise late arrivals can degrade performance or destabilize control this http URL this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted in robotic communications,suffers severe degradation under high robot traffic loads, with contention-induced collisions and delays disrupting the on-time arrival of mission-critical packets. To address this problem, we propose an IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's deterministic slot scheduling with CSMA's adaptability for heterogeneous robot this http URL protocol achieves collision-free, low-latency mission-critical command delivery and IEEE 802.11 compatibility through the synergistic integration of sub-microsecond PTP-based slot synchronization-essential for establishing precise timing for TDMA, a three-session superframe with dynamic TDMA allocation for structured and adaptable traffic management,and beacon-NAV protection to preemptively secure these critical communication sessions from interference. Emulation experiments on real-time SDR testbed and Robot Operating System (ROS) simulation show that the proposed protocol reduces missed-deadline errors by 93% compared to the CSMA baseline. In high-speed robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS) trajectory error by up to 90% compared with a CSMA baseline, all while maintaining throughput for non-critical traffic within +-2%.

Paper number 79:
Title: VehiclePassport: A GAIA-X-Aligned, Blockchain-Anchored Privacy-Preserving, Zero-Knowledge Digital Passport for Smart Vehicles
Authors: Pradyumna Kaushal
Abstract: Modern vehicles accumulate fragmented lifecycle records across OEMs, owners, and service centers that are difficult to verify and prone to fraud. We propose VehiclePassport, a GAIA-X-aligned digital passport anchored on blockchain with zero-knowledge proofs (ZKPs) for privacy-preserving verification. VehiclePassport immutably commits to manufacturing, telemetry, and service events while enabling selective disclosure via short-lived JWTs and Groth16 proofs. Our open-source reference stack anchors hashes on Polygon zkEVM at <$0.02 per event, validates proofs in <10 ms, and scales to millions of vehicles. This architecture eliminates paper-based KYC, ensures GDPR-compliant traceability, and establishes a trustless foundation for insurance, resale, and regulatory applications in global mobility data markets.

Paper number 80:
Title: Ignore Drift, Embrace Simplicity: Constrained Nonlinear Control through Driftless Approximation
Authors: Ram Padmanabhan, Melkior Ornik
Abstract: We present a novel technique to drive a nonlinear system to reach a target state under input constraints. The proposed controller consists only of piecewise constant inputs, generated from a simple linear driftless approximation to the original nonlinear system. First, we construct this approximation using only the effect of the control input at the initial state. Next, we partition the time horizon into successively shorter intervals and show that optimal controllers for the linear driftless system result in a bounded error from a specified target state in the nonlinear system. We also derive conditions under which the input constraint is guaranteed to be satisfied. On applying the optimal control inputs, we show that the error monotonically converges to zero as the intervals become successively shorter, thus achieving arbitrary closeness to the target state with time. Using simulation examples on classical nonlinear systems, we illustrate how the presented technique is used to reach a target state while still satisfying input constraints. In particular, we show that our method completes the task even when assumptions of the underlying theory are violated or when classical linearization-based methods may fail.

Paper number 81:
Title: 20 Years in Life of a Smart Building: A retrospective
Authors: Karolina Skrivankova, Mark Handley, Stephen Hailes
Abstract: Operating an intelligent smart building automation system in 2025 is met with many challenges: hardware failures, vendor obsolescence, evolving security threats and more. None of these have been comprehensibly addressed by the industrial building nor home automation industries, limiting feasibility of operating large, truly smart automation deployments. This paper introduces KaOS, a distributed control platform for constructing robust and evolvable smart building automation systems using affordable, off-the-shelf IoT hardware. Supporting control applications and distributed system operations by leveraging containerisation and managed resource access, KaOS seeks to achieve flexibility, security, and fault tolerance without sacrificing cost-effectiveness. Initial evaluation confirms the practical feasibility of our approach, highlighting its potential to sustainably maintain and incrementally evolve building control functionalities over extended timeframes.

Paper number 82:
Title: Beyond Diagonal IRS Aided OFDM: Rate Maximization under Frequency-Dependent Reflection
Authors: Ye Yuan, Shuowen Zhang
Abstract: This paper studies a broadband orthogonal frequency division multiplexing (OFDM) system aided by a beyond diagonal intelligent reflecting surface (BD-IRS), where inter-connections exist among different elements such that the reflection matrix can exhibit a beyond diagonal structure. Under practical circuit structures, the reflection matrix of the BD-IRS is generally dependent on the circuit parameters (e.g., capacitance matrix for all tunable capacitors) as well as the operating frequency, which leads to couplings among the BD-IRS reflection matrices over different sub-carriers and consequently new challenges in the BD-IRS design. Motivated by this, we first model the relationship between the BD-IRS reflection matrices over different sub-carriers and the tunable capacitance matrix, and then formulate the joint optimization problem of the tunable capacitance matrix and power allocation over OFDM sub-carriers to maximize the achievable rate of the OFDM system. Despite the non-convexity of the problem, we propose an effective algorithm for finding a high-quality feasible solution via leveraging alternating optimization and successive convex approximation. Numerical results show the superiority of our proposed design over benchmark designs.

Paper number 83:
Title: Graph Neural Networks for Resource Allocation in Interference-limited Multi-Channel Wireless Networks with QoS Constraints
Authors: Lili Chen, Changyang She, Jingge Zhu, Jamie Evans
Abstract: Meeting minimum data rate constraints is a significant challenge in wireless communication systems, particularly as network complexity grows. Traditional deep learning approaches often address these constraints by incorporating penalty terms into the loss function and tuning hyperparameters empirically. However, this heuristic treatment offers no theoretical convergence guarantees and frequently fails to satisfy QoS requirements in practical scenarios. Building upon the structure of the WMMSE algorithm, we first extend it to a multi-channel setting with QoS constraints, resulting in the enhanced WMMSE (eWMMSE) algorithm, which is provably convergent to a locally optimal solution when the problem is feasible. To further reduce computational complexity and improve scalability, we develop a GNN-based algorithm, JCPGNN-M, capable of supporting simultaneous multi-channel allocation per user. To overcome the limitations of traditional deep learning methods, we propose a principled framework that integrates GNN with a Lagrangian-based primal-dual optimization method. By training the GNN within the Lagrangian framework, we ensure satisfaction of QoS constraints and convergence to a stationary point. Extensive simulations demonstrate that JCPGNN-M matches the performance of eWMMSE while offering significant gains in inference speed, generalization to larger networks, and robustness under imperfect channel state information. This work presents a scalable and theoretically grounded solution for constrained resource allocation in future wireless networks.

Paper number 84:
Title: VQualA 2025 Challenge on Image Super-Resolution Generated Content Quality Assessment: Methods and Results
Authors: Yixiao Li, Xin Li, Chris Wei Zhou, Shuo Xing, Hadi Amirpour, Xiaoshuai Hao, Guanghui Yue, Baoquan Zhao, Weide Liu, Xiaoyuan Yang, Zhengzhong Tu, Xinyu Li, Chuanbiao Song, Chenqi Zhang, Jun Lan, Huijia Zhu, Weiqiang Wang, Xiaoyan Sun, Shishun Tian, Dongyang Yan, Weixia Zhang, Junlin Chen, Wei Sun, Zhihua Wang, Zhuohang Shi, Zhizun Luo, Hang Ouyang, Tianxin Xiao, Fan Yang, Zhaowang Wu, Kaixin Deng
Abstract: This paper presents the ISRGC-Q Challenge, built upon the Image Super-Resolution Generated Content Quality Assessment (ISRGen-QA) dataset, and organized as part of the Visual Quality Assessment (VQualA) Competition at the ICCV 2025 Workshops. Unlike existing Super-Resolution Image Quality Assessment (SR-IQA) datasets, ISRGen-QA places a greater emphasis on SR images generated by the latest generative approaches, including Generative Adversarial Networks (GANs) and diffusion models. The primary goal of this challenge is to analyze the unique artifacts introduced by modern super-resolution techniques and to evaluate their perceptual quality effectively. A total of 108 participants registered for the challenge, with 4 teams submitting valid solutions and fact sheets for the final testing phase. These submissions demonstrated state-of-the-art (SOTA) performance on the ISRGen-QA dataset. The project is publicly available at: this https URL.

Paper number 85:
Title: Perception-oriented Bidirectional Attention Network for Image Super-resolution Quality Assessment
Authors: Yixiao Li, Xiaoyuan Yang, Guanghui Yue, Jun Fu, Qiuping Jiang, Xu Jia, Paul L. Rosin, Hantao Liu, Wei Zhou
Abstract: Many super-resolution (SR) algorithms have been proposed to increase image resolution. However, full-reference (FR) image quality assessment (IQA) metrics for comparing and evaluating different SR algorithms are limited. In this work, we propose the Perception-oriented Bidirectional Attention Network (PBAN) for image SR FR-IQA, which is composed of three modules: an image encoder module, a perception-oriented bidirectional attention (PBA) module, and a quality prediction module. First, we encode the input images for feature representations. Inspired by the characteristics of the human visual system, we then construct the perception-oriented PBA module. Specifically, different from existing attention-based SR IQA methods, we conceive a Bidirectional Attention to bidirectionally construct visual attention to distortion, which is consistent with the generation and evaluation processes of SR images. To further guide the quality assessment towards the perception of distorted information, we propose Grouped Multi-scale Deformable Convolution, enabling the proposed method to adaptively perceive distortion. Moreover, we design Sub-information Excitation Convolution to direct visual perception to both sub-pixel and sub-channel attention. Finally, the quality prediction module is exploited to integrate quality-aware features and regress quality scores. Extensive experiments demonstrate that our proposed PBAN outperforms state-of-the-art quality assessment methods.

Paper number 86:
Title: Information-Theoretic Bounds and Task-Centric Learning Complexity for Real-World Dynamic Nonlinear Systems
Authors: Sri Satish Krishna Chaitanya Bulusu, Mikko Sillanp√§√§
Abstract: Dynamic nonlinear systems exhibit distortions arising from coupled static and dynamic effects. Their intertwined nature poses major challenges for data-driven modeling. This paper presents a theoretical framework grounded in structured decomposition, variance analysis, and task-centric complexity bounds. The framework employs a directional lower bound on interactions between measurable system components, extending orthogonality in inner product spaces to structurally asymmetric settings. This bound supports variance inequalities for decomposed systems. Key behavioral indicators are introduced along with a memory finiteness index. A rigorous power-based condition establishes a measurable link between finite memory in realizable systems and the First Law of Thermodynamics. This offers a more foundational perspective than classical bounds based on the Second Law. Building on this foundation, we formulate a `Behavioral Uncertainty Principle,' demonstrating that static and dynamic distortions cannot be minimized simultaneously. We identify that real-world systems seem to resist complete deterministic decomposition due to entangled static and dynamic effects. We also present two general-purpose theorems linking function variance to mean-squared Lipschitz continuity and learning complexity. This yields a model-agnostic, task-aware complexity metric, showing that lower-variance components are inherently easier to learn. These insights explain the empirical benefits of structured residual learning, including improved generalization, reduced parameter count, and lower training cost, as previously observed in power amplifier linearization experiments. The framework is broadly applicable and offers a scalable, theoretically grounded approach to modeling complex dynamic nonlinear systems.

Paper number 87:
Title: An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields
Authors: Sajad Ahmadi, Mohammadreza Davoodi, Javad Mohammadpour Velni
Abstract: This paper presents an adaptive coverage control method for a fleet of off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic (time-varying) agricultural environments. Traditional coverage control approaches often assume static conditions, making them unsuitable for real-world farming scenarios where obstacles, such as moving machinery and uneven terrains, create continuous challenges. To address this, we propose a real-time path planning framework that integrates Unmanned Aerial Vehicles (UAVs) for obstacle detection and terrain assessment, allowing UGVs to dynamically adjust their coverage paths. The environment is modeled as a weighted directed graph, where the edge weights are continuously updated based on the UAV observations to reflect obstacle motion and terrain variations. The proposed approach incorporates Voronoi-based partitioning, adaptive edge weight assignment, and cost-based path optimization to enhance navigation efficiency. Simulation results demonstrate the effectiveness of the proposed method in improving path planning, reducing traversal costs, and maintaining robust coverage in the presence of dynamic obstacles and muddy terrains.

Paper number 88:
Title: Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways
Authors: Sajad Ahmadi, Hossein Nejatbakhsh Esfahani, Javad Mohammadpour Velni
Abstract: Deploying self-navigating surface vessels in inland waterways offers a sustainable alternative to reduce road traffic congestion and emissions. However, navigating confined waterways presents unique challenges, including narrow channels, higher traffic density, and hydrodynamic disturbances. Existing methods for autonomous vessel navigation often lack the robustness or precision required for such environments. This paper presents a new motion planning approach for Automated Surface Vessels (ASVs) using Robust Model Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By incorporating channel borders and obstacles as safety constraints within the control design framework, the proposed method ensures both collision avoidance and robust navigation on complex waterways. Simulation results demonstrate the efficacy of the proposed method in safely guiding ASVs under realistic conditions, highlighting its improved safety and adaptability compared to the state-of-the-art.

Paper number 89:
Title: Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization
Authors: Minheng Chen, Youyong Kong
Abstract: Intraoperative 2D/3D registration aligns preoperative 3D volumes with real-time 2D radiographs, enabling accurate localization of instruments and implants. A recent fully differentiable similarity learning framework approximates geodesic distances on SE(3), expanding the capture range of registration and mitigating the effects of substantial disturbances, but existing Euclidean approximations distort manifold structure and slow convergence. To address these limitations, we explore similarity learning in non-Euclidean spherical feature spaces to better capture and fit complex manifold structure. We extract feature embeddings using a CNN-Transformer encoder, project them into spherical space, and approximate their geodesic distances with Riemannian distances in the bi-invariant SO(4) space. This enables a more expressive and geometrically consistent deep similarity metric, enhancing the ability to distinguish subtle pose differences. During inference, we replace gradient descent with fully differentiable Levenberg-Marquardt optimization to accelerate convergence. Experiments on real and synthetic datasets show superior accuracy in both patient-specific and patient-agnostic scenarios.

Paper number 90:
Title: BatStation: Toward In-Situ Radar Sensing on 5G Base Stations with Zero-Shot Template Generation
Authors: Zhihui Gao, Zhecun Liu, Tingjun Chen
Abstract: The coexistence between incumbent radar signals and commercial 5G signals necessitates a versatile and ubiquitous radar sensing for efficient and adaptive spectrum sharing. In this context, leveraging the densely deployed 5G base stations (BS) for radar sensing is particularly promising, offering both wide coverage and immediate feedback to 5G scheduling. However, the targeting radar signals are superimposed with concurrent 5G uplink transmissions received by the BS, and practical deployment also demands a lightweight, portable radar sensing model. This paper presents BatStation, a lightweight, in-situ radar sensing framework seamlessly integrated into 5G BSs. BatStation leverages uplink resource grids to extract radar signals through three key components: (i) radar signal separation to cancel concurrent 5G transmissions and reveal the radar signals, (ii) resource grid reshaping to align time-frequency resolution with radar pulse characteristics, and (iii) zero-shot template correlation based on a portable model trained purely on synthetic data that supports detection, classification, and localization of radar pulses without fine-tuning using experimental data. We implement BatStation on a software-defined radio (SDR) testbed and evaluate its performance with real 5G traffic in the CBRS band. Results show robust performance across diverse radar types, achieving detection probabilities of 97.02% (PUCCH) and 79.23% (PUSCH), classification accuracy up to 97.00%, and median localization errors of 2.68-6.20 MHz (frequency) and 24.6-32.4 microseconds (time). Notably, BatStation achieves this performance with a runtime latency of only 0.11/0.94 ms on GPU/CPU, meeting the real-time requirement of 5G networks.

Paper number 91:
Title: Continuous Audio Language Models
Authors: Rouard Simon, Orsini Manu, Roebel Axel, Zeghidour Neil, D√©fossez Alexandre
Abstract: Audio Language Models (ALM) have emerged as the dominant paradigm for speech and music generation by representing audio as sequences of discrete tokens. Yet, unlike text tokens, which are invertible, audio tokens are extracted from lossy codecs with a limited bitrate. As a consequence, increasing audio quality requires generating more tokens, which imposes a trade-off between fidelity and computational cost. We address this issue by studying Continuous Audio Language Models (CALM). These models instantiate a large Transformer backbone that produces a contextual embedding at every timestep. This sequential information then conditions an MLP that generates the next continuous frame of an audio VAE through consistency modeling. By avoiding lossy compression, CALM achieves higher quality at lower computational cost than their discrete counterpart. Experiments on speech and music demonstrate improved efficiency and fidelity over state-of-the-art discrete audio language models, facilitating lightweight, high-quality audio generation. Samples are available at this https URL

Paper number 92:
Title: Benchmarking Music Autotagging with MGPHot Expert Annotations vs. Generic Tag Datasets
Authors: Pedro Ramoneda, Pablo Alonso-Jimenez, Sergio Oramas, Xavier Serra, Dmitry Bogdanov
Abstract: Music autotagging aims to automatically assign descriptive tags, such as genre, mood, or instrumentation, to audio recordings. Due to its challenges, diversity of semantic descriptions, and practical value in various applications, it has become a common downstream task for evaluating the performance of general-purpose music representations learned from audio data. We introduce a new benchmarking dataset based on the recently published MGPHot dataset, which includes expert musicological annotations, allowing for additional insights and comparisons with results obtained on common generic tag datasets. While MGPHot annotations have been shown to be useful for computational musicology, the original dataset neither includes audio nor provides evaluation setups for its use as a standardized autotagging benchmark. To address this, we provide a curated set of YouTube URLs with retrievable audio, and propose a train/val/test split for standardized evaluation, and precomputed representations for seven state-of-the-art models. Using these resources, we evaluated these models in MGPHot and standard reference tag datasets, highlighting key differences between expert and generic tag annotations. Altogether, our contributions provide a more advanced benchmarking framework for future research in music understanding.

Paper number 93:
Title: Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments
Authors: Jiahui Yang, Jason Jingzhou Liu, Yulong Li, Youssef Khaky, Kenneth Shaw, Deepak Pathak
Abstract: Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACT's static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policy's dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at this https URL

Paper number 94:
Title: Time-Varying Graph Learning with Constraints on Graph Temporal Variation
Authors: Haruki Yokota, Koki Yamada, Yuichi Tanaka, Antonio Ortega
Abstract: We propose a novel framework for learning time-varying graphs from spatiotemporal measurements. Given an appropriate prior on the temporal behavior of signals, our proposed method can estimate time-varying graphs from a small number of available measurements. To achieve this, we introduce two regularization terms in convex optimization problems that constrain sparseness of temporal variations of the time-varying networks. Moreover, a computationally-scalable algorithm is introduced to efficiently solve the optimization problem. The experimental results with synthetic and real datasets (point cloud and temperature data) demonstrate our proposed method outperforms the existing state-of-the-art methods.

Paper number 95:
Title: Data-Driven Robust Optimization for Energy-Aware Safe Motion Planning of Electric Vehicles
Authors: Simran Kumari, Ashish R. Hota, Siddhartha Mukhopadhyay
Abstract: In this paper, we simultaneously address the problems of energy optimal and safe motion planning of electric vehicles (EVs) in a data-driven robust optimization framework. Safe maneuvers, especially in urban traffic, are characterized by frequent lateral motions, such as lane changes, overtakes and turning along curved roads. Motivated by our previous work which shows a 3-10 % increase in energy consumption due to lateral motion when an electric vehicle changes its lane once every kilometer while following standard drive cycles, we incorporate vehicle lateral dynamics in the modeling and control synthesis, which is in contrast with most prior works. In the context of safety, we leverage past data of obstacle motion to construct a future occupancy set with probabilistic guarantees, and formulate robust collision avoidance constraints with respect to such an occupancy set using convex programming duality. Consequently, we formulate a finite-horizon optimal control problem subject to robust collision avoidance constraints while penalizing resulting energy consumption, and solve it in a receding horizon fashion. Finally, we show the effectiveness of the proposed approach in reducing energy consumption and collision avoidance via numerical simulations involving curved roads and multiple obstacles. A detailed analysis of energy consumption along different components of EV motion highlights appreciable improvement under the proposed approach.

Paper number 96:
Title: Data-Adaptive Graph Framelets with Generalized Vanishing Moments for Graph Machine Learning
Authors: Ruigang Zheng, Xiaosheng Zhuang
Abstract: In this paper, we propose a general framework for constructing tight framelet systems on graphs with localized supports based on partition trees. Our construction of framelets provides a simple and efficient way to obtain the orthogonality with $k$ arbitrary orthonormal vectors. When the $k$ vectors contain most of the energy of a family of graph signals, the orthogonality of the framelets intuitively possesses ``generalized ($k$-)vanishing'' moments, and thus, the coefficients are sparse. Moreover, our construction provides not only framelets that are overall sparse vectors but also fast and schematically concise transforms. In a data-adaptive setting, the graph framelet systems can be learned by conducting optimizations on Stiefel manifolds to provide the utmost sparsity for a given family of graph signals. Furthermore, we further exploit the generality of our proposed graph framelet systems for heterophilous graph learning, where graphs are characterized by connecting nodes mainly from different classes. The usual assumption that connected nodes are similar and belong to the same class for homophilious graphs is contradictory for heterophilous graphs. Thus, we are motivated to bypass simple assumptions on heterophilous graphs and focus on generating rich node features induced by the graph structure, so as to improve the graph learning ability of certain neural networks in node classification. We derive a specific system of graph framelets and propose a heuristic method to select framelets as features for neural network input. Several experiments demonstrate the effectiveness and superiority of our approach for non-linear approximation, denoising, and node classification.

Paper number 97:
Title: Fairness-Aware Data Augmentation for Cardiac MRI using Text-Conditioned Diffusion Models
Authors: Grzegorz Skorupko, Richard Osuala, Zuzanna Szafranowska, Kaisar Kushibar, Vien Ngoc Dang, Nay Aung, Steffen E Petersen, Karim Lekadir, Polyxeni Gkontra
Abstract: While deep learning holds great promise for disease diagnosis and prognosis in cardiac magnetic resonance imaging, its progress is often constrained by highly imbalanced and biased training datasets. To address this issue, we propose a method to alleviate imbalances inherent in datasets through the generation of synthetic data based on sensitive attributes such as sex, age, body mass index (BMI), and health condition. We adopt ControlNet based on a denoising diffusion probabilistic model to condition on text assembled from patient metadata and cardiac geometry derived from segmentation masks. We assess our method using a large-cohort study from the UK Biobank by evaluating the realism of the generated images using established quantitative metrics. Furthermore, we conduct a downstream classification task aimed at debiasing a classifier by rectifying imbalances within underrepresented groups through synthetically generated samples. Our experiments demonstrate the effectiveness of the proposed approach in mitigating dataset imbalances, such as the scarcity of diagnosed female patients or individuals with normal BMI level suffering from heart failure. This work represents a major step towards the adoption of synthetic data for the development of fair and generalizable models for medical classification tasks. Notably, we conduct all our experiments using a single, consumer-level GPU to highlight the feasibility of our approach within resource-constrained environments. Our code is available at this https URL.

Paper number 98:
Title: VIBESegmentator: Full Body MRI Segmentation for the NAKO and UK Biobank
Authors: Robert Graf, Paul-S√∂ren Platzek, Evamaria Olga Riedel, Constanze Ramsch√ºtz, Sophie Starck, Hendrik Kristian M√∂ller, Matan Atad, Henry V√∂lzke, Robin B√ºlow, Carsten Oliver Schmidt, Julia R√ºdebusch, Matthias Jung, Marco Reisert, Jakob Weiss, Maximilian L√∂ffler, Fabian Bamberg, Bene Wiestler, Johannes C. Paetzold, Daniel Rueckert, Jan Stefan Kirschke
Abstract: Objectives: To present a publicly available deep learning-based torso segmentation model that provides comprehensive voxel-wise coverage, including delineations that extend to the boundaries of anatomical compartments. Materials and Methods: We extracted preliminary segmentations from TotalSegmentator, spine, and body composition models for Magnetic Resonance Tomography (MR) images, then improved them iteratively and retrained an nnUNet model. Using a random retrospective subset of German National Cohort (NAKO), UK Biobank, internal MR and Computed Tomography (CT) data (Training: 2897 series from 626 subjects, 290 female; mean age 53+-16; 3-fold-cross validation (20% hold-out). Internal testing 36 series from 12 subjects, 6 male; mean age 60+-11), we segmented 71 structures in torso MR and 72 in CT images: 20 organs, 10 muscles, 19 vessels, 16 bones, ribs in CT, intervertebral discs, spinal cord, spinal canal and body composition (subcutaneous fat, unclassified muscles and visceral fat). For external validation, we used existing automatic organ segmentations, independent ground truth segmentations on gradient echo images, and the Amos data. We used non-parametric bootstrapping for confidence intervals and Wilcoxon rank-sum test for computing statistical significance. Results: We achieved an average Dice score of 0.90+-0.06 on our internal gradient echo test set, which included 71 semantic segmentation labels. Our model ties with the best model on Amos with a Dice of 0,81+-0.14, while having a larger field of view and a considerably higher number structures included. Conclusion: Our work presents a publicly available full-torso segmentation model for MRI and CT images that classifies almost all subject voxels to date.

Paper number 99:
Title: Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach
Authors: Alireza Saber, Pouria Parhami, Alimohammad Siahkarzadeh, Mansoor Fateh, Amirreza Fateh
Abstract: Pneumonia, a prevalent respiratory infection, remains a leading cause of morbidity and mortality worldwide, particularly among vulnerable populations. Chest X-rays serve as a primary tool for pneumonia detection; however, variations in imaging conditions and subtle visual indicators complicate consistent interpretation. Automated tools can enhance traditional methods by improving diagnostic reliability and supporting clinical decision-making. In this study, we propose a novel multi-scale transformer approach for pneumonia detection that integrates lung segmentation and classification into a unified framework. Our method introduces a lightweight transformer-enhanced TransUNet for precise lung segmentation, achieving a Dice score of 95.68% on the "Chest X-ray Masks and Labels" dataset with fewer parameters than traditional transformers. For classification, we employ pre-trained ResNet models (ResNet-50 and ResNet-101) to extract multi-scale feature maps, which are then processed through a modified transformer module to enhance pneumonia detection. This integration of multi-scale feature extraction and lightweight transformer modules ensures robust performance, making our method suitable for resource-constrained clinical environments. Our approach achieves 93.75% accuracy on the "Kermany" dataset and 96.04% accuracy on the "Cohen" dataset, outperforming existing methods while maintaining computational efficiency. This work demonstrates the potential of multi-scale transformer architectures to improve pneumonia diagnosis, offering a scalable and accurate solution to global healthcare challenges. this https URL

Paper number 100:
Title: "Iridescent" Reflective Tags to Enable Radar-based Orientation Estimation
Authors: Onel L. A. L√≥pez, Zhu Han, Ashutosh Sabharwal
Abstract: Accurate orientation estimation of objects can aid in scene understanding in many applications. In this paper, we consider use cases where passive tags could be deployed to assist radar systems in estimating object orientation. Towards that end, we propose the concept of passive iridescent reflective tags that selectively reflect different wavelengths in different directions. We propose a conceptual tag design based on leaky-wave antennas. We develop a framework for signal modeling and orientation estimation with a multi-tone radar. We analyze the impact of imperfect tag location information, revealing that it minimally impacts orientation estimation accuracy. To reduce estimator complexity, we propose a radiation pointing angle-based estimator with near-optimal performance. We derive its feasible orientation estimation region and show that it depends mainly on the system bandwidth. Monte Carlo simulations validate our analytical results while evincing that the low-complexity estimator achieves near-optimal accuracy and that its feasible orientation estimation region closely matches that of the other estimators. Finally, we show that the optimal number of tones increases with the sensing time under a power budget constraint, multipath effects may be negligible, signal-to-noise ratio gains rise with the number of tones, and many radar antennas can hurt estimation performance when the signal contains very few tones.

Paper number 101:
Title: NeuroBOLT: Resting-state EEG-to-fMRI Synthesis with Multi-dimensional Feature Mapping
Authors: Yamin Li, Ange Lou, Ziyuan Xu, Shengchao Zhang, Shiyu Wang, Dario J. Englot, Soheil Kolouri, Daniel Moyer, Roza G. Bayrak, Catie Chang
Abstract: Functional magnetic resonance imaging (fMRI) is an indispensable tool in modern neuroscience, providing a non-invasive window into whole-brain dynamics at millimeter-scale spatial resolution. However, fMRI is constrained by issues such as high operation costs and immobility. With the rapid advancements in cross-modality synthesis and brain decoding, the use of deep neural networks has emerged as a promising solution for inferring whole-brain, high-resolution fMRI features directly from electroencephalography (EEG), a more widely accessible and portable neuroimaging modality. Nonetheless, the complex projection from neural activity to fMRI hemodynamic responses and the spatial ambiguity of EEG pose substantial challenges both in modeling and interpretability. Relatively few studies to date have developed approaches for EEG-fMRI translation, and although they have made significant strides, the inference of fMRI signals in a given study has been limited to a small set of brain areas and to a single condition (i.e., either resting-state or a specific task). The capability to predict fMRI signals in other brain areas, as well as to generalize across conditions, remain critical gaps in the field. To tackle these challenges, we introduce a novel and generalizable framework: NeuroBOLT, i.e., Neuro-to-BOLD Transformer, which leverages multi-dimensional representation learning from temporal, spatial, and spectral domains to translate raw EEG data to the corresponding fMRI activity signals across the brain. Our experiments demonstrate that NeuroBOLT effectively reconstructs unseen resting-state fMRI signals from primary sensory, high-level cognitive areas, and deep subcortical brain regions, achieving state-of-the-art accuracy with the potential to generalize across varying conditions and sites, which significantly advances the integration of these two modalities.

Paper number 102:
Title: LS-EEND: Long-Form Streaming End-to-End Neural Diarization with Online Attractor Extraction
Authors: Di Liang, Xiaofei Li
Abstract: This work proposes a frame-wise online/streaming end-to-end neural diarization (EEND) method, which detects speaker activities in a frame-in-frame-out fashion. The proposed model mainly consists of a causal embedding encoder and an online attractor decoder. Speakers are modeled in the self-attention-based decoder along both the time and speaker dimensions, and frame-wise speaker attractors are automatically generated and updated for new speakers and existing speakers, respectively. Retention mechanism is employed and especially adapted for long-form diarization with a linear temporal complexity. A multi-step progressive training strategy is proposed for gradually learning from easy tasks to hard tasks in terms of the number of speakers and audio length. Finally, the proposed model (referred to as long-form streaming EEND, LS-EEND) is able to perform streaming diarization for a high (up to 8) and flexible number speakers and very long (say one hour) audio recordings. Experiments on various simulated and real-world datasets show that: 1) when not using oracle speech activity information, the proposed model achieves new state-of-the-art online diarization error rate on all datasets, including CALLHOME (12.11%), DIHARD II (27.58%), DIHARD III (19.61%), and AMI (20.76%); 2) Due to the frame-in-frame-out processing fashion and the linear temporal complexity, the proposed model achieves several times lower real-time-factor than comparison online diarization models.

Paper number 103:
Title: Line Spectral Analysis Using the G-Filter: An Atomic Norm Minimization Approach
Authors: Bin Zhu, Jiale Tang
Abstract: The area of spectral analysis has a traditional dichotomy between continuous spectra (spectral densities) which correspond to purely nondeterministic processes, and line spectra (Dirac impulses) which represent sinusoids. While the former case is important in the identification of discrete-time linear stochastic systems, the latter case is essential for the analysis and modeling of time series with notable applications in radar systems. In this paper, we develop a novel approach for line spectral estimation which combines ideas of Georgiou's filter banks (G-filters) and atomic norm minimization (ANM), a mainstream method for line spectral analysis in the last decade following the theory of compressed sensing. Such a combination is only possible because a Carath√©odory--Fej√©r-type decomposition is available for the covariance matrix of the filter output. The ANM problem can be characterized via semidefinite programming which can be solved efficiently. As a consequence, our optimization scheme can be seen as a substantial generalization of the standard ANM for line spectral estimation. Moreover, our ANM approach with a G-filter has significant advantages over subspace methods because it can work with just one output vector and without \emph{a priori} knowledge about the number of sinusoids in the input. Simulation results show that our approach performs favorably against the standard ANM, the frequency-selective ANM, and standard subspace methods MUSIC and ESPRIT under a variety of parameter configurations when the G-filter is suitably designed.

Paper number 104:
Title: Near-Optimal Emission-Aware Online Ride Assignment Algorithm for Peak Demand Hours
Authors: Ali Zeynali, Mahsa Sahebdel, Noman Bashir, Ramesh K. Sitaraman, Mohammad Hajiesmaili
Abstract: Ridesharing has experienced significant global growth over the past decade and is becoming an integral component of modern transportation systems. However, despite their benefits, ridesharing platforms face fundamental inefficiencies that contribute to negative environmental impacts. A prominent source of such inefficiency is the deadhead miles. This issue becomes especially severe during high-demand periods, when the volume of ride requests exceeds the available driver supply, leading to suboptimal rider-to-driver assignments, longer deadhead trips, and increased emissions. Although limiting these unproductive miles can reduce emissions, doing so may increase passenger wait times due to limited driver availability, thereby degrading the overall service experience. In this paper, we introduce LARA, an online rider-to-driver assignment algorithm that dynamically adjusts the maximum allowable distance between rider and drivers and assigns ride requests accordingly. While LARA is applicable in general settings, it is particularly effective during peak demand periods, achieving reductions in both emissions and wait times. We provide theoretical guarantees showing that LARA achieves near-optimal performance in online environments, with respect to an optimal offline benchmark. Beside our theoretical analysis, our empirical evaluations on both synthetic and real-world datasets show that LARA achieves up to a 34% reduction in carbon emissions and up to a 50% decrease in rider wait times, compared to state-of-the-art baselines. While prior work has explored emission-aware ride assignment, LARA is, to our knowledge, the first algorithm to offer both rigorous theoretical guarantees and strong empirical performance.

Paper number 105:
Title: Asymptotic Analysis of One-bit Quantized Box-Constrained Precoding in Large-Scale Multi-User Systems
Authors: Xiuxiu Ma, Abla Kammoun, Mohamed-Slim Alouini, Tareq Y. Al-Naffouri
Abstract: This paper addresses the design of multi-antenna precoding strategies, considering hardware limitations such as low-resolution digital-to-analog converters (DACs), which necessitate the quantization of transmitted signals. The typical approach starts with optimizing a precoder, followed by a quantization step to meet hardware requirements. This study analyzes the performance of a quantization scheme applied to the box-constrained regularized zero-forcing (RZF) precoder in the asymptotic regime, where the number of antennas and users grows proportionally. The box constraint, initially designed to cope with low-dynamic range amplifiers, is used here to control quantization noise rather than for amplifier compatibility. A significant challenge in analyzing the quantized precoder is that the input to the quantization operation does not follow a Gaussian distribution, making traditional methods such as Bussgang's decomposition unsuitable. To overcome this, the paper extends the Gordon's inequality and introduces a novel Gaussian Min-Max Theorem to model the distribution of the channel-distorted precoded signal. The analysis derives the tight lower bound for the signal-to-distortion-plus-noise ratio (SDNR) and the bit error rate (BER), showing that optimal tuning of the amplitude constraint improves performance.

Paper number 106:
Title: Multimodal Latent Fusion of ECG Leads for Early Assessment of Pulmonary Hypertension
Authors: Mohammod N. I. Suvon, Shuo Zhou, Prasun C. Tripathi, Wenrui Fan, Samer Alabed, Bishesh Khanal, Venet Osmani, Andrew J. Swift, Chen (Cherise)Chen, Haiping Lu
Abstract: Recent advancements in early assessment of pulmonary hypertension (PH) primarily focus on applying machine learning methods to centralized diagnostic modalities, such as 12-lead electrocardiogram (12L-ECG). Despite their potential, these approaches fall short in decentralized clinical settings, e.g., point-of-care and general practice, where handheld 6-lead ECG (6L-ECG) can offer an alternative but is limited by the scarcity of labeled data for developing reliable models. To address this, we propose a lead-specific electrocardiogram multimodal variational autoencoder (\textsc{LS-EMVAE}), which incorporates a hierarchical modality expert (HiME) fusion mechanism and a latent representation alignment loss. HiME combines mixture-of-experts and product-of-experts to enable flexible, adaptive latent fusion, while the alignment loss improves coherence among lead-specific and shared representations. To alleviate data scarcity and enhance representation learning, we adopt a transfer learning strategy: the model is first pre-trained on a large unlabeled 12L-ECG dataset and then fine-tuned on smaller task-specific labeled 6L-ECG datasets. We validate \textsc{LS-EMVAE} across two retrospective cohorts in a 6L-ECG setting: 892 subjects from the ASPIRE registry for (1) PH detection and (2) phenotyping pre-/post-capillary PH, and 16,416 subjects from UK Biobank for (3) predicting elevated pulmonary atrial wedge pressure, where it consistently outperforms unimodal and multimodal baseline methods and demonstrates strong generalizability and interpretability. The code is available at this https URL.

Paper number 107:
Title: Vanishing Stacked-Residual PINN for State Reconstruction of Hyperbolic Systems
Authors: Katayoun Eshkofti, Matthieu Barreau
Abstract: In a more connected world, modeling multi-agent systems with hyperbolic partial differential equations (PDEs) offers a compact, physics-consistent description of collective dynamics. However, classical control tools need adaptation for these complex systems. Physics-informed neural networks (PINNs) provide a powerful framework to fix this issue by inferring solutions to PDEs by embedding governing equations into the neural network. A major limitation of original PINNs is their inability to capture steep gradients and discontinuities in hyperbolic PDEs. To tackle this problem, we propose a stacked residual PINN method enhanced with a vanishing viscosity mechanism. Initially, a basic PINN with a small viscosity coefficient provides a stable, low-fidelity solution. Residual correction blocks with learnable scaling parameters then iteratively refine this solution, progressively decreasing the viscosity coefficient to transition from parabolic to hyperbolic PDEs. Applying this method to traffic state reconstruction improved results by an order of magnitude in relative $\mathcal{L}^2$ error, demonstrating its potential to accurately estimate solutions where original PINNs struggle with instability and low fidelity.

Paper number 108:
Title: Joint Design of Radar Receive Filter and Unimodular ISAC Waveform with Sidelobe Level Control
Authors: Kecheng Zhang, Ya-Feng Liu, Zhongbin Wang, Weijie Yuan, Musa Furkan Keskin, Henk Wymeersch, Shuqiang Xia
Abstract: Integrated sensing and communication (ISAC) has been considered a key feature of next-generation wireless networks. This paper investigates the joint design of the radar receive filter and dual-functional transmit waveform for the multiple-input multiple-output (MIMO) ISAC system. While optimizing the mean square error (MSE) of the radar receive spatial response and maximizing the achievable rate at the communication receiver, besides the constraints of full-power radar receiving filter and unimodular transmit sequence, we control the maximum range sidelobe level, which is often overlooked in existing ISAC waveform design literature, for better radar imaging performance. To solve the formulated optimization problem with convex and nonconvex constraints, we propose an inexact augmented Lagrangian method (ALM) algorithm. For each subproblem in the proposed inexact ALM algorithm, we custom-design a block successive upper-bound minimization (BSUM) scheme with closed-form solutions for all blocks of variable to enhance the computational efficiency. Convergence analysis shows that the proposed algorithm is guaranteed to provide a stationary and feasible solution. Extensive simulations are performed to investigate the impact of different system parameters on communication and radar imaging performance. Comparison with the existing works shows the superiority of the proposed algorithm.

Paper number 109:
Title: Iterative Decoder of Channel-polarized Multilevel Coding for Data Center Networks
Authors: Takeshi Kakizaki, Masanori Nakamura, Fukutaro Hamaoka, Shuto Yamamoto, Etsushi Yamazaki
Abstract: Data center networks (DCNs) require a low-cost, low-power optical transceiver to handle increased traffic from generative artificial intelligence, video streaming services, and more. Improving the required signal-to-noise ratio (RSNR) by digital signal processing such as forward error correction (FEC) mitigates the requirements for electrical and optical components. The optical transceivers in DCNs exploit a low-complexity soft-decision (SD) FEC, consisting of short block-length linear error-correcting codes and a low-complexity SD decoder (SDD), such as Chase decoding and ordered statistics decoding. The low-complexity SDD efficiently approaches a maximum likelihood decoding (MLD). However, the decoding performance of MLD is limited by its finite block length. In this paper, we describe the details of our proposed channel-polarized multilevel coding with iterative decoding (CP-MLC-ID). The proposed CP-MLC-ID improves the decoding performance by extending the codeword length to weakly and indirectly connect codewords via bypassed bits. The 19.5%-OH CP-MLC-ID using 128-bit extended Bose-Chaudhuri-Hocquenghem (eBCH) and KP4 codes outperforms the concatenated eBCH and KP4 codes with a net coding gain of 0.25 and 0.40 dB for the same and double the number of SDDs, respectively. We also investigate the dependency of the decoding performance on the size of a bit interleaver. The performance degradation of CP-MLC-ID using an 8-bit interleaver is about 0.1 dB compared to using the large-bit interleaver. Our results indicate that even a weak connection by exclusive-OR between codewords improves the decoding performance, compared to simple concatenated codes in the DCNs.

Paper number 110:
Title: Data-driven Distributionally Robust Control Based on Sinkhorn Ambiguity Sets
Authors: Riccardo Cescon, Andrea Martin, Giancarlo Ferrari-Trecate
Abstract: As the complexity of modern control systems increases, it becomes challenging to derive an accurate model of the uncertainty that affects their dynamics. Wasserstein Distributionally Robust Optimization (DRO) provides a powerful framework for decision-making under distributional uncertainty only using noise samples. However, while the resulting policies inherit strong probabilistic guarantees when the number of samples is sufficiently high, their performance may significantly degrade when only a few data are available. Inspired by recent results from the machine learning community, we introduce an entropic regularization to penalize deviations from a given reference distribution and study data-driven DR control over Sinkhorn ambiguity sets. We show that for finite-horizon control problems, the optimal DR linear policy can be computed via convex programming. By analyzing the relation between the ambiguity set defined in terms of Wasserstein and Sinkhorn discrepancies, we reveal that, as the regularization parameter increases, this optimal policy interpolates between the solution of the Wasserstein DR problem and that of the stochastic problem under the reference distribution. We validate our theoretical findings and the effectiveness of our approach when only scarce data are available on a numerical example.

Paper number 111:
Title: Community-Centric Multi-Criteria Assessment Framework for Energy Transition
Authors: Jayashree Yadav, Ingemar Mathiasson, Bindu Panikkar, Mads Almassalkhi
Abstract: The transition to low-carbon energy systems demands comprehensive technical, economic, environmental, and social evaluation tools. While numerous studies address specific aspects of energy transition, few provide an integrated framework to capture the full spectrum of impacts. This work developed a community-collaborative assessment framework that integrates intelligent energy devices with optimization-based coordination of energy assets. The proposed framework uses techno-economic, environmental, and social criteria to evaluate transition pathways. A detailed case study is performed for a remote community in Alaska to assess its applicability, where the feasibility of renewable energy transitions remains underexplored. Three distinct pathways, including heat pump and battery integration, resource coordination, and expanded community solar PV, are analyzed using a year-long dataset of demand, renewable energy, and transformer data. The analysis revealed that using heat pumps lowers the overall energy costs by 30% and carbon emissions by 28%. In addition, the share of the population spending more than 10% of their income on energy falls from 74% in the existing scenario to 40% with heat pump adoption, indicating significant affordability improvements. By combining a general, community-centric assessment framework with a data-driven case study, this work offers a practical tool for utilities, community stakeholders, and policymakers to work toward equitable and sustainable energy transitions.

Paper number 112:
Title: Universal Approximation with XL MIMO Systems: OTA Classification via Trainable Analog Combining
Authors: Kyriakos Stylianopoulos, George C. Alexandropoulos
Abstract: In this paper, we show that an eXtremely Large (XL) Multiple-Input Multiple-Output (MIMO) wireless system with appropriate analog combining components exhibits the properties of a universal function approximator, similar to a feedforward neural network. By treating the channel coefficients as the random nodes of a hidden layer and the receiver's analog combiner as a trainable output layer, we cast the XL MIMO system to the Extreme Learning Machine (ELM) framework, leading to a novel formulation for Over-The-Air (OTA) edge inference without requiring traditional digital processing nor pre-processing at the transmitter. Through theoretical analysis and numerical evaluation, we showcase that XL-MIMO-ELM enables near-instantaneous training and efficient classification, even in varying fading conditions, suggesting the paradigm shift of beyond massive MIMO systems as OTA artificial neural networks alongside their profound communications role. Compared to deep learning approaches and conventional ELMs, the proposed framework achieves on par performance with orders of magnitude lower complexity, making it highly attractive for inference tasks with ultra low power wireless devices.

Paper number 113:
Title: Gaussian behaviors: representations and data-driven control
Authors: Andr√°s Sasfi, Ivan Markovsky, Alberto Padoan, Florian D√∂rfler
Abstract: We propose a modeling framework for stochastic systems, termed Gaussian behaviors, that describes finite-length trajectories of a system as a Gaussian process. The proposed model naturally quantifies the uncertainty in the trajectories, yet it is simple enough to allow for tractable formulations. We relate the proposed model to existing descriptions of dynamical systems including deterministic and stochastic behaviors, and linear time-invariant (LTI) state-space models with Gaussian noise. Gaussian behaviors can be estimated directly from observed data as the empirical sample covariance. The distribution of future outputs conditioned on inputs and past outputs provides a predictive model that can be incorporated in predictive control frameworks. We show that subspace predictive control is a certainty-equivalence control formulation with the estimated Gaussian behavior. Furthermore, the regularized data-enabled predictive control (DeePC) method is shown to be a distributionally optimistic formulation that optimistically accounts for uncertainty in the Gaussian behavior. To mitigate the excessive optimism of DeePC, we propose a novel distributionally robust control formulation, and provide a convex reformulation allowing for efficient implementation.

Paper number 114:
Title: UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning
Authors: Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch
Abstract: Accurate mobile device localization is critical for emerging 5G/6G applications such as autonomous vehicles and augmented reality. In this paper, we propose a unified localization method that integrates model-based and machine learning (ML)-based methods to reap their respective advantages by exploiting available map information. In order to avoid supervised learning, we generate training labels automatically via optimal transport (OT) by fusing geometric estimates with building layouts. Ray-tracing based simulations are carried out to demonstrate that the proposed method significantly improves positioning accuracy for both line-of-sight (LoS) users (compared to ML-based methods) and non-line-of-sight (NLoS) users (compared to model-based methods). Remarkably, the unified method is able to achieve competitive overall performance with the fully-supervised fingerprinting, while eliminating the need for cumbersome labeled data measurement and collection.

Paper number 115:
Title: Contactless pulse rate assessment: Results and insights for application in driving simulator
Authors: ƒêorƒëe D. Ne≈°koviƒá, Kristina Stojmenova Peƒçeƒçnik, Jaka Sodnik, Nadica Miljkoviƒá
Abstract: Remote photoplethysmography (rPPG) offers a promising solution for non-contact driver monitoring by detecting subtle blood flow-induced facial color changes from video. However, motion artifacts in dynamic driving environments remain key challenges. This study presents an rPPG framework that combines signal processing techniques before and after applying Eulerian Video Magnification (EVM) for pulse rate (PR) estimation in driving simulators. While not novel, the approach offers insights into the efficiency of the EVM method and its time complexity. We compare results of the proposed rPPG approach against reference Empatica E4 data and also compare it with existing achievements from the literature. Additionally, the possible bias of the Empatica E4 is further assessed using an independent dataset with both the Empatica E4 and the Faros 360 measurements. EVM slightly improves PR estimation, reducing the mean absolute error (MAE) from 6.48 bpm to 5.04 bpm (the lowest MAE (~2 bpm) was achieved under strict conditions) with an additional time required for EVM of about 20 s for 30 s sequence. Furthermore, statistically significant differences are identified between younger and older drivers in both reference and rPPG data. Our findings demonstrate the feasibility of using rPPG-based PR monitoring, encouraging further research in driving simulations.

Paper number 116:
Title: Potential Contrast: Properties, Equivalences, and Generalization to Multiple Classes
Authors: Wallace Peaslee, Anna Breger, Carola-Bibiane Sch√∂nlieb
Abstract: Potential contrast is typically used as an image quality measure and quantifies the maximal possible contrast between samples from two classes of pixels in an image after an arbitrary grayscale transformation. It has been applied in cultural heritage to evaluate multispectral images using a small number of labeled pixels. In this work, we introduce a normalized version of potential contrast that removes dependence on image format and also prove equalities that enable generalization to more than two classes and to continuous settings. Finally, we exemplify the utility of multi-class normalized potential contrast through an application to a medieval music manuscript with visible bleedthrough from the back of the page. We share our implementations, based on both original algorithms and our new equalities, including generalization to multiple classes, at this https URL.

Paper number 117:
Title: Content Generation Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges
Authors: Yuan Zhang, Xinfeng Zhang, Xiaoming Qi, Xinyu Wu, Feng Chen, Guanyu Yang, Huazhu Fu
Abstract: Content generation modeling has emerged as a promising direction in computational pathology, offering capabilities such as data-efficient learning, synthetic data augmentation, and task-oriented generation across diverse diagnostic tasks. This review provides a comprehensive synthesis of recent progress in the field, organized into four key domains: image generation, text generation, molecular profile-morphology generation, and other specialized generation applications. By analyzing over 150 representative studies, we trace the evolution of content generation architectures -- from early generative adversarial networks to recent advances in diffusion models and generative vision-language models. We further examine the datasets and evaluation protocols commonly used in this domain and highlight ongoing limitations, including challenges in generating high-fidelity whole slide images, clinical interpretability, and concerns related to the ethical and legal implications of synthetic data. The review concludes with a discussion of open challenges and prospective research directions, with an emphasis on developing integrated and clinically deployable generation systems. This work aims to provide a foundational reference for researchers and practitioners developing content generation models in computational pathology.

Paper number 118:
Title: SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline
Authors: Helin Wang, Jiarui Hai, Dongchao Yang, Chen Chen, Kai Li, Junyi Peng, Thomas Thebaud, Laureano Moro Velazquez, Jesus Villalba, Najim Dehak
Abstract: Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high perceptual quality, these models often introduce unwanted artifacts, reduce naturalness, and are sensitive to discrepancies between training and testing environments. On the other hand, generative models for TSE lag in perceptual quality and intelligibility. To address these challenges, we present SoloSpeech, a novel cascaded generative pipeline that integrates compression, extraction, reconstruction, and correction processes. SoloSpeech features a speaker-embedding-free target extractor that utilizes conditional information from the cue audio's latent space, aligning it with the mixture audio's latent space to prevent mismatches. Evaluated on the widely-used Libri2Mix dataset, SoloSpeech achieves the new state-of-the-art intelligibility and quality in target speech extraction while demonstrating exceptional generalization on out-of-domain data and real-world scenarios.

Paper number 119:
Title: Multi-output Classification using a Cross-talk Architecture for Compound Fault Diagnosis of Motors in Partially Labeled Condition
Authors: Wonjun Yi, Wonho Jung, Hyeonuk Nam, Kangmin Jang, Yong-Hwa Park
Abstract: The increasing complexity of rotating machinery and the diversity of operating conditions, such as rotating speed and varying torques, have amplified the challenges in fault diagnosis in scenarios requiring domain adaptation, particularly involving compound faults. This study addresses these challenges by introducing a novel multi-output classification (MOC) framework tailored for domain adaptation in partially labeled target datasets. Unlike conventional multi-class classification (MCC) approaches, the MOC framework classifies the severity levels of compound faults simultaneously. Furthermore, we explore various single-task and multi-task architectures applicable to the MOC formulation-including shared trunk and cross-talk-based designs-for compound fault diagnosis under partially labeled conditions. Based on this investigation, we propose a novel cross-talk architecture, residual neural dimension reductor (RNDR), that enables selective information sharing across diagnostic tasks, effectively enhancing classification performance in compound fault scenarios. In addition, frequency-layer normalization was incorporated to improve domain adaptation performance on motor vibration data. Compound fault conditions were implemented using a motor-based test setup and evaluated across six domain adaptation scenarios. The experimental results demonstrate its superior macro F1 performance compared to baseline models. We further showed that the structural advantage of RNDR is more pronounced in compound fault settings through a single-fault comparison. We also found that frequency-layer normalization fits the fault diagnosis task better than conventional methods. Lastly, we analyzed the RNDR with various conditions, other models with increased number of parameters, and compared with the ablated RNDR structure.

Paper number 120:
Title: Simultaneous Segmentation of Ventricles and Normal/Abnormal White Matter Hyperintensities in Clinical MRI using Deep Learning
Authors: Mahdi Bashiri Bawil, Mousa Shamsi, Abolhassan Shakeri Bavil
Abstract: Multiple sclerosis (MS) diagnosis and monitoring rely heavily on accurate assessment of brain MRI biomarkers, particularly white matter hyperintensities (WMHs) and ventricular changes. Current segmentation approaches suffer from several limitations: they typically segment these structures independently despite their pathophysiological relationship, struggle to differentiate between normal and pathological hyperintensities, and are poorly optimized for anisotropic clinical MRI data. We propose a novel 2D pix2pix-based deep learning framework for simultaneous segmentation of ventricles and WMHs with the unique capability to distinguish between normal periventricular hyperintensities and pathological MS lesions. Our method was developed and validated on FLAIR MRI scans from 300 MS patients. Compared to established methods (SynthSeg, Atlas Matching, BIANCA, LST-LPA, LST-LGA, and WMH-SynthSeg), our approach achieved superior performance for both ventricle segmentation (Dice: 0.801+/-0.025, HD95: 18.46+/-7.1mm) and WMH segmentation (Dice: 0.624+/-0.061, precision: 0.755+/-0.161). Furthermore, our method successfully differentiated between normal and abnormal hyperintensities with a Dice coefficient of 0.647. Notably, our approach demonstrated exceptional computational efficiency, completing end-to-end processing in approximately 4 seconds per case, up to 36 times faster than baseline methods, while maintaining minimal resource requirements. This combination of improved accuracy, clinically relevant differentiation capability, and computational efficiency addresses critical limitations in current neuroimaging analysis, potentially enabling integration into routine clinical workflows and enhancing MS diagnosis and monitoring.

Paper number 121:
Title: PRO: Projection Domain Synthesis for CT Imaging
Authors: Kang Chen, Bin Huang, Xuebin Yang, Junyan Zhang, Yongbo Wang, Qiegen Liu
Abstract: Synthetic CT projection data is crucial for advancing imaging research, yet its generation remains challenging. Current image domain methods are limited as they cannot simulate the physical acquisition process or utilize the complete statistical information present in projection data, restricting their utility and fidelity. In this work, we present PRO, a projection domain synthesis foundation model for CT imaging. To the best of our knowledge, this is the first study that performs CT synthesis in the projection domain. Unlike previous approaches that operate in the image domain, PRO learns rich structural representations from projection data and leverages anatomical text prompts for controllable synthesis. Projection data generation models can utilize complete measurement signals and simulate the physical processes of scanning, including material attenuation characteristics, beam hardening, scattering, and projection geometry, and support research on downstream imaging tasks. Moreover, PRO functions as a foundation model, capable of generalizing across diverse downstream tasks by adjusting its generative behavior via prompt inputs. Experimental results demonstrated that incorporating our synthesized data significantly improves performance across multiple downstream tasks, including low-dose and sparse-view reconstruction. These findings underscore the versatility and scalability of PRO in data generation for various CT applications. These results highlight the potential of projection domain synthesis as a powerful tool for data augmentation and robust CT imaging. Our source code is publicly available at: this https URL.

Paper number 122:
Title: Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems
Authors: Anders Hansson, Jo√£o Victor Galv√£o da Mata, Martin S. Andersen
Abstract: In this paper we investigate identifiability and maximum likelihood estimation for direct system identification of networks of dynamical systems. We provide necessary and sufficient conditions for network identifiability in terms of Gr√∂bner bases. We show that the maximum likelihood approach is both consistent and efficient, which is in contrast to existing prediction error approaches. Moreover, our approach has wider applicability, i.e., it is applicable whenever network identifiability holds. Finally, we show that we can formulate the maximum likelihood problem without the use of a predictor, which is the key to numerically being able to solve it efficiently.

Paper number 123:
Title: Revisiting Z Transform Laplace Inversion: To Correct flaws in Signal and System Theory
Authors: Yuxin Yang, Hang Zhou, Chaojie Li, Xin Li, Yingyi Yan, Mingyang Zheng
Abstract: This paper revisits the classical formulation of the Z-transform and its relationship to the inverse Laplace transform (L-1), originally developed by Ragazzini in sampled-data theory. It identifies a longstanding mathematical oversight in standard derivations, which typically neglect the contribution from the infinite arc in the complex plane during inverse Laplace evaluation. This omission leads to inconsistencies, especially at discontinuities such as t = 0. By incorporating the full Bromwich contour, including all boundary contributions, we restore internal consistency between L-1 and the Z-transform, aligning the corrected L-1 with results from Discrete-Time Fourier Transform (DTFT) aliasing theory. Consequently, this necessitates a structural revision of the Z-transform, inverse Laplace transform, and the behavior of the Heaviside step function at discontinuities, providing a more accurate foundation for modeling and analysis of sampled-data systems.

Paper number 124:
Title: An Efficient Detector for Faulty GNSS Measurements Detection With Non-Gaussian Noises
Authors: Penggao Yan, Baoshan Song, Xiao Xia, Weisong Wen, Li-Ta Hsu
Abstract: Fault detection is crucial to ensure the reliability of navigation systems. However, mainstream fault detection methods are developed based on Gaussian assumptions on nominal errors, while current attempts at non-Gaussian fault detection are either heuristic or lack rigorous statistical properties. The performance and reliability of these methods are challenged in real-world applications. This paper proposes the jackknife detector, a fault detection method tailored for linearized pseudorange-based positioning systems under non-Gaussian nominal errors. Specifically, by leveraging the jackknife technique, a test statistic is derived as a linear combination of measurement errors, eliminating the need for restrictive distributional assumptions while maintaining computational efficiency. A hypothesis test with the Bonferroni correction is then constructed to detect potential faults in measurements. Theoretical analysis proves the equivalence between the jackknife detector and the solution separation (SS) detector, while revealing the former's superior computational efficiency. Through a worldwide simulation and a real-world satellite clock anomaly detection experiment--both involving non-Gaussian nominal errors--the proposed jackknife detector demonstrates equivalent detection performance to the SS detector but achieves a fourfold improvement in computational efficiency. These results highlight the jackknife detector's substantial potential for real-time applications requiring robust and efficient fault detection in non-Gaussian noise environments.

Paper number 125:
Title: Robust Bandwidth Estimation for Real-Time Communication with Offline Reinforcement Learning
Authors: Jian Kai, Tianwei Zhang, Zihan Ling, Yang Cao, Can Shen
Abstract: Accurate bandwidth estimation (BWE) is critical for real-time communication (RTC) systems. Traditional heuristic approaches offer limited adaptability under dynamic networks, while online reinforcement learning (RL) suffers from high exploration costs and potential service disruptions. Offline RL, which leverages high-quality data collected from real-world environments, offers a promising alternative. However, challenges such as out-of-distribution (OOD) actions, policy extraction from behaviorally diverse datasets, and reliable deployment in production systems remain unsolved. We propose RBWE, a robust bandwidth estimation framework based on offline RL that integrates Q-ensemble (an ensemble of Q-functions) with a Gaussian mixture policy to mitigate OOD risks and enhance policy learning. A fallback mechanism ensures deployment stability by switching to heuristic methods under high uncertainty. Experimental results show that RBWE reduces overestimation errors by 18% and improves the 10th percentile Quality of Experience (QoE) by 18.6%, demonstrating its practical effectiveness in real-world RTC applications. The implementation is publicly available at this https URL.

Paper number 126:
Title: Grid impedance estimation based Kalman Filter
Authors: Phuoc Sang Nguyen, Ghavameddin Nourbakhsh, Gerard Ledwich
Abstract: Modern power systems face new operational hurdles due to the increasing adoption of inverter-coupled distributed energy resources, which impact system stability and control. Central to these challenges is the dynamic nature of grid impedance. To address this, a novel real-time estimation algorithm based on the Discrete Fourier Transform is proposed. This algorithm is embedded within an Advanced Angle Estimation Kalman Filter framework that employs a Linear Quadratic Regulator for current control (AAEKF-LQR). The impedance data directly informs and refines the controller's phase angle estimation. Simulation analyses demonstrate robust collaboration between the estimator and controller, sustaining system stability under weak grid conditions. The technique proves capable of delivering swift and accurate impedance updates during grid variations, which is crucial for maintaining stable inverter operation

Paper number 127:
Title: Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study
Authors: Yuqing Shen, Yuanyuan Shi, Daniel Kirschen, Yize Chen
Abstract: Power systems decarbonization are at the focal point of the clean energy transition. While system operators and utility companies increasingly publicize system-level carbon emission information, it remains unclear how emissions from individual generators are transported through the grid and how they impact electricity users at specific locations. This paper presents a novel and computationally efficient approach for exact quantification of nodal average and marginal carbon emission rates, applicable to both AC and DC optimal power flow problems. The approach leverages graph-based topological sorting and directed cycle removal techniques, applied to directed graphs formed by generation dispatch and optimal power flow solutions. Our proposed algorithm efficiently identifies each generator's contribution to each node, capturing how emissions are spatially distributed under varying system conditions. To validate its effectiveness and reveal locational and temporal emission patterns in the real world, we simulate the 8,870-bus realistic California grid using actual CAISO data and the CATS model. Based on year long hourly data on nodal loads and renewable generation, obtained or estimated from CAISO public data, our method accurately estimates power flow conditions, generation mixes, and systemwide emissions, and delivers fine grained spatiotemporal emission analysis for every California county. Both our algorithm and the California study are open-sourced, providing a foundation for future research on grid emissions, planning, operations, and energy policy.

Paper number 128:
Title: Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder
Authors: Biagio Brattoli, Jack Shi, Jongchan Park, Taebum Lee, Donggeun Yoo, Sergio Pereira
Abstract: Identifying actionable driver mutations in non-small cell lung cancer (NSCLC) can impact treatment decisions and significantly improve patient outcomes. Despite guideline recommendations, broader adoption of genetic testing remains challenging due to limited availability and lengthy turnaround times. Machine Learning (ML) methods for Computational Pathology (CPath) offer a potential solution; however, research often focuses on only one or two common mutations, limiting the clinical value of these tools and the pool of patients who can benefit from them. This study evaluates various Multiple Instance Learning (MIL) techniques to detect six key actionable NSCLC driver mutations: ALK, BRAF, EGFR, ERBB2, KRAS, and MET ex14. Additionally, we introduce an Asymmetric Transformer Decoder model that employs queries and key-values of varying dimensions to maintain a low query dimensionality. This approach efficiently extracts information from patch embeddings and minimizes overfitting risks, proving highly adaptable to the MIL setting. Moreover, we present a method to directly utilize tissue type in the model, addressing a typical MIL limitation where either all regions or only some specific regions are analyzed, neglecting biological relevance. Our method outperforms top MIL models by an average of 3%, and over 4% when predicting rare mutations such as ERBB2 and BRAF, moving ML-based tests closer to being practical alternatives to standard genetic testing.

Paper number 129:
Title: Digital Twin Channel-Aided CSI Prediction: An Environment-Based Subspace Extraction Approach for Achieving Low Overhead and High Robustness
Authors: Yichen Cai, Jianhua Zhang, Li Yu, Zhen Zhang, Yuxiang Zhang, Lianzheng Shi, Yuelong Qiu, Yong Zeng
Abstract: To meet the robust and high-speed communication requirements of the sixth-generation (6G) mobile communication system in complex scenarios, sensing- and artificial intelligence (AI)-based digital twin channel (DTC) techniques become a promising approach to reduce system overhead. In this paper, we propose an environment-specific channel subspace basis (ECB)-aided partial-to-whole channel state information (CSI) prediction method (ECB-P2WCP) for realizing DTC-enabled low-overhead channel prediction. Specifically, we introduce a wireless environment knowledge (WEK) construction method that extracts ECB from the digital twin environment via subspace estimation. This ECB characterizes the static statistical properties of the electromagnetic environment and serves as environment information prior to the prediction task. Then, we fuse ECB with real-time estimated local CSI to predict the entire spatial-frequency domain channel for both the present and future time instances. Hence, an ECB-based partial-to-whole CSI prediction network (ECB-P2WNet) is designed to achieve a robust channel prediction scheme in various complex scenarios. Simulation results indicate that incorporating ECB provides significant benefits under low signal-to-noise ratio and pilot ratio conditions, achieving a reduction of up to 50\% in pilot overhead. Additionally, the proposed method maintains robustness against multi-user interference, tolerating 3-meter localization errors with only a 0.5 dB normalized mean square error increase, and predicts CSI for the next channel coherent time within 1.3 milliseconds.

Paper number 130:
Title: Joint Transmit and Pinching Beamforming Design for Pinching Antenna-assisted Symbiotic Radio
Authors: Ze Wang, Guoping Zhang, Hongbo Xu, Ming Zeng, Ana Garc√≠a Armada, Fang Fang, Dusit Niyato
Abstract: This paper investigates a novel downlink symbiotic radio framework enabled by the pinching antenna system (PASS), designed to enhance both primary and secondary transmissions through reconfigurable antenna positioning. This reconfigurability introduces additional degrees of freedom for adaptive pinching beamforming, thereby enabling constructive signal enhancement and interference suppression tailored to the locations of the backscatter device, the Internet of Things (IoT) receiver, and the primary receivers. To fully exploit these benefits, we formulate a joint transmit and pinching beamforming optimization problem that maximizes the achievable sum rate while satisfying the IoT receiver's detection error probability constraint and feasible deployment constraints for the pinching antennas. The resulting problem is inherently nonconvex and highly coupled. To address this challenge, we develop two complementary solution approaches. The first is a learning-aided gradient descent method, where the constrained optimization is reformulated into a differentiable form and solved through end-to-end learning. In this approach, the pinching antenna position matrix is reparameterized to automatically satisfy minimum spacing constraints, while transmit power and waveguide length limits are enforced via projection and normalization. The second approach is an optimization-based successive convex approximation-particle swarm optimization method, which first determines the transmit beamforming solution using successive convex approximation and subsequently optimizes pinching beamforming via a particle swarm optimization search over candidate pinching antenna placements.

Paper number 131:
Title: Understanding the Fundamental Trade-Off Between Age of Information and Throughput in Unreliable Wireless Networks
Authors: Lin Wang, I-Hong Hou
Abstract: This paper characterizes the fundamental trade-off between throughput and Age of Information (AoI) in wireless networks where multiple devices transmit status updates to a central base station over unreliable channels. To address the complexity introduced by stochastic transmission successes, we propose the throughput-AoI capacity region, which defines all feasible throughput-AoI pairs achievable under any scheduling policy. Using a second-order approximation that incorporates both mean and temporal variance, we derive an outer bound and a tight inner bound for the throughput-AoI capacity region. Furthermore, we propose a simple and low complexity scheduling policy and prove that it achieves every interior point within the tight inner bound. This establishes a systematic and theoretically grounded framework for the joint optimization of throughput and information freshness in practical wireless communication scenarios. To validate our theoretical framework and demonstrate the utility of the throughput-AoI capacity region, extensive simulations are implemented. Simulation results demonstrate that our proposed policy significantly outperforms conventional methods across various practical network optimization scenarios. The findings highlight our approach's effectiveness in optimizing both throughput and AoI, underscoring its applicability and robustness in practical wireless networks.

Paper number 132:
Title: Hessian-Based Lightweight Neural Network HessNet for State-of-the-Art Brain Vessel Segmentation on a Minimal Training Dataset
Authors: Alexandra Bernadotte, Elfimov Nikita, Mikhail Shutov, Ivan Menshikov
Abstract: Accurate segmentation of blood vessels in brain magnetic resonance angiography (MRA) is essential for successful surgical procedures, such as aneurysm repair or bypass surgery. Currently, annotation is primarily performed through manual segmentation or classical methods, such as the Frangi filter, which often lack sufficient accuracy. Neural networks have emerged as powerful tools for medical image segmentation, but their development depends on well-annotated training datasets. However, there is a notable lack of publicly available MRA datasets with detailed brain vessel annotations. To address this gap, we propose a novel semi-supervised learning lightweight neural network with Hessian matrices on board for 3D segmentation of complex structures such as tubular structures, which we named HessNet. The solution is a Hessian-based neural network with only 6000 parameters. HessNet can run on the CPU and significantly reduces the resource requirements for training neural networks. The accuracy of vessel segmentation on a minimal training dataset reaches state-of-the-art results. It helps us create a large, semi-manually annotated brain vessel dataset of brain MRA images based on the IXI dataset (annotated 200 images). Annotation was performed by three experts under the supervision of three neurovascular surgeons after applying HessNet. It provides high accuracy of vessel segmentation and allows experts to focus only on the most complex important cases. The dataset is available at this https URL.

Paper number 133:
Title: Learn2Reg 2024: New Benchmark Datasets Driving Progress on New Challenges
Authors: Lasse Hansen, Wiebke Heyer, Christoph Gro√übr√∂hmer, Frederic Madesta, Thilo Sentker, Wang Jiazheng, Yuxi Zhang, Hang Zhang, Min Liu, Junyi Wang, Xi Zhu, Yuhua Li, Liwen Wang, Daniil Morozov, Nazim Haouchine, Joel Honkamaa, Pekka Marttinen, Yichao Zhou, Zuopeng Tan, Zhuoyuan Wang, Yi Wang, Hongchao Zhou, Shunbo Hu, Yi Zhang, Qian Tao, Lukas F√∂rner, Thomas Wendler, Bailiang Jian, Christian Wachinger, Jin Kim, Dan Ruan, Marek Wodzinski, Henning M√ºller, Tony C.W. Mok, Xi Jia, Jinming Duan, Mikael Brudfors, Seyed-Ahmad Ahmadi, Yunzheng Zhu, William Hsu, Tina Kapur, William M. Wells, Alexandra Golby, Aaron Carass, Harrison Bai, Yihao Liu, Perrine Paul-Gilloteaux, Joakim Lindblad, Nata≈°a Sladoje, Andreas Walter, Junyu Chen, Reuben Dorent, Alessa Hering, Mattias P. Heinrich
Abstract: Medical image registration is critical for clinical applications, and fair benchmarking of different methods is essential for monitoring ongoing progress. To date, the Learn2Reg 2020-2023 challenges have released several complementary datasets and established metrics for evaluations. However, these editions did not capture all aspects of the registration problem, particularly in terms of modality diversity and task complexity. To address these limitations, the 2024 edition introduces three new tasks, including large-scale multi-modal registration and unsupervised inter-subject brain registration, as well as the first microscopy-focused benchmark within Learn2Reg. The new datasets also inspired new method developments, including invertibility constraints, pyramid features, keypoints alignment and instance optimisation.

Paper number 134:
Title: YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform
Authors: Po-Heng Chou, Wei-Lung Mao, Ru-Ping Lin
Abstract: This letter proposes a YOLO-based framework for spatial bearing fault diagnosis using time-frequency spectrograms derived from continuous wavelet transform (CWT). One-dimensional vibration signals are first transformed into time-frequency spectrograms using Morlet wavelets to capture transient fault signatures. These spectrograms are then processed by YOLOv9, v10, and v11 models to classify fault types. Evaluated on three benchmark datasets, including Case Western Reserve University (CWRU), Paderborn University (PU), and Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline achieves significantly higher accuracy and generalizability than the baseline MCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8% (PU), and 99.5% (IMS). In addition, its region-aware detection mechanism enables direct visualization of fault locations in spectrograms, offering a practical solution for condition monitoring in rotating machinery.

Paper number 135:
Title: Cutoff Rate Bounds and Constellation Shaping under Mixed Gaussian-Impulsive Noise
Authors: Tianfu Qi, Jun Wang
Abstract: Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN), appears in numerous communication scenarios and can severely degrade system performance. In this paper, we optimize the transmitted constellation under mixed noise based on a theoretical analysis of the cutoff rate (CR). First, starting from the passband model of the mixed noise, we derive its corresponding baseband representation. Then, the baseband model is employed to obtain closed-form lower and upper bounds of the CR. A piecewise linear approximation is applied to derive efficient bounds by exploiting the algebraic properties of the integral terms. These bounds are then used as criteria to optimize the transmitted constellation points in both geometric positions and probabilistic distributions. The projected gradient method is employed to solve the optimization problem, and the convergence and properties of the solutions are analyzed. Numerical results demonstrate that the proposed CR bounds are tight and exhibit the expected asymptotic behavior. Furthermore, the optimized constellation scheme achieves a significant rate improvement compared to baselines.

Paper number 136:
Title: On the Effect of Sampling-Time Jitter
Authors: Dieter Schwarzmann, Simon K√§ser
Abstract: This brief, aimed at practitioners, offers an analysis of the effect of sampling-time jitter, i. e., the error produced by execution-time inaccuracies. We propose reinterpreting jitter-afflicted linear time-invariant systems through equivalent jitter-free analogs. By constructing a perceived system that absorbs the effects of timing perturbations into its dynamics, we find an affine scaling of jitter. We examine both measurement and implementation scenarios, demonstrating that the presence of jitter effectively scales the system matrices. Moreover, we observe that, in the Laplace domain, jitter can be interpreted as a frequency scaling.

Paper number 137:
Title: Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification
Authors: Rudi Coppola, Hovsep Touloujian, Pierfrancesco Ombrini, Manuel Mazo Jr
Abstract: Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of modern technology. In the last decades, the production and design of such batteries and their adjacent embedded charging and safety protocols, denoted by Battery Management Systems (BMS), has taken central stage. A fundamental challenge to be addressed is the trade-off between the speed of charging and the ageing behavior, resulting in the loss of capacity in the battery cell. We rely on a high-fidelity physics-based battery model and propose an approach to data-driven charging and safety protocol design. Following a Counterexample-Guided Inductive Synthesis scheme, we combine Reinforcement Learning (RL) with recent developments in data-driven formal methods to obtain a hybrid control strategy: RL is used to synthesise the individual controllers, and a data-driven abstraction guides their partitioning into a switched structure, depending on the initial output measurements of the battery. The resulting discrete selection among RL-based controllers, coupled with the continuous battery dynamics, realises a hybrid system. When a design meets the desired criteria, the abstraction provides probabilistic guarantees on the closed-loop performance of the cell.

Paper number 138:
Title: AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations
Authors: Shuhan Ding, Jingjing Fu, Yu Gu, Naiteek Sangani, Mu Wei, Paul Vozila, Nan Liu, Jiang Bian, Hoifung Poon
Abstract: Medical image synthesis has become an essential strategy for augmenting datasets and improving model generalization in data-scarce clinical settings. However, fine-grained and controllable synthesis remains difficult due to limited high-quality annotations and domain shifts across datasets. Existing methods, often designed for natural images or well-defined tumors, struggle to generalize to chest radiographs, where disease patterns are morphologically diverse and tightly intertwined with anatomical structures. To address these challenges, we propose AURAD, a controllable radiology synthesis framework that jointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike prior approaches that rely on randomly sampled masks-limiting diversity, controllability, and clinical relevance-our method learns to generate masks that capture multi-pathology coexistence and anatomical-pathological consistency. It follows a progressive pipeline: pseudo masks are first generated from clinical prompts conditioned on anatomical structures, and then used to guide image synthesis. We also leverage pretrained expert medical models to filter outputs and ensure clinical plausibility. Beyond visual realism, the synthesized masks also serve as labels for downstream tasks such as detection and segmentation, bridging the gap between generative modeling and real-world clinical applications. Extensive experiments and blinded radiologist evaluations demonstrate the effectiveness and generalizability of our method across tasks and datasets. In particular, 78% of our synthesized images are classified as authentic by board-certified radiologists, and over 40% of predicted segmentation overlays are rated as clinically useful. All code, pre-trained models, and the synthesized dataset will be released upon publication.

Paper number 139:
Title: Categorical semantics of compositional reinforcement learning
Authors: Georgios Bakirtzis, Michail Savvas, Ufuk Topcu
Abstract: Compositional knowledge representations in reinforcement learning (RL) facilitate modular, interpretable, and safe task specifications. However, generating compositional models requires the characterization of minimal assumptions for the robustness of the compositionality feature, especially in the case of functional decompositions. Using a categorical point of view, we develop a knowledge representation framework for a compositional theory of RL. Our approach relies on the theoretical study of the category MDP, whose objects are Markov decision processes (MDPs) acting as models of tasks. The categorical semantics models the compositionality of tasks through the application of pushout operations akin to combining puzzle pieces. As a practical application of these pushout operations, we introduce zig-zag diagrams that rely on the compositional guarantees engendered by the category MDP. We further prove that properties of the category MDP unify concepts, such as enforcing safety requirements and exploiting symmetries, generalizing previous abstraction theories for RL.

Paper number 140:
Title: ADIR: Adaptive Diffusion for Image Reconstruction
Authors: Shady Abu-Hussein, Tom Tirer, Raja Giryes
Abstract: Denoising diffusion models have recently achieved remarkable success in image generation, capturing rich information about natural image statistics. This makes them highly promising for image reconstruction, where the goal is to recover a clean image from a degraded observation. In this work, we introduce a conditional sampling framework that leverages the powerful priors learned by diffusion models while enforcing consistency with the available measurements. To further adapt pre-trained diffusion models to the specific degradation at hand, we propose a novel fine-tuning strategy. In particular, we employ LoRA-based adaptation using images that are semantically and visually similar to the degraded input, efficiently retrieved from a large and diverse dataset via an off-the-shelf vision-language model. We evaluate our approach on two leading publicly available diffusion models--Stable Diffusion and Guided Diffusion--and demonstrate that our method, termed Adaptive Diffusion for Image Reconstruction (ADIR), yields substantial improvements across a range of image reconstruction tasks.

Paper number 141:
Title: Offline Learning of Decision Functions in Multiplayer Games with Expectation Constraints
Authors: Yuanhanqing Huang, Jianghai Hu
Abstract: We explore a class of stochastic multiplayer games where each player in the game aims to optimize its objective under uncertainty and adheres to some expectation constraints. The study employs an offline learning paradigm, leveraging a pre-existing dataset containing auxiliary features. While prior research in deterministic and stochastic multiplayer games primarily explored vector-valued decisions, this work departs by considering function-valued decisions that incorporate auxiliary features as input. We leverage the law of large deviations and degree theory to establish the almost sure convergence of the offline learning solution to the true solution as the number of data samples increases.

Paper number 142:
Title: A Hypergraph Approach to Distributed Broadcast
Authors: Qi Cao, Yulin Shao, Fan Yang, Octavia A. Dobre
Abstract: This paper explores the distributed broadcast problem within the context of network communications, a critical challenge in decentralized information dissemination. We put forth a novel hypergraph-based approach to address this issue, focusing on minimizing the number of broadcasts to ensure comprehensive data sharing among all network users. The key contributions of this work include the establishment of a general lower bound for the problem using the min-cut capacity of hypergraphs, and a distributed broadcast for quasi-trees (DBQT) algorithm tailored for the unique structure of quasi-trees, which is proven to be optimal. This paper advances both network communication strategies and hypergraph theory, with implications for a wide range of real-world applications, from vehicular and sensor networks to distributed storage systems.

Paper number 143:
Title: Linearly Controlled Language Generation with Performative Guarantees
Authors: Emily Cheng, Carmen Amo Alonso
Abstract: The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM's latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model's hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. In particular, we propose to directly intervene the activations of the token that is being generated in embedding space in an online fashion. Crucially, we do not simply steer activations towards a desirable region. Instead, our method relies on classical techniques from control theory to precisely control activations in a context-dependent way, and guarantees that they are brought into a specific pre-defined region of embedding space that corresponds to allowed semantics. Our intervention is computed in closed-form according to an optimal controller formulation, minimally impacting generation time. This control of the activations in embedding space allows for fine-grained steering of attributes of the generated sequence. We demonstrate the effectiveness of our approach on different objectives-- toxicity avoidance and sentiment control-- while maintaining text quality.

Paper number 144:
Title: Quantitative Group Testing and Pooled Data in the Linear Regime with Sublinear Tests
Authors: Nelvin Tan, Pablo Pascual Cobo, Ramji Venkataramanan
Abstract: In the pooled data problem, the goal is to identify the categories associated with a large collection of items via a sequence of pooled tests. Each pooled test reveals the number of items in the pool belonging to each category. A prominent special case is quantitative group testing (QGT), which is the case of pooled data with two categories. We consider these problems in the non-adaptive and linear regime, where the fraction of items in each category is of constant order. We propose a scheme with a spatially coupled Bernoulli test matrix and an efficient approximate message passing (AMP) algorithm for recovery. We rigorously characterize its asymptotic performance in both the noiseless and noisy settings, and prove that in the noiseless case, the AMP algorithm achieves almost-exact recovery with a number of tests sublinear in the total number of items $p$. Although there exist other efficient schemes for noiseless QGT and pooled data that achieve recovery with order-optimal sample complexity ($\Theta(\frac{p}{\log p})$ tests), there are no guarantees on their performance in the presence of noise, even at low noise-levels. In comparison, our scheme achieves recovery in the noiseless case with a number of tests sublinear in $p$, and its performance degrades gracefully in the presence of noise. Numerical simulations illustrate the benefits of the spatially coupled scheme at finite dimensions, showing that it outperforms i.i.d. test designs as well as other recovery algorithms based on convex programming.

Paper number 145:
Title: Confirmation Bias in Gaussian Mixture Models
Authors: Amnon Balanov, Tamir Bendory, Wasim Huleihel
Abstract: Confirmation bias, the tendency to interpret information in a way that aligns with one's preconceptions, can profoundly impact scientific research, leading to conclusions that reflect the researcher's hypotheses even when the observational data do not support them. This issue is especially critical in scientific fields involving highly noisy observations, such as cryo-electron microscopy. This study investigates confirmation bias in Gaussian mixture models. We consider the following experiment: A team of scientists assumes they are analyzing data drawn from a Gaussian mixture model with known signals (hypotheses) as centroids. However, in reality, the observations consist entirely of noise without any informative structure. The researchers use a single iteration of the K-means or expectation-maximization algorithms, two popular algorithms to estimate the centroids. Despite the observations being pure noise, we show that these algorithms yield biased estimates that resemble the initial hypotheses, contradicting the unbiased expectation that averaging these noise observations would converge to zero. Namely, the algorithms generate estimates that mirror the postulated model, although the hypotheses (the presumed centroids of the Gaussian mixture) are not evident in the observations. Specifically, among other results, we prove a positive correlation between the estimates produced by the algorithms and the corresponding hypotheses. We also derive explicit closed-form expressions of the estimates for a finite and infinite number of hypotheses. This study underscores the risks of confirmation bias in low signal-to-noise environments, provides insights into potential pitfalls in scientific methodologies, and highlights the importance of prudent data interpretation.

Paper number 146:
Title: AARK: An Open Toolkit for Autonomous Racing Research
Authors: James Bockman, Matthew Howe, Adrian Orenstein, Feras Dayoub
Abstract: Autonomous racing demands safe control of vehicles at their physical limits for extended periods of time, providing insights into advanced vehicle safety systems which increasingly rely on intervention provided by vehicle autonomy. Participation in this field carries with it a high barrier to entry. Physical platforms and their associated sensor suites require large capital outlays before any demonstrable progress can be made. Simulators allow researches to develop soft autonomous systems without purchasing a platform. However, currently available simulators lack visual and dynamic fidelity, can still be expensive to buy, lack customisation, and are difficult to use. AARK provides three packages, ACI, ACDG, and ACMPC. These packages enable research into autonomous control systems in the demanding environment of racing to bring more people into the field and improve reproducibility: ACI provides researchers with a computer vision-friendly interface to Assetto Corsa for convenient comparison and evaluation of autonomous control solutions; ACDG enables generation of depth, normal and semantic segmentation data for training computer vision models to use in perception systems; and ACMPC gives newcomers to the field a modular full-stack autonomous control solution, capable of controlling vehicles to build from. AARK aims to unify and democratise research into a field critical to providing safer roads and trusted autonomous systems.

Paper number 147:
Title: Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks
Authors: Han Ji, Xiping Wu, Zhihong Zeng, Chen Chen
Abstract: Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a promising paradigm of heterogeneous network (HetNet), attributed to the complementary physical properties of optical spectra and radio frequency. However, the current development of such HetNets is mostly bottlenecked by the existing transmission control protocol (TCP), which restricts the user equipment (UE) to connecting one access point (AP) at a time. While the ongoing investigation on multipath TCP (MPTCP) can bring significant benefits, it complicates the network topology of HetNets, making the existing load balancing (LB) learning models less effective. Driven by this, we propose a graph neural network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets, which results in a partial mesh topology. Such a topology can be modeled as a graph, with the channel state information and data rate requirement embedded as node features, while the LB solutions are deemed as edge labels. Compared to the conventional deep neural network (DNN), the proposed GNN-based model exhibits two key strengths: i) it can better interpret a complex network topology; and ii) it can handle various numbers of APs and UEs with a single trained model. Simulation results show that against the traditional optimisation method, the proposed learning model can achieve near-optimal throughput within a gap of 11.5%, while reducing the inference time by 4 orders of magnitude. In contrast to the DNN model, the new method can improve the network throughput by up to 21.7%, at a similar inference time level.

Paper number 148:
Title: Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks
Authors: Cyrus Neary, Nathan Tsao, Ufuk Topcu
Abstract: We develop compositional learning algorithms for coupled dynamical systems, with a particular focus on electrical networks. While deep learning has proven effective at modeling complex relationships from data, compositional couplings between system components typically introduce algebraic constraints on state variables, posing challenges to many existing data-driven approaches to modeling dynamical systems. Towards developing deep learning models for constrained dynamical systems, we introduce neural port-Hamiltonian differential algebraic equations (N-PHDAEs), which use neural networks to parameterize unknown terms in both the differential and algebraic components of a port-Hamiltonian DAE. To train these models, we propose an algorithm that uses automatic differentiation to perform index reduction, automatically transforming the neural DAE into an equivalent system of neural ordinary differential equations (N-ODEs), for which established model inference and backpropagation methods exist. Experiments simulating the dynamics of nonlinear circuits exemplify the benefits of our approach: the proposed N-PHDAE model achieves an order of magnitude improvement in prediction accuracy and constraint satisfaction when compared to a baseline N-ODE over long prediction time horizons. We also validate the compositional capabilities of our approach through experiments on a simulated DC microgrid: we train individual N-PHDAE models for separate grid components, before coupling them to accurately predict the behavior of larger-scale networks.

Paper number 149:
Title: Spatial exponential decay of perturbations in optimal control of general evolution equations
Authors: Simone G√∂ttlich, Benedikt Oppeneiger, Manuel Schaller, Karl Worthmann
Abstract: We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. We extend this result to the case of a space-dependent transport velocity. Finally we leverage the results for the transport equation to characterize domain-uniform stabilizability of the wave equation. Numerical examples in one space dimension complement the theoretical results.

Paper number 150:
Title: Synthetic data enables context-aware bioacoustic sound event detection
Authors: Benjamin Hoffman, David Robinson, Marius Miron, Vittorio Baglione, Daniela Canestrari, Damian Elias, Eva Trapote, Felix Effenberger, Maddie Cusimano, Masato Hagiwara, Olivier Pietquin
Abstract: We propose a methodology for training foundation models that enhances their in-context learning capabilities within the domain of bioacoustic signal processing. We use synthetically generated training data, introducing a domain-randomization-based pipeline that constructs diverse acoustic scenes with temporally strong labels. We generate over 8.8 thousand hours of strongly-labeled audio and train a query-by-example, transformer-based model to perform few-shot bioacoustic sound event detection. Our second contribution is a public benchmark of 13 diverse few-shot bioacoustics tasks. Our model outperforms previously published methods, and improves relative to other training-free methods by $64\%$. We demonstrate that this is due to increase in model size and data scale, as well as algorithmic improvements. We make our trained model available via an API, to provide ecologists and ethologists with a training-free tool for bioacoustic sound event detection.

Paper number 151:
Title: Robust detection of overlapping bioacoustic sound events
Authors: Louis Mahon, Benjamin Hoffman, Logan James, Maddie Cusimano, Masato Hagiwara, Sarah C Woolley, Felix Effenberger, Sara Keen, Jen-Yu Liu, Olivier Pietquin
Abstract: We propose a method for accurately detecting bioacoustic sound events that is robust to overlapping events, a common issue in domains such as ethology, ecology and conservation. While standard methods employ a frame-based, multi-label approach, we introduce an onset-based detection method which we name Voxaboxen. It takes inspiration from object detection methods in computer vision, but simultaneously takes advantage of recent advances in self-supervised audio encoders. For each time window, Voxaboxen predicts whether it contains the start of a vocalization and how long the vocalization is. It also does the same in reverse, predicting whether each window contains the end of a vocalization, and how long ago it started. The two resulting sets of bounding boxes are then fused using a graph-matching algorithm. We also release a new dataset designed to measure performance on detecting overlapping vocalizations. This consists of recordings of zebra finches annotated with temporally-strong labels and showing frequent overlaps. We test Voxaboxen on seven existing data sets and on our new data set. We compare Voxaboxen to natural baselines and existing sound event detection methods and demonstrate SotA results. Further experiments show that improvements are robust to frequent vocalization overlap.

Paper number 152:
Title: Exploiting Multistage Optimization Structure in Proximal Solvers
Authors: Roland Schwan, Daniel Kuhn, Colin N. Jones
Abstract: This paper presents an efficient structure-exploiting algorithm for multistage optimization problems. The proposed method extends existing approaches by supporting full coupling between stages and global decision variables in the cost, as well as equality and inequality constraints. The algorithm is implemented as a new backend in the PIQP solver and leverages a specialized block-tri-diagonal-arrow Cholesky factorization within a proximal interior-point framework to handle the underlying problem structure efficiently. The implementation features automatic structure detection and seamless integration with existing interfaces. Numerical experiments demonstrate significant performance improvements, achieving up to 13x speed-up compared to a generic sparse backend and matching/exceeding the performance of the state-of-the-art specialized solver HPIPM. The solver is particularly effective for applications such as model predictive control, robust scenario optimization, and periodic optimization problems.

Paper number 153:
Title: Modeling, Observability, and Inertial Parameter Estimation of a Planar Multi-Link System with Thrusters
Authors: Nicholas B. Andrews, Kristi A. Morgansen
Abstract: This research provides a theoretical foundation for modeling and real-time estimation of both the pose and inertial parameters of a free-floating multi-link system with link thrusters, which are essential for safe and effective controller design and performance. First, we adapt a planar nonlinear multi-link snake robot model to represent a planar chain of bioinspired salp robots by removing joint actuators, introducing link thrusters, and allowing for non-uniform link lengths, masses, and moments of inertia. Second, we conduct a nonlinear observability analysis of the multi-link system with link thrusters, proving that the link angles, angular velocities, masses, and moments of inertia are locally observable when equipped with inertial measurement units and operating under specific thruster conditions. The analytical results are demonstrated in simulation with a three-link system.

Paper number 154:
Title: Robust Feedback Optimization with Model Uncertainty: A Regularization Approach
Authors: Winnie Chan, Zhiyu He, Keith Moffat, Saverio Bolognani, Michael Muehlebach, Florian D√∂rfler
Abstract: Feedback optimization optimizes the steady state of a dynamical system by implementing optimization iterations in closed loop with the plant. It relies on online measurements and limited model information, namely, the input-output sensitivity. In practice, various issues including inaccurate modeling, lack of observation, or changing conditions can lead to sensitivity mismatches, causing closed-loop sub-optimality or even instability. To handle such uncertainties, we pursue robust feedback optimization, where we optimize the closed-loop performance against all possible sensitivities lying in specific uncertainty sets. We provide tractable reformulations for the corresponding min-max problems via regularizations and characterize the online closed-loop performance through the tracking error in case of time-varying optimal solutions. Simulations on a distribution grid illustrate the effectiveness of our robust feedback optimization controller in addressing sensitivity mismatches in a non-stationary environment.

Paper number 155:
Title: The Ground Cost for Optimal Transport of Angular Velocity
Authors: Karthik Elamvazhuthi, Abhishek Halder
Abstract: We revisit the optimal transport problem over angular velocity dynamics given by the controlled Euler equation. The solution of this problem enables stochastic guidance of spin states of a rigid body (e.g., spacecraft) over a hard deadline constraint by transferring a given initial state statistics to a desired terminal state statistics. This is an instance of generalized optimal transport over a nonlinear dynamical system. While prior work has reported existence-uniqueness and numerical solution of this dynamical optimal transport problem, here we present structural results about the equivalent Kantorovich a.k.a. optimal coupling formulation. Specifically, we focus on deriving the ground cost for the associated Kantorovich optimal coupling formulation. The ground cost is equal to the cost of transporting unit amount of mass from a specific realization of the initial or source joint probability measure to a realization of the terminal or target joint probability measure, and determines the Kantorovich formulation. Finding the ground cost leads to solving a structured deterministic nonlinear optimal control problem, which is shown to be amenable to an analysis technique pioneered by Athans et al. We show that such techniques have broader applicability in determining the ground cost (thus Kantorovich formulation) for a class of generalized optimal mass transport problems involving nonlinear dynamics with translated norm-invariant drift.

Paper number 156:
Title: Stability of Polling Systems for a Large Class of Markovian Switching Policies
Authors: Konstantin Avrachenkov, Kousik Das, Veeraruna Kavitha, Vartika Singh
Abstract: We consider a polling system with two queues, where a single server is attending the queues in a cyclic order and requires non-zero switching times to switch between the queues. Our aim is to identify a fairly general and comprehensive class of Markovian switching policies that renders the system stable. Potentially a class of policies that can cover the Pareto frontier related to individual-queue-centric performance measures like the stationary expected number of waiting customers in each queue; for instance, such a class of policies is identified recently for a polling system near the fluid regime (with large arrival and departure rates), and we aim to include that class. We also aim to include a second class that facilitates switching between the queues at the instance the occupancy in the opposite queue crosses a threshold and when that in the visiting queue is below a threshold (this inclusion facilitates design of `robust' polling systems). Towards this, we consider a class of two-phase switching policies, which includes the above mentioned classes. In the maximum generality, our policies can be represented by eight parameters, while two parameters are sufficient to represent the aforementioned classes. We provide simple conditions to identify the sub-class of switching policies that ensure system stability. By numerically tuning the parameters of the proposed class, we illustrate that the proposed class can cover the Pareto frontier for the stationary expected number of customers in the two queues.

Paper number 157:
Title: Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond
Authors: Fenghao Zhu, Xinquan Wang, Siming Jiang, Xinyi Li, Maojun Zhang, Yixuan Chen, Chongwen Huang, Zhaohui Yang, Xiaoming Chen, Zhaoyang Zhang, Richeng Jin, Yongming Huang, Wei Feng, Tingting Yang, Baoming Bai, Feifei Gao, Kun Yang, Yuanwei Liu, Sami Muhaidat, Chau Yuen, Kaibin Huang, Kai-Kit Wong, Dusit Niyato, Ying-Chang Liang, M√©rouane Debbah
Abstract: The emergence of sixth-generation and beyond communication systems is expected to fundamentally transform digital experiences through introducing unparalleled levels of intelligence, efficiency, and connectivity. A promising technology poised to enable this revolutionary vision is the wireless large AI model (WLAM), characterized by its exceptional capabilities in data processing, inference, and decision-making. In light of these remarkable capabilities, this paper provides a comprehensive survey of WLAM, elucidating its fundamental principles, diverse applications, critical challenges, and future research opportunities. We begin by introducing the background of WLAM and analyzing the key synergies with wireless networks, emphasizing the mutual benefits. Subsequently, we explore the foundational characteristics of WLAM, delving into their unique relevance in wireless environments. Then, the role of WLAM in optimizing wireless communication systems across various use cases and the reciprocal benefits are systematically investigated. Furthermore, we discuss the integration of WLAM with emerging technologies, highlighting their potential to enable transformative capabilities and breakthroughs in wireless communication. Finally, we thoroughly examine the high-level challenges hindering the practical implementation of WLAM and discuss pivotal future research directions.

Paper number 158:
Title: ComplexVCoder: An LLM-Driven Framework for Systematic Generation of Complex Verilog Code
Authors: Jian Zuo, Junzhe Liu, Xianyong Wang, Yicheng Liu, Navya Goli, Tong Xu, Hao Zhang, Umamaheswara Rao Tida, Zhenge Jia, Mengying Zhao
Abstract: Recent advances have demonstrated the promising capabilities of large language models (LLMs) in generating register-transfer level (RTL) code, such as Verilog. However, existing LLM-based frameworks still face significant challenges in accurately handling the complexity of real-world RTL designs, particularly those that are large-scale and involve multi-level module instantiations. To address this issue, we present ComplexVCoder, an open-source LLM-driven framework that enhances both the generation quality and efficiency of complex Verilog code. Specifically, we introduce a two-stage generation mechanism, which leverages an intermediate representation to enable a more accurate and structured transition from natural language descriptions to intricate Verilog designs. In addition, we introduce a rule-based alignment method and a domain-specific retrieval-augmented generation (RAG) to further improve the correctness of the synthesized code by incorporating relevant design knowledge during generation. To evaluate our approach, we construct a comprehensive dataset comprising 55 complex Verilog designs derived from real-world implementations. We also release an open-source benchmark suite for systematically assessing the quality of auto-generated RTL code together with the ComplexVCoder framework. Experimental results show that ComplexVCoder outperforms SOTA frameworks such as CodeV and RTLCoder by 14.6% and 22.2%, respectively, in terms of function correctness on complex Verilog benchmarks. Furthermore, ComplexVcoder achieves comparable generation performances in terms of functionality correctness using a lightweight 32B model (Qwen2.5), rivaling larger-scale models such as GPT-3.5 and DeepSeek-V3.

Paper number 159:
Title: Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model
Authors: David Grasev
Abstract: Gas turbine engines are complex and highly nonlinear dynamical systems. Deriving their physics-based models can be challenging because it requires performance characteristics that are not always available, often leading to many simplifying assumptions. This paper discusses the limitations of conventional experimental methods used to derive component-level and locally linear parameter-varying models, and addresses these issues by employing identification techniques based on data collected from standard engine operation under closed-loop control. The rotor dynamics are estimated using the sparse identification of nonlinear dynamics. Subsequently, the autonomous part of the dynamics is mapped into an optimally constructed Koopman eigenfunction space. This process involves eigenvalue optimization using metaheuristic algorithms and temporal projection, followed by gradient-based eigenfunction identification. The resulting Koopman model is validated against an in-house reference component-level model. A globally optimal nonlinear feedback controller and a Kalman estimator are then designed within the eigenfunction space and compared to traditional and gain-scheduled proportional-integral controllers, as well as a proposed internal model control approach. The eigenmode structure enables targeting individual modes during optimization, leading to improved performance tuning. Results demonstrate that the Koopman-based controller surpasses other benchmark controllers in both reference tracking and disturbance rejection under sea-level and varying flight conditions, due to its global nature.

Paper number 160:
Title: Base Station Placement Optimization for Networked Sensing Exploiting Target Location Distribution
Authors: Kaiyue Hou, Shuowen Zhang
Abstract: This paper studies a networked sensing system with multiple base stations (BSs), which collaboratively sense the unknown and random three-dimensional (3D) location of a target based on the target-reflected echo signals received at the BSs. Considering a practical scenario where the target location distribution is known a priori for exploitation, we aim to design the placement of the multiple BSs to optimize the networked sensing performance. Firstly, we characterize the posterior Cram√©r-Rao bound (PCRB) of the mean-squared error (MSE) in sensing the target's 3D location. Despite its complex form under networked sensing, we derive its closed-form expression in terms of the BS locations. Next, we formulate the BS placement optimization problem to minimize the sensing PCRB, which is non-convex and difficult to solve. By leveraging a series of equivalent transformations and the iterative inner approximation method, we devise an algorithm with polynomial-time complexity which is guaranteed to converge to a solution satisfying the Karush-Kuhn Tucker (KKT) conditions of the problem. Numerical results show that the proposed placement design significantly outperforms various benchmark designs.

Paper number 161:
Title: Direct Pseudospectral Optimal Control by Orthogonal Polynomial Integral Collocation
Authors: Thomas L. Ahrens, Ian M. Down, Manoranjan Majji
Abstract: This paper details a methodology to transcribe an optimal control problem into a nonlinear program for generation of the trajectories that optimize a given functional by approximating only the highest order derivatives of a given system's dynamics. The underlying method uses orthogonal polynomial integral collocation by which successive integrals are taken to approximate all lower order states. Hence, one set of polynomial coefficients can represent an entire coordinate's degree of freedom. Specifically, Chebyshev polynomials of the first and second kind and Legendre polynomials are used over their associated common interpolating grids derived from the bases' roots and extrema. Simple example problems compare different polynomial bases' performance to analytical solutions. The planar circular orbit raising problem is used to verify the method with solutions obtained by other pseudospectral methods in literature. Finally, a rocket landing flip maneuver problem is solved to demonstrate the ability to solve complex problems with multiple states and control variables with constraints. Simulations establish this method's performance, and reveal that the polynomial/node choice for a given problem notably affects the performance.

Paper number 162:
Title: Bipedal Balance Control with Whole-body Musculoskeletal Standing and Falling Simulations
Authors: Chengtian Ma, Yunyue Wei, Chenhui Zuo, Chen Zhang, Yanan Sui
Abstract: Balance control is important for human and bipedal robotic systems. While dynamic balance during locomotion has received considerable attention, quantitative understanding of static balance and falling remains limited. This work presents a hierarchical control pipeline for simulating human balance via a comprehensive whole-body musculoskeletal system. We identified spatiotemporal dynamics of balancing during stable standing, revealed the impact of muscle injury on balancing behavior, and generated fall contact patterns that aligned with clinical data. Furthermore, our simulated hip exoskeleton assistance demonstrated improvement in balance maintenance and reduced muscle effort under perturbation. This work offers unique muscle-level insights into human balance dynamics that are challenging to capture experimentally. It could provide a foundation for developing targeted interventions for individuals with balance impairments and support the advancement of humanoid robotic systems.

Paper number 163:
Title: A Contemporary Survey on Fluid Antenna Systems: Fundamentals and Networking Perspectives
Authors: Hanjiang Hong, Kai-Kit Wong, Hao Xu, Xinghao Guo, Farshad Rostami Ghadi, Yu Chen, Yin Xu, Chan-Byoung Chae, Baiyang Liu, Kin-Fai Tong, Yangyang Zhang
Abstract: The explosive growth of teletraffic, fueled by the convergence of cyber-physical systems and data-intensive applications, such as the Internet of Things (IoT), autonomous systems, and immersive communications, demands a multidisciplinary suite of innovative solutions across the physical and network layers. Fluid antenna systems (FAS) represent a transformative advancement in antenna design, offering enhanced spatial degrees of freedom through dynamic reconfigurability. By exploiting spatial flexibility, FAS can adapt to varying channel conditions and optimize wireless performance, making it a highly promising candidate for next-generation communication networks. This paper provides a comprehensive survey of the state of the art in FAS research. We begin by examining key application scenarios in which FAS offers significant advantages. We then present the fundamental principles of FAS, covering channel measurement and modeling, single-user configurations, and the multi-user fluid antenna multiple access (FAMA) framework. Following this, we delve into key network-layer techniques such as quality-of-service (QoS) provisioning, power allocation, and content placement strategies. We conclude by identifying prevailing challenges and outlining future research directions to support the continued development of FAS in next-generation wireless networks.

Paper number 164:
Title: Ontology Neural Network and ORTSF: A Framework for Topological Reasoning and Delay-Robust Control
Authors: Jaehong Oh
Abstract: The advancement of autonomous robotic systems has led to impressive capabilities in perception, localization, mapping, and control. Yet, a fundamental gap remains: existing frameworks excel at geometric reasoning and dynamic stability but fall short in representing and preserving relational semantics, contextual reasoning, and cognitive transparency essential for collaboration in dynamic, human-centric environments. This paper introduces a unified architecture comprising the Ontology Neural Network (ONN) and the Ontological Real-Time Semantic Fabric (ORTSF) to address this gap. The ONN formalizes relational semantic reasoning as a dynamic topological process. By embedding Forman-Ricci curvature, persistent homology, and semantic tensor structures within a unified loss formulation, ONN ensures that relational integrity and topological coherence are preserved as scenes evolve over time. The ORTSF transforms reasoning traces into actionable control commands while compensating for system delays. It integrates predictive and delay-aware operators that ensure phase margin preservation and continuity of control signals, even under significant latency conditions. Empirical studies demonstrate the ONN + ORTSF framework's ability to unify semantic cognition and robust control, providing a mathematically principled and practically viable solution for cognitive robotics.

Paper number 165:
Title: Soft Robotics-Inspired Flexible Antenna Arrays
Authors: Elio Faddoul, Andreas Nicolaides, Konstantinos Ntougias, Ioannis Krikidis
Abstract: In this work, a novel soft continuum robot-inspired antenna array is proposed, featuring tentacle-like structures with multiple antenna elements. The proposed array achieves reconfigurability through continuous deformation of its geometry, in contrast to reconfigurable antennas which incur a per-element control. More specifically, the deformation is modeled by amplitude and spatial frequency parameters. We consider a multi-user multiple-input single-output downlink system, whereby the optimal deformation parameters are found to maximize the sum rate in the network. A successive convex approximation method is adopted to solve the problem. Numerical results show that the proposed deformable array significantly outperforms fixed geometry and per-element reconfigurable arrays in sum rate, demonstrating the benefits of structure-level flexibility for next-generation antenna arrays.

Paper number 166:
Title: Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression
Authors: Zheng Jie Wong, Bingquan Shen
Abstract: Currently, Automatic Speech Recognition (ASR) models are deployed in an extensive range of applications. However, recent studies have demonstrated the possibility of adversarial attack on these models which could potentially suppress or disrupt model output. We investigate and verify the robustness of these attacks and explore if it is possible to increase their imperceptibility. We additionally find that by relaxing the optimisation objective from complete suppression to partial suppression, we can further decrease the imperceptibility of the attack. We also explore possible defences against these attacks and show a low-pass filter defence could potentially serve as an effective defence.

Paper number 167:
Title: Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models
Authors: Haoyu Wang, Guangyan Zhang, Jiale Chen, Jingyu Li, Yuehai Wang, Yiwen Guo
Abstract: With the development of speech large language models (speech LLMs), users can now interact directly with assistants via speech. However, most existing models only convert response content into speech without fully capturing the rich emotional cues in user queries, where the same sentence may convey different meanings depending on the expression. Emotional understanding is thus essential for improving human-machine interaction. Most empathetic speech LLMs rely on massive datasets, demanding high computational cost. A key challenge is to build models that generate empathetic responses with limited data and without large-scale training. To this end, we propose Emotion Omni, a model that understands emotional content in user speech and generates empathetic responses. We further developed a data pipeline to construct a 200k emotional dialogue dataset supporting empathetic speech assistants. Experiments show that Emotion Omni achieves comparable instruction-following ability without large-scale pretraining, while surpassing existing models in speech quality (UTMOS:4.41) and empathy (Emotion GPT Score: 3.97). These results confirm its improvements in both speech fidelity and emotional expressiveness. Demos are available at this https URL.

Paper number 168:
Title: QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning
Authors: Yinuo Wang, Gavin Tao
Abstract: We address vision-guided quadruped motion control with reinforcement learning (RL) and highlight the necessity of combining proprioception with vision for robust control. We propose QuadKAN, a spline-parameterized cross-modal policy instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates a spline encoder for proprioception and a spline fusion head for proprioception-vision inputs. This structured function class aligns the state-to-action mapping with the piecewise-smooth nature of gait, improving sample efficiency, reducing action jitter and energy consumption, and providing interpretable posture-action sensitivities. We adopt Multi-Modal Delay Randomization (MMDR) and perform end-to-end training with Proximal Policy Optimization (PPO). Evaluations across diverse terrains, including both even and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate that QuadKAN achieves consistently higher returns, greater distances, and fewer collisions than state-of-the-art (SOTA) baselines. These results show that spline-parameterized policies offer a simple, effective, and interpretable alternative for robust vision-guided locomotion. A repository will be made available upon acceptance.

Paper number 169:
Title: A QoS Framework for Service Provision in Multi-Infrastructure-Sharing Networks
Authors: Quang Minh Nguyen, Eytan Modiano
Abstract: We propose a framework for resource provisioning with QoS guarantees in shared infrastructure networks. Our novel framework provides tunable probabilistic service guarantees for throughput and delay. Key to our approach is a Modified Dirft-plus-Penalty (MDP) policy that ensures long-term stability while capturing short-term probabilistic service guarantees using linearized upper-confidence bounds. We characterize the feasible region of service guarantees and show that our MDP procedure achieves mean rate stability and an optimality gap that vanishes with the frame size over which service guarantees are provided. Finally, empirical simulations validate our theory and demonstrate the favorable performance of our algorithm in handling QoS in multi-infrastructure networks.

Paper number 170:
Title: Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built from a Five Bar Linkage
Authors: Yash Vyas, Matteo Bottin
Abstract: A force balanced manipulator design based on the closed chain planar five bar linkage is developed and experimentally validated. We present 2 variants as a modular design: Forbal-2, a planar 2-DOF manipulator, and its extension to 5-DOF spatial motion called Forbal-5. The design considerations in terms of geometric, kinematic, and dynamic design that fulfill the force balance conditions while maximizing workspace are discussed. Then, the inverse kinematics of both variants are derived from geometric principles. We validate the improvements from force balancing the manipulator through comparative experiments with counter mass balanced and unbalanced configurations. The results show how the balanced configuration yields a reduction in the average reaction moments of up to 66%, a reduction of average joint torques of up to 79%, as well as a noticeable reduction in position error for Forbal-2. For Forbal-5, which has a higher end effector payload mass, the joint torques are reduced up to 84% for the balanced configuration. Experimental results validate that the balanced manipulator design is suitable for applications where the reduction of joint torques and reaction forces/moments helps achieve millimeter level precision.

Paper number 171:
Title: CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals
Authors: Wenhui Cui, Christopher Sandino, Hadi Pouransari, Ran Liu, Juri Minxha, Ellen Zippi, Aman Verma, Anna Sedlackova, Erdrin Azemi, Behrooz Mahasseni
Abstract: Hand gesture classification using high-quality structured data such as videos, images, and hand skeletons is a well-explored problem in computer vision. Leveraging low-power, cost-effective biosignals, e.g. surface electromyography (sEMG), allows for continuous gesture prediction on wearables. In this paper, we demonstrate that learning representations from weak-modality data that are aligned with those from structured, high-quality data can improve representation quality and enables zero-shot classification. Specifically, we propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and pose representations, where we learn an EMG encoder that produces high-quality and pose-informative representations. We assess the gesture classification performance of our model through linear probing and zero-shot setups. Our model outperforms emg2pose benchmark models by up to 21% on in-distribution gesture classification and 72% on unseen (out-of-distribution) gesture classification.

Paper number 172:
Title: Optimal Damping for the 1D Wave Equation Using a Single Damper
Authors: Petar Mlinariƒá, Serkan Gugercin, Zoran Tomljanoviƒá
Abstract: Vibrational structures are susceptible to catastrophic failures or structural damages when external forces induce resonances or repeated unwanted oscillations. One common mitigation strategy is to use dampers to suppress these disturbances. This leads to the problem of finding optimal damper viscosities and positions for a given vibrational structure. Although extensive research exists for the case of finite-dimensional systems, optimizing damper positions remains challenging due to its discrete nature. To overcome this, we introduce a novel model for the damped wave equation (at the PDE level) with a damper of viscosity $\mathfrak{g}$ at position $\mathfrak{p}$ and develop a system-theoretic input/output-based analysis in the frequency domain. In this system-theoretic formulation, while we consider average displacement as the output, for input (forcing), we analyze two separate cases, namely, the uniform and boundary forcing. For both cases, explicit formulas are derived for the corresponding transfer functions, parametrized by $\mathfrak{p}$ and $\mathfrak{g}$. This explicit parametrization by $\mathfrak{p}$ and $\mathfrak{g}$ facilitates analyzing the optimal damping problem (at the PDE level) using norms such as the $\mathcal{H}_2$ and $\mathcal{H}_\infty$ norms. We also examine limiting cases, such as when the viscosity is very large or when no external damping is present. To illustrate our approach, we present numerical examples, compare different optimization criteria, and discuss the impact of damping parameters on the damped wave equation.

Paper number 173:
Title: Learning and composing of classical music using restricted Boltzmann machines
Authors: Mutsumi Kobayashi, Hiroshi Watanabe
Abstract: Recently, software has been developed that uses machine learning to mimic the style of a particular composer, such as J. S. Bach. However, since such software often adopts machine learning models with complex structures, it is difficult to analyze how the software understands the characteristics of the composer's music. In this study, we adopted J. S. Bach's music for training of a restricted Boltzmann machine (RBM). Since the structure of RBMs is simple, it allows us to investigate the internal states after learning. We found that the learned RBM is able to compose music.
    