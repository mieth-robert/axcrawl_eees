
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: A model of the Unity High Definition Render Pipeline, with applications to flat-panel and head-mounted display characterization
Authors: Richard F. Murray
Abstract: Game engines such as Unity and Unreal Engine have become popular tools for creating perceptual and behavioral experiments based on complex, interactive scenes. They are often used with flat-panel displays, and also with head-mounted displays. Here I describe and test a mathematical model of luminance and color in Unity's High Definition Render Pipeline (HDRP). I show that the HDRP has several non-obvious features, such as nonlinearities applied to material properties and rendered values, that must be taken into account in order to show well-controlled stimuli. I also show how the HDRP can be configured to display gamma-corrected luminance and color, and I provide software to create the specialized files needed for gamma correction.

Paper number 2:
Title: Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off
Authors: Adeline Guéret
Abstract: Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect "sector coupling" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime.

Paper number 3:
Title: Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control
Authors: Apurva Patil, Alfredo Duarte, Fabrizio Bisetti, Takashi Tanaka
Abstract: The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method.

Paper number 4:
Title: A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty
Authors: Yi Zhang, Yushen Long, Liping Huang, Yicheng Zhang, Sheng Zhang, Yifang Yin
Abstract: This paper presents a closed-loop framework for conflict-free routing and scheduling of multi-aircraft in Terminal Manoeuvring Areas (TMA), aimed at reducing congestion and enhancing landing efficiency. Leveraging data-driven arrival inputs (either historical or predicted), we formulate a mixed-integer optimization model for real-time control, incorporating an extended TMA network spanning a 50-nautical-mile radius around Changi Airport. The model enforces safety separation, speed adjustments, and holding time constraints while maximizing runway throughput. A rolling-horizon Model Predictive Control (MPC) strategy enables closed-loop integration with a traffic simulator, dynamically updating commands based on real-time system states and predictions. Computational efficiency is validated across diverse traffic scenarios, demonstrating a 7-fold reduction in computation time during peak congestion compared to onetime optimization, using Singapore ADS-B dataset. Monte Carlo simulations under travel time disturbances further confirm the framework's robustness. Results highlight the approach's operational resilience and computational scalability, offering actionable decision support for Air Traffic Controller Officers (ATCOs) through real-time optimization and adaptive replanning.

Paper number 5:
Title: A K-means Inspired Solution Framework for Large-Scale Multi-Traveling Salesman Problems
Authors: Xiubin Chen
Abstract: The Multi-Traveling Salesman Problem (MTSP) is a commonly used mathematical model for multi-agent task allocation. However, as the number of agents and task targets increases, existing optimization-based methods often incur prohibitive computational costs, posing significant challenges to large-scale coordination in unmanned systems. To address this issue, this paper proposes a K-means-inspired task allocation framework that reformulates the MTSP as a spatially constrained classification process. By leveraging spatial coherence, the proposed method enables fast estimation of path costs and efficient task grouping, thereby fundamentally reducing overall computational complexity. Extensive simulation results demonstrate that the framework can maintain high solution quality even in extremely large-scale scenarios-for instance, in tasks involving 1000 agents and 5000 targets. The findings indicate that this "cluster-then-route" decomposition strategy offers an efficient and reliable solution for large-scale multi-agent task allocation.

Paper number 6:
Title: Not Quite Anything: Overcoming SAMs Limitations for 3D Medical Imaging
Authors: Keith Moore
Abstract: Foundation segmentation models such as SAM and SAM-2 perform well on natural images but struggle with brain MRIs where structures like the caudate and thalamus lack sharp boundaries and have low contrast. Rather than fine tune these models (for example MedSAM), we propose a compositional alternative where the foundation model output is treated as an additional input channel and passed alongside the MRI to highlight regions of interest. We generate SAM-2 prompts by using a lightweight 3D U-Net that was previously trained on MRI segmentation. The U-Net may have been trained on a different dataset, so its guesses are often imprecise but usually in the correct region. The edges of the resulting foundation model guesses are smoothed to improve alignment with the MRI. We also test prompt free segmentation using DINO attention maps in the same framework. This has-a architecture avoids modifying foundation weights and adapts to domain shift without retraining the foundation model. It reaches about 96 percent volume accuracy on basal ganglia segmentation, which is sufficient for our study of longitudinal volume change. The approach is fast, label efficient, and robust to out of distribution scans. We apply it to study inflammation linked changes in sudden onset pediatric OCD.

Paper number 7:
Title: A Multi-Stage Deep Learning Framework with PKCP-MixUp Augmentation for Pediatric Liver Tumor Diagnosis Using Multi-Phase Contrast-Enhanced CT
Authors: Wanqi Wang, Chun Yang, Jianbo Shao, Yaokai Zhang, Xuehua Peng, Jin Sun, Chao Xiong, Long Lu, Lianting Hu
Abstract: Pediatric liver tumors are one of the most common solid tumors in pediatrics, with differentiation of benign or malignant status and pathological classification critical for clinical treatment. While pathological examination is the gold standard, the invasive biopsy has notable limitations: the highly vascular pediatric liver and fragile tumor tissue raise complication risks such as bleeding; additionally, young children with poor compliance require anesthesia for biopsy, increasing medical costs or psychological trauma. Although many efforts have been made to utilize AI in clinical settings, most researchers have overlooked its importance in pediatric liver tumors. To establish a non-invasive examination procedure, we developed a multi-stage deep learning (DL) framework for automated pediatric liver tumor diagnosis using multi-phase contrast-enhanced CT. Two retrospective and prospective cohorts were enrolled. We established a novel PKCP-MixUp data augmentation method to address data scarcity and class imbalance. We also trained a tumor detection model to extract ROIs, and then set a two-stage diagnosis pipeline with three backbones with ROI-masked images. Our tumor detection model has achieved high performance (mAP=0.871), and the first stage classification model between benign and malignant tumors reached an excellent performance (AUC=0.989). Final diagnosis models also exhibited robustness, including benign subtype classification (AUC=0.915) and malignant subtype classification (AUC=0.979). We also conducted multi-level comparative analyses, such as ablation studies on data and training pipelines, as well as Shapley-Value and CAM interpretability analyses. This framework fills the pediatric-specific DL diagnostic gap, provides actionable insights for CT phase selection and model design, and paves the way for precise, accessible pediatric liver tumor diagnosis.

Paper number 8:
Title: Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks
Authors: Jinming Gao, Yijing Wang, Wentao Zhang, Rui Zhao, Yang Shi, Zhiqiang Zuo
Abstract: This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method.

Paper number 9:
Title: State Feedback Controllers with Operational Constraints
Authors: Eugene Lavretsky
Abstract: In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems.

Paper number 10:
Title: The Selective Disk Bispectrum and Its Inversion, with Application to Multi-Reference Alignment
Authors: Adele Myers, Nina Miolane
Abstract: In many computer vision and shape analysis tasks, practitioners are interested in learning from the shape of the object in an image, while disregarding the object's orientation. To this end, it is valuable to define a rotation-invariant representation of images, retaining all information about that image, but disregarding the way an object is rotated in the frame. To be practical for learning tasks, this representation must be computationally efficient for large datasets and invertible, so the representation can be visualized in image space. To this end, we present the selective disk bispectrum: a fast, rotation-invariant representation for image shape analysis. While the translational bispectrum has long been used as a translational invariant representation for 1-D and 2-D signals, its extension to 2-D (disk) rotational invariance on images has been hindered by the absence of an invertible formulation and its cubic complexity. In this work, we derive an explicit inverse for the disk bispectrum, which allows us to define a "selective" disk bispectrum, which only uses the minimal number of coefficients needed for faithful shape recovery. We show that this representation enables multi-reference alignment for rotated images-a task previously intractable for disk bispectrum methods. These results establish the disk bispectrum as a practical and theoretically grounded tool for learning on rotation-invariant shape data.

Paper number 11:
Title: Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study
Authors: Theodor Hagström, Lars Herre
Abstract: Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework.

Paper number 12:
Title: Multi-Hypotheses Ego-Tracking for Resilient Navigation
Authors: Peter Iwer Hoedt Karstensen, Roberto Galeazzi
Abstract: Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vul- nerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identi- fication and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks

Paper number 13:
Title: Latent-space metrics for Complex-Valued VAE out-of-distribution detection under radar clutter
Authors: Y. A. Rouzoumka, E. Terreaux, C. Morisseau, J.-P. Ovarlez, C. Ren
Abstract: We investigate complex-valued Variational AutoEncoders (CVAE) for radar Out-Of-Distribution (OOD) detection in complex radar environments. We proposed several detection metrics: the reconstruction error of CVAE (CVAE-MSE), the latent-based scores (Mahalanobis, Kullback-Leibler divergence (KLD)), and compared their performance against the classical ANMF-Tyler detector (ANMF-FP). The performance of all these detectors is analyzed on synthetic and experimental radar data, showing the advantages and the weaknesses of each detector.

Paper number 14:
Title: White-Box Modeling of V2X Link Performance Using Stabilized Symbolic Regression
Authors: Rahul Gulia, Feyisayo Favour Popoola, Ashish Sheikh
Abstract: Reliable modeling of block error rate in vehicle-to-everything wireless networks is critical for designing robust communication systems under dynamic mobility and diverse channel conditions. Traditional machine learning approaches, such as deep neural networks, achieve high predictive accuracy but lack interpretability and impose significant computational costs, limiting their applicability in real-time, resource-constrained environments. In this work, we propose a stabilized symbolic regression framework to derive compact, analytically interpretable expressions for block error rate prediction. Trained on realistic vehicle-to-everything simulation data, the symbolic regression framework for vehicle-to-everything model accurately captures nonlinear dependencies on key system parameters, including signal-to-noise ratio, relative velocity, modulation and coding schemes, number of demodulation reference signal symbols, and environmental factors (line of sight/non-line of sight). Our final symbolic expression comprises only 158 nodes, enabling ultra-fast inference suitable for embedded deployment. On the test set, the symbolic regression framework for vehicle-to-everything model achieves a coefficient of determination $R^2 = 0.8684$ and mean squared error $= 2.08 \times 10^{-2}$ in the original block error rate domain, outperforming conventional fixed-form regressions and offering comparable accuracy to neural networks while remaining fully interpretable. Overall, the proposed Stabilized Symbolic Regression Framework for V2X combines predictive performance, physical fidelity, and computational efficiency thus providing a powerful tool for real-time V2X communication system design, adaptive resource allocation, and rapid scenario evaluation.

Paper number 15:
Title: Parallel Delay-Doppler Estimation via Order-Reversed Two-Stage Prony Method
Authors: Yutaka Jitsumatsu, Liangchen Sun
Abstract: This paper proposes a Prony-based parallel two-stage method for delay-Doppler estimation in OTFS systems. By performing delay-first and Doppler-first estimations in parallel and fusing the results, the method resolves ambiguities caused by similar path characteristics. The simulation results demonstrate the superior accuracy and robustness of the proposed method under various conditions. This method provides a promising solution for future applications such as Vehicle-to-Vehicle (V2V) and Integrated Sensing and Communication (ISAC).

Paper number 16:
Title: An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement
Authors: Mobina Nankali, Michael W. Levin
Abstract: This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks.

Paper number 17:
Title: Joint Classification and Regression Deep Learning Model for Universal Phase-based Ranging in Multiple Environments
Authors: Pantelis Stefanakis, Ming Shen
Abstract: Phase-Based Ranging (PBR) offers several advantages for estimating distances between wirelessly connected devices, including high accuracy over large distances and the removal of the need for antenna arrays at each transceiver. This study investigates the use of Neural Network (NN)-based models for accurate PBR in three distinct environments: Openfield, Office, and Near Buildings, comparing their performance with established non-NN methods. A novel 2NN Model is proposed, integrating two neural networks: one to classify the environment and another to predict distances. Performance was evaluated over 20 trials for each method and dataset using root mean square error (RMSE) and maximum prediction error. Results show that the 2NN Model consistently outperformed other methods, frequently ranking among the top methods in minimizing both RMSE and maximum error. In addition, the 2NN Model achieved the best average RMSE and the lowest maximum error. To assess the effect of environment misclassification, filtered versions of the NN models were evaluated by omitting misclassified measurements prior to RMSE calculation. Although unsuitable for production use, the filtered models revealed that misclassifications in the 2NN Model had a significant impact. Its filtered variant achieved the lowest RMSE and maximum error across all datasets, and ranked first in the frequency of attaining the lowest maximum error over 20 trials. Overall, the findings show that NN models deliver robust, high-accuracy ranging across diverse environments, outperforming non-NN methods and reinforcing their potential as universal PBR solutions when trained on comprehensive distance datasets.

Paper number 18:
Title: DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and Zero-Shot Customization of Diffusion Models
Authors: Jun Jia, Hongyi Miao, Yingjie Zhou, Linhan Cao, Yanwei Jiang, Wangqiu Zhou, Dandan Zhu, Hua Yang, Wei Sun, Xiongkuo Min, Guangtao Zhai
Abstract: With the rapid advancement of diffusion models, a variety of fine-tuning methods have been developed, enabling high-fidelity image generation with high similarity to the target content using only 3 to 5 training images. More recently, zero-shot generation methods have emerged, capable of producing highly realistic outputs from a single reference image without altering model weights. However, technological advancements have also introduced significant risks to facial privacy. Malicious actors can exploit diffusion model customization with just a few or even one image of a person to create synthetic identities nearly identical to the original identity. Although research has begun to focus on defending against diffusion model customization, most existing defense methods target fine-tuning approaches and neglect zero-shot generation defenses. To address this issue, this paper proposes Dual-Layer Anti-Diffusion (DLADiff) to defense both fine-tuning methods and zero-shot methods. DLADiff contains a dual-layer protective mechanism. The first layer provides effective protection against unauthorized fine-tuning by leveraging the proposed Dual-Surrogate Models (DSUR) mechanism and Alternating Dynamic Fine-Tuning (ADFT), which integrates adversarial training with the prior knowledge derived from pre-fine-tuned models. The second layer, though simple in design, demonstrates strong effectiveness in preventing image generation through zero-shot methods. Extensive experimental results demonstrate that our method significantly outperforms existing approaches in defending against fine-tuning of diffusion models and achieves unprecedented performance in protecting against zero-shot generation.

Paper number 19:
Title: AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload
Authors: Akash Doshi, Pinar Sen, Kirill Ivanov, Wei Yang, June Namgoong, Runxin Wang, Rachel Wang, Taesang Yoo, Jing Jiang, Tingfang Ji
Abstract: Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance gains could be obtained by employing joint source channel coding, aided by deep learning-based techniques. In this paper, we learn a transformer-based encoder using a novel "free-lunch" training algorithm and propose per-codeword power shaping to exploit the source prior at the encoder whilst being robust to small changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to achieve a low negative acknowledgement (NACK) error rate to avoid radio link failures resulting from multiple NACK errors. We develop an extension of the Neyman-Pearson test to a coded bit system with multiple information bits to achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally, we apply the proposed encoder and decoder designs to a 5G New Radio (NR) compliant uplink setup under a fading channel, describing the optimal receiver design and a low complexity coherent approximation to it. Our results demonstrate 3-6 dB reduction in the average transmit power required to achieve the target error rates compared to the NR baseline, while also achieving a 2-3 dB reduction in the maximum transmit power, thus providing for significant coverage gains and power savings.

Paper number 20:
Title: Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities
Authors: Zhenyu Tao, Wei Xu, Xiaohu You
Abstract: Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed.

Paper number 21:
Title: Cross-Modal Semantic Communication for Heterogeneous Collaborative Perception
Authors: Mingyi Lu, Guowei Liu, Le Liang, Chongtao Guo, Hao Ye, Shi Jin
Abstract: Collaborative perception, an emerging paradigm in autonomous driving, has been introduced to mitigate the limitations of single-vehicle systems, such as limited sensor range and occlusion. To improve the robustness of inter-vehicle data sharing, semantic communication has recently further been integrated into collaborative perception systems to enhance overall performance. However, practical deployment of such systems is challenged by the heterogeneity of sensors across different connected autonomous vehicles (CAVs). This diversity in perceptual data complicates the design of a unified communication framework and impedes the effective fusion of shared information. To address this challenge, we propose a novel cross-modal semantic communication (CMSC) framework to facilitate effective collaboration among CAVs with disparate sensor configurations. Specifically, the framework first transforms heterogeneous perceptual features from different sensor modalities into a unified and standardized semantic space. Subsequently, encoding, transmission, and decoding are performed within this semantic space, enabling seamless and effective information fusion. Extensive experiments demonstrate that CMSC achieves significantly stronger perception performance than existing methods, particularly in low signal-to-noise ratio (SNR) regimes.

Paper number 22:
Title: Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds
Authors: Simin Zhu, Satish Ravindran, Alexander Yarovoy, Francesco Fioranelli
Abstract: Conventional radar segmentation research has typically focused on learning category labels for different moving objects. Although fundamental differences between radar and optical sensors lead to differences in the reliability of predicting accurate and consistent category labels, a review of common radar perception tasks in automotive reveals that determining whether an object is moving or static is a prerequisite for most tasks. To fill this gap, this study proposes a neural network based solution that can simultaneously segment static and moving objects from radar point clouds. Furthermore, since the measured radial velocity of static objects is correlated with the motion of the radar, this approach can also estimate the instantaneous 2D velocity of the moving platform or vehicle (ego motion). However, despite performing dual tasks, the proposed method employs very simple yet effective building blocks for feature extraction: multi layer perceptrons (MLPs) and recurrent neural networks (RNNs). In addition to being the first of its kind in the literature, the proposed method also demonstrates the feasibility of extracting the information required for the dual task directly from unprocessed point clouds, without the need for cloud aggregation, Doppler compensation, motion compensation, or any other intermediate signal processing steps. To measure its performance, this study introduces a set of novel evaluation metrics and tests the proposed method using a challenging real world radar dataset, RadarScenes. The results show that the proposed method not only performs well on the dual tasks, but also has broad application potential in other radar perception tasks.

Paper number 23:
Title: BERT-APC: A Reference-free Framework for Automatic Pitch Correction via Musical Context Inference
Authors: Sungjae Kim, Kihyun Na, Jinyoung Choi, Injung Kim
Abstract: Automatic Pitch Correction (APC) enhances vocal recordings by aligning pitch deviations with the intended musical notes. However, existing APC systems either rely on reference pitches, which limits their practical applicability, or employ simple pitch estimation algorithms that often fail to preserve expressiveness and naturalness. We propose BERT-APC, a novel reference-free APC framework that corrects pitch errors while maintaining the natural expressiveness of vocal performances. In BERT-APC, a novel stationary pitch predictor first estimates the perceived pitch of each note from the detuned singing voice. A context-aware note pitch predictor estimates the intended pitch sequence by leveraging a music language model repurposed to incorporate musical context. Finally, a note-level correction algorithm fixes pitch errors while preserving intentional pitch deviations for emotional expression. In addition, we introduce a learnable data augmentation strategy that improves the robustness of the music language model by simulating realistic detuning patterns. Compared to two recent singing voice transcription models, BERT-APC demonstrated superior performance in note pitch prediction, outperforming the second-best model, ROSVOT, by 10.49%p on highly detuned samples in terms of the raw pitch accuracy. In the MOS test, BERT-APC achieved the highest score of $4.32 \pm 0.15$, which is significantly higher than those of the widely-used commercial APC tools, AutoTune ($3.22 \pm 0.18$) and Melodyne ($3.08 \pm 0.18$), while maintaining a comparable ability to preserve expressive nuances. To the best of our knowledge, this is the first APC model that leverages a music language model to achieve reference-free pitch correction with symbolic musical context. The corrected audio samples of BERT-APC are available online.

Paper number 24:
Title: Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports
Authors: Youzhe Yang, Hafiz Majid Hussain, Juha Haakana, Pedro Nardelli
Abstract: A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations.

Paper number 25:
Title: Sparse MIMO-OFDM Channel Estimation via RKHS Regularization
Authors: James Delfeld, Gian Marti, Chris Dick
Abstract: We propose a method for channel estimation in multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) wireless communication systems. The method exploits the band-sparsity of wireless channels in the delay-beamspace domain by solving a regularized optimization problem in a reproducing kernel Hilbert space (RKHS). A suitable representer theorem allows us to transform the infinite-dimensional optimization problem into a finite-dimensional one, which we then approximate with a low-dimensional surrogate. We solve the resulting optimization problem using a forward- backward splitting (FBS)-based algorithm. By exploiting the problem's modulation structure, we achieve a computational complexity per iteration that is quasi-linear in the number of unknown variables. We also propose a data-driven deep-unfolding based extension to improve the performance at a reduced number of iterations. We evaluate our channel estimators on ray-traced channels generated with SionnaRT. The results show that our methods significantly outperform linear methods such as linear minimum mean squared error (LMMSE) channel estimation based on aggregate channel statistics, both in terms of raw estimation accuracy as well as in downstream performance.

Paper number 26:
Title: Joint Bit-Partitioning and Modulation Design for Digital AirComp
Authors: Xiaojing Yan, Carlo Fischione
Abstract: For digital over-the-air computation, the ChannelComp framework has recently been proposed to design digital modulations to compute any arbitrary function over a multiple access channel. To reduce modulation design complexity while increasing computation reliability, this paper integrates a bit-partitioning procedure into ChannelComp. The key process is to partition the input bit sequence into several groups, map each group to a single modulation symbol and transmit the encoded symbol sequence across multiple time slots. With the objective to maximize a worst-case constellation distance, we develop two bit-partitioning methods. In uniform bit-partitioning, bits are evenly distributed across groups and modulation is designed via a max-min optimization, which is handled by a CCCP that solves a sequence of second-order cone programming subproblems. In importance-adaptive bit-partitioning (IABP), the bit allocation is adapted to the significance of individual bit positions, and the modulation and partitioning are jointly optimized. To keep the overall complexity manageable, simulated annealing is employed in the outer loop to update the partitioning, while a CCCP-based solver is used in the inner loop for modulation design. Numerical results show that both methods provide robust computation in noisy channels, and IABP achieves up to a 5 dB reduction in computation error compared to Sequential Modulation for AirComp, especially for product computation.

Paper number 27:
Title: Optimal Waveform Design for Continuous Aperture Array (CAPA)-aided ISAC Systems
Authors: Junjie Ye, Zhaolin Wang, Yuanwei Liu, Peichang Zhang, Lei Huang, Arumugam Nallanathan
Abstract: A novel continuous-aperture-array (CAPA)-aided integrated sensing and communication (ISAC) framework is proposed. Specifically, an optimal continuous ISAC waveform is designed to form a directive beampattern for multi-target sensing while suppressing the multi-user interference (MUI). To achieve the goal of optimal waveform design, the directional beampattern of CAPA is first derived based on Green's function, whereafter a reference sensing waveform is obtained through wavenumber-domain optimization. Based on the reference sensing waveform, a weighted functional programming on the tradeoff between sensing beampattern mismatch and MUI is formulated. To solve the resulting problem, an optimal CAPA-ISAC waveform structure is analytically derived using a Lagrangian-transformation and calculus-of-variations method, where the Lagrangian multiplier associated with the optimal waveform structure is determined via Bisection search. The obtained optimal waveform reveals that it is concurrently affected by the reference sensing waveform, the channel correlations and the channel-symbol correlations. Finally, numerical results validate the effectiveness of the proposed system and waveform design, demonstrating that CAPA can achieve significant performance gains against the ISAC designs based on conventional spatially discrete array in both sensing accuracy and communication reliability.

Paper number 28:
Title: Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis
Authors: Zeynab Kaseb, Matthias Moller, Lindsay Spoor, Jerry J. Guo, Yu Xiang, Peter Palensky, Pedro P. Vergara
Abstract: The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions.

Paper number 29:
Title: Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection
Authors: Jan Krejčí, Oliver Kost, Yuxuan Xia, Lennart Svensson, Ondřej Straka
Abstract: This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks.

Paper number 30:
Title: Rectified Flow for Vision-Aided mmWave V2I Beam Prediction
Authors: Can Zheng, Jiguang He, Chung G. Kang, Guofa Cai, Chongwen Huang, Henk Wymeersch
Abstract: This paper proposes a flow matching (FM) framework based on rectified flow for vision-aided beam prediction in vehicle-to-infrastructure (V2I) links. Instead of modeling discrete beam index sequences, the method learns a continuous latent flow governed by an ordinary differential equation (ODE)-based vector field, enabling smooth beam trajectories and fast sampling. A terminal flow constraint enforces global consistency under finite-step integration, stabilizing long-term prediction. The resulting FM-based model significantly improves top-K accuracy over RNN and LSTM baselines, approaches the performance of large language model-based approaches, and achieves inference speedups on the order of 10 x and 10^4 x on identical GPU and CPU deployments, respectively.

Paper number 31:
Title: LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design
Authors: Lianzhe Hu, Yu Wang, Bikash Pal
Abstract: This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations.

Paper number 32:
Title: SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms
Authors: Dnyandeep Mandaokar, Bernhard Rinner
Abstract: Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.

Paper number 33:
Title: Log-Mu Fading Process: Second-Order Statistics for Diversity-Combining Techniques
Authors: Godfred Kumi Tenkorang, Michel Daoud Yacoub
Abstract: This paper derives second-order statistics for diversity-combining techniques over Log-mu fading channels. Closed-form expressions for the level crossing rate (LCR) and average fading duration (AFD) are derived for pure selection combining (PSC), while exact multidimensional integral expressions are obtained for equal gain combining (EGC) and maximal ratio combining (MRC). The analysis considers M unbalanced, independent, and non-identically distributed (i.n.i.d.) Log-mu fading channels. Monte Carlo simulations are conducted to validate the theoretical results, demonstrating excellent agreement and confirming the accuracy of the proposed expressions.

Paper number 34:
Title: Next-Generation MIMO Transceivers for Integrated Sensing and Communications: Unique Security Vulnerabilities and Solutions
Authors: Kawon Han, Christos Masouros, Taneli Riihonen, Moeness G. Amin
Abstract: Integrated sensing and communications (ISAC), which is recognized as a key enabler for sixth generation (6G), has brought new opportunities for intelligent, sustainable, and connected wireless networks. Multiple-input multiple-output (MIMO) transceiver technology lies at the core of this paradigm, providing the degrees of freedom required for simultaneous data transmission and accurate radar sensing. The tight integration of sensing and communication introduces unique security vulnerabilities that extend beyond conventional physical-layer security (PLS). In particular, high-power transmissions directed at sensing targets may empower adversarial eavesdroppers, whereas passive interception of ISAC echoes can reveal sensitive information such as target locations and mobility patterns. This article presents an overview of recent advances in MIMO ISAC transceiver design, considering transmitter perspectives, receiver architectures, and full-duplex implementations. We examine MIMO transceiver designs under unique security threats specific to ISAC and highlight emerging countermeasures, including secure signaling design, interference exploitation, and transceiver optimization under adversarial conditions. Finally, we discuss challenges and research opportunities for developing secure ISAC systems in next-generation wireless networks.

Paper number 35:
Title: Bridging the Educational Divide: A Delay-Tolerant Networking Approach for Equitable Digital Learning in Rural Areas
Authors: Salah Abdeljabar, Mohamed-Slim Alouini
Abstract: Access to quality education remains unequal, particularly in rural areas where Internet connectivity is limited or nonexistent. This paper introduces a framework for a digital learning platform that uses Delay Tolerant Networking (DTN) to extend educational opportunities to underserved communities. Unlike conventional models that rely on continuous Internet access, DTN offers an affordable and sustainable solution by leveraging existing transportation infrastructure. Beyond its technical contributions, the framework addresses ethical imperatives by promoting educational equity and digital inclusion. We present a prototype tested on a university campus, demonstrating the feasibility of DTN for educational delivery. By addressing the digital divide, this framework aligns with global goals of inclusive education and sustainable development.

Paper number 36:
Title: Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks
Authors: Viet-Anh Le, Andreas A. Malikopoulos
Abstract: In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied.

Paper number 37:
Title: Adaptive Meshing for CPA Lyapunov Function Synthesis
Authors: Amy K. Strong, Samuel Akinwande, Leila Bridgeman
Abstract: Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods.

Paper number 38:
Title: Digital Twin-Assisted High-Precision Massive MIMO Localization in Urban Canyons
Authors: Ziqin Zhou, Hui Chen, Gerhard Steinböck, Henk Wymeersch
Abstract: High-precision wireless localization in urban canyons is challenged by noisy measurements and severe non-line-of-sight (NLOS) propagation. This paper proposes a robust three-stage algorithm synergizing a digital twin (DT) model with the random sample consensus (RANSAC) algorithm to overcome these limitations. The method leverages the DT for geometric path association and employs RANSAC to identify reliable line-of-sight (LOS) and single-bounce NLOS paths while rejecting multi-bounce outliers. A final optimization on the resulting inlier set estimates the user's position and clock bias. Simulations validate that by effectively turning NLOS paths into valuable geometric information via the DT, the approach enables accurate localization, reduces reliance on direct LOS, and significantly lowers system deployment costs, making it suitable for practical deployment.

Paper number 39:
Title: Learning Control Barrier Functions with Deterministic Safety Guarantees
Authors: Amy K. Strong, Ali Kashani, Claus Danielson, Leila Bridgeman
Abstract: Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems.

Paper number 40:
Title: Development of a fully deep learning model to improve the reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction
Authors: Marzio Galdi, Davide Cannatà, Flavia Celentano, Luigia Rizzo, Domenico Rossi, Tecla Bocchino, Stefano Martina
Abstract: Objectives. The aim of the present study was to develop a fully deep learning model to reduce the intra- and inter-operator reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction. Methods. Three orthodontists (Os) and three general dental practitioners (GDPs) classified the position of unerupted maxillary canines on 306 radiographs (T0) according to the three different sector classification systems (5-, 4-, and 3-sector classification system). The assessment was repeated after four weeks (T1). Intra- and inter-observer agreement were evaluated with Cohen's K and Fleiss K, and between group differences with a z-test. The same radiographs were tested on different artificial intelligence (AI) models, pre-trained on an extended dataset of 1,222 radiographs. The best-performing model was identified based on its sensitivity and precision. Results. The 3-sector system was found to be the classification method with highest reproducibility, with an agreement (Cohen's K values) between observations (T0 versus T1) for each examiner ranged from 0.80 to 0.92, and an overall agreement of 0.85 [95% confidence interval (CI) = 0.83-0.87]. The overall inter-observer agreement (Fleiss K) ranged from 0.69 to 0.7. The educational background did not affect either intra- or inter-observer agreement (p>0.05). DenseNet121 proved to be the best-performing model in allocating impacted canines in the three different classes, with an overall accuracy of 76.8%. Conclusion. AI models can be designed to automatically classify the position of unerupted maxillary canines.

Paper number 41:
Title: Causal Feature Selection for Weather-Driven Residential Load Forecasting
Authors: Elise Zhang, François Mirallès, Stéphane Dellacherie, Di Wu, Benoit Boulet
Abstract: Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting.

Paper number 42:
Title: Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of Cavitation Activity
Authors: Tatiana Gelvez-Barrera, Barbara Nicolas, Denis Kouamé, Bruno Gilles, Adrian Basarab
Abstract: Passive acoustic mapping enables the spatial mapping and temporal monitoring of cavitation activity, playing a crucial role in therapeutic ultrasound applications. Most conventional beamforming methods, whether implemented in the time or frequency domains, suffer from limited axial resolution due to the absence of a reference emission onset time. While frequency-domain methods, the most efficient of which are based on the cross-spectral matrix, require long signals for accurate estimation, time-domain methods typically achieve lower spatial resolution. To address these limitations, we propose a linear model-based beamforming framework fully formulated in the time domain. The linear forward model relates a discretized spatiotemporal distribution of cavitation activity to the temporal signals recorded by a probe, explicitly accounting for time-of-flight delays dictated by the acquisition geometry. This model is then inverted using regularization techniques that exploit prior knowledge of cavitation activity in both spatial and temporal domains. Experimental results show that the proposed framework achieves enhanced or competitive cavitation map quality while using only 20\% of the data typically required by frequency-domain methods. This highlights the substantial gain in data efficiency and the flexibility of our spatiotemporal regularization to adapt to diverse passive cavitation scenarios, outperforming state-of-the-art techniques.

Paper number 43:
Title: From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc
Authors: Haoyu Wang, Andrea Alfonsi, Roberto Ponciroli, Richard Vilim
Abstract: The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\(\approx 10\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting.

Paper number 44:
Title: Near-Field Multipath MIMO Channels: Modeling Reflectors and Exploiting NLOS Paths
Authors: Mohamadreza Delbari, George C. Alexandropoulos, Robert Schober, H. Vincent Poor, Vahid Jamali
Abstract: Near-field (NF) communications is receiving renewed interest in the context of multiple-input multiple-output (MIMO) systems involving large physical apertures with respect to the signal wavelength. While line-of-sight (LOS) links are typically expected to dominate in NF scenarios, the impact of non-LOS (NLOS) components at both in centimeter- and millimeter-wave frequencies may be in general non-negligible. Moreover, although weaker than the LOS path, NLOS links may be essential for achieving multiplexing gains in MIMO systems. The commonly used NF channel models for NLOS links in the literature are based on the point scattering assumption, which is not valid for large reflectors such as walls, ceilings, and the ground. In this paper, we develop a generalized statistical NF MIMO channel model that extends the widely adopted point scattering framework to account for imperfect reflections from large surfaces. This model is then leveraged to investigate how the physical characteristics of these reflectors influence the resulting NF MIMO channel. In addition, using the proposed channel model, we analytically demonstrate for a multi-user scenario that, even when users are located within the NF regime, relying solely on LOS NF links may be insufficient to achieve multiplexing gains, thus exploiting NLOS links becomes essential. Our simulation results validate the accuracy of the proposed model and show that, in many practical settings, the contribution of NLOS components is non-negligible and must be carefully accounted for in the system design.

Paper number 45:
Title: Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency
Authors: Winfrey Paul Sagayam Dennis
Abstract: Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.

Paper number 46:
Title: Systemic approach for modeling a generic smart grid
Authors: Sofiane Ben Amor, Guillaume Guerard, Loup-Noé Levy
Abstract: Smart grid technological advances present a recent class of complex interdisciplinary modeling and increasingly difficult simulation problems to solve using traditional computational methods. To simulate a smart grid requires a systemic approach to integrated modeling of power systems, energy markets, demand-side management, and much other resources and assets that are becoming part of the current paradigm of the power grid. This paper presents a backbone model of a smart grid to test alternative scenarios for the grid. This tool simulates disparate systems to validate assumptions before the human scale model. Thanks to a distributed optimization of subsystems, the production and consumption scheduling is achieved while maintaining flexibility and scalability.

Paper number 47:
Title: Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization
Authors: Jack Yarndley
Abstract: Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.

Paper number 48:
Title: The Determinant Ratio Matrix Approach to Solving 3D Matching and 2D Orthographic Projection Alignment Tasks
Authors: Andrew J. Hanson, Sonya M. Hanson
Abstract: Pose estimation is a general problem in computer vision with wide applications. The relative orientation of a 3D reference object can be determined from a 3D rotated version of that object, or from a projection of the rotated object to a 2D planar image. This projection can be a perspective projection (the PnP problem) or an orthographic projection (the OnP problem). We restrict our attention here to the OnP problem and the full 3D pose estimation task (the EnP problem). Here we solve the least squares systems for both the error-free EnP and OnP problems in terms of the determinant ratio matrix (DRaM) approach. The noisy-data case can be addressed with a straightforward rotation correction scheme. While the SVD and optimal quaternion eigensystem methods solve the noisy EnP 3D-3D alignment exactly, the noisy 3D-2D orthographic (OnP) task has no known comparable closed form, and can be solved by DRaM-class methods. We note that while previous similar work has been presented in the literature exploiting both the QR decomposition and the Moore-Penrose pseudoinverse transformations, here we place these methods in a larger context that has not previously been fully recognized in the absence of the corresponding DRaM solution. We term this class of solutions as the DRaM family, and conduct comparisons of the behavior of the families of solutions for the EnP and OnP rotation estimation problems. Overall, this work presents both a new solution to the 3D and 2D orthographic pose estimation problems and provides valuable insight into these classes of problems. With hindsight, we are able to show that our DRaM solutions to the exact EnP and OnP problems possess derivations that could have been discovered in the time of Gauss, and in fact generalize to all analogous N-dimensional Euclidean pose estimation problems.

Paper number 49:
Title: Blinking Beyond EAR: A Stable Eyelid Angle Metric for Driver Drowsiness Detection and Data Augmentation
Authors: Mathis Wolter, Julie Stephany Berrio Perez, Mao Shan
Abstract: Detecting driver drowsiness reliably is crucial for enhancing road safety and supporting advanced driver assistance systems (ADAS). We introduce the Eyelid Angle (ELA), a novel, reproducible metric of eye openness derived from 3D facial landmarks. Unlike conventional binary eye state estimators or 2D measures, such as the Eye Aspect Ratio (EAR), the ELA provides a stable geometric description of eyelid motion that is robust to variations in camera angle. Using the ELA, we design a blink detection framework that extracts temporal characteristics, including the closing, closed, and reopening durations, which are shown to correlate with drowsiness levels. To address the scarcity and risk of collecting natural drowsiness data, we further leverage ELA signals to animate rigged avatars in Blender 3D, enabling the creation of realistic synthetic datasets with controllable noise, camera viewpoints, and blink dynamics. Experimental results in public driver monitoring datasets demonstrate that the ELA offers lower variance under viewpoint changes compared to EAR and achieves accurate blink detection. At the same time, synthetic augmentation expands the diversity of training data for drowsiness recognition. Our findings highlight the ELA as both a reliable biometric measure and a powerful tool for generating scalable datasets in driver state monitoring.

Paper number 50:
Title: Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic Assessment
Authors: Muhao Guo, Yang Weng
Abstract: The rapid expansion of distributed photovoltaic (PV) systems poses challenges for power grid management, as many installations remain undocumented. While satellite imagery provides global coverage, traditional computer vision (CV) models such as CNNs and U-Nets require extensive labeled data and fail to generalize across regions. This study investigates the cross-domain generalization of a multimodal large language model (LLM) for global PV assessment. By leveraging structured prompts and fine-tuning, the model integrates detection, localization, and quantification within a unified schema. Cross-regional evaluation using the $\Delta$F1 metric demonstrates that the proposed model achieves the smallest performance degradation across unseen regions, outperforming conventional CV and transformer baselines. These results highlight the robustness of multimodal LLMs under domain shift and their potential for scalable, transferable, and interpretable global PV mapping.

Paper number 51:
Title: A Hybrid Dominant-Interferer Approximation for SINR Coverage in Poisson Cellular Networks
Authors: Sunder Ram Krishnan, Junaid Farooq, Kumar Vijay Mishra, Xingchen Liu, S. Unnikrishna Pillai, Theodore S. Rappaport
Abstract: Accurate radio propagation and interference modeling is essential for the design and analysis of modern cellular networks. Stochastic geometry offers a rigorous framework by treating base station locations as a Poisson point process and enabling coverage characterization through spatial averaging, but its expressions often involve nested integrals and special functions that limit general applicability. Probabilistic interference models seek closed-form characterizations through moment-based approximations, yet these expressions remain tractable only for restricted parameter choices and become unwieldy when interference moments lack closed-form representations. This work introduces a hybrid approximation framework that addresses these challenges by combining Monte Carlo sampling of a small set of dominant interferers with a Laplace functional representation of the residual far-field interference. The resulting dominant-plus-tail structure provides a modular, numerically stable, and path-loss-agnostic estimator suitable for both noise-limited and interference-limited regimes. We further derive theoretical error bounds that decrease with the number of dominant interferers and validate the approach against established stochastic geometry and probabilistic modeling benchmarks.

Paper number 52:
Title: Anytime-Feasible First-Order Optimization via Safe Sequential QCQP
Authors: Jiarui Wang, Mahyar Fazlyab
Abstract: This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT.

Paper number 53:
Title: An Accelerated Distributed Algorithm with Equality and Inequality Coupling Constraints
Authors: Chenyang Qiu, Yangyang Qian, Zongli Lin, Yacov A. Shamash
Abstract: This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget.

Paper number 54:
Title: Non-Ergodic Convergence Algorithms for Distributed Consensus and Coupling-Constrained Optimization
Authors: Chenyang Qiu, Zongli Lin
Abstract: We study distributed convex optimization with two ubiquitous forms of coupling: consensus constraints and global affine equalities. We first design a linearized method of multipliers for the consensus optimization problem. Without smoothness or strong convexity, we establish non-ergodic sublinear rates of order O(1/\sqrt{k}) for both the objective optimality and the consensus violation. Leveraging duality, we then show that the economic dispatch problem admits a dual consensus formulation, and that applying the same algorithm to the dual economic dispatch yields non-ergodic O(1/\sqrt{k}) decay for the error of the summation of the cost over the network and the equality-constraint residual under convexity and Slater's condition. Numerical results on the IEEE 118-bus system demonstrate faster reduction of both objective error and feasibility error relative to the state-of-the-art baselines, while the dual variables reach network-wide consensus.

Paper number 55:
Title: A Distributed Gradient-based Algorithm for Optimization Problems with Coupled Equality Constraints
Authors: Chenyang Qiu, Zongli Lin
Abstract: This paper studies a class of distributed optimization problems with coupled equality constraints in networked systems. Many existing distributed algorithms rely on solving local subproblems via the $\operatorname{argmin}$ operator in each iteration. Such approaches become computationally burdensome or intractable when local cost functions are complex. To address this challenge, we propose a novel distributed gradient-based algorithm that avoids solving a local optimization problem at each iteration by leveraging first-order approximations and projection onto local feasible sets. The algorithm operates in a fully distributed manner, requiring only local communication without exchanging gradients or primal variables. We rigorously establish sublinear convergence for general convex cost functions and linear convergence under strong convexity and smoothness conditions. Numerical simulation on the IEEE 118-bus system demonstrates the superior computational efficiency and scalability of the proposed method compared to several state-of-the-art distributed optimization algorithms.

Paper number 56:
Title: An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design
Authors: Roberto Garrone
Abstract: Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.

Paper number 57:
Title: Joint Satellite Power Consumption and Handover Optimization for LEO Constellations
Authors: Yassine Afif, Mohammed Almekhlafi, Antoine Lesage-Landry, Gunes Karabulut Kurt
Abstract: In satellite constellation-based communication systems, continuous user coverage requires frequent handoffs due to the dynamic topology induced by the Low Earth Orbit (LEO) satellites. Each handoff between a satellite and ground users introduces additional signaling and power consumption, which can become a significant burden as the size of the constellation continues to increase. This work focuses on the optimization of the total transmission rate in a LEO-to-user system, by jointly considering the total transmitted power, user-satellite associations, and power consumption, the latter being handled through a penalty on handoff events. We consider a system where LEO satellites serve users located in remote areas with no terrestrial connectivity, and formulate the power allocation problem as a mixed-integer concave linear program (MICP) subject to power and association constraints. Our approach can be solved with off-the-shelf solvers and is benchmarked against a naive baseline where users associate to their closest visible satellite. Extensive Monte Carlo simulations demonstrate the effectiveness of the proposed method in controlling the handoff frequency while maintaining high user throughput. These performance gains highlight the effectiveness of our handover-aware optimization strategy, which ensures that user rates improve significantly, by about 40%, without incurring a disproportionate rise in the handoff frequency.

Paper number 58:
Title: Field Test of 5G New Radio (NR) UL-MIMO and UL-256QAM for HD Live-Streaming
Authors: Kasidis Arunruangsirilert
Abstract: The exponential growth of User-Generated Content (UGC), especially High-Definition (HD) live video streaming, places a significant demand on the uplink capabilities of mobile networks. To address this, the 5G New Radio (NR) standard introduced key uplink enhancements, including Uplink Multi-Input Multi-Output (UL-MIMO) and Uplink 256QAM, to improve throughput and spectral efficiency. However, while the benefits of these features for raw data rates are well-documented, their practical impact on real-time applications like live-streaming is not yet well understood. This paper investigates the performance of UL-MIMO and UL-256QAM for HD live-streaming over a commercial 5G network using the Real-Time Messaging Protocol (RTMP). To ensure a fair assessment, we conduct a comparative analysis by modifying the modem firmware of commercial User Equipment (UE), allowing these features to be selectively enabled and disabled on the same device. Performance is evaluated based on key metrics, including dropped video frames and connection stability. Furthermore, this study analyzes 5G Radio Frequency (RF) parameters to quantify the spectral efficiency impact, specifically examining metrics derived from the Channel State Information (CSI) framework, including Reference Signal Received Power (CSI-RSRP), Reference Signal Received Quality (CSI-RSRQ), and Signal-to-Interference-plus-Noise Ratio (CSI-SINR).

Paper number 59:
Title: It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models
Authors: Xiangyu Zhao, Yaling Shen, Yiwen Jiang, Zimu Wang, Jiahe Liu, Maxmartwell H Cheng, Guilherme C Oliveira, Robert Desimone, Dominic Dwyer, Zongyuan Ge
Abstract: Depression is one of the most prevalent mental health disorders globally. In recent years, multi-modal data, such as speech, video, and transcripts, has been increasingly used to develop AI-assisted depression assessment systems. Large language models have further advanced this field due to their strong language understanding and generalization capabilities. However, conventional LLMs remain text-centric and cannot process the rich non-verbal cues found in audio and visual modalities, which are critical components in mental health evaluation. While multi-modal LLMs offer a promising direction, few are tailored for psychological applications. In this study, we propose a novel multi-modal LLM framework for depression detection. Our approach augments an audio language model with visual understanding and aligns audio-visual features at the timestamp level. This fine-grained alignment improves modeling of temporal dynamics across modalities while reducing the need for extensive training data and computational resources. Experiments on the DAIC-WoZ dataset demonstrate that our model outperforms both single-modality approaches and previous multi-modal methods. Moreover, the proposed framework can be extended to incorporate additional physiological signals, paving the way for broader clinical applications beyond mental health.

Paper number 60:
Title: Towards Edge General Intelligence: Knowledge Distillation for Mobile Agentic AI
Authors: Yuxuan Wu, Linghan Ma, Ruichen Zhang, Yinqiu Liu, Dusit Niyato, Shunpu Tang, Zehui Xiong, Zhu Han, Zhaohui Yang, Kaibin Huang, Zhaoyang Zhang, Kai-Kit Wong
Abstract: Edge General Intelligence (EGI) represents a paradigm shift in mobile edge computing, where intelligent agents operate autonomously in dynamic, resource-constrained environments. However, the deployment of advanced agentic AI models on mobile and edge devices faces significant challenges due to limited computation, energy, and storage resources. To address these constraints, this survey investigates the integration of Knowledge Distillation (KD) into EGI, positioning KD as a key enabler for efficient, communication-aware, and scalable intelligence at the wireless edge. In particular, we emphasize KD techniques specifically designed for wireless communication and mobile networking, such as channel-aware self-distillation, cross-model Channel State Information (CSI) feedback distillation, and robust modulation/classification distillation. Furthermore, we review novel architectures natively suited for KD and edge deployment, such as Mamba, RWKV (Receptance, Weight, Key, Value) and Cross-Architecture distillation, which enhance generalization capabilities. Subsequently, we examine diverse applications in which KD-driven architectures enable EGI across vision, speech, and multimodal tasks. Finally, we highlight the key challenges and future directions for KD in EGI. This survey aims to provide a comprehensive reference for researchers exploring KD-driven frameworks for mobile agentic AI in the era of EGI.

Paper number 61:
Title: iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization
Authors: Xiucheng Wang, Tingwei Yuan, Yang Cao, Nan Cheng, Ruijin Sun, Weihua Zhuang
Abstract: Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at this https URL.

Paper number 62:
Title: Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach
Authors: Huu Tuong Tu, Ha Viet Khanh, Tran Tien Dat, Vu Huan, Thien Van Luong, Nguyen Tien Cuong, Nguyen Thi Thu Trang
Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

Paper number 63:
Title: CSI Prediction Frameworks for Enhanced 5G Link Adaptation: Performance-Complexity Trade-offs
Authors: Francisco Díaz-Ruiz, Francisco J. Martín-Vega, Jose A. Cortés, Gerardo Gómez, Mari Carmen Aguayo
Abstract: Accurate and timely channel state information (CSI) is fundamental for efficient link adaptation. However, challenges such as channel aging, user mobility, and feedback delays significantly impact the performance of adaptive modulation and coding (AMC). This paper proposes and evaluates two CSI prediction frameworks applicable to both time division duplexing (TDD) and frequency division duplexing (FDD) systems. The proposed methods operate in the effective signal to interference plus noise ratio (SINR) domain to reduce complexity while preserving predictive accuracy. A comparative analysis is conducted between a classical Wiener filter and state-of-the-art deep learning frameworks based on gated recurrent units (GRUs), long short-term memory (LSTM) networks, and a delayed deep neural network (DNN). The evaluation considers the accuracy of the prediction in terms of mean squared error (MSE), the performance of the system, and the complexity of the implementation regarding floating point operations (FLOPs). Furthermore, we investigate the generalizability of both approaches under various propagation conditions. The simulation results show that the Wiener filter performs close to GRU in terms of MSE and throughput with lower computational complexity, provided that the second-order statistics of the channel are available. However, the GRU model exhibits enhanced generalization across different channel scenarios. These findings suggest that while learningbased solutions are well-suited for TDD systems where the base station (BS) handles the computation, the lower complexity of classical methods makes them a preferable choice for FDD setups, where prediction occurs at the power-constrained user equipment (UE).

Paper number 64:
Title: Communication-Efficient Learning for Satellite Constellations
Authors: Ruxandra-Stefania Tudose, Moritz H.W. Grüss, Grace Ra Kim, Karl H. Johansson, Nicola Bastianello
Abstract: Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.

Paper number 65:
Title: Self-Identifying Internal Model-Based Online Optimization
Authors: Wouter J. A. van Weerelt, Lantian Zhang, Silun Zhang, Nicola Bastianello
Abstract: In this paper, we propose a novel online optimization algorithm built by combining ideas from control theory and system identification. The foundation of our algorithm is a control-based design that makes use of the internal model of the online problem. Since such prior knowledge of this internal model might not be available in practice, we incorporate an identification routine that learns this model on the fly. The algorithm is designed starting from quadratic online problems but can be applied to general problems. For quadratic cases, we characterize the asymptotic convergence to the optimal solution trajectory. We compare the proposed algorithm with existing approaches, and demonstrate how the identification routine ensures its adaptability to changes in the underlying internal model. Numerical results also indicate strong performance beyond the quadratic setting.

Paper number 66:
Title: Nonuniform-Grid Markov Chain Approximation of Continuous Processes with Time-Linear Moments
Authors: Do Hyun Kim, Ahemt Cetinkaya
Abstract: We propose a method to approximate continuous-time, continuous-state stochastic processes by a discrete-time Markov chain defined on a nonuniform grid. Our method provides exact moment matching for processes whose first and second moments are linear functions of time. In particular, we show that, under certain conditions, the transition probabilities of a Markov chain can be chosen so that its first two moments match prescribed linear functions of time. These conditions depend on the grid points of the Markov chain and the coefficients of the linear mean and variance functions. Our proof relies on two recurrence relations for the expectation and variance across time. This approach enables simulation-based numerical analysis of continuous processes while preserving their key characteristics. We illustrate its efficacy by approximating continuous processes describing heat diffusion and geometric Brownian motion (GBM). For heat diffusion, we show that the heat profile at a set of points can be investigated by embedding those points inside the nonuniform grid of our Markov chain. For GBM, numerical simulations demonstrate that our approach, combined with suitable nonuniform grids, yields accurate approximations, with consistently small empirical Wasserstein-1 distances at long time horizons.

Paper number 67:
Title: Power-Efficient Autonomous Mobile Robots
Authors: Liangkai Liu, Weisong Shi, Kang G. Shin
Abstract: This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.

Paper number 68:
Title: Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning
Authors: Allen Emmanuel Binny, Mahathi Anand, Hugo T. M. Kussaba, Lingyun Chen, Shreenabh Agrawal, Fares J. Abu-Dakka, Abdalla Swikir
Abstract: Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.

Paper number 69:
Title: Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition
Authors: Yujin Kim, Sarah Dean
Abstract: Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: this https URL

Paper number 70:
Title: Iterated Invariant Extended Kalman Filter (IterIEKF)
Authors: Sven Goffin, Axel Barrau, Silvère Bonnabel, Olivier Brüls, Pierre Sacré
Abstract: We study the mathematical properties of the Invariant Extended Kalman Filter (IEKF) when iterating on the measurement update step, following the principles of the well-known Iterated Extended Kalman Filter. This iterative variant of the IEKF (IterIEKF) systematically improves its accuracy through Gauss-Newton-based relinearization, and exhibits additional theoretical properties, particularly in the low-noise regime, that resemble those of the linear Kalman filter. We apply the proposed approach to the problem of estimating the extended pose of a crane payload using an inertial measurement unit. Our results suggest that the IterIEKF significantly outperforms the IEKF when measurements are highly accurate.

Paper number 71:
Title: An Adaptive Method for Contextual Stochastic Multi-armed Bandits with Rewards Generated by a Linear Dynamical System
Authors: Jonathan Gornet, Mehdi Hosseinzadeh, Bruno Sinopoli
Abstract: Online decision-making can be formulated as the popular stochastic multi-armed bandit problem where a learner makes decisions (or takes actions) to maximize cumulative rewards collected from an unknown environment. This paper proposes to model a stochastic multi-armed bandit as an unknown linear Gaussian dynamical system, as many applications, such as bandits for dynamic pricing problems or hyperparameter selection for machine learning models, can benefit from this perspective. Following this approach, we can build a matrix representation of the system's steady-state Kalman filter that takes a set of previously collected observations from a time interval of length $s$ to predict the next reward that will be returned for each action. This paper proposes a solution in which the parameter $s$ is determined via an adaptive algorithm by analyzing the model uncertainty of the matrix representation. This algorithm helps the learner adaptively adjust its model size and its length of exploration based on the uncertainty of its environmental model. The effectiveness of the proposed scheme is demonstrated through extensive numerical studies, revealing that the proposed scheme is capable of increasing the rate of collected cumulative rewards.

Paper number 72:
Title: Shaping Frequency Dynamics in Modern Power Systems with Grid-forming Converters
Authors: Carlos Collados-Rodriguez, Daniel Westerman Spier, Marc Cheah-Mane, Eduardo Prieto-Araujo, Oriol Gomis-Bellmunt
Abstract: In this paper, frequency dynamics in modern power systems with a high penetration of converter-based generation is analysed. A fundamental analysis of the frequency dynamics is performed to identify the limitations and challenges when the converter penetration is increased. The voltage-source behaviour is found as an essential characteristic of converters to improve the initial frequency derivative of Synchronous Generators (SGs). A detailed small-signal analysis, based on the system's eigenvalues, participation factors and mode shapes, is then performed in a reduced system for different converter penetrations, showing that the flexibility of grid-forming (GFOR) converters as well as the system's inertia reduction may lead to have a more controllable system frequency. First-order frequency responses can be programmed for high converter penetrations, when GFOR operation can impose their dominance over SGs. These results have been validated in the IEEE 118-bus system simulated in PSCAD.

Paper number 73:
Title: KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning
Authors: M. Umar B. Niazi, John Cao, Matthieu Barreau, Karl Henrik Johansson
Abstract: This paper proposes a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems. The design of a KKL observer involves finding an injective map that transforms the system state into a higher-dimensional observer state, whose dynamics is linear and stable. The observer's state is then mapped back to the original system coordinates via the inverse map to obtain the state estimate. However, finding this transformation and its inverse is quite challenging. We propose learning the forward mapping using a physics-informed neural network, and then learning its inverse mapping with a conventional feedforward neural network. Theoretical guarantees for the robustness of state estimation against approximation error and system uncertainties are provided, including non-asymptotic learning guarantees that link approximation quality to finite sample sizes. The effectiveness of the proposed approach is demonstrated through numerical simulations on benchmark examples, showing superior generalization capability outside the training domain compared to state-of-the-art methods.

Paper number 74:
Title: Enhancing Medical Image Analysis through Geometric and Photometric transformations
Authors: Khadija Rais, Mohamed Amroune, Mohamed Yassine Haouam, Abdelmadjid Benmachiche
Abstract: Medical image analysis suffers from a lack of labeled data due to several challenges including patient privacy and lack of experts. Although some AI models only perform well with large amounts of data, we will move to data augmentation where there is a solution to improve the performance of our models and increase the dataset size through traditional or advanced techniques. In this paper, we evaluate the effectiveness of data augmentation techniques on two different medical image datasets. In the first step, we applied some transformation techniques to the skin cancer dataset containing benign and malignant classes. Then, we trained the convolutional neural network (CNN) on the dataset before and after augmentation, which significantly improved test accuracy from 90.74% to 96.88% and decreased test loss from 0.7921 to 0.1468 after augmentation. In the second step, we used the Mixup technique by mixing two random images and their corresponding masks using the retina and blood vessels dataset, then we trained the U-net model and obtained the Dice coefficient which increased from 0 before augmentation to 0.4163 after augmentation. The result shows the effect of using data augmentation to increase the dataset size on the classification and segmentation performance.

Paper number 75:
Title: Improving Lesion Segmentation in Medical Images by Global and Regional Feature Compensation
Authors: Chuhan Wang, Zhenghao Chen, Jean Y. H. Yang, Jinman Kim
Abstract: Automated lesion segmentation of medical images has made tremendous improvements in recent years due to deep learning advancements. However, accurately capturing fine-grained global and regional feature representations remains a challenge. Many existing methods obtain suboptimal performance on complex lesion segmentation due to information loss during typical downsampling operations and the insufficient capture of either regional or global features. To address these issues, we propose the Global and Regional Compensation Segmentation Framework (GRCSF), which introduces two key innovations: the Global Compensation Unit (GCU) and the Region Compensation Unit (RCU). The proposed GCU addresses resolution loss in the U-shaped backbone by preserving global contextual features and fine-grained details during multiscale downsampling. Meanwhile, the RCU introduces a self-supervised learning (SSL) residual map generated by Masked Autoencoders (MAE), obtained as pixel-wise differences between reconstructed and original images, to highlight regions with potential lesions. These SSL residual maps guide precise lesion localization and segmentation through a patch-based cross-attention mechanism that integrates regional spatial and pixel-level features. Additionally, the RCU incorporates patch-level importance scoring to enhance feature fusion by leveraging global spatial information from the backbone. Experiments on two publicly available medical image segmentation datasets, including brain stroke lesion and coronary artery calcification datasets, demonstrate that our GRCSF outperforms state-of-the-art methods, confirming its effectiveness across diverse lesion types and its potential as a generalizable lesion segmentation solution.

Paper number 76:
Title: An Active Dry-Contact Continuous EEG Monitoring System for Seizure Detection Applications in Clinical Neurophysiology
Authors: Nima L. Wickramasinghe, Dinuka Sandun Udayantha, Akila Abeyratne, Kavindu Weerasinghe, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya
Abstract: Objective: Young children and infants, especially newborns, are highly susceptible to seizures, which, if undetected and untreated, can lead to severe long-term neurological consequences. Early detection typically requires continuous electroencephalography (cEEG) monitoring in hospital settings, involving costly equipment and highly trained specialists. This study presents a low-cost, active dry-contact electrode-based, adjustable electroencephalography (EEG) headset, combined with an explainable deep learning model for seizure detection from reduced-montage EEG, and a multimodal artifact removal algorithm to enhance signal quality. Methods: EEG signals were acquired via active electrodes and processed through a custom-designed analog front end for filtering and digitization. The adjustable headset was fabricated using three-dimensional printing and laser cutting to accommodate varying head sizes. The deep learning model was trained to detect neonatal seizures in real time, and a dedicated multimodal algorithm was implemented for artifact removal while preserving seizure-relevant information. System performance was evaluated in a representative clinical setting on a pediatric patient with absence seizures, with simultaneous recordings obtained from the proposed device and a commercial wet-electrode cEEG system for comparison. Results: Signals from the proposed system exhibited a correlation coefficient exceeding 0.8 with those from the commercial device. Signal-to-noise ratio analysis indicated noise mitigation performance comparable to the commercial system. The deep learning model achieved accuracy and recall improvements of 2.76% and 16.33%, respectively, over state-of-the-art approaches. The artifact removal algorithm effectively identified and eliminated noise while preserving seizure-related EEG features.

Paper number 77:
Title: Deep learning-derived arterial input function for dynamic brain PET
Authors: Junyu Chen, Zirui Jiang, Jennifer M. Coughlin, Ian Cheong, Kelly A. Mills, Martin G. Pomper, Yong Du
Abstract: Dynamic positron emission tomography (PET) imaging combined with radiotracer kinetic modeling is a powerful technique for visualizing biological processes in the brain, offering valuable insights into brain functions and neurological disorders such as Alzheimer's and Parkinson's diseases. Accurate kinetic modeling relies heavily on the use of a metabolite-corrected arterial input function (AIF), which typically requires invasive and labor-intensive arterial blood sampling. While alternative non-invasive approaches have been proposed, they often compromise accuracy or still necessitate at least one invasive blood sampling. In this study, we present the deep learning-derived arterial input function (DLIF), a deep learning framework capable of estimating a metabolite-corrected AIF directly from dynamic PET image sequences without any blood sampling. We validated DLIF using existing dynamic PET patient data. We compared DLIF and resulting parametric maps against ground truth measurements. Our evaluation shows that DLIF achieves accurate and robust AIF estimation. By leveraging deep learning's ability to capture complex temporal dynamics and incorporating prior knowledge of typical AIF shapes through basis functions, DLIF provides a rapid, accurate, and entirely non-invasive alternative to traditional AIF measurement methods.

Paper number 78:
Title: Multi-Symbol Digital AirComp via Modulation Design and Power Adaptation
Authors: Xiaojing Yan, Saeed Razavikia, Carlo Fischione
Abstract: Recently, over-the-air computation (AirComp) leverages the superposition property of wireless channels to enable efficient function computation over a multiple access channel (MAC). However, existing digital AirComp methods either rely on single-symbol modulation, which limits flexibility and robustness, or on multi-symbol extensions that suffer from high complexity or approximation errors. To overcome these limitations, we propose a new multi-symbol modulation framework, termed sequential modulation for AirComp (SeMAC), which encodes each input into a sequence of symbols with distinct constellation diagrams across multiple time slots. This approach increases design flexibility and robustness against channel noise. Specifically, the modulation design is formulated as a non-convex optimization problem and efficiently solved through a successive convex approximation (SCA) combined with stochastic subgradient descent (SSD). For fixed modulation formats, we further develop SeMAC with power adaptation (SeMAC-PA) to adjusts transmit power and phase while preserving the modulation structure. Notably, numerical results show that SeMAC improves computation accuracy by up to 14 dB compared to the existing methods for computing nonlinear functions such as the product function.

Paper number 79:
Title: Time-Frequency Mode Decomposition: A Morphological Segmentation Framework for Signal Analysis and Its Application
Authors: Wei Zhou, Wei-Jian Li, Desen Zhu, Hongbin Xu, Wei-Xin Ren
Abstract: While time-frequency analysis provides rich representations of multicomponent signals, current decomposition methods often overlook the morphological structure where components manifest as distinct regions. This study introduces time-frequency mode decomposition (TFMD), a novel framework that formulates signal decomposition as a generalized morphological segmentation problem within the continuous phase space. TFMD establishes an operator-theoretic framework utilizing the short-time Fourier transform as a canonical tight frame. The methodology employs unsupervised k-means clustering to identify high-energy pixels, followed by connected component labeling to establish core regions. A novel iterative competitive dilation algorithm is then applied to expand these core regions to recover the full support of each mode and define its specific time-frequency mask for mode reconstruction. This approach automatically determines the number of components without prior specification while strictly enforcing mutual exclusivity between modes. Comprehensive numerical investigations demonstrate TFMD's superior reconstruction fidelity, noise robustness, and computational efficiency compared to benchmark methods. TFMD achieves the lowest individual mode errors across diverse non-stationary signals and secures the second-best runtime. Practical validation through wind turbine vibration analysis confirms TFMD's ability to isolate both dominant fundamental frequencies and weaker harmonic components across discrete operational states, overcoming limitations of mode splitting and mixing issues observed in benchmark methods.

Paper number 80:
Title: FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems
Authors: Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun
Abstract: We present FMPlug, a novel plug-in framework that enhances foundation flow-matching (FM) priors for solving ill-posed inverse problems. Unlike traditional approaches that rely on domain-specific or untrained priors, FMPlug smartly leverages two simple but powerful insights: the similarity between observed and desired objects and the Gaussianity of generative flows. By introducing a time-adaptive warm-up strategy and sharp Gaussianity regularization, FMPlug unlocks the true potential of domain-agnostic foundation models. Our method beats state-of-the-art methods that use foundation FM priors by significant margins, on image super-resolution and Gaussian deblurring.

Paper number 81:
Title: LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation
Authors: Cristian Minoccheri, Matthew Hodgman, Haoyuan Ma, Rameez Merchant, Emily Wittrup, Craig Williamson, Kayvan Najarian
Abstract: Aneurysmal subarachnoid hemorrhage (SAH) is a life-threatening neurological emergency with mortality rates exceeding 30%. Transfer learning from related hematoma types represents a potentially valuable but underexplored approach. Although Unet architectures remain the gold standard for medical image segmentation due to their effectiveness on limited datasets, Low-Rank Adaptation (LoRA) methods for parameter-efficient transfer learning have been rarely applied to convolutional neural networks in medical imaging contexts. We implemented a Unet architecture pre-trained on computed tomography scans from 124 traumatic brain injury patients across multiple institutions, then fine-tuned on 30 aneurysmal SAH patients from the University of Michigan Health System using 3-fold cross-validation. We developed a novel CP-LoRA method based on tensor CP-decomposition and introduced DoRA variants (DoRA-C, convDoRA, CP-DoRA) that decompose weight matrices into magnitude and directional components. We compared these approaches against existing LoRA methods (LoRA-C, convLoRA) and standard fine-tuning strategies across different modules on a multi-view Unet model. LoRA-based methods consistently outperformed standard Unet fine-tuning. Performance varied by hemorrhage volume, with all methods showing improved accuracy for larger volumes. CP-LoRA achieved comparable performance to existing methods while using significantly fewer parameters. Over-parameterization with higher ranks consistently yielded better performance than strictly low-rank adaptations. This study demonstrates that transfer learning between hematoma types is feasible and that LoRA-based methods significantly outperform conventional Unet fine-tuning for aneurysmal SAH segmentation.

Paper number 82:
Title: Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems
Authors: Pedro H. C. de Souza (1), Luiz A. M. Pereira (1), Faustino R. Gómez (1), Elsa M. Materón (1), Jorge Ricardo Mejía-Salazar (1) ((1) National Institute of Telecommunications)
Abstract: Ongoing discussions about the future of wireless communications are reaching a turning point as standardization activities for the sixth generation of mobile networks (6G) become more mature. New technologies must now face renewed scrutiny by the industry and academia in order to be ready for deployment in the near future. Recently, reconfigurable intelligent surfaces (RISs) gained attention as a promising solution for improving the propagation conditions of signal transmission in general. The RIS is a planar array of tunable resonant elements designed to dynamically and precisely manipulate the reflection of incident electromagnetic waves. However, the physical structure of the RIS and its components may be subject to practical limitations and imperfections. It is imperative that the hardware imperfections (HWIs) associated with the RIS be analyzed, so that it remains a feasible technology from a practical standpoint. Moreover, solutions for mitigating the HWIs must be considered, as is discussed in this work. More specifically, we introduce a gradient descent optimization for mitigating HWIs in RIS-aided wideband communication systems. Numerical results show that the proposed optimization is able to compensate for HWIs such as the phase-shift noise (PSN) and RIS surface deformations.

Paper number 83:
Title: Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization
Authors: Yunpu Zhang, Changsheng You, Hing Cheung So, Dusit Niyato, Yonina C. Eldar
Abstract: In this paper, we propose to leverage rotatable antennas (RAs) for improving the communication performance in mixed near-field and far-field communication systems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna rotation to mitigate complex near-field interference and mixed-field interference. Specifically, we investigate a modular RA-enabled mixed-field downlink communication system, where a base station (BS) consisting of multiple RA subarrays communicates with multiple near-field users in the presence of several legacy far-field users. We formulate an optimization problem to maximize the sum-rate of the near-field users by jointly optimizing the power allocation and rotation angles of all subarrays at the BS. To gain useful insights into the effect of RAs on mixed-field communications, we first analyze a special case where all subarrays share the same rotation angle and obtain closed-form expressions for the rotation-aware normalized near-field interference and the rotation-aware normalized mixed-field interference using the Fresnel integrals. We then analytically reveal that array rotation effectively suppresses both interference types, thereby significantly enhancing mixed-field communication performance. For the general case involving subarray-wise rotation, we propose an efficient double-layer algorithm to obtain a high-quality solution, where the inner layer optimizes power allocation using the successive convex approximation (SCA) technique, while the outer layer determines the rotation angles of all subarrays via particle swarm optimization (PSO). Finally, numerical results highlight the significant performance gains achieved by RAs over conventional fixed-antenna systems and demonstrate the effectiveness of our developed joint design compared to benchmark schemes.

Paper number 84:
Title: CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models
Authors: Karim Kadry, Shoaib Goraya, Ajay Manicka, Abdalla Abdelwahed, Naravich Chutisilp, Farhad Nezami, Elazer Edelman
Abstract: Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.

Paper number 85:
Title: Optimization of High-Order Quarter-Wave Plate for Residual Birefringence Suppression in FOCS
Authors: Yuechen Liu, Boqi Meng
Abstract: Fiber optic current sensors (FOCS) are widely adopted in modern power grids due to high sensitivity, excellent insulation, and strong immunity to electromagnetic interference. This prominence necessitates precise investigation into their error sources and corresponding optimization. This study examines reflective FOCS based on the Faraday effect. A theoretical model is established to simulate phase error caused by linear birefringence from the quarter-wave plate. Conventional methods using circular birefringence are analyzed, revealing inherent limitations. Innovatively, a compensation strategy employing high-order quarter-wave plates is proposed to effectively eliminate linear birefringence effects. This approach significantly enhances the accuracy and practicality of FOCS in precision metrology.

Paper number 86:
Title: AnyPPG: An ECG-Guided PPG Foundation Model Trained on Over 100,000 Hours of Recordings for Holistic Health Profiling
Authors: Guangkun Nie, Gongzheng Tang, Yujie Xiao, Jun Li, Shun Huang, Deyun Zhang, Qinghao Zhao, Shenda Hong
Abstract: Background: Photoplethysmography (PPG) offers a noninvasive and accessible modality for health monitoring beyond clinical settings. However, existing studies are limited by the scale and diversity of labeled data, constraining model accuracy, generalizability, and the exploration of broader applications. This study investigates the potential of PPG for holistic health profiling through the integration of foundation model techniques. Methods: We present AnyPPG, a PPG foundation model pretrained on large-scale, multi-source synchronized PPG-ECG data. By aligning PPG and ECG representations within a shared space, AnyPPG learns physiologically meaningful features from unlabeled signals. Its capability was further evaluated across a diverse set of downstream tasks, encompassing both conventional physiological analysis and comprehensive multi-organ disease diagnosis. Results: Across eleven physiological analysis tasks spanning six independent datasets, AnyPPG achieved state-of-the-art performance, with average improvements of 12.8% in regression and 9.1% in classification tasks over the next-best model. In multi-organ disease diagnosis, AnyPPG demonstrated broad cross-system diagnostic potential. Among 1,014 ICD-10 three-digit disease categories, 13 achieved an AUC above 0.8 and 137 exceeded 0.7. Beyond strong performance in cardiovascular diseases such as heart failure, valvular disorders, and hypertension, AnyPPG also showed substantial diagnostic value for non-cardiovascular conditions, exemplified by Parkinson's disease (AUC = 0.78) and chronic kidney disease (AUC = 0.74). Conclusions: AnyPPG demonstrates that a PPG foundation model trained through physiological alignment with ECG can produce accurate and robust signal representations. Building on this capability, it underscores the potential of PPG as a modality for comprehensive assessment of systemic and multi-organ health.

Paper number 87:
Title: Disentangled Control of Multi-Agent Systems
Authors: Ruoyu Lin, Gennaro Notomista, Magnus Egerstedt
Abstract: This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments.

Paper number 88:
Title: A Visual Perception-Based Tunable Framework and Evaluation Benchmark for H.265/HEVC ROI Encryption
Authors: Xiang Zhang, Geng Wu, Wenbin Huang, Daoyong Fu, Fei Peng, Zhangjie Fu
Abstract: ROI selective encryption, as an efficient privacy protection technique, encrypts only the key regions in the video, thereby ensuring security while minimizing the impact on coding efficiency. However, existing ROI-based video encryption methods suffer from insufficient flexibility and lack of a unified evaluation system. To address these issues, we propose a visual perception-based tunable framework and evaluation benchmark for H.265/HEVC ROI encryption. Our scheme introduces three key contributions: 1) A ROI region recognition module based on visual perception network is proposed to accurately identify the ROI region in videos. 2) A three-level tunable encryption strategy is implemented while balancing security and real-time performance. 3) A unified ROI encryption evaluation benchmark is developed to provide a standardized quantitative platform for subsequent research. This triple strategy provides new solution and significant unified performance evaluation methods for ROI selective encryption field. Experimental results indicate that the proposed benchmark can comprehensively measure the performance of the ROI selective encryption. Compared to existing ROI encryption algorithms, our proposed enhanced and advanced level encryption exhibit superior performance in multiple performance metrics. In general, the proposed framework effectively meets the privacy protection requirements in H.265/HEVC and provides a reliable solution for secure and efficient processing of sensitive video content.

Paper number 89:
Title: Computable Characterisations of Scaled Relative Graphs of Closed Operators
Authors: Talitha Nauta, Richard Pates
Abstract: Scaled Relative Graphs (SRGs) provide a promising tool for stability and robustness analysis of multi-input-multi-output systems. In this paper, we provide tools for exact and computable constructions of the SRG for closed linear operators, based on maximum and minimum gain computations. The results are suitable for bounded and unbounded operators, and we specify how they can be used to draw SRGs for the typical operators that are used to model linear-time-invariant dynamical systems. Furthermore, for the special case of state-space models, we show how the Bounded Real Lemma can be used to construct the SRG.

Paper number 90:
Title: Multimodal Optical Imaging Platform for Quantitative Burn Assessment
Authors: Nathaniel Hanson, Mateusz Wolak, Jonathan Richardson, Patrick Walker, David M. Burmeister, Chakameh Jafari
Abstract: Accurate assessment of burn severity at injury onset remains a major clinical challenge due to the lack of objective methods for detecting subsurface tissue damage. This limitation is critical in battlefield and mass-casualty settings, where rapid and reliable evaluation of burn depth is essential for triage and surgical decision-making. We present a multimodal optical imaging framework that establishes the foundation for a compact, low-size, weight, and power (low-SWaP) field-deployable device for quantitative burn assessment. The system integrates broadband hyperspectral imaging (VSWIR, 400 -- 2100 nm) with laser speckle contrast imaging to jointly evaluate biochemical composition and microvascular perfusion. Using short-wave infrared (SWIR, >1000 nm) wavelengths, we developed and validated novel deep-tissue parameters linked to water, lipid, and collagen absorption features that enhance burn-tissue separability and burn severity classification. We implemented and validated unsupervised learning methods for spectral feature extraction, band down-selection, and clustering against histology, establishing a foundation for a rugged, data-driven device for early quantitative burn evaluation in austere environments.

Paper number 91:
Title: OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation
Authors: Qi Jiang, Xiaolong Qian, Yao Gao, Lei Sun, Kailun Yang, Zhonghua Yi, Wenyong Li, Ming-Hsuan Yang, Luc Van Gool, Kaiwei Wang
Abstract: Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at this https URL.

Paper number 92:
Title: BeamCKM: A Framework of Channel Knowledge Map Construction for Multi-Antenna Systems
Authors: Haohan Wang, Xu Shi, Hengyu Zhang, Yashuai Cao, Sufang Yang, Jintao Wang, Kaibin Huang
Abstract: The channel knowledge map (CKM) enables efficient construction of high-fidelity mapping between spatial environments and channel parameters via electromagnetic information analysis. Nevertheless, existing studies are largely confined to single-antenna systems, failing to offer dedicated guidance for multi-antenna communication scenarios. To address the inherent conflict between traditional real-value pathloss map and multi-degree-of-freedom (DoF) coherent beamforming in B5G/6G systems, this paper proposes a novel concept of BeamCKM and CKMTransUNet architecture. The CKMTransUNet approach combines a UNet backbone for multi-scale feature extraction with a vision transformer (ViT) module to capture global dependencies among encoded linear vectors, utilizing a composite loss function to characterize the beam propagation characteristics. Furthermore, based on the CKMTransUNet backbone, this paper presents a methodology named M3ChanNet. It leverages the multi-modal learning technique and cross-attention mechanisms to extract intrinsic side information from environmental profiles and real-time multi-beam observations, thereby further improving the map construction accuracy. Simulation results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) interpolation methods and deep learning (DL) approaches, delivering superior performance even when environmental contours are inaccurate. For reproducibility, the code is publicly accessible at this https URL.

Paper number 93:
Title: Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic Lesion Segmentation
Authors: Gia Huy Thai, Hoang-Nguyen Vu, Anh-Minh Phan, Quang-Thinh Ly, Tram Dinh, Thi-Ngoc-Truc Nguyen, Nhat Ho
Abstract: The substantial diversity in cell scale and form remains a primary challenge in computer-aided cancer detection on gigapixel Whole Slide Images (WSIs), attributable to cellular heterogeneity. Existing CNN-Transformer hybrids rely on static computation graphs with fixed routing, which consequently causes redundant computation and limits their adaptability to input variability. We propose Shape-Adapting Gated Experts (SAGE), an input-adaptive framework that enables dynamic expert routing in heterogeneous visual networks. SAGE reconfigures static backbones into dynamically routed expert architectures. SAGE's dual-path design features a backbone stream that preserves representation and selectively activates an expert path through hierarchical gating. This gating mechanism operates at multiple hierarchical levels, performing a two-level, hierarchical selection between shared and specialized experts to modulate model logits for Top-K activation. Our Shape-Adapting Hub (SA-Hub) harmonizes structural and semantic representations across the CNN and the Transformer module, effectively bridging diverse modules. Embodied as SAGE-UNet, our model achieves superior segmentation on three medical benchmarks: EBHI, DigestPath, and GlaS, yielding state-of-the-art Dice Scores of 95.57%, 95.16%, and 94.17%, respectively, and robustly generalizes across domains by adaptively balancing local refinement and global context. SAGE provides a scalable foundation for dynamic expert routing, enabling flexible visual reasoning.

Paper number 94:
Title: SafePR: Unified Approach for Safe Parallel Robots by Contact Detection and Reaction with Redundancy Resolution
Authors: Aran Mohammad, Tim-Lukas Habich, Thomas Seel, Moritz Schappler
Abstract: Fast and safe motion is crucial for the successful deployment of physically interactive robots. Parallel robots (PRs) offer the potential for higher speeds while maintaining the same energy limits due to their low moving masses. However, they require methods for contact detection and reaction while avoiding singularities and self-collisions. We address this issue and present SafePR - a unified approach for the detection and localization, including the distinction between collision and clamping to perform a reaction that is safe for humans and feasible for PRs. Our approach uses information from the encoders and motor currents to estimate forces via a generalized-momentum observer. Neural networks and particle filters classify and localize the contacts. We introduce reactions with redundancy resolution to avoid self-collisions and type-II singularities. Our approach detected and terminated 72 real-world collision and clamping contacts with end-effector speeds of up to 1.5 m/s, each within 25-275 ms. The forces were below the thresholds from ISO/TS 15066. By using built-in sensors, SafePR enables safe interaction with already assembled PRs without the need for new hardware components.

Paper number 95:
Title: Learning Hierarchical Sparse Transform Coding of 3DGS
Authors: Hao Xu, Xiaolin Wu, Xi Zhang
Abstract: 3D Gaussian Splatting (3DGS) supports fast, high quality, novel view synthesis but has a heavy memory footprint, making the compression of its model crucial. Current state-of-the-art (SOTA) 3DGS compression methods adopt an anchor-based architecture that pairs the Scaffold-GS representation with conditional entropy coding. However, these methods forego the analysis-synthesis transform, a vital mechanism in visual data compression. As a result, redundancy remains intact in the signal and its removal is left to the entropy coder, which computationally overburdens the entropy coding module, increasing coding latency. Even with added complexity thorough redundancy removal is a task unsuited to an entropy coder. To fix this critical omission, we introduce a Sparsity-guided Hierarchical Transform Coding (SHTC) method, the first study on the end-to-end learned neural transform coding of 3DGS. SHTC applies KLT to decorrelate intra-anchor attributes, followed by quantization and entropy coding, and then compresses KLT residuals with a low-complexity, scene-adaptive neural transform. Aided by the sparsity prior and deep unfolding technique, the learned transform uses only a few trainable parameters, reducing the memory usage. Overall, SHTC achieves an appreciably improved R-D performance and at the same time higher decoding speed over SOTA. Its prior-guided, parameter-efficient design may also inspire low-complexity neural image and video codecs. Our code will be released at this https URL.

Paper number 96:
Title: Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis
Authors: Weichien Liao
Abstract: High-throughput imaging workflows, such as Parallel Rapid Imaging with Spectroscopic Mapping (PRISM), generate data at rates that exceed conventional real-time processing capabilities. We present a scalable FPGA-based preprocessing pipeline for real-time denoising, implemented via High-Level Synthesis (HLS) and optimized for DRAM-backed buffering. Our architecture performs frame subtraction and averaging directly on streamed image data, minimizing latency through burst-mode AXI4 interfaces. The resulting kernel operates below the inter-frame interval, enabling inline denoising and reducing dataset size for downstream CPU/GPU analysis. Validated under PRISM-scale acquisition, this modular FPGA framework offers a practical solution for latency-sensitive imaging workflows in spectroscopy and microscopy.

Paper number 97:
Title: Lessons Learned from Developing a Privacy-Preserving Multimodal Wearable for Local Voice-and-Vision Inference
Authors: Yonatan Tussa, Andy Heredia, Nirupam Roy
Abstract: Many promising applications of multimodal wearables require continuous sensing and heavy computation, yet users reject such devices due to privacy concerns. This paper shares our experiences building an ear-mounted voice-and-vision wearable that performs local AI inference using a paired smartphone as a trusted personal edge. We describe the hardware-software co-design of this privacy-preserving system, including challenges in integrating a camera, microphone, and speaker within a 30-gram form factor, enabling wake word-triggered capture, and running quantized vision-language and large-language models entirely offline. Through iterative prototyping, we identify key design hurdles in power budgeting, connectivity, latency, and social acceptability. Our initial evaluation shows that fully local multimodal inference is feasible on commodity mobile hardware with interactive latency. We conclude with design lessons for researchers developing embedded AI systems that balance privacy, responsiveness, and usability in everyday settings.

Paper number 98:
Title: Design of A Low-Latency and Parallelizable SVD Dataflow Architecture on FPGA
Authors: Fangqiang Du, Sixuan Chong, Zixuan Huang, Rui Qin, Fengnan Mi, Caibao Hu, Jiangang Chen
Abstract: Singular value decomposition (SVD) is widely used for dimensionality reduction and noise suppression, and it plays a pivotal role in numerous scientific and engineering applications. As the dimensions of the matrix grow rapidly, the computational cost increases significantly, posing a serious challenge to the efficiency of data analysis and signal processing systems, especially in time-sensitive scenarios involving large-scale datasets. Although various dedicated hardware architectures have been proposed to accelerate the computation of intensive SVD, many of these designs suffer from limited scalability and high consumption of on-chip memory resources. Moreover, they typically overlook the computational and data transfer challenges associated with SVD, making them unsuitable for real-time processing of large-scale data stream matrices in embedded systems. In this paper, we propose a Data Stream-Based SVD processing algorithm (DSB Jacobi), which significantly reduces on-chip BRAM usage while improving computational speed, offering a practical solution for real-time SVD computation of large-scale data streams. Compared to previous works, our experimental results indicate that the proposed method reduces on-chip RAM consumption by 41.5 percent and improves computational efficiency by a factor of 23.

Paper number 99:
Title: PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation
Authors: Huadai Liu, Kaicheng Luo, Wen Wang, Qian Chen, Peiwen Sun, Rongjie Huang, Xiangang Li, Jieping Ye, Wei Xue
Abstract: Video-to-Audio (V2A) generation requires balancing four critical perceptual dimensions: semantic consistency, audio-visual temporal synchrony, aesthetic quality, and spatial accuracy; yet existing methods suffer from objective entanglement that conflates competing goals in single loss functions and lack human preference alignment. We introduce PrismAudio, the first framework to integrate Reinforcement Learning into V2A generation with specialized Chain-of-Thought (CoT) planning. Our approach decomposes monolithic reasoning into four specialized CoT modules (Semantic, Temporal, Aesthetic, and Spatial CoT), each paired with targeted reward functions. This CoT-reward correspondence enables multidimensional RL optimization that guides the model to jointly generate better reasoning across all perspectives, solving the objective entanglement problem while preserving interpretability. To make this optimization computationally practical, we propose Fast-GRPO, which employs hybrid ODE-SDE sampling that dramatically reduces the training overhead compared to existing GRPO implementations. We also introduce AudioCanvas, a rigorous benchmark that is more distributionally balanced and covers more realistically diverse and challenging scenarios than existing datasets, with 300 single-event classes and 501 multi-event samples. Experimental results demonstrate that PrismAudio achieves state-of-the-art performance across all four perceptual dimensions on both the in-domain VGGSound test set and out-of-domain AudioCanvas benchmark. The project page is available at this https URL.
    