
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Diffusion models applied to skin and oral cancer classification
Authors: José J. M. Uliana, Renato A. Krohling
Abstract: This study investigates the application of diffusion models in medical image classification (DiffMIC), focusing on skin and oral lesions. Utilizing the datasets PAD-UFES-20 for skin cancer and P-NDB-UFES for oral cancer, the diffusion model demonstrated competitive performance compared to state-of-the-art deep learning models like Convolutional Neural Networks (CNNs) and Transformers. Specifically, for the PAD-UFES-20 dataset, the model achieved a balanced accuracy of 0.6457 for six-class classification and 0.8357 for binary classification (cancer vs. non-cancer). For the P-NDB-UFES dataset, it attained a balanced accuracy of 0.9050. These results suggest that diffusion models are viable models for classifying medical images of skin and oral lesions. In addition, we investigate the robustness of the model trained on PAD-UFES-20 for skin cancer but tested on the clinical images of the HIBA dataset.

Paper number 2:
Title: Set-based state estimation of nonlinear discrete-time systems using constrained zonotopes and polyhedral relaxations
Authors: Brenner S. Rego, Guilherme V. Raffo, Marco H. Terra, Joseph K. Scott
Abstract: This paper presents a new algorithm for set-based state estimation of nonlinear discrete-time systems with bounded uncertainties. The novel method builds upon essential properties and computational advantages of constrained zonotopes (CZs) and polyhedral relaxations of factorable representations of nonlinear functions to propagate CZs through nonlinear functions, which is usually done using conservative linearization in the literature. The new method also refines the propagated enclosure using nonlinear measurements. To achieve this, a lifted polyhedral relaxation is computed for the composite nonlinear function of the system dynamics and measurement equations, in addition to incorporating the measured output through equality constraints. Polyhedral relaxations of trigonometric functions are enabled for the first time, allowing to address a broader class of nonlinear systems than our previous works. Additionally, an approach to obtain an equivalent enclosure with fewer generators and constraints is developed. Thanks to the advantages of the polyhedral enclosures based on factorable representations, the new state estimation method provides better approximations than those resulting from linearization procedures. This led to significant improvements in the computation of convex sets enclosing the system states consistent with measured outputs. Numerical examples highlight the advantages of the novel algorithm in comparison to existing CZ methods based on the Mean Value Theorem and DC programming principles.

Paper number 3:
Title: Data-driven Power Loss Identification through Physics-Based Thermal Model Backpropagation
Authors: Mattia Scarpa, Francesco Pase, Ruggero Carli, Mattia Bruschetta, Franscesco Toso
Abstract: Digital twins for power electronics require accurate power losses whose direct measurements are often impractical or impossible in real-world applications. This paper presents a novel hybrid framework that combines physics-based thermal modeling with data-driven techniques to identify and correct power losses accurately using only temperature measurements. Our approach leverages a cascaded architecture where a neural network learns to correct the outputs of a nominal power loss model by backpropagating through a reduced-order thermal model. We explore two neural architectures, a bootstrapped feedforward network, and a recurrent neural network, demonstrating that the bootstrapped feedforward approach achieves superior performance while maintaining computational efficiency for real-time applications. Between the interconnection, we included normalization strategies and physics-guided training loss functions to preserve stability and ensure physical consistency. Experimental results show that our hybrid model reduces both temperature estimation errors (from 7.2+-6.8°C to 0.3+-0.3°C) and power loss prediction errors (from 5.4+-6.6W to 0.2+-0.3W) compared to traditional physics-based approaches, even in the presence of thermal model uncertainties. This methodology allows us to accurately estimate power losses without direct measurements, making it particularly helpful for real-time industrial applications where sensor placement is hindered by cost and physical limitations.

Paper number 4:
Title: Performance analysis of metasurface-based spatial multimode transmission for 6G wireless communications
Authors: Ju Yong Lee, Seung-Won Keum, Sang Min Oh, Dang-Oh Kim, Dong-Ho Cho
Abstract: In 6th generation wireless communication technology, it is important to utilize space resources efficiently. Recently, holographic multiple-input multiple-output (HMIMO) and meta-surface technology have attracted attention as technologies that maximize space utilization for 6G mobile communications. However, studies on HMIMO communications are still in an initial stage and its fundamental limits are yet to be unveiled. It is well known that the Fourier transform relationship can be obtained using a lens in the optical field, but research to apply it to the mobile communication field is in the early stages. In this paper, we show that the Fourier transform relationship between signals can be obtained when two metasurfaces are aligned or unaligned, and analyze the transmission and reception power, and the maximum number of spatial multimodes that can be transmitted. In addition, to reduce transmission complexity, we propose a spatial multimode transmission system using three metasurfaces and analyze signal characteristics on the meta-surfaces. In numerical results, we provide the performance of spatial multimode transmission in case of using rectangular and Gaussian signals.

Paper number 5:
Title: Nuclear Microreactor Control with Deep Reinforcement Learning
Authors: Leo Tunkle, Kamal Abdulraheem, Linyu Lin, Majdi I. Radaideh
Abstract: The economic feasibility of nuclear microreactors will depend on minimizing operating costs through advancements in autonomous control, especially when these microreactors are operating alongside other types of energy systems (e.g., renewable energy). This study explores the application of deep reinforcement learning (RL) for real-time drum control in microreactors, exploring performance in regard to load-following scenarios. By leveraging a point kinetics model with thermal and xenon feedback, we first establish a baseline using a single-output RL agent, then compare it against a traditional proportional-integral-derivative (PID) controller. This study demonstrates that RL controllers, including both single- and multi-agent RL (MARL) frameworks, can achieve similar or even superior load-following performance as traditional PID control across a range of load-following scenarios. In short transients, the RL agent was able to reduce the tracking error rate in comparison to PID. Over extended 300-minute load-following scenarios in which xenon feedback becomes a dominant factor, PID maintained better accuracy, but RL still remained within a 1% error margin despite being trained only on short-duration scenarios. This highlights RL's strong ability to generalize and extrapolate to longer, more complex transients, affording substantial reductions in training costs and reduced overfitting. Furthermore, when control was extended to multiple drums, MARL enabled independent drum control as well as maintained reactor symmetry constraints without sacrificing performance -- an objective that standard single-agent RL could not learn. We also found that, as increasing levels of Gaussian noise were added to the power measurements, the RL controllers were able to maintain lower error rates than PID, and to do so with less control effort.

Paper number 6:
Title: Exact local recovery for Chemical Shift Imaging
Authors: Cristobal Arrieta, Carlos A. Sing Long
Abstract: Chemical Shift Imaging (CSI) or Chemical Shift Encoded Magnetic Resonance Imaging (CSE-MRI) enables the quantification of different chemical species in the human body, and it is one of the most widely used imaging modalities used to quantify fat in the human body. Although there have been substantial improvements in the design of signal acquisition protocols and the development of a variety of methods for the recovery of parameters of interest from the measured signal, it is still challenging to obtain a consistent and reliable quantification over the entire field of view. In fact, there are still discrepancies in the quantities recovered by different methods, and each exhibits a different degree of sensitivity to acquisition parameters such as the choice of echo times. Some of these challenges have their origin in the signal model itself. In particular, it is non-linear, and there may be different sets of parameters of interest compatible with the measured signal. For this reason, a thorough analysis of this model may help mitigate some of the remaining challenges, and yield insight into novel acquisition protocols. In this work, we perform an analysis of the signal model underlying CSI, focusing on finding suitable conditions under which recovery of the parameters of interest is possible. We determine the sources of non-identifiability of the parameters, and we propose a reconstruction method based on smooth non-convex optimization under convex constraints that achieves exact local recovery under suitable conditions. A surprising result is that the concentrations of the chemical species in the sample may be identifiable even when other parameters are not. We present numerical results illustrating how our theoretical results may help develop novel acquisition techniques, and showing how our proposed recovery method yields results comparable to the state-of-the-art.

Paper number 7:
Title: Detecting Glioma, Meningioma, and Pituitary Tumors, and Normal Brain Tissues based on Yolov11 and Yolov8 Deep Learning Models
Authors: Ahmed M. Taha, Salah A. Aly, Mohamed F. Darwish
Abstract: Accurate and quick diagnosis of normal brain tissue Glioma, Meningioma, and Pituitary Tumors is crucial for optimal treatment planning and improved medical results. Magnetic Resonance Imaging (MRI) is widely used as a non-invasive diagnostic tool for detecting brain abnormalities, including tumors. However, manual interpretation of MRI scans is often time-consuming, prone to human error, and dependent on highly specialized expertise. This paper proposes an advanced AI-driven technique to detecting glioma, meningioma, and pituitary brain tumors using YoloV11 and YoloV8 deep learning models. Methods: Using a transfer learning-based fine-tuning approach, we integrate cutting-edge deep learning techniques with medical imaging to classify brain tumors into four categories: No-Tumor, Glioma, Meningioma, and Pituitary Tumors. Results: The study utilizes the publicly accessible CE-MRI Figshare dataset and involves fine-tuning pre-trained models YoloV8 and YoloV11 of 99.49% and 99.56% accuracies; and customized CNN accuracy of 96.98%. The results validate the potential of CNNs in achieving high precision in brain tumor detection and classification, highlighting their transformative role in medical imaging and diagnostics.

Paper number 8:
Title: Output-feedback model predictive control under dynamic uncertainties using integral quadratic constraints
Authors: Lukas Schwenkel, Johannes Köhler, Matthias A. Müller, Frank Allgöwer
Abstract: In this work, we propose an output-feedback tube-based model predictive control (MPC) scheme for linear systems under dynamic uncertainties that are described via integral quadratic constraints (IQC). By leveraging IQCs, a large class of nonlinear and dynamic uncertainties can be addressed. We leverage recent IQC synthesis tools to design a dynamic controller and an observer that are robust to these uncertainties and minimize the size of the resulting constraint tightening in the MPC. Thereby, we show that the robust estimation problem using IQCs with peak-to-peak performance can be convexified. We guarantee recursive feasibility, robust constraint satisfaction, and input-to-state stability of the resulting MPC scheme.

Paper number 9:
Title: Distributed Model Predictive Control for Dynamic Cooperation of Multi-Agent Systems
Authors: Matthias Köhler, Matthias A. Müller, Frank Allgöwer
Abstract: We propose a distributed model predictive control (MPC) framework for coordinating heterogeneous, nonlinear multi-agent systems under individual and coupling constraints. The cooperative task is encoded as a shared objective function minimized collectively by the agents. Each agent optimizes an artificial reference as an intermediate step towards the cooperative objective, along with a control input to track it. We establish recursive feasibility, asymptotic stability, and transient performance bounds under suitable assumptions. The solution to the cooperative task is not predetermined but emerges from the optimized interactions of the agents. We demonstrate the framework on numerical examples inspired by satellite constellation control, collision-free narrow passage traversal, and coordinated quadrotor flight.

Paper number 10:
Title: Learning from Disengagements: An Analysis of Safety Driver Interventions during Remote Driving
Authors: Ole Hans, Jürgen Adamy
Abstract: This study investigates disengagements of Remote Driving Systems (RDS) based on interventions by an in-vehicle Safety Drivers (SD) in real-world Operational Design Domains (ODD) with a focus on Remote Driver (RD) performance during their driving training. Based on an analysis of over 14,000 km on remote driving data, the relationship between the driving experience of 25 RD and the frequency of disengagements is systematically investigated. The results show that the number of SD interventions decreases significantly within the first 400 km of driving experience, which illustrates a clear learning curve of the RD. In addition, the most common causes for 183 disengagements analyzed are identified and categorized, whereby four main scenarios for SD interventions were identified and illustrated. The results emphasize the need for experience-based and targeted training programs aimed at developing basic driving skills early on, thereby increasing the safety, controllability and efficiency of RDS, especially in complex urban environment ODDs.

Paper number 11:
Title: DiffDenoise: Self-Supervised Medical Image Denoising with Conditional Diffusion Models
Authors: Basar Demir, Yikang Liu, Xiao Chen, Eric Z. Chen, Lin Zhao, Boris Mailhe, Terrence Chen, Shanhui Sun
Abstract: Many self-supervised denoising approaches have been proposed in recent years. However, these methods tend to overly smooth images, resulting in the loss of fine structures that are essential for medical applications. In this paper, we propose DiffDenoise, a powerful self-supervised denoising approach tailored for medical images, designed to preserve high-frequency details. Our approach comprises three stages. First, we train a diffusion model on noisy images, using the outputs of a pretrained Blind-Spot Network as conditioning inputs. Next, we introduce a novel stabilized reverse sampling technique, which generates clean images by averaging diffusion sampling outputs initialized with a pair of symmetric noises. Finally, we train a supervised denoising network using noisy images paired with the denoised outputs generated by the diffusion model. Our results demonstrate that DiffDenoise outperforms existing state-of-the-art methods in both synthetic and real-world medical image denoising tasks. We provide both a theoretical foundation and practical insights, demonstrating the method's effectiveness across various medical imaging modalities and anatomical structures.

Paper number 12:
Title: On-the-fly Surrogation for Complex Nonlinear Dynamics
Authors: E. Javier Olucha, Rajiv Singh, Amritam Das, Roland Tóth
Abstract: High-fidelity models are essential for accurately capturing nonlinear system dynamics. However, simulation of these models is often computationally too expensive and, due to their complexity, they are not directly suitable for analysis, control design or real-time applications. Surrogate modelling techniques seek to construct simplified representations of these systems with minimal complexity, but adequate information on the dynamics given a simulation, analysis or synthesis objective at hand. Despite the widespread availability of system linearizations and the growing computational potential of autograd methods, there is no established approach that systematically exploits them to capture the underlying global nonlinear dynamics. This work proposes a novel surrogate modelling approach that can efficiently build a global representation of the dynamics on-the-fly from local system linearizations without ever explicitly computing a model. Using radial basis function interpolation and the second fundamental theorem of calculus, the surrogate model is only computed at its evaluation, enabling rapid computation for simulation and analysis and seamless incorporation of new linearization data. The efficiency and modelling capabilities of the method are demonstrated on simulation examples.

Paper number 13:
Title: Directional excitability in Hilbert spaces
Authors: Gustave Bainier, Alessio Franci
Abstract: We introduce a generalized excitable system in which spikes can happen in a continuum of directions, therefore drastically enriching the expressivity and control capability of the spiking dynamics. In this generalized excitable system, spiking trajectories happen in a Hilbert space with an excitable resting state at the origin and spike responses that can be triggered in any direction as a function of the system's state and inputs. State-dependence of the spiking direction provide the system with a vanishing spiking memory trace, which enables robust tracking and integration of inputs in the spiking direction history. The model exhibits generalized forms of both Hodgkin's Type I and Type II excitability, capturing their usual bifurcation behaviors in an abstract setting. When used as the controller of a two-dimensional navigation task, this model facilitates both the sparseness of the actuation and its sensitivity to environmental inputs. These results highlight the potential of the proposed generalized excitable model for excitable control in high- and infinite-dimensional spaces.

Paper number 14:
Title: Deconver: A Deconvolutional Network for Medical Image Segmentation
Authors: Pooya Ashtari, Shahryar Noei, Fateme Nateghi Haredasht, Jonathan H. Chen, Giuseppe Jurman, Aleksandra Pizurica, Sabine Van Huffel
Abstract: While convolutional neural networks (CNNs) and vision transformers (ViTs) have advanced medical image segmentation, they face inherent limitations such as local receptive fields in CNNs and high computational complexity in ViTs. This paper introduces Deconver, a novel network that integrates traditional deconvolution techniques from image restoration as a core learnable component within a U-shaped architecture. Deconver replaces computationally expensive attention mechanisms with efficient nonnegative deconvolution (NDC) operations, enabling the restoration of high-frequency details while suppressing artifacts. Key innovations include a backpropagation-friendly NDC layer based on a provably monotonic update rule and a parameter-efficient design. Evaluated across four datasets (ISLES'22, BraTS'23, GlaS, FIVES) covering both 2D and 3D segmentation tasks, Deconver achieves state-of-the-art performance in Dice scores and Hausdorff distance while reducing computational costs (FLOPs) by up to 90% compared to leading baselines. By bridging traditional image restoration with deep learning, this work offers a practical solution for high-precision segmentation in resource-constrained clinical workflows. The project is available at this https URL.

Paper number 15:
Title: Inverted Gaussian Process Optimization for Nonparametric Koopman Operator Discovery
Authors: Abhigyan Majumdar, Navid Mojahed, Shima Nazari
Abstract: The Koopman Operator Theory opens the door for application of rich linear systems theory for computationally efficient modeling and optimal control of nonlinear systems by providing a globally linear representation for complex nonlinear systems. However, methodologies for Koopman Operator discovery struggle with the dependency on the set of selected observable functions and meaningful uncertainty quantification. The primary objective of this work is to leverage Gaussian process regression (GPR) to develop a probabilistic Koopman linear model while removing the need for heuristic observable specification. In this work, we present inverted Gaussian process optimization based Koopman Operator learning (iGPK), an automatic differentiation-based approach to simultaneously learn the observable-operator combination. We show that the proposed iGPK method is robust to observation noise in the training data, while also providing good uncertainty quantification, such that the predicted distribution consistently encapsulates the ground truth, even for noisy training data.

Paper number 16:
Title: Methodology for Detecting Energy Anomalies due to Multi-Replay Attacks on Electric Vehicle Charging Infrastructure
Authors: Sagar Babu Mitikiri, Vedantham Lakshmi Srinivas, Mayukha Pal
Abstract: The increasing deployment of Electric Vehicle Charging Infrastructures (EVCIs) introduces cybersecurity challenges, particularly due to inherent vulnerabilities, making them susceptible to cyberattacks. The vulnerable points in EVCI are charging ports, which serve as the links between the EVs and the EVCI as they transfer the data along with the power. Data spoofing attacks targeting these ports can compromise security, reliability, and overall system performance by introducing anomalies in operational data. An efficient method for identifying the charging port current magnitude variations is presented in this research. The MATLAB/SIMULINK environment simulates an EVCI system for various data generating scenarios. A Temporal Convolution Network - Autoencoder (TCN-AE) model is used in training the multivariate time series data of EVCI and reconstructing it. The abnormalities in data are that various charging port current magnitudes are replaced with their respective data of different durations, thus enabling the replay attack scenarios. To detect anomalies, the error between the original and reconstructed data is computed, and these error values are used for detecting the anomalies. With the help of the mean vector and covariance matrices of the errors, the anomaly score is computed in the form of Mahalanobis distance. The threshold is obtained from the short sub-sequence of the errors and optimized for the whole time series data. The obtained optimal threshold is compared with the anomaly score to detect the anomaly. The model demonstrates robust performance in data reconstruction by identifying anomalies with an accuracy of 99.64%, to enhance the reliability and security in operations of EVCI.

Paper number 17:
Title: A Hybrid Systems Model of Feedback Optimization for Linear Systems
Authors: Oscar Jed Chuy, Matthew Hale, Ricardo Sanfelice
Abstract: Feedback optimization algorithms compute inputs to a system in real time, which helps mitigate the effects of unknown disturbances. However, existing work models both system dynamics and computations in either discrete or continuous time, which does not faithfully model some applications. In this work, we model linear system dynamics in continuous time, and we model the computations of inputs in discrete time. Therefore, we present a novel hybrid systems framework for modeling feedback optimization of linear time-invariant systems that are subject to unknown, constant disturbances. For this setup, we first establish the well-posedness of the hybrid model and establish completeness of solutions while ruling out Zeno behavior. Then, our main result derives a convergence rate and an error bound for the full hybrid computation-in-theloop system and shows that it converges exponentially towards a ball of known radius about a desired fixed point. Simulation results show that this approach successfully mitigates the effects of disturbances, with the magnitude of steady-state error being 81% less than the magnitude of the disturbances in the system.

Paper number 18:
Title: Adaptive Radar Detection in joint Range and Azimuth based on the Hierarchical Latent Variable Model
Authors: Linjie Yan, Chengpeng Hao, Sudan Han, Giuseppe Ricci, Zhanhao Hu, Danilo Orlando
Abstract: This paper focuses on the design of a robust decision scheme capable of operating in target-rich scenarios with unknown signal signatures (including their range positions, angles of arrival, and number) in a background of Gaussian disturbance. To solve the problem at hand, a novel estimation procedure is conceived resorting to the expectation-maximization algorithm in conjunction with the hierarchical latent variable model that are exploited to come up with a maximum \textit{a posteriori} rule for reliable signal classification and angle of arrival estimation. The estimates returned by the procedure are then used to build up an adaptive detection architecture in range and azimuth based on the likelihood ratio test with enhanced detection performance. Remarkably, it is shown that the new decision scheme can maintain constant the false alarm rate when the interference parameters vary in the considered range of values. The performance assessment, conducted by means of Monte Carlo simulation, highlights that the proposed detector exhibits superior detection performance in comparison with the existing GLRT-based competitors.

Paper number 19:
Title: Control Barrier Function Synthesis for Nonlinear Systems with Dual Relative Degree
Authors: Gilbert Bahati, Ryan K. Cosner, Max H. Cohen, Ryan M. Bena, Aaron D. Ames
Abstract: Control barrier functions (CBFs) are a powerful tool for synthesizing safe control actions; however, constructing CBFs remains difficult for general nonlinear systems. In this work, we provide a constructive framework for synthesizing CBFs for systems with dual relative degree -- where different inputs influence the outputs at two different orders of differentiation; this is common in systems with orientation-based actuation, such as unicycles and quadrotors. In particular, we propose dual relative degree CBFs (DRD-CBFs) and show that these DRD-CBFs can be constructively synthesized and used to guarantee system safety. Our method constructs DRD-CBFs by leveraging the dual relative degree property -- combining a CBF for an integrator chain with a Lyapunov function certifying the tracking of safe inputs generated for this linear system. We apply these results to dual relative degree systems, both in simulation and experimentally on hardware using quadruped and quadrotor robotic platforms.

Paper number 20:
Title: Interpreting and Improving Optimal Control Problems with Directional Corrections
Authors: Trevor Barron, Xiaojing Zhang
Abstract: Many robotics tasks, such as path planning or trajectory optimization, are formulated as optimal control problems (OCPs). The key to obtaining high performance lies in the design of the OCP's objective function. In practice, the objective function consists of a set of individual components that must be carefully modeled and traded off such that the OCP has the desired solution. It is often challenging to balance multiple components to achieve the desired solution and to understand, when the solution is undesired, the impact of individual cost components. In this paper, we present a framework addressing these challenges based on the concept of directional corrections. Specifically, given the solution to an OCP that is deemed undesirable, and access to an expert providing the direction of change that would increase the desirability of the solution, our method analyzes the individual cost components for their "consistency" with the provided directional correction. This information can be used to improve the OCP formulation, e.g., by increasing the weight of consistent cost components, or reducing the weight of - or even redesigning - inconsistent cost components. We also show that our framework can automatically tune parameters of the OCP to achieve consistency with a set of corrections.

Paper number 21:
Title: Efficient and Sustainable Task Offloading in UAV-Assisted MEC Systems via Meta Deep Reinforcement Learning
Authors: Maryam Farajzadeh Dehkordi, Bijan Jabbari
Abstract: Integrated into existing Mobile Edge Computing (MEC) systems, Unmanned Aerial Vehicles (UAVs) serve as a cornerstone in meeting the stringent requirements of future Internet of Things (IoT) networks. The current endeavor studies an MEC system, in which a computationally-empowered UAV, wirelessly linked to a cloud server, is destined for task offloading in uplink transmission of IoT devices. The performance of this system is studied by formulating a resource allocation problem, which aims to maximize the long-term computed task efficiency, while ensuring the stability of task buffers at the IoT devices, UAV and cloud. The problem jointly optimizes the uplink transmit power of IoT devices and their offloading decisions, the trajectory of the UAV and computing power at all transceivers. Regarding the non-convex and stochastic nature of the problem, we devise a multi-step solution approach. Initially, by invoking the fractional programming and Lyapunov theory, we transform the long-term optimization problem into an equivalent per-time-slot form. Subsequently, we recast the reformulated problem as a Markov Decision Process (MDP), which reflects the network dynamics. The MDP model, eventually, serves for training a Meta Twin Delayed Deep Deterministic Policy Gradient (MTD3) agent, in charge of adaptive resource allocation with respect to the MEC system variations derived from the mobility of the UAV and IoT devices. Simulations reveal the dominance of our proposed resource allocation approach over its Deep Reinforcement Learning (DRL)-powered counterparts, increasing computed task efficiency and reducing task buffer lengths.

Paper number 22:
Title: Aggregate Flexibility of Thermostatically Controlled Loads using Generalized Polymatroids
Authors: Karan Mukhi, Alessandro Abate
Abstract: Leveraging populations of thermostatically controlled loads could provide vast storage capacity to the grid. To realize this potential, their flexibility must be accurately aggregated and represented to the system operator as a single, controllable virtual device. Mathematically this is computed by calculating the Minkowski sum of the individual flexibility of each of the devices. Previous work showed how to exactly characterize the flexibility of lossless storage devices as generalized polymatroids-a family of polytope that enable an efficient computation of the Minkowski sum. In this paper we build on these results to encompass devices with dissipative storage dynamics. In doing so we are able to provide tractable methods of accurately characterizing the flexibility in populations consisting of a variety of heterogeneous devices. Numerical results demonstrate that the proposed characterizations are tight.

Paper number 23:
Title: Perturbation-Based Pinning Control Strategy for Enhanced Synchronization in Complex Networks
Authors: Ziang Mao, Tianlong Fan, Linyuan Lü
Abstract: Synchronization is essential for the stability and coordinated operation of complex networked systems. Pinning control, which selectively controls a subset of nodes, provides a scalable solution to enhance network synchronizability. However, existing strategies face key limitations: heuristic centrality-based methods lack a direct connection to synchronization dynamics, while spectral approaches, though effective, are computationally intensive. To address these challenges, we propose a perturbation-based optimized strategy (PBO) that dynamically evaluates each node's spectral impact on the Laplacian matrix, achieving improved synchronizability with significantly reduced computational costs (with complexity O(kM)). Extensive experiments demonstrate that the proposed method outperforms traditional strategies in synchronizability, convergence rate, and pinning robustness to node failures. Notably, in all the empirical networks tested and some generated networks, PBO significantly outperforms the brute-force greedy strategy, demonstrating its ability to avoid local optima and adapt to complex connectivity patterns. Our study establishes the theoretical relationship between network synchronizability and convergence rate, offering new insights into efficient synchronization strategies for large-scale complex networks.

Paper number 24:
Title: Carbon and Reliability-Aware Computing for Heterogeneous Data Centers
Authors: Yichao Zhang, Yubo Song, Subham Sahoo
Abstract: The rapid expansion of data centers (DCs) has intensified energy and carbon footprint, incurring a massive environmental computing cost. While carbon-aware workload migration strategies have been examined, existing approaches often overlook reliability metrics such as server lifetime degradation, and quality-of-service (QoS) that substantially affects both carbon and operational efficiency of DCs. Hence, this paper proposes a comprehensive optimization framework for spatio-temporal workload migration across distributed DCs that jointly minimizes operational and embodied carbon emissions while complying with service-level agreements (SLA). A key contribution is the development of an embodied carbon emission model based on servers' expected lifetime analysis, which explicitly considers server heterogeneity resulting from aging and utilization conditions. These issues are accommodated using new server dispatch strategies, and backup resource allocation model, accounting hardware, software and workload-induced failure. The overall model is formulated as a mixed-integer optimization problem with multiple linearization techniques to ensure computational tractability. Numerical case studies demonstrate that the proposed method reduces total carbon emissions by up to 21%, offering a pragmatic approach to sustainable DC operations.

Paper number 25:
Title: Symmetry-based observers for ODE systems
Authors: Stefano Battilotti
Abstract: In this paper we introduce an observer design framework for ordinary differential equation (ODE) systems based on various types of existing or even novel one-parameter symmetries (exact, asymptotic and variational) ending up with a certain number of semi-global and global observers, with bounded or unbounded system's solutions and with infinite- or finite-time convergence. We compare some of these symmetry-based observers with existing observers, recovering for instance the same performances of high-gain semiglobal observers and the finite-time convergence capabilities of sliding mode observers, while obtaining novel global observers where existing techniques are not able to provide any.

Paper number 26:
Title: Deep Learning-Based Extended Target Tracking in ISAC Systems
Authors: Yiqiu Wang, Meixia Tao, Shu Sun
Abstract: In this paper, we explore the feasibility of using communication signals for extended target (ET) tracking in an integrated sensing and communication (ISAC) system. The ET is characterized by its center range, azimuth, orientation, and contour shape, for which conventional scatterer-based tracking algorithms are hardly feasible due to the limited scatterer resolution in ISAC. To address this challenge, we propose ISACTrackNet, a deep learning-based tracking model that directly estimates ET kinematic and contour parameters from noisy received echoes. The model consists of three modules: Denoising module for clutter and self-interference suppression, Encoder module for instantaneous state estimation, and KalmanNet module for prediction refinement within a constant-velocity state-space model. Simulation results show that ISACTrackNet achieves near-optimal accuracy in position and angle estimation compared to radar-based tracking methods, even under limited measurement resolution and partial occlusions, but orientation and contour shape estimation remains slightly suboptimal. These results clearly demonstrate the feasibility of using communication-only signals for reliable ET tracking.

Paper number 27:
Title: Near Field Localization via AI-Aided Subspace Methods
Authors: Arad Gast, Luc Le Magoarou, Nir Shlezinger
Abstract: The increasing demands for high-throughput and energy-efficient wireless communications are driving the adoption of extremely large antennas operating at high-frequency bands. In these regimes, multiple users will reside in the radiative near-field, and accurate localization becomes essential. Unlike conventional far-field systems that rely solely on DOA estimation, near-field localization exploits spherical wavefront propagation to recover both DOA and range information. While subspace-based methods, such as MUSIC and its extensions, offer high resolution and interpretability for near-field localization, their performance is significantly impacted by model assumptions, including non-coherent sources, well-calibrated arrays, and a sufficient number of snapshots. To address these limitations, this work proposes AI-aided subspace methods for near-field localization that enhance robustness to real-world challenges. Specifically, we introduce NF-SubspaceNet, a deep learning-augmented 2D MUSIC algorithm that learns a surrogate covariance matrix to improve localization under challenging conditions, and DCD-MUSIC, a cascaded AI-aided approach that decouples angle and range estimation to reduce computational complexity. We further develop a novel model-order-aware training method to accurately estimate the number of sources, that is combined with casting of near field subspace methods as AI models for learning. Extensive simulations demonstrate that the proposed methods outperform classical and existing deep-learning-based localization techniques, providing robust near-field localization even under coherent sources, miscalibrations, and few snapshots.

Paper number 28:
Title: How Cyclic Acoustic Patterns Influence ASMR Perception: A Signal Processing Perspective
Authors: Zexin Fang, Bin Han, Henrik H. Sveen, C. Clark Cao, Hans D. Schotten
Abstract: Autonomous Sensory Meridian Response (ASMR) has been remarkably popular in the recent decade. While its effect has been validated through behavioral studies and neuro-physiological measurements such as electroencephalography (EEG) and related bio-signal analyses, its development and triggers remain a subject of debate. Previous studies suggest that its triggers are highly linked with cyclic patterns: predictable patterns introduce relaxation while variations maintain intrigue. To validate this and further understand the impact of acoustic features on ASMR effects, we designed three distinct cyclic patterns with monophonic and stereophonic variations, while controlling their predictability and randomness, and collected ASMR triggering scores through online surveys. Then, we extracted cyclic features and carried out regression analysis, seeking an explainable mapping of cyclic features and ASMR triggers. We found that relaxing effects accumulate progressively and are independent of spatial orientation. Cyclic patterns significantly influence psychological and physical effects, which remain invariant with time. Regression analysis revealed that smoothly spread and energy-dense cyclic patterns most effectively trigger ASMR responses.

Paper number 29:
Title: New Insights into the Decidability of Opacity in Timed Automata
Authors: Weilin Deng, Daowen Qiu, Jingkai Yang
Abstract: This paper investigates the decidability of opacity in timed automata (TA), a property that has been proven to be undecidable in general. First, we address a theoretical gap in recent work by J. An et al. (FM 2024) by providing necessary and sufficient conditions for the decidability of location-based opacity in TA. Based on these conditions, we identify a new decidable subclass of TA, called timed automata with integer resets (IRTA), where clock resets are restricted to occurring at integer time points. We also present a verification algorithm for opacity in IRTA. On the other hand, we consider achieving decidable timed opacity by weakening the capabilities of intruders. Specifically, we show that opacity in general TA becomes decidable under the assumption that intruders can only observe time in discrete units. These results establish theoretical foundations for modeling timed systems and intruders in security analysis, enabling an effective balance between expressiveness and decidability.

Paper number 30:
Title: Probabilistically safe and efficient model-based Reinforcement Learning
Authors: Filippo Airaldi, Bart De Schutter, Azita Dabiri
Abstract: This paper proposes tackling safety-critical stochastic Reinforcement Learning (RL) tasks with a samplebased, model-based approach. At the core of the method lies a Model Predictive Control (MPC) scheme that acts as function approximation, providing a model-based predictive control policy. To ensure safety, a probabilistic Control Barrier Function (CBF) is integrated into the MPC controller. A sample-based approach with guarantees is employed to approximate the effects of stochasticies in the optimal control formulation and to guarantee the probabilistic CBF condition. A learnable terminal cost formulation is included in the MPC objective to counterbalance the additional computational burden due to sampling. An RL algorithm is deployed to learn both the terminal cost and the CBF constraint. Results from our numerical experiment on a constrained LTI problem corroborate the effectiveness of the proposed methodology in reducing computation time while preserving control performance and safety.

Paper number 31:
Title: Adaptive Pricing for Optimal Coordination in Networked Energy Systems with Nonsmooth Cost Functions
Authors: Jiayi Li, Jiale Wei, Matthew Motoki, Yan Jiang, Baosen Zhang
Abstract: Incentive-based coordination mechanisms for distributed energy consumption have shown promise in aligning individual user objectives with social welfare, especially under privacy constraints. Our prior work proposed a two-timescale adaptive pricing framework, where users respond to prices by minimizing their local cost, and the system operator iteratively updates the prices based on aggregate user responses. A key assumption was that the system cost need to smoothly depend on the aggregate of the user demands. In this paper, we relax this assumption by considering the more realistic model of where the cost are determined by solving a DCOPF problem with constraints. We present a generalization of the pricing update rule that leverages the generalized gradients of the system cost function, which may be nonsmooth due to the structure of DCOPF. We prove that the resulting dynamic system converges to a unique equilibrium, which solves the social welfare optimization problem. Our theoretical results provide guarantees on convergence and stability using tools from nonsmooth analysis and Lyapunov theory. Numerical simulations on networked energy systems illustrate the effectiveness and robustness of the proposed scheme.

Paper number 32:
Title: In-Context Learning for Zero-Shot Speed Estimation of BLDC motors
Authors: Alessandro Colombo, Riccardo Busetto, Valentina Breschi, Marco Forgione, Dario Piga, Simone Formentin
Abstract: Accurate speed estimation in sensorless brushless DC motors is essential for high-performance control and monitoring, yet conventional model-based approaches struggle with system nonlinearities and parameter uncertainties. In this work, we propose an in-context learning framework leveraging transformer-based models to perform zero-shot speed estimation using only electrical measurements. By training the filter offline on simulated motor trajectories, we enable real-time inference on unseen real motors without retraining, eliminating the need for explicit system identification while retaining adaptability to varying operating conditions. Experimental results demonstrate that our method outperforms traditional Kalman filter-based estimators, especially in low-speed regimes that are crucial during motor startup.

Paper number 33:
Title: RapidPD: Rapid Human and Pet Presence Detection System for Smart Vehicles via Wi-Fi
Authors: Hancheng Guo, Zhen Chen, Mo Huang, Xiu Yin Zhang
Abstract: Heatstroke and life threatening incidents resulting from the retention of children and animals in vehicles pose a critical global safety issue. Current presence detection solutions often require specialized hardware or suffer from detection delays that do not meet safety standards. To tackle this issue, by re-modeling channel state information (CSI) with theoretical analysis of path propagation, this study introduces RapidPD, an innovative system utilizing CSI in subcarrier dimension to detect the presence of humans and pets in vehicles. The system models the impact of motion on CSI and introduces motion statistics in subcarrier dimension using a multi-layer autocorrelation method to quantify environmental changes. RapidPD is implemented using commercial Wi-Fi chipsets and tested in real vehicle environments with data collected from 10 living organisms. Experimental results demonstrate that RapidPD achieves a detection accuracy of 99.05% and a true positive rate of 99.32% within a 1-second time window at a low sampling rate of 20 Hz. These findings represent a significant advancement in vehicle safety and provide a foundation for the widespread adoption of presence detection systems.

Paper number 34:
Title: Stochastic Model Predictive Control of Charging Energy Hubs with Conformal Prediction
Authors: Diego Fernández-Zapico, Theo Hofman, Mauro Salazar
Abstract: This paper presents an online energy management system for an energy hub where electric vehicles are charged combining on-site photovoltaic generation and battery energy storage with the power grid, with the objective to decide on the battery (dis)charging to minimize the costs of operation. To this end, we devise a scenario-based stochastic model predictive control (MPC) scheme that leverages probabilistic 24-hour-ahead forecasts of charging load, solar generation and day-ahead electricity prices to achieve a cost-optimal operation of the energy hub. The probabilistic forecasts leverage conformal prediction providing calibrated distribution-free confidence intervals starting from a machine learning model that generates no uncertainty quantification. We showcase our controller by running it over a 280-day evaluation in a closed-loop simulated environment to compare the observed cost of two scenario-based MPCs with two deterministic alternatives: a version with point forecast and a version with perfect forecast. Our results indicate that, compared to the perfect forecast implementation, our proposed scenario-based MPCs are 11\% more expensive, and 1\% better than their deterministic point-forecast counterpart.

Paper number 35:
Title: Intermodal Network of Autonomous Mobility-on-Demand and Micromobility Systems
Authors: S. J. Abbasi Koumleh (1), Fabio Paparella (2) ((1) Politecnico di Milano, (2) Eindhoven University of Technology)
Abstract: This paper studies models for Autonomous Micromobility-on-Demand (AMoD), a paradigm in which a fleet of autonomous vehicles delivers mobility services on demand in conjunction with micromobility systems. Specifically, we introduce a network flow model to encapsulate the interaction between AMoD and micromobility under an intermodal connection scenario. The primary objective is to analyze the system's behavior, optimizing passenger travel time. Following this theoretical development, we apply these models to the transportation networks of Sioux Falls, enabling a quantifiable evaluation of the reciprocal influences between the two transportation modes. We found that increasing the number of vehicles in any of these two modes of transportation also incentivizes users to use the other. Moreover, increasing the rebalancing capacity of the micromobility system will make the AMoD system need less rebalancing.

Paper number 36:
Title: Reinforcement learning for robust dynamic metabolic control
Authors: Sebastián Espinel-Ríos, River Walser, Dongda Zhang
Abstract: Dynamic metabolic control can enhance bioprocess flexibility and expand the available optimization degrees of freedom via real-time modulation of metabolic enzyme expression. This allows target metabolic fluxes to be dynamically tuned throughout the process. However, identifying optimal dynamic control policies is challenging due to the presence of potential metabolic burden, cytotoxic effects, and the generally high-dimensional solution space, making exhaustive experimentation impractical. Here, we propose an approach based on reinforcement learning to derive optimal dynamic metabolic control policies by allowing an agent or controller to interact with a surrogate dynamic model $\textit{in silico}$. To incorporate and test robustness, we apply domain randomization, enabling the controller to generalize across system uncertainties. Our approach provides an alternative to conventional model-based control such as model predictive control, which requires differentiating the models with respect to decision variables; an often impractical task when dealing with complex stochastic, nonlinear, stiff, or piecewise-defined dynamics. In contrast, our approach only requires forward integration, making the task computationally much simpler with off-the-shelf solvers. We demonstrate our approach with a case study on the dynamic control of acetyl-CoA carboxylase in $\textit{Escherichia coli}$ for fatty acid biosynthesis. The derived dynamic metabolic control policies outperform static control, achieving up to 40 % higher titers while remaining robust under uncertainty.

Paper number 37:
Title: Expanding and Analyzing ODAQ -- the Open Dataset of Audio Quality
Authors: Sascha Dick, Christoph Thompson, Chih-Wei Wu, Matteo Torcoli, Pablo Delgado, Phillip A. Williams, Emanuel Habets
Abstract: The Open Dataset of Audio Quality (ODAQ) was recently introduced to address the scarcity of openly available audio datasets with corresponding subjective quality scores. The dataset, released under permissive licenses, comprises audio material processed using six different signal processing methods operating at five quality levels, along with corresponding subjective test results. To expand the dataset, we provided listener training to university students to conduct further subjective tests and obtained results consistent with previous expert listeners. We also showed how different training approaches affect the use of absolute scales and anchors. The expanded dataset now comprises results from three international laboratories providing a total of 42 listeners and 10080 subjective scores. This paper provides the details of the expansion and an in-depth analysis. As part of this analysis, we initiate the use of ODAQ as a benchmark to evaluate objective audio quality metrics in their ability to predict subjective scores

Paper number 38:
Title: Spatiotemporal Synchronization of Distributed Arrays using Particle-Based Loopy Belief Propagation
Authors: Benjamin J. B. Deutschmann, Peter Vouras
Abstract: Sensing and imaging with distributed radio infrastructures (e.g., distributed MIMO, wireless sensor networks, multistatic radar) rely on knowledge of the positions, orientations, and clock parameters of distributed apertures. We extend a particle-based loopy belief propagation (BP) algorithm to cooperatively synchronize distributed agents to anchors in space and time. Substituting marginalization over nuisance parameters with approximate but closed-form concentration, we derive an efficient estimator that bypasses the need for preliminary channel estimation and operates directly on noisy channel observations. Our algorithm demonstrates scalable, accurate spatiotemporal synchronization on simulated data.

Paper number 39:
Title: Semi-Data-Driven Model Predictive Control: A Physics-Informed Data-Driven Control Approach
Authors: Sebastian Zieglmeier, Mathias Hudoba de Badyn, Narada D. Warakagoda, Thomas R. Krogstad, Paal Engelstad
Abstract: Data-enabled predictive control (DeePC) has emerged as a powerful technique to control complex systems without the need for extensive modeling efforts. However, relying solely on offline collected data trajectories to represent the system dynamics introduces certain drawbacks. Therefore, we present a novel semi-data-driven model predictive control (SD-MPC) framework that combines (limited) model information with DeePC to address a range of these drawbacks, including sensitivity to noisy data, lack of robustness, and a high computational burden. In this work we focus on the performance of DeePC in operating regimes not captured by the offline collected data trajectories and demonstrate how incorporating an underlying parametric model can counteract this issue. SD-MPC exhibits equivalent closed-loop performance as DeePC for deterministic linear time-invariant systems. Simulations demonstrate the general control performance of the proposed SD-MPC for both a linear time-invariant system and a nonlinear system modeled as a linear parameter-varying system. These results provide numerical evidence of the enhanced robustness of SD-MPC over classical DeePC.

Paper number 40:
Title: Boosting the transient performance of reference tracking controllers with neural networks
Authors: Nicolas Kirsch, Leonardo Massai, Giancarlo Ferrari-Trecate
Abstract: Reference tracking is a key objective in many control systems, including those characterized by complex nonlinear dynamics. In these settings, traditional control approaches can effectively ensure steady-state accuracy but often struggle to explicitly optimize transient performance. Neural network controllers have gained popularity due to their adaptability to nonlinearities and disturbances; however, they often lack formal closed-loop stability and performance guarantees. To address these challenges, a recently proposed neural-network control framework known as Performance Boosting (PB) has demonstrated the ability to maintain $\mathcal{L}_p$ stability properties of nonlinear systems while optimizing generic transient costs. This paper extends the PB approach to reference tracking problems. First, we characterize the complete set of nonlinear controllers that preserve desired tracking properties for nonlinear systems equipped with base reference-tracking controllers. Then, we show how to optimize transient costs while searching within subsets of tracking controllers that incorporate expressive neural network models. Furthermore, we analyze the robustness of our method to uncertainties in the underlying system dynamics. Numerical simulations on a robotic system demonstrate the advantages of our approach over the standard PB framework.

Paper number 41:
Title: Timely Trajectory Reconstruction in Finite Buffer Remote Tracking Systems
Authors: Sunjung Kang, Vishrant Tripathi, Christopher G. Brinton
Abstract: Remote tracking systems play a critical role in applications such as IoT, monitoring, surveillance and healthcare. In such systems, maintaining both real-time state awareness (for online decision making) and accurate reconstruction of historical trajectories (for offline post-processing) are essential. While the Age of Information (AoI) metric has been extensively studied as a measure of freshness, it does not capture the accuracy with which past trajectories can be reconstructed. In this work, we investigate reconstruction error as a complementary metric to AoI, addressing the trade-off between timely updates and historical accuracy. Specifically, we consider three policies, each prioritizing different aspects of information management: Keep-Old, Keep-Fresh, and our proposed Inter-arrival-Aware dropping policy. We compare these policies in terms of impact on both AoI and reconstruction error in a remote tracking system with a finite buffer. Through theoretical analysis and numerical simulations of queueing behavior, we demonstrate that while the Keep-Fresh policy minimizes AoI, it does not necessarily minimize reconstruction error. In contrast, our proposed Inter-arrival-Aware dropping policy dynamically adjusts packet retention decisions based on generation times, achieving a balance between AoI and reconstruction error. Our results provide key insights into the design of efficient update policies for resource-constrained IoT networks.

Paper number 42:
Title: Physics-informed machine learning for building performance simulation-A review of a nascent field
Authors: Zixin Jiang, Xuezheng Wang, Han Li, Tianzhen Hong, Fengqi You, Ján Drgoňa, Draguna Vrabie, Bing Dong
Abstract: Building performance simulation (BPS) is critical for understanding building dynamics and behavior, analyzing performance of the built environment, optimizing energy efficiency, improving demand flexibility, and enhancing building resilience. However, conducting BPS is not trivial. Traditional BPS relies on an accurate building energy model, mostly physics-based, which depends heavily on detailed building information, expert knowledge, and case-by-case model calibrations, thereby significantly limiting their scalability. With the development of sensing technology and increased data availability, there is a growing attention and interest in data-driven BPS. However, purely data-driven models often suffer from limited generalization ability and a lack of physical consistency, resulting in poor performance in real-world applications. To address these limitations, recent studies have started to incorporate physics priors into data-driven models, a methodology called physics-informed machine learning (PIML). PIML is an emerging field with the definitions, methodologies, evaluation criteria, application scenarios, and future directions that remain open. To bridge those gaps, this study systematically reviews the state-of-art PIML for BPS, offering a comprehensive definition of PIML, and comparing it to traditional BPS approaches regarding data requirements, modeling effort, performance and computation cost. We also summarize the commonly used methodologies, validation approaches, application domains, available data sources, open-source packages and testbeds. In addition, this study provides a general guideline for selecting appropriate PIML models based on BPS applications. Finally, this study identifies key challenges and outlines future research directions, providing a solid foundation and valuable insights to advance R&D of PIML in BPS.

Paper number 43:
Title: Analyzing cell-to-cell heterogeneities and cell configurations in parallel-connected battery modules using physics-based modeling
Authors: Simone Fasolato, Anirudh Allam, Simona Onori, Davide M. Raimondo
Abstract: In parallel-connected cells, cell-to-cell (CtC) heterogeneities can lead to current and thermal gradients that may adversely impact the battery performance and aging. Sources of CtC heterogeneity include manufacturing process tolerances, poor module configurations, and inadequate thermal management. Understanding which CtC heterogeneity sources most significantly impact battery performance is crucial, as it can provide valuable insights. In this study, we use an experimentally validated electrochemical battery model to simulate hundreds of battery configurations, each consisting of four cells in parallel. We conduct a statistical analysis to evaluate the relative importance of key cell-level parameters, interconnection resistance, cell spacing, and location on performance and aging. The analysis reveals that heterogeneities in electrode active material volume fractions primarily impact module capacity, energy, and cell current, leading to substantial thermal gradients. However, to fully capture the output behavior, interconnection resistance, state of charge gradients and the effect of the temperature on parameter values must also be considered. Additionally, module design configurations, particularly cell location, exacerbate thermal gradients, accelerating long-term module degradation. This study also offers insights into optimizing cell arrangement during module design to reduce thermal gradients and enhance overall battery performance and longevity. Simulation results with four cells indicate a reduction of 51.8% in thermal gradients, leading to a 5.2% decrease in long-term energy loss.

Paper number 44:
Title: Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning
Authors: Muhammad Umer, Muhammad Ahmed Mohsin, Huma Ghafoor, Syed Ali Hassan
Abstract: This thesis delves into the forefront of wireless communication by exploring the synergistic integration of three transformative technologies: STAR-RIS, CoMP, and NOMA. Driven by the ever-increasing demand for higher data rates, improved spectral efficiency, and expanded coverage in the evolving landscape of 6G development, this research investigates the potential of these technologies to revolutionize future wireless networks. The thesis analyzes the performance gains achievable through strategic deployment of STAR-RIS, focusing on mitigating inter-cell interference, enhancing signal strength, and extending coverage to cell-edge users. Resource sharing strategies for STAR-RIS elements are explored, optimizing both transmission and reflection functionalities. Analytical frameworks are developed to quantify the benefits of STAR-RIS assisted CoMP-NOMA networks under realistic channel conditions, deriving key performance metrics such as ergodic rates and outage probabilities. Additionally, the research delves into energy-efficient design approaches for CoMP-NOMA networks incorporating RIS, proposing novel RIS configurations and optimization algorithms to achieve a balance between performance and energy consumption. Furthermore, the application of Deep Reinforcement Learning (DRL) techniques for intelligent and adaptive optimization in aerial RIS-assisted CoMP-NOMA networks is explored, aiming to maximize network sum rate while meeting user quality of service requirements. Through a comprehensive investigation of these technologies and their synergistic potential, this thesis contributes valuable insights into the future of wireless communication, paving the way for the development of more efficient, reliable, and sustainable networks capable of meeting the demands of our increasingly connected world.

Paper number 45:
Title: A Parametric Model for Near-Optimal Online Synthesis with Robust Reach-Avoid Guarantees
Authors: Mario Gleirscher, Philip Hönnecke
Abstract: Objective: To obtain explainable guarantees in the online synthesis of optimal controllers for high-integrity cyber-physical systems, we re-investigate the use of exhaustive search as an alternative to reinforcement learning. Approach: We model an application scenario as a hybrid game automaton, enabling the synthesis of robustly correct and near-optimal controllers online without prior training. For modal synthesis, we employ discretised games solved via scope-adaptive and step-pre-shielded discrete dynamic programming. Evaluation: In a simulation-based experiment, we apply our approach to an autonomous aerial vehicle scenario. Contribution: We propose a parametric system model and a parametric online synthesis.

Paper number 46:
Title: Data-Driven Safety Verification using Barrier Certificates and Matrix Zonotopes
Authors: Mohammed Adib Oumer, Amr Alanwar, Majid Zamani
Abstract: Ensuring safety in cyber-physical systems (CPSs) is a critical challenge, especially when system models are difficult to obtain or cannot be fully trusted due to uncertainty, modeling errors, or environmental disturbances. Traditional model-based approaches rely on precise system dynamics, which may not be available in real-world scenarios. To address this, we propose a data-driven safety verification framework that leverages matrix zonotopes and barrier certificates to verify system safety directly from noisy data. Instead of trusting a single unreliable model, we construct a set of models that capture all possible system dynamics that align with the observed data, ensuring that the true system model is always contained within this set. This model set is compactly represented using matrix zonotopes, enabling efficient computation and propagation of uncertainty. By integrating this representation into a barrier certificate framework, we establish rigorous safety guarantees without requiring an explicit system model. Numerical experiments demonstrate the effectiveness of our approach in verifying safety for dynamical systems with unknown models, showcasing its potential for real-world CPS applications.

Paper number 47:
Title: A Novel Distance-Based Metric for Quality Assessment in Image Segmentation
Authors: Niklas Rottmayer, Claudia Redenbach
Abstract: The assessment of segmentation quality plays a fundamental role in the development, optimization, and comparison of segmentation methods which are used in a wide range of applications. With few exceptions, quality assessment is performed using traditional metrics, which are based on counting the number of erroneous pixels but do not capture the spatial distribution of errors. Established distance-based metrics such as the average Hausdorff distance are difficult to interpret and compare for different methods and datasets. In this paper, we introduce the Surface Consistency Coefficient (SCC), a novel distance-based quality metric that quantifies the spatial distribution of errors based on their proximity to the surface of the structure. Through a rigorous analysis using synthetic data and real segmentation results, we demonstrate the robustness and effectiveness of SCC in distinguishing errors near the surface from those further away. At the same time, SCC is easy to interpret and comparable across different structural contexts.

Paper number 48:
Title: SACA: A Scenario-Aware Collision Avoidance Framework for Autonomous Vehicles Integrating LLMs-Driven Reasoning
Authors: Shiyue Zhao, Junzhi Zhang, Neda Masoud, Heye Huang, Xingpeng Xia, Chengkun He
Abstract: Reliable collision avoidance under extreme situations remains a critical challenge for autonomous vehicles. While large language models (LLMs) offer promising reasoning capabilities, their application in safety-critical evasive maneuvers is limited by latency and robustness issues. Even so, LLMs stand out for their ability to weigh emotional, legal, and ethical factors, enabling socially responsible and context-aware collision avoidance. This paper proposes a scenario-aware collision avoidance (SACA) framework for extreme situations by integrating predictive scenario evaluation, data-driven reasoning, and scenario-preview-based deployment to improve collision avoidance decision-making. SACA consists of three key components. First, a predictive scenario analysis module utilizes obstacle reachability analysis and motion intention prediction to construct a comprehensive situational prompt. Second, an online reasoning module refines decision-making by leveraging prior collision avoidance knowledge and fine-tuning with scenario data. Third, an offline evaluation module assesses performance and stores scenarios in a memory bank. Additionally, A precomputed policy method improves deployability by previewing scenarios and retrieving or reasoning policies based on similarity and confidence levels. Real-vehicle tests show that, compared with baseline methods, SACA effectively reduces collision losses in extreme high-risk scenarios and lowers false triggering under complex conditions. Project page: this https URL.

Paper number 49:
Title: Robust Control of General Linear Delay Systems under Dissipativity Part I: A KSD based Framework
Authors: Qian Feng, Wei Xing Zheng, Xiaoyu Wang, Feng Xiao
Abstract: This paper introduces an effective framework for designing memoryless dissipative full-state feedbacks for general linear delay systems via the Krasovskiĭ functional (KF) approach, where an unlimited number of pointwise and general distributed delays (DDs) exists in the state, input and output. To handle the infinite dimensionality of DDs, we employ the Kronecker-Seuret Decomposition (KSD) which we recently proposed for analyzing matrix-valued functions in the context of delay systems. The KSD enables factorization or least-squares approximation of any number of $\fL^2$ DD kernel from any number of DDs without introducing conservatism. This also facilitates the construction of a complete-type KF with flexible integral kernels, following from an application of a novel integral inequalities derived from the least-squares principle. Our solution includes two theorems and an iterative algorithm to compute controller gains without relying on nonlinear solvers. A challenging numerical example, intractable for existing methods, underscores the efficacy of this approach.

Paper number 50:
Title: Non-Asymptotic Analysis of Classical Spectrum Estimators for $L$-mixing Time-series Data with Unknown Means
Authors: Yuping Zheng, Andrew Lamperski
Abstract: Spectral estimation is an important tool in time series analysis, with applications including economics, astronomy, and climatology. The asymptotic theory for non-parametric estimation is well-known but the development of non-asymptotic theory is still ongoing. Our recent work obtained the first non-asymptotic error bounds on the Bartlett and Welch methods for $L$-mixing stochastic processes. The class of $L$-mixing processes contains common models in time series analysis, including autoregressive processes and measurements of geometrically ergodic Markov chains. Our prior analysis assumes that the process has zero mean. While zero-mean assumptions are common, real-world time-series data often has unknown, non-zero mean. In this work, we derive non-asymptotic error bounds for both Bartlett and Welch estimators for $L$-mixing time-series data with unknown means. The obtained error bounds are of $O(\frac{1}{\sqrt{k}})$, where $k$ is the number of data segments used in the algorithm, which are tighter than our previous results under the zero-mean assumption.

Paper number 51:
Title: System Identification from Partial Observations under Adversarial Attacks
Authors: Jihun Kim, Javad Lavaei
Abstract: This paper is concerned with the partially observed linear system identification, where the goal is to obtain reasonably accurate estimation of the balanced truncation of the true system up to the order $k$ from output measurements. We consider the challenging case of system identification under adversarial attacks, where the probability of having an attack at each time is $\Theta(1/k)$ while the value of the attack is arbitrary. We first show that the $l_1$-norm estimator exactly identifies the true Markov parameter matrix for nilpotent systems under any type of attack. We then build on this result to extend it to general systems and show that the estimation error exponentially decays as $k$ grows. The estimated balanced truncation model accordingly shows an exponentially decaying error for the identification of the true system up to the similarity transformation. This work is the first to provide the input-output analysis of the system with partial observations under arbitrary attacks.

Paper number 52:
Title: An Iterative Algorithm to Symbolically Derive Generalized n-Trailer Vehicle Kinematics
Authors: Yuvraj Singh, Adithya Jayakumar, Giorgio Rizzoni
Abstract: Articulated multi-axle vehicles are interesting from a control-theoretic perspective due to their peculiar kinematic offtracking characteristics, instability modes, and singularities. Holonomic and nonholonomic constraints affecting the kinematic behavior is investigated in order to develop control-oriented kinematic models representative of these peculiarities. Then, the structure of these constraints is exploited to develop an iterative algorithm to symbolically derive yaw-plane kinematic models of generalized $n$-trailer articulated vehicles with an arbitrary number of multi-axle vehicle units. A formal proof is provided for the maximum number of kinematic controls admissible to a large-scale generalized articulated vehicle system, which leads to a generalized Ackermann steering law for $n$-trailer systems. Moreover, kinematic data collected from a test vehicle is used to validate the kinematic models and, to understand the rearward yaw rate amplification behavior of the vehicle pulling multiple simulated trailers.

Paper number 53:
Title: Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments
Authors: Joshua Moore, Aly Sabri Abdalla, Prabesh Khanal, Vuk Marojevic
Abstract: The Open Radio Access Network (O-RAN) architecture is reshaping telecommunications by promoting openness, flexibility, and intelligent closed-loop optimization. By decoupling hardware and software and enabling multi-vendor deployments, O-RAN reduces costs, enhances performance, and allows rapid adaptation to new technologies. A key innovation is intelligent network slicing, which partitions networks into isolated slices tailored for specific use cases or quality of service requirements. The RAN Intelligent Controller further optimizes resource allocation, ensuring efficient utilization and improved service quality for user equipment (UEs). However, the modular and dynamic nature of O-RAN expands the threat surface, necessitating advanced security measures to maintain network integrity, confidentiality, and availability. Intrusion detection systems have become essential for identifying and mitigating attacks. This research explores using large language models (LLMs) to generate security recommendations based on the temporal traffic patterns of connected UEs. The paper introduces an LLM-driven intrusion detection framework and demonstrates its efficacy through experimental deployments, comparing non fine-tuned and fine-tuned models for task-specific accuracy.

Paper number 54:
Title: Robust Transmission Design for Active RIS-Aided Systems
Authors: Jinho Yang, Hyeongtaek Lee, Junil Choi
Abstract: Different from conventional passive reconfigurable intelligent surfaces (RISs), incident signals and thermal noise can be amplified at active RISs. By exploiting the amplifying capability of active RISs, noticeable performance improvement can be expected when precise channel state information (CSI) is available. Since obtaining perfect CSI related to an RIS is difficult in practice, a robust transmission design is proposed in this paper to tackle the channel uncertainty issue, which will be more severe for active RIS-aided systems. To account for the worst-case scenario, the minimum achievable rate of each user is derived under a statistical CSI error model. Subsequently, an optimization problem is formulated to maximize the sum of the minimum achievable rate. Since the objective function is non-concave, the formulated problem is transformed into a tractable lower bound maximization problem, which is solved using an alternating optimization method. Numerical results show that the proposed robust design outperforms a baseline scheme that only exploits estimated CSI.

Paper number 55:
Title: Robust Continuous-Time Generation Scheduling under Power Demand Uncertainty: An Affine Decision Rule Approach
Authors: Youngchae Cho, Insoon Yang, Takayuki Ishizaki
Abstract: Most existing generation scheduling models for power systems under demand uncertainty rely on energy-based formulations with a finite number of time periods, which may fail to ensure that power supply and demand are balanced continuously over time. To address this issue, we propose a robust generation scheduling model in a continuous-time framework, employing a decision rule approach. First, for a given set of demand trajectories, we formulate a general robust generation scheduling problem to determine a decision rule that maps these demand trajectories and time points to the power outputs of generators. Subsequently, we derive a surrogate of it as our model by carefully designing a class of decision rules that are affine in the current demand, with coefficients invariant over time and constant terms that are continuous piecewise affine functions of time. As a result, our model can be recast as a finite-dimensional linear program to determine the coefficients and the function values of the constant terms at each breakpoint, solvable via the cutting-plane method. Our model is non-anticipative unlike most existing continuous-time models, which use Bernstein polynomials, making it more practical. We also provide illustrative numerical examples.

Paper number 56:
Title: Egocentric Conformal Prediction for Safe and Efficient Navigation in Dynamic Cluttered Environments
Authors: Jaeuk Shin, Jungjin Lee, Insoon Yang
Abstract: Conformal prediction (CP) has emerged as a powerful tool in robotics and control, thanks to its ability to calibrate complex, data-driven models with formal guarantees. However, in robot navigation tasks, existing CP-based methods often decouple prediction from control, evaluating models without considering whether prediction errors actually compromise safety. Consequently, ego-vehicles may become overly conservative or even immobilized when all potential trajectories appear infeasible. To address this issue, we propose a novel CP-based navigation framework that responds exclusively to safety-critical prediction errors. Our approach introduces egocentric score functions that quantify how much closer obstacles are to a candidate vehicle position than anticipated. These score functions are then integrated into a model predictive control scheme, wherein each candidate state is individually evaluated for safety. Combined with an adaptive CP mechanism, our framework dynamically adjusts to changes in obstacle motion without resorting to unnecessary conservatism. Theoretical analyses indicate that our method outperforms existing CP-based approaches in terms of cost-efficiency while maintaining the desired safety levels, as further validated through experiments on real-world datasets featuring densely populated pedestrian environments.

Paper number 57:
Title: Learning-Based Approximate Nonlinear Model Predictive Control Motion Cueing
Authors: Camilo Gonzalez Arango (1), Houshyar Asadi (1), Mohammad Reza Chalak Qazani (2), Chee Peng Lim (3) ((1) Institute for Intelligent Systems Research and Innovation, Deakin University, Waurn Ponds, Victoria, 3216, Australia. (2) Sohar University, Sohar, 311, Oman. (3) Swinburne University, Hawthorn, Victoria, 3122, Australia.)
Abstract: Motion Cueing Algorithms (MCAs) encode the movement of simulated vehicles into movement that can be reproduced with a motion simulator to provide a realistic driving experience within the capabilities of the machine. This paper introduces a novel learning-based MCA for serial robot-based motion simulators. Building on the differentiable predictive control framework, the proposed method merges the advantages of Nonlinear Model Predictive Control (NMPC) - notably nonlinear constraint handling and accurate kinematic modeling - with the computational efficiency of machine learning. By shifting the computational burden to offline training, the new algorithm enables real-time operation at high control rates, thus overcoming the key challenge associated with NMPC-based motion cueing. The proposed MCA incorporates a nonlinear joint-space plant model and a policy network trained to mimic NMPC behavior while accounting for joint acceleration, velocity, and position limits. Simulation experiments across multiple motion cueing scenarios showed that the proposed algorithm performed on par with a state-of-the-art NMPC-based alternative in terms of motion cueing quality as quantified by the RMSE and correlation coefficient with respect to reference signals. However, the proposed algorithm was on average 400 times faster than the NMPC baseline. In addition, the algorithm successfully generalized to unseen operating conditions, including motion cueing scenarios on a different vehicle and real-time physics-based simulations.

Paper number 58:
Title: Hierarchical Attention Networks for Lossless Point Cloud Attribute Compression
Authors: Yueru Chen, Wei Zhang, Dingquan Li, Jing Wang, Ge Li
Abstract: In this paper, we propose a deep hierarchical attention context model for lossless attribute compression of point clouds, leveraging a multi-resolution spatial structure and residual learning. A simple and effective Level of Detail (LoD) structure is introduced to yield a coarse-to-fine representation. To enhance efficiency, points within the same refinement level are encoded in parallel, sharing a common context point group. By hierarchically aggregating information from neighboring points, our attention model learns contextual dependencies across varying scales and densities, enabling comprehensive feature extraction. We also adopt normalization for position coordinates and attributes to achieve scale-invariant compression. Additionally, we segment the point cloud into multiple slices to facilitate parallel processing, further optimizing time complexity. Experimental results demonstrate that the proposed method offers better coding performance than the latest G-PCC for color and reflectance attributes while maintaining more efficient encoding and decoding runtimes.

Paper number 59:
Title: Contextualized Autonomous Drone Navigation using LLMs Deployed in Edge-Cloud Computing
Authors: Hongqian Chen, Yun Tang, Antonios Tsourdos, Weisi Guo
Abstract: Autonomous navigation is usually trained offline in diverse scenarios and fine-tuned online subject to real-world experiences. However, the real world is dynamic and changeable, and many environmental encounters/effects are not accounted for in real-time due to difficulties in describing them within offline training data or hard to describe even in online scenarios. However, we know that the human operator can describe these dynamic environmental encounters through natural language, adding semantic context. The research is to deploy Large Language Models (LLMs) to perform real-time contextual code adjustment to autonomous navigation. The challenge not evaluated in literature is what LLMs are appropriate and where should these computationally heavy algorithms sit in the computation-communication edge-cloud computing architectures. In this paper, we evaluate how different LLMs can adjust both the navigation map parameters dynamically (e.g., contour map shaping) and also derive navigation task instruction sets. We then evaluate which LLMs are most suitable and where they should sit in future edge-cloud of 6G telecommunication architectures.

Paper number 60:
Title: Multi-stage Group Testing with (r,s)-regular design Algorithms
Authors: Michael Balzer
Abstract: In industrial engineering and manufacturing, quality control is an essential part of the production process of a product. To ensure proper functionality of a manufactured good, rigorous testing has to be performed to identify defective products before shipment to the customer. However, testing products individually in a sequential manner is often tedious, cumbersome and not widely applicable given that time, resources and personnel are limited. Thus, statistical methods have been employed to investigate random samples of products from batches. For instance, group testing has emerged as an alternative to reliably test manufactured goods by evaluating joint test results. Despite the clear advantages, existing group testing methods often struggle with efficiency and practicality in real-world industry settings, where minimizing the average number of tests and overall testing duration is critical. In this paper, novel multistage (r,s)-regular design algorithms in the framework of group testing for the identification of defective products are investigated. Motivated by the application in quality control in manufacturing, unifying expressions for the expected number of tests and expected duration are derived. The results show that the novel group testing algorithms outperform established algorithms for low probabilities of defectiveness and get close to the optimal counting bound while maintaining a low level of complexity. Mathematical proofs are supported by rigorous simulation studies and an evaluation of the performance.

Paper number 61:
Title: Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models
Authors: Alireza Aghabagherloo, Aydin Abadi, Sumanta Sarkar, Vishnu Asutosh Dasu, Bart Preneel
Abstract: The accuracy and robustness of machine learning models against adversarial attacks are significantly influenced by factors such as training data quality, model architecture, the training process, and the deployment environment. In recent years, duplicated data in training sets, especially in language models, has attracted considerable attention. It has been shown that deduplication enhances both training performance and model accuracy in language models. While the importance of data quality in training image classifier Deep Neural Networks (DNNs) is widely recognized, the impact of duplicated images in the training set on model generalization and performance has received little attention. In this paper, we address this gap and provide a comprehensive study on the effect of duplicates in image classification. Our analysis indicates that the presence of duplicated images in the training set not only negatively affects the efficiency of model training but also may result in lower accuracy of the image classifier. This negative impact of duplication on accuracy is particularly evident when duplicated data is non-uniform across classes or when duplication, whether uniform or non-uniform, occurs in the training set of an adversarially trained model. Even when duplicated samples are selected in a uniform way, increasing the amount of duplication does not lead to a significant improvement in accuracy.

Paper number 62:
Title: Design and Validation of an Intention-Aware Probabilistic Framework for Trajectory Prediction: Integrating COLREGS, Grounding Hazards, and Planned Routes
Authors: Dhanika Mahipala, Trym Tengesdal, Børge Rokseth, Tor Arne Johansen
Abstract: Collision avoidance capability is an essential component in an autonomous vessel navigation system. To this end, an accurate prediction of dynamic obstacle trajectories is vital. Traditional approaches to trajectory prediction face limitations in generalizability and often fail to account for the intentions of other vessels. While recent research has considered incorporating the intentions of dynamic obstacles, these efforts are typically based on the own-ship's interpretation of the situation. The current state-of-the-art in this area is a Dynamic Bayesian Network (DBN) model, which infers target vessel intentions by considering multiple underlying causes and allowing for different interpretations of the situation by different vessels. However, since its inception, there have not been any significant structural improvements to this model. In this paper, we propose enhancing the DBN model by incorporating considerations for grounding hazards and vessel waypoint information. The proposed model is validated using real vessel encounters extracted from historical Automatic Identification System (AIS) data.

Paper number 63:
Title: $C^2$AV-TSE: Context and Confidence-aware Audio Visual Target Speaker Extraction
Authors: Wenxuan Wu, Xueyuan Chen, Shuai Wang, Jiadong Wang, Lingwei Meng, Xixin Wu, Helen Meng, Haizhou Li
Abstract: Audio-Visual Target Speaker Extraction (AV-TSE) aims to mimic the human ability to enhance auditory perception using visual cues. Although numerous models have been proposed recently, most of them estimate target signals by primarily relying on local dependencies within acoustic features, underutilizing the human-like capacity to infer unclear parts of speech through contextual information. This limitation results in not only suboptimal performance but also inconsistent extraction quality across the utterance, with some segments exhibiting poor quality or inadequate suppression of interfering speakers. To close this gap, we propose a model-agnostic strategy called the Mask-And-Recover (MAR). It integrates both inter- and intra-modality contextual correlations to enable global inference within extraction modules. Additionally, to better target challenging parts within each sample, we introduce a Fine-grained Confidence Score (FCS) model to assess extraction quality and guide extraction modules to emphasize improvement on low-quality segments. To validate the effectiveness of our proposed model-agnostic training paradigm, six popular AV-TSE backbones were adopted for evaluation on the VoxCeleb2 dataset, demonstrating consistent performance improvements across various metrics.

Paper number 64:
Title: A Unified Theoretic and Algorithmic Framework for Solving Multivariate Linear Model with $\ell^1$-norm Optimization
Authors: Zhi-Qiang Feng, Hong-Yan Zhanga, Ji Ma, Daniel Delahaye, Ruo-Shi Yang, Man Liang
Abstract: It is a challenging problem that solving the \textit{multivariate linear model} (MLM) $\mathbf{A}\mathbf{x}=\mathbf{b}$ with the $\ell_1 $-norm approximation method such that $||\mathbf{A}\mathbf{x}-\mathbf{b}||_1$, the $\ell_1$-norm of the \textit{residual error vector} (REV), is minimized. In this work, our contributions lie in two aspects: firstly, the equivalence theorem for the structure of the $\ell_1$-norm optimal solution to the MLM is proposed and proved; secondly, a unified algorithmic framework for solving the MLM with $\ell_1$-norm optimization is proposed and six novel algorithms (L1-GPRS, L1-TNIPM, L1-HP, L1-IST, L1-ADM, L1-POB) are designed. There are three significant characteristics in the algorithms discussed: they are implemented with simple matrix operations which do not depend on specific optimization solvers; they are described with algorithmic pseudo-codes and implemented with Python and Octave/MATLAB which means easy usage; and the high accuracy and efficiency of our six new algorithms can be achieved successfully in the scenarios with different levels of data redundancy. We hope that the unified theoretic and algorithmic framework with source code released on GitHub could motivate the applications of the $\ell_1$-norm optimization for parameter estimation of MLM arising in science, technology, engineering, mathematics, economics, and so on.

Paper number 65:
Title: REMAA: Reconfigurable Pixel Antenna-based Electronic Movable-Antenna Arrays for Multiuser Communications
Authors: Kangjian Chen, Chenhao Qi, Yujing Hong, Chau Yuen
Abstract: In this paper, we investigate reconfigurable pixel antenna (RPA)-based electronic movable antennas (REMAs) for multiuser communications. First, we model each REMA as an antenna characterized by a set of predefined and discrete selectable radiation positions within the radiating region. Considering the trade-off between performance and cost, we propose two types of REMA-based arrays: the partially-connected RPA-based electronic movable-antenna array (PC-REMAA) and fully-connected REMAA (FC-REMAA). Then, we formulate a multiuser sum-rate maximization problem subject to the power constraint and hardware constraints of the PC-REMAA or FC-REMAA. To solve this problem, we propose a two-step multiuser beamforming and antenna selection scheme. In the first step, we develop a two-loop joint beamforming and antenna selection (TL-JBAS) algorithm. In the second step, we apply the coordinate descent method to further enhance the solution of the TL-JBAS algorithm. In addition, we revisit mechanical movable antennas (MMAs) to establish a benchmark for evaluating the performance of REMA-enabled multiuser communications, where MMAs can continuously adjust the positions within the transmission region. We also formulate a sum-rate maximization problem for MMA-enabled multiuser communications and propose an alternating beamforming and antenna position optimization scheme to solve it. Finally, we analyze the performance gap between REMAs and MMAs. Based on Fourier analysis, we derive the maximum power loss of REMAs compared to MMAs for any given position interval. Specifically, we show that the REMA incurs a maximum power loss of only 3.25\% compared to the MMA when the position interval is set to one-tenth of the wavelength. Simulation results demonstrate the effectiveness of the proposed methods.

Paper number 66:
Title: Feedback Optimization with State Constraints through Control Barrier Functions
Authors: Giannis Delimpaltadakis, Pol Mestres, Jorge Cortés, W.P.M.H. Heemels
Abstract: Recently, there has been a surge of research on a class of methods called feedback optimization. These are methods to steer the state of a control system to an equilibrium that arises as the solution of an optimization problem. Despite the growing literature on the topic, the important problem of enforcing state constraints at all times remains unaddressed. In this work, we present the first feedback-optimization method that enforces state constraints. The method combines a class of dynamics called safe gradient flows with high-order control barrier functions. We provide a number of results on our proposed controller, including well-posedness guarantees, anytime constraint-satisfaction guarantees, equivalence between the closed-loop's equilibria and the optimization problem's critical points, and local asymptotic stability of optima.

Paper number 67:
Title: Time-optimal Convexified Reeds-Shepp Paths on a Sphere
Authors: Sixu Li, Deepak Prakash Kumar, Swaroop Darbha, Yang Zhou
Abstract: This article addresses time-optimal path planning for a vehicle capable of moving both forward and backward on a unit sphere with a unit maximum speed, and constrained by a maximum absolute turning rate $U_{max}$. The proposed formulation can be utilized for optimal attitude control of underactuated satellites, optimal motion planning for spherical rolling robots, and optimal path planning for mobile robots on spherical surfaces or uneven terrains. By utilizing Pontryagin's Maximum Principle and analyzing phase portraits, it is shown that for $U_{max}\geq1$, the optimal path connecting a given initial configuration to a desired terminal configuration falls within a sufficient list of 23 path types, each comprising at most 6 segments. These segments belong to the set $\{C,G,T\}$, where $C$ represents a tight turn with radius $r=\frac{1}{\sqrt{1+U_{max}^2}}$, $G$ represents a great circular arc, and $T$ represents a turn-in-place motion. Closed-form expressions for the angles of each path in the sufficient list are derived. The source code for solving the time-optimal path problem and visualization is publicly available at this https URL.

Paper number 68:
Title: A YOLO-Based Semi-Automated Labeling Approach to Improve Fault Detection Efficiency in Railroad Videos
Authors: Dylan Lester, James Gao, Samuel Sutphin, Pingping Zhu, Husnu Narman, Ammar Alzarrad
Abstract: Manual labeling for large-scale image and video datasets is often time-intensive, error-prone, and costly, posing a significant barrier to efficient machine learning workflows in fault detection from railroad videos. This study introduces a semi-automated labeling method that utilizes a pre-trained You Only Look Once (YOLO) model to streamline the labeling process and enhance fault detection accuracy in railroad videos. By initiating the process with a small set of manually labeled data, our approach iteratively trains the YOLO model, using each cycle's output to improve model accuracy and progressively reduce the need for human intervention. To facilitate easy correction of model predictions, we developed a system to export YOLO's detection data as an editable text file, enabling rapid adjustments when detections require refinement. This approach decreases labeling time from an average of 2 to 4 minutes per image to 30 seconds to 2 minutes, effectively minimizing labor costs and labeling errors. Unlike costly AI based labeling solutions on paid platforms, our method provides a cost-effective alternative for researchers and practitioners handling large datasets in fault detection and other detection based machine learning applications.

Paper number 69:
Title: Harmonic model predictive control for tracking sinusoidal references and its application to trajectory tracking
Authors: Pablo Krupa, Daniel Limon, Alberto Bemporad, Teodoro Alamo
Abstract: Harmonic model predictive control (HMPC) is a recent model predictive control (MPC) formulation for tracking piece-wise constant references that includes a parameterized artificial harmonic reference as a decision variable, resulting in an increased performance and domain of attraction with respect to other MPC formulations. This article presents an extension of the HMPC formulation to track periodic harmonic/sinusoidal references and discusses its use for tracking arbitrary trajectories. The proposed formulation inherits the benefits of its predecessor, namely its good performance and large domain of attraction when using small prediction horizons, and that the complexity of its optimization problem does not depend on the period of the reference. We show closed-loop results discussing its performance and comparing it to other MPC formulations.

Paper number 70:
Title: DT-DDNN: A Physical Layer Security Attack Detector in 5G RF Domain for CAVs
Authors: Ghazal Asemian, Mohammadreza Amini, Burak Kantarci, Melike Erol-Kantarci
Abstract: The Synchronization Signal Block (SSB) is a fundamental component of the 5G New Radio (NR) air interface, crucial for the initial access procedure of Connected and Automated Vehicles (CAVs), and serves several key purposes in the network's operation. However, due to the predictable nature of SSB transmission, including the Primary and Secondary Synchronization Signals (PSS and SSS), jamming attacks are critical threats. These attacks, which can be executed without requiring high power or complex equipment, pose substantial risks to the 5G network, particularly as a result of the unencrypted transmission of control signals. Leveraging RF domain knowledge, this work presents a novel deep learning-based technique for detecting jammers in CAV networks. Unlike the existing jamming detection algorithms that mostly rely on network parameters, we introduce a double-threshold deep learning jamming detector by focusing on the SSB. The detection method is focused on RF domain features and improves the robustness of the network without requiring integration with the pre-existing network infrastructure. By integrating a preprocessing block to extract PSS correlation and energy per null resource elements (EPNRE) characteristics, our method distinguishes between normal and jammed received signals with high precision. Additionally, by incorporating of Discrete Wavelet Transform (DWT), the efficacy of training and detection are optimized. A double-threshold double Deep Neural Network (DT-DDNN) is also introduced to the architecture complemented by a deep cascade learning model to increase the sensitivity of the model to variations of signal-to-jamming noise ratio (SJNR). Results show that the proposed method achieves 96.4% detection rate in extra low jamming power, i.e., SJNR between 15 to 30 dB. Further, performance of DT-DDNN is validated by analyzing real 5G signals obtained from a practical testbed.

Paper number 71:
Title: Gaussian Processes with Noisy Regression Inputs for Dynamical Systems
Authors: Tobias M. Wolff, Victor G. Lopez, Matthias A. Müller
Abstract: This paper is centered around the approximation of dynamical systems by means of Gaussian processes. To this end, trajectories of such systems must be collected to be used as training data. The measurements of these trajectories are typically noisy, which implies that both the regression inputs and outputs are corrupted by noise. However, most of the literature considers only noise in the regression outputs. In this paper, we show how to account for the noise in the regression inputs in an extended Gaussian process framework to approximate scalar and multidimensional systems. We demonstrate the potential of our framework by comparing it to different state-of-the-art methods in several simulation examples.

Paper number 72:
Title: Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation
Authors: Siyin Wang, Wenyi Yu, Yudong Yang, Changli Tang, Yixuan Li, Jimin Zhuang, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Guangzhi Sun, Lu Lu, Yuxuan Wang, Chao Zhang
Abstract: Speech quality assessment typically requires evaluating audio from multiple aspects, such as mean opinion score (MOS) and speaker similarity (SIM) \etc., which can be challenging to cover using one small model designed for a single task. In this paper, we propose leveraging recently introduced auditory large language models (LLMs) for automatic speech quality assessment. By employing task-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B testing results, which are commonly used for evaluating text-to-speech systems. Additionally, the finetuned auditory LLM is able to generate natural language descriptions assessing aspects like noisiness, distortion, discontinuity, and overall quality, providing more interpretable outputs. Extensive experiments have been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality datasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and Qwen2-Audio. For the natural language descriptions task, a commercial model Google Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory LLMs achieve competitive performance compared to state-of-the-art task-specific small models in predicting MOS and SIM, while also delivering promising results in A/B testing and natural language descriptions. Our data processing scripts and finetuned model checkpoints can be found at this https URL.

Paper number 73:
Title: Mutual Coupling-Aware Channel Estimation and Beamforming for RIS-Assisted Communications
Authors: Pinjun Zheng, Simon Tarboush, Hadi Sarieddeen, Tareq Y. Al-Naffouri
Abstract: This work studies the problems of channel estimation and beamforming for active reconfigurable intelligent surface (RIS)-assisted multiple-input multiple-output (MIMO) communication, incorporating the mutual coupling (MC) effect through an electromagnetically consistent model based on scattering parameters. We first demonstrate that MC can be incorporated into a compressed sensing (CS) estimation formulation, albeit with an increase in the dimensionality of the sensing matrix. To overcome this increased complexity, we propose a two-stage strategy. Initially, a low-complexity MC-unaware CS estimation is performed to obtain a coarse channel estimate, which is then used to implement a dictionary reduction (DR), effectively reducing the dimensionality of the sensing matrices. This method achieves low complexity comparable to the conventional MC-unaware approach while providing estimation accuracy close to that of the high-complexity MC-aware CS method. Furthermore, we consider the joint optimization of RIS configuration, base station precoding, and user combining in an single-user MIMO system. We employ an alternating optimization strategy to optimize these three beamformers. The primary challenge lies in optimizing the RIS configuration, as the MC effect renders the problem non-convex and intractable. To address this, we propose a novel algorithm based on the successive convex approximation (SCA) and the Neumann series expansion. Within the SCA framework, we propose a surrogate function that rigorously satisfies both convexity and equal-gradient conditions to update the iteration direction. Numerical results validate our proposal, demonstrating that the proposed channel estimation and beamforming methods effectively manage the MC in RIS, achieving higher spectral efficiency compared to state-of-the-art approaches.

Paper number 74:
Title: Non-overshooting output shaping for switched linear systems under arbitrary switching using eigenstructure assignment
Authors: Kai Wulff, Maria Christine Honecker, Robert Schmid, Johann Reger
Abstract: We consider the analytical control design for a pair of switched linear multiple-input multiple-output (MIMO) systems that are subject to arbitrary switching signals. A state feedback controller design method is proposed to obtain an eigenstructure assignment that ensures that the closed-loop switched system is globally asymptotically stable, and the outputs achieve the non-overshooting tracking of a step reference. Our analysis indicates whether non-overshooting or even monotonic tracking is achievable for the given system and considered outputs and provides a choice of possible eigenstructures to be assigned to the constituent subsystems. We derive a structural condition that verifies the feasibility of the chosen assignment. A constructive algorithm to obtain suitable feedback matrices is provided, and the method is illustrated with numerical examples.

Paper number 75:
Title: Minimally Conservative Controlled-Invariant Set Synthesis Using Control Barrier Certificates
Authors: Naeim Ebrahimi Toulkani, Reza Ghabcheloo
Abstract: Finding a controlled-invariant set for a system with state and control constraints is crucial for safety-critical applications. However, existing methods often produce overly conservative solutions. This paper presents a method for generating controlled-invariant (safe) sets for nonlinear polynomial control-affine systems using Control Barrier Certificates (CBCs). We formulate CBC conditions as Sum-of-Squares (SOS) constraints and solve them via an SOS Program (SOSP). First, we generalize existing SOSPs for CBC synthesis to handle environments with complex unsafe state representations. Then, we propose an iterative algorithm that progressively enlarges the safe set constructed by the synthesized CBCs by maximizing boundary expansion at each iteration. We theoretically prove that our method guarantees strict safe set expansion at every step. Finally, we validate our approach with numerical simulations in 2D and 3D for single-input and multi-input systems. Empirical results show that the safe set generated by our method covers in most part a larger portion of the state space compared to two state-of-the-art techniques.

Paper number 76:
Title: Patient-specific prediction of glioblastoma growth via reduced order modeling and neural networks
Authors: D. Cerrone, D. Riccobelli, S. Gazzoni, P. Vitullo, F. Ballarin, J. Falco, F. Acerbi, A. Manzoni, P. Zunino, P. Ciarletta
Abstract: Glioblastoma is among the most aggressive brain tumors in adults, characterized by patient-specific invasion patterns driven by the underlying brain microstructure. In this work, we present a proof-of-concept for a mathematical model of GBL growth, enabling real-time prediction and patient-specific parameter identification from longitudinal neuroimaging data. The framework exploits a diffuse-interface mathematical model to describe the tumor evolution and a reduced-order modeling strategy, relying on proper orthogonal decomposition, trained on synthetic data derived from patient-specific brain anatomies reconstructed from magnetic resonance imaging and diffusion tensor imaging. A neural network surrogate learns the inverse mapping from tumor evolution to model parameters, achieving significant computational speed-up while preserving high accuracy. To ensure robustness and interpretability, we perform both global and local sensitivity analyses, identifying the key biophysical parameters governing tumor dynamics and assessing the stability of the inverse problem solution. These results establish a methodological foundation for future clinical deployment of patient-specific digital twins in neuro-oncology.

Paper number 77:
Title: HCMA-UNet: A Hybrid CNN-Mamba UNet with Axial Self-Attention for Efficient Breast Cancer Segmentation
Authors: Haoxuan Li, Wei song, Peiwu Qin, Xi Yuan, Zhenglin Chen
Abstract: Breast cancer lesion segmentation in DCE-MRI remains challenging due to heterogeneous tumor morphology and indistinct boundaries. To address these challenges, this study proposes a novel hybrid segmentation network, HCMA-UNet, for lesion segmentation of breast cancer. Our network consists of a lightweight CNN backbone and a Multi-view Axial Self-Attention Mamba (MISM) module. The MISM module integrates Visual State Space Block (VSSB) and Axial Self-Attention (ASA) mechanism, effectively reducing parameters through Asymmetric Split Channel (ASC) strategy to achieve efficient tri-directional feature extraction. Our lightweight model achieves superior performance with 2.87M parameters and 126.44 GFLOPs. A Feature-guided Region-aware loss function (FRLoss) is proposed to enhance segmentation accuracy. Extensive experiments on one private and two public DCE-MRI breast cancer datasets demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. FRLoss also exhibits good cross-architecture generalization capabilities. The source code is available at this https URL.

Paper number 78:
Title: Set-point control and local stability for flat nonlinear systems using model-following control
Authors: Julian Willkomm, Kai Wulff, Johann Reger
Abstract: We consider the set-point control problem for nonlinear systems with flat output that are subject to perturbations. The nonlinear dynamics as well as the perturbations are locally Lipschitz. We apply the model-following control (MFC) approach which consists of a model control loop (MCL) for a feedforward generation and a process control loop (PCL) that compensates the perturbations using high-gain feedback. We analyse the resulting closed-loop system and discuss its relation to a standard flatness-based high-gain approach. In particular we analyse the estimated region of attraction provided by a quadratic Lyapunov function. A case study illustrates the approach and quantifies the region of attraction obtained for each control approach. Using the initial condition of the model control loop as tuning parameter for the MFC design, provides that a significantly larger region of attraction can be guaranteed compared to a conventional single-loop high-gain design.

Paper number 79:
Title: Data-Efficient Extremum-Seeking Control Using Kernel-Based Function Approximation
Authors: Wouter Weekers, Alessandro Saccon, Nathan van de Wouw
Abstract: Existing extremum-seeking control (ESC) approaches typically rely on applying repeated perturbations to input parameters and performing measurements of the corresponding performance output. The required separation between the different timescales in the ESC loop means that performing these measurements can be time-consuming. Moreover, performing these measurements can be costly in practice, e.g., due to the use of resources. With these challenges in mind, it is desirable to reduce the number of measurements needed to optimize performance. Therefore, in this work, we present a sampled-data ESC approach aimed at reducing the number of measurements that need to be performed. In the proposed approach, we use input-output data obtained during regular operation of the extremum-seeking controller to construct online an approximation of the system's underlying cost function. By using this approximation to perform parameter updates when a decrease in the cost can be guaranteed, instead of performing additional measurements to perform this update, we make more efficient use of data collected during regular operation of the extremum-seeking controller. As a result, we indeed obtain a reduction in the required number of measurements to achieve optimization. We provide a stability analysis of the novel sampled-data ESC approach, and demonstrate the benefits of the synergy between kernel-based function approximation and standard ESC in simulation on a multi-input dynamical system.

Paper number 80:
Title: Analysis and Optimization of Robustness in Multiplex Flow Networks Against Cascading Failures
Authors: Orkun İrsoy, Osman Yağan
Abstract: Networked systems are susceptible to cascading failures, where the failure of an initial set of nodes propagates through the network, often leading to system-wide failures. In this work, we propose a multiplex flow network model to study robustness against cascading failures triggered by random failures. The model is inspired by systems where nodes carry or support multiple types of flows, and failures result in the redistribution of flows within the same layer rather than between layers. To represent different types of interdependencies between the layers of the multiplex network, we define two cases of failure conditions: layer-independent overload and layer-influenced overload. We provide recursive equations and their solutions to calculate the steady-state fraction of surviving nodes, validate them through a set of simulation experiments, and discuss optimal load-capacity allocation strategies. Our results demonstrate that allocating the total excess capacity to each layer proportional to the mean effective load in the layer and distributing that excess capacity equally among the nodes within the layer ensures maximum robustness. The proposed framework for different failure conditions allows us to analyze the two overload conditions presented and can be extended to explore more complex interdependent relationships.

Paper number 81:
Title: Semantic Learning for Molecular Communication in Internet of Bio-Nano Things
Authors: Hanlin Cai, Ozgur B. Akan
Abstract: Molecular communication (MC) provides a foundational framework for information transmission in the Internet of Bio-Nano Things (IoBNT), where efficiency and reliability are crucial. However, the inherent limitations of molecular channels, such as low transmission rates, noise, and intersymbol interference (ISI), limit their ability to support complex data transmission. This paper proposes an end-to-end semantic learning framework designed to optimize task-oriented molecular communication, with a focus on biomedical diagnostic tasks under resource-constrained conditions. The proposed framework employs a deep encoder-decoder architecture to efficiently extract, quantize, and decode semantic features, prioritizing taskrelevant semantic information to enhance diagnostic classification performance. Additionally, a probabilistic channel network is introduced to approximate molecular propagation dynamics, enabling gradient-based optimization for end-to-end learning. Experimental results demonstrate that the proposed semantic framework improves diagnostic accuracy by at least 25% compared to conventional JPEG compression with LDPC coding methods under resource-constrained communication scenarios.

Paper number 82:
Title: Decentralized State Estimation and Opacity Verification Based on Partially Ordered Observation Sequences
Authors: Dajiang Sun, Christoforos N. Hadjicostis, Zhiwu Li
Abstract: In this paper, we investigate state estimation and opacity verification problems within a decentralized observation architecture. Specifically, we consider a discrete event system whose behavior is recorded by a set of observation sites. These sites transmit the partially ordered sequences of observations that they record to a coordinator whenever a \textit{synchronization} occurs. To properly analyze the system behavior from the coordinator's viewpoint, we first introduce the notion of a Complete Synchronizing Sequence structure (CSS structure), which concisely captures the state evolution of each system state upon different information provided by the observation sites. Based on the CSS structure, we then construct corresponding current-state and initial-state estimators for offline state estimation at the coordinator. When used to verify state-isolation properties under this decentralized architecture, the use of CSS structure demonstrates a significant reduction in complexity compared with existing approaches in the literature. In particular, we discuss how to verify initial-state opacity at the coordinator, as well as a novel opacity notion, namely current-state-at-synchronization opacity.

Paper number 83:
Title: A Comparative Tutorial of the Histogram-based Image Segmentation Methods
Authors: ZhenZhou Wang
Abstract: The histogram of an image is the accurate graphical representation of the numerical grayscale distribution and it is also an estimate of the probability distribution of image pixels. Therefore, histogram has been widely adopted to calculate the clustering means and partitioning thresholds for image segmentation. There have been many classical histogram-based image segmentation methods proposed and played important roles in both academics and industry. In this tutorial, the histories and recent advances of the histogram-based image segmentation techniques are first reviewed and then they are divided into four categories: (1) the means-based method, (2) the Gaussian-mixture-model-based method, (3) the entropy-based method and (4) the feature-points-based method. The purpose of this tutorial is threefold: 1) to teach the principles of the classical histogram-based image segmentation methods to the interested readers; 2) to evaluate the advantages and disadvantages of these classical histogram-based image segmentation methods objectively; 3) to compare the performances of these classical histogram-based image segmentation methods with state-of-the-art deep learning based methods objectively.

Paper number 84:
Title: Minimal positive Markov realizations
Authors: Hamed Taghavian, Jens Sjölund
Abstract: Finding a positive state-space realization with the minimum dimension for a given transfer function is an open problem in control theory. In this paper, we focus on positive realizations in Markov form and propose a linear programming approach that computes them with a minimum dimension. Such minimum dimension of positive Markov realizations is an upper bound of the minimal positive realization dimension. However, we show that these two dimensions are equal for certain systems.

Paper number 85:
Title: UAV-Assisted Coverage Hole Detection Using Reinforcement Learning in Urban Cellular Networks
Authors: Mushfiqur Rahman, Ismail Guvenc, David Ramirez, Chau-Wai Wong
Abstract: Deployment of cellular networks in urban areas requires addressing various challenges. For example, high-rise buildings with varying geometrical shapes and heights contribute to signal attenuation, reflection, diffraction, and scattering effects. This creates a high possibility of coverage holes (CHs) within the proximity of the buildings. Detecting these CHs is critical for network operators to ensure quality of service, as customers in these areas may experience weak or no signal reception. To address this challenge, we propose an approach using an autonomous vehicle, such as an unmanned aerial vehicle (UAV), to detect CHs, for minimizing drive test efforts and reducing human labor. The UAV leverages reinforcement learning (RL) to find CHs using stored local building maps, its current location, and measured signal strengths. As the UAV moves, it dynamically updates its knowledge of the signal environment and its direction to a nearby CH while avoiding collisions with buildings. We created a wide range of testing scenarios using building maps from OpenStreetMap and signal strength data generated by NVIDIA Sionna raytracing simulations. The results show that the RL-based approach outperforms non-machine learning, geometry-based methods in detecting CHs in urban areas. Additionally, even with a limited number of UAV measurements, the method achieves performance close to theoretical upper bounds that assume complete knowledge of all signal strengths.

Paper number 86:
Title: Routing Guidance for Emerging Transportation Systems with Improved Dynamic Trip Equity
Authors: Ting Bai, Anni Li, Gehui Xu, Christos G. Cassandras, Andreas A. Malikopoulos
Abstract: In this paper, we present a dynamic routing guidance system that optimizes route recommendations for individual vehicles within an emerging transportation system while enhancing travelers' trip equity. We develop a framework to quantify trip quality and equity in a dynamic travel environment, providing new insights into how routing guidance influences equity in road transportation. Our approach enables real-time routing by incorporating both monitored and anticipated traffic congestion. We provide conditions that ensure achieving perfect trip equity for all travelers in a free-flow network. Finally, simulation studies on 1,000 vehicles traversing an urban road network in Boston demonstrate that our proposed method improves trip equity by approximately 11.4\% compared to the shortest-route strategy. In addition, the results reveal that our approach redistributes travel costs across vehicle types through route optimization, contributing to a more equitable transportation system.

Paper number 87:
Title: Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data
Authors: Ananya Ganapthy, Praveen Shastry, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Varshinipriya M, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam
Abstract: Background: This study introduces a Vision-Language Model (VLM) leveraging SIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB) screening. By integrating chest X-ray images and clinical notes, the model aims to enhance diagnostic accuracy and efficiency, particularly in resource-limited settings. Methods: The VLM combines visual data from chest X-rays with clinical context to generate detailed, context-aware diagnostic reports. The architecture employs SIGLIP for visual encoding and Gemma-3b for decoding, ensuring effective representation of acute TB-specific pathologies and clinical insights. Results: Key acute TB pathologies, including consolidation, cavities, and nodules, were detected with high precision (97percent) and recall (96percent). The model demonstrated strong spatial localization capabilities and robustness in distinguishing TB-positive cases, making it a reliable tool for acute TB diagnosis. Conclusion: The multimodal capability of the VLM reduces reliance on radiologists, providing a scalable solution for acute TB screening. Future work will focus on improving the detection of subtle pathologies and addressing dataset biases to enhance its generalizability and application in diverse global healthcare settings.

Paper number 88:
Title: Insights into the explainability of Lasso-based DeePC for nonlinear systems
Authors: Gianluca Giacomelli, Simone Formentin, Victor G. Lopez, Matthias A. Müller, Valentina Breschi
Abstract: Data-enabled Predictive Control (DeePC) has recently gained the spotlight as an easy-to-use control technique that allows for constraint handling while relying on raw data only. Initially proposed for linear time-invariant systems, several DeePC extensions are now available to cope with nonlinear systems. Nonetheless, these solutions mainly focus on ensuring the controller's effectiveness, overlooking the explainability of the final result. As a step toward explaining the outcome of DeePC for the control of nonlinear systems, in this paper, we focus on analyzing the earliest and simplest DeePC approach proposed to cope with nonlinearities in the controlled system, using a Lasso regularization. Our theoretical analysis highlights that the decisions undertaken by DeePC with Lasso regularization are unexplainable, as control actions are determined by data incoherent with the system's local behavior. This result is true even when the available input/output samples are grouped according to the different operating conditions explored during data collection. Our numerical study confirms these findings, highlighting the benefits of data grouping in terms of performance while showing that explainability remains a challenge in control design via DeePC.

Paper number 89:
Title: Near-Field THz Bending Beamforming: A Convex Optimization Perspective
Authors: Aoran Liu, Weidong Mei, Peilan Wang, Dong Wang, Ya Fei Wu, Zhi Chen, Boyu Ning
Abstract: Terahertz (THz) communication systems suffer severe blockage issues, which may significantly degrade the communica tion coverage and quality. Bending beams, capable of adjusting their propagation direction to bypass obstacles, have recently emerged as a promising solution to resolve this issue by engineer ing the propagation trajectory of the beam. However, traditional bending beam generation methods rely heavily on the specific geometric properties of the propagation trajectory and can only achieve sub-optimal performance. In this paper, we propose a new and general bending beamforming method by adopting the convex optimization techniques. In particular, we formulate the bending beamforming design as a max-min optimization problem, aiming to optimize the analog or digital transmit beamforming vector to maximize the minimum received signal power among all positions along the bending beam trajectory. However, the resulting problem is non-convex and difficult to be solved optimally. To tackle this difficulty, we apply the successive convex approximation (SCA) technique to obtain a high-quality suboptimal solution. Numerical results show that our proposed bending beamforming method outperforms the traditional method and shows robustness to the obstacle in the environment.

Paper number 90:
Title: QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions
Authors: Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang
Abstract: This paper explores a novel perspective to speech quality assessment by leveraging natural language descriptions, offering richer, more nuanced insights than traditional numerical scoring methods. Natural language feedback provides instructive recommendations and detailed evaluations, yet existing datasets lack the comprehensive annotations needed for this approach. To bridge this gap, we introduce QualiSpeech, a comprehensive low-level speech quality assessment dataset encompassing 11 key aspects and detailed natural language comments that include reasoning and contextual insights. Additionally, we propose the QualiSpeech Benchmark to evaluate the low-level speech understanding capabilities of auditory large language models (LLMs). Experimental results demonstrate that finetuned auditory LLMs can reliably generate detailed descriptions of noise and distortion, effectively identifying their types and temporal characteristics. The results further highlight the potential for incorporating reasoning to enhance the accuracy and reliability of quality assessments. The dataset will be released at this https URL.

Paper number 91:
Title: Nonhuman Primate Brain Tissue Segmentation Using a Transfer Learning Approach
Authors: Zhen Lin, Hongyu Yuan, Richard Barcus, Qing Lyu, Sucheta Chakravarty, Megan E. Lipford, Carol A. Shively, Suzanne Craft, Mohammad Kawas, Jeongchul Kim, Christopher T. Whitlow
Abstract: Non-human primates (NHPs) serve as critical models for understanding human brain function and neurological disorders due to their close evolutionary relationship with humans. Accurate brain tissue segmentation in NHPs is critical for understanding neurological disorders, but challenging due to the scarcity of annotated NHP brain MRI datasets, the small size of the NHP brain, the limited resolution of available imaging data and the anatomical differences between human and NHP brains. To address these challenges, we propose a novel approach utilizing STU-Net with transfer learning to leverage knowledge transferred from human brain MRI data to enhance segmentation accuracy in the NHP brain MRI, particularly when training data is limited. The combination of STU-Net and transfer learning effectively delineates complex tissue boundaries and captures fine anatomical details specific to NHP brains. Notably, our method demonstrated improvement in segmenting small subcortical structures such as putamen and thalamus that are challenging to resolve with limited spatial resolution and tissue contrast, and achieved DSC of over 0.88, IoU over 0.8 and HD95 under 7. This study introduces a robust method for multi-class brain tissue segmentation in NHPs, potentially accelerating research in evolutionary neuroscience and preclinical studies of neurological disorders relevant to human health.

Paper number 92:
Title: OncoReg: Medical Image Registration for Oncological Challenges
Authors: Wiebke Heyer, Yannic Elser, Lennart Berkel, Xinrui Song, Xuanang Xu, Pingkun Yan, Xi Jia, Jinming Duan, Zi Li, Tony C. W. Mok, BoWen LI, Christian Staackmann, Christoph Großbröhmer, Lasse Hansen, Alessa Hering, Malte M. Sieren, Mattias P. Heinrich
Abstract: In modern cancer research, the vast volume of medical data generated is often underutilised due to challenges related to patient privacy. The OncoReg Challenge addresses this issue by enabling researchers to develop and validate image registration methods through a two-phase framework that ensures patient privacy while fostering the development of more generalisable AI models. Phase one involves working with a publicly available dataset, while phase two focuses on training models on a private dataset within secure hospital networks. OncoReg builds upon the foundation established by the Learn2Reg Challenge by incorporating the registration of interventional cone-beam computed tomography (CBCT) with standard planning fan-beam CT (FBCT) images in radiotherapy. Accurate image registration is crucial in oncology, particularly for dynamic treatment adjustments in image-guided radiotherapy, where precise alignment is necessary to minimise radiation exposure to healthy tissues while effectively targeting tumours. This work details the methodology and data behind the OncoReg Challenge and provides a comprehensive analysis of the competition entries and results. Findings reveal that feature extraction plays a pivotal role in this registration task. A new method emerging from this challenge demonstrated its versatility, while established approaches continue to perform comparably to newer techniques. Both deep learning and classical approaches still play significant roles in image registration, with the combination of methods - particularly in feature extraction - proving most effective.

Paper number 93:
Title: Designing Heterogeneous GNNs with Desired Permutation Properties for Wireless Resource Allocation
Authors: Jianyu Zhao, Chenyang Yang, Tingting Liu
Abstract: Graph neural networks (GNNs) have been designed for learning a variety of wireless policies, i.e., the mappings from environment parameters to decision variables, thanks to their superior performance, and the potential in enabling scalability and size generalizability. These merits are rooted in leveraging permutation prior, i.e., satisfying the permutation property of the policy to be learned (referred to as desired permutation property). Many wireless policies are with complicated permutation properties. To satisfy these properties, heterogeneous GNNs (HetGNNs) should be used to learn such policies. There are two critical factors that enable a HetGNN to satisfy a desired permutation property: constructing an appropriate heterogeneous graph and judiciously designing the architecture of the HetGNN. However, both the graph and the HetGNN are designed heuristically so far. In this paper, we strive to provide a systematic approach for the design to satisfy the desired permutation property. We first propose a method for constructing a graph for a policy, where the edges and their types are defined for the sake of satisfying complicated permutation properties. Then, we provide and prove three sufficient conditions to design a HetGNN such that it can satisfy the desired permutation property when learning over an appropriate graph. These conditions suggest a method of designing the HetGNN with desired permutation property by sharing the processing, combining, and pooling functions according to the types of vertices and edges of the graph. We take power allocation and hybrid precoding policies as examples for demonstrating how to apply the proposed methods and validating the impact of the permutation prior by simulations.

Paper number 94:
Title: HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model
Authors: Di Wang, Meiqi Hu, Yao Jin, Yuchun Miao, Jiaqi Yang, Yichu Xu, Xiaolei Qin, Jiaqi Ma, Lingyu Sun, Chenxing Li, Chuan Fu, Hongruixuan Chen, Chengxi Han, Naoto Yokoya, Jing Zhang, Minqiang Xu, Lin Liu, Lefei Zhang, Chen Wu, Bo Du, Dacheng Tao, Liangpei Zhang
Abstract: Accurate hyperspectral image (HSI) interpretation is critical for providing valuable insights into various earth observation-related applications such as urban planning, precision agriculture, and environmental monitoring. However, existing HSI processing methods are predominantly task-specific and scene-dependent, which severely limits their ability to transfer knowledge across tasks and scenes, thereby reducing the practicality in real-world applications. To address these challenges, we present HyperSIGMA, a vision transformer-based foundation model that unifies HSI interpretation across tasks and scenes, scalable to over one billion parameters. To overcome the spectral and spatial redundancy inherent in HSIs, we introduce a novel sparse sampling attention (SSA) mechanism, which effectively promotes the learning of diverse contextual features and serves as the basic block of HyperSIGMA. HyperSIGMA integrates spatial and spectral features using a specially designed spectral enhancement module. In addition, we construct a large-scale hyperspectral dataset, HyperGlobal-450K, for pre-training, which contains about 450K hyperspectral images, significantly surpassing existing datasets in scale. Extensive experiments on various high-level and low-level HSI tasks demonstrate HyperSIGMA's versatility and superior representational capability compared to current state-of-the-art methods. Moreover, HyperSIGMA shows significant advantages in scalability, robustness, cross-modal transferring capability, real-world applicability, and computational efficiency. The code and models will be released at this https URL.

Paper number 95:
Title: Battery Operations in Electricity Markets: Strategic Behavior and Distortions
Authors: Jerry Anunrojwong, Santiago R. Balseiro, Omar Besbes, Bolun Xu
Abstract: Electric power systems are undergoing a major transformation as they integrate intermittent renewable energy sources, and batteries to smooth out variations in renewable energy production. As privately-owned batteries grow from their role as marginal "price-takers" to significant players in the market, a natural question arises: How do batteries operate in electricity markets, and how does the strategic behavior of decentralized batteries distort decisions compared to centralized batteries? We propose an analytically tractable model that captures salient features of the highly complex electricity market. We derive in closed form the resulting battery behavior and generation cost in three operating regimes: (i) no battery, (ii) centralized battery, and (ii) decentralized profit-maximizing battery. We establish that a decentralized battery distorts its discharge decisions in three ways. First, there is quantity withholding, i.e., discharging less than centrally optimal. Second, there is a shift in participation from day-ahead to real-time, i.e., postponing some of its discharge from day-ahead to real-time. Third, there is reduction in real-time responsiveness, or discharging less in response to smoothing real-time demand than centrally optimal. We also quantify the impact of the battery market power on total system cost via the Price of Anarchy metric, and prove that the it is always between $9/8$ and $4/3$. That is, incentive misalignment always exists, but it is bounded even in the worst case. We calibrate our model to real data from Los Angeles and Houston. Lastly, we show that competition is very effective at reducing distortions, but many market power mitigation mechanisms backfire, and lead to higher total cost.

Paper number 96:
Title: STONE: Self-supervised Tonality Estimator
Authors: Yuexuan Kong, Vincent Lostanlen, Gabriel Meseguer-Brocal, Stella Wong, Mathieu Lagrange, Romain Hennequin
Abstract: Although deep neural networks can estimate the key of a musical piece, their supervision incurs a massive annotation effort. Against this shortcoming, we present STONE, the first self-supervised tonality estimator. The architecture behind STONE, named ChromaNet, is a convnet with octave equivalence which outputs a key signature profile (KSP) of 12 structured logits. First, we train ChromaNet to regress artificial pitch transpositions between any two unlabeled musical excerpts from the same audio track, as measured as cross-power spectral density (CPSD) within the circle of fifths (CoF). We observe that this self-supervised pretext task leads KSP to correlate with tonal key signature. Based on this observation, we extend STONE to output a structured KSP of 24 logits, and introduce supervision so as to disambiguate major versus minor keys sharing the same key signature. Applying different amounts of supervision yields semi-supervised and fully supervised tonality estimators: i.e., Semi-TONEs and Sup-TONEs. We evaluate these estimators on FMAK, a new dataset of 5489 real-world musical recordings with expert annotation of 24 major and minor keys. We find that Semi-TONE matches the classification accuracy of Sup-TONE with reduced supervision and outperforms it with equal supervision.

Paper number 97:
Title: Content-decoupled Contrastive Learning-based Implicit Degradation Modeling for Blind Image Super-Resolution
Authors: Jiang Yuan, Ji Ma, Bo Wang, Weiming Hu
Abstract: Implicit degradation modeling-based blind super-resolution (SR) has attracted more increasing attention in the community due to its excellent generalization to complex degradation scenarios and wide application range. How to extract more discriminative degradation representations and fully adapt them to specific image features is the key to this task. In this paper, we propose a new Content-decoupled Contrastive Learning-based blind image super-resolution (CdCL) framework following the typical blind SR pipeline. This framework introduces negative-free contrastive learning technique for the first time to model the implicit degradation representation, in which a new cyclic shift sampling strategy is designed to ensure decoupling between content features and degradation features from the data perspective, thereby improving the purity and discriminability of the learned implicit degradation space. In addition, we propose a detail-aware implicit degradation adapting module that can better adapt degradation representations to specific LR features by enhancing the basic adaptation unit's perception of image details, significantly reducing the overall SR model complexity. Extensive experiments on synthetic and real data show that our method achieves highly competitive quantitative and qualitative results in various degradation settings while obviously reducing parameters and computational costs, validating the feasibility of designing practical and lightweight blind SR tools.

Paper number 98:
Title: Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games
Authors: Chinmay Maheshwari, Manxi Wu, Shankar Sastry
Abstract: Markov games provide a powerful framework for modeling strategic multi-agent interactions in dynamic environments. Traditionally, convergence properties of decentralized learning algorithms in these settings have been established only for special cases, such as Markov zero-sum and potential games, which do not fully capture real-world interactions. In this paper, we address this gap by studying the asymptotic properties of learning algorithms in general-sum Markov games. In particular, we focus on a decentralized algorithm where each agent adopts an actor-critic learning dynamic with asynchronous step sizes. This decentralized approach enables agents to operate independently, without requiring knowledge of others' strategies or payoffs. We introduce the concept of a Markov Near-Potential Function (MNPF) and demonstrate that it serves as an approximate Lyapunov function for the policy updates in the decentralized learning dynamics, which allows us to characterize the convergent set of strategies. We further strengthen our result under specific regularity conditions and with finite Nash equilibria.

Paper number 99:
Title: 1-2-3-Go! Policy Synthesis for Parameterized Markov Decision Processes via Decision-Tree Learning and Generalization
Authors: Muqsit Azeem, Debraj Chakraborty, Sudeep Kanav, Jan Kretinsky, Mohammadsadegh Mohagheghi, Stefanie Mohr, Maximilian Weininger
Abstract: Despite the advances in probabilistic model checking, the scalability of the verification methods remains limited. In particular, the state space often becomes extremely large when instantiating parameterized Markov decision processes (MDPs) even with moderate values. Synthesizing policies for such \emph{huge} MDPs is beyond the reach of available tools. We propose a learning-based approach to obtain a reasonable policy for such huge MDPs. The idea is to generalize optimal policies obtained by model-checking small instances to larger ones using decision-tree learning. Consequently, our method bypasses the need for explicit state-space exploration of large models, providing a practical solution to the state-space explosion problem. We demonstrate the efficacy of our approach by performing extensive experimentation on the relevant models from the quantitative verification benchmark set. The experimental results indicate that our policies perform well, even when the size of the model is orders of magnitude beyond the reach of state-of-the-art analysis tools.

Paper number 100:
Title: Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes
Authors: Gabriel Fernández-Blanco, Iván Froiz-Míguez, Paula Fraga-Lamas, Tiago M. Fernández-Caramés
Abstract: The educational system manages extensive documentation and paperwork, which can lead to human errors and sometimes abuse or fraud, such as the falsification of diplomas, certificates or other credentials. In fact, in the last years, multiple cases of fraud have been detected, which have a significant cost to society, since they harm the trustworthiness of certificates and academic institutions. To tackle such an issue, this article proposes a solution aimed at recording and verifying academic records through a decentralized application that is supported by a smart contract deployed in the Ethereum blockchain and by a decentralized storage system based on Inter-Planetary File System (IPFS). The proposed solution is evaluated in terms of performance and energy-efficiency, comparing the results obtained with a traditional Proof-of-Work (PoW) consensus protocol and the new Proof-of-Authority (PoA) protocol. The results shown in this paper indicate that the latter is clearly greener and demands less CPU load. Moreover, this article compares the performance of a traditional computer and two SBCs (a Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of the latter low-power devices to implement blockchain nodes but at the cost of higher response latency. Furthermore, the impact of Ethereum gas limit is evaluated, demonstrating its significant influence on the blockchain network performance. Thus, this article provides guidelines, useful practical evaluations and key findings that will help the next generation of green blockchain developers and researchers.

Paper number 101:
Title: Robust Bayesian Optimization via Localized Online Conformal Prediction
Authors: Dongwon Kim, Matteo Zecchin, Sangwoo Park, Joonhyuk Kang, Osvaldo Simeone
Abstract: Bayesian optimization (BO) is a sequential approach for optimizing black-box objective functions using zeroth-order noisy observations. In BO, Gaussian processes (GPs) are employed as probabilistic surrogate models to estimate the objective function based on past observations, guiding the selection of future queries to maximize utility. However, the performance of BO heavily relies on the quality of these probabilistic estimates, which can deteriorate significantly under model misspecification. To address this issue, we introduce localized online conformal prediction-based Bayesian optimization (LOCBO), a BO algorithm that calibrates the GP model through localized online conformal prediction (CP). LOCBO corrects the GP likelihood based on predictive sets produced by LOCBO, and the corrected GP likelihood is then denoised to obtain a calibrated posterior distribution on the objective function. The likelihood calibration step leverages an input-dependent calibration threshold to tailor coverage guarantees to different regions of the input space. Under minimal noise assumptions, we provide theoretical performance guarantees for LOCBO's iterates that hold for the unobserved objective function. These theoretical findings are validated through experiments on synthetic and real-world optimization tasks, demonstrating that LOCBO consistently outperforms state-of-the-art BO algorithms in the presence of model misspecification.

Paper number 102:
Title: S-KEY: Self-supervised Learning of Major and Minor Keys from Audio
Authors: Yuexuan Kong, Gabriel Meseguer-Brocal, Vincent Lostanlen, Mathieu Lagrange, Romain Hennequin
Abstract: STONE, the current method in self-supervised learning for tonality estimation in music signals, cannot distinguish relative keys, such as C major versus A minor. In this article, we extend the neural network architecture and learning objective of STONE to perform self-supervised learning of major and minor keys (S-KEY). Our main contribution is an auxiliary pretext task to STONE, formulated using transposition-invariant chroma features as a source of pseudo-labels. S-KEY matches the supervised state of the art in tonality estimation on FMAKv2 and GTZAN datasets while requiring no human annotation and having the same parameter budget as STONE. We build upon this result and expand the training set of S-KEY to a million songs, thus showing the potential of large-scale self-supervised learning in music information retrieval.

Paper number 103:
Title: RG-Attn: Radian Glue Attention for Multi-modality Multi-agent Cooperative Perception
Authors: Lantao Li, Kang Yang, Wenqi Zhang, Xiaoxue Wang, Chen Sun
Abstract: Cooperative perception offers an optimal solution to overcome the perception limitations of single-agent systems by leveraging Vehicle-to-Everything (V2X) communication for data sharing and fusion across multiple agents. However, most existing approaches focus on single-modality data exchange, limiting the potential of both homogeneous and heterogeneous fusion across agents. This overlooks the opportunity to utilize multi-modality data per agent, restricting the system's performance. In the automotive industry, manufacturers adopt diverse sensor configurations, resulting in heterogeneous combinations of sensor modalities across agents. To harness the potential of every possible data source for optimal performance, we design a robust LiDAR and camera cross-modality fusion module, Radian-Glue-Attention (RG-Attn), applicable to both intra-agent cross-modality fusion and inter-agent cross-modality fusion scenarios, owing to the convenient coordinate conversion by transformation matrix and the unified sampling/inversion mechanism. We also propose two different architectures, named Paint-To-Puzzle (PTP) and Co-Sketching-Co-Coloring (CoS-CoCo), for conducting cooperative perception. PTP aims for maximum precision performance and achieves smaller data packet size by limiting cross-agent fusion to a single instance, but requiring all participants to be equipped with LiDAR. In contrast, CoS-CoCo supports agents with any configuration-LiDAR-only, camera-only, or LiDAR-camera-both, presenting more generalization ability. Our approach achieves state-of-the-art (SOTA) performance on both real and simulated cooperative perception datasets. The code is now available at GitHub.

Paper number 104:
Title: Heterogeneous bimodal attention fusion for speech emotion recognition
Authors: Jiachen Luo, Huy Phan, Lin Wang, Joshua Reiss
Abstract: Multi-modal emotion recognition in conversations is a challenging problem due to the complex and complementary interactions between different modalities. Audio and textual cues are particularly important for understanding emotions from a human perspective. Most existing studies focus on exploring interactions between audio and text modalities at the same representation level. However, a critical issue is often overlooked: the heterogeneous modality gap between low-level audio representations and high-level text representations. To address this problem, we propose a novel framework called Heterogeneous Bimodal Attention Fusion (HBAF) for multi-level multi-modal interaction in conversational emotion recognition. The proposed method comprises three key modules: the uni-modal representation module, the multi-modal fusion module, and the inter-modal contrastive learning module. The uni-modal representation module incorporates contextual content into low-level audio representations to bridge the heterogeneous multi-modal gap, enabling more effective fusion. The multi-modal fusion module uses dynamic bimodal attention and a dynamic gating mechanism to filter incorrect cross-modal relationships and fully exploit both intra-modal and inter-modal interactions. Finally, the inter-modal contrastive learning module captures complex absolute and relative interactions between audio and text modalities. Experiments on the MELD and IEMOCAP datasets demonstrate that the proposed HBAF method outperforms existing state-of-the-art baselines.

Paper number 105:
Title: Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions
Authors: Declan Jagt, Sergei Chernyshenko, Matthew Peet
Abstract: PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, for 2nd order PDEs with periodic boundary conditions, the nullspace of the differential operator $\frac{\partial^2}{\partial x^2}$ is nontrivial on the PDE domain, and solutions may converge to non-stationary trajectories existing in this nullspace. To test this convergence behaviour, in this paper, it is shown how we can model these trajectories for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any function $\mathbf{u}(t)$ in the PDE domain can be decomposed into a component defined by $\mathbf{u}_{xx}(t)$, and a component $\bar{\mathbf{u}}(t)$ existing in the nullspace of $\frac{\partial^2}{\partial x^2}$. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both $\mathbf{u}_{xx}(t)$ and $\bar{\mathbf{u}}(t)$. Finally, a notion of exponential stability is defined for trajectories $\mathbf{u}^*(t)=\bar{\mathbf{u}}(t)$, and it is shown that stability of these trajectories as well as of the equilibrium $\mathbf{u}^*\equiv0$ can be tested by solving a linear operator inequality. The proposed methodology is applied to two examples, demonstrating that stability can be verified with tight bounds on the rate of exponential decay.
    