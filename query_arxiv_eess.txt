
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Segmenting Bi-Atrial Structures Using ResNext Based Framework
Authors: Malitha Gunawardhana, Fangqiang Xu, Jichao Zhao
Abstract: Atrial fibrillation (AF) is the most common cardiac arrhythmia, significantly contributing to mortality, particularly in older populations. While pulmonary vein isolation is a standard treatment, its effectiveness is limited in patients with persistent AF. Recent research highlights the importance of targeting additional atrial regions, particularly fibrotic areas identified via late gadolinium-enhanced MRI (LGE-MRI). However, existing manual segmentation methods are time-consuming and prone to variability. Deep learning techniques, particularly convolutional neural networks (CNNs), have shown promise in automating segmentation. However, most studies focus solely on the left atrium (LA) and rely on small datasets, limiting generalizability. In this paper, we propose a novel two-stage framework incorporating ResNeXt encoders and a cyclic learning rate to segment both the right atrium (RA) and LA walls and cavities in LGE-MRIs. Our method aims to improve the segmentation of challenging small structures, such as atrial walls while maintaining high performance in larger regions like the atrial cavities. The results demonstrate that our approach offers superior segmentation accuracy and robustness compared to traditional architectures, particularly for imbalanced class structures.

Paper number 2:
Title: Modality-Agnostic Style Transfer for Holistic Feature Imputation
Authors: Seunghun Baek, Jaeyoon Sim, Mustafa Dere, Minjeong Kim, Guorong Wu, Won Hwa Kim
Abstract: Characterizing a preclinical stage of Alzheimer's Disease (AD) via single imaging is difficult as its early symptoms are quite subtle. Therefore, many neuroimaging studies are curated with various imaging modalities, e.g., MRI and PET, however, it is often challenging to acquire all of them from all subjects and missing data become inevitable. In this regards, in this paper, we propose a framework that generates unobserved imaging measures for specific subjects using their existing measures, thereby reducing the need for additional examinations. Our framework transfers modality-specific style while preserving AD-specific content. This is done by domain adversarial training that preserves modality-agnostic but AD-specific information, while a generative adversarial network adds an indistinguishable modality-specific style. Our proposed framework is evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) study and compared with other imputation methods in terms of generated data quality. Small average Cohen's $d$ $< 0.19$ between our generated measures and real ones suggests that the synthetic data are practically usable regardless of their modality type.

Paper number 3:
Title: OCL: Ordinal Contrastive Learning for Imputating Features with Progressive Labels
Authors: Seunghun Baek, Jaeyoon Sim, Guorong Wu, Won Hwa Kim
Abstract: Accurately discriminating progressive stages of Alzheimer's Disease (AD) is crucial for early diagnosis and prevention. It often involves multiple imaging modalities to understand the complex pathology of AD, however, acquiring a complete set of images is challenging due to high cost and burden for subjects. In the end, missing data become inevitable which lead to limited sample-size and decrease in precision in downstream analyses. To tackle this challenge, we introduce a holistic imaging feature imputation method that enables to leverage diverse imaging features while retaining all subjects. The proposed method comprises two networks: 1) An encoder to extract modality-independent embeddings and 2) A decoder to reconstruct the original measures conditioned on their imaging modalities. The encoder includes a novel {\em ordinal contrastive loss}, which aligns samples in the embedding space according to the progression of AD. We also maximize modality-wise coherence of embeddings within each subject, in conjunction with domain adversarial training algorithms, to further enhance alignment between different imaging modalities. The proposed method promotes our holistic imaging feature imputation across various modalities in the shared embedding space. In the experiments, we show that our networks deliver favorable results for statistical analysis and classification against imputation baselines with Alzheimer's Disease Neuroimaging Initiative (ADNI) study.

Paper number 4:
Title: Surgical Vision World Model
Authors: Saurabh Koju, Saurav Bastola, Prashant Shrestha, Sanskar Amgain, Yash Raj Shrestha, Rudra P. K. Poudel, Binod Bhattarai
Abstract: Realistic and interactive surgical simulation has the potential to facilitate crucial applications, such as medical professional training and autonomous surgical agent training. In the natural visual domain, world models have enabled action-controlled data generation, demonstrating the potential to train autonomous agents in interactive simulated environments when large-scale real data acquisition is infeasible. However, such works in the surgical domain have been limited to simplified computer simulations, and lack realism. Furthermore, existing literature in world models has predominantly dealt with action-labeled data, limiting their applicability to real-world surgical data, where obtaining action annotation is prohibitively expensive. Inspired by the recent success of Genie in leveraging unlabeled video game data to infer latent actions and enable action-controlled data generation, we propose the first surgical vision world model. The proposed model can generate action-controllable surgical data and the architecture design is verified with extensive experiments on the unlabeled SurgToolLoc-2022 dataset. Codes and implementation details are available at this https URL

Paper number 5:
Title: Machine Learning Applications to Diffuse Reflectance Spectroscopy in Optical Diagnosis; A Systematic Review
Authors: Nicola Rossberg, Celina L. Li, Simone Innocente, Stefan Andersson-Engels, Katarzyna Komolibus, Barry O'Sullivan, Andrea Visentin
Abstract: Diffuse Reflectance Spectroscopy has demonstrated a strong aptitude for identifying and differentiating biological tissues. However, the broadband and smooth nature of these signals require algorithmic processing, as they are often difficult for the human eye to distinguish. The implementation of machine learning models for this task has demonstrated high levels of diagnostic accuracies and led to a wide range of proposed methodologies for applications in various illnesses and conditions. In this systematic review, we summarise the state of the art of these applications, highlight current gaps in research and identify future directions. This review was conducted in accordance with the PRISMA guidelines. 77 studies were retrieved and in-depth analysis was conducted. It is concluded that diffuse reflectance spectroscopy and machine learning have strong potential for tissue differentiation in clinical applications, but more rigorous sample stratification in tandem with in-vivo validation and explainable algorithm development is required going forward.

Paper number 6:
Title: Diagnosis of Patients with Viral, Bacterial, and Non-Pneumonia Based on Chest X-Ray Images Using Convolutional Neural Networks
Authors: Carlos Arizmendi, Jorge Pinto, Alejandro Arboleda, Hernando González
Abstract: According to the World Health Organization (WHO), pneumonia is a disease that causes a significant number of deaths each year. In response to this issue, the development of a decision support system for the classification of patients into those without pneumonia and those with viral or bacterial pneumonia is proposed. This is achieved by implementing transfer learning (TL) using pre-trained convolutional neural network (CNN) models on chest x-ray (CXR) images. The system is further enhanced by integrating Relief and Chi-square methods as dimensionality reduction techniques, along with support vector machines (SVM) for classification. The performance of a series of experiments was evaluated to build a model capable of distinguishing between patients without pneumonia and those with viral or bacterial pneumonia. The obtained results include an accuracy of 91.02%, precision of 97.73%, recall of 98.03%, and an F1 Score of 97.88% for discriminating between patients without pneumonia and those with pneumonia. In addition, accuracy of 93.66%, precision of 94.26%, recall of 92.66%, and an F1 Score of 93.45% were achieved for discriminating between patients with viral pneumonia and those with bacterial pneumonia.

Paper number 7:
Title: Hyperspectral Image Restoration and Super-resolution with Physics-Aware Deep Learning for Biomedical Applications
Authors: Yuchen Xiang, Zhaolu Liu, Monica Emili Garcia-Segura, Daniel Simon, Boxuan Cao, Vincen Wu, Kenneth Robinson, Yu Wang, Ronan Battle, Robert T.Murray, Xavier Altafaj, Luca Peruzzotti-Jametti, Zoltan Takats
Abstract: Hyperspectral imaging is a powerful bioimaging tool which can uncover novel insights, thanks to its sensitivity to the intrinsic properties of materials. However, this enhanced contrast comes at the cost of system complexity, constrained by an inherent trade-off between spatial resolution, spectral resolution, and imaging speed. To overcome this limitation, we present a deep learning-based approach that restores and enhances pixel resolution post-acquisition without any a priori knowledge. Fine-tuned using metrics aligned with the imaging model, our physics-aware method achieves a 16X pixel super-resolution enhancement and a 12X imaging speedup without the need of additional training data for transfer learning. Applied to both synthetic and experimental data from five different sample types, we demonstrate that the model preserves biological integrity, ensuring no features are lost or hallucinated. We also concretely demonstrate the model's ability to reveal disease-associated metabolic changes in Downs syndrome that would otherwise remain undetectable. Furthermore, we provide physical insights into the inner workings of the model, paving the way for future refinements that could potentially surpass instrumental limits in an explainable manner. All methods are available as open-source software on GitHub.

Paper number 8:
Title: Computer-aided shape features extraction and regression models for predicting the ascending aortic aneurysm growth rate
Authors: Leonardo Geronzi, Antonio Martinez, Michel Rochette, Kexin Yan, Aline Bel-Brunon, Pascal Haigron, Pierre Escrig, Jacques Tomasi, Morgan Daniel, Alain Lalande, Siyu Lin, Diana Marcela Marin-Castrillon, Olivier Bouchot, Jean Porterie, Pier Paolo Valentini, Marco Evangelos Biancolini
Abstract: Objective: ascending aortic aneurysm growth prediction is still challenging in clinics. In this study, we evaluate and compare the ability of local and global shape features to predict ascending aortic aneurysm growth. Material and methods: 70 patients with aneurysm, for which two 3D acquisitions were available, are included. Following segmentation, three local shape features are computed: (1) the ratio between maximum diameter and length of the ascending aorta centerline, (2) the ratio between the length of external and internal lines on the ascending aorta and (3) the tortuosity of the ascending tract. By exploiting longitudinal data, the aneurysm growth rate is derived. Using radial basis function mesh morphing, iso-topological surface meshes are created. Statistical shape analysis is performed through unsupervised principal component analysis (PCA) and supervised partial least squares (PLS). Two types of global shape features are identified: three PCA-derived and three PLS-based shape modes. Three regression models are set for growth prediction: two based on gaussian support vector machine using local and PCA-derived global shape features; the third is a PLS linear regression model based on the related global shape features. The prediction results are assessed and the aortic shapes most prone to growth are identified. Results: the prediction root mean square error from leave-one-out cross-validation is: 0.112 mm/month, 0.083 mm/month and 0.066 mm/month for local, PCA-based and PLS-derived shape features, respectively. Aneurysms close to the root with a large initial diameter report faster growth. Conclusion: global shape features might provide an important contribution for predicting the aneurysm growth.

Paper number 9:
Title: Interpretable Few-Shot Retinal Disease Diagnosis with Concept-Guided Prompting of Vision-Language Models
Authors: Deval Mehta, Yiwen Jiang, Catherine L Jan, Mingguang He, Kshitij Jadhav, Zongyuan Ge
Abstract: Recent advancements in deep learning have shown significant potential for classifying retinal diseases using color fundus images. However, existing works predominantly rely exclusively on image data, lack interpretability in their diagnostic decisions, and treat medical professionals primarily as annotators for ground truth labeling. To fill this gap, we implement two key strategies: extracting interpretable concepts of retinal diseases using the knowledge base of GPT models and incorporating these concepts as a language component in prompt-learning to train vision-language (VL) models with both fundus images and their associated concepts. Our method not only improves retinal disease classification but also enriches few-shot and zero-shot detection (novel disease detection), while offering the added benefit of concept-based model interpretability. Our extensive evaluation across two diverse retinal fundus image datasets illustrates substantial performance gains in VL-model based few-shot methodologies through our concept integration approach, demonstrating an average improvement of approximately 5.8\% and 2.7\% mean average precision for 16-shot learning and zero-shot (novel class) detection respectively. Our method marks a pivotal step towards interpretable and efficient retinal disease recognition for real-world clinical applications.

Paper number 10:
Title: ExposNet: A Deep Learning Framework for EMF Exposure Prediction in Complex Urban Environments
Authors: Yarui Zhang, Shanshan Wang, Joe Wiart
Abstract: The prediction of the electric field (E-field) plays a crucial role in monitoring radiofrequency electromagnetic field (RF-EMF) exposure induced by cellular networks. In this paper, a deep learning framework is proposed to predict E-field levels in complex urban environments. First, the measurement campaign and publicly accessible databases used to construct the training dataset are introduced, with a detailed explanation provided on how these datasets are formulated and integrated to enhance their suitability for Convolutional Neural Networks (CNNs)-based models. Then, the proposed model, ExposNet, is presented, and its network architecture and workflow are thoroughly explained. Two variations of the network structure are proposed, and extensive experimental analyses are conducted, demonstrating that ExposNet achieves good prediction accuracy with both configurations. Furthermore, the generalization capability of the model is evaluated. The overall results indicate that, despite being trained and tested on real-world measurements, the model performs well and achieves better accuracy compared to previous studies.

Paper number 11:
Title: HARP 2.0: Expanding Hosted, Asynchronous, Remote Processing for Deep Learning in the DAW
Authors: Christodoulos Benetatos, Frank Cwitkowitz, Nathan Pruyne, Hugo Flores Garcia, Patrick O'Reilly, Zhiyao Duan, Bryan Pardo
Abstract: HARP 2.0 brings deep learning models to digital audio workstation (DAW) software through hosted, asynchronous, remote processing, allowing users to route audio from a plug-in interface through any compatible Gradio endpoint to perform arbitrary transformations. HARP renders endpoint-defined controls and processed audio in-plugin, meaning users can explore a variety of cutting-edge deep learning models without ever leaving the DAW. In the 2.0 release we introduce support for MIDI-based models and audio/MIDI labeling models, provide a streamlined pyharp Python API for model developers, and implement numerous interface and stability improvements. Through this work, we hope to bridge the gap between model developers and creatives, improving access to deep learning models by seamlessly integrating them into DAW workflows.

Paper number 12:
Title: Regularization for Covariance Parameterization of Direct Data-Driven LQR Control
Authors: Feiran Zhao, Alessandro Chiuso, Florian Dörfler
Abstract: As the benchmark of data-driven control methods, the linear quadratic regulator (LQR) problem has gained significant attention. A growing trend is direct LQR design, which finds the optimal LQR gain directly from raw data and bypassing system identification. To achieve this, our previous work develops a direct LQR formulation parameterized by sample covariance. In this paper, we propose a regularization method for the covariance-parameterized LQR. We show that the regularizer accounts for the uncertainty in both the steady-state covariance matrix corresponding to closed-loop stability, and the LQR cost function corresponding to averaged control performance. With a positive or negative coefficient, the regularizer can be interpreted as promoting either exploitation or exploration, which are well-known trade-offs in reinforcement learning. In simulations, we observe that our covariance-parameterized LQR with regularization can significantly outperform the certainty-equivalence LQR in terms of both the optimality gap and the robust closed-loop stability.

Paper number 13:
Title: Identification of High Impedance Faults Utilizing Recurrence Plots
Authors: Pallav Kumar Bera, Samita Rani Pani, Rajesh Kumar
Abstract: This paper presents a systematic approach to detecting High Impedance Faults (HIFs) in medium voltage distribution networks using recurrence plots and machine learning. We first simulate 1150 internal faults, including 300 HIFs, 1000 external faults, and 40 normal conditions using the PSCAD/EMTDC software. Key features are extracted from the 3-phase differential currents using wavelet coefficients, which are then converted into recurrence matrices. A multi-stage classification framework is employed, where the first classification stage identifies internal faults, and the second stage distinguishes HIFs from other internal faults. The framework is evaluated using accuracy, precision, recall, and F1 score. Tree-based classifiers, particularly Random Forest and Decision Tree, achieve superior performance, with 99.24% accuracy in the first stage and 98.26% in the second. The results demonstrate the effectiveness of integrating recurrence analysis with machine learning for fault detection in power distribution networks.

Paper number 14:
Title: Learning Precoding in Multi-user Multi-antenna Systems: Transformer or Graph Transformer?
Authors: Yuxuan Duan, Jia Guo, Chenyang Yang
Abstract: Transformers have been designed for channel acquisition tasks such as channel prediction and other tasks such as precoding, while graph neural networks (GNNs) have been demonstrated to be efficient for learning a multitude of communication tasks. Nonetheless, whether or not Transformers are efficient for the tasks other than channel acquisition and how to reap the benefits of both architectures are less understood. In this paper, we take learning precoding policies in multi-user multi-antenna systems as an example to answer the questions. We notice that a Transformer tailored for precoding can reflect multiuser interference, which is essential for its generalizability to the number of users. Yet the tailored Transformer can only leverage partial permutation property of precoding policies and hence is not generalizable to the number of antennas, same as a GNN learning over a homogeneous graph. To provide useful insight, we establish the relation between Transformers and the GNNs that learn over heterogeneous graphs. Based on the relation, we propose Graph Transformers, namely 2D- and 3D-Gformers, for exploiting the permutation properties of baseband precoding and hybrid precoding policies. The learning performance, inference and training complexity, and size-generalizability of the Gformers are evaluated and compared with Transformers and GNNs via simulations.

Paper number 15:
Title: Multi-Step Deep Koopman Network (MDK-Net) for Vehicle Control in Frenet Frame
Authors: Mohammad Abtahi, Mahdis Rabbani, Armin Abdolmohammadi, Shima Nazari
Abstract: The highly nonlinear dynamics of vehicles present a major challenge for the practical implementation of optimal and Model Predictive Control (MPC) approaches in path planning and following. Koopman operator theory offers a global linear representation of nonlinear dynamical systems, making it a promising framework for optimization-based vehicle control. This paper introduces a novel deep learning-based Koopman modeling approach that employs deep neural networks to capture the full vehicle dynamics-from pedal and steering inputs to chassis states-within a curvilinear Frenet frame. The superior accuracy of the Koopman model compared to identified linear models is shown for a double lane change maneuver. Furthermore, it is shown that an MPC controller deploying the Koopman model provides significantly improved performance while maintaining computational efficiency comparable to a linear MPC.

Paper number 16:
Title: Integrated Communication and RIS-aided Track-Before-Detect Radar Sensing
Authors: Georgios Mylonopoulos, Luca Venturino, Emanuele Grossi, Stefano Buzzi, Ciro D'Elia
Abstract: This paper investigates an integrated sensing and communication system where the base station serves multiple downlink users, while employing a passive reconfigurable intelligent surface to detect small, noncooperative airborne targets. We propose a method to design the two-way beampattern of the RIS-assisted monostatic radar, which allows controlling the sidelobe levels in the presence of eavesdroppers, jammers, and other scattering objects and avoiding any radar interference to the users. To obtain more favorable system tradeoffs, we exploit the correlation of the target echoes over consecutive scans by resorting to a multi-frame radar detector, which includes a detector, a plot-extractor, and a track-before-detect processor. A numerical analysis is provided to verify the effectiveness of the proposed solutions and to assess the achievable tradeoffs. Our results show that, by increasing the number of scans processed by the radar detector (and therefore its implementation complexity), we can reduce the amount of power dedicated to the radar function while maintaining the same sensing performance (measured in terms of probability of target detection and root mean square error in the estimation of target position); this excess power can be reused to increase the user sum-rate.

Paper number 17:
Title: Federated Learning Meets Fluid Antenna: Towards Robust and Scalable Edge Intelligence
Authors: Sangjun Park, Hyowoon Seo
Abstract: Federated learning (FL) is an emerging machine learning paradigm with immense potential to support advanced services and applications in future industries. However, when deployed over wireless communication systems, FL suffers from significant communication overhead, which can be alleviated by integrating over-the-air computation (AirComp). Despite its advantages, AirComp introduces learning inaccuracies due to the inherent randomness of wireless channels, which can degrade overall learning performance. To address this issue, this paper explores the integration of fluid antenna systems (FAS) into AirComp-based FL to enhance system robustness and efficiency. Fluid antennas offer dynamic spatial diversity by adaptively selecting antenna ports, thereby mitigating channel variations and improving signal aggregation. Specifically, we propose an antenna selection rule for fluid-antenna-equipped devices that optimally enhances learning robustness or training performance. Building on this, we develop a learning algorithm and provide a theoretical convergence analysis. The simulation results validate the effectiveness of fluid antennas in improving FL performance, demonstrating their potential as a key enabler for wireless AI applications.

Paper number 18:
Title: Implicit U-KAN2.0: Dynamic, Efficient and Interpretable Medical Image Segmentation
Authors: Chun-Wun Cheng, Yining Zhao, Yanqi Cheng, Javier Montoya, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero
Abstract: Image segmentation is a fundamental task in both image analysis and medical applications. State-of-the-art methods predominantly rely on encoder-decoder architectures with a U-shaped design, commonly referred to as U-Net. Recent advancements integrating transformers and MLPs improve performance but still face key limitations, such as poor interpretability, difficulty handling intrinsic noise, and constrained expressiveness due to discrete layer structures, often lacking a solid theoretical this http URL this work, we introduce Implicit U-KAN 2.0, a novel U-Net variant that adopts a two-phase encoder-decoder structure. In the SONO phase, we use a second-order neural ordinary differential equation (NODEs), called the SONO block, for a more efficient, expressive, and theoretically grounded modeling approach. In the SONO-MultiKAN phase, we integrate the second-order NODEs and MultiKAN layer as the core computational block to enhance interpretability and representation power. Our contributions are threefold. First, U-KAN 2.0 is an implicit deep neural network incorporating MultiKAN and second order NODEs, improving interpretability and performance while reducing computational costs. Second, we provide a theoretical analysis demonstrating that the approximation ability of the MultiKAN block is independent of the input dimension. Third, we conduct extensive experiments on a variety of 2D and a single 3D dataset, demonstrating that our model consistently outperforms existing segmentation networks.

Paper number 19:
Title: Determinantal Learning for Subset Selection in Wireless Networks
Authors: Xiangliu Tu, Chiranjib Saha, Harpreet S. Dhillon
Abstract: Subset selection is central to many wireless communication problems, including link scheduling, power allocation, and spectrum management. However, these problems are often NP-complete, because of which heuristic algorithms applied to solve these problems struggle with scalability in large-scale settings. To address this, we propose a determinantal point process-based learning (DPPL) framework for efficiently solving general subset selection problems in massive networks. The key idea is to model the optimal subset as a realization of a determinantal point process (DPP), which balances the trade-off between quality (signal strength) and similarity (mutual interference) by enforcing negative correlation in the selection of {\em similar} links (those that create significant mutual interference). However, conventional methods for constructing similarity matrices in DPP impose decomposability and symmetry constraints that often do not hold in practice. To overcome this, we introduce a new method based on the Gershgorin Circle Theorem for constructing valid similarity matrices. The effectiveness of the proposed approach is demonstrated by applying it to two canonical wireless network settings: an ad hoc network in 2D and a cellular network serving drones in 3D. Simulation results show that DPPL selects near-optimal subsets that maximize network sum-rate while significantly reducing computational complexity compared to traditional optimization methods, demonstrating its scalability for large-scale networks.

Paper number 20:
Title: UnPuzzle: A Unified Framework for Pathology Image Analysis
Authors: Dankai Liao, Sicheng Chen, Nuwa Xi, Qiaochu Xue, Jieyu Li, Lingxuan Hou, Zeyu Liu, Chang Han Low, Yufeng Wu, Yiling Liu, Yanqin Jiang, Dandan Li, Yueming Jin, Shangqing Lyu
Abstract: Pathology image analysis plays a pivotal role in medical diagnosis, with deep learning techniques significantly advancing diagnostic accuracy and research. While numerous studies have been conducted to address specific pathological tasks, the lack of standardization in pre-processing methods and model/database architectures complicates fair comparisons across different approaches. This highlights the need for a unified pipeline and comprehensive benchmarks to enable consistent evaluation and accelerate research progress. In this paper, we present UnPuzzle, a novel and unified framework for pathological AI research that covers a broad range of pathology tasks with benchmark results. From high-level to low-level, upstream to downstream tasks, UnPuzzle offers a modular pipeline that encompasses data pre-processing, model composition,taskconfiguration,this http URL, it facilitates efficient benchmarking for both Whole Slide Images (WSIs) and Region of Interest (ROI) tasks. Moreover, the framework supports variouslearningparadigms,includingself-supervisedlearning,multi-task learning,andmulti-modallearning,enablingcomprehensivedevelopment of pathology AI models. Through extensive benchmarking across multiple datasets, we demonstrate the effectiveness of UnPuzzle in streamlining pathology AI research and promoting reproducibility. We envision UnPuzzle as a cornerstone for future advancements in pathology AI, providing a more accessible, transparent, and standardized approach to model evaluation. The UnPuzzle repository is publicly available at this https URL.

Paper number 21:
Title: The Untapped Potential of Smart Charging: How EV Owners Can Save Money and Reduce Emissions Without Behavioral Change
Authors: Yash Gupta, William Vreeland, Andrew Peterman, Coley Girouard, Brian Wang
Abstract: The transportation sector is the single largest contributor to US emissions and the second largest globally. Electric vehicles (EVs) are expected to represent half of global car sales by 2035, emerging as a pivotal solution to reduce emissions and enhance grid flexibility. The electrification of buildings, manufacturing, and transportation is expected to grow electricity demand substantially over the next decade. Without effectively managed EV charging, EVs could strain energy grid infrastructure and increase electricity costs. Drawing on de-identified 2023 EV telematics data from Rivian Automotive, this study found that 72% of home charging commenced after the customer plugged in their vehicle regardless of utility time of use (TOU) tariffs or managed charging programs. In fewer than 26% of charging sessions in the sample, EV owners actively scheduled charging times to align or participate in utility tariffs or programs. With a majority of drivers concurrently plugged in during optimal charging periods yet not actively charging, the study identified an opportunity to reduce individual EV owner costs and carbon emissions through smarter charging habits without significant behavioral modifications or sacrifice in user preferences. By optimizing home charging schedules within existing plug-in and plug-out windows, the study suggests that EV owners can save an average of $140 annually and reduce the associated carbon emissions of charging their EV by as much as 28%.

Paper number 22:
Title: On the Data-Driven Modeling of Price-Responsive Flexible Loads: Formulation and Algorithm
Authors: Mingji Chen, Shuai Lu, Wei Gu, Zhaoyang Dong, Yijun Xu, Jiayi Ding
Abstract: The flexible loads in power systems, such as interruptible and transferable loads, are critical flexibility resources for mitigating power imbalances. Despite their potential, accurate modeling of these loads is a challenging work and has not received enough attention, limiting their integration into operational frameworks. To bridge this gap, this paper develops a data-driven identification theory and algorithm for price-responsive flexible loads (PRFLs). First, we introduce PRFL models that capture both static and dynamic decision mechanisms governing their response to electricity price variations. Second, We develop a data-driven identification framework that explicitly incorporates forecast and measurement errors. Particularly, we give a theoretical analysis to quantify the statistical impact of such noise on parameter estimation. Third, leveraging the bilevel structure of the identification problem, we propose a Bayesian optimization-based algorithm that features the scalability to large sample sizes and the ability to offer posterior differentiability certificates as byproducts. Numerical tests demonstrate the effectiveness and superiority of the proposed approach.

Paper number 23:
Title: PathRWKV: Enabling Whole Slide Prediction with Recurrent-Transformer
Authors: Sicheng Chen, Tianyi Zhang, Dankai Liao, Dandan Li, Low Chang Han, Yanqin Jiang, Yueming Jin, Shangqing Lyu
Abstract: Pathological diagnosis plays a critical role in clinical practice, where the whole slide images (WSIs) are widely applied. Through a two-stage paradigm, recent deep learning approaches enhance the WSI analysis with tile-level feature extracting and slide-level feature modeling. Current Transformer models achieved improvement in the efficiency and accuracy to previous multiple instance learning based approaches. However, three core limitations persist, as they do not: (1) robustly address the modeling on variable scales for different slides, (2) effectively balance model complexity and data availability, and (3) balance training efficiency and inference performance. To explicitly address them, we propose a novel model for slide modeling, PathRWKV. Via a recurrent structure, we enable the model for dynamic perceptible tiles in slide-level modeling, which novelly enables the prediction on all tiles in the inference stage. Moreover, we employ linear attention instead of conventional matrix multiplication attention to reduce model complexity and overfitting problem. Lastly, we hinge multi-task learning to enable modeling on versatile tasks simultaneously, improving training efficiency, and asynchronous structure design to draw an effective conclusion on all tiles during inference, enhancing inference performance. Experimental results suggest that PathRWKV outperforms the current state-of-the-art methods in various downstream tasks on multiple datasets. The code and datasets are publicly available.

Paper number 24:
Title: Rice Grain Size Measurement using Image Processing
Authors: Ankush Tyagi, Dhruv Motwani, Vipul K. Dabhi, Harshadkumar B. Prajapati
Abstract: The rice grain quality can be determined from its size and chalkiness. The traditional approach to measure the rice grain size involves manual inspection, which is inefficient and leads to inconsistent results. To address this issue, an image processing based approach is proposed and developed in this research. The approach takes image of rice grains as input and outputs the number of rice grains and size of each rice grain. The different steps, such as extraction of region of interest, segmentation of rice grains, and sub-contours removal, involved in the proposed approach are discussed. The approach was tested on rice grain images captured from different height using mobile phone camera. The obtained results show that the proposed approach successfully detected 95\% of the rice grains and achieved 90\% accuracy for length and width measurement.

Paper number 25:
Title: Joint Bistatic Positioning and Monostatic Sensing: Optimized Beamforming and Performance Tradeoff
Authors: Yuchen Zhang, Hui Chen, Pinjun Zheng, Boyu Ning, Hong Niu, Henk Wymeersch, Tareq Y. Al-Naffouri
Abstract: We investigate joint bistatic positioning (BP) and monostatic sensing (MS) within a multi-input multi-output orthogonal frequency-division system. Based on the derived Cramér-Rao Bounds (CRBs), we propose novel beamforming optimization strategies that enable flexible performance trade-offs between BP and MS. Two distinct objectives are considered in this multi-objective optimization problem, namely, enabling user equipment to estimate its own position while accounting for unknown clock bias and orientation, and allowing the base station to locate passive targets. We first analyze digital schemes, proposing both weighted-sum CRB and weighted-sum mismatch (of beamformers and covariance matrices) minimization approaches. These are examined under full-dimension beamforming (FDB) and low-complexity codebook-based power allocation (CPA). To adapt to low-cost hardwares, we develop unit-amplitude analog FDB and CPA schemes based on the weighted-sum mismatch of the covariance matrices paradigm, solved using distinct methods. Numerical results confirm the effectiveness of our designs, highlighting the superiority of minimizing the weighted-sum mismatch of covariance matrices, and the advantages of mutual information fusion between BP and MS.

Paper number 26:
Title: Good practices for evaluation of synthesized speech
Authors: Erica Cooper, Sébastien Le Maguer, Esther Klabbers, Junichi Yamagishi
Abstract: This document is provided as a guideline for reviewers of papers about speech synthesis. We outline some best practices and common pitfalls for papers about speech synthesis, with a particular focus on evaluation. We also recommend that reviewers check the guidelines for authors written in the paper kit and consider those as reviewing criteria as well. This is intended to be a living document, and it will be updated as we receive comments and feedback from readers. We note that this document is meant to provide guidance only, and that reviewers should ultimately use their own discretion when evaluating papers.

Paper number 27:
Title: Interactive Segmentation and Report Generation for CT Images
Authors: Yannian Gu, Wenhui Lei, Hanyu Chen, Xiaofan Zhang, Shaoting Zhang
Abstract: Automated CT report generation plays a crucial role in improving diagnostic accuracy and clinical workflow efficiency. However, existing methods lack interpretability and impede patient-clinician understanding, while their static nature restricts radiologists from dynamically adjusting assessments during image review. Inspired by interactive segmentation techniques, we propose a novel interactive framework for 3D lesion morphology reporting that seamlessly generates segmentation masks with comprehensive attribute descriptions, enabling clinicians to generate detailed lesion profiles for enhanced diagnostic assessment. To our best knowledge, we are the first to integrate the interactive segmentation and structured reports in 3D CT medical images. Experimental results across 15 lesion types demonstrate the effectiveness of our approach in providing a more comprehensive and reliable reporting system for lesion segmentation and capturing. The source code will be made publicly available following paper acceptance.

Paper number 28:
Title: On the Relation Between Speech Quality and Quantized Latent Representations of Neural Codecs
Authors: Mhd Modar Halimeh, Matteo Torcoli, Philipp Grundhuber, Emanuël A. P. Habets
Abstract: Neural audio signal codecs have attracted significant attention in recent years. In essence, the impressive low bitrate achieved by such encoders is enabled by learning an abstract representation that captures the properties of encoded signals, e.g., speech. In this work, we investigate the relation between the latent representation of the input signal learned by a neural codec and the quality of speech signals. To do so, we introduce Latent-representation-to-Quantization error Ratio (LQR) measures, which quantify the distance from the idealized neural codec's speech signal model for a given speech signal. We compare the proposed metrics to intrusive measures as well as data-driven supervised methods using two subjective speech quality datasets. This analysis shows that the proposed LQR correlates strongly (up to 0.9 Pearson's correlation) with the subjective quality of speech. Despite being a non-intrusive metric, this yields a competitive performance with, or even better than, other pre-trained and intrusive measures. These results show that LQR is a promising basis for more sophisticated speech quality measures.

Paper number 29:
Title: ScaleFusionNet: Transformer-Guided Multi-Scale Feature Fusion for Skin Lesion Segmentation
Authors: Saqib Qamar, Syed Furqan Qadri, Roobaea Alroobaea, Majed Alsafyani, Abdullah M. Baqasah
Abstract: Melanoma is a malignant tumor originating from skin cell lesions. Accurate and efficient segmentation of skin lesions is essential for quantitative medical analysis but remains challenging. To address this, we propose ScaleFusionNet, a segmentation model that integrates Cross-Attention Transformer Module (CATM) and AdaptiveFusionBlock to enhance feature extraction and fusion. The model employs a hybrid architecture encoder that effectively captures both local and global features. We introduce CATM, which utilizes Swin Transformer Blocks and Cross Attention Fusion (CAF) to adaptively refine encoder-decoder feature fusion, reducing semantic gaps and improving segmentation accuracy. Additionally, the AdaptiveFusionBlock is improved by integrating adaptive multi-scale fusion, where Swin Transformer-based attention complements deformable convolution-based multi-scale feature extraction. This enhancement refines lesion boundaries and preserves fine-grained details. ScaleFusionNet achieves Dice scores of 92.94% and 91.65% on ISIC-2016 and ISIC-2018 datasets, respectively, demonstrating its effectiveness in skin lesion analysis. Our code implementation is publicly available at GitHub.

Paper number 30:
Title: Safety Verification of Nonlinear Stochastic Systems via Probabilistic Tube
Authors: Zishun Liu, Saber Jafarpour, Yongxin Chen
Abstract: We address the problem of safety verification for nonlinear stochastic systems, specifically the task of certifying that system trajectories remain within a safe set with high probability. To tackle this challenge, we adopt a set-erosion strategy, which decouples the effects of stochastic disturbances from deterministic dynamics. This approach converts the stochastic safety verification problem on a safe set into a deterministic safety verification problem on an eroded subset of the safe set. The success of this strategy hinges on the depth of erosion, which is determined by a probabilistic tube that bounds the deviation of stochastic trajectories from their corresponding deterministic trajectories. Our main contribution is the establishment of a tight bound for the probabilistic tube of nonlinear stochastic systems. To obtain a probabilistic bound for stochastic trajectories, we adopt a martingale-based approach. The core innovation lies in the design of a novel energy function associated with the averaged moment generating function, which forms an affine martingale, a generalization of the traditional c-martingale. Using this energy function, we derive a precise bound for the probabilistic tube. Furthermore, we enhance this bound by incorporating the union-bound inequality for strictly contractive dynamics. By integrating the derived probabilistic tubes into the set-erosion strategy, we demonstrate that the safety verification problem for nonlinear stochastic systems can be reduced to a deterministic safety verification problem. Our theoretical results are validated through applications in reachability-based safety verification and safe controller synthesis, accompanied by several numerical examples that illustrate their effectiveness.

Paper number 31:
Title: SEAL: Safety Enhanced Trajectory Planning and Control Framework for Quadrotor Flight in Complex Environments
Authors: Yiming Wang, Jianbin Ma, Junda Wu, Huizhe Li, Zhexuan Zhou, Youmin Gong, Jie Mei, Guangfu Ma
Abstract: For quadrotors, achieving safe and autonomous flight in complex environments with wind disturbances and dynamic obstacles still faces significant challenges. Most existing methods address wind disturbances in either trajectory planning or control, which may lead to hazardous situations during flight. The emergence of dynamic obstacles would further worsen the situation. Therefore, we propose an efficient and reliable framework for quadrotors that incorporates wind disturbance estimations during both the planning and control phases via a generalized proportional integral observer. First, we develop a real-time adaptive spatial-temporal trajectory planner that utilizes Hamilton-Jacobi (HJ) reachability analysis for error dynamics resulting from wind disturbances. By considering the forward reachability sets propagation on an Euclidean Signed Distance Field (ESDF) map, safety is guaranteed. Additionally, a Nonlinear Model Predictive Control (NMPC) controller considering wind disturbance compensation is implemented for robust trajectory tracking. Simulation and real-world experiments verify the effectiveness of our framework. The video and supplementary material will be available at this https URL.

Paper number 32:
Title: Composite Nonlinear Trajectory Tracking Control of Co-Driving Vehicles Using Self-Triggered Adaptive Dynamic Programming
Authors: Chuan Hu, Sicheng Ge, Yingkui Shi, Weinan Gao, Wenfeng Guo, Xi Zhang
Abstract: This article presents a composite nonlinear feedback (CNF) control method using self-triggered (ST) adaptive dynamic programming (ADP) algorithm in a human-machine shared steering framework. For the overall system dynamics, a two-degrees-of-freedom (2-DOF) vehicle model is established and a two-point preview driver model is adopted. A dynamic authority allocation strategy based on cooperation level is proposed to combine the steering input of the human driver and the automatic controller. To make further improvements in the controller design, three main contributions are put forward. Firstly, the CNF controller is designed for trajectory tracking control with refined transient performance. Besides, the self-triggered rule is applied such that the system will update in discrete times to save computing resources and increase efficiency. Moreover, by introducing the data-based ADP algorithm, the optimal control problem can be solved through iteration using system input and output information, reducing the need for accurate knowledge of system dynamics. The effectiveness of the proposed control method is validated through Carsim-Simulink co-simulations in diverse driving scenarios.

Paper number 33:
Title: Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells
Authors: Martina Russo, Giulia Bertolini, Vera Cappelletti, Cinzia De Marco, Serena Di Cosimo, Petra Paiè, Nadia Brancati
Abstract: Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy, offering a noninvasive tool for cancer patient management. However, their identification remains particularly challenging due to their limited number and heterogeneity. Labeling samples for contrast limits the generalization of fluorescence-based methods across different hospital datasets. Analyzing single-cell images enables detailed assessment of cell morphology, subcellular structures, and phenotypic variations, often hidden in clustered images. Developing a method based on bright-field single-cell analysis could overcome these limitations. CTCs can be isolated using an unbiased workflow combining Parsortix technology, which selects cells based on size and deformability, with DEPArray technology, enabling precise visualization and selection of single cells. Traditionally, DEPArray-acquired digital images are manually analyzed, making the process time-consuming and prone to variability. In this study, we present a Deep Learning-based classification pipeline designed to distinguish CTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and optimize clinical workflows. Our approach employs images from the bright-field channel acquired through DEPArray technology leveraging a ResNet-based CNN. To improve model generalization, we applied three types of data augmentation techniques and incorporated fluorescence (DAPI) channel images into the training phase, allowing the network to learn additional CTC-specific features. Notably, only bright-field images have been used for testing, ensuring the model's ability to identify CTCs without relying on fluorescence markers. The proposed model achieved an F1-score of 0.798, demonstrating its capability to distinguish CTCs from leukocytes. These findings highlight the potential of DL in refining CTC analysis and advancing liquid biopsy applications.

Paper number 34:
Title: Skeletonisation Scale-Spaces
Authors: Julia Gierke, Pascal Peter
Abstract: The medial axis transform is a well-known tool for shape recognition. Instead of the object contour, it equivalently describes a binary object in terms of a skeleton containing all centres of maximal inscribed discs. While this shape descriptor is useful for many applications, it is also sensitive to noise: Small boundary perturbations can result in large unwanted expansions of the skeleton. Pruning offers a remedy by removing unwanted skeleton parts. In our contribution, we generalise this principle to skeleton sparsification: We show that subsequently removing parts of the skeleton simplifies the associated shape in a hierarchical manner that obeys scale-space properties. To this end, we provide both a continuous and discrete theory that incorporates architectural and simplification statements as well as invariances. We illustrate how our skeletonisation scale-spaces can be employed for practical applications with two proof-of-concept implementations for pruning and compression.

Paper number 35:
Title: Bridging Synthetic-to-Real Gaps: Frequency-Aware Perturbation and Selection for Single-shot Multi-Parametric Mapping Reconstruction
Authors: Linyu Fan, Che Wang, Ming Ye, Qizhi Yang, Zejun Wu, Xinghao Ding, Yue Huang, Jianfeng Bao, Shuhui Cai, Congbo Cai
Abstract: Data-centric artificial intelligence (AI) has remarkably advanced medical imaging, with emerging methods using synthetic data to address data scarcity while introducing synthetic-to-real gaps. Unsupervised domain adaptation (UDA) shows promise in ground truth-scarce tasks, but its application in reconstruction remains underexplored. Although multiple overlapping-echo detachment (MOLED) achieves ultra-fast multi-parametric reconstruction, extending its application to various clinical scenarios, the quality suffers from deficiency in mitigating the domain gap, difficulty in maintaining structural integrity, and inadequacy in ensuring mapping accuracy. To resolve these issues, we proposed frequency-aware perturbation and selection (FPS), comprising Wasserstein distance-modulated frequency-aware perturbation (WDFP) and hierarchical frequency-aware selection network (HFSNet), which integrates frequency-aware adaptive selection (FAS), compact FAS (cFAS) and feature-aware architecture integration (FAI). Specifically, perturbation activates domain-invariant feature learning within uncertainty, while selection refines optimal solutions within perturbation, establishing a robust and closed-loop learning pathway. Extensive experiments on synthetic data, along with diverse real clinical cases from 5 healthy volunteers, 94 ischemic stroke patients, and 46 meningioma patients, demonstrate the superiority and clinical applicability of FPS. Furthermore, FPS is applied to diffusion tensor imaging (DTI), underscoring its versatility and potential for broader medical applications. The code is available at this https URL.

Paper number 36:
Title: Intermediate Domain-guided Adaptation for Unsupervised Chorioallantoic Membrane Vessel Segmentation
Authors: Pengwu Song, Liang Xu, Peng Yao, Shuwei Shen, Pengfei Shao, Mingzhai Sun, Ronald X. Xu
Abstract: The chorioallantoic membrane (CAM) model is widely employed in angiogenesis research, and distribution of growing blood vessels is the key evaluation indicator. As a result, vessel segmentation is crucial for quantitative assessment based on topology and morphology. However, manual segmentation is extremely time-consuming, labor-intensive, and prone to inconsistency due to its subjective nature. Moreover, research on CAM vessel segmentation algorithms remains limited, and the lack of public datasets contributes to poor prediction performance. To address these challenges, we propose an innovative Intermediate Domain-guided Adaptation (IDA) method, which utilizes the similarity between CAM images and retinal images, along with existing public retinal datasets, to perform unsupervised training on CAM images. Specifically, we introduce a Multi-Resolution Asymmetric Translation (MRAT) strategy to generate intermediate images to promote image-level interaction. Then, an Intermediate Domain-guided Contrastive Learning (IDCL) module is developed to disentangle cross-domain feature representations. This method overcomes the limitations of existing unsupervised domain adaptation (UDA) approaches, which primarily concentrate on directly source-target alignment while neglecting intermediate domain information. Notably, we create the first CAM dataset to validate the proposed algorithm. Extensive experiments on this dataset show that our method outperforms compared approaches. Moreover, it achieves superior performance in UDA tasks across retinal datasets, highlighting its strong generalization capability. The CAM dataset and source codes are available at this https URL.

Paper number 37:
Title: Transformer-Based Power Optimization for Max-Min Fairness in Cell-Free Massive MIMO
Authors: Irched Chafaa, Giacomo Bacci, Luca Sanguinetti
Abstract: Power allocation is an important task in wireless communication networks. Classical optimization algorithms and deep learning methods, while effective in small and static scenarios, become either computationally demanding or unsuitable for large and dynamic networks with varying user loads. This letter explores the potential of transformer-based deep learning models to address these challenges. We propose a transformer neural network to jointly predict optimal uplink and downlink power using only user and access point positions. The max-min fairness problem in cell-free massive multiple input multiple output systems is considered. Numerical results show that the trained model provides near-optimal performance and adapts to varying numbers of users and access points without retraining, additional processing, or updating its neural network architecture. This demonstrates the effectiveness of the proposed model in achieving robust and flexible power allocation for dynamic networks.

Paper number 38:
Title: A Comparative Analysis of Generalised Echo and Interference Cancelling and Extended Multichannel Wiener Filtering for Combined Noise Reduction and Acoustic Echo Cancellation
Authors: Arnout Roebben, Toon van Waterschoot, Marc Moonen
Abstract: Two algorithms for combined acoustic echo cancellation (AEC) and noise reduction (NR) are analysed, namely the generalised echo and interference canceller (GEIC) and the extended multichannel Wiener filter (MWFext). Previously, these algorithms have been examined for linear echo paths, and assuming access to voice activity detectors (VADs) that separately detect desired speech and echo activity. However, algorithms implementing VADs may introduce detection errors. Therefore, in this paper, the previous analyses are extended by 1) modelling general nonlinear echo paths by means of the generalised Bussgang decomposition, and 2) modelling VAD error effects in each specific algorithm, thereby also allowing to model specific VAD assumptions. It is found and verified with simulations that, generally, the MWFext achieves a higher NR performance, while the GEIC achieves a more robust AEC performance.

Paper number 39:
Title: Distributed Distortion-Aware Beamforming Designs for Cell-Free mMIMO Systems
Authors: Mengzhen Liu, Ming Li, Rang Liu, Qian Liu
Abstract: Cell-free massive multi-input multi-output (CF-mMIMO) systems have emerged as a promising paradigm for next-generation wireless communications, offering enhanced spectral efficiency and coverage through distributed antenna arrays. However, the non-linearity of power amplifiers (PAs) in these arrays introduce spatial distortion, which may significantly degrade system performance. This paper presents the first investigation of distortion-aware beamforming in a distributed framework tailored for CF-mMIMO systems, enabling pre-compensation for beam dispersion caused by nonlinear PA distortion. Using a third-order memoryless polynomial distortion model, the impact of the nonlinear PA on the performance of CF-mMIMO systems is firstly analyzed by evaluating the signal-to-interference-noise-and-distortion ratio (SINDR) at user equipment (UE). Then, we develop two distributed distortion-aware beamforming designs based on ring topology and star topology, respectively. In particular, the ring-topology-based fully-distributed approach reduces interconnection costs and computational complexity, while the star-topology-based partially-distributed scheme leverages the superior computation capability of the central processor to achieve improved sum-rate performance. Extensive simulations demonstrate the effectiveness of the proposed distortion-aware beamforming designs in mitigating the effect of nonlinear PA distortion, while also reducing computational complexity and backhaul information exchange in CF-mMIMO systems.

Paper number 40:
Title: Tri-timescale Beamforming Design for Tri-hybrid Architectures with Reconfigurable Antennas
Authors: Mengzhen Liu, Ming Li, Rang Liu, Qian Liu
Abstract: Reconfigurable antennas possess the capability to dynamically adjust their fundamental operating characteristics, thereby enhancing system adaptability and performance. To fully exploit this flexibility in modern wireless communication systems, this paper considers a novel tri-hybrid beamforming architecture, which seamlessly integrates pattern-reconfigurable antennas with both analog and digital beamforming. The proposed tri-hybrid architecture operates across three layers: (\textit{i}) a radiation beamformer in the electromagnetic (EM) domain for dynamic pattern alignment, (\textit{ii}) an analog beamformer in the radio-frequency (RF) domain for array gain enhancement, and (\textit{iii}) a digital beamformer in the baseband (BB) domain for multi-user interference mitigation. To establish a solid theoretical foundation, we first develop a comprehensive mathematical model for the tri-hybrid beamforming system and formulate the signal model for a multi-user multi-input single-output (MU-MISO) scenario. The optimization objective is to maximize the sum-rate while satisfying practical constraints. Given the challenges posed by high pilot overhead and computational complexity, we introduce an innovative tri-timescale beamforming framework, wherein the radiation beamformer is optimized over a long-timescale, the analog beamformer over a medium-timescale, and the digital beamformer over a short-timescale. This hierarchical strategy effectively balances performance and implementation feasibility. Simulation results validate the performance gains of the proposed tri-hybrid architecture and demonstrate that the tri-timescale design significantly reduces pilot overhead and computational complexity, highlighting its potential for future wireless communication systems.

Paper number 41:
Title: Modelowanie nieliniowej charakterystyki szerokopasmowych wzmacniaczy radiowych o zmiennym napięciu zasilania; Modeling Nonlinear Characteristics of Wideband Radio Frequency Amplifiers with Variable Supply Voltage
Authors: Kornelia Kostrzewska, Paweł Kryszkiewicz
Abstract: The work aims to propose a new nonlinear characteristics model for a wideband radio amplifier of variable supply voltage. An extended Rapp model proposal is presented. The proposed model has been verified by measurements of three different amplifiers. This model can be used to design frontend-aware 6G systems. -- Praca ma na celu zaproponowanie nowego modelu dla nieliniowej charakterystyki wzmacniacza radiowego ze zmiennym napięciem zasilania pracującym w szerokim zakresie częstotliwości. Przedstawiona została propozycja rozszerzonego modelu Rappa. Zaproponowany model zweryfikowano na podstawie pomiarów charakterystyk trzech różnych wzmacniaczy. Model ten może być wykorzystany do projektowania systemów 6G "świadomych" niedoskonałości układów wejściowo-wyjściowych.

Paper number 42:
Title: Optimal Policy Design for Repeated Decision-Making under Social Influence
Authors: Chiara Ravazzi, Valentina Breschi, Paolo Frasca, Fabrizio Dabbene, Mara Tanelli
Abstract: In this paper, we present a novel model to characterize individual tendencies in repeated decision-making scenarios, with the goal of designing model-based control strategies that promote virtuous choices amidst social and external influences. Our approach builds on the classical Friedkin and Johnsen model of social influence, extending it to include random factors (e.g., inherent variability in individual needs) and controllable external inputs. We explicitly account for the temporal separation between two processes that shape opinion dynamics: individual decision-making and social imitation. While individual decisions occur at regular, frequent intervals, the influence of social imitation unfolds over longer periods. The inclusion of random factors naturally leads to dynamics that do not converge in the classical sense. However, under specific conditions, we prove that opinions exhibit ergodic behavior. Building on this result, we propose a constrained asymptotic optimal control problem designed to foster, on average, social acceptance of a target action within a network. To address the transient dynamics of opinions, we reformulate this problem within a Model Predictive Control (MPC) framework. Simulations highlight the significance of accounting for these transient effects in steering individuals toward virtuous choices while managing policy costs.

Paper number 43:
Title: A modeling framework to support the electrification of private transport in African cities: a case study of Addis Ababa
Authors: Jérémy Dumoulin, Dawit Gebremeskel, Kanchwodia Gashaw, Ingeborg Graabak, Noémie Jeannin, Alejandro Pena-Bello, Christophe Ballif, Nicolas Wyrsch
Abstract: The electrification of road transport, as the predominant mode of transportation in Africa, represents a great opportunity to reduce greenhouse gas emissions and dependence on costly fuel imports. However, it introduces major challenges for local energy infrastructures, including the deployment of charging stations and the impact on often fragile electricity grids. Despite its importance, research on electric mobility planning in Africa remains limited, while existing planning tools rely on detailed local mobility data that is often unavailable, especially for privately owned passenger vehicles. In this study, we introduce a novel framework designed to support private vehicle electrification in data-scarce regions and apply it to Addis Ababa, simulating the mobility patterns and charging needs of 100,000 electric vehicles. Our analysis indicate that these vehicles generate a daily charging demand of approximately 350 MWh and emphasize the significant influence of the charging location on the spatial and temporal distribution of this demand. Notably, charging at public places can help smooth the charging demand throughout the day, mitigating peak charging loads on the electricity grid. We also estimate charging station requirements, finding that workplace charging requires approximately one charging point per three electric vehicles, while public charging requires only one per thirty. Finally, we demonstrate that photovoltaic energy can cover a substantial share of the charging needs, emphasizing the potential for renewable energy integration. This study lays the groundwork for electric mobility planning in Addis Ababa while offering a transferable framework for other African cities.

Paper number 44:
Title: Ambiguity-Free Broadband DOA Estimation Relying on Parameterized Time-Frequency Transform
Authors: Wei Wang, Shefeng Yan, Linlin Mao, Zeping Sui, Jirui Yang
Abstract: An ambiguity-free direction-of-arrival (DOA) estimation scheme is proposed for sparse uniform linear arrays under low signal-to-noise ratios (SNRs) and non-stationary broadband signals. First, for achieving better DOA estimation performance at low SNRs while using non-stationary signals compared to the conventional frequency-difference (FD) paradigms, we propose parameterized time-frequency transform-based FD processing. Then, the unambiguous compressive FD beamforming is conceived to compensate the resolution loss induced by difference operation. Finally, we further derive a coarse-to-fine histogram statistics scheme to alleviate the perturbation in compressive FD beamforming with good DOA estimation accuracy. Simulation results demonstrate the superior performance of our proposed algorithm regarding robustness, resolution, and DOA estimation accuracy.

Paper number 45:
Title: Opportunistic Routing in Wireless Communications via Learnable State-Augmented Policies
Authors: Sourajit Das, Navid NaderiAlizadeh, Rahul Mangharam, Alejandro Ribeiro
Abstract: This paper addresses the challenge of packet-based information routing in large-scale wireless communication networks. The problem is framed as a constrained statistical learning task, where each network node operates using only local information. Opportunistic routing exploits the broadcast nature of wireless communication to dynamically select optimal forwarding nodes, enabling the information to reach the destination through multiple relay nodes simultaneously. To solve this, we propose a State-Augmentation (SA) based distributed optimization approach aimed at maximizing the total information handled by the source nodes in the network. The problem formulation leverages Graph Neural Networks (GNNs), which perform graph convolutions based on the topological connections between network nodes. Using an unsupervised learning paradigm, we extract routing policies from the GNN architecture, enabling optimal decisions for source nodes across various flows. Numerical experiments demonstrate that the proposed method achieves superior performance when training a GNN-parameterized model, particularly when compared to baseline algorithms. Additionally, applying the method to real-world network topologies and wireless ad-hoc network test beds validates its effectiveness, highlighting the robustness and transferability of GNNs.

Paper number 46:
Title: Comparison of Experimental and Theoretical Mechanical Jitter in a THz Communication Link
Authors: Ethan Abele, Karl Strecker, John F. OHara
Abstract: The effect of mechanical vibration (jitter) is an increasingly important parameter for next-generation, long-distance wireless communication links and the channel models used for their engineering. Existing investigations of jitter effects on the terahertz (THz) backhaul channel are theoretical and derived primarily from free space optical models. These lack an empirical and validated treatment of the true statistical nature of antenna motion. We present novel experimental data which reveals that the statistical nature of mechanical jitter in 6G links is more complex than previously assumed. An unexpected multimodal distribution is discovered, which cannot be fit with the commonly cited model. These results compel the refinement of THz channel models under jitter and the resulting system performance metrics.

Paper number 47:
Title: Fine-Tuning Whisper for Inclusive Prosodic Stress Analysis
Authors: Samuel S. Sohn, Sten Knutsen, Karin Stromswold
Abstract: Prosody plays a crucial role in speech perception, influencing both human understanding and automatic speech recognition (ASR) systems. Despite its importance, prosodic stress remains under-studied due to the challenge of efficiently analyzing it. This study explores fine-tuning OpenAI's Whisper large-v2 ASR model to recognize phrasal, lexical, and contrastive stress in speech. Using a dataset of 66 native English speakers, including male, female, neurotypical, and neurodivergent individuals, we assess the model's ability to generalize stress patterns and classify speakers by neurotype and gender based on brief speech samples. Our results highlight near-human accuracy in ASR performance across all three stress types and near-perfect precision in classifying gender and neurotype. By improving prosody-aware ASR, this work contributes to equitable and robust transcription technologies for diverse populations.

Paper number 48:
Title: Robust time series generation via Schrödinger Bridge: a comprehensive evaluation
Authors: Alexandre Alouadi, Baptiste Barreau, Laurent Carlier, Huyên Pham
Abstract: We investigate the generative capabilities of the Schrödinger Bridge (SB) approach for time series. The SB framework formulates time series synthesis as an entropic optimal interpolation transport problem between a reference probability measure on path space and a target joint distribution. This results in a stochastic differential equation over a finite horizon that accurately captures the temporal dynamics of the target time series. While the SB approach has been largely explored in fields like image generation, there is a scarcity of studies for its application to time series. In this work, we bridge this gap by conducting a comprehensive evaluation of the SB method's robustness and generative performance. We benchmark it against state-of-the-art (SOTA) time series generation methods across diverse datasets, assessing its strengths, limitations, and capacity to model complex temporal dependencies. Our results offer valuable insights into the SB framework's potential as a versatile and robust tool for time series generation.

Paper number 49:
Title: MIMO-PASS: Uplink and Downlink Transmission via MIMO Pinching-Antenna Systems
Authors: Ali Bereyhi, Chongjun Ouyang, Saba Asaad, Zhiguo Ding, H. Vincent Poor
Abstract: Pinching-antenna systems (PASSs) are a recent flexible-antenna technology that is realized by attaching simple components, referred to as pinching elements, to dielectric waveguides. This work explores the potential of deploying PASS for uplink and downlink transmission in multiuser MIMO settings. For downlink PASS-aided communication, we formulate the optimal hybrid beamforming, in which the digital precoding matrix at the access point and the location of pinching elements on the waveguides are jointly optimized to maximize the achievable weighted sum-rate. Invoking fractional programming and Gauss-Seidel approach, we propose two low-complexity algorithms to iteratively update the precoding matrix and activated locations of the pinching elements. We further study uplink transmission aided by a PASS, where an iterative scheme is designed to address the underlying hybrid multiuser detection problem. We validate the proposed schemes through extensive numerical experiments. The results demonstrate that using a PASS, the throughput in both uplink and downlink is boosted significantly as compared with baseline MIMO architectures, such as massive MIMO~and classical hybrid analog-digital designs. This highlights the great potential of PASSs, making it a promising reconfigurable antenna technology for next-generation wireless systems.

Paper number 50:
Title: Lead Instrument Detection from Multitrack Music
Authors: Longshen Ou, Yu Takahashi, Ye Wang
Abstract: Prior approaches to lead instrument detection primarily analyze mixture audio, limited to coarse classifications and lacking generalization ability. This paper presents a novel approach to lead instrument detection in multitrack music audio by crafting expertly annotated datasets and designing a novel framework that integrates a self-supervised learning model with a track-wise, frame-level attention-based classifier. This attention mechanism dynamically extracts and aggregates track-specific features based on their auditory importance, enabling precise detection across varied instrument types and combinations. Enhanced by track classification and permutation augmentation, our model substantially outperforms existing SVM and CRNN models, showing robustness on unseen instruments and out-of-domain testing. We believe our exploration provides valuable insights for future research on audio content analysis in multitrack music settings.

Paper number 51:
Title: Sensing Rate Optimization for Multi-Band Cooperative ISAC Systems
Authors: Nemanja Stefan Perović, Mark F. Flanagan, Le-Nam Tran
Abstract: Integrated sensing and communication (ISAC) has been recognized as one of the key technologies for future wireless networks, which potentially need to operate in multiple frequency bands to satisfy ever-increasing demands for both communication and sensing services. Motivated by this, we consider the sum sensing rate (SR) optimization for a cooperative ISAC system with linear precoding, where each base station (BS) works in a different frequency band. With this aim, we propose an optimization algorithm based on the semi-definite rank relaxation that introduces covariance matrices as optimization variables, and we apply the inner approximation (IA) method to deal with the nonconvexity of the resulting problem. Simulation results show that the proposed algorithm increases the SR by approximately 25 % and 40 % compared to the case of equal power distribution in a cooperative ISAC system with two and three BSs, respectively. Additionally, the algorithm converges in only a few iterations, while its most optimal implementation scenario is in the low power regime.

Paper number 52:
Title: Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles
Authors: Alexandre Benoit, Pedram Asef
Abstract: We offer a new in-depth investigation of global path planning (GPP) for unmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP is essential for ROMIE's optimal performance, which is translated into solving the traveling salesman problem, a complex graph theory challenge that is crucial for determining the most effective route to cover all sampling locations in a mining field. This problem is central to enhancing ROMIE's operational efficiency and competitiveness against human labor by optimizing cost and time. The primary aim of this research is to advance GPP by developing, evaluating, and improving a cost-efficient software and web application. We delve into an extensive comparison and analysis of Google operations research (OR)-Tools optimization algorithms. Our study is driven by the goal of applying and testing the limits of OR-Tools capabilities by integrating Reinforcement Learning techniques for the first time. This enables us to compare these methods with OR-Tools, assessing their computational effectiveness and real-world application efficiency. Our analysis seeks to provide insights into the effectiveness and practical application of each technique. Our findings indicate that Q-Learning stands out as the optimal strategy, demonstrating superior efficiency by deviating only 1.2% on average from the optimal solutions across our datasets.

Paper number 53:
Title: Video Super-Resolution: All You Need is a Video Diffusion Model
Authors: Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai
Abstract: We present a generic video super-resolution algorithm in this paper, based on the Diffusion Posterior Sampling framework with an unconditional video generation model in latent space. The video generation model, a diffusion transformer, functions as a space-time model. We argue that a powerful model, which learns the physics of the real world, can easily handle various kinds of motion patterns as prior knowledge, thus eliminating the need for explicit estimation of optical flows or motion parameters for pixel alignment. Furthermore, a single instance of the proposed video diffusion transformer model can adapt to different sampling conditions without re-training. Due to limited computational resources and training data, our experiments provide empirical evidence of the algorithm's strong super-resolution capabilities using synthetic data.

Paper number 54:
Title: Controlled Invariance in Fully Actuated Max-plus Linear Systems with Precedence Semimodules
Authors: Davide Zorzenon, Jörg Raisch
Abstract: Given a max-plus linear system and a semimodule, the problem of computing the maximal controlled invariant subsemimodule is still open to this day. In this paper, we consider this problem for the specific class of fully actuated systems and constraints in the form of precedence semimodules. The assumption of full actuation corresponds to the existence of an input for each component of the system state. A precedence semimodule is the set of solutions of inequalities typically used to represent time-window constraints. We prove that, in this setting, it is possible to (i) compute the maximal controlled invariant subsemimodule and (ii) decide the convergence of a fixed-point algorithm introduced by R.D. Katz in strongly polynomial time.

Paper number 55:
Title: A Novel Multi-Criteria Local Latin Hypercube Refinement System for Commutation Angle Improvement in IPMSMs
Authors: Pedram Asef, Mouloud Denai, Johannes J. H. Paulides, Bruno Ricardo Marques, Andrew Lapthorn
Abstract: The commutation angle is defined as the angle between the fundamental of the motor phase current and the fundamental of the back-EMF. It can be utilised to provide a compensating effect in IPMSMs. This is due to the reluctance torque component being dependent on the commutation angle of the phase current even before entering the extended speed range. A real-time maximum torque per current and voltage strategy is demonstrated to find the trajectory and optimum commutation angles, gamma, where the level of accuracy depends on the application and available computational speed. A magnet volume reduction using a novel multi-criteria local Latin hypercube refinement (MLHR) sampling system is also presented to improve the optimisation process. The proposed new technique minimises the magnet mass to motor torque density whilst maintaining a similar phase current level. A mapping of gamma allows the determination of the optimum angles, as shown in this paper. The 3rd generation Toyota Prius IPMSM is considered as the reference motor, where the rotor configuration is altered to allow for an individual assessment.

Paper number 56:
Title: DTU-Net: A Multi-Scale Dilated Transformer Network for Nonlinear Hyperspectral Unmixing
Authors: ChenTong Wang, Jincheng Gao, Fei Zhu, Abderrahim Halimi, C'edric Richard
Abstract: Transformers have shown significant success in hyperspectral unmixing (HU). However, challenges remain. While multi-scale and long-range spatial correlations are essential in unmixing tasks, current Transformer-based unmixing networks, built on Vision Transformer (ViT) or Swin-Transformer, struggle to capture them effectively. Additionally, current Transformer-based unmixing networks rely on the linear mixing model, which lacks the flexibility to accommodate scenarios where nonlinear effects are significant. To address these limitations, we propose a multi-scale Dilated Transformer-based unmixing network for nonlinear HU (DTU-Net). The encoder employs two branches. The first one performs multi-scale spatial feature extraction using Multi-Scale Dilated Attention (MSDA) in the Dilated Transformer, which varies dilation rates across attention heads to capture long-range and multi-scale spatial correlations. The second one performs spectral feature extraction utilizing 3D-CNNs with channel attention. The outputs from both branches are then fused to integrate multi-scale spatial and spectral information, which is subsequently transformed to estimate the abundances. The decoder is designed to accommodate both linear and nonlinear mixing scenarios. Its interpretability is enhanced by explicitly modeling the relationships between endmembers, abundances, and nonlinear coefficients in accordance with the polynomial post-nonlinear mixing model (PPNMM). Experiments on synthetic and real datasets validate the effectiveness of the proposed DTU-Net compared to PPNMM-derived methods and several advanced unmixing networks.

Paper number 57:
Title: Coordinated Trajectories for Non-stop Flying Carriers Holding a Cable-Suspended Load
Authors: Chiara Gabellieri, Antonio Franchi
Abstract: Multirotor UAVs have been typically considered for aerial manipulation, but their scarce endurance prevents long-lasting manipulation tasks. This work demonstrates that the non-stop flights of three or more carriers are compatible with holding a constant pose of a cable-suspended load, thus potentially enabling aerial manipulation with energy-efficient non-stop carriers. It also presents an algorithm for generating the coordinated non-stop trajectories. The proposed method builds upon two pillars: (1)~the choice of $n$ special linearly independent directions of internal forces within the $3n-6$-dimensional nullspace of the grasp matrix of the load, chosen as the edges of a Hamiltonian cycle on the graph that connects the cable attachment points on the load. Adjacent pairs of directions are used to generate $n$ forces evolving on distinct 2D affine subspaces, despite the attachment points being generically in 3D; (2)~the construction of elliptical trajectories within these subspaces by mapping, through appropriate graph coloring, each edge of the Hamiltonian cycle to a periodic coordinate while ensuring that no adjacent coordinates exhibit simultaneous zero derivatives. Combined with conditions for load statics and attachment point positions, these choices ensure that each of the $n$ force trajectories projects onto the corresponding cable constraint sphere with non-zero tangential velocity, enabling perpetual motion of the carriers while the load is still. The theoretical findings are validated through simulations and laboratory experiments with non-stopping multirotor UAVs.

Paper number 58:
Title: Potential gains of communication-compute-control co-design based performance optimization methods in cyber-physical systems
Authors: Sándor Rácz, Norbert Reider
Abstract: In this paper we propose and quantitatively evaluate three performance optimization methods that exploit the concept of communication-compute-control co-design by introducing awareness of communication and compute characteristics into the application logic in different ways to improve overall system performance. We have implemented a closed-loop control of a robotic arm over a wireless network where the controller is deployed into an edge cloud environment. When implementing an industrial system that leverages network and cloud technologies, the level of determinism of the control application can be decreased by nature. This means that some imperfections may be introduced into the control system, and the closed-loop control in substance changes to open-loop during disturbances. We aim to improve the performance of these open-loop control periods by applying methods that can compensate for the imperfections statistically or in a guaranteed way. We demonstrate that co-design-based application improvements with minimal dependencies on the underlying technologies can already yield an order of magnitude gain when it comes to the accurate execution of the robot trajectories during the openloop control periods. Furthermore, by combining the proposed methods, the performance improvements add up and can produce up to 45% shorter trajectory executions compared to individual evaluations.

Paper number 59:
Title: Simulation-Based Application of Safety of The Intended Functionality to Mitigate Foreseeable Misuse in Automated Driving Systems
Authors: Milin Patel, Rolf Jung
Abstract: The development of Automated Driving Systems (ADS) has the potential to revolutionise the transportation industry, but it also presents significant safety challenges. One of the key challenges is ensuring that the ADS is safe in the event of Foreseeable Misuse (FM) by the human driver. To address this challenge, a case study on simulation-based testing to mitigate FM by the driver using the driving simulator is presented. FM by the human driver refers to potential driving scenarios where the driver misinterprets the intended functionality of ADS, leading to hazardous behaviour. Safety of the Intended Functionality (SOTIF) focuses on ensuring the absence of unreasonable risk resulting from hazardous behaviours related to functional insufficiencies caused by FM and performance limitations of sensors and machine learning-based algorithms for ADS. The simulation-based application of SOTIF to mitigate FM in ADS entails determining potential misuse scenarios, conducting simulation-based testing, and evaluating the effectiveness of measures dedicated to preventing or mitigating FM. The major contribution includes defining (i) test requirements for performing simulation-based testing of a potential misuse scenario, (ii) evaluation criteria in accordance with SOTIF requirements for implementing measures dedicated to preventing or mitigating FM, and (iii) approach to evaluate the effectiveness of the measures dedicated to preventing or mitigating FM. In conclusion, an exemplary case study incorporating driver-vehicle interface and driver interactions with ADS forming the basis for understanding the factors and causes contributing to FM is investigated. Furthermore, the test procedure for evaluating the effectiveness of the measures dedicated to preventing or mitigating FM by the driver is developed in this work.

Paper number 60:
Title: Simulation-Based Performance Evaluation of 3D Object Detection Methods with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use Case
Authors: Milin Patel, Rolf Jung
Abstract: Safety of the Intended Functionality (SOTIF) addresses sensor performance limitations and deep learning-based object detection insufficiencies to ensure the intended functionality of Automated Driving Systems (ADS). This paper presents a methodology examining the adaptability and performance evaluation of the 3D object detection methods on a LiDAR point cloud dataset generated by simulating a SOTIF-related Use Case. The major contributions of this paper include defining and modelling a SOTIF-related Use Case with 21 diverse weather conditions and generating a LiDAR point cloud dataset suitable for application of 3D object detection methods. The dataset consists of 547 frames, encompassing clear, cloudy, rainy weather conditions, corresponding to different times of the day, including noon, sunset, and night. Employing MMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art (SOTA) 3D object detection methods is evaluated and compared by testing the pre-trained Deep Learning (DL) models on the generated dataset using Average Precision (AP) and Recall metrics.

Paper number 61:
Title: Optimal Beamforming for Multi-Target Multi-User ISAC Exploiting Prior Information: How Many Sensing Beams Are Needed?
Authors: Jiayi Yao, Shuowen Zhang
Abstract: This paper studies a multi-target multi-user integrated sensing and communication (ISAC) system where a multi-antenna base station (BS) communicates with multiple single-antenna users in the downlink and senses the unknown and random angle information of multiple targets based on their reflected echo signals at the BS receiver as well as their prior probability information. We focus on a general beamforming structure with both communication beams and dedicated sensing beams, whose design is highly non-trivial as more sensing beams provide more flexibility in sensing, but introduce extra interference to communication. To resolve this trade-off, we first characterize the periodic posterior Cramér-Rao bound (PCRB) as a lower bound of the mean-cyclic error (MCE) in multi-target sensing. Then, we optimize the beamforming to minimize the maximum periodic PCRB among all targets to ensure fairness, subject to individual communication rate constraints at multiple users. Despite the non-convexity of this problem, we propose a general construction method for the optimal solution by leveraging semi-definite relaxation (SDR), and derive a general bound on the number of sensing beams needed. Moreover, we unveil specific structures of the optimal solution in various cases, where tighter bounds on the number of sensing beams needed are derived (e.g., no or at most one sensing beam is needed under stringent rate constraints or with homogeneous targets). Next, we study the beamforming optimization to minimize the sum periodic PCRB under user rate constraints. By applying SDR, we propose a general construction method for the optimal solution and its specific structures which yield lower computational complexities. We derive a general bound and various tighter bounds on the number of sensing beams needed. Numerical results validate our analysis and effectiveness of our proposed beamforming designs.

Paper number 62:
Title: Towards an Emotion-Aware Metaverse: A Human-Centric Shipboard Fire Drill Simulator
Authors: Musaab H. Hamed-Ahmed, Diego Ramil-López, Paula Fraga-Lamas, Tiago M. Fernández-Caramés
Abstract: Traditional XR and Metaverse applications prioritize user experience (UX) for adoption and success but often overlook a crucial aspect of user interaction: emotions. This article addresses this gap by presenting an emotion-aware Metaverse application: a Virtual Reality (VR) fire drill simulator designed to prepare crews for shipboard emergencies. The simulator detects emotions in real time, assessing trainees responses under stress to improve learning outcomes. Its architecture incorporates eye-tracking and facial expression analysis via Meta Quest Pro headsets. The system features four levels whose difficulty is increased progressively to evaluate user decision-making and emotional resilience. The system was evaluated in two experimental phases. The first phase identified challenges, such as navigation issues and lack of visual guidance. These insights led to an improved second version with a better user interface, visual cues and a real-time task tracker. Performance metrics like completion times, task efficiency and emotional responses were analyzed. The obtained results show that trainees with prior VR or gaming experience navigated the scenarios more efficiently. Moreover, the addition of task-tracking visuals and navigation guidance significantly improved user performance, reducing task completion times between 14.18\% and 32.72\%. Emotional responses were captured, revealing that some participants were engaged, while others acted indifferently, indicating the need for more immersive elements. Overall, this article provides useful guidelines for creating the next generation of emotion-aware Metaverse applications.

Paper number 63:
Title: Domain Consistent Industrial Decarbonisation of Global Coal Power Plants
Authors: Waqar Muhammad Ashraf, Vivek Dua, Ramit Debnath
Abstract: Machine learning and optimisation techniques (MLOPT) hold significant potential to accelerate the decarbonisation of industrial systems by enabling data-driven operational improvements. However, the practical application of MLOPT in industrial settings is often hindered by a lack of domain compliance and system-specific consistency, resulting in suboptimal solutions with limited real-world applicability. To address this challenge, we propose a novel human-in-the-loop (HITL) constraint-based optimisation framework that integrates domain expertise with data-driven methods, ensuring solutions are both technically sound and operationally feasible. We demonstrate the efficacy of this framework through a case study focused on enhancing the thermal efficiency and reducing the turbine heat rate of a 660 MW supercritical coal-fired power plant. By embedding domain knowledge as constraints within the optimisation process, our approach yields solutions that align with the plant's operational patterns and are seamlessly integrated into its control systems. Empirical validation confirms a mean improvement in thermal efficiency of 0.64\% and a mean reduction in turbine heat rate of 93 kJ/kWh. Scaling our analysis to 59 global coal power plants with comparable capacity and fuel type, we estimate a cumulative lifetime reduction of 156.4 million tons of carbon emissions. These results underscore the transformative potential of our HITL-MLOPT framework in delivering domain-compliant, implementable solutions for industrial decarbonisation, offering a scalable pathway to mitigate the environmental impact of coal-based power generation worldwide.

Paper number 64:
Title: Digital Twin-Enabled Blockage-Aware Dynamic mmWave Multi-Hop V2X Communication
Authors: Supat Roongpraiwan, Zongdian Li, Tao Yu, Kei Sakaguchi
Abstract: Millimeter wave (mmWave) technology in vehicle-to-everything (V2X) communication offers unprecedented data rates and low latency, but faces significant reliability challenges due to signal blockages and limited range. This paper introduces a novel system for managing dynamic multi-hop mmWave V2X communications in complex blocking environments. We present a system architecture that integrates a mobility digital twin (DT) with the multi-hop routing control plane, providing a comprehensive, real-time view of the network and its surrounding traffic environment. This integration enables the control plane to make informed routing decisions based on rich contextual data about vehicles, infrastructure, and potential signal blockages. Leveraging this DT-enhanced architecture, we propose an advanced routing algorithm that combines high-precision environmental data with trajectory prediction to achieve blockage-aware mmWave multi-hop V2X routing. Our algorithm anticipates network topology changes and adapts topology dynamically to maintain reliable connections. We evaluate our approach through proof-of-concept simulations using a mobility DT of the Nishishinjuku area. Results demonstrate that our DT-enabled routing strategy significantly outperforms conventional methods in maintaining reliable mmWave V2X connections across various traffic scenarios, including fully connected and mixed traffic environments.

Paper number 65:
Title: Design and Implementation of an IoT Cluster with Raspberry Pi Powered by Solar Energy: A Theoretical Approach
Authors: Noel Portillo
Abstract: This document presents the design and implementation of a low-power IoT server cluster, based on Raspberry Pi 3 Model B and powered by solar energy. The proposed architecture integrates Kubernetes (K3s) and Docker, providing an efficient, scalable, and high-performance computing environment. The cluster is designed to optimize energy consumption, leveraging a 200W solar panel system and a 100Ah lithium-ion battery to support continuous operation under favorable environmental conditions. Performance analysis was conducted based on theoretical inferences and data obtained from external sources, evaluating resource allocation, power consumption, and service availability. These analyses provide theoretical estimates of the system's operational feasibility under different scenarios. The results suggest that this system can serve as a viable and sustainable alternative for edge computing applications and cloud services, reducing dependence on traditional data centers. In addition to its positive impact on environmental sustainability by significantly reducing the carbon footprint, this solution also addresses economic concerns, as conventional data centers consume enormous amounts of energy, leading to increased demand on the power grid and higher operational costs.

Paper number 66:
Title: TeraSim: Uncovering Unknown Unsafe Events for Autonomous Vehicles through Generative Simulation
Authors: Haowei Sun, Xintao Yan, Zhijie Qiao, Haojie Zhu, Yihao Sun, Jiawei Wang, Shengyin Shen, Darian Hogue, Rajanikant Ananta, Derek Johnson, Greg Stevens, Greg McGuire, Yifan Wei, Wei Zheng, Yong Sun, Yasuo Fukai, Henry X. Liu
Abstract: Traffic simulation is essential for autonomous vehicle (AV) development, enabling comprehensive safety evaluation across diverse driving conditions. However, traditional rule-based simulators struggle to capture complex human interactions, while data-driven approaches often fail to maintain long-term behavioral realism or generate diverse safety-critical events. To address these challenges, we propose TeraSim, an open-source, high-fidelity traffic simulation platform designed to uncover unknown unsafe events and efficiently estimate AV statistical performance metrics, such as crash rates. TeraSim is designed for seamless integration with third-party physics simulators and standalone AV stacks, to construct a complete AV simulation system. Experimental results demonstrate its effectiveness in generating diverse safety-critical events involving both static and dynamic agents, identifying hidden deficiencies in AV systems, and enabling statistical performance evaluation. These findings highlight TeraSim's potential as a practical tool for AV safety assessment, benefiting researchers, developers, and policymakers. The code is available at this https URL.

Paper number 67:
Title: Motion Planning and Control with Unknown Nonlinear Dynamics through Predicted Reachability
Authors: Zhiquan Zhang, Gokul Puthumanaillam, Manav Vora, Melkior Ornik
Abstract: Autonomous motion planning under unknown nonlinear dynamics presents significant challenges. An agent needs to continuously explore the system dynamics to acquire its properties, such as reachability, in order to guide system navigation adaptively. In this paper, we propose a hybrid planning-control framework designed to compute a feasible trajectory toward a target. Our approach involves partitioning the state space and approximating the system by a piecewise affine (PWA) system with constrained control inputs. By abstracting the PWA system into a directed weighted graph, we incrementally update the existence of its edges via affine system identification and reach control theory, introducing a predictive reachability condition by exploiting prior information of the unknown dynamics. Heuristic weights are assigned to edges based on whether their existence is certain or remains indeterminate. Consequently, we propose a framework that adaptively collects and analyzes data during mission execution, continually updates the predictive graph, and synthesizes a controller online based on the graph search outcomes. We demonstrate the efficacy of our approach through simulation scenarios involving a mobile robot operating in unknown terrains, with its unknown dynamics abstracted as a single integrator model.

Paper number 68:
Title: 4D Radar Ground Truth Augmentation with LiDAR-to-4D Radar Data Synthesis
Authors: Woo-Jin Jung, Dong-Hee Paek, Seung-Hyun Kong
Abstract: Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object detection, as it enhances object density by leveraging ground truth bounding boxes (GT bboxes). However, directly applying GT-Aug to 4D Radar tensor data overlooks important measurements outside the GT bboxes-such as sidelobes-leading to synthetic distributions that deviate from real-world 4D Radar data. To address this limitation, we propose 4D Radar Ground Truth Augmentation (4DR GT-Aug). Our approach first augments LiDAR data and then converts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS) module, which explicitly accounts for measurements both inside and outside GT bboxes. In doing so, it produces 4D Radar data distributions that more closely resemble real-world measurements, thereby improving object detection accuracy. Experiments on the K-Radar dataset show that the proposed method achieves improved performance compared to conventional GT-Aug in object detection for 4D Radar. The implementation code is available at this https URL.

Paper number 69:
Title: Quantification of Tenseness in English and Japanese Tense-Lax Vowels: A Lagrangian Model with Indicator $θ_1$ and Force of Tenseness Ftense(t)
Authors: Tatsuya Ishizaki
Abstract: The concept of vowel tenseness has traditionally been examined through the binary distinction of tense and lax vowels. However, no universally accepted quantitative definition of tenseness has been established in any language. Previous studies, including those by Jakobson, Fant, and Halle (1951) and Chomsky and Halle (1968), have explored the relationship between vowel tenseness and the vocal tract. Building on these foundations, Ishizaki (2019, 2022) proposed an indirect quantification of vowel tenseness using formant angles $\theta_1$ and $\theta_{F1}$ and their first and second derivatives, $d^Z_1(t)/dt = \lim \tan \theta_1(t$) and $d^2 Z_1(t)/dt^2 = d/dt \lim \tan \theta_1(t)$. This study extends this approach by investigating the potential role of a force-related parameter in determining vowel quality. Specifically, we introduce a simplified model based on the Lagrangian equation to describe the dynamic interaction of the tongue and jaw within the oral cavity during the articulation of close vowels. This model provides a theoretical framework for estimating the forces involved in vowel production across different languages, offering new insights into the physical mechanisms underlying vowel articulation. The findings suggest that this force-based perspective warrants further exploration as a key factor in phonetic and phonological studies.

Paper number 70:
Title: Super-Resolution on Rotationally Scanned Photoacoustic Microscopy Images Incorporating Scanning Prior
Authors: Kai Pan, Linyang Li, Li Lin, Pujin Cheng, Junyan Lyu, Lei Xi, Xiaoyin Tang
Abstract: Photoacoustic Microscopy (PAM) images integrating the advantages of optical contrast and acoustic resolution have been widely used in brain studies. However, there exists a trade-off between scanning speed and image resolution. Compared with traditional raster scanning, rotational scanning provides good opportunities for fast PAM imaging by optimizing the scanning mechanism. Recently, there is a trend to incorporate deep learning into the scanning process to further increase the scanning this http URL, most such attempts are performed for raster scanning while those for rotational scanning are relatively rare. In this study, we propose a novel and well-performing super-resolution framework for rotational scanning-based PAM imaging. To eliminate adjacent rows' displacements due to subject motion or high-frequency scanning distortion,we introduce a registration module across odd and even rows in the preprocessing and incorporate displacement degradation in the training. Besides, gradient-based patch selection is proposed to increase the probability of blood vessel patches being selected for training. A Transformer-based network with a global receptive field is applied for better performance. Experimental results on both synthetic and real datasets demonstrate the effectiveness and generalizability of our proposed framework for rotationally scanned PAM images'super-resolution, both quantitatively and qualitatively. Code is available at this https URL.

Paper number 71:
Title: Deep Learning-based MRI Reconstruction with Artificial Fourier Transform Network (AFTNet)
Authors: Yanting Yang, Yiren Zhang, Zongyu Li, Jeffery Siyuan Tian, Matthieu Dagommer, Jia Guo
Abstract: Deep complex-valued neural networks (CVNNs) provide a powerful way to leverage complex number operations and representations and have succeeded in several phase-based applications. However, previous networks have not fully explored the impact of complex-valued networks in the frequency domain. Here, we introduce a unified complex-valued deep learning framework-Artificial Fourier Transform Network (AFTNet)-which combines domain-manifold learning and CVNNs. AFTNet can be readily used to solve image inverse problems in domain transformation, especially for accelerated magnetic resonance imaging (MRI) reconstruction and other applications. While conventional methods typically utilize magnitude images or treat the real and imaginary components of k-space data as separate channels, our approach directly processes raw k-space data in the frequency domain, utilizing complex-valued operations. This allows for a mapping between the frequency (k-space) and image domain to be determined through cross-domain learning. We show that AFTNet achieves superior accelerated MRI reconstruction compared to existing approaches. Furthermore, our approach can be applied to various tasks, such as denoised magnetic resonance spectroscopy (MRS) reconstruction and datasets with various contrasts. The AFTNet presented here is a valuable preprocessing component for different preclinical studies and provides an innovative alternative for solving inverse problems in imaging and spectroscopy. The code is available at: this https URL.

Paper number 72:
Title: Multimodal Action Quality Assessment
Authors: Ling-An Zeng, Wei-Shi Zheng
Abstract: Action quality assessment (AQA) is to assess how well an action is performed. Previous works perform modelling by only the use of visual information, ignoring audio information. We argue that although AQA is highly dependent on visual information, the audio is useful complementary information for improving the score regression accuracy, especially for sports with background music, such as figure skating and rhythmic gymnastics. To leverage multimodal information for AQA, i.e., RGB, optical flow and audio information, we propose a Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models modality-specific information and mixed-modality information. Our model consists of with three modality-specific branches that independently explore modality-specific information and a mixed-modality branch that progressively aggregates the modality-specific information from the modality-specific branches. To build the bridge between modality-specific branches and the mixed-modality branch, three novel modules are proposed. First, a Modality-specific Feature Decoder module is designed to selectively transfer modality-specific information to the mixed-modality branch. Second, when exploring the interaction between modality-specific information, we argue that using an invariant multimodal fusion policy may lead to suboptimal results, so as to take the potential diversity in different parts of an action into consideration. Therefore, an Adaptive Fusion Module is proposed to learn adaptive multimodal fusion policies in different parts of an action. This module consists of several FusionNets for exploring different multimodal fusion strategies and a PolicyNet for deciding which FusionNets are enabled. Third, a module called Cross-modal Feature Decoder is designed to transfer cross-modal features generated by Adaptive Fusion Module to the mixed-modality branch.

Paper number 73:
Title: LeqMod: Adaptable Lesion-Quantification-Consistent Modulation for Deep Learning Low-Count PET Image Denoising
Authors: Menghua Xia, Huidong Xie, Qiong Liu, Bo Zhou, Hanzhong Wang, Biao Li, Axel Rominger, Quanzheng Li, Ramsey D. Badawi, Kuangyu Shi, Georges El Fakhri, Chi Liu
Abstract: Deep learning-based positron emission tomography (PET) image denoising offers the potential to reduce radiation exposure and scanning time by transforming low-count images into high-count equivalents. However, existing methods typically blur crucial details, leading to inaccurate lesion quantification. This paper proposes a lesion-perceived and quantification-consistent modulation (LeqMod) strategy for enhanced PET image denoising, via employing downstream lesion quantification analysis as auxiliary tools. The LeqMod is a plug-and-play design adaptable to a wide range of model architectures, modulating the sampling and optimization procedures of model training without adding any computational burden to the inference phase. Specifically, the LeqMod consists of two components, the lesion-perceived modulation (LeMod) and the multiscale quantification-consistent modulation (QuMod). The LeMod enhances lesion contrast and visibility by allocating higher sampling weights and stricter loss criteria to lesion-present samples determined by an auxiliary segmentation network than lesion-absent ones. The QuMod further emphasizes quantification accuracy for both the mean and maximum standardized uptake value (SUVmean and SUVmax) across multiscale sub-regions throughout the entire image, thereby reducing biases of denoised results relative to high-count references. Experiments conducted on large PET datasets from multiple centers and vendors, and varying noise levels demonstrated the LeqMod efficacy across various denoising frameworks. Compared to frameworks without LeqMod, the integration of LeqMod reduces the lesion SUVmax bias by 5.92% on average and increases the peak signal-to-noise ratio (PSNR) by 0.36 on average, when denoising images across participating sites.

Paper number 74:
Title: Deep Unfolding-Aided Parameter Tuning for Plug-and-Play-Based Video Snapshot Compressive Imaging
Authors: Takashi Matsuda, Ryo Hayakawa, Youji Iiguni
Abstract: Snapshot compressive imaging (SCI) captures high-dimensional data efficiently by compressing it into two-dimensional observations and reconstructing high-dimensional data from two-dimensional observations with various algorithms. The plug-and-play (PnP) method is a promising approach for the video SCI reconstruction because it can leverage both observation models and denoising methods for videos. Since the reconstruction accuracy significantly depends on the choice of noise level parameters, this paper proposes a deep unfolding-based method for tuning these parameters in PnP-based video SCI. For the training of the parameters, we prepare training data from the densely annotated video segmentation dataset, reparametrize the noise level parameters, and apply the checkpointing technique to reduce the required memory. Simulation results show that the trained noise level parameters via the proposed approach exhibit a non-monotonic pattern, which is different from the assumptions in the conventional convergence analyses of PnP-based algorithms. These findings provide new insights into both the application of deep unfolding and the theoretical basis of PnP algorithms.

Paper number 75:
Title: Distributed Optimization by Network Flows with Spatio-Temporal Compression
Authors: Zihao Ren, Lei Wang, Xinlei Yi, Xi Wang, Deming Yuan, Tao Yang, Zhengguang Wu, Guodong Shi
Abstract: Several data compressors have been proposed in distributed optimization frameworks of network systems to reduce communication overhead in large-scale applications. In this paper, we demonstrate that effective information compression may occur over time or space during sequences of node communications in distributed algorithms, leading to the concept of spatio-temporal compressors. This abstraction classifies existing compressors as spatio-temporal compressors, with their effectiveness described by constructive stability criteria from nonlinear system theory. Subsequently, we apply these spatio-temporal compressors to standard continuous-time consensus flows and distributed prime-dual flows, establishing conditions ensuring convergence. Additionally, we introduce a novel observer-based distributed primal-dual continuous flow integrated with spatio-temporal compressors, which provides broader convergence conditions. These continuous flows achieve exponential convergence to the global optimum when the objective function is strongly convex and can be discretized using Euler approximations. Finally, numerical simulations illustrate the versatility of the proposed spatio-temporal compressors and verify the convergence of algorithms.

Paper number 76:
Title: LDPM: Towards undersampled MRI reconstruction with MR-VAE and Latent Diffusion Prior
Authors: Xingjian Tang, Jingwei Guan, Linge Li, Ran Shi, Youmei Zhang, Mengye Lyu, Li Yan
Abstract: Diffusion models, as powerful generative models, have found a wide range of applications and shown great potential in solving image reconstruction problems. Some works attempted to solve MRI reconstruction with diffusion models, but these methods operate directly in pixel space, leading to higher computational costs for optimization and inference. Latent diffusion models, pre-trained on natural images with rich visual priors, are expected to solve the high computational cost problem in MRI reconstruction by operating in a lower-dimensional latent space. However, direct application to MRI reconstruction faces three key challenges: (1) absence of explicit control mechanisms for medical fidelity, (2) domain gap between natural images and MR physics, and (3) undefined data consistency in latent space. To address these challenges, a novel Latent Diffusion Prior-based undersampled MRI reconstruction (LDPM) method is proposed. Our LDPM framework addresses these challenges by: (1) a sketch-guided pipeline with a two-step reconstruction strategy, which balances perceptual quality and anatomical fidelity, (2) an MRI-optimized VAE (MR-VAE), which achieves an improvement of approximately 3.92 dB in PSNR for undersampled MRI reconstruction compared to that with SD-VAE \cite{sd}, and (3) Dual-Stage Sampler, a modified version of spaced DDPM sampler, which enforces high-fidelity reconstruction in the latent space. Experiments on the fastMRI dataset\cite{fastmri} demonstrate the state-of-the-art performance of the proposed method and its robustness across various scenarios. The effectiveness of each module is also verified through ablation experiments.

Paper number 77:
Title: Improved Estimation Accuracy in OFDM-based Joint Communication and Sensing through Kalman Tracking and Interpolation
Authors: Charlotte Muth, Leon Schmidt, Shrinivas Chimmalgi, Laurent Schmalen
Abstract: We investigate a monostatic orthogonal frequency-division multiplexing (OFDM)-based joint communication and sensing (JCAS) system for object tracking. Our setup consists of a transmitter and receiver equipped with an antenna array for fully digital beamforming. The native resolution of range and velocity in all radar-like sensing, including OFDM radar sensing, is limited by the observation time and bandwidth. In this work, we improve the parameter estimates (estimates of range) through interpolation methods and tracking algorithms. We verify our method by comparing the root mean squared error (RMSE) of the estimated range, velocity and angle and by comparing the mean Euclidean distance between the estimated and true position. We demonstrate how both a Kalman filter for tracking, and interpolation methods using zero-padding and the chirp Z-transform (CZT) improve the estimation error. We discuss the computational complexity of the different methods. We propose the KalmanCZT approach that combines tracking via Kalman filtering and interpolation via the CZT, resulting in a solution with flexible resolution that significantly improves the range RMSE.

Paper number 78:
Title: XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder
Authors: Shenghao Zhu, Yifei Chen, Shuo Jiang, Weihong Chen, Chang Liu, Yuanhan Wang, Xu Chen, Yifan Ke, Feiwei Qin, Changmiao Wang, Zhu Zhu
Abstract: Neurogliomas are among the most aggressive forms of cancer, presenting considerable challenges in both treatment and monitoring due to their unpredictable biological behavior. Magnetic resonance imaging (MRI) is currently the preferred method for diagnosing and monitoring gliomas. However, the lack of specific imaging techniques often compromises the accuracy of tumor segmentation during the imaging process. To address this issue, we introduce the XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder framework with the Vision XLSTM module to reconstruct missing MRI modalities. By deeply fusing spatial and temporal features, it enhances tumor segmentation performance. The key innovation of our approach is the Self-Attention Variational Encoder (SAVE) module, which improves the integration of modal features. Additionally, it optimizes the interaction of features between segmentation and reconstruction tasks through the Squeeze-Fusion-Excitation Cross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset demonstrate that our model significantly outperforms existing advanced methods in handling cases where modalities are missing. Our source code is available at this https URL.

Paper number 79:
Title: A Structurally Coherent Spatial Phase Estimate
Authors: Brian Knight, Naoki Saito
Abstract: The monogenic signal (MS) was introduced by Felsberg and Sommer, and independently by Larkin under the name vortex operator. It is a two-dimensional (2D) analog of the well-known analytic signal, and allows for direct amplitude and phase demodulation of (amplitude and phase) modulated images so long as the signal is intrinsically one-dimensional (i1D). Felsberg's PhD dissertation also introduced the structure multivector (SMV), a model allowing for intrinsically 2D (i2D) structure. While the monogenic signal has become a well-known tool in the image processing community, the SMV is little used, although even in the case of i1D signals it provides a more robust orientation estimation than the MS. We argue the SMV is more suitable in standard i1D image feature extraction due to the this improvement, and extend the steerable wavelet frames of Held et al. to accommodate the additional features of the SMV. We then propose a novel quality map based on local orientation variance which values structurally coherent patches. This yields a multiscale phase estimate which performs well even when signal to noise ratio (SNR) is $\le$ 1. The performance is evaluated on several synthetic phase estimation tasks as well as on a fine-scale fingerprint registration task related to the 2D phase demodulation problem.

Paper number 80:
Title: Intelligent Reflecting Surfaces for Wireless Networks: Deployment Architectures, Key Solutions, and Field Trials
Authors: Qingqing Wu, Guangji Chen, Qiaoyan Peng, Wen Chen, Yifei Yuan, Zhenqiao Cheng, Jianwu Dou, Zhiyong Zhao, Ping Li
Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a transformative technology for wireless networks by improving coverage, capacity, and energy efficiency through intelligent manipulation of wireless propagation environments. This paper provides a comprehensive study on the deployment and coordination of IRSs for wireless networks. By addressing both single- and multi-reflection IRS architectures, we examine their deployment strategies across diverse scenarios, including point-to-point, point-to-multipoint, and point-to-area setups. For the single-reflection case, we highlight the trade-offs between passive and active IRS architectures in terms of beamforming gain, coverage extension, and spatial multiplexing. For the multi-reflection case, we discuss practical strategies to optimize IRS deployment and element allocation, balancing cooperative beamforming gains and path loss. The paper further discusses practical challenges in IRS implementation, including environmental conditions, system compatibility, and hardware limitations. Numerical results and field tests validate the effectiveness of IRS-aided wireless networks and demonstrate their capacity and coverage improvements. Lastly, promising research directions, including movable IRSs, near-field deployments, and network-level optimization, are outlined to guide future investigations.

Paper number 81:
Title: PainDECOG: Machine Learning-Based Identification of Pain Biomarkers from sEEG Signals
Authors: Sidharth Sidharth, Vishwas Sathish, Shweta Bansal, Samantha Sun, Timmy Pham, Kurt Weaver, Rajesh P. N. Rao, Jeffrey Herron
Abstract: This study presents a systematic machine-learning approach for classifying acute pain from raw electrophysiological signals. We address binary and ternary classification tasks, leveraging Power-In-Band (PIB) and signal coherence as distinguishing features. Our method evaluates the effectiveness of traditional machine learning algorithms on a manually curated electrophysiological dataset obtained from intracranial electroencephalography (iEEG), offering valuable insights into model performance for pain detection. Furthermore, we identify critical electrode pairings associated with acute pain, providing a clearer understanding of the neural markers that differentiate pain states. This work highlights the potential of targeted feature engineering in advancing pain classification, setting the stage for future enhancements in real-time and personalized pain assessment tools. Additionally, these findings have promising applications in neuromodulation and Deep Brain Stimulation (DBS), where adaptive and closed-loop systems could leverage identified pain markers to modulate pain-related brain regions more precisely, offering improved therapeutic options for chronic pain management

Paper number 82:
Title: Performance Evaluation of V2V Visible Light Communication: Coherence Time and Throughput in Motion Scenarios
Authors: Jinrui Hong, Xiayue Liu, Hanye Li, Yufei Jiang
Abstract: This study evaluates the performance of Vehicle-to-Vehicle Visible Light Communication in dynamic environments, focusing on the effects of speed, horizontal offset, and other factors on communication reliability. Using On-Off Keying modulation, we analyze the BER, optimal communication distance, correlation time and the maximum amount of data per communication. Our results demonstrate that maintaining an optimal vehicle distance is critical for stable communication, with speed and horizontal offset significantly influencing communication. This work extends the analysis of V-VLC to real-world dynamic scenarios, providing insights for future research.

Paper number 83:
Title: Perceptual Multi-Exposure Fusion
Authors: Xiaoning Liu
Abstract: As an ever-increasing demand for high dynamic range (HDR) scene shooting, multi-exposure image fusion (MEF) technology has abounded. In recent years, multi-scale exposure fusion approaches based on detail-enhancement have led the way for improvement in highlight and shadow details. Most of such methods, however, are too computationally expensive to be deployed on mobile devices. This paper presents a perceptual multi-exposure fusion method that not just ensures fine shadow/highlight details but with lower complexity than detailenhanced methods. We analyze the potential defects of three classical exposure measures in lieu of using detail-enhancement component and improve two of them, namely adaptive Wellexposedness (AWE) and the gradient of color images (3-D gradient). AWE designed in YCbCr color space considers the difference between varying exposure images. 3-D gradient is employed to extract fine details. We build a large-scale multiexposure benchmark dataset suitable for static scenes, which contains 167 image sequences all told. Experiments on the constructed dataset demonstrate that the proposed method exceeds existing eight state-of-the-art approaches in terms of visually and MEF-SSIM value. Moreover, our approach can achieve a better improvement for current image enhancement techniques, ensuring fine detail in bright light.

Paper number 84:
Title: Simple Alternating Minimization Provably Solves Complete Dictionary Learning
Authors: Geyu Liang, Gavin Zhang, Salar Fattahi, Richard Y. Zhang
Abstract: This paper focuses on the noiseless complete dictionary learning problem, where the goal is to represent a set of given signals as linear combinations of a small number of atoms from a learned dictionary. There are two main challenges faced by theoretical and practical studies of dictionary learning: the lack of theoretical guarantees for practically-used heuristic algorithms and their poor scalability when dealing with huge-scale datasets. Towards addressing these issues, we propose a simple and efficient algorithm that provably recovers the ground truth when applied to the nonconvex and discrete formulation of the problem in the noiseless setting. We also extend our proposed method to mini-batch and online settings where the data is huge-scale or arrives continuously over time. At the core of our proposed method lies an efficient preconditioning technique that transforms the unknown dictionary to a near-orthonormal one, for which we prove a simple alternating minimization technique converges linearly to the ground truth under minimal conditions. Our numerical experiments on synthetic and real datasets showcase the superiority of our method compared with the existing techniques.

Paper number 85:
Title: Geometric Impedance Control on SE(3) for Robotic Manipulators
Authors: Joohwan Seo, Nikhil Potu Surya Prakash, Alexander Rose, Jongeun Choi, Roberto Horowitz
Abstract: After its introduction, impedance control has been utilized as a primary control scheme for robotic manipulation tasks that involve interaction with unknown environments. While impedance control has been extensively studied, the geometric structure of SE(3) for the robotic manipulator itself and its use in formulating a robotic task has not been adequately addressed. In this paper, we propose a differential geometric approach to impedance control. Given a left-invariant error metric in SE(3), the corresponding error vectors in position and velocity are first derived. We then propose the impedance control schemes that adequately account for the geometric structure of the manipulator in SE(3) based on a left-invariant potential function. The closed-loop stabilities for the proposed control schemes are verified using Lyapunov function-based analysis. The proposed control design clearly outperformed a conventional impedance control approach when tracking challenging trajectory profiles.

Paper number 86:
Title: Optimal transmission expansion modestly reduces decarbonization costs of U.S. electricity
Authors: Rangrang Zheng, Greg Schivley, Patricia Hidalgo-Gonzalez, Matthias Fripp, Michael J. Roberts
Abstract: Solar and wind power are cost-competitive with fossil fuels, yet their intermittent nature presents challenges. Significant temporal and geographic differences in land, wind, and solar resources suggest that long-distance transmission could be particularly beneficial. Using a detailed, open-source model, we analyze optimal transmission expansion jointly with storage, generation, and hourly operations across the three primary interconnects in the United States. Transmission expansion offers far more benefits in a high-renewable system than in a system with mostly conventional generation. Yet while an optimal nationwide plan would have more than triple current interregional transmission, transmission decreases the cost of a 100% clean system by only 7% compared to a plan that relies solely on current transmission. Expanding capacity only within existing interconnects can achieve most of these savings. Adjustments to energy storage and generation mix can leverage the current interregional transmission infrastructure to build a clean power system at a reasonable cost.

Paper number 87:
Title: Structured Input-Output Modeling and Robust Stability Analysis of Compressible Flows
Authors: Diganta Bhattacharjee, Talha Mushtaq, Peter Seiler, Maziar S. Hemati
Abstract: The recently introduced structured input-output analysis is a powerful method for capturing nonlinear phenomena associated with incompressible flows, and this paper extends that method to the compressible regime. The proposed method relies upon a reformulation of the compressible Navier-Stokes equations, which allows for an exact quadratic formulation of the dynamics of perturbations about a steady base flow. To facilitate the structured input-output analysis, a pseudo-linear model for the quadratic nonlinearity is proposed and the structural information of the nonlinearity is embedded into a structured uncertainty comprising unknown `perturbations'. The structured singular value framework is employed to compute the input-output gain, which provides an estimate of the robust stability margin of the flow perturbations, as well as the forcing and response modes that are consistent with the nonlinearity structure. The analysis is then carried out on a plane, laminar compressible Couette flow over a range of Mach numbers. The structured input-output gains identify an instability mechanism, characterized by a spanwise elongated structure in the streamwise-spanwise wavenumber space at a subsonic Mach number, that takes the form of an oblique structure at sonic and supersonic Mach numbers. In addition, the structured input-output forcing and response modes provide insight into the thermodynamic and momentum characteristics associated with a source of instability. Comparisons with a resolvent/unstructured analysis reveal discrepancies in the distribution of input-output gains over the wavenumber space as well as in the modal behavior of an instability, thus highlighting the strong correlation between the structural information of the nonlinearity and the underlying flow physics.

Paper number 88:
Title: Generative Diffusion Models for High Dimensional Channel Estimation
Authors: Xingyu Zhou, Le Liang, Jing Zhang, Peiwen Jiang, Yong Li, Shi Jin
Abstract: Along with the prosperity of generative artificial intelligence (AI), its potential for solving conventional challenges in wireless communications has also surfaced. Inspired by this trend, we investigate the application of the advanced diffusion models (DMs), a representative class of generative AI models, to high dimensional wireless channel estimation. By capturing the structure of multiple-input multiple-output (MIMO) wireless channels via a deep generative prior encoded by DMs, we develop a novel posterior inference method for channel reconstruction. We further adapt the proposed method to recover channel information from low-resolution quantized measurements. Additionally, to enhance the over-the-air viability, we integrate the DM with the unsupervised Stein's unbiased risk estimator to enable learning from noisy observations and circumvent the requirements for ground truth channel data that is hardly available in practice. Results reveal that the proposed estimator achieves high-fidelity channel recovery while reducing estimation latency by a factor of 10 compared to state-of-the-art schemes, facilitating real-time implementation. Moreover, our method outperforms existing estimators while reducing the pilot overhead by half, showcasing its scalability to ultra-massive antenna arrays.

Paper number 89:
Title: CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for Classroom Environments
Authors: Ahmed Adel Attia, Dorottya Demszky, Tolulope Ogunremi, Jing Liu, Carol Espy-Wilson
Abstract: Creating Automatic Speech Recognition (ASR) systems that are robust and resilient to classroom conditions is paramount to the development of AI tools to aid teachers and students. In this work, we study the efficacy of continued pretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that CPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of Wav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the model's robustness to different noises, microphones and classroom conditions.

Paper number 90:
Title: POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances
Authors: Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux
Abstract: The joint detection and tracking of a moving target embedded in an unknown disturbance represents a key feature that motivates the development of the cognitive radar paradigm. Building upon recent advancements in robust target detection with multiple-input multiple-output (MIMO) radars, this work explores the application of a Partially Observable Markov Decision Process (POMDP) framework to enhance the tracking and detection tasks in a statistically unknown environment. In the POMDP setup, the radar system is considered as an intelligent agent that continuously senses the surrounding environment, optimizing its actions to maximize the probability of detection $(P_D)$ and improve the target position and velocity estimation, all this while keeping a constant probability of false alarm $(P_{FA})$. The proposed approach employs an online algorithm that does not require any apriori knowledge of the noise statistics, and it relies on a much more general observation model than the traditional range-azimuth-elevation model employed by conventional tracking algorithms. Simulation results clearly show substantial performance improvement of the POMDP-based algorithm compared to the State-Action-Reward-State-Action (SARSA)-based one that has been recently investigated in the context of massive MIMO (MMIMO) radar systems.

Paper number 91:
Title: Learning Maximal Safe Sets Using Hypernetworks for MPC-based Local Trajectory Planning in Unknown Environments
Authors: Bojan Derajić, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Wolfgang Hönig
Abstract: This paper presents a novel learning-based approach for online estimation of maximal safe sets for local trajectory planning in unknown static environments. The neural representation of a set is used as the terminal set constraint for a model predictive control (MPC) local planner, resulting in improved recursive feasibility and safety. To achieve real-time performance and desired generalization properties, we employ the idea of hypernetworks. We use the Hamilton-Jacobi (HJ) reachability analysis as the source of supervision during the training process, allowing us to consider general nonlinear dynamics and arbitrary constraints. The proposed method is extensively evaluated against relevant baselines in simulations for different environments and robot dynamics. The results show a success rate increase of up to 52 \% compared to the best baseline while maintaining comparable execution speed. Additionally, we deploy our proposed method, NTC-MPC, on a physical robot and demonstrate its ability to safely avoid obstacles in scenarios where the baselines fail.

Paper number 92:
Title: Joint-repositionable Inner-wireless Planar Snake Robot
Authors: Ayato Kanada, Ryo Takahashi, Keito Hayashi, Ryusuke Hosaka, Wakako Yukita, Yasutaka Nakashima, Tomoyuki Yokota, Takao Someya, Mitsuhiro Kamezaki, Yoshihiro Kawahara, Motoji Yamamoto
Abstract: Bio-inspired multi-joint snake robots offer the advantages of terrain adaptability due to their limbless structure and high flexibility. However, a series of dozens of motor units in typical multiple-joint snake robots results in a heavy body structure and hundreds of watts of high power consumption. This paper presents a joint-repositionable, inner-wireless snake robot that enables multi-joint-like locomotion using a low-powered underactuated mechanism. The snake robot, consisting of a series of flexible passive links, can dynamically change its joint coupling configuration by repositioning motor-driven joint units along rack gears inside the robot. Additionally, a soft robot skin wirelessly powers the internal joint units, avoiding the risk of wire tangling and disconnection caused by the movable joint units. The combination of the joint-repositionable mechanism and the wireless-charging-enabled soft skin achieves a high degree of bending, along with a lightweight structure of 1.3 kg and energy-efficient wireless power transmission of 7.6 watts.

Paper number 93:
Title: DMVC-Tracker: Distributed Multi-Agent Trajectory Planning for Target Tracking Using Dynamic Buffered Voronoi and Inter-Visibility Cells
Authors: Yunwoo Lee, Jungwon Park, H. Jin Kim
Abstract: This letter presents a distributed trajectory planning method for multi-agent aerial tracking. The proposed method uses a Dynamic Buffered Voronoi Cell (DBVC) and a Dynamic Inter-Visibility Cell (DIVC) to formulate the distributed trajectory generation. Specifically, the DBVC and the DIVC are time-variant spaces that prevent mutual collisions and occlusions among agents, while enabling them to maintain suitable distances from the moving target. We combine the DBVC and the DIVC with an efficient Bernstein polynomial motion primitive-based tracking generation method, which has been refined into a less conservative approach than in our previous work. The proposed algorithm can compute each agent's trajectory within several milliseconds on an Intel i7 desktop. We validate the tracking performance in challenging scenarios, including environments with dozens of obstacles.

Paper number 94:
Title: Minimum Data Rate Maximization for Uplink Pinching-Antenna Systems
Authors: Sotiris A. Tegos, Panagiotis D. Diamantoulakis, Zhiguo Ding, George K. Karagiannidis
Abstract: This paper addresses, for the first time, the uplink performance optimization of multi-user pinching-antenna (PA) systems, recently developed for next-generation wireless networks. By leveraging the unique capabilities of PAs to dynamically configure wireless channels, we focus on maximizing the minimum achievable data rate between devices to achieve a balanced trade-off between throughput and fairness. An effective approach is proposed that separately optimizes the positions of the PAs and the resource allocation. The antenna positioning problem is reformulated into a convex one, while a closed-form solution is provided for the resource allocation. Simulation results demonstrate the superior performance of the investigated system using the proposed algorithm over corresponding counterparts, emphasizing the significant potential of PA systems for robust and efficient uplink communication in next-generation wireless networks.

Paper number 95:
Title: Performance Optimizations and Evaluations for the Small Direct Currents Measurement System
Authors: Shunyi Liang, Juncheng Liang, Kezhu Song, Yijie Jiang, Zhijie Yang
Abstract: Ionization chambers are essential for activity determinations in radionuclide metrology. We have developed a high-precision integrating-differentiating (int-diff) system for measuring small currents. It is anticipated to enhance the ionization current measurement capability of the 4{\pi}{\gamma} ionization chamber radioactivity standard at the National Institute of Metrology (NIM), China. Besides, it has broad application prospects in physical experiments and fundamental metrology. The design of the measurement system is optimized through circuit analysis and simulation. The structure of the integrating capacitor array is redesigned to reduce the error of the amplification gain, and a relay is used as the reset switch to achieve improved noise and leakage performance. The digital readout and control module is also enhanced in terms of flexibility and functionality. High-precision test platforms utilizing the standard small current source at NIM China and an ionization chamber were developed to evaluate the performance of the system. The results demonstrate an ultra-low noise floor (<1 fA/\sqrt{Hz}) and a low current bias of fA-level, as well as a low temperature coefficient of the amplification gain of 2.1 ppm/{\textdegree}C. The short-term stability and linearity of the gain are also tested and exhibit comparable indicators to those of the Keithley 6430. Reasonable results are obtained in the long-term reproducibility test. Therefore, the system enables high-precision measurements for small direct currents and shows promise for applications in ionization chambers.

Paper number 96:
Title: Wireless Communication with Flexible Reflector: Joint Placement and Rotation Optimization for Coverage Enhancement
Authors: Haiquan Lu, Zhi Yu, Yong Zeng, Shaodan Ma, Shi Jin, Rui Zhang
Abstract: Passive metal reflectors for communication enhancement have appealing advantages such as ultra low cost, zero energy expenditure, maintenance-free operation, long life span, and full compatibility with legacy wireless systems. To unleash the full potential of passive reflectors for wireless communications, this paper proposes a new passive reflector architecture, termed flexible reflector (FR), for enabling the flexible adjustment of beamforming direction via the FR placement and rotation optimization. We consider the multi-FR aided area coverage enhancement and aim to maximize the minimum expected receive power over all locations within the target coverage area, by jointly optimizing the placement positions and rotation angles of multiple FRs. To gain useful insights, the special case of movable reflector (MR) with fixed rotation is first studied to maximize the expected receive power at a target location, where the optimal single-MR placement positions for electrically large and small reflectors are derived in closed-form, respectively. It is shown that the reflector should be placed at the specular reflection point for electrically large reflector. While for area coverage enhancement, the optimal placement is obtained for the single-MR case and a sequential placement algorithm is proposed for the multi-MR case. Moreover, for the general case of FR, joint placement and rotation design is considered for the single-/multi-FR aided coverage enhancement, respectively. Numerical results are presented which demonstrate significant performance gains of FRs over various benchmark schemes under different practical setups in terms of receive power enhancement.

Paper number 97:
Title: Machine Learning-Enabled Multidimensional Data Utilization Through Multi-Resonance Architecture: A Pathway to Enhanced Accuracy in Biosensing
Authors: Majid Aalizadeh, Morteza Azmoudeh Afshar, Xudong Fan
Abstract: A novel framework is proposed that combines multi-resonance biosensors with machine learning (ML) to significantly enhance the accuracy of parameter prediction in biosensing. Unlike traditional single-resonance systems, which are limited to one-dimensional datasets, this approach leverages multi-dimensional data generated by a custom-designed nanostructure, a periodic array of silicon nanorods with a triangular cross-section over an aluminum reflector. High bulk sensitivity values are achieved for this multi-resonant structure, with certain resonant peaks reaching up to 1706 nm/RIU. The field analysis reveals Mie resonances as the physical reason behind the peaks. The predictive power of multiple resonant peaks from transverse magnetic (TM) and transverse electric (TE) polarizations is evaluated using Ridge Regression modeling. Systematic analysis reveals that incorporating multiple resonances yields up to three orders of magnitude improvement in refractive index detection precision compared to single-peak analyses. This precision enhancement is achieved without modifications to the biosensor hardware, highlighting the potential of data-centric strategies in biosensing. The findings establish a new paradigm in biosensing, demonstrating that the synergy between multi-resonance data acquisition and ML-based analysis can significantly enhance detection accuracy. This study provides a scalable pathway for advancing high-precision biosensing technologies.

Paper number 98:
Title: CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition
Authors: Martijn Bartelds, Ananjan Nandi, Moussa Koulako Bala Doumbouya, Dan Jurafsky, Tatsunori Hashimoto, Karen Livescu
Abstract: Modern deep learning models often achieve high overall performance, but consistently fail on specific subgroups. Group distributionally robust optimization (group DRO) addresses this problem by minimizing the worst-group loss, but it fails when group losses misrepresent performance differences between groups. This is common in domains like speech, where the widely used connectionist temporal classification (CTC) loss scales with input length and varies with linguistic and acoustic properties, leading to spurious differences between group losses. We present CTC-DRO, which addresses the shortcomings of the group DRO objective by smoothing the group weight update to prevent overemphasis on consistently high-loss groups, while using input length-matched batching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of multilingual automatic speech recognition (ASR) across five language sets from the ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and CTC-based baseline models, reducing the worst-language error by up to 47.1% and the average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal computational costs, and offers the potential for reducing group disparities in other domains with similar challenges.

Paper number 99:
Title: Parameter-Dependent Control Lyapunov Functions for Stabilizing Nonlinear Parameter-Varying Systems
Authors: Pan Zhao
Abstract: This paper introduces the concept of parameter-dependent (PD) control Lyapunov functions (CLFs) for gain-scheduled stabilization of nonlinear parameter-varying (NPV) systems. It shows that given a PD-CLF, a min-norm control law can be constructed by solving a robust quadratic program. For polynomial control-affine NPV systems, it provides convex conditions, based on the sum of squares programming, to jointly synthesize a PD-CLF and a PD controller while maximizing the PD region of stabilization. Input constraints can be straightforwardly incorporated into the synthesis procedure. Unlike traditional linear parameter-varying (LPV) methods that rely on linearization or over-approximation to get an LPV model, the proposed framework fully captures the nonlinearities of the system dynamics. The theoretical results are validated through numerical simulations, including a 2D rocket landing case study under varying mass and inertia.

Paper number 100:
Title: TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning
Authors: Giuseppe Paolo, Abdelhakim Benechehab, Hamza Cherkaoui, Albert Thomas, Balázs Kégl
Abstract: Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two levels or require centralized training, which limits their practical applicability. We introduce TAME Agent Framework (TAG), a framework for constructing fully decentralized hierarchical multi-agent systems. TAG enables hierarchies of arbitrary depth through a novel LevelEnv concept, which abstracts each hierarchy level as the environment for the agents above it. This approach standardizes information flow between levels while preserving loose coupling, allowing for seamless integration of diverse agent types. We demonstrate the effectiveness of TAG by implementing hierarchical architectures that combine different RL agents across multiple levels, achieving improved performance over classical multi-agent RL baselines on standard benchmarks. Our results show that decentralized hierarchical organization enhances both learning speed and final performance, positioning TAG as a promising direction for scalable multi-agent systems.

Paper number 101:
Title: DeePen: Penetration Testing for Audio Deepfake Detection
Authors: Nicolas Müller, Piotr Kawa, Adriana Stan, Thien-Phuc Doan, Souhwan Jung, Wei Herng Choong, Philip Sperl, Konstantin Böttinger
Abstract: Deepfakes - manipulated or forged audio and video media - pose significant security risks to individuals, organizations, and society at large. To address these challenges, machine learning-based classifiers are commonly employed to detect deepfake content. In this paper, we assess the robustness of such classifiers through a systematic penetration testing methodology, which we introduce as DeePen. Our approach operates without prior knowledge of or access to the target deepfake detection models. Instead, it leverages a set of carefully selected signal processing modifications - referred to as attacks - to evaluate model vulnerabilities. Using DeePen, we analyze both real-world production systems and publicly available academic model checkpoints, demonstrating that all tested systems exhibit weaknesses and can be reliably deceived by simple manipulations such as time-stretching or echo addition. Furthermore, our findings reveal that while some attacks can be mitigated by retraining detection systems with knowledge of the specific attack, others remain persistently effective. We release all associated code.

Paper number 102:
Title: Exploiting Vulnerabilities in Speech Translation Systems through Targeted Adversarial Attacks
Authors: Chang Liu, Haolin Wu, Xi Yang, Kui Zhang, Cong Wu, Weiming Zhang, Nenghai Yu, Tianwei Zhang, Qing Guo, Jie Zhang
Abstract: As speech translation (ST) systems become increasingly prevalent, understanding their vulnerabilities is crucial for ensuring robust and reliable communication. However, limited work has explored this issue in depth. This paper explores methods of compromising these systems through imperceptible audio manipulations. Specifically, we present two innovative approaches: (1) the injection of perturbation into source audio, and (2) the generation of adversarial music designed to guide targeted translation, while also conducting more practical over-the-air attacks in the physical world. Our experiments reveal that carefully crafted audio perturbations can mislead translation models to produce targeted, harmful outputs, while adversarial music achieve this goal more covertly, exploiting the natural imperceptibility of music. These attacks prove effective across multiple languages and translation models, highlighting a systemic vulnerability in current ST architectures. The implications of this research extend beyond immediate security concerns, shedding light on the interpretability and robustness of neural speech processing systems. Our findings underscore the need for advanced defense mechanisms and more resilient architectures in the realm of audio systems. More details and samples can be found at this https URL.

Paper number 103:
Title: A Multi-Sensor Fusion Approach for Rapid Orthoimage Generation in Large-Scale UAV Mapping
Authors: Jialei He, Zhihao Zhan, Zhituo Tu, Xiang Zhu, Jie Yuan
Abstract: Rapid generation of large-scale orthoimages from Unmanned Aerial Vehicles (UAVs) has been a long-standing focus of research in the field of aerial mapping. A multi-sensor UAV system, integrating the Global Positioning System (GPS), Inertial Measurement Unit (IMU), 4D millimeter-wave radar and camera, can provide an effective solution to this problem. In this paper, we utilize multi-sensor data to overcome the limitations of conventional orthoimage generation methods in terms of temporal performance, system robustness, and geographic reference accuracy. A prior-pose-optimized feature matching method is introduced to enhance matching speed and accuracy, reducing the number of required features and providing precise references for the Structure from Motion (SfM) process. The proposed method exhibits robustness in low-texture scenes like farmlands, where feature matching is difficult. Experiments show that our approach achieves accurate feature matching orthoimage generation in a short time. The proposed drone system effectively aids in farmland detection and management.
    