
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Propagation Measurements and Modeling for Low Altitude UAVs From 1 to 24 GHz
Authors: Cesar Briso, Cesar Calvo, Zhuangzhuang Cui, Lei Zhang, Youyun Xu
Abstract: In most countries, small (<2 kg) and medium (<25 kg) size unmanned aerial vehicles (UAVs) must fly at low altitude, below 120 m, and with permanent radio communications with ground for control and telemetry. These communications links can be provided using 4G/5G networks or dedicated links, but in either this case the communications can be significantly degraded by frequent Non Line of Sight (NLoS) propagation. In this case, reflection and diffraction from ground objects are critical to maintain links, and hence accurate propagation models for this must be considered. In this letter we present a model for path loss when the UAV is flying in NLOS conditions. The study is based on measurements made at frequencies of 1, 4, 12, and 24 GHz with a UAV flying in a suburban environment. Measurements have been used to model NLOS propagation below 4 GHz, where the dominant mechanism is diffraction, and above 4GHzwhere multipath is the dominant propagationmechanism. The model can be of use in predicting excess losses when UAVs fly in suburban NLOS conditions.

Paper number 2:
Title: Interpretable Dual-Filter Fuzzy Neural Networks for Affective Brain-Computer Interfaces
Authors: Xiaowei Jiang, Yanan Chen, Nikhil Ranjan Pal, Yu-Cheng Chang, Yunkai Yang, Thomas Do, Chin-Teng Lin
Abstract: Fuzzy logic provides a robust framework for enhancing explainability, particularly in domains requiring the interpretation of complex and ambiguous signals, such as brain-computer interface (BCI) systems. Despite significant advances in deep learning, interpreting human emotions remains a formidable challenge. In this work, we present iFuzzyAffectDuo, a novel computational model that integrates a dual-filter fuzzy neural network architecture for improved detection and interpretation of emotional states from neuroimaging data. The model introduces a new membership function (MF) based on the Laplace distribution, achieving superior accuracy and interpretability compared to traditional approaches. By refining the extraction of neural signals associated with specific emotions, iFuzzyAffectDuo offers a human-understandable framework that unravels the underlying decision-making processes. We validate our approach across three neuroimaging datasets using functional Near-Infrared Spectroscopy (fNIRS) and Electroencephalography (EEG), demonstrating its potential to advance affective computing. These findings open new pathways for understanding the neural basis of emotions and their application in enhancing human-computer interaction.

Paper number 3:
Title: DCentNet: Decentralized Multistage Biomedical Signal Classification using Early Exits
Authors: Xiaolin Li, Binhua Huang, Barry Cardiff, Deepu John
Abstract: DCentNet is a novel decentralized multistage signal classification approach designed for biomedical data from IoT wearable sensors, integrating early exit points (EEP) to enhance energy efficiency and processing speed. Unlike traditional centralized processing methods, which result in high energy consumption and latency, DCentNet partitions a single CNN model into multiple sub-networks using EEPs. By introducing encoder-decoder pairs at EEPs, the system compresses large feature maps before transmission, significantly reducing wireless data transfer and power usage. If an input is confidently classified at an EEP, processing stops early, optimizing efficiency. Initial sub-networks can be deployed on fog or edge devices to further minimize energy consumption. A genetic algorithm is used to optimize EEP placement, balancing performance and complexity. Experimental results on ECG classification show that with one EEP, DCentNet reduces wireless data transmission by 94.54% and complexity by 21%, while maintaining original accuracy and sensitivity. With two EEPs, sensitivity reaches 98.36%, accuracy 97.74%, wireless data transmission decreases by 91.86%, and complexity is reduced by 22%. Implemented on an ARM Cortex-M4 MCU, DCentNet achieves an average power saving of 73.6% compared to continuous wireless ECG transmission.

Paper number 4:
Title: AirTag, You're It: Reverse Logistics and Last Mile Dynamics
Authors: David Noever, Forrest McKee
Abstract: This study addresses challenges in reverse logistics, a frequently overlooked but essential component of last-mile delivery, particularly in disaster relief scenarios where infrastructure disruptions demand adaptive solutions. While hub-and-spoke logistics networks excel at long-distance scalability, they often fail to optimize closely spaced spokes reliant on distant hubs, introducing inefficiencies in transit times and resource allocation. Using 20 Apple AirTags embedded in packages, this research provides empirical insights into logistical flows, capturing granular spatial and temporal data through Bluetooth LE (BLE) 5 trackers integrated with the Apple Find My network. These trackers demonstrated their value in monitoring dynamic cargo movements, enabling real-time adjustments in mobile hub placement and route optimization, particularly in disaster relief contexts like Hurricane Helene. A novel application of discrete event simulation (DES) further explored the saddle point in hub-spoke configurations, where excessive hub reliance clashes with diminishing spoke interaction demand. By coupling simulation results with empirical AirTag tracking, the study highlights the potential of BLE technology to refine reverse logistics, reduce delays, and improve operational flexibility in both routine and crisis-driven delivery networks.

Paper number 5:
Title: Physics Informed Neural Network Estimated Circuit Parameter Adaptive Modulation of DAB
Authors: Saikat Dey, Ayan Mallik
Abstract: This article presents the development, implementation, and validation of a loss-optimized and circuit parameter-sensitive TPS modulation scheme for a dual-active-bridge DC-DC converter. The proposed approach dynamically adjusts control parameters based on circuit parameters estimated using a physics-informed neural network.

Paper number 6:
Title: Smart Sampling Strategies for Wireless Industrial Data Acquisition
Authors: Marcos Soto (Universidad Loyola AndalucÃ­a)
Abstract: In industrial environments, data acquisition accuracy is crucial for process control and optimization. Wireless telemetry has proven to be a valuable tool for improving efficiency in well-testing operations, enabling bidirectional communication and real-time control of downhole tools. However, high sampling frequencies present challenges in telemetry, including data storage, transmission, computational resource consumption, and battery life of wireless devices. This study explores how optimizing data acquisition strategies can reduce aliasing effects and systematic errors while improving sampling rates without compromising measurement accuracy. A reduction of 80% in sampling frequency was achieved without degrading measurement quality, demonstrating the potential for resource optimization in industrial environments.

Paper number 7:
Title: MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition
Authors: Mehran Shabanpour, Kasra Rad, Sadaf Khademi, Arash Mohammadi
Abstract: High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework's robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.

Paper number 8:
Title: Study on Downlink CSI compression: Are Neural Networks the Only Solution?
Authors: K. Sai Praneeth, Anil Kumar Yerrapragada, Achyuth Sagireddi, Sai Prasad, Radha Krishna Ganti
Abstract: Massive Multi Input Multi Output (MIMO) systems enable higher data rates in the downlink (DL) with spatial multiplexing achieved by forming narrow beams. The higher DL data rates are achieved by effective implementation of spatial multiplexing and beamforming which is subject to availability of DL channel state information (CSI) at the base station. For Frequency Division Duplexing (FDD) systems, the DL CSI has to be transmitted by User Equipment (UE) to the gNB and it constitutes a significant overhead which scales with the number of transmitter antennas and the granularity of the CSI. To address the overhead issue, AI/ML methods using auto-encoders have been investigated, where an encoder neural network model at the UE compresses the CSI and a decoder neural network model at the gNB reconstructs it. However, the use of AI/ML methods has a number of challenges related to (1) model complexity, (2) model generalization across channel scenarios and (3) inter-vendor compatibility of the two sides of the model. In this work, we investigate a more traditional dimensionality reduction method that uses Principal Component Analysis (PCA) and therefore does not suffer from the above challenges. Simulation results show that PCA based CSI compression actually achieves comparable reconstruction performance to commonly used deep neural networks based models.

Paper number 9:
Title: Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation
Authors: BÃ¡lint TÃ³th, Dominik Senti, Thorir Mar Ingolfsson, Jeffrey Zweidler, Alexandre Elsig, Luca Benini, Yawei Li
Abstract: Blood pressure (BP) is a key indicator of cardiovascular health. As hypertension remains a global cause of morbidity and mortality, accurate, continuous, and non-invasive BP monitoring is therefore of paramount importance. Photoplethysmography (PPG) and electrocardiography (ECG) can potentially enable continuous BP monitoring, yet training accurate and robust machine learning (ML) models remains challenging due to variability in data quality and patient-specific factors. Recently, multiple research groups explored Electroencephalographic (EEG)--based foundation models and demonstrated their exceptional ability to learn rich temporal resolution. Considering the morphological similarities between different biosignals, the question arises of whether a model pre-trained on one modality can effectively be exploited to improve the accuracy of a different signal type. In this work, we take an initial step towards generalized biosignal foundation models by investigating whether model representations learned from abundant EEG data can effectively be transferred to ECG/PPG data solely with fine-tuning, without the need for large-scale additional pre-training, for the BP estimation task. Evaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach achieves near state-of-the-art accuracy for diastolic BP (mean absolute error of 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP (mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8 quantization, reducing the smallest model size by over 3.5x (from 13.73 MB down to 3.83 MB) while preserving performance, thereby enabling unobtrusive, real-time BP monitoring on resource-constrained wearable devices.

Paper number 10:
Title: The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG
Authors: Francesco Stefano Carzaniga, Gary Tom Hoppeler, Michael Hersche, Kaspar Anton Schindler, Abbas Rahimi
Abstract: All data modalities are not created equal, even when the signal they measure comes from the same source. In the case of the brain, two of the most important data modalities are the scalp electroencephalogram (EEG), and the intracranial electroencephalogram (iEEG). They are used by human experts, supported by deep learning (DL) models, to accomplish a variety of tasks, such as seizure detection and motor imagery classification. Although the differences between EEG and iEEG are well understood by human experts, the performance of DL models across these two modalities remains under-explored. To help characterize the importance of clean data on the performance of DL models, we propose BrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that training BrainCodec on iEEG and then transferring to EEG yields higher reconstruction quality than training on EEG directly. In addition, we also find that training BrainCodec on both EEG and iEEG improves fidelity when reconstructing EEG. Our work indicates that data sources with higher SNR, such as iEEG, provide better performance across the board also in the medical time-series domain. BrainCodec also achieves up to a 64x compression on iEEG and EEG without a notable decrease in quality. BrainCodec markedly surpasses current state-of-the-art compression models both in final compression ratio and in reconstruction fidelity. We also evaluate the fidelity of the compressed signals objectively on a seizure detection and a motor imagery task performed by standard DL models. Here, we find that BrainCodec achieves a reconstruction fidelity high enough to ensure no performance degradation on the downstream tasks. Finally, we collect the subjective assessment of an expert neurologist, that confirms the high reconstruction quality of BrainCodec in a realistic scenario. The code is available at this https URL.

Paper number 11:
Title: SincPD: An Explainable Method based on Sinc Filters to Diagnose Parkinson's Disease Severity by Gait Cycle Analysis
Authors: Armin Salimi-Badr, Mahan Veisi, Sadra Berangi
Abstract: In this paper, an explainable deep learning-based classifier based on adaptive sinc filters for Parkinson's Disease diagnosis (PD) along with determining its severity, based on analyzing the gait cycle (SincPD) is presented. Considering the effects of PD on the gait cycle of patients, the proposed method utilizes raw data in the form of vertical Ground Reaction Force (vGRF) measured by wearable sensors placed in soles of subjects' shoes. The proposed method consists of Sinc layers that model adaptive bandpass filters to extract important frequency-bands in gait cycle of patients along with healthy subjects. Therefore, by considering these frequencies, the reasons behind the classification a person as a patient or healthy can be explained. In this method, after applying some preprocessing processes, a large model equipped with many filters is first trained. Next, to prune the extra units and reach a more explainable and parsimonious structure, the extracted filters are clusters based on their cut-off frequencies using a centroid-based clustering approach. Afterward, the medoids of the extracted clusters are considered as the final filters. Therefore, only 15 bandpass filters for each sensor are derived to classify patients and healthy subjects. Finally, the most effective filters along with the sensors are determined by comparing the energy of each filter encountering patients and healthy subjects.

Paper number 12:
Title: Large Cognition Model: Towards Pretrained EEG Foundation Model
Authors: Chi-Sheng Chen, Ying-Jung Chen, Aidan Hung-Wen Tsai
Abstract: Electroencephalography provides a non-invasive window into brain activity, offering valuable insights for neurological research, brain-computer interfaces, and clinical diagnostics. However, the development of robust machine learning models for EEG analysis is hindered by the scarcity of large-scale, well-annotated datasets and the inherent variability of EEG signals across subjects and recording conditions. Inspired by the success of foundation models in natural language processing and computer vision, we propose the Large Cognition Model-a transformer-based foundation model designed to generalize across diverse EEG datasets and downstream tasks. Unlike traditional approaches, our proposed transformer-based architecture demonstrates strong generalization capabilities across datasets and tasks, even without pretraining, surpassing some existing EEG universal models on specific downstream applications. LCM leverages large-scale self-supervised learning techniques to capture universal EEG representations, enabling efficient fine-tuning for applications such as cognitive state decoding, disease classification, and neurofeedback systems. We introduce a novel architecture that integrates temporal and spectral attention mechanisms, optimizing the model's ability to extract meaningful features from raw EEG signals. Extensive evaluations demonstrate that LCM outperforms state-of-the-art approaches across multiple EEG benchmarks, exhibiting strong cross-subject and cross-task generalization. Our findings highlight the potential of pretrained EEG foundation models to accelerate advancements in neuroscience, personalized medicine, and BCI technology.

Paper number 13:
Title: Bridging Brain Signals and Language: A Deep Learning Approach to EEG-to-Text Decoding
Authors: Mostafa El Gedawy, Omnia Nabil, Omar Mamdouh, Mahmoud Nady, Nour Alhuda Adel, Ahmed Fares
Abstract: Brain activity translation into human language delivers the capability to revolutionize machine-human interaction while providing communication support to people with speech disability. Electronic decoding reaches a certain level of achievement yet current EEG-to-text decoding methods fail to reach open vocabularies and depth of meaning and individual brain-specific variables. We introduce a special framework which changes conventional closed-vocabulary EEG-to-text decoding approaches by integrating subject-specific learning models with natural language processing methods to resolve detection obstacles. This method applies a deep representation learning approach to extract important EEG features which allow training of neural networks to create elaborate sentences that extend beyond original data content. The ZuCo dataset analysis demonstrates that research findings achieve higher BLEU, ROUGE and BERTScore performance when compared to current methods. The research proves how this framework functions as an effective approach to generate meaningful and correct texts while understanding individual brain variations. The proposed research aims to create a connection between open-vocabulary Text generation systems and human brain signal interpretation for developing efficacious brain-to-text systems. The research produces interdisciplinary effects through innovative assistive technology development and personalized communication systems which extend possibilities for human-computer interaction in various settings.

Paper number 14:
Title: CSSSTN: A Class-sensitive Subject-to-subject Semantic Style Transfer Network for EEG Classification in RSVP Tasks
Authors: Ziyue Yang, Chengrui Chen, Yong Peng, Qiong Chen, Wanzeng Kong
Abstract: The Rapid Serial Visual Presentation (RSVP) paradigm represents a promising application of electroencephalography (EEG) in Brain-Computer Interface (BCI) systems. However, cross-subject variability remains a critical challenge, particularly for BCI-illiterate users who struggle to effectively interact with these systems. To address this issue, we propose the Class-Sensitive Subject-to-Subject Semantic Style Transfer Network (CSSSTN), which incorporates a class-sensitive approach to align feature distributions between golden subjects (BCI experts) and target (BCI-illiterate) users on a class-by-class basis. Building on the SSSTN framework, CSSSTN incorporates three key components: (1) subject-specific classifier training, (2) a unique style loss to transfer class-discriminative features while preserving semantic information through a modified content loss, and (3) an ensemble approach to integrate predictions from both source and target domains. We evaluated CSSSTN using both a publicly available dataset and a self-collected dataset. Experimental results demonstrate that CSSSTN outperforms state-of-the-art methods, achieving mean balanced accuracy improvements of 6.4\% on the Tsinghua dataset and 3.5\% on the HDU dataset, with notable benefits for BCI-illiterate users. Ablation studies confirm the effectiveness of each component, particularly the class-sensitive transfer and the use of lower-layer features, which enhance transfer performance and mitigate negative transfer. Additionally, CSSSTN achieves competitive results with minimal target data, reducing calibration time and effort. These findings highlight the practical potential of CSSSTN for real-world BCI applications, offering a robust and scalable solution to improve the performance of BCI-illiterate users while minimizing reliance on extensive training data. Our code is available at this https URL.

Paper number 15:
Title: PixleepFlow: A Pixel-Based Lifelog Framework for Predicting Sleep Quality and Stress Level
Authors: Younghoon Na
Abstract: The analysis of lifelogs can yield valuable insights into an individual's daily life, particularly with regard to their health and well-being. The accurate assessment of quality of life is necessitated by the use of diverse sensors and precise synchronization. To rectify this issue, this study proposes the image-based sleep quality and stress level estimation flow (PixleepFlow). PixleepFlow employs a conversion methodology into composite image data to examine sleep patterns and their impact on overall health. Experiments were conducted using lifelog datasets to ascertain the optimal combination of data formats. In addition, we identified which sensor information has the greatest influence on the quality of life through Explainable Artificial Intelligence(XAI). As a result, PixleepFlow produced more significant results than various data formats. This study was part of a written-based competition, and the additional findings from the lifelog dataset are detailed in Section Section IV. More information about PixleepFlow can be found at this https URL.

Paper number 16:
Title: MC2SleepNet: Multi-modal Cross-masking with Contrastive Learning for Sleep Stage Classification
Authors: Younghoon Na
Abstract: Sleep profoundly affects our health, and sleep deficiency or disorders can cause physical and mental problems. % Despite significant findings from previous studies, challenges persist in optimizing deep learning models, especially in multi-modal learning for high-accuracy sleep stage classification. Our research introduces MC2SleepNet (Multi-modal Cross-masking with Contrastive learning for Sleep stage classification Network). It aims to facilitate the effective collaboration between Convolutional Neural Networks (CNNs) and Transformer architectures for multi-modal training with the help of contrastive learning and cross-masking. % Raw single channel EEG signals and corresponding spectrogram data provide differently characterized modalities for multi-modal learning. Our MC2SleepNet has achieved state-of-the-art performance with an accuracy of both 84.6% on the SleepEDF-78 and 88.6% accuracy on the Sleep Heart Health Study (SHHS). These results demonstrate the effective generalization of our proposed network across both small and large datasets.

Paper number 17:
Title: In-sensor 24 classes HAR under 850 Bytes
Authors: Ahmed.S Benmessaoud, Wassim Kezai, Farida Medjani, Khalid Bouaita, Tahar Kezai
Abstract: The year 2023 was a key year for tinyML unleashing a new age of intelligent sensors pushing intelligence from the MCU into the source of the data at the sensor level, enabling them to perform sophisticated algorithms and machine learning models in real-time. This study presents an innovative approach to Human Activity Recognition (HAR) using Intelligent Sensor Processing Units (ISPUs), demonstrating the feasibility of deploying complex machine learning models directly on ultra-constrained sensor hardware. We developed a 24-class HAR model achieving 85\% accuracy while operating within an 850-byte stack memory limit. The model processes accelerometer and gyroscope data in real time, reducing latency, enhancing data privacy, and consuming only 0.5 mA of power. To address memory constraints, we employed incremental class injection and feature optimization techniques, enabling scalability without compromising performance. This work underscores the transformative potential of on-sensor processing for applications in healthcare, predictive maintenance, and smart environments, while introducing a publicly available, diverse HAR dataset for further research. Future efforts will explore advanced compression techniques and broader IoT integration to push the boundaries of TinyML on constrained devices.

Paper number 18:
Title: Model-Based Learning for DOA Estimation with One-Bit Single-Snapshot Sparse Arrays
Authors: Yunqiao Hu, Shunqiao Sun, Yimin D. Zhang
Abstract: We address the challenging problem of estimating the directions-of-arrival (DOAs) of multiple off-grid signals using a single snapshot of one-bit quantized measurements. Conventional DOA estimation methods face difficulties in tackling this problem effectively. This paper introduces a domain-knowledge-guided learning framework to achieve high-resolution DOA estimation in such a scenario, thus drastically reducing hardware complexity without compromising performance. We first reformulate DOA estimation as a maximum a posteriori (MAP) problem, unifying on-grid and off-grid scenarios under a Laplacian-type sparsity prior to effectively enforce sparsity for both uniform and sparse linear arrays. For off-grid signals, a first-order approximation grid model is embedded into the one-bit signal model. We then reinterpret one-bit sensing as a binary classification task, employing a multivariate Bernoulli likelihood with a logistic link function to enhance stability and estimation accuracy. To resolve the non-convexity inherent in the MAP formulation, we develop augmented algorithmic frameworks based on majorization-minimization principles. Further, we design model-based inference neural networks by deep unrolling these frameworks, significantly reducing computational complexity while preserving the estimation precision. Extensive simulations demonstrate the robustness of the proposed framework across a wide range of input signal-to-noise ratio values and off-grid deviations. By integrating the unified model-based priors with data-driven learning, this work bridges the gap between theoretical guarantees and practical feasibility in one-bit single-snapshot DOA estimation, offering a scalable, hardware-efficient solution for next-generation radar and communication systems.

Paper number 19:
Title: Estimating Time Delays between Signals under Mixed Noise Influence with Novel Cross- and Bispectral Methods
Authors: Tin Jurhar, Franziska Pellegrini, Ana I. NuÃ±es del Toro, Tilman Stephani, Guido Nolte, Stefan Haufe
Abstract: A common problem to signal processing are biases introduced by correlated noise. In Time-Delay Estimation (TDE), which quantifies a time lag between two signals, noise mixing introduces a bias towards zero delay in conventional TDE protocols based on the cross- or bispectrum. Here we propose two novel TDE approaches that address these shortcomings: (1) A cross-spectrum based TDE protocol that relies on estimating the periodicity of the phase spectrum rather than its slope, and (2) a bispectrum based TDE analysis, bispectral antisymmetrization, which removes contributions from not just Gaussian but all independent sources. In a simulation study, we compare conventional and novel TDE protocols and resolve differences in performance with respect to noise Gaussianity and auto-correlation structure. As a proof-of-concept, we also perform TDE analysis on a neural stimulation dataset (n=3). We find that antisymmetrization consistently outperforms conventional bispectral TDE methods at low signal-to-noise ratios (SNR) and removes spurious zero-delay estimates in all mixed-noise environments. TDE based on phase periodicity also improves signal sensitivity compared to conventional cross-spectral methods. These observations are stable with respect to the magnitude of the delay and the statistical properties of the noise.

Paper number 20:
Title: ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis
Authors: Xu Wang, Jiaju Kang, Puyu Han
Abstract: We present ECG-Expert-QA, a comprehensive multimodal dataset designed for evaluating diagnostic capabilities in ECG interpretation, integrating real clinical data with systematically generated synthetic cases. The dataset encompasses six fundamental diagnostic tasks, comprising 47,211 meticulously curated question-answer pairs that span a spectrum of clinical scenarios, from basic rhythm analysis to complex case interpretation. By simulating challenging clinical cases through a rigorous medical knowledge-guided process, ECG-Expert-QA not only enhances the availability of annotated diagnostic data but also significantly increases the complexity and diversity of clinical presentations, including rare cardiac conditions and temporal progression patterns. This design enables comprehensive evaluation of medical language models across multiple dimensions, including diagnostic accuracy, clinical reasoning, and knowledge integration. To facilitate global research collaboration, ECG-Expert-QA is available in both Chinese and English versions, with rigorous quality control ensuring linguistic and clinical consistency. The dataset's challenging diagnostic tasks, which include interpretation of complex arrhythmias, identification of subtle ischemic changes, and integration of clinical context, establish it as an effective benchmark for advancing AI-assisted ECG interpretation and pushing the boundaries of current diagnostic models. Our dataset is open-source and available at this https URL.

Paper number 21:
Title: Fusion of ECG Foundation Model Embeddings to Improve Early Detection of Acute Coronary Syndromes
Authors: Zeyuan Meng, Lovely Yeswanth Panchumarthi, Saurabh Kataria, Alex Fedorov, Jessica ZÃ¨gre-Hemsey, Xiao Hu, Ran Xiao
Abstract: Acute Coronary Syndrome (ACS) is a life-threatening cardiovascular condition where early and accurate diagnosis is critical for effective treatment and improved patient outcomes. This study explores the use of ECG foundation models, specifically ST-MEM and ECG-FM, to enhance ACS risk assessment using prehospital ECG data collected in ambulances. Both models leverage self-supervised learning (SSL), with ST-MEM using a reconstruction-based approach and ECG-FM employing contrastive learning, capturing unique spatial and temporal ECG features. We evaluate the performance of these models individually and through a fusion approach, where their embeddings are combined for enhanced prediction. Results demonstrate that both foundation models outperform a baseline ResNet-50 model, with the fusion-based approach achieving the highest performance (AUROC: 0.843 +/- 0.006, AUCPR: 0.674 +/- 0.012). These findings highlight the potential of ECG foundation models for early ACS detection and motivate further exploration of advanced fusion strategies to maximize complementary feature utilization.

Paper number 22:
Title: Frequency-Aware Masked Autoencoders for Human Activity Recognition using Accelerometers
Authors: Niels R. Lorenzen, Poul J. Jennum, Emmanuel Mignot, Andreas Brink-Kjaer
Abstract: Wearable accelerometers are widely used for continuous monitoring of physical activity. Supervised machine learning and deep learning algorithms have long been used to extract meaningful activity information from raw accelerometry data, but progress has been hampered by the limited amount of publicly available labeled data. Exploiting large unlabeled datasets using self-supervised pretraining is a relatively new and underexplored approach in the field of human activity recognition (HAR). We used a time-series transformer masked autoencoder (MAE) approach to self-supervised pretraining and propose a novel spectrogram-based loss function named the log-scale mean magnitude (LMM) loss. We compared MAE models pretrained with LMM to one trained with the mean squared error (MSE) loss. We leveraged the large unlabeled UK Biobank accelerometry dataset (n = 109k) for pretraining and evaluated downstream HAR performance using linear classifier in a smaller labelled dataset. We found that pretraining with the LMM loss improved performance compared to a model pretrained with the MSE loss, with balanced accuracies of 0.848 and 0.709, respectively. Further analysis revealed that better convergence of the LMM loss, but not the MSE loss significantly correlated with improved downstream performance (r=-0.61, p=0.04) for balanced accuracy). Finally, we compared our MAE models to the state-of-the-art for HAR, also pretrained on the UK Biobank accelerometry data. Our LMM-pretrained models performed better when finetuned using a linear classifier and performed comparably when finetuned using an LSTM classifier, while MSE-pretrained models consistently underperformed. Our findings demonstrate that the LMM loss is a robust and effective method for pretraining MAE models on accelerometer data for HAR. Future work should explore optimizing loss function combinations and extending our approach to other tasks.

Paper number 23:
Title: Low-Interference Near-Field Multi-User Communication Enabled by Spatially Converging Multi-Mode Vortex Waves
Authors: Yufei Zhao, Qihao Lv, Yuanbin Chen, Afkar Mohamed Ismail, Yong Liang Guan, Chau Yuen
Abstract: This paper proposes a multi-user Spatial Division Multiplexing (SDM) near-field access scheme, inspired by the orthogonal characteristics of multi-mode vortex waves. A Reconfigurable Meta-surface (RM) is ingeniously employed as the gateway for information transmission. This RM not only receives spatially overlapping multiplexed multi-mode vortex beams but also converts them into focused point beams in the near field. Specifically, a multi-port microstrip array method is utilized to generate multiple orthogonal vortex electromagnetic wave modes. Different ports serve as feeding points for baseband signals, allowing independent modulated data to be flexibly loaded onto different modes. After being adjusted by the RM, the vortex electromagnetic waves are converted into energy-focusing point beams, which can be directed to arbitrary 3D positions in the RM's near-field region and received by different users. Since the spatial positions of the point beams are non-overlapping, this approach not only ensures energy concentration but also significantly reduces inter-user interference. Near-field scanning results in a microwave anechoic chamber validate the effectiveness of this method, while real-time communication demonstrations confirm the system's capability for low-interference information multiplexing and transmission in practical scenarios.

Paper number 24:
Title: Brain-to-Text Decoding: A Non-invasive Approach via Typing
Authors: Jarod LÃ©vy, Mingfang Zhang, Svetlana Pinet, JÃ©rÃ©my Rapin, Hubert Banville, StÃ©phane d'Ascoli, Jean-RÃ©mi King
Abstract: Modern neuroprostheses can now restore communication in patients who have lost the ability to speak or move. However, these invasive devices entail risks inherent to neurosurgery. Here, we introduce a non-invasive method to decode the production of sentences from brain activity and demonstrate its efficacy in a cohort of 35 healthy volunteers. For this, we present Brain2Qwerty, a new deep learning architecture trained to decode sentences from either electro- (EEG) or magneto-encephalography (MEG), while participants typed briefly memorized sentences on a QWERTY keyboard. With MEG, Brain2Qwerty reaches, on average, a character-error-rate (CER) of 32% and substantially outperforms EEG (CER: 67%). For the best participants, the model achieves a CER of 19%, and can perfectly decode a variety of sentences outside of the training set. While error analyses suggest that decoding depends on motor processes, the analysis of typographical errors suggests that it also involves higher-level cognitive factors. Overall, these results narrow the gap between invasive and non-invasive methods and thus open the path for developing safe brain-computer interfaces for non-communicating patients.

Paper number 25:
Title: Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid Self-Supervised Learning Framework
Authors: Cheol-Hui Lee, Hakseung Kim, Byung C. Yoon, Dong-Joo Kim
Abstract: Sleep is essential for maintaining human health and quality of life. Analyzing physiological signals during sleep is critical in assessing sleep quality and diagnosing sleep disorders. However, manual diagnoses by clinicians are time-intensive and subjective. Despite advances in deep learning that have enhanced automation, these approaches remain heavily dependent on large-scale labeled datasets. This study introduces SynthSleepNet, a multimodal hybrid self-supervised learning framework designed for analyzing polysomnography (PSG) data. SynthSleepNet effectively integrates masked prediction and contrastive learning to leverage complementary features across multiple modalities, including electroencephalogram (EEG), electrooculography (EOG), electromyography (EMG), and electrocardiogram (ECG). This approach enables the model to learn highly expressive representations of PSG data. Furthermore, a temporal context module based on Mamba was developed to efficiently capture contextual information across signals. SynthSleepNet achieved superior performance compared to state-of-the-art methods across three downstream tasks: sleep-stage classification, apnea detection, and hypopnea detection, with accuracies of 89.89%, 99.75%, and 89.60%, respectively. The model demonstrated robust performance in a semi-supervised learning environment with limited labels, achieving accuracies of 87.98%, 99.37%, and 77.52% in the same tasks. These results underscore the potential of the model as a foundational tool for the comprehensive analysis of PSG data. SynthSleepNet demonstrates comprehensively superior performance across multiple downstream tasks compared to other methodologies, making it expected to set a new standard for sleep disorder monitoring and diagnostic systems.

Paper number 26:
Title: Multi-View Contrastive Network (MCNet) for Motor Imagery Classification
Authors: Ziwei Wang, Siyang Li, Xiaoqing Chen, Wei Li, Dongrui Wu
Abstract: Objective: An electroencephalography (EEG)-based brain-computer interface (BCI) serves as a direct communication pathway between the human brain and an external device. While supervised learning has been extensively explored for motor imagery (MI) EEG classification, small data quantity has been a key factor limiting the performance of deep feature learning. Methods: This paper proposes a knowledge-driven time-space-frequency based multi-view contrastive network (MCNet) for MI EEG decoding in BCIs. MCNet integrates knowledge from the time, space, and frequency domains into the training process through data augmentations from multiple views, fostering more discriminative feature learning of the characteristics of EEG data. We introduce a cross-view contrasting module to learn from different augmented views and a cross-model contrasting module to enhance the consistency of features extracted between knowledge-guided and data-driven models. Results: The combination of EEG data augmentation strategies was systematically investigated for more informative supervised contrastive learning. Experiments on four public MI datasets and three different architectures demonstrated that MCNet outperformed 10 existing approaches. Significance: Our approach can significantly boost EEG classification performance beyond designated networks, showcasing the potential to enhance the feature learning process for better EEG decoding.

Paper number 27:
Title: ConSense: Continually Sensing Human Activity with WiFi via Growing and Picking
Authors: Rong Li, Tao Deng, Siwei Feng, Mingjie Sun, Juncheng Jia
Abstract: WiFi-based human activity recognition (HAR) holds significant application potential across various fields. To handle dynamic environments where new activities are continuously introduced, WiFi-based HAR systems must adapt by learning new concepts without forgetting previously learned ones. Furthermore, retaining knowledge from old activities by storing historical exemplar is impractical for WiFi-based HAR due to privacy concerns and limited storage capacity of edge devices. In this work, we propose ConSense, a lightweight and fast-adapted exemplar-free class incremental learning framework for WiFi-based HAR. The framework leverages the transformer architecture and involves dynamic model expansion and selective retraining to preserve previously learned knowledge while integrating new information. Specifically, during incremental sessions, small-scale trainable parameters that are trained specifically on the data of each task are added in the multi-head self-attention layer. In addition, a selective retraining strategy that dynamically adjusts the weights in multilayer perceptron based on the performance stability of neurons across tasks is used. Rather than training the entire model, the proposed strategies of dynamic model expansion and selective retraining reduce the overall computational load while balancing stability on previous tasks and plasticity on new tasks. Evaluation results on three public WiFi datasets demonstrate that ConSense not only outperforms several competitive approaches but also requires fewer parameters, highlighting its practical utility in class-incremental scenarios for HAR.

Paper number 28:
Title: Urinary Tract Infection Detection in Digital Remote Monitoring: Strategies for Managing Participant-Specific Prediction Complexity
Authors: Kexin Fan, Alexander Capstick, Ramin Nilforooshan, Payam Barnaghi
Abstract: Urinary tract infections (UTIs) are a significant health concern, particularly for people living with dementia (PLWD), as they can lead to severe complications if not detected and treated early. This study builds on previous work that utilised machine learning (ML) to detect UTIs in PLWD by analysing in-home activity and physiological data collected through low-cost, passive sensors. The current research focuses on improving the performance of previous models, particularly by refining the Multilayer Perceptron (MLP), to better handle variations in home environments and improve sex fairness in predictions by making use of concepts from multitask learning. This study implemented three primary model designs: feature clustering, loss-dependent clustering, and participant ID embedding which were compared against a baseline MLP model. The results demonstrated that the loss-dependent MLP achieved the most significant improvements, increasing validation precision from 48.92% to 72.60% and sensitivity from 27.44% to 70.52%, while also enhancing model fairness across sexes. These findings suggest that the refined models offer a more reliable and equitable approach to early UTI detection in PLWD, addressing participant-specific data variations and enabling clinicians to detect and screen for UTI risks more effectively, thereby facilitating earlier and more accurate treatment decisions.

Paper number 29:
Title: Multimodal Sleep Stage and Sleep Apnea Classification Using Vision Transformer: A Multitask Explainable Learning Approach
Authors: Kianoosh Kazemi, Iman Azimi, Michelle Khine, Rami N. Khayat, Amir M. Rahmani, Pasi Liljeberg
Abstract: Sleep is an essential component of human physiology, contributing significantly to overall health and quality of life. Accurate sleep staging and disorder detection are crucial for assessing sleep quality. Studies in the literature have proposed PSG-based approaches and machine-learning methods utilizing single-modality signals. However, existing methods often lack multimodal, multilabel frameworks and address sleep stages and disorders classification separately. In this paper, we propose a 1D-Vision Transformer for simultaneous classification of sleep stages and sleep disorders. Our method exploits the sleep disorders' correlation with specific sleep stage patterns and performs a simultaneous identification of a sleep stage and sleep disorder. The model is trained and tested using multimodal-multilabel sensory data (including photoplethysmogram, respiratory flow, and respiratory effort signals). The proposed method shows an overall accuracy (cohen's Kappa) of 78% (0.66) for five-stage sleep classification and 74% (0.58) for sleep apnea classification. Moreover, we analyzed the encoder attention weights to clarify our models' predictions and investigate the influence different features have on the models' outputs. The result shows that identified patterns, such as respiratory troughs and peaks, make a higher contribution to the final classification process.

Paper number 30:
Title: Using Graph Convolutional Networks to Address fMRI Small Data Problems
Authors: Thomas Screven, Andras Necz, Jason Smucny, Ian Davidson
Abstract: Although great advances in the analysis of neuroimaging data have been made, a major challenge is a lack of training data. This is less problematic in tasks such as diagnosis, where much data exists, but particularly prevalent in harder problems such as predicting treatment responses (prognosis), where data is focused and hence limited. Here, we address the learning from small data problems for medical imaging using graph neural networks. This is particularly challenging as the information about the patients is themselves graphs (regions of interest connectivity graphs). We show how a spectral representation of the connectivity data allows for efficient propagation that can yield approximately 12\% improvement over traditional deep learning methods using the exact same data. We show that our method's superior performance is due to a data smoothing result that can be measured by closing the number of triangle inequalities and thereby satisfying transitivity.

Paper number 31:
Title: Accuracy of Wearable ECG Parameter Calculation Method for Long QT and First-Degree A-V Block Detection: A Multi-Center Real-World Study with External Validations Compared to Standard ECG Machines and Cardiologist Assessments
Authors: Sumei Fan, Deyun Zhang, Yue Wang, Shijia Geng, Kun Lu, Meng Sang, Weilun Xu, Haixue Wang, Qinghao Zhao, Chuandong Cheng, Peng Wang, Shenda Hong
Abstract: In recent years, wearable devices have revolutionized cardiac monitoring by enabling continuous, non-invasive ECG recording in real-world settings. Despite these advances, the accuracy of ECG parameter calculations (PR interval, QRS interval, QT interval, etc.) from wearables remains to be rigorously validated against conventional ECG machines and expert clinician assessments. In this large-scale, multicenter study, we evaluated FeatureDB, a novel algorithm for automated computation of ECG parameters from wearable single-lead signals Three diverse datasets were employed: the AHMU-FH dataset (n=88,874), the CSE dataset (n=106), and the HeartVoice-ECG-lite dataset (n=369) with annotations provided by two experienced cardiologists. FeatureDB demonstrates a statistically significant correlation with key parameters (PR interval, QRS duration, QT interval, and QTc) calculated by standard ECG machines and annotated by clinical doctors. Bland-Altman analysis confirms a high level of this http URL,FeatureDB exhibited robust diagnostic performance in detecting Long QT syndrome (LQT) and atrioventricular block interval abnormalities (AVBI),with excellent area under the ROC curve (LQT: 0.836, AVBI: 0.861),accuracy (LQT: 0.856, AVBI: 0.845),sensitivity (LQT: 0.815, AVBI: 0.877),and specificity (LQT: 0.856, AVBI: 0.845).This further validates its clinical reliability. These results validate the clinical applicability of FeatureDB for wearable ECG analysis and highlight its potential to bridge the gap between traditional diagnostic methods and emerging wearable this http URL,this study supports integrating wearable ECG devices into large-scale cardiovascular disease management and early intervention strategies,and it highlights the potential of wearable ECG technologies to deliver accurate,clinically relevant cardiac monitoring while advancing broader applications in cardiovascular care.

Paper number 32:
Title: Attention-based UAV Trajectory Optimization for Wireless Power Transfer-assisted IoT Systems
Authors: Li Dong, Feibo Jiang, Yubo Peng
Abstract: Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted Internet of Things (IoT) systems face the following challenges: limited resources and suboptimal trajectory planning. Reinforcement learning-based trajectory planning schemes face issues of low search efficiency and learning instability when optimizing large-scale systems. To address these issues, we present an Attention-based UAV Trajectory Optimization (AUTO) framework based on the graph transformer, which consists of an Attention Trajectory Optimization Model (ATOM) and a Trajectory lEarNing Method based on Actor-critic (TENMA). In ATOM, a graph encoder is used to calculate the self-attention characteristics of all IoTDs, and a trajectory decoder is developed to optimize the number and trajectories of UAVs. TENMA then trains the ATOM using an improved Actor-Critic method, in which the real reward of the system is applied as the baseline to reduce variances in the critic network. This method is suitable for high-quality and large-scale multi-UAV trajectory planning. Finally, we develop numerous experiments, including a hardware experiment in the field case, to verify the feasibility and efficiency of the AUTO framework.

Paper number 33:
Title: Multimodal Bearing Fault Classification Under Variable Conditions: A 1D CNN with Transfer Learning
Authors: Tasfiq E. Alam, Md Manjurul Ahsan, Shivakumar Raman
Abstract: Bearings play an integral role in ensuring the reliability and efficiency of rotating machinery - reducing friction and handling critical loads. Bearing failures that constitute up to 90% of mechanical faults highlight the imperative need for reliable condition monitoring and fault detection. This study proposes a multimodal bearing fault classification approach that relies on vibration and motor phase current signals within a one-dimensional convolutional neural network (1D CNN) framework. The method fuses features from multiple signals to enhance the accuracy of fault detection. Under the baseline condition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the model reaches an accuracy of 96% with addition of L2 regularization. This represents a notable improvement of 2% compared to the non-regularized model. In addition, the model demonstrates robust performance across three distinct operating conditions by employing transfer learning (TL) strategies. Among the tested TL variants, the approach that preserves parameters up to the first max-pool layer and then adjusts subsequent layers achieves the highest performance. While this approach attains excellent accuracy across varied conditions, it requires more computational time due to its greater number of trainable parameters. To address resource constraints, less computationally intensive models offer feasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal 1D CNN framework with late fusion and TL strategies lays a foundation for more accurate, adaptable, and efficient bearing fault classification in industrial environments with variable operating conditions.

Paper number 34:
Title: Interference Factors and Compensation Methods when Using Infrared Thermography for Temperature Measurement: A Review
Authors: Dong Pan, Tan Mo, Zhaohui Jiang, Yuxia Duan, Xavier Maldague, Weihua Gui
Abstract: Infrared thermography (IRT) is a widely used temperature measurement technology, but it faces the problem of measurement errors under interference factors. This paper attempts to summarize the common interference factors and temperature compensation methods when applying IRT. According to the source of factors affecting the infrared temperature measurement accuracy, the interference factors are divided into three categories: factors from the external environment, factors from the measured object, and factors from the infrared thermal imager itself. At the same time, the existing compensation methods are classified into three categories: Mechanism Modeling based Compensation method (MMC), Data-Driven Compensation method (DDC), and Mechanism and Data jointly driven Compensation method (MDC). Furthermore, we discuss the problems existing in the temperature compensation methods and future research directions, aiming to provide some references for researchers in academia and industry when using IRT technology for temperature measurement.

Paper number 35:
Title: Temperature Compensation Method of Six-Axis Force/Torque Sensor Using Gated Recurrent Unit
Authors: Hyun-Bin Kim, Seokju Lee, Byeong-Il Ham, Kyung-Soo Kim
Abstract: This study aims to enhance the accuracy of a six-axis force/torque sensor compared to existing approaches that utilize Multi-Layer Perceptron (MLP) and the Least Square Method. The sensor used in this study is based on a photo-coupler and operates with infrared light, making it susceptible to dark current effects, which cause drift due to temperature variations. Additionally, the sensor is compact and lightweight (45g), resulting in a low thermal capacity. Consequently, even small amounts of heat can induce rapid temperature changes, affecting the sensor's performance in real time. To address these challenges, this study compares the conventional MLP approach with the proposed Gated Recurrent Unit (GRU)-based method. Experimental results demonstrate that the GRU approach, leveraging sequential data, achieves superior performance.

Paper number 36:
Title: A Machine Learning Approach for Design of Frequency Selective Surface based Radar Absorbing Material via Image Prediction
Authors: Vijay Kumar Sutrakar, Anjana P K, Sajal Kesharwani, Siddharth Bisariya
Abstract: The paper presents an innovative methodology for designing frequency selective surface (FSS) based radar absorbing materials using machine learning (ML) technique. In conventional electromagnetic design, unit cell dimensions of FSS are used as input and absorption coefficient is then predicted for a given design. In this paper, absorption coefficient is considered as input to ML model and image of FSS unit cell is predicted. Later, this image is used for generating the FSS unit cell parameters. Eleven different ML models are studied over a wide frequency band of 1GHz to 30GHz. Out of which six ML models (i.e. (a) Random Forest classification, (b) K- Neighbors Classification, (c) Grid search regression, (d) Random Forest regression, (e) Decision tree classification, and (f) Decision tree regression) show training accuracy more than 90%. The absorption coefficients with varying frequencies of these predicted images are subsequently evaluated using commercial electromagnetic solver. The performance of these ML models is encouraging, and it can be used for accelerating design and optimization of high performance FSS based radar absorbing material for advanced electromagnetic applications in future.

Paper number 37:
Title: CLEP-GAN: An Innovative Approach to Subject-Independent ECG Reconstruction from PPG Signals
Authors: Xiaoyan Li, Shixin Xu, Faisal Habib, Neda Aminnejad, Arvind Gupta, Huaxiong Huang
Abstract: This study addresses the challenge of reconstructing unseen ECG signals from PPG signals, a critical task for non-invasive cardiac monitoring. While numerous public ECG-PPG datasets are available, they lack the diversity seen in image datasets, and data collection processes often introduce noise, complicating ECG reconstruction from PPG even with advanced machine learning models. To tackle these challenges, we first introduce a novel synthetic ECG-PPG data generation technique using an ODE model to enhance training diversity. Next, we develop a novel subject-independent PPG-to-ECG reconstruction model that integrates contrastive learning, adversarial learning, and attention gating, achieving results comparable to or even surpassing existing approaches for unseen ECG reconstruction. Finally, we examine factors such as sex and age that impact reconstruction accuracy, emphasizing the importance of considering demographic diversity during model training and dataset augmentation.

Paper number 38:
Title: Gaussian Process-Based Scalar Field Estimation in GPS-Denied Environments
Authors: Muzaffar Qureshi, Tochukwu Elijah Ogri, Humberto Ramos, Zachary I. Bell, Rushikesh Kamalapurkar
Abstract: This paper presents a methodology for an autonomous agent to map an unknown scalar field in GPS-denied regions. To reduce localization errors, the agent alternates between GPS-enabled and GPS-denied areas while collecting measurements. User-defined error bounds determine the dwell time in each region. A switching trajectory is then designed to ensure field measurements in GPS-denied regions remain within the specified error limits. A Lyapunov-based stability analysis guarantees bounded error trajectories while tracking the desired path. The effectiveness of the proposed methodology is demonstrated through simulations, with an error analysis comparing the GP-predicted scalar field model to the actual field.

Paper number 39:
Title: Data-Driven Input-Output Control Barrier Functions
Authors: MMohammad Bajelani, Klaske van Heusden
Abstract: Control Barrier Functions (CBFs) offer a framework for ensuring set invariance and designing constrained control laws. However, crafting a valid CBF relies on system-specific assumptions and the availability of an accurate system model, underscoring the need for systematic data-driven synthesis methods. This paper introduces a data-driven approach to synthesizing a CBF for discrete-time LTI systems using only input-output measurements. The method begins by computing the maximal control invariant set using an input-output data-driven representation, eliminating the need for precise knowledge of the system's order and explicit state estimation. The proposed CBF is then systematically derived from this set, which can accommodate multiple input-output constraints. Furthermore, the proposed CBF is leveraged to develop a minimally invasive safety filter that ensures recursive feasibility with an adaptive decay rate. To improve clarity, we assume a noise-free dataset, though data-driven control techniques can be used to robustify the approach. Finally, the effectiveness of the proposed method is demonstrated on an unknown time-delay system.

Paper number 40:
Title: Distributed Zonotopic Fusion Estimation for Multi-sensor Systems
Authors: Yuchen Zhang, Bo Chen, Zheming Wang, Wen-An Zhang, Li Yu, Lei Guo
Abstract: Fusion estimation is often used in multi-sensor systems to provide accurate state information which plays an important role in the design of efficient control and decision-making. This paper is concerned with the distributed zonotopic fusion estimation problem for multi-sensor systems. The objective is to propose a zonotopic fusion estimation approach using different zonotope fusion criteria. We begin by proposing a novel zonotope fusion criterion to compute a distributed zonotopic fusion estimate (DZFE). The DZFE is formulated as a zonotope enclosure for the intersection of local zonotopic estimates from individual sensors. Then, the optimal parameter matrices for tuning the DZFE are determined by the analytical solution of an optimization problem. To reduce the conservatism of the DZFE with optimal parameters, we enhance our approach with an improved zonotope fusion criterion, which further improves the estimation performance of this DZFE by constructing tight strips for the intersection. In addition, we tackle the problem of handling sequentially arrived local estimates in realistic communication environments with a sequential zonotope fusion criterion. This sequential zonotope fusion offers reduced computational complexity compared to batch zonotope fusion. Notice that the proposed zonotope fusion criteria are designed to meet the state inclusion property and demonstrate performance superiority over local zonotopic estimates. We also derive stability conditions for these DZFEs to ensure their generator matrices are ultimately bounded. Finally, two illustrative examples are employed to show the effectiveness and advantages of the proposed methods.

Paper number 41:
Title: Label-free Prediction of Vascular Connectivity in Perfused Microvascular Networks in vitro
Authors: Liang Xu, Pengwu Song, Shilu Zhu, Yang Zhang, Ru Zhang, Zhiyuan Zheng, Qingdong Zhang, Jie Gao, Chen Han, Mingzhai Sun, Peng Yao, Min Ye, Ronald X. Xu
Abstract: Continuous monitoring and in-situ assessment of microvascular connectivity have significant implications for culturing vascularized organoids and optimizing the therapeutic strategies. However, commonly used methods for vascular connectivity assessment heavily rely on fluorescent labels that may either raise biocompatibility concerns or interrupt the normal cell growth process. To address this issue, a Vessel Connectivity Network (VC-Net) was developed for label-free assessment of vascular connectivity. To validate the VC-Net, microvascular networks (MVNs) were cultured in vitro and their microscopic images were acquired at different culturing conditions as a training dataset. The VC-Net employs a Vessel Queue Contrastive Learning (VQCL) method and a class imbalance algorithm to address the issues of limited sample size, indistinctive class features and imbalanced class distribution in the dataset. The VC-Net successfully evaluated the vascular connectivity with no significant deviation from that by fluorescence imaging. In addition, the proposed VC-Net successfully differentiated the connectivity characteristics between normal and tumor-related MVNs. In comparison with those cultured in the regular microenvironment, the averaged connectivity of MVNs cultured in the tumor-related microenvironment decreased by 30.8%, whereas the non-connected area increased by 37.3%. This study provides a new avenue for label-free and continuous assessment of organoid or tumor vascularization in vitro.

Paper number 42:
Title: Waveguide Division Multiple Access for Pinching-Antenna Systems (PASS)
Authors: Jingjing Zhao, Xidong Mu, Kaiquan Cai, Yanbo Zhu, Yuanwei Liu
Abstract: A novel concept of waveguide division multiple access (WDMA) is proposed for multi-user pinching-antenna systems (PASS). The key principle of WDMA is to allocate each user with a dedicated waveguide, which is regarded as a new type of radio resources, so as to facilitate multi-user communications. By adjusting the activation positions of pinching antennas (PAs) over each waveguide, the pinching beamforming can be exploited for intended user signal enhancement and inter-user interference mitigation. Considering both ideal continuous and practical discrete PA position activation schemes, a joint power allocation and pinching beamforming optimization problem is formulated for the maximization of the sum rate. An alternating optimization-based algorithm is developed to address the formulated nonconvex problem. For solving the power allocation subproblem, the successive convex approximation method is invoked. For the pinching beamforming design subproblem, a penalty-based gradient ascent algorithm is first developed for the continuous PA activation case. Then, for the discrete PA activation case, a matching theory-based algorithm is proposed to achieve the near-optimal performance but with a low complexity. Numerical results unveil that: 1) For both continuous and discrete activation cases, PASS can achieve a significant performance gain over conventional fixed-position antenna systems; 2) the proposed WDMA can effectively underpin multi-user communications with the near orthogonality in free space achieved by the pinching beamforming; and 3) the performance gap between the discrete and continuous activation cases can be significantly alleviated with practically feasible numbers of PA candidate positions.

Paper number 43:
Title: Terahertz Aerospace Communications: Enabling Technologies and Future Directions
Authors: Weijun Gao, Chong Han, Zhi Chen, Yong Chen, Yuanzhi He, Wenjun Zhang
Abstract: To achieve ubiquitous connectivity in next-generation networks through aerospace communications while maintaining high data rates, Terahertz (THz) band communications (0.1-10 THz) with large continuous bandwidths are considered a promising candidate technology. However, key enabling techniques and practical implementations of THz communications for aerospace applications remain limited. In this paper, the wireless channel characteristics, enabling communication techniques, and networking strategies for THz aerospace communications are investigated, aiming to assess their feasibility and encourage future research efforts toward system realization. Specifically, the wireless channel characteristics across various altitudes and scenarios are first analyzed, focusing on modeling the interaction between the THz wave and the external environment, from ground to outer space. Next, key enabling communication technologies, including multiple-input multiple-output (MIMO) technique, beam alignment and tracking, integrated communication and radar sensing (ICARS), and resource allocation for networking are discussed. Finally, the existing challenges and possible future directions are summarized and discussed.

Paper number 44:
Title: Joint Communication and Radar Sensing for Terahertz Space-Air-Ground Integrated Networks (SAGIN)
Authors: Chong Han, Weijun Gao, Zhepu Yin, Chuang Yang, Mugen Peng, Wenjun Zhang
Abstract: The transition from isolated systems to integrated solutions has driven the development of space-air-ground integrated networks (SAGIN) as well as the integration of communication and radar sensing functionalities. By leveraging the unique properties of the Terahertz (THz) band, THz joint communication and radar sensing (JCRS) supports high-speed communication and precise sensing, addressing the growing demands of SAGIN for connectivity and environmental awareness. However, most existing THz studies focus on terrestrial and static scenarios, with limited consideration for the dynamic and non-terrestrial environments of SAGIN. In this paper, the THz JCRS techniques for SAGIN are comprehensively investigated. Specifically, propagation characteristics and channel models of THz waves in non-terrestrial environments are analyzed. A link capacity comparison with millimeter-wave, THz, and free-space optical frequency bands is conducted to highlight the advantages of THz frequencies. Moreover, novel JCRS waveform design strategies are presented to achieve mutual merit of communication and radar sensing, while networking strategies are developed to overcome challenges in SAGIN such as high mobility. Furthermore, advancements in THz device technologies, including antennas and amplifiers, are reviewed to assess their roles in enabling practical JCRS implementations.

Paper number 45:
Title: Hybrid Beamforming with Orthogonal delay-Doppler Division Multiplexing Modulation for Terahertz Sensing and Communication
Authors: Meilin Li, Chong Han, Shi Jin
Abstract: The Terahertz band holds a promise to enable both super-accurate sensing and ultra-fast communication. However, challenges arise that severe Doppler effects call for a waveform with high Doppler robustness while severe propagation path loss urges for an ultra-massive multiple-input multiple-output (UM-MIMO) structure. To tackle these challenges, hybrid beamforming with orthogonal delay-Doppler multiplexing modulation (ODDM) is investigated in this paper. First, the integration of delay-Doppler waveform and MIMO is explored by deriving a hybrid beamforming-based UM-MIMO ODDM input-output relation. Then, a multi-dimension sensing algorithm on target azimuth angle, elevation angle, range and velocity is proposed, which features low complexity and high accuracy. Finally, a sensing-centric hybrid beamforming is proposed to design the sensing combiner by minimizing the CramÃ©r-Rao lower bounds (CRLB) of angles. After that, the precoder that affects both communication and sensing is then designed to maximize the spectral efficiency. Numerical results show that the sensing accuracy of the proposed sensing algorithm is sufficiently close to CRLB. Moreover, the proposed hybrid beamforming design allows to achieve maximal spectral efficiency, millimeter-level range estimation accuracy, millidegree-level angle estimation accuracy and millimeter-per-second-level velocity estimation accuracy. Take-away lessons are two-fold. Combiner design is critical especially for sensing, which is commonly neglected in hybrid beamforming design for communication. Furthermore, the optimization problems for communication and sensing can be decoupled and solved independently, significantly reducing the computational complexity of the THz monostatic ISAC system.

Paper number 46:
Title: Feedback-Free Resource Scheduling: Towards Flexible Multi-BS Cooperation in FD-RAN
Authors: Jingbo Liu, Jiacheng Chen, Zeyu Sun, Bo Qian, Haibo Zhou
Abstract: Flexible cooperation among base stations (BSs) is critical to improve resource utilization efficiency and meet personalized user demands. However, its practical implementation is hindered by the current radio access network (RAN), which relies on the coupling of uplink and downlink transmissions and channel state information feedback with inherent issues such as overheads and delays. To overcome these limitations, we consider the fully-decoupled RAN (FD-RAN), in which uplink and downlink networks are independent, and feedback-free MIMO transmission is adopted at the physical layer. To further deliver flexible cooperation in FD-RAN, we investigate the practical scheduling process and study feedback-free downlink multi-BS resource scheduling. The problem is considered based on network load conditions. In heavy-load states where it is impossible for all user demands to be met, an optimal greedy algorithm is proposed, maximizing the weighted sum of user demand satisfaction rates. In light-load states where at least one solution exists to satisfy all user demands, an optimal two-stage resource allocation algorithm is designed to further minimize network energy consumption by leveraging the flexibility of cooperation. Extensive simulations validate the superiority of proposed algorithms in performance and running time, and highlight the potential for realizing flexible cooperation in practice.

Paper number 47:
Title: TagGAN: A Generative Model for Data Tagging
Authors: Muhammad Nawaz, Basma Nasir, Tehseen Zia, Zawar Hussain, Catarina Moreira
Abstract: Precise identification and localization of disease-specific features at the pixel-level are particularly important for early diagnosis, disease progression monitoring, and effective treatment in medical image analysis. However, conventional diagnostic AI systems lack decision transparency and cannot operate well in environments where there is a lack of pixel-level annotations. In this study, we propose a novel Generative Adversarial Networks (GANs)-based framework, TagGAN, which is tailored for weakly-supervised fine-grained disease map generation from purely image-level labeled data. TagGAN generates a pixel-level disease map during domain translation from an abnormal image to a normal representation. Later, this map is subtracted from the input abnormal image to convert it into its normal counterpart while preserving all the critical anatomical details. Our method is first to generate fine-grained disease maps to visualize disease lesions in a weekly supervised setting without requiring pixel-level annotations. This development enhances the interpretability of diagnostic AI by providing precise visualizations of disease-specific regions. It also introduces automated binary mask generation to assist radiologists. Empirical evaluations carried out on the benchmark datasets, CheXpert, TBX11K, and COVID-19, demonstrate the capability of TagGAN to outperform current top models in accurately identifying disease-specific pixels. This outcome highlights the capability of the proposed model to tag medical images, significantly reducing the workload for radiologists by eliminating the need for binary masks during training.

Paper number 48:
Title: Beamforming with hybrid reconfigurable parasitic antenna arrays
Authors: Nitish Vikas Deshpande, Miguel Rodrigo Castellanos, Saeed R. Khosravirad, Jinfeng Du, Harish Viswanathan, Robert W. Heath Jr
Abstract: A parasitic reconfigurable antenna array is a low-power approach for beamforming using passive tunable elements. Prior work on reconfigurable antennas in communication theory is based on ideal radiation pattern abstractions. It does not address the problem of physical realizability. Beamforming with parasitic elements is inherently difficult because mutual coupling creates non-linearity in the beamforming gain objective. We develop a multi-port circuit-theoretic model of the hybrid array with parasitic elements and antennas with active RF chain validated through electromagnetic simulations with a dipole array. We then derive the beamforming weight of the parasitic element using the theoretical beam pattern expression for the case of a single active antenna and multiple parasitic elements. We show that the parasitic beamforming is challenging because the weights are subject to coupled magnitude and phase constraints. We simplify the beamforming optimization problem using a shift-of-origin transformation to the typical unit-modulus beamforming weight. With this transformation, we derive a closed-form solution for the reconfigurable parasitic reactance. We generalize this solution to the multi-active multi-parasitic hybrid array operating in a multi-path channel. Our proposed hybrid architecture with parasitic elements outperforms conventional architectures in terms of energy efficiency.

Paper number 49:
Title: 5G Direct Position Estimation for Precise Localization in Dense Urban Area
Authors: Sijia Li, Sergio Vicenzo, Bing Xu
Abstract: In recent years, the fifth-generation (5G) new radio (NR) signals have emerged as a promising supplementary resource for urban navigation. However, a major challenge in utilizing 5G signals lies in their vulnerability to non-line-of-sight (NLoS) propagation effects, which are especially prevalent in urban street canyons. This paper applies the direct position estimation (DPE) method to 5G cellular signals to mitigate the NLoS bias as well as the multipath effects, thereby enabling precise localization in urbanized environments. The feasibility of applying the DPE method to NR positioning is analyzed, followed by a discussion of the tapped delay line (TDL) channel propagation model provided by the 3rd Generation Partnership Project (3GPP). The positioning performance is then evaluated through large-scale system-level simulations. The simulation results demonstrate that 5G DPE achieves satisfactory positioning accuracy in a 10 dB noisy channel, with an overall root mean square error (RMSE) constrained within 6 m. In addition, 5G DPE outperforms the observed time difference of arrival (OTDoA) method by 95.24% in terms of positioning accuracy in an NLoS-dominated propagation environment.

Paper number 50:
Title: A graph neural network-based multispectral-view learning model for diabetic macular ischemia detection from color fundus photographs
Authors: Qinghua He, Hongyang Jiang, Danqi Fang, Dawei Yang, Truong X. Nguyen, Anran Ran, Clement C. Tham, Simon K. H. Szeto, Sobha Sivaprasad, Carol Y. Cheung
Abstract: Diabetic macular ischemia (DMI), marked by the loss of retinal capillaries in the macular area, contributes to vision impairment in patients with diabetes. Although color fundus photographs (CFPs), combined with artificial intelligence (AI), have been extensively applied in detecting various eye diseases, including diabetic retinopathy (DR), their applications in detecting DMI remain unexplored, partly due to skepticism among ophthalmologists regarding its feasibility. In this study, we propose a graph neural network-based multispectral view learning (GNN-MSVL) model designed to detect DMI from CFPs. The model leverages higher spectral resolution to capture subtle changes in fundus reflectance caused by ischemic tissue, enhancing sensitivity to DMI-related features. The proposed approach begins with computational multispectral imaging (CMI) to reconstruct 24-wavelength multispectral fundus images from CFPs. ResNeXt101 is employed as the backbone for multi-view learning to extract features from the reconstructed images. Additionally, a GNN with a customized jumper connection strategy is designed to enhance cross-spectral relationships, facilitating comprehensive and efficient multispectral view learning. The study included a total of 1,078 macula-centered CFPs from 1,078 eyes of 592 patients with diabetes, of which 530 CFPs from 530 eyes of 300 patients were diagnosed with DMI. The model achieved an accuracy of 84.7 percent and an area under the receiver operating characteristic curve (AUROC) of 0.900 (95 percent CI: 0.852-0.937) on eye-level, outperforming both the baseline model trained from CFPs and human experts (p-values less than 0.01). These findings suggest that AI-based CFP analysis holds promise for detecting DMI, contributing to its early and low-cost screening.

Paper number 51:
Title: Sample-efficient diffusion-based control of complex nonlinear systems
Authors: Hongyi Chen, Jingtao Ding, Jianhai Shu, Xinchun Yu, Xiaojun Liang, Yong Li, Xiao-Ping Zhang
Abstract: Complex nonlinear system control faces challenges in achieving sample-efficient, reliable performance. While diffusion-based methods have demonstrated advantages over classical and reinforcement learning approaches in long-term control performance, they are limited by sample efficiency. This paper presents SEDC (Sample-Efficient Diffusion-based Control), a novel diffusion-based control framework addressing three core challenges: high-dimensional state-action spaces, nonlinear system dynamics, and the gap between non-optimal training data and near-optimal control solutions. Through three innovations - Decoupled State Diffusion, Dual-Mode Decomposition, and Guided Self-finetuning - SEDC achieves 39.5\%-49.4\% better control accuracy than baselines while using only 10\% of the training samples, as validated across three complex nonlinear dynamic systems. Our approach represents a significant advancement in sample-efficient control of complex nonlinear systems. The implementation of the code can be found at this https URL.

Paper number 52:
Title: Optimum Noncoherent Detection of Constant-Envelope Signals using Received Signal Magnitudes -- Energy Detection and Amplitude Detection
Authors: Mu Jia, Junting Chen, Ying-Chang Liang, Pooi-Yuen Kam
Abstract: Constant-envelope signals are widely employed in wireless communication systems due to their hardware-friendly design, energy efficiency, and enhanced reliability. However, detecting these signals reliably using simple, power-efficient receivers remains a critical challenge. While coherent detection methods generally offer superior performance, they require complex frequency synchronization, which increases receiver complexity and power consumption. In contrast, noncoherent detection is inherently simpler since it avoids frequency synchronization. However, traditional noncoherent detection approaches still rely on In-phase and Quadrature-phase (IQ) demodulators to extract the noisy received signal magnitudes, and assume the energy detector as the test statistic according to the IQ structure, without rigorous theoretical justification. Motivated by the practical need for robust and low-complexity detection, this paper proposes a comprehensive framework for optimal signal detection using a simple bandpass-filter envelope-detector (BFED) in conjunction with a Bayesian approach and the generalized likelihood ratio test (GLRT) under unknown amplitude conditions. By leveraging approximations of the modified Bessel functions, we derive two distinct regimes of the optimal detector. In the low SNR regime, we rigorously prove that the energy detector emerges as the Bayesian-optimal solution, thereby establishing its theoretical validity for the first time. In the high SNR regime, we derive a novel amplitude-based detector that directly compares the estimated amplitude against the noise standard deviation, leading to a simple yet optimal detection strategy. Numerical simulations validate the theoretical findings, confirming that both the energy and amplitude detectors achieve the minimum error probability in their respective SNR domains.

Paper number 53:
Title: Upper Mid-Band Spectrum for 6G: Vision, Opportunity and Challenges
Authors: Ahmad Bazzi, Roberto Bomfin, Marco Mezzavilla, Sundeep Rangan, Theodore Rappaport, Marwa Chafii
Abstract: Driven by the pursuit of gigabit-per-second data speeds for future 6G mobile networks, in addition to the support of sensing and artificial intelligence applications, the industry is expanding beyond crowded sub-6 GHz bands with innovative new spectrum allocations. In this paper, we chart a compelling vision for 6G within the frequency range 3 (FR3) spectrum, i.e. $7.125$-$24.25$ $\GHz$, by delving into its key enablers and addressing the multifaceted challenges that lie ahead for these new frequency bands. Here we highlight the physical properties of this \textcolor{black}{never-before} used spectrum by reviewing recent channel measurements for outdoor and indoor environments, including path loss, delay and angular spreads, and material penetration loss, all which offer insights that underpin future 5G/6G wireless communication designs. Building on the fundamental knowledge of the channel properties, we explore FR3 spectrum agility strategies that balance coverage and capacity (e.g. data rate) tradeoffs, while also examining coexistence with incumbent systems, such as satellites, radio astronomy, and earth exploration. Moreover, we discuss the potential of massive multiple-input multiple-output, compact and digital architectures, and evaluate the potential of multiband sensing for FR3 integrated sensing and communications. Finally, we outline 6G standardization features that are likely to emerge from 3GPP radio frame innovations and open radio access network developments.

Paper number 54:
Title: 3D Anatomical Structure-guided Deep Learning for Accurate Diffusion Microstructure Imaging
Authors: Xinrui Ma, Jian Cheng, Wenxin Fan, Ruoyou Wu, Yongquan Ye, Shanshan Wang
Abstract: Diffusion magnetic resonance imaging (dMRI) is a crucial non-invasive technique for exploring the microstructure of the living human brain. Traditional hand-crafted and model-based tissue microstructure reconstruction methods often require extensive diffusion gradient sampling, which can be time-consuming and limits the clinical applicability of tissue microstructure information. Recent advances in deep learning have shown promise in microstructure estimation; however, accurately estimating tissue microstructure from clinically feasible dMRI scans remains challenging without appropriate constraints. This paper introduces a novel framework that achieves high-fidelity and rapid diffusion microstructure imaging by simultaneously leveraging anatomical information from macro-level priors and mutual information across parameters. This approach enhances time efficiency while maintaining accuracy in microstructure estimation. Experimental results demonstrate that our method outperforms four state-of-the-art techniques, achieving a peak signal-to-noise ratio (PSNR) of 30.51$\pm$0.58 and a structural similarity index measure (SSIM) of 0.97$\pm$0.004 in estimating parametric maps of multiple diffusion models. Notably, our method achieves a 15$\times$ acceleration compared to the dense sampling approach, which typically utilizes 270 diffusion gradients.

Paper number 55:
Title: Designing Waveforms with Adjustable PAPR for Integrated Sensing and Communication
Authors: Ahmad Bazzi, Marwa Chafii
Abstract: This paper presents a new optimization framework dedicated for integrated sensing and communication (ISAC) waveform design. In particular, the problem aims at maximizing the total achievable sum-rate, through multi-user interference minimization, while preserving a certain level of similarity to a given desired radar waveform. Aiming towards feasible and practical PHY architectures, we also offer the flexibility of tuning the peak-to-average power ratio to a desired level. Towards this design, a non-convex optimization problem is formulated, and an alternating direction method of multipliers based solution is derived to converge towards the superiority of the final ISAC waveform. Finally, simulation results validate the proposed ISAC waveform design, as compared to state-of-the-art solutions.

Paper number 56:
Title: Generating Correlation Matrices with Graph Structures Using Convex Optimization
Authors: Ali Fakhar (STATIFY, LJK), KÃ©vin Polisano (SVH, LJK), IrÃ¨ne Gannaz (G-SCOP\_GROG, G-SCOP), Sophie Achard (STATIFY, LJK)
Abstract: This work deals with the generation of theoretical correlation matrices with specific sparsity patterns, associated to graph structures. We present a novel approach based on convex optimization, offering greater flexibility compared to existing techniques, notably by controlling the mean of the entry distribution in the generated correlation matrices. This allows for the generation of correlation matrices that better represent realistic data and can be used to benchmark statistical methods for graph inference.

Paper number 57:
Title: Multi-Cell Coordinated Beamforming for Integrate Communication and Multi-TMT Localization
Authors: Meidong Xia, Wei Xu, Jindan Xu, Zhenyao He, Zhaohui Yang, Derrick Wing Kwan Ng
Abstract: This paper investigates integrated localization and communication in a multi-cell system and proposes a coordinated beamforming algorithm to enhance target localization accuracy while preserving communication performance. Within this integrated sensing and communication (ISAC) system, the Cramer-Rao lower bound (CRLB) is adopted to quantify the accuracy of target localization, with its closed-form expression derived for the first time. It is shown that the nuisance parameters can be disregarded without impacting the CRLB of time of arrival (TOA)-based target localization. Capitalizing on the derived CRLB, we formulate a nonconvex coordinated beamforming problem to minimize the CRLB while satisfying signal-to-interference-plus-noise ratio (SINR) constraints in communication. To facilitate the development of solution, we reformulate the original problem into a more tractable form and solve it through semi-definite programming (SDP). Notably, we show that the proposed algorithm can always obtain rank-one global optimal solutions under mild conditions. Finally, numerical results demonstrate the superiority of the proposed algorithm over benchmark algorithms and reveal the performance trade-off between localization accuracy and communication SINR.

Paper number 58:
Title: Generative AI-enabled Wireless Communications for Robust Low-Altitude Economy Networking
Authors: Changyuan Zhao, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Geng Sun, Hongyang Du, Dong In Kim, Abbas Jamalipour
Abstract: Low-Altitude Economy Networks (LAENets) have emerged as significant enablers of social activities, offering low-altitude services such as the transportation of packages, groceries, and medical supplies. Unlike traditional terrestrial networks, LAENets are characterized by control mechanisms and ever-changing operational factors, which make them more complex and susceptible to vulnerabilities. As applications of LAENet continue to expand, robustness of these systems becomes crucial. In this paper, we investigate a novel application of Generative Artificial Intelligence (GenAI) to improve the robustness of LAENets. We conduct a systematic analysis of robustness requirements for LAENets, complemented by a comprehensive review of robust Quality of Service (QoS) metrics from the wireless physical layer perspective. We then investigate existing GenAI-enabled approaches for robustness enhancement. This leads to our proposal of a novel diffusion-based optimization framework with a Mixture of Expert (MoE)-transformer actor network. In the robust beamforming case study, the proposed framework demonstrates its effectiveness by optimizing beamforming under uncertainties, achieving a more than 44% increase in the worst-case achievable secrecy rate. These findings highlight the significant potential of GenAI in strengthening LAENet robustness.

Paper number 59:
Title: Edge Training and Inference with Analog ReRAM Technology for Hand Gesture Recognition
Authors: Victoria Clerico, Anirvan Dutta, Donato Francesco Falcone, Wooseok Choi, Matteo Galetta, Tommaso Stecconi, AndrÃ¡s HorvÃ¡th, Shokoofeh Varzandeh, Bert Jan Offrein, Mohsen Kaboli, Valeria Bragaglia
Abstract: Tactile hand gesture recognition is a crucial task for user control in the automotive sector, where Human-Machine Interactions (HMI) demand low latency and high energy efficiency. This study addresses the challenges of power-constrained edge training and inference by utilizing analog Resistive Random Access Memory (ReRAM) technology in conjunction with a real tactile hand gesture dataset. By optimizing the input space through a feature engineering strategy, we avoid relying on large-scale crossbar arrays, making the system more suitable for edge deployment. Through realistic hardware-aware simulations that account for device non-idealities derived from experimental data, we demonstrate the functionalities of our analog ReRAM-based analog in-memory computing for on-chip training, utilizing the state-of-the-art Tiki-Taka algorithm. Furthermore, we validate the classification accuracy of approximately 91.4% for post-deployment inference of hand gestures. The results highlight the potential of analog ReRAM technology and crossbar architecture with fully parallelized matrix computations for real-time HMI systems at the Edge.

Paper number 60:
Title: VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention
Authors: Adnan Iltaf, Rayan Merghani Ahmed, Bin Li, Shoujun Zhou
Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, particularly for complex anatomical structures like vessels. In this work, we propose VesselSAM, a modified version of the Segmentation Anything Model (SAM), specifically designed for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module that combines Atrous Attention with Low-Rank Adaptation (LoRA), to improve segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine local details and broader global context. At the same time, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and ensuring computational efficiency. We evaluate VesselSAM on two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance with DSC scores of 93.50\%, 93.25\%, 93.02\%, and 93.26\% across multiple medical centers. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at this https URL.

Paper number 61:
Title: Task-Agnostic Semantic Communication with Multimodal Foundation Models
Authors: Jiangjing Hu, Haotian Wu, Wenjing Zhang, Fengyu Wang, Wenjun Xu, Hui Gao, Deniz GÃ¼ndÃ¼z
Abstract: Most existing semantic communication (SemCom) systems use deep joint source-channel coding (DeepJSCC) to encode task-specific semantics in a goal-oriented manner. However, their reliance on predefined tasks and datasets significantly limits their flexibility and generalizability in practical deployments. Multi-modal foundation models provide a promising solution by generating universal semantic tokens. Inspired by this, we introduce SemCLIP, a task-agnostic SemCom framework leveraging the contrastive language-image pre-training (CLIP) model. By transmitting CLIP-generated image tokens instead of raw images, SemCLIP enables efficient semantic communications under low bandwidth and challenging channel conditions, facilitating diverse downstream tasks and zero-shot applications. Specifically, we propose a DeepJSCC scheme for efficient CLIP tokens encoding. To mitigate potential degradation caused by compression and channel noise, a multi-modal transmission-aware prompt learning mechanism is designed at the receiver, which adapts prompts based on transmission quality, enhancing system robustness and channel adaptability. Simulation results demonstrate that SemCLIP outperforms the baselines, achieving a $41\%$ improvement in zero-shot accuracy at a low signal-to-noise ratio. Meanwhile, SemCLIP reduces bandwidth usage by more than $50$-fold compared to different image transmission methods, demonstrating the potential of foundation models towards a generalized, task-agnostic SemCom solution.

Paper number 62:
Title: A Normal Variance Mixture Model for Robust Kalman Filtering
Authors: Michael J. Walsh
Abstract: The Kalman filter is ubiquitous for state space models because of its desirable statistical properties, ease of implementation, and generally good performance. However, it can perform poorly in the presence of outliers, or measurements with noise variances much greater than those assumed by the filter. An algorithm that is similar to the Kalman filter but robust to outliers is derived in this report. This algorithm -- called the normal variance mixture filter (NVMF) -- replaces the Gaussian distribution for the noise in the Kalman filter measurement model with a normal variance mixture distribution that admits heavier tails. Choice of the mixing density determines the complexity and performance of the NVMF. When the mixing density is the Dirac delta function, the NVMF is equivalent to the Kalman filter. Choice of an inverse gamma mixing density leads to closed-form recursions for the state estimate and its error covariance matrix that are robust to outliers. The NVMF is compared to the benchmark probabilistic data association filter (PDAF), as well as two other robust filters from the recent literature, for a simulated example. While all four robust filters outperform the Kalman filter when outliers are present, the NVMF provides the most consistent performance across all simulations.

Paper number 63:
Title: Liver Cirrhosis Stage Estimation from MRI with Deep Learning
Authors: Jun Zeng, Debesh Jha, Ertugrul Aktas, Elif Keles, Alpay Medetalibeyoglu, Matthew Antalek, Amir A. Borhani, Daniela P. Ladner, Gorkem Durak, Ulas Bagci
Abstract: We present an end-to-end deep learning framework for automated liver cirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe scarring (fibrosis) of the liver and a common endpoint of various chronic liver diseases. Early diagnosis is vital to prevent complications such as decompensation and cancer, which significantly decreases life expectancy. However, diagnosing cirrhosis in its early stages is challenging, and patients often present with life-threatening complications. Our approach integrates multi-scale feature learning with sequence-specific attention mechanisms to capture subtle tissue variations across cirrhosis progression stages. Using CirrMRI600+, a large-scale publicly available dataset of 628 high-resolution MRI scans from 339 patients, we demonstrate state-of-the-art performance in three-stage cirrhosis classification. Our best model achieves 72.8% accuracy on T1W and 63.8% on T2W sequences, significantly outperforming traditional radiomics-based approaches. Through extensive ablation studies, we show that our architecture effectively learns stage-specific imaging biomarkers. We establish new benchmarks for automated cirrhosis staging and provide insights for developing clinically applicable deep learning systems. The source code will be available at this https URL.

Paper number 64:
Title: A Reverse Mamba Attention Network for Pathological Liver Segmentation
Authors: Jun Zeng, Ulas Bagci, Debesh Jha
Abstract: We present RMA-Mamba, a novel architecture that advances the capabilities of vision state space models through a specialized reverse mamba attention module (RMA). The key innovation lies in RMA-Mamba's ability to capture long-range dependencies while maintaining precise local feature representation through its hierarchical processing pipeline. By integrating Vision Mamba (VMamba)'s efficient sequence modeling with RMA's targeted feature refinement, our architecture achieves superior feature learning across multiple scales. This dual-mechanism approach enables robust handling of complex morphological patterns while maintaining computational efficiency. We demonstrate RMA-Mamba's effectiveness in the challenging domain of pathological liver segmentation (from both CT and MRI), where traditional segmentation approaches often fail due to tissue variations. When evaluated on a newly introduced cirrhotic liver dataset (CirrMRI600+) of T2-weighted MRI scans, RMA-Mamba achieves the state-of-the-art performance with a Dice coefficient of 92.08%, mean IoU of 87.36%, and recall of 92.96%. The architecture's generalizability is further validated on the cancerous liver segmentation from CT scans (LiTS: Liver Tumor Segmentation dataset), yielding a Dice score of 92.9% and mIoU of 88.99%. The source code of the proposed RMA-Mamba is available at this https URL.

Paper number 65:
Title: Integrated Localization and Communication with Sparse MIMO: Will Virtual Array Technology also Benefit Wireless Communication?
Authors: Hongqi Min, Xinrui Li, Ruoguang Li, Yong Zeng
Abstract: For the 6G wireless networks, achieving high-performance integrated localization and communication (ILAC) is critical to unlock the full potential of wireless networks. To simultaneously enhance localization and communication performance cost-effectively, this paper proposes sparse multiple-input multiple-output (MIMO) based ILAC with nested and co-prime sparse arrays deployed at the base station. Sparse MIMO relaxes the traditional half-wavelength antenna spacing constraint to enlarge the antenna aperture, thus enhancing localization degrees of freedom and providing finer spatial resolution. However, it also leads to undesired grating lobes, which may cause severe inter-user interference for communication and angular ambiguity for localization. While the latter issue can be effectively addressed by the virtual array technology, by forming sum or difference co-arrays via signal (conjugate) correlation among array elements, it is unclear whether the similar virtual array technology also benefits wireless communications for ILAC systems. In this paper, we first reveal that the answer to the above question is negative, by showing that forming virtual arrays for wireless communication will cause destruction of phase information, degradation of signal-to-noise ratio and aggravation of multi-user interference. Therefore, we propose the hybrid processing for sparse MIMO based ILAC, i.e., physical array based communication while virtual array based localization. To this end, we characterize the beam pattern of sparse arrays by three metrics, demonstrating that despite of the introduction of grating lobes, sparse arrays can also bring benefits to communications thanks to its narrower main lobe beam width than the conventional compact arrays. Extensive simulation results are presented to demonstrate the performance gains of sparse MIMO based ILAC over that based on the conventional compact MIMO.

Paper number 66:
Title: A Complex-Valued Feedback Linearization-Based Controller for a Voltage Source Inverter Tied to the Grid via a Second-Order Filter
Authors: Gerardo Tapia-Otaegui, Jorge A. Solsona, Sebastian Gomez Jorge, Ana Susperregui, Claudio A. Busada, M. Itsaso MartÃ­nez
Abstract: In this document, a nonlinear control law for a grid-tied converter is introduced. The converter topology consists of a voltage source inverter (VSI) linked to the grid through an inductive-capacitive second-order filter, its input being connected to a capacitive DC-link supplied by a renewable energy-based input power source. In order to achieve good performance in presence of large state excursions caused mainly by substantial set-point modifications and/or considerable disturbances, a nonlinear control law based on a complex-valued feedback linearization strategy is designed. Specifically, a flat output is adopted, which is given by the summation of the energy stored in the DC-link capacitor and in the output filter's inductor and capacitor, as well as by the reactive energy at the output. After linearizing the system through a pertinent coordinate transformation and a nonlinear feedback, a linear trajectory tracking control law is implemented. The performance of the system controlled by applying the proposed strategy is tested via simulation for a very weak grid of unity X/R ratio, yielding satisfactory results.

Paper number 67:
Title: A Deep-Unfolding Approach to RIS Phase Shift Optimization Via Transformer-Based Channel Prediction
Authors: Ishan Koralege, Arthur S. de Sena, Nurul H. Mahmood, Farjam Karim, Dimuthu Lesthuruge, Samitha Gunarathne
Abstract: Reconfigurable intelligent surfaces (RISs) have emerged as a promising solution that can provide dynamic control over the propagation of electromagnetic waves. The RIS technology is envisioned as a key enabler of sixth-generation networks by offering the ability to adaptively manipulate signal propagation through the smart configuration of its phase shift coefficients, thereby optimizing signal strength, coverage, and capacity. However, the realization of this technology's full potential hinges on the accurate acquisition of channel state information (CSI). In this paper, we propose an efficient CSI prediction framework for a RIS-assisted communication system based on the machine learning (ML) transformer architecture. Architectural modifications are introduced to the vanilla transformer for multivariate time series forecasting to achieve high prediction accuracy. The predicted channel coefficients are then used to optimize the RIS phase shifts. Simulation results present a comprehensive analysis of key performance metrics, including data rate and outage probability. Our results confirm the effectiveness of the proposed ML approach and demonstrate its superiority over other baseline ML-based CSI prediction schemes such as conventional deep neural networks and long short-term memory architectures, albeit at the cost of slightly increased complexity.

Paper number 68:
Title: RSSI-Based Localization Utilizing Antenna Radiation Pattern And Biased CRLB Analysis
Authors: Zhisheng Rong, Wenzhi Liu, Xiayue Liu, Zhixiang Xu, Yufei Jiang
Abstract: This paper presents a novel indoor positioning approach that leverages antenna radiation pattern characteristics through Received Signal Strength Indication (RSSI) measurements in a single-antenna system. By rotating the antenna or reconfiguring its radiation pattern, we derive a maximum likelihood estimation (MLE) algorithm that achieves near-optimal positioning accuracy approaching the Cramer-Rao lower bound (CRLB). Through theoretical analysis, we establish three fundamental theorems characterizing the estimation accuracy bounds and demonstrating how performance improves with increased signal-to-noise ratio, antenna rotation count, and radiation pattern variations. Additionally, we propose a two-position measurement strategy that eliminates dependence on receiving antenna patterns. Simulation results validate that our approach provides an effective solution for indoor robot tracking applications where both accuracy and system simplicity are essential considerations.

Paper number 69:
Title: Sparse Bayesian Generative Modeling for Joint Parameter and Channel Estimation
Authors: Benedikt BÃ¶ck, Franz WeiÃer, Michael Baur, Wolfgang Utschick
Abstract: Leveraging the inherent connection between sensing systems and wireless communications can improve their overall performance and is the core objective of joint communications and sensing. For effective communications, one has to frequently estimate the channel. Sensing, on the other hand, infers properties of the environment mostly based on estimated physical channel parameters, such as directions of arrival or delays. This work presents a low-complexity generative modeling approach that simultaneously estimates the wireless channel and its physical parameters without additional computational overhead. To this end, we leverage a recently proposed physics-informed generative model for wireless channels based on sparse Bayesian generative modeling and exploit the feature of conditionally Gaussian generative models to approximate the conditional mean estimator.

Paper number 70:
Title: Off-Policy Temporal Difference Learning for Perturbed Markov Decision Processes: Theoretical Insights and Extensive Simulations
Authors: Ali Forootani, Raffaele Iervolino, Massimo Tipaldi, Mohammad Khosravi
Abstract: Dynamic Programming suffers from the curse of dimensionality due to large state and action spaces, a challenge further compounded by uncertainties in the environment. To mitigate these issue, we explore an off-policy based Temporal Difference Approximate Dynamic Programming approach that preserves contraction mapping when projecting the problem into a subspace of selected features, accounting for the probability distribution of the perturbed transition probability matrix. We further demonstrate how this Approximate Dynamic Programming approach can be implemented as a particular variant of the Temporal Difference learning algorithm, adapted for handling perturbations. To validate our theoretical findings, we provide a numerical example using a Markov Decision Process corresponding to a resource allocation problem.

Paper number 71:
Title: Inversion-free feed-forward and feedback control of MSM based actuator with large non-smooth input hysteresis
Authors: Michael Ruderman, Gianluca Giostra, Matteo Sette
Abstract: Dynamic systems with a large and non-smooth hysteresis in feed-forward challenge the design of feedback control since the instantaneous input gain is varying during operation, in worst case between zero and infinity. Magnetic shape memory (MSM) actuators with multi-stable transitions represent such untypical system plant with only measured output displacement. This paper provides a case study of designing the feed-froward and feedback control system for an MSM-based actuator setup with a fairly high level of the output sensing noise. First, a recently introduced inversion-free feed-forward hysteresis compensator is adapted for the Krasnoselskii-Pokrovskii operator model. Then, a robust feedback proportional-integral (PI) loop shaping is performed, while taking into account the lagging behavior of the low-pass filtering and plant uncertainties. Experimental results show that the parallel action of feed-forward and feedback parts improves the overall position control performance.

Paper number 72:
Title: Complex Electromagnetic Space Combat System-of-systems Modeling and Key Node Identification Method
Authors: Xiao Liu, Sudan Han, Jinlin Peng
Abstract: With the application of advanced science and technology in the military field, modern warfare has developed into a confrontation between systems. The combat system-of-systems (CSoS) has numerous nodes, multiple attributes and complex interactions, and its research and analysis are facing great difficulties. Electromagnetic space is an important dimension of modern warfare. Modeling and analyzing the CSoS from this perspective is of great significance to studying modern warfare and can provide a reference for the research of electromagnetic warfare. In this study, the types of nodes and relationships in the complex electromagnetic space of CSoS are first divided, the important attributes of the combat nodes are extracted, and the relationship weights are normalized to establish a networked model. On this basis, the calculation method of CSoS combat effectiveness based on the combat cycle is proposed, and then the identification and sorting of key nodes can be realized by the node deletion method. Finally, by constructing an instance of aircraft carrier fleet confrontation, the feasibility of this method has been verified, and the experimental results have been compared with classical algorithms to demonstrate the advanced nature of this method.

Paper number 73:
Title: Doctor-in-the-Loop: An Explainable, Multi-View Deep Learning Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer
Authors: Alice Natalina Caragliano, Filippo Ruffini, Carlo Greco, Edy Ippolito, Michele Fiore, Claudia Tacconi, Lorenzo Nibid, Giuseppe Perrone, Sara Ramella, Paolo Soda, Valerio Guarrasi
Abstract: Non-small cell lung cancer (NSCLC) remains a major global health challenge, with high post-surgical recurrence rates underscoring the need for accurate pathological response predictions to guide personalized treatments. Although artificial intelligence models show promise in this domain, their clinical adoption is limited by the lack of medically grounded guidance during training, often resulting in non-explainable intrinsic predictions. To address this, we propose Doctor-in-the-Loop, a novel framework that integrates expert-driven domain knowledge with explainable artificial intelligence techniques, directing the model toward clinically relevant anatomical regions and improving both interpretability and trustworthiness. Our approach employs a gradual multi-view strategy, progressively refining the model's focus from broad contextual features to finer, lesion-specific details. By incorporating domain insights at every stage, we enhance predictive accuracy while ensuring that the model's decision-making process aligns more closely with clinical reasoning. Evaluated on a dataset of NSCLC patients, Doctor-in-the-Loop delivers promising predictive performance and provides transparent, justifiable outputs, representing a significant step toward clinically explainable artificial intelligence in oncology.

Paper number 74:
Title: On Neural Inertial Classification Networks for Pedestrian Activity Recognition
Authors: Zeev Yampolsky, Ofir Kruzel, Victoria Khalfin Fekson, Itzik Klein
Abstract: Inertial sensors are crucial for recognizing pedestrian activity. Recent advances in deep learning have greatly improved inertial sensing performance and robustness. Different domains and platforms use deep-learning techniques to enhance network performance, but there is no common benchmark. The latter is crucial for fair comparison and evaluation within a standardized framework. The aim of this paper is to fill this gap by defining and analyzing ten data-driven techniques for improving neural inertial classification networks. In order to accomplish this, we focused on three aspects of neural networks: network architecture, data augmentation, and data preprocessing. The experiments were conducted across four datasets collected from 78 participants. In total, over 936 minutes of inertial data sampled between 50-200Hz were analyzed. Data augmentation through rotation and multi-head architecture consistently yields the most significant improvements. Additionally, this study outlines benchmarking strategies for enhancing neural inertial classification networks.

Paper number 75:
Title: Perceptual Noise-Masking with Music through Deep Spectral Envelope Shaping
Authors: ClÃ©mentine Berger (IP Paris, IDS, S2A), Roland Badeau (IP Paris, IDS, S2A), Slim Essid (IP Paris, IDS, S2A)
Abstract: People often listen to music in noisy environments, seeking to isolate themselves from ambient sounds. Indeed, a music signal can mask some of the noise's frequency components due to the effect of simultaneous masking. In this article, we propose a neural network based on a psychoacoustic masking model, designed to enhance the music's ability to mask ambient noise by reshaping its spectral envelope with predicted filter frequency responses. The model is trained with a perceptual loss function that balances two constraints: effectively masking the noise while preserving the original music mix and the user's chosen listening level. We evaluate our approach on simulated data replicating a user's experience of listening to music with headphones in a noisy environment. The results, based on defined objective metrics, demonstrate that our system improves the state of the art.

Paper number 76:
Title: VANPY: Voice Analysis Framework
Authors: Gregory Koushnir, Michael Fire, Galit Fuhrmann Alpert, Dima Kagan
Abstract: Voice data is increasingly being used in modern digital communications, yet there is still a lack of comprehensive tools for automated voice analysis and characterization. To this end, we developed the VANPY (Voice Analysis in Python) framework for automated pre-processing, feature extraction, and classification of voice data. The VANPY is an open-source end-to-end comprehensive framework that was developed for the purpose of speaker characterization from voice data. The framework is designed with extensibility in mind, allowing for easy integration of new components and adaptation to various voice analysis applications. It currently incorporates over fifteen voice analysis components - including music/speech separation, voice activity detection, speaker embedding, vocal feature extraction, and various classification models. Four of the VANPY's components were developed in-house and integrated into the framework to extend its speaker characterization capabilities: gender classification, emotion classification, age regression, and height regression. The models demonstrate robust performance across various datasets, although not surpassing state-of-the-art performance. As a proof of concept, we demonstrate the framework's ability to extract speaker characteristics on a use-case challenge of analyzing character voices from the movie "Pulp Fiction." The results illustrate the framework's capability to extract multiple speaker characteristics, including gender, age, height, emotion type, and emotion intensity measured across three dimensions: arousal, dominance, and valence.

Paper number 77:
Title: SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for radiotherapy
Authors: Adrian Thummerer, Erik van der Bijl, Arthur Jr Galapon, Florian Kamp, Mark Savenije, Christina Muijs, Shafak Aluwini, Roel J.H.M. Steenbakkers, Stephanie Beuel, Martijn P.W. Intven, Johannes A. Langendijk, Stefan Both, Stefanie Corradini, Viktor Rogowski, Maarten Terpstra, Niklas Wahl, Christopher Kurz, Guillaume Landry, Matteo Maspero
Abstract: Medical imaging is essential in modern radiotherapy, supporting diagnosis, treatment planning, and monitoring. Synthetic imaging, particularly synthetic computed tomography (sCT), is gaining traction in radiotherapy. The SynthRAD2025 dataset and Grand Challenge promote advancements in sCT generation by providing a benchmarking platform for algorithms using cone-beam CT (CBCT) and magnetic resonance imaging (MRI). The dataset includes 2362 cases: 890 MRI-CT and 1472 CBCT-CT pairs from head-and-neck, thoracic, and abdominal cancer patients treated at five European university medical centers (UMC Groningen, UMC Utrecht, Radboud UMC, LMU University Hospital Munich, and University Hospital of Cologne). Data were acquired with diverse scanners and protocols. Pre-processing, including rigid and deformable image registration, ensures high-quality, modality-aligned images. Extensive quality assurance validates image consistency and usability. All imaging data is provided in MetaImage (.mha) format, ensuring compatibility with medical image processing tools. Metadata, including acquisition parameters and registration details, is available in structured CSV files. To maintain dataset integrity, SynthRAD2025 is divided into training (65%), validation (10%), and test (25%) sets. The dataset is accessible at this https URL under the SynthRAD2025 collection. This dataset supports benchmarking and the development of synthetic imaging techniques for radiotherapy applications. Use cases include sCT generation for MRI-only and MR-guided photon/proton therapy, CBCT-based dose calculations, and adaptive radiotherapy workflows. By integrating diverse acquisition settings, SynthRAD2025 fosters robust, generalizable image synthesis algorithms, advancing personalized cancer care and adaptive radiotherapy.

Paper number 78:
Title: A Priori Generalizability Estimate for a CNN
Authors: Cito Balsells, Beatrice Riviere, David Fuentes
Abstract: We formulate truncated singular value decompositions of entire convolutional neural networks. We demonstrate the computed left and right singular vectors are useful in identifying which images the convolutional neural network is likely to perform poorly on. To create this diagnostic tool, we define two metrics: the Right Projection Ratio and the Left Projection Ratio. The Right (Left) Projection Ratio evaluates the fidelity of the projection of an image (label) onto the computed right (left) singular vectors. We observe that both ratios are able to identify the presence of class imbalance for an image classification problem. Additionally, the Right Projection Ratio, which only requires unlabeled data, is found to be correlated to the model's performance when applied to image segmentation. This suggests the Right Projection Ratio could be a useful metric to estimate how likely the model is to perform well on a sample.

Paper number 79:
Title: CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement
Authors: Lei Chenga, Lihao Guoa, Tianya Zhangb, Tam Bangb, Austin Harrisb, Mustafa Hajijc, Mina Sartipib, Siyang Cao
Abstract: Accurate multi-sensor calibration is essential for deploying robust perception systems in applications such as autonomous driving, robotics, and intelligent transportation. Existing LiDAR-camera calibration methods often rely on manually placed targets, preliminary parameter estimates, or intensive data preprocessing, limiting their scalability and adaptability in real-world settings. In this work, we propose a fully automatic, targetless, and online calibration framework, CalibRefine, which directly processes raw LiDAR point clouds and camera images. Our approach is divided into four stages: (1) a Common Feature Discriminator that trains on automatically detected objects--using relative positions, appearance embeddings, and semantic classes--to generate reliable LiDAR-camera correspondences, (2) a coarse homography-based calibration, (3) an iterative refinement to incrementally improve alignment as additional data frames become available, and (4) an attention-based refinement that addresses non-planar distortions by leveraging a Vision Transformer and cross-attention mechanisms. Through extensive experiments on two urban traffic datasets, we show that CalibRefine delivers high-precision calibration results with minimal human involvement, outperforming state-of-the-art targetless methods and remaining competitive with, or surpassing, manually tuned baselines. Our findings highlight how robust object-level feature matching, together with iterative and self-supervised attention-based adjustments, enables consistent sensor fusion in complex, real-world conditions without requiring ground-truth calibration matrices or elaborate data preprocessing.

Paper number 80:
Title: The Cyber Immune System: Harnessing Adversarial Forces for Security Resilience
Authors: Krti Tallam
Abstract: Both parasites in biological systems and adversarial forces in cybersecurity are often perceived as threats: disruptive elements that must be eliminated. However, these entities play a critical role in revealing systemic weaknesses, driving adaptation, and ultimately strengthening resilience. This paper draws from environmental epidemiology and cybersecurity to reframe parasites and cyber exploiters as essential stress-testers of complex systems, exposing hidden vulnerabilities and pushing defensive innovations forward. By examining how biological and digital systems evolve in response to persistent threats, we highlight the necessity of adversarial engagement in fortifying security frameworks. The recent breach of the DOGE website serves as a timely case study, illustrating how adversarial forces, whether biological or digital, compel systems to reassess and reinforce their defenses.

Paper number 81:
Title: Learning Backbones: Sparsifying Graphs through Zero Forcing for Effective Graph-Based Learning
Authors: Obaid Ullah Ahmad, Anwar Said, Mudassir Shabbir, Xenofon Koutsoukos, Waseem Abbas
Abstract: This paper introduces a novel framework for graph sparsification that preserves the essential learning attributes of original graphs, improving computational efficiency and reducing complexity in learning algorithms. We refer to these sparse graphs as "learning backbones". Our approach leverages the zero-forcing (ZF) phenomenon, a dynamic process on graphs with applications in network control. The key idea is to generate a tree from the original graph that retains critical dynamical properties. By correlating these properties with learning attributes, we construct effective learning backbones. We evaluate the performance of our ZF-based backbones in graph classification tasks across eight datasets and six baseline models. The results demonstrate that our method outperforms existing techniques. Additionally, we explore extensions using node distance metrics to further enhance the framework's utility.

Paper number 82:
Title: The GigaMIDI Dataset with Features for Expressive Music Performance Detection
Authors: Keon Ju Maverick Lee, Jeff Ens, Sara Adkins, Pedro Sarmento, Mathieu Barthet, Philippe Pasquier
Abstract: The Musical Instrument Digital Interface (MIDI), introduced in 1983, revolutionized music production by allowing computers and instruments to communicate efficiently. MIDI files encode musical instructions compactly, facilitating convenient music sharing. They benefit Music Information Retrieval (MIR), aiding in research on music understanding, computational musicology, and generative music. The GigaMIDI dataset contains over 1.4 million unique MIDI files, encompassing 1.8 billion MIDI note events and over 5.3 million MIDI tracks. GigaMIDI is currently the largest collection of symbolic music in MIDI format available for research purposes under fair dealing. Distinguishing between non-expressive and expressive MIDI tracks is challenging, as MIDI files do not inherently make this distinction. To address this issue, we introduce a set of innovative heuristics for detecting expressive music performance. These include the Distinctive Note Velocity Ratio (DNVR) heuristic, which analyzes MIDI note velocity; the Distinctive Note Onset Deviation Ratio (DNODR) heuristic, which examines deviations in note onset times; and the Note Onset Median Metric Level (NOMML) heuristic, which evaluates onset positions relative to metric levels. Our evaluation demonstrates these heuristics effectively differentiate between non-expressive and expressive MIDI tracks. Furthermore, after evaluation, we create the most substantial expressive MIDI dataset, employing our heuristic, NOMML. This curated iteration of GigaMIDI encompasses expressively-performed instrument tracks detected by NOMML, containing all General MIDI instruments, constituting 31% of the GigaMIDI dataset, totalling 1,655,649 tracks.

Paper number 83:
Title: Toward 6-DOF Autonomous Underwater Vehicle Energy-Aware Position Control based on Deep Reinforcement Learning: Preliminary Results
Authors: Gustavo BorÃ© (1), Vicente SufÃ¡n (1), SebastiÃ¡n RodrÃ­guez-MartÃ­nez (2), Giancarlo Troni (2) ((1) Pontificia Universidad CatÃ³lica de Chile, (2) Monterey Bay Aquarium Research Institute)
Abstract: The use of autonomous underwater vehicles (AUVs) for surveying, mapping, and inspecting unexplored underwater areas plays a crucial role, where maneuverability and power efficiency are key factors for extending the use of these platforms, making six degrees of freedom (6-DOF) holonomic platforms essential tools. Although Proportional-Integral-Derivative (PID) and Model Predictive Control controllers are widely used in these applications, they often require accurate system knowledge, struggle with repeatability when facing payload or configuration changes, and can be time-consuming to fine-tune. While more advanced methods based on Deep Reinforcement Learning (DRL) have been proposed, they are typically limited to operating in fewer degrees of freedom. This paper proposes a novel DRL-based approach for controlling holonomic 6-DOF AUVs using the Truncated Quantile Critics (TQC) algorithm, which does not require manual tuning and directly feeds commands to the thrusters without prior knowledge of their configuration. Furthermore, it incorporates power consumption directly into the reward function. Simulation results show that the TQC High-Performance method achieves better performance to a fine-tuned PID controller when reaching a goal point, while the TQC Energy-Aware method demonstrates slightly lower performance but consumes 30% less power on average.

Paper number 84:
Title: A digital eye-fixation biomarker using a deep anomaly scheme to classify Parkisonian patterns
Authors: Juan NiÃ±o, Luis GuayacÃ¡n, Santiago GÃ³mez, Fabio MartÃ­nez
Abstract: Oculomotor alterations constitute a promising biomarker to detect and characterize Parkinson's disease (PD), even in prodromal stages. Currently, only global and simplified eye movement trajectories are employed to approximate the complex and hidden kinematic relationships of the oculomotor function. Recent advances on machine learning and video analysis have encouraged novel characterizations of eye movement patterns to quantify PD. These schemes enable the identification of spatiotemporal segments primarily associated with PD. However, they rely on discriminative models that require large training datasets and depend on balanced class distributions. This work introduces a novel video analysis scheme to quantify Parkinsonian eye fixation patterns with an anomaly detection framework. Contrary to classical deep discriminative schemes that learn differences among labeled classes, the proposed approach is focused on one-class learning, avoiding the necessity of a significant amount of data. The proposed approach focuses only on Parkinson's representation, considering any other class sample as an anomaly of the distribution. This approach was evaluated for an ocular fixation task, in a total of 13 control subjects and 13 patients on different stages of the disease. The proposed digital biomarker achieved an average sensitivity and specificity of 0.97 and 0.63, respectively, yielding an AUC-ROC of 0.95. A statistical test shows significant differences (p < 0.05) among predicted classes, evidencing a discrimination between patients and control subjects.

Paper number 85:
Title: GPUArmor: A Hardware-Software Co-design for Efficient and Scalable Memory Safety on GPUs
Authors: Mohamed Tarek Ibn Ziad, Sana Damani, Mark Stephenson, Stephen W. Keckler, Aamer Jaleel
Abstract: Memory safety errors continue to pose a significant threat to current computing systems, and graphics processing units (GPUs) are no exception. A prominent class of memory safety algorithms is allocation-based solutions. The key idea is to maintain each allocation's metadata (base address and size) in a disjoint table and retrieve it at runtime to verify memory accesses. While several previous solutions have adopted allocation-based algorithms (e.g., cuCatch and GPUShield), they typically suffer from high memory overheads or scalability problems. In this work, we examine the key characteristics of real-world GPU workloads and observe several differences between GPU and CPU applications regarding memory access patterns, memory footprint, number of live allocations, and active allocation working set. Our observations motivate GPUArmor, a hardware-software co-design framework for memory safety on GPUs. We show that a simple compiler analysis combined with lightweight hardware support using a small Memory Lookaside Buffer (MLB) can help prevent spatial and temporal memory violations on modern GPU workloads with 2.3% average run time overheads. More importantly, GPUArmor achieves speed-of-light performance with negligible storage requirements. This result benefits both base and bounds solutions and memory tagging techniques, which we showcase with GPUArmor-HWOnly, a variation of GPUArmor that does not require recompilation, and achieves 2.2% slowdowns while significantly reducing storage overheads beyond traditional memory tagging approaches.

Paper number 86:
Title: URO-Bench: A Comprehensive Benchmark for End-to-End Spoken Dialogue Models
Authors: Ruiqi Yan, Xiquan Li, Wenxi Chen, Zhikang Niu, Chen Yang, Ziyang Ma, Kai Yu, Xie Chen
Abstract: In recent years, with advances in large language models (LLMs), end-to-end spoken dialogue models (SDMs) have made significant strides. Compared to text-based LLMs, the evaluation of SDMs needs to take speech-related aspects into account, such as paralinguistic information and speech quality. However, there is still a lack of comprehensive evaluations for SDMs in speech-to-speech (S2S) scenarios. To address this gap, we propose URO-Bench, an extensive benchmark for SDMs. Notably, URO-Bench is the first S2S benchmark that covers evaluations about multilingualism, multi-round dialogues, and paralinguistics. Our benchmark is divided into two difficulty levels: basic track and pro track, consisting of 16 and 20 datasets respectively, evaluating the model's abilities in Understanding, Reasoning, and Oral conversation. Evaluations on our proposed benchmark reveal that current open-source SDMs perform rather well in daily QA tasks, but lag behind their backbone LLMs in terms of instruction-following ability and also suffer from catastrophic forgetting. Their performance in advanced evaluations of paralinguistic information and audio understanding remains subpar, highlighting the need for further research in this direction. We hope that URO-Bench can effectively facilitate the development of spoken dialogue models by providing a multifaceted evaluation of existing models and helping to track progress in this area.

Paper number 87:
Title: Silent Speech Sentence Recognition with Six-Axis Accelerometers using Conformer and CTC Algorithm
Authors: Yudong Xie, Zhifeng Han, Qinfan Xiao, Liwei Liang, Lu-Qi Tao, Tian-Ling Ren
Abstract: Silent speech interfaces (SSI) are being actively developed to assist individuals with communication impairments who have long suffered from daily hardships and a reduced quality of life. However, silent sentences are difficult to segment and recognize due to elision and linking. A novel silent speech sentence recognition method is proposed to convert the facial motion signals collected by six-axis accelerometers into transcribed words and sentences. A Conformer-based neural network with the Connectionist-Temporal-Classification algorithm is used to gain contextual understanding and translate the non-acoustic signals into words sequences, solely requesting the constituent words in the database. Test results show that the proposed method achieves a 97.17% accuracy in sentence recognition, surpassing the existing silent speech recognition methods with a typical accuracy of 85%-95%, and demonstrating the potential of accelerometers as an available SSI modality for high-accuracy silent speech sentence recognition.

Paper number 88:
Title: EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling
Authors: Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane
Abstract: Deep learning has achieved significant progress in the development of electroencephalogram (EEG) foundation models, with Transformer-based architectures excelling at capturing long-range dependencies. However, their quadratic computational complexity presents challenges in memory efficiency, training, and inference speed, limiting their scalability and generalizability as a foundation model. In this paper, we propose EEGM2, a self-supervised framework based on structured state space duality (SSD) that overcomes these limitations. EEGM2 introduces three key innovations: (1) a reconstruction-based framework that captures both local and global EEG features through Mamba-2 structured state space models, (2) a spatiotemporal-aware loss function that enhances robustness to noise and preserves spectral information, and (3) a multi-branch receptive field input embedding strategy that improves cross-subject generalization and stability for EEG sequences of varying lengths. In comparison to traditional pretraining methods, on raw EEG or latent representation spaces, EEGM2 shows superior performance on long-sequence tasks, where conventional models struggle. Our experimental results on six EEG datasets validate that EEGM2 not only achieves state-of-the-art cross-domain accuracy but also reduces computational overhead, making it a more efficient solution for deployment on resource-constrained BCI devices.

Paper number 89:
Title: Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models
Authors: Andrei Apostol, Maria Nutu
Abstract: In Romania, cardiovascular problems are the leading cause of death, accounting for nearly one-third of annual fatalities. The severity of this situation calls for innovative diagnosis method for cardiovascular diseases. This article aims to explore efficient, light-weight and rapid methods for arrhythmia diagnosis, in resource-constrained healthcare settings. Due to the lack of Romanian public medical data, we trained our systems using international public datasets, having in mind that the ECG signals are the same regardless the patients' nationality. Within this purpose, we combined multiple datasets, usually used in the field of arrhythmias classification: PTB-XL electrocardiography dataset , PTB Diagnostic ECG Database, China 12-Lead ECG Challenge Database, Georgia 12-Lead ECG Challenge Database, and St. Petersburg INCART 12-lead Arrhythmia Database. For the input data, we employed ECG signal processing methods, specifically a variant of the Pan-Tompkins algorithm, useful in arrhythmia classification because it provides a robust and efficient method for detecting QRS complexes in ECG signals. Additionally, we used machine learning techniques, widely used for the task of classification, including convolutional neural networks (1D CNNs, 2D CNNs, ResNet) and Vision Transformers (ViTs). The systems were evaluated in terms of accuracy and F1 score. We annalysed our dataset from two perspectives. First, we fed the systems with the ECG signals and the GRU-based 1D CNN model achieved the highest accuracy of 93.4% among all the tested architectures. Secondly, we transformed ECG signals into images and the CNN2D model achieved an accuracy of 92.16%.

Paper number 90:
Title: A Tutorial on Movable Antennas for Wireless Networks
Authors: Lipeng Zhu, Wenyan Ma, Weidong Mei, Yong Zeng, Qingqing Wu, Boyu Ning, Zhenyu Xiao, Xiaodan Shao, Jun Zhang, Rui Zhang
Abstract: Movable antenna (MA) has been recognized as a promising technology to enhance the performance of wireless communication and sensing by enabling antenna movement. Such a significant paradigm shift from conventional fixed antennas (FAs) to MAs offers tremendous new opportunities towards realizing more versatile, adaptive and efficient next-generation wireless networks such as 6G. In this paper, we provide a comprehensive tutorial on the fundamentals and advancements in the area of MA-empowered wireless networks. First, we overview the historical development and contemporary applications of MA technologies. Next, to characterize the continuous variation in wireless channels with respect to antenna position and/or orientation, we present new field-response channel models tailored for MAs, which are applicable to narrowband and wideband systems as well as far-field and near-field propagation conditions. Subsequently, we review the state-of-the-art architectures for implementing MAs and discuss their practical constraints. A general optimization framework is then formulated to fully exploit the spatial degrees of freedom (DoFs) in antenna movement for performance enhancement in wireless systems. In particular, we delve into two major design issues for MA systems. First, we address the intricate antenna movement optimization problem for various communication and/or sensing systems to maximize the performance gains achievable by MAs. Second, we deal with the challenging channel acquisition issue in MA systems for reconstructing the channel mapping between arbitrary antenna positions inside the transmitter and receiver regions. Moreover, we show existing prototypes developed for MA-aided communication/sensing and the experimental results based on them. Finally, the extension of MA design to other wireless systems and its synergy with other emerging wireless technologies are discussed.

Paper number 91:
Title: Enhancing Speech Quality through the Integration of BGRU and Transformer Architectures
Authors: Souliman Alghnam, Mohammad Alhussien, Khaled Shaheen
Abstract: Speech enhancement plays an essential role in improving the quality of speech signals in noisy environments. This paper investigates the efficacy of integrating Bidirectional Gated Recurrent Units (BGRU) and Transformer models for speech enhancement tasks. Through a comprehensive experimental evaluation, our study demonstrates the superiority of this hybrid architecture over traditional methods and standalone models. The combined BGRU-Transformer framework excels in capturing temporal dependencies and learning complex signal patterns, leading to enhanced noise reduction and improved speech quality. Results show significant performance gains compared to existing approaches, highlighting the potential of this integrated model in real-world applications. The seamless integration of BGRU and Transformer architectures not only enhances system robustness but also opens the road for advanced speech processing techniques. This research contributes to the ongoing efforts in speech enhancement technology and sets a solid foundation for future investigations into optimizing model architectures, exploring many application scenarios, and advancing the field of speech processing in noisy environments.

Paper number 92:
Title: Quantum Annealing-Based Sum Rate Maximization for Multi-UAV-Aided Wireless Networks
Authors: Seon-Geun Jeong, Pham Dang Anh Duc, Quang Vinh Do, Dae-Il Noh, Nguyen Xuan Tung, Trinh Van Chien, Quoc-Viet Pham, Mikio Hasegawa, Hiroo Sekiya, Won-Joo Hwang
Abstract: In wireless communication networks, it is difficult to solve many NP-hard problems owing to computational complexity and high cost. Recently, quantum annealing (QA) based on quantum physics was introduced as a key enabler for solving optimization problems quickly. However, only some studies consider quantum-based approaches in wireless communications. Therefore, we investigate the performance of a QA solution to an optimization problem in wireless networks. Specifically, we aim to maximize the sum rate by jointly optimizing clustering, sub-channel assignment, and power allocation in a multi-unmanned aerial vehicle-aided wireless network. We formulate the sum rate maximization problem as a combinatorial optimization problem. Then, we divide it into two sub-problems: 1) a QA-based clustering and 2) sub-channel assignment and power allocation for a given clustering configuration. Subsequently, we obtain an optimized solution for the joint optimization problem by solving these two sub-problems. For the first sub-problem, we convert the problem into a simplified quadratic unconstrained binary optimization (QUBO) model. As for the second sub-problem, we introduce a novel QA algorithm with optimal scaling parameters to address it. Simulation results demonstrate the effectiveness of the proposed algorithm in terms of the sum rate and running time.

Paper number 93:
Title: Remote Training in Task-Oriented Communication: Supervised or Self-Supervised with Fine-Tuning?
Authors: Hongru Li, Hang Zhao, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief
Abstract: Task-oriented communication focuses on extracting and transmitting only the information relevant to specific tasks, effectively minimizing communication overhead. Most existing methods prioritize reducing this overhead during inference, often assuming feasible local training or minimal training communication resources. However, in real-world wireless systems with dynamic connection topologies, training models locally for each new connection is impractical, and task-specific information is often unavailable before establishing connections. Therefore, minimizing training overhead and enabling label-free, task-agnostic pre-training before the connection establishment are essential for effective task-oriented communication. In this paper, we tackle these challenges by employing a mutual information maximization approach grounded in self-supervised learning and information-theoretic analysis. We propose an efficient strategy that pre-trains the transmitter in a task-agnostic and label-free manner, followed by joint fine-tuning of both the transmitter and receiver in a task-specific, label-aware manner. Simulation results show that our proposed method reduces training communication overhead to about half that of full-supervised methods using the SGD optimizer, demonstrating significant improvements in training efficiency.

Paper number 94:
Title: Quadrotor Neural Dead Reckoning in Periodic Trajectories
Authors: Shira Massas, Itzik Klein
Abstract: In real world scenarios, due to environmental or hardware constraints, the quadrotor is forced to navigate in pure inertial navigation mode while operating indoors or outdoors. To mitigate inertial drift, end-to-end neural network approaches combined with quadrotor periodic trajectories were suggested. There, the quadrotor distance is regressed and combined with inertial model-based heading estimation, the quadrotor position vector is estimated. To further enhance positioning performance, in this paper we propose a quadrotor neural dead reckoning approach for quadrotors flying on periodic trajectories. In this case, the inertial readings are fed into a simple and efficient network to directly estimate the quadrotor position vector. Our approach was evaluated on two different quadrotors, one operating indoors while the other outdoors. Our approach improves the positioning accuracy of other deep-learning approaches, achieving an average 27% reduction in error outdoors and an average 79% reduction indoors, while requiring only software modifications. With the improved positioning accuracy achieved by our method, the quadrotor can seamlessly perform its tasks.

Paper number 95:
Title: NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms
Authors: Yashan Wang, Shangda Wu, Jianhuai Hu, Xingjian Du, Yueqi Peng, Yongxin Huang, Shuai Fan, Xiaobing Li, Feng Yu, Maosong Sun
Abstract: We introduce NotaGen, a symbolic music generation model aiming to explore the potential of producing high-quality classical sheet music. Inspired by the success of Large Language Models (LLMs), NotaGen adopts pre-training, fine-tuning, and reinforcement learning paradigms (henceforth referred to as the LLM training paradigms). It is pre-trained on 1.6M pieces of music, and then fine-tuned on approximately 9K high-quality classical compositions conditioned on "period-composer-instrumentation" prompts. For reinforcement learning, we propose the CLaMP-DPO method, which further enhances generation quality and controllability without requiring human annotations or predefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in symbolic music generation models with different architectures and encoding schemes. Furthermore, subjective A/B tests show that NotaGen outperforms baseline models against human compositions, greatly advancing musical aesthetics in symbolic music this http URL project homepage is this https URL.

Paper number 96:
Title: High-precision visual navigation device calibration method based on collimator
Authors: Shunkun Liang, Dongcai Tan, Banglei Guan, Zhang Li, Guangcheng Dai, Nianpeng Pan, Liang Shen, Yang Shang, Qifeng Yu
Abstract: Visual navigation devices require precise calibration to achieve high-precision localization and navigation, which includes camera and attitude calibration. To address the limitations of time-consuming camera calibration and complex attitude adjustment processes, this study presents a collimator-based calibration method and system. Based on the optical characteristics of the collimator, a single-image camera calibration algorithm is introduced. In addition, integrated with the precision adjustment mechanism of the calibration frame, a rotation transfer model between coordinate systems enables efficient attitude calibration. Experimental results demonstrate that the proposed method achieves accuracy and stability comparable to traditional multi-image calibration techniques. Specifically, the re-projection errors are less than 0.1463 pixels, and average attitude angle errors are less than 0.0586 degrees with a standard deviation less than 0.0257 degrees, demonstrating high precision and robustness.

Paper number 97:
Title: HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers
Authors: Yifeng Wang, Yi Zhao
Abstract: Low-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.

Paper number 98:
Title: Monitoring snow avalanches from SAR data with deep learning
Authors: Filippo Maria Bianchi, Jakob Grahn
Abstract: Snow avalanches present significant risks to human life and infrastructure, particularly in mountainous regions, making effective monitoring crucial. Traditional monitoring methods, such as field observations, are limited by accessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture Radar (SAR) data has become an important tool for large-scale avalanche detection, as it can capture data in all weather conditions and across remote areas. However, traditional processing methods struggle with the complexity and variability of avalanches. This chapter reviews the application of deep learning for detecting and segmenting snow avalanches from SAR data. Early efforts focused on the binary classification of SAR images, while recent advances have enabled pixel-level segmentation, providing greater accuracy and spatial resolution. A case study using Sentinel-1 SAR data demonstrates the effectiveness of deep learning models for avalanche segmentation, achieving superior results over traditional methods. We also present an extension of this work, testing recent state-of-the-art segmentation architectures on an expanded dataset of over 4,500 annotated SAR images. The best-performing model among those tested was applied for large-scale avalanche detection across the whole of Norway, revealing important spatial and temporal patterns over several winter seasons.

Paper number 99:
Title: Determined Blind Source Separation with Sinkhorn Divergence-based Optimal Allocation of the Source Power
Authors: Jianyu Wang, Shanzheng Guan, Nicolas Dobigeon, Jingdong Chen
Abstract: Blind source separation (BSS) refers to the process of recovering multiple source signals from observations recorded by an array of sensors. Common approaches to BSS, including independent vector analysis (IVA), and independent low-rank matrix analysis (ILRMA), typically rely on second-order models to capture the statistical independence of source signals for separation. However, these methods generally do not account for the implicit structural information across frequency bands, which may lead to model mismatches between the assumed source distributions and the distributions of the separated source signals estimated from the observed mixtures. To tackle these limitations, this paper shows that conventional approaches such as IVA and ILRMA can easily be leveraged by the Sinkhorn divergence, incorporating an optimal transport (OT) framework to adaptively correct source variance estimates. This allows for the recovery of the source distribution while modeling the inter-band signal dependence and reallocating source power across bands. As a result, enhanced versions of these algorithms are developed, integrating a Sinkhorn iterative scheme into their standard implementations. Extensive simulations demonstrate that the proposed methods consistently enhance BSS performance.

Paper number 100:
Title: Steering Language Model to Stable Speech Emotion Recognition via Contextual Perception and Chain of Thought
Authors: Zhixian Zhao, Xinfa Zhu, Xinsheng Wang, Shuiyuan Wang, Xuelong Geng, Wenjie Tian, Lei Xie
Abstract: Large-scale audio language models (ALMs), such as Qwen2-Audio, are capable of comprehending diverse audio signal, performing audio analysis and generating textual responses. However, in speech emotion recognition (SER), ALMs often suffer from hallucinations, resulting in misclassifications or irrelevant outputs. To address these challenges, we propose C$^2$SER, a novel ALM designed to enhance the stability and accuracy of SER through Contextual perception and Chain of Thought (CoT). C$^2$SER integrates the Whisper encoder for semantic perception and Emotion2Vec-S for acoustic perception, where Emotion2Vec-S extends Emotion2Vec with semi-supervised learning to enhance emotional discrimination. Additionally, C$^2$SER employs a CoT approach, processing SER in a step-by-step manner while leveraging speech content and speaking styles to improve recognition. To further enhance stability, C$^2$SER introduces self-distillation from explicit CoT to implicit CoT, mitigating error accumulation and boosting recognition accuracy. Extensive experiments show that C$^2$SER outperforms existing popular ALMs, such as Qwen2-Audio and SECap, delivering more stable and precise emotion recognition. We release the training code, checkpoints, and test sets to facilitate further research.

Paper number 101:
Title: Machine Learning for Future Wireless Communications: Channel Prediction Perspectives
Authors: Hwanjin Kim, Junil Choi, David J. Love
Abstract: Precise channel state knowledge is crucial in future wireless communication systems, which drives the need for accurate channel prediction without additional pilot overhead. While machine-learning (ML) methods for channel prediction show potential, existing approaches have limitations in their capability to adapt to environmental changes due to their extensive training requirements. In this paper, we introduce the channel prediction approaches in terms of the temporal channel prediction and the environmental adaptation. Then, we elaborate on the use of the advanced ML-based channel prediction to resolve the issues in traditional ML methods. The numerical results show that the advanced ML-based channel prediction has comparable accuracy with much less training overhead compared to conventional prediction methods. Also, we examine the training process, dataset characteristics, and the impact of source tasks and pre-trained models on channel prediction approaches. Finally, we discuss open challenges and possible future research directions of ML-based channel prediction.

Paper number 102:
Title: Software implemented fault diagnosis of natural gas pumping unit based on feedforward neural network
Authors: Mykola Kozlenko, Olena Zamikhovska, Leonid Zamikhovskyi
Abstract: In recent years, more and more attention has been paid to the use of artificial neural networks (ANN) for diagnostics of gas pumping units (GPU). Usually, ANN training is carried out on models of GPU workflows, and generated sets of diagnostic data are used to simulate defect conditions. At the same time, the results obtained do not allow assessing the real state of the GPU. It is proposed to use the values of the characteristics of the acoustic and vibration processes of the GPU as the input data of the ANN. A descriptive statistical analysis of real vibration and acoustic processes generated by the operation of the GPU type GTK-25-i (Nuovo Pignone, Italy) has been carried out. The formation of packets of diagnostic signs arriving at the input of the ANN has been carried out. The diagnostic features are the five maximum amplitude components of the acoustic and vibration signals, as well as the value of the standard deviation for each sample. Diagnostic signs are calculated directly in the input pipeline of ANN data in real time for three technical states of the GPU. Using the frameworks TensorFlow, Keras, NumPy, pandas, in the Python 3 programming language, an architecture was developed for a deep fully connected feedforward ANN, training on the error backpropagation algorithm. The results of training and testing of the developed ANN are presented. During testing, it was found that the signal classification precision for the "nominal" state of all 1475 signal samples is 1.0000, for the "current" state, precision equils 0.9853, and for the "defective" state, precision is 0.9091. The use of the developed ANN makes it possible to classify the technical states of the GPU with an accuracy sufficient for practical use, which will prevent the occurrence of GPU failures. ANN can be used to diagnose GPU of any type and power.

Paper number 103:
Title: Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach
Authors: Taha Ahmadi Pargo, Mohsen Akbarpour Shirazi, Dawud Fadai
Abstract: Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries. On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss. One of these technologies is the Internet of Things (IoT). Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems. Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems. In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval. The designed system comprises sensors, a central agent, and irrigation nodes. These agents follow defined rules to maintain soil moisture at a desired level cooperatively. For system simulation, a hybrid agent-based and system dynamics model was designed. In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach. The proposed model, was implemented in AnyLogic computer simulation software. Utilizing the simulation model, irrigation rules were examined. The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed. Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests. Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time.

Paper number 104:
Title: GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music
Authors: Xinran Liu, Xu Dong, Diptesh Kanojia, Wenwu Wang, Zhenhua Feng
Abstract: Generating high-quality full-body dance sequences from music is a challenging task as it requires strict adherence to genre-specific choreography. Moreover, the generated sequences must be both physically realistic and precisely synchronized with the beats and rhythm of the music. To overcome these challenges, we propose GCDance, a classifier-free diffusion framework for generating genre-specific dance motions conditioned on both music and textual prompts. Specifically, our approach extracts music features by combining high-level pre-trained music foundation model features with hand-crafted features for multi-granularity feature fusion. To achieve genre controllability, we leverage CLIP to efficiently embed genre-based textual prompt representations at each time step within our dance generation pipeline. Our GCDance framework can generate diverse dance styles from the same piece of music while ensuring coherence with the rhythm and melody of the music. Extensive experimental results obtained on the FineDance dataset demonstrate that GCDance significantly outperforms the existing state-of-the-art approaches, which also achieve competitive results on the AIST++ dataset. Our ablation and inference time analysis demonstrate that GCDance provides an effective solution for high-quality music-driven dance generation.

Paper number 105:
Title: From Vision to Sound: Advancing Audio Anomaly Detection with Vision-Based Algorithms
Authors: Manuel Barusco, Francesco Borsatti, Davide Dalle Pezze, Francesco Paissan, Elisabetta Farella, Gian Antonio Susto
Abstract: Recent advances in Visual Anomaly Detection (VAD) have introduced sophisticated algorithms leveraging embeddings generated by pre-trained feature extractors. Inspired by these developments, we investigate the adaptation of such algorithms to the audio domain to address the problem of Audio Anomaly Detection (AAD). Unlike most existing AAD methods, which primarily classify anomalous samples, our approach introduces fine-grained temporal-frequency localization of anomalies within the spectrogram, significantly improving explainability. This capability enables a more precise understanding of where and when anomalies occur, making the results more actionable for end users. We evaluate our approach on industrial and environmental benchmarks, demonstrating the effectiveness of VAD techniques in detecting anomalies in audio signals. Moreover, they improve explainability by enabling localized anomaly identification, making audio anomaly detection systems more interpretable and practical.

Paper number 106:
Title: Semantic and Goal-oriented Wireless Network Coverage: The Area of Effectiveness
Authors: Mattia Merluzzi, Giuseppe Di Poce, Paolo Di Lorenzo
Abstract: Assessing wireless coverage is a fundamental task for public network operators and private deployments, whose goal is to guarantee quality of service across the network while minimizing material waste and energy consumption. These maps are usually built through ray tracing techniques and/or channel measurements that can be consequently translated into network Key Performance Indicators (KPIs), such as capacity or throughput. However, next generation networks (e.g., 6G) typically involve beyond communication resources, towards services that require data transmission, but also processing (local and remote) to perform complex decision making in real time, with the best balance between performance, energy consumption, material waste, and privacy. In this paper, we introduce the novel concept of areas of effectiveness, which goes beyond the legacy notion of coverage, towards one that takes into account capability of the network of offering edge Artificial Intelligence (AI)-related computation. We will show that radio coverage is a poor indicator of real system performance, depending on the application and the computing capabilities of network and devices. This opens new challenges in network planning, but also resource orchestration during operation to achieve the specific goal of communication.

Paper number 107:
Title: Equidistant-Sample or Wait-and-Sample to Minimize Age Under Sampling Constraint?
Authors: Subhankar Banerjee, Sennur Ulukus
Abstract: We study a status update system with a source, a sampler, a transmitter, and a monitor. The source governs a stochastic process that the monitor wants to observe in a timely manner. To achieve this, the sampler samples fresh update packets which the transmitter transmits via an error prone communication channel to the monitor. The transmitter can transmit without any constraint, i.e., it can transmit whenever an update packet is available to the transmitter. However, the sampler is imposed with a sampling rate constraint. The goal of the sampler is to devise an optimal policy that satisfies the resource constraint while minimizing the age of the monitor. We formulate this problem as a constrained Markov decision process (CMDP). We find several structures of an optimal policy. We leverage the optimal structures to find a low complexity optimal policy in an explicit manner, without resorting to complex iterative schemes or techniques that require bounding the age.

Paper number 108:
Title: Exploring Gender Disparities in Automatic Speech Recognition Technology
Authors: Hend ElGhazaly, Bahman Mirheidari, Nafise Sadat Moosavi, Heidi Christensen
Abstract: This study investigates factors influencing Automatic Speech Recognition (ASR) systems' fairness and performance across genders, beyond the conventional examination of demographics. Using the LibriSpeech dataset and the Whisper small model, we analyze how performance varies across different gender representations in training data. Our findings suggest a complex interplay between the gender ratio in training data and ASR performance. Optimal fairness occurs at specific gender distributions rather than a simple 50-50 split. Furthermore, our findings suggest that factors like pitch variability can significantly affect ASR accuracy. This research contributes to a deeper understanding of biases in ASR systems, highlighting the importance of carefully curated training data in mitigating gender bias.

Paper number 109:
Title: Multi-Armed Bandit Dynamic Beam Zooming for mmWave Alignment and Tracking
Authors: Nathan Blinn, Matthieu Bloch
Abstract: We propose an Integrated Sensing and Communication (ISAC) algorithm that exploits the structure of a hierarchical codebook of beamforming vectors using a best-arm identification Multi-Armed Bandit (MAB) approach for initial alignment and tracking of a Mobile Entity (ME). The algorithm, called Dynamic Beam Zooming (DBZ), performs beam adjustments that mitigate the severe outages associated with wireless mmWave systems and allow for adaptive control of the parameters governing communications. We analyze the sample complexity of DBZ and use it to inform how the algorithm adapts to the nonstationary MAB statistics based on ME motion and Signal-to-Noise Ratio (SNR). We perform extensive simulations to validate the approach and demonstrate that DBZ is competitive against existing Bayesian algorithms, without requiring channel multipath or fading knowledge. In particular, DBZ outperforms other low-complexity algorithms in the low SNR regime. We also illustrate the efficacy of DBZ in standardized rural and urban scenarios using NYU Sim.

Paper number 110:
Title: A New Non-Negative Matrix Factorization Approach for Blind Source Separation of Cardiovascular and Respiratory Sound Based on the Periodicity of Heart and Lung Function
Authors: Yasaman Torabi, Shahram Shirani, James P. Reilly
Abstract: Auscultation provides a rich diversity of information to diagnose cardiovascular and respiratory diseases. However, sound auscultation is challenging due to noise. In this study, a modified version of the affine non-negative matrix factorization (NMF) approach is proposed to blindly separate lung and heart sounds recorded by a digital stethoscope. This method applies a novel NMF algorithm, which embodies a parallel structure of multilayer units on the input signal, to find a proper estimation of source signals. Another key innovation is the use of the periodic property of the signals which improves accuracy compared to previous works. The method is tested on 100 cases. Each case consists of two synthesized mixtures of real measurements. The effect of different parameters is discussed, and the results are compared to other current methods. Results demonstrate improvements in the source-to-distortion ratio (SDR), source-to-interference ratio (SIR), and source-to-artifacts ratio (SAR) of heart and lung sounds, respectively.

Paper number 111:
Title: Mutual Information Based Pilot Design for ISAC
Authors: Ahmad Bazzi, Marwa Chafii
Abstract: The following paper presents a novel orthogonal pilot design dedicated for \textcolor{black}{integrated sensing and communications (ISAC)} systems performing multi-user communications and target detection. After careful characterization of both sensing and communication metrics based on mutual information (MI), we propose a multi-objective optimization problem (MOOP) tailored for pilot design, dedicated for simultaneously maximizing both sensing and communication MIs. Moreover, the MOOP is further simplified to a single-objective optimization problem, which characterizes trade-offs between sensing and communication performances. Due to the non-convex nature of the optimization problem, we propose to solve it via the projected gradient descent method on the Stiefel manifold. Closed-form gradient expressions are derived, which enable execution of the projected gradient descent algorithm. Furthermore, we prove convergence to a fixed orthogonal pilot matrix. Finally, we demonstrate the capabilities and superiority of the proposed pilot design, and corroborate relevant trade-offs between sensing MI and communication MI. In particular, significant signal-to-noise ratio (SNR) gains for communication are reported, while re-using the same pilots for target detection with significant gains in terms of probability of detection for fixed false-alarm probability. Other interesting findings are reported through simulations, such as an \textit{information overlap} phenomenon, whereby the fruitful ISAC integration can be fully exploited.

Paper number 112:
Title: Coordination Control of Discrete Event Systems under Cyber Attacks
Authors: Fei Wang, Jan Komenda, Feng Lin
Abstract: In this paper, coordination control of discrete event systems under joint sensor and actuator attacks is investigated. Sensor attacks are described by a set of attack languages using a proposed ALTER model. Several local supervisors are used to control the system. The goal is to design local supervisors to ensure safety of the system even under cyber attacks (CA). The necessary and sufficient conditions for the existence of such supervisors are derived in terms of conditional decomposability, CA-controllability and CA-observability. A method is developed to calculate local state estimates under sensor attacks. Two methods are also developed to design local supervisors, one for discrete event systems satisfying conditional decomposability, CA-controllability and CA-observability, and one for discrete event systems satisfying conditional decomposability only. The approach works for both stealthy and non-stealthy attacks. A practical example is given to illustrate the results.

Paper number 113:
Title: Computationally Efficient Electromagnetic Transient Power System Studies using Bayesian Optimization
Authors: Marius Kuhn, Evelyn Heylen, Willem Leterme
Abstract: The power system of the future will be governed by complex interactions and non-linear phenomena at small time-scales, that should be studied more and more through computationally expensive software simulations. To solve the abovementioned problems, power system engineers face problems with following characteristics: (i) a computationally expensive simulator, (ii) non-linear functions to optimize and (iii) lack of abundance of data. Existing optimization settings involving EMT-type simulations have been developed, but mainly use a deterministic model and optimizer, which may be computationally inefficient and do not guarantee finding a global optimum. Furthermore, the main focus has been on optimization routines, and less attention has been paid to other tasks such as classification. In this paper, an automation framework based on Bayesian Optimization is introduced, and applied to two case studies involving optimization and classification. It is found that the framework has the potential to reduce computational effort, outperform deterministic optimizers and is applicable to a multitude of problems. Nevertheless, it was found that the output of the Bayesian Optimization depends on the number of samples used for initialization, and in addition, careful selection of surrogate models, which should be subject to future investigation.

Paper number 114:
Title: Design and Control of a VTOL Aerial Vehicle Tilting its Rotors Only with Rotor Thrusts and a Passive Joint
Authors: Takumi Ito, Riku Funada, Mitsuji Sampei
Abstract: This paper presents a novel VTOL UAV that owns a link connecting four rotors and a fuselage by a passive joint, allowing the control of the rotor's tilting angle by adjusting the rotors' thrust. This unique structure contributes to eliminating additional actuators, such as servo motors, to control the tilting angles of rotors, resulting in the UAV's weight lighter and simpler structure. We first derive the dynamical model of the newly designed UAV and analyze its controllability. Then, we design the controller that leverages the tiltable link with four rotors to accelerate the UAV while suppressing a deviation of the UAV's angle of attack from the desired value to restrain the change of the aerodynamic force. Finally, the validity of the proposed control strategy is evaluated in simulation study.

Paper number 115:
Title: Machine Learning and Feature Ranking for Impact Fall Detection Event Using Multisensor Data
Authors: Tresor Y. Koffi, Youssef Mourchid, Mohammed Hindawi, Yohan Dupuis
Abstract: Falls among individuals, especially the elderly population, can lead to serious injuries and complications. Detecting impact moments within a fall event is crucial for providing timely assistance and minimizing the negative consequences. In this work, we aim to address this challenge by applying thorough preprocessing techniques to the multisensor dataset, the goal is to eliminate noise and improve data quality. Furthermore, we employ a feature selection process to identify the most relevant features derived from the multisensor UP-FALL dataset, which in turn will enhance the performance and efficiency of machine learning models. We then evaluate the efficiency of various machine learning models in detecting the impact moment using the resulting data information from multiple sensors. Through extensive experimentation, we assess the accuracy of our approach using various evaluation metrics. Our results achieve high accuracy rates in impact detection, showcasing the power of leveraging multisensor data for fall detection tasks. This highlights the potential of our approach to enhance fall detection systems and improve the overall safety and well-being of individuals at risk of falls.

Paper number 116:
Title: D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation
Authors: Youssef Mourchid, Rim Slama
Abstract: This paper tackles the challenge of automatically assessing physical rehabilitation exercises for patients who perform the exercises without clinician supervision. The objective is to provide a quality score to ensure correct performance and achieve desired results. To achieve this goal, a new graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with Transformer, is introduced. This model combines a modified version of STGCN and transformer architectures for efficient handling of spatio-temporal data. The key idea is to consider skeleton data respecting its non-linear structure as a graph and detecting joints playing the main role in each rehabilitation exercise. Dense connections and GRU mechanisms are used to rapidly process large 3D skeleton inputs and effectively model temporal dynamics. The transformer encoder's attention mechanism focuses on relevant parts of the input sequence, making it useful for evaluating rehabilitation exercises. The evaluation of our proposed approach on the KIMORE and UI-PRMD datasets highlighted its potential, surpassing state-of-the-art methods in terms of accuracy and computational time. This resulted in faster and more accurate learning and assessment of rehabilitation exercises. Additionally, our model provides valuable feedback through qualitative illustrations, effectively highlighting the significance of joints in specific exercises.

Paper number 117:
Title: Trustworthy UAV Cooperative Localization: Information Analysis of Performance and Security
Authors: Zexin Fang, Bin Han, Hans D. Schotten
Abstract: This paper presents a trustworthy framework for achieving accurate cooperative localization in multiple unmanned aerial vehicle (UAV) systems. The Cramer-Rao low bound (CRLB) for the three-dimensional (3D) cooperative localization network is derived, with particular attention given to practical scenarios involving non-uniform spatial distribution of anchor nodes. Challenges of mobility are then addressed with Mobility Adaptive Gradient Descent (MAGD). In the context of system security, we derive the CRLB of localization under the influence of falsified information. The methods and strategies of injecting such information and their impact on system performance are studied. To assure robust performance under falsified data, we propose a mitigation solution named Time-evolving Anomaly Detection (TAD). Furthermore, we model the system performance regarding the density and magnitude of falsified information, focusing on realistic scenarios where the adversary is resource-constrained. With the vulnerability of cooperative localization understood, we apply TAD and formulate an optimization problem from the adversary's perspective. Next, we discuss the design principles of an anomaly detector, with emphasis of the trade-off of reducing such optimum and system performance. Additionally, we also deploy a reputation propagation (RP) mechanism to fully utilize the anomaly detection and further optimize the TAD. Our proposed approaches are demonstrated through numerical simulations.

Paper number 118:
Title: Scheduling Power-Intensive Operations of Battery Energy Storage Systems and Application to Hybrid Hydropower Plants
Authors: Stefano Cassano, Fabrizio Sossan
Abstract: This paper proposes a novel set of power constraints for Battery Energy Storage Systems (BESSs), referred to as Dynamic Power Constraints (DPCs), that account for the voltage and current limits of the BESS as a function of its State of Charge (SOC). These constraints are formulated for integration into optimization-based BESS scheduling problems, providing a significant improvement over traditional static constraints. It is shown that, under mild assumptions typically verified during practical operations, DPCs can be expressed as a linear function of the BESS power, thus making it possible to retrofit existing scheduling problems without altering their tractability property (i.e., convexity). The DCPs unify voltage and current constraints into a single framework, filling a gap between simplified models used in BESS schedulers and more advanced models in real-time controllers and Battery Management Systems (BMSs). By improving the representation of the BESS's power capability, the proposed constraints enable schedulers to make more reliable and feasible decision, especially in power-intensive applications where the BESS operates near its rated power. To demonstrate the effectiveness of the DPCs, a simulation-based performance evaluation is conducted using a hybrid system comprising a 230 MW Hydropower Plant (HPP) and a 750 kVA/500 kWh BESS. Compared to state-of-the-art formulations such as static power constraints and DPC formulations without voltage constraints the proposed method reduces BESS constraint violations by 93% during real-time operations.

Paper number 119:
Title: TiRE-GAN: Task-Incentivized Generative Learning for Radiomap Estimation
Authors: Yueling Zhou, Achintha Wijesinghe, Yibo Ma, Songyang Zhang, Zhi Ding
Abstract: To characterize radio frequency (RF) signal power distribution in wireless communication systems, the radiomap is a useful tool for resource allocation and network management. Usually, a dense radiomap is reconstructed from sparse observations collected by deployed sensors or mobile devices. To leverage both physical principles of radio propagation models and data statistics from sparse observations, this work introduces a novel task-incentivized generative learning model, namely TiRE-GAN, for radiomap estimation. Specifically, we first introduce a radio depth map to capture the overall pattern of radio propagation and shadowing effects, following which a task-driven incentive network is proposed to provide feedback for radiomap compensation depending on downstream tasks. Our experimental results demonstrate the power of the radio depth map to capture radio propagation information, and the efficiency of the proposed TiRE-GAN for radiomap estimation.

Paper number 120:
Title: IG-CFAT: An Improved GAN-Based Framework for Effectively Exploiting Transformers in Real-World Image Super-Resolution
Authors: Alireza Aghelan, Ali Amiryan, Abolfazl Zarghani, Modjtaba Rouhani
Abstract: In the field of single image super-resolution (SISR), transformer-based models, have demonstrated significant advancements. However, the potential and efficiency of these models in applied fields such as real-world image super-resolution have been less noticed and there are substantial opportunities for improvement. Recently, composite fusion attention transformer (CFAT), outperformed previous state-of-the-art (SOTA) models in classic image super-resolution. In this paper, we propose a novel GAN-based framework by incorporating the CFAT model to effectively exploit the performance of transformers in real-world image super-resolution. In our proposed approach, we integrate a semantic-aware discriminator to reconstruct fine details more accurately and employ an adaptive degradation model to better simulate real-world degradations. Moreover, we introduce a new combination of loss functions by adding wavelet loss to loss functions of GAN-based models to better recover high-frequency details. Empirical results demonstrate that IG-CFAT significantly outperforms existing SOTA models in both quantitative and qualitative metrics. Our proposed model revolutionizes the field of real-world image super-resolution and demonstrates substantially better performance in recovering fine details and generating realistic textures. The introduction of IG-CFAT offers a robust and adaptable solution for real-world image super-resolution tasks.

Paper number 121:
Title: Optimal Sensor and Actuator Selection for Factored Markov Decision Processes: Complexity, Approximability and Algorithms
Authors: Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram
Abstract: Factored Markov Decision Processes (fMDPs) are a class of Markov Decision Processes (MDPs) in which the states (and actions) can be factored into a set of state (and action) variables and can be encoded compactly using a factored representation. In this paper, we consider a setting where the state of the fMDP is not directly observable, and the agent relies on a set of potential sensors to gather information. Each sensor has a selection cost and the designer must select a subset of sensors under a limited budget. We formulate the problem of selecting a set of sensors for fMDPs (under a budget) to maximize the infinite-horizon discounted return provided by the optimal policy. We show the fundamental result that it is NP-hard to approximate this problem to within any non-trivial factor. Our inapproximability results for optimal sensor selection also extend to a general class of Partially Observable MDPs (POMDPs). We then study the dual problem of budgeted actuator selection (at design-time) to maximize the expected return under the optimal policy. Again, we show that it is NP-hard to approximate this problem to within any non-trivial factor. Furthermore, with explicit examples, we show the failure of greedy algorithms for both the sensor and actuator selection problems and provide insights into the factors that cause these problems to be challenging. Despite this, through extensive simulations, we show the practical effectiveness and near-optimal performance of the greedy algorithm for actuator and sensor selection in many real-world and randomly generated instances.

Paper number 122:
Title: Personalized Topology-Informed Localization of Standard 12-Lead ECG Electrode Placement from Incomplete Cardiac MRIs for Efficient Cardiac Digital Twins
Authors: Lei Li, Hannah Smith, Yilin Lyu, Julia Camps, Shuang Qian, Blanca Rodriguez, Abhirup Banerjee, Vicente Grau
Abstract: Cardiac digital twins (CDTs) offer personalized in-silico cardiac representations for the inference of multi-scale properties tied to cardiac mechanisms. The creation of CDTs requires precise information about the electrode position on the torso, especially for the personalized electrocardiogram (ECG) calibration. However, current studies commonly rely on additional acquisition of torso imaging and manual/semi-automatic methods for ECG electrode localization. In this study, we propose a novel and efficient topology-informed model to fully automatically extract personalized ECG standard electrode locations from 2D clinically standard cardiac MRIs. Specifically, we obtain the sparse torso contours from the cardiac MRIs and then localize the standard electrodes of 12-lead ECG from the contours. Cardiac MRIs aim at imaging of the heart instead of the torso, leading to incomplete torso geometry within the imaging. To tackle the missing topology, we incorporate the electrodes as a subset of the keypoints, which can be explicitly aligned with the 3D torso topology. The experimental results demonstrate that the proposed model outperforms the time-consuming conventional model projection-based method in terms of accuracy (Euclidean distance: $1.24 \pm 0.293$ cm vs. $1.48 \pm 0.362$ cm) and efficiency ($2$~s vs. $30$-$35$~min). We further demonstrate the effectiveness of using the detected electrodes for in-silico ECG simulation, highlighting their potential for creating accurate and efficient CDT models. The code is available at this https URL.

Paper number 123:
Title: Optimal Joint Radar and Communication User Association in Cell-Free mMIMO Systems
Authors: Ahmed Naeem, El Mehdi Amhoud, HÃ¼seyin Arslan
Abstract: The cell-free massive multiple-input multiple-output (CF-mMIMO) systems are crucial for 6G development due to their high spectral efficiency and uniform user-experienced data rates. A key aspect of CF-mMIMO is user association (UA) and optimal cluster formation. Traditional methods focusing solely on communication-related metrics fall short in this context, as sensing is becoming integral to 6G. This study delves into a framework for joint radar and communication (JRC) in CF-mMIMO systems and investigates JRC-based UA techniques. We propose a novel method to optimize UA, enhancing both communication spectral efficiency and sensing accuracy. Existing literature has not explored this dual requirement integration for UA. Our proposed two-step scheme optimizes UA clusters for both communication and sensing. The first step involves selecting access points (APs) based on channel quality, followed by a second step that further refines the selection by choosing APs from the initial group that are also optimal for sensing. We utilize the signal-clutter plus noise ratio to exclude APs with clutter in front of the user equipment (UE) and the AP view angle, ensuring that radar echoes are received only from the specific UE, not the surrounding clutter. Theoretical analysis and simulations demonstrate that the same APs optimized for communication are not necessarily optimal for sensing, highlighting the need for schemes that incorporate sensing requirements in UA. The results show the effectiveness of the proposed method, showing its potential to improve CF-mMIMO system performance in JRC scenarios.

Paper number 124:
Title: WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling
Authors: Shengpeng Ji, Ziyue Jiang, Wen Wang, Yifu Chen, Minghui Fang, Jialong Zuo, Qian Yang, Xize Cheng, Zehan Wang, Ruiqi Li, Ziang Zhang, Xiaoda Yang, Rongjie Huang, Yidi Jiang, Qian Chen, Siqi Zheng, Zhou Zhao
Abstract: Language models have been effectively applied to modeling natural signals, such as images, video, speech, and audio. A crucial component of these models is the codec tokenizer, which compresses high-dimensional natural signals into lower-dimensional discrete tokens. In this paper, we introduce WavTokenizer, which offers several advantages over previous SOTA acoustic codec models in the audio domain: 1)extreme compression. By compressing the layers of quantizers and the temporal dimension of the discrete codec, one-second audio of 24kHz sampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved subjective quality. Despite the reduced number of tokens, WavTokenizer achieves state-of-the-art reconstruction quality with outstanding UTMOS scores and inherently contains richer semantic information. Specifically, we achieve these results by designing a broader VQ space, extended contextual windows, and improved attention networks, as well as introducing a powerful multi-scale discriminator and an inverse Fourier transform structure. We conducted extensive reconstruction experiments in the domains of speech, audio, and music. WavTokenizer exhibited strong performance across various objective and subjective metrics compared to state-of-the-art models. We also tested semantic information, VQ utilization, and adaptability to generative models. Comprehensive ablation studies confirm the necessity of each module in WavTokenizer. The related code, demos, and pre-trained models are available at this https URL.

Paper number 125:
Title: Imaging foundation model for universal enhancement of non-ideal measurement CT
Authors: Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Shangwen Yang, Yuan Gao, Chenyu You, Ge Wang, Yang Chen, Shuo Li
Abstract: Non-ideal measurement computed tomography (NICT) employs suboptimal imaging protocols to expand CT applications. However, the resulting trade-offs degrade image quality, limiting clinical acceptability. Although deep learning methods have been used to enhance NICT images, their reliance on large training datasets and limited generalizability across diverse settings hinder practical use. We propose the multi-scale integrated Transformer AMPlifier (TAMP), the first imaging foundation model for universal NICT enhancement. Pre-trained on 10.8 million physics-driven simulated NICT images, TAMP generalizes effectively across various NICT settings, defect degrees, and body regions. Moreover, a parameter-efficient fine-tuning strategy enables TAMP to adapt to specific clinical scenarios using only few slices. Extensive experiments, including radiologists and real-world validations, demonstrate that TAMP consistently improves image quality and clinical acceptability, underscoring its significant potential to advance CT imaging and broaden NICT applications in clinical practice.

Paper number 126:
Title: Optimal Distribution System Restoration with Tractable Modeling of Decision-Dependent Interruption Cost and Cold Load Pickup
Authors: Wei Wang, Minwu Chen, Hongbin Wang, Gaoqiang Peng, Hongzhou Chen
Abstract: Developing optimized restoration strategies for power distribution systems (PDSs) is essential to meet the pressing demand for enhanced resilience. Prior knowledge of customer interruption cost (CIC) and load restoration behaviors, particularly cold load pickup (CLPU), is crucial for guiding effective restoration; however, both are reciprocally affected by the realized customer interruption duration (CID), making them decision-dependent and challenging to model especially given the limited understanding of underlying physical mechanisms. This paper presents a novel approach by constructing tractable models to capture the varying patterns of CIC and CLPU with CID - patterns which can be derived from limited data and reflect observed surface-level correlations rather than underlying mechanisms, thereby enabling practical surrogate modeling of these decision-dependencies. Specifically, quadratic functions are used to model the increasing rate of CIC with CID based on data fitting. Several defining characteristics of CLPU are extracted, each modeled in a piecewise linear form relative to CID, and the actual restored load accounting for CLPU is subsequently retrieved. Building on these models, a PDS restoration optimization model is constructed, incorporating mobile energy storage systems (MESSs) and network reconfiguration. Case studies validate our approach and also highlight MESS's unique potential to accelerate CLPU-related restoration.

Paper number 127:
Title: Squint-Aware Synesthesia of Machine (SoM)-Driven Analog Precoder Optimization for Enhanced ISAC Performance in Sub-THz Systems
Authors: Zonghui Yang, Shijian Gao, Xiang Cheng
Abstract: The potential benefits of integrated sensing and communication (ISAC) are anticipated to play a significant role in future sub-terahertz (sub-THz) mobile information networks. However, the beam squint effect is pronounced in sub-THz systems, expanding coverage areas while severely degrading the communication performance. Existing analog precoder designs struggle to balance both functionalities in the presence of beam squint, limiting the performance gain achievable through ISAC. To address this challenge, we propose two squint-aware analog precoding schemes for sub-THz systems that proactively regulate the correlation between communication and sensing channels, leveraging the inherent degrees of freedom in the hardware architecture to enhance ISAC performance. We first introduce a squint-aware optimization-based analog precoder design approach (SA-Opt). Inspired by the synesthesia of machine (SoM), we further develop an unsupervised learning-assisted complex-valued squint-aware network (CSP-Net) to reduce complexity based on both communication and sensing channel data, tailoring its architecture to the specific data and task characteristics. The effectiveness of the proposed schemes is demonstrated through simulations.

Paper number 128:
Title: Efficient Transmission of Radiomaps via Physics-Enhanced Semantic Communications
Authors: Yueling Zhou, Achintha Wijesinghe, Yue Wang, Songyang Zhang, Zhipeng Cai
Abstract: Enriching information of spectrum coverage, radiomap plays an important role in many wireless communication applications, such as resource allocation and network optimization. To enable real-time, distributed spectrum management, particularly in the scenarios with unstable and dynamic environments, the efficient transmission of spectrum coverage information for radiomaps from edge devices to the central server emerges as a critical problem. In this work, we propose an innovative physics-enhanced semantic communication framework tailored for efficient radiomap transmission based on generative learning models. Specifically, instead of bit-wise message passing, we only transmit the key "semantics" in radiomaps characterized by the radio propagation behavior and surrounding environments, where semantic compression schemes are utilized to reduce the communication overhead. Incorporating the novel concepts of Radio Depth Maps, the radiomaps are reconstructed from the delivered semantic information backboned on the conditional generative adversarial networks. Our framework is further extended to facilitate its implementation in the scenarios of multi-user edge computing, by integrating with federated learning for collaborative model training while preserving the data privacy. Experimental results show that our approach achieves high accuracy in radio coverage information recovery at ultra-high bandwidth efficiency, which has great potentials in many wireless-generated data transmission applications.

Paper number 129:
Title: RIS-Aided Monitoring With Cooperative Jamming: Design and Performance Analysis
Authors: Shuying Lin, Yulong Zou, Zhiyang Li, Tong Wu, Eduard E. Bahingayi, Le-Nam Tran
Abstract: We investigate a reconfigurable intelligent surface (RIS) aided wireless surveillance system. In this system, a monitor not only receives signal from suspicious transmitter via a RIS-enhanced legitimate surveillance (LS) link but also simultaneously takes control of multiple jammers to degrade the quality of received suspicious signal. Under this setup, to enhance monitoring performance requires improvements of both the received signal quality at the monitor and the cooperative jamming (CJ). Considering that the surveillance system is aided by one RIS, whose phase shift optimization involves both channel state information (CSI) of the LS and CJ links, we utilize partial CSI to alleviate the CSI acquisition burden in our design. We propose two RIS-aided monitoring schemes with optimal jammer selection (OJS), and derive their closed-form expressions of surveillance success probability (SSP), respectively. Furthermore, we consider RIS-aided monitoring schemes with random jammer selection as corresponding benchmarks. Thereafter, we analyze special cases where the jammers are using power control to avoid being found, making it appears like passive monitoring. Also, the effect of RIS is highlighted by considering asymptotically large number of RIS elements. Numerical results verify that the proposed OJS strategy further enhances the RIS-aided monitoring performance compared with non-jammer-selection RISLR and RISCR schemes, where the superiority comes at the cost of CSI knowledge and becomes marginal in the region of high jamming power. In addition, the RISLO shows surveillance performance advantage overRISCOwhen the suspicious power is low or when the number of RIS elements is large.

Paper number 130:
Title: The Adaptive $Ï$-Lasso: Robustness and Oracle Properties
Authors: Emadaldin Mozafari-Majd, Visa Koivunen
Abstract: This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional datasets subject to gross contamination in the response variables and covariates. The resulting estimator, termed adaptive $\tau$-Lasso, is robust to outliers and high-leverage points. It also incorporates an adaptive $\ell_1$-norm penalty term, which enables the selection of relevant variables and reduces the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property, ensuring both variable-selection consistency and asymptotic normality. Asymptotic normality applies only to the entries of the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We characterize its robustness by establishing the finite-sample breakdown point and the influence function. We carry out extensive simulations and observe that the class of $\tau$-Lasso estimators exhibits robustness and reliable performance in both contaminated and uncontaminated data settings. We also validate our theoretical findings on robustness properties through simulations. In the face of outliers and high-leverage points, the adaptive $\tau$-Lasso and $\tau$-Lasso estimators achieve the best performance or match the best performances of competing regularized estimators, with minimal or no loss in terms of prediction and variable selection accuracy for almost all scenarios considered in this study. Therefore, the adaptive $\tau$-Lasso and $\tau$-Lasso estimators provide attractive tools for a variety of sparse linear regression problems, particularly in high-dimensional settings and when the data is contaminated by outliers and high-leverage points.

Paper number 131:
Title: T3D: Advancing 3D Medical Vision-Language Pre-training by Learning Multi-View Visual Consistency
Authors: Che Liu, Cheng Ouyang, Yinda Chen, Cesar CÃ©sar QuilodrÃ¡n-Casas, Lei Ma, Jie Fu, Yike Guo, Anand Shah, Wenjia Bai, Rossella Arcucci
Abstract: While 3D visual self-supervised learning (vSSL) shows promising results in capturing visual representations, it overlooks the clinical knowledge from radiology reports. Meanwhile, 3D medical vision-language pre-training (MedVLP) remains underexplored due to the lack of a large-scale, publicly available 3D medical image-report dataset. To bridge this gap, we introduce **CT-3DVLP**, the first and largest **public** 3D volume-report dataset, establishing a comprehensive benchmark for 3D MedVLP research. Meanwhile, we propose the **T3D** framework, which enhances 3D MedVLP beyond naive CLIP-style alignment that directly pairs volumes with reports but neglects local visual representations. Instead, we introduce **Text-informed Multi-view Alignment (TMA)**, a novel approach that clusters volumetric data while enforcing consistency across different views of the same volume-report pair. TMA integrates textual features into fine-grained visual representations, ensuring contextual coherence across views. We evaluate T3D across multiple downstream tasks in both unimodal and cross-modal settings, including zero-shot and fine-tuned classification, cross-modal retrieval, report generation, and semantic segmentation. Our results show that T3D consistently outperforms existing vSSL and multimodal methods, demonstrating superior zero-shot and fine-tuning capabilities and setting a new benchmark for 3D medical image understanding.

Paper number 132:
Title: As Good As A Coin Toss: Human detection of AI-generated images, videos, audio, and audiovisual stimuli
Authors: Di Cooke, Abigail Edwards, Sophia Barkoff, Kathryn Kelly
Abstract: Despite advancements in technology led synthetic media authentication and recent government efforts to address the threats posed by maliciously employed synthetic content via the mechanisms of law or through more public education, one of the current principal defenses against weaponized synthetic media continues to be the ability of the targeted individual to visually or auditorily recognize AI-generated content when they encounter it. However, as the realism of synthetic media continues to rapidly improve, it is vital to have an accurate understanding of just how susceptible people currently are to potentially being misled by convincing but false AI generated content. We conducted a perceptual study with 1276 participants to assess how capable people were at distinguishing between authentic and synthetic images, audio, video, and audiovisual media. We find that on average, people struggled to distinguish between synthetic and authentic media, with the mean detection performance close to a chance level performance of 50%. We also find that accuracy rates worsen when the stimuli contain any degree of synthetic content, features foreign languages, and the media type is a single modality. People are also less accurate at identifying synthetic images when they feature human faces, and when audiovisual stimuli have heterogeneous authenticity. Finally, we find that higher degrees of prior knowledgeability about synthetic media does not significantly impact detection accuracy rates, but age does, with older individuals performing worse than their younger counterparts. Collectively, these results highlight that it is no longer feasible to rely on the perceptual capabilities of people to protect themselves against the growing threat of weaponized synthetic media, and that the need for alternative countermeasures is more critical than ever before.

Paper number 133:
Title: $\mathsf{QuITO}$ $\textsf{v.2}$: Trajectory Optimization with Uniform Error Guarantees under Path Constraints
Authors: Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a direct multiple shooting technique -- $\mathsf{QuITO}$ $\textsf{v.2}$ (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties, along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce, and make freely available, a new software package based on $\mathsf{QuITO}$ $\textsf{v.2}$ along with all its functionalities for completeness. The package is available at: this https URL.

Paper number 134:
Title: MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation
Authors: Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji
Abstract: This study aims to construct an audio-video generative model with minimal computational cost by leveraging pre-trained single-modal generative models for audio and video. To achieve this, we propose a novel method that guides single-modal models to cooperatively generate well-aligned samples across modalities. Specifically, given two pre-trained base diffusion models, we train a lightweight joint guidance module to adjust scores separately estimated by the base models to match the score of joint distribution over audio and video. We show that this guidance can be computed using the gradient of the optimal discriminator, which distinguishes real audio-video pairs from fake ones independently generated by the base models. Based on this analysis, we construct a joint guidance module by training this discriminator. Additionally, we adopt a loss function to stabilize the discriminator's gradient and make it work as a noise estimator, as in standard diffusion models. Empirical evaluations on several benchmark datasets demonstrate that our method improves both single-modal fidelity and multimodal alignment with relatively few parameters. The code is available at: this https URL.

Paper number 135:
Title: PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance
Authors: Qijun Gan, Song Wang, Shengtao Wu, Jianke Zhu
Abstract: Recently, artificial intelligence techniques for education have been received increasing attentions, while it still remains an open problem to design the effective music instrument instructing systems. Although key presses can be directly derived from sheet music, the transitional movements among key presses require more extensive guidance in piano performance. In this work, we construct a piano-hand motion generation benchmark to guide hand movements and fingerings for piano playing. To this end, we collect an annotated dataset, PianoMotion10M, consisting of 116 hours of piano playing videos from a bird's-eye view with 10 million annotated hand poses. We also introduce a powerful baseline model that generates hand motions from piano audios through a position predictor and a position-guided gesture generator. Furthermore, a series of evaluation metrics are designed to assess the performance of the baseline model, including motion similarity, smoothness, positional accuracy of left and right hands, and overall fidelity of movement distribution. Despite that piano key presses with respect to music scores or audios are already accessible, PianoMotion10M aims to provide guidance on piano fingering for instruction purposes. The source code and dataset can be accessed at this https URL.

Paper number 136:
Title: Learning System Dynamics without Forgetting
Authors: Xikun Zhang, Dongjin Song, Yushan Jiang, Yixin Chen, Dacheng Tao
Abstract: Observation-based trajectory prediction for systems with unknown dynamics is essential in fields such as physics and biology. Most existing approaches are limited to learning within a single system with fixed dynamics patterns. However, many real-world applications require learning across systems with evolving dynamics patterns, a challenge that has been largely overlooked. To address this, we systematically investigate the problem of Continual Dynamics Learning (CDL), examining task configurations and evaluating the applicability of existing techniques, while identifying key challenges. In response, we propose the Mode-switching Graph ODE (MS-GODE) model, which integrates the strengths LG-ODE and sub-network learning with a mode-switching module, enabling efficient learning over varying dynamics. Moreover, we construct a novel benchmark of biological dynamic systems for CDL, Bio-CDL, featuring diverse systems with disparate dynamics and significantly enriching the research field of machine learning for dynamic systems. Our code available at this https URL.

Paper number 137:
Title: Sewer Image Super-Resolution with Depth Priors and Its Lightweight Network
Authors: Gang Pan, Chen Wang, Zhijie Sui, Shuai Guo, Yaozhi Lv, Honglie Li, Di Sun, Zixia Xia
Abstract: The Quick-view (QV) technique serves as a primary method for detecting defects within sewerage systems. However, the effectiveness of QV is impeded by the limited visual range of its hardware, resulting in suboptimal image quality for distant portions of the sewer network. Image super-resolution is an effective way to improve image quality and has been applied in a variety of scenes. However, research on super-resolution for sewer images remains considerably unexplored. In response, this study leverages the inherent depth relationships present within QV images and introduces a novel Depth-guided, Reference-based Super-Resolution framework denoted as DSRNet. It comprises two core components: a depth extraction module and a depth information matching module (DMM). DSRNet utilizes the adjacent frames of the low-resolution image as reference images and helps them recover texture information based on the correlation. By combining these modules, the integration of depth priors significantly enhances both visual quality and performance benchmarks. Besides, in pursuit of computational efficiency and compactness, a super-resolution knowledge distillation model based on an attention mechanism is introduced. This mechanism facilitates the acquisition of feature similarity between a more complex teacher model and a streamlined student model, with the latter being a lightweight version of DSRNet. Experimental results demonstrate that DSRNet significantly improves PSNR and SSIM compared with other methods. This study also conducts experiments on sewer defect semantic segmentation, object detection, and classification on the Pipe dataset and Sewer-ML dataset. Experiments show that the method can improve the performance of low-resolution sewer images in these tasks.

Paper number 138:
Title: SONICS: Synthetic Or Not -- Identifying Counterfeit Songs
Authors: Md Awsafur Rahman, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Bishmoy Paul, Shaikh Anowarul Fattah
Abstract: The recent surge in AI-generated songs presents exciting possibilities and challenges. These innovations necessitate the ability to distinguish between human-composed and synthetic songs to safeguard artistic integrity and protect human musical artistry. Existing research and datasets in fake song detection only focus on singing voice deepfake detection (SVDD), where the vocals are AI-generated but the instrumental music is sourced from real songs. However, these approaches are inadequate for detecting contemporary end-to-end artificial songs where all components (vocals, music, lyrics, and style) could be AI-generated. Additionally, existing datasets lack music-lyrics diversity, long-duration songs, and open-access fake songs. To address these gaps, we introduce SONICS, a novel dataset for end-to-end Synthetic Song Detection (SSD), comprising over 97k songs (4,751 hours) with over 49k synthetic songs from popular platforms like Suno and Udio. Furthermore, we highlight the importance of modeling long-range temporal dependencies in songs for effective authenticity detection, an aspect entirely overlooked in existing methods. To utilize long-range patterns, we introduce SpecTTTra, a novel architecture that significantly improves time and memory efficiency over conventional CNN and Transformer-based models. For long songs, our top-performing variant outperforms ViT by 8% in F1 score, is 38% faster, and uses 26% less memory, while also surpassing ConvNeXt with a 1% F1 score gain, 20% speed boost, and 67% memory reduction.

Paper number 139:
Title: Peer-to-Peer Learning Dynamics of Wide Neural Networks
Authors: Shreyas Chaudhari, Srinivasa Pranav, Emile Anand, JosÃ© M. F. Moura
Abstract: Peer-to-peer learning is an increasingly popular framework that enables beyond-5G distributed edge devices to collaboratively train deep neural networks in a privacy-preserving manner without the aid of a central server. Neural network training algorithms for emerging environments, e.g., smart cities, have many design considerations that are difficult to tune in deployment settings -- such as neural network architectures and hyperparameters. This presents a critical need for characterizing the training dynamics of distributed optimization algorithms used to train highly nonconvex neural networks in peer-to-peer learning environments. In this work, we provide an explicit characterization of the learning dynamics of wide neural networks trained using popular distributed gradient descent (DGD) algorithms. Our results leverage both recent advancements in neural tangent kernel (NTK) theory and extensive previous work on distributed learning and consensus. We validate our analytical results by accurately predicting the parameter and error dynamics of wide neural networks trained for classification tasks.

Paper number 140:
Title: Reverb: Open-Source ASR and Diarization from Rev
Authors: Nishchal Bhandari, Danny Chen, Miguel Ãngel del RÃ­o FernÃ¡ndez, Natalie Delworth, Jennifer Drexler Fox, MigÃ¼el JettÃ©, Quinten McNamara, Corey Miller, OndÅej NovotnÃ½, JÃ¡n Profant, Nan Qin, Martin Ratajczak, Jean-Philippe Robichaud
Abstract: Today, we are open-sourcing our core speech recognition and diarization models for non-commercial use. We are releasing both a full production pipeline for developers as well as pared-down research models for experimentation. Rev hopes that these releases will spur research and innovation in the fast-moving domain of voice technology. The speech recognition models released today outperform all existing open source speech recognition models across a variety of long-form speech recognition domains.

Paper number 141:
Title: Epsilon-VAE: Denoising as Visual Decoding
Authors: Long Zhao, Sanghyun Woo, Ziyu Wan, Yandong Li, Han Zhang, Boqing Gong, Hartwig Adam, Xuhui Jia, Ting Liu
Abstract: In generative modeling, tokenization simplifies complex data into compact, structured representations, creating a more efficient, learnable space. For high-dimensional visual data, it reduces redundancy and emphasizes key features for high-quality generation. Current visual tokenization methods rely on a traditional autoencoder framework, where the encoder compresses data into latent representations, and the decoder reconstructs the original input. In this work, we offer a new perspective by proposing denoising as decoding, shifting from single-step reconstruction to iterative refinement. Specifically, we replace the decoder with a diffusion process that iteratively refines noise to recover the original image, guided by the latents provided by the encoder. We evaluate our approach by assessing both reconstruction (rFID) and generation quality (FID), comparing it to state-of-the-art autoencoding approaches. By adopting iterative reconstruction through diffusion, our autoencoder, namely $\epsilon$-VAE, achieves high reconstruction quality, which in turn enhances downstream generation quality by 22% and provides 2.3$\times$ inference speedup. We hope this work offers new insights into integrating iterative generation and autoencoding for improved compression and generation.

Paper number 142:
Title: Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation
Authors: Peiwen Sun, Sitong Cheng, Xiangtai Li, Zhen Ye, Huadai Liu, Honggang Zhang, Wei Xue, Yike Guo
Abstract: Recently, diffusion models have achieved great success in mono-channel audio generation. However, when it comes to stereo audio generation, the soundscapes often have a complex scene of multiple objects and directions. Controlling stereo audio with spatial contexts remains challenging due to high data costs and unstable generative models. To the best of our knowledge, this work represents the first attempt to address these issues. We first construct a large-scale, simulation-based, and GPT-assisted dataset, BEWO-1M, with abundant soundscapes and descriptions even including moving and multiple sources. Beyond text modality, we have also acquired a set of images and rationally paired stereo audios through retrieval to advance multimodal generation. Existing audio generation models tend to generate rather random and indistinct spatial audio. To provide accurate guidance for Latent Diffusion Models, we introduce the SpatialSonic model utilizing spatial-aware encoders and azimuth state matrices to reveal reasonable spatial guidance. By leveraging spatial guidance, our model not only achieves the objective of generating immersive and controllable spatial audio from text but also extends to other modalities as the pioneer attempt. Finally, under fair settings, we conduct subjective and objective evaluations on simulated and real-world data to compare our approach with prevailing methods. The results demonstrate the effectiveness of our method, highlighting its capability to generate spatial audio that adheres to physical rules.

Paper number 143:
Title: LLM-Enhanced Dialogue Management for Full-Duplex Spoken Dialogue Systems
Authors: Hao Zhang, Weiwei Li, Rilin Chen, Vinay Kothapally, Meng Yu, Dong Yu
Abstract: Achieving full-duplex communication in spoken dialogue systems (SDS) requires real-time coordination between listening, speaking, and thinking. This paper proposes a semantic voice activity detection (VAD) module as a dialogue manager (DM) to efficiently manage turn-taking in full-duplex SDS. Implemented as a lightweight (0.5B) LLM fine-tuned on full-duplex conversation data, the semantic VAD predicts four control tokens to regulate turn-switching and turn-keeping, distinguishing between intentional and unintentional barge-ins while detecting query completion for handling user pauses and hesitations. By processing input speech in short intervals, the semantic VAD enables real-time decision-making, while the core dialogue engine (CDE) is only activated for response generation, reducing computational overhead. This design allows independent DM optimization without retraining the CDE, balancing interaction accuracy and inference efficiency for scalable, next-generation full-duplex SDS.

Paper number 144:
Title: A Concise Lyapunov Analysis of Nesterov's Accelerated Gradient Method
Authors: Jun Liu
Abstract: Convergence analysis of Nesterov's accelerated gradient method has attracted significant attention over the past decades. While extensive work has explored its theoretical properties and elucidated the intuition behind its acceleration, a simple and direct proof of its convergence rates is still lacking. We provide a concise Lyapunov analysis of the convergence rates of Nesterov's accelerated gradient method for both general convex and strongly convex functions.
    