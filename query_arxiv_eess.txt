
    Selection criteria:
    Papers that are related to power and energy systems or electricity markets.

    Below is a list of papers. For each paper, indicate if it matches the criteria. 
    Respond with a list of the numbers of the matching papers.
    Only write the numbers separated by commas. 
    You should not respond with numbers that are not in the paper list. 

    Paper number 1:
Title: Data-Driven Deep MIMO Detection:Network Architectures and Generalization Analysis
Authors: Yongwei Yi, Xinping Yi, Wenjin Wang, Xiao Li, Shi Jin
Abstract: In practical Multiuser Multiple-Input Multiple-Output (MU-MIMO) systems, symbol detection remains challenging due to severe inter-user interference and sensitivity to Channel State Information (CSI) uncertainty. In contrast to the mostly studied belief propagation-type model-driven methods, which incur high computational complexity, Soft Interference Cancellation (SIC) strikes a good balance between performance and complexity. To further address CSI mismatch and nonlinear effects, the recently proposed data-driven deep neural receivers, such as DeepSIC, leverage the advantages of deep neural networks for interference cancellation and symbol detection, demonstrating strong empirical performance. However, there is still a lack of theoretical underpinning for why and to what extent DeepSIC could generalize with the number of training samples. This paper proposes inspecting the fully data-driven DeepSIC detection within a Network-of-MLPs architecture, which is composed of multiple interconnected MLPs via outer and inner Directed Acyclic Graphs (DAGs). Within such an architecture, DeepSIC can be upgraded as a graph-based message-passing process using Graph Neural Networks (GNNs), termed GNNSIC, with shared model parameters across users and iterations. Notably, GNNSIC achieves excellent expressivity comparable to DeepSIC with substantially fewer trainable parameters, resulting in improved sample efficiency and enhanced user generalization. By conducting a norm-based generalization analysis using Rademacher complexity, we reveal that an exponential dependence on the number of iterations for DeepSIC can be eliminated in GNNSIC due to parameter sharing. Simulation results demonstrate that GNNSIC attains comparable or improved Symbol Error Rate (SER) performance to DeepSIC with significantly fewer parameters and training samples.

Paper number 2:
Title: AINet: Anchor Instances Learning for Regional Heterogeneity in Whole Slide Image
Authors: Tingting Zheng, Hongxun Yao, Kui Jiang, Sicheng Zhao, Yi Xiao
Abstract: Recent advances in multi-instance learning (MIL) have witnessed impressive performance in whole slide image (WSI) analysis. However, the inherent sparsity of tumors and their morphological diversity lead to obvious heterogeneity across regions, posing significant challenges in aggregating high-quality and discriminative representations. To address this, we introduce a novel concept of anchor instance (AI), a compact subset of instances that are representative within their regions (local) and discriminative at the bag (global) level. These AIs act as semantic references to guide interactions across regions, correcting non-discriminative patterns while preserving regional diversity. Specifically, we propose a dual-level anchor mining (DAM) module to \textbf{select} AIs from massive instances, where the most informative AI in each region is extracted by assessing its similarity to both local and global embeddings. Furthermore, to ensure completeness and diversity, we devise an anchor-guided region correction (ARC) module that explores the complementary information from all regions to \textbf{correct} each regional representation. Building upon DAM and ARC, we develop a concise yet effective framework, AINet, which employs a simple predictor and surpasses state-of-the-art methods with substantially fewer FLOPs and parameters. Moreover, both DAM and ARC are modular and can be seamlessly integrated into existing MIL frameworks, consistently improving their performance.

Paper number 3:
Title: Targeted T2-FLAIR Dropout Training Improves Robustness of nnU-Net Glioblastoma Segmentation to Missing T2-FLAIR
Authors: Marco Öchsner, Lena Kaiser, Robert Stahl, Nathalie L. Albert, Thomas Liebig, Robert Forbrig, Jonas Reis
Abstract: Purpose: To determine whether targeted T2 fluid-attenuated inversion recovery (T2-FLAIR) dropout training improves glioblastoma MRI tumor segmentation robustness to missing T2-FLAIR without degrading performance when T2-FLAIR is available. Materials and Methods: This retrospective multi-dataset study developed nnU-Net models on BraTS 2021 (n=848) and externally tested them on UPenn-GBM glioblastoma MRI (n=403; 2006-2018; age 18-89 years; 60% male). Models were trained with no dropout or targeted T2-FLAIR dropout (probability rate r=0.35 or 0.50) by replacing only the T2-FLAIR channel with zeros. Inference used T2-FLAIR-present and T2-FLAIR-absent scenarios (T2-FLAIR set to zero). The primary endpoint was Dice similarity coefficient (DSC); secondary endpoints were 95th percentile Hausdorff distance and Bland-Altman whole-tumor volume bias. Equivalence was assessed with two one-sided tests using +/-1.5 DSC percentage points, and noninferiority versus HD-GLIO used a -1.5-point margin. Results: With T2-FLAIR present, median overall DSC was 94.8% (interquartile range, 90.0%-97.1%) with dropout and 95.0% (interquartile range, 90.3%-97.1%) without dropout (equivalence supported, p<0.001). With T2-FLAIR absent, median overall DSC improved from 81.0% (interquartile range, 75.1%-86.4%) without dropout to 93.4% (interquartile range, 89.1%-96.2%) with dropout (r=0.35); edema DSC improved from 14.0% to 87.0%, edema 95th percentile Hausdorff distance improved from 22.44 mm to 2.45 mm, and whole-tumor volume bias improved from -45.6 mL to 0.83 mL. Dropout was noninferior to HD-GLIO under T2-FLAIR-present (all p<0.001). Conclusion: Targeted T2-FLAIR dropout preserved segmentation performance when T2-FLAIR was available and reduced segmentation error and whole-tumor volume bias when T2-FLAIR was absent.

Paper number 4:
Title: The Sim-to-Real Gap in MRS Quantification: A Systematic Deep Learning Validation for GABA
Authors: Zien Ma, S. M. Shermer, Oktay Karakuş, Frank C. Langbein
Abstract: Magnetic resonance spectroscopy (MRS) is used to quantify metabolites in vivo and estimate biomarkers for conditions ranging from neurological disorders to cancers. Quantifying low-concentration metabolites such as GABA ($\gamma$-aminobutyric acid) is challenging due to low signal-to-noise ratio (SNR) and spectral overlap. We investigate and validate deep learning for quantifying complex, low-SNR, overlapping signals from MEGA-PRESS spectra, devise a convolutional neural network (CNN) and a Y-shaped autoencoder (YAE), and select the best models via Bayesian optimisation on 10,000 simulated spectra from slice-profile-aware MEGA-PRESS simulations. The selected models are trained on 100,000 simulated spectra. We validate their performance on 144 spectra from 112 experimental phantoms containing five metabolites of interest (GABA, Glu, Gln, NAA, Cr) with known ground truth concentrations across solution and gel series acquired at 3 T under varied bandwidths and implementations. These models are further assessed against the widely used LCModel quantification tool. On simulations, both models achieve near-perfect agreement (small MAEs; regression slopes $\approx 1.00$, $R^2 \approx 1.00$). On experimental phantom data, errors initially increased substantially. However, modelling variable linewidths in the training data significantly reduced this gap. The best augmented deep learning models achieved a mean MAE for GABA over all phantom spectra of 0.151 (YAE) and 0.160 (FCNN) in max-normalised relative concentrations, outperforming the conventional baseline LCModel (0.220). A sim-to-real gap remains, but physics-informed data augmentation substantially reduced it. Phantom ground truth is needed to judge whether a method will perform reliably on real data.

Paper number 5:
Title: Fast Spectrogram Event Extraction via Offline Self-Supervised Learning: From Fusion Diagnostics to Bioacoustics
Authors: Nathaniel Chen, Kouroche Bouchiat, Peter Steiner, Andrew Rothstein, David Smith, Max Austin, Mike van Zeeland, Azarakhsh Jalalvand, Egemen Kolemen
Abstract: Next-generation fusion facilities like ITER face a "data deluge," generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a "signals-first" self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in this https URL.

Paper number 6:
Title: Cooperative ISAC for Joint Localization and Velocity Estimation in Cell-Free MIMO Systems
Authors: Zihuan Wang, Vincent W.S. Wong, Robert Schober
Abstract: In this paper, we explore a cooperative integrated sensing and communication (ISAC) framework that utilizes orthogonal frequency division multiplexing (OFDM) waveforms. Under the control of a central processing unit (CPU), multiple access points (APs) collaboratively perform multistatic sensing while providing communication service in a cell-free multiple-input multiple-output (MIMO) system. Achieving high sensing accuracy requires the collection of global sensing information at the CPU, which can lead to significant fronthaul signaling overhead due to the feedback of the sensing signals from each AP. To tackle this issue, we propose a collaborative processing scheme in which the APs locally compress and quantize the received sensing signals before forwarding them to the CPU. The CPU then aggregates the information from all APs to estimate the location and velocity of the targets. We develop a distributed vector-quantized variational autoencoder (D-VQVAE) to enable an end-to-end implementation of this scheme. D-VQVAE consists of distributed encoders at the APs to locally encode the received sensing signals, codebooks for quantizing the encoded results, and a decoder at the CPU for location and velocity estimation. It effectively reduces the amount of data transmitted from each AP to the CPU while maintaining a high sensing accuracy. We employ a collaborative learning-assisted scheme to train D-VQVAE in an end-to-end manner. Simulation results show that the proposed D-VQVAE network outperforms the baseline schemes in sensing accuracy and reduces fronthaul signaling overhead by 99% when compared with the centralized sensing approach.

Paper number 7:
Title: Waveform Design for Partial-Time Superimposed ISAC Systems
Authors: Xi Nan, Rugui Yao, Ye Fan, Ruikang Zhong, Xiaoya Zuo, Theodoros A. Tsiftsis, Alexandros-Apostolos A. Boulogeorgos
Abstract: Nowadays, waveforms of integrated sensing and communication (ISAC) are almost based on conventional communication and sensing signal, which bounds both the communication and sensing performance. To deal with this issue, in this paper, a novel waveform design is presented for the partial-time superimposed (PTS) ISAC system. At the base station (BS), a parameter-adjustable linear frequency modulation (LFM) pulse signal and a continuous communication orthogonal frequency division multiplexing (OFDM) signal are employed to broadcast public information and perform sensing tasks, respectively, using a PTS scheme. Pulse compression gain enhances the system's long-range sensing capability, while OFDM ensures the system's high-speed data transmission capability. Meanwhile, the LFM signal is utilized as superimposed pilot for channel estimation, which has higher time-frequency resource utilization and stronger real-time performance compared to orthogonal pilots. We present an accurate parameter estimation method of multi-path sensing signal for reconstructing and interference cancellation in communication users. Additionally, a cyclic maximum likelihood method is introduced for channel estimation and the Cramer-Rao lower bound (CRLB) of channel estimation is derived. Simulations demonstrate the accuracy and robustness of the proposed parameter estimation algorithm as well as the improved channel estimation performance over traditional methods. The proposed waveform design method can achieve reliable data transmission and accurate target sensing.

Paper number 8:
Title: StochasticBarrier.jl: A Toolbox for Stochastic Barrier Function Synthesis
Authors: Rayan Mazouz, Frederik Baymler Mathiesen, Luca Laurenti, Morteza Lahijanian
Abstract: We present this http URL, an open-source Julia-based toolbox for generating Stochastic Barrier Functions (SBFs) for safety verification of discrete-time stochastic systems with additive Gaussian noise. this http URL certifies linear, polynomial, and piecewise affine (PWA) systems. The latter enables verification for a wide range of system dynamics, including general nonlinear types. The toolbox implements a Sum-of-Squares (SOS) optimization approach, as well as methods based on piecewise constant (PWC) functions. For SOS-based SBFs, this http URL leverages semi-definite programming solvers, while for PWC SBFs, it offers three engines: two using linear programming (LP) and one based on gradient descent (GD). Benchmarking this http URL against the state-of-the-art shows that the tool outperforms existing tools in computation time, safety probability bounds, and scalability across over 30 case studies. Compared to its closest competitor, this http URL is up to four orders of magnitude faster, achieves significant safety probability improvements, and supports higher-dimensional systems.

Paper number 9:
Title: IoT-Driven Building Energy Management Systems (BEMS) for Net Zero Energy Buildings: Concept, Integration and Future Directions
Authors: Haizum Hanim Ab Halim, Dalila Alias, Akmal Zaini Arsad, Lewis Tee Jen Looi, Rosdiadee Nordin, Denny Ng Kok Sum
Abstract: Construction and operating of buildings is one of the major contributors to global greenhouse emissions. With the inefficient usage of energy due to human behavior and manual operation, the energy consumption of buildings is further increased. These challenges highlight the need for improved Building Energy Management Systems (BEMS) integrated with Internet of Things (IoT) and data driven intelligence to enhance energy-efficiency in a building and contribute to Net-Zero Energy Buildings (NZEB) targets. This paper offers four keys contributions: i) a systematic review of IoT enabled BEMS including components, network architecture and functional capabilities, ii) an evaluation of real-world BEMS datasets to support Artificial Intelligence (AI) based predictive control, iii) an analysis of integration challenges related to interoperability, smart grids and net-zero energy strategies, and iv) a case study highlighting global best practices, performances outcomes, and lesson learned for scaling advanced BEMS solutions.

Paper number 10:
Title: Height-Dependent Spectrum Activity Measurements and Modeling: A Case Study with FM Radio Bands
Authors: Sung Joon Maeng, Amir Hossein Fahim Raouf, Ozgur Ozdemir, İsmail Güvenç, Mihail L. Sichitiu
Abstract: The increasing demand for wireless connectivity necessitates advanced spectrum modeling to enable efficient spectrum sharing for next-generation aerial communications. While traditional models often overlook vertical variations in signal behavior, this paper proposes a height-dependent propagation model using a helikite-mounted software-defined radio (SDR). We collected extensive measurement data across the 88 MHz to 6 GHz range in both urban and rural environments. As a case study to validate our methodology, we focus on the FM radio band, which allows us to use publicly available transmitter locations and transmit power levels to facilitate comparisons between analytical with measurement results. We identify a clear transition from non-line-of-sight (NLoS) to line-of-sight (LoS) regimes at a specific altitude threshold and propose an altitude-dependent path loss model that incorporates this transition. Our results demonstrate that the proposed model significantly outperforms the standard free space path loss (FSPL) model in complex urban topologies, providing a more accurate framework for altitude-aware spectrum prediction and management across emerging aerial wireless technologies and bands.

Paper number 11:
Title: Comparing Implicit Neural Representations and B-Splines for Continuous Function Fitting from Sparse Samples
Authors: Hongze Yu, Yun Jiang, Jeffrey A. Fessler
Abstract: Continuous signal representations are naturally suited for inverse problems, such as magnetic resonance imaging (MRI) and computed tomography, because the measurements depend on an underlying physically continuous signal. While classical methods rely on predefined analytical bases like B-splines, implicit neural representations (INRs) have emerged as a powerful alternative that use coordinate-based networks to parameterize continuous functions with implicitly defined bases. Despite their empirical success, direct comparisons of their intrinsic representation capabilities with conventional models remain limited. This preliminary empirical study compares a positional-encoded INR with a cubic B-spline model for continuous function fitting from sparse random samples, isolating the representation capacity difference by only using coefficient-domain Tikhonov regularization. Results demonstrate that, under oracle hyperparameter selection, the INR achieves a lower normalized root-mean-squared error, yielding sharper edge transitions and fewer oscillatory artifacts than the oracle-tuned B-spline model. Additionally, we show that a practical bilevel optimization framework for INR hyperparameter selection based on measurement data split effectively approximates oracle performance. These findings empirically support the superior representation capacity of INRs for sparse data fitting.

Paper number 12:
Title: Progressive Per-Branch Depth Optimization for DEFOM-Stereo and SAM3 Joint Analysis in UAV Forestry Applications
Authors: Yida Lin, Bing Xue, Mengjie Zhang, Sam Schofield, Richard Green
Abstract: Accurate per-branch 3D reconstruction is a prerequisite for autonomous UAV-based tree pruning; however, dense disparity maps from modern stereo matchers often remain too noisy for individual branch analysis in complex forest canopies. This paper introduces a progressive pipeline integrating DEFOM-Stereo foundation-model disparity estimation, SAM3 instance segmentation, and multi-stage depth optimization to deliver robust per-branch point clouds. Starting from a naive baseline, we systematically identify and resolve three error families through successive refinements. Mask boundary contamination is first addressed through morphological erosion and subsequently refined via a skeleton-preserving variant to safeguard thin-branch topology. Segmentation inaccuracy is then mitigated using LAB-space Mahalanobis color validation coupled with cross-branch overlap arbitration. Finally, depth noise - the most persistent error source - is initially reduced by outlier removal and median filtering, before being superseded by a robust five-stage scheme comprising MAD global detection, spatial density consensus, local MAD filtering, RGB-guided filtering, and adaptive bilateral filtering. Evaluated on 1920x1080 stereo imagery of Radiata pine (Pinus radiata) acquired with a ZED Mini camera (63 mm baseline) from a UAV in Canterbury, New Zealand, the proposed pipeline reduces the average per-branch depth standard deviation by 82% while retaining edge fidelity. The result is geometrically coherent 3D point clouds suitable for autonomous pruning tool positioning. All code and processed data are publicly released to facilitate further UAV forestry research.

Paper number 13:
Title: On Channel Estimation for Group-Connected Beyond Diagonal RIS Assisted Multi-User MIMO Communication
Authors: Rui Wang, Junyuan Gao, Shuowen Zhang, Bruno Clerckx, Liang Liu
Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS) architectures offer superior beamforming gain over conventional diagonal RISs. However, the channel estimation overhead is the main hurdle for reaping the above gain in practice. This letter addresses this issue for group-connected BDRIS aided uplink communication from multiple multi-antenna users to one multi-antenna base station (BS). We first reveal that within each BD-RIS group, the cascaded channel associated with one user antenna and one BD-RIS element is a scaled version of that associated with any other user antenna and BD-RIS element due to the common RIS-BS channel. This insight drastically reduces the dimensionality of the channel estimation problem. Building on this property, we propose an efficient two-phase channel estimation protocol. In the first phase, the reference cascaded channels for all groups are estimated in parallel based on common received signals while determining the scaling coefficients for a single reference antenna. In the second phase, the scaling coefficients for all remaining user antennas are estimated. Numerical results demonstrate that our proposed framework achieves substantially lower estimation error with fewer pilot signals compared to state-of-the-art benchmark schemes.

Paper number 14:
Title: Provable orbit recovery over SO(3) from the non-uniform second moment
Authors: Tamir Bendory, Dan Edidin, Josh Katz, Shay Kreymer, Nir Sharon
Abstract: We study the recovery of an unknown three-dimensional band-limited signal from multiple noisy observations that are randomly rotated by latent elements of SO(3), where the rotations are drawn from an unknown, non-uniform distribution. Because the rotations are unobserved, only the signal orbit under the rotation group can be recovered. We show that the signal orbit and the rotation distribution are jointly identifiable from the first and second moments. This yields an improved high-noise sample complexity that scales quadratically with the noise variance, rather than cubically as in the uniform-rotation case. We further develop a provable, computationally efficient reconstruction algorithm that recovers the 3-D signal by successively solving a sequence of well-conditioned linear systems. The algorithm is validated through extensive numerical experiments. Our results provide a principled and tractable framework for high-noise 3-D orbit recovery, with potential relevance to cryo-electron microscopy and cryo-electron tomography modeling, where molecules are observed in unknown orientations.

Paper number 15:
Title: Grid-Mind: An LLM-Orchestrated Multi-Fidelity Agent for Automated Connection Impact Assessment
Authors: Mohamed Shamseldein
Abstract: Large language models (LLMs) have demonstrated remarkable tool-use capabilities, yet their application to power system operations remains largely unexplored. This paper presents Grid-Mind, a domain-specific LLM agent that interprets natural-language interconnection requests and autonomously orchestrates multi-fidelity power system simulations. The LLM-first architecture positions the language model as the central decision-making entity, employing an eleven-tool registry to execute Connection Impact Assessment (CIA) studies spanning steadystate power flow, N-1 contingency analysis, transient stability, and electromagnetic transient screening. A violation inspector grounds every decision in quantitative simulation outputs, while a three-layer anti-hallucination defence mitigates numerical fabrication risk through forced capacity-tool routing and post-response grounding validation. A prompt-level self-correction mechanism extracts distilled lessons from agent failures, yielding progressive accuracy improvements without model retraining. End-to-end evaluation on 50 IEEE 118-bus scenarios (DeepSeek-V3, 2026-02-23) achieved 84.0% tool-selection accuracy and 100% parsing accuracy. A separate 56-scenario self-correction suite passed 49 of 56 cases (87.5%) with a mean score of 89.3. These results establish a reproducible baseline for continued refinement while maintaining auditable, simulation-grounded decision support.

Paper number 16:
Title: Fast-Response Balancing Capacity of Alkaline Electrolyzers
Authors: Marvin Dorn, Julian Hoffmann, André Weber, Veit Hagenmeyer
Abstract: The energy transition requires flexible technologies to maintain grid stability, and electrolyzers are playing an increasingly important role in meeting this need. While previous studies often question the dynamic capabilities of large-scale alkaline electrolyzer systems, we assess their potential to provide balancing services using real manufacturer data. Unlike common approaches, we propose the decoupling between the total electrolyzer power and a smaller fractions of power actually offered on balancing markets. Adapting an existing methodology, we analyze alkaline electrolyzer systems and extend the assessment to Germany and Europe. Our results show that large-scale electrolyzers are technically capable of delivering fast-response balancing services, with significantly lower dynamic requirements than previously assumed. The planned electrolyzers in Germany could cover the entire balancing capacity market, potentially saving around 13 % of their electricity costs, excluding energy balancing revenues. The decoupling also resolves part of the trade-off for electrolyzer manufacturers, enabling the design of less dynamic but more stable systems.

Paper number 17:
Title: Functional Continuous Decomposition
Authors: Teymur Aghayev
Abstract: The analysis of non-stationary time-series data requires insight into its local and global patterns with physical interpretability. However, traditional smoothing algorithms, such as B-splines, Savitzky-Golay filtering, and Empirical Mode Decomposition (EMD), lack the ability to perform parametric optimization with guaranteed continuity. In this paper, we propose Functional Continuous Decomposition (FCD), a JAX-accelerated framework that performs parametric, continuous optimization on a wide range of mathematical functions. By using Levenberg-Marquardt optimization to achieve up to $C^1$ continuous fitting, FCD transforms raw time-series data into $M$ modes that capture different temporal patterns from short-term to long-term trends. Applications of FCD include physics, medicine, financial analysis, and machine learning, where it is commonly used for the analysis of signal temporal patterns, optimized parameters, derivatives, and integrals of decomposition. Furthermore, FCD can be applied for physical analysis and feature extraction with an average SRMSE of 0.735 per segment and a speed of 0.47s on full decomposition of 1,000 points. Finally, we demonstrate that a Convolutional Neural Network (CNN) enhanced with FCD features, such as optimized function values, parameters, and derivatives, achieved 16.8% faster convergence and 2.5% higher accuracy over a standard CNN.

Paper number 18:
Title: FGFRFT: Fast Graph Fractional FourierTransform via Fourier Series Approximation
Authors: Ziqi Yan, Sen Shi, Feiyue Zhao, Manjun Cui, Yangfan He, Zhichao Zhang
Abstract: The graph fractional Fourier transform (GFRFT) generalizes the graph Fourier transform (GFT) but suffers from a significant computational bottleneck: determining the optimal transform order requires expensive eigendecomposition and matrix multiplication, leading to $O(N^3)$ complexity. To address this issue, we propose a fast GFRFT (FGFRFT) algorithm for unitary GFT matrices based on Fourier series approximation and an efficient caching strategy. FGFRFT reduces the complexity of generating transform matrices to $O(2LN^2)$ while preserving differentiability, thereby enabling adaptive order learning. We validate the algorithm through theoretical analysis, approximation accuracy tests, and order learning experiments. Furthermore, we demonstrate its practical efficacy for image and point cloud denoising and present the fractional specformer, which integrates the FGFRFT into the specformer architecture. This integration enables the model to overcome the limitations of a fixed GFT basis and learn optimal fractional orders for complex data. Experimental results confirm that the proposed algorithm significantly accelerates computation and achieves superior performance compared with the GFRFT.

Paper number 19:
Title: Symbol-Aware Precoder Design for Physical-Layer Anonymous Communications
Authors: Yu Li, Milad Tatar Mamaghani, Xiangyun Zhou, Nan Yang
Abstract: Physical-layer characteristics, such as channel state information (CSI) and transmitter noise induced by hardware impairments, are often uniquely associated with a transmitter. This paper investigates transmitter anonymity at the physical layer from a signal design perspective. We consider an anonymous communication problem where the receiver should reliably decode the signal from the transmitter but should not make use of the signal to infer the transmitter's this http URL anonymity is quantified using a Kullback-Leibler divergence (KLD)-based metric, which enables the formulation of explicit anonymity constraints in the precoder this http URL then propose an anonymous symbol-level precoding strategy that preserves reliable communication under spatial multiplexing while preventing transmitter identification. The proposed framework employs a partitioned equal-gain combining (P-EGC) scheme that leverages receiver diversity without requiring transmitter-specific CSI. Simulation results demonstrate anonymity-reliability tradeoffs across different signal-to-noise ratios (SNRs) and numbers of data streams. Moreover, the results reveal opposite trends of anonymity with respect to transmitter-dependent noise variations in the low-SNR and high-SNR regimes.

Paper number 20:
Title: Continuous-Time Analysis of AFDM: Fundamental Bounds, and Effects of Pulse-Shaping and Hardware Impairments
Authors: Michele Mirabella, Hyeon Seok Rou, Pasquale Di Viesti, Giuseppe Thadeu Freitas de Abreu, Giorgio Matteo Vitetta
Abstract: Affine frequency division multiplexing (AFDM) has recently emerged as a resilient waveform candidate for high-mobility next-generation wireless systems. However, current literature mostly focuses on discrete time (DT) models, often overlooking effects and hardware non-idealities of actual continuous time (CT) signal generation. In this paper, we bridge this gap by developing a CT-analytical framework based on the affine Fourier series (AFS) representation, which allows us to demonstrate that strictly bandlimited pulses and subcarrier suppression strategies are essential to maintain the multicarrier structure of the signal. In addition, we derive the analytical power spectral density of AFDM and evaluate its spectral characteristics in comparison with other multicarrier schemes, considering the impact of realistic truncated pulse-shaping. Furthermore, we analyze the sensitivity of the CT model to phase noise, carrier frequency offset, and sampling jitter, providing a theoretical analysis of communication performance. Finally, we derive closed-form Cramér-Rao bounds for channel parameter estimation, showing that the chirped modulation peculiar of AFDM increases the estimation variance but enables the resolution of Doppler ambiguities. Our findings provide the necessary theoretical and practical foundations for the implementation of AFDM in realistic wireless transceivers.

Paper number 21:
Title: Synapse-Inspired Energy Networks: A Neuromorphic Approach to Microgrid Protection without Communication Links
Authors: Saurabh Prabhakar, Bijaya Ketan Panigrahi, Frede Blaabjerg, Subham Sahoo
Abstract: Traditional protection systems for microgrids, which rely on high fault currents and continuous communication, struggle to keep up with the changing dynamics and cybersecurity concerns of decentralized networks. In this study, we introduce a novel biologically inspired protection system based on neuromorphic principles, where each distributed energy resource (DER) functions as a simple neuron. These neurons process local changes in voltage, current signals, and converting them into spike patterns that represent the severity of disturbances. Just as neurons communicate via synapses in biological systems, we exploit transmission cables to coordinate between DERs, enabling them to share information and respond to faults collectively. Fault detection and circuit breaker activation are driven by a First-To-Spike (FTTS) mechanism, similar to the concept of traveling wave protection, but without needing GPS synchronization or communication links. A key innovation is the ability to use the timing of spikes to locally determine the nature of a fault, offering an intelligent, adaptive response to disturbances. Performance shows tripping latency of 10-58 ms, surpassing conventional relays and even traveling-wave methods (60 ms), while maintaining detection accuracy above 98% and spatial selectivity over 97%, enabling real-time, communication-free, scalable protection for plug-and-play microgrids.

Paper number 22:
Title: Timing Recovery and Sequence Detection for Integrate-and-Fire Time Encoding Receivers
Authors: Neil Irwin Bernardo
Abstract: Recent advances in neuromorphic signal processing have introduced time encoding machines as a promising alternative to conventional uniform sampling for low-power communication receivers. In this paradigm, analog signals are converted into event timings by an integrate-and-fire circuit, allowing information to be represented through spike times rather than amplitude samples. While event-driven sampling eliminates the need for a fixed-rate clock, receivers equipped with integrate-and-fire time encoding machines, called time encoding receivers, often assume perfect symbol synchronization, leaving the problem of symbol timing recovery unresolved. This paper presents a joint timing recovery and data detection framework for integrate-and-fire time encoding receivers. The log-likelihood function is derived to capture the dependence between firing times, symbol timing offset, and transmitted sequence, leading to a maximum likelihood formulation for joint timing estimation and sequence detection. A practical two-stage receiver is developed, consisting of a timing recovery algorithm followed by a zero-forcing detector. Simulation results demonstrate accurate symbol timing offset estimation and improved symbol error rate performance compared to existing time encoding receivers.

Paper number 23:
Title: Training-Free Intelligibility-Guided Observation Addition for Noisy ASR
Authors: Haoyang Li, Changsong Liu, Wei Rao, Hao Shi, Sakriani Sakti, Eng Siong Chng
Abstract: Automatic speech recognition (ASR) degrades severely in noisy environments. Although speech enhancement (SE) front-ends effectively suppress background noise, they often introduce artifacts that harm recognition. Observation addition (OA) addressed this issue by fusing noisy and SE enhanced speech, improving recognition without modifying the parameters of the SE or ASR models. This paper proposes an intelligibility-guided OA method, where fusion weights are derived from intelligibility estimates obtained directly from the backend ASR. Unlike prior OA methods based on trained neural predictors, the proposed method is training-free, reducing complexity and enhances generalization. Extensive experiments across diverse SE-ASR combinations and datasets demonstrate strong robustness and improvements over existing OA baselines. Additional analyses of intelligibility-guided switching-based alternatives and frame versus utterance-level OA further validate the proposed design.

Paper number 24:
Title: Cell-Free Massive MIMO-Assisted SWIPT Using Stacked Intelligent Metasurfaces
Authors: Thien Duc Hua, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou
Abstract: This study explores a next-generation multiple access (NGMA) framework for cell-free massive MIMO (CF-mMIMO) systems enhanced by stacked intelligent metasurfaces (SIMs), aiming to improve simultaneous wireless information and power transfer (SWIPT) performance. A fundamental challenge lies in optimally selecting the operating modes of access points (APs) to jointly maximize the received energy and satisfy spectral efficiency (SE) quality-of-service constraints. Practical system impairments, including a non-linear harvested energy model, pilot contamination (PC), channel estimation errors, and reliance on long-term statistical channel state information (CSI), are considered. We derive closed-form expressions for both the achievable SE and the average sum harvested energy (sum-HE). A mixed-integer non-convex optimization problem is formulated to jointly optimize the SIM phase shifts, APs mode selection, and power allocation to maximize average sum-HE under SE and average harvested energy constraints. To solve this problem, we propose a centralized training, decentralized execution (CTDE) framework based on deep reinforcement learning (DRL), which efficiently handles high-dimensional decision spaces. A Markovian environment and a normalized joint reward function are introduced to enhance the training stability across on-policy and off-policy DRL algorithms. Additionally, we provide a two-phase convex-based solution as a theoretical robust performance. Numerical results demonstrate that the proposed DRL-based CTDE framework achieves SWIPT performance comparable to convexification-based solution, while significantly outperforming baselines.

Paper number 25:
Title: Multimodal MRI Report Findings Supervised Brain Lesion Segmentation with Substructures
Authors: Yubin Ge, Yongsong Huang, Xiaofeng Liu
Abstract: Report-supervised (RSuper) learning seeks to alleviate the need for dense tumor voxel labels with constraints derived from radiology reports (e.g., volumes, counts, sizes, locations). In MRI studies of brain tumors, however, we often involve multi-parametric scans and substructures. Here, fine-grained modality/parameter-wise reports are usually provided along with global findings and are correlated with different substructures. Moreover, the reports often describe only the largest lesion and provide qualitative or uncertain cues (``mild,'' ``possible''). Classical RSuper losses (e.g., sum volume consistency) can over-constrain or hallucinate unreported findings under such incompleteness, and are unable to utilize these hierarchical findings or exploit the priors of varied lesion types in a merged dataset. We explicitly parse the global quantitative and modality-wise qualitative findings and introduce a unified, one-sided, uncertainty-aware formulation (MS-RSuper) that: (i) aligns modality-specific qualitative cues (e.g., T1c enhancement, FLAIR edema) with their corresponding substructures using existence and absence losses; (ii) enforces one-sided lower-bounds for partial quantitative cues (e.g., largest lesion size, minimal multiplicity); and (iii) adds extra- vs. intra-axial anatomical priors to respect cohort differences. Certainty tokens scale penalties; missing cues are down-weighted. On 1238 report-labeled BraTS-MET/MEN scans, our MS-RSuper largely outperforms both a sparsely-supervised baseline and a naive RSuper method.

Paper number 26:
Title: Optimal QAM Constellation for Over-the-Air Computation in the Presence of Heavy-Tailed Channel Noise
Authors: Saeed Razavikia, Deniz Gündüz, Carlo Fischione
Abstract: Over-the-air computation (OAC) enables low-latency aggregation over multiple-access channels (MACs) by exploiting the superposition property of the wireless medium to compute functions efficiently in distributed networks. A critical but often overlooked challenge is that electromagnetic interference in practical radio channels frequently exhibits heavy-tailed behavior, causing strong impulsive noise that severely degrades computation performance. This work studies digital OAC with QAM-based signaling under heavy-tailed interference modeled by a Cauchy distribution (lacking a finite second moment). We seek QAM-like constellations that minimize the mean-squared error (MSE) of sum aggregation subject to an average-power constraint. The problem is formulated as a constrained optimization, whose solution yields unique optimality conditions. Numerical results confirm the effectiveness of the proposed design. Notably, the framework extends naturally to nomographic functions, broader constellation families, and alternative noise models.

Paper number 27:
Title: Distributed Continuous Aperture Arrays for Multiuser SWIPT
Authors: Muhammad Zeeshan Mumtaz, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou
Abstract: This paper proposes a distributed continuous aperture array (D CAPA) to support simultaneous wireless information and power transfer (SWIPT) to multiple information users (IUs) and energy users (EUs). Each metasurface supports continuous surface currents that radiate electromagnetic (EM) waves for information and energy transmission to the users. These waves propagate through continuous EM channels characterized by the dyadic Green function. We formulate a system power consumption (PC) minimization problem subject to spectral efficiency and energy harvesting quality of service (QoS) requirements, where the QoS requirements are derived under the equal power allocation (EPA) scheme. An efficient two layer optimization algorithm is developed to solve this problem by optimizing the power allocation subject to the QoS violation penalties using augmented Lagrangian transformation. Our numerical results show that well optimized current distributions over each metasurface in the proposed D CAPA achieve up to 65% and 61% reductions in overall system PC compared to the EPA and colocated CAPA (C CAPA) cases, while maintaining the same total aperture size and transmission power.

Paper number 28:
Title: BRISC: A Dataset of Channel Measurements at 5 GHz With a Reflective Intelligent Surface
Authors: Mattia Piana, Giovanni Angelo Alghisi, Anna Valeria Guglielmi, Giovanni Perin, Francesco Gringoli, Stefano Tomasin
Abstract: We introduce the broadband reconfigurable intelligent surface (RIS) channel (BRISC) dataset. The dataset comprises measurements of channel state information (CSI) collected at 5.53 GHz using a 256-element RIS with binary states. In the measurement campaign, the transmitter and receiver are two software defined radios (SDRs), phase-synchronized via an OctoClock, where the transmitter (receiver) is equipped with one (two) antenna(s). To manage complexity, the RIS elements are grouped into blocks of different sizes, where all elements within a block share the same state. CSIs have been captured for multiple a) transmitter positions (and fixed receiver location), b) pilot block sizes, and c) state configurations. Furthermore, we calibrated the parameters of state-of-the-art RIS channel models to fit the measured CSI. With approximately 10000 configurations explored per transmitting position, BRISC serves as a robust benchmark in communication applications. We also show here an example of its use for physical-layer authentication.

Paper number 29:
Title: Resilient Cell-Free Massive MIMO Networks
Authors: Junbin Yu, Tianyu Lu, Mohammadali Mohammadi, Michail Matthaiou
Abstract: This paper proposes a novel optimization framework for enhancing the security resilience of cell-free massive multiple-input multiple-output (CF-mMIMO) networks with multi-antenna access points (APs) and protective partial zero-forcing (PPZF) under active eavesdropping. Based on the main principles of absorption, adaptation, and recovery, we formulate a security-aware resilience metric to quantify the system performance during and after a security outage. A multi-user service priority-aware power allocation problem is formulated to minimize the mean squared error (MSE) between real-time and desired security efficiency, thereby enabling a trade-off between the target user's secrecy performance and multi-user quality of service (QoS). To solve this non-convex problem, a security-aware iterative algorithm based on the successive convex approximation (SCA) is employed. The proposed algorithm determines the optimal power allocation strategy by balancing solution quality against recovery time. At each iteration, it evaluates the overall resilience score and selects the strategy that achieves the highest value. Simulation results confirm that the proposed framework significantly improves the resilience of CF-mMIMO networks, allowing flexible adaptation between rapid recovery and high-quality recovery, depending on system requirements.

Paper number 30:
Title: A Survey of Recent Developments in SYCL Compiler Implementations
Authors: Huy Trinh
Abstract: This survey discusses recent advancements in SYCL compiler implementations, one of the crucial aspects of compiler construction for heterogeneous computing systems. We explore the transition from traditional compiler construction, from Single-Source Multiple Compiler Passes (SMCP) to a more advanced approach to Single-Source Single Compiler Pass (SSCP). The survey analyzes multiple papers that researched the different developments of SYCL implementation based on SSCP and their approach to enhancing performance and addressing separate challenges.

Paper number 31:
Title: Attention-Based SINR Estimation in User-Centric Non-Terrestrial Networks
Authors: Bruno De Filippo, Alessandro Guidotti, Alessandro Vanelli-Coralli
Abstract: The signal-to-interference-plus-noise ratio (SINR) is central to performance optimization in user-centric beamforming for satellite-based non-terrestrial networks (NTNs). Its assessment either requires the transmission of dedicated pilots or relies on computing the beamforming matrix through minimum mean squared error (MMSE)-based formulations beforehand, a process that introduces significant computational overhead. In this paper, we propose a low-complexity SINR estimation framework that leverages multi-head self-attention (MHSA) to extract inter-user interference features directly from either channel state information or user location reports. The proposed dual MHSA (DMHSA) models evaluate the SINR of a scheduled user group without requiring explicit MMSE calculations. The architecture achieves a computational complexity reduction by a factor of three in the CSI-based setting and by two orders of magnitude in the location-based configuration, the latter benefiting from the lower dimensionality of user reports. We show that both DMHSA models maintain high estimation accuracy, with the root mean squared error typically below 1 dB with priority-queuing-based scheduled users. These results enable the integration of DMHSA-based estimators into scheduling procedures, allowing the evaluation of multiple candidate user groups and the selection of those offering the highest average SINR and capacity.

Paper number 32:
Title: Vision-Inspired Image Quality Assessment for Radar-Based Human Activity Representations
Authors: Huy Trinh, Davis Liu, Munia Humaira, Peter Lee, Zhou Wang
Abstract: Radar-based human activity recognition has gained attention as a privacy-preserving alternative to vision and wearable sensors, especially in sensitive environments like long-term care facilities. Micro-Doppler spectrograms derived from FMCW radar signals are central to recognizing dynamic activities, but their effectiveness is limited by noise and clutter. In this work, we use a benchmark radar dataset to reimplement and assess three recent denoising and preprocessing techniques: adaptive preprocessing, adaptive thresholding, and entropy-based denoising. To illustrate the shortcomings of conventional metrics in low-SNR regimes, we evaluate performance using both perceptual image quality measures and standard error-based metrics. We additionally propose a novel framework for static activity recognition using range-angle feature maps to expand HAR beyond dynamic activities. We present two important contributions: a temporal tracking algorithm to enforce consistency and a no-reference quality scoring algorithm to assess RA-map fidelity. According to experimental findings, our suggested techniques enhance classification performance and interpretability for both dynamic and static activities, opening the door for more reliable radar-based HAR systems.

Paper number 33:
Title: KAN-Koopman Based Rapid Detection Of Battery Thermal Anomalies With Diagnostics Guarantees
Authors: Sanchita Ghosh, Tanushree Roy
Abstract: Early diagnosis of battery thermal anomalies is crucial to ensure safe and reliable battery operation by preventing catastrophic thermal failures. Battery diagnostics primarily rely on battery surface temperature measurements and/or estimation of core temperatures. However, aging-induced changes in the battery model and limited training data remain major challenges for model-based and machine-learning based battery state estimation and diagnostics. To address these issues, we propose a Kolomogorov-Arnold network (KAN) in conjunction with a Koopman-based detection algorithm that leverages the unique advantages of both methods. Firstly, the lightweight KAN provides a model-free estimation of the core temperature to ensure rapid detection of battery thermal anomalies. Secondly, the Koopman operator is learned in real time using the estimated core temperature from KAN and the measured surface temperature of the battery to provide a prediction for diagnostic residual generation. This online learning approach overcomes the challenges of model changes, while the integrated structure reduces the dependence on large datasets. Furthermore, we derive analytical conditions that provide diagnostic guarantees on our KAN-Koopman detection scheme. Our simulation results illustrate a significant reduction in detection time with the proposed algorithm compared to the baseline Koopman-only algorithm.

Paper number 34:
Title: A Light Fixture Color Temperature and Color Rendering Index Measuring Device
Authors: Gianluca Hiss Garbim, Luis Carlos Mathias, André Massami Assakawa, Taufik Abrão
Abstract: The correlated color temperature (CCT) and color rendering index (CRI) of artificial light sources are important because they have implications for human biology and professional applications. Although CCT information is generally available for commercial lamps, CRI is commonly not reported. In addition, devices measuring these parameters are difficult to access as they require a spectrophotometer, a commonly expensive device. In this context, the present work designs and builds a meter in detail, from the structural part of the equipment, interface with sensors, and the calculation to the compensation algorithms implementation, aiming to build the dedicated functionalities of a spectrophotometer, which is designed without the use of optical lenses. In addition to simplifying the device, this approach allows measurements free from dispersions caused by chromatic aberrations typical of optical lenses. The prototype obtained proved to be effective, capturing the spectral power distributions of various light sources and calculating their CCT and CRI.

Paper number 35:
Title: Graph Modelling Analysis of Speech-Gesture Interaction for Aphasia Severity Estimation
Authors: Navya Martin Kollapally, Christa Akers, Renjith Nelson Joseph
Abstract: Aphasia is an acquired language disorder caused by injury to the regions of the brain that are responsible for language. Aphasia may impair the use and comprehension of written and spoken language. The Western Aphasia Battery-Revised (WAB-R) is an assessment tool administered by speech-language pathologists (SLPs) to evaluate the aphasia type and severity. Because the WAB-R measures isolated linguistic skills, there has been growing interest in the assessment of discourse production as a more holistic representation of everyday language abilities. Recent advancements in speech analysis focus on automated estimation of aphasia severity from spontaneous speech, relying mostly in isolated linguistic or acoustical features. In this work, we propose a graph neural network-based framework for estimating aphasia severity. We represented each participant's discourse as a directed multi-modal graph, where nodes represent lexical items and gestures and edges encode word-word, gesture-word, and word-gesture transitions. GraphSAGE is employed to learn participant-level embeddings, thus integrating information from immediate neighbors and overall graph structure. Our results suggest that aphasia severity is not encoded in isolated lexical distribution, but rather emerges from structured interactions between speech and gesture. The proposed architecture offers a reliable automated aphasia assessment, with possible uses in bedside screening and telehealth-based monitoring.

Paper number 36:
Title: GSNR: Graph Smooth Null-Space Representation for Inverse Problems
Authors: Romario Gualdrón-Hurtado, Roman Jacome, Rafael S. Suarez, Henry Arguello
Abstract: Inverse problems in imaging are ill-posed, leading to infinitely many solutions consistent with the measurements due to the non-trivial null-space of the sensing matrix. Common image priors promote solutions on the general image manifold, such as sparsity, smoothness, or score function. However, as these priors do not constrain the null-space component, they can bias the reconstruction. Thus, we aim to incorporate meaningful null-space information in the reconstruction framework. Inspired by smooth image representation on graphs, we propose Graph-Smooth Null-Space Representation (GSNR), a mechanism that imposes structure only into the invisible component. Particularly, given a graph Laplacian, we construct a null-restricted Laplacian that encodes similarity between neighboring pixels in the null-space signal, and we design a low-dimensional projection matrix from the $p$-smoothest spectral graph modes (lowest graph frequencies). This approach has strong theoretical and practical implications: i) improved convergence via a null-only graph regularizer, ii) better coverage, how much null-space variance is captured by $p$ modes, and iii) high predictability, how well these modes can be inferred from the measurements. GSNR is incorporated into well-known inverse problem solvers, e.g., PnP, DIP, and diffusion solvers, in four scenarios: image deblurring, compressed sensing, demosaicing, and image super-resolution, providing consistent improvement of up to 4.3 dB over baseline formulations and up to 1 dB compared with end-to-end learned models in terms of PSNR.

Paper number 37:
Title: On the Optimal Integer-Forcing Precoding: A Geometric Perspective and a Polynomial-Time Algorithm
Authors: Junren Qin, Fan Jiang, Tao Yang, Shanxiang Lyu, Rongke Liu, Shi Jin
Abstract: The joint optimization of the integer matrix $\mathbf{A}$ and the power scaling matrix $\mathbf{D}$ is central to achieving the capacity-approaching performance of Integer-Forcing (IF) precoding. This problem, however, is known to be NP-hard, presenting a fundamental computational bottleneck. In this paper, we reveal that the solution space of this problem admits a intrinsic geometric structure: it can be partitioned into a finite number of conical regions, each associated with a distinct full-rank integer matrix $\mathbf{A}$. Leveraging this decomposition, we transform the NP-hard problem into a search over these regions and propose the Multi-Cone Nested Stochastic Pattern Search (MCN-SPS) algorithm. Our main theoretical result is that MCN-SPS finds a near-optimal solution with a computational complexity of $\mathcal{O}\left(K^4\log K\log_2(r_0)\right)$, which is polynomial in the number of users $K$. Numerical simulations corroborate the theoretical analysis and demonstrate the algorithm's efficacy.

Paper number 38:
Title: Memory-guided Prototypical Co-occurrence Learning for Mixed Emotion Recognition
Authors: Ming Li, Yong-Jin Liu, Fang Liu, Huankun Sheng, Yeying Fan, Yixiang Wei, Minnan Luo, Weizhan Zhang, Wenping Wang
Abstract: Emotion recognition from multi-modal physiological and behavioral signals plays a pivotal role in affective computing, yet most existing models remain constrained to the prediction of singular emotions in controlled laboratory settings. Real-world human emotional experiences, by contrast, are often characterized by the simultaneous presence of multiple affective states, spurring recent interest in mixed emotion recognition as an emotion distribution learning problem. Current approaches, however, often neglect the valence consistency and structured correlations inherent among coexisting emotions. To address this limitation, we propose a Memory-guided Prototypical Co-occurrence Learning (MPCL) framework that explicitly models emotion co-occurrence patterns. Specifically, we first fuse multi-modal signals via a multi-scale associative memory mechanism. To capture cross-modal semantic relationships, we construct emotion-specific prototype memory banks, yielding rich physiological and behavioral representations, and employ prototype relation distillation to ensure cross-modal alignment in the latent prototype space. Furthermore, inspired by human cognitive memory systems, we introduce a memory retrieval strategy to extract semantic-level co-occurrence associations across emotion categories. Through this bottom-up hierarchical abstraction process, our model learns affectively informative representations for accurate emotion distribution prediction. Comprehensive experiments on two public datasets demonstrate that MPCL consistently outperforms state-of-the-art methods in mixed emotion recognition, both quantitatively and qualitatively.

Paper number 39:
Title: Quantifying Dimensional Independence in Speech: An Information-Theoretic Framework for Disentangled Representation Learning
Authors: Bipasha Kashyap, Björn W. Schuller, Pubudu N. Pathirana
Abstract: Speech signals encode emotional, linguistic, and pathological information within a shared acoustic channel; however, disentanglement is typically assessed indirectly through downstream task performance. We introduce an information-theoretic framework to quantify cross-dimension statistical dependence in handcrafted acoustic features by integrating bounded neural mutual information (MI) estimation with non-parametric validation. Across six corpora, cross-dimension MI remains low, with tight estimation bounds ($< 0.15$ nats), indicating weak statistical coupling in the data considered, whereas Source--Filter MI is substantially higher (0.47 nats). Attribution analysis, defined as the proportion of total MI attributable to source versus filter components, reveals source dominance for emotional dimensions (80\%) and filter dominance for linguistic and pathological dimensions (60\% and 58\%, respectively). These findings provide a principled framework for quantifying dimensional independence in speech.

Paper number 40:
Title: Efficient Solvers for Coupling-Aware Beamforming in Continuous Aperture Arrays
Authors: Geonhee Lee, Kwonyeol Park, Hyeongjun Park, Jinwoo An, Junil Choi
Abstract: In continuous aperture arrays (CAPAs), careful consideration of the underlying physics is essential, among which electromagnetic (EM) mutual coupling plays a critical role in beamforming performance. Building on a physically consistent mutual coupling model, the beamforming design is formulated as a functional optimization whose optimality condition leads to a Fredholm integral equation. The incorporation of the coupling model, however, substantially increases computational complexity, necessitating efficient and accurate integral equation solvers. In this letter, we propose two efficient solvers: 1) a coordinate-transformation-based kernel approximation that preserves the operator structure while alleviating discretization demands, and 2) a direct lower-upper (LU)-based solver that stably handles the Nyström-discretized system. Numerical results demonstrate improved accuracy and reduced computational overhead compared to conventional methods, with the LU-based solver emerging as an efficient and scalable solution for large-scale CAPA optimization via offline factorization.

Paper number 41:
Title: Hawkes Identification with a Prescribed Causal Basis: Closed-Form Estimators and Asymptotics
Authors: Xinhui Rong, Girish N. Nair
Abstract: Driven by the recent surge in neural-inspired modeling, point processes have gained significant traction in systems and control. While the Hawkes process is the standard model for characterizing random event sequences with memory, identifying its unknown kernels is often hindered by nonlinearity. Approaches using prescribed basis kernels have emerged to enable linear parameterization, yet they typically rely on iterative likelihood methods and lack rigorous analysis under model misspecification. This paper justifies a closed-form Least Squares identification framework for Hawkes processes with prescribed kernels. We guarantee estimator existence via the almost-sure positive definiteness of the empirical Gram matrix and prove convergence to the true parameters under correct specification, or to well-defined pseudo-true parameters under misspecification. Furthermore, we derive explicit Central Limit Theorems for both regimes, providing a complete and interpretable asymptotic theory. We demonstrate these theoretical findings through comparative numerical simulations.

Paper number 42:
Title: Geometric Analysis of Speech Representation Spaces: Topological Disentanglement and Confound Detection
Authors: Bipasha Kashyap, Pubudu N. Pathirana
Abstract: Speech-based clinical tools are increasingly deployed in multilingual settings, yet whether pathological speech markers remain geometrically separable from accent variation remains unclear. Systems may misclassify healthy non-native speakers or miss pathology in multilingual patients. We propose a four-metric clustering framework to evaluate geometric disentanglement of emotional, linguistic, and pathological speech features across six corpora and eight dataset combinations. A consistent hierarchy emerges: emotional features form the tightest clusters (Silhouette 0.250), followed by pathological (0.141) and linguistic (0.077). Confound analysis shows pathological-linguistic overlap remains below 0.21, which is above the permutation null but bounded for clinical deployment. Trustworthiness analysis confirms embedding fidelity and robustness of the geometric conclusions. Our framework provides actionable guidelines for equitable and reliable speech health systems across diverse populations.

Paper number 43:
Title: Hierarchic-EEG2Text: Assessing EEG-To-Text Decoding across Hierarchical Abstraction Levels
Authors: Anupam Sharma, Harish Katti, Prajwal Singh, Shanmuganathan Raman, Krishna Miyapuram
Abstract: An electroencephalogram (EEG) records the spatially averaged electrical activity of neurons in the brain, measured from the human scalp. Prior studies have explored EEG-based classification of objects or concepts, often for passive viewing of briefly presented image or video stimuli, with limited classes. Because EEG exhibits a low signal-to-noise ratio, recognizing fine-grained representations across a large number of classes remains challenging; however, abstract-level object representations may exist. In this work, we investigate whether EEG captures object representations across multiple hierarchical levels, and propose episodic analysis, in which a Machine Learning (ML) model is evaluated across various, yet related, classification tasks (episodes). Unlike prior episodic EEG studies that rely on fixed or randomly sampled classes of equal cardinality, we adopt hierarchy-aware episode sampling using WordNet to generate episodes with variable classes of diverse hierarchy. We also present the largest episodic framework in the EEG domain for detecting observed text from EEG signals in the PEERS dataset, comprising $931538$ EEG samples under $1610$ object labels, acquired from $264$ human participants (subjects) performing controlled cognitive tasks, enabling the study of neural dynamics underlying perception, decision-making, and performance monitoring. We examine how the semantic abstraction level affects classification performance across multiple learning techniques and architectures, providing a comprehensive analysis. The models tend to improve performance when the classification categories are drawn from higher levels of the hierarchy, suggesting sensitivity to abstraction. Our work highlights abstraction depth as an underexplored dimension of EEG decoding and motivates future research in this direction.

Paper number 44:
Title: Scaling Vision Transformers: Evaluating DeepSpeed for Image-Centric Workloads
Authors: Huy Trinh, Rebecca Ma, Zeqi Yu, Tahsin Reza
Abstract: Vision Transformers (ViTs) have demonstrated remarkable potential in image processing tasks by utilizing self-attention mechanisms to capture global relationships within data. However, their scalability is hindered by significant computational and memory demands, especially for large-scale models with many parameters. This study aims to leverage DeepSpeed, a highly efficient distributed training framework that is commonly used for language models, to enhance the scalability and performance of ViTs. We evaluate intra- and inter-node training efficiency across multiple GPU configurations on various datasets like CIFAR-10 and CIFAR-100, exploring the impact of distributed data parallelism on training speed, communication overhead, and overall scalability (strong and weak scaling). By systematically varying software parameters, such as batch size and gradient accumulation, we identify key factors influencing performance of distributed training. The experiments in this study provide a foundational basis for applying DeepSpeed to image-related tasks. Future work will extend these investigations to deepen our understanding of DeepSpeed's limitations and explore strategies for optimizing distributed training pipelines for Vision Transformers.

Paper number 45:
Title: Robustness certificates in data-driven non-convex optimization with additively-uncertain constraints
Authors: Alexander J Gallo, Massimiliano Zoggia, Alessandro Falsone, Maria Prandini, Simone Garatti
Abstract: We consider decision-making problems that are formulated as non-convex optimization programs where uncertainty enters the constraints through an additive term, independent of the decision variables, and robustness is imposed using a finite data-set, according to the scenario robust optimization paradigm. By exploiting the structure of the constraints, we show that both a priori and a posteriori distribution-free probabilistic robustness certificates for a possibly sub-optimal solution to the resulting data-driven optimization problem can be obtained with minimal computational effort. Building on these results, we also discuss a one-shot and an incremental procedure to determine the size of the data-set so as to guarantee a user-chosen robustness level. Notably, both the a posteriori robustness assessment and incremental data-set sizing do not require to solve the non-convex scenario program. A comparative analysis performed on the unit commitment problem using real data reveals a limited increase in conservativeness with a significant computational saving with respect to the application of scenario theory results for general, non necessarily structured, non-convex problems.

Paper number 46:
Title: Disturbance-Adaptive Data-Driven Predictive Control: Trading Comfort Violations for Savings in Building Climate Control
Authors: Jicheng Shi, Christophe Salzmann, Colin N. Jones
Abstract: Model Predictive Control (MPC) has demonstrated significant potential in improving energy efficiency in building climate control, outperforming traditional controllers commonly used in modern building management systems. Among MPC variants, Data-driven Predictive Control (DPC) offers the advantage of modeling building dynamics directly from data, thereby substantially reducing commissioning efforts. However, inevitable model uncertainties and measurement noise can result in comfort violations, even with dedicated MPC setups. This paper introduces a Disturbance-Adaptive DPC (DAD-DPC) framework that ensures asymptotic satisfaction of predefined violation bounds without knowing the uncertainty and noise distributions. The framework employs a data-driven pipeline based on Willems' Fundamental Lemma and conformal prediction for application in building climate control. The proposed DAD-DPC framework was validated through four building cases using the high-fidelity BOPTEST simulation platform and an occupied campus building, Polydome. DAD-DPC successfully regulated the average comfort violations to meet pre-defined bounds. Notably, the 5%-violation DAD-DPC setup achieved 30.1%/11.2%/27.1%/20.5% energy savings compared to default controllers across four cases. These results demonstrate the framework's effectiveness in balancing energy consumption and comfort violations, offering a practical solution for building climate control applications.

Paper number 47:
Title: Superimposed Pilot-Based OTFS: Will It Work?
Authors: Yuta Kanazawa, Hiroki Iimori, Chandan Pradhan, Szabolcs Malomsoky, Naoki Ishikawa
Abstract: Orthogonal time frequency space (OTFS) modulation is a promising solution to handle doubly-selective fading, but its channel estimation is a nontrivial task in terms of maximizing spectral efficiency. Conventional pilot assignment approaches face challenges: the standard embedded pilot-based scheme suffers from low transmission rates, and the single superimposed pilot (SP)-based scheme experiences inevitable data-pilot interference, leading to coarse channel estimation. To cope with this issue, focusing on the SP-based OTFS system in channel coded scenarios, we propose a novel pilot assignment scheme and an iterative algorithm. The proposed scheme allocates multiple SPs per frame to estimate channel coefficients accurately. Furthermore, the proposed algorithm performs refined interference cancellation, utilizing a replica of data symbols generated from soft-decision outputs provided by a decoder. Assuming fair and unified conditions, we evaluate each pilot assignment scheme in terms of reliability, channel estimation accuracy, effective throughput, and computational complexity. Our numerical simulations demonstrate that the multiple SP-based scheme, which balances the transmission rate and the interference cancellation performance, has the best throughput at the expense of slightly increased complexity. In addition, we confirm that the multiple SP-based scheme achieves further improved throughput due to the proposed interference cancellation algorithm.

Paper number 48:
Title: MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition
Authors: Mehran Shabanpour, Kasra Rad, Sadaf Khademi, Arash Mohammadi
Abstract: High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework's robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.

Paper number 49:
Title: Interaction-Aware Model Predictive Decision-Making for Socially-Compliant Autonomous Driving in Mixed Urban Traffic Scenarios
Authors: Balint Varga, Thomas Brand, Marcus Schmitz, Ehsan Hashemi
Abstract: Autonomous vehicles must negotiate with pedestrians in ways that are both safe and socially compliant. We present an interaction-aware model predictive decision-making (IAMPDM) framework that integrates a gap-acceptance-inspired intention model with MPC to jointly reason about human intent and vehicle control in real time. The pedestrian module produces a continuous crossing-propensity signal - driven by time-to-collision (TTC) with an intention discounting mechanism - that modulates MPC safety terms and minimum-distance constraints. We implement IAMPDM in a projection-based, motion-tracked simulator and compare it against a rule-based intention-aware controller (RBDM) and a conservative non-interactive baseline (NIA). In a human-in-the-decision-loop study with 25 participants, intention-aware methods shortened negotiation and completion time relative to NIA across scenarios, at the expense of tighter TTC/DST margins, with no significant difference between IAMPDM and RBDM except for TTC in one scenario. Results indicate that intention-aware decision-making algorithms reduce pedestrian crossing time and improve subjective ratings of comfort, safety, and trust relative to a non-cooperative decision-making algorithm. We discuss implications for real-world deployment of interaction-aware autonomous vehicles. We detail decision-making calibration and real-time implementation (CasADi/IPOPT) and propose deployment guardrails - minimum surrogate-safety margins, deadlock prevention - to balance efficiency with safety.

Paper number 50:
Title: Single-Satellite-Based Geolocation of Broadcast GNSS Spoofers from Low Earth Orbit
Authors: Zachary L. Clements, Patrick B. Ellis, Iain Goodridge, Matthew J. Murrian, Mark L. Psiaki, Todd E. Humphreys
Abstract: This paper presents an analysis and experimental demonstration of single-satellite single-pass geolocation of a terrestrial broadcast Global Navigation Satellite System (GNSS) spoofer from Low Earth Orbit (LEO). The proliferation of LEO-based GNSS receivers offers the prospect of unprecedented spectrum awareness, enabling persistent GNSS interference detection and geolocation. Accurate LEO-based single-receiver emitter geolocation is possible when a range-rate time history can be extracted for the emitter. This paper presents a technique crafted specifically for indiscriminate broadcast-type GNSS spoofing signals. Furthermore, it explores how unmodeled oscillator instability and worst-case spoofer-introduced signal variations degrade the geolocation estimate. The proposed geolocation technique is validated by a controlled experiment, in partnership with Spire Global, in which a LEO-based receiver captures broadcast GNSS spoofing signals transmitted from a known ground station on a non-GNSS frequency band.

Paper number 51:
Title: Reproducing and Improving CheXNet: Deep Learning for Chest X-ray Disease Classification
Authors: Daniel J. Strick, Carlos Garcia, Anthony Huang, Thomas Gardos
Abstract: Deep learning for radiologic image analysis is a rapidly growing field in biomedical research and is likely to become a standard practice in modern medicine. On the publicly available NIH ChestX-ray14 dataset, containing X-ray images that are classified by the presence or absence of 14 different diseases, we reproduced an algorithm known as CheXNet, as well as explored other algorithms that outperform CheXNet's baseline metrics. Model performance was primarily evaluated using the F1 score and AUC-ROC, both of which are critical metrics for imbalanced, multi-label classification tasks in medical imaging. The best model achieved an average AUC-ROC score of 0.85 and an average F1 score of 0.39 across all 14 disease classifications present in the dataset.

Paper number 52:
Title: UBGAN: Enhancing Coded Speech with Blind and Guided Bandwidth Extension
Authors: Kishan Gupta, Srikanth Korse, Andreas Brendel, Nicola Pia, Guillaume Fuchs
Abstract: In practical application of speech codecs, a multitude of factors such as the quality of the radio connection, limiting hardware or required user experience necessitate trade-offs between achievable perceptual quality, engendered bitrate and computational complexity. Most conventional and neural speech codecs operate on wideband (WB) speech signals to achieve this compromise. To further enhance the perceptual quality of coded speech, bandwidth extension (BWE) of the transmitted speech is an attractive and popular technique in conventional speech coding. In contrast, neural speech codecs are typically trained end-to-end to a specific set of requirements and are often not easily adaptable. In particular, they are typically trained to operate at a single fixed sampling rate. With the Universal Bandwidth Extension Generative Adversarial Network (UBGAN), we propose a modular and lightweight GAN-based solution that increases the operational flexibility of a wide range of conventional and neural codecs. Our model operates in the subband domain and extends the bandwidth of WB signals from 8 kHz to 16 kHz, resulting in super-wideband (SWB) signals. We further introduce two variants, guided-UBGAN and blind-UBGAN, where the guided version transmits quantized learned representation as a side information at a very low bitrate additional to the bitrate of the codec, while blind-BWE operates without such side-information. Our subjective assessments demonstrate the advantage of UBGAN applied to WB codecs and highlight the generalization capacity of our proposed method across multiple codecs and bitrates.

Paper number 53:
Title: Binaural Target Speaker Extraction using Individualized HRTF
Authors: Yoav Ellinson, Sharon Gannot
Abstract: In this work, we address the problem of binaural target-speaker extraction in the presence of multiple simultane-ous talkers. We propose a novel approach that leverages the individual listener's Head-Related Transfer Function (HRTF) to isolate the target speaker. The proposed method is speaker-independent, as it does not rely on speaker embeddings. We employ a fully complex-valued neural network that operates directly on the complex-valued Short-Time Fourier transform (STFT) of the mixed audio signals, and compare it to a Real-Imaginary (RI)-based neural network, demonstrating the advantages of the former. We first evaluate the method in an anechoic, noise-free scenario, achieving excellent extraction performance while preserving the binaural cues of the target signal. We then extend the evaluation to reverberant conditions. Our method proves robust, maintaining speech clarity and source directionality while simultaneously reducing reverberation. A comparative analysis with existing binaural Target Speaker Extraction (TSE) methods shows that the proposed approach achieves performance comparable to state-of-the-art techniques in terms of noise reduction and perceptual quality, while providing a clear advantage in preserving binaural cues. Demo-page: this https URL

Paper number 54:
Title: Hierarchical Multi-Agent MCTS for Safety-Critical Coordination in Mixed-Autonomy Roundabouts
Authors: Zhihao Lin, Jianglin Lan, Shuo Liu, Zhen Tian, Dezong Zhao, Chongfeng Wei
Abstract: Navigating unsignalized roundabouts in mixed-autonomy traffic presents significant challenges due to dense vehicle interactions, lane-changing complexities, and behavioral uncertainties of human-driven vehicles (HDVs). This paper proposes a safety-critical decision-making framework for connected and automated vehicles (CAVs) navigating dual-lane roundabouts alongside HDVs. We formulate the problem as a multi-agent Markov Decision Process and develop a hierarchical safety assessment mechanism that evaluates three critical interaction types: CAV-to-CAV (C2C), CAV-to-HDV (C2H), and CAV-to-Boundary (C2B). A key contribution is our lane-specific uncertainty model for HDVs, which captures distinct behavioral patterns between inner and outer lanes, with outer-lane vehicles exhibiting $2.3\times$ higher uncertainty due to less constrained movements. We integrate this safety framework with a multi-agent Monte Carlo Tree Search (MCTS) algorithm that employs safety-aware pruning to eliminate high-risk trajectories while maintaining computational efficiency. The reward function incorporates Shapley value-based credit assignment to balance individual performance with group coordination. Extensive simulation results validate the effectiveness of the proposed approach under both fully autonomous (100% AVs) and mixed traffic (50% AVs + 50% HDVs) conditions. Compared to benchmark methods, our framework consistently reduces trajectory deviations across all AVs and significantly lowers the rate of Post-Encroachment Time (PET) violations, achieving only 1.0% in the fully autonomous scenario and 3.2% in the mixed traffic setting.

Paper number 55:
Title: MSR-Codec: A Low-Bitrate Multi-Stream Residual Codec for High-Fidelity Speech Generation with Information Disentanglement
Authors: Jingyu Li, Guangyan Zhang, Zhen Ye, Yiwen Guo
Abstract: Audio codecs are a critical component of modern speech generation systems. This paper introduces a low-bitrate, multi-scale residual codec that encodes speech into four distinct streams: semantic, timbre, prosody, and residual. This architecture achieves high-fidelity speech reconstruction at competitive low bitrates while demonstrating an inherent ability for information disentanglement. We construct a two-stage language model for text-to-speech (TTS) synthesis using this codec, which, despite its lightweight design and minimal data requirements, achieves a state-of-the-art Word Error Rate (WER) and superior speaker similarity compared to several larger models. Furthermore, the codec's design proves highly effective for voice conversion, enabling independent manipulation of speaker timbre and prosody. Our inference code, pre-trained models, and audio samples are available at this https URL.

Paper number 56:
Title: Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery
Authors: Antonio Martínez-Ibarra, Aurora González-Vidal, Adrián Cánovas-Rodríguez, Antonio F. Skarmeta
Abstract: The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems.

Paper number 57:
Title: Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty
Authors: Geon Roh, Jip Kim
Abstract: Dynamic line rating (DLR) enables greater utilization of existing transmission lines by leveraging real-time weather data. However, the elevated temperature operation (ETO) of conductors under DLR is often overlooked, despite its long-term impact on conductor health. This paper addresses this issue by 1) quantifying risk-based depreciation costs associated with ETO and 2) proposing a Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs in operational decisions. CHA-UC incorporates a robust linear approximation of conductor temperature and integration of expected depreciation costs due to hourly ETO into the objective function. Case studies on the Texas 123-bus backbone test system using NOAA weather data demonstrate that the proposed CHA-UC model reduces the total cost by 0.74\% and renewable curtailment by 85\% compared to static line rating (SLR) and outperforms quantile regression forest-based methods, while conventional DLR operation without risk consideration resulted in higher costs due to excessive ETO. Further analysis of the commitment decisions and the line temperature statistics confirms that the CHA-UC achieves safer line flows by shifting generator commitments. Finally, we examine the emergent correlation behaviors arising between wind generation and DLR forecast errors, and show that CHA-UC adaptively manages this effect by relaxing flows for risk-hedging conditions while tightening flows for risk-amplifying ones.

Paper number 58:
Title: An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement
Authors: Mobina Nankali, Michael W. Levin
Abstract: This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks.

Paper number 59:
Title: Bistatic Passive Sensing via CSI Power
Authors: Zhongqin Wang, J. Andrew Zhang, Kai Wu, Kuangda Chen, Min Xu, Y. Jay Guo
Abstract: Passive object sensing with communication signals is a key enabler of perceptive mobile networks and integrated sensing and communication. In practical bistatic deployments, transmitter-receiver asynchrony and hardware impairments introduce time-varying random phase offsets in Channel State Information (CSI). Together with limited bandwidth and small antenna arrays, these effects degrade sensing accuracy. This work proposes a lightweight bistatic passive tracking and sensing framework that operates in the CSI-power domain. CSI power suppresses these offsets without explicit phase calibration, while preserving target-induced sensing cues. We show that physically admissible constraints in the spatial-frequency domain induced by transmitter-receiver geometry can resolve the mirror ambiguity inherent to real-valued CSI power. Building on these properties, we develop a real-time 3D Fourier-domain processing pipeline that jointly recovers spectral (delay), spatial (angle), and temporal (Doppler) signatures. The resulting features are integrated into an online framework with adaptive motion detection, outlier suppression, and extended Kalman filter tracking with deterministic initialization, followed by position-refined micro-Doppler feature extraction for micro-motion sensing. Extensive experiments, including simulations, a real-world prototype using 3.1 GHz LTE signals, and an open-source gait recognition dataset, demonstrate the effectiveness of the proposed CSI-power-based framework for bistatic passive tracking and sensing.

Paper number 60:
Title: Optimal Transport-Based Decentralized Multi-Agent Distribution Matching
Authors: Kooktae Lee
Abstract: This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.

Paper number 61:
Title: SAS-Net: Scene-Appearance Separation Network for Robust Spatiotemporal Registration in Bidirectional Photoacoustic Microscopy
Authors: Jiahao Qin
Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional scanning enables rapid functional brain imaging but introduces severe spatiotemporal misalignment from coupled scan-direction-dependent domain shift and geometric distortion. Conventional registration methods rely on brightness constancy, an assumption violated under bidirectional scanning, leading to unreliable alignment. A unified scene-appearance separation framework is proposed to jointly address domain shift and spatial misalignment. The proposed architecture separates domain-invariant scene content from domain-specific appearance characteristics, enabling cross-domain reconstruction with geometric preservation. A scene consistency loss promotes geometric correspondence in the latent space, linking domain shift correction with spatial registration within a single framework. For in vivo mouse brain vasculature imaging, the proposed method achieves normalized cross-correlation (NCC) of 0.961 and structural similarity index (SSIM) of 0.894, substantially outperforming conventional methods. Ablation studies demonstrate that domain alignment loss is critical, with its removal causing 82% NCC reduction (0.961 to 0.175), while scene consistency and cycle consistency losses provide complementary regularization for optimal performance. The method achieves 11.2 ms inference time per frame (86 fps), substantially exceeding typical OR-PAM acquisition rates and enabling real-time processing. These results suggest that the proposed framework enables robust high-speed bidirectional OR-PAM for reliable quantitative and longitudinal functional imaging. The code will be publicly available at this https URL

Paper number 62:
Title: Evaluating CNN with Stacked Feature Representations and Audio Spectrogram Transformer Models for Sound Classification
Authors: Parinaz Binandeh Dehaghania, Danilo Penab, A. Pedro Aguiar
Abstract: Environmental sound classification (ESC) has gained significant attention due to its diverse applications in smart city monitoring, fault detection, acoustic surveillance, and manufacturing quality control. To enhance CNN performance, feature stacking techniques have been explored to aggregate complementary acoustic descriptors into richer input representations. In this paper, we investigate CNN-based models employing various stacked feature combinations, including Log-Mel Spectrogram (LM), Spectral Contrast (SPC), Chroma (CH), Tonnetz (TZ), Mel-Frequency Cepstral Coefficients (MFCCs), and Gammatone Cepstral Coefficients (GTCC). Experiments are conducted on the widely used ESC-50 and UrbanSound8K datasets under different training regimes, including pretraining on ESC-50, fine-tuning on UrbanSound8K, and comparison with Audio Spectrogram Transformer (AST) models pretrained on large-scale corpora such as AudioSet. This experimental design enables an analysis of how feature-stacked CNNs compare with transformer-based models under varying levels of training data and pretraining diversity. The results indicate that feature-stacked CNNs offer a more computationally and data-efficient alternative when large-scale pretraining or extensive training data are unavailable, making them particularly well suited for resource-constrained and edge-level sound classification scenarios.

Paper number 63:
Title: Rethinking RSSI for WiFi Sensing
Authors: Zhongqin Wang, J. Andrew Zhang, Kai Wu, Y. Jay Guo
Abstract: The Received Signal Strength Indicator (RSSI) is ubiquitously available on commodity WiFi devices but is commonly regarded as too coarse for fine-grained sensing. This paper revisits its sensing potential and presents WiRSSI, a bistatic WiFi sensing framework that enables RSSI-only passive human tracking and motion sensing. WiRSSI employs a transmitter and a receiver equipped with a three-antenna array (1Tx-3Rx), and is readily extensible to Multiple-Input Multiple-Output (MIMO) deployments. We first show how Channel State Information (CSI) power implicitly preserves phase-related motion modulation and how this relationship carries over to RSSI, indicating that RSSI can retain exploitable Doppler, Angle-of-Arrival (AoA), and delay cues. WiRSSI extracts Doppler-AoA features via a lightweight 2D Fast Fourier Transform (FFT) pipeline and infers bistatic delay from amplitude-only information in the absence of subcarrier-level phase. The estimated AoA and delay are then mapped to Cartesian coordinates and denoised to recover motion trajectories. Experiments in practical environments show that WiRSSI achieves median XY localization errors of 0.905 m, 0.784 m, and 0.785 m for elliptical, linear, and rectangular trajectories, respectively, compared with 0.574 m, 0.599 m, and 0.514 m from a representative CSI-based method. We further demonstrate RSSI-only gesture recognition on the Widar3.0 dataset, where WiRSSI features provide meaningful discriminative performance. These results suggest that, despite lacking subcarrier-level information compared with CSI, RSSI can support practical WiFi sensing as a complementary and hardware-friendly option when CSI is restricted, unreliable, or privacy-sensitive.

Paper number 64:
Title: Enroll-on-Wakeup: A First Comparative Study of Target Speech Extraction for Seamless Interaction in Real Noisy Human-Machine Dialogue Scenarios
Authors: Yiming Yang, Guangyong Wang, Haixin Guan, Yanhua Long
Abstract: Target speech extraction (TSE) typically relies on pre-recorded high-quality enrollment speech, which disrupts user experience and limits feasibility in spontaneous interaction. In this paper, we propose Enroll-on-Wakeup (EoW), a novel framework where the wake-word segment, captured naturally during human-machine interaction, is automatically utilized as the enrollment reference. This eliminates the need for pre-collected speech to enable a seamless experience. We perform the first systematic study of EoW-TSE, evaluating advanced discriminative and generative models under real diverse acoustic conditions. Given the short and noisy nature of wake-word segments, we investigate enrollment augmentation using LLM-based TTS. Results show that while current TSE models face performance degradation in EoW-TSE, TTS-based assistance significantly enhances the listening experience, though gaps remain in speech recognition accuracy.

Paper number 65:
Title: Usability Study of Security Features in Programmable Logic Controllers
Authors: Karen Li, Kopo M. Ramokapane, Awais Rashid
Abstract: Programmable Logic Controllers (PLCs) drive industrial processes critical to society, for example, water treatment and distribution, electricity and fuel networks. Search engines, e.g., Shodan, have highlighted that PLCs are often left exposed to the Internet, one of the main reasons being the misconfigurations of security settings. This leads to the question - why do these misconfigurations occur and, specifically, whether usability of security controls plays a part. To date, the usability of configuring PLC security mechanisms has not been studied. We present the first investigation through a task based study and subsequent semi-structured interviews (N=19). We explore the usability of PLC connection configurations and two key security mechanisms (i.e., access levels and user administration). We find that the use of unfamiliar labels, layouts and misleading terminology exacerbates an already complex process of configuring security mechanisms. Our results uncover various misperceptions about the security controls and how design constraints, e.g., safety and lack of regular updates due to the long-term nature of such systems, provide significant challenges to the realization of modern HCI and usability principles. Based on these findings, we provide design recommendations to bring usable security in industrial settings at par with its IT counterpart.

Paper number 66:
Title: Revolutionizing Future Connectivity: A Contemporary Survey on AI-empowered Satellite-based Non-Terrestrial Networks in 6G
Authors: Shadab Mahboob, Lingjia Liu
Abstract: Non-Terrestrial Networks (NTN) are expected to be a critical component of 6th Generation (6G) networks, providing ubiquitous, continuous, and scalable services. Satellites emerge as the primary enabler for NTN, leveraging their extensive coverage, stable orbits, scalability, and adherence to international regulations. However, satellite-based NTN presents unique challenges, including long propagation delay, high Doppler shift, frequent handovers, spectrum sharing complexities, and intricate beam and resource allocation, among others. The integration of NTNs into existing terrestrial networks in 6G introduces a range of novel challenges, including task offloading, network routing, network slicing, and many more. To tackle all these obstacles, this paper proposes Artificial Intelligence (AI) as a promising solution, harnessing its ability to capture intricate correlations among diverse network parameters. We begin by providing a comprehensive background on NTN and AI, highlighting the potential of AI techniques in addressing various NTN challenges. Next, we present an overview of existing works, emphasizing AI as an enabling tool for satellite-based NTN, and explore potential research directions. Furthermore, we discuss ongoing research efforts that aim to enable AI in satellite-based NTN through software-defined implementations, while also discussing the associated challenges. Finally, we conclude by providing insights and recommendations for enabling AI-driven satellite-based NTN in future 6G networks.

Paper number 67:
Title: Learning to Control Unknown Strongly Monotone Games
Authors: Siddharth Chandak, Ilai Bistritz, Nicholas Bambos
Abstract: Consider a strongly monotone game where the players' utility functions include a reward function and a linear term for each dimension, with coefficients that are controlled by the manager. Gradient play converges to a unique Nash equilibrium (NE) that does not optimize the global objective. The global performance at NE can be improved by imposing linear constraints on the NE, also known as a generalized Nash equilibrium (GNE). We therefore want the manager to control the coefficients such that they impose the desired constraint on the NE. However, this requires knowing the players' rewards and action sets. Obtaining this game information is infeasible in a large-scale network and violates user privacy. To overcome this, we propose a simple algorithm that learns to shift the NE to meet the linear constraints by adjusting the controlled coefficients online. Our algorithm only requires the linear constraints violation as feedback and does not need to know the reward functions or the action sets. We prove that our algorithm converges with probability 1 to the set of GNE given by coupled linear constraints. We then prove an L2 convergence rate of near-$O(t^{-1/4})$.

Paper number 68:
Title: Qubit-Efficient Quantum Annealing for Stochastic Unit Commitment
Authors: Wei Hong, Wangkun Xu, Fei Teng
Abstract: Stochastic Unit Commitment (SUC) has been proposed to manage the uncertainties driven by renewable integration, but it leads to significant computational complexity. When accelerated by Benders Decomposition (BD), the master problem becomes binary integer programming, which is still NP-hard and computationally demanding for classical methods. Quantum Annealing (QA), known for efficiently solving Quadratic Unconstrained Binary Optimization (QUBO) problems, presents a potential solution. However, existing quantum algorithms rely on slack variables to handle linear binary inequality constraints, leading to increased qubit consumption and reduced computational efficiency. To solve the problem, this paper introduces the Powell-Hestenes-Rockafellar Augmented Lagrangian Multiplier (PHR-ALM) method to eliminate the need for slack variables, making qubit consumption independent of the increasing number of Benders cuts. To further reduce the qubit overhead, quantum ADMM is applied to break large-scale SUC into smaller blocks for sequential solutions, which does not scale with the number of generators. Finally, the simulation results on both 4-generator and the IEEE bus-118 systems demonstrate the feasibility and scalability of the proposed algorithm, indicating its superior qubit and runtime efficiency over classical and baseline quantum approaches on the D-Wave QPU platform.

Paper number 69:
Title: Learning Hierarchical Sparse Transform Coding for 3DGS Compression
Authors: Hao Xu, Xiaolin Wu, Xi Zhang
Abstract: Current 3DGS compression methods largely forego the neural analysis-synthesis transform, which is a crucial component in learned signal compression systems. As a result, redundancy removal is left solely to the entropy coder, overburdening the entropy coding module and reducing rate-distortion (R-D) performance. To fix this critical omission, we propose a training-time transform coding (TTC) method that adds the analysis-synthesis transform and optimizes it jointly with the 3DGS representation and entropy model. Concretely, we adopt a hierarchical design: a channel-wise KLT for decorrelation and energy compaction, followed by a sparsity-aware neural transform that reconstructs the KLT residuals with minimal parameter and computational overhead. Experiments show that our method delivers strong R-D performance with fast decoding, offering a favorable BD-rate-decoding-time trade-off over SOTA 3DGS compressors.

Paper number 70:
Title: Wasserstein Barycenter Soft Actor-Critic
Authors: Zahra Shahrooei, Ali Baheri
Abstract: Deep off-policy actor-critic algorithms have emerged as the leading framework for reinforcement learning in continuous control domains. However, most of these algorithms suffer from poor sample efficiency, especially in environments with sparse rewards. In this paper, we take a step towards addressing this issue by providing a principled directed exploration strategy. We propose Wasserstein Barycenter Soft Actor-Critic (WBSAC) algorithm, which benefits from a pessimistic actor for temporal difference learning and an optimistic actor to promote exploration. This is achieved by using the Wasserstein barycenter of the pessimistic and optimistic policies as the exploration policy and adjusting the degree of exploration throughout the learning process. We compare WBSAC with state-of-the-art off-policy actor-critic algorithms and show that WBSAC is more sample-efficient on MuJoCo continuous control tasks.

Paper number 71:
Title: K-Function: Joint Pronunciation Transcription and Feedback for Evaluating Kids Language Function
Authors: Shuhe Li, Chenxu Guo, Jiachen Lian, Cheol Jun Cho, Wenshuo Zhao, Xiner Xu, Ruiyu Jin, Xiaoyu Shi, Xuanru Zhou, Dingkun Zhou, Sam Wang, Grace Wang, Jingze Yang, Jingyi Xu, Ruohan Bao, Xingrui Chen, Elise Brenner, Brandon In, Francesca Pei, Maria Luisa Gorno-Tempini, Gopala Anumanchipalli
Abstract: Evaluating young children's language is challenging for automatic speech recognizers due to high-pitched voices, prolonged sounds, and limited data. We introduce K-Function, a framework that combines accurate sub-word transcription with objective, Large Language Model (LLM)-driven scoring. Its core, Kids-Weighted Finite State Transducer (K-WFST), merges an acoustic phoneme encoder with a phoneme-similarity model to capture child-specific speech errors while remaining fully interpretable. K-WFST achieves a 1.39 % phoneme error rate on MyST and 8.61 % on Multitudes-an absolute improvement of 10.47 % and 7.06 % over a greedy-search decoder. These high-quality transcripts are used by an LLM to grade verbal skills, developmental milestones, reading, and comprehension, with results that align closely with human evaluators. Our findings show that precise phoneme recognition is essential for creating an effective assessment framework, enabling scalable language screening for children.

Paper number 72:
Title: NRSeg: Noise-Resilient Learning for BEV Semantic Segmentation via Driving World Models
Authors: Siyu Li, Fei Teng, Yihong Cao, Kailun Yang, Zhiyong Li, Yaonan Wang
Abstract: Birds' Eye View (BEV) semantic segmentation is an indispensable perception task in end-to-end autonomous driving systems. Unsupervised and semi-supervised learning for BEV tasks, as pivotal for real-world applications, underperform due to the homogeneous distribution of the labeled data. In this work, we explore the potential of synthetic data from driving world models to enhance the diversity of labeled data for robustifying BEV segmentation. Yet, our preliminary findings reveal that generation noise in synthetic data compromises efficient BEV model learning. To fully harness the potential of synthetic data from world models, this paper proposes NRSeg, a noise-resilient learning framework for BEV semantic segmentation. Specifically, a Perspective-Geometry Consistency Metric (PGCM) is proposed to quantitatively evaluate the guidance capability of generated data for model learning. This metric originates from the alignment measure between the perspective road mask of generated data and the mask projected from the BEV labels. Moreover, a Bi-Distribution Parallel Prediction (BiDPP) is designed to enhance the inherent robustness of the model, where the learning process is constrained through parallel prediction of multinomial and Dirichlet distributions. The former efficiently predicts semantic probabilities, whereas the latter adopts evidential deep learning to realize uncertainty quantification. Furthermore, a Hierarchical Local Semantic Exclusion (HLSE) module is designed to address the non-mutual exclusivity inherent in BEV semantic segmentation tasks. Experimental results demonstrate that NRSeg achieves state-of-the-art performance, yielding the highest improvements in mIoU of 13.8% and 11.4% in unsupervised and semi-supervised BEV segmentation tasks, respectively. The source code will be made publicly available at this https URL.

Paper number 73:
Title: Characterizing State Space Model and Hybrid Language Model Performance with Long Context
Authors: Saptarshi Mitra, Rachid Karami, Haocheng Xu, Sitao Huang, Hyoukjun Kwon
Abstract: Emerging applications such as AR are driving demands for machine intelligence capable of processing continuous and/or long-context inputs on local devices. However, currently dominant models based on Transformer architecture suffers from the quadratic computational and memory overhead, which hinders applications required to process long contexts. This has spurred a paradigm shift towards new architectures like State Space Models (SSMs) and SSM-Transformer hybrid models, which provide near-linear scaling. The near-linear scaling enabled efficient handling of millions of tokens while delivering high performance in recent studies. Although such works present promising results, their workload characteristics in terms of computational performance and hardware resource requirements are not yet thoroughly explored, which limits our understanding of their implications to the system level optimizations. To address this gap, we present a comprehensive, compara-ive benchmarking of carefully selected Transformers, SSMs, and hybrid models specifically for long-context inference on consumer and embedded GPUs. Our analysis shows that SSMs are well-suited for on-device AI on consumer and embedded GPUs for long context inferences. While Transformers are up to 1.9x faster at short sequences (<8K tokens), SSMs demonstrate a dramatic performance inversion, becoming up to 4x faster at very long contexts (~57K tokens), thanks to their linear computational complexity and ~64% reduced memory footrprint. Our operator-level analysis reveals that custom SSM kernels like selective scan despite being hardware-aware to minimize memory IO, dominate the inference runtime on edge platforms, accounting for over 55% of latency due to their sequential, element-wise nature. To foster further research, we will open-source our characterization framework.

Paper number 74:
Title: Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation
Authors: Haiyun Zhang, Stefano Dalla Gasperina, Saad N. Yousaf, Toshimitsu Tsuboi, Tetsuya Narita, Ashish D. Deshpande
Abstract: Hand exoskeletons are critical tools for dexterous teleoperation and immersive manipulation interfaces, but achieving accurate hand tracking remains a challenge due to user-specific anatomical variability and donning inconsistencies. These issues lead to kinematic misalignments that degrade tracking performance and limit applicability in precision tasks. We propose a subject-specific calibration framework for exoskeleton-based hand tracking that estimates virtual link parameters through residual-weighted optimization. A data-driven approach is introduced to empirically tune cost function weights using motion capture ground truth, enabling accurate and consistent calibration across users. Implemented on the Maestro hand exoskeleton with seven healthy participants, the method achieved substantial reductions in joint and fingertip tracking errors across diverse hand geometries. Qualitative visualizations using a Unity-based virtual hand further demonstrate improved motion fidelity. The proposed framework generalizes to exoskeletons with closed-loop kinematics and minimal sensing, laying the foundation for high-fidelity teleoperation and robot learning applications.

Paper number 75:
Title: An Adaptive CMSA for Solving the Longest Filled Common Subsequence Problem with an Application in Audio Querying
Authors: Marko Djukanovic, Christian Blum, Aleksandar Kartelj, Ana Nikolikj, Guenther Raidl
Abstract: This paper addresses the Longest Filled Common Subsequence (LFCS) problem, a challenging NP-hard problem with applications in bioinformatics, including gene mutation prediction and genomic data reconstruction. Existing approaches, including exact, metaheuristic, and approximation algorithms, have primarily been evaluated on small-sized instances, which offer limited insights into their scalability. In this work, we introduce a new benchmark dataset with significantly larger instances and demonstrate that existing datasets lack the discriminative power needed to meaningfully assess algorithm performance at scale. To solve large instances efficiently, we utilize an adaptive Construct, Merge, Solve, Adapt (CMSA) framework that iteratively generates promising subproblems via component-based construction and refines them using feedback from prior iterations. Subproblems are solved using an external black-box solver. Extensive experiments on both standard and newly introduced benchmarks show that the proposed adaptive CMSA achieves state-of-the-art performance, outperforming five leading methods. Notably, on 1,510 problem instances with known optimal solutions, our approach solves 1,486 of them -- achieving over 99.9% optimal solution quality and demonstrating exceptional scalability. We additionally propose a novel application of LFCS for song identification from degraded audio excerpts as an engineering contribution, using real-world energy-profile instances from popular music. Finally, we conducted an empirical explainability analysis to identify critical feature combinations influencing algorithm performance, i.e., the key problem features contributing to success or failure of the approaches across different instance types are revealed.

Paper number 76:
Title: A Spectral Framework for Graph Neural Operators: Convergence Guarantees and Tradeoffs
Authors: Roxanne Holden, Luana Ruiz
Abstract: Graphons, as limits of graph sequences, provide an operator-theoretic framework for analyzing the asymptotic behavior of graph neural operators. Spectral convergence of sampled graphs to graphons induces convergence of the corresponding neural operators, enabling transferability analyses of graph neural networks (GNNs). This paper develops a unified spectral framework that brings together convergence results under different assumptions on the underlying graphon, including no regularity, global Lipschitz continuity, and piecewise-Lipschitz continuity. The framework places these results in a common operator setting, enabling direct comparison of their assumptions, convergence rates, and tradeoffs. We further illustrate the empirical tightness of these rates on synthetic and real-world graphs.

Paper number 77:
Title: Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes
Authors: Jonas Hein, Lazaros Vlachopoulos, Maurits Geert Laurent Olthof, Bastian Sigrist, Philipp Fürnstahl, Matthias Seibold
Abstract: Purpose: Surgical scene understanding is key to advancing computer-aided and intelligent surgical systems. Current approaches predominantly rely on visual data or end-to-end learning, which limits fine-grained contextual modeling. This work aims to enhance surgical scene representations by integrating 3D acoustic information, enabling temporally and spatially aware multimodal understanding of surgical environments. Methods: We propose a novel framework for generating 4D audio-visual representations of surgical scenes by projecting acoustic localization information from a phased microphone array onto dynamic point clouds from an RGB-D camera. A transformer-based acoustic event detection module identifies relevant temporal segments containing tool-tissue interactions which are spatially localized in the audio-visual scene representation. The system was experimentally evaluated in a realistic operating room setup during simulated surgical procedures performed by experts. Results: The proposed method successfully localizes surgical acoustic events in 3D space and associates them with visual scene elements. Experimental evaluation demonstrates accurate spatial sound localization and robust fusion of multimodal data, providing a comprehensive, dynamic representation of surgical activity. Conclusion: This work introduces the first approach for spatial sound localization in dynamic surgical scenes, marking a significant advancement toward multimodal surgical scene representations. By integrating acoustic and visual data, the proposed framework enables richer contextual understanding and provides a foundation for future intelligent and autonomous surgical systems.

Paper number 78:
Title: GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing
Authors: Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin
Abstract: Human perception for effective object tracking in 2D video streams arises from the implicit use of prior 3D knowledge and semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings, while neglecting 3D geometric cues, making them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to infer geometric cues from only a few 2D images. To address the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing. By leveraging null-space constraints during model updates, it incorporates geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking. The project page is available at this https URL.
    